\chapter{Diagramming machine learning
\label{ch:diagram}

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, tidy=TRUE, fig.height=8, 
                      echo=FALSE,  warning=FALSE, message=FALSE, dev='pdf')
options(xtable.comment = FALSE)
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(),'../ml_lit/all_refs.sqlite3')
library(ggplot2)
```


> Machine learning is not magic; it cannot get something from nothing. What it does is get more from less. Programming, like all engineering, is a lot of work: we have to build everything from scratch. Learning is more like farming, which lets nature do most of the work. Farmers combine seeds with nutrients to grow crops. Learners combine knowledge with data to grow programs. [@Domingos_2012, 81] \index{Domingos, Pedro}

>Take the verb 'moving': if we write 'it-moving' we are expressing a multiplicity in a diagrammatic way. It-moving indicates a complex abstract machine which can appear independent of any subjective tendency -- it could refer to an individual, an army, an insect, an object, a machine, an emotion, an idea. It allows for all the possibilities of moving, so that the verb retains it machinic character [@Guattari_1984, 139]\index{Guattari, Félix}.

Many different tendencies shape what is happening to data today, but our  sense of the potentials of data and calculation is closely linked to what Pedro Domingos terms 'a lot of work' done by machine learners. Although it sounds a bit banal, there is quite a lot at stake and many complications in this work. The problem is: who works on what? And conversely, and slightly more awkwardly, *what* works on who? In both of the epigraphs above, one from a renowned machine learning researcher and the other from the French philosopher, Félix Guattari, this flipping between who and what can be observed. In Pedro Domingo's talk of 'learners,' we might find it hard to decide what the end point is: a program or learning something? These slightly awkward formulations, with their emphasis on 'diagrammatic' combinations are worth pursuing I believe because they help us to make sense of an immense Magellanic constellation of documents, software, publications, blog pages, books, spreadsheets, databases, data centre architectures,  whiteboard and blackboard diagrams, and an inordinate amount of talk and visual media in orbit around machine learning.

The changes in calculative practice associated with machine learning work on multiple levels, ranging from infrastructures and chip architectures through to mathematical functions and categorisations with significant social and economic implications. In this chapter, however, I attend to a seemingly much more banal set of practices concerning data. On the one hand, ways of working with  data have shifted substantially over the last decade or so due to the growth in open source programming languages and as a part of the broader and well-known expansion of digital media cultures [@Couldry_2013]. The fact that scientists, software developers and data analysts use programming languages such as `python` and `R` \index{Python} \index{R programming language} just as much as commercial statistical and data software packages such as Matlab, SAS or SPSS is symptomatic of shifts in calculative culture [@Muenchen_2014]. Scientific research, which has long relied on counting and calculation, increasingly organises and processes data more comprehensively because workflows, datasets, algorithms and databases can be quickly and flexibly assembled in code. (Scientific computing languages such as FORTRAN  -- 'Formula Translator' -- have long underpinned scientific research and engineering applications in various fields [@Campbell-Kelly_2003, 34-35].\index{FORTRAN}) On the other hand, several decades of concentrated research and intensive application of statistical and machine learning algorithms in science, government, industry and commerce have gradually developed fairly powerful ways of automating the construction of models that classify and predict events and associations between things, people, processes, etc. This means that programs are being written differently (and this is why Domingos speaks of 'growing' programs), and that they implement and concentrate new layers of abstraction. In some ways, this different mode of writing code is precisely the level of abstraction at which we might need to move in order to know and come to grips with contemporary compositions of power and subjectivity. 

## A diachronic diagram of reading machine learning

In the course of writing this book, as well as reading the academic textbooks, popular how-to books, software manuals, help documents and blog-how-to posts,  I attended graduate courses in Bayesian statistics, genomic data analysis, data mining, and missing data. Significantly, I also participated in the online machine learning courses and some machine learning competitions.[^1.4] These are all typical activities for people learning to do machine learning. Importantly, these courses, books, competitions and programming languages are widely viewed and used. Andrew Ng's \index{Ng, Andrew} machine learning course on Coursera (of which he is co-founder, along with Daphne Koller, another machine learning scientist from Stanford) \index{Koller, Daphne}, has a typical enrolment of 100,000. Youtube videos of his Stanford University lectures have cumulative viewing figures of around 500,000 [@Ng_2008]. Amidst this avalanching mass, a  single highly cited and compendious textbook, _Elements of Statistical Learning: Data Mining, Inference, and Prediction_ [@Hastie_2009], currently in its second edition, can be seen from almost any point of the terrain.[^1.12] \index{\textit{_Elements of Statistical Learning_ }} The authors of the book, Jeff Hastie, Rob Tibshirani and Jerome Friedman \index{Hastie, Jeff} \index{Tibshirani, Rob} \index{Friedman, Jerome} are statisticians working at Stanford and Columbia University. (Statisticians and computer scientists from Stanford University loom large in the world of machine learning, perhaps due to their proximity to Silicon Valley.)  In terms of scientific publications, this book is like the Death Star in the _Stars Wars_ film series. It is a  massive object, densely bristling with diagrams, equations, tables, algorithms,  graphs and references to other scientific literature. It has some hyperobject-like tendencies [@Morton_2013] in the range of references, it's combinations of code, diagram, equation, scientific disciplines and computational elements, and perhaps in the somewhat viscous, interobjectively diverse referentiality that impinges on any reading of it. \index{hyperobject} Like the online machine learning courses and programming books I discuss below, _Elements of Statistical Learning_  combines statistical science with various algorithms to 'learn from data' [@Hastie_2009, 1]. The 768 pages of this often tersely written and quite mathematical book range across various kinds of problems (identifying spam email, predicting risk of heart disease, recognising handwritten digits, etc.), and various machine learning techniques, methods and algorithms (linear regression, k-nearest neighbours, neural networks, support vector machines, the Google Page Rank algorithm, etc.). This is not the only juggernaut machine learning texts.  I could just have well cleaved to Alpaydin's _Introduction to Machine Learning_ [@Alpaydin_2010]  (a more computer science-base account), to Christopher Bishop's  heavily mathematical _Pattern recognition and machine learning_ [@Bishop_2006], Brian Ripley's luminously illustrated and almost coffee-table formatted _Pattern Recognition and Neural Networks_ [@Ripley_1996] \index{Ripley, Brian}, Tom Mitchell's  earlier artificial intelligence-centred _Machine learning_ [@Mitchell_1997] \index{Mitchell, Tom}, Peter Flach's  perspicuous _Machine Learning: The Art and Science of Algorithms that Make Sense of Data_ [@Flach_2012] \index{Flach, Peter}, or further afield, the sobering and laconic _Statistical Learning for Biomedical Data_ [@Malley_2011].  These and quite a few other recent machine learning textbooks display a range of emphases, ranging from the highly theoretical to the very practical, from an orientation to statistical inference to an emphasis on computational processes, from  science to commercial applications. 

[^1.12]: The complete text of the book can be downloaded from the website [http://statweb.stanford.edu/~tibs/ElemStatLearn/](http://statweb.stanford.edu/~tibs/ElemStatLearn/). At the end of short intensive course on data minin at the Centre of Postgraduate Statistics, Lancaster University, the course convenor, Brian Francis, recommended this book as the authoritative text. Some part of me rues that day. That book is a poisoned chalice; that is, something shiny, valuable but also somewhat toxic. 

The book attracts different styles of reading. It is often cited by academic machine learning practitioners as an authoritative guide. On the other hand, students participating in new data science courses often come from different disciplinary backgrounds and find the tome unhelpful (see the comment by students during an introductory data science course documented in [@Schutt_2013]). Whether the citations are friendly or not, Google Scholar reports over 20,00 citations of the book http://scholar.google.com/scholar?hl=en&q=elements+of+statistical+machine+learning, October 2014), a huge citation count by any standards. (Michel Foucault's _The History of Sexuality: an Introduction_, one of the most highly cited book in the humanities,  receives about the same number of citations.) The citations that [@Hastie_2009] as well as its previous edition [@Hastie_2001] receive do not arrive principally from machine learning researchers. They come from a wide variety of fields. It is hard to find a field of contemporary science, engineering, natural, applied, health and indeed social science that has not cited it. A Thomson-Reuters Scientific 'Web of Science'(TM) search for references citing either the first or second edition of [@Hastie_2009] yields around 9000 results. These  publications sprawl across well over 100 different fields of research.  While computer science, mathematics and statistics dominate, a very diverse set of references comes from disciplines from archaeology, through fisheries and forestry, genetics, robotics, telecommunications and toxicology ripple out from this book since 2001. Table \ref{tab:fields_citing_hastie} shows the top 20 fields by count. One could learn something about the diagrammatic movement of machine learners  from that reference list, which itself spans biomedical, engineering, telecommunications, ecology, operations research and many other fields. While it is not surprising to see computer science, mathematics and engineering appearing at highest concentration in the literature, the molecular biology, control and automation, operation research, business and public health soon appear, suggesting something of the propagating energy of machine learning. 

```{r hastie_field, results='asis', cache=TRUE}
library(stringr)
library(xtable)
query = 'select * from basic_refs where anchor like "hastie%"'
res = dbGetQuery(con, query)
sc = res$SC
fields = str_trim(unlist(str_split(sc, ';')))
tab = xtable(as.data.frame(sort(table(fields), decreasing=TRUE)[1:20]), label = 'tab:fields_citing_hastie', caption = 'Subject categories of academic research literature citing \textit{Elements of Statistical Learning} 2001-2015. These subject categories derive from Thomson-Reuter \textit{Web of Science}.' )
print(tab, comment=FALSE)
```

```{r hastie_pages, engine='python', cache=TRUE, echo=FALSE}

import pandas as pd
import re
import os
import sys

def load_records(data_dir):
    """Return dataframe of all records,
    with new column of cited references as list"""

    # I saved all the WoS full records for the search term in this directory
    files = os.listdir(data_dir)
    wos_df = pd.concat([pd.read_table(wos_df, sep='\t', index_col=False)
                        for wos_df in [data_dir+f for f in files
                        if f.count('.txt') > 0]])
    wos_df = wos_df.drop_duplicates()

    #fix index
    index = range(0, wos_df.shape[0])
    wos_df.index = index

    #to get all cited refs
    if wos_df.columns.tolist().count('CR') > 0:
        cited_refs = [list(re.split(pattern='; ',
                                    string=str(ref).lower().lstrip().rstrip()))
                                    for ref in wos_df.CR]
        # add as column to dataframe
        wos_df['cited_refs'] = cited_refs

    # normalise authors
    if wos_df.columns.tolist().count('AF') > 0:
        wos_df.au = [str(au).lower().lstrip().rstrip() for au in wos_df.AF]

    return wos_df


def clean_fields(wos_df):

    """ Returns dataframe with a new field 'field' that lists
    the fields for each reference"""

    wos_df['fields'] = wos_df.SC.dropna().str.lower().str.split('; ')
    return wos_df


def clean_topics(wos_df):
    """Wos.DE field has a mixture of topics and techniques.
    -------------------------------------
    Returns a cleaned-up, de-pluralised list version of all the topics and techniques
    """

    wos_df['topics'] = wos_df.DE.dropna().str.lower().str.strip().str.replace('\(\w+ \)', '').str.replace('($  )|(  )', ' ')
    # wos_df['topics'] = wos_df.topics.str.replace("[\(\](\w+ ?)+[\)\]]\W*",  '')
    wos_df.topics = wos_df.topics.str.replace('svm', 'support vector machine')
    wos_df.topics = wos_df.topics.str.replace('support vector machine(\w*)',
                                            'support vector machine')
    wos_df.topics = wos_df.topics.str.replace('(artificial neural network)|(neural networks)|(neural net\b)',
                                            'neural network')
    wos_df.topics = wos_df.topics.str.replace('decision tree(.*)', 'decision tree')
    wos_df.topics = wos_df.topics.str.replace('random forest(\w+)', 'random forest')
    # Web of science topics often have  a bracket expansion
    wos_df['topics'] = wos_df.topics.str.replace("(\w+)\W*[\[\(].+[\)\]]\W*", '\\1 ')
    wos_df.topics = wos_df.topics.str.split('; ')
    return wos_df

def keyword_counts(wos_df):
    """ Returns a dictionary with keyword counts"""
    de_all = [d for de in wos_df.topics.dropna() for d in de]
    key_counts = collections.Counter(de_all)
    return key_counts


    df = load_records('data/hastie_elem_WOS/')
    print('There are %s records in the dataset' % df.shape[0])
    df = clean_topics(df)
    df = clean_fields(df)

    print('%s topic fields are null' % sum(df.topics.isnull()))
    print('%s abstract fields are null' % sum(df.AB.isnull()))
    print('%s keywords Plus fields are null' % sum(df.ID.isnull()))
    print('% s author fields are null' % sum(df.AF.isnull()))

    all_fields = sorted([e for el in df.fields.dropna() for e in el])
    fields_set = set(all_fields)
    field_counts = {e: all_fields.count(e) for e in fields_set}

    print('%s different fields appear in the literature citing Hastie (2001/2009)' % len(fields_set))
    field_counts_s = sorted(field_counts.iteritems(), key=lambda(k, v):(-v, k))
    field_counts_s[0:30]
    major_fields = {f:v for f,v in field_counts.iteritems() if v > 3 or f is not 'computer science'}
    print(len(field_counts), len(major_fields))
    kw = keyword_counts(df)
    kw.most_common()[:50]
    #find the most commonly cited pages
    hastie = df.CR.str.findall('Hastie.*?;')
    hastie = hastie.map(lambda x:  x[0] if len(x) ==1 else '')
    hastie_pages = hastie[hastie.str.contains('P')]
    pages = hastie_pages.str.findall('\d{1,3};').map(lambda x: x[0] if len(x) ==1 else '').str.replace(';', '')
    pages = pages[pages != '']
    pages = pages.astype('int')
    pages_counted = pages.value_counts()
    pages_counted_sorted = pages_counted.sort_index()
    pages_counted_sorted.to_csv('data/hastie_pages.csv')

```

```{r plot_hastie_pages, results='hide', include=FALSE, cache=TRUE}
library(ggplot2)
hastie_pages = read.csv('data/hastie_pages.csv')
colnames(hastie_pages) = c('page', 'reference_count')
plt = ggplot(hastie_pages, aes(x =page, y = reference_count))
plt + geom_bar(stat = 'identity')
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/plot_hastie_pages-1.pdf}
        \caption[Pages cited from \textit{Elements of Statistical Learning }]{Pages cited from \textit{Elements of Statistical Learning} by academic publications in all fields.}
  \label{fig:hastie_pages}
\end{figure}

So we know that _Elements of Statistical Learning_ passes into many fields. But what do people read in the book? In general, the thousands of citations of the book themselves comprise a diachronic diagram of readings of the book, and their relative concentrations and sparsities suggest there may be specific sites of engagement in the techniques, approaches and machines that the book describes. Of the around 760 pages in [@Hastie_2009] and [@Hastie_2001], around `r dim(hastie_pages)[1]` distinct pages are referenced in the citing literature. As Figure \ref{ref:hastie_pages} indicates, certain portions of the book are much more heavily cited than others. This distribution of page references in the literature that cites _Elements of Statistical Learning_ is a rough guide to how the book has been read in different settings. For instance, the most commonly cited page in the book is page `r hastie_pages$page[which.max(hastie_pages$reference_count)]`. That page begins a section called 'Non-negative Matrix Factorization', \index{Non-negative matrix factorization} a technique frequently used to process digital images to compress their visual complexity into a simpler set of visual signals [@Hastie_2009, 553]. It is particularly powerful because it, as Hastie and co-authors write, 'learns to represent faces with a set of basis images resembling parts of faces' [@Hastie_2009, 555]. (So `kittydar`, which doesn't use NMF, might do better if it did, because it could work just with parts of the images that lie somewhere near the parts of a cat's face -- its nose, its eyes, its ears.\index{`kittydar`}) \index{face recognition}

Conversely, the semiotic machinery of the book generates vectors and orbital trajectories that veer and peel off in many different directions. The hyperobject-like aspect of the book, its somewhat forbidding citational presence in the literature, comes from the vast semiotic weave of equations, diagrams, tables, algorithms, bibliographic apparatus, and numbers wreathed in typographic luxuriance drawn from many other sources. For instance, in terms of outgoing references, _Elements of Statistical Learning_ webs together a field of scientific and technical work with data and predictive models ranging across half a century. The reference list beginning at page 699 [@Hastie_2009, 699] runs for around 35 pages, and the five hundred or so references there point in many directions. The weave of these elements differs greatly from documents in the humanities or social sciences, and, almost before anything else, prompts attention to the problem of reading parts and fragments, and relating to an object or perhaps an apparatus in the sense that Karen Barad ascribes to experimental setups [@Barad_2007]. 

```{r hastie_references, results='hide', include=FALSE, cache=TRUE, echo=FALSE}
system('pdftotext -f 717 -l 746 ../ml_lit/hastie_elem/hastie_elements_2009.pdf hastie_references.txt')
refs_text = read.delim('../ml_lit/hastie_elem/hastie_references.txt', sep='\n', stringsAsFactors=FALSE)
refs_text = readLines('../ml_lit/hastie_elem/hastie_references.txt')
refs_parsed = paste(refs_text, sep=' ', collapse='\n')
refs_split = unlist(str_split(refs_parsed, '\\.\n'))
refs_clean = str_trim(str_replace_all(refs_split, '\n', ' '))
years = str_replace_all(str_extract(refs_clean, '\\(\\d{4}\\)'), '[()]', replacement='')
years_df = as.data.frame(table(years))
rowcount = dim(years_df)[1]
years_df = years_df[1:rowcount-1,]
colnames(years_df) = c('Year', 'Citations')
g2 = ggplot(years_df, aes(x=as.Date(Year, '%Y'), y=Citations, group=1)) + geom_freqpoly(stat='identity')
g2 + ylab('Publications cited/year') + xlab('Year of publication') 
```

\begin{figure}
  \centering
      \includegraphics[width=0.9\textwidth]{figure/hastie_references-1.pdf}
        \caption{Publications cited by \textit{Elements of Statistical Learning}. The references range over almost 80 years, with peaks in late 1970s, late 1980s, mid-1990s and mid-2000s}
  \label{fig:hastie_cited_refs}
\end{figure}


While many of these references either point to Hastie, Tibshirani or Friedman's own publications, or that of their statistical colleagues, the references show that these authors are also roving quite widely in other fields and over time (see Figure \ref{fig:hastie_cited_refs}. _Elements of Statistical Learning_ as a text is processing, assimilating and recombining techniques, diagrams and data from many different places and times. Both the inward and outward movements of citation suggest that the book, like much in field of  machine learning, has a wave function or matrix-like character that constantly superimposes and transposes elements across boundaries and barriers. The implication here is that machine learning as a field has a highly circulatory texture, and in this respect differs somewhat from the classical understandings of scientific disciplines as bounded by communities of practice, norms and problems (as for instance, in Thomas Kuhn's account of normal science [@Kuhn_1996]. \index{Kuhn, Thomas}  


