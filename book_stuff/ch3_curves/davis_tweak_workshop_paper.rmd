# The vitality of data methods: case study of R

Adrian Mackenzie, Cesagen, Lancaster University
a.mackenzie@lancaster.ac.uk

## Abstract (238)

Data (numbers and text) seems to have a certain primacy today that they maybe didn't have even a few years ago. In this setting, the social life of methods for working with data might be worth analysing more closely. The statistical programming and graphics environment R (www.r-project.org) is one place that data methods move through. It is said that R has recently overtaken all other statistical software as the most popular way to work with data. The structure of R as a programming language, and the organisation of the R project as large package repository offer some explanation for its popularity. The ways in which academic research in many scientific fields ranging from astrophysics to finance, from ecology to neurology is quickly implemented in R packages testifies to the affordances of a common statistical programming language and software platform. The plethora of packages that interface to various data sources and formats ranging from DNA sequences to currency exchange values might be another. All of this could be analysed from an empirical standpoint using fairly standard social science research methods. Rather than seeing R as a site where knowledge production drives the development of techniques and methods of working with data, what it would mean to see R as a place whose vitality and liveliness lies much closer to the contagiousness of Youtube videos? What would seeing R as statistical media add to our understanding of the data deluge?  

## 1. Introduction 

### a. Working with R: acting out or participating?

Methods of working with data are not fixed.  The statistical programming language R is a typical tool in the visual and mathematical cultures of science. Much of what appears in scientific publications and presentations - graphs, plots, etc – is made or could be made using R. R is also typical of what has allowed contemporary network media to take shape– it is a programming language, an open source platform, and the result of much collective, distributed work. The R package repository CRAN is like the Perl programming languages CPAN.

It seems to me that R is a place where contemporary desires and beliefs about the value of data might be found entangled with habits and practices of working with network media.  The question for me is whether R is, to use a psychoanalytic term, a form of 'acting out' (i.e. performing an action rather than managing the impulse to perform it; more technically: 'the present situation, somehow associatively connected with the repressed content, is used as an occasion for the discharge of repressed energies; the cathexis is displaced from the repressed memories to the present “derivative”, and this displacement makes the discharge possible' (Fenichel, 1945)⁠ ).  Or can work with R be read as getting more real, as living, as vital, as participating in the present moment?

My reflections derive from what could be regarded as a couple of years of quite intensely unproductive work with R – mostly learning to scrape, cut, reshape, sort and plot numbers extracted from text, from websites, from databases, from publications, but also attending courses, reading and playing around with various statistical modelling approaches and data mining techniques.This has occasioned much frustration, as well as some interesting results in terms of numbers, tables, graphics, and particular curves relating to some particular things that I study but won't be talking about (synthetic biology, biological wikis and next generation DNA sequencing, amongst other things). It has also has triggered a much broader and wide ranging interest in how data is being handled in various settings, especially in the life sciences, but also in clinics, in field sciences, in social network media and in a couple of other places. The methods and techniques of working with data have become an object of obsession for me. And that turn of events is quite interesting in its own right, assuming that I'm somehow typical in this regard. 

A wide variety of people use R – statisticians, scientists, programmers, business analysts, etc. Some of these people have been using R for almost 20 years. Many are likely to have started using it in the last few years. Although I'm very interested in how R is being used in various settings (insurance companies, Google, Facebook, NYT, Guardian, eBirds, etc), I'm perhaps more interested in what moves between these different settings. Techniques, methods, tools and practices are moving around in the form of R code, R packages and R-produced graphics. The kinds of questions I'm asking about what is happening to data in R are hardly the ones that are uppermost in most online or print discussions of R; they are not the ones that pragmatically matter to participants or proponents of R development. But why is R somewhat contagious? What is it growing rapidly? What is at stake in its growth?

## b. What role do we play in this? What do we do?

There is a debate in sociology at the moment about the crisis of empirical work (Savage & Burrows 2007; Savage & Burrows 2009). The argument is that data analytics  obviates most of the methods – surveys, interviews, focus groups, ethnography, etc – that have been the painstaking mainstay of sociology for the last half century. Market research and business analytics can do anything sociologists do, and do it bigger and better. Also they can do it without social theory, as Chris Anderson, an editor at Wired  argued several years ago (Anderson 2008). 
What should critical researchers do when faced by much increased availability of data afforded by network media? Of course, there is the classical interpretive work of analysing and evaluating the claims being made about data, especially by contextualising how belief in and desire for more data is connected to markets for IT and IT services, or how it more broadly fits with global tendencies and policies concerning the knowledge economy or informatic capitalism. 
However, perhaps more riskily, it seems worthwhile beginning to experiment with platforms, techniques and approaches that directly engage with data, in order to see what scope for invention or creation of new things there might be there. Here I'm primarily interested in how and where we put ourselves in the deluge, and how we invest ourselves in data and in statistics. This could be framed in many different ways. I will explore the following idea: what if the belief in and desire for data resulted from belief and desire in data? That is, what if we saw the current growth in interest, investment or reliance on data as occasioned by something in the data itself? 
## c. To discuss about R
There is much to discuss in R. I will focus on three different facets – 
i. curves, graphics and plotting; 
ii. media, data deluge and data-munging; 
iii. probability, statistics and population trends.

## 2. A theory of curves, graphics & plots

### a. Curves and the visibility of R
I want to begin by talking about plots, charts and curves – the kinds of graphics seen in many scientific publications, but also in newspapers, magazines and many different online or screen-based settings. It is hard to say for sure (I haven't done the empirical work to check) whether there is a growth curve for curves. I expect that more curves are being plotted today than in 10 or 20 years ago. If the curves that show the growth of R are correct (Muenchen, 2011)⁠, then there should be more curves appearing. 
When I say 'curves,' I'm including lines, especially lines that slope up or slow down. Lines are a special case of curves. There is a deeper problem with straight lines we need to return to, but for the moment, they are just another kind of curve or contour. It seems to me that despite the proliferation of network or map-based visualisations, curves are perhaps still the primary form in which most data ends up appearing in the world.

 Even when lines are not drawn between points (as for instance, in the plotting of data points in the plot below (Durbin et al. 2010, p.1067)), the distribution of points is usually something to do with the peaks and troughs of curves. 

Why are curves important? Practically, they are a kind of endpoint or final distillation of all the work that goes in getting, cleaning, organising and analysing data. Whether they are a simple graphical summary of the distribution of values in a spreadsheet, or whether they represent a highly sophisticated synthesis of empirical data and statistical distributions derived from a complex mathematical model, curves are the most visible result of work with data. They are also, as we will, what supports or underlies data analysis.

### b. Curves are movements
One of the key claims for R is that it makes curves. Not that plenty of other software can't draw curves quickly, and without needing to write code. Charts can easily be generated from spreadsheets, for instance. However, spreadsheet charts stay close to the tables of data from which they derive. The social life of the spreadsheet is, we might say, a bit closeted in comparison to the gregarious life of R code. 
The appeal of R as a way of drawing curves is both pragmatic and principled. Pragmatically, the development of R is closely coupled with the imperatives of scientific publication. For instance, it supports various print-ready and screen-ready image formats. More importantly, as a programming language, it supports countless small adjustments and variations in how the curve is plotted (particularly in more recent graphics packages such as ggplot2). Whole different approaches to graphing or plotting can be added or laid over existing approaches (as for instance when heatmaps became very popular in the late 1990s in molecular biology)
In terms of principles, what is going on in R graphics is more complicated. It relates to the social life of curves more generally. Here I want to introduce a theory of statistical graphics  and statistical media borrowed from the work of 19th century sociologist Gabriel Tarde. For much of his work life, Tarde was a judge as well as a criminologist noted for his work in reorganising the collection and publication of legal statistics in France. Like the philosopher C.S. Pierce, whose work on the US Coastal Survey influenced his take on logic, signs and science, Tarde's own work with tabular data runs fairly deeply in his theory of social life. You don't need to read much of the more theoretical end of recent European social science to know that Tarde is now being cited, amongst other things, for a prescient take on the role of statistics and data in social life. I'm not going to say much about the various takes on his work, but simply refer you to Bruno Latour's recent publications as leading examples (Latour & Lépinay, 2008)⁠. Latour claims that what Tarde predicted about statistics is coming to pass, and that his vision of sociology as the fundamental science is belatedly coming into being through computers, network media and digital methods. 
How could this be the case? Tarde predicted a time when statistical graphics of a certain fairly simple kind -- the kind that show growth and decay, increase, and decrease in any quantity – would be available for almost any quantity we could think of (for instance, the use of a particular code construct in R, or the retention ratios of newly registered Facebook users). He was right: peaks and troughs, the rise and fall of curves, are at the centre of many people's worlds, in finance, in sciences, in business, in commerce, in government and in institutions. 

### c. Curves, faces, landscapes and birds in flight

In the Laws of Imitation, Tarde compares curves and other visual things such as faces, landscapes and perhaps most famously, the flight of a swallow (Tarde, 1895)⁠. All the comparisons make a similar point: graphical curves drawn by statistics should be seen as forms of movement. We should see curves as forms of movement. Even though they are made from tables of numbers, they are more like seeing the flight of a bird – they relate to movement. While sometimes curves are interpreted as semiotic, and line of flight of a bird are seen as real, Tarde maintains they are both primarily seen as forms of movement.

 Indeed, Tarde goes so far as to say that there is no fundamental difference between seeing a bird in flight and seeing a statistical graphic (Park et al. 2001). Visual experience and statistical visualization are for Tarde fundamentally the same thing. Curves track movements in the same way our eyes track bird flights. A curve is an externalised way of seeing movement, as if we plotted all retinal excitations in order to see a bird flying. A curve is a kind of constructed act of seeing things in movement.
The only difference that matters between seeing curves and seeing birds flying is how, when, where and by whom the curves are made. The immediacy of seeing the  flight of a bird contrasts with the work that has to be done to extract curves from numbers by plotting them and drawing lines through them. 

> La différence la plus saisissable qui subsiste dès lors entre les courbes graphiques des statisticiens et les images visuelles, c'est que les premiers coûtent de la peine à l'homme qui les trace et même à celui qui les interprète, tandis que les secondes se font en nous et sans nul effort de notre part, et se laissent interpréter le plus facilement du monde;  (Tarde 1895, p.101)⁠

Work is needed to make and make sense of curves. Unpredictable, irregular time intervals come between the event and its presentation as data in a curve. What should we make of this work, the delay between the event and its graphing? I will come back to this, since much is at stake in this work that comes between collecting data and finally plotting it so that it looks like a curve (or a line).

### d. Plateaus and lines: the most boring curve is still philosophically problematic

How, given a curve, should we make sense of what we see? There is no way of simply making sense of a curve. According to Tarde, the most boring curve you can find is still philosophically problematic. Say we think about the simplest curve, a horizontal straight line. In terms of the landscape analogy, the straight line is a plateaux. What could be interesting about plateaux? Plateaux, and indeed straight lines, whether they go up or down, only ever testify to a provisional equilibrium between things. The question of what underlies the regularity of a straight line deeply shapes what we do with data.

### e. Regularity testifies to a great deal of repetition

There are two different ways of understanding a more or less straight line according to Tarde. Firstly, we can see any regularity such as a line as evidence of the workings of law, for instance, a law of nature. Much of the statistical work done using R is oriented in this direction insofar as it relies on underlying population distributions. 

For instance, to take one example amongst many, the data mining website Kaggle.com ran a competition in 2010-11 to see who could come up with the best predictive model for the packages that R users will install (http://www.kaggle.com/c/R/Data). The idea here was to use a dataset describing the packages installed by 52 R users to create a 'recommendation engine.' The recommendation engines that competitors created generally started from the assumption that there is some statistical association between the packages installed by an R user and such things as how often people look at that package, how many other packages a particular package depends on, whether the package is part of the R core, and so forth. The starting point for the recommendation engine would look like this in R code:
library('ProjectTemplate')
try(load.project())

logit.fit <- glm(Installed ~ LogDependencyCount +
                             LogSuggestionCount +
                             LogImportCount +
                             LogViewsIncluding +
                             LogPackagesMaintaining +
                             CorePackage +
                             RecommendedPackage,
                 data = training.data,
                 family = binomial(link = 'logit'))
summary(logit.fit)

Here the code takes the training dataset, defines a model in which the installed package depends on various other variables, and then asks the R generalized linear model function (glm) to fit the model to the data. The statistical model at the core of the sample solution is quite simple: 'logistic regression', a form of linear modelling that allows the probability of an event to be predicted on the basis of several variables, variables whose relative contributions to the occurrence of the event are not known in advance. 

The aim here is to see how well the data can fits along a straight line, itself projected on the basis of an underlying curve, the logistic function (Cramer 2004). 

As we can see, the straight line that the R recommendation engine looks for in order to provide recommendations itself relies on an underlying curve. For Tarde, in fact, straight lines are always the product of looking at things from a distance, and not seeing all the curves, large and small, that underlie them. Whenever we see a more or less straight line, we are seeing the results of a great deal of repetition cancelling out the differences. Tarde's preferred way to think of regularities, and straight lines in particular, is as the result of great numbers of more or less successful repetitions or imitations. Laws of nature then, or laws of social life, attest to repetition occurring for a relatively long time, nothing more. The law of large numbers does produce normal curves, but such curves are not an underlying law. They simply attest to the accumulation of many different curves.
Tarde's point is that we should look at the curves that underlie the curves in social life. In contrast to the reliance on a toolkit of different distribution curves (normal, logistic, exponential, Poisson, etc) as the underlying regularities, we should account for things, whether they are natural or social, all on one level. More theoretically, rather than social life being understood as the result of large structures/distributions shaping individuals or actions, we should see lives, individuals, habitats, institutions and large collectives like nations or economies as being constantly made and remade through a multitude of curves, accumulating on top of each other. The quantities in these curves come from processes of imitation and invention. The rise and fall of imitations, and the variations that rise when different flows of imitation encounter each other run through social life. 

In order to see how things come into being or disappear, we need to look at as many curves as possible, and preferable look at them at the same time time. Shifts in fashion, customs, migration, reproduction, climate, food, business, crime, health – the curves in all these intersect in picturing social life. The only way to look at these things in precise detail is through numbers, large tables of numbers collected over time. This understanding of social life lends a certain importance to statistics and to data in particular. Only through the accumulation of records of accumulation and drift of numbers that quantify repeated imitation that we can account for the growth and decline of various forms of social life. 
Note that this way of seeing curves differs from the classical views of statistics and numbers in several ways. It tends to treat data not as the more or less error-prone measurement of the action of general laws or as samples of an underlying population distribution, but rather as sign of fluxes of imitation and invention or variation that are infinitesimally individuated. Again, I think this understanding of what is going on in  curves deserves attention. If there is growth of curves currently occurring, then we would need to think about the implications of fluxes of imitation of curves.

## 3. Data deluge and network media  

### a. Differences between media and statistics
Tarde's hope or expectation was that the difference between statistics and media would disappear. While he was insisting on the deep kinship between statistical graphics and visual perceptions, he was also arguing that the mass media (newspapers) should become more like statistics. Media, at least media that is directed towards public good, should become less like sensory perception and more like statistics. There is one element of this theory of the social life of curves that seems problematic to me, and that is where R comes in.
Tarde's image of future statistical media as pure data flows draws again on an idealised model of the senses. For him, statistics in its present state is like the sensory organs of simpler organisms. Their sensing of movement or warmth or food gathers many different vibrations, signals, variations and flows into gradients along which act or react. Their life and intelligence is completely bound up with with their senses, and is nothing apart from that. More complicated, or evolved organisms tend to be able to react to their sensations and perceptions in different ways. Given statistics is always somehow making things to look at, then it can be seen as a kind of sense organ, according to Tarde. The development of sensors, instruments, measurement platforms and bureau creates new forms of social sensing comparable to eyes and ears. Hence for Tarde, media and statistics needs to progress so that it become more like a higher sense, rather than a sense in which life and intelligence are completely intermingled with each other. The higher statistics he hopes for will also be a higher media form, one in which editorial control no longer seeks to construct an opinion and broadcast it to a public, but in which it redacts data into curves that can be viewed by anyone at any time:

> L'idéal du genre, ce serait un journal sans article politique et tout plein de courbes graphiques, d'entrefilets secs ou d'adresses. (103)

Media would become sociological. Tarde's ideal spectator has quite sociological interests, and would be more interested by curves and tables than images and opinions. 
But the development of media and statistics are somewhat in tension with each other. At the same time as the differences between data and perception disappears (all curves are perceptions of movements), the differences between media and perception are meant to open up (curves are less like the packaged perceptions produced by mass media). Data is meant to be more open for judgment and interpretation (as we see in the many contemporary efforts to share data or make data more open in various domains)

### b. Data comes after new media?
I don't think this tension between the immediacy of data and the need to stand back from it is peculiar to Tarde's work. Perhaps we all inhabit it to a lesser or great extent, especially today when there are many difference coalescences and divergences between data, media, publics and audiovisual experience. The so-called data-deluge, and all the belief and desire in data as making possible new forms of political, scientific, commercial and cultural value also inhabits this space. 
The place of R in making sense of this predicament might be as a media ecology in which some of these tensions play out, and are worked on. It is an increasingly salient case, since as a platform that combines many thousands of techniques, tools and indeed machines for working with data, it percolates widely through disciplines, institutions, and organisations. And as an open source programming language, it opens itself up to the processes of imitation, variation and invention we associate with software cultures. The fact that it is a programming language, and a massive patchwork of packages that embody very different treatments of data, as well as many connections and interfaces to other databases, programming languages, data forms and data streams makes it in interesting lens through which to view how these tensions between the immediacy of data and the need for it to not . 
Why R today? Why not Excel spreadsheets? After all, are not spreadsheets tables really the data microbes in the social body of the exabyte deluge? In science, business, government and private life, spreadsheets probably massively outnumber the big datasets that get all the attention. R differs significantly in other data processing software such as Excel, or databases, or data manipulation programs, or well-known statistical software such as SPSS or SAS by virtue of its mode of existence as a programming language. R is more like GNU/Linux than Excel since it is a platform that can modify itself, and modify its own circulation in ways that commercial software finds much difficult. To use Chris Kelty's term, R can operate as a 'recursive public' (Kelty, 2008). In other words, rather than R being a tool or set of tools for tracking the flows of imitation and invention that make of the growth and death of social life, R can itself become network media, a flow of imitations and inventions that takes on its own social life (or 'community'). 
This warps Tarde's picture of the convergence of statistics and media in fairly profound ways. Tarde had a fairly straightforward view of statistics progressing linearly. However, if statistics itself become subject to flows of imitation and invention, if there are intense zones of imitation within the making of the curves (or maps, or network plots), then any simple convergence becomes much more unstable. I think something of this instability can be seen in R.

### c. Growth of data from network media

If R attracts more attention today, more than it did even 5 year ago, it is because something is happening to data. It wouldn't be hard to argue that the term 'data' resonates today in ways that 'network' did around 10 years ago. In a way that is apposite, because we have data today in the wake of the proliferation of network forms has been going on for the last few decades. The growth of network has been described elsewhere by sociologists, and media and communication scholars. The concomitant growth of data is less often discussed, although there is a sociological subfield of surveillance studies that has paid a lot of attention to the growth of government and commercial databases. Moreover, techniques of social network analysis have been developed partly in response to the growth of network media (mobile phones, as well as internet). Programming work on network media via inevitably entails data, and databases in particular, since nearly all forms of network media are dependent on database platforms. This means that databases and data structures have become almost the vital element in social media, both commercially, scientifically or epistemically.  
Growth of networks comes about partly through work on networks. That is, through is programming, coding and scripting of platforms that support new forms of communication. Webservers, databases, wikis, blogs and various other social media platforms are the result of this work and they continue to rapidly evolve in various ways. 
d. Open source software becomes open data + business analytics
At the same time as social media grow, science itself starts to look increasingly like social media. Indeed, scientific infrastructures – ranging from the physics-inspired WWW to the bibliometrics-inspired PageRank algorithm – have contributed significantly to the evolution of network media. There are good grounds to see science as one place where communication, and particularly communication of data is subject to reinvention driven by the epistemic desires of scientists. But science is clearly not alone in the desire to reinvent communication. It is not the only place where social life takes a strong interest in data. Open data imperatives, and open data efforts are very widespread across science, government and civil society. In big data science, in predictive analytics and in data journalism, media and science are entangled with the same desires and beliefs in data. Data journalism, just to focus on one case, might be seen as realisation of Tarde's hope for more sober mass media. 

### e. R crosses between science and media

All of this plays out in many ways in R. To mention just a few: 
1. the mixture of programming constructs present in R suggests a very mixed set of influences, borrowing from various programming languages and software engineering approaches; 
2. the ecology of R packages and ways of doing things in R is quite complicated, and is cross-cut by various disciplinary paradigms and techniques, ranging from field, social and observational sciences to relatively formal knowledges coming from mathematics, statistics, and computer science;
3. the extreme diversity of ways of doing things in R – something that new and experienced users of R sometimes complain of – again  suggests that there are very different ways of viewing what data is for, where it has come from, and where it is going to end up.
However, I want to shift to a broader argument about what the sprawling development of methods, tools and techniques found in R might mean about data more generally. 

## 4. Statistics, imitation and invention

If R is itself a way in which statistical modelling, data analytics or data visualisation is intensified, then R participates in the world that it seeks to know. Rather than R simply help in the accumulation of data, models or indices of change, it shapes that change. R modifies the distribution of statistical media by virtue of the way it joins existing statistical and graphical methods with new data. It is as if, to use a metaphor that might make sense, social life becomes more Bayesian as statistical media developes and spreads. 
The question then is what kind of change do we want from R? Again, Tarde offers a useful taking stock of what data can do. He writes:

> la statistique est circonscrite dans le champ de l'imitation et que celui de l'invention lui est interdit.  103
> Statistics is circumscribed in the field of imitation and the field of invention is barred to it. 

Statistics can give access to imitation, to flows of imitation, and to the tremendous effects that come from accumulating imitation. But in principle it cannot access invention in advance. If this is so (and this claim needs to be discussed more), what is at stake then in R? 

### a. Underlying all numbers are variations in belief and desire

Much of the work being done with R pursues variations and seeks to enumerate them and determine them precisely. For instance, in genomic research, the R BioConductor packages are part of an intensive effort to track down elusive variations in human, animal, plant and microbial genomes in order to elucidate associations between disease and genome. What R and data more generally can do is, according to Tarde, allow us to assess the imitative potential of particular tendencies, and also assessing how they relate to existing habits, institutions, and conditions. And from that, it might be possible to say what is good, and what is injurious, what is gained and what is lost, in a given change. So limiting statistics and data to the field of imitation is not writing data off. 
But there is another issue here that goes to heart of the data deluge. All the different forms of data that are found running through R scripts, code and packages, attest to something like the diversity of imitative fluxes that Tarde envisaged being brought to together in the various curves of statistical media. The acceptance of diverse and plural data was however itself only a response to a deeper problem: that we cannot easily get data on the variations that really matter: the variations in belief and desire. These variations make things happen. 
Again, I'm not going into the detail of Tarde's argument here, but it is necessary to point out the many forms of imitation represented in various datasets themselves are only energised by or derived from fluxes of desire and belief. Imitations and inventions come into being as forms in which beliefs and desires are acted out. Ideas and desires have to be embodied or materialised in some way. At core, both believing and desiring are the forces that give substance to any particular form of imitation. If it were possible to directly measure desires and beliefs (something that psychology has long struggled with), then they such measurements would provide the underpinnings of all the derived data on habits, fashions and trends that we are left to work with. 

### b. Potential energy of our collective consists in desired imitations?
As Tarde writes:

> Il importe beaucoup, en parcourant les ouvrages des statisticiens, de ne pas oublier qu'au fond les choses à mesurer statistiquement sont des qualités internes, des croyances et des désirs, et que bien souvent, à nombre égal, les actes chiffrés par eux expriment des poids très différents de ces choses. (85)

The same statistical number can mean different things in relation to beliefs and desires. Moreover, it might not mean much at all in relation to what is only potentially present in a given social setting. Desires and belief that have not yet found forms that allow them to propagate or be imitated in large numbers will not register there.  If beliefs and desires are vital, then their intensities become the underlying quantities that all other data indirectly measures.

### c. As imitation succeeds, invention becomes rarer, and statistical power increases

In certain situations, the potential for invention is very much diminished. This happens when certain forms of imitation are so effective that they exstinguish the very possibility of major inventions. The potential energies of social life are somewhat depleted.  As a result, statistical power varies in relation to social life according to how much invention is occurring. Statistical power increases when the forms of imitation are more coherent and comprehensive. It diminishes when there is a great of interference or noise surrounding imitation. This happens when many different desires and beliefs are vying with each other.

### d. The more statistics succeeds, the less it can expect to find out

A final implication of all this is that the predictive power of data grows when there is least happening. Indeed, the predictive power of data, and imitations of prediction that occur through statistical media could have precisely just such an effect. The more that working with data is imitated and acted upon, the more successful R becomes, the less there is to be found out, at least in terms of radically new things. Predictive power grows as invention diminishes. Tarde describes situations when fluxes of imitation accumulate and become highly organised as exhausting invention.

>L'invention vraie, celle qui mérite ce nom, devient chaque jour plus difficile, et il ne se peut dès lors qu'elle ne devienne pas, demain ou après-demain, chaque jour plus rare. Il faudra donc qu'elle s'épuise enfin.  104

> True invention, invention which merits the name,  becomes each day more difficult, and it may be that it will become tomorrow or the day after tomorrow, more rare each day. It will have to exhaust itself finally. 

## Bibliography (153)

Anderson, C., 2008. The End of Theory: The Data Deluge Makes the Scientific Method Obsolete. Wired Magazine, 16(7). Available at: http://www.wired.com/science/discoveries/magazine/16-07/pb_theory [Accessed August 25, 2011].
Cramer, J.S., 2004. The early origins of the logit model. Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences, 35(4), pp.613–626.
Durbin, R.M. et al., 2010. A map of human genome variation from population-scale sequencing. Nature, 467(7319), pp.1061–1073.
Park, K.J., Rosén, M. & Hedenstr\öm, A., 2001. Flight kinematics of the barn swallow (Hirundo rustica) over a wide range of speeds in a wind tunnel. Journal of Experimental Biology, 204(15), p.2741.
Savage, M. & Burrows, R., 2009. Some Further Reflections on the Coming Crisis of Empirical Sociology. Sociology, 43(4), pp.762-772.
Savage, M. & Burrows, R., 2007. The Coming Crisis of Empirical Sociology. Sociology, 41(5), pp.885-899.
Tarde, G., 1895. Les lois de l’imitation: Étude sociologique 2nd ed., Available at: http://openlibrary.org/b/OL23311522M/lois_de_l%27imitation.