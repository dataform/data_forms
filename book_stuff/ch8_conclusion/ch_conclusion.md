
\chapter{Conclusion: Out of the Data}
\label{ch:conclusion}



> `These diagrams of the diagrammatic domains,  they kernel together in localization. `

> `In this contrusion of major forms of invention in natures in machine learning techniques, inter-places, leveraged in and distributed.`

The two sentences above are the products of a generative model \index{model!generative} trained on the raw text of this book. Without any model of syntax, any dictionary of words or terms, relying purely on character sequences as probability distributions, the neural network that sampled these sentences out of its own unsupervised model of the book vectorised as data was primed with starting text of '`If `.' \index{machine learner!neural network} 'Diagrams of the diagrammatic domains,' kernelling together in localization, a 'contrusion' of major forms of invention in natures, in machine learning techniques, leveraged in and distributed in inter-places: all of that has been put quite well by the generative model, a two-layer 'long short term memory' recurrent neural net [@Karpathy_2016].  

I began with a relatively limited question: if machine learning is transforming the production of knowledge, might the practice of critical thought itself change, whether in its empirical or theoretical orientations? Could the 'experimentation of concepts' [@Stengers_2000,153] work with machine learning?   My answer is provisionally affirmative. If a book could be a generative model, then I hope this auto-archaeology \index{archaeology!auto} might generate or multiply the capacity to problematize the present.   For such a machine learner, a model that would learn machine learning in order to diagram a diagrammatic domain, predictions would figure less as statements that rank, order and classify, than as a technology of critical experimentation, a means of effecting a certain number of transformative operations on one's own conduct, thinking and ways of being amidst the determinations of contemporary reality. It would function as a mode of experimentation on statements. \index{statements!experimentation on}  

# 250,000 machine learners

For at least 230,800 human machine learners -- the number of unique authors listed in the corpus of machine learning research literature I have been drawing on -- \index{machine learner!number of}, a new kind of operational formation jells in machine learning. People and things, knowledge and power, combine in novel forms to generate statements. Understanding the distribution and production of elements that make up this emerging common space of decision, classification, prediction and anticipation matters contemporary critical thought in its engagement with power, production, conduct, communication, ways of being and thinking, materiality and experience.

Let us take 146,000 scientific articles, publications and books as statements concerning operations occurring in a variety of sites, modes, and settings connected in the operational formation we are discussing.\index{operational formation!constrast with discursive formation}. As in Foucault's discursive formations, statements in operational formations function by reference to the position of a subject (\index{subject!position of} the expert, the engineer, the doctor, the patient, the judge, the teacher, the student), amidst an organised or grouped accumulation of devices, settings and fields (positivity\index{positivity}),  and with greater or lesser reference to the practices of human-machine interaction.   For instance, writing the code that allows the recurrent neural net to build a generative model of this text.

Although subjects for Foucault do not author statements, the assignment of subject positions always passes through a human subject. In operational formations, subject positions are less distinct, yet highly populated (as the 230,000 authors of these paper suggest).  The machine-human mixing in operational formations is highly variable, dynamic and mutable, sometimes planing through code, sometimes diagrammed in visible forms such as graphs and tables, and often ramifying through infrastructures. \index{statements!human-machine}  

Affective elements have a long-standing connection with computation.  Elizabeth Wilson's study, _Affect and Artificial Intelligence_ [@Wilson_2010], draws on a combination of psychoanalytic, psychological and archival materials discussing the work of key figures in the early history of artificial intelligence such as Alan Turing on intelligent machinery,  Warren McCulloch and Walter Pitts on neural nets, and recent examples of affective computing and robots such as the MIT robot Kismet. \index{Wilson, Elizabeth!on artificial intelligence and affect} Her framing of the psychic nexus with machines such as the perceptron is provocative:
    
> Sometimes machines are the very means by which we can stay alive psychically, and they can  just as readily be a means for affective expansion and amplification as for affective attenuation. This is especially the case of computational machines [@Wilson_2010, 30].

Under what conditions do machines and for present purposes, computational machines, become 'the very means we can stay alive psychically'? Wilson  addresses this question by positing 'some kind of intrinsic affinity, some kind of intuitive alliance between the machinic and the affective, between calculation and feeling' (31), and suggesting that the 'one of the most important challenges will be to operationalize affectivity in ways that facilitate pathways of introjection between humans and machines' (31). \index{operational formation!affect in} \index{artificial intelligence!affect in} Introjection, the process of bringing the world within self is, according to psychoanalytic accounts of subjectivity, crucial to the formation of 'a stable subject position' (25). Wilson envisages introjection of machine processes as a good, not as a failure or attenuation of relation to the world.

While I tend to go in the same direction as Wilson in relation to 'affective expansion', I don't see that expansion as unfolding from introjection, but rather from an intensification of diagrammatic processes, the act of creating a 'concrete being, an intersecting of references' or abstraction [@Stengers_2000, 85] \index {diagram!affect of}

# A summary of the argument

I have been experimenting with abstraction in midst of data practices of machine learning. Let me resume the argument of the book, an archaeological argument that excavates seven major facets or intersecting planes that belong to the machine learning as an operational formation. \index{operational formation}    Chapter \ref{ch:diagram} addressed the problem of where amidst the mire of data, mathematics, code, infrastructures, scientific and other knowledge fields, a critical engagement with machine learning might situate itself.   I suggested that we should consider the formal, mathematical abstraction  and certain transformations in the production of software associated with machine learning as diagrammatic processes that organise and assemble human-machine relations. \index{human-machine relations}  Amidst a great accumulation of statements, figures, techniques, constructs, datasets and code implementations derived from many settings, the task is to map the intersecting references, the diagonal connections, and the transformatinos and substitutions that weave through machine learning. The positivity \index{positivity} of machine learning, its specific forms of accumulation, regularity and rarety do not attest to the power of algorithms but rather lend  liveliness to the field by concentrating expressions from many regions. 

Chapter \ref{ch:vector} examined the practices of vectorising data, situating machine learners themselves in an organised, dimensioned space accommodating an increasing repertoire of transformations operating on vectors. \index{vectorisation} Viewed as another mutation of the tabular grid, vector space invites transformations of data.  Machine learning is a practice of working with data  to accommodate all differences within an expanding dimensional space, a space in which data is under the strain of smooth surfaces, straight lines, regular curves and hyper-planes. \index{data!strain} Both in terms of infrastructure and epistemic cultures, the vector space abstracts and concretises \index{abstraction!see concretisation} spaces inside data. 

What is learning in machine learning? If information and computation can be understood as responding to a crisis in control, what do machine learners do? Chapter \ref{ch:function} examined how learning institutes experimental relays between operation and observation in optimising functions that predict and classify. The proliferation of methods and devices in machine learning and the attempts to unify them as 'learners' was understood as a result of this entwining of operations and observations. The interplay between operational transformations and observational functions in optimisation accounts for much of the 'learning' effect in machine learning.   \index{learning!optimisation}

An important and wide-reaching critical strand of work in humanities and social sciences over the last few decades has focused on knowledge in its entanglements with apparatuses of governmentalised power. Populations and other large aggregates have been central objects of concern.\index{population!power relations in}  They remain so in contemporary operational formations,  although under somewhat altered conditions. Having all the data, chapter \ref{ch:probability} suggested, is not the principal stake in contemporary data cultures. Instead, the probabilisation \index{probabilisation} of both data and machine learners as  populations, as distributed probabilities, indicates a different axis along which power-knowledge develops in machine learning.  

What happens to differences amidst vectorisation, learning as optimisation, probabilisation and the generalized diagrammatic abstraction of machine learning? \index{differences}. Are all differences reduced to quantitative comparisons?  Treated  as pattern, chapter \ref{ch:pattern} explored different treatments of difference in machine learning. Differences bifurcate between infinitesimal graduation and rigid decision boundaries, sometimes blurring or overlapping, and sometimes distributed into inaccessibly high-dimensional inner data spaces. The archaeological task amidst the dispersed patterns is to locate differences in kind. 

Rather than any new materiality, I have pointed to transformations in referentiality associated with machine learning.    From the standpoint of operational \gls{archaeology}, the materiality of machine learning refers to the practices of re-use that stabilise references. Science, by virtue of its experimental inventiveness and truth-authority, cross-validates the referentiality of machine learning. \index{science!referentiality of}  The topic of chapter \ref{ch:genome} was  a particularly data-intensive contemporary scientific hyperobject, the genome. As a data form, genomic sequence data provokes re-use, transcription and transmission of classifications and predictions. This incites both infrastructural transformations but also new concretisations of the hyperobject (as for instance in genome wide association studies).

Finally, chapter \ref{ch:subject} explored the subject position of machine learners. Within operational formations, subject positions arise in gaps between operations and statements concerning operations. The argument here concerned human-machine differences and the dispersion of subject positions through operations that alter those differences. Even amongst machine learners themselves, subject positions are not fixed or unified. The deep neural networks that beat Go champions in 2015 and 2016 [@Silver_2016] or developed hitherto unseen tactics in playing Atari computer games [@Mnih_2015] evidence the deeply competitive or test-based administration of this gap.  \index{machine learning!competition in} 

# In-situ hybridization

Beyond these facets of the argument concerning abstraction, inclusion, control, multiplicity, differences, materiality and subject positions, another argument shaped discussion in the preceding chapters, one that affectively underpins of the writing. A central problem for critical thought today (and by critical thought I mean post-Foucaultean engagements with the events that constitute us subjects of what we say, do and think \index{critical thought}) concerns how to engage with operational formations. To an even greater extant than the discursive formations that Foucault and many subsequent scholars have analysed, operational formations in production, communication, and the regulation of conduct become the field in which the work of ethics and politics takes place.  \index{operational formation!compared to discursive formation}  

The problem of engagement with operational formations is not so much how to gain control, or challenge the asymmetries of access and control that loom so large in them (Facebook can machine learn exponentially more patterns than I can), but to begin to grasp the forms of change that are possible and desirable. Mark Hansen has, for instance, posed the challenge of engaging with data-intensive prediction directly in terms of experience. He writes:

> this imperative enjoins us to use the technologies of data capture, analysis and prediction to create a feed-forward structure capable of marshaling the full productive potentiality of data -- its commonality, accessibility, and openness -- in order to improve, indeed to improve by _intensifying_, our experience [@Hansen_2015, 77] \index{Hansen, Mark!using potentiality of data}

Treating prediction as more than means of disciplinary control, and instead as a resource for individuals and collective to modulate experience, Hansen's project draws on an extensive engagement with phenomenology and Whitehead's philosophy. The crucial task in his view is creative or inventive: the 'feed-forward structure' must marshal 'the productive potentiality of data.'

One way to do this is broadly aligned with Foucault's emphasis in his later work on care of the self.  Technologies of the self 'permit individuals to effect a certain number of operations of their bodies and social, thoughts, conduct and ways of being, so as to transform themselves in order to attain a certain state of happiness, purity, wisdom, perfection or even immortality' [@Foucault_1997, 225]. Could Hansen's feed-forward structure -- the term itself referring to the first phase of neural net's learning  -- operate as a technology of the self, not so much focused on improvement or perfection of experience but in name of the potential to invent new tests of and new relations to pressing realities? For scholars producing critical knowledge in humanities and social science through a variety of textual, empirical, theoretical and increasingly implicitly or explicitly computational practices, technologies of self offer a concrete path  wending a way into domains of production, communication and governance.  Rather than immortality or purity, operations effected on ways of thinking, living and being might  transform oneself in the interests of a limited experience of freedom. \index{technologies of self!machine learning as} 

Under what conditions could something like care of the self and technologies of the self have any purchase, relevance or even toehold in the operational formation of machine learning? Five elements, it seems to me, need to be assembled in order to think through that conjunction. The recognition of ourselves as subjects of machine learning is an elementary archaeological task. Whether in relation to knowledge, communication (in the broadest sense), conduct or ways of living, this recognition relies on a description of practices associated with differences, multiplicities, materialities, knowledges and control. Second, as I have endeavoured to emphasise in describing machine learning as an operational formation, the liveliness of machine learning should be understood as a localisation of power-knowledge relations, or a primary field of expressions issuing from many parts (to paraphrase Whitehead \index{Whitehead, Alfred North!life}). 'They kernel together in localization' as my recurrent neural network \index{machine learner!neural network!recurrent} puts it. Third, while the accumulating plethora of techniques, applications and sites is neither unified by a master algorithm or by a latent, underlying meaning, it does demonstrate regularities and point of indetermination or slippage. Fourth, understood as a field of the expression of many parts, an operational formation can also be site of collective individuation. Participating in a collective, individual subjects, far from losing whatever defines their unique or essential identity, gain the chance to individuate, at least in part, the share of pre-individual reality that marks the collective within them. Fifth, by participating in a collective, even an operational formation, individuals may transform themselves (in order to attain certain states or experiences), but also  affect the collective itself. 

Whether this might affect the internet filter bubble [@Pariser_2011], the 'stack to come' [@Bratton_2016], digital citizenship [@Isin_2015], the character of work [@Brynjolfsson_2014], the fabric of experience [@Hansen_2015] or what counts as knowledge [@Bowker_2014] is hard to say.    As an operational formation, machine learning does not determine anything in its operations, even if it connects directly to strategies of power. Foucault writes that 'archaeology describes the different spaces of dissension' [@Foucault_1972, 152] \index{archaeology!spaces of dissension}. These spaces of dissension, it seems to me, form a field in which initiatives, individuations and technologies of the self might articulate a certain number of transformative operations. 

# Critical operational practice?

Under what conditions would that experimental practice and operation on ways of thinking and saying be divergent rather than convergent? Writing this book, and learning to machine learn in order to write about machine learning, involves participation in a collective, the collective of at least 230,000 scientist-machine learners, and the tends of thousands of programmers developing machine learners evident on Github.com. By participating in the collective operational formation, running the risk of being mobilized by existing interests, we might also individuate differently a share of the pre-individual  reality included within us [@Virno_2004,79]. \index{Virno, Paolo!collective individuation} \index{collective!individuation of} Like Anne-Marie Mol's 'praxiography,' which seeks to maintain reality multiples in describing practice [@Mol_2003, 6], the description of machine learning as data practice intends to  sustain the multiple of reality by identifying the practices that make it multiple. \index{Mol, Anne-Marie!on praxiography} \index{data practice!as multiple} 

The path I've taken here combines writing (a discursive practice) and coding (an operational practice). Writing about machine learning is a practice of diagrammatically mapping the re-iterative drawing of human-machine relations in code, and in particular, in coding that learns from data.  Datasets, scientific and engineering publications, textbooks such as _Elements of Statistical Learning_, software libraries and packages, spectacular demonstrations comprise a whole series of criss-crossings. While not the path that everyone would or should want to take, for me moving into the data like or as a machine learner perhaps allows writing to become more diagrammatic. 'Between the figure and the text we must admit a whole series of criss-crossings' wrote Foucault [@Foucault_1972, 66], in defining \gls{archaeology} as a mode of exploration of knowledges, politics and ways of being. 

Very mundanely, I've read articles and books, downloaded data and software libraries, watched Youtube lectures and presentations, configured and written bits of code and text, made plots and diagrams, and done much configuration work across various platforms (Github.com, linux, Google Compute, `R`, `python` and `ipython`).   Amidst all of this data practice (and much practising), there is no reason to assume that learning machine learning is solely the performance of a conscious subject. When we look at an equation repeatedly, when we comply with the machine learning injunction to 'find a useful approximation $\hat(f)(x)$ to the function $f(x)$ that underlies the predictive relationship between input and output' [@Hastie_2009, 28] by writing code to cross-validate a model, we surrender to 'learning' that, however fascinating or surprising, is not that of a conscious human subject but also of human-machine assemblage. To the extent that it is archaeological, operational, diagrammatic writing vibrates around  the axis of knowledge/practice, not knowledge/consciousness. \index{archaeology!writing practice} 

# Obstacles to the work of freeing machine learning

As I have emphasised on several occasions, machine learning is an uneasy mixture of massively repeated and familiar forms, and something that is not easily understood. On the one hand, the level of imitation, duplications, copying and reproduction associated with the techniques suggests that a process of remaking the world according to particular forms is in process (for instance, in chapter \ref{ch:probability}  we saw how Naive Bayes classifiers are almost demonstrated on spam classification problems.) The scientific and engineering literature, with its really frequent variations on similar themes, suggests that imitation and copying are very much  at the heart of the movements I have been describing. This is nothing new. \index{machine learning!imitation in} It would be strange of these techniques were not subject to imitation and emulation. That imitation is predictable. We expect it and can account for it sociologically.[^8.2] Some symptoms of these imitative fluxes can be found in the scientific and engineering literature.  As we have seen, work on image and video classification, on text and speech, on gene interaction prediction or above all, on predictions of relations or associations between people and things (usually commodities, but not always) is striking in its persevering homogeneity. Moreover, the powerful aspirations evident amongst large media platforms such as Baidu, Google  and Facebook to re-ground machine learning in the project of artificial intelligence amidst social media or web page-related data  in many ways continues business as usual for computer scientists [@Gulcehre_2014].  

How would we get any sense of what is not so easily digested and laid out in social practice? Archaeologies of  operational formations aim to present some of the necessary elements for that purpose.  In the closing pages of _The Archaeology of Knowledge_, Foucault writes: 

>the positivities that I have tried to establish must not be understood as a set of determinations imposed from the outside on the thought of individuals, or inhabiting it from the inside, in advance as it were; they constitute rather the set of conditions in accordance with which a practice is exercised, in accordance with which that practices gives rise to partially or totally new statements, and in accordance with which it can be modified. These positivities are no so much limitations imposed on the initiative of subjects as the field in which that initiative is articulated [@Foucault_1972, 208-209]. \index{positivity}

Here Foucault refers to the restricted freedom that discursive practices and formations open for us. If it is increasingly difficult for science, media, government and business to think and act outside data. And yet Foucault is quite clear that amidst the positivities of knowledge production, knowing the conditions, setting out the rules, and identifying the relations that striate the density and complexity of practice is a pre-condition to any transformations in practice. 

As a data practice, however, machine learning is not entirely predictable. Machine learners,  as we have seen, vary too much, they are biased, they overfit, they underfit, and they often fail to generalise. \index{machine learning!limitations of} Despite this, they have enormous allure. In the history of automata, automation and animation, kinetic lures have long exercised fascination, and this may be part of the effect of machine learning. Animating transformations of data (think of the 366 times the logistic regression traverses the `South African Heart Disease` dataset), and then looking at those optimising animations as 'learning' generates operational power dynamics. \index{automation!animation of} 

Machine learning more broadly attracts infrastructural, technical, professional, semiotic and financial diagonals -- think of the upswing in Google searches for 'machine learning' shown in figure \ref{fig:google_trends} in chapter \ref{ch:introduction} --   that render its traits more real, more thickly transformative and more 'performant.' Yet such performant diagrams generate referential effects. Machine learning becomes ontologically potent. As Maurizio Lazzarato writes in *Signs and Machines*, 'ontological mutations are always machinic. They are never the simple result of the actions or choices of the "man" who, leaving the assemblage, removes himself from the non-human, technical, or incorporeal elements that constitute him' [@Lazzarato_2014, 83]. \index{Lazzarato, Maurizio!asemiotic machine} 

New machine learners arise from diagrammatic superimposition of existing practices or procedures. Neural networks are like a massively proliferating nest of perceptrons.  Moreover, machine learning techniques often repeat something familiar by very different means (think of how `kittydar` treats photographs, or how a decision tree is legible but often unfamiliar). The event, then, resides less in either something intrinsic to devices operating as algorithmic models, or in something about the domains and places in which the devices operate (biomedicine, state security and intelligence agencies, finance, business, commerce, science, etc.). Perhaps it is a rather more modest event in which the tending of abstractions through estimation,  optimisation, high-dimensional vectorisation, probabilistic mixing of latent and feature  variables, and imputation unevenly replace existing ontological and epistemic norms of verification, objectification, and attribution. \index{machine learning!unpredictable operation of}

I have been less interested in treating these techniques as the predictable re-animation of alienated reason, and more inclined to look for those elements in machine learning that diagrammatically abstract away from structures of representations, subjectification or indeed implementation associated with platforms, services and products (for instance, the interminable implementations of document classifiers, sentiment analyses, or image labelling, or handwritten digit recognition, or autonomous navigation, etc.). 


[^8.2]: Accounts that might do this can be found in science and technology studies, particularly in actor-network theory versions, as well as in recent social and cultural theory that, for instance, draws on the work of the 19th century French sociologist, Gabriele Tarde [@Tarde_1902; @Borch_2005].


