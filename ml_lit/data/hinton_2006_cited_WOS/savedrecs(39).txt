PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
J	Hinton, GE; Salakhutdinov, RR				Hinton, G. E.; Salakhutdinov, R. R.			Reducing the dimensionality of data with neural networks	SCIENCE			English	Article							REDUCTION	High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder'' networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Hinton, GE (reprint author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	hinton@cs.toronto.edu					DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; HECHTNIELSEN R, 1995, SCIENCE, V269, P1860, DOI 10.1126/science.269.5232.1860; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; Plaut D. C., 1987, Computer Speech and Language, V2, DOI 10.1016/0885-2308(87)90026-X; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	12	741	815	AMER ASSOC ADVANCEMENT SCIENCE	WASHINGTON	1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA	0036-8075			SCIENCE	Science	JUL 28	2006	313	5786					504	507		10.1126/science.1127647		4	Multidisciplinary Sciences	Science & Technology - Other Topics	067MZ	WOS:000239308600057	16873662	
J	Byrne, P; Becker, S; Burgess, N				Byrne, Patrick; Becker, Suzanna; Burgess, Neil			Remembering the past and imagining the future: A neural model of spatial memory and imagery	PSYCHOLOGICAL REVIEW			English	Review						navigation; path integration; representational neglect; hippocampus; computational model	HIPPOCAMPAL PLACE CELLS; HEAD-DIRECTION SYSTEM; TRANSCRANIAL MAGNETIC STIMULATION; DORSOLATERAL PREFRONTAL CORTEX; CONTINUOUS ATTRACTOR NETWORKS; ASSOCIATIVE PARIETAL CORTEX; VENTRAL INTRAPARIETAL AREA; PATH-INTEGRATION; WORKING-MEMORY; HUMAN NAVIGATION	The authors model the neural mechanisms underlying spatial cognition, integrating neuronal systems and behavioral data, and address the relationships between long-term memory, short-term memory, and imagery, and between egocentric and allocentric and visual and ideothetic representations. Long-term spatial memory is modeled as attractor dynamics within medial-temporal allocentric representations, and short-term memory is modeled as egocentric parietal representations driven by perception, retrieval, and imagery and modulated by directed attention. Both encoding and retrieval/imagery require translation between egocentric and allocentric representations, which are mediated by posterior parietal and retrosplenial areas and the use of head direction representations in Papez's circuit. Thus, the hippocampus effectively indexes information by real or imagined location, whereas Papez's circuit translates to imagery or from perception according to the direction of view. Modulation of this translation by motor efference allows spatial updating of representations, whereas prefrontal simulated motor efference allows mental exploration. The alternating temporal-parietal flows of information are organized by the theta rhythm. Simulations demonstrate the retrieval and updating of familiar spatial scenes, hemispatial neglect in memory, and the effects on hippocampal place cell firing of lesioned head direction representations and of conflicting visual and ideothetic inputs.	McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada; UCL, Inst Cognit Neurosci, London, England; UCL, Dept Anat, London, England	Becker, S (reprint author), McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada.	becker@mcmaster.ca	Byrne, Patrick/A-4546-2008; Burgess, Neil/B-2420-2009; Becker, Suzanna/H-8197-2013				Abrahams S, 1997, NEUROPSYCHOLOGIA, V35, P11, DOI 10.1016/S0028-3932(96)00051-6; Addis DR, 2007, NEUROPSYCHOLOGIA, V45, P1363, DOI 10.1016/j.neuropsychologia.2006.10.016; Aggleton JP, 1999, BEHAV BRAIN SCI, V22, P425; Aguirre GK, 1999, BRAIN, V122, P1613, DOI 10.1093/brain/122.9.1613; Alyan S, 1999, BEHAV NEUROSCI, V113, P19, DOI 10.1037//0735-7044.113.1.19; SUZUKI WA, 1994, J COMP NEUROL, V350, P497, DOI 10.1002/cne.903500402; ANDERSEN RA, 1985, SCIENCE, V230, P456, DOI 10.1126/science.4048942; Andersen RA, 1999, ANN NY ACAD SCI, V871, P282, DOI 10.1111/j.1749-6632.1999.tb09192.x; Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2; Baddeley A. D., 1980, ATTENTION PERFORM, P521; Barry C, 2006, REV NEUROSCIENCE, V17, P71; Battaglia FP, 2004, J NEUROSCI, V24, P4541, DOI 10.1523/JNEUROSCI.4896-03.2004; Bayley PJ, 2005, NEURON, V46, P799, DOI 10.1016/j.neuron.2005.04.034; Becker S, 2001, ADV NEUR IN, V13, P96; Becker S, 2005, HIPPOCAMPUS, V15, P722, DOI 10.1002/hipo.20095; Behrmann M, 1997, NEUROPSYCHOLOGIA, V35, P1445, DOI 10.1016/S0028-3932(97)00058-4; Beschin N, 2000, CORTEX, V36, P401, DOI 10.1016/S0010-9452(08)70849-9; Bird CM, 2006, J NEUROL NEUROSUR PS, V77, P1008, DOI 10.1136/jnnp.2006.094417; BISIACH E, 1978, CORTEX, V14, P129; Bohbot VD, 1998, NEUROPSYCHOLOGIA, V36, P1217, DOI 10.1016/S0028-3932(97)00161-9; Bremmer F, 2002, EUR J NEUROSCI, V16, P1569, DOI 10.1046/j.1460-9568.2002.02206.x; Brun VH, 2002, SCIENCE, V296, P2243, DOI 10.1126/science.1071089; Burgess N, 1996, HIPPOCAMPUS, V6, P749; Burgess N, 2001, NEUROIMAGE, V14, P439, DOI 10.1006/nimg.2001.0806; Burgess N., 1999, HIPPOCAMPAL PARIETAL; Burgess N, 2006, TRENDS COGN SCI, V10, P551, DOI 10.1016/j.tics.2006.10.005; Burgess N, 2005, TRENDS COGN SCI, V9, P535, DOI 10.1016/j.tics.2005.09.011; Burgess N, 2004, COGNITION, V94, P149, DOI 10.1016/j.cognition.2004.01.001; Burgess N, 2001, PHILOS T R SOC B, V356, P1493, DOI 10.1098/rstb.2001.0948; Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9; BYRNE P, 2006, UNPUB PRINCIPLE LEAR; Byrne P, 2004, NEURAL COMPUT, V16, P1851, DOI 10.1162/0899766041336468; Calton JL, 2003, J NEUROSCI, V23, P9719; Caplan JB, 2003, J NEUROSCI, V23, P4726; Chafee MV, 1998, J NEUROPHYSIOL, V79, P2919; CHEN LL, 1994, EXP BRAIN RES, V101, P24, DOI 10.1007/BF00243213; Clower DM, 2001, J NEUROSCI, V21, P6283; Colby C.L., 1999, HIPPOCAMPAL PARIETAL, P104; Commins S, 1999, BEHAV BRAIN RES, V104, P197, DOI 10.1016/S0166-4328(99)00094-7; Conklin J, 2005, J COMPUT NEUROSCI, V18, P183, DOI 10.1007/s10827-005-6558-z; Cooper BG, 2001, J NEUROSCI, V21, P3986; Cooper BG, 2001, BEHAV NEUROSCI, V115, P1012, DOI 10.1037//0735-7044.115.5.1012; Crane J, 2005, HIPPOCAMPUS, V15, P216, DOI 10.1002/hipo.20043; Cressant A, 1997, J NEUROSCI, V17, P2531; Davachi L, 2001, J NEUROPHYSIOL, V85, P2590; Ding SL, 2000, J COMP NEUROL, V425, P510, DOI 10.1002/1096-9861(20001002)425:4<510::AID-CNE4>3.0.CO;2-R; Diwadkar VA, 1997, PSYCHOL SCI, V8, P302, DOI 10.1111/j.1467-9280.1997.tb00442.x; Doricchi F, 2003, NEUROREPORT, V14, P2239, DOI 10.1097/01.wnr.0000091132.75061.64; Duhamel JR, 1998, J NEUROPHYSIOL, V79, P126; DUHAMEL JR, 1992, SCIENCE, V255, P90; EASTON RD, 1995, J EXP PSYCHOL LEARN, V21, P483, DOI 10.1037/0278-7393.21.2.483; Egorov AV, 2002, NATURE, V420, P173, DOI 10.1038/nature01171; EICHENBAUM H, 1988, TRENDS NEUROSCI, V11, P244, DOI 10.1016/0166-2236(88)90100-2; Eichenbaum H, 2001, BEHAV BRAIN RES, V127, P199, DOI 10.1016/S0166-4328(01)00365-5; Ekstrom AD, 2003, NATURE, V425, P184, DOI 10.1038/nature01964; Epstein R, 1998, NATURE, V392, P598, DOI 10.1038/33402; Etienne AS, 1996, J EXP BIOL, V199, P201; Etienne AS, 1998, NATURE, V396, P161, DOI 10.1038/24151; Fell J, 2003, EUR J NEUROSCI, V17, P1082, DOI 10.1046/j.1460-9568.2003.02522.x; Fletcher PC, 1996, BRAIN, V119, P1587, DOI 10.1093/brain/119.5.1587; Formisano E, 2002, NEURON, V35, P185, DOI 10.1016/S0896-6273(02)00747-X; FRISK V, 1990, NEUROPSYCHOLOGIA, V28, P349, DOI 10.1016/0028-3932(90)90061-R; Fruhmann-Berger M, 2005, J NEUROL, V252, P1194, DOI 10.1007/s00415-005-0831-y; FUNAHASHI S, 1989, J NEUROPHYSIOL, V61, P331; Galati G, 2000, EXP BRAIN RES, V133, P156, DOI 10.1007/s002210000375; Galletti C, 1995, EUR J NEUROSCI, V7, P2486, DOI 10.1111/j.1460-9568.1995.tb01047.x; GEORGOPOULOS AP, 1988, FASEB J, V2, P2849; Ghaem O, 1997, NEUROREPORT, V8, P739, DOI 10.1097/00001756-199702100-00032; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; Goodridge JP, 2000, J NEUROPHYSIOL, V83, P3402; Gothard KM, 2001, J NEUROSCI, V21, P7284; Gothard KM, 1996, J NEUROSCI, V16, P8027; GRAZIANO MSA, 1993, EXP BRAIN RES, V97, P96; Guariglia C, 2005, NEUROPSYCHOLOGIA, V43, P1138, DOI 10.1016/j.neuropsychologia.2004.11.021; Guazzelli A, 2001, HIPPOCAMPUS, V11, P216, DOI 10.1002/hipo.1039; Haarmeier T, 1997, NATURE, V389, P849; Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721; Hahnloser RHR, 2003, NEUROSCIENCE, V120, P877, DOI 10.1016/S0306-4522(03)00201-X; Hartley T, 2007, HIPPOCAMPUS, V17, P34, DOI 10.1002/hipo.20240; Hartley T, 2003, NEURON, V37, P877, DOI 10.1016/S0896-6273(03)00095-3; Hartley T, 2004, COGNITION, V94, P39, DOI 10.1016/j.cognition.2003.12.001; Hartley T, 2000, HIPPOCAMPUS, V10, P369, DOI 10.1002/1098-1063(2000)10:4<369::AID-HIPO3>3.0.CO;2-0; Hassabis D, 2007, P NATL ACAD SCI USA, V104, P1726, DOI 10.1073/pnas.0610561104; Hasselmo ME, 2002, NEURAL COMPUT, V14, P793, DOI 10.1162/089976602317318965; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holdstock JS, 2000, NEUROPSYCHOLOGIA, V38, P410, DOI 10.1016/S0028-3932(99)00099-8; Howard MW, 2005, PSYCHOL REV, V112, P75, DOI 10.1037/0033-295X.112.1.75; Huxter J, 2003, NATURE, V425, P828, DOI 10.1038/nature02058; Iaria G, 2003, J NEUROSCI, V23, P5945; Ino T, 2002, NEUROSCI LETT, V322, P182, DOI 10.1016/S0304-3940(02)00019-8; JARRARD LE, 1993, BEHAV NEURAL BIOL, V60, P9, DOI 10.1016/0163-1047(93)90664-4; Jeffery KJ, 1997, EXP BRAIN RES, V117, P131, DOI 10.1007/s002210050206; Jeffery KJ, 1999, EXP BRAIN RES, V127, P151, DOI 10.1007/s002210050785; Jensen O, 1996, LEARN MEMORY, V3, P279, DOI 10.1101/lm.3.2-3.279; Kahana MJ, 1999, NATURE, V399, P781, DOI 10.1038/21645; Karnath HO, 1997, NEUROPSYCHOLOGIA, V35, P435, DOI 10.1016/S0028-3932(96)00118-2; KIM JJ, 1992, SCIENCE, V256, P675, DOI 10.1126/science.1585183; King JA, 2005, NEUROIMAGE, V28, P256, DOI 10.1016/j.neuroimage.2005.05.057; King JA, 2004, NEUROPSYCHOLOGY, V18, P405, DOI 10.1037/0894-4105.18.3.405; King JA, 2002, HIPPOCAMPUS, V12, P811, DOI 10.1002/hipo.10070; Klam F, 2003, EUR J NEUROSCI, V18, P995, DOI 10.1046/j.1460-9568.2003.02813.x; Klein SB, 2002, SOC COGNITION, V20, P353, DOI 10.1521/soco.20.5.353.21125; Klink R, 1997, J NEUROPHYSIOL, V77, P1829; Knauff M, 2000, NEUROREPORT, V11, P3957, DOI 10.1097/00001756-200012180-00011; Kobayashi Y, 2003, J COMP NEUROL, V466, P48, DOI 10.1002/cne.10883; KOSSLYN SM, 1980, RECHERCHE, V11, P156; Làdavas E, 1998, J Cogn Neurosci, V10, P581, DOI 10.1162/089892998562988; Lever C, 2002, NATURE, V416, P90, DOI 10.1038/416090a; Levy R, 2000, EXP BRAIN RES, V133, P23, DOI 10.1007/s002210000397; Levy WB, 1996, HIPPOCAMPUS, V6, P579, DOI 10.1002/(SICI)1098-1063(1996)6:6<579::AID-HIPO3>3.0.CO;2-C; LOOMIS JM, 1993, J EXP PSYCHOL GEN, V122, P73, DOI 10.1037//0096-3445.122.1.73; Maguire EA, 2001, SCAND J PSYCHOL, V42, P225, DOI 10.1111/1467-9450.00233; Maguire EA, 1996, NEUROPSYCHOLOGIA, V34, P993, DOI 10.1016/0028-3932(96)00022-X; Maguire EA, 1998, SCIENCE, V280, P921, DOI 10.1126/science.280.5365.921; MARR D, 1971, PHILOS T ROY SOC B, V262, P23, DOI 10.1098/rstb.1971.0078; Matsumura N, 1999, J NEUROSCI, V19, P2381; MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419; McNamara TP, 2003, PSYCHON B REV, V10, P589, DOI 10.3758/BF03196519; MCNAUGHTON BL, 1987, TRENDS NEUROSCI, V10, P408, DOI 10.1016/0166-2236(87)90011-7; MCNAUGHTON BL, 1983, EXP BRAIN RES, V52, P41; McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932; MILNER A, 1999, P ROY SOC LOND B BIO, V26, P2225; Mittelstaedt ML, 2001, EXP BRAIN RES, V139, P318, DOI 10.1007/s002210100735; Morris RG, 1982, NATURE, V24, P681; MORRONGIELLO BA, 1995, J EXP CHILD PSYCHOL, V59, P211, DOI 10.1006/jecp.1995.1010; Mou WM, 2004, J EXP PSYCHOL LEARN, V30, P142, DOI 10.1037/0278-7393.30.1.142; Mou WM, 2006, J EXP PSYCHOL LEARN, V32, P1274, DOI 10.1037/0278-7393.32.6.1274; Mou WM, 2002, J EXP PSYCHOL LEARN, V28, P162, DOI 10.1037//0278-7393.28.1.162; Muller R, 1996, NEURON, V17, P979; Murray EA, 1999, TRENDS COGN SCI, V3, P142, DOI 10.1016/S1364-6613(99)01303-0; Nakazawa K, 2002, SCIENCE, V297, P211, DOI 10.1126/science.1071795; Norman G, 2004, BEHAV BRAIN RES, V148, P79, DOI 10.1016/S0166-4328(03)00176-1; O'Keefe J, 1978, HIPPOCAMPUS COGNITIV; OKEEFE J, 1976, EXP NEUROL, V51, P78, DOI 10.1016/0014-4886(76)90055-8; OKEEFE J, 1993, HIPPOCAMPUS, V3, P317, DOI 10.1002/hipo.450030307; OKeefe J, 1996, NATURE, V381, P425, DOI 10.1038/381425a0; O'Keefe J, 2005, HIPPOCAMPUS, V15, P853, DOI 10.1002/hipo.20115; Okuda J, 2003, NEUROIMAGE, V19, P1369, DOI 10.1016/S1053-8119(03)00179-4; Oliveri M, 2001, CEREB CORTEX, V11, P606, DOI 10.1093/cercor/11.7.606; ONO T, 1993, J NEUROPHYSIOL, V70, P1516; Papez JW, 1937, ARCH NEURO PSYCHIATR, V38, P725; PAVLIDES C, 1988, BRAIN RES, V439, P383, DOI 10.1016/0006-8993(88)91499-0; PHILLIPS RG, 1992, BEHAV NEUROSCI, V106, P274, DOI 10.1037//0735-7044.106.2.274; Pierrot-Deseilligny C, 2002, ANN NEUROL, V52, P10, DOI 10.1002/ana.10273; PIGGOT S, 1993, NEUROPSYCHOLOGIA, V31, P1; Pinto-Hamuy T, 2004, BEHAV BRAIN RES, V153, P465, DOI 10.1016/j.bbr.2004.01.003; Postle BR, 2006, Q J EXP PSYCHOL, V59, P100, DOI 10.1080/17470210500151410; POUCET B, 1993, PSYCHOL REV, V100, P163, DOI 10.1037/0033-295X.100.2.163; Pouget A, 1997, J COGNITIVE NEUROSCI, V9, P222, DOI 10.1162/jocn.1997.9.2.222; Recce M, 1996, HIPPOCAMPUS, V6, P735, DOI 10.1002/(SICI)1098-1063(1996)6:6<735::AID-HIPO15>3.0.CO;2-1; Redish AD, 1999, COGNITIVE MAP PLACE; Redish AD, 2000, J NEUROSCI, V20, P9298; Redish AD, 1996, NETWORK-COMP NEURAL, V7, P671, DOI 10.1088/0954-898X/7/4/004; Redish AD, 2000, NEUROCOMPUTING, V32, P235, DOI 10.1016/S0925-2312(00)00169-7; RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037//0278-7393.15.6.1157; Rockland KS, 1999, CEREB CORTEX, V9, P232, DOI 10.1093/cercor/9.3.232; Rode G, 2001, NEUROPSYCHOLOGIA, V39, P1250, DOI 10.1016/S0028-3932(01)00064-1; Rolls ET, 1995, HIPPOCAMPUS, V5, P409, DOI 10.1002/hipo.450050504; Rosenbaum RS, 2004, NEUROPSYCHOLOGIA, V42, P1619, DOI 10.1016/j.neuropsychologia.2004.04.010; Sack AT, 2002, NEURON, V35, P195, DOI 10.1016/S0896-6273(02)00745-6; Sala J, 2003, NEUROPSYCHOLOGIA, V41, P341, DOI 10.1016/S0028-3932(02)00166-5; Samsonovich A, 1997, J NEUROSCI, V17, P5900; Save E, 2005, EUR J NEUROSCI, V21, P522, DOI 10.1111/j.1460-9568.2005.03882.x; Save E, 1996, BEHAV NEUROSCI, V110, P74; Save E, 1998, J NEUROSCI, V18, P1818; Save E, 2001, BEHAV NEUROSCI, V115, P1212, DOI 10.1037//0735-7044.115.6.1212; SCOVILLE WB, 1957, J NEUROL NEUROSUR PS, V20, P11, DOI 10.1136/jnnp.20.1.11; Sederberg PB, 2003, J NEUROSCI, V23, P10809; Shallice T., 1988, NEUROPSYCHOLOGY MENT; Sharp PE, 1999, BEHAV NEUROSCI, V113, P643, DOI 10.1037/0735-7044.113.4.643; Shelton AL, 2001, COGNITIVE PSYCHOL, V43, P274, DOI 10.1006/cogp.2001.0758; Simons DJ, 1998, PSYCHOL SCI, V9, P315, DOI 10.1111/1467-9280.00062; Skaggs W E, 1995, Adv Neural Inf Process Syst, V7, P173; SMITH ML, 1989, NEUROPSYCHOLOGIA, V27, P71, DOI 10.1016/0028-3932(89)90091-2; Snyder LH, 1998, NATURE, V394, P887; Spiers HJ, 2001, BRAIN, V124, P2476, DOI 10.1093/brain/124.12.2476; SQUIRE LR, 1986, SCIENCE, V232, P1612, DOI 10.1126/science.3086978; Stringer SM, 2002, NETWORK-COMP NEURAL, V13, P217, DOI 10.1088/0954-898X/13/2/304; Stringer SN, 2002, NETWORK-COMP NEURAL, V13, P429, DOI 10.1088/0954-898X/13/4/301; Taube JS, 1998, PROG NEUROBIOL, V55, P225, DOI 10.1016/S0301-0082(98)00004-5; Thiebaut de Schotten M, 2005, SCIENCE, V309, P2226, DOI 10.1126/science.1116251; TREVES A, 1992, HIPPOCAMPUS, V2, P189, DOI 10.1002/hipo.450020209; Ungerleider L., 1982, ANAL VISUAL BEHAV, P549; Wallenstein GV, 1998, TRENDS NEUROSCI, V21, P317, DOI 10.1016/S0166-2236(97)01220-4; Wallentin M, 2006, NEUROIMAGE, V32, P1850, DOI 10.1016/j.neuroimage.2006.05.002; Waller D, 2006, J EXP PSYCHOL LEARN, V32, P867, DOI 10.1037/0278-7393.32.4.867; Wang RF, 2002, TRENDS COGN SCI, V6, P376, DOI 10.1016/S1364-6613(02)01961-7; Wang RXF, 2003, J EXP PSYCHOL LEARN, V29, P398, DOI 10.1037/0278-7393.29.3.398; Wang RXF, 1999, COGNITION, V70, P191; Wang RXF, 2000, COGNITION, V77, P215, DOI 10.1016/S0010-0277(00)00105-0; Whishaw IQ, 1999, HIPPOCAMPUS, V9, P659, DOI 10.1002/(SICI)1098-1063(1999)9:6<659::AID-HIPO7>3.0.CO;2-E; Wills TJ, 2005, SCIENCE, V308, P873, DOI 10.1126/science.1108905; WYSS JM, 1992, HIPPOCAMPUS, V2, P1; YOUNG BJ, 1994, J NEUROSCI, V14, P6553; Zhang K, 1996, J NEUROSCI, V16, P2112; ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0	197	230	233	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0033-295X			PSYCHOL REV	Psychol. Rev.	APR	2007	114	2					340	375		10.1037/0033-295X.114.2.340		36	Psychology; Psychology, Multidisciplinary	Psychology	158AW	WOS:000245764200005	17500630	
J	Dahl, GE; Yu, D; Deng, L; Acero, A				Dahl, George E.; Yu, Dong; Deng, Li; Acero, Alex			Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Artificial neural network-hidden Markov model (ANN-HMM); context-dependent phone; deep belief network; deep neural network hidden Markov model (DNN-HMM); speech recognition; large-vocabulary speech recognition (LVSR)	MINIMUM CLASSIFICATION ERROR; HIDDEN MARKOV-MODELS; BOTTLE-NECK FEATURES; ADAPTATION; FRAMEWORK; ALGORITHM; LVCSR	We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.	[Dahl, George E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5A 2N4, Canada; [Yu, Dong; Deng, Li; Acero, Alex] Microsoft Res, Speech Res Grp, Redmond, WA 98034 USA	Dahl, GE (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5A 2N4, Canada.	gdahl@cs.toronto.edu; dongyu@microsoft.com; deng@microsoft.com; alexac@microsoft.com					Acero A, 2008, INT CONF ACOUST SPEE, P5256, DOI 10.1109/ICASSP.2008.4518845; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P78, DOI 10.1109/MSP.2009.932707; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Bengio Y, 2010, COMPUT INTELL, V26, P449, DOI 10.1111/j.1467-8640.2010.00366.x; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; BENGIO Y, 2007, LARG SCAL KERN MACH; Bengio Y, 2010, P AISTATS 2010, V9, P249; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Boulard H., 1993, IEEE T NEURAL NETWOR, V4, P893; BOURLARD H, 1994, KLUWER INT SERIES EN, P247; BOURLARD H, 1992, P IEEE INT C AC SPEE, P349, DOI 10.1109/ICASSP.1992.226048; Bridle J., 1998, 1998 WORKSH LANG ENG, P1; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Dahl G., 2011, P ICASSP; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P256, DOI 10.1109/TSA.2005.854107; Deng L, 1998, SPEECH COMMUN, V24, P299, DOI 10.1016/S0167-6393(98)00023-5; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; DENG L, 1999, NATO ASI SER, P199; Erhan D., 2010, P AISTATS 2010 MAY, V9, P201; Erhan D, 2009, P 12 INT C ART INT S, P153; FOUSEK P, 2008, P INT, P1433; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Gales MJF, 1996, COMPUT SPEECH LANG, V10, P249, DOI 10.1006/csla.1996.0013; Grezl F, 2008, INT CONF ACOUST SPEE, P4729, DOI 10.1109/ICASSP.2008.4518713; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Gunawardana A., 2005, P INTERSPEECH, P1117; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; HEIGOLD G, 2010, THESIS AACHEN U AACH; HENNEBERT J, 1997, P EUROSPEECH, V4, P1951; Hermansky H, 2000, P ICASSP, V3, P1635; Hifny Y, 2009, IEEE T AUDIO SPEECH, V17, P354, DOI 10.1109/TASL.2008.2010286; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hwang MY, 1993, IEEE T SPEECH AUDI P, V1, P414; Jarrett K., 2009, P INT C COMP VIS ICC; JIANG H, 2007, P IEEE INT C AC SPEE, V4, P629; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257; KAPADIA S, 1993, P ICASSP, V2, P491; Lee CH, 2000, P IEEE, V88, P1241; Li JY, 2009, COMPUT SPEECH LANG, V23, P389, DOI 10.1016/j.csl.2009.02.001; Li XW, 2005, INT CONF ACOUST SPEE, P513; Martens J, 2010, P 27 INT C MACH LEAR, P735; McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778; Mnih V., 2009, 2009004 UTML TR DEP; Mnih V., 2010, P 11 EUR C COMP VIS; MOHAMED A, 2011, IEEE T AUD SPEECH LA, V19; Mohamed A.-R., 2010, P INTERSPEECH, P2846; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Morgan N, 2005, IEEE SIGNAL PROC MAG, V22, P81, DOI 10.1109/MSP.2005.1511826; Morgan N., 1990, P IEEE INT C AC SPEE, P413; Morris J., 2006, P INT, P597; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Neto J., 1995, P EUROSPEECH 1995, P2171; Neto JP, 1996, INT CONF ACOUST SPEE, P3382, DOI 10.1109/ICASSP.1996.550603; Povey D., 2003, THESIS CAMBRIDGE U C; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Robinson AJ, 2002, SPEECH COMMUN, V37, P27, DOI 10.1016/S0167-6393(01)00058-9; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R. R., 2007, P SIGIR WORKSH INF R; Sha F, 2006, INT CONF ACOUST SPEE, P265; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sutskever I., 2009, P NIPS; Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8; Valente F., 2010, P INT, P2630; VERGYRI D, 2008, P INT, P1437; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; WELLING M, 2004, ADV NEURAL INF PROCE, V17; Yan YH, 1997, INT CONF ACOUST SPEE, P3241; YU D, 2010, P INT, P2986; Yu D, 2007, P IEEE INT C SEM COM, P429; YU D, 2010, P NIPS 2010 WORKSH D; YU D, 2006, P INT, P2418; Yu D., 2007, P INT, P2709; Yu D, 2009, IEEE T AUDIO SPEECH, V17, P1348, DOI 10.1109/TASL.2009.2020890; Yu D, 2008, COMPUT SPEECH LANG, V22, P415, DOI 10.1016/j.csl.2008.03.002; Yu D., 2007, P INT C AC SPEECH SI, V4, P1137; Zhu Q., 2005, P INT, P2141; Zweig Geoffrey, 2009, Proceedings of the 2009 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU 2009), DOI 10.1109/ASRU.2009.5372916; ZWEIG G, 2010, P INT	84	178	190	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	JAN	2012	20	1					30	42		10.1109/TASL.2011.2134090		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	865QO	WOS:000298325600007		
J	Hinton, G; Deng, L; Yu, D; Dahl, GE; Mohamed, AR; Jaitly, N; Senior, A; Vanhoucke, V; Nguyen, P; Sainath, TN; Kingsbury, B				Hinton, Geoffrey; Deng, Li; Yu, Dong; Dahl, George E.; Mohamed, Abdel-rahman; Jaitly, Navdeep; Senior, Andrew; Vanhoucke, Vincent; Patrick Nguyen; Sainath, Tara N.; Kingsbury, Brian			Deep Neural Networks for Acoustic Modeling in Speech Recognition	IEEE SIGNAL PROCESSING MAGAZINE			English	Article							FEATURES; NETS; REPRESENTATIONS; EXPERTS		[Deng, Li] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada; [Deng, Li; Yu, Dong; Patrick Nguyen] MSR, Redmond, WA USA; [Deng, Li] MIT, ATR Interpreting Telecommun Res Labs, Kyoto, Japan; [Deng, Li] Hong Kong Univ Sci & Technol, Hong Kong, Hong Kong, Peoples R China; [Mohamed, Abdel-rahman] Katholieke Univ Leuven, ESAT PSI Speech Grp, Louvain, Belgium; [Vanhoucke, Vincent] Speech R&D Team ,Nuance, Menlo Pk, CA USA; [Patrick Nguyen] Panason Speech Technol Lab, Santa Barbara, CA USA; [Jaitly, Navdeep] Capr Pharmaceut, Montreal, PQ, Canada	Hinton, G (reprint author), Univ Toronto, Toronto, ON M5S 1A1, Canada.	geoffrey.hinton@gmail.com; deng@microsoft.com; dongyu@ieee.org; george.dahl@gmail.com; asamir@cs.toronto.edu; ndjaitly@yahoo.com; andrewsenior@google.com; vanhoucke@google.com; drpng@google.com; tsainath@us.ibm.com; bedk@us.ibm.com	Magazine, Signal Processing/E-9947-2015				Abdel-Hamid O., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288864; Bahl L., 1986, P INT C AC SPEECH SI, V11, P49, DOI DOI 10.1109/ICASSP.1986.1169179>; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Bengio Y., 1991, P EUROSPEECH; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DENG L, 2012, P ICASSP, P2133; Deng L., 2003, MATH FDN SPEECH LANG, P115; Deng L., 1999, COMPUTATIONAL MODELS, P199; Deng L, 2011, P INTERSPEECH, P2285; Deng L, 2007, INT CONF ACOUST SPEE, P445; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; DENG L, 1994, J ACOUST SOC AM, V95, P2702, DOI 10.1121/1.409839; FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530; Furui S., 2000, DIGITAL SPEECH PROCE; Glorot X., 2010, P AISTATS, P249; Grezl F., 2007, P ICASSP; Halberstadt A., 1998, P ICSLP; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; Hifny Y, 2009, IEEE T AUDIO SPEECH, V17, P354, DOI 10.1109/TASL.2008.2010286; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton G.E., 2010, 2010003 UTML TR DEP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hutchinson B., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288994; Jaitly N., APPL PRETRAINE UNPUB; JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Le QV, 2011, P 28 INT C MACH LEAR, P265; Lee H., 2009, ADV NEURAL INFORM PR, V22, P1096; Martens J, 2010, P 27 INT C MACH LEAR, P735; MING J, 1998, ACOUST SPEECH SIG PR, P409; Mohamed A., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288863; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A.-R., 2010, P INTERSPEECH, P2846; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Morgan N, 2005, IEEE SIGNAL PROC MAG, V22, P81, DOI 10.1109/MSP.2005.1511826; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Pearl J., 1988, PROBABILISTIC INFERE; Plahl C., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288836; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Prabhavalkar R, 2010, INT CONF ACOUST SPEE, P5534, DOI 10.1109/ICASSP.2010.5495222; Rifai S., 2011, P 28 INT C MACH LEAR, P833; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath T. N., 2011, 2010003 IBM UTML TR; Sainath T. N., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288833; Sainath TN, 2011, IEEE T AUDIO SPEECH, V19, P2598, DOI 10.1109/TASL.2011.2155060; Sainath TN, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P359, DOI 10.1109/ASRU.2009.5373263; Seide F., 2011, P ASRU, P24; Seide F., 2011, P INTERSPEECH, P437; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Sun JP, 2002, J ACOUST SOC AM, V111, P1086, DOI 10.1121/1.1420380; Vanhoucke V., 2011, P DEEP LEARN UNS FEA; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vinyals O, 2011, INT CONF ACOUST SPEE, P4596; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824; Yu D., 2010, P NIPS WORKSH DEEP L; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4169; Zen H, 2012, IEEE T AUDIO SPEECH, V20, P794, DOI 10.1109/TASL.2011.2165280; Zweig G, 2011, INT CONF ACOUST SPEE, P5044	68	175	179	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888			IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	NOV	2012	29	6					82	97		10.1109/MSP.2012.2205597		16	Engineering, Electrical & Electronic	Engineering	027IF	WOS:000310345000010		
J	Mohamed, AR; Dahl, GE; Hinton, G				Mohamed, Abdel-rahman; Dahl, George E.; Hinton, Geoffrey			Acoustic Modeling Using Deep Belief Networks	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Acoustic modeling; deep belief networks (DBNs); neural networks; phone recognition	NEURAL-NETWORKS; SPEECH RECOGNITION; CLASSIFICATION; ALGORITHM; NETS	Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.	[Mohamed, Abdel-rahman; Dahl, George E.; Hinton, Geoffrey] Univ Toronto, Toronto, ON M5S 3G4, Canada	Mohamed, AR (reprint author), Univ Toronto, Toronto, ON M5S 3G4, Canada.	asamir@cs.toronto.edu; gdahl@cs.toronto.edu; hinton@cs.toronto.edu			Natural Sciences and Engineering Research Council of Canada; Canadian Institute for Advanced Research	The research was supported in part by a gift from Microsoft Research and in part by grants from the Natural Sciences and Engineering Research Council of Canada and the Canadian Institute for Advanced Research. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Nelson Morgan.	Allen JB, 1994, IEEE T SPEECH AUDI P, V2, P567, DOI 10.1109/89.326615; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; BENGIO Y, 1991, THESIS MCGILL U MONT; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Brown P., 1987, THESIS CARNEGIE MELL; CARREIRAPERPIGN.MA, 2005, P ARTIF INTELL STATI; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Dahl G., IEEE T AUDI IN PRESS; Deng L, 2007, INT CONF ACOUST SPEE, P445; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; DIGALAKIS VV, 1992, IEEE T SIGNAL PROCES, V40, P2885, DOI 10.1109/78.175733; Halberstadt A., 1998, P ICSLP; Hermansky H., 1998, P INT C SPOK LANG PR, P1003; Hifny Y, 2009, IEEE T AUDIO SPEECH, V17, P354, DOI 10.1109/TASL.2008.2010286; Hinton G., 2010, 2010003 U TOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jansen A, 2008, INT CONF ACOUST SPEE, P4093, DOI 10.1109/ICASSP.2008.4518554; Krizhevsky A., 2009, THESIS U TORONTO TOR; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; MING J, 1998, ACOUST SPEECH SIG PR, P409; MNIH V, 2010, P EUR C COMP VIS; Mnih V., 2009, 2009004 UTML TR DEP; MOHAMED A, 2010, P INT 10; Morgan N, 2005, IEEE SIGNAL PROC MAG, V22, P81, DOI 10.1109/MSP.2005.1511826; MORIS J, 2006, P INT, P597; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Pearl J., 1988, PROBABILISTIC INFERE; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; SAINATH TN, 2009, P IEEE AUT SPEECH RE; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Sha F, 2006, INT CONF ACOUST SPEE, P265; SUTSKEVER I, 2008, ADV NEURAL INF PROCE, V21, P1593; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Williams C., 2002, EDIINFRR0120 U ED I	41	138	147	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	JAN	2012	20	1					14	22		10.1109/TASL.2011.2109382		9	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	865QO	WOS:000298325600005		
J	Sussillo, D; Abbott, LF				Sussillo, David; Abbott, L. F.			Generating Coherent Patterns of Activity from Chaotic Neural Networks	NEURON			English	Article							CORTEX; COMPUTATION; PREMOTOR; SYSTEMS; NEURONS; DELAY	Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.	[Sussillo, David; Abbott, L. F.] Columbia Univ Coll Phys & Surg, Dept Physiol & Cellular Biophys, Dept Neurosci, New York, NY 10032 USA	Sussillo, D (reprint author), Columbia Univ Coll Phys & Surg, Dept Physiol & Cellular Biophys, Dept Neurosci, New York, NY 10032 USA.	sussillo@neurotheory.columbia.edu; ifa2103@columbia.edu			NIH [5-DP1-OD114-02]; National Institute of Mental Health [MH-58754]	Research was supported by an NIH Director's Pioneer Award, part of the NIH Roadmap for Medical Research, through grant number 5-DP1-OD114-02 and by National Institute of Mental Health grant MH-58754. We thank Taro Toyoizumi, Surya Ganguli, Greg Wayne, and Graham Taylor for helpful comments and suggestions.	Abarbanel HDI, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.016208; Amit DJ, 1997, CEREB CORTEX, V7, P237, DOI 10.1093/cercor/7.3.237; Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741; Bertschinger N, 2004, NEURAL COMPUT, V16, P1413, DOI 10.1162/089976604323057443; Brunel N, 2000, J PHYSIOLOGY-PARIS, V94, P445, DOI 10.1016/S0928-4257(00)01084-6; BUONOMANO DV, 1995, SCIENCE, V267, P1028, DOI 10.1126/science.7863330; Buonomano DV, 2009, NAT REV NEUROSCI, V10, P113, DOI 10.1038/nrn2558; Churchland MM, 2007, J NEUROPHYSIOL, V97, P348, DOI 10.1152/jn.00808.2006; Churchland MM, 2007, J NEUROPHYSIOL, V97, P4235, DOI 10.1152/jn.00095.2007; Churchland MM, 2006, J NEUROSCI, V26, P3697, DOI 10.1523/JNEUROSCI.3762-05.2006; DOYA K, 1992, IEEE INT S CIRCUITS, V6, P2777; FETZ EE, 1992, BEHAV BRAIN SCI, V15, P679; Ganguli S, 2008, P NATL ACAD SCI USA, V105, P18970, DOI 10.1073/pnas.0804451105; Haykin S., 2002, ADAPTIVE FILTER THEO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaeger H, 2003, ADV NEURAL INFORM PR, V15, P593; Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Maass W, 2007, PLOS COMPUT BIOL, V3, P15, DOI 10.1371/journal.pcbi.0020165.eor; MIALL RC, 1993, J MOTOR BEHAV, V25, P203; MOLGEDEY L, 1992, PHYS REV LETT, V69, P3717, DOI 10.1103/PhysRevLett.69.3717; Pearlmutter B. A., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.263; ROBINSON DA, 1992, BEHAV BRAIN SCI, V15, P644; Rumelhart D. E., 1986, EXPLORATIONS MICROST, V1; SOMPOLINSKY H, 1988, PHYS REV LETT, V61, P259, DOI 10.1103/PhysRevLett.61.259; Strogatz S. H., 1994, NONLINEAR DYNAMICS C; SUSSILLO D, 2009, THESIS COLUMBIA U NE, P93; TAYLOR GW, 2006, ADV NEURAL INFORM PR, V19, P1370; vanVreeswijk C, 1996, SCIENCE, V274, P1724; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; Yuste R, 2005, NAT REV NEUROSCI, V6, P477, DOI 10.1038/nrn1686	31	106	108	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	0896-6273			NEURON	Neuron	AUG 27	2009	63	4					544	557		10.1016/j.neuron.2009.07.018		14	Neurosciences	Neurosciences & Neurology	491HV	WOS:000269570400013	19709635	
J	Hinton, GE				Hinton, Geoffrey E.			Learning multiple a layers of representation	TRENDS IN COGNITIVE SCIENCES			English	Review							NATURAL IMAGES; NEURAL-NETWORKS; ALGORITHM; MODELS; MACHINES	To achieve its impressive performance in tasks such as speech perception or object recognition, the brain extracts multiple levels of representation from the sensory input. Backpropagation was the first computationally efficient model of how neural networks could learn multiple layers of representation, but it required labeled training data and it did not work well in deep networks. The limitations of backpropagation learning can now be overcome by using multilayer neural networks that contain top-down connections and training them to generate sensory data rather than to classify it. Learning multilayer generative models might seem difficult, but a recent discovery makes it easy to learn nonlinear distributed representations one layer at a time.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Hinton, GE (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Colll Rd, Toronto, ON M5S 3G4, Canada.	hinton@cs.toronto.edu					Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BENGIO Y, LARGE SCALE KERNEL M; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bishop CM, 2006, PATTERN RECOGNITION; BISHOP CM, 2002, ADV NEURAL INFORMATI, V15, P793; Cowell RG, 2003, PROBABILISTIC NETWOR; Dayan P., 2001, THEORETICAL NEUROSCI; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Hinton G. E., 1994, ADV NEURAL INFORMATI, V6, P3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hoyer PO, 2002, VISION RES, V42, P1593, DOI 10.1016/S0042-6989(02)00017-2; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Karklin Y, 2003, NETWORK-COMP NEURAL, V14, P483, DOI 10.1088/0954-898X/14/3/306; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Lewicki MS, 1997, ADV NEUR IN, V9, P529; Marks T. K., 2001, P INT C IND COMP AN, P481; Memisevic R., 2007, COMPUTER VISION PATT, P1; Mnih A., 2007, P 24 INT C MACH LEAR, P641, DOI 10.1145/1273496.1273577; MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; O'Reilly RC, 1998, TRENDS COGN SCI, V2, P455, DOI 10.1016/S1364-6613(98)01241-8; OSINDERO S, IN PRESS ADV NEURAL, V20; Pearl J., 1988, PROBABILISTIC INFERE; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; RANZATO M, 2007, P 11 INT C ART INT S, P368; ROTH S, 2005, CVPR, V2, P860; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Schwartz O, 2006, NEURAL COMPUT, V18, P2680, DOI 10.1162/neco.2006.18.11.2680; Sutskever I., 2007, P 11 INT C ART INT S, P544; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Welling M, 2002, LECT NOTES COMPUT SC, V2415, P351; WINN J, 2005, 10 IEEE INT C COMP V, V1, P756, DOI 10.1109/ICCV.2005.148	43	100	104	ELSEVIER SCIENCE LONDON	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	1364-6613			TRENDS COGN SCI	TRENDS COGN. SCI.	OCT	2007	11	10					428	434		10.1016/j.tics.2007.09.004		7	Behavioral Sciences; Neurosciences; Psychology, Experimental	Behavioral Sciences; Neurosciences & Neurology; Psychology	229GG	WOS:000250790600007	17921042	
J	Salakhutdinov, R; Hinton, G				Salakhutdinov, Ruslan; Hinton, Geoffrey			Semantic hashing	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article; Proceedings Paper	Workshop on Information Retrieval and Graphical Models held at the 30th Annual International ACM SIGIR Conference	JUL 23-27, 2007	Amsterdam, NETHERLANDS	ACM		Information retrieval; Graphical models; Unsupervised learning		We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs "semantic hashing": Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is Much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set. (C) 2008 Elsevier Inc. All rights reserved.	[Salakhutdinov, Ruslan; Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Salakhutdinov, R (reprint author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	rsalakhu@cs.toronto.edu; hinton@cs.toronto.edu					ANDONI A, 2006, FOCS, P459; Bengio Y., 2007, SCALING LEARNING ALG; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; CHOPRA S, 2005, IEEE COMPUTER VISION, P539; DATAR I, 2004, COMPGEOM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; FRIEDMAN JH, 1975, ALGORITHM FINDING BE; GEHLER P, 2006, P 23 INT C MACH LEAR; Hinton G. E., 2002, ADV NEURAL INFORM PR, P833; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hofmann T., 1999, P 15 C UNC ART INT U, P289; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Liu T., 2004, ADV NEURAL INFORM PR; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Salakhutdinov R., 2007, AI STAT; SALTON, 1991, SCIENCE, P253; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Torralba A., 2008, P IEEE C COMP VIS PA; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Xing E.P., 2005, P 21 C UNC ART INT U	22	98	108	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	JUL	2009	50	7					969	978		10.1016/j.ijar.2008.11.006		10	Computer Science, Artificial Intelligence	Computer Science	472RC	WOS:000268148700005		
J	Erhan, D; Bengio, Y; Courville, A; Manzagol, PA; Vincent, P; Bengio, S				Erhan, Dumitru; Bengio, Yoshua; Courville, Aaron; Manzagol, Pierre-Antoine; Vincent, Pascal; Bengio, Samy			Why Does Unsupervised Pre-training Help Deep Learning?	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						deep architectures; unsupervised pre-training; deep belief networks; stacked denoising auto-encoders; non-convex optimization	NEURAL-NETWORKS; CONTRASTIVE DIVERGENCE; DIMENSIONALITY	Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pretraining guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.	[Erhan, Dumitru; Bengio, Yoshua; Courville, Aaron; Manzagol, Pierre-Antoine; Vincent, Pascal] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J8, Canada; [Bengio, Samy] Google Res, Mountain View, CA 94043 USA	Erhan, D (reprint author), Univ Montreal, Dept Informat & Rech Operat, 2920 Chemin Tour, Montreal, PQ H3T 1J8, Canada.	DUMITRU.ERHAN@UMONTREAL.CA; YOSHUA.BENGIO@UMONTREAL.CA; AARON.COURVILLE@UMONTREAL.CA; PIERRE-ANTOINE.MANZAGOL@UMONTREAL.CA; PASCAL.VINCENT@UMONTREAL.CA; BENGIO@GOOGLE.COM			NSERC; MITACS; FQRNT; Canada Research Chairs	This research was supported by funding from NSERC, MITACS, FQRNT, and the Canada Research Chairs. The authors also would like to thank the editor and reviewers, as well as Fernando Pereira for their helpful comments and suggestions.	Amari S, 1997, IEEE T NEURAL NETWOR, V8, P985, DOI 10.1109/72.623200; Bahl L. R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4); BARRON AR, 1991, NATO ADV SCI I C-MAT, V335, P561; Belkin M, 2002, ADV NEURAL INFORM PR, V14; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BORNSTEIN MH, 1987, SENSITIVE PERIODS DE; Chapelle O., 2006, SEMISUPERVISED LEARN; Chapelle O., 2003, ADV NEURAL INFORM PR, V15, P585; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Erhan D., 2009, 1341 U MONTR; GALLINARI P, 1987, P COGNITIVA PAR VILL, V87; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646; HADSELL R, 2008, P INT ROB SYST IROS, P628; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Larochelle Hugo, 2007, ICML, P473; Lasserre J. A., 2006, P IEEE C COMP VIS PA, P87; LeCun Y., 1987, THESIS U PARIS 6; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee Honglak, 2009, P 26 INT C MACH LEAR; Loosli G., 2007, LARGE SCALE KERNEL M, P301; Mobahi H., 2009, P 26 ANN INT C MACH, P737; Ng AY, 2002, ADV NEUR IN, V14, P841; Osindero S, 2008, ADV NEURAL INFORM PR, V20, P1121; Povey D., 2002, P IEEE INT C AC SPEE, V1; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; Salakhutdinov R., 2007, P 2007 WORKSH INF RE; Salakhutdinov RR, 2008, ADV NEURAL INFORM PR, V20, P1249; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Seung HS, 1998, ADV NEUR IN, V10, P654; Sjoberg J, 1995, INT J CONTROL, V62, P1391, DOI 10.1080/00207179508921605; Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; Yao A. C., 1985, P 26 ANN IEEE S FDN, P1; Zhu L, 2009, IEEE T PATTERN ANAL, V31, P114, DOI 10.1109/TPAMI.2008.67	51	96	106	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2010	11						625	660				36	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	589XC	WOS:000277186500007		
J	Clark, A				Clark, Andy			Whatever next? Predictive brains, situated agents, and the future of cognitive science	BEHAVIORAL AND BRAIN SCIENCES			English	Article						action; attention; Bayesian brain; expectation; generative model; hierarchy; perception; precision; predictive coding; prediction; prediction error; top-down processing	PRIMARY VISUAL-CORTEX; SIZE-WEIGHT ILLUSION; ATTENTION ALTERS APPEARANCE; LATENT SEMANTIC ANALYSIS; COMPLEX CELL PROPERTIES; GRIFFITHS ET-AL.; BINOCULAR-RIVALRY; RECEPTIVE-FIELDS; FREE-ENERGY; PHONOLOGICAL TYPICALITY	Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this "hierarchical prediction machine" approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.	Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Edinburgh EH8 9AD, Midlothian, Scotland	Clark, A (reprint author), Univ Edinburgh, Sch Philosophy Psychol & Language Sci, Edinburgh EH8 9AD, Midlothian, Scotland.	andy.clark@ed.ac.uk			AHRC, under the ESF Eurocores CONTACT (Consciousness in Interaction) project [AH/E511139/1]	This target article has benefitted enormously from comments and reactions from a wide variety of readers and audiences. Special thanks are due to the BBS referees, who provided an especially rich and challenging set of comments and suggestions. The present incarnation of this article owes a great deal to their patient and extensive help and probing. Thanks also to Karl Friston, Jakob Hohwy, Tim Bayne, Andreas Roepstorff, Chris Thornton, Liz Irvine, Matteo Colombo, and all the participants at the Predictive Coding Workshop (School of Informatics, University of Edinburgh, January 2010); to Phil Gerrans, Nick Shea, Mark Sprevak, Aaron Sloman, and the participants at the first meeting of the UK Mind Network held at the Faculty of Philosophy, Oxford University, March 2010; to Markus Werning, and the organizers and participants of the 2010 meeting of the European Society for Philosophy and Psychology, held at Ruhr-Universitat Bochum, August 2010; to Nihat Ay, Ray Guillery, Bruno Olshausen, Murray Sherman, Fritz Sommer, and the participants at the Perception & Action Workshop, Santa Fe Institute, New Mexico, September 2010; to Daniel Dennett, Rosa Cao, Justin Junge, and Amber Ross (captain and crew of the hurricane-Irene-blocked 2011 Cognitive Cruise); to Miguel Eckstein, Mike Gazzaniga, Michael Rescorla, and the faculty and students at the Sage Center for the Study of Mind, University of California, Santa Barbara, where, as a Visiting Fellow in September 2011, I was privileged to road-test much of this material; and to Peter Konig, Jon Bird, Lee de-Wit, Suzanna Siegel, Matt Nudds, Mike Anderson, Robert Rupert, Bill Phillips, and Rae Langton. A much earlier version of some of this material was prepared thanks to support from the AHRC, under the ESF Eurocores CONTACT (Consciousness in Interaction) project, AH/E511139/1.	ABELSON RP, 1981, AM PSYCHOL, V36, P715, DOI 10.1037/0003-066X.36.7.715; Adams F, 2001, PHILOS PSYCHOL, V14, P43, DOI 10.1080/09515080120033571; Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029; Alink A, 2010, J NEUROSCI, V30, P2960, DOI 10.1523/JNEUROSCI.3730-10.2010; Anderson C., 1994, COMPUTATIONAL INTELL, P213; Anderson ML, 2007, PHILOS PSYCHOL, V20, P143, DOI 10.1080/09515080701197163; ANDERSON ML, 2006, PHENOMENOLOGY COGNIT, V5, P125, DOI 10.1007/s11097-005-9008-5; Angelucci A, 2002, J NEUROSCI, V22, P8633; Anton-Erxleben K, 2007, J VISION, V7, DOI 10.1167/7.11.5; Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914; Arthur B, 1994, INCREASING RETURNS P; Ashby WR, 1947, J GEN PSYCHOL, V37, P125, DOI 10.1080/00221309.1947.9918144; Ashby WR, 1940, J MENT SCI, V86, P478; Ay N, 2008, EUR PHYS J B, V63, P329, DOI 10.1140/epjb/e2008-00175-0; Baerger DR, 1999, NARRAT INQ, V9, P69, DOI 10.1075/ni.9.1.05bae; Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005; Barlow H.B., 1961, SENS COMMUN, P217; Barrett LF, 2009, PERSPECT PSYCHOL SCI, V4, P326, DOI 10.1111/j.1745-6924.2009.01134.x; Barrett LF, 2009, PHILOS T R SOC B, V364, P1325, DOI 10.1098/rstb.2008.0312; Baugh LA, 2012, J NEUROPHYSIOL, V108, P1262, DOI 10.1152/jn.00263.2012; BECHTEL W, 2006, MATTER MIND PHILOS E, pCH8; Beer RD, 2000, TRENDS COGN SCI, V4, P91, DOI 10.1016/S1364-6613(99)01440-0; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; BERLYNE DE, 1970, PERCEPT PSYCHOPHYS, V8, P279, DOI 10.3758/BF03212593; Berniker M, 2008, NAT NEUROSCI, V11, P1454, DOI 10.1038/nn.2229; Betsch BY, 2004, BIOL CYBERN, V90, P41, DOI 10.1007/s00422-003-0434-6; BINDRA D, 1959, PSYCHOL REV, V66, P96, DOI 10.1037/h0046410; Blake R, 2001, BRAIN MIND, V2, P5, DOI [10.1023/A:1017925416289, DOI 10.1023/A:1017925416289]; Blake R., 2005, BINOCULAR RIVALRY; Blakemore SJ, 2003, NEUROPSYCHOLOGIA, V41, P1058, DOI 10.1016/S0028-3932(02)00313-5; BORN RT, 2009, DYNAMICS VISUAL MOTI, P37, DOI 10.1007/978-1-4419-0781-3_2; Bourdieu Pierre, 1977, OUTLINE THEORY PRACT; BRAINARD D, 2009, VISUAL NEUROSCI, P395; Brayanov JB, 2010, J NEUROPHYSIOL, V103, P1518, DOI 10.1152/jn.00814.2009; Brown H, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00218; BROWN M, 2012, P 34 ANN C COGN SCI, P1374; Brown M, 2011, PSYCHON B REV, V18, P1189, DOI 10.3758/s13423-011-0167-9; Brown R. G., 1992, INTRO RANDOM SIGNALS; BROWN S, 2003, B PSYCHOL ARTS, V4, P14; BRUNER J, 1991, CRIT INQUIRY, V18, P1, DOI 10.1086/448619; Bruner J., 1986, ACTUAL MINDS POSSIBL; BUBIC A, 2010, FRONT HUM NEUROSCI, V4, P1, DOI DOI 10.3389/FNHUM.2010.00025/ABSTRACT.ACCESSED:2012; Buckingham G, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009709; Buhusi CV, 2005, NAT REV NEUROSCI, V6, P755, DOI 10.1038/nrn1764; Burge J, 2010, J NEUROSCI, V30, P7269, DOI 10.1523/JNEUROSCI.5551-09.2010; Burr D, 2007, NAT NEUROSCI, V10, P423, DOI 10.1038/nn1874; Carandini M, 2012, NAT NEUROSCI, V15, P507, DOI 10.1038/nn.3043; Carandini M, 2005, J NEUROSCI, V25, P10577, DOI 10.1523/JNEUROSCI.3726-05.2005; Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012; Carrasco M, 2004, NAT NEUROSCI, V7, P308, DOI 10.1038/nn1194; Chappell J, 2007, INT J UNCONV COMPUT, V3, P211; Chater N, 2006, TRENDS COGN SCI, V10, P335, DOI 10.1016/j.tics.2006.05.006; Chemero A, 2009, BRADFORD BOOKS, P1; Chen L, 2005, VIS COGN, V12, P553, DOI 10.1080/13506280444000256; CHENNU S, 2009, PLOS COMPUT BIOL, V5, P1; Chittka L, 2011, P ROY SOC B-BIOL SCI, V278, P885, DOI 10.1098/rspb.2010.2699; Churchland PM, 2012, PLATO'S CAMERA: HOW THE PHYSICAL BRAIN CAPTURES A LANDSCAPE OF ABSTRACT UNIVERSALS, P1; CHURCHLAND PM, 1989, NEUROCOMPUT PERSPECT; CLARK A, 1993, MIND, V102, P587, DOI 10.1093/mind/102.408.587; CLARK A, 1989, MICROCOGNITION PHILO; Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096; CLARK A, 2008, SUPERSIZING MIND ACT; Clark A, 2006, TRENDS COGN SCI, V10, P370, DOI 10.1016/j.tics.2006.06.012; Clark A, 2012, MIND, V121, P753, DOI 10.1093/mind/fzs106; CLARK A, PERCEPTION IN PRESS; CLARK A, 1987, MIND LANG, V2, P277, DOI DOI 10.1111/J.1468-0017.1987.TB00123.X; Clark A., 1997, BEING THERE PUTTING; Clark A, 2006, PHILOS PSYCHOL, V19, P291, DOI 10.1080/09515080600689872; Clark A, 1997, BEHAV BRAIN SCI, V20, P57; Clifford CWG, 2007, VISION RES, V47, P3125, DOI 10.1016/j.visres.2007.08.023; Coltheart M, 2007, Q J EXP PSYCHOL, V60, P1041, DOI 10.1080/17470210701338071; CONRAD K, 1958, BEGINNENDE SCHIZOPHE; Corlett PR, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.012.2009; Corlett PR, 2010, PROG NEUROBIOL, V92, P345, DOI 10.1016/j.pneurobio.2010.06.007; Corlett PR, 2009, PSYCHOPHARMACOLOGY, V206, P515, DOI 10.1007/s00213-009-1561-0; Craig AD, 2003, CURR OPIN NEUROBIOL, V13, P500, DOI 10.1016/S0959-4388(03)00090-4; Craig AD, 2009, NAT REV NEUROSCI, V10, P59, DOI 10.1038/nrn2555; Craik K., 1943, NATURE EXPLANATION; Critchley H, 2012, NEURON, V74, P423, DOI 10.1016/j.neuron.2012.04.012; Critchley HD, 2004, NAT NEUROSCI, V7, P189, DOI 10.1038/nn1176; CRUTCHFIELD JP, 1989, PHYS REV LETT, V63, P105, DOI 10.1103/PhysRevLett.63.105; Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498; Damasio A, 2000, FEELING WHAT HAPPENS; Danckert J, 2004, SCHIZOPHR RES, V70, P241, DOI 10.1016/j.schres.2003.12.007; Daprati E, 1997, COGNITION, V65, P71, DOI 10.1016/S0010-0277(97)00039-5; Darwin C., 1871, DESCENT MAN SELECTIO; Davidson D., 1974, P ADDRESSES AM PHILO, V47, P5; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DAYAN P, 1997, FOUND COMPUT MATH, P43; DEGARDELLE V, 2012, CEREBRAL CORTEX; Dehaene S., 2009, READING BRAIN; Demos AP, 2012, J EXP PSYCHOL GEN, V141, P49, DOI 10.1037/a0023843; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; Dennett D., 1991, CONSCIOUSNESS EXPLAI; Dennett D, 2009, P NATL ACAD SCI USA, V106, P10061, DOI 10.1073/pnas.0904433106; DENNETT D, 1978, BRAINSTORMS PHILOS; Dennett DC, 1987, INTENTIONAL STANCE; den Ouden HEM, 2010, J NEUROSCI, V30, P3210, DOI 10.1523/JNEUROSCI.4458-09.2010; den Ouden HEM, 2009, CEREB CORTEX, V19, P1175, DOI 10.1093/cercor/bhn161; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; De-Wit L, 2010, J NEUROSCI, V30, P8702, DOI 10.1523/JNEUROSCI.2248-10.2010; DEWIT LH, 2012, J VIS, V12, P1, DOI DOI 10.1167/12.11.12.[; Di Paolo Ezequiel, 2010, ENACTION NEW PARADIG, P33; Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751; Dilley LC, 2008, J MEM LANG, V59, P294, DOI 10.1016/j.jml.2008.06.006; Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743; Dima D, 2010, NEUROIMAGE, V52, P824, DOI 10.1016/j.neuroimage.2009.12.086; Dima D, 2009, NEUROIMAGE, V46, P1180, DOI 10.1016/j.neuroimage.2009.03.033; Di Paolo E, 2009, TOPOI-INT REV PHILOS, V28, P9, DOI 10.1007/s11245-008-9042-3; Doherty MJ, 2010, DEVELOPMENTAL SCI, V13, P714, DOI 10.1111/j.1467-7687.2009.00931.x; Doherty MJ, 2008, PERCEPTION, V37, P1426, DOI 10.1068/p5946; Doya K., 2007, BAYESIAN BRAIN PROBA; Dumoulin SO, 2006, J NEUROPHYSIOL, V95, P3654, DOI 10.1152/jn.01156.2005; Egner T, 2010, J NEUROSCI, V30, P16601, DOI 10.1523/JNEUROSCI.2770-10.2010; Einhauser W, 2002, EUR J NEUROSCI, V15, P475, DOI 10.1046/j.0953-816x.2001.01885.x; Einhauser W, 2009, ANN NY ACAD SCI, V1164, P353, DOI 10.1111/j.1749-6632.2008.03709.x; Eliades SJ, 2008, NATURE, V453, P1102, DOI 10.1038/nature06910; ELIASMITH C, BUILD BRAIN IN PRESS; ELIASMITH C, 2003, NEURAL ENG COMPUT; Eliasmith C, 2007, SYNTHESE, V159, P373, DOI 10.1007/s11229-007-9235-0; Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266; Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565; Erlhagen W, 2003, BIOL CYBERN, V88, P409, DOI 10.1007/s00422-002-0387-1; Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a; Ernst MO, 2010, CURR BIOL, V20, pR357, DOI 10.1016/j.cub.2010.03.009; Everitt BJ, 2001, BRAIN RES REV, V36, P129, DOI 10.1016/S0165-0173(01)00088-1; Evrard HC, 2012, NEURON, V74, P482, DOI 10.1016/j.neuron.2012.03.003; Fabre-Thorpe M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00243; Farmer TA, 2011, J EXP PSYCHOL LEARN, V37, P1318, DOI 10.1037/a0023063; Farmer TA, 2006, P NATL ACAD SCI USA, V103, P12203, DOI 10.1073/pnas.0602173103; Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215; Feldman JA, 2010, TRENDS COGN SCI, V14, P341, DOI 10.1016/j.tics.2010.05.008; ffytche DH, 1999, BRAIN, V122, P1247, DOI 10.1093/brain/122.7.1247; FINE AB, UNPUB; Fiorillo Christopher D., 2012, Information, V3, DOI 10.3390/info3020175; Flanagan JR, 2000, NAT NEUROSCI, V3, P737, DOI 10.1038/76701; Flanagan JR, 2008, CURR BIOL, V18, P1742, DOI 10.1016/j.cub.2008.09.042; Fletcher PC, 2009, NAT REV NEUROSCI, V10, P48, DOI 10.1038/nrn2536; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Freeman TCA, 2010, CURR BIOL, V20, P757, DOI 10.1016/j.cub.2010.02.059; Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000211; Friston K, 2011, NEURON, V72, P488, DOI 10.1016/j.neuron.2011.10.018; Friston K. J., 2011, IMPLICATIONS EMBODIM, P89; Friston KJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006421; Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005; Friston KJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00151; Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005; Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z; Friston KJ, 2007, SYNTHESE, V159, P417, DOI 10.1007/s11229-007-9237-y; Friston KJ, 2002, ANNU REV NEUROSCI, V25, P221, DOI 10.1146/annurev.neuro.25.112701.142846; Friston KJ, 2011, BIOL CYBERN, V104, P137, DOI 10.1007/s00422-011-0424-z; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; Friston KJ, 2009, NEURAL NETWORKS, V22, P1093, DOI 10.1016/j.neunet.2009.07.023; Frith C, 1999, TRENDS COGN SCI, V3, P105, DOI 10.1016/S1364-6613(99)01281-4; Frith C, 2012, CONSCIOUS COGN, V21, P52, DOI 10.1016/j.concog.2011.06.010; FRITH CD, ENCYL PHILO IN PRESS, V1; FRITH CD, 2007, MAKING UP MIND BRAIN; FROESE T, 2010, CYBERNETICS HUMAN KN, V17, P83; Froese T, 2011, PRAGMAT COGN, V19, P1, DOI 10.1075/pc.19.1.01fro; FROESE T, 2009, ARTIF INTELL, V173, P366; Fuster JM, 2001, NEURON, V30, P319, DOI 10.1016/S0896-6273(01)00285-9; Gallagher S, 2004, PSYCHOPATHOLOGY, V37, P8, DOI 10.1159/000077014; GALTON F, 1883, INQUIRES HUMAN FAC; GEERTZ C, 1966, INTERPRETATION CULTU, P87; Geisler WS, 2002, NAT NEUROSCI, V5, P508, DOI 10.1038/nn0602-508; GEISSLER HG, 1991, ESTRATTO COMUN SCI P, V5, P47; GEISSLER HG, 1983, MODERN ISSUES PERCEP, P87; Geldmacher David S., 2003, Frontiers in Bioscience, V8, P428; Gerrans P, 2007, BIOL PHILOS, V22, P35, DOI 10.1007/s10539-006-9025-y; Gershman SJ, 2012, COMPUT NEUROSCI-MIT, P293; Gibson J. J., 1966, SENSES CONSIDERED PE; GIBSON JJ, 1979, ECOL APPROACH VISUAL; Gilbert DT, 2009, PHILOS T R SOC B, V364, P1335, DOI 10.1098/rstb.2008.0305; GLIMCHER P, 2010, FDN NEUROECONOMIC AN; Glimcher PW, 2003, BRADFORD BOOKS, P1; GOLD JN, 2001, TRENDS COGN SCI, V5, P16238; GOOCH CM, 2001, FRONTIERS INTEGRATIV, V5, P1; Gowaty PA, 2009, P NATL ACAD SCI USA, V106, P10017, DOI 10.1073/pnas.0901130106; Gowaty PA, 2005, INTEGR COMP BIOL, V45, P931, DOI 10.1093/icb/45.5.931; Graesser AC, 1997, ANNU REV PSYCHOL, V48, P163, DOI 10.1146/annurev.psych.48.1.163; Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893; Grahn JA, 2009, NEUROIMAGE, V47, P1894, DOI 10.1016/j.neuroimage.2009.04.039; Gregory R, 1998, BRIT MED J, V317, P1693; GREGORY RL, 1980, PHILOS T ROY SOC B, V290, P181, DOI 10.1098/rstb.1980.0090; GRIFFITHS PE, 2001, CYCLES CONTINGENCY D, P195; Griffiths TL, 2010, TRENDS COGN SCI, V14, P357, DOI 10.1016/j.tics.2010.05.004; Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006; Grodner D. J., 2011, PROCESSING ACQUISITI, V2327, P239; Grossberg S, 2013, NEURAL NETWORKS, V37, P1, DOI 10.1016/j.neunet.2012.09.017; Grush R, 2004, BEHAV BRAIN SCI, V27, P377; Hajcak G, 2008, PSYCHOL SCI, V19, P103, DOI 10.1111/j.1467-9280.2008.02053.x; Harman KL, 1999, CURR BIOL, V9, P1315, DOI 10.1016/S0960-9822(00)80053-6; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; HARRISON LM, 2011, FRONT HUM NEUROSCI, V5, P1; Haugeland J, 1998, HAVING THOUGHT ESSAY, P207; Hawkins J., 2004, INTELLIGENCE; Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027; Helbig HB, 2007, EXP BRAIN RES, V179, P595, DOI 10.1007/s00221-006-0814-y; Hennig H, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026457; Hesselmann G, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009926; HINTON G, 2006, ADV NEURAL INFORM PR, V18, P515; Dayan P, 1996, NEURAL NETWORKS, V9, P1385, DOI 10.1016/S0893-6080(96)00009-3; HINTON GE, 1994, ADV NEURAL INFORM PR, V6; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168306; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HINTON GE, 2007, COMPUT NEUROSCI THEO; HIRSCH HVB, 1970, SCIENCE, V168, P869, DOI 10.1126/science.168.3933.869; Hirsh JB, 2012, PSYCHOL REV, V119, P304, DOI 10.1037/a0026767; Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI 10.1016/0262-8856(83)90003-3; Hohwy J, 2008, COGNITION, V108, P687, DOI 10.1016/j.cognition.2008.05.010; HOHWY J, 2012, FRONT PSYCHOL, V3, P1, DOI DOI 10.3389/FPSYG.2012.00096.[; Hohwy J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009416; Hohwy J, 2007, SYNTHESE, V159, P315, DOI 10.1007/s11229-007-9240-3; HOLLENSEN P, 2011, COSYNE ANN M SALT LA; Hollerman JR, 1998, NAT NEUROSCI, V1, P304; HOLM L, J EXP PSYCH IN PRESS; Horstmann G, 2002, PSYCHOL SCI, V13, P499, DOI 10.1111/1467-9280.00488; Hosoya T, 2005, NATURE, V436, P71, DOI 10.1038/nature03689; Howe CQ, 2006, J THEOR BIOL, V241, P866, DOI 10.1016/j.jtbi.2006.01.017; Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142; HUBBELL SP, 1987, AM NAT, V130, P91, DOI 10.1086/284700; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; Hume David, 1964, TREATISE HUMAN NATUR; Humphrey N, 2000, J CONSCIOUSNESS STUD, V7, P5; Hurley MM, 2011, INSIDE JOKES: USING HUMOR TO REVERSE-ENGINEER THE MIND, P1; Hurley Susan L., 1998, CONSCIOUSNESS ACTION; Huron D., 2006, SWEET ANTICIPATION M; Hutchins E, 1995, COGNITION WILD; Ikegami T, 2007, J CONSCIOUSNESS STUD, V14, P111; Iriki A, 2012, PHILOS T R SOC B, V367, P10, DOI 10.1098/rstb.2011.0190; JAEGER H, 2011, OCCAM 2011; Jahanshahi M, 2000, NEUROIMAGE, V12, P713, DOI 10.1006/nimg.2000.0647; James W, 1890, PRINCIPLES PSYCHOL; Janoff-Bulman R., 1992, SHATTERED ASSUMPTION; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Jaynes ET, 2003, PROBABILITY THEORY L; Jeannerod M, 2003, SELF IN NEUROSCIENCE AND PSYCHIATRY, P380, DOI 10.1017/CBO9780511543708.019; Jeannerod M, 2006, MOTOR COGNITION; Jehee JFM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000373; Jiang JF, 2012, BEHAV NEUROSCI, V126, P575, DOI 10.1037/a0029029; Johnston A, 2006, CURR BIOL, V16, P472, DOI 10.1016/j.cub.2006.01.032; Kalman R.E., 1960, T ASME D, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]; Kant I., 1781, CRITIQUE PURE REASON; Karcher SM, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00037; Karmarkar UR, 2007, NEURON, V53, P427, DOI 10.1016/j.neuron.2007.01.006; Karmiloff-Smith A., 1992, MODULARITY DEV PERSP; KAWATO M, 1993, NETWORK-COMP NEURAL, V4, P415, DOI 10.1088/0954-898X/4/4/001; Kay J, 1998, NEURAL NETWORKS, V11, P117, DOI 10.1016/S0893-6080(97)00110-X; KAY J, 2010, B MATH BIOL, V73, P344, DOI DOI 10.1007/S11538-010-9564-X; KEANE BP, J ABNORMAL IN PRESS; Keller GB, 2012, NEURON, V74, P809, DOI 10.1016/j.neuron.2012.03.040; Khalil EL, 2010, J ECON BEHAV ORGAN, V75, P268, DOI 10.1016/j.jebo.2010.04.004; KHALIL EL, 1989, HIST EC SOC B, V11, P222; Kinoshita M, 2009, J NEUROPHYSIOL, V102, P1930, DOI 10.1152/jn.90882.2008; KITAYAMA S, 2010, HDB CULTURAL PSYCHOL; KLEINSCHMIDT D, 2011, COMP MODELING COMP L; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Koethe D, 2009, EUR ARCH PSY CLIN N, V259, P195, DOI 10.1007/s00406-008-0851-6; KOHONEN T, 1986, SELFORGANIZATION ASS; KOK P, 2011, CEREB CORTEX, V22, P2197, DOI DOI 10.1093/CERCOR/BHR310; Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034; Konig P, 2006, BIOL CYBERN, V94, P325, DOI [10.1007/s00422-006-0050-3, 10.1007/S00422-006-0050-3]; Kording KP, 2007, NAT NEUROSCI, V10, P779, DOI 10.1038/nn1901; Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169; Kording K.P., 2000, NETWORK-COMP NEURAL, V11, P1; Kording KP, 2004, J NEUROPHYSIOL, V91, P206, DOI 10.1152/jn.00149.2003; KOSSLYN SM, 1995, NATURE, V378, P496, DOI 10.1038/378496a0; Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x; KRIEGSTEIN K, 2006, PLOS BIOL, V4, pE326; Kukona A, 2011, COGNITION, V119, P23, DOI 10.1016/j.cognition.2010.12.002; Kurumada C., 2012, P 34 ANN C COGN SCI, P647; Kveraga K, 2007, BRAIN COGNITION, V65, P145, DOI 10.1016/j.bandc.2007.06.007; Ladinig O, 2009, MUSIC PERCEPT, V26, P377, DOI 10.1525/MP.2009.26.4.377; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Lange C. G., 1885, CLASSICAL PSYCHOL, P672; Langner R, 2011, CEREB CORTEX, V21, P2850, DOI 10.1093/cercor/bhr083; Large EW, 2002, PSYCHOL RES-PSYCH FO, V66, P3, DOI 10.1007/s004260100069; Lee D, 2009, NEUROECONOMICS: DECISION MAKING AND THE BRAIN, P481, DOI 10.1016/B978-0-12-374176-9.00031-2; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee MD, 2010, TRENDS COGN SCI, V14, P345, DOI 10.1016/j.tics.2010.05.011; Lee SH, 2005, NAT NEUROSCI, V8, P22, DOI 10.1038/nn1365; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; LEHNERT W, 2007, BELIEFS REASONING DE, P143; Lehnert Wendy, 2007, 3 ANN M COGN SCI SOC; Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439; Leopold DA, 1999, TRENDS COGN SCI, V3, P254, DOI 10.1016/S1364-6613(99)01332-7; Levinson S. C., 2006, ROOTS HUMAN SOCIALIT, P39; Lewis PA, 2003, CURR OPIN NEUROBIOL, V13, P250, DOI 10.1016/S0959-4388(03)00036-9; Lewis PA, 2006, BEHAV PROCESS, V71, P226, DOI 10.1016/j.beproc.2005.12.009; Ling S, 2006, NAT NEUROSCI, V9, P1243, DOI 10.1038/nn1761; LINSKER R, 1989, ADV NEURAL INFORM PR, V1, P86; LITTLE DY, 2011, ARXIVE11121125; Lochmann T, 2012, J NEUROSCI, V32, P4179, DOI 10.1523/JNEUROSCI.0817-11.2012; Lochmann T, 2011, CURR OPIN NEUROBIOL, V21, P774, DOI 10.1016/j.conb.2011.05.018; Loui P, 2010, MUSIC PERCEPT, V27, P377; LUCK SJ, 2006, 1 HALF 2 MICROGENESI, P187; MACKAY DJC, 1995, ELECTRON LETT, V31, P445; MACKAY DM, 1956, AUTOMATA STUDIES, P235; Madison G, 2009, INTELLIGENCE, V37, P68, DOI 10.1016/j.intell.2008.07.006; Madison G, 2001, J EXP PSYCHOL HUMAN, V27, P411, DOI 10.1037//0096-1523.27.2.2411; MAHER BA, 1988, DELUSIONAL BELIEFS, P15; Maloney LT, 2009, VISUAL NEUROSCI, V26, P147, DOI 10.1017/S0952523808080905; Maloney LT, 2010, VISION RES, V50, P2362, DOI 10.1016/j.visres.2010.09.031; Mamassian P, 2002, NEU INF PRO, P13; Mandler J. M., 1984, STORIES SCRIPTS SCEN; Mar RA, 2008, PERSPECT PSYCHOL SCI, V3, P173, DOI 10.1111/j.1745-6924.2008.00073.x; MARCUS G, 2008, HAHPHAZARD CONSTRUCT; MARESCHAL D, 2007, NEUROCONSTRUCTIVISM, V1; Marr D., 1982, VISION COMPUTATIONAL; Matell MS, 2004, COGNITIVE BRAIN RES, V21, P139, DOI 10.1016/j.cogbrainres.2004.06.012; MATTUSEK P, 1987, CLIN ROOTS SCHIZOPHR, P87; McAdams DP, 2006, J CONSTR PSYCHOL, V19, P109, DOI 10.1080/10720530500508720; MCADAMS DP, 1997, STORIES WE LIVE PERS; McCarthy J, 2008, ARTIF INTELL, V172, P2003, DOI 10.1016/j.artint.2008.10.001; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V2; McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002; MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375; McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002; Melloni L, 2011, J NEUROSCI, V31, P1386, DOI 10.1523/JNEUROSCI.4570-10.2011; Menary R, 2007, NEW DIR PHILOS COGN, P1, DOI 10.1057/9780230592889; Meng M, 2004, J VISION, V4, P539, DOI 10.1167/4.7.2; Merker B, 2004, CORTEX, V40, P559, DOI 10.1016/S0010-9452(08)70148-5; Merker BH, 2009, CORTEX, V45, P4, DOI 10.1016/j.cortex.2008.06.011; Meyer L.B., 1956, EMOTION MEANING MUSI; Meyer T, 2011, P NATL ACAD SCI USA, V108, P19401, DOI 10.1073/pnas.1112895108; Miall C., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.359; Milner D. A., 2006, VISUAL BRAIN ACTION; Molnar-Szakacs I, 2006, SOC COGN AFFECT NEUR, V1, P235, DOI 10.1093/scan/nsl029; Morrone MC, 2005, NAT NEUROSCI, V8, P950, DOI 10.1038/nn1488; Muckli L, 2013, CURR OPIN NEUROBIOL, V23, P195, DOI 10.1016/j.conb.2013.01.020; Muckli L, 2010, INT J IMAG SYST TECH, V20, P131, DOI 10.1002/ima.20236; Muckli L, 2005, PLOS BIOL, V3, P1501, DOI 10.1371/journal.pbio.0030265; MUMFORD D, 1994, LARGE SCALE NEURONAL, P125; MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477; Murray DJ, 1999, PERCEPT PSYCHOPHYS, V61, P1681, DOI 10.3758/BF03213127; Murray SO, 2002, P NATL ACAD SCI USA, V99, P15164, DOI 10.1073/pnas.192579399; Murray SO, 2004, NEURAL NETWORKS, V17, P695, DOI 10.1016/j.neunet.2004.03.010; Murray SO, 2006, NAT NEUROSCI, V9, P429, DOI 10.1038/nn1641; MUSMANN HG, 1979, ADV ELECT ELECT PH S, V12, P73; Nagarajan SS, 1998, J NEUROSCI, V18, P1559; Nagel Saskia K, 2005, J Neural Eng, V2, pR13, DOI 10.1088/1741-2560/2/4/R02; Narmour E, 1990, ANAL COGNITION BASIC; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Neisser U., 1967, COGNITIVE PSYCHOL; Nelson K, 2003, MEMORY, V11, P125, DOI 10.1080/09658210244000315; Nelson KD, 2004, PSYCHOL REV, V111, P486, DOI 10.1037/0033-295X.111.2.486; NELSON P, 2012, TOPICS MUSICAL UNIV; Noe A, 2004, ACTION PERCEPTION; Noe A., 2009, OUT OUR HEADS WHY YO; North A. C., 1995, PSYCHOMUSICOLOGY, V14, P77, DOI DOI 10.1037/H0094090; Nudds Matt, COMMUNICATION; Oatley K., 1999, REV GEN PSYCHOL, V3, P101, DOI DOI 10.1037/1089-2680.3.2.101; Oatley K., 1992, BEST LAID SCHEMES PS; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639; Overy K, 2009, MUSIC PERCEPT, V26, P489, DOI 10.1525/MP.2009.26.5.489; Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131; OYAMA S, 1999, EVOLUTIONS EYE BIOL; Pack CC, 2001, NATURE, V409, P1040, DOI 10.1038/35059085; Palaniyappan L, 2012, J PSYCHIATR NEUROSCI, V37, P17, DOI 10.1503/jpn.100176; Pascual-Leone A, 2001, PROG BRAIN RES, V134, P427; Paulus MP, 2006, BIOL PSYCHIAT, V60, P383, DOI 10.1016/j.biopsych.2006.03.042; PEARCE JM, 1980, PSYCHOL REV, V87, P532, DOI 10.1037//0033-295X.87.6.532; Pecenka N, 2011, EXP BRAIN RES, V211, P505, DOI 10.1007/s00221-011-2616-0; Pennebaker JW, 1999, J CLIN PSYCHOL, V55, P1243, DOI 10.1002/(SICI)1097-4679(199910)55:10<1243::AID-JCLP6>3.0.CO;2-N; PETERSON JB, 1999, MAPS MEANING ARCHIT; PETKOVA VI, 2008, PLOS ONE, V3; PFEIFER R, 2007, LECT NOTES COMP SCI, V4850; Phillips WA, 1997, BEHAV BRAIN SCI, V20, P657, DOI 10.1017/S0140525X9700160X; Phillips WA, 2004, PERCEPTION, V33, P79, DOI 10.1068/p5110; PHILLIPS WA, 1995, NETWORK-COMP NEURAL, V6, P225, DOI 10.1088/0954-898X/6/2/005; Phillips William A., 2012, Information, V3, DOI 10.3390/info3010001; Phillips WA, 2003, BEHAV BRAIN SCI, V26, P65, DOI 10.1017/S0140525X03000025; PHILLIPS WA, 2010, STRUNGMANN FORUM REP, V5, P1; Phillips-Silver J, 2007, COGNITION, V105, P533, DOI 10.1016/j.cognition.2006.11.006; Phillips-Silver J, 2008, BRAIN COGNITION, V67, P94, DOI 10.1016/j.bandc.2007.11.007; Piaget J, 1952, ORIGINS INTELLIGENCE; Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002; Platt ML, 1999, NATURE, V400, P233, DOI 10.1038/22268; Ploghaus A, 1999, SCIENCE, V284, P1979, DOI 10.1126/science.284.5422.1979; POSNER M, 1980, Q J EXPERIM PSYCHOL, V32, P33; Pouget A, 2003, ANNU REV NEUROSCI, V26, P381, DOI 10.1146/annurev.neuro.26.041002.131112; Powers W. T., 1973, BEHAV CONTROL PERCEP; PRIBRAM KH, 1971, LANGUAGES BRAIN; PRIBRAM KH, 1980, ORIENTING REFLEX HUM, P3; PRINZ J, 2005, COGNITION BRAIN PHIL, P381, DOI DOI 10.1017/CBO9780511610608.012; Proulx T, 2012, TRENDS COGN SCI, V16, P285, DOI 10.1016/j.tics.2012.04.002; Purves D., 2003, WHY WE SEE WHAT WE D; Quine W. V., 1951, PHILOS REV, V60, P20, DOI DOI 10.2307/2181906; Rammsayer TH, 1999, Q J EXP PSYCHOL-B, V52, P273; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao RPN, 2002, NEU INF PRO, P297; Rauss K, 2011, NEUROSCI BIOBEHAV R, V35, P1237, DOI 10.1016/j.neubiorev.2010.12.011; Read J, 2001, PSYCHIATRY, V64, P319, DOI 10.1521/psyc.64.4.319.18602; Read J, 2005, ACTA PSYCHIAT SCAND, V112, P330, DOI 10.1111/j.1600-0447.2005.00634.x; Reddy L, 2010, NEUROIMAGE, V50, P818, DOI 10.1016/j.neuroimage.2009.11.084; Reich L, 2011, CURR BIOL, V21, P363, DOI 10.1016/j.cub.2011.01.040; REICHERT DP, 2010, ADV NEURAL INFORM PR, V23, P2020; Repp BH, 1999, PERCEPT PSYCHOPHYS, V61, P529, DOI 10.3758/BF03211971; RESCORLA M, OXFORD HDB IN PRESS; Ricoeur P, 1990, TIME NARRATIVE, V3; Rieke F, 1999, SPIKES EXPLORING NEU; Riesenhuber M, 2000, NAT NEUROSCI, V3, P1199, DOI 10.1038/81479; ROBBINS H, 1956, 3RD P BERK S MATH ST, V1, P157; Roepstorff A, 2010, NEURAL NETWORKS, V23, P1051, DOI 10.1016/j.neunet.2010.08.002; Roepstorff A, 2008, PHILOS T R SOC B, V363, P2049, DOI 10.1098/rstb.2008.0015; Roepstorff A, 2012, ANTHROPOL THEOR, V12, P101, DOI 10.1177/1463499612436467; Rorty Richard, 1979, PHILOS MIRROR NATURE; Ross D, 2008, MIDBRAIN MUTINY: THE PICOECONOMICS AND NEUROECONOMICS OF DISORDERED GAMBLING: ECONOMIC THEORY AND COGNITIVE SCIENCE, P1; ROSS HE, 1969, Q J EXP PSYCHOL, V21, P346, DOI 10.1080/14640746908400230; ROWLANDS M, 1999, BODY MIND COGNITIVE; ROWLANDS M, 2006, BODY LANGUAGE REPRES; Rust NC, 2005, NEURON, V46, P945, DOI 10.1016/j.neuron.2005.05.021; SACHS E, 1967, COMP PSYCHOPATHOLOGY, P249; Sadakata M, 2006, MUSIC PERCEPT, V23, P269, DOI 10.1525/mp.2006.23.3.269; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; SANDERS LL, 2012, PSYCHIAT RES; Santhouse AM, 2000, BRAIN, V123, P2055, DOI 10.1093/brain/123.10.2055; SARBIN TR, 1986, NARRATIVE PSYCHOL; Sass LA, 1992, MADNESS MODERNISM; SAXE A, 2011, COSYNE 2011; SCHACHTER S, 1962, PSYCHOL REV, V69, P379, DOI 10.1037/h0046234; Schaefer RS, 2011, INT J PSYCHOPHYSIOL, V82, P254, DOI 10.1016/j.ijpsycho.2011.09.007; Schaefer RS, 2011, PSYCHOL RES-PSYCH FO, V75, P95, DOI 10.1007/s00426-010-0293-4; Schank R. C., 1977, SCRIPTS PLANS GOALS; Schenk T, 2010, COGN NEUROSCI-UK, V1, P52, DOI 10.1080/17588920903388950; Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593; Schwartz O, 2007, NAT REV NEUROSCI, V8, P522, DOI 10.1038/nrn2155; SEGALL MH, 1963, SCIENCE, V139, P769, DOI 10.1126/science.139.3556.769; Sellars W., 1963, SCI PERCEPTION REALI; Sellars Wilfrid, 1962, FRONTIERS SCI PHILOS, P35; Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395; Shi YQ, 1999, IMAGE VIDEO COMPRESS; Silverstein SM, 2009, J INTEGR NEUROSCI, V8, P175, DOI 10.1142/S0219635209002113; Silverstein SM, 2011, SCHIZOPHRENIA BULL, V37, P690, DOI 10.1093/schbul/sbr052; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Simons JS, 2006, NEUROPSYCHOLOGIA, V44, P1388, DOI 10.1016/j.neuropsychologia.2006.01.005; Singer T, 2009, TRENDS COGN SCI, V13, P334, DOI 10.1016/j.tics.2009.05.001; SINGER W, 1995, SCIENCE, V270, P758, DOI 10.1126/science.270.5237.758; SLOMA A, 1978, COMPUTER REVOLUTION; SLOMAN A, 1982, PHYS BIOL PROCESSING, P380; Sloman A, 2009, LECT NOTES ARTIF INT, V5436, P248, DOI 10.1007/978-3-642-00616-6_12; SLOMAN A, 2008, COSYPR0801; SLOMAN A, 2006, COSYDP0604; SLOMAN A, 2002, DIAGRAMMATIC REPRESE, P7; SLOMAN A, 1990, EVOLVING KNOWLEDGE; SLOMAN A, 2010, P INT S MATH PRACT C, P30; SLOMAN A, 1971, P 2 IJCAI, P209; SLOMAN A, 1993, PHILOS COGNITIVE SCI, P69; SLOMAN A, 2011, WHATS VISION HOW DOE; SLOMAN A, 1987, ADV ARTIFICIAL INTEL, V2, P369; Sloman A., 1989, Journal of Experimental and Theoretical Artificial Intelligence, V1, DOI 10.1080/09528138908953711; Sloman A, 1996, MOR KAUF R, P627; SLOMAN A, 2011, METAREASONING THINKI, P307; SLOMAN A, 1979, ANAL MEANING INFORM, V5, P1; SMITH FW, 2010, P NATL ACAD SCI USA, V16, P20099; Smith L, 2005, ARTIF LIFE, V11, P13, DOI 10.1162/1064546053278973; Smith PL, 2004, TRENDS NEUROSCI, V27, P161, DOI 10.1016/j.tins.2004.01.006; Sokolov E. N., 1960, CENTRAL NERVOUS SYST, P187; SPORNS O, 2007, NEUROCONSTRUCTIVISM, V2, P179; Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008; Spratling MW, 2012, NEURAL COMPUT, V24, P60, DOI 10.1162/NECO_a_00222; Spratling MW, 2011, VISION RES, V51, P563, DOI 10.1016/j.visres.2011.01.017; Spratling MW, 2012, BIOL CYBERN, V106, P37, DOI 10.1007/s00422-012-0477-7; Spratling MW, 2010, J NEUROSCI, V30, P3531, DOI 10.1523/JNEUROSCI.4911-09.2010; Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009; SRINIVASAN MV, 1982, PROC R SOC SER B-BIO, V216, P427, DOI 10.1098/rspb.1982.0085; Staum Casasanto L, 2008, P 30 ANN M COGN SCI, P799; Stephan KE, 2009, SCHIZOPHRENIA BULL, V35, P509, DOI 10.1093/schbul/sbn176; Sterelny K, 2007, PHILOS T R SOC B, V362, P719, DOI 10.1098/rstb.2006.2006; Sterelny Kim, 2003, THOUGHT HOSTILE WORL; Still S, 2009, EPL-EUROPHYS LETT, V85, DOI 10.1209/0295-5075/85/28005; Stormer VS, 2009, P NATL ACAD SCI USA, V106, P22456, DOI 10.1073/pnas.0907573106; Stotz K, 2010, PHENOMENOL COGN SCI, V9, P483, DOI 10.1007/s11097-010-9178-7; Summerfield C, 2009, TRENDS COGN SCI, V13, P403, DOI 10.1016/j.tics.2009.06.003; Summerfield Christopher, 2011, Front Hum Neurosci, V5, P67, DOI 10.3389/fnhum.2011.00067; Summerfield C, 2006, SCIENCE, V314, P1311, DOI 10.1126/science.1132028; Summerfield C, 2008, NAT NEUROSCI, V11, P1004, DOI 10.1038/nn.2163; Summerfield C, 2008, NEURON, V59, P336, DOI 10.1016/j.neuron.2008.05.021; SWITKES E, 1978, VISION RES, V18, P1393; Synofzik M, 2010, BRAIN, V133, P262, DOI 10.1093/brain/awp291; Tanaka K, 1996, ANNU REV NEUROSCI, V19, P109, DOI 10.1146/annurev.ne.19.030196.000545; Tanenhaus MK, 2007, TRENDS COGN SCI, V11, P93, DOI 10.1016/j.tics.2006.11.010; Temperley D, 2004, MUSIC PERCEPT, V21, P313, DOI 10.1525/mp.2004.21.3.313; Violentyev A, 2005, NEUROREPORT, V16, P1107, DOI 10.1097/00001756-200507130-00015; VONHELMHOLTZ H, 1876, HDB PHYSIOL OPTIK; VONHELMHOLTZ H, 1860, HDB PHYSIOL OPTIK, V3; Cooper SB, 2013, ALAN TURING: HIS WORK AND IMPACT, P1; David Velleman J., 1989, PRACTICAL REFLECTION; Temperley D., 2007, MUSIC PROBABILITY; Thelen E., 1994, DYNAMIC SYSTEMS APPR; Thompson E., 2007, MIND LIFE BIOL PHENO; Tishby N., 1999, P 37 ANN ALL C COMM, P368; Todorov E, 2004, NAT NEUROSCI, V7, P907, DOI 10.1038/nn1309; TODOROV E, 2009, COGNITIVE NEUROSCIEN, P613; TODOROV E, 2006, BAYESIAN BRAIN PROBA, P269; Todorov E, 2002, NAT NEUROSCI, V5, P1226, DOI 10.1038/nn963; Todorovic A, 2011, J NEUROSCI, V31, P9118, DOI 10.1523/JNEUROSCI.1425-11.2011; Tong F, 2006, TRENDS COGN SCI, V10, P502, DOI 10.1016/j.tics.2006.09.003; TOUSSAINT M, 2009, KUNSTLICHE INTELLIGE, V3, P23; Townsend BR, 2006, J NEUROPHYSIOL, V96, P2578, DOI 10.1152/jn.01086.2005; TREHUB A, 1991, COGNITIVE BRAIN; TRIBUS M, 1961, THERMODYNAMICS THERM; Tudusciuc O, 2009, J NEUROPHYSIOL, V101, P2984, DOI 10.1152/jn.90713.2008; TURING AM, 1952, PHILOS T ROY SOC B, V237, P37, DOI 10.1098/rstb.1952.0012; Uhlhaas PJ, 2007, SCHIZOPHRENIA BULL, V33, P142, DOI 10.1093/schbul/sbl047; Ungerleider L., 1982, ANAL VISUAL BEHAV, P549; Van Essen DC, 2005, PROG BRAIN RES, V149, P173, DOI 10.1016/S0079-6123(05)49013-5; VANVOORHIS S, 1977, PERCEPT PSYCHOPHYS, V22, P54; Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550; Varela F. J., 1999, NATURALIZING PHENOME, P266; Varela F. J., 1991, EMBODIED MIND; Verschure PFMJ, 2003, NATURE, V425, P620, DOI 10.1038/nature02024; VETTER P, 2012, FRONT PSYCHOL, V3, P1; VETTER P, UNPUB; Vilares I, 2011, ANN NY ACAD SCI, V1224, P22, DOI 10.1111/j.1749-6632.2011.05965.x; VILLALONTURRUBI.I, 2004, P INT C COMP COMMUN, V7, P48; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; VONDERMALSBURG C, 2010, STRUNGMANN FORUM REP, V5; VONUEXKULL J, 1934, INSTINCTIVE BEHAV DE; Vuust P, 2008, BEHAV BRAIN SCI, V31, P599, DOI 10.1017/S0140525X08005542; Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012; Waelti P, 2001, NATURE, V412, P43, DOI 10.1038/35083500; Waydo S, 2006, J NEUROSCI, V26, P10232, DOI 10.1523/JNEUROSCI.2101-06.2006; WEBER J, 2002, JUDGEMENT EYE METAMO; Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858; Wells JB, 2009, COGNITIVE PSYCHOL, V58, P250, DOI 10.1016/j.cogpsych.2008.08.002; Wheeler M, 2005, RECONSTRUCTING COGNI; WHEELER M, 2009, PHILOS T R SOC B, V363, P3563; WILSON RA, 2004, BOUNDARIES MIND INDI; WILSON RA, 1994, MIND, V103, P351, DOI 10.1093/mind/103.411.351; Womelsdorf T, 2006, NAT NEUROSCI, V9, P1156, DOI 10.1038/nn1748; WU Z, 1985, IEEE T ACOUST SPEECH, V33, P1576; Wyart V, 2012, P NATL ACAD SCI USA, V109, P3593, DOI 10.1073/pnas.1120118109; Wyss R, 2004, P ROY SOC B-BIOL SCI, V271, pS50, DOI 10.1098/rsbl.2003.0098; Yeshurun Y, 1998, NATURE, V396, P72; Yu AJ, 2007, CURR BIOL, V17, pR977, DOI 10.1016/j.cub.2007.09.007; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002; Zahedi K, 2010, ADAPT BEHAV, V18, P338, DOI 10.1177/1059712310375314; Zhu Q, 2011, EVOL HUM BEHAV, V32, P288, DOI 10.1016/j.evolhumbehav.2010.11.005	552	89	90	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0140-525X	1469-1825		BEHAV BRAIN SCI	Behav. Brain Sci.	JUN	2013	36	3					181	204		10.1017/S0140525X12000477		24	Psychology, Biological; Behavioral Sciences; Neurosciences	Psychology; Behavioral Sciences; Neurosciences & Neurology	143ZT	WOS:000318909200001	23814868	
J	Bengio, Y; Courville, A; Vincent, P				Bengio, Yoshua; Courville, Aaron; Vincent, Pascal			Representation Learning: A Review and New Perspectives	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Deep learning; representation learning; feature learning; unsupervised learning; Boltzmann machine; autoencoder; neural nets	NONLINEAR DIMENSIONALITY REDUCTION; ORGANIZING NEURAL NETWORK; COMPLEX CELL PROPERTIES; SLOW FEATURE ANALYSIS; OBJECT RECOGNITION; COMPONENT ANALYSIS; DENOISING AUTOENCODERS; NATURAL IMAGES; CORTEX; DECOMPOSITION	The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.	[Bengio, Yoshua; Courville, Aaron; Vincent, Pascal] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada	Bengio, Y (reprint author), Univ Montreal, Dept Comp Sci & Operat Res, POB 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.				NSERC; CIFAR; Canada Research Chairs	The authors would like to thank David Warde-Farley, Razvan Pascanu, and Ian Goodfellow for useful feedback, as well as NSERC, CIFAR, and the Canada Research Chairs for funding.	Alain G., 2012, 12114246 ARXIV U MON; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Bach F, 2012, STAT SCI, V27, P450, DOI 10.1214/12-STS394; Bagnell J.A, 2009, P NEUR INF PROC SYST, P113; Baird H., 1990, P IAPR WORKSH SYNT S, P38; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2010, COMPUT INTELL, V26, P449, DOI 10.1111/j.1467-8640.2010.00366.x; Bengio Y., 2008, SCHOLARPEDIA, V3; Bengio Y., 2009, P INT C MACH LEARN; Bengio Y., 2012, ARXIV12070057; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000327; Bengio Y., 2004, P NEUR INF PROC SYST, P129; Bengio Y., 2003, P NEUR INF PROC SYST; Bengio Y., 2012, JMLR WORKSHOPS C P, V27, P17; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y., 2011, P INT C ALG LEARN TH; Bengio Y., 2013, P INT C MACH LEARN; Bengio Y., 2013, NEURAL NETWORKS TRIC; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2003, J MACHINE LEARNING R, V3, P137; Bengio Y., 2005, P NEUR INF PROC SYST; Bengio Y., 2006, P NEUR INF PROC SYST; Bergstra J., 2011, P NEUR INF PROC SYST; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bergstra J., 2009, P NEUR INF PROC SYST; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; BESAG J, 1975, STATISTICIAN, V24, P179, DOI 10.2307/2987782; Bordes A., 2012, P INT C ART INT STAT; Boulanger-Lewandowski N., 2012, P INT C MACH LEARN; Boureau Y., 2011, P IEEE INT C COMP VI; Boureau Y.-L., 2010, P INT C MACH LEARN; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Brand M., 2002, P NEUR INF PROC SYST, P961; Breuleux O., 2011, NEURAL COMPUT, V23, P2053; Bruna J., 2011, P INT C PATT REC; Cadieu C., 2009, P NEUR INF PROC SYST, P209; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Chen Minmin, 2012, P INT C MACH LEARN; Cho K., 2011, P INT C MACH LEARN, P105; Cho K., 2010, P INT JOINT C NEUR N; Ciresan D., 2012, ARXIV12022745; Ciresan D.C., 2010, NEURAL COMPUT, V22, P1; Coates A., 2011, P NEUR INF PROC SYST; Coates A., 2011, P INT C MACH LEARN; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Collobert R., 2008, P INT C MACH LEARN; Courville A., 2011, P INT C MACH LEARN; Courville A., 2011, P INT C ART INT STAT; Dahl G.E., 2010, P NEUR INF PROC SYST; Dahl George E., 2012, IEEE T AUDIO SPEECH, V20, P33; Deng L., 2010, P ANN C INT SPEECH C; Desjardins G., 2010, P 13 INT C ART INT S, V9, P145; Desjardins G., 2011, P NEUR INF PROC SYST; Desjardins G., 2012, ARXIV12034416V1 U MO; Desjardins G., 2008, 1327 U MONTR DEP IRO; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Donoho D.L., 2003, 200308 STANF U DEP S; Eisner J., 2012, P ICML WORKSH INT SE; Erhan D., 2010, 1355 DIRO U MONTR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Freund Y., 1994, UCSCCRL9425; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Glorot X., 2010, P C ART INT STAT; Glorot X., 2011, P C ART INT STAT; Glorot X., 2011, P INT C MACH LEARN; Goodfellow I., 2009, P NEUR INF PROC SYST, P646; Goodfellow I., 2011, P NIPS WORKSH CHALL; Goodfellow I.J., 2012, ARXIV12013382; Gregor K., 2010, P INT C MACH LEARN; Gregor K., 2011, P NEUR INF PROC SYST; Gregor K., 2010, ARXIV10060448; Gribonval R, 2011, IEEE T SIGNAL PROCES, V59, P2405, DOI 10.1109/TSP.2011.2107908; Grosse R., 2007, P C UNC ART INT; Grubb A., 2010, P INT C MACH LEARN; Gutmann M., 2010, P C ART INT STAT; Hamel P., 2011, P INT C MUS INF RETR; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Henaff M., 2011, P INT C MUS INF RETR; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G., 2011, P INT C ART NEUR NET; Hinton G. E., 1986, P 8 ANN C COGN SCI S, P1; Hinton G.E., 2000, 2000004 GCNU TR GATS; Hinton G.E., 2010, 2010003 UTML TR DEP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1999, P INT C ART NEUR NET; Hinton G.E., 1993, P NEUR INF PROC SYST; Hinton G.E., 2002, P NEUR INF PROC SYST; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Hurri J., 2002, P NEUR INF PROC SYST; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A, 2008, NEURAL COMPUT, V20, P3087, DOI 10.1162/neco.2008.10-06-384; Hyvarinen A, 2009, NATURAL IMAGE STAT P; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Hyvarinen A, 2001, NEURAL COMPUT, V13, P1527, DOI 10.1162/089976601750264992; Hyvarinen A, 2007, COMPUT STAT DATA AN, V51, P2499, DOI 10.1016/j.csda.2006.09.003; Jaeger H, 2007, SCHOLARPEDIA, V2, P2330, DOI DOI 10.4249/SCH0LARPEDIA.2330; Jain V., 2008, P NEUR INF PROC SYST; Jarrett K., 2009, P IEEE INT C COMP VI; Jenatton R., 2009, ARXIV09043523; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Kavukcuoglu K., 2010, P NEUR INF PROC SYST; Kavukcuoglu K., 2008, CBLLTR20081201 NEW Y; Kavukcuoglu K., 2009, P IEEE C COMP VIS PA; Kingma D., 2010, P NEUR INF PROC SYST; Kivinen J.J., 2012, P C ART INT STAT; Kording KP, 2004, J NEUROPHYSIOL, V91, P206, DOI 10.1152/jn.00149.2003; Krizhevsky A., 2009, TECHNICAL REPORT; Krizhevsky A., 2010, TECHNICAL REPORT; Krizhevsky A, 2012, P NEUR INF PROC SYST; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H., 2008, P INT C MACH LEARN; Lazebnik S., 2006, P IEEE C COMP VIS PA; Le H.-S., 2013, IEEE T AUDIO SPEECH, V21, P197; Le Q., 2010, P NEUR INF PROC SYST; Le Q., 2011, P INT C MACH LEARN; Le Q.V., 2011, P IEEE C COMP VIS PA; Le Q.V., 2011, P NEUR INF PROC SYST; Le Roux N., 2007, P NEUR INF PROC SYST; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LeCun Y., 1987, THESIS U PARIS 6; LeCun Y., 1986, DISORDERED SYSTEMS B, P233; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, NEURAL NETWORKS TRIC; LeCun Y., 1989, CONNECTIONISM PERSPE; Lee H., 2009, P INT C MACH LEARN; Lee H., 2007, P NEUR INF PROC SYST; Lee H., 2009, P NEUR INF PROC SYST; Lin Y., 2010, P NEUR INF PROC SYST; Lowe D.G., 1999, P IEEE INT C COMP VI; Mallat S., 2012, COMM PURE APPL MATH; Marlin B., 2011, P C UNC ART INT; Marlin B.M., 2010, P 13 INT C ART INT S, P509; Martens J, 2010, P 27 INT C MACH LEAR, P735; Martens J., 2011, P INT C MACH LEARN; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Mesnil G., 2011, P UNS TRANSF LEARN C, V7; Mikolov T., 2011, P ANN C INT SPEECH C; Mobahi H., 2009, P INT C MACH LEARN; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Montufar G.F., 2012, ARXIV12060387; Murray I., 2008, P NEUR INF PROC SYST, P1137; Nair V., 2010, P INT C MACH LEARN; Neal R., 1993, CRGTR931 U TOR DEP C; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Ngiam J, 2011, P INT C MACH LEARN; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Orr G., 1998, NEURAL NETWORKS TRIC; Pascanu R., 2013, ARXIV13013584; Raiko T., 2012, P C ART INT STAT; Raina R, 2007, P INT C MACH LEARN; Ranzato M., 2006, P NEUR INF PROC SYST; Ranzato M., 2007, P NEUR INF PROC SYST; Ranzato M., 2010, P C ART INT STAT, P621; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Ranzato M., 2010, P NEUR INF PROC SYST; Ranzato M.A., 2011, P IEEE C COMP VIS PA; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rifai S., 2011, P NEUR INF PROC SYST; Rifai S., 2011, P INT C MACH LEARN; Rifai S., 2011, P EUR C MACH LEARN K; Rifai S., 2012, P INT C MACH LEARN; Roweis S., 1997, CNSTR9702 CALTECH; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Salakhutdinov R., 2007, P INT C MACH LEARN; Salakhutdinov R., 2010, P C ART INT STAT; Salakhutdinov R., 2010, P NEUR INF PROC SYST; Salakhutdinov R., 2009, P INT C ART INT STAT, P448; Salakhutdinov R., 2010, P INT C MACH LEARN; Salakhutdinov R., 2007, P INT ACM SIGIR C RE; Savard F., 2011, THESIS U MONTREAL; Schmah T., 2008, P NEUR INF PROC SYST, P1409; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Schwenk H., 2012, P WORKSH FUT LANG MO; Seide F., 2011, P IEEE WORKSH AUT SP; Seide F., 2011, P INTERSPEECH, P437; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Seung S.H., 1997, P NEUR INF PROC SYST; Simard D., 2003, P 7 INT C DOC AN REC; Simard P., 1991, P NEUR INF PROC SYST; Simard P.Y., 1992, P NEUR INF PROC SYST; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Snoek J., 2012, P NEUR INF PROC SYST; Socher R., 2011, P C EMP METH NAT LAN; Socher R., 2011, P NEUR INF PROC SYST; Srivastava N., 2012, P NEUR INF PROC SYST; Stoyanov V., 2011, P C ART INT STAT; Sutskever I., 2010, P C ART INT STAT; Sutskever I, 2012, THESIS U TORONTO; Sutskever I., 2008, P NEUR INF PROC SYST; Swersky K., 2011, P INT C MACHI LEARN; Swersky K., 2010, THESIS U BRIT COLUMB; Taylor G., 2009, P INT C MACH LEARN; Taylor G.W., 2010, P EUR C COMP VIS; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tieleman T., 2009, P INT C MACH LEARN; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881; van der Maaten L., 2009, P C ART INT STAT; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, P INT C MACH LEARN; Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142; Vincent P., 2002, P NEUR INF PROC SYST; Weinberger KQ, 2004, PROC CVPR IEEE, P988; Welling M., 2002, P NEUR INF PROC SYST; Welling M., 2009, P C UNC ART INT; Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3; Weston J., 2008, P INT C MACH LEARN; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI 10.1080/17442509908834179; Yu D, 2010, IEEE J-STSP, V4, P965, DOI 10.1109/JSTSP.2010.2075990; Yu K., 2010, P INT C MACH LEARN; Yu K., 2009, P NEUR INF PROC SYST; Yu K., 2011, P IEEE C COMP VIS PA; Yuille A.L., 2004, P NEUR INF PROC SYST, P1593; Zeiler M., 2010, P IEEE C COMP VIS PA; Zou W. Y., 2011, P NIPS WORKSH DEEP L	225	88	94	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1798	1828		10.1109/TPAMI.2013.50		31	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	164AP	WOS:000320381400002	23787338	
J	Atrey, PK; Hossain, MA; Saddik, A; Kankanhalli, MS				Atrey, Pradeep K.; Hossain, M. Anwar; El Saddik, Abdulmotaleb; Kankanhalli, Mohan S.			Multimodal fusion for multimedia analysis: a survey	MULTIMEDIA SYSTEMS			English	Article						Multimodal information fusion; Multimedia analysis	OPTIMAL SENSOR SELECTION; SPORTS VIDEO; EVENT DETECTION; BIOMETRIC AUTHENTICATION; SEMANTIC ANNOTATION; MAXIMUM-ENTROPY; OBJECT TRACKING; SYSTEMS; RECOGNITION; AUDIO	This survey aims at providing multimedia researchers with a state-of-the-art overview of fusion strategies, which are used for combining multiple modalities in order to accomplish various multimedia analysis tasks. The existing literature on multimodal fusion research is presented through several classifications based on the fusion methodology and the level of fusion (feature, decision, and hybrid). The fusion methods are described from the perspective of the basic concept, advantages, weaknesses, and their usage in various analysis tasks as reported in the literature. Moreover, several distinctive issues that influence a multimodal fusion process such as, the use of correlation and independence, confidence level, contextual information, synchronization between different modalities, and the optimal modality selection are also highlighted. Finally, we present the open issues for further research in the area of multimodal fusion.	[Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada; [Hossain, M. Anwar; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada; [Kankanhalli, Mohan S.] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore	Atrey, PK (reprint author), Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.	p.atrey@uwinnipeg.ca; anwar@mcrlab.uottawa.ca; abed@mcrlab.uottawa.ca; mohan@comp.nus.edu.sg	Hossain, Mohammad Anwar/J-9601-2013; El Saddik, Abdulmotaleb/D-4159-2009	Hossain, Mohammad Anwar/0000-0002-7673-8410; El Saddik, Abdulmotaleb/0000-0002-7690-8547	Natural Sciences and Engineering Research Council (NSERC) of Canada	The authors would like to thank the editor and the anonymous reviewers for their valuable comments in improving the content of this paper. This work is partially supported by the Natural Sciences and Engineering Research Council (NSERC) of Canada.	Adams WH, 2003, EURASIP J APPL SIG P, V2003, P170, DOI 10.1155/S1110865703211173; AGUILAR JF, 2003, INT C VID BAS BIOM P, P830; Aleksic PS, 2006, P IEEE, V94, P2025, DOI 10.1109/JPROC.2006.886017; Andrieu C, 2004, P IEEE, V92, P423, DOI 10.1109/JPROC.2003.823142; [Anonymous], PETS PERFORMANCE EVA; Argillander J, 2005, INT CONF ACOUST SPEE, P153; Atrey PK, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198304; Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8; ATREY PK, 2007, INT C MULT MOD SING, P155; AYACHE S, 2007, 29 EUR C INF RETR RE, P494; Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555; Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]; BAILLYBAILLIERE E, 2003, INT C AUD VID BAS BI, P625; Beal MJ, 2003, IEEE T PATTERN ANAL, V25, P828, DOI 10.1109/TPAMI.2003.1206512; Bendjebbour A, 2001, IEEE T GEOSCI REMOTE, V39, P1789, DOI 10.1109/36.942557; Bengio S., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00089-1; BENGIO S, 2003, 4 INT C AUD VID BAS, P770; Bredin H, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/70186; Bredin H., 2007, IEEE INT C AC SPEECH, V2, P233; BREMOND F, 1996, EUR C COMP VIS ORL; Brooks R., 1998, MULTISENSOR FUSION F; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CARUANA R, 2006, ACM INT C DAT MIN MA, P828; Chaisorn L, 2003, WORLD WIDE WEB, V6, P187, DOI 10.1023/A:1023622605600; CHANG SF, 2005, IEEE INT C AC SPEECH, V5, P1005; CHEN Q, 2006, INT C DAT MIN LAS VE, P232; CHETTY G, 2006, NICTA HCSNET MULT US, P17; CHIEU HL, 2004, INT ACM SIGIR C RES, P425; Choudhury T., 2002, 16 INT C PATT REC QU, V3, P789; Chua T. S., 2004, ACM MM 04, p[pp, 10]; Corradini A., 2003, NATO ASI C DAT FUS S; Crisan D, 2002, IEEE T SIGNAL PROCES, V50, P736, DOI 10.1109/78.984773; CUTLER R, 2000, IEEE INT C MULT EXP, P1589; DARRELL T, 2000, INT C MULT INT BEIJ; DATCU D, 2005, IEEE INT C MULT EXP, P193; Debouk R, 2002, DISCRETE EVENT DYN S, V12, P417, DOI 10.1023/A:1019770124060; DING Y, 2007, INT WORKSH SEM LEARN; FISHER J, 2000, ADV NEURAL INFORM PR, P772; FORESTI GL, 2002, IEEE INT C IM PROC R; GANDETTO M, 2003, IEEE INT C MULT EXP, P641; Gehrig T, 2005, INT INTEG REL WRKSP, P118, DOI 10.1109/ASPAA.2005.1540183; Guironnet M., 2005, 13 EUR SIGN PROC C A; Hall DL, 1997, P IEEE, V85, P6, DOI 10.1109/5.554205; Hershey J, 2000, ADV NEUR IN, V12, P813; HERSHEY J, 2004, IEEE INT C SPEECH AC, P649; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOLZAPFEL H, 2004, ACM INT C MULT INT I, P175; HOSSAIN MA, 2011, ACM T MULTIMED COMPU, V7; HOSSAIN MA, 2007, 3 IET INT C INT ENV, P589; HSU W, 2004, INT C AC SPEECH SIGN; HSU WHM, 2004, IEEE INT C MULT EXP, P1091; HU H, 2005, CSM422 U ESS, P422; HUA XS, 2004, 5 PAC RIM C MULT TOK; ISLER V, 2005, IPSN, P151, DOI 10.1109/IPSN.2005.1440917; IYENGAR G, 2003, IEEE INT C AC SPEECH; Iyengar G., 2003, ACM MULTIMEDIA, P255; JAFFRE G, 2006, INT WORKSH MULTIMODA; Jaimes A., 2005, IEEE INT WORKSH HUM; Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012; JASINSCHI RS, 2002, INT C AC SPEECH SIGN, V2, P2057; Jeon J, 2004, LECT NOTES COMPUT SC, V3115, P24; Jiang SB, 2003, IEEE T AUTOMAT CONTR, V48, P369, DOI 10.1109/TAC.2003.809144; Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797; Kalman R.E., 1960, T ASME D, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]; Kankanhalli MS, 2006, IEEE T MULTIMEDIA, V8, P947, DOI 10.1109/TMM.2006.879875; Kankanhalli MS, 2006, IEEE T MULTIMEDIA, V8, P937, DOI 10.1109/TMM.2006.879876; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; LAM KY, 2004, ACM INT WORKSH VID S, P63; Leon T, 2007, PATTERN RECOGN, V40, P2621, DOI 10.1016/j.patcog.2007.02.002; Li D., 2003, ACM INT C MULT; Li F. F., 2005, IEEE C COMP VIS PATT, V2, P524, DOI DOI 10.1109/CVPR.2005.16; LI M, 2003, INT C MULT EXP BALT, P473; Liu XZ, 2005, PATTERN RECOGN, V38, P887, DOI 10.1016/j.patcog.2004.11.008; LIU Y, 2007, 13 INT MULT MOD C SI, P185; LOH A, 2004, INT C CONTR AUT ROB, V3, P1569, DOI 10.1109/ICARCV.2004.1469293; LUCEY S, 2001, INT S INT MULT VID S, P551; Luo RC, 2002, IEEE SENS J, V2, P107, DOI 10.1109/JSEN.2002.1000251; Magalhaes J., 2007, INT C IM VID RETR AM, P619; MAKKOOK MA, 2007, THESIS U WATERLOO CA; MATAS J, 2000, COMP FACE VERIFICATI, P4858; McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61; Mena J.B., 2003, INT ARCH PHOTOGRAMME, VXXXIV, P139; Meyer G.F., 2004, J INF FUSION, V5, P91; Nefian A.V., 2002, EURASIP J APPL SIG P, V11, P1; NETI C, 2000, INT C RIAO PAR FRANC; Ni J., 2004, IEEE INT C INF ACQ; NICKEL K, 2005, 7 INT C MULT INT TOR, P61; NOCK HJ, 2002, ACM INT C MULT C MUL; NOCK HJ, 2003, INT C IM VID RETR UR; NOULAS AK, 2006, INT C MULT INT, P201; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; OSHMAN Y, 1994, IEEE T AERO ELEC SYS, V30, P307, DOI 10.1109/7.272256; Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398; Oviatt S, 2000, COMMUN ACM, V43, P45, DOI 10.1145/330534.330538; Oviatt S, 2003, HUMAN COMPUTER INTER; Pahalawatta PV, 2004, IEEE IMAGE PROC, P3073; PEREZ DG, 2003, IEEE INT C IM PROC; PFLEGER N, 2005, ICMI 2005 TOR IT; Pfleger N., 2004, ACM INT C MULT INT S, P265; Pitsikalis V., 2006, 9 INT C SPOK LANG PR; Poh N, 2006, PATTERN RECOGN, V39, P223, DOI 10.1016/j.patcog.2005.06.011; Poh N, 2005, IEEE T SIGNAL PROCES, V53, P4384, DOI 10.1109/TSP.2005.857006; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; Potamianos G, 2001, INT CONF ACOUST SPEE, P165, DOI 10.1109/ICASSP.2001.940793; Potamitis R, 2004, IEEE T SPEECH AUDI P, V12, P520, DOI 10.1109/TSA.2004.833004; Radova V, 1997, INT CONF ACOUST SPEE, P1135, DOI 10.1109/ICASSP.1997.596142; RASHIDI A, 2003, COMM 4 JOINT WORKSH, V2, P31; REDDY BS, 2007, THESIS U WATERLOO CA; Ribeiro M.I., 2004, KALMAN EXTENDED KALM; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; SALICETTI SG, 2003, INT C AUD VID BAS BI, P845; Sanderson C, 2004, DIGIT SIGNAL PROCESS, V14, P449, DOI 10.1016/j.dsp.2004.05.001; Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960; SIEGEL M, 2004, IEEE INT WORKSH ROB, P96; Singh R, 2006, IEICE ELECTRON EXPR, V3, P429, DOI 10.1587/elex.3.429; SLANEY M, 2000, NEURAL INFORM PROCES, V13; Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6; Snoek C. G. M., 2005, ACM MULTIMEDIA, P399; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; SNOEK CGM, 2002, IEEE INT C MULT EXP, P21; SRIDHARAN H, 2003, ACM WORKSH EXP TEL B; STAUFFER C, 2005, MITCSAILTR2005057; Strobel N, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.911196; TALANTZIS F, 2006, IEEE 8 WORKSH MULT S, P243; TATBUL N, 2004, WORKSH DAT MAN SENS; TAVAKOLI A, 2005, 2 INT WORKSH NETW SE; Teissier P, 1998, J VLSI SIG PROCESS S, V20, P25, DOI 10.1023/A:1008014206206; TERIYAN VY, 1997, INT INT C MOD US CON, P21; TESIC J, 2007, IEEE INT C MULT EXP; Town C, 2007, INT J COMPUT VISION, V71, P235, DOI 10.1007/s11263-0006-7834-8; VERMAAK J, 2001, 8 IEEE INT C COMP VI, V1, P741; VOORHEES EM, 1995, ACM INT C RES DEV IN, P172; Wall M., 2003, SINGULAR VALUE DECOM, P91; WANG J, 2003, ACM INT C MULT BERK, P319; WANG J, 2003, ACM WORKSH VID SURV; Wang S, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236473; Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12; WESTERVELD T, 2000, RIAO CONTENT BASED M; Wu Huadong, 2003, THESIS CARNEGIE MELL; WU K, 2004, IEEE INT C IM PROC S, P2391; WU Y, 2005, ACM INT C MULT MM, P872; Wu Y, 2004, ACM INT C MULT NEW Y, P572; WU Z, 2006, INT C ADV BIOM, P493; Xie L., 2005, IEEE INT C AC SPEECH, V2, P1053; Xiong N., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00055-6; Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912; Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346; Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007; Yan R., 2006, THESIS CARNEGIE MELL; Yan R., 2004, ACM MULTIMEDIA 2004, P548; Yang MT, 2005, INT J IMAG SYST TECH, V15, P131, DOI 10.1002/ima.20046; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou QM, 2006, IMAGE VISION COMPUT, V24, P1244, DOI 10.1016/j.imavis.2005.06.008; ZHOU ZH, 2006, 9 PAC RIM INT C ART, P5; Zhu Q., 2006, ACM INT C MULT SANT, P211; Zotkins D., 2002, EURASIP J APPL SIG P, V11, P1154; Zou X, 2005, IEEE C COMP VIS PATT, P4; TRECVID DATA AVAILAB	158	84	84	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0942-4962			MULTIMEDIA SYST	Multimedia Syst.	NOV	2010	16	6					345	379		10.1007/s00530-010-0182-0		35	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	671MV	WOS:000283511100001		
J	Vincent, P; Larochelle, H; Lajoie, I; Bengio, Y; Manzagol, PA				Vincent, Pascal; Larochelle, Hugo; Lajoie, Isabelle; Bengio, Yoshua; Manzagol, Pierre-Antoine			Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						deep learning; unsupervised feature learning; deep belief networks; autoencoders; denoising	NEURAL-NETWORKS; CONTRASTIVE DIVERGENCE; NOISE; EQUIVALENT	We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.	[Vincent, Pascal; Lajoie, Isabelle; Bengio, Yoshua; Manzagol, Pierre-Antoine] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J8, Canada; [Larochelle, Hugo] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Vincent, P (reprint author), Univ Montreal, Dept Informat & Rech Operat, 2920 Chemin Tour, Montreal, PQ H3T 1J8, Canada.	PASCAL.VINCENT@UMONTREAL.CA; LAROCHEH@CS.TORONTO.EDU; ISABELLE.LAJOIE.1@UMONTREAL.CA; YOSHUA.BENGIO@UMONTREAL.CA; PIERRE-ANTOINE.MANZAGOL@UMONTREAL.CA			NSERC; MITACS; FQRNT; CIFAR; Canada Research Chairs	This research was supported by funding from NSERC, MITACS, FQRNT, CIFAR, and the Canada Research Chairs, and partly carried out on computation resources made available by RQCHP.	An GZ, 1996, NEURAL COMPUT, V8, P643, DOI 10.1162/neco.1996.8.3.643; BAIRD H, 1990, IAPR WORKSH SYNT STR, P38; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BENGIO Y, 2007, LARGE SCALE KERNAL M; BERGSTRA J, 2006, THESIS U MONTREAL; BESAG J, 1975, STATISTICIAN, V24, P179, DOI 10.2307/2987782; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Chapelle O., 2006, SEMISUPERVISED LEARN; CHO Y, 2010, ADV NEURAL INFORM PR, V22, P342; Erhan D, 2010, J MACH LEARN RES, V11, P625; GALLINARI P, 1987, P COGNITIVA 87 PAR L; Grandvalet Y, 1997, NEURAL COMPUT, V9, P1093, DOI 10.1162/neco.1997.9.5.1093; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Heckerman D., 2000, J MACHINE LEARNING R, V1, P49; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOLMSTROM L, 1992, IEEE T NEURAL NETWOR, V3, P24, DOI 10.1109/72.105415; HOPFIELD J, 1982, P NATL ACAD SCI US, V79; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; JAIN V, 2008, ADV NEURAL INFORM PR, V21; Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Larochelle H., 2009, P 12 INT C ART INT S, P312; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LeCun Y., 1987, THESIS U PARIS 6; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; LINSKER R, 1989, ADV NEURAL INFORM PR, V1; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V2; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; POGGIO T, 1992, 1347 AI MIT; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; SCALETTAR R, 1988, CONNECTIONIST MODELS, P309; Scholkopf B., 1996, LECT NOTES COMPUT SC, V1112, P47; SEUNG SH, 1998, ADV NEURAL INFORM PR, V10, P654; SIETSMA J, 1991, NEURAL NETWORKS, V4, P67, DOI 10.1016/0893-6080(91)90033-2; SIMARD P, 1992, ADV NEUR IN, V4, P895; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; VONLEHMANN A, 1988, IEEE INT C NEURAL NE, V1, P335; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303	53	81	100	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	DEC	2010	11						3371	3408				38	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	712BO	WOS:000286637200004		
J	Larochelle, H; Bengio, Y; Louradour, J; Lamblin, P				Larochelle, Hugo; Bengio, Yoshua; Louradour, Jerome; Lamblin, Pascal			Exploring Strategies for Training Deep Neural Networks	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						artificial neural networks; deep belief networks; restricted Boltzmann machines; autoassociators; unsupervised learning	COMPONENT ANALYSIS; BLIND SEPARATION; BELIEF NETWORKS; LOCAL MINIMA; ALGORITHM; DIMENSIONALITY; MACHINE	Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms.	[Larochelle, Hugo; Bengio, Yoshua; Louradour, Jerome; Lamblin, Pascal] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J8, Canada	Larochelle, H (reprint author), Univ Montreal, Dept Informat & Rech Operat, 2920 Chemin Tour, Montreal, PQ H3T 1J8, Canada.	LAROCHEH@IRO.UMONTREAL.CA; BENGIOY@IRO.UMONTREAL.CA; LOURADOJ@IRO.UMONTREAL.CA; LAMBLINP@IRO.UMONTREAL.CA			NSERC; MITACS; Canada Research Chairs	The author are particularly grateful for the inspiration from and constructive discussions with Dan Popovici, Aaron Courville, Olivier Delalleau, James Bergstra, and Dumitru Erhan. The authors also want to thank the editor and reviewers for their helpful comments and suggestions. This research was performed thanks to funding from NSERC, MITACS, and the Canada Research Chairs.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; AUER P, 1996, ADV NEURAL INFORM PR, V8, P315; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bengio Y., 2007, LARGE SCALE KERNEL M; BENGIO Y, 2007, 1311 U MONTR DEP IRO; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y., 2007, 1312 U MONTR DEP IRO; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bouchard G., 2004, IASC INT S COMP STAT, P721; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Cottrell G. W., 1987, 9TH ANN C COGN SCI S, P462; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; Fahlman S. E., 1990, ADV NEURAL INFORMATI, P524; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; Frey B. J., 1998, GRAPHICAL MODELS MAC; Fukumizu K, 2000, NEURAL NETWORKS, V13, P317, DOI 10.1016/S0893-6080(00)00009-5; HADSELL R, 2008, P INT ROB SYST IROS; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hinton G. E., 1995, SCIENCE, V268, P1558; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HINTON GE, 2006, 2006003 UTML TR U TO; HOLUB A, 2005, CVPR 05, V1, P664; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jaakkola T., 1999, ADV NEURAL INFORM PR, V11; Jebara T., 2003, MACHINE LEARNING DIS; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Larochelle H., 2007, 24 INT C MACH LEARN, P473; Lasserre J.A., 2006, CVPR 06, P87; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lengelle R, 1996, NEURAL NETWORKS, V9, P83, DOI 10.1016/0893-6080(95)00096-8; MOVELLAN JR, 2002, NEURAL COMPUT, V14, P1501; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Ng AY, 2001, NIPS, P841; OSINDERO S, 2008, NEUR INF PROC SYST C, V20; Ranzato M., 2007, ADV NEURAL INFORM PR, V19; Ranzato M., 2007, P COMP VIS PATT REC; RANZATO MA, 2008, ADV NEURAL INFORM PR, V20; Salakhutdinov R., 2007, P 2007 WORKSH INF RE; Salakhutdinov R., 2007, ICML 07, P791; Salakhutdinov R., 2008, P INT C MACH LEARN, V25; SALAKHUTDINOV R, 2007, P AISTATS 2007 SAN J; Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, V20; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; SAUND E, 1989, IEEE T PATTERN ANAL, V11, P304, DOI 10.1109/34.21799; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wegener I, 1987, COMPLEXITY BOOLEAN F; Welling M., 2005, ADV NEURAL INFORM PR, V17; WELLING M, 2002, ICANN 02; Weston J., 2008, P 25 INT C MACH LEAR; Yao A. C., 1985, P 26 ANN IEEE S FDN, P1	61	62	65	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JAN	2009	10						1	40				40	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BF	WOS:000270824100001		
J	Bergstra, J; Bengio, Y				Bergstra, James; Bengio, Yoshua			Random Search for Hyper-Parameter Optimization	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						global optimization; model selection; neural networks; deep learning; response surface modeling		Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success-they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.	[Bergstra, James; Bengio, Yoshua] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Bergstra, J (reprint author), Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.	JAMES.BERGSTRA@UMONTREAL.CA; YOSHUA.BENGIO@UMONTREAL.CA			National Science and Engineering Research Council of Canada; Compute Canada	This work was supported by the National Science and Engineering Research Council of Canada and Compute Canada, and implemented with Theano (Bergstra et al., 2010).	Antonov I. A., 1979, USSR COMP MATH MATH, V19, P252, DOI 10.1016/0041-5553(79)90085-5; Bellman R, 1961, ADAPTIVE CONTROL PRO; Bengio Y., 2010, P AISTATS 2010, P249; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergstra J, 2010, P PHYTH SCI COMP C S; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bratley P., 1992, SIMULATION, V2, P195; Caflisch R, 1997, VALUATION MORTGAGE B; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Czogiel I., 2005, RESPONSE SURFACE MET; Drew SS, 2006, Proceedings of the 2006 Winter Simulation Conference, Vols 1-5, P774, DOI 10.1109/WSC.2006.323158; Erhan D, 2010, J MACH LEARN RES, V11, P625; Galassi M., 2009, GNU SCI LIB REFERENC; Halton J.H., 1960, NUMER MATH, V2, P84, DOI [10.1007/BF01386213, DOI 10.1007/BF01386213]; Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970; Hinton G., 2010, 2010003 U TOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hutter F., 2009, THESIS U BRIT COLUMB; Hutter F., 2011, LION 5; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kleinman NL, 1999, MANAGE SCI, V45, P1570, DOI 10.1287/mnsc.45.11.1570; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, NEURAL NETWORKS TRIC; MCKAY MD, 1979, TECHNOMETRICS, V21, P239, DOI 10.2307/1268522; Nareyek A., 2003, APPL OPTIMIZATION, V86, P523; Neal R. M., 1998, Neural Networks and Machine Learning. Proceedings; NELDER JA, 1965, COMPUT J, V7, P308; Powell MJD, 1994, ADV OPTIMIZATION NUM, P51; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rechenberg I., 1973, EVOLUTIONSTRATEGIE O; Srinivasan A, 2011, J MACH LEARN RES, V12, P627; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Weise T., 2009, GLOBAL OPTIMIZATION	34	59	60	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2012	13						281	305				25	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	929FF	WOS:000303046000003		
J	Bavelier, D; Green, CS; Pouget, A; Schrater, P		Hyman, SE		Bavelier, Daphne; Green, C. Shawn; Pouget, Alexandre; Schrater, Paul			Brain Plasticity Through the Life Span: Learning to Learn and Action Video Games	ANNUAL REVIEW OF NEUROSCIENCE, VOL 35	Annual Review of Neuroscience		English	Review; Book Chapter						transfer; generalization; probabilistic inference; cognitive control; resource allocation; knowledge; hierarchy; learning rules	PROBABILISTIC POPULATION CODES; CORTICAL MAP REORGANIZATION; MULTIPLE-OBJECT TRACKING; WORKING-MEMORY; COGNITIVE CONTROL; SPATIAL COGNITION; OLDER-ADULTS; SELECTIVE ATTENTION; INFORMAL-EDUCATION; BAYESIAN-INFERENCE	The ability of the human brain to learn is exceptional. Yet, learning is typically quite specific to the exact task used during training, a limiting factor for practical applications such as rehabilitation, workforce training, or education. The possibility of identifying training regimens that have a broad enough impact to transfer to a variety of tasks is thus highly appealing. This work reviews how complex training environments such as action video game play may actually foster brain plasticity and learning. This enhanced learning capacity, termed learning to learn, is considered in light of its computational requirements and putative neural mechanisms.	[Bavelier, Daphne; Pouget, Alexandre] Univ Geneva, Dept Psychol & Educ Sci, CH-1211 Geneva 4, Switzerland; [Bavelier, Daphne; Pouget, Alexandre] Univ Rochester, Dept Brain & Cognit Sci, Rochester, NY 14627 USA; [Green, C. Shawn] Univ Wisconsin, Dept Psychol, Eye Res Inst, Madison, WI 53706 USA; [Schrater, Paul] Univ Minnesota, Dept Psychol, Minneapolis, MN 55455 USA; [Schrater, Paul] Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Bavelier, D (reprint author), Univ Geneva, Dept Psychol & Educ Sci, CH-1211 Geneva 4, Switzerland.	daphne@bcs.rochester.edu; csgreen2@wisc.edu; alex@bcs.rochester.edu; schrater@umn.edu					Anderson AF, 2011, COMPUTER GAMES AND INSTRUCTION, P307; Andrews G., 2006, FRONTIERS COGNITIVE, P145; Badre D, 2008, TRENDS COGN SCI, V12, P193, DOI 10.1016/j.tics.2008.02.004; Bailey K, 2010, PSYCHOPHYSIOLOGY, V47, P34, DOI 10.1111/j.1469-8986.2009.00925.x; Baldassarre A, 2012, P NATL ACAD SCI USA, V109, P3516, DOI 10.1073/pnas.1113148109; Baluchi F, 2011, TRENDS NEUROSCI, V34, P210, DOI 10.1016/j.tins.2011.02.003; Bao SW, 2001, NATURE, V412, P79, DOI 10.1038/35083586; Bavelier D, 2012, VISION RES, V61, P132, DOI 10.1016/j.visres.2011.08.007; Bavelier D, 2010, J NEUROSCI, V30, P14964, DOI 10.1523/JNEUROSCI.4812-10.2010; Beck JM, 2008, NEURON, V60, P1142, DOI 10.1016/j.neuron.2008.09.021; Behrens TEJ, 2007, NAT NEUROSCI, V10, P1214, DOI 10.1038/nn1954; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Benson PG, 2001, CORSINI ENCY PSYCHOL, P667; Binet A., 1984, IDEES MODERNES ENFAN; Boot WR, 2008, ACTA PSYCHOL, V129, P387, DOI 10.1016/j.actpsy.2008.09.005; Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009; Buckley D, 2010, VISION RES, V50, P548, DOI 10.1016/j.visres.2009.11.018; Buschkuehl M, 2008, PSYCHOL AGING, V23, P743, DOI 10.1037/a0014342; Cain MS, 2012, ATTEN PERCEPT PSYCHO, V74, P641, DOI 10.3758/s13414-012-0284-1; Carrasco Marisa, 2002, J Vis, V2, P467, DOI 10.1167/2.6.4; Castel AD, 2005, ACTA PSYCHOL, V119, P217, DOI 10.1016/j.actpsy.2005.02.004; Cavanagh P, 2005, TRENDS COGN SCI, V9, P349, DOI 10.1016/j.tics.2005.05.009; Chisholm JD, 2011, ATTEN PERCEPT PSYCHO, V74, P257; Chisholm JD, 2010, ATTEN PERCEPT PSYCHO, V72, P667, DOI 10.3758/APP.72.3.667; Christoff K, 2007, PERSPECTIVES RULE GU, P107; Clapp WC, 2011, P NATL ACAD SCI USA, V108, P7212, DOI 10.1073/pnas.1015297108; Cohen J. E., 2007, COMPUTER GAMES ADULT, P205; Colzato L. S., 2010, FRONT PSYCHOL, V1, P1, DOI DOI 10.3389/FPSYG.2010.00008; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; Dahlin E, 2008, PSYCHOL AGING, V23, P720, DOI 10.1037/a0014296; Daily Mail, 2009, DAILY MAIL ONLI 0228; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; DiCarlo JJ, 2007, TRENDS COGN SCI, V11, P333, DOI 10.1016/j.tics.2007.06.010; Donohue SE, 2010, ATTEN PERCEPT PSYCHO, V72, P1120, DOI 10.3758/APP.72.4.1120; Dosenbach NUF, 2008, TRENDS COGN SCI, V12, P99, DOI 10.1016/j.tics.2008.01.001; Dosher BA, 1998, P NATL ACAD SCI USA, V95, P13988, DOI 10.1073/pnas.95.23.13988; Durkin K, 2010, REV GEN PSYCHOL, V14, P122, DOI 10.1037/a0019438; Dye MWG, 2010, VISION RES, V50, P452, DOI 10.1016/j.visres.2009.10.010; Dye MWG, 2009, NEUROPSYCHOLOGIA, V47, P1780, DOI 10.1016/j.neuropsychologia.2009.02.002; Dye MWG, 2009, CURR DIR PSYCHOL SCI, V18, P321; Egerton A, 2009, NEUROSCI BIOBEHAV R, V33, P1109, DOI 10.1016/j.neubiorev.2009.05.005; Erickson KI, 2009, BRIT J SPORT MED, V43, P22, DOI 10.1136/bjsm.2008.052498; Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x; Frey SH, 2011, NEUROREHAB NEURAL RE, V25, p6S, DOI 10.1177/1545968311410940; Fuster JM, 2004, TRENDS COGN SCI, V8, P143, DOI 10.1016/j.tics.2004.02.004; Gallistel Charles R., 2009, MEMORY COMPUTATIONAL; Gallistel CR, 2008, LEARN THEORY BEHAV, V1, P529; Goard M, 2009, NAT NEUROSCI, V12, P1444, DOI 10.1038/nn.2402; GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325; Green CS, 2006, COGNITION, V101, P217, DOI 10.1016/j.cognition.2005.10.004; Green CS, 2010, CURR BIOL, V20, P1573, DOI 10.1016/j.cub.2010.07.040; Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647; Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x; Green CS, 2012, CURR BIOL, V22, pR167; Green CS, 2006, J EXP PSYCHOL HUMAN, V32, P1465, DOI 10.1037/0096-1523.32.6.1465; Greenfield PM, 2009, SCIENCE, V323, P69, DOI 10.1126/science.1167190; Greenfield PM, 1994, J APPL DEV PSYCHOL, V15, P105, DOI DOI 10.1016/0193-3973(94)90008-6; Halpern Diane F, 2007, Psychol Sci Public Interest, V8, P1, DOI 10.1111/j.1529-1006.2007.00032.x; HARLOW HF, 1949, PSYCHOL REV, V56, P51, DOI 10.1037/h0062474; Herrero JL, 2008, NATURE, V454, P1110, DOI 10.1038/nature07141; Hillman CH, 2008, NAT REV NEUROSCI, V9, P58, DOI 10.1038/nrn2298; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Ma WJ, 2009, J VISION, V9, DOI 10.1167/9.11.3; Hubert-Wallander B, 2011, ATTEN PERCEPT PSYCHO, V73, P2399, DOI 10.3758/s13414-011-0194-7; Jaeggi SM, 2008, P NATL ACAD SCI USA, V105, P6829, DOI 10.1073/pnas.0801268105; Ji WQ, 2001, J NEUROPHYSIOL, V86, P211; Karle JW, 2010, ACTA PSYCHOL, V134, P70, DOI 10.1016/j.actpsy.2009.12.007; Kemp C, 2010, COGNITIVE SCI, V23, P1; Khoe WW, 2010, SOC NEUROSCI MEET PL; Kilgard MP, 1998, SCIENCE, V279, P1714, DOI 10.1126/science.279.5357.1714; Klingberg T, 2010, TRENDS COGN SCI, V14, P317, DOI 10.1016/j.tics.2010.05.002; Knill D.C, 1996, PERCEPTION BAYESIAN; Koechlin E., 2008, ATTENTION PERFORM, P483; Koechlin E, 2007, TRENDS COGN SCI, V11, P229, DOI 10.1016/j.tics.2007.04.005; Koepp MJ, 1998, NATURE, V393, P266; Larochelle H, 2007, P INT C MACH LEARN 2; Lashley K., 1951, CEREBRAL MECH BEHAV, P112; Lavie N, 2005, TRENDS COGN SCI, V9, P75, DOI 10.1016/j.tics.2004.12.004; Lee H, 2009, P INT C MACH LEARN 2; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; LEGGE GE, 1985, VISION RES, V25, P253, DOI 10.1016/0042-6989(85)90118-X; Li RJ, 2010, J VISION, V10, DOI 10.1167/10.14.33; Li RJ, 2009, NAT NEUROSCI, V12, P549, DOI 10.1038/nn.2296; Li RW, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001135; Li S, 2009, NEURON, V62, P441, DOI 10.1016/j.neuron.2009.03.016; Lustig C, 2009, NEUROPSYCHOL REV, V19, P504, DOI 10.1007/s11065-009-9119-9; Lutz A, 2008, TRENDS COGN SCI, V12, P163, DOI 10.1016/j.tics.2008.01.005; Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790; MCCLURG PA, 1987, J EDUC COMPUT RES, V3, P95; McKinley RA, 2011, AVIAT SPACE ENVIR MD, V82, P635, DOI 10.3357/ASEM.2958.2011; McNab F, 2009, SCIENCE, V323, P800, DOI 10.1126/science.1166102; Mishra J, 2011, J NEUROSCI, V31, P992, DOI 10.1523/JNEUROSCI.4834-10.2011; Mohamed A., 2011, IEEE T AUDIO SPEECH; OKAGAKI L, 1994, J APPL DEV PSYCHOL, V15, P33, DOI DOI 10.1016/0193-3973(94)90005-1; Olesen PJ, 2004, NAT NEUROSCI, V7, P75, DOI 10.1038/nn1165; Ophir E, 2009, P NATL ACAD SCI USA, V106, P15583, DOI 10.1073/pnas.0903620106; Palmer J, 2005, J VISION, V5, P376, DOI 10.1167/5.5.1; Paupathy A, 2002, NAT NEUROSCI, V5, P1332; Perfors AF, 2009, ANN C COGN SCI SOC 3; Polley DB, 2006, J NEUROSCI, V26, P4970, DOI 10.1523/JNEUROSCI.3771-05.2006; Pouget A., 1991, Connection Science, V3, DOI 10.1080/09540099108946581; PYLYSHYN Z W, 1988, Spatial Vision, V3, P179, DOI 10.1163/156856888X00122; Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976; Ratcliff R, 2008, NEURAL COMPUT, V20, P873, DOI 10.1162/neco.2008.12-06-420; Renner MJ, 1987, ENRICHED IMPOVERISHE; Ribas-Fernandes JJF, 2011, NEURON, V71, P370, DOI 10.1016/j.neuron.2011.05.042; Roelfsema PR, 2010, TRENDS COGN SCI, V14, P64, DOI 10.1016/j.tics.2009.11.005; ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037//0096-3445.104.3.192; Rosen LD, 2007, ME MYSPACE I; Rosser JC, 2007, ARCH SURG-CHICAGO, V142, P181, DOI 10.1001/archsurg.142.2.181; Rougier NP, 2005, P NATL ACAD SCI USA, V102, P7338, DOI 10.1073/pnas.0502455102; Rumelhart D., 1987, PARALLEL DISTRIBUTED, V1; Saffell T, 2003, VISION RES, V43, P1365, DOI 10.1016/S0042-6989(03)00137-8; Sakai K, 2008, ANNU REV NEUROSCI, V31, P219, DOI 10.1146/annurev.neuro.31.060407.125642; Sarter M, 2005, BRAIN RES REV, V48, P98, DOI 10.1016/j.brainresrev.2004.08.006; Schellenberg EG, 2004, PSYCHOL SCI, V15, P511; Schlickum MK, 2009, WORLD J SURG, V33, P2360, DOI 10.1007/s00268-009-0151-y; Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593; Serences JT, 2004, J NEUROPHYSIOL, V92, P3538, DOI 10.1152/jn.00435.2004; Shapiro D. C., 1982, DEV MOVEMENT CONTROL, P113; Shapiro KL, 1997, TRENDS COGN SCI, V1, P291, DOI 10.1016/S1364-6613(97)01094-2; Simen P, 2009, J EXP PSYCHOL HUMAN, V35, P1865, DOI 10.1037/a0016926; Simon H. A., 1973, VISUAL INFORMATION P, P215; SITARAM N, 1978, SCIENCE, V201, P274, DOI 10.1126/science.351808; Spelke ES, 2005, AM PSYCHOL, V60, P950, DOI 10.1037/0003-066X.60.9.950; Spence I, 2010, REV GEN PSYCHOL, V14, P92, DOI 10.1037/a0019491; Spence I, 2009, J EXP PSYCHOL LEARN, V35, P1097, DOI 10.1037/a0015641; Stevens C, 2012, DEV COGN NEUROS-NETH, V2, pS30, DOI 10.1016/j.dcn.2011.11.001; Stilp CE, 2010, P NATL ACAD SCI USA, V107, P21914, DOI 10.1073/pnas.1009020107; Strobach T, 2012, ACTA PSYCHOL, V140, P13, DOI 10.1016/j.actpsy.2012.02.001; Subrahmanyan K., 1994, J APPL DEV PSYCHOL, V15, P13, DOI DOI 10.1016/0193-3973(94)90004-3; Takeuchi H, 2010, J NEUROSCI, V30, P3297, DOI 10.1523/JNEUROSCI.4611-09.2010; Tang YY, 2009, TRENDS COGN SCI, V13, P222, DOI 10.1016/j.tics.2009.01.009; Thorndike EL, 1901, PSYCHOL REV, V8, P247; Toepper M, 2010, NEUROSCIENCE, V165, P1244, DOI 10.1016/j.neuroscience.2009.11.019; Trick LM, 2005, COGNITIVE DEV, V20, P373, DOI 10.1016/j.cogdev.2005.05.009; Vul E, 2009, J EXP PSYCHOL GEN, V138, P546, DOI 10.1037/a0017352; Vul E, 2010, ADV NEURAL INF P SYS, V32, P1955; West GL, 2008, J VISION, V8, DOI 10.1167/8.16.13; Yamane Y, 2008, NAT NEUROSCI, V11, P1352, DOI 10.1038/nn.2202	141	53	53	ANNUAL REVIEWS	PALO ALTO	4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA	0147-006X		978-0-8243-2435-3	ANNU REV NEUROSCI	Annu. Rev. Neurosci.		2012	35						391	416		10.1146/annurev-neuro-060909-152832		26	Neurosciences	Neurosciences & Neurology	BBR21	WOS:000307960400020	22715883	
J	Witten, DM; Tibshirani, R				Witten, Daniela M.; Tibshirani, Robert			Covariance-regularized regression and classification for high dimensional problems	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Classification; Covariance regularization; n < p; Regression; Variable selection	B-CELL LYMPHOMA; MAXIMUM-LIKELIHOOD-ESTIMATION; GENE-EXPRESSION; DISCRIMINANT-ANALYSIS; SHRUNKEN CENTROIDS; VARIABLE SELECTION; MODEL SELECTION; MICROARRAYS; LASSO; PREDICTION	We propose covariance-regularized regression, a family of methods for prediction in high dimensional settings that uses a shrunken estimate of the inverse covariance matrix of the features to achieve superior prediction. An estimate of the inverse covariance matrix is obtained by maximizing the log-likelihood of the data, under a multivariate normal model, subject to a penalty; it is then used to estimate coefficients for the regression of the response onto the features. We show that ridge regression, the lasso and the elastic net are special cases of covariance-regularized regression, and we demonstrate that certain previously unexplored forms of covariance-regularized regression can outperform existing methods in a range of situations. The covariance-regularized regression framework is extended to generalized linear models and linear discriminant analysis, and is used to analyse gene expression data sets with multiple class and survival outcomes.	[Witten, Daniela M.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Witten, DM (reprint author), Stanford Univ, Dept Stat, 390 Serra Mall, Stanford, CA 94305 USA.	dwitten@stanford.edu			National Defense Science and Engineering Graduate Fellowship; National Science Foundation [DMS-9971405]; National Institutes of Health [N01-HV-28183]	We thank the Joint Editor and two reviewers for helpful comments. We thank Trevor Hastie for showing us the solution to the penalized log-likelihood with an L<INF>2</INF>-penalty. We thank both Trevor Hastie and Jerome Friedman for valuable discussions and for providing the code for the L<INF>2</INF>-penalized multiclass logistic regression and the elastic net. Daniela Witten was supported by a National Defense Science and Engineering Graduate Fellowship. Robert Tibshirani was partially supported by National Science Foundation grant DMS-9971405 and National Institutes of Health contract N01-HV-28183.	Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.00200108; Banerjee O, 2008, J MACH LEARN RES, V9, P485; BICKEL P, 2008, ANN STAT IN PRESS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; DEY DK, 1985, ANN STAT, V13, P1581, DOI 10.1214/aos/1176349756; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; FRIEDMAN J, 2008, REGULARIZAT IN PRESS; Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GREEN PJ, 1984, J ROY STAT SOC B MET, V46, P149; Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035; HAFF LR, 1979, ANN STAT, V7, P1264, DOI 10.1214/aos/1176344845; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hummel M, 2006, NEW ENGL J MED, V354, P2419, DOI 10.1056/NEJMoa055351; James W., 1961, P 4 BERK S MATH STAT, V1, P361; Kalbfleisch J. D., 1980, STAT ANAL FAILURE TI; Liang F, 2007, STAT SCI, V22, P189, DOI 10.1214/088342307000000032; Mardia K. V., 1979, MULTIVARIATE ANAL; McLachlan GJ, 1992, DISCRIMINANT ANAL ST; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Monti S, 2005, BLOOD, V105, P1851, DOI 10.1182/blood-2004.07.2947; ONEILL TJ, 1978, J AM STAT ASSOC, V73, P821, DOI 10.2307/2286287; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; Rothman AJ, 2008, ELECTRON J STAT, V2, P494, DOI 10.1214/08-EJS176; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhu J, 2004, BIOSTATISTICS, V5, P427, DOI 10.1093/biostatistics/kxg046; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	35	52	52	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1369-7412	1467-9868		J R STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2009	71		3				615	636		10.1111/j.1467-9868.2009.00699.x		22	Statistics & Probability	Mathematics	453HT	WOS:000266602200003		
J	Knights, D; Costello, EK; Knight, R				Knights, Dan; Costello, Elizabeth K.; Knight, Rob			Supervised classification of human microbiota	FEMS MICROBIOLOGY REVIEWS			English	Review						human microbiota; microbial forensics; microbiota classification; machine learning; supervised classification	SUPPORT VECTOR MACHINES; GENE-EXPRESSION; MICROARRAY DATA; GUT MICROBIOTA; RIBOSOMAL-RNA; DIVERSITY; COMMUNITIES; SELECTION; REGULARIZATION; IDENTIFICATION	Recent advances in DNA sequencing technology have allowed the collection of high-dimensional data from human-associated microbial communities on an unprecedented scale. A major goal of these studies is the identification of important groups of microorganisms that vary according to physiological or disease states in the host, but the incidence of rare taxa and the large numbers of taxa observed make that goal difficult to obtain using traditional approaches. Fortunately, similar problems have been addressed by the machine learning community in other fields of study such as microarray analysis and text classification. In this review, we demonstrate that several existing supervised classifiers can be applied effectively to microbiota classification, both for selecting subsets of taxa that are highly discriminative of the type of community, and for building models that can accurately classify unlabeled data. To encourage the development of new approaches to supervised classification of microbiota, we discuss several structures inherent in microbial community data that may be available for exploitation in novel approaches, and we include as supplemental information several benchmark classification tasks for use by the community.	[Knight, Rob] Univ Colorado, Dept Chem & Biochem, Boulder, CO 80309 USA; [Knight, Rob] Howard Hughes Med Inst, Chevy Chase, MD USA; [Costello, Elizabeth K.] Stanford Univ, Dept Microbiol & Immunol, Stanford, CA 94305 USA; [Knights, Dan] Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA	Knight, R (reprint author), Univ Colorado, Dept Chem & Biochem, UCB 215, Boulder, CO 80309 USA.	rob@spot.colorado.edu					Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BLEI DM, 2008, ADV NIPS, P121; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Caporaso JG, 2010, NAT METHODS, V7, P335, DOI 10.1038/nmeth.f.303; CHANG J, 2010, LDA COLLAPSED GIBBS; Clayton TA, 2009, P NATL ACAD SCI USA, V106, P14728, DOI 10.1073/pnas.0904489106; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Costello EK, 2009, SCIENCE, V326, P1694, DOI 10.1126/science.1177486; Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1; Dimitriadou E., 2010, E1071 MISC FUNCTIONS, pe1071; EDGAR RC, 2010, UCLUST; Field D, 2008, NAT BIOTECHNOL, V26, P541, DOI 10.1038/nbt1360; Fierer N, 2008, P NATL ACAD SCI USA, V105, P17994, DOI 10.1073/pnas.0807920105; Fierer N, 2010, P NATL ACAD SCI USA, V107, P6477, DOI 10.1073/pnas.1000162107; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Friedman J, 2010, J STAT SOFTW, V33, P1; Gashler M., 2008, 7 INT C MACH LEARN A, P900, DOI DOI 10.1109/ICMLA.2008.154; Grice EA, 2009, SCIENCE, V324, P1190, DOI 10.1126/science.1171700; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 2009, PAMR PREDICTION ANAL; Hastie T., 2009, ELEMENTS STAT LEARNI; Hehemann JH, 2010, NATURE, V464, P908, DOI 10.1038/nature08937; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hooper LV, 2001, SCIENCE, V292, P1115, DOI 10.1126/science.1058709; Horner-Devine MC, 2007, ECOLOGY, V88, P1345, DOI 10.1890/06-0286; Kuhnert P, 2008, PASTEURELLACEAE BIOL; Lal T.N., 2006, FEATURE EXTRACTION F, P137; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Lee SS, 2000, COMPUT STAT DATA AN, V34, P165, DOI 10.1016/S0167-9473(99)00095-X; Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098; Ley RE, 2008, NAT REV MICROBIOL, V6, P776, DOI 10.1038/nrmicro1978; Li M, 2008, P NATL ACAD SCI USA, V105, P2117, DOI 10.1073/pnas.0712038105; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lozupone C, 2005, APPL ENVIRON MICROB, V71, P8228, DOI 10.1128/AEM.71.12.8228-8235.2005; Lozupone CA, 2008, FEMS MICROBIOL REV, V32, P557, DOI 10.1111/j.1574-6976.2008.00111.x; Magurran A.E., 2004, MEASURING BIOL DIVER; MANMZ, 2004, J BIOPHARM STAT, V14, P1065; Martin AP, 2002, APPL ENVIRON MICROB, V68, P3673, DOI 10.1128/AEM.68.8.3673-3682.2002; McCallum A., 2006, P 21 NAT C ART INT, P433; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nigam K, 1998, AAAI 98 WORKSH LEARN, V752; Quince C, 2009, NAT METHODS, V6, P639, DOI [10.1038/nmeth.1361, 10.1038/NMETH.1361]; Saeys Y, 2007, BIOINFORMATICS, V23, pI418, DOI 10.1093/bioinformatics/btm177; Schloss PD, 2005, APPL ENVIRON MICROB, V71, P1501, DOI 10.1128/AEM.71.3.1501-1506.2005; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Turnbaugh PJ, 2009, SCI TRANSL MED, V1, DOI 10.1126/scitranslmed.3000322; Turnbaugh PJ, 2009, NATURE, V457, P480, DOI 10.1038/nature07540; Turnbaugh PJ, 2007, NATURE, V449, P804, DOI 10.1038/nature06244; Van Eldere J, 2003, J ANTIMICROB CHEMOTH, V51, P347, DOI 10.1093/jac/dkg102; Wang Q, 2007, APPL ENVIRON MICROB, V73, P5261, DOI 10.1128/AEM.00062-07; Wen L, 2008, NATURE, V455, P1109, DOI 10.1038/nature07336; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Weston J, 2001, ADV NEUR IN, V13, P668; Yang CY, 2006, J MICROBIOL METH, V65, P49, DOI 10.1016/j.mimet.2005.06.012; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	57	51	52	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0168-6445			FEMS MICROBIOL REV	Fems Microbiol. Rev.	MAR	2011	35	2					343	359		10.1111/j.1574-6976.2010.00251.x		17	Microbiology	Microbiology	714VR	WOS:000286837600006	21039646	
J	Ganmor, E; Segev, R; Schneidman, E				Ganmor, Elad; Segev, Ronen; Schneidman, Elad			Sparse low-order interaction network underlies a highly correlated and learnable neural population code	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						high-order; correlations; maximum entropy; neural networks; sparseness	FIRING PATTERNS; NEURONAL POPULATION; MOVEMENT DIRECTION; CORTICAL NETWORKS; CELL ASSEMBLIES; PRIMATE RETINA; INFORMATION; REDUNDANCY; MODEL; REDUCTION	Information is carried in the brain by the joint activity patterns of large groups of neurons. Understanding the structure and function of population neural codes is challenging because of the exponential number of possible activity patterns and dependencies among neurons. We report here that for groups of similar to 100 retinal neurons responding to natural stimuli, pairwise-based models, which were highly accurate for small networks, are no longer sufficient. We show that because of the sparse nature of the neural code, the higher-order interactions can be easily learned using a novel model and that a very sparse low-order interaction network underlies the code of large populations of neurons. Additionally, we show that the interaction network is organized in a hierarchical and modular manner, which hints at scalability. Our results suggest that learnability may be a key feature of the neural code.	[Segev, Ronen] Ben Gurion Univ Negev, Dept Life Sci, IL-84105 Beer Sheva, Israel; [Segev, Ronen] Ben Gurion Univ Negev, Zlotowski Ctr Neurosci, IL-84105 Beer Sheva, Israel; [Ganmor, Elad; Schneidman, Elad] Weizmann Inst Sci, Dept Neurobiol, IL-76100 Rehovot, Israel	Segev, R (reprint author), Ben Gurion Univ Negev, Dept Life Sci, IL-84105 Beer Sheva, Israel.	ronensgv@bgu.ac.il; elad.schneidman@weizmann.ac.il	SEGEV, RONEN/F-1550-2012		Israel Science Foundation; The Center for Complexity Science; Minerva Foundation; ERASysBio+ program; The Clore Center for Biological Physics; The Peter and Patricia Gruber Foundation	We thank M. Tsodyks, I. Lampl, R. Paz, O. Barak, M. Shamir, Y. Pilpel, G. Tkacik, and W. Bialek for discussions and comments on the manuscript. This work was supported by the Israel Science Foundation and The Center for Complexity Science. E.S. is supported by the Minerva Foundation, ERASysBio+ program, The Clore Center for Biological Physics, and The Peter and Patricia Gruber Foundation.	Abbeel P, 2006, J MACH LEARN RES, V7, P1743; Amari S, 2001, IEEE T INFORM THEORY, V47, P1701, DOI 10.1109/18.930911; Averbeck BB, 2004, TRENDS NEUROSCI, V27, P225, DOI 10.1016/j.tins.2004.02.006; Bair W, 2001, J NEUROSCI, V21, P1676; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; BETHGE M, 2008, NEAR MAXIMUM ENTROPY, P97; BRODERICK T, 2007, ARXIV07122437QBIOQM; Brown EN, 1998, J NEUROSCI, V18, P7411; Chechik G, 2006, NEURON, V51, P359, DOI 10.1016/j.neuron.2006.06.030; Cocco S, 2009, P NATL ACAD SCI USA, V106, P14058, DOI 10.1073/pnas.0906705106; Dan Y, 1998, NAT NEUROSCI, V1, P501, DOI 10.1038/2217; Ganmor E, 2011, J NEUROSCI, V31, P3044, DOI 10.1523/JNEUROSCI.3682-10.2011; GEORGOPOULOS AP, 1986, SCIENCE, V233, P1416, DOI 10.1126/science.3749885; Harris KD, 2003, NATURE, V424, P552, DOI 10.1038/nature01834; Hatsopoulos NG, 1998, P NATL ACAD SCI USA, V95, P15706, DOI 10.1073/pnas.95.26.15706; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; Huber D, 2008, NATURE, V451, P61, DOI 10.1038/nature06445; LEMASSON G, 1993, SCIENCE, V259, P1915, DOI 10.1126/science.8456317; Marre O, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.138101; Martignon L, 2000, NEURAL COMPUT, V12, P2621, DOI 10.1162/089976600300014872; Narayanan NS, 2005, J NEUROSCI, V25, P4207, DOI 10.1523/JNEUROSCI.4697-04.2005; Ohiorhenuan IE, 2010, NATURE, V466, P617, DOI 10.1038/nature09178; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Pearl J, 1988, PROBABILISTIC REASON; Perkel D. H., 1968, NEUROSCI RES PROGRAM, V6, P221; Pillow JW, 2008, NATURE, V454, P995, DOI 10.1038/nature07140; Puchalla JL, 2005, NEURON, V46, P493, DOI 10.1016/j.neuron.2005.03.026; Riehle A, 1997, SCIENCE, V278, P1950, DOI 10.1126/science.278.5345.1950; Rieke F, 1997, SPIKES EXPLORING NEU; Santos GS, 2010, J NEUROSCI, V30, P8720, DOI 10.1523/JNEUROSCI.6141-09.2010; Schneidman E, 2006, NATURE, V440, P1007, DOI 10.1038/nature04701; Schneidman E, 2003, J NEUROSCI, V23, P11539; Schneidman E, 2003, PHYS REV LETT, V91, DOI 10.1103/PhysRevLett.91.238701; Schnitzer MJ, 2003, NEURON, V37, P499, DOI 10.1016/S0896-6273(03)00004-7; Shlens J, 2006, J NEUROSCI, V26, P8254, DOI 10.1523/JNEUROSCI.1282-06.2006; Shlens J, 2009, J NEUROSCI, V29, P5022, DOI 10.1523/JNEUROSCI.5187-08.2009; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Stopfer M, 1997, NATURE, V390, P70; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; Tang A, 2008, J NEUROSCI, V28, P505, DOI 10.1523/JNEUROSCI.3359-07.2008; TKACIK G, 2006, ARXIV0611072QBIO; TURRIGIANO G, 1994, SCIENCE, V264, P974, DOI 10.1126/science.8178157	45	50	50	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUN 7	2011	108	23					9679	9684		10.1073/pnas.1019641108		6	Multidisciplinary Sciences	Science & Technology - Other Topics	773WE	WOS:000291341400071	21602497	
J	Arel, I; Rose, DC; Karnowski, TP				Arel, Itamar; Rose, Derek C.; Karnowski, Thomas P.			Deep Machine Learning-A New Frontier in Artificial Intelligence Research	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							NEURAL-NETWORK MODEL; OBJECT RECOGNITION; VISUAL-CORTEX; FACE DETECTION; NEOCOGNITRON; ARCHITECTURE		[Arel, Itamar; Rose, Derek C.; Karnowski, Thomas P.] Univ Tennessee, Knoxville, TN 37996 USA	Arel, I (reprint author), Univ Tennessee, Knoxville, TN 37996 USA.						Adler A, 2007, IEEE T SYST MAN CY B, V37, P1248, DOI 10.1109/TSMCB.2007.907036; [Anonymous], MNIST DATABASE HANDW; AREL I, 2008, P 2008 AAAI WORKSH B; Behnke S., 2003, HIERARCHICAL NEURAL; Bellman R., 1957, DYNAMIC PROGRAMMING; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; *CALT, 2001, CALT 101 DAT; CHEN YN, 2006, P 18 2NT C PATT REC, P552; DEAN T, 2005, P NAT C ART INT, V20, P938; DEAN T, 2007, P NAT C ART INT, V1597; De Jong KA, 2008, IEEE COMPUT INTELL M, V3, P12, DOI 10.1109/MCI.2007.913370; Duda R.O., 2000, PATTERN RECOGNITION; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; Fukushima K, 2005, NEURAL NETWORKS, V18, P33, DOI 10.1016/j.neunet.2004.05.001; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; George D., 2008, THESIS STANFORD U ST; HADSELL R, 2008, P INT ROB SYST IROS, P628; HAWKINS J, 2004, TIMES BOOKS      OCT; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang F.-J., 2006, P COMP VIS PATT REC; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Kavukcuoglu K., 2009, P INT C COMP VIS PAT; Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551; LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ADV NEURAL INFORM PR, V22; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; LOCKETT A, 2009, AI0904 U TEX DEP COM; Marr D, 1983, VISION COMPUTATIONAL; Miller J., 2006, P SPIE, V6384; Mobahi H., 2009, P 26 ANN INT C MACH, P737; Newton EM, 2009, IEEE T SYST MAN CY A, V39, P4, DOI 10.1109/TSMCA.2008.2008210; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Pearl J, 1988, PROBABILISTIC REASON; Ranzato M., 2007, P COMP VIS PATT REC; RICE SV, 1996, TR9601 INF SCI RES I; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; Sukittanon S., 2004, INTERSPEECH, P1077; SUTSKEVER I, 2007, P 11 INT C ART INT S; SZARVAS M, 2006, P IEEE INT S INT VEH, P213; TIVIVE F, 2003, P INT JOINT C NEUR N, V3, P2157, DOI 10.1109/IJCNN.2003.1223742; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Wallace K. A., 1999, Ethics and Information Technology, V1; Wallis G, 1997, PROG NEUROBIOL, V51, P167, DOI 10.1016/S0301-0082(96)00054-8; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; Yao X., 2008, IEEE COMPUTATIONAL I, V3, P31, DOI DOI 10.1109/MCI.2007.913386	55	47	52	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-603X			IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	NOV	2010	5	4					13	18		10.1109/MCI.2010.938364		6	Computer Science, Artificial Intelligence	Computer Science	670TT	WOS:000283450900001		
J	Friston, KJ; Kiebel, S				Friston, Karl J.; Kiebel, Stefan			Cortical circuits for perceptual inference	NEURAL NETWORKS			English	Article						Generative models; Predictive coding; Hierarchical; Dynamic; Nonlinear; Circuits; Variational; Birdsong; Free-energy	VISUAL-CORTEX; PATTERN-RECOGNITION; MODEL; CONNECTIONS; DYNAMICS; HIERARCHY; NEOCORTEX; MONKEY; ARCHITECTURE; INTEGRATION	This paper assumes that cortical circuits have evolved to enable inference about the causes of sensory input received by the brain. This provides a principled specification of what neural circuits have to achieve. Here, we attempt to address how the brain makes inferences by casting inference as an optimisation problem. We look at how the ensuing recognition dynamics Could be Supported by directed connections and message-passing among neuronal populations, given our knowledge of intrinsic and extrinsic neuronal connections. We assume that the brain models the world as a dynamic system, which imposes causal structure on the sensorium. Perception is equated with the optimisation or inversion of this internal model, to explain sensory input. Given a model of how sensory data are generated, we use a generic variational approach to model inversion to furnish equations that prescribe recognition: i.e., the dynamics of neuronal activity that represents the causes of sensory input. Here, we focus on a model whose hierarchical and dynamical structure enables Simulated brains to recognise and predict sequences of sensory states. We first review these models and their inversion under a variational free-energy formulation. We then show that the brain has the necessary infrastructure to implement this inversion and present stimulations using synthetic birds that generate and recognise birdsongs. (C) 2009 Elsevier Ltd. All rights reserved.	[Friston, Karl J.] UCL, Wellcome Trust Ctr Neuroimaging, Inst Neurol, London WC1N 3BG, England	Friston, KJ (reprint author), UCL, Wellcome Trust Ctr Neuroimaging, Inst Neurol, Queen Sq, London WC1N 3BG, England.	k.friston@fil.ion.ucl.ac.uk	Friston, Karl/D-9230-2011; Kiebel, Stefan/B-1551-2009	Friston, Karl/0000-0001-7984-8909; 	Wellcome Trust	The Wellcome Trust funded this work. We would like to thank our colleagues for invaluable discussion about these ideas and Marcia Bennett for helping to prepare this manuscript.	Angelucci A, 2002, J NEUROSCI, V22, P8633; BALLARD DH, 1983, NATURE, V306, P21, DOI 10.1038/306021a0; Barlow HB, 1961, SENSORY COMMUNICATIO; Botvinick MM, 2007, PHILOS T R SOC B, V362, P1615, DOI 10.1098/rstb.2007.2056; Breakspear M, 2005, PHILOS T R SOC B, V360, P1051, DOI 10.1098/rstb.2005.1643; Byrne P, 2007, PSYCHOL REV, V114, P340, DOI 10.1037/0033-295X.114.2.340; Canolty RT, 2006, SCIENCE, V313, P1626, DOI 10.1126/science.1128115; Chait M, 2007, J NEUROSCI, V27, P5207, DOI 10.1523/JNEUROSCI.0318-07.2007; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Dean T., 2006, P 9 INT S ART INT MA; Deco G, 2003, EUR J NEUROSCI, V18, P2374, DOI 10.1046/j.1460-9568.2003.02956.x; DeFelipe J, 2002, J NEUROCYTOL, V31, P299, DOI 10.1023/A:1024130211265; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Feynman R. P., 1972, STAT MECH; FREEMAN WJ, 1987, BIOL CYBERN, V56, P139, DOI 10.1007/BF00317988; Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000211; Friston KJ, 1997, NEUROIMAGE, V5, P164, DOI 10.1006/nimg.1997.0259; Friston KJ, 2006, J PHYSIOL-PARIS, V100, P70, DOI 10.1016/j.jphysparis.2006.10.001; FRISTON KJ, 2009, PHILOS T R SOC B, V264, P1211; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; George D, 2005, IEEE IJCNN, P1812; HAKEN H, 1990, NEURAL NETWORKS, V3, P395, DOI 10.1016/0893-6080(90)90022-D; Hasson U, 2008, J NEUROSCI, V28, P2539, DOI 10.1523/JNEUROSCI.5487-07.2008; Helmholtz H., 1860, HDB PHYSL OPTIK, V3; Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168306; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hupe JM, 1998, NATURE, V394, P784; Jirsa VK, 1998, NEURAL COMPUT, V10, P2019, DOI 10.1162/089976698300016954; Kass RE, 1989, J AM STAT ASSOC, V407, P717, DOI [10.1080/01621459.1989.10478825, DOI 10.1080/01621459.1989.10478825)]; KAWATO M, 1993, NETWORK-COMP NEURAL, V4, P415, DOI 10.1088/0954-898X/4/4/001; Kiebel SJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000209; Kopell N, 2000, P NATL ACAD SCI USA, V97, P1867, DOI 10.1073/pnas.97.4.1867; Laje R, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.288102; Laje R, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.051921; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; MACKAY DJC, 1995, ELECTRON LETT, V31, P445; MAUNSELL JHR, 1983, J NEUROSCI, V3, P2563; McCrea DA, 2008, BRAIN RES REV, V57, P134, DOI 10.1016/j.brainresrev.2007.08.006; MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477; MURPHY PC, 1987, NATURE, V329, P727, DOI 10.1038/329727a0; Neal R, 1998, LEARNING GRAPHICAL M; Neisser U., 1967, COGNITIVE PSYCHOL; NORDBY H, 1994, PSYCHOPHYSIOLOGY, V31, P544, DOI 10.1111/j.1469-8986.1994.tb02347.x; Rabinovich M, 2008, SCIENCE, V321, P48, DOI 10.1126/science.1155564; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao RPN, 2006, BAYESIAN BRAIN PROBA, P239; ROCKLAND KS, 1979, BRAIN RES, V179, P3, DOI 10.1016/0006-8993(79)90485-2; ROSIER AM, 1993, J COMP NEUROL, V335, P369, DOI 10.1002/cne.903350307; Sherman SM, 1998, P NATL ACAD SCI USA, V95, P7121, DOI 10.1073/pnas.95.12.7121; Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008; Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009; Tsodyks M, 1999, HIPPOCAMPUS, V9, P481, DOI 10.1002/(SICI)1098-1063(1999)9:4<481::AID-HIPO14>3.0.CO;2-S; Yabe H, 1997, NEUROREPORT, V8, P1971, DOI 10.1097/00001756-199705260-00035; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085; ZEKI S, 1988, NATURE, V335, P311, DOI 10.1038/335311a0	55	45	45	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	OCT	2009	22	8			SI		1093	1104		10.1016/j.neunet.2009.07.023		12	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	511OO	WOS:000271175800006	19635656	
J	Collobert, R; Weston, J; Bottou, L; Karlen, M; Kavukcuoglu, K; Kuksa, P				Collobert, Ronan; Weston, Jason; Bottou, Leon; Karlen, Michael; Kavukcuoglu, Koray; Kuksa, Pavel			Natural Language Processing (Almost) from Scratch	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						natural language processing; neural networks	SPEECH RECOGNITION; SEMANTIC ROLES; MODELS; ALGORITHM; NETWORKS; ENTROPY; ENGLISH	We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.	[Collobert, Ronan; Weston, Jason; Bottou, Leon; Karlen, Michael; Kavukcuoglu, Koray; Kuksa, Pavel] NEC Labs Amer, Princeton, NJ 08540 USA; [Kavukcuoglu, Koray] NYU, New York, NY USA; [Kuksa, Pavel] Rutgers State Univ, New Brunswick, NJ 08903 USA		RONAN@COLLOBERT.COM; JWESTON@GOOGLE.COM; LEON@BOTTOU.ORG; MICHAEL.KARLEN@GMAIL.COM; KORAY@CS.NYU.EDU; PKUKSA@CS.RUTGERS.EDU			NEC	We acknowledge the persistent support of NEC for this research effort. We thank Yoshua Bengio, Samy Bengio, Eric Cosatto, Vincent Etter, Hans-Peter Graf, Ralph Grishman, and Vladimir Vapnik for their useful feedback and comments.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; Bell R. M., 2007, BELLKOR SOLUTION NET; Bengio Y, 2007, ADV NEURAL INFORM PR; Bengio Y., 2001, ADV NEURAL INFORM PR; Bengio Y., 2009, INT C MACH LEARN ICM; Bottou L., 1991; Bottou L., 1997, P489; Bottou L., 1991; Bottou L., 1998, ONLINE LEARNING NEUR; Bridle J. S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop; Brown P. F., 1992, Computational Linguistics, V18; Burges C. J. C., 2007, P193; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chapelle O., 2006, SEMISUPERVISED LEARN; Charniak E., 2000, P132; Chieu H. L., 2003, P160; CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113, DOI 10.1109/TIT.1956.1056813; Clemencon S, 2007, J MACH LEARN RES, V8, P2671; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; Cohn T., 2005; Collins M., 1999, THESIS U PENNSYLVANI; Collobert R., 2011; Collobert R., 2004, THESIS U PARIS 6; COVER TM, 1978, IEEE T INFORM THEORY, V24, P413, DOI 10.1109/TIT.1978.1055912; Florian R., 2003, P168; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; Gildea D., 2002, P239; Gimenez J., 2004; Haghighi A., 2005; Harris Z., 1968, MATH STRUCTURES LANG; Heckerman D, 2001, J MACH LEARN RES, V1, P49, DOI 10.1162/153244301753344614; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hollingshead K., 2005, P787; Huang F., 2009, P495; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; Joachims T., 1999, INT C MACH LEARN ICM; Klein D, 2002, ADV NEUR IN, V14, P35; Koo T., 2008, P595; Koomen P., 2005, CONLL 2004, P181; Kudo T., 2001, P1; Kudoh T., 2000, CONLL 2000 LLL 2000, P142; Lafferty J., 2001, INT C MACH LEARN ICM; Brown P. F., 1992, Computational Linguistics, V18; LeCun Y., 1998, Neural networks: tricks of the trade; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1985, P COGNITIVA, V85, P599; Lewis DD, 2004, J MACH LEARN RES, V5, P361; Liang P., 2005, THESIS MIT; Liang P., 2008, P592; Lin D., 2009, P1030; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; McCallum A., 2003, P188; McClosky D., 2006; McDonald R., 2005, P987; Miller S., 2004, P337; Miller S., 2000; Mnih A., 2007, ICML, P641; Musillo G., 2006; Neal R.M., 1996, LECT NOTES STAT, V118; Okanohara D., 2007, P73; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Pearl J, 1988, PROBABILISTIC REASON; Plaut D. C., 1987, Computer Speech and Language, V2, DOI 10.1016/0885-2308(87)90026-X; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Pradhan S., 2005, P217; Pradhan S., 2004; Punyakanok V., 2005, P1117; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ratinov L, 2009, CONLL 09, P147; Ratnaparkhi A., 1996, P133; Rosenfeld B., 2007, P600; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Schutze H., 1995, P141; Schwenk H, 2002, INT CONF ACOUST SPEE, P765; Sha F., 2003, C N AM CHAPT ASS COM, P134; SHANNON CE, 1951, AT&T TECH J, V30, P50; Shen H, 2005, LECT NOTES COMPUT SC, V3501, P389; Shen L., 2007; Smith N. A., 2005, P354; SUDDARTH SC, 1991, INT J MAN MACH STUD, V35, P291, DOI 10.1016/S0020-7373(05)80130-0; Sun X., 2008, P841; Sutton C, 2007, J MACH LEARN RES, V8, P693; Sutton C., 2005, P748; Sutton C., 2005, P225; Suzuki J., 2008, C N AM CHAPT ASS COM, P665; Teahan W., 1996, DAT COMPR C, P53; Toutanova K., 2003, C N AM CHAPT ASS COM; Turian J., 2010, P384; Ueffing N., 2007, P25; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Weston J., 2008, ICML 08, P1168	91	43	49	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	AUG	2011	12						2493	2537				45	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	862OJ	WOS:000298102200003		
J	Worden, K; Staszewski, WJ; Hensman, JJ				Worden, Keith; Staszewski, Wieslaw J.; Hensman, James J.			Natural computing for mechanical systems research: A tutorial overview	MECHANICAL SYSTEMS AND SIGNAL PROCESSING			English	Review						Natural computing; Soft computing; Machine learning; System; Identification; Condition monitoring; Structural health monitoring	AUTOASSOCIATIVE NEURAL NETWORKS; HEALTH MONITORING METHODOLOGY; PRINCIPAL COMPONENT ANALYSIS; PARTICLE SWARM OPTIMIZATION; FREQUENCY SIGNAL ANALYSIS; EXPLORATORY DATA-ANALYSIS; OUTPUT PARAMETRIC MODELS; RELEVANCE VECTOR MACHINE; HILBERT-HUANG TRANSFORM; HIDDEN MARKOV-MODELS	A great many computational algorithms developed over the past half-century have been motivated or suggested by biological systems or processes, the most well-known being the artificial neural networks. These algorithms are commonly grouped together under the terms soft or natural computing. A property shared by most natural computing algorithms is that they allow exploration of, or learning from, data. This property has proved extremely valuable in the solution of many diverse problems in science and engineering. The current paper is intended as a tutorial overview of the basic theory of some of the most common methods of natural computing as they are applied in the context of mechanical systems research. The application of some of the main algorithms is illustrated using case studies. The paper also attempts to give some indication as to which of the algorithms emerging now from the machine learning community are likely to be important for mechanical systems research in the future. (C) 2010 Elsevier Ltd. All rights reserved.	[Worden, Keith; Staszewski, Wieslaw J.; Hensman, James J.] Univ Sheffield, Dept Mech Engn, Dynam Res Grp, Sheffield S1 3JD, S Yorkshire, England	Worden, K (reprint author), Univ Sheffield, Dept Mech Engn, Dynam Res Grp, Mappin St, Sheffield S1 3JD, S Yorkshire, England.	k.worden@sheffield.ac.uk			UK Engineering and Physical Sciences Research Council (EPSRC); QinetiQ	The authors would like to thank all of their colleagues over the years who have helped them learn of and apply the methods detailed here. They would specifically like to thank Dr. Graeme Manson of the University of Sheffield, who collaborated on much of the SHM work, including that which led to the case study of the Gnat Aircraft in Section 4.6, and much of the optimisation work detailed in Section 7. The case study in Section 4.9 is the result of a joint project with Dr. Gareth Pierce of the University of Stratclyde and Professor Abderrezak Bezazi of the University of Guelma, Algeria, for which the authors are grateful. The authors would also like to thank Dr. Cecilia Surace of the Politecnico di Torino for collaborating on the work which led to the case study in Section 4.10. Funding for the work has been secured from various agencies over the years, but notably from the UK Engineering and Physical Sciences Research Council (EPSRC) and QinetiQ and again the authors are very grateful. Finally, the authors would like to thank Mr. Andrew Spencer and Dr. Tony Dodd (both of the University of Sheffield) for their careful reading of the manuscript and for their many useful comments on the nature of computation, biological and artificial.	Abeles M, 1991, CORTICONICS NEURAL C; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Addison P S, 2002, ILLUSTRATED WAVELET; ANDERSON G, 1992, SENSORS          SEP, P15; Antoni J, 2006, MECH SYST SIGNAL PR, V20, P308, DOI 10.1016/j.ymssp.2004.09.002; ATHANS M, 1980, P 19 IEEE C DEC CONT, P12; Auger F., 1996, TIME FREQUENCY TOOLB; Austin J., 1998, Proceedings of EuroFusio 98. International Data Fusion Conference; AUSTIN J, 2004, E SCI ALL HANDS M NO; Banzhaf W, 1999, GENETIC PROGRAMMING; Barnett V., 1994, OUTLIERS STAT DATA, V3rd; Bar-Shalom Y., 1990, MULTITARGET MULTISEN; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Becker W., 2008, P 23 INT C NOIS VIBR; BEDROSIA.E, 1971, PR INST ELECTR ELECT, V59, P1688, DOI 10.1109/PROC.1971.8525; BEDWORTH M, 1999, OMNIBUS MODEL NEW MO; BEDWORTH M, 1994, DRACISSE16518M94AS03; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bennett K. P., 1999, ADV KERNEL METHODS S; Bilchev G., 1996, P ACEDC, P145; BILCHEV G, 1995, EV COMP AISB WORKSH; BILLINGS SA, 1991, MECH SYST SIGNAL PR, V5, P233, DOI 10.1016/0888-3270(91)90045-7; Billingsley P., 1995, PROBABILITY MEASURE; Bishop C. M., 2007, PATTERN RECOGNITION; BISHOP CM, 2003, ADV NEURAL INFORM PR, P793; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; BISHOP CM, 1999, ICANN 99, P1; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blackman S. S., 1986, MULTIPLE TARGET TRAC; BOASHASH B, 1991, ADV SPECTRUM ANAL AR, V1; BOSSE E, 1999, P EUROFUSION99 INT C, P85; Boualem Boashash B., 1992, TIME FREQUENCY SIGNA; Box G. E. P., 2008, TIME SERIES ANAL FOR, V4th; BOYD J, 1987, MAXWELL AFB LECT; Braun S., 1986, MECH SIGNATURE ANAL; Broomhead D. S., 1988, Complex Systems, V2; Brown M., 1994, NEUROFUZZY ADAPTIVE; BRYSON A, 1963, AIAA J, V1, P25; Buckley J. J., 1994, FUZZY SETS NEURAL NE; Bunks C, 2000, MECH SYST SIGNAL PR, V14, P597, DOI 10.1006/mssp.2000.1309; Burges C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Cajal SR, 1911, HISTOLOGIE SYSTEME N, P196; Carpenter G. A., 2003, HDB BRAIN THEORY NEU, P87; Cempel C., 1991, VIBROACOUSTIC CONDIT; Chan KCC, 1999, P SOC PHOTO-OPT INS, V3719, P279, DOI 10.1117/12.341349; CHEN S, 1990, INT J CONTROL, V52, P1327, DOI 10.1080/00207179008953599; CHEN S, 1992, INT J CONTROL, V55, P1051, DOI 10.1080/00207179208934272; Cheng JS, 2007, MECH SYST SIGNAL PR, V21, P1197, DOI 10.1016/j.ymssp.2005.09.005; Cherkassky V., 1998, LEARNING DATA CONCEP; Chipperfield A., GENETIC ALGORITHM TO; Chiswell I., 2007, MATH LOGIC; CHOI HI, 1989, IEEE T ACOUST SPEECH, V37, P862, DOI 10.1109/ASSP.1989.28057; Chui C. K., 1997, WAVELETS MATH TOOL S; Chui C. K., 1992, INTRO WAVELETS, P1; Chui C.K., 1992, WAVELET ANAL ITS APP, V2; CLAASEN TACM, 1980, PHILIPS J RES, V35, P217; CLAASEN TACM, 1980, PHILIPS J RES, V35, P276; Clerc M., 2006, PARTICLE SWARM OPTIM; CLERC M, 2004, NEW OPTIMISATION TEC; Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI [10.1109/TEVC.2004.826067, 10.1109/tevc.2004.826067]; COHEN L, 1989, P IEEE, V77, P941, DOI 10.1109/5.30749; COIFMAN RR, 1989, P INT C WAV MARS MAS; COLEMAN T, 1999, OPTIMISATION TOOLBOX; Coley D. A., 1999, INTRO GENETIC ALGORI; CORANA A, 1987, ACM T MATH SOFTWARE, V13, P262, DOI 10.1145/29380.29864; Cristianini N., 2000, INTRO SUPPORT VECTOR; Culshaw Brain, 1996, SMART STRUCTURES MAT; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; *DAT FUS DEV STRAT, 1991, FUNCT DESCR DAT FUS; Daubechies I, 1992, 10 LECT WAVELETS; Davalo Eric, 1991, NEURAL NETWORKS; De Castro L. N., 2002, ARTIFICIAL IMMUNE SY; DECASTRO LN, 1999, 0199 TRDCA UN; Deemter van Kees, 2010, NOT EXACTLY PRAISE V; Demuth H., 2010, NEURAL NETWORK TOOLB; DEWERRA D, 1989, OR SPEKTRUM, V11, P131; DOEBLING SW, 1996, LA13070 LOS AL LAB; DONG Y, 2005, KEY ENG MATER, V294, P71; Dong YG, 2006, MECH SYST SIGNAL PR, V20, P1461, DOI 10.1016/j.ymssp.2004.12.006; DONOHO D, 1994, CR HEBD ACAD SCI, V1319, P1317; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Dorigo M, 2004, ANT COLONY OPTIMIZATION, pIX; Dorigo M., 1991, 91016 POL MIL; DORIGO M, 1996, IEEE T SYST MAN CY B, V20, P1; Dron JP, 2004, J SOUND VIB, V270, P61, DOI 10.1016/S0022-460X(03)00483-8; Dubois D., 1988, POSSIBILITY THEORY A; Eberhart R., 2001, SWARM INTELLIGENCE; Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81; EBERHART RC, 1995, P 6 INT S MICROMACHI, P43; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; ESTEBAN J, 1999, P EUROFUSION99 INT C, P187; Ewins D. J., 2000, MODAL TESTING THEORY, V2nd; Farrar CR, 2007, PHILOS T R SOC A, V365, P303, DOI 10.1098/rsta.2006.1928; FAUL A, 2001, P ICANN 01, P95; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Feldman M, 2009, MECH SYST SIGNAL PR, V23, P2059, DOI 10.1016/j.ymssp.2009.04.002; FLANDRIN P, 1989, WAVELETS TIME FREQUE; Fletcher R., 2000, PRACTICAL METHODS OP; Fonseca CM, 1998, IEEE T SYST MAN CY A, V28, P26, DOI 10.1109/3468.650319; Fonseca CM, 1998, IEEE T SYST MAN CY A, V28, P38, DOI 10.1109/3468.650320; Forbes N., 2004, IMITATION LIFE BIOL; Forrester B.D., 1990, P 44 M MECH FAIL PRE, P225; FORRESTER BD, 1992, TIME FREQUENCY SIGNA; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; Friess T., 1998, MACHINE LEARNING; Friswell MI, 1995, FINITE ELEMENT MODEL; GATEPAILLE S, 1999, P EUROFUSION99 INT C, P97; Ge M, 2004, MECH SYST SIGNAL PR, V18, P391, DOI 10.1016/S0888-3270(03)00076-1; Gelman A, 2004, BAYESIAN DATA ANAL, V2nd; Ghandi M. V., 1992, SMART MAT STRUCTURES; GIROLAMI M, 2009, ARXIV09071100; Glover F., 1989, ORSA Journal on Computing, V1; Glover F., 1990, J COMPUTING, V2, P4; Goebel K, 1999, P SOC PHOTO-OPT INS, V3719, P52, DOI 10.1117/12.341370; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GOSS S, 1989, NATURWISSENSCHAFTEN, V76, P579, DOI 10.1007/BF00462870; Gros X E, 1997, NDT DATA FUSION; Guyon I., 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hamming R. W., 1989, DIGITAL FILTERS; HAMMOND JK, 1997, MECH SYSTEMS SIGNAL, V11; Harris C. J., 1998, Proceedings of the International Conference on Multisource-Multisensor Information Fusion. FUSION '98; Harris J. W., 1998, HDB MATH COMPUTATION; Haykin S., 1994, NEURAL NETWORKS COMP; Hayton P, 2007, PHILOS T R SOC A, V365, P493, DOI 10.1098/rsta.2006.1931; Hebb DO, 1949, ORG BEHAV; HENRY MP, 1993, SELF VALIDATING SENS; HENRY MP, 1994, VALIDATING DATA SMAR; HENRY MP, 1995, SELF VALIDATING CORI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Holdobler B., 1990, ANTS; HOLLAND JH, 1992, ADAPTATION NATURAL A, P290; HOPFIELD JJ, 1984, P NATL ACAD SCI USA, V52, P2554; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; Hsu C. W., PRACTICAL GUIDE SUPP; Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903; Huang N.E., 2005, HILBERTHUANG TRANSFO; Hubbard B. S., 1998, WORLD ACCORDING WAVE; Huber P. J., 1964, ANN MATH STAT, V35; HUNDAL MS, 1986, SHOCK VIBRATION DIGE, V8, P3; ISHIBUCHI H, 1992, P 2 INT C FUZZ LOG N, P337; Jang JSR, 1993, IEEE T SYST MAN CYB, V23, P665; JEROCHE H, 1999, ADAPTRONICS SMART ST; JING Z, 1998, P INT C MULT MULT IN, P373; Joachims T., 1999, ADV KERNEL METHODS S; Jordan M. I., 1998, LEARNING GRAPHICAL M; Karlsson B., 1998, Proceedings of the International Conference on Multisource-Multisensor Information Fusion. FUSION '98; Kennedy J, 1995, P IEEE INT C NEUR NE, P4; Kerschen G, 2008, J VIB CONTROL, V14, P77, DOI 10.1177/1077546307079381; Kim J. O., 1978, FACTOR ANAL STAT MET; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KLEIN LA, 1999, SENSOR DATA FUSIO TT, V14; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 2000, SELF ORG MAPS; Korpisaari P., 1998, Proceedings of the International Conference on Multisource-Multisensor Information Fusion. FUSION '98; Kosko B., 1992, NEURAL NETWORKS FUZZ; Kosko Bart, 1994, FUZZY THINKING NEW S; Koza J. R., 1993, GENETIC PROGRAMMING; KOZA JR, 1994, GENETIC PROGRAMMING, pR2; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; KRAMER MA, 1992, COMPUT CHEM ENG, V16, P313, DOI 10.1016/0098-1354(92)80051-A; Krige D.G., 1951, THESIS U WITWATERSRA; Kruse R., 1994, FDN FUZZY SYSTEMS; Lafferty J., 2001, CONDITIONAL RANDOM F, P282; Lawrence ND, 2004, ADV NEUR IN, V16, P329; LAWRENCE ND, 2006, P 23 INT C MACH LEAR, P520; LeCun Y., 1986, DISORDERED SYSTEMS B, P233; Lei Y, 2007, MECH SYST SIGNAL PR, V21, P2280, DOI 10.1016/j.ymssp.2006.11.003; LEMMON MD, 1999, IEEE T AUTOMATIC CON, V44; LEONTARITIS IJ, 1985, INT J CONTROL, V41, P329, DOI 10.1080/0020718508961130; LEONTARITIS IJ, 1985, INT J CONTROL, V41, P303, DOI 10.1080/0020718508961129; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lew TL, 2006, MECH SYST SIGNAL PR, V20, P1819, DOI 10.1016/j.ymssp.2005.12.003; LEWIS FL, 1998, INT J CONTROL, V70; Liang B, 2004, LECT NOTES COMPUT SC, V3177, P430; LIANG Z, 2007, MECH SYSTEMS SIGNAL, V21, P1273; Liang Zhang, 2005, Mechanical Systems and Signal Processing, V19, DOI 10.1016/j.ymssp.2004.03.002; Ljung L, 1998, SYSTEM IDENTIFICATIO; Lobo V. J., 1998, Proceedings of the International Conference on Multisource-Multisensor Information Fusion. FUSION '98; Lou XS, 2004, MECH SYST SIGNAL PR, V18, P1077, DOI 10.1016/S0888-3270(03)00077-3; Lowe D, 1997, ADV NEUR IN, V9, P543; Lowe D, 1999, NEURAL COMPUT APPL, V8, P77, DOI 10.1007/s005210050009; Lowe D, 1996, NEURAL COMPUT APPL, V4, P83, DOI 10.1007/BF01413744; Luenberger DG, 2008, INT SER OPER RES MAN, V116, P1; Luo F.-L., 1998, APPL NEURAL NETWORKS; LUO MA, 1992, DATA FUSION ROBOTICS; MacKay D., 2003, INFORM THEORY INFERE; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MacKay DJ, 1997, LECT NOTES TUTORIAL; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; MAHFOUD SW, 1995, PARALLEL COMPUT, V21, P1, DOI 10.1016/0167-8191(94)00071-H; Malinowski G., 2001, BLACKWELL GUIDE PHIL; Mallat S., 1998, WAVELET TOUR SIGNAL; Manson G, 2003, J SOUND VIB, V259, P345, DOI 10.1006/jsvi.2002.5167; Manson G., 2003, J SOUND VIBRATION, V259, P356; Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019; Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI [10.1016/j.sigpro.2003.07.018, 10.1016/j.sigpro.2003.018]; MASRI SF, 1993, J APPL MECH-T ASME, V60, P123, DOI 10.1115/1.2900734; Masri SF, 1996, J ENG MECH-ASCE, V122, P350, DOI 10.1061/(ASCE)0733-9399(1996)122:4(350); Matheron G., 1963, ECON GEOL, V58, P1246, DOI [DOI 10.2113/GSECONGEO.58.8.1246, 10.2113/gsecongeo.58.8.1246]; Matheron G., 1973, Advances in Applied Probability, V5, DOI 10.2307/1425829; *MATHWORKS INC, 2007, US SIM VERS 6 6; *MATHWORKS INC, MATLAB 6 5 VERS WAV; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; MCFADDEN PD, 1990, 18590 OUEL DEP ENG; *MERC, 1909, PHILOS T R SOC A, V209, P415; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Meyer Y, 1993, WAVELETS ALGORITHMS; Michalewicz Z., 2004, SOLVE IT MODERN HEUR; Michalewicz Z., 1996, GENETIC ALGORITHMS D; Middleton D., 1960, INTRO STAT COMMUNICA; Miller A.J., 1990, SUBSET SELECTION REG; Minsky M, 1988, PERCEPTRONS; Mitchell M., 1998, INTRO GENETIC ALGORI; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Mujica L, 2009, P SPIE, V7286; Nabney I., 2001, NETLAB ALGORITHMS PA; Narendra K. S., 1990, IEEE T NEURAL NETWOR, V1, P1; Nauck D., 1997, FDN NEUROFUZZY SYSTE; Neal R. M., 1996, BAYESIAN LEARNING NE; Neal R.M., 1997, PHYSICS9701026 ARXIV; NEWLAND DE, 1994, P ROY SOC LOND A MAT, V444, P605, DOI 10.1098/rspa.1994.0042; Oakley JE, 2004, J ROY STAT SOC B, V66, P751, DOI 10.1111/j.1467-9868.2004.05304.x; Oh CK, 2009, SMART MATER STRUCT, V18, DOI 10.1088/0964-1726/18/12/125022; Oh CK, 2009, J SOUND VIB, V325, P224, DOI 10.1016/j.jsv.2009.03.014; O'Hagan A, 2004, RELIAB ENG SYST SAFE, V85, P239, DOI 10.1016/j.ress.2004.03.014; OHAGAN A, 1978, J ROYAL STAT SOC B, V20, P1; Overton G, 2004, STRAIN, V40, P59, DOI 10.1111/j.1475-1305.2004.00123.x; Pachaud C, 1997, MECH SYST SIGNAL PR, V11, P903, DOI 10.1006/mssp.1997.0115; Papadopoulos G, 2001, IEEE T NEURAL NETWOR, V12, P1278, DOI 10.1109/72.963764; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; PHILIPS CL, 1988, FEEDBACK CONTROL SYS; PLATT JC, 1914, MSRTR9814; Poli R., 2008, FIELD GUIDE GENETIC; Pomerleau D.A., 1993, ADV NEURAL INFORM PR, V5; POWELL MJD, 1985, 1985NA12 DAMPT U CAM; Pratt W. K., 1991, DIGITAL IMAGE PROCES; Press W.H., 1992, NUMERICAL RECIPES C; PRICE KV, 2005, NAT COMP SER, pR7; Priestley M.B., 1988, NONLINEAR NONSTATION; Qian S., 1996, JOINT TIME FREQUENCY; Rabbani M, 1991, DIGITAL IMAGE COMPRE; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; REQUENA I, 1992, P 2 INT C FUZZ LOG N, P793; Ribo M., 1998, Proceedings of EuroFusio 98. International Data Fusion Conference; Roberts SJ, 2002, IEEE T SIGNAL PROCES, V50, P2245, DOI 10.1109/TSP.2002.801921; ROGOVA GL, 1999, P EUROFUSION 99 INT, P9; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Ross T.J., 1995, FUZZY LOGIC ENG APPL; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Rumelhart D.E., 1988, PARALLEL DISTRIBUTED; Ruotolo R, 1997, J SOUND VIB, V206, P567, DOI 10.1006/jsvi.1997.1109; RUOTOLO R, 1996, P ISMA21 LEUV BELG, P1005; Rytter A, 1993, THESIS U AALBORG DEN; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Sandell N. R., 1980, Proceedings of the 19th IEEE Conference on Decision & Control Including the Symposium on Adaptive Processes; SARTOR P, 2010, P 5 EUR WORKSH STRUC; Schalkoff R.J., 1992, PATTERN RECOGNITION; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 1999, ADV KERNEL METHODS S; Scholkopf B, 2000, ADV NEUR IN, V12, P582; Shannon CE, 1959, MATH THEORY COMMUNIC; SHARKEY AJC, 1996, CONNECT SCI, V8, P314; Sharma S., 1995, APPL MULTIVARIATE TE; Shi V., 1998, EVOLUTIONARY PROGRAM, P591; SIDE S, 1997, P INT WORKSH DAM ASS, P135; Siegelmann HT, 1997, IEEE T SYST MAN CY B, V27, P208, DOI 10.1109/3477.558801; Skolnik M. I., 2001, INTRO RADAR SYSTEMS; Smith J. F.  III, 1998, Proceedings of the International Conference on Multisource-Multisensor Information Fusion. FUSION '98; Soderstrom T., 1994, SYSTEM IDENTIFICATIO; Sohn H, 2001, SMART MATER STRUCT, V10, P446, DOI 10.1088/0964-1726/10/3/304; Sohn H, 2007, PHILOS T R SOC A, V365, P539, DOI 10.1098/rsta.2006.1935; SOHN H, 2004, LA13976MS19962001 LO; STASZEWSKI WJ, 1997, P 2 IEE IEEE INT C G; STASZEWSKI WJ, 1994, THESIS U MANCHESTER; STASZEWSKI WJ, 1998, P 4 EUR C SMART MAT; Staszewski WJ, 1998, J SOUND VIB, V211, P735, DOI 10.1006/jsvi.1997.1380; STASZEWSKI WJ, 1997, P INT C ENG APPL NEU; STASZEWSKI WJ, 1994, MECH SYSTEMS SIGNAL, V8, P298; STASZEWSKI WJ, 1993, SAFETY EVALUATION BA; Stein ML, 1999, INTERPOLATION SPATIA; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Strang G, 1986, INTRO APPL MATH; Strang G., 1996, WAVELETS FILTER BANK; Stubberud SC, 1999, P SOC PHOTO-OPT INS, V3719, P242, DOI 10.1117/12.341346; Surace C, 2010, MECH SYST SIGNAL PR, V24, P1114, DOI 10.1016/j.ymssp.2009.09.009; SURACE C, 1997, P 3 INT C MOD PRACT, P89; Suykens Johan A. K, 2002, LEAST SQUARES SUPPOR; SWELDENS W, 1995, WAVELETS THEIR APPL; Takagi H., 1991, International Journal of Approximate Reasoning, V5, DOI 10.1016/0888-613X(91)90008-A; Takagi H., 1985, IEEE T SYST MAN CYB, V5, P116; TAKAGI H, 1983, P IFAC S FUZZ INF KN, P55; Takagi H., 1992, Second International Workshop on Industrial Fuzzy Control and Intelligent Systems; TARASSENKO L, 1994, IEE P-VIS IMAGE SIGN, V141, P210; Tarassenko L., 1995, P 4 IEE INT C ART NE, P442; Tarassenko L., 1998, GUIDE NEURAL COMPUTI; Taylor O, 1998, P SOC PHOTO-OPT INS, V3376, P210, DOI 10.1117/12.303681; Taylor O., 1998, Proceedings of EuroFusio 98. International Data Fusion Conference; Taylor O., 1998, Proceedings of the International Conference on Multisource-Multisensor Information Fusion. FUSION '98; The MathWorks Inc, 2010, FUZZ LOG TOOLB 2 US; The MathWorks Inc, 1992, MATLAB REF GUID; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TIPPING ME, 2001, ADV NEURAL INFORM PR; Tipping ME, 2000, ADV NEUR IN, V12, P652; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TOKUNAGA M, 1992, P 2 INT C FUZZ LOG N, P123; Van Laarhoven P. J., 1987, SIMULATED ANNEALING; VANDIJK GM, 1992, P NOND TEST 1992 C; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik V. N., 1998, STAT LEARNING THEORY; Vose M. D., 1999, SIMPLE GENETIC ALGOR; WALTZ E., 1990, MULTISENSOR DATA FUS; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Wang WJ, 1996, J SOUND VIB, V192, P927, DOI 10.1006/jsvi.1996.0226; WANG WJ, 1993, MECH SYST SIGNAL PR, V7, P193, DOI 10.1006/mssp.1993.1008; WANG WJ, 1993, THESIS OXFORD U; WANG WJ, 1995, MECH SYST SIGNAL PR, V9, P497, DOI 10.1006/mssp.1995.0038; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Werbos P., 1974, THESIS HARVARD U; WHITE FE, 1990, TECHN P JOINT SERV D, P469; Wickerhauser M. V., 1992, WAVELETS TUTORIAL TH; Widrow B., 1960, IRE Wescon Convention Record, V4; WONG CS, 1998, INT C NOIS VIBR ENG, V23, P1417; Worden K., 2003, SMART TECHNOLOGIES; Worden K, 1997, J SOUND VIB, V201, P85, DOI 10.1006/jsvi.1996.0747; Worden K, 2000, STRAIN, V36, P61, DOI 10.1111/j.1475-1305.2000.tb01175.x; Worden K, 2001, ENG STRUCT, V23, P885, DOI 10.1016/S0141-0296(00)00118-8; Worden K, 2000, INVERSE PROBL ENG, V8, P25, DOI 10.1080/174159700088027717; Worden K., 2000, NONLINEARITY STRUCTU; Worden K, 2009, MECH SYST SIGNAL PR, V23, P1792, DOI 10.1016/j.ymssp.2008.11.003; Worden K, 2003, J SOUND VIB, V259, P323, DOI 10.1006/jsvi.2002.5168; Worden K, 2000, J SOUND VIB, V229, P647, DOI 10.1006/jsvi.1999.2514; Wu Z, 2005, ENSEMBLE EMPIRICAL M; Yamakawa T., 1992, P 2 INT C FUZZ LOG N, P477; YIP PCP, 1995, IEEE T NEURAL NETWOR, P290; Yuan SF, 2007, MECH SYST SIGNAL PR, V21, P1787, DOI 10.1016/j.ymssp.2006.07.008; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zadeh L.A., 1978, FUZZY SETS SYSTEMS, V1, P1, DOI DOI 10.1016/0165-0114(78)90029-5; ZHANG J, 2008, P 26 INT MOD AN C IM; Zhang Z, 2003, COMPOS SCI TECHNOL, V63, P2029, DOI 10.1016/S0266-3538(03)00106-4; ZHENG YL, 2003, INT C MACH LEARN CYB, P3; Ziemer R. E., 1976, PRINCIPLES COMMUNICA	350	43	46	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0888-3270			MECH SYST SIGNAL PR	Mech. Syst. Signal Proc.	JAN	2011	25	1					4	111		10.1016/j.ymssp.2010.07.013		108	Engineering, Mechanical	Engineering	701NL	WOS:000285824500002		
J	Le Roux, N; Bengio, Y				Le Roux, Nicolas; Bengio, Yoshua			Representational power of restricted Boltzmann machines and deep belief networks	NEURAL COMPUTATION			English	Article								Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton, Osindero, and Teh (2006) along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM), used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modeling power, while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs Within DBNs.	[Le Roux, Nicolas; Bengio, Yoshua] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Le Roux, N (reprint author), Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.	lerouxni@iro.umontreal.ca; bengioy@iro.umontreal.ca					ACKLEY D, 1985, COGNITIVE SCI, V9, P144; AJTAI M, 1983, ANN PURE APPL LOGIC, V24, P1, DOI 10.1016/0168-0072(83)90038-6; ALLEN HE, 1996, SETAC NEWS, V16, P18; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P115; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; HASTAD JOHAN, 1987, COMPUTATIONAL LIMITA; Hinton G., 1999, P 9 INT C ART NEUR N, V1, P1; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Ranzato M., 2007, ADV NEURAL INFORM PR, V19; SALAKHUTDINOV R, 2007, P AISTATS2007 SAN JU; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Welling M., 2005, ADV NEURAL INFORM PR, V17	18	43	43	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JUN	2008	20	6					1631	1649		10.1162/neco.2008.04-07-510		19	Computer Science, Artificial Intelligence	Computer Science	296BH	WOS:000255518000011	18254699	
J	Hinton, GE		Cisek, P; Drew, T; Kalaska, JF		Hinton, Geoffrey E.			To recognize shapes, first learn to generate images	COMPUTATIONAL NEUROSCIENCE: THEORETICAL INSIGHTS INTO BRAIN FUNCTION	Progress in Brain Research		English	Review; Book Chapter						learning algorithms; multilayer neural networks; unsupervised learning; Boltzmann machines; wake-sleep algorithm; contrastive divergence; feature discovery; shape recognition; generative models	NEURAL-NETWORKS; ALGORITHM; SLEEP	The uniformity of the cortical architecture and the ability of functions to move to different areas of cortex following early damage strongly suggest that there is a single basic learning algorithm for extracting underlying structure from richly structured, high-dimensional sensory data. There have been many attempts to design such an algorithm, but until recently they all suffered from serious computational weaknesses. This chapter describes several of the proposed algorithms and shows how they can be combined to produce hybrid methods that work efficiently in networks with many layers and millions of adaptive connections.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Hinton, GE (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	hinton@cs.toronto.edu					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bryson A., 1975, APPL OPTIMAL CONTROL; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; JABRI M, 1992, IEEE T NEURAL NETWOR, V3, P154, DOI 10.1109/72.105429; KARNI A, 1994, SCIENCE, V265, P679, DOI 10.1126/science.8036518; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lecun Y., 2004, P CVPR 04; LeCun Y., 1985, P COGNITIVA, V85, P599; MAZZONI P, 1991, P NATL ACAD SCI USA, V88, P4433, DOI 10.1073/pnas.88.10.4433; MERZENICH MM, 1983, NEUROSCIENCE, V8, P1; Minsky M., 1969, PERCEPTRONS INTRO CO; Parker D.B, 1985, TR47 MIT CTR COMP RE; RANZATO M, 2007, ADV NEURAL INFORM PR, V17; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SELFRIDGE OG, 1958, MECHANISATION THOUGH; Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X; Sharma J, 2000, NATURE, V404, P841, DOI 10.1038/35009043; Simard P. Y., 2003, INT C DOC AN REC ICD, P958; Vapnik V., 2000, NATURE STAT LEARNING; Werbos P., 1974, THESIS HARVARD U	25	36	37	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0079-6123		978-0-444-52823-0	PROG BRAIN RES	Prog. Brain Res.		2007	165						535	547		10.1016/S0079-6123(06)65034-6		13	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	BQC07	WOS:000280608900035	17925269	
J	Buesing, L; Bill, J; Nessler, B; Maass, W				Buesing, Lars; Bill, Johannes; Nessler, Bernhard; Maass, Wolfgang			Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons	PLOS COMPUTATIONAL BIOLOGY			English	Article							LEARNING ALGORITHM; BAYESIAN-INFERENCE; BINOCULAR-RIVALRY; VISUAL-CORTEX; REPRESENTATIONS; VARIABILITY; INTEGRATION; POPULATION; PERCEPTION; REVEALS	The organization of computations in networks of spiking neurons in the brain is still largely unknown, in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations, probabilistic inference by sampling, which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems, such as Gibbs sampling, are inconsistent with the dynamics of spiking neurons, we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution, both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.	[Buesing, Lars; Bill, Johannes; Nessler, Bernhard; Maass, Wolfgang] Graz Univ Technol, Inst Theoret Comp Sci, A-8010 Graz, Austria	Buesing, L (reprint author), UCL, Gatsby Computat Neurosci Unit, London, England.	lars@gatsby.ucl.ac.uk			European Union [FP7-237955, FP7-269921, FP7-216593, FP7-506778, FP7-243914]	This paper was written under partial support by the European Union project #FP7-237955 (FACETS-ITN), project #FP7-269921 (BrainScaleS), project #FP7-216593 (SECO), project #FP7-506778 (PASCAL2) and project #FP7-243914 (BRAIN-I-NETS). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Antic SD, 2010, J NEUROSCI RES, V88, P2991, DOI 10.1002/jnr.22444; Azouz R, 1999, J NEUROSCI, V19, P2209; Bartels A, 2010, J VISION, V10, DOI 10.1167/10.12.3; Berkes P, 2011, SCIENCE, V331, P83, DOI 10.1126/science.1195870; Binzegger T, 2009, NEURAL NETWORKS, V22, P1071, DOI 10.1016/j.neunet.2009.07.011; Binzegger T, 2004, J NEUROSCI, V24, P8441, DOI 10.1523/JNEUROSCI.1400-04.2004; Bishop CM, 2006, PATTERN RECOGNITION; Blake R., 2005, BINOCULAR RIVALRY; Blake R, 2002, NAT REV NEUROSCI, V3, P13, DOI 10.1038/nrn701; Brascamp JW, 2006, J VISION, V6, P1244, DOI 10.1167/6.11.8; BRUEDERLE D, 2010, P IEEE INT S CIRC SY; Cannon RC, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000886; Churchland MM, 2010, NAT NEUROSCI, V13, P369, DOI 10.1038/nn.2501; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; DENISON S, 2009, P 32 ANN C COGN SCI; Doya K., 2007, BAYESIAN BRAIN PROBA; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Fiser J, 2004, NATURE, V431, P573, DOI 10.1038/nature02907; FLIGHT M, 2010, NAT REV NEUROSCI, V9, P736; Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201; Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z; Gardiner C.W., 2004, HDB STOCHASTIC METHO, V3rd; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GERSHMAN SJ, 2009, P 22 C ADV NEUR INF; Gerstner W., 2002, SPIKING NEURON MODEL; Gold JI, 2007, ANNU REV NEUROSCI, V30, P535, DOI 10.1146/annurev.neuro.29.051605.113038; Gopnik A, 2007, DEVELOPMENTAL SCI, V10, P281, DOI 10.1111/j.1467-7687.2007.00584.x; Griffiths TL, 2006, PSYCHOL SCI, V17, P767, DOI 10.1111/j.1467-9280.2006.01780.x; GRIFFITHS TL, 2008, HDB COMPUTATIONAL CO, P59; Grimmett G. R., 2001, PROBABILITY RANDOM P, V3rd; HINTON G, 2000, P 13 C ADV NEUR INF; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; Hoyer P, 2003, P 16 C ADV NEUR INF; Kenet T, 2003, NATURE, V425, P954, DOI 10.1038/nature02078; Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Leopold DA, 2002, NAT NEUROSCI, V5, P605, DOI 10.1038/nn851; LITVAK S, 2009, NEURAL COMPUT, V21, P1; Merolla PA, 2007, IEEE T CIRCUITS-I, V54, P301, DOI 10.1109/TCSI.2006.887474; NESSLER B, 2009, P 21 C ADV NEUR INF; OAKSFORD M, 2007, BAYESIAN RATIONALLY; Pearl J, 1988, PROBABILISTIC REASON; Pillow JW, 2008, NATURE, V454, P995, DOI 10.1038/nature07140; Pospischil M, 2009, J PHYSIOLOGY-PARIS, V103, P98, DOI 10.1016/j.jphysparis.2009.05.010; *PYTH, 2011, PYTH LANG REF; Rao RPN, 2007, BAYESIAN BRAIN PROBA, P239; Rao RPN, 2002, PROBABILISTIC MODELS; RINGACH DL, 2009, CURR OPIN NEUROBIOL, V19, P1; Rolls ET, 2010, NOISY BRAIN STOCHAST; Sadaghiani Sepideh, 2010, Front Syst Neurosci, V4, P20, DOI 10.3389/fnsys.2010.00020; Sahani M, 2003, NEURAL COMPUT, V15, P2255, DOI 10.1162/089976603322362356; Shinomoto S, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000433; SOFTKY WR, 1993, J NEUROSCI, V13, P334; Steimer A, 2009, NEURAL COMPUT, V21, P2502, DOI 10.1162/neco.2009.08-08-837; Sundareswara R., 2008, J VIS, V8, P1, DOI DOI 10.1167/8.5.12; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; TOUSSAINT M, 2010, STUDIES COMPUTATIONA, P227; TOUSSAINT M, 2009, KUNSTLICHE INTELLIGE, V3, P23; Vul E, 2008, PSYCHOL SCI, V19, P645, DOI 10.1111/j.1467-9280.2008.02136.x; Yang T, 2007, NATURE, V447, P1075, DOI 10.1038/nature05852; ZEMEL R, 2005, P 17 C ADV NEUR INF	68	33	34	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X			PLOS COMPUT BIOL	PLoS Comput. Biol.	NOV	2011	7	11							e1002211	10.1371/journal.pcbi.1002211		22	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	851JG	WOS:000297263700002	22096452	
J	Hadsell, R; Sermanet, P; Ben, J; Erkan, A; Scoffier, M; Kavukcuoglu, K; Muller, U; Lecun, Y				Hadsell, Raia; Sermanet, Pierre; Ben, Jan; Erkan, Ayse; Scoffier, Marco; Kavukcuoglu, Koray; Muller, Urs; LeCun, Yann			Learning Long-Range Vision for Autonomous Off-Road Driving	JOURNAL OF FIELD ROBOTICS			English	Article							NAVIGATION; ROBOT	Most vision-based approaches to mobile robotics suffer from the limitations imposed by stereo obstacle detection, which is short range and prone to failure. We present a self-supervised learning process for long-range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning. The success of the learning process is due to the self-supervised training data that are generated on every frame: robust, visually consistent labels from a stereo module; normalized wide-context input windows; and a discriminative and concise feature representation. A deep hierarchical network is trained to extract informative and meaningful features from an input image, and the features are used to train a real-time classifier to predict traversability. The trained classifier sees obstacles and paths from 5 to more than 100 m, far beyond the maximum stereo range of 12 m, and adapts very quickly to new environments. The process was developed and tested on the LAGR (Learning Applied to Ground Robots) mobile robot. Results from a ground truth data set, as well as field test results, are given. (C) 2009 Wiley Periodicals, Inc.	[Hadsell, Raia; Erkan, Ayse; Scoffier, Marco; Kavukcuoglu, Koray; LeCun, Yann] NYU, Courant Inst Math Sci, New York, NY 10003 USA; [Sermanet, Pierre; Ben, Jan; Scoffier, Marco; Muller, Urs] Net Scale Technol, Morganville, NJ 07751 USA	Hadsell, R (reprint author), NYU, Courant Inst Math Sci, 251 Mercer St, New York, NY 10003 USA.	raia@cs.nyu.edu			DARPA	The authors wish to thank Larry Jackel, Dan D. Lee, and Martial Hebert for helpful discussions. This work was supported by DARPA under the Learning Applied to Ground Robots program.	ANGELOVA A, 2007, P ROB SC SYST RSS AT, V29; DAHLKAMP H, 2006, P ROB SCI SYST RSS P, P5; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Goldberg S.B., 2002, IEEE AER C P BIG SKY, V5, P2025, DOI DOI 10.1109/AERO.2002.1035370; GRUDIC G, 2006, P ROB SCI SYST RSS P, P20; HAPPOLD M, 2006, P ROB SCI SYST RSS P, P6; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HONG T, 2002, P SPIE AER C ORL FL, P311; Jackel LD, 2006, J FIELD ROBOT, V23, P945, DOI 10.1002/rob.20161; Kelly A, 1998, INT C ROB AUT WORKSH; Kim D., 2006, P IEEE INT C ROB AUT, P518; KONOLIGE K, 2008, SPRINGER TRACTS ADV, P179; KRIEGMAN DJ, 1989, IEEE T ROBOTIC AUTOM, V5, P792, DOI 10.1109/70.88100; LeCun Y., 1995, HDB BRAIN THEORY NEU; LEIB D, 2005, P ROB SCI SYST RSS C, P36; RANZATO M, 2007, P C COMP VIS PATT RE; SERMANET P, 2008, P INT C INT ROB SYST, P2525; Sermanet P, 2009, J FIELD ROBOT, V26, P52, DOI [10.1002/rob.20270, 10.1002/rob.2270]; SOFMAN B, 2006, P ROB SCI SYST RSS P, V4; STAVENS D, 2006, P C UNC AI UAI CAMBR; Thrun S, 2006, J FIELD ROBOT, V23, P661, DOI 10.1002/rob.20147; WELLINGTON C, 2004, P INT C ROB AUT ICRA, P96	22	33	36	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1556-4959			J FIELD ROBOT	J. Field Robot.	FEB	2009	26	2					120	144		10.1002/rob.20276		25	Robotics	Robotics	402HN	WOS:000263004900003		
J	Abbott, LF				Abbott, L. F.			Theoretical Neuroscience Rising	NEURON			English	Article							TIMING-DEPENDENT PLASTICITY; NATURAL IMAGES; ORIENTATION SELECTIVITY; NEURAL-NETWORKS; SIMPLE CELLS; SYNAPTIC PLASTICITY; CORTICAL-CELLS; WORKING-MEMORY; COMPLEX CELLS; MODEL	Theoretical neuroscience has experienced explosive growth over the past 20 years. In addition to bringing new researchers into the field with backgrounds in physics, mathematics, computer science, and engineering, theoretical approaches have helped to introduce new ideas and shape directions of neuroscience research. This review presents some of the developments that have occurred and the lessons they have taught us.	[Abbott, L. F.] Columbia Univ, Med Ctr, Dept Neurosci, New York, NY 10032 USA; [Abbott, L. F.] Columbia Univ, Med Ctr, Dept Physiol & Cellular Biophys, New York, NY 10032 USA	Abbott, LF (reprint author), Columbia Univ, Med Ctr, Dept Neurosci, New York, NY 10032 USA.	lfabbott@columbia.edu					AMIT DJ, 1985, PHYS REV A, V32, P1007, DOI 10.1103/PhysRevA.32.1007; Amit DJ, 1997, CEREB CORTEX, V7, P237, DOI 10.1093/cercor/7.3.237; AMIT DJ, 1994, NEURAL COMPUT, V6, P957, DOI 10.1162/neco.1994.6.5.957; Atick JJ, 1990, NEURAL COMPUT, V2, P308, DOI 10.1162/neco.1990.2.3.308; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Borges JL, 1975, UNIVERSAL HIST INFAM; Brunel N, 2000, J PHYSIOLOGY-PARIS, V94, P445, DOI 10.1016/S0928-4257(00)01084-6; Buchs NJ, 2002, J COMPUT NEUROSCI, V13, P167, DOI 10.1023/A:1020210230751; Cadieu C, 2007, J NEUROPHYSIOL, V98, P1733, DOI 10.1152/jn.01265.2006; Chance FS, 1999, NAT NEUROSCI, V2, P277; Compte A, 2000, CEREB CORTEX, V10, P910, DOI 10.1093/cercor/10.9.910; Dan Y, 2006, PHYSIOL REV, V86, P1033, DOI 10.1152/physrev.00030.2005; DONG DW, 1995, NETWORK-COMP NEURAL, V6, P159, DOI 10.1088/0954-898X/6/2/003; Emes RD, 2008, NAT NEUROSCI, V11, P799, DOI 10.1038/nn.2135; Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Fusi S, 2002, BIOL CYBERN, V87, P459, DOI 10.1007/s00422-002-0356-8; Fusi S, 2005, NEURON, V45, P599, DOI 10.1016/j.neuron.2005.02.001; Gerstner W, 1996, NATURE, V383, P76, DOI 10.1038/383076a0; GROSSBERG S, 1982, PSYCHOL REV, V89, P529, DOI 10.1037/0033-295X.89.5.529; HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152; Jaeger H, 2003, ADV NEURAL INFORM PR, V15, P593; Kang S, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000022; Knill D.C, 1996, PERCEPTION BAYESIAN; Kopell N, 2000, P NATL ACAD SCI USA, V97, P1867, DOI 10.1073/pnas.97.4.1867; Kording KP, 2006, TRENDS COGN SCI, V10, P319, DOI 10.1016/j.tics.2006.05.003; Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831; Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Machens CK, 2005, SCIENCE, V307, P1121, DOI 10.1126/science.1104171; Marder E, 2007, PROG BRAIN RES, V165, P193, DOI 10.1016/S0079-6123(06)65012-7; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; Miller KD, 2003, CEREB CORTEX, V13, P73, DOI 10.1093/cercor/13.1.73; Mongillo G, 2008, SCIENCE, V319, P1543, DOI 10.1126/science.1150769; Morrison A, 2007, NEURAL COMPUT, V19, P1437, DOI 10.1162/neco.2007.19.6.1437; Niven JE, 2007, PLOS BIOL, V5, P828, DOI 10.1371/journal.pbio.0050116; Nowotny T, 2003, J NEUROSCI, V23, P9776; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Paninski L, 2007, PROG BRAIN RES, V165, P493, DOI 10.1016/S0079-6123(06)65031-0; Poirazi P, 2003, NEURON, V37, P989, DOI 10.1016/S0896-6273(03)00149-1; Rao RPN, 2002, PROBABILISTIC MODELS; Rieke F., 1996, SPIKES EXPLORING NEU; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Salinas E, 2001, NAT REV NEUROSCI, V2, P539, DOI 10.1038/35086012; Schultz W, 1997, SCIENCE, V275, P1593, DOI 10.1126/science.275.5306.1593; Segev I, 2000, SCIENCE, V290, P744, DOI 10.1126/science.290.5492.744; Seung HS, 2000, NEURON, V26, P259, DOI 10.1016/S0896-6273(00)81155-1; Shadlen Michael N., 1994, Current Opinion in Neurobiology, V4, P569, DOI 10.1016/0959-4388(94)90059-0; Sharpee T, 2004, NEURAL COMPUT, V16, P223, DOI 10.1162/089976604322742010; SOFTKY WR, 1992, NEURAL COMPUT, V4, P643, DOI 10.1162/neco.1992.4.5.643; SOMERS DC, 1995, J NEUROSCI, V15, P5448; Sompolinsky H, 1997, CURR OPIN NEUROBIOL, V7, P514, DOI 10.1016/S0959-4388(97)80031-1; Song S, 2001, NEURON, V32, P339, DOI 10.1016/S0896-6273(01)00451-2; Stocker AA, 2006, NAT NEUROSCI, V9, P578, DOI 10.1038/nn1669; Tao L, 2004, P NATL ACAD SCI USA, V101, P366, DOI 10.1073/pnas.2036460100; TOLHURST DJ, 1992, OPHTHAL PHYSL OPT, V12, P229, DOI 10.1111/j.1475-1313.1992.tb00296.x; Troyer TW, 1997, NEURAL COMPUT, V9, P971, DOI 10.1162/neco.1997.9.5.971; vanderSchaaf A, 1996, VISION RES, V36, P2759, DOI 10.1016/0042-6989(96)00002-8; VanHateren JH, 1997, VISION RES, V37, P3407, DOI 10.1016/S0042-6989(97)00105-3; vanVreeswijk C, 1996, SCIENCE, V274, P1724; Wang XJ, 2002, NEURON, V36, P955, DOI 10.1016/S0896-6273(02)01092-9; Wen Q, 2008, J NEUROPHYSIOL, V99, P2320, DOI 10.1152/jn.00280.2007; Womelsdorf T, 2007, CURR OPIN NEUROBIOL, V17, P154, DOI 10.1016/j.conb.2007.02.002; WORGOTTER F, 1991, J NEUROSCI, V11, P1959	69	32	35	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	0896-6273			NEURON	Neuron	NOV 6	2008	60	3					489	495		10.1016/j.neuron.2008.10.019		7	Neurosciences	Neurosciences & Neurology	373PI	WOS:000260983800021	18995824	
J	Ji, SW; Xu, W; Yang, M; Yu, K				Ji, Shuiwang; Xu, Wei; Yang, Ming; Yu, Kai			3D Convolutional Neural Networks for Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; convolutional neural networks; 3D convolution; model combination; action recognition	FEATURES; VIDEOS; FIELDS	We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.	[Ji, Shuiwang] Old Dominion Univ, Dept Comp Sci, Norfolk, VA 23529 USA; [Xu, Wei] Facebook Inc, Menlo Pk, CA 94304 USA; [Yang, Ming] NEC Labs Amer Inc, Cupertino, CA 95014 USA; [Yu, Kai] Baidu Inc, Beijing 100085, Peoples R China	Ji, SW (reprint author), Old Dominion Univ, Dept Comp Sci, Suite 3300,4700 Elkhorn Ave, Norfolk, VA 23529 USA.	sji@cs.odu.edu; emailweixu@fb.com; myang@nec-labs.com; yukai@baidu.com					Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bromley J., 1994, P ADV NEUR INF PROC, V6, P737; Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Delaitre V., 2010, P 21 BRIT MACH VIS C; Dollar P., 2005, P IEEE INT WORKSH VI, P65; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Efros A.A., 2003, COMP VIS P 9 IEEE IN, V2, P726; Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286; Freund Y., 1996, P 13 INT C MACH LEAR, P148; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jain V., 2009, P ADV NEUR INF PROC, V21, P769; Jain V., 2007, P 11 IEEE INT C COMP; Jarrett K., 2009, P 12 IEEE INT C COMP; Jhuang H., 2007, P IEEE INT C COMP VI, P1; Ji S., 2010, P 27 INT C MACH LEAR, P495; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Kim HJ, 2007, LECT NOTES COMPUT SC, V4492, P715; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Laptev I., 2007, P INT C COMP VIS, P1; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432; Laptev I., 2008, P IEEE C COMP VIS PA; Lazebnik S., 2006, CVPR, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, NEURAL NETWORKS TRIC; Lee H., 2009, ADV NEURAL INFORM PR, V22, P1096; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Liu JG, 2009, PROC CVPR IEEE, P1996; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marszalek M., 2009, P IEEE C COMP VIS PA, P2929; Mobahi H., 2009, P 26 ANN INT C MACH, P737; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Ning F, 2005, IEEE T IMAGE PROCESS, V14, P1360, DOI 10.1109/TIP.2005.852470; Norouzi M.R.M., 2009, P IEEE C COMP VIS PA; Ranzato M., 2007, P IEEE C COMP VIS PA; Schindler K., 2008, P IEEE C COMP VIS PA; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881; Wang H., 2009, P BRIT MACH VIS C, P127; Wang Y, 2009, PROC CVPR IEEE, P872; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Yang M., 2009, P TREC VID RETR EV W; Yang M, 2009, IEEE I CONF COMP VIS, P1554, DOI 10.1109/ICCV.2009.5459252; Yu K., 2009, P ADV NEUR INF PROC, V21, P1889; Zhu Guan, 2009, P165, DOI 10.1007/978-3-540-74042-1_5	54	30	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					221	231		10.1109/TPAMI.2012.59		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	037SV	WOS:000311127700019	22392705	
J	Lee, H; Grosse, R; Ranganath, R; Ng, AY				Lee, Honglak; Grosse, Roger; Ranganath, Rajesh; Ng, Andrew Y.			Unsupervised Learning of Hierarchical Representations with Convolutional Deep Belief Networks	COMMUNICATIONS OF THE ACM			English	Article							NATURAL IMAGES; VISUAL-CORTEX; INFERENCE; STIMULI; FILTERS; V2	There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks (DBNs); however, scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model that scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique that shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.	[Lee, Honglak] Univ Michigan, Comp Sci & Engn Div, Ann Arbor, MI 48109 USA; [Grosse, Roger] MIT, CSAIL, Cambridge, MA 02139 USA; [Ranganath, Rajesh; Ng, Andrew Y.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Lee, H (reprint author), Univ Michigan, Comp Sci & Engn Div, Ann Arbor, MI 48109 USA.	honglak@eecs.umich.edu; rgrosse@mit.edu; rajeshr@cs.stanford.edu; ang@cs.stanford.edu			DARPA [FA8750-05-2-0249]	We give warm thanks to Daniel Oblinger and Rajat Raina for helpful discussions. This work was supported by the DARPA transfer learning program under contract number FA8750-05-2-0249.	Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2007, ADV NEURAL INFORM PR; Berg A. C., 2005, P IEEE C COMP VIS PA; Desjardins G., 2008, EMPIRICAL EVALUATION; Fei-Fei L., 2004, CVPR WORKSH GEN MOD; Gehler P.V., 2009, P INT C COMP VIS; Grosse R., 2007, P C UNC ART INT; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 2005, P INT C ART INT STAT; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hyvarinen A, 2005, BMC NEUROSCI, V6, DOI 10.1186/1471-2202-6-12; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; LAROCHELLE H, 2007, P INT C MACH LEARN; Lazebnik S., 2006, P IEEE C COMP VIS PA; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lee H., 2008, ADV NEURAL INFORM PR, V20; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Mutch J, 2006, P IEEE C COMP VIS PA; NOROUZI M, 2009, P IEEE C COMPR VIS P; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Osindero S, 2006, NEURAL COMPUT, V18, P381, DOI 10.1162/089976606775093936; Raina R, 2007, P INT C MACH LEARN; RAINA R, 2009, P INT C MACH LEARN; Ranzato M., 2007, P IEEE C COMP VIS PA; Ranzato M, 2006, ADV NEURAL INFORM PR, P1137; Ranzato Marc'Aurelio, 2007, ADV NEURAL INFORM PR; Salakhutdinov R., 2009, P INT C ART INT STAT; Salakhutdinov R., 2007, P INT C MACH LEARN; Taylor G.W., 2007, ADV NEURAL INFORM PR, V19; Tieleman T., 2008, P INT C MACH LEARN; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359; Weston J., 2008, P INT C MACH LEARN; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Yu K., 2009, ADV NEURAL INFORM PR; YUILLE AL, 2005, ADV NEURAL INFORM PR, V17; Zhang H, 2006, P IEEE C COMP VIS PA	38	30	32	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	0001-0782			COMMUN ACM	Commun. ACM	OCT	2011	54	10					95	103		10.1145/2001269.2001295		9	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	835FZ	WOS:000296022500023		
B	Zhang, D; Wang, J; Cal, D; Lu, JS		Chen, HH; Efthimiadis, EN; Savoy, J; Crestani, F; MarchandMaillet, S		Zhang, Dell; Wang, Jun; Cal, Deng; Lu, Jinsong			Self-Taught Hashing for Fast Similarity Search	SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL			English	Proceedings Paper	33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval	JUL 19-23, 2010	Geneva, SWITZERLAND	Special Interest Grp Informat Retrieval, Assoc Comp Machinery, Baidu, Google, Microsoft Res, Yahoo, Informat Retrieval Fac, IBM Res, FNSNF, Swiss Natl Sci Fdn		Similarity Search; Semantic Hashing; Laplacian Eigenmap; Support Vector Machine	INFORMATION-RETRIEVAL; MATHEMATICAL-THEORY; DIMENSIONALITY; COMMUNICATION	The ability of fast similarity search at large scale is of great importance to many Information Retrieval (IR) applications. A promising way to accelerate similarity search is semantic hashing which designs compact binary codes for a large number of documents so that semantically similar documents are mapped to similar codes (within a short Hamming distance). Although some recently proposed techniques are able to generate high-quality codes for documents known in advance, obtaining the codes for previously unseen documents remains to be a very challenging problem. In this paper, we emphasise this issue and propose a novel Self-Taught Hashing (STH) approach to semantic hashing: we first find the optimal l-bit binary codes for all documents in the given corpus via unsupervised learning, and then train 1 classifiers via supervised learning to predict the l-bit code for any query document unseen before. Our experiments on three real-world text datasets show that the proposed approach using binarised Laplacian Eigenmap (LapEig) and linear Support Vector Machine (SVM) outperforms state-of-the-art techniques significantly.	[Zhang, Dell] Univ London, DCSIS, London WC1E 7HX, England	Zhang, D (reprint author), Univ London, DCSIS, Malet St, London WC1E 7HX, England.	dell.z@ieee.org; jun.wang@cs.ucl.ac.uk; dengcai@cad.zju.edu.cn; jingsong.lu@gmail.com					Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Baluja S., 2008, DATA MIN KNOWL DISC, V17, P402; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belongie S., 2002, P 7 EUR C COMP VIS E, P531; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Chung F. R. K., 1997, SPECTRAL GRAPH THEOR; Cormen T. H., 2001, INTRO ALGORITHMS, V2nd; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Dumais S., 1998, 7 INT C INF KNOWL MA, P148, DOI 10.1145/288627.288651; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Golub G. H., 1996, MATRIX COMPUTATIONS; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36; Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276382; He X, 2004, P 27 ANN INT ACM SIG, P96, DOI 10.1145/1008992.1009012; He X., 2003, ADV NEURAL INFORM PR, V16, P153; Henzinger M., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1148170.1148222; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsieh C.J., 2008, P 25 INT C MACH LEAR, P408, DOI [10.1145/1390156.1390208, DOI 10.1145/1390156.1390208]; Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI DOI 10.1145/1150402.1150429; Joachims T, 1998, EUR C MACH LEARN ECM, P137; Joachims T., 2002, LEARNING CLASSIFY TE; Knuth D, 1997, ART COMPUTER PROGRAM; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI DOI 10.1145/1401890.1401944; Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; LIN J, 2009, P 32 ANN INT ACM, P155; Manning C.D., 2008, INTRO INFORM RETRIEV; Mitchell T. M., 1997, MACHINE LEARNING; PANDEY S., 2009, P 18 INT C WORLD WID, P441, DOI http://dx.doi.org/10.1145/1526709.1526769; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schapire R. E., 2003, NONLINEAR ESTIMATION; Scholkopf B., 2002, LEARNING KERNELS; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; SHANNON CE, 1948, AT&T TECH J, V27, P623; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Shi QF, 2009, J MACH LEARN RES, V10, P2615; Stein B., 2007, P 30 ANN INT ACM SIG, P527, DOI 10.1145/1277741.1277832; Stein B, 2007, P 30 ANN INT ACM SIG, P825, DOI 10.1145/1277741.1277928; Torralba A, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2008.4587633; Wagner P., 1960, COMMUNICATIONS ACM C, V3, P322; Weber R, 1998, VLDB, P194; Weinberger K. Q., 2009, P 26 ANN INT C MACH, P140; Weiss Y., 2008, ADV NEURAL INFORM PR, V21, P1753; Yang Y., 1999, 22 ANN INT ACM SIGIR, P42; Zhang D., 2010, P 32 EUR C IR RES EC, P577	50	30	30	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-60558-896-4				2010							18	25				8	Computer Science, Information Systems	Computer Science	BTG52	WOS:000286904100004		
S	Taylor, GW; Fergus, R; LeCun, Y; Bregler, C		Daniilidis, K; Maragos, P; Paragios, N		Taylor, Graham W.; Fergus, Rob; LeCun, Yann; Bregler, Christoph			Convolutional Learning of Spatio-temporal Features	COMPUTER VISION - ECCV 2010, PT VI	Lecture Notes in Computer Science		English	Proceedings Paper	11th European Conference on Computer Vision	SEP 05-11, 2010	Heraklion, GREECE	Inst Natl Rech Informat & Automat, Google, Microsoft Res, Technicolor, Adobe, DynaVox Mayer-Johnson, Eur Res Consortium Informat Math, Gen Elect, IBM, Johnson Controls, Point Grey, Univ Houston, Siemens		unsupervised learning; restricted Boltzmann machines; convolutional nets; optical flow; video analysis; activity recognition		We address the problem of learning good features for understanding video data. We introduce a model that learns latent representations of image sequences from pairs of successive images. The convolutional architecture of our model allows it to scale to realistic image sizes whilst using a compact parametrization. In experiments on the NORB dataset, we show our model extracts latent "flow fields" which correspond to the transformation between the pair of input frames. We also use our model to extract low-level motion features in a multi-stage architecture for action recognition, demonstrating competitive performance on both the KTH and Hollywood2 datasets.	[Taylor, Graham W.; Fergus, Rob; LeCun, Yann; Bregler, Christoph] NYU, Courant Inst Math Sci, New York, NY 10012 USA	Taylor, GW (reprint author), NYU, Courant Inst Math Sci, New York, NY 10012 USA.	gwtaylor@cs.nyu.edu; fergus@cs.nyu.edu; yann@cs.nyu.edu; bregler@cs.nyu.edu					CADIEU C, 2009, NIPS, P209; DEAN T, 2009, P IEEE INT WORKSH MU; Dollar P, 2005, VS PETS; FREUND Y, 1992, P NIPS, V4; He XM, 2004, PROC CVPR IEEE, P695; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jhuang H., 2007, ICCV; Laptev I., 2008, CVPR; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432; Larochelle Hugo, 2007, ICML, P473; LeCun Y, 2004, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, NIPS, P873; Lee H., 2007, NIPS, P801; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Mairal J., 2009, ICML, P689; Marszalek M., 2009, CVPR, P2929; Memisevic R., 2007, CVPR; MEMISEVIC R, 2010, NEURAL COMPUT; Nair V, 2009, NIPS, P1339; Norouzi M., 2009, CVPR; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Ranzato M. A., 2006, NIPS, P1137; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Sutskever I., 2007, AISTATS; Wang H., 2009, BMVC, P127; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48	30	28	28	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15566-6	LECT NOTES COMPUT SC			2010	6316						140	153				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BTD63	WOS:000286578700011		
J	Salakhutdinov, R; Hinton, G				Salakhutdinov, Ruslan; Hinton, Geoffrey			An Efficient Learning Procedure for Deep Boltzmann Machines	NEURAL COMPUTATION			English	Article							NETWORKS	We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent statistics are estimated using a variational approximation that tends to focus on a single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer pretraining phase that initializes the weights sensibly. The pretraining also allows the variational inference to be initialized sensibly with a single bottom-up pass. We present results on the MNIST and NORB data sets showing that deep Boltzmann machines learn very good generative models of handwritten digits and 3D objects. We also show that the features discovered by deep Boltzmann machines are a very effective way to initialize the hidden layers of feedforward neural nets, which are then discriminatively fine-tuned.	[Salakhutdinov, Ruslan] Univ Toronto, Dept Stat, Toronto, ON M5S 3G3, Canada; [Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G3, Canada	Salakhutdinov, R (reprint author), Univ Toronto, Dept Stat, Toronto, ON M5S 3G3, Canada.	rsalakhu@utstat.toronto.edu; hinton@cs.toronto.edu			NSERC	This research was supported by NSERC and by gifts from Google and Microsoft.	Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Carreira-Perpignan M. A., 2005, ARTIFICIAL INTELLIGE; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Desjardins G., 2010, P 13 INT C ART INT S, P145; Galland C, 1991, THESIS U TORONTO; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Hinton G. E., 1994, ADV NEURAL INFORMATI, V6, P3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton G.E., 2010, 2010000 U TOR MACH L; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Jordan M., 1999, LEARNING GRAPHICAL M; Kappen HJ, 1998, ADV NEUR IN, V10, P280; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LeCun Y, 2004, PROC CVPR IEEE, P97; Mandic D. P., 2001, P INT C MACH LEARN; Marks T. K., 2001, P INT C IND COMP AN, P481; Mohamed A., 2012, IEEE T AUDIO SPEECH, P14; Murray I., 2009, ADV NEURAL INFORM PR, V21, P1137; Nair V, 2009, ADV NEURAL INFORM PR, V21, P1145; Nair V., 2010, P 27 INT C MACH LEAR, P807; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Neal RM, 1998, NATO ADV SCI I D BEH, P355; Osindero S, 2008, ADV NEURAL INFORM PR, V20, P1121; Peterson C., 1987, Complex Systems, V1; Ranzato M., 2007, P IEEE C COMP VIS PA; Ranzato M. A, 2009, THESIS NEW YORK U; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, V22, P1607; Salakhutdinov R., 2009, P INT C ART INT STAT, V12, P448; Salakhutdinov R. R., 2007, P INT C ART INT STAT, V11, P412; Salakhutdinov R. R, 2008, P INT C MACH LEARN, V25, P872; Salakhutdinov R. R, 2009, ADV NEURAL INFORM PR, V23, P1598; Sejnowski T. J, 1983, P IEEE C COMP VIS PA; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T, 2008, MACH LEARN P 21 INT, P1064; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Welling M, 2009, P 26 ANN INT C MACH, P141; Williams C., 2002, EDIINFRR0120 U ED I; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI 10.1080/17442509908834179; Yuille AL, 2004, ADV NEURAL INFORM PR, V17, P1593; Zemel R. S, 1993, THESIS U TORONTO	52	27	29	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	AUG	2012	24	8					1967	2006				40	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	960TP	WOS:000305414000001	22509963	
J	Escalante, HJ; Montes, M; Sucar, LE				Jair Escalante, Hugo; Montes, Manuel; Enrique Sucar, Luis			Particle Swarm Model Selection	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						full model selection; machine learning challenge; particle swarm optimization; experimentation; cross validation	OPTIMIZATION; CLASSIFICATION; CLASSIFIERS; ALGORITHMS; REGRESSION	This paper proposes the application of particle swarm optimization (PSO) to the problem of full model selection, FMS, for classification tasks. FMS is defined as follows: given a pool of preprocessing methods, feature selection and learning algorithms, to select the combination of these that obtains the lowest classification error for a given data set; the task also includes the selection of hyperparameters for the considered methods. This problem generates a vast search space to be explored, well suited for stochastic optimization techniques. FMS can be applied to any classification domain as it does not require domain knowledge. Different model types and a variety of algorithms can be considered under this formulation. Furthermore, competitive yet simple models can be obtained with FMS. We adopt PSO for the search because of its proven performance in different problems and because of its simplicity, since neither expensive computations nor complicated operations are needed. Interestingly, the way the search is guided allows PSO to avoid overfitting to some extend. Experimental results on benchmark data sets give evidence that the proposed approach is very effective, despite its simplicity. Furthermore, results obtained in the framework of a model selection challenge show the competitiveness of the models selected with PSO, compared to models selected with other techniques that focus on a single algorithm and that use domain knowledge.	[Jair Escalante, Hugo; Montes, Manuel; Enrique Sucar, Luis] Natl Inst Astrophys Opt & Elect, Dept Computat Sci, Puebla 72840, Mexico	Escalante, HJ (reprint author), Natl Inst Astrophys Opt & Elect, Dept Computat Sci, Puebla 72840, Mexico.	HUGOJAIR@CCC.INAOEP.MX; MMONTESG@INAOEP.MX; ESUCAR@INAOEP.MX			UNIPEN foundation; US National Science Foundation; INAOE	We would like to thank the organizers and participants of the NIPS multi-level inference workshop and model selection game, and of the IJCNN ALvsPK challenge. The first author thanks the UNIPEN foundation and the US National Science Foundation for travel support. We also thank editors and anonymous reviewers for their useful comments that have help us to improve this paper. We thank Dr. Eduardo Morales for his useful suggestions about the content of the paper. Last, but not least, we thank Dr. Aurelio Lopez and INAOE for the provided support.	Angeline P. J., 1998, LECT NOTES COMPUTER, V1447, P601, DOI DOI 10.1007/BFB0040811; Bengio Y., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753634; Bishop CM, 2006, PATTERN RECOGNITION; BOULLE M, 2007, P 20 INT JOINT C NEU, P1802; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CAWLEY G, 2007, P 20 INT JOINT C NEU, P1444; CAWLEY G, 2007, P 20 INT JOINT C NEU, P1439; CAWLEY GC, 2006, P INT JOINT C NEUR N, P2970; Cawley GC, 2007, J MACH LEARN RES, V8, P841; Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692; Demsar J, 2006, J MACH LEARN RES, V7, P1; DENNIS J., 1994, P 5 AIAA USAF NASA I, P922; Dietterich T, 1995, ACM COMPUT SURV, V27, P326, DOI 10.1145/212094.212114; Engelbrecht A.P., 2006, FUNDAMENTALS COMPUTA; Escalante HJ, 2007, P 20 INT JOING C NEU, P1191; ESCALANTE HJ, 2009, PARTICLE SWARM UNPUB; Franc V., 2004, STAT PATTERN RECOGNI; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gorissen D., 2007, THESIS KATHOLIEKE U; Gorissen D, 2008, IEEE C EVOL COMPUTAT, P989, DOI 10.1109/CEC.2008.4630917; Gudise VG, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P110, DOI 10.1109/SIS.2003.1202255; Guyon I, 2008, NEURAL NETWORKS, V21, P544, DOI 10.1016/j.neunet.2007.12.024; GUYON I, 2006, NIPS WORKSH MULT INF; Guyon I., 2006, SERIES STUDIES FUZZI; Guyon I., 2007, P 20 INT JOINT C NEU, P1232; GUYON I, 2006, P INT JOINT C NEUR N, P2958; Guyon I., 2004, ADV NEURAL INFORM PR, V17, P545; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2001, ELEMENTS STAT LEARNI; HERNANDEZ E, 2004, EVOLVABLE HARDWARE, P183; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; Hue C, 2007, J MACH LEARN RES, V8, P2727; Bi J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753643; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; Kennedy J., 2001, SWARM INTELLIGENCE, V3rd; Kennedy J., 1995, P IEEE INT C NEUR NE, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J, 2002, P C EV COMP CEC 02, P1671, DOI 10.1109/CEC.2002.1004493; Kennedy J., 2008, INT J COMPUTATIONAL, V4, P71; Kim Y, 2002, INTELL DATA ANAL, V6, P531; Kirkpatrick S., 1983, SCIENCE, V220, P4598; Loughrey J., 2005, RES DEV INTELLIGENT, VXXI, P33; LUTZ R, 2006, P INT JOINT C NEUR N, P1657; Mika S, 2000, ADV NEUR IN, V12, P526; Momma M., 2002, P SIAM C DAT MIN; Nelles O, 2001, NONLINEAR SYSTEM IDE; Ozcan E., 1998, INTELLIGENT ENG SYST, P253; PRANCKEVICIENE E, 2007, P 20 INT JOINT C NEU, P1422; Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6; Quinlan J.R., 1995, P 14 INT JOINT C ART, P1019; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; REUNANEN J, 2007, P 20 INT JOINT C NEU, P1674; REYES M, 2006, INT J COMPUTATIONAL, V3; Robinson J, 2004, IEEE T ANTENN PROPAG, V52, P397, DOI 10.1109/TAP.2004.823969; Saffari A., 2006, QUICKSTART GUIDE CLO; Salerno J, 1997, PROC INT C TOOLS ART, P45, DOI 10.1109/TAI.1997.632235; Saunders C., 1998, P 15 INT C MACH LEAR, P515; Shi V., 1998, EVOLUTIONARY PROGRAM, P591; Shi Y., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.785511; SONNENBURG S, 2006, NIPS WORKSH MACH LEA; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; van den Bergh F, 2001, THESIS U PRETORIA SU; VANDERHEIJDEN F, 2004, PRTOOLS MATLAB BASED; Voss M.S., 2002, P 15 IFAC WORLD C AU; Weston J., 2005, SPIDER MACHINE LEARN; Wichard J., 2007, ENTOOL MATLAB TOOLBO; WICHARD J, 2007, P 20 INT JOINT C NEU, P1753; Witten I. H., 2005, DATA MINING PRACTICA; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Xiaohui Hu, 2003, Proceedings of the 2003 IEEE Swarm Intelligence Symposium. SIS'03 (Cat. No.03EX706), DOI 10.1109/SIS.2003.1202247; Yoshida H, 2000, IEEE T POWER SYST, V15, P1232, DOI 10.1109/59.898095	73	27	28	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2009	10						405	440				36	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BG	WOS:000270824200011		
J	Hansen, K; Montavon, G; Biegler, F; Fazli, S; Rupp, M; Scheffler, M; von Lilienfeld, OA; Tkatchenko, A; Muller, KR				Hansen, Katja; Montavon, Gregoire; Biegler, Franziska; Fazli, Siamac; Rupp, Matthias; Scheffler, Matthias; von Lilienfeld, O. Anatole; Tkatchenko, Alexandre; Mueller, Klaus-Robert			Assessment and Validation of Machine Learning Methods for Predicting Molecular Atomization Energies	JOURNAL OF CHEMICAL THEORY AND COMPUTATION			English	Article							MIXED-EFFECTS MODELS; NEURAL-NETWORKS; SURFACES; DEEP; RECOGNITION; REGRESSION; SELECTION; NETS; BIAS	The accurate and reliable prediction of properties of molecules typically requires computationally intensive quantum-chemical calculations. Recently, machine learning techniques applied to ab initio calculations have been proposed as an efficient approach for describing the energies of molecules in their given ground-state structure throughout chemical compound space (Rupp et al. Phys. Rev. Lett. 2012, 108, 058301). In this paper we outline a number of established machine learning techniques and investigate the influence of the molecular representation on the methods performance. The best methods achieve prediction errors of 3 kcal/mol for the atomization energies of a wide variety of molecules. Rationales for this performance improvement are given together with pitfalls and challenges when applying machine learning approaches to the prediction of quantum-mechanical observables.	[Hansen, Katja; Scheffler, Matthias; Tkatchenko, Alexandre] Max Planck Gesell, Fritz Haber Inst, Berlin, Germany; [Montavon, Gregoire; Biegler, Franziska; Fazli, Siamac; Mueller, Klaus-Robert] TU Berlin, Machine Learning Grp, Berlin, Germany; [Rupp, Matthias] Swiss Fed Inst Technol, Inst Pharmaceut Sci, Zurich, Switzerland; [von Lilienfeld, O. Anatole] Argonne Natl Lab, Argonne Leadership Comp Facil, Lemont, IL USA; [Mueller, Klaus-Robert] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Hansen, K (reprint author), Max Planck Gesell, Fritz Haber Inst, Faradayweg 4-6, Berlin, Germany.	hansen@fhi-berlin.mpg.de; klaus-robert.mueller@tu-berlin.de	von Lilienfeld, O. Anatole/D-8529-2011		European Research Council (ERC); World Class University Program through the National Research Foundation of Korea; Ministry of Education, Science, and Technology [R31-10008]; Einstein Foundation; U.S. Department of Energy, Basic Energy Sciences, Office of Science [DE-AC02-06CH11357]; Natural Sciences and Engineering Research Council of Canada; DFG [MU 987/17-1]; FP7 programme of the European Community [Marie Curie IEF 273039]	This work is supported by the European Research Council (ERC Starting Grant VDW-CMAT), by the World Class University Program through the National Research Foundation of Korea funded by the Ministry of Education, Science, and Technology, under Grant R31-10008, the Einstein Foundation, and by the U.S. Department of Energy, Basic Energy Sciences, Office of Science, under contract # DE-AC02-06CH11357. The work of Franziska Biegler is funded, in part, by the Natural Sciences and Engineering Research Council of Canada. The authors also acknowledge partial support by DFG (MU 987/17-1). Matthias Rupp acknowledges support by FP7 programme of the European Community (Marie Curie IEF 273039).	Amari S, 1997, IEEE T NEURAL NETWOR, V8, P985, DOI 10.1109/72.623200; Balabin RM, 2009, J CHEM PHYS, V131, DOI 10.1063/1.3206326; Balabin RM, 2011, PHYS CHEM CHEM PHYS, V13, P11710, DOI 10.1039/c1cp00051a; Bartok AP, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.136403; BEHLER, 2011, J PHYS CHEM CHEM PHY, V13, P17930; Behler J, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.146401; Behler J, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.185501; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BENSON SW, 1965, BOND ENERGIES; Bishop C. M., 2011, PATTERN RECOGNITION; BLANK TB, 1995, J CHEM PHYS, V103, P4129, DOI 10.1063/1.469597; Blum LC, 2009, J AM CHEM SOC, V131, P8732, DOI 10.1021/ja902302h; Blum V, 2009, COMPUT PHYS COMMUN, V180, P2175, DOI 10.1016/j.cpc.2009.06.022; Bottou L., 2007, LARGE SCALE KERNEL M; Bottou L., 1991, P NEURONIMES, V91, P687; Braun ML, 2008, J MACH LEARN RES, V9, P1875; BREIMAN L, 1992, INT STAT REV, V60, P291, DOI 10.2307/1403680; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Cawley GC, 2010, J MACH LEARN RES, V11, P2079; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; CRISTIANINI N, 2000, INTRO SUPPORT VECTOR, P112; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DETILLEGHEM CL, 2007, 07027 U CATH LOUV; Duda R, 2001, PATTERN CLASSIFICATI; Emzerhof M., 1999, J CHEM PHYS, V110, P5029; Fazli S, 2011, NEUROIMAGE, V56, P2100, DOI 10.1016/j.neuroimage.2011.03.061; Guha R, 2006, J CHEM INF MODEL, V46, P991, DOI 10.1021/ci050400b; Handley CM, 2010, J PHYS CHEM A, V114, P3371, DOI 10.1021/jp9105585; Handley CM, 2009, J CHEM THEORY COMPUT, V5, P1474, DOI 10.1021/ct800468h; Hansen K, 2009, J CHEM INF MODEL, V49, P1486, DOI 10.1021/ci9000794; Hastie T., 2001, SPRINGER SERIES STAT; Hautier G, 2010, CHEM MATER, V22, P3762, DOI 10.1021/cm100795d; Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu LH, 2003, J CHEM PHYS, V119, P11501, DOI 10.1063/1.1630951; Ivosev G, 2008, ANAL CHEM, V80, P4933, DOI 10.1021/ac800110w; Jose KVJ, 2012, J CHEM PHYS, V136, DOI 10.1063/1.4712397; Kersting K., 2007, P 24 INT C MACH LEAR, P393, DOI 10.1145/1273496.1273546; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LECUN Y, 1998, LECT NOTES COMPUTER, V1524, P5; Lemm S, 2011, NEUROIMAGE, V56, P387, DOI 10.1016/j.neuroimage.2010.11.004; Lorenz S, 2004, CHEM PHYS LETT, V395, P210, DOI 10.1016/j.cplett.2004.07.076; Lorenz S, 2006, PHYS REV B, V73, DOI 10.1103/PhysRevB.73.115431; Manzhos S, 2006, J CHEM PHYS, V125, DOI 10.1063/1.2336223; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Mills MJL, 2011, COMPUT THEOR CHEM, V975, P42, DOI 10.1016/j.comptc.2011.04.004; MONTAVON G, 2013, NEW J PHYS IN PRESS; Montavon G, 2011, J MACH LEARN RES, V12, P2563; MONTAVON G, 2012, NEURAL NETWORKS TRIC, V7700; Montavon G, 2013, IEEE SIGNAL PROC MAG, V30, P62, DOI 10.1109/MSP.2013.2249294; Moussa JE, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.059801; Muller K., 2012, ADV NEURAL INFORM PR, V25, P449; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Muller KR, 1996, NEURAL COMPUT, V8, P1085, DOI 10.1162/neco.1996.8.5.1085; Muller KR, 2005, J CHEM INF MODEL, V45, P249, DOI 10.1021/ci049737o; OLLIFFE IT, 2002, PRINCIPAL COMPONENT; Perdew JP, 1996, PHYS REV LETT, V77, P3865, DOI 10.1103/PhysRevLett.77.3865; PINHEIRO JC, 2000, MIXED EFFECTS MODELS, pR7; Platt JC, 1998, ADV KERNEL METHODS S, P185; Pozun ZD, 2012, J CHEM PHYS, V136, DOI 10.1063/1.4707167; Rahimi A., 2008, ADV NEURAL INFORM PR, V20, P1177; RAPPE AK, 1992, J AM CHEM SOC, V114, P10024, DOI 10.1021/ja00051a040; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rupp M, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.059802; Rupp M, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.058301; Schelldorfer J, 2011, SCAND J STAT, V38, P197, DOI 10.1111/j.1467-9469.2011.00740.x; Scholkopf B., 2002, LEARNING KERNELS; Selassie C.D., 2003, BURGERS MED CHEM DRU, V1, P1; Snyder JC, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.253002; Stewart JJP, 2007, J MOL MODEL, V13, P1173, DOI 10.1007/s00894-007-0233-4; STONE M, 1974, J ROY STAT SOC, V36, P11; SUGIYAMA M, 2012, DENSITY RATION ESTIM, P119; SUMPTER BG, 1992, CHEM PHYS LETT, V192, P455, DOI 10.1016/0009-2614(92)85498-Y; TIBSHIRANI P, 1996, J R STAT SOC B, P267; VAPNIK V, 1998, STAT LEARNING THEORY, P443; Vapnik V. N., 1995, NATURE STAT LEARNING; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Zheng X, 2004, CHEM PHYS LETT, V390, P186, DOI 10.1016/j.cplett.2004.04.020	78	24	24	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9618	1549-9626		J CHEM THEORY COMPUT	J. Chem. Theory Comput.	AUG	2013	9	8					3404	3419		10.1021/ct400195d		16	Chemistry, Physical; Physics, Atomic, Molecular & Chemical	Chemistry; Physics	202DK	WOS:000323193500015		
J	Wang, YX; Wang, DL				Wang, Yuxuan; Wang, DeLiang			Towards Scaling Up Classification-Based Speech Separation	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Computational auditory scene analysis (CASA); deep belief networks; feature learning; monaural speech separation; support vector machines	REVERBERANT SPEECH; NEURAL-NETWORKS; SEGREGATION; NOISE; INTELLIGIBILITY; ALGORITHM; RECOGNITION; DIVERGENCE; LIBRARY	Formulating speech separation as a binary classification problem has been shown to be effective. While good separation performance is achieved in matched test conditions using kernel support vector machines (SVMs), separation in unmatched conditions involving new speakers and environments remains a big challenge. A simple yet effective method to cope with the mismatch is to include many different acoustic conditions into the training set. However, large-scale training is almost intractable for kernel machines due to computational complexity. To enable training on relatively large datasets, we propose to learn more linearly separable and discriminative features from raw acoustic features and train linear SVMs, which are much easier and faster to train than kernel SVMs. For feature learning, we employ standard pre-trained deep neural networks (DNNs). The proposed DNN-SVM system is trained on a variety of acoustic conditions within a reasonable amount of time. Experiments on various test mixtures demonstrate good generalization to unseen speakers and background noises.	[Wang, Yuxuan; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Wang, DeLiang] Ohio State Univ, Ctr Cognit Sci, Columbus, OH 43210 USA	Wang, YX (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	wangyuxu@cse.ohio-state.edu; dwang@cse.ohio-state.edu			Air Force Office of Scientific Research (AFOSR) [FA9550-12-1-0130]; Ohio Supercomputer Center	Manuscript received June 07, 2012; revised September 26, 2012; accepted February 21, 2013. Date of publication March 07, 2013; date of current version March 22, 2013. This work was supported in part by the Air Force Office of Scientific Research (AFOSR) under Grant (FA9550-12-1-0130), in part by an STTR subcontract from Kuzer, and in part by the Ohio Supercomputer Center. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Bryan Pardo.	[Anonymous], 1969, IEEE T AUDIO ELECTRO, VAU-17, P225; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Boersma P., 2005, PRAAT DOING PHONETIC; BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209; Bordes A, 2005, J MACH LEARN RES, V6, P1579; Bottou L, 2008, ADV NEURAL INFORM PR, V20, P161; Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Christensen H., 2010, P INTERSPEECH; Coates, 2011, P 28 INT C MACH LEAR; Coates A., 2011, P 14 INT C ART INT S; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Ephraim Y., 1984, ACOUSTICS SPEECH SIG, V32, P1109; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771; Garofolo JS, 1993, DARPA TIMIT ACOUSTIC; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; Hartmann W, 2011, INT CONF ACOUST SPEE, P4804; Hendriks RC, 2010, INT CONF ACOUST SPEE, P4266, DOI 10.1109/ICASSP.2010.5495680; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hu G., 2004, 100 NONSPEECH ENV SO; Hu GN, 2010, IEEE T AUDIO SPEECH, V18, P2067, DOI 10.1109/TASL.2010.2041110; Hu GN, 2008, J ACOUST SOC AM, V124, P1306, DOI 10.1121/1.2939132; Jin ZZ, 2011, IEEE T AUDIO SPEECH, V19, P1091, DOI 10.1109/TASL.2010.2077280; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Kim G, 2010, IEEE T AUDIO SPEECH, V18, P2080, DOI 10.1109/TASL.2010.2041116; Kim W, 2011, SPEECH COMMUN, V53, P1, DOI 10.1016/j.specom.2010.08.005; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Ozerov A, 2012, IEEE T AUDIO SPEECH, V20, P1118, DOI 10.1109/TASL.2011.2172425; Platt J., 1999, ADV LARGE MARGIN CLA, V10, P61; Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463; Seltzer ML, 2004, SPEECH COMMUN, V43, P379, DOI 10.1016/j.specom.2004.03.006; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598; Singh S, 2003, IEEE T PATTERN ANAL, V25, P1534, DOI 10.1109/TPAMI.2003.1251146; Tatti N, 2007, J MACH LEARN RES, V8, P131; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wang D., 2006, COMPUTATIONAL AUDITO; Wang Y., 2012, ADV NEURAL INF PROCE, V25, P224; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459	47	24	25	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	JUL	2013	21	7					1381	1390		10.1109/TASL.2013.2250961		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	116XC	WOS:000316915600006		
J	Nessler, B; Pfeiffer, M; Buesing, L; Maass, W				Nessler, Bernhard; Pfeiffer, Michael; Buesing, Lars; Maass, Wolfgang			Bayesian Computation Emerges in Generic Cortical Microcircuits through Spike-Timing-Dependent Plasticity	PLOS COMPUTATIONAL BIOLOGY			English	Article							LONG-TERM POTENTIATION; PRIMARY VISUAL-CORTEX; WINNER-TAKE-ALL; COOPER-MUNRO RULE; SYNAPTIC PLASTICITY; NEURAL-NETWORKS; EM ALGORITHM; INTRINSIC EXCITABILITY; NATURAL IMAGES; NEURONS	The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.	[Nessler, Bernhard; Pfeiffer, Michael; Buesing, Lars; Maass, Wolfgang] Graz Univ Technol, Inst Theoret Comp Sci, A-8010 Graz, Austria; [Pfeiffer, Michael] Univ Zurich, Inst Neuroinformat, Zurich, Switzerland; [Pfeiffer, Michael] Swiss Fed Inst Technol, Zurich, Switzerland	Nessler, B (reprint author), Graz Univ Technol, Inst Theoret Comp Sci, A-8010 Graz, Austria.	nessler@igi.tugraz.at			European Union [FP7-216593, FP7-269921, FP7-506778, FP7-243914]; Samsung Advanced Institute of Technology; University of Zurich	This work was written under partial support by project #FP7-216593 (SECO), project #FP7-506778 (PASCAL2), project #FP7-243914 (BRAIN-I-NETS) and project #FP7-269921 (BrainScaleS) of the European Union. MP has been supported by the Samsung Advanced Institute of Technology and a Forschungskredit grant of the University of Zurich. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453; Bi GQ, 1998, J NEUROSCI, V18, P10464; Binzegger T, 2007, J NEUROSCI, V27, P12242, DOI 10.1523/JNEUROSCI.3753-07.2007; Bishop CM, 2006, PATTERN RECOGNITION; Brea J., 2011, ADV NEURAL INF PROCE, V24, P1422; Buesing L, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002211; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; Celeux G., 1985, COMPUTATIONAL STATIS, V2, P73; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Clopath C, 2010, NAT NEUROSCI, V13, P344, DOI 10.1038/nn.2479; Cudmore RH, 2004, J NEUROPHYSIOL, V92, P341, DOI 10.1152/jn.01059.2003; Dan Y, 2004, NEURON, V44, P23, DOI 10.1016/j.neuron.2004.09.007; Daoudal G, 2003, LEARN MEMORY, V10, P456, DOI 10.1101/lm.64103; Dayan P., 2001, THEORETICAL NEUROSCI; Debanne Dominique, 2010, Front Synaptic Neurosci, V2, P21, DOI 10.3389/fnsyn.2010.00021; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; Deneve S, 2008, NEURAL COMPUT, V20, P118, DOI 10.1162/neco.2008.20.1.118; DESIMONE R, 1991, J COGNITIVE NEUROSCI, V3, P1, DOI 10.1162/jocn.1991.3.1.1; Destexhe A, 2001, NEUROSCIENCE, V107, P13, DOI 10.1016/S0306-4522(01)00344-X; de Villers-Sidani E, 2011, PROG BRAIN RES, V191, P119, DOI 10.1016/B978-0-444-53752-2.00009-6; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Doya K., 2007, BAYESIAN BRAIN PROBA; Ecker AS, 2010, SCIENCE, V327, P584, DOI 10.1126/science.1179867; Espinosa JS, 2012, NEURON, V75, P230, DOI 10.1016/j.neuron.2012.06.009; Faisal AA, 2008, NAT REV NEUROSCI, V9, P292, DOI 10.1038/nrn2258; Feldman DE, 2012, NEURON, V75, P556, DOI 10.1016/j.neuron.2012.08.001; Fino E, 2011, NEURON, V69, P1188, DOI 10.1016/j.neuron.2011.02.025; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Froemke RC, 2002, NATURE, V416, P433, DOI 10.1038/416433a; Gerstner W., 2002, SPIKING NEURON MODEL; Ghahramani Z, 1997, COMPUTATIONAL LEARNI, V4, P67; Gilbert CD, 2009, J PHYSIOL-LONDON, V587, P2743, DOI 10.1113/jphysiol.2009.171488; Gilbert CD, 2001, NEURON, V31, P681, DOI 10.1016/S0896-6273(01)00424-X; Gilson M, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002231; Gjorgjieva J, 2011, P NATL ACAD SCI USA, V108, P19383, DOI 10.1073/pnas.1105933108; Goard M, 2009, NAT NEUROSCI, V12, P1444, DOI 10.1038/nn.2402; Graupner M, 2012, P NATL ACAD SCI USA, V109, P3991, DOI 10.1073/pnas.1109359109; Griffiths TL, 2008, HDB COMPUTATIONAL CO, P59100; Griffiths TL, 2006, PSYCHOL SCI, V17, P767, DOI 10.1111/j.1467-9280.2006.01780.x; Grillner S, 2006, MICROCIRCUITS INTERF; Gupta A, 2007, IEEE IJCNN, P53, DOI 10.1109/IJCNN.2007.4370930; Gupta A, 2009, IEEE IJCNN, P1189; Gutig R, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000141; Habenschuss S., 2012, ADV NEURAL INF PROCE, V25, P782; Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072; Hebb DO, 1949, ORG BEHAV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jank W, 2006, PERSPECTIVES OPERATI, P367; Jin X, 2010, COMPUT SCI ENG, V12, P91; Jolivet R, 2006, J COMPUT NEUROSCI, V21, P35, DOI 10.1007/s10827-006-7074-5; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Keck C, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002432; Kempter R, 2001, NEURAL COMPUT, V13, P2709, DOI 10.1162/089976601317098501; Kempter R, 1999, PHYS REV E, V59, P4498, DOI 10.1103/PhysRevE.59.4498; Kerr JND, 2007, J NEUROSCI, V27, P13316, DOI 10.1523/JNEUROSCI.2210-07.2007; Kobayashi K, 2004, NEURON, V41, P445, DOI 10.1016/S0896-6273(03)00873-0; Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169; Kushner H., 2003, STOCHASTIC APPROXIMA, V35; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li Y, 2006, NAT NEUROSCI, V9, P676, DOI 10.1038/nn1684; LIAO D, 1992, NEURON, V9, P1089, DOI 10.1016/0896-6273(92)90068-O; Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790; Maass W, 2000, NEURAL COMPUT, V12, P2519, DOI 10.1162/089976600300014827; Maldonado P, 2008, J NEUROPHYSIOL, V100, P1523, DOI 10.1152/jn.00076.2008; Markov NT, 2011, CEREB CORTEX, V21, P1254, DOI 10.1093/cercor/bhq201; Masquelier T, 2009, NEURAL COMPUT, V21, P1259, DOI 10.1162/neco.2008.06-08-804; Masquelier T, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001377; Masquelier T, 2009, J NEUROSCI, V29, P13484, DOI 10.1523/JNEUROSCI.2207-09.2009; Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758; Montgomery JM, 2001, NEURON, V29, P691, DOI 10.1016/S0896-6273(01)00244-6; Morrison A, 2008, BIOL CYBERN, V98, P459, DOI 10.1007/s00422-008-0233-1; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Nessler B, 2009, P NIPS ADV NEURAL IN, V22, P1; Nessler B, 2009, P NIPS 2008 ADV NEUR, P21; Nikolic D, 2009, PLOS BIOL, V7, P1; Nowlan S, 1990, ADV NEURAL INFORMATI, V2, P574; Nowlan SJ, 1991, CS91126 CARN MELL U; Oaksford M., 2007, BAYESIAN RATIONALITY; Okun M, 2008, NAT NEUROSCI, V11, P535, DOI 10.1038/nn.2105; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639; Oster M, 2009, NEURAL COMPUT, V21, P2437, DOI 10.1162/neco.2009.07-08-829; Pecevski D, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002294; Pfeiffer M, 2010, NEURAL COMPUT, V22, P1399, DOI 10.1162/neco.2010.03-09-980; Pfister JP, 2006, NEURAL COMPUT, V18, P1318, DOI 10.1162/neco.2006.18.6.1318; Poon H, 2011, COMP VIS WORKSH ICCV, P689; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Rao RP, 2005, ADV NEURAL INFORM PR, V17, P1113; Rao RPN, 2007, BAYESIAN BRAIN PROBA, P239; Rao RPN, 2002, PROBABILISTIC MODELS; Rezende D., 2011, ADV NEURAL INF PROCE, V24, P136; Rumelhart DE, 1988, CONNECTIONIST MODELS, P205; Rutishauser U, 2009, NEURAL COMPUT, V21, P478, DOI 10.1162/neco.2008.03-08-734; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Sato M, 1999, TECHNICAL REPORT; Sato M, 2000, NEURAL COMPUT, V12, P407, DOI 10.1162/089976600300015853; Savin C, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000757; Schemmel J, 2007, IEEE INT SYMP CIRC S, P3367, DOI 10.1109/ISCAS.2007.378289; Schmiedt J.-T., 2010, ADV NEURAL INFORM PR, V23, P2110, DOI [10.3389/conf.fncom.2010.51.00084, DOI 10.3389/C0NF.FNC0M.2010.51.00084]; Sjostrom PJ, 2001, NEURON, V32, P1149, DOI 10.1016/S0896-6273(01)00542-6; Song S, 2000, NAT NEUROSCI, V3, P919; Song S, 2001, NEURON, V32, P339, DOI 10.1016/S0896-6273(01)00451-2; Toyoizumi T, 2005, P NATL ACAD SCI USA, V102, P5239, DOI 10.1073/pnas.0500495102; Turrigiano G, 2011, ANNU REV NEUROSCI, V34, P89, DOI 10.1146/annurev-neuro-060909-153238; Uhlhaas PJ, 2010, TRENDS COGN SCI, V14, P72, DOI 10.1016/j.tics.2009.12.002; Uhlhaas Peter J, 2009, Front Integr Neurosci, V3, P17, DOI 10.3389/neuro.07.017.2009; Zemel R, 2005, ADV NEURAL INFORM PR, V17, P1609	113	24	24	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-7358			PLOS COMPUT BIOL	PLoS Comput. Biol.	APR	2013	9	4							e1003037	10.1371/journal.pcbi.1003037		30	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	132LN	WOS:000318069800036	23633941	
J	Bo, LF; Ren, XF; Fox, D			IEEE	Bo, Liefeng; Ren, Xiaofeng; Fox, Dieter			Depth Kernel Descriptors for Object Recognition	2011 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS	IEEE International Conference on Intelligent Robots and Systems		English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems	SEP 25-30, 2011	San Francisco, CA	IEEE, Robot Soc Japan (RSJ), BOSCH, HONDA, KUKA, SRI Int, ABB, Willow Garage, ALDEBARAN, Google, INTUITIVE Surg, SCHUNK, IEEE Ind Elect Soc (IES), Soc Instrument & Control Engineers (SICE), New Technol Fdn (NTF), IEEE Robot & Automat Soc (RAS), Inst Control, Robto & Syst (ICROS)				Consumer depth cameras, such as the Microsoft Kinect, are capable of providing frames of dense depth values at real time. One fundamental question in utilizing depth cameras is how to best extract features from depth frames. Motivated by local descriptors on images, in particular kernel descriptors, we develop a set of kernel features on depth images that model size, 3D shape, and depth edges in a single framework. Through extensive experiments on object recognition, we show that (1) our local features capture different aspects of cues from a depth frame/view that complement one another; (2) our kernel features significantly outperform traditional 3D features (e. g. Spin images); and (3) we significantly improve the capabilities of depth and RGB-D (color+depth) recognition, achieving 10-15% improvement in accuracy over the state of the art.	[Bo, Liefeng; Fox, Dieter] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Bo, LF (reprint author), Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.	lfb@cs.washington.edu; xiaofeng.ren@intel.com; fox@cs.washington.edu					Bo L, 2010, ADV NEURAL INFORM PR; Bo L., 2009, ADV NEURAL INFORM PR; Bo L., 2011, IEEE INT C COMP VIS; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang Chih-Chung, 2001, LIBVSM LIB SUPPORT V; Coates A., 2011, ICML; Deng J., 2009, IEEE INT C COMP VIS; Drost Bertram, 2010, IEEE INT C COMP VIS; Endres F., 2009, ROB SCI SYST C; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Johnson A., 1999, IEEE T PATTERN ANAL, V21; Lai K., 2010, INT J ROBOTICS RES; Lai K., 2011, IEEE INT C ROB AUT; Lazebnik S., 2006, IEEE INT C COMP VIS; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN; Lin Y., 2011, IEEE C COMP VIS PATT; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Microsoft, MICR KIN; Rusu R.B., 2009, IEEE INT C ROB AUT; Shalev-Shwartz S., 2007, ICML 07, P807; Shotton Jamie, 2011, IEEE INT C COMP VIS; Steder B., 2011, IEEE INT C ROB AUT; Wang J., 2010, IEEE INT C COMP VIS	25	23	23	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0858		978-1-61284-455-8	IEEE INT C INT ROBOT			2011							821	826				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BXX70	WOS:000297477501026		
J	Shao, L; Liu, L; Li, XL				Shao, Ling; Liu, Li; Li, Xuelong			Feature Learning for Image Classification via Multiobjective Genetic Programming	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Feature extraction; genetic programming (GP); image classification; multiobjective optimization	OBJECT RECOGNITION; FEATURE-EXTRACTION; SCENE; RETRIEVAL; CONTEXT; CORTEX; SHAPE	Feature extraction is the first and most critical step in image classification. Most existing image classification methods use hand-crafted features, which are not adaptive for different image domains. In this paper, we develop an evolutionary learning methodology to automatically generate domain-adaptive global feature descriptors for image classification using multiobjective genetic programming (MOGP). In our architecture, a set of primitive 2-D operators are randomly combined to construct feature descriptors through the MOGP evolving and then evaluated by two objective fitness criteria, i.e., the classification error and the tree complexity. After the entire evolution procedure finishes, the best-so-far solution selected by the MOGP is regarded as the (near-)optimal feature descriptor obtained. To evaluate its performance, the proposed approach is systematically tested on the Caltech-101, the MIT urban and nature scene, the CMU PIE, and Jochen Triesch Static Hand Posture II data sets, respectively. Experimental results verify that our method significantly outperforms many state-of-the-art hand-designed features and two feature learning techniques in terms of classification accuracy.	[Shao, Ling] Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China; [Shao, Ling; Liu, Li] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, State Key Lab Transient Opt & Photon, Ctr OPT IMagery Anal & Learning, Xian 710119, Peoples R China	Shao, L (reprint author), Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.	ling.shao@sheffield.ac.uk; elp11ll@sheffield.ac.uk; xuelong_li@opt.ac.uk			University of Sheffield; National Natural Science Foundation of China [61125106, 91120302]; Shaanxi Key Innovation Team of Science and Technology [2012KCT-04]	This work was supported in part by The University of Sheffield, in part by the National Natural Science Foundation of China under Grant 61125106 and Grant 91120302, and in part by the Shaanxi Key Innovation Team of Science and Technology under Grant 2012KCT-04.	Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469; Atkins D, 2011, IEEE C EVOL COMPUTAT, P238; Bai Y., 2009, P 16 IEEE INT C IM P, P3305; Belongie S, 2001, ADV NEUR IN, V13, P831; Bot MCJ, 2001, LECT NOTES COMPUT SC, V2038, P256; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Dalal N, 2005, PROC CVPR IEEE, P886; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Fogel DB, 2000, IEEE SPECTRUM, V37, P26, DOI 10.1109/6.819926; Guo H, 2005, IEEE T SYST MAN CY B, V35, P89, DOI 10.1109/TSMCB.2004.841426; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jain M., 2012, INT J ADV RES COMPUT, V2, P252; Korenblum D, 2011, J DIGIT IMAGING, V24, P739, DOI 10.1007/s10278-010-9328-z; Koza J. R., 1992, P 1 EUR C ART LIF, P110; Koza J. R., 2005, SEARCH METHODOLOGIES, P127, DOI 10.1007/0-387-28356-0_5; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Li L, 2007, P IEEE INT C COMP VI, P1; Liddle T., 2010, P IEEE C EV COMP, P1; Liu L., 2013, P 21 ACM INT C MULT, P997; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luke S., 2002, P GEN EV COMP C, P829; Martin D., 2001, P 8 INT C COMP VIS, V2, P416, DOI 10.1109/ICCV.2001.937655; Olague G, 2012, APPL SOFT COMPUT, V12, P2566, DOI 10.1016/j.asoc.2012.03.058; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Poli R., 1996, P 1 ANN C GEN PROGR, P363; Poli R., 2008, FIELD GUIDE GENETIC; Ranhel J, 2012, IEEE T NEUR NET LEAR, V23, P916, DOI 10.1109/TNNLS.2012.2190421; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Sherrah J., 1996, P AUSTR NZ C INT INF, P284; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sim T., 2002, P IEEE INT C AUT FAC, P46, DOI DOI 10.1109/AFGR.2002.1004130; Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939; TACKETT WA, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P303; Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010; Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vogel J, 2004, LECT NOTES COMPUT SC, V3175, P195; Wang P, 2012, IEEE T NEUR NET LEAR, V23, P33, DOI 10.1109/TNNLS.2011.2178324; Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620; Watchareeruetai U, 2010, IEICE T INF SYST, VE93D, P2614, DOI 10.1587/transinf.E93.D.2614; Wei H, 2012, IEEE T NEUR NET LEAR, V23, P150, DOI 10.1109/TNNLS.2011.2178472; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Zhang Y, 2006, STUD COMP INTELL, V16, P75	46	22	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	JUL	2014	25	7					1359	1371		10.1109/TNNLS.2013.2293418		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	AJ7VF	WOS:000337906300010		
J	Saon, G; Chien, JT				Saon, George; Chien, Jen-Tzung			Large-Vocabulary Continuous Speech Recognition Systems	IEEE SIGNAL PROCESSING MAGAZINE			English	Article							HIDDEN MARKOV-MODELS; CONVERSATIONAL TELEPHONE SPEECH; BROADCAST NEWS TRANSCRIPTION; MAXIMUM-LIKELIHOOD; SPEAKER ADAPTATION; LANGUAGE MODELS; LINEAR-REGRESSION; FEATURES; TRANSFORMS; ERROR		[Chien, Jen-Tzung] Natl Cheng Kung Univ, Tainan 70101, Taiwan; [Chien, Jen-Tzung] Natl Chiao Tung Univ, Dept Elect & Comp Engn, Taipei, Taiwan		gsaon@us.ibm.com; jtchien@nctu.edu.tw	Magazine, Signal Processing/E-9947-2015				Acero Alex, 2000, P ICSLP, P869; Axelrod S, 2002, P ICSLP, P2177; Bahl L. R., 1986, P IEEE INT C AC SPEE, P49; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P78, DOI 10.1109/MSP.2009.932707; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Bishop CM, 2006, PATTERN RECOGNITION; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056; Brown P. F., 1992, Computational Linguistics, V18; Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147; Chen JC, 2009, INT CONF ACOUST SPEE, P3765, DOI 10.1109/ICASSP.2009.4960446; Chen K., 2000, P INT C SPOK LANG PR, P742; Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128; Chen S.F., 2003, P EUR C SPEECH COMM, P1169; Chen SF, 2006, IEEE T AUDIO SPEECH, V14, P1596, DOI 10.1109/TASL.2006.879814; Chen S.F, 2009, P HLT NAACL, P468, DOI 10.3115/1620754.1620822; Chien JT, 2010, SPEECH COMMUN, V52, P223, DOI 10.1016/j.specom.2009.10.003; Chien JT, 2006, IEEE T AUDIO SPEECH, V14, P1719, DOI 10.1109/TSA.2005.858551; Chien JT, 2006, IEEE T AUDIO SPEECH, V14, P797, DOI 10.1109/TSA.2005.860847; Chien JT, 2011, IEEE T AUDIO SPEECH, V19, P482, DOI 10.1109/TASL.2010.2050717; Chien JT, 2005, IEEE T SPEECH AUDI P, V13, P377, DOI 10.1109/TSA.2005.845810; Chu SM, 2010, INT CONF ACOUST SPEE, P4374, DOI 10.1109/ICASSP.2010.5495639; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DENG L, 2000, P ICSLP, P806; Evermann G., 2004, P IEEE ICASSP MONTR, P249; Evermann G., 2000, P SPEECH TRANSCR WOR; Fiscus J. G., 1997, P IEEE WORKSH AUT SP, P347; Fox EB, 2010, IEEE SIGNAL PROC MAG, V27, P43, DOI 10.1109/MSP.2010.937999; Furui S., 1997, P ESCA NATO TUT RES, P11; FURUI S, 1986, IEEE T ACOUST SPEECH, V34, P52, DOI 10.1109/TASSP.1986.1164788; Gales MJF, 2002, IEEE T SPEECH AUDI P, V10, P37, DOI 10.1109/89.985541; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Gales MJF, 1996, IEEE T SPEECH AUDI P, V4, P352, DOI 10.1109/89.536929; Gales MJF, 2006, IEEE T AUDIO SPEECH, V14, P1513, DOI 10.1109/TASL.2006.878264; Gales MJF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P58; Gildea D., 1999, P EUROSPEECH, P2167; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Gunawardana A., 2001, P EUR C SPEECH COMM, P1203; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; Hilger F, 2006, IEEE T AUDIO SPEECH, V14, P845, DOI 10.1109/TSA.2005.857792; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang SF, 2010, IEEE T AUDIO SPEECH, V18, P1941, DOI 10.1109/TASL.2010.2040782; Jiang H, 2006, IEEE T AUDIO SPEECH, V14, P1584, DOI 10.1109/TASL.2006.879805; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257; Kanthak S., 2002, P INT C SPOK LANG PR, P1309; Kingsbury B, 2011, INT CONF ACOUST SPEE, P4672; KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394; Kuhn R, 2000, IEEE T SPEECH AUDI P, V8, P695, DOI 10.1109/89.876308; Kumar N, 1998, SPEECH COMMUN, V26, P283, DOI 10.1016/S0167-6393(98)00061-2; Kuo HKJ, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P327, DOI 10.1109/ASRU.2009.5373470; Lamel L., 2007, P INT 2007 ANTW, P2077; Lamel L, 2002, COMPUT SPEECH LANG, V16, P115, DOI 10.1006/csla.2001.0186; Lee L, 1998, IEEE T SPEECH AUDI P, V6, P49, DOI 10.1109/89.650310; LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010; Li JY, 2007, IEEE T AUDIO SPEECH, V15, P2393, DOI 10.1109/TASL.2007.906178; Liao H, 2008, SPEECH COMMUN, V50, P265, DOI 10.1016/j.specom.2007.10.004; Mangu L., 2011, P IEEE AUT SPEECH RE, P272; Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152; Matsoukas S, 2006, IEEE T AUDIO SPEECH, V14, P1541, DOI 10.1109/TASL.2006.878257; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184; Ng T, 2009, INT CONF ACOUST SPEE, P4309; Noamany M., 2007, P NAACL HLT 2007 ROC, P129; Olsen PA, 2004, IEEE T SPEECH AUDI P, V12, P37, DOI 10.1109/TSA.2003.819943; Padmanabhan M., 2000, P ISCA ITRW ASR2000, P128; Plahl C., 2009, P ANN C INT SPEECH C, P2307; Povey D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1145; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Povey D, 2005, INT CONF ACOUST SPEE, P961; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Povey D, 2011, COMPUT SPEECH LANG, V25, P404, DOI 10.1016/j.csl.2010.06.003; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Reichl W., 1995, P EUR C SPEECH COMM, P537; Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011; Sainath TN, 2011, IEEE T AUDIO SPEECH, V19, P2598, DOI 10.1109/TASL.2011.2155060; Saon G., 2004, P IEEE INT C AC SPEE, P329; SAON G, 2000, ACOUST SPEECH SIG PR, P1129; Saon G, 2012, SPEECH COMMUN, V54, P212, DOI 10.1016/j.specom.2011.07.011; Saon G, 2010, INT CONF ACOUST SPEE, P4378, DOI 10.1109/ICASSP.2010.5495640; Saon G., 2003, P EUR, P1977; Saon G., 2005, P INTERSPEECH, P549; Saon G, 2012, IEEE T AUDIO SPEECH, V20, P43, DOI 10.1109/TASL.2011.2129911; Saon G, 2011, INT CONF ACOUST SPEE, P5056; Saon G, 2011, INT CONF ACOUST SPEE, P5316; Saon G, 2009, INT CONF ACOUST SPEE, P3753, DOI 10.1109/ICASSP.2009.4960443; Saon G, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P920; Saon G., 2011, P IEEE AUT SPEECH RE, P65; Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003; Seide F., 2011, P INTERSPEECH, P437; Sha F, 2007, INT CONF ACOUST SPEE, P313; Sinha R., 2006, P INT C AC SPEECH SI, P14; Sinha R., 2006, P NIST LVCSR WORKSH, P14; Siohan O, 2005, INT CONF ACOUST SPEE, P197; Soltau H, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P276, DOI 10.1109/ASRU.2009.5372904; Soltau H, 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), DOI 10.1109/SLT.2010.5700829; Soltau H, 2009, IEEE T AUDIO SPEECH, V17, P884, DOI 10.1109/TASL.2009.2022966; Stolcke A, 2006, IEEE T AUDIO SPEECH, V14, P1729, DOI 10.1109/TASL.2006.879807; Tam Y. C., 2005, P INTERSPEECH, P5; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vergyri D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1437; Wang L, 2008, COMPUT SPEECH LANG, V22, P256, DOI 10.1016/j.csl.2007.09.001; Watanabe S, 2004, IEEE T SPEECH AUDI P, V12, P365, DOI 10.1109/TSA.2004.828640; Wegmann S, 1996, INT CONF ACOUST SPEE, P339, DOI 10.1109/ICASSP.1996.541101; Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824; Zhang B, 2006, INT CONF ACOUST SPEE, P313; Zhang Y, 2009, INT CONF ACOUST SPEE, P3857; Zheng J., 2005, P INT, P2125; Zweig G, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P152, DOI 10.1109/ASRU.2009.5372916; Zweig G, 2004, ADV COMPUT, V60, P249, DOI 10.1016/S0065-2458(03)60007-0	117	22	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888			IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	NOV	2012	29	6					18	33		10.1109/MSP.2012.2197156		16	Engineering, Electrical & Electronic	Engineering	027IF	WOS:000310345000005		
J	Goodman, ND; Ullman, TD; Tenenbaum, JB				Goodman, Noah D.; Ullman, Tomer D.; Tenenbaum, Joshua B.			Learning a Theory of Causality	PSYCHOLOGICAL REVIEW			English	Article						learning; nativism; causality; probabilistic models; blessing of abstraction	BAYESIAN MODELS; PERCEPTION; INFANCY; NETS	The very early appearance of abstract knowledge is often taken as evidence for innateness. We explore the relative learning speeds of abstract and specific knowledge within a Bayesian framework and the role for innate structure. We focus on knowledge about causality, seen as a domain-general intuitive theory, and ask whether this knowledge can be learned from co-occurrence of events. We begin by phrasing the causal Bayes nets theory of causality and a range of alternatives in a logical language for relational theories. This allows us to explore simultaneous inductive learning of an abstract theory of causality and a causal model for each of several causal systems. We find that the correct theory of causality can be learned relatively quickly, often becoming available before specific causal theories have been learned-an effect we term the blessing of abstraction. We then explore the effect of providing a variety of auxiliary evidence and find that a collection of simple perceptual input analyzers can help to bootstrap abstract knowledge. Together, these results suggest that the most efficient route to causal knowledge may be to build in not an abstract notion of causality but a powerful inductive learning mechanism and a variety of perceptual supports. While these results are purely computational, they have implications for cognitive development, which we explore in the conclusion.	[Goodman, Noah D.] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA; [Goodman, Noah D.; Ullman, Tomer D.; Tenenbaum, Joshua B.] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA	Goodman, ND (reprint author), Stanford Univ, Dept Psychol, Jordan Hall 01-420,450 Serra Mall, Stanford, CA 94305 USA.	ngoodman@stanford.edu			J. S. McDonnell Foundation Causal Learning Collaborative Initiative, Office of Naval Research [N00014-09-0124]; Air Force Office of Scientific Research [FA9550-07-1-0075]; Army Research Office [W911NF-08-1-0242]	We would like to thank Jim Woodward and Mike Oaksford for helpful comments and discussion. This work was supported by the J. S. McDonnell Foundation Causal Learning Collaborative Initiative, Office of Naval Research Grant N00014-09-0124, Air Force Office of Scientific Research Grant FA9550-07-1-0075, and Army Research Office Grant W911NF-08-1-0242.	Bonawitz EB, 2010, COGNITION, V115, P104, DOI 10.1016/j.cognition.2009.12.001; Carey S., 2009, ORIGIN CONCEPTS; Cheng PW, 1997, PSYCHOL REV, V104, P367, DOI 10.1037//0033-295X.104.2.367; Gelman A., 1995, BAYESIAN DATA ANAL; Gergely G, 2003, TRENDS COGN SCI, V7, P287, DOI 10.1016/S1364-6613(03)00128-1; GOODMAN ND, 2007, PROBABILISTIC MIND P, P377; Gopnik A, 2004, PSYCHOL REV, V111, P3, DOI 10.1037/0033-295X.111.1.3; Griffiths T. L., 2005, COGNITIVE PSYCHOL, V51, P285; Griffiths TL, 2009, PSYCHOL REV, V116, P661, DOI 10.1037/a0017201; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUME D, 2008, ENQUIRY CONCERNING H; Kemp C., 2007, P 29 ANN C COGN SCI, P389; Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x; KEMP C, 2008, P 30 ANN C COGN SCI, P1601; Lu HJ, 2008, PSYCHOL REV, V115, P955, DOI 10.1037/a0013256; MacKay D., 2003, INFORM THEORY INFERE; Waldmann MR, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1102; Pearl J., 2000, CASUALITY MODELS REA; Saxe R, 2006, ACTA PSYCHOL, V123, P144, DOI 10.1016/j.actpsy.2006.05.005; Schulz L., 2007, CAUSAL LEARNING PSYC, P37; Spelke ES, 1998, INFANT BEHAV DEV, V21, P181, DOI 10.1016/S0163-6383(98)90002-9; Steyvers M, 2003, COGNITIVE SCI, V27, P453, DOI 10.1016/S0364-0213(03)00010-7; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Tenenbaum JB, 2007, CAUSAL LEARNING PSYC, P301, DOI DOI 10.1093/ACPROF:OSO/9780195176803.003.0020; Ullman T. D., 2010, P 32 ANN C COGN SCI, P2840; Wellman H.M., 1998, HDB CHILD PSYCHOL, V2, P523; White PA, 2009, PSYCHOL REV, V116, P580, DOI 10.1037/a0016337; Woodward J., 2003, MAKING THINGS HAPPEN	28	22	22	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0033-295X			PSYCHOL REV	Psychol. Rev.	JAN	2011	118	1					110	119		10.1037/a0021336		10	Psychology; Psychology, Multidisciplinary	Psychology	711BK	WOS:000286560500007	21244189	
J	Li, P; Wang, M; Cheng, J; Xu, CS; Lu, HQ				Li, Peng; Wang, Meng; Cheng, Jian; Xu, Changsheng; Lu, Hanqing			Spectral Hashing With Semantically Consistent Graph for Image Indexing	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Graph Laplacian; metric learning; similarity search; spectral hashing	APPROXIMATE NEAREST-NEIGHBOR; VIDEO ANNOTATION; DIMENSIONALITY; RETRIEVAL; ALGORITHM	The ability of fast similarity search in a large-scale dataset is of great importance to many multimedia applications. Semantic hashing is a promising way to accelerate similarity search, which designs compact binary codes for a large number of images so that semantically similar images are mapped to close codes. Retrieving similar neighbors is then simply accomplished by retrieving images that have codes within a small Hamming distance of the code of the query. Among various hashing approaches, spectral hashing (SH) has shown promising performance by learning the binary codes with a spectral graph partitioning method. However, the Euclidean distance is usually used to construct the graph Laplacian in SH, which may not reflect the inherent distribution of the data. Therefore, in this paper, we propose a method to directly optimize the graph Laplacian. The learned graph, which can better represent similarity between samples, is then applied to SH for effective binary code learning. Meanwhile, our approach, unlike metric learning, can automatically determine the scale factor during the optimization. Extensive experiments are conducted on publicly available datasets and the comparison results demonstrate the effectiveness of our approach.	[Li, Peng; Cheng, Jian; Xu, Changsheng; Lu, Hanqing] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Wang, Meng] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China	Li, P (reprint author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.	pli@nlpr.ia.ac.cn; eric.mengwang@gmail.com; jcheng@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn; luhq@nlpr.ia.ac.cn			973 Program [2010CB327905]; National Natural Science Foundation of China [61170127, 60975010, 60833006, 61070104]	This work was supported in part by the 973 Program under Project 2010CB327905, by the National Natural Science Foundation of China under Grant 61170127, 60975010, 60833006, and 61070104. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Xian-Sheng Hua.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Chua T.-S., 2009, P ACM INT C IM VID R; Chung F. R. K., 1997, AM MATH SOC; Cormen T. H., 2001, INTRO ALGORITHMS, V2nd; Datar M., 2004, P 20 ANN S COMP GEOM, P253, DOI 10.1145/997817.997857; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Frome A., 2007, P IEEE INT C COMP VI, P1; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Goldberger J., 2005, P ADV NEUR INF PROC, P1; He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jain Prateek, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1145/1452567.1452569; Jiang Y., 2011, P 1 ACM INT C MULT R; Jin R, 2009, PROC CVPR IEEE, P896; Joachims T., 2003, P 20 INT C MACH LEAR, P1; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Liu T., 2007, P 8 IEEE WORKSH APPL; Liu W., 2011, P 28 INT C MACH LEAR; Mu Y., 2011, P 1 ACM INT C MULT R; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Ng A. Y., 2003, P ADV NEUR INF PROC, P1; Qi G.-J., 2009, P 17 ACM INT C MULT, P243, DOI 10.1145/1631272.1631307; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schapire R.E., 2002, P MSRI WORKSH NONL E; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Silpa-Anan C., 2008, P IEEE C COMP VIS PA, P1, DOI [DOI 10.1109/CVPR.2008.4587638, 10.1109/CVPR.2008.4587638]; Stein B., 2007, P 30 ANN INT ACM SIG, P527, DOI 10.1145/1277741.1277832; Torralba A, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2008.4587633; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672; Wang J., 2010, P INT C MACH LEARN; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400; Wang M, 2009, COMPUT VIS IMAGE UND, V113, P384, DOI 10.1016/j.cviu.2008.08.003; Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045; Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919; Wang S., 2010, P ACM INT C MULT; Wang X.-J., 2006, P IEEE C COMP VIS PA, P1483; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Weinberger K., 2005, PRODUCTION ENG RES D, P1; Weiss Y., 2008, P ADV NEUR INF PROC, V21, P1753; Zhang D, 2004, PATTERN RECOGN, P1; Zhang H., 2006, IEEE INT C COMP VIS, V2, P2126; Zhou D., 2010, P 33 INT ACM SIGIR C, P18	49	21	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210	1941-0077		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	JAN	2013	15	1					141	152		10.1109/TMM.2012.2199970		12	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	058PS	WOS:000312646600012		
J	Bo, LF; Lai, K; Ren, XF; Fox, D			IEEE	Bo, Liefeng; Lai, Kevin; Ren, Xiaofeng; Fox, Dieter			Object Recognition with Hierarchical Kernel Descriptors	2011 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 20-25, 2011	Colorado Springs, CO	IEEE			IMAGES; SCALE	Kernel descriptors [1] provide a unified way to generate rich visual feature sets by turning pixel attributes into patch-level features, and yield impressive results on many object recognition tasks. However, best results with kernel descriptors are achieved using efficient match kernels in conjunction with nonlinear SVMs, which makes it impractical for large-scale problems. In this paper, we propose hierarchical kernel descriptors that apply kernel descriptors recursively to form image-level features and thus provide a conceptually simple and consistent way to generate image-level features from pixel attributes. More importantly, hierarchical kernel descriptors allow linear SVMs to yield state-of-the-art accuracy while being scalable to large datasets. They can also be naturally extended to extract features over depth images. We evaluate hierarchical kernel descriptors both on the CIFAR10 dataset and the new RGB-D Object Dataset consisting of segmented RGB and depth images of 300 everyday objects.	[Bo, Liefeng; Lai, Kevin; Fox, Dieter] Univ Washington, Seattle, WA 98195 USA	Bo, LF (reprint author), Univ Washington, Seattle, WA 98195 USA.	lfb@cs.washington.edu; kevinlai@cs.washington.edu; xiaofeng.ren@intel.com; fox@cs.washington.edu					Bo L., 2010, NIPS; Bo L., 2009, NIPS; Carreira-Perpinan M., 2005, AISTATS, P1729; Coates A., 2010, NIPS 2010 WORKSH DEE; Dalal N., 2005, CVPR; DENG J, 2009, CVPR; Felzenszwalb P, 2009, IEEE T PATTERN ANAL, V32, P1627, DOI DOI 10.1109/TPAMI.2009.167; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hua G., 2007, ICCV; Jarrett K., 2009, ICCV; Johnson A., 1999, IEEE PAMI, V21; Kavukcuoglu K., 2009, CVPR; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Lai K., 2011, IEEE INT C ROB AUT; Le Q. V., 2010, NIPS; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ICML; Lee H., 2006, NIPS, P801; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Philbin J., 2010, ECCV; Ranzato M., 2010, CVPR; Ranzato M., 2010, AISTATS; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wang J., 2010, CVPR; Y C., 2009, NIPS, P1730; Yang J., 2009, CVPR; Yu K., 2010, ICML, P1215; Yu K., 2009, NIPS	31	21	21	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4577-0393-5	PROC CVPR IEEE			2011							1729	1736				8	Computer Science, Artificial Intelligence	Computer Science	BXB85	WOS:000295615801103		
J	Bengio, Y; Delalleau, O				Bengio, Yoshua; Delalleau, Olivier			Justifying and Generalizing Contrastive Divergence	NEURAL COMPUTATION			English	Article								We study an expansion of the log likelihood in undirected graphical models such as the restricted Boltzmann machine (RBM), where each term in the expansion is associated with a sample in a Gibbs chain alternating between two random variables (the visible vector and the hidden vector in RBMs). We are particularly interested in estimators of the gradient of the log likelihood obtained through this expansion. We show that its residual term converges to zero, justifying the use of a truncation-running only a short Gibbs chain, which is the main idea behind the contrastive divergence (CD) estimator of the log-likelihood gradient. By truncating even more, we obtain a stochastic reconstruction error, related through a mean-field approximation to the reconstruction error often used to train autoassociators and stacked autoassociators. The derivation is not specific to the particular parametric forms used in RBMs and requires only convergence of the Gibbs chain. We present theoretical and empirical evidence linking the number of Gibbs steps k and the magnitude of the RBM parameters to the bias in the CD estimator. These experiments also suggest that the sign of the CD estimator is correct most of the time, even when the bias is large, so that CD-k is a good descent direction even for small k.	[Bengio, Yoshua; Delalleau, Olivier] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada	Bengio, Y (reprint author), Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada.	bengioy@iro.umontreal.ca; delallea@iro.umontreal.ca					Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Freund Y., 1994, UCSCCRL9425; Hernandez-Lerma O., 2003, MARKOV CHAINS INVARI; Hinton G., 1999, P 9 INT C ART NEUR N, V1, P1; Hinton G, 1986, PARALLEL DISTRIBUTED, V1; Hinton G. E., 1994, ADV NEURAL INFORMATI, V6, P3; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1984, TRCMUCS84119 DEP COM; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Japkowicz N, 2000, NEURAL COMPUT, V12, P531, DOI 10.1162/089976600300015691; Larochelle H., 2007, 24 INT C MACH LEARN, P473; MACKAY D, 2001, FAILURES ONE S UNPUB; Ranzato M., 2007, ADV NEURAL INFORM PR, V19; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2007, P 2007 WORKSH INF RE; SCHMIDT V, 2006, LECT NOTES SUMMER 20; SCHWENK H, 1995, ADV NEURAL INFORMATI, V7, P991; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; TIELEMAN T, 2008, P INT C MACH LEARN, V25, P1064; Welling M., 2005, ADV NEURAL INFORM PR, V17; Yuille A., 2005, ADV NEURAL INFORM PR, V17, P1593	26	21	22	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JUN	2009	21	6					1601	1621		10.1162/neco.2008.11-07-647		21	Computer Science, Artificial Intelligence	Computer Science	449VS	WOS:000266359000005	19018704	
J	Huang, GB; Lee, H; Learned-Miller, E			IEEE	Huang, Gary B.; Lee, Honglak; Learned-Miller, Erik			Learning Hierarchical Representations for Face Verification with Convolutional Deep Belief Networks	2012 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 16-21, 2012	Providence, RI	IEEE			RECEPTIVE-FIELD PROPERTIES; CLASSIFICATION	Most modern face recognition systems rely on a feature representation given by a hand-crafted image descriptor, such as Local Binary Patterns (LBP), and achieve improved performance by combining several such representations. In this paper, we propose deep learning as a natural source for obtaining additional, complementary representations. To learn features in high-resolution images, we make use of convolutional deep belief networks. Moreover, to take advantage of global structure in an object class, we develop local convolutional restricted Boltzmann machines, a novel convolutional learning model that exploits the global structure by not assuming stationarity of features across the image, while maintaining scalability and robustness to small misalignments. We also present a novel application of deep learning to descriptors other than pixel intensity values, such as LBP. In addition, we compare performance of networks trained using unsupervised learning against networks with random filters, and empirically show that learning weights not only is necessary for obtaining good multi-layer representations, but also provides robustness to the choice of the network architecture parameters. Finally, we show that a recognition system using only representations obtained from deep learning can achieve comparable accuracy with a system using a combination of hand-crafted image descriptors. Moreover, by combining these representations, we achieve state-of-the-art results on a real-world face verification database.	[Huang, Gary B.; Learned-Miller, Erik] Univ Massachusetts, Amherst, MA 01003 USA	Huang, GB (reprint author), Univ Massachusetts, Amherst, MA 01003 USA.	gbhuang@cs.umass.edu; honglak@eecs.umich.edu; elm@cs.umass.edu					Bengio Y., 2007, NIPS; Boureau Y.L., 2010, CVPR; Cao Z., 2010, CVPR; Chapelle O., 2006, SEMISUPERVISED LEARN; Davis J. V., 2007, ICML; Doi E, 2003, NEURAL COMPUT, V15, P397, DOI 10.1162/089976603762552960; Goodfellow I. J., 2009, NIPS, V22; Guillaumin M., 2009, ICCV; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang G. B., 2007, 0749 U MASS; Jarrett K., 2009, ICCV; Kumar N., 2009, ICCV; Larochelle H., 2007, ICML; Lee H., 2009, ICML; Lee H., 2007, NIPS; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nair V., 2010, ICML; Nguyen H. V., 2010, ACCV; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pinto N., 2011, AUTOMATIC FACE GESTU; Pinto N., 2009, CVPR; Raina R., 2007, ICML; Ranzato M., 2007, NIPS; Ranzato M., 2011, CVPR; Ranzato M., 2010, CVPR; Ranzato M., 2007, CVPR; Ranzato M., 2006, NIPS; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Saxe A., 2011, ICML; Sohn K., 2011, ICCV; Sonnenburg S, 2010, J MACH LEARN RES, V11, P1799; Susskind J., 2011, CVPR; Welling M., 2003, NIPS; Wolf L., 2009, ACCV; Yang J., 2009, CVPR; Yin Q., 2011, CVPR; Zeiler M., 2010, CVPR	41	20	21	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4673-1228-8	PROC CVPR IEEE			2012							2518	2525				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BBZ37	WOS:000309166202086		
J	Goertzel, B; Lian, RT; Arel, I; de Garis, H; Chen, S				Goertzel, Ben; Lian, Ruiting; Arel, Itamar; de Garis, Hugo; Chen, Shuo			A world survey of artificial brain projects, Part II Biologically inspired cognitive architectures	NEUROCOMPUTING			English	Article						Artificial brains; Cognitive architectures		A number of leading cognitive architectures that are inspired by the human brain at various levels of granularity are reviewed and compared with special attention paid to the way their internal structures and dynamics map onto neural processes Four categories of Biologically Inspired Cognitive Architectures (BICAs) are considered with multiple examples of each category briefly reviewed and selected examples discussed in more depth primarily symbolic architectures (e g ACT-R) emergentist architectures (e g DeSTIN) developmental robotics architectures (e g IM-CLEVER) and our central focus hybrid architectures (e g LIDA CLARION 4D/RCS DUAL MicroPsi and OpenCog) Given the state of the art in BICA it is not yet possible to tell whether emulating the brain on the architectural level is going to be enough to allow rough emulation of brain function and given the state of the art in neuroscience it is not yet possible to connect BICAs with large-scale brain simulations in a thoroughgoing way However it is nonetheless possible to draw reasonably close function connections between various components of various BICAs and various brain regions and dynamics and as both BICAs and brain simulations mature these connections should become richer and may extend further into the domain of internal dynamics as well as overall behavior (C) 2010 Elsevier B V All rights reserved	[Goertzel, Ben] Novamente LLC, Rockville, MD 20851 USA; [Goertzel, Ben; Lian, Ruiting; de Garis, Hugo; Chen, Shuo] Xiamen Univ, Fujian Key Lab Brain Intelligent Syst, Xiamen, Peoples R China; [Arel, Itamar] Univ Tennessee, Dept Elect Engn & Comp Sci, Machine Intelligence Lab, Knoxville, TN USA	Goertzel, B (reprint author), Novamente LLC, 1405 Bernerd Pl, Rockville, MD 20851 USA.				Chinese National Science Foundation [60975084/F030603]	This work funded in part by Chinese National Science Foundation Grant # 60975084/F030603	Albu J S, 2008, P AAAI FALL S WASH D; Albus J.S., 2001, ENG MIND INTRO SCI I; Albus JS, 2005, ANNU REV CONTROL, V29, P87, DOI 10.1016/j.arcontrol.2004.12.003; Anderson JR, 2008, TRENDS COGN SCI, V12, P136, DOI 10.1016/j.tics.2008.01.006; ANDERSON JR, 2003, BEHAV BRAIN SCI, V26; Arel I., 2009, NIPS 2009 WORKSH DEE; Arel I., 2009, P AAAI WORKSH BIOL I; Bach J., 2009, PRINCIPLES SYNTHETIC; Bakker B, 2006, P INT C ROB AUT; Bakker B., 2004, P 8 C INT AUT SYST; Baranes A, 2009, P IEEE INT C LEARN D, V33; Cassimans N, 2007, ADV ARTIFICIAL GEN I, P151; Duch W, 2008, P 2 C AGI; Fauconnier Gilles, 2002, WAY WE THINK CONCEPT; Fleischer J, 2007, P NATL ACAD SCI, V104; Franklin S, 2006, INT C INT DES PROC T; Friedlander D, 2008, LIDA THEORY MIND ART; Goertael B, 2008, P BICA 08, P86; Goertzel B, 2006, P BIONLP WORKSH HLT; Goertzel B., 2006, HIDDEN PATTERN; Goertzel B, 2009, PROBABILISTIC LOGIC NETWORKS: A COMPREHENSIVE FRAMEWORK FOR UNCERTAIN INFERENCE, P1, DOI 10.1007/978-0-387-76872-4; GOERTZEL B, 2009, P ICCI 09 HONG KONG; Goutel B, 2008, P AGI 08; Gray W, 2009, BEHAV BRAIN SCI; Han J, 2002, P 2 INT C DEV LEARN; Hawkins J., 2006, INTELLIGENCE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hofstadter D., 1996, FLUID CONCEPTS CREAT; JWeng, 2006, IEEE COMPUTATIONAL I; Kaplan F, 2008, FRONTIERS NEUROSCIEN; Laird J., 1987, ARTIFICIAL INTELLIGE, V33; LANGLEY P, 2005, P 2005 IEEE WIC ACM; LeCun Y., 1990, ADV NEURAL INFORM PR, V2; Lee MH, 2007, ROBOT AUTON SYST, V55, P750, DOI 10.1016/j.robot.2007.05.002; Lee MH, 2007, ADAPT BEHAV, V15, P241, DOI 10.1177/1059712307082085; Look M, 2006, THESIS WASHINGTON U; Marvin M, 2006, EMOTION MACHINE; Marvin M, 1988, SOC MIND; Metta G., 2008, PERF METR INT SYST W; Meyer D E, 1997, PSYCHOL REV, V104; Modayil J, 2007, AAAI 07, V07; Mugan J, 2009, IJCAI 09; Mugan J, 2008, INT C EP ROB; Nestor A, 2004, INT J INFORM THEORIE, V11; Nilsson N, 2009, LECT NOTES ARTIF INT, V33, P48; O'Reilly R. C., 1999, MODELS WORKING MEMOR, P375, DOI DOI 10.1017/CB09781139174909.014; Oudeyer P, 2006, CONNECTION SCI; Pelikan M., 2005, HIERARCHICAL BAYESIA; Schmidhuber J., 1991, P INT C SIM AD BEH A; Schmidhuber J., 1991, P INT JOINT C NEUR N; SCHMIDHUBER J, 2002, ADV EVOLUTIONARY COM; Schmidhuber J, 2006, CONNECTION SCI; Schmidhuber Juergen, 1995, P ICANN 95; SHAPIRO S, 2007, AI MAGAZINE, V28; Shastn L, 1993, BEHAV BRAIN SCI, V16; Simsek J, 2006, P 23 INT C MACH LEAR; Singh P., 2005, THESIS MIT; Singh S, 2005, P NEUR INF PROC SYST, V17; Sun R., 2004, COGNITIVE SYSTEMS RE, V5; Tulving E., 2005, OXFORD HDB MEMORY; WENG J, 2000, P 1 IEEE RAS INT C H	61	20	20	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	DEC	2010	74	1-3			SI		30	49		10.1016/j.neucom.2010.08.012		20	Computer Science, Artificial Intelligence	Computer Science	701GG	WOS:000285805800003		
J	Mohamed, AR; Sainath, TN; Dahl, G; Ramabhadran, B; Hinton, GE; Picheny, MA			IEEE	Mohamed, Abdel-rahman; Sainath, Tara N.; Dahl, George; Ramabhadran, Bhuvana; Hinton, Geoffrey E.; Picheny, Michael A.			DEEP BELIEF NETWORKS USING DISCRIMINATIVE FEATURES FOR PHONE RECOGNITION	2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 22-27, 2011	Prague, CZECH REPUBLIC	Inst Elect & Elect Engineers Signal Processing Soc, IEEE	Prague Congress Ctr	Discriminative feature transformation; Deep belief networks; Phone recognition	SPEECH RECOGNITION	Deep Belief Networks (DBNs) are multi-layer generative models. They can be trained to model windows of coefficients extracted from speech and they discover multiple layers of features that capture the higher-order statistical structure of the data. These features can be used to initialize the hidden units of a feed-forward neural network that is then trained to predict the HMM state for the central frame of the window. Initializing with features that are good at generating speech makes the neural network perform much better than initializing with random weights. DBNs have already been used successfully for phone recognition with input coefficients that are MFCCs or filterbank outputs [1, 2]. In this paper, we demonstrate that they work even better when their inputs are speaker adaptive, discriminative features. On the standard TIMIT corpus, they give phone error rates of 19.6% using monophone HMMs and a bigram language model and 19.4% using monophone HMMs and a trigram language model.	[Mohamed, Abdel-rahman; Dahl, George; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada	Mohamed, AR (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.	asamir@cs.toronto.edu; tsainath@us.ibm.com; gdahl@cs.toronto.edu; bhuvana@us.ibm.com; hinton@cs.toronto.edu; picheny@us.ibm.com					Bourlard H.A., 1993, CONNECTIONIST SPEECH; Dahl G.E., 2010, NIPS; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Hinton G., 2010, 2010003 U TOR MACH L; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257; Larochelle Hugo, 2007, ICML, P473; Lee K.F., 1989, IEEE T AUDIO SPEECH, V37, P16411648; Mohamed A., 2011, IEEE T AUDIO SPEECH; POVEY D, 2008, BOOSTED MMI MODEL FE, P4057; Sainath TN, 2009, P ASRU; SAINATH TN, 2010, TSAP UNPUB; SOLTAU H, 2010, P IEEE WORK IN PRESS; Young S., 2002, HTK BOOK, P3	16	18	19	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4577-0539-7	INT CONF ACOUST SPEE			2011							5060	5063				4	Acoustics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Engineering; Imaging Science & Photographic Technology	BXG36	WOS:000296062405167		
J	Yu, D; Deng, L				Yu, Dong; Deng, Li			Deep Learning and Its Applications to Signal and Information Processing	IEEE SIGNAL PROCESSING MAGAZINE			English	Article									[Yu, Dong; Deng, Li] Microsoft Res, Redmond, WA USA	Yu, D (reprint author), Microsoft Res, Redmond, WA USA.	dongyu@microsoft.com; deng@microsoft.com	Magazine, Signal Processing/E-9947-2015				Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; COLLOBERT R, 2008, P ICML 2008; Deng L., 2010, P INT; Deng L, 2008, IEEE SIGNAL PROC MAG, V25, P2, DOI 10.1109/MSP.2008.920380; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Hinton G., 2010, 2010003 U TOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; MOHAMED A, 2010, P INT SEPT; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; NAIR V, 2009, P NIPS; Ranzato M., 2007, P INT C DOC AN REC I; Salakhutdinov R. R., 2007, P SIGIR WORKSH INF R; TANG Y, 2010, P ICML; TAYLOR GW, 2007, P NIPS; YU D, 2010, J SELECT TOPICS SIGN	15	18	22	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888			IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	JAN	2011	28	1					145	+		10.1109/MSP.2010.939038		6	Engineering, Electrical & Electronic	Engineering	697NI	WOS:000285519900015		
J	Mohamed, AR; Hinton, G; Penn, G			IEEE	Mohamed, Abdel-rahman; Hinton, Geoffrey; Penn, Gerald			UNDERSTANDING HOW DEEP BELIEF NETWORKS PERFORM ACOUSTIC MODELLING	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		Deep belief networks; neural networks; acoustic modeling		Deep Belief Networks (DBNs) are a very competitive alternative to Gaussian mixture models for relating states of a hidden Markov model to frames of coefficients derived from the acoustic input. They are competitive for three reasons: DBNs can be fine-tuned as neural networks; DBNs have many non-linear hidden layers; and DBNs are generatively pre-trained. This paper illustrates how each of these three aspects contributes to the DBN's good recognition performance using both phone recognition performance on the TIMIT corpus and a dimensionally reduced visualization of the relationships between the feature vectors learned by the DBNs that preserves the similarity structure of the feature vectors at multiple scales. The same two methods are also used to	[Mohamed, Abdel-rahman; Hinton, Geoffrey; Penn, Gerald] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada	Mohamed, AR (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.						Allen JB, 1994, IEEE T SPEECH AUDI P, V2, P567, DOI 10.1109/89.326615; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Dahl G., 2011, IEEE T AUDIO SPEECH; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Mohamed A., 2011, IEEE T AUDIO SPEECH; Sainath T. N., 2011, ASRU; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579	9	17	17	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							4273	4276				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381404086		
J	Islam, MM; Sattar, MA; Amin, MF; Yao, X; Murase, K				Islam, Md. Monirul; Sattar, Md. Abdus; Amin, Md. Faijul; Yao, Xin; Murase, Kazuyuki			A New Constructive Algorithm for Architectural and Functional Adaptation of Artificial Neural Networks	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						Architectural adaptation; artificial neural networks (ANNs); constructive approach; functional adaptation; generalization ability	MULTILAYER FEEDFORWARD NETWORKS; PATTERN-CLASSIFICATION; LEARNING ALGORITHMS; CAPABILITIES; PERFORMANCE; WEIGHTS	The generalization ability of artificial neural networks (ANNs) is greatly dependent on their architectures. Constructive algorithms provide an attractive automatic way of determining a near-optimal ANN architecture for a given problem. Several such algorithms have been proposed in the literature and shown their effectiveness. This paper presents a new constructive algorithm (NCA) in automatically determining ANN architectures. Unlike most previous studies on determining ANN architectures, NCA puts emphasis on architectural adaptation and functional adaptation in its architecture determination process. It uses a constructive approach to determine the number of hidden layers in an ANN and of neurons in each hidden layer. To achieve functional adaptation, NCA trains hidden neurons in the ANN by using different training sets that were created by employing a similar concept used in the boosting algorithm. The purpose of using different training sets is to encourage hidden neurons to learn different parts or aspects of the training data so that the ANN can learn the whole training data in a better way. In this paper, the convergence and computational issues of NCA are analytically studied. The computational complexity of NCA is found to be O(W x P(t) x t), where W is the number of weights in the ANN, Pt is the number of training examples, and t is the number of training epochs. This complexity has the same order as what the backpropagation learning algorithm requires for training a fixed ANN architecture. A set of eight classification and two approximation benchmark problems was used to evaluate the performance of NCA. The experimental results show that NCA can produce ANN architectures with fewer hidden neurons and better generalization ability compared to existing constructive and nonconstructive algorithms.	[Islam, Md. Monirul; Sattar, Md. Abdus] Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka 1000, Bangladesh; [Islam, Md. Monirul; Murase, Kazuyuki] Univ Fukui, Grad Sch Engn, Dept Human & Artificial Intelligence Syst, Fukui 9108507, Japan; [Yao, Xin] Univ Birmingham, Sch Comp Sci, Ctr Excellence Res Computat Intelligence & Applic, Birmingham B15 2TT, W Midlands, England; [Murase, Kazuyuki] Univ Fukui, Res & Educ Program Life Sci, Fukui 9108507, Japan	Islam, MM (reprint author), Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka 1000, Bangladesh.	monirul@synapse.his.fukui-u.ac.jp	Murase, Kazuyuki/O-4881-2014		Japanese Society for the Promotion of Science	The work of M. Islam was supported in part by a fellowship grant from the Japanese Society for the Promotion of Science. This paper was recommended by Associate Editor E. Santos, Jr.	Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; DEVILLIERS J, 1992, IEEE T NEURAL NETWOR, V4, P136; Engelbrecht AP, 2001, IEEE T NEURAL NETWOR, V12, P1386, DOI 10.1109/72.963775; Fahlman S. E., 1990, P ADV NEUR INF PROC, V2, P524; Fahlman S. E., 1988, CMUCS88162; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GALUSHKIN AI, 2007, NEURAL NETWORKS THEO, P53; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Guo P, 2003, IEEE T SYST MAN CY B, V33, P35, DOI 10.1109/TSMCB.2003.808176; Han SJ, 2006, IEEE T SYST MAN CY B, V36, P559, DOI 10.1109/TSMCB.2005.860136; Hassibi B., 1993, ADV NEURAL INFORMATI, V5, P164; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Islam MM, 2001, NEURAL NETWORKS, V14, P1265, DOI 10.1016/S0893-6080(01)00075-2; Islam MM, 2008, IEEE T SYST MAN CY B, V38, P771, DOI 10.1109/TSMCB.2008.922055; Islam MM, 2009, IEEE T SYST MAN CY B, V39, P705, DOI 10.1109/TSMCB.2008.2008724; Kirkpatrick S., 1983, SCIENCE, V220, P4598; Kreyszig E., 1989, INTRO FUNCTIONAL ANA; Kwok TY, 1997, IEEE T NEURAL NETWOR, V8, P1131; Kwok T.-Y., 1997, IEEE T NEURAL NETWOR, V3, P630; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lauret P, 2006, IEEE T NEURAL NETWOR, V17, P273, DOI 10.1109/TNN.2006.871707; LECUN Y, 1990, P ADV NEUR INF PROC, V2, P598; Lehtokangas M, 2000, IEEE T NEURAL NETWOR, V11, P795, DOI 10.1109/72.846749; Leung CS, 2001, NEURAL NETWORKS, V14, P147, DOI 10.1016/S0893-6080(00)00093-9; Ludermir TB, 2006, IEEE T NEURAL NETWOR, V17, P1452, DOI 10.1109/TNN.2006.881047; Ma LY, 2005, IEEE T NEURAL NETWOR, V16, P821, DOI 10.1109/TNN.2005.851786; MEZARD M, 1989, J PHYS A-MATH GEN, V22, P2191, DOI 10.1088/0305-4470/22/12/019; MURRAY AF, 1994, IEEE T NEURAL NETWOR, V5, P792, DOI 10.1109/72.317730; Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013; Parikh D, 2007, IEEE T SYST MAN CY B, V37, P437, DOI 10.1109/TSMCB.2006.883873; PHATAK DS, 1994, IEEE T NEURAL NETWOR, V5, P930, DOI 10.1109/72.329690; Prechelt L, 1996, NEURAL NETWORKS, V9, P457, DOI 10.1016/0893-6080(95)00123-9; Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0; PRECHELT L, 1994, 2194 U KARLS FAC INF; Rasiah AI, 1997, IEE P-VIS IMAGE SIGN, V144, P345, DOI 10.1049/ip-vis:19971613; REED R, 1993, IEEE T NEURAL NETWOR, V4, P740, DOI 10.1109/72.248452; REN JD, 2003, P 2 INT C MACH LEARN, P1127; Rivals I, 2003, IEEE T NEURAL NETWOR, V14, P804, DOI 10.1109/TNN.2003.811356; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Russel S., 2004, ARTIFICIAL INTELLIGE; SATTAR MA, 2007, P 14 ICONIP KIT JAP, P317; SCHAEFER P, 1990, EARTH ISL J, V5, P2; SETIONO R, 1995, IEEE T NEURAL NETWOR, V6, P273, DOI 10.1109/72.363426; Tamura S, 1997, IEEE T NEURAL NETWOR, V8, P251, DOI 10.1109/72.557662; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	48	17	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	DEC	2009	39	6					1590	1605		10.1109/TSMCB.2009.2021849		16	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	498MB	WOS:000270143800021	19502131	
J	Shao, L; Zhen, XT; Tao, DC; Li, XL				Shao, Ling; Zhen, Xiantong; Tao, Dacheng; Li, Xuelong			Spatio-Temporal Laplacian Pyramid Coding for Action Recognition	IEEE TRANSACTIONS ON CYBERNETICS			English	Article						Action recognition; computer vision; max pooling; spatio-temporal Laplacian pyramid	TIME INTEREST POINTS; SCENE CLASSIFICATION; VISUAL-ATTENTION; FEATURES; CONTEXT; REPRESENTATION; APPEARANCE; IMAGES; MODEL	We present a novel descriptor, called spatio-temporal Laplacian pyramid coding (STLPC), for holistic representation of human actions. In contrast to sparse representations based on detected local interest points, STLPC regards a video sequence as a whole with spatio-temporal features directly extracted from it, which prevents the loss of information in sparse representations. Through decomposing each sequence into a set of band-pass-filtered components, the proposed pyramid model localizes features residing at different scales, and therefore is able to effectively encode the motion information of actions. To make features further invariant and resistant to distortions as well as noise, a bank of 3-D Gabor filters is applied to each level of the Laplacian pyramid, followed by max pooling within filter bands and over spatio-temporal neighborhoods. Since the convolving and pooling are performed spatio-temporally, the coding model can capture structural and motion information simultaneously and provide an informative representation of actions. The proposed method achieves superb recognition rates on the KTH, the multiview IXMAS, the challenging UCF Sports, and the newly released HMDB51 datasets. It outperforms state of the art methods showing its great potential on action recognition.	[Shao, Ling] Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China; [Shao, Ling; Zhen, Xiantong] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England; [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, State Key Lab Transient Opt & Photon, Ctr OPT IMagery Anal & Learning, Xian 710119, Peoples R China	Shao, L (reprint author), Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.	ling.shao@sheffield.ac.uk; elr10xz@sheffield.ac.uk; dacheng.tao@ieee.org; xuelong_li@opt.ac.cn			University of Sheffield; China Scholarship Council; National Basic Research Program of China (973 Program) [2012CB316400]; National Natural Science Foundation of China [61125106, 61072093]; Shaanxi Key Innovation Team of Science and Technology [2012KCT-04]	This work was supported in part by the University of Sheffield, the China Scholarship Council, the National Basic Research Program of China (973 Program) under Grant 2012CB316400, the National Natural Science Foundation of China under Grant 61125106 and Grant 61072093, and the Shaanxi Key Innovation Team of Science and Technology under Grant 2012KCT-04. Paper recommended by Associate Editor W. Hu. (Corresponding author: L. Shao.)	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; ALBRIGHT TD, 1995, P NATL ACAD SCI USA, V92, P2433, DOI 10.1073/pnas.92.7.2433; Bobick A., 2002, IEEE T PATTERN ANAL, V23, P257; Boureau Y., 2010, P INT C MACH LEARN, P547; Bregonzio M, 2009, PROC CVPR IEEE, P1948; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178); Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jhuang H., 2007, P IEEE INT C COMP VI, P1; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang Y.-G., 2012, P EUR C COMP VIS FLO, P425; Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22; Klaser A., 2008, P BRIT MACH VIS C, P995; KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Kuehne H, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2556, DOI 10.1109/ICCV.2011.6126543; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; Lindeberg T., 1994, J APPL STAT, V21, P225, DOI DOI 10.1080/757582976; [刘军 LIU Jun], 2008, [高分子通报, Polymer Bulletin], P1, DOI 10.1145/1509315.1509331; Liu JG, 2009, PROC CVPR IEEE, P1996; Liu L., 2013, IEEE T CYBERN; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu HC, 2012, IEEE T SYST MAN CY B, V42, P889, DOI 10.1109/TSMCB.2011.2182048; Lu ZW, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1503; Matikainen P, 2010, LECT NOTES COMPUT SC, V6311, P508, DOI 10.1007/978-3-642-15549-9_37; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Ning H., 2007, P IEEE INT C IM PROC, V6, P337; Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864; Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rodriguez M., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587727; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Savarese S., 2008, P IEEE WORKSH MOT VI, P1; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, P 15 INT C MULT, P357, DOI 10.1145/1291233.1291311; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939; Sun J, 2009, PROC CVPR IEEE, P2004; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Tissainayagam P, 2005, PATTERN RECOGN, V38, P105, DOI 10.1016/j.patcog.2004.05.011; Uemura H., 2008, P BRIT MACH VIS C, P1; Varma M., 2009, P 26 ANN INT C MACH, P1065, DOI DOI 10.1145/1553374.1553510; Wang H., 2011, P IEEE C COMP VIS PA, P3169; Wang H., 2009, P BRIT MACH VIS C, P1; Wang S, 2012, PROC CVPR IEEE, P1370; Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635; Weinland D., 2007, P INT C COMP VIS, P1; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; Wu XX, 2011, PROC CVPR IEEE, P489; Yan P., 2008, P IEEE C COMP VIS PA, P1; Yang JC, 2009, PROC CVPR IEEE, P1794; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201; Yilmaz A, 2005, PROC CVPR IEEE, P984; Zhang T., 2008, IEEE T KNOWL DATA EN, V21, P1299; Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157; Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817; Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916; Zheng X., 2013, P IEEE INT C AUT FAC, P1	66	16	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2168-2267	2168-2275		IEEE T CYBERNETICS	IEEE T. Cybern.	JUN	2014	44	6					817	827		10.1109/TCYB.2013.2273174		11	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	AJ8MT	WOS:000337960000008	23912503	
J	Healy, EW; Yoho, SE; Wang, YX; Wang, DL				Healy, Eric W.; Yoho, Sarah E.; Wang, Yuxuan; Wang, DeLiang			An algorithm to improve speech recognition in noise for hearing-impaired listeners	JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA			English	Article							BACKGROUND-NOISE; GAP DETECTION; INTELLIGIBILITY; MASKING; REDUCTION; RECEPTION; SEGREGATION; INTEGRATION; PERCEPTION; SEPARATION	Despite considerable effort, monaural (single-microphone) algorithms capable of increasing the intelligibility of speech in noise have remained elusive. Successful development of such an algorithm is especially important for hearing-impaired (HI) listeners, given their particular difficulty in noisy backgrounds. In the current study, an algorithm based on binary masking was developed to separate speech from noise. Unlike the ideal binary mask, which requires prior knowledge of the premixed signals, the masks used to segregate speech from noise in the current study were estimated by training the algorithm on speech not used during testing. Sentences were mixed with speech-shaped noise and with babble at various signal-to-noise ratios (SNRs). Testing using normal-hearing and HI listeners indicated that intelligibility increased following processing in all conditions. These increases were larger for HI listeners, for the modulated background, and for the least-favorable SNRs. They were also often substantial, allowing several HI listeners to improve intelligibility from scores near zero to values above 70%. (C) 2013 Acoustical Society of America.	[Healy, Eric W.; Yoho, Sarah E.] Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA; [Healy, Eric W.; Yoho, Sarah E.; Wang, Yuxuan; Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA; [Wang, Yuxuan; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Healy, EW (reprint author), Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.	healy.66@osu.edu			National Institute on Deafness and other Communication Disorders [R01 DC08594, R01 DC012048]; Air Force Office of Scientific Research [FA9550-12-1-0130]; STTR subcontract from Kuzer	This work was supported in part by grants from the National Institute on Deafness and other Communication Disorders (Grant No. R01 DC08594 to E. W. H. and Grant No. R01 DC012048 to D.L.W.) and from the Air Force Office of Scientific Research (Grant No. FA9550-12-1-0130 to D.L.W.) and an STTR subcontract from Kuzer (to D.L.W.).	ANSI, 2004, S321R2009 ANSI AC SO; ANSI, 1987, S339R2012 ANSI AC SO; Anzalone MC, 2006, EAR HEARING, V27, P480, DOI 10.1097/01.aud.0000233891.86809.df; Apoux F, 2009, HEARING RES, V255, P99, DOI 10.1016/j.heares.2009.06.005; Apoux F, 2010, J ACOUST SOC AM, V128, P2075, DOI 10.1121/1.3478845; Bacon S. P., 2004, COMPRESSION COCHLEA, P136; BACON SP, 1992, J SPEECH HEAR RES, V35, P642; Bacon SP, 1998, J SPEECH LANG HEAR R, V41, P549; BAER T, 1993, J ACOUST SOC AM, V94, P1229, DOI 10.1121/1.408176; Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132; Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929; Cao SY, 2011, J ACOUST SOC AM, V129, P2227, DOI 10.1121/1.3559707; FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247; Fink N, 2012, J ACOUST SOC AM, V132, P1718, DOI 10.1121/1.4739441; FITZGIBBONS PJ, 1982, J ACOUST SOC AM, V72, P761, DOI 10.1121/1.388256; Garofolo J., 1993, NISTIR4930; GLASBERG BR, 1987, J ACOUST SOC AM, V81, P1546, DOI 10.1121/1.394507; Grant KW, 2007, J ACOUST SOC AM, V121, P1164, DOI 10.1121/1.2405859; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; Han K, 2013, IEEE T AUDIO SPEECH, V21, P166, DOI 10.1109/TASL.2012.2215596; Healy EW, 2010, J SPEECH LANG HEAR R, V53, P1087, DOI 10.1044/1092-4388(2010/09-0185); Healy EW, 2002, J SPEECH LANG HEAR R, V45, P1262, DOI 10.1044/1092-4388(2002/101); Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu GN, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P79; Hu Y, 2007, J ACOUST SOC AM, V122, P1777, DOI 10.1121/1.2766778; Hu Y, 2010, J ACOUST SOC AM, V127, P3689, DOI 10.1121/1.3365256; Institute of Electrical and Electronics Engineers (IEEE), 1969, IEEE T AUDIO ELECTRO, P225, DOI DOI 10.1109/TAU.1969.1162058; Kim C, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2598; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Levitt H., 1997, GUEST EDITORIAL PRAC, pxi; Levitt H, 2001, J REHABIL RES DEV, V38, P111; Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617; Li YP, 2009, SPEECH COMMUN, V51, P230, DOI 10.1016/j.specom.2008.09.001; Loizou P, 2007, SPEECH ENHANCEMENT T; Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103; Moore B. C. J., 2007, COCHLEAR HEARING LOS, P45; MOORE BCJ, 1992, BRIT J AUDIOL, V26, P229, DOI 10.3109/03005369209076641; Narayanan A, 2012, IEEE T AUDIO SPEECH, V20, P2518, DOI 10.1109/TASL.2012.2205242; Nelson PB, 1997, J SPEECH LANG HEAR R, V40, P1387; NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469; Souza PE, 2006, J SPEECH LANG HEAR R, V49, P138, DOI 10.1044/1092-4388(2006/011); TERKEURS M, 1992, J ACOUST SOC AM, V91, P2872, DOI 10.1121/1.402950; TERKEURS M, 1993, J ACOUST SOC AM, V93, P1547, DOI 10.1121/1.406813; Turner CW, 1999, J SPEECH LANG HEAR R, V42, P773; Wang D., 2006, COMPUTATIONAL AUDITO, P1; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; WILSON RH, 1969, J ACOUST SOC AM, V46, P998, DOI 10.1121/1.1911820	51	16	16	ACOUSTICAL SOC AMER AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0001-4966	1520-8524		J ACOUST SOC AM	J. Acoust. Soc. Am.	OCT	2013	134	4					3029	3038		10.1121/1.4820893		10	Acoustics; Audiology & Speech-Language Pathology	Acoustics; Audiology & Speech-Language Pathology	295MH	WOS:000330119700056	24116438	
J	Ashburner, J; Kloppel, S				Ashburner, John; Kloeppel, Stefan			Multivariate models of inter-subject anatomical variability	NEUROIMAGE			English	Review							DIFFEOMORPHIC IMAGE REGISTRATION; COMPUTATIONAL ANATOMY; WHITE-MATTER; BRAIN IMAGES; MR-IMAGES; DIFFUSION TRACTOGRAPHY; ALZHEIMERS-DISEASE; COMPONENT ANALYSIS; HUMAN THALAMUS; HUMAN CORTEX	This paper presents a very selective review of some of the approaches for multivariate modelling of intersubject variability among brain images. It focusses on applying probabilistic kernel-based pattern recognition approaches to pre-processed anatomical MRI, with the aim of most accurately modelling the difference between populations of subjects. Some of the principles underlying the pattern recognition approaches of Gaussian process classification and regression are briefly described, although the reader is advised to look elsewhere for full implementational details. Kernel pattern recognition methods require matrices that encode the degree of similarity between the images of each pair of subjects. This review focusses on similarity measures derived from the relative shapes of the subjects' brains. Pre-processing is viewed as generative modelling of anatomical variability, and there is a special emphasis on the diffeomorphic image registration framework, which provides a very parsimonious representation of relative shapes. Although the review is largely methodological, excessive mathematical notation is avoided as far as possible, as the paper attempts to convey a more intuitive understanding of various concepts. The paper should be of interest to readers wishing to apply pattern recognition methods to MRI data, with the aim of clinical diagnosis or biomarker development. It also tries to explain that the best models are those that most accurately predict, so similar approaches should also be relevant to basic science. Knowledge of some basic linear algebra and probability theory should make the review easier to follow, although it may still have something to offer to those readers whose mathematics may be more limited. (C) 2010 Elsevier Inc. All rights reserved.	[Ashburner, John] Wellcome Trust Ctr Neuroimaging, London WC1N 3BG, England; [Kloeppel, Stefan] Univ Hosp Freiburg, Sect Gerontopsychiat & Neuropsychol Freiburg Brai, Dept Psychiat & Psychotherapy, Freiburg, Germany	Ashburner, J (reprint author), Wellcome Trust Ctr Neuroimaging, 12 Queen Sq, London WC1N 3BG, England.		Ashburner, John/I-3757-2013		Wellcome Trust	JA is funded by the Wellcome Trust. Many thanks to Karl Friston for correcting a draught of this document.	ADAMS DC, 2004, ITAL J ZOOL, V710, P5; ALEXANDER DC, 1999, P IEEE C COMP VIS PA, V1, P244; ALLASSONNIERE S, 2007, J R STAT SOC B METHO, V690, P3; Amari SI, 2007, METHODS INFORM GEOME; Ashburner J, 2001, NEUROIMAGE, V14, P1238, DOI 10.1006/nimg.2001.0961; Ashburner J, 1998, HUM BRAIN MAPP, V6, P348, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<348::AID-HBM4>3.0.CO;2-P; Ashburner J., 2009, NEUROIMAGE, V450, P333; Ashburner J, 1997, NEUROIMAGE, V6, P209, DOI 10.1006/nimg.1997.0290; Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007; Avants B, 2004, NEUROIMAGE, V23, pS139, DOI 10.1016/j.neuroimage.2004.07.010; BALOCH S, 2009, NEUROIMAGE, V450, P73; Baron-Cohen S, 2002, TRENDS COGN SCI, V6, P248, DOI 10.1016/S1364-6613(02)01904-6; Beckmann CF, 2004, IEEE T MED IMAGING, V23, P137, DOI 10.1109/TMI.2003.822821; Beg MF, 2006, I S BIOMED IMAGING, P1116; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Behrens TEJ, 2006, NEUROIMAGE, V30, P220, DOI 10.1016/j.neuroimage.2005.09.036; Behrens TEJ, 2003, NAT NEUROSCI, V6, P750, DOI 10.1038/nn1075; Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bishop CM, 2007, BAYESIAN STAT, V8, P3; Bishop CM, 2006, PATTERN RECOGNITION; BISHOP CM, 1999, ICANN 99 9 INT C, V1; Bookstein F. L., 1997, MORPHOMETRIC TOOLS L; BOOKSTEIN FL, 1996, NEUROINFORMATICS OVE; Boser B. E., 1992, COMPUTATIONAL LEARNI, P144; BroNielsen M, 1996, COMPUT GRAPH FORUM, V15, pC57; BUTCHER J, 2007, LANCET NEUROL, V60, P480; Chance SA, 2005, SCHIZOPHR RES, V74, P163, DOI 10.1016/j.schres.2004.09.001; Chapelle O., 2006, SEMISUPERVISED LEARN; CHRISTENSEN GE, 1995, COMP IMAG VIS, V3, P101; Costa L. D. F., 2001, SHAPE ANAL CLASSIFIC; COTTER CJ, 2006, NLINSI0605020 ARXIV; Cristianini N., 2000, INTRO SUPPORT VECTOR; CSETE ME, 2002, REVERSE ENG BIOL COM; DAVATZIKOS C, 2004, IEEE INT S BIOM IM N, P587; Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010; Davies R., 2008, STAT MODELS SHAPE OP; Dryden I.L., 1998, STAT SHAPE ANAL; Duda R, 2001, PATTERN CLASSIFICATI; ELSTEIN AS, 2002, CLIN PROBLEM SOLVING; Fan Y, 2005, LECT NOTES COMPUT SC, V3749, P1; FLETCHER PC, 1996, NEUROIMAGE, V30, P209; Friston KJ, 2007, NEUROIMAGE, V34, P220, DOI 10.1016/j.neuroimage.2006.08.035; Friston KJ, 2008, NEUROIMAGE, V39, P181, DOI 10.1016/j.neuroimage.2007.08.013; FRISTON KJ, 1996, HUM BRAIN MAPP, V40; FRISTON KJ, 1994, HUM BRAIN MAPP, V20, P189; Friston KJ, 2004, NEUROIMAGE, V23, P21, DOI 10.1016/j.neuroimage.2004.04.021; GERARDIN E, 2009, NEUROIMAGE; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; Golland P, 2005, MED IMAGE ANAL, V9, P69, DOI 10.1016/j.media.2004.07.003; Golland P, 2001, LECT NOTES COMPUTER, P517; GOLLAND P, 2002, ADV NEURAL INF PROCE, V1, P745; Grenander U, 1998, Q APPL MATH, V56, P617; Grenander U., 2007, PATTERN THEORY REPRE; GUIMOND A, 2002, P ISBI, V2; HAND DJ, 2001, STAT NEERL, V550, P3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirsch JE, 2007, P NATL ACAD SCI USA, V104, P19193, DOI 10.1073/pnas.0707962104; HOLUB AD, 2008, INT J COMPUT VISION, V770, P239; Hoyer P. O., 2009, ADV NEURAL INFORM PR, V21, P689; Huxley J. S, 1993, PROBLEMS RELATIVE GR; Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405; Jaynes ET, 2003, PROBABILITY THEORY L; Johansen-Berg H, 2005, CEREB CORTEX, V15, P31, DOI 10.1093/cercor/bhh105; Jordan M. I., 2005, 688 U CAL DEP STAT; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Kendall D.G., 1999, SHAPE SHAPE THEORY; Kiebel SJ, 2008, NEUROIMAGE, V39, P728, DOI 10.1016/j.neuroimage.2007.09.005; Kitano H, 2002, NATURE, V420, P206, DOI 10.1038/nature01254; Klein JC, 2007, NEUROIMAGE, V34, P204, DOI 10.1016/j.neuroimage.2006.08.022; KLOPPEL S, 2008, BRAIN, V681; Kloppel S., 2008, BRAIN; Krim H., 2006, STAT ANAL SHAPES; LAO Z, 2004, NEUROIMAGE, V210, P46; LASSERRE JA, 2006, 2006 IEEE COMP SOC C, V1; Lee DD, 1999, NATURE, V401, P788; Lele S, 2001, INVARIANT APPROACH S; Lorenzen P, 2005, LECT NOTES COMPUT SC, V3750, P411; Luders E, 2002, NEUROREPORT, V13, P2371, DOI 10.1097/01.wnr.0000049603.85580.da; MacKay D., 2003, INFORM THEORY INFERE; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MAGNIN B, 2009, NEURORADIOLOGY, V510, P73; Makrogiannis S, 2007, IEEE T MED IMAGING, V26, P619, DOI 10.1109/TMI.2007.893285; Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498; Markram H, 2006, NAT REV NEUROSCI, V7, P153, DOI 10.1038/nrn1848; Marsland S, 2007, LECT NOTES COMPUT SC, V4584, P396; MARTIN RD, 1981, NATURE, V293, P57, DOI 10.1038/293057a0; Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293; McIntosh AR, 1996, NEUROIMAGE, V3, P143, DOI 10.1006/nimg.1996.0016; Mechelli A, 2005, J NEUROSCI, V25, P8303, DOI 10.1523/JNEUROSCI.0357-05.2005; MILLER M, 1997, STAT METHODS MED RES, V60, P269; MILLER MI, 2009, NEUROIMAGE, V450, P16; Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0; MILLER MI, 2008, HUM BRAIN MAPP, V300, P2132; Miller MI, 2004, NEUROIMAGE, V23, pS19, DOI 10.1016/j.neuroimage.2004.07.021; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Mueller Susanne G, 2005, Alzheimers Dement, V1, P55, DOI 10.1016/j.jalz.2005.06.003; Mumford D., 1996, PERCEPTION BAYESIAN, P25; MUMFORD D, 1994, LARGE SCALE NEURONAL, P125; MUMFORD D, 2005, NEW DIRECTIONS STAT; MUMFORD D, 2002, P INT C MATH, V3; OISHI K, 2008, NEUROIMAGE, V430, P447; Park HJ, 2003, NEUROIMAGE, V20, P1995, DOI 10.1016/j.neuroimage.2003.08.008; Penny WD, 2004, NEUROIMAGE, V22, P1157, DOI 10.1016/j.neuroimage.2004.03.026; PEREIRA F, 2009, NEUROIMAGE, V450, P199; Petersson KM, 1999, PHILOS T R SOC B, V354, P1239, DOI 10.1098/rstb.1999.0477; Qiu AQ, 2008, NEUROIMAGE, V42, P1430, DOI 10.1016/j.neuroimage.2008.04.257; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; RASMUSSEN CE, 2005, MACH LEARN INT WORKS, V22, P689; RILLING JK, 2006, EVOL ANTHR ISSUES NE, V150; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Ruiz-Alzola J, 2002, MED IMAGE ANAL, V6, P143, DOI 10.1016/S1361-8415(02)00055-5; Sabuncu MR, 2010, CEREB CORTEX, V20, P130, DOI 10.1093/cercor/bhp085; SALIMIKHORSHIDI G, 2009, NEUROIMAGE, V450, P810; Saxe R, 2006, NEUROIMAGE, V30, P1088, DOI 10.1016/j.neuroimage.2005.12.062; SCHMAH T, 2008, GENERATIVE VERSUS DI; Scholkopf B., 2002, LEARNING KERNELS SUP; SEELEY WW, 2009, NEURON, V620, P42; Small C. G., 1996, STAT THEORY SHAPE; SMITH SM, 2009, P NATL ACAD SCI USA, V1060, P13040; Stephan KE, 2001, PHILOS T ROY SOC B, V356, P1159; Thompson D. W., 1942, GROWTH FORM; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Trouve A, 2005, FOUND COMPUT MATH, V5, P173, DOI 10.1007/s10208-004-0128-z; TROUVE A, 2001, LECT NOTES COMPUT SC, P50; Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023; Van Horn J.D., 2009, NEUROIMAGE; Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Vemuri P, 2008, NEUROIMAGE, V39, P1186, DOI 10.1016/j.neuroimage.2007.09.073; Wang L, 2007, IEEE T MED IMAGING, V26, P462, DOI 10.1109/TMI.2006.887380; Watanabe S., 1969, KNOWING GUESSING QUA; West GB, 2001, NATURE, V413, P628, DOI 10.1038/35098076; WEST GB, 2005, ORIGIN ALLOMETRIC SC; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; WILLIAMS CKI, 1996, ADV NEURAL INF PROCE, V8; Woods RP, 2003, NEUROIMAGE, V18, P769, DOI 10.1016/S1053-8119(03)00019-3; Wright IC, 1995, NEUROIMAGE, V2, P244, DOI 10.1006/nimg.1995.1032; Xu L, 2008, INT CONF ACOUST SPEE, P533; YOUNES L, 2009, NEUROIMAGE, V450, P40; YOUNES L, 2008, J MATH IMAGING VIS, V320, P41; Younes L, 2007, Q APPL MATH, V65, P113; Zhang H, 2006, MED IMAGE ANAL, V10, P764, DOI 10.1016/j.media.2006.06.004; Zhang K, 2000, P NATL ACAD SCI USA, V97, P5621, DOI 10.1073/pnas.090504197; Zhu X, 2009, SYNTH LECT ARTIF INT, V30, P1; Zou KH, 2007, CIRCULATION, V115, P654, DOI 10.1161/CIRCULATIONAHA.105.594929	148	16	16	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119			NEUROIMAGE	Neuroimage	MAY 15	2011	56	2			SI		422	439		10.1016/j.neuroimage.2010.03.059		18	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	757JS	WOS:000290081900005	20347998	
J	Hinton, GE				Hinton, Geoffrey E.			Learning to represent visual input	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES			English	Review						neural networks; learning algorithms; computational neuroscience	BELIEF NETWORKS; NEURAL-NETWORKS; ALGORITHM; RECOGNITION; MODELS; SLEEP; DEEP	One of the central problems in computational neuroscience is to understand how the object-recognition pathway of the cortex learns a deep hierarchy of nonlinear feature detectors. Recent progress in machine learning shows that it is possible to learn deep hierarchies without requiring any labelled data. The feature detectors are learned one layer at a time and the goal of the learning procedure is to form a good generative model of images, not to predict the class of each image. The learning procedure only requires the pairwise correlations between the activations of neuron-like processing units in adjacent layers. The original version of the learning procedure is derived from a quadratic 'energy' function but it can be extended to allow third-order, multiplicative interactions in which neurons gate the pairwise interactions between other neurons. A technique for factoring the third-order interactions leads to a learning module that again has a simple learning rule based on pairwise correlations. This module looks remarkably like modules that have been proposed by both biologists trying to explain the responses of neurons and engineers trying to create systems that can recognize objects.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Hinton, GE (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	hinton@cs.toronto.edu					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Carandini M, 2005, J NEUROSCI, V25, P10577, DOI 10.1523/JNEUROSCI.3726-05.2005; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; CRICK F, 1983, NATURE, V304, P111, DOI 10.1038/304111a0; Erhan D, 2009, P 12 INT C ART INT S, P153; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hopfield J. J., 1982, P NATL ACAD SCI USA, V79, p2554aAS2558; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790410; Marr D, 1982, VISION; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Pearl J., 1988, PROBABILISTIC INFERE; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sejnowski T. J., 1986, AIP C P, V151, P398; Selfridge O., 1958, P S HELD NAT PHYS LA, P513; SERRE L, 2007, IEEE T PATTERN ANAL, V29, P411; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; Werbos P., 1974, THESIS HARVARD U; ZEMEL RS, 1994, THESIS U TORONTO	33	16	16	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	0962-8436			PHILOS T R SOC B	Philos. Trans. R. Soc. B-Biol. Sci.	JAN 12	2010	365	1537					177	184		10.1098/rstb.2009.0200		8	Biology	Life Sciences & Biomedicine - Other Topics	531ET	WOS:000272647200017	20008395	
J	Ranzato, M; Hinton, GE			IEEE	Ranzato, Marc'Aurelio; Hinton, Geoffrey E.			Modeling Pixel Means and Covariances Using Factorized Third-Order Boltzmann Machines	2010 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	23rd IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 13-18, 2010	San Francisco, CA	IEEE Comp Soc			IMAGES; SCENE; SET	Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset.	[Ranzato, Marc'Aurelio; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	Ranzato, M (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd, Toronto, ON, Canada.	ranzato@cs.toronto.edu; hinton@cs.toronto.edu					Bengio Y., 2007, NIPS; Bishop C. M., 1999, J ROYAL STAT SOC B, V61, P611; Dalal N., 2005, CVPR; Freund Y., 1994, UNSUPERVISED LEARNIN; He X., 2006, ECCV; Heess N., 2009, BMCV; Hinton G., 2006, SCIENCE, V313, P504; Hinton G, 2006, COGNITIVE SCI, V30, P725, DOI 10.1207/s15516709cog0000_76; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K., 2009, ICCV; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Kavukcuoglu K., 2009, CVPR; Koster U., 2007, ICANN, P1; Krizhevsky A., 2009, THESIS U TORONTO; Lee H., 2009, P ICML; Lowe D. G., 2004, IJCV; Memisevic R., 2010, NEURAL COMP; Neal R. M., 1996, BAYESIAN LEARNING NE; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osindero S., 2008, NIPS; Osindero S., 2006, NEURAL COMPUT, V18, P344; Raina R., 2007, ICML; Ranzato M., 2007, CVPR 07; Ranzato M., 2010, AISTATS; Roth S., 2005, CVPR; Sejnowski T., 1986, AIP C P; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torralba A. B., 2008, CVPR; Vincent P., 2008, ICML; Wainwright M., 2000, NIPS	33	16	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		978-1-4244-6984-0	PROC CVPR IEEE			2010							2551	2558		10.1109/CVPR.2010.5539962		8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematics, Applied; Imaging Science & Photographic Technology	Computer Science; Mathematics; Imaging Science & Photographic Technology	BTN70	WOS:000287417502077		
J	Lochmann, T; Ernst, UA; Deneve, S				Lochmann, Timm; Ernst, Udo A.; Deneve, Sophie			Perceptual Inference Predicts Contextual Modulations of Sensory Responses	JOURNAL OF NEUROSCIENCE			English	Article							PRIMARY VISUAL-CORTEX; CLASSICAL RECEPTIVE-FIELD; MACAQUE V1 NEURONS; PRIMARY AUDITORY-CORTEX; RETINAL GANGLION-CELLS; CAT STRIATE CORTEX; POPULATION CODES; GAIN-CONTROL; ORIENTATION SELECTIVITY; SOMATOSENSORY CORTEX	Sensory receptive fields (RFs) vary as a function of stimulus properties and measurement methods. Previous stimuli or surrounding stimuli facilitate, suppress, or change the selectivity of sensory neurons' responses. Here, we propose that these spatiotemporal contextual dependencies are signatures of efficient perceptual inference and can be explained by a single neural mechanism, input targeted divisive inhibition. To respond both selectively and reliably, sensory neurons should behave as active predictors rather than passive filters. In particular, they should remove input they can predict ("explain away") from the synaptic inputs to all other neurons. This implies that RFs are constantly and dynamically reshaped by the spatial and temporal context, while the true selectivity of sensory neurons resides in their "predictive field." This approach motivates a reinvestigation of sensory representations and particularly the role and specificity of surround suppression and adaptation in sensory areas.	[Lochmann, Timm] Tech Univ Berlin, Neural Informat Proc Grp, Dept Software Engn & Theoret Comp Sci, D-10587 Berlin, Germany; [Lochmann, Timm; Deneve, Sophie] Ecole Normale Super, Coll France, Grp Neural Theory, Dept Etud Cognit, F-75005 Paris, France; [Ernst, Udo A.] Univ Bremen, Inst Theoret Neurophys, Dept Phys, D-28334 Bremen, Germany	Lochmann, T (reprint author), Tech Univ Berlin, Neural Informat Proc Grp, Dept Software Engn & Theoret Comp Sci, Franklinstr 28-29, D-10587 Berlin, Germany.	lochman@ni.tu-berlin.de			Marie Curie Excellence Grant [MECT-CT-2005-024831]	This work was funded by the Marie Curie Excellence Grant: MECT-CT-2005-024831. A book chapter "Contextual modulations of visual receptive fields: A Bayesian perspective" (S. Deneve and T. Lochmann) containing a brief version of portions of this research appears in J. Trommershauser, K. Kording, and M. Landy (Eds), Sensory Cue Integration, Oxford UP.	AERTSEN AMHJ, 1981, BIOL CYBERN, V42, P133, DOI 10.1007/BF00336731; Ahrens MB, 2008, J NEUROSCI, V28, P1929, DOI 10.1523/JNEUROSCI.3377-07.2008; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Berkes P, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000495; Blake DT, 2002, J NEUROPHYSIOL, V88, P3409, DOI 10.1152/jn.00233.2002; BLAKEMOR.C, 1972, EXP BRAIN RES, V15, P439; Boloori AR, 2006, J NEUROSCI, V26, P3767, DOI 10.1523/JNEUROSCI.4056-05.2006; BONDS AB, 1989, VISUAL NEUROSCI, V2, P41; Brosch M, 1997, J NEUROPHYSIOL, V77, P923; Butts DA, 2007, NATURE, V449, P92, DOI [10.1038/nature06105, 10.1038/natureO6105]; Carandini M, 1998, NEUROPHARMACOLOGY, V37, P501, DOI 10.1016/S0028-3908(98)00069-0; Carandini M, 2002, J NEUROSCI, V22, P10053; CARANDINI M, 1994, SCIENCE, V264, P1333, DOI 10.1126/science.8191289; Carandini M, 2005, J NEUROSCI, V25, P10577, DOI 10.1523/JNEUROSCI.3726-05.2005; Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2530, DOI 10.1152/jn.00692.2001; Chichilnisky EJ, 2001, NETWORK-COMP NEURAL, V12, P199, DOI 10.1088/0954-898X/12/2/306; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; Dragoi V, 2000, NEURON, V28, P287, DOI 10.1016/S0896-6273(00)00103-3; ENROTHCU.C, 1966, J PHYSIOL-LONDON, V187, P517; Freeman RD, 2001, PROG BRAIN RES, V134, P157; Geffen MN, 2007, PLOS BIOL, V5, P640, DOI 10.1371/journal.pbio.0050065; Goldman MS, 2002, J NEUROSCI, V22, P584; Gur M, 2006, CEREB CORTEX, V16, P888, DOI 10.1093/cercor/bhj032; HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181; Helmholtz von H, 1856, HDB PHYSL OPTICS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; ITO M, 1985, J NEUROPHYSIOL, V54, P479; Jin DZ, 2005, J NEUROPHYSIOL, V94, P4038, DOI 10.1152/jn.00571.2004; Kabara JF, 2001, J NEUROPHYSIOL, V86, P2703; Knill D.C, 1996, PERCEPTION BAYESIAN; Kohn A, 2007, J NEUROPHYSIOL, V97, P3155, DOI 10.1152/jn.00086.2007; Kohn A, 2005, J NEUROSCI, V25, P3661, DOI 10.1523/JNEUROSCI.5106-04.2005; Kohn A, 2004, NAT NEUROSCI, V7, P764, DOI 10.1038/nn1267; Lochmann T, 2008, NEW J PHYS, V10, DOI 10.1088/1367-2630/10/5/055019; Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790; Machens CK, 2004, J NEUROSCI, V24, P1089, DOI 10.1523/JNEUROSCI.4445-03.2004; MAFFEI L, 1976, VISION RES, V16, P1131, DOI 10.1016/0042-6989(76)90253-4; Malone BJ, 2007, J NEUROPHYSIOL, V97, P407, DOI 10.1152/jn.00830.2006; Mizobe K, 2001, VISUAL NEUROSCI, V18, P377, DOI 10.1017/S0952523801183045; Moore CI, 1999, TRENDS NEUROSCI, V22, P513, DOI 10.1016/S0166-2236(99)01452-6; Movshon JA, 1996, J NEUROSCI, V16, P7733; Nauhaus I, 2009, NAT NEUROSCI, V12, P70, DOI 10.1038/nn.2232; Olsen SR, 2008, NATURE, V452, P956, DOI 10.1038/nature06864; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Pearl J, 1988, PROBABILISTIC REASON; Perez-Orive J, 2002, SCIENCE, V297, P359, DOI 10.1126/science.1070502; Pfister JP, 2010, NAT NEUROSCI, V13, P1271, DOI 10.1038/nn.2640; Pillow JW, 2008, NATURE, V454, P995, DOI 10.1038/nature07140; Polat U, 1998, NATURE, V391, P580; Priebe NJ, 2006, NAT NEUROSCI, V9, P552, DOI 10.1038/nn1660; Rabiner L.W., 1989, P IEEE, V77, P2; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976; Reid RC, 1997, VISUAL NEUROSCI, V14, P1015; Reisert J, 2001, J PHYSIOL-LONDON, V530, P113, DOI 10.1111/j.1469-7793.2001.0113m.x; Rieke R., 1997, SPIKES EXPLORING NEU; Rozell CJ, 2008, NEURAL COMPUT, V20, P2526, DOI 10.1162/neco.2008.03-07-486; Sceniak MP, 1999, NAT NEUROSCI, V2, P733, DOI 10.1038/11197; Sceniak MP, 2002, J NEUROPHYSIOL, V88, P1363, DOI 10.1152/jn.00967.2001; Schwabe L, 2006, J NEUROSCI, V26, P9117, DOI 10.1523/JNEUROSCI.1253-06.2006; Schwartz O, 2007, NAT REV NEUROSCI, V8, P522, DOI 10.1038/nrn2155; Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526; Shapley R, 1984, PROGR RETINAL RES, V3, P264; Sherrington C, 1906, INTEGRATIVE ACTION N; SILLITO AM, 1995, NATURE, V378, P492; Solomon SG, 2006, J NEUROSCI, V26, P8715, DOI 10.1523/JNEUROSCI.0821-06.2006; Somers DC, 1998, CEREB CORTEX, V8, P204, DOI 10.1093/cercor/8.3.204; Spratling MW, 2010, J NEUROSCI, V30, P3531, DOI 10.1523/JNEUROSCI.4911-09.2010; Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009; SRINIVASAN MV, 1982, PROC R SOC SER B-BIO, V216, P427, DOI 10.1098/rspb.1982.0085; STEMMLER M, 1995, SCIENCE, V269, P1877, DOI 10.1126/science.7569930; Stevenson IH, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012436; Stevenson RJ, 2007, PERCEPTION, V36, P1821, DOI 10.1068/p5563; Sutter ML, 2000, J NEUROPHYSIOL, V84, P1012; Teich AF, 2003, J NEUROPHYSIOL, V89, P2086, DOI 10.1152/jn.00970.2002; Theunissen FE, 2000, J NEUROSCI, V20, P2315; TOLHURST DJ, 1983, VISION RES, V23, P775, DOI 10.1016/0042-6989(83)90200-6; VanLeeuwen M, 2009, J NEUROSCI, V29, P6358, DOI 10.1523/JNEUROSCI.5834-08.2009; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; Wark B, 2009, NEURON, V61, P750, DOI 10.1016/j.neuron.2009.01.019; Wark B, 2007, CURR OPIN NEUROBIOL, V17, P423, DOI 10.1016/j.conb.2007.07.001; Wehr M, 2003, NATURE, V426, P442, DOI 10.1038/nature02116; Wiese M, 2007, VISION RES, V47, P1963, DOI 10.1016/j.visres.2007.04.010; Zemel RS, 1998, NEURAL COMPUT, V10, P403, DOI 10.1162/089976698300017818	86	15	15	SOC NEUROSCIENCE	WASHINGTON	11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA	0270-6474			J NEUROSCI	J. Neurosci.	MAR 21	2012	32	12					4179	4195		10.1523/JNEUROSCI.0817-11.2012		17	Neurosciences	Neurosciences & Neurology	916RB	WOS:000302119800020	22442081	
J	Burger, HC; Schuler, CJ; Harmeling, S			IEEE	Burger, Harold C.; Schuler, Christian J.; Harmeling, Stefan			Image denoising: Can plain Neural Networks compete with BM3D?	2012 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 16-21, 2012	Providence, RI	IEEE			WAVELET DOMAIN; ALGORITHM; SPARSE; REPRESENTATIONS; DICTIONARIES	Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. The best currently available denoising methods approximate this mapping with cleverly engineered algorithms. In this work we attempt to learn this mapping directly with a plain multi layer perceptron (MLP) applied to image patches. While this has been done before, we will show that by training on large image databases we are able to compete with the current state-of-the-art image denoising methods. Furthermore, our approach is easily adapted to less extensively studied types of noise (by merely exchanging the training data), for which we achieve excellent results as well.	[Burger, Harold C.; Schuler, Christian J.; Harmeling, Stefan] Max Planck Inst Intelligent Syst, Tubingen, Germany	Burger, HC (reprint author), Max Planck Inst Intelligent Syst, Tubingen, Germany.						Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Everingham M., PASCAL VISUAL OBJECT; Foi A, 2011, I S BIOMED IMAGING, P1809, DOI 10.1109/ISBI.2011.5872758; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Jain V., 2008, ADV NEURAL INFORM PR, V21, P769; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, NEURAL NETWORKS TRIC, P546; Levin Anat, 2011, IEEE C COMP VIS PATT; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Makitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693; Martin D., 2001, P 8 INT C COMP VIS, V2, P416, DOI 10.1109/ICCV.2001.937655; Nosratinia A, 2001, J VLSI SIG PROCESS S, V27, P69, DOI 10.1023/A:1008167430544; Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Ranzato M., 2007, P C AI STAT AI STATS; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russell B., 2007, INT J COMPUTER VISIO; Sermanet P., 2011, P INT JOINT C NEUR N; Simoncelli E. P., 1996, Proceedings. International Conference on Image Processing (Cat. No.96CH35919), DOI 10.1109/ICIP.1996.559512; Tomasi C., 1998, P IEEE INT C COMP VI, P839; Weickert J., 1998, ECMI SERIES; Weiss Y., 2007, P IEEE C COMP VIS PA, P1; Zhang S, 2005, INT CONF ACOUST SPEE, P989	28	15	15	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4673-1228-8	PROC CVPR IEEE			2012							2392	2399				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BBZ37	WOS:000309166202070		
J	Sainath, TN; Kingsbury, B; Ramabhadran, B			IEEE	Sainath, Tara N.; Kingsbury, Brian; Ramabhadran, Bhuvana			AUTO-ENCODER BOTTLENECK FEATURES USING DEEP BELIEF NETWORKS	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		Deep Belief Networks; Speech Recognition		Neural network (NN) bottleneck (BN) features are typically created by training a NN with a middle bottleneck layer. Recently, an alternative structure was proposed which trains a NN with a constant number of hidden units to predict output targets, and then reduces the dimensionality of these output probabilities through an auto-encoder, to create auto-encoder bottleneck (AE-BN) features. The benefit of placing the BN after the posterior estimation network is that it avoids the loss in frame classification accuracy incurred by networks that place the BN before the softmax. In this work, we investigate the use of pre-training when creating AE-BN features. Our experiments indicate that with the AE-BN architecture, pre-trained and deeper NNs produce better AE-BN features. On a 50-hour English Broadcast News task, the AE-BN features provide over a 1% absolute improvement compared to a state-of-the-art GMM/HMM with a WER of 18.8% and pre-trained NN hybrid system with a WER of 18.4%. In addition, on a larger 430-hour Broadcast News task, AE-BN features provide a 0.5% absolute improvement over a strong GMM/HMM baseline with a WER of 16.0%. Finally, system combination with the GMM/HMM baseline and AE-BN systems provides an additional 0.5% absolute on 430 hours over the AE-BN system alone, yielding a final WER of 15.0%.	[Sainath, Tara N.; Kingsbury, Brian; Ramabhadran, Bhuvana] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Sainath, TN (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	tsainath@us.ibm.com; bedk@us.ibm.com; bhuvana@us.ibm.com					Bourlard H.A., 1993, CONNECTIONIST SPEECH; Grezl F., 2008, P ICASSP; Grezl F., 2007, P ICASSP; Hermansky H., 2000, P ICASSP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury B., 2009, P ICASSP; Mangu L., 2011, P ASRU IN PRESS; Mohamed A., 2011, IEEE TSAP; Sainath T. N., 2011, P ASRU IN PRESS; Saon G., 2011, P ICASSP; Seide F., 2011, P INTERSPEECH; Yu D., 2011, P INTERSPEECH	12	15	15	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							4153	4156				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381404056		
J	French, RM; Addyman, C; Mareschal, D				French, Robert M.; Addyman, Caspar; Mareschal, Denis			TRACX: A Recognition-Based Connectionist Framework for Sequence Segmentation and Chunk Extraction	PSYCHOLOGICAL REVIEW			English	Article						chunk extraction; statistical learning; implicit learning; recursive autoassociative memory; autoassociators	BRIEF AUDITORY EXPERIENCE; WORD SEGMENTATION; PHONOTACTIC CONSTRAINTS; 8-MONTH-OLD INFANTS; NEURAL-NETWORKS; CONDITIONAL-PROBABILITY; LANGUAGE-ACQUISITION; ARTIFICIAL-LANGUAGE; NATURAL-LANGUAGE; SPEECH	Individuals of all ages extract structure from the sequences of patterns they encounter in their environment, an ability that is at the very heart of cognition. Exactly what underlies this ability has been the subject of much debate over the years. A novel mechanism, implicit chunk recognition (ICR), is proposed for sequence segmentation and chunk extraction. The mechanism relies on the recognition of previously encountered subsequences (chunks) in the input rather than on the prediction of upcoming items in the input sequence. A connectionist autoassociator model of ICR, truncated recursive autoassociative chunk extractor (TRACX), is presented in which chunks are extracted by means of truncated recursion. The performance and robustness of the model is demonstrated in a series of 9 simulations of empirical data, covering a wide range of phenomena from the infant statistical learning and adult implicit learning literatures, as well as 2 simulations demonstrating the model's ability to generalize to new input and to develop internal representations whose structure reflects that of the items in the input sequence. TRACX outperforms PARSER (Perruchet & Vintner, 1998) and the simple recurrent network (SRN, Cleeremans & McClelland, 1991) in matching human sequence segmentation on existing data. A new study is presented exploring 8-month-olds' use of backward transitional probabilities to segment auditory sequences.	[French, Robert M.] Univ Bourgogne, LEAD CNRS UMR 5022, Pole AAFE,Ctr Natl Rech Sci,Unite Mixte Rech 5022, Lab Etud Apprentissage & Dev,Dept Psychol, Dijon, France; [Addyman, Caspar] Univ Bourgogne, Dept Psychol, LEAD CNRS UMR 5022, F-21004 Dijon, France; [Addyman, Caspar; Mareschal, Denis] Birkbeck Univ London, CBCD, Dept Psychol Sci, London, England	French, RM (reprint author), Univ Bourgogne, LEAD CNRS UMR 5022, Pole AAFE,Ctr Natl Rech Sci,Unite Mixte Rech 5022, Lab Etud Apprentissage & Dev,Dept Psychol, Dijon, France.	robert.french@u-bourgogne.fr	Mareschal, Denis/C-4671-2008; Addyman, Caspar/	Mareschal, Denis/0000-0002-9828-9548; Addyman, Caspar/0000-0003-0001-9548	European Commission [FP6-NEST-029088]; French Agence Nationale de la Recherche [ANR-10-065-GETPIMA]; United Kingdom Economic and Social Research Council [RES-062-23-0819]; Open Research Area France-United Kingdom funding initiative	This work was made possible in part by European Commission Grant FP6-NEST-029088, French Agence Nationale de la Recherche Grant ANR-10-065-GETPIMA, and United Kingdom Economic and Social Research Council Grant RES-062-23-0819 under the auspices of the Open Research Area France-United Kingdom funding initiative. We thank Pierre Perruchet for his many insightful comments on the work in this article, his assistance in the preparation of the familiarization sequence and test stimuli for the replication of Aslin et al. (1998), and his allowing us to use his input-data encodings for a number of the simulations presented in this article.	Altmann GTM, 2002, COGNITION, V85, pB43, DOI 10.1016/S0010-0277(02)00106-3; Anderson B, 1999, BRAIN LANG, V70, P86, DOI 10.1006/brln.1999.2145; ANDERSON JA, 1977, PSYCHOL REV, V84, P413, DOI 10.1037//0033-295X.84.5.413; Aslin RN, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P117; Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063; Bernstein-Ratner N, 1987, CHILDRENS LANGUAGE, V6, P159; BERRY DC, 1984, Q J EXP PSYCHOL-A, V36, P209; BLANK DS, 1992, COG SCI SER, P113; Bloom P., 1997, TRENDS COGN SCI, V11, P9; Boucher L, 2003, COGNITIVE SCI, V27, P807, DOI 10.1016/j.cogsci.2003.03.001; Brent MR, 1996, COGNITION, V61, P93, DOI 10.1016/S0010-0277(96)00719-6; Brent MR, 1999, MACH LEARN, V34, P71, DOI 10.1023/A:1007541817488; CAIRNS P, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P136; Cairns P, 1997, COGNITIVE PSYCHOL, V33, P111, DOI 10.1006/cogp.1997.0649; Casillas G, 2008, LINGUA, V118, P636, DOI 10.1016/j.lingua.2007.03.007; Chalmers D. J., 1990, Connection Science, V2, DOI 10.1080/09540099008915662; Chambers KE, 2010, J EXP PSYCHOL LEARN, V36, P821, DOI 10.1037/a0018991; Chambers KE, 2003, COGNITION, V87, pB69, DOI 10.1016/S0010-0277(02)00233-0; Christiansen MH, 1999, PROCEEDINGS OF THE TWENTY FIRST ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P114; Christiansen MH, 2009, DEVELOPMENTAL SCI, V12, P388, DOI 10.1111/j.1467-7687.2009.00824.x; Christiansen MH, 1998, LANG COGNITIVE PROC, V13, P221; Christoff K, 2003, BEHAV NEUROSCI, V117, P1161, DOI 10.1037/0735-7044.117.6.1161; Clark RE, 1998, SCIENCE, V280, P77, DOI 10.1126/science.280.5360.77; CLEEREMANS A, 1991, J EXP PSYCHOL GEN, V120, P235, DOI 10.1037/0096-3445.120.3.235; Cleeremans A., 1993, MECH IMPLICIT LEARNI, DOI [10.1007/BF00114843, DOI 10.1007/BF00114843]; Cole R. A., 1980, PERCEPTION PRODUCTIO, P133; Cooper W. E., 1980, SYNTAX SPEECH; Cottrell G. W., 1991, ADV NEURAL INFORMATI, P564; Cottrell GW, 1988, ADV COGNITIVE SCI, V3, P208; CRICK F, 1989, NATURE, V337, P129, DOI 10.1038/337129a0; Cunillera T, 2010, EXP PSYCHOL, V57, P134, DOI 10.1027/1618-3169/a000017; Dahan D, 1999, J EXP PSYCHOL GEN, V128, P165, DOI 10.1037/0096-3445.128.2.165; Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; de Marcken C., 1995, 1558 AI MIT; Destrebecqz A, 2001, PSYCHON B REV, V8, P343, DOI 10.3758/BF03196171; Cleeremans A, 2008, CAMB HANDB PSYCHOL, P396; DIENES Z, 1992, COGNITIVE SCI, V16, P41, DOI 10.1207/s15516709cog1601_2; Dienes Z, 1999, BEHAV BRAIN SCI, V22, P735; Dominey PF, 2000, LANG COGNITIVE PROC, V15, P87; Dominey PF, 1998, COGNITIVE BRAIN RES, V6, P163, DOI 10.1016/S0926-6410(97)00029-3; DULANY DE, 1984, J EXP PSYCHOL GEN, V113, P541, DOI 10.1037/0096-3445.113.4.541; Dutoit T., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607874; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Fahlman S. E., 1988, P 1988 CONN MOD SUMM, P38; Farrell S, 2002, PSYCHON B REV, V9, P59, DOI 10.3758/BF03196257; Fiser J, 2002, P NATL ACAD SCI USA, V99, P15822, DOI 10.1073/pnas.232472899; Frank MC, 2010, COGNITION, V117, P107, DOI 10.1016/j.cognition.2010.07.005; French R., 2002, IMPLICIT LEARNING CO; French RM, 1998, PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P368; French R. M., 2001, P 23 ANN C COGN SCI, P307; French RM, 2004, J EXP PSYCHOL GEN, V133, P382, DOI 10.1037/0096-3445.133.3.382; Gambell T., 2005, MECH CONSTRAIN UNPUB; Gambell T., 2003, P 34 NE LING SOC M, P368; Gelbard-Sagiv H, 2008, SCIENCE, V322, P96, DOI 10.1126/science.1164685; Giroux I, 2009, COGNITIVE SCI, V33, P260, DOI 10.1111/j.1551-6709.2009.01012.x; Gluck MA, 1997, ANNU REV PSYCHOL, V48, P481, DOI 10.1146/annurev.psych.48.1.481; GLUCK MA, 1993, ANNU REV NEUROSCI, V16, P667, DOI 10.1146/annurev.ne.16.030193.003315; GOLDWATER S, 2006, P 21 INT C COMP LING, P673, DOI DOI 10.1016/J.COGNITION.2009.03.008; Goldwater S, 2009, COGNITION, V112, P21, DOI 10.1016/j.cognition.2009.03.008; Graf Estes Katharine, 2007, Psychol Sci, V18, P254, DOI 10.1111/j.1467-9280.2007.01885.x; Gupta P, 2002, PSYCHOL REV, V109, P401, DOI 10.1037//0033-295X.109.2.401; Harris ZS, 1955, LANGUAGE, V31, P190, DOI 10.2307/411036; Harris ZS, 1954, WORD, V10, P146; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holmes P, 2008, J MOTOR BEHAV, V40, P433, DOI 10.3200/JMBR.40.5.433-445; JEANNEROD M, 1995, NEUROPSYCHOLOGIA, V33, P1419, DOI 10.1016/0028-3932(95)00073-C; Johnson EK, 2001, J MEM LANG, V44, P548, DOI 10.1006/jmla.2000.2755; JOHNSON MK, 1981, PSYCHOL REV, V88, P67, DOI 10.1037//0033-295X.88.1.67; Jusczyk PW, 1999, PERCEPT PSYCHOPHYS, V61, P1465, DOI 10.3758/BF03213111; Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716; JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010; Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5; KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986; Korman M., 1984, 1 LANGUAGE, V5, P44; Lebiere C., 1998, P 2 C COGN MOD ECCM, P183; LUCE RD, 1995, ANNU REV PSYCHOL, V46, P1, DOI 10.1146/annurev.ps.46.020195.000245; MACWHINNEY B, 1985, J CHILD LANG, V12, P271; Marcovitch S, 2009, DEVELOPMENTAL SCI, V12, P1020, DOI 10.1111/j.1467-7687.2009.00838.x; Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77; Mareschal D., 2010, NEOCONSTRUCTIVISM NE, P213; Mareschal D, 2000, DEV PSYCHOL, V36, P635, DOI 10.1037//0012-1649.36.5.635; Mareschal D, 2000, INFANCY, V1, P59, DOI 10.1207/S15327078IN0101_06; Maskara A., 1993, Connection Science, V5, DOI 10.1080/09540099308915692; MATHEWS RC, 1989, J EXP PSYCHOL LEARN, V15, P1083, DOI 10.1037//0278-7393.15.6.1083; Mattys SL, 1999, COGNITIVE PSYCHOL, V38, P465, DOI 10.1006/cogp.1999.0721; McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002; Mirman D, 2010, INFANCY, V15, P471, DOI 10.1111/j.1532-7078.2009.00023.x; Mirman D, 2008, COGNITION, V108, P271, DOI 10.1016/j.cognition.2008.02.003; NAKATANI LH, 1978, J ACOUST SOC AM, V63, P234, DOI 10.1121/1.381719; Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037//0096-1523.24.3.756; NISBETT RE, 1977, PSYCHOL REV, V84, P231, DOI 10.1037/0033-295X.84.3.231; NISSEN MJ, 1987, COGNITIVE PSYCHOL, V19, P1, DOI 10.1016/0010-0285(87)90002-8; O'Reilly RC, 2000, COMPUTATIONAL EXPLOR; Onishi KH, 2002, COGNITION, V83, pB13, DOI 10.1016/S0010-0277(01)00165-2; Pacton S, 2001, J EXP PSYCHOL GEN, V130, P401, DOI 10.1037//0096-3445.130.3.401; Pelucchi B, 2009, COGNITION, V113, P244, DOI 10.1016/j.cognition.2009.07.011; Pelucchi B, 2009, CHILD DEV, V80, P674, DOI 10.1111/j.1467-8624.2009.01290.x; Perlman A, 2010, J EXP PSYCHOL HUMAN, V36, P649, DOI 10.1037/a0017178; Perruchet P, 2008, MEM COGNITION, V36, P1299, DOI 10.3758/MC.36.7.1299; Perruchet P, 2002, BEHAV BRAIN SCI, V25, P297; Perruchet P, 2006, TRENDS COGN SCI, V10, P233, DOI 10.1016/j.tics.2006.03.006; Perruchet P, 1998, J MEM LANG, V39, P246, DOI 10.1006/jmla.1998.2576; Perruchet P, 2010, COGNITIVE SCI, V34, P255, DOI 10.1111/j.1551-6709.2009.01074.x; PERRUCHET P, 1990, J EXP PSYCHOL GEN, V119, P264, DOI 10.1037//0096-3445.119.3.264; Plunkett K., 1992, Connection Science, V4, DOI 10.1080/09540099208946620; Pollack J., 1989, ADV NEURAL INFORMATI, P527; POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K; Pothos EM, 2007, PSYCHOL BULL, V133, P227, DOI 10.1037/0033-2909.133.2.227; Quine W. van Orman, 1960, WORD OBJECT; REBER AS, 1967, J VERB LEARN VERB BE, V6, P855, DOI 10.1016/S0022-5371(67)80149-X; Robinet V., 2009, P 31 ANN C COGN SCI, P3866; Rolls ET, 1997, NEURAL NETWORKS BRAI; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Saffran JR, 2001, COGNITION, V81, P149, DOI 10.1016/S0010-0277(01)00132-9; Saffran JR, 1997, PSYCHOL SCI, V8, P101, DOI 10.1111/j.1467-9280.1997.tb00690.x; Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4; Saffran JR, 2003, INFANCY, V4, P273, DOI 10.1207/S15327078IN0402_07; Seidenberg MS, 1999, SCIENCE, V284, P434; SERVANSCHREIBER D, 1991, MACH LEARN, V7, P161, DOI 10.1007/BF00114843; SERVANSCHREIBER E, 1990, J EXP PSYCHOL LEARN, V16, P592, DOI 10.1037/0278-7393.16.4.592; Shanks D., 2005, HDB COGNITION, P202; Shanks DR, 2010, ANNU REV PSYCHOL, V61, P273, DOI 10.1146/annurev.psych.093008.100519; Sirois S, 2004, J COGNITIVE NEUROSCI, V16, P1352, DOI 10.1162/0898929042304778; Sirois S, 2000, DEVELOPMENTAL SCI, V3, P442, DOI 10.1111/1467-7687.00138; Sun R, 1997, NEURAL NETWORKS, V10, P1317, DOI 10.1016/S0893-6080(97)00050-6; Swingley D, 2005, COGNITIVE PSYCHOL, V50, P86, DOI 10.1016/j.cogpsych.2004.06.001; Thiessen ED, 2009, ANN NY ACAD SCI, V1169, P225, DOI 10.1111/j.1749-6632.2009.04547.x; Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706; Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5; van de Weijer J., 1998, THESIS U NIJMEGEN NI; Venkataraman A, 2001, COMPUT LINGUIST, V27, P351, DOI 10.1162/089120101317066113; Waxman SR, 2001, COGNITIVE PSYCHOL, V43, P217, DOI 10.1006/cogp.2001.0764	133	15	15	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0033-295X			PSYCHOL REV	Psychol. Rev.	OCT	2011	118	4					614	636		10.1037/a0025255		23	Psychology; Psychology, Multidisciplinary	Psychology	836DE	WOS:000296088300005	22003842	
J	Ling, ZH; Deng, L; Yu, D				Ling, Zhen-Hua; Deng, Li; Yu, Dong			Modeling Spectral Envelopes Using Restricted Boltzmann Machines and Deep Belief Networks for Statistical Parametric Speech Synthesis	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep belief network; hidden Markov model; restricted Boltzmann machine; spectral envelope; speech synthesis	ARTICULATORY FEATURES; NEURAL-NETWORKS; HMM; RECOGNITION; ALGORITHM; SYSTEM	This paper presents a new spectral modeling method for statistical parametric speech synthesis. In the conventional methods, high-level spectral parameters, such as mel-cepstra or line spectral pairs, are adopted as the features for hidden Markov model (HMM)-based parametric speech synthesis. Our proposed method described in this paper improves the conventional method in two ways. First, distributions of low-level, un-transformed spectral envelopes (extracted by the STRAIGHT vocoder) are used as the parameters for synthesis. Second, instead of using single Gaussian distribution, we adopt the graphical models with multiple hidden variables, including restricted Boltzmann machines (RBM) and deep belief networks (DBN), to represent the distribution of the low-level spectral envelopes at each HMM state. At the synthesis time, the spectral envelopes are predicted from the RBM-HMMs or the DBN-HMMs of the input sentence following the maximum output probability parameter generation criterion with the constraints of the dynamic features. A Gaussian approximation is applied to the marginal distribution of the visible stochastic variables in the RBM or DBN at each HMM state in order to achieve a closed-form solution to the parameter generation problem. Our experimental results show that both RBM-HMM and DBN-HMM are able to generate spectral envelope parameter sequences better than the conventional Gaussian-HMM with superior generalization capabilities and that DBN-HMM and RBM-HMM perform similarly due possibly to the use of Gaussian approximation. As a result, our proposed method can significantly alleviate the over-smoothing effect and improve the naturalness of the conventional HMM-based speech synthesis system using mel-cepstra.	[Ling, Zhen-Hua] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China; [Deng, Li; Yu, Dong] Microsoft Res, Redmond, WA 98052 USA	Ling, ZH (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China.	zhling@ustc.edu.cn; deng@microsoft.com; dongyu@microsoft.com			National Nature Science Foundation of China [61273032]; China Scholarship Council Young Teacher Study Abroad Project	Manuscript received January 25, 2013; revised April 18, 2013; accepted June 13, 2013. Date of publication June 18, 2013; date of current version July 22, 2013. This work was supported in part by the National Nature Science Foundation of China under Grant No. 61273032 and in part by the China Scholarship Council Young Teacher Study Abroad Project. This paper is the expanded version of the conference paper published in ICASSP-2013 [1]. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Chung-Hsien Wu.	Abdel-Hamid O, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1332; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; Chen L.H., 2013, P INTERSPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L, 2000, J ACOUST SOC AM, V108, P3036, DOI 10.1121/1.1315288; Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692; Deng L, 2003, SPEECH PROCESSING DY; DENG L, 1994, J ACOUST SOC AM, V95, P2702, DOI 10.1121/1.409839; Fernandez R., 2013, P ICASSP, P6885; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; KANG SY, 2013, P ICASSP, P8012; Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5; Ling ZH, 2012, IEEE T AUDIO SPEECH, V20, P1492, DOI 10.1109/TASL.2011.2182511; Ling ZH, 2010, SPEECH COMMUN, V52, P834, DOI 10.1016/j.specom.2010.06.006; Ling ZH, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2034; Ling Z.-H., 2006, P BLIZZ CHALL WORKSH; Ling Z.-H., 2013, P ICASSP, P7825; Ling ZH, 2009, IEEE T AUDIO SPEECH, V17, P1171, DOI 10.1109/TASL.2009.2014796; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Paliwal KK, 1993, IEEE T SPEECH AUDI P, V1, P3, DOI 10.1109/89.221363; Salakhutdinov R., 2009, THESIS U TORONTO TOR; Shannon M., 2011, P INTERSPEECH, V2011, P121; Shinoda K., 2000, Journal of the Acoustical Society of Japan (E), V21, DOI 10.1250/ast.21.79; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Toda T., 2011, HIDDEN MARKOV MODELS; Toda T, 2007, IEICE T INF SYST, VE90D, P816, DOI 10.1093/ietisy/e90-d.5.816; Tokuda K., 2004, REFORMULATING HMM TR; Tokuda K., 2004, TEXT SPEECH SYNTHESI; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Tokuda K, 2002, IEICE T INF SYST, VE85D, P455; Uria B., 2011, P NIPS 2011 WORKSH D; Wu YJ, 2006, INT CONF ACOUST SPEE, P89; Yoshimura T., 2001, P EUROSPEECH, P2263; Yoshimura T., 1999, P EUR, P2347; Yu J, 2007, INT CONF ACOUST SPEE, P709; Zen H., 2013, P ICASSP, P7962; Zen H, 2007, COMPUT SPEECH LANG, V21, P153, DOI 10.1016/j.csl.2006.01.002; Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004; Zen HG, 2007, IEICE T INF SYST, VE90D, P325, DOI 10.1093/ietisy/e90-d.1.325	42	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	OCT	2013	21	10					2129	2139		10.1109/TASL.2013.2269291		11	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	190JE	WOS:000322334900012		
J	Eickholt, J; Cheng, JL				Eickholt, Jesse; Cheng, Jianlin			Predicting protein residue-residue contacts using deep networks and boosting	BIOINFORMATICS			English	Article							NEURAL-NETWORKS; CORRELATED MUTATIONS; MAP PREDICTION; MODELS; INFORMATION	Motivation: Protein residue-residue contacts continue to play a larger and larger role in protein tertiary structure modeling and evaluation. Yet, while the importance of contact information increases, the performance of sequence-based contact predictors has improved slowly. New approaches and methods are needed to spur further development and progress in the field. Results: Here we present DNCON, a new sequence-based residue-residue contact predictor using deep networks and boosting techniques. Making use of graphical processing units and CUDA parallel computing technology, we are able to train large boosted ensembles of residue-residue contact predictors achieving state-of-the-art performance.	[Eickholt, Jesse; Cheng, Jianlin] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA; [Cheng, Jianlin] Univ Missouri, Inst Informat, Columbia, MO 65211 USA; [Cheng, Jianlin] Univ Missouri, C Bond Life Sci Ctr, Columbia, MO 65211 USA	Cheng, JL (reprint author), Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.	chengji@missouri.edu	Cheng, Jianlin/N-8209-2013		National Library of Medicine Biomedical and Health Informatics Training fellowship; NIH NIGMS [R01GM093123]	The work was partially supported by a National Library of Medicine Biomedical and Health Informatics Training fellowship (to J.E.) and a NIH NIGMS grant (R01GM093123 to J.C.).	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Atchley WR, 2005, P NATL ACAD SCI USA, V102, P6395, DOI 10.1073/pnas.0408677102; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bjorkholm P, 2009, BIOINFORMATICS, V25, P1264, DOI 10.1093/bioinformatics/btp149; Cheng JL, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-113; Cheng J, 2005, NUCLEIC ACIDS RES, V33, pW72, DOI 10.1093/nar/gki396; Cuff AL, 2011, NUCLEIC ACIDS RES, V39, pD420, DOI 10.1093/nar/gkq1001; Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475; Eickholt J, 2011, BMC STRUCT BIOL, V11, DOI 10.1186/1472-6807-11-38; Ezkurdia I, 2009, PROTEINS, V77, P196, DOI 10.1002/prot.22554; Fariselli P, 2001, PROTEIN ENG, V14, P835, DOI 10.1093/protein/14.11.835; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GOBEL U, 1994, PROTEINS, V18, P309, DOI 10.1002/prot.340180402; Grana O, 2005, PROTEINS, V61, P214, DOI 10.1002/prot.20739; Hamilton N, 2004, PROTEINS, V56, P679, DOI 10.1002/prot.20160; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, UTML2010003 U TOR; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 2002, NEURAL COMPUT, V14, P30; Huang ES, 1996, J MOL BIOL, V257, P716, DOI 10.1006/jmbi.1996.0196; Izarzugaza JMG, 2007, PROTEINS, V69, P152, DOI 10.1002/prot.21637; Jones DT, 2012, BIOINFORMATICS, V28, P184, DOI 10.1093/bioinformatics/btr638; Kliger Y, 2009, P NATL ACAD SCI USA, V106, P13797, DOI 10.1073/pnas.0906514106; Li YQ, 2011, BIOINFORMATICS, V27, P3379, DOI 10.1093/bioinformatics/btr579; Lippi M, 2009, BIOINFORMATICS, V25, P2326, DOI 10.1093/bioinformatics/btp421; Miller CS, 2008, BIOINFORMATICS, V24, P1575, DOI 10.1093/bioinformatics/btn248; Miyazawa S, 1999, PROTEINS, V36, P357, DOI 10.1002/(SICI)1097-0134(19990815)36:3<357::AID-PROT10>3.0.CO;2-U; Mnih V., 2009, TECHNICAL REPORT; Monastyrskyy B, 2011, PROTEINS, V79, P119, DOI 10.1002/prot.23160; Moult J, 2011, PROTEINS, V79, P1, DOI 10.1002/prot.23200; Olmea O, 1997, FOLD DES, V2, pS25, DOI 10.1016/S1359-0278(97)00060-6; Pollastri G, 2002, Bioinformatics, V18 Suppl 1, pS62; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tegge AN, 2009, NUCLEIC ACIDS RES, V37, pW515, DOI 10.1093/nar/gkp305; Tress ML, 2010, PROTEINS, V78, P1980, DOI 10.1002/prot.22714; Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430; Vicatos S, 2005, PROTEINS, V58, P935, DOI 10.1002/prot.20370; Walsh I, 2009, BMC STRUCT BIOL, V9, DOI 10.1186/1472-6807-9-5; Wang Z, 2011, BIOINFORMATICS, V27, P1715, DOI 10.1093/bioinformatics/btr268; Wu S, 2008, BIOINFORMATICS, V24, P924, DOI 10.1093/bioinformatics/btn069; Wu ST, 2011, STRUCTURE, V19, P1182, DOI 10.1016/j.str.2011.05.004; Xue B, 2009, PROTEINS, V76, P176, DOI 10.1002/prot.22329; Zhu HY, 1999, PROTEIN SCI, V8, P326	43	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	DEC 1	2012	28	23					3066	3072		10.1093/bioinformatics/bts598		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	048HT	WOS:000311902700008	23047561	
J	Sainath, TN; Ramabhadran, B; Nahamoo, D; Kanevsky, D; Van Compernolle, D; Demuynck, K; Gemmeke, JF; Bellegarda, JR; Sundaram, S				Sainath, Tara N.; Ramabhadran, Bhuvana; Nahamoo, David; Kanevsky, Dimitri; Van Compernolle, Dirk; Demuynck, Kris; Gemmeke, Jort Florent; Bellegarda, Jerome R.; Sundaram, Shiva			Exemplar-Based Processing for Speech Recognition	IEEE SIGNAL PROCESSING MAGAZINE			English	Article							SPARSE IMPUTATION; FACE RECOGNITION; CLASSIFICATION; AUDIO; RETRIEVAL; ENTROPY		[Sainath, Tara N.] IBM TJ Watson Ctr, Speech & Language Algorithms Grp, Yorktown Hts, NY USA; [Ramabhadran, Bhuvana] IBM TJ Watson Ctr, Speech Transcript & Synth Res Grp, Yorktown Hts, NY USA; [Ramabhadran, Bhuvana] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA; [Kanevsky, Dimitri] IBM TJ Watson Ctr, Dept Speech & Language Algorithms, Yorktown Hts, NY USA; [Kanevsky, Dimitri] Inst Adv Studies, Princeton, NJ USA; [Van Compernolle, Dirk] Katholieke Univ Leuven, Dept Elect Engn, Louvain, Belgium; [Van Compernolle, Dirk] INTERSPEECH, Antwerp, Belgium; [Demuynck, Kris] Katholieke Univ Leuven, Dept Elect Engn ESAT, Louvain, Belgium; [Sundaram, Shiva] Tech Univ Berlin, Berlin, Germany	Sainath, TN (reprint author), IBM TJ Watson Ctr, Speech & Language Algorithms Grp, Yorktown Hts, NY USA.	tsainath@us.ibm.com; bhuvana@us.ibm.com; nahamoo@us.ibm.com; kanevsky@us.ibm.com; Dirk.VanCompernolle@esat.kuleuven.be; kris.demuynck@esat.kuleuven.be; jgemmeke@amadana.nl; jerome@apple.com; shiva.sundaram@ieee.org	Magazine, Signal Processing/E-9947-2015				Aradilla J. V. G., 2006, P ICSLP, P2570; Belkin M., 2003, P 15 ANN C NEUR INF, P929; Bellegarda JR, 2005, IEEE SIGNAL PROC MAG, V22, P70, DOI 10.1109/MSP.2005.1511825; Berger AL, 1996, COMPUT LINGUIST, V22, P39; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; De Wachter M., 2004, P ICASSP MONTR CAN, P181; De Wachter M., 2007, THESIS ESAT K U LEUV; De Wachter M., 2007, P EUR C SPEECH COMM, P1485; Demange S, 2009, P INTERSPEECH SEPT, P3067; Demuynck K, 2011, INT CONF ACOUST SPEE, P5048; Demuynck K, 2011, INT CONF ACOUST SPEE, P4692; Deselaers T., 2007, P INT, P2093; De Wachter M, 2007, IEEE T AUDIO SPEECH, V15, P1377, DOI 10.1109/TASL.2007.894524; DeWachter M., 2003, P EUROSPEECH, P1133; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P1, DOI 10.1007/978-1-4419-7011-4; Gemmeke J. F., 2009, P EUSIPCO GLASG SCOT, P1755; Gemmeke J. F., 2011, P EUSIPCO, P1490; Gemmeke JF, 2009, INT CONF ACOUST SPEE, P4645, DOI 10.1109/ICASSP.2009.4960666; Gemmeke JF, 2011, IEEE T AUDIO SPEECH, V19, P2067, DOI 10.1109/TASL.2011.2112350; Gemmeke JF, 2011, COMPUT SPEECH LANG, V25, P462, DOI 10.1016/j.csl.2010.06.004; Glass JR, 2003, COMPUT SPEECH LANG, V17, P137, DOI 10.1016/S0885-2308(03)00006-8; Golipour L, 2009, INT CONF ACOUST SPEE, P1341, DOI 10.1109/ICASSP.2009.4959840; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jelinek F., 1997, STAT METHODS SPEECH; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Lamel L., 1986, P DARPA SPEECH REC W; Lee K, 2010, IEEE T AUDIO SPEECH, V18, P1406, DOI 10.1109/TASL.2009.2034776; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1; Mika S, 1999, P IEEE NEUR NETW SIG, P41; Mitchell T. M., 1997, MACHINE LEARNING; Mordohai P, 2010, J MACH LEARN RES, V11, P411; MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844; Nilsson M, 2007, IEEE T INFORM THEORY, V53, P2330, DOI 10.1109/TIT.2007.899533; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Panagakis Y., 2009, P EUR SIGN PROC C GL, P1; Plumbley M. D., 2009, P IEEE, V98, P995; Raj B, 2005, IEEE SIGNAL PROC MAG, V22, P101, DOI 10.1109/MSP.2005.1511828; SAINATH T, 2010, P INTERSPEECH, P2254; Sainath T. N., 2011, P ASRU, P59; Sainath TN, 2011, P ICASSP; Sainath T.N., 2011, P INTERSPEECH, P785; Samet H., 2008, P INT C PATT REC; Schmidt M. N., 2007, P IEEE WORKSH APPL S, P26; Seltzer M., 2011, P ASRU; Silverman B.W., 1986, DENSITY ESTIMATION S; Singh-Miller N., 2009, P NIPS, P1678; Smaragdis P., 2009, P NEUR INF PROC SYST, P1705; Smaragdis P., 2003, P IEEE WORKSH APPL S, P177, DOI DOI 10.1109/ASPAA.2003.1285860; Sun Y., 2011, P INTERSPEECH, P1669; SUNDARAM S, 2008, P IEEE C MULT EXP IC, P1341; Sundaram S., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288826; Sundaram S, 2008, INT CONF ACOUST SPEE, P49, DOI 10.1109/ICASSP.2008.4517543; Sundaram S, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P881; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Van Hamme H, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2554; Vapnik V. N., 1995, NATURE STAT LEARNING; Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253; Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zhang H., 2006, P IEEE C COMP VIS PA, P2126, DOI DOI 10.1109/CVPR.2006.301; Zweig G., 2007, P ASRU, P152	64	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888	1558-0792		IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	NOV	2012	29	6					98	113		10.1109/MSP.2012.2208663		16	Engineering, Electrical & Electronic	Engineering	027IF	WOS:000310345000011		
J	Stuhlsatz, A; Lippel, J; Zielke, T				Stuhlsatz, Andre; Lippel, Jens; Zielke, Thomas			Feature Extraction with Deep Neural Networks by a Generalized Discriminant Analysis	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Deep neural networks; dimensionality reduction; discriminant analysis; face detection; feature extraction; restricted Boltzmann machines; sensor fusion	FACE DETECTION; LEARNING ALGORITHM; DIMENSIONALITY; RECOGNITION	We present an approach to feature extraction that is a generalization of the classical linear discriminant analysis (LDA) on the basis of deep neural networks (DNNs). As for LDA, discriminative features generated from independent Gaussian class conditionals are assumed. This modeling has the advantages that the intrinsic dimensionality of the feature space is bounded by the number of classes and that the optimal discriminant function is linear. Unfortunately, linear transformations are insufficient to extract optimal discriminative features from arbitrarily distributed raw measurements. The generalized discriminant analysis (GerDA) proposed in this paper uses nonlinear transformations that are learnt by DNNs in a semisupervised fashion. We show that the feature extraction based on our approach displays excellent performance on real-world recognition and detection tasks, such as handwritten digit recognition and face detection. In a series of experiments, we evaluate GerDA features with respect to dimensionality reduction, visualization, classification, and detection. Moreover, we show that GerDA DNNs can preprocess truly high-dimensional input data to low-dimensional representations that facilitate accurate predictions even if simple linear predictors or measures of similarity are used.	[Stuhlsatz, Andre] SMS Siemag AG, Div Res & Dev, D-40237 Dusseldorf, Germany; [Lippel, Jens; Zielke, Thomas] Dusseldorf Univ Appl Sci, Dept Mech & Proc Engn, D-40474 Dusseldorf, Germany	Stuhlsatz, A (reprint author), SMS Siemag AG, Div Res & Dev, D-40237 Dusseldorf, Germany.	andre.stuhlsatz@sms-siemag.com; jens.lippel@fh-duesseldorf.de; thomas.zielke@fh-duesseldorf.de					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bhuiyan A.-A., 2007, WORLD ACAD SCI ENG T, V28, P51; Bohme M, 2009, LECT NOTES COMPUT SC, V5742, P167; Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1; Cai D, 2007, IEEE DATA MINING, P427; Cook J, 2007, IEEE T INF FOREN SEC, V2, P529, DOI 10.1109/TIFS.2007.902405; Dhir CS, 2011, IEEE T NEURAL NETWOR, V22, P845, DOI 10.1109/TNN.2011.2122266; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fisher RA, 1936, ANN EUGENIC, V7, P179; Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Islam MM, 2009, IEEE T SYST MAN CY B, V39, P705, DOI 10.1109/TSMCB.2008.2008724; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kashima H, 2009, IEICE T INF SYST, VE92D, P1338, DOI 10.1587/transinf.E92.D.1338; Kolb A., 2008, P IEEE C CVPR ANCH A, P1; Kovesi P.D., MATLAB OCTAVE FUNCTI; Labusch K, 2008, IEEE T NEURAL NETWOR, V19, P1985, DOI 10.1109/TNN.2008.2005830; Larochelle H., 2009, J MACHINE LEARNING R; LeCun Y., MNIST DATABASE HANDW; Li P., 2010, P IEEE INFOCOM, P1; Maaten L, 2009, P AISTATS JMLR WCP, V5, P384; Mallapragada Pavan Kumar, 2009, IEEE Trans Pattern Anal Mach Intell, V31, P2000, DOI 10.1109/TPAMI.2008.235; Mika S, 1999, P IEEE NEUR NETW SIG, P41; Nie F, 2007, P IEEE C COMP VIS PA, P1; Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958; OSMAN H, 1994, IEEE T PATTERN ANAL, V16, P837, DOI 10.1109/34.308481; Ranzato M. A., 2006, ADV NEURAL INFORM PR; Salakhutdinov R., 2007, P INT C ART INT STAT, V11, P1; Sips M, 2009, COMPUT GRAPH FORUM, V28, P831; Sonka M, 1998, IMAGE PROCESSING ANA; Stuhlsatz Andre, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), DOI 10.1109/ICPR.2010.377; Stuhlsatz A., 2010, P INT JOINT C NEUR N, P1; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Sugiyama M, 2007, J MACH LEARN RES, V8, P1027; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Wolf C, 2010, COMM COM INF SC, V97, P200; Ye J., 2009, BIOMETRICS THEORY ME, P1, DOI 10.1002/9780470522356.ch1; Zhang CS, 2010, NEUROCOMPUTING, V73, P959, DOI 10.1016/j.neucom.2009.08.014; Zhang Y, 2011, IEEE T NEURAL NETWOR, V22, P1207, DOI 10.1109/TNN.2011.2156808; Zheng WM, 2010, IEEE T NEURAL NETWOR, V21, P393, DOI 10.1109/TNN.2009.2037149	45	14	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X			IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	APR	2012	23	4					596	608		10.1109/TNNLS.2012.2183645		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	924QE	WOS:000302705600006	24805043	
J	Schmah, T; Yourganov, G; Zemel, RS; Hinton, GE; Small, SL; Strother, SC				Schmah, Tanya; Yourganov, Grigori; Zemel, Richard S.; Hinton, Geoffrey E.; Small, Steven L.; Strother, Stephen C.			Comparing Classification Methods for Longitudinal fMRI Studies	NEURAL COMPUTATION			English	Article							SUPPORT VECTOR MACHINES; OBJECT RECOGNITION; NEUROIMAGING DATA; BRAIN IMAGES; PREDICTION; CLASSIFIERS; PIPELINES; SELECTION; PATTERNS; CORTEX	We compare 10 methods of classifying fMRI volumes by applying them to data from a longitudinal study of stroke recovery: adaptive Fisher's linear and quadratic discriminant; gaussian naive Bayes; support vector machines with linear, quadratic, and radial basis function (RBF) kernels; logistic regression; two novel methods based on pairs of restricted Boltzmann machines (RBM); and K-nearest neighbors. All methods were tested on three binary classification tasks, and their out-of-sample classification accuracies are compared. The relative performance of the methods varies considerably across subjects and classification tasks. The best overall performers were adaptive quadratic discriminant, support vector machines with RBF kernels, and generatively trained pairs of RBMs.	[Schmah, Tanya; Zemel, Richard S.; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Strother, Stephen C.] Univ Toronto, Baycrest Ctr, Rotman Res Inst, Dept Med Biophys, Toronto, ON M6A 2E1, Canada; [Yourganov, Grigori; Strother, Stephen C.] Univ Toronto, Inst Med Sci, Toronto, ON M6A 2E1, Canada; [Small, Steven L.] Univ Chicago, Dept Neurol, Chicago, IL 60637 USA	Schmah, T (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.	schmah@cs.toronto.edu; gyourganov@rotman-baycrest.on.ca; zemel@cs.toronto.edu; hinton@cs.toronto.edu; small@uchicago.edu; sstrother@rotman-baycrest.on.ca			Brain Network Recovery Group through the James S. McDonnell Foundation [22002082]; National Institutes of Health [R01 DC7488]; Centre for Stroke Recovery of the Heart and Stroke Foundation of Ontario	We thank Natasa Kovacevic for coregistering and motion-correcting the fMRI data used in this study. This work was supported by the Brain Network Recovery Group through a grant from the James S. McDonnell Foundation (No. 22002082) and a grant from the National Institutes of Health (No. R01 DC7488). S. C. S. is partially supported by the Centre for Stroke Recovery of the Heart and Stroke Foundation of Ontario.	Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Carroll MK, 2009, NEUROIMAGE, V44, P112, DOI 10.1016/j.neuroimage.2008.08.020; Conover W.J, 1998, PRACTICAL NONPARAMET; De Martino F, 2008, NEUROIMAGE, V43, P44, DOI 10.1016/j.neuroimage.2008.06.037; Demsar J, 2006, J MACH LEARN RES, V7, P1; Friston K, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P1; Hansen LK, 2007, BRAIN LANG, V102, P186, DOI 10.1016/j.bandl.2006.12.004; Hanson SJ, 2008, NEURAL COMPUT, V20, P486, DOI 10.1162/neco.2007.09-06-340; Hanson SJ, 2004, NEUROIMAGE, V23, P156, DOI 10.1016/j.neuroimage.2004.05.020; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Haynes JD, 2005, NAT NEUROSCI, V8, P686, DOI 10.1038/nn1445; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2007, SCHOLARPEDIA, V2, P1668; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Joachims T., 1999, ADV KERNEL METHODS S; Kjems U, 2001, ADV NEUR IN, V13, P549; Kjems U, 2002, NEUROIMAGE, V15, P772, DOI 10.1006/nimg.2001.1033; Kustra R, 2001, IEEE T MED IMAGING, V20, P376, DOI 10.1109/42.925291; LaConte S, 2005, NEUROIMAGE, V26, P317, DOI 10.1016/j.neuroimage.2005.01.048; LAROCHELLE H, 2008, ICML 08; Lukic AS, 2007, IEEE T MED IMAGING, V26, P1613, DOI 10.1109/TMI.2007.896934; Mardia K. V., 1979, MULTIVARIATE ANAL; McIntosh AR, 2004, NEUROIMAGE, V23, pS250, DOI 10.1016/j.neuroimage.2004.07.020; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Morch N, 1997, LECT NOTES COMPUT SC, V1230, P259; Ng AY, 2002, ADV NEUR IN, V14, P841; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; O'Toole AJ, 2007, J COGNITIVE NEUROSCI, V19, P1735, DOI 10.1162/jocn.2007.19.11.1735; Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007; Pessoa L, 2006, CEREB CORTEX, V16, P366, DOI 10.1093/cercorbhi115; Press W. H., 1992, NUMERICAL RECIPES C, V2nd; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Small SL, 2002, BRAIN, V125, P1544, DOI 10.1093/brain/awf148; Strother S, 2004, NEUROIMAGE, V23, pS196, DOI 10.1016/j.neuroimage.2004.07.022; Strother SC, 2006, IEEE ENG MED BIOL, V25, P27, DOI 10.1109/MEMB.2006.1607667; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P139, DOI 10.1097/00004728-199801000-00027; Yamashita O, 2008, NEUROIMAGE, V42, P1414, DOI 10.1016/j.neuroimage.2008.05.050; Zhang J, 2008, NEUROINFORMATICS, V6, P123, DOI 10.1007/s12021-008-9014-1	41	14	14	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	NOV	2010	22	11					2729	2762		10.1162/NECO_a_00024		34	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	662OR	WOS:000282820100001	20804386	
J	Zeiler, MD; Krishnan, D; Taylor, GW; Fergus, R			IEEE	Zeiler, Matthew D.; Krishnan, Dilip; Taylor, Graham W.; Fergus, Rob			Deconvolutional Networks	2010 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	23rd IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 13-18, 2010	San Francisco, CA	IEEE Comp Soc			RECOGNITION; ALGORITHM	Building robust low and mid-level image representations, beyond edge primitives, is a long-standing goal in vision. Many existing feature detectors spatially pool edge information which destroys cues such as edge intersections, parallelism and symmetry. We present a learning framework where features that capture these mid-level cues spontaneously emerge from image data. Our approach is based on the convolutional decomposition of images under a sparsity constraint and is totally unsupervised. By building a hierarchy of such decompositions we can learn rich feature sets that are a robust image representation for both the analysis and synthesis of images.	[Zeiler, Matthew D.; Krishnan, Dilip; Taylor, Graham W.; Fergus, Rob] NYU, Courant Inst, Dept Comp Sci, New York, NY 10003 USA	Zeiler, MD (reprint author), NYU, Courant Inst, Dept Comp Sci, New York, NY 10003 USA.	zeiler@cs.nyu.edu; dilip@cs.nyu.edu; gwtaylor@cs.nyu.edu; fergus@cs.nyu.edu					Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Bengio Y., 2007, NIPS, P153; Chen S. S., 1999, SIAM J SCI COMPUT, V20, P33; Fidler S., 2008, CVPR; Fidler S., 2007, CVPR; GEMAN D, 1995, PAMI, V4, P932; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K., 2009, ICCV; JIN Y, 2006, CVPR, V2, P2145; Krishnan D., 2009, NIPS; Lazebnik S., 2006, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2007, NIPS, P801; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Mairal J., 2008, NIPS; Mairal J., 2009, ICML, P689; Marr D, 1982, VISION; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Raina R., 2007, ICML; RANZATO M, 2008, NIPS; Ranzato M. A., 2006, NIPS, P1137; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Serre T., 2005, CVPR; Tu Z, 2006, INT J COMPUT VISION, V69, P223, DOI 10.1007/s11263-006-6995-9; Vincent P., 2008, INT C MACH LEARN, P1096; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Yang J., 2009, CVPR; Zhang H., 2006, CVPR; Zhu L., 2009, PAMI             MAR, P2; ZHU S, 2006, GRAPHICS VISION, V2, P259	31	14	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		978-1-4244-6984-0	PROC CVPR IEEE			2010							2528	2535		10.1109/CVPR.2010.5539957		8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematics, Applied; Imaging Science & Photographic Technology	Computer Science; Mathematics; Imaging Science & Photographic Technology	BTN70	WOS:000287417502074		
J	Sutskever, I; Hinton, GE				Sutskever, Ilya; Hinton, Geoffrey E.			Deep, Narrow Sigmoid Belief Networks Are Universal Approximators	NEURAL COMPUTATION			English	Article								In this note, we show that exponentially deep belief networks can approximate any distribution over binary vectors to arbitrary accuracy, even when the width of each layer is limited to the dimensionality of the data. We further show that such networks can be greedily learned in an easy yet impractical way.	[Sutskever, Ilya; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M55 3G4, Canada	Sutskever, I (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M55 3G4, Canada.	ilya@cs.utoronto.ca; hinton@cs.utoronto.ca					Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; LEROUX N, 2007, 1294 DIRO U MONTR; NEAL R, 1990, LEARNING STOCHASTIC; ROJAS R, 2003, P INT JOINT C NEUR N, V4, P3124, DOI 10.1109/IJCNN.2003.1224071; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALAKHUTDINOV R, 2007, P SIGIR WORKSH GRAPH; Salakhutdinov R., 2007, ADV NEURAL INFORM PR, V20	13	14	15	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	NOV	2008	20	11					2629	2636		10.1162/neco.2008.12-07-661		8	Computer Science, Artificial Intelligence	Computer Science	361FS	WOS:000260113500002	18533819	
J	Makin, JG; Fellows, MR; Sabes, PN				Makin, Joseph G.; Fellows, Matthew R.; Sabes, Philip N.			Learning Multisensory Integration and Coordinate Transformation via Density Estimation	PLOS COMPUTATIONAL BIOLOGY			English	Article							POSTERIOR PARIETAL CORTEX; CORTICAL CONNECTIONS; SENSORY INTEGRATION; REFERENCE FRAMES; MACAQUE MONKEY; NEURAL NETWORK; SENSORIMOTOR; INFORMATION; AREA; REPRESENTATIONS	Sensory processing in the brain includes three key operations: multisensory integration-the task of combining cues into a single estimate of a common underlying stimulus; coordinate transformations-the change of reference frame for a stimulus (e.g., retinotopic to body-centered) effected through knowledge about an intervening variable (e.g., gaze position); and the incorporation of prior information. Statistically optimal sensory processing requires that each of these operations maintains the correct posterior distribution over the stimulus. Elements of this optimality have been demonstrated in many behavioral contexts in humans and other animals, suggesting that the neural computations are indeed optimal. That the relationships between sensory modalities are complex and plastic further suggests that these computations are learned-but how? We provide a principled answer, by treating the acquisition of these mappings as a case of density estimation, a well-studied problem in machine learning and statistics, in which the distribution of observed data is modeled in terms of a set of fixed parameters and a set of latent variables. In our case, the observed data are unisensory-population activities, the fixed parameters are synaptic connections, and the latent variables are multisensory-population activities. In particular, we train a restricted Boltzmann machine with the biologically plausible contrastive-divergence rule to learn a range of neural computations not previously demonstrated under a single approach: optimal integration; encoding of priors; hierarchical integration of cues; learning when not to integrate; and coordinate transformation. The model makes testable predictions about the nature of multisensory representations.	Univ Calif San Francisco, Ctr Integrat Neurosci, San Francisco, CA USA; [Makin, Joseph G.] Univ Calif San Francisco, Dept Physiol, San Francisco, CA USA	Makin, JG (reprint author), Univ Calif San Francisco, Dept Physiol, Box 0444, San Francisco, CA USA.	makin@phy.ucsf.edu			Reorganization and Plasticity to Accelerate Injury Recovery (REPAIR) [N66001-10-C-2010]; NIH NEI [EY015679]	This work was supported by Reorganization and Plasticity to Accelerate Injury Recovery (REPAIR; N66001-10-C-2010, http://www.darpa.mil/) and NIH NEI (EY015679, http://www.nih.gov/). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Avillac M, 2005, NAT NEUROSCI, V8, P941, DOI 10.1038/nn1480; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow HB, 1961, SENS COMMUN, V1, P217; Battaglia-Mayer A, 2003, CEREB CORTEX, V13, P1009, DOI 10.1093/cercor/13.10.1009; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; BELL CC, 1993, P NATL ACAD SCI USA, V90, P4650, DOI 10.1073/pnas.90.10.4650; Bremner LR, 2012, NEURON, V75, P342, DOI 10.1016/j.neuron.2012.03.041; Buneo CA, 2006, NEUROPSYCHOLOGIA, V44, P2594, DOI 10.1016/j.neuropsychologia.2005.10.011; BURNOD Y, 1992, J NEUROSCI, V12, P1435; Chang SWC, 2010, P NATL ACAD SCI USA, V107, P7951, DOI 10.1073/pnas.0913209107; Davison AP, 2006, J NEUROSCI, V26, P5604, DOI 10.1523/JNEUROSCI.5263-05.2006; Dayan P., 2001, THEORETICAL NEUROSCI; Deneve S, 2001, NAT NEUROSCI, V4, P826, DOI 10.1038/90541; Duhamel JR, 1997, NATURE, V389, P845, DOI 10.1038/39865; Duhamel JR, 1998, J NEUROPHYSIOL, V79, P126; Eichhorn J, 2009, PLOS COMPUTATIONAL B, V5, P1; Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a; Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002; Ferraina S, 1997, J NEUROPHYSIOL, V77, P1034; Fetsch CR, 2012, NAT NEUROSCI, V15, P146, DOI 10.1038/nn.2983; FOLDIAK P, 1993, COMPUTATION AND NEURAL SYSTEMS, P55; Galletti C, 2001, EUR J NEUROSCI, V13, P1572, DOI 10.1046/j.0953-816x.2001.01538.x; Ghahramani Z, 1996, J NEUROSCI, V16, P7085; Ghahramani Z, 1995, ADV NEURAL INFORM PR; Graziano MSA, 1998, CURR OPIN NEUROBIOL, V8, P195, DOI 10.1016/S0959-4388(98)80140-2; Graziano MSA, 1999, P NATL ACAD SCI USA, V96, P10418, DOI 10.1073/pnas.96.18.10418; HELD R, 1963, SCIENCE, V142, P455, DOI 10.1126/science.142.3591.455; HELD R, 1963, J COMP PHYSIOL PSYCH, V56, P872, DOI 10.1037/h0040546; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Johnson PB, 1996, CEREB CORTEX, V6, P102, DOI 10.1093/cercor/6.2.102; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; KNUDSEN EI, 1989, J NEUROSCI, V9, P3306; Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943; Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169; Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587; Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831; Lewis JW, 2000, J COMP NEUROL, V428, P112, DOI 10.1002/1096-9861(20001204)428:1<112::AID-CNE8>3.0.CO;2-9; LISMAN J, 1989, P NATL ACAD SCI USA, V86, P9574, DOI 10.1073/pnas.86.23.9574; Lyckman Alvin W, 2002, Results Probl Cell Differ, V39, P139; Ma WJ, 2006, NAT NEUROSCI, V9, P1423; McCullagh P, 1989, GEN LINEAR MODELS, P26; McGuire LMM, 2009, NAT NEUROSCI, V12, P1056, DOI 10.1038/nn.2357; McGuire LMM, 2011, J NEUROSCI, V31, P6661, DOI 10.1523/JNEUROSCI.2921-10.2011; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Pesaran B, 2006, NEURON, V51, P125, DOI 10.1016/j.neuron.2006.05.025; Pouget A, 2002, NATURE REV NEUROSCIE, V3, P1; Redding GM, 2005, NEUROSCI BIOBEHAV R, V29, P431, DOI 10.1016/j.neubiorev.2004.12.004; Sabes PN, 2011, PROG BRAIN RES, V191, P195, DOI 10.1016/B978-0-444-53752-2.00004-7; SALINAS E, 1995, J NEUROSCI, V15, P6461; Shipp S, 1998, EUR J NEUROSCI, V10, P3171, DOI 10.1046/j.1460-9568.1998.00327.x; Simani MC, 2007, J NEUROPHYSIOL, V98, P2827, DOI 10.1152/jn.00290.2007; Sober SJ, 2003, J NEUROSCI, V23, P6982; Sober SJ, 2005, NAT NEUROSCI, V8, P490, DOI 10.1038/nn1427; Sohl-Dickstein J, 2011, P ICML, V2011, P905; Stocker AA, 2006, NAT NEUROSCI, V9, P578, DOI 10.1038/nn1669; Sur M, 1990, TINS, V13, P341; van Beers RJ, 1999, J NEUROPHYSIOL, V81, P1355; Verstynen T, 2011, J NEUROSCI, V31, P10050, DOI 10.1523/JNEUROSCI.6525-10.2011; Welling M., 2004, NEURAL INF PROCESS S, V17, P1481; Wise SP, 1997, ANNU REV NEUROSCI, V20, P25, DOI 10.1146/annurev.neuro.20.1.25; Wu S, 2005, NEURAL COMPUT, V17, P2215, DOI 10.1162/0899766054615626; Xing J, 2000, J COGNITIVE NEUROSCI, V12, P601, DOI 10.1162/089892900562363; Yildirim I, 2012, COGNITIVE SCI, V36, P305, DOI 10.1111/j.1551-6709.2011.01216.x	67	13	13	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-7358			PLOS COMPUT BIOL	PLoS Comput. Biol.	APR	2013	9	4							e1003035	10.1371/journal.pcbi.1003035		17	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	132LN	WOS:000318069800034	23637588	
J	Kello, CT				Kello, Christopher T.			Critical Branching Neural Networks	PSYCHOLOGICAL REVIEW			English	Article						criticality; power law; 1/f noise; neuronal avalanche; fractal spike train	RANGE TEMPORAL CORRELATIONS; HUMAN BRAIN OSCILLATIONS; LOCAL-FIELD POTENTIALS; LIQUID-STATE-MACHINE; NEURONAL AVALANCHES; 1/F NOISE; SPIKING NEURONS; HUMAN COGNITION; SYNAPTIC PLASTICITY; SCALING BEHAVIOR	It is now well-established that intrinsic variations in human neural and behavioral activity tend to exhibit scaling laws in their fluctuations and distributions. The meaning of these scaling laws is an ongoing matter of debate between isolable causes versus pervasive causes. A spiking neural network model is presented that self-tunes to critical branching and, in doing so, simulates observed scaling laws as pervasive to neural and behavioral activity. These scaling laws are related to neural and cognitive functions, in that critical branching is shown to yield spiking activity with maximal memory and encoding capacities when analyzed using reservoir computing techniques. The model is also shown to account for findings of pervasive scaling in speech and cued response behaviors that are difficult to explain by isolable causes. Issues and questions raised by the model and its results are discussed from the perspectives of physics, neuroscience, computer and information sciences, and psychological and cognitive sciences.	Univ Calif, Sch Social Sci Humanities & Arts, Merced, CA 95343 USA	Kello, CT (reprint author), Univ Calif, Sch Social Sci Humanities & Arts, 5200 N Lake Rd, Merced, CA 95343 USA.	ckello@ucmerced.edu			National Academies Keck Futures Initiative; National Science Foundation [BCS 0842784, 1031903]; DARPA [HR0011-09-C-0002]	The views and conclusions contained herein are those of the author and should not be interpreted as representing the official policies, either expressly or implied, of the Defense Advanced Research Projects Agency (DARPA) or the U.S. Government. This research was supported by awards from the National Academies Keck Futures Initiative, the National Science Foundation (Grants BCS 0842784 and 1031903), and DARPA under Contract HR0011-09-C-0002. I thank John Beggs, Rick Dale, Marty Mayberry, David Noelle, Guy Van Orden, Michael Spivey, and members of the Cognitive Mechanics Lab (University of California, Merced) for comments and discussions.	Abraham WC, 2008, NAT REV NEUROSCI, V9, P387, DOI 10.1038/nrn2356; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Aisa B, 2008, NEURAL NETWORKS, V21, P1146, DOI 10.1016/j.neunet.2008.06.016; Andersen C. M, 2000, CONSCIOUSNESS EMOTIO, V1, P193, DOI 10.1075/ce.1.2.02and; Antonelo EA, 2008, NEURAL NETWORKS, V21, P862, DOI 10.1016/j.neunet.2008.06.010; Arieli A, 1996, SCIENCE, V273, P1868, DOI 10.1126/science.273.5283.1868; Baddeley R, 1997, P ROY SOC B-BIOL SCI, V264, P1775; BAK P, 1987, PHYS REV LETT, V59, P381, DOI 10.1103/PhysRevLett.59.381; BAK P, 1995, P NATL ACAD SCI USA, V92, P6689, DOI 10.1073/pnas.92.15.6689; Baptista MS, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.178102; Bedard C, 2009, BIOPHYS J, V96, P2589, DOI 10.1016/j.bpj.2008.12.3951; Beggs JM, 2008, PHILOS T R SOC A, V366, P329, DOI 10.1098/rsta.2007.2092; Beggs JM, 2003, J NEUROSCI, V23, P11167; Beltz B. C, 2006, FOCUS COGNITIVE PSYC, P25; Benayoun M, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000846; Bershadskii A, 2001, PHYS LETT A, V289, P337, DOI 10.1016/S0375-9601(01)00624-7; Bertschinger N, 2004, NEURAL COMPUT, V16, P1413, DOI 10.1162/089976604323057443; Bhattacharya J, 2005, NEUROSCIENCE, V131, P547, DOI 10.1016/j.neuroscience.2004.11.013; Bressler SL, 2001, TRENDS COGN SCI, V5, P26, DOI 10.1016/S1364-6613(00)01564-3; Brooks V, 1986, NEURAL BASIS MOTOR C; Brunel N, 2000, J COMPUT NEUROSCI, V8, P183, DOI 10.1023/A:1008925309027; Buesing L, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002211; Burgsteiner H, 2007, APPL INTELL, V26, P99, DOI 10.1007/s10489-006-0007-1; Cao J, 2000, PHYS REV E, V61, P1825, DOI 10.1103/PhysRevE.61.1825; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Chklovskii DB, 2002, NEURON, V34, P341, DOI 10.1016/S0896-6273(02)00679-7; Cluff T, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005998; Crutchfield J.P., 1990, ENTROPY COMPLEXITY P, P223; Dan Y, 2004, NEURON, V44, P23, DOI 10.1016/j.neuron.2004.09.007; Davidsen J, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.050101; Davidsen J, 2002, PHYS REV E, V65, DOI 10.1103/PhysRevE.65.026120; de Arcangelis L, 2006, PHYS REV LETT, V96, DOI 10.1103/PhysRevLett.96.028107; de Arcangelis L, 2010, P NATL ACAD SCI USA, V107, P3977, DOI 10.1073/pnas.0912289107; Ding MZ, 2002, BRAIN COGNITION, V48, P98, DOI 10.1006/brcg.2001.1306; Duarte M, 2001, PHYS LETT A, V283, P124, DOI 10.1016/S0375-9601(01)00188-8; Elman J., 1990, COGNITIVE, V15, P179, DOI DOI 10.1207/S15516709C0G1402_1; Ermentrout G. B., 2001, OSCILLATORY NEURAL N, DOI [10.1038/npg.els.0000276, DOI 10.1038/NPG.ELS.0000276]; Farrell S, 2006, PSYCHON B REV, V13, P737, DOI 10.3758/BF03193989; Friedman N, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.208102; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Ganguli S, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.188701; Ganguli S, 2008, P NATL ACAD SCI USA, V105, P18970, DOI 10.1073/pnas.0804451105; GERSTEIN GL, 1964, BIOPHYS J, V4, P41; Gilden DL, 2007, PSYCHOL SCI, V18, P796, DOI 10.1111/j.1467-9280.2007.01982.x; Gilden DL, 2009, COGNITIVE SCI, V33, P1441, DOI 10.1111/j.1551-6709.2009.01060.x; Gilden DL, 2001, PSYCHOL REV, V108, P33, DOI 10.1037/0033-295X.108.1.33; GILDEN DL, 1995, SCIENCE, V267, P1837, DOI 10.1126/science.7892611; Granger C. W. J., 1980, Journal of Time Series Analysis, V1, DOI 10.1111/j.1467-9892.1980.tb00297.x; GRANGER CWJ, 1980, J ECONOMETRICS, V14, P227, DOI 10.1016/0304-4076(80)90092-5; Hahn G, 2010, J NEUROPHYSIOL, V104, P3312, DOI 10.1152/jn.00953.2009; Haldeman C, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.058101; Harm MW, 1999, PSYCHOL REV, V106, P491, DOI 10.1037//0033-295X.106.3.491; Harris TE, 1989, THEORY BRANCHING PRO; Hayer A, 2005, PLOS COMPUT BIOL, V1, P137, DOI 10.1371/journal.pcbi.0010020; He BYJ, 2010, NEURON, V66, P353, DOI 10.1016/j.neuron.2010.04.020; Higley MJ, 2006, J NEUROSCI, V26, P448, DOI 10.1523/JNEUROSCI.3506-05.2006; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hobbs JP, 2010, J CLIN NEUROPHYSIOL, V27, P380, DOI 10.1097/WNP.0b013e3181fdf8d3; Holden JG, 2011, J EXP PSYCHOL HUMAN, V37, P935, DOI 10.1037/a0020991; Holden JG, 2009, PSYCHOL REV, V116, P318, DOI 10.1037/a0014849; Holmgren CD, 2001, J NEUROSCI, V21, P8270; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Hotton S, 2011, COGNITIVE SCI, V35, P444, DOI 10.1111/j.1551-6709.2010.01151.x; Hsu D, 2006, NEUROCOMPUTING, V69, P1134, DOI 10.1016/j.neucom.2005.12.060; Hu K, 2004, PHYSICA A, V337, P307, DOI 10.1016/j.physa.2004.01.042; Ibata K, 2008, NEURON, V57, P819, DOI 10.1016/j.neuron.2008.02.031; Ihlen EAF, 2010, J EXP PSYCHOL GEN, V139, P436, DOI 10.1037/a0019098; Iyengar S, 1997, BIOL CYBERN, V77, P289, DOI 10.1007/s004220050390; Jackson BS, 2004, NEURAL COMPUT, V16, P2125, DOI 10.1162/0899766041732413; Jaeger H, 2007, NEURAL NETWORKS, V20, P287, DOI 10.1016/j.neunet.2007.04.001; Jensen H J, 1998, SELF ORG CRITICALITY; Joshi P, 2005, NEURAL COMPUT, V17, P1715, DOI 10.1162/0899766054026684; KATCHALSKY A., 1962, BIOPHYS JOUR, V2, P53; Kello C, 2011, COGNITIVE SCI, V35, P838, DOI 10.1111/j.1551-6709.2011.01185.x; Kello C., 2011, P COMP SYST NEUR 201, DOI [10.1038/npre.2011.5893.1, DOI 10.1038/NPRE.2011.5893.1]; Kello C. T., 2010, IEEE WORLD C COMP IN, P1475; Kello CT, 2010, TRENDS COGN SCI, V14, P223, DOI 10.1016/j.tics.2010.02.005; Kello C. T., 2011, 34 ANN M COGN SCI SO; Kello CT, 2007, J EXP PSYCHOL GEN, V136, P551, DOI 10.1037/0096-3445.136.4.551; Kello CT, 2008, COGNITIVE SCI, V32, P1217, DOI 10.1080/03640210801944898; Kello CT, 1998, BEHAV RES METH INS C, V30, P371, DOI 10.3758/BF03200668; Kello CT, 2009, NONLIN DYNAM PSYCHOL, V13, P57; Kelso J. A. S., 1995, DYNAMIC PATTERNS SEL; Kinouchi O, 2006, NAT PHYS, V2, P348, DOI 10.1038/nphys289; Kwok T, 2005, NEURAL COMPUT, V17, P2454, DOI 10.1162/0899766054796860; LANGTON CG, 1990, PHYSICA D, V42, P12, DOI 10.1016/0167-2789(90)90064-V; Large E. W., 1994, Connection Science, V6, DOI 10.1080/09540099408915723; Laufs H, 2003, P NATL ACAD SCI USA, V100, P11053, DOI 10.1073/pnas.1831638100; Linkenkaer-Hansen K, 2005, J NEUROSCI, V25, P10131, DOI 10.1523/JNEUROSCI.3244-05.2005; Linkenkaer-Hansen K, 2001, J NEUROSCI, V21, P1370; Linkenkaer-Hansen K, 2004, EUR J NEUROSCI, V19, P203, DOI 10.1111/j.1460-9568.2004.03116.x; Lisman JE, 2001, CURR BIOL, V11, pR788, DOI 10.1016/S0960-9822(01)00472-9; Liu QS, 2000, STOCH PROC APPL, V86, P263, DOI 10.1016/S0304-4149(99)00097-6; Liu ZM, 2010, NEUROIMAGE, V51, P102, DOI 10.1016/j.neuroimage.2010.01.092; Lubeck S, 2004, INT J MOD PHYS B, V18, P3977, DOI 10.1142/S0217979204027748; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Maass W, 2007, PLOS COMPUT BIOL, V3, P15, DOI 10.1371/journal.pcbi.0020165.eor; Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7; Marder E, 2006, NAT REV NEUROSCI, V7, P563, DOI 10.1038/nrn1949; Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213; Marr D., 1982, VISION COMPUTATIONAL; Martin FMD, 2011, COGNITIVE SCI, V35, P785, DOI 10.1111/j.1551-6709.2011.01184.x; Mattia M, 2000, NEURAL COMPUT, V12, P2305, DOI 10.1162/089976600300014953; Mazzoni A, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000439; McClung CA, 2004, MOL BRAIN RES, V132, P146, DOI 10.1016/j.molbrainres.2004.05.014; Micheva KD, 2010, NEURON, V68, P639, DOI 10.1016/j.neuron.2010.09.024; Mitchell M., 1999, COMPLEXITY METAPHORS, P497; Montez T, 2009, P NATL ACAD SCI USA, V106, P1614, DOI 10.1073/pnas.0811699106; O'Connor DH, 2005, P NATL ACAD SCI USA, V102, P9679, DOI 10.1073/pnas.0502332102; Packard N., 1988, DYNAMIC PATTERNS COM, P293; PEARLMUTTER BA, 1995, IEEE T NEURAL NETWOR, V6, P1212, DOI 10.1109/72.410363; Petermann T, 2009, P NATL ACAD SCI USA, V106, P15921, DOI 10.1073/pnas.0904089106; Petersen CCH, 1998, P NATL ACAD SCI USA, V95, P4732, DOI 10.1073/pnas.95.8.4732; Poil SS, 2008, HUM BRAIN MAPP, V29, P770, DOI 10.1002/hbm.20590; Rabinovich MI, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000072; Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676; Raichle ME, 2005, J COMP NEUROL, V493, P167, DOI 10.1002/cne.20752; Rangarajan G, 2000, PHYS REV E, V61, P4991, DOI 10.1103/PhysRevE.61.4991; Rasouli G, 2006, NEUROSCIENCE, V139, P1153, DOI 10.1016/j.neuroscience.2006.01.012; Rieke F., 1996, SPIKES EXPLORING NEU; Riley MA, 2002, J MOTOR BEHAV, V34, P99; Robin K, 2009, J NEUROSCI METH, V179, P142, DOI 10.1016/j.jneumeth.2009.01.020; Rowat P, 2007, NEURAL COMPUT, V19, P1215, DOI 10.1162/neco.2007.19.5.1215; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shadlen MN, 1998, J NEUROSCI, V18, P3870; Shew WL, 2009, J NEUROSCI, V29, P15595, DOI 10.1523/JNEUROSCI.3864-09.2009; Shin CW, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.045101; Shipley T. F., 2011, P 33 ANN M COGN SCI, P1685; Shockley K, 2003, J EXP PSYCHOL HUMAN, V29, P326, DOI 10.1037/0096-1523.29.2.326; Shu YS, 2003, NATURE, V423, P288, DOI 10.1038/nature01616; Simon H. A., 1973, HIERARCHY THEORY CHA, P1; Smith PL, 2004, TRENDS NEUROSCI, V27, P161, DOI 10.1016/j.tins.2004.01.006; SOFTKY WR, 1993, J NEUROSCI, V13, P334; Somette D., 2004, CRITICAL PHENOMENA N, Vsecond; Song S, 2000, NAT NEUROSCI, V3, P919; Spivey M., 2007, CONTINUITY MIND; Stanley H. E., 1987, INTRO PHASE TRANSITI; Stein RB, 2005, NAT REV NEUROSCI, V6, P389, DOI 10.1038/nrn1668; Stellwagen D, 2006, NATURE, V440, P1054, DOI 10.1038/nature04671; Stephen DG, 2011, CHAOS SOLITON FRACT, V44, P160, DOI 10.1016/j.chaos.2011.01.005; SWENSON R, 1991, Ecological Psychology, V3, P317, DOI 10.1207/s15326969eco0304_2; TEICH MC, 1994, IEEE ENG MED BIOL, V13, P197, DOI 10.1109/51.281678; Teich MC, 1997, J OPT SOC AM A, V14, P529, DOI 10.1364/JOSAA.14.000529; Thornton TL, 2005, PSYCHON B REV, V12, P409, DOI 10.3758/BF03193785; Tong MH, 2007, NEURAL NETWORKS, V20, P424, DOI 10.1016/j.neunet.2007.04.013; Torre K, 2009, HUM MOVEMENT SCI, V28, P297, DOI 10.1016/j.humov.2009.01.001; Touboul J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008982; Troyer TW, 1997, NEURAL COMPUT, V9, P971, DOI 10.1162/neco.1997.9.5.971; Turcotte DL, 2002, P NATL ACAD SCI USA, V99, P2530, DOI 10.1073/pnas.012582199; Turrigiano GG, 2004, NAT REV NEUROSCI, V5, P97, DOI 10.1038/nrn1327; USHER M, 1995, PHYS REV LETT, V74, P326, DOI 10.1103/PhysRevLett.74.326; USHER M, 1994, NEURAL COMPUT, V6, P795, DOI 10.1162/neco.1994.6.5.795; Van Orden GC, 2010, ECOL PSYCHOL, V22, P24, DOI 10.1080/10407410903493145; Van Orden GC, 2003, J EXP PSYCHOL GEN, V132, P331, DOI 10.1037/0096-3445.132.3.331; vanVreeswijk C, 1996, SCIENCE, V274, P1724; Verstraeten D, 2005, INFORM PROCESS LETT, V95, P521, DOI 10.1016/j.ipl.2005.05.019; Wagenmakers EJ, 2004, PSYCHON B REV, V11, P579, DOI 10.3758/BF03196615; Welling M, 2010, J PHYS CONF SER, V233, DOI 10.1088/1742-6596/233/1/012005; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; ZAPPERI S, 1995, PHYS REV LETT, V75, P4071, DOI 10.1103/PhysRevLett.75.4071; Zheng Y, 2005, PHYS LETT A, V344, P253, DOI 10.1016/j.physleta.2005.06.092	162	13	13	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0033-295X			PSYCHOL REV	Psychol. Rev.	JAN	2013	120	1					230	254		10.1037/a0030970		25	Psychology; Psychology, Multidisciplinary	Psychology	073UR	WOS:000313769100009	23356781	
J	Zeiler, MD; Taylor, GW; Fergus, R			IEEE	Zeiler, Matthew D.; Taylor, Graham W.; Fergus, Rob			Adaptive Deconvolutional Networks for Mid and High Level Feature Learning	2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)			English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	NOV 06-13, 2011	Barcelona, SPAIN	IEEE, Toyota, Google, Microsoft Res, Siemens, Technicolor, Adobe, Alcatel Lucent, Gentex Corp, Kooaba Image Recognit, Mitsubishi Elect, Mobileye, Object Video (OV), Toshiba, Xerox, Zeiss, 2d3, SATURNUS			RECOGNITION; ALGORITHM	We present a hierarchical model that learns image decompositions via alternating layers of convolutional sparse coding and max pooling. When trained on natural images, the layers of our model capture image information in a variety of forms: low-level edges, mid-level edge junctions, high-level object parts and complete objects. To build our model we rely on a novel inference scheme that ensures each layer reconstructs the input, rather than just the output of the layer directly beneath, as is common with existing hierarchical approaches. This makes it possible to learn multiple layers of representation and we show models with 4 layers, trained on images from the Caltech-101 and 256 datasets. When combined with a standard classifier, features extracted from these models outperform SIFT, as well as representations from other feature learning methods.	[Zeiler, Matthew D.; Taylor, Graham W.; Fergus, Rob] NYU, Dept Comp Sci, Courant Inst, New York, NY 10003 USA	Zeiler, MD (reprint author), NYU, Dept Comp Sci, Courant Inst, New York, NY 10003 USA.	zeiler@cs.nyu.edu; gwtaylor@cs.nyu.edu; fergus@cs.nyu.edu					Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boureau Y.L., 2010, CVPR; Chen B., 2010, JMLR UNPUB, p[1, 2, 5, 7, 8]; Fidler S., 2008, CVPR; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K., 2009, ICCV; Kavukcuoglu K., 2010, NIPS; Lazebnik S., 2006, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Ranzato M., 2007, CVPR; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rigamonti R., 2010, 152499 EPFL, P7; Serre T., 2005, CVPR; Tu Z, 2006, INT J COMPUT VISION, V69, P223, DOI 10.1007/s11263-006-6995-9; Wang J., 2010, CVPR; Winder S., 2009, CVPR; Yang J., 2009, CVPR; Zeiler M., 2010, CVPR; Zhu L., 2009, PAMI             MAR, P2; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	22	13	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4577-1102-2				2011							2018	2025				8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BYS97	WOS:000300061900257		
J	Mitra, V; Nam, H; Espy-Wilson, CY; Saltzman, E; Goldstein, L				Mitra, Vikramjit; Nam, Hosung; Espy-Wilson, Carol Y.; Saltzman, Elliot; Goldstein, Louis			Retrieving Tract Variables From Acoustics: A Comparison of Different Machine Learning Strategies	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING			English	Article						Articulatory phonology; articulatory speech recognition (ASR); artificial neural networks (ANNs); coarticulation; distal supervised learning; mixture density networks; speech inversion; task dynamic and applications model; vocal-tract variables	OVERLAPPING ARTICULATORY FEATURES; AUTOMATIC SPEECH RECOGNITION; TO-VOWEL COARTICULATION; VOCAL-TRACT; NEURAL-NETWORKS; MODEL; ALGORITHM; INFORMATION; PHONOLOGY; DYNAMICS	Many different studies have claimed that articulatory information can be used to improve the performance of automatic speech recognition systems. Unfortunately, such articulatory information is not readily available in typical speaker-listener situations. Consequently, such information has to be estimated from the acoustic signal in a process which is usually termed "speech-inversion." This study aims to propose and compare various machine learning strategies for speech inversion: Trajectory mixture density networks (TMDNs), feedforward artificial neural networks (FF-ANN), support vector regression (SVR), autoregressive artificial neural network (AR-ANN), and distal supervised learning (DSL). Further, using a database generated by the Haskins Laboratories speech production model, we test the claim that information regarding constrictions produced by the distinct organs of the vocal tract (vocal tract variables) is superior to flesh-point information (articulatory pellet trajectories) for the inversion process.	[Mitra, Vikramjit; Espy-Wilson, Carol Y.] Univ Maryland, Dept Elect & Comp Engn, Syst Res Inst, College Pk, MD 20742 USA; [Nam, Hosung] Haskins Lab, New Haven, CT 06511 USA; [Saltzman, Elliot] Boston Univ, Dept Phys Therapy & Athlet Training, Boston, MA 02215 USA; [Saltzman, Elliot; Goldstein, Louis] Haskins Labs Inc, New Haven, CT 06511 USA; [Goldstein, Louis] Univ So Calif, Dept Linguist, Los Angeles, CA 90089 USA	Mitra, V (reprint author), Univ Maryland, Dept Elect & Comp Engn, Syst Res Inst, College Pk, MD 20742 USA.	vmitra@glue.umd.edu; nam@haskins.yale.edu; espy@glue.umd.edu; esaltz@bu.edu; louisgol@usc.edu			National Science Foundation (NSF) [IIS-0703859, IIS-0703048, IIS-0703782]; NIH-NIDCD [DC-02717]	This work was supported by National Science Foundation (NSF) under Grants IIS-0703859, IIS-0703048, IIS-0703782, and NIH-NIDCD grant DC-02717. V. Mitra and H. Nam contributed equally to this work.	ATAL BS, 1978, J ACOUST SOC AM, V63, P1535, DOI 10.1121/1.381848; Atal B. S., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing; BISHOP C, NCRG4288 AST U DEP C; Browman Catherine, 1986, PHONOLOGY YB, V3, P219; BROWMAN CP, 1991, PAPERS LAB PHON, V1; BROWMAN CP, 1988, PHONETICA, V45, P140; BROWMAN CP, 1992, PHONETICA, V49, P155; BROWMAN CP, 1990, J PHONETICS, V18, P299; BROWMAN CP, 1990, J PHONETICS, V18, P411; Browman CP, 1989, PHONOLOGY, V6, P201, DOI 10.1017/S0952675700001019; Byrd D, 2003, J PHONETICS, V31, P149, DOI 10.1016/S0095-4470(02)00085-2; CETIN O, 2007, P ICASSP, V4, P645; Chang SY, 2005, SPEECH COMMUN, V47, P290, DOI 10.1016/j.specom.2005.01.006; CHEN S, 2000, P ICSLP, V4, P113; Chomsky Noam, 1968, SOUND PATTERN ENGLIS; Clements G. N., 1995, HDB PHONOLOGICAL THE; Cole R., 1995, P EUR C SPEECH COMM, P821; Cole R., 1986, INVARIANCE VARIABILI, P325; Deng L, 1997, SPEECH COMMUN, V22, P93, DOI 10.1016/S0167-6393(97)00018-6; Deng L, 2000, J ACOUST SOC AM, V108, P3036, DOI 10.1121/1.1315288; DENG L, 1992, SIGNAL PROCESS, V27, P65, DOI 10.1016/0165-1684(92)90112-A; Deng L., 2004, P ICASSP, V1, P557; Deng L, 1998, SPEECH COMMUN, V24, P299, DOI 10.1016/S0167-6393(98)00023-5; DENG L, 1991, P ICASSP 91, P193, DOI 10.1109/ICASSP.1991.150310; DENG L, 1994, INT CONF ACOUST SPEE, P45; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; DENG L, 1994, J ACOUST SOC AM, V95, P2702, DOI 10.1121/1.409839; Deshmukh O, 2005, IEEE T SPEECH AUDI P, V13, P776, DOI 10.1109/TSA.2005.851910; DUSAN S, 2000, STAT ESTIMATION ARTI; ELENIUS K, 1992, P ICSLP, P1279; ELENIUS K, 1991, P EUR C SPEECH COMM, P121; Erler K., 1993, Computer Speech and Language, V7, DOI 10.1006/csla.1993.1014; ESPYWILSON CY, 1999, J ACOUST SOC AM, V105, P1400, DOI 10.1121/1.426610; Espy-Wilson CY, 2000, J ACOUST SOC AM, V108, P343, DOI 10.1121/1.429469; Fowler C.A., 2003, HDB PSYCHOL EXPT PSY, V4, P237; Fowler CA, 2000, LANG SPEECH, V43, P1; FOWLER CA, 1993, LANG SPEECH, V36, P171; FRANKEL J, 2004, P INT C SPOK LANG PR, P1202, DOI DOI 10.1016/J.SPECOM.2008.05.004; FRANKEL J, 2001, P EUR AALB DENM, P599, DOI DOI 10.1109/TSA.2005.851910; Frankel J., 2005, P INT JAN, P3045; Frankel J., 2000, P ICSLP, V4, P254; Fujimura O., 1986, INVARIANCE VARIABILI, P226; FUJIMURA O, 1973, Computers in Biology and Medicine, V3, P371, DOI 10.1016/0010-4825(73)90003-6; Hanson HM, 2002, J ACOUST SOC AM, V112, P1158, DOI 10.1121/1.1498851; HANSON HM, 1999, P ICASSP, V1, P85; Harris John, 1994, ENGLISH SOUND STRUCT; Hasegawa-Johnson M., 2007, P ICPHS SAARBR GERM, P297; He X., 2008, DISCRIMINATIVE LEARN; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOGDEN J, 1998, LAUR963945 LOS AL NA; Hogden J, 2007, SPEECH COMMUN, V49, P361, DOI 10.1016/j.specom.2007.02.008; Hogden J, 1996, J ACOUST SOC AM, V100, P1819, DOI 10.1121/1.416001; Huang F., 2002, P IEEE INT C AC SPEE, V2, P2037; JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1; JUNEJA A, 2004, THESIS U MD COLL PAR; Jung TP, 1996, IEEE T SPEECH AUDI P, V4, P2; Jurafsky D., 2001, P IEEE INT C AC SPEE, V1, P577; Katsamanis A, 2009, IEEE T AUDIO SPEECH, V17, P411, DOI 10.1109/TASL.2008.2008740; King S, 2000, COMPUT SPEECH LANG, V14, P333, DOI 10.1006/csla.2000.0148; King S., 2005, P INTERSPEECH, P3385; Kirchhoff K, 2002, SPEECH COMMUN, V37, P303, DOI 10.1016/S0167-6393(01)00020-6; Kirchhoff K., 1999, THESIS U BIELEFELD B; KOBAYASHI T, 1985, P ICASSP, P1001; LADEFOGED P, 1978, J ACOUST SOC AM, V64, P1027, DOI 10.1121/1.382086; Laver J., 1994, PRINCIPLES PHONETICS; Livescu K., 2007, P ICASSP, V4, P621; Lochschmidt B., 1982, Automatic Speech Analysis and Recognition. Proceedings of the NATO Advanced Study Institute; Ma JZ, 2000, COMPUT SPEECH LANG, V14, P101, DOI 10.1006/csla.2000.0136; MANUEL SY, 1990, J ACOUST SOC AM, V88, P1286, DOI 10.1121/1.399705; Manuel S., 1984, SR7778 HASK LAB, P69; Markov K, 2006, SPEECH COMMUN, V48, P161, DOI 10.1016/j.specom.2005.07.003; Martinet Andre, 1957, MANUAL PHONETICS, P252; MCGOWAN RS, 1994, SPEECH COMMUN, V14, P19, DOI 10.1016/0167-6393(94)90055-8; Metze F., 2002, P INT C SPOK LANG PR, P2133; MING J, 1998, ACOUST SPEECH SIG PR, P409; Mitra V., 2009, P INT UK, P2759; MITRA V, 2009, J ACOUST SOC AM, V125, P2530; Mitra V, 2009, INT CONF ACOUST SPEE, P4497, DOI 10.1109/ICASSP.2009.4960629; MITRA V, J ACOUST SOC A UNPUB; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Mori R. D., 1976, IEEE T ACOUST SPEECH, V24, P365; Nam H., 2004, J ACOUST SOC AM, V115, P2430, DOI DOI 10.1016/J.SPECOM.2005.07.003; Neiberg D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1485; OHMAN SEG, 1966, J ACOUST SOC AM, V39, P151; OKADOME T, 2000, P 5 SEM SPEECH PROD, P229; OMAR MK, 2002, P ICASSP, V1, P81; Ostendorf M., 1999, P IEEE AUT SPEECH RE, V1, P79; PAPCUN G, 1992, J ACOUST SOC AM, V92, P688, DOI 10.1121/1.403994; Qin C., 2007, P INT, P74; Rahim M. G., 1991, P IEEE INT C AC SPEE, P485, DOI 10.1109/ICASSP.1991.150382; RAHIM MG, 1993, J ACOUST SOC AM, V93, P1109, DOI 10.1121/1.405559; RECASENS D, 1984, PHONETICA, V41, P125; Richmond K, 2007, LECT NOTES ARTIF INT, V4885, P263; Richmond K., 2001, ESTIMATING ARTICULAT; Ryalls J., 2000, INTRO SPEECH SCI BAS; Saltzman E., 1989, ECOL PSYCHOL, V1, P332; Schmidbauer O., 1989, P ICASSP, P616; SCHRAUWEN B, 2009, P NIPS WORKSH DEEP L; SHIRAI K, 1986, SPEECH COMMUN, V5, P159, DOI 10.1016/0167-6393(86)90005-1; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; STEVENS KN, 1960, J ACOUST SOC AM, V32, P47, DOI 10.1121/1.1907874; Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026; Stevens K. N., 2000, CURRENT STUDIES LING; STEVENS KN, 1999, P 1J INT C PHON SCI, V2, P1117; Sun J. P., 2000, P INT S CHIN SPOK LA, V3, P31; Sun JP, 2002, J ACOUST SOC AM, V111, P1086, DOI 10.1121/1.1420380; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Togneri R, 2003, IEEE T SIGNAL PROCES, V51, P3061, DOI 10.1109/TSP.2003.819013; TOKUDA K, 2000, P ICASSP, V3, P1315; TOUTIOS A, 2005, P SPECOM; Toutios A., 2005, P INT EUR 2005 PORT, P3221; Vapnik V. N., 1998, STAT LEARNING THEORY; Westbury JR, 1994, XRAY MICROBEAM SPEEC; Wester M., 2001, P EUR AALB DENM, P1729; WESTER M, 2004, P I EL INF COMM ENG, V104, P37; WESTON J., 2003, SVM PRACTICAL SESSIO; WINDHEUSER C, 1994, P ICSLP, P287; Wrench A., 1999, MOCHA TIMIT ARTICULA; Yallop C., 1995, INTRO PHONETICS PHON; ZACHS J, 1994, COMPUTER SPEECH LANG, V8, P189; Zhuang X., 2009, P INT, P2763; Zhuang X., 2008, P INT, P1489	123	13	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1932-4553			IEEE J-STSP	IEEE J. Sel. Top. Signal Process.	DEC	2010	4	6					1027	1045		10.1109/JSTSP.2010.2076013		19	Engineering, Electrical & Electronic	Engineering	681XW	WOS:000284358700012		
J	Murray, JF; Kreutz-Delgado, K				Murray, Joseph F.; Kreutz-Delgado, Kenneth			Visual recognition and inference using dynamic overcomplete sparse learning	NEURAL COMPUTATION			English	Article							ASYMMETRIC NEURAL-NETWORKS; BOLTZMANN MACHINES; OBJECT RECOGNITION; SINGLE NEURONS; NATURAL IMAGES; CORTEX; SYSTEMS; ALGORITHM; MODELS; REPRESENTATIONS	We present a hierarchical architecture and learning algorithm for visual recognition and other visual inference tasks such as imagination, reconstruction of occluded images, and expectation-driven segmentation. Using properties of biological vision for guidance, we posit a stochastic generative world model and from it develop a simplified world model (SWM) based on a tractable variational approximation that is designed to enforce sparse coding. Recent developments in computational methods for learning overcomplete representations (Lewicki & Sejnowski, 2000; Teh, Welling, Osindero, & Hinton, 2003) suggest that overcompleteness can be useful for visual tasks, and we use an overcomplete dictionary learning algorithm (Kreutz-Delgado, et al., 2003) as a preprocessing stage to produce accurate, sparse codings of images. Inference is performed by constructing a dynamic multilayer network with feedforward, feedback, and lateral connections, which is trained to approximate the SWM. Learning is done with a variant of the backpropagation-through-time algorithm, which encourages convergence to desired states within a fixed number of iterations. Vision tasks require large networks, and to make learning efficient, we take advantage of the sparsity of each layer to update only a small subset of elements in a large weight matrix at each iteration. Experiments on a set of rotated objects demonstrate various types of visual inference and show that increasing the degree of overcompleteness improves recognition performance in difficult scenes with occluded objects in clutter.	MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA; Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	Murray, JF (reprint author), MIT, Dept Brain & Cognit Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	murrayjf@mit.edu; kreutz@ece.ucsd.edu					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; APOLLONI B, 1991, BIOL CYBERN, V61, P61; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BARBER D, 2000, ADV NEURAL INFORM PR, V12; BARLOW HB, 1959, MECHANISATION THOUGH; Bertsekas D. P., 1995, DYNAMIC PROGRAMMING; BROOK D, 1964, BIOMETRIKA, V51, P481; Callaway EM, 2004, NEURAL NETWORKS, V17, P625, DOI 10.1016/j.neunet.2004.04.004; Chengxiang Z, 2000, Neural Comput, V12, P865, DOI 10.1162/089976600300015628; Cover T. M., 1991, ELEMENTS INFORM THEO; CRISANTI A, 1988, PHYS REV A, V37, P4865, DOI 10.1103/PhysRevA.37.4865; Ejima Y, 2003, NEUROREPORT, V14, P1579, DOI 10.1097/01.wnr.0000086098.47480.44; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Fukushima K, 2005, NEURAL NETWORKS, V18, P33, DOI 10.1016/j.neunet.2004.05.001; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; GALLAND CC, 1993, NETWORK-COMP NEURAL, V4, P355, DOI 10.1088/0954-898X/4/3/007; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gill J., 2001, GENERALIZED LINEAR M; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; GUTFREUND H, 1990, NEURAL NETWORKS SPIN; Hawkins J., 2004, INTELLIGENCE; HECHTNIELSEN R, 1998, P 1998 INT C NEUR IN, P1459; Hertz J, 1991, INTRO THEORY NEURAL; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Hoyer PO, 2002, VISION RES, V42, P1593, DOI 10.1016/S0042-6989(02)00017-2; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Johnson O., 2004, INFORM THEORY CENTRA; Jordan M. I., 1998, LEARNING GRAPHICAL M; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; Kappen HJ, 2000, PHYS REV E, V61, P5658, DOI 10.1103/PhysRevE.61.5658; Kay S. M., 1993, FUNDAMENTALS STAT SI; Kosslyn SM, 1997, NEUROIMAGE, V6, P320, DOI 10.1006/nimg.1997.0295; Kreiman G, 2000, NAT NEUROSCI, V3, P946; Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Mezard M., 1987, SPIN GLASS THEORY; Mountcastle V., 1978, MINDFUL BRAIN; MURRAY JF, 2001, 35 AS C SIGN SYST CO, V1, P347; Murray JF, 2005, THESIS U CALIFORNIA; Murray JF, 2006, J VLSI SIG PROC SYST, V45, P97, DOI 10.1007/s11265-006-9774-5; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Olshausen B.A., 2005, 23 PROBLEMS SYSTEMS; PARISI G, 1986, J PHYS A-MATH GEN, V19, pL675, DOI 10.1088/0305-4470/19/11/005; Peterson C., 1987, Complex Systems, V1; Quiroga RQ, 2005, NATURE, V435, P1102, DOI 10.1038/nature03687; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 1999, VISION RES, V39, P1963, DOI 10.1016/S0042-6989(98)00279-X; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rolls ET, 2000, NEURAL COMPUT, V12, P2547, DOI 10.1162/089976600300014845; SAUL LK, 1998, LEARNING GRAPHICAL M; SERENO MI, 1995, SCIENCE, V268, P889, DOI 10.1126/science.7754376; SOMPOLINSKY H, 1988, PHYS TODAY, V41, P70, DOI 10.1063/1.881142; Stevens CF, 2001, NATURE, V411, P193, DOI 10.1038/35075572; Sudderth E.B., 2005, ICCV, V2, P1331; Teh Y. W., 2003, J MACHINE LEARNING R, V4, P1235, DOI 10.1162/jmlr.2003.4.7-8.1235; Teh YW, 2001, ADV NEUR IN, V13, P908; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; Welling M, 2003, ARTIF INTELL, V143, P19, DOI 10.1016/S0004-3702(02)00361-2; Williams R. J., 1990, NEURAL COMPUT, V2, P490, DOI 10.1162/neco.1990.2.4.490	70	13	13	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	SEP	2007	19	9					2301	2352		10.1162/neco.2007.19.9.2301		52	Computer Science, Artificial Intelligence	Computer Science	194HY	WOS:000248336600002	17650062	
J	Chen, CLP; Zhang, CY				Chen, C. L. Philip; Zhang, Chun-Yang			Data-intensive applications, challenges, techniques and technologies: A survey on Big Data	INFORMATION SCIENCES			English	Article						Big Data; Data-intensive computing; e-Science; Parallel and distributed computing; Cloud computing	NEURAL-NETWORKS; SOCIAL NETWORKS; NONLINEAR-SYSTEMS; DATA-STORAGE; DATA SETS; ALGORITHM; OPTIMIZATION; INFORMATION; MAPREDUCE; FUTURE	It is already true that Big Data has drawn huge attention from researchers in information sciences, policy and decision makers in governments and enterprises. As the speed of information growth exceeds Moore's Law at the beginning of this new century, excessive data is making great troubles to human beings. However, there are so much potential and highly useful values hidden in the huge volume of data. A new scientific paradigm is born as data-intensive scientific discovery (DISD), also known as Big Data problems. A large number of fields and sectors, ranging from economic and business activities to public administration, from national security to scientific researches in many areas, involve with Big Data problems. On the one hand, Big Data is extremely valuable to produce productivity in businesses and evolutionary breakthroughs in scientific disciplines, which give us a lot of opportunities to make great progresses in many fields. There is no doubt that the future competitions in business productivity and technologies will surely converge into the Big Data explorations. On the other hand, Big Data also arises with many challenges, such as difficulties in data capture, data storage, data analysis and data visualization. This paper is aimed to demonstrate a close-up view about Big Data, including Big Data applications, Big Data opportunities and challenges, as well as the state-of-the-art techniques and technologies we currently adopt to deal with the Big Data problems. We also discuss several underlying methodologies to handle the data deluge, for example, granular computing, cloud computing, bio-inspired computing, and quantum computing. (C) 2014 Elsevier Inc. All rights reserved.	[Chen, C. L. Philip; Zhang, Chun-Yang] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macao, Peoples R China	Chen, CLP (reprint author), Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macao, Peoples R China.	Philip.Chen@ieee.org; cyzhangfst@gmail.com			National 973 Basic Research Program of China [2011CB302801]; Macau Science and Technology Development Fund [008/2010/A1]; University of Macau Multiyear Research Grants	This work was supported in part by the National 973 Basic Research Program of China under Grant 2011CB302801 and the Macau Science and Technology Development Fund under Grant 008/2010/A1 and University of Macau Multiyear Research Grants.	Adamov Abzetdin, 2012 6 INT C APPL IN, P1; Agrawal D., 2011, CHALLENGES OPPORTUNI; Ahn Byungik, 2012, 2012 IEEE INT C COMP, P143; Ahrens J, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.933522; Ahrens JP, 2011, COMPUT SCI ENG, V13, P14, DOI 10.1109/MCSE.2011.77; Anderson C., 2008, END THEORY DATA DELU; Andrianantoandro E, 2006, MOL SYST BIOL, V2, DOI 10.1038/msb4100073; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Auradkar A, 2012, PROC INT CONF DATA, P1370, DOI 10.1109/ICDE.2012.147; Bahga A, 2012, IEEE T PARALL DISTR, V23, P1831, DOI 10.1109/TPDS.2011.306; Barbarossa Sergio, 2009, IEEE SIGNAL PROCESS, V24, P95; Bekkerman R, 2012, SCALING MACHINE LEAR; Bell G, 2009, SCIENCE, V323, P1297, DOI 10.1126/science.1170411; Bencivenni M, 2008, IEEE T NUCL SCI, V55, P1621, DOI 10.1109/TNS.2008.924087; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bennett J., 2009, IEEE INT C CLUST COM, P1; Bertone P, 2001, IEEE ENG MED BIOL, V20, P33, DOI 10.1109/51.940042; Bezdek J.C., 1981, PATTERN RECOGNITION; Bingham E., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Bongard J, 2009, COMPUTER, V42, P95, DOI 10.1109/MC.2009.104; Bringmann B, 2010, IEEE INTELL SYST, V25, P26, DOI 10.1109/MIS.2010.91; Brumfiel G, 2011, NATURE, V469, P282, DOI 10.1038/469282a; Bryant Randal E., 2007, CMUCS07128; Bryant RE, 2011, COMPUT SCI ENG, V13, P25, DOI 10.1109/MCSE.2011.73; Bzoch P, 2011, 2011 2ND EASTERN EUROPEAN REGIONAL CONFERENCE ON THE ENGINEERING OF COMPUTER BASED SYSTEMS (ECBS-EERC), P153, DOI 10.1109/ECBS-EERC.2011.34; Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669; Cannataro M, 2004, IEEE T SYST MAN CY B, V34, P2451, DOI 10.1109/TSMCB.2004.836890; Cao Y, 2012, IEEE T INTELL TRANSP, V13, P1855, DOI 10.1109/TITS.2012.2205145; Capriolo Edward, 2011, CASSANDRA HIGH PERFO; Chang F., 2008, ACM T COMPUT SYST, V4, P26; Chauhan J., 2012, 2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC 2012), DOI 10.1109/3PGCIC.2012.55; Chen C, 2013, IEEE T INTELL TRANSP, V14, P22, DOI 10.1109/TITS.2012.2205144; Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455; Ciresan D.C., 2012, IEEE C COMP VIS PATT; Deam Jeffrey, 2008, COMMUN ACM, V51, P107; del Valle XYamille, 2008, IEEE T EVOLUT COMPUT, V12, P171; Di Ciaccio A., 2012, ADV STAT METHODS ANA; Dong JX, 2005, IEEE T PATTERN ANAL, V27, P603; Esteves R.M., 2011, 2011 IEEE WORKSH INT, P514; Esteves Rui Maximo, 2011, 2011 IEEE 3 INT C CL, P565; Foster I., 2008, GRID COMP ENV WORKSH, V901, P1; FUJIMOTO Y, 1992, IEEE T NEURAL NETWOR, V3, P876, DOI 10.1109/72.165590; Furht B., 2011, HDB CLOUD COMPUTING; Garber L, 2012, COMPUTER, V45, P16, DOI 10.1109/MC.2012.358; Garcia A.O., 2011, 2011 IEEE S LARG DAT, P125; Geng B, 2012, IEEE T MULTIMEDIA, V14, P55, DOI 10.1109/TMM.2011.2174781; Gillick D., 2006, MAPREDUCE DISTRIBUTE; Gokhale M, 2008, COMPUTER, V41, P60, DOI 10.1109/MC.2008.125; Guan NY, 2012, IEEE T NEUR NET LEAR, V23, P1087, DOI 10.1109/TNNLS.2012.2197827; Gulisano V, 2012, IEEE T PARALL DISTR, V23, P2351, DOI 10.1109/TPDS.2012.24; Han J., 2000, DATA MINING CONCEPTS; Han J., 2011, 2011 6 INT C PERV CO, P363; Han Xixian, 2012, IEEE T KNOWL DATA EN, P1; HASSAN K, 1987, MATH MODELLING, V8, P34, DOI 10.1016/0270-0255(87)90536-7; Hastie T., 2009, ELEMENTS STAT LEARNI; Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137; Hey T, 2002, FUTURE GENER COMP SY, V18, P1017, DOI 10.1016/S0167-739X(02)00082-1; Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hirota Kaoru, 1999, P IEEE, V87, P575; Horne Andrew, 2012, GOOD DATA WONT GUARA; Howe D, 2008, NATURE, V455, P47, DOI 10.1038/455047a; Hsiao WF, 2008, EXPERT SYST APPL, V34, P1599, DOI 10.1016/j.eswa.2007.01.018; Hutchinson Lee, 2012, SOLID STATE REVOLUTI; Ingersoll Grant, 2009, INTRO APACHE MAHOUT; Isard M., 2007, SIGOPS OPER SYST REV, V41, P59, DOI DOI 10.1145/1272998.1273005; Isard Michael, 2007, P 2007 EUR C; Ishii Renato Porfirio, 2011, INFOCOMP Journal of Computer Science, V10; Ishii R.P., 2009, P 21 IASTED INT C PA; Ishii RP, 2012, IEEE T PARALL DISTR, V23, P1017, DOI 10.1109/TPDS.2011.256; Jacob B., 2005, INTRO GRID COMPUTING; Jacobs A, 2009, COMMUN ACM, V52, P36, DOI 10.1145/1536616.1536632; Jamali M., 2006, IEEE WIC ACM INT C W, P66, DOI DOI 10.1109/WI.2006.61; Jason Brooks, 2009, REV TALEND OPEN STUD; Jeon G, 2006, IEEE T CONSUM ELECTR, V52, P1348, DOI 10.1109/TCE.2006.273155; Jiang DW, 2011, IEEE T KNOWL DATA EN, V23, P1299, DOI 10.1109/TKDE.2010.248; JIANG W, 2008, IEEE IMAGE PROC, P161; Kasavajhala Vamsee, 2012, SOLID STATE DRIVE VS; Keim DA, 2004, IEEE COMPUT GRAPH, V24, P36, DOI 10.1109/MCG.2004.41; Kelly Jeff, 2013, APACHE DRILL BRINGS; Kim Wooyoung, 2009, PARALLEL ALGORITHMS; Klemens B, 2009, MODELING WITH DATA: TOOLS AND TECHNIQUES FOR SCIENTIFIC COMPUTING, P1; Kouzes RT, 2009, COMPUTER, V42, P26, DOI 10.1109/MC.2009.26; Kraft S., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), DOI 10.1109/CLOUD.2012.120; Lakshmi K Prasanna, 2010, 2010 International Conference on Networking and Information Technology (ICNIT 2010), DOI 10.1109/ICNIT.2010.5508473; Lane ND, 2011, IEEE PERVAS COMPUT, V10, P45, DOI 10.1109/MPRV.2011.70; Laney Doug, 2001, APPL DELIVERY STRATE; Le Q. V., 2012, P 29 INT C MACH LEAR; Lee JA, 2007, INFORM SCI STAT, P1; Leong D, 2009, IEEE POTENTIALS, V28, P32, DOI 10.1109/MPOT.2009.934894; Lesk A. M., 2008, INTRO BIOINFORMATICS; Li H, 2012, SECOND INTERNATIONAL CONFERENCE ON CLOUD AND GREEN COMPUTING / SECOND INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING AND ITS APPLICATIONS (CGC/SCA 2012), P675, DOI 10.1109/CGC.2012.23; Li Xiaodong, 2008, IEEE T EVOLUT COMPUT, V16, P210; Liang Zhong, 2010, 2 INT C COMP MOD SIM, V1, P194; Lin CY, 2012, P IEEE, V100, P2759, DOI 10.1109/JPROC.2012.2203090; Liu YJ, 2011, IEEE T NEURAL NETWOR, V22, P1162, DOI 10.1109/TNN.2011.2146788; Liu YM, 2011, IEEE T PATTERN ANAL, V33, P1022, DOI 10.1109/TPAMI.2010.142; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Loughran S, 2012, IEEE INTERNET COMPUT, V16, P40, DOI 10.1109/MIC.2011.163; Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004; Lynch C, 2008, NATURE, V455, P28, DOI 10.1038/455028a; Ma H, 2012, IEEE T KNOWL DATA EN, V24, P1051, DOI 10.1109/TKDE.2011.18; Ma Kwan-Liu, 2004, IEEE COMPUT GRAPH, V24, P36; Mansour Y, 1997, IEEE T POWER SYST, V12, P954, DOI 10.1109/59.589789; Manyika James, 2012, BIG DATA NEXT FRONTI; Mao Y, 2010, IEEE ACM T NETWORK, V18, P761, DOI 10.1109/TNET.2010.2046645; Marz N., 2012, BIG DATA PRINCIPLES; McDermott Jason, 2009, COMPUTATIONAL SYSTEM; McGuffin Michael J., 2007, IEEE T VIS COMPUT GR, V13, P1302; Melnik S., 2010, P VLDB ENDOW, V3, P330; Mikolov Tomas, 2011, IEEE WORKSH AUT SPEE; Mistry Ross, 2012, INTRO MICROSOFT SQL; Mitra Pabitra, 2004, IEEE T PATTERN ANAL, V26, P603; MOLCHANOV I., 2005, THEORY RANDOM SETS; Molinari Christian, 2012, NO ONE SIZE FITS ALL; Muhleisen H, 2012, IEEE COMPUT INTELL M, V7, P32, DOI 10.1109/MCI.2012.2188586; Nakano Tadashi, 2010, 2010 13 INT C NETW B, P42; Nandi A, 2012, IEEE T KNOWL DATA EN, V24, P1747, DOI 10.1109/TKDE.2011.257; Neumeyer L., 2010, P 2010 IEEE INT C DA, P170, DOI DOI 10.1109/1CDMW.2010.172; Nielsen M. A., 2009, QUANTUM COMPUTATION; Oehmen C, 2006, IEEE T PARALL DISTR, V17, P740, DOI 10.1109/TPDS.2006.112; Oh C, 2010, IEEE T NEURAL NETWOR, V21, P633, DOI 10.1109/TNN.2010.2040291; Oleg Sysoev, 2011, COMPUT STAT DATA AN, V55, P2463; Oliveira Simone Ferlin, 2012, IEEE 14 INT C HIGH P; Oprea Alina, 2005, P 12 ANN NETW DISTR; Oracle, 2012, OR INF ARCH ARCH GUI; Ozsu Tamer M., 2011, PRINCIPLES DISTRIBUT; Palit I, 2012, IEEE T KNOWL DATA EN, V24, P1904, DOI 10.1109/TKDE.2011.208; Pavlo A, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P165; Pearson MJ, 2007, IEEE T NEURAL NETWOR, V18, P1472, DOI 10.1109/TNN.2007.891203; Pebay P., 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, DOI 10.1109/IPDPS.2011.293; Pedrycz W., 2008, HDB GRANULAR COMPUTI; Peters G, 2011, IEEE T FUZZY SYST, V19, P1141, DOI 10.1109/TFUZZ.2011.2162416; Pirovano A., 2003, IEEE INT EL DEV M, DOI DOI 10.1109/IEDM.2003.1269376; Plugge E., 2010, DEFINITIVE GUIDE MON; Proffitt Brian, 2012, BIG DATA TOOLS VENDO; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; Ranger C, 2007, INT S HIGH PERF COMP, P13; Ranka Sanjay, 1991, IEEE T PARALL DISTR, V2, P532; Ratner M, 2002, NANOTECHNOLOGY GENTL; Raykar VC, 2008, IEEE T PATTERN ANAL, V30, P1158, DOI 10.1109/TPAMI.2007.70776; Sahimi M, 2010, COMPUT SCI ENG, V12, P74, DOI 10.1109/MCSE.2010.85; Sakr S, 2011, IEEE COMMUN SURV TUT, V13, P311, DOI 10.1109/SURV.2011.032211.00087; Samson Ted, 2012, SPLUNK STORM BRINGS; Samuels Diana, 2012, SKYTREE MACHINE LEAR; Savitz Eric, 2012, GARTNER TOP 10 STRAT; Savitz Eric, 2012, GARTNER 10 CRITICAL; Schadt EE, 2010, NAT REV GENET, V11, P647, DOI 10.1038/nrg2857; Seenumani G, 2012, IEEE T CONTR SYST T, V20, P232, DOI 10.1109/TCST.2011.2107909; Seiffert U, 2006, IEEE IJCNN, P5324; Shen HY, 2011, IEEE T MOBILE COMPUT, V10, P982, DOI 10.1109/TMC.2010.214; Shen XH, 2003, IEEE T PARALL DISTR, V14, P1262, DOI 10.1109/TPDS.2003.1255638; Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107; Shi WY, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P769, DOI 10.1109/ICMLA.2008.41; Shibata K., 2009, ICROS SICE INT JOINT, P5008; Simeonidou D, 2005, J LIGHTWAVE TECHNOL, V23, P3347, DOI 10.1109/JLT.2005.856254; Simoff SJ, 2008, LECT NOTES COMPUT SC, V4404, P1, DOI 10.1007/978-3-540-71080-6; Simon D. R., 1994, SIAM J COMPUT, V26, P116; Sipper M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585894; Smith M., 2012, 2012 IEEE 2nd International Conference on Computational Advances in Bio and Medical Sciences (ICCABS), DOI 10.1109/ICCABS.2012.6182659; Spiliopoulou M, 1996, IEEE T KNOWL DATA EN, V8, P429, DOI 10.1109/69.506710; Sridhar Pavan, 2013, INT J ENHANCED RES S, V2, P87; Stonebraker M, 2005, SIGMOD RECORD, V34, P42, DOI 10.1145/1107499.1107504; Su Shun-Feng, 2011, IEEE T SYST MAN CY B, V19, P1141; Sun P, 2010, IEEE T NEURAL NETWOR, V21, P883, DOI 10.1109/TNN.2010.2044244; Szalay A. S., 2006, NATURE, V440, P23; Szalay AS, 2011, COMPUT SCI ENG, V13, P34, DOI 10.1109/MCSE.2011.74; Tang K, 2009, NEUROCOMPUTING, V72, P2796, DOI 10.1016/j.neucom.2008.09.022; Taniar D, 2012, INT CON ADV INFO NET, P5, DOI 10.1109/AINA.2012.140; Thompson David, 2011, 2011 IEEE S LARG DAT, P23; Tim Jones M., 2012, PROCESS REAL TIME BI; Tkacz Ewaryst, 2009, INTERNET TECHNICAL D; Tony Hey, 2009, 4 PARADIGM DATA INTE; Vettiger P, 2002, IEEE T NANOTECHNOL, V1, P39, DOI 10.1109/TNANO.2002.1005425; Vijayakumar S., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), DOI 10.1109/CLOUD.2012.34; Vouk MA, 2008, ITI, P31, DOI 10.1109/ITI.2008.4588381; Wang FY, 2007, IEEE INTELL SYST, V22, P79, DOI 10.1109/MIS.2007.41; Wang Lijuan, 2012, 2012 IEEE 1 INT C SE, P16; Wang Q, 2009, IEEE INFOCOM SER, P954, DOI 10.1109/INFCOM.2009.5062006; Wang QA, 2011, IEEE T PARALL DISTR, V22, P847, DOI 10.1109/TPDS.2010.183; Wayner Peter, 2012, 7 TOP TOOLS TAMING B; Weiss R., 2003, Natural Computing, V2, DOI 10.1023/A:1023307812034; Wilkinson L, 2008, TECHNOMETRICS, V50, P418, DOI 10.1198/004017008000000460; WORLTON WJ, 1971, IEEE T MAGN, VMAG7, P830, DOI 10.1109/TMAG.1971.1067246; Wu YC, 2012, IEEE T VIS COMPUT GR, V18, P2526; Yan J, 2011, IEEE T KNOWL DATA EN, V23, P1103, DOI 10.1109/TKDE.2010.34; Yang ZY, 2008, INFORM SCIENCES, V178, P2985, DOI 10.1016/j.ins.2008.02.017; Yao W, 2012, IEEE T NEUR NET LEAR, V23, P247, DOI 10.1109/TNNLS.2011.2178560; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Yu Yuan, 2008, 8 USENIX S OP SYST D; Yuan Jiawei, 2013, PRIVACY PRESERVING B; Yurcik William, 2005, INT C INF TECHN COD, V2, P205; Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001; Zhang Y, 2012, IEEE J SEL AREA COMM, V30, P2136, DOI 10.1109/JSAC.2012.121206; Zhou Jin, 2013, IEEE T FUZZY SYST, P1; Zhou Q, 2012, IEEE T SYST MAN CY B, V42, P1608, DOI 10.1109/TSMCB.2012.2196432; Zikopoulos P., 2011, UNDERSTANDING BIG DA	200	12	12	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255	1872-6291		INFORM SCIENCES	Inf. Sci.	AUG 10	2014	275						314	347		10.1016/j.ins.2014.01.015		34	Computer Science, Information Systems	Computer Science	AI8TF	WOS:000337199200021		
J	Dahl, GE; Yu, D; Deng, L; Acero, A			IEEE	Dahl, George E.; Yu, Dong; Deng, Li; Acero, Alex			LARGE VOCABULARY CONTINUOUS SPEECH RECOGNITION WITH CONTEXT-DEPENDENT DBN-HMMS	2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 22-27, 2011	Prague, CZECH REPUBLIC	Inst Elect & Elect Engineers Signal Processing Soc, IEEE	Prague Congress Ctr	Speech recognition; deep belief network; context-dependent phone; LVCSR; DBN-HMM		The context-independent deep belief network (DBN) hidden Markov model (HMM) hybrid architecture has recently achieved promising results for phone recognition. In this work, we propose a context-dependent DBN-HMM system that dramatically outperforms strong Gaussian mixture model (GMM)-HMM baselines on a challenging, large vocabulary, spontaneous speech recognition dataset from the Bing mobile voice search task. Our system achieves absolute sentence accuracy improvements of 5.8% and 9.2% over GMM-HMMs trained using the minimum phone error rate (MPE) and maximum likelihood (ML) criteria, respectively, which translate to relative error reductions of 16.0% and 23.2%.	[Dahl, George E.] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	Dahl, GE (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.						ACERO A, 2008, P ICASSP, P5256; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; DENG L, 2010, P INT, P1692; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hwang MY, 1993, IEEE T SPEECH AUDI P, V1, P414; McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778; Mnih V., 2009, 2009004 UTML DEP COM; Mohamed A.-R., 2010, P INTERSPEECH, P2846; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Povey D., 2003, THESIS CAMBRIDGE U; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; YU D, 2010, P INT, P2986; Yu D., 2007, P INT C AC SPEECH SI, V4, P1137; Zweig Geoffrey, 2009, Proceedings of the 2009 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU 2009), DOI 10.1109/ASRU.2009.5372916	16	12	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4577-0539-7	INT CONF ACOUST SPEE			2011							4688	4691				4	Acoustics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Engineering; Imaging Science & Photographic Technology	BXG36	WOS:000296062405074		
J	Sohn, K; Jung, DY; Lee, H; Hero, AO			IEEE	Sohn, Kihyuk; Jung, Dae Yon; Lee, Honglak; Hero, Alfred O., III			Efficient Learning of Sparse, Distributed, Convolutional Feature Representations for Object Recognition	2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)			English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	NOV 06-13, 2011	Barcelona, SPAIN	IEEE, Toyota, Google, Microsoft Res, Siemens, Technicolor, Adobe, Alcatel Lucent, Gentex Corp, Kooaba Image Recognit, Mitsubishi Elect, Mobileye, Object Video (OV), Toshiba, Xerox, Zeiss, 2d3, SATURNUS				Informative image representations are important in achieving state-of-the-art performance in object recognition tasks. Among feature learning algorithms that are used to develop image representations, restricted Boltzmann machines (RBMs) have good expressive power and build effective representations. However, the difficulty of training RBMs has been a barrier to their wide use. To address this difficulty, we show the connections between mixture models and RBMs and present an efficient training method for RBMs that utilize these connections. To the best of our knowledge, this is the first work showing that RBMs can be trained with almost no hyperparameter tuning to provide classification performance similar to or significantly better than mixture models (e. g., Gaussian mixture models). Along with this efficient training, we evaluate the importance of convolutional training that can capture a larger spatial context with less redundancy, as compared to non-convolutional training. Overall, our method achieves state-of-the-art performance on both Caltech 101 / 256 datasets using a single type of feature.	[Sohn, Kihyuk; Jung, Dae Yon; Lee, Honglak; Hero, Alfred O., III] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	Sohn, K (reprint author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.	kihyuks@umich.edu; dyjung@umich.edu; honglak@umich.edu; hero@umich.edu					Agarwal A., 2006, EUR C COMP VIS, P30; Bengio Y., 2007, NIPS; Bishop C. M., 2006, PATTERN RECOGNITION, V4; Boureau Y.L., 2010, CVPR; Coates A., 2011, AISTATS; Dalal N., 2005, CVPR; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Fei-fei L., 2004, CVPR; Griffin G., 2007, CALTECH 256 OBJECT C; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kavukcuoglu K., 2010, NIPS; Lazebnik S., 2006, CVPR; Lee H., 2009, ICML; Lee H., 2008, NIPS; Lowe D.G., 1999, ICCV; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ranzato M., 2010, AISTATS; Ranzato M. A., 2006, NIPS, P1137; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; van Gemert J. C., 2008, ECCV, V3; Wang J., 2010, CVPR; Winn J., 2005, ICCV; Yang JC, 2009, PROC CVPR IEEE, P1794; Yu K., 2009, NIPS; Zeiler M., 2010, CVPR	27	12	12	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4577-1102-2				2011							2643	2650				8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BYS97	WOS:000300061900336		
J	White, H; Chalak, K				White, Halbert; Chalak, Karim			Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						causal models; game theory; machine learning; recursive estimation; simultaneous equations	INFLUENCE DIAGRAMS; NEURAL-NETWORKS; ALGORITHM; INFERENCE; TIME	Judea Pearl's Causal Model is a rich framework that provides deep insight into the nature of causal relations. As yet, however, the Pearl Causal Model (PCM) has had a lesser impact on economics or econometrics than on other disciplines. This may be due in part to the fact that the PCM is not as well suited to analyzing structures that exhibit features of central interest to economists and econometricians: optimization, equilibrium, and learning. We offer the settable systems framework as an extension of the PCM that permits causal discourse in systems embodying optimization, equilibrium, and learning. Because these are common features of physical, natural, or social systems, our framework may prove generally useful for machine learning. Important features distinguishing the settable system framework from the PCM are its countable dimensionality and the use of partitioning and partition-specific response functions to accommodate the behavior of optimizing and interacting agents and to eliminate the requirement of a unique fixed point for the system. Refinements of the PCM include the settable systems treatment of attributes, the causal role of exogenous variables, and the dual role of variables as causes and responses. A series of closely related machine learning examples and examples from game theory and machine learning with feedback demonstrates some limitations of the PCM and motivates the distinguishing features of settable systems.	[White, Halbert] Univ Calif San Diego, Dept Econ, La Jolla, CA 92093 USA; [Chalak, Karim] Boston Coll, Dept Econ, Chestnut Hill, MA 02467 USA	White, H (reprint author), Univ Calif San Diego, Dept Econ, 9500 Gilman Dr, La Jolla, CA 92093 USA.	HWHITE@UCSD.EDU; CHALAK@BC.EDU					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Berge C., 1963, TOPOLOGICAL SPACES; CHALAK K, 2008, EXTENDED CLASS INSTR; Chalak K., 2008, INDEPENDENCE CONDITI; Chen XH, 1998, J ECON THEORY, V82, P190, DOI 10.1006/jeth.1998.2432; Dawid AP, 2002, INT STAT REV, V70, P161; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; EICHLER M, 2007, P 23 ANN C UNC ART I; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; FISHER FM, 1970, ECONOMETRICA, V38, P73, DOI 10.2307/1909242; FRIEDMAN JW, 1971, REV ECON STUD, V38, P1, DOI 10.2307/2296617; GEIGER D, 1990, NETWORKS, V20, P507, DOI 10.1002/net.3230200504; Gibbons R., 1992, GAME THEORY APPL EC; Halpern JY, 2000, J ARTIF INTELL RES, V12, P317; Heckerman D, 1995, J ARTIF INTELL RES, V3, P405; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1986, PARALLEL DISTRIBUTED, V1, P282; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOLLAND PW, 1986, J AM STAT ASSOC, V81, P945, DOI 10.2307/2289064; Howard R. A., 1984, READINGS PRINCIPLES; JORDAN MI, 1992, J MATH PSYCHOL, V36, P396, DOI 10.1016/0022-2496(92)90029-7; Kalman R.E., 1960, T ASME D, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]; Koller D, 2003, GAME ECON BEHAV, V45, P181, DOI 10.1016/S0899-8256(02)00544-4; KUAN CM, 1994, NEURAL COMPUT, V6, P420, DOI 10.1162/neco.1994.6.3.420; Kushner H. J., 1978, STOCHASTIC APPROXIMA; Ljung L., 1983, THEORY PRACTICE RECU; Marsden J., 2003, VECTOR CALCULUS; NASH JF, 1950, P NATL ACAD SCI USA, V36, P48, DOI 10.1073/pnas.36.1.48; Neuberg LG, 2003, ECONOMET THEOR, V19, P675, DOI 10.1017/S026646603004109; Pearl J., 2000, CAUSALITY; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; SCHENNACH S, 2008, ESTIMATING AVERAGE M; Sergeyev YD, 2001, J COMPUT ANAL APPL, V3, P123, DOI 10.1023/A:1010185125012; Shipley B., 2000, CAUSE CORRELATION BI; STROTZ RH, 1960, ECONOMETRICA, V28, P417, DOI 10.2307/1907731; Van Huffel S., 2002, TOTAL LEAST SQUARES; WHITE H, 2009, METHODOLOGY PRACTICE; WHITE H, 2007, IDENTIFYING EFFECTS; White H., 2001, ASYMPTOTIC THEORY EC; White H, 2006, J ECONOMETRICS, V135, P527, DOI 10.1016/j.jeconom.2005.07.013	40	12	12	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	AUG	2009	10						1759	1799				41	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BO	WOS:000270825200001		
J	Deng, L; Li, X				Deng, Li; Li, Xiao			Machine Learning Paradigms for Speech Recognition: An Overview	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Machine learning; speech recognition; supervised; unsupervised; discriminative; generative; dynamics; adaptive; Bayesian; deep learning	HIDDEN MARKOV-MODELS; MINIMUM CLASSIFICATION ERROR; CONVEX-OPTIMIZATION; BAYES-RISK; PARAMETER-ESTIMATION; MIXTURE OBSERVATIONS; MAXIMUM-LIKELIHOOD; NEURAL-NETWORKS; MULTIPLE TASKS; PHONE ERROR	Automatic Speech Recognition (ASR) has historically been a driving force behind many machine learning (ML) techniques, including the ubiquitously used hidden Markov model, discriminative learning, structured sequence learning, Bayesian learning, and adaptive learning. Moreover, ML can and occasionally does use ASR as a large-scale, realistic application to rigorously test the effectiveness of a given technique, and to inspire new problems arising from the inherently sequential and dynamic nature of speech. On the other hand, even though ASR is available commercially for some applications, it is largely an unsolved problem-for almost all applications, the performance of ASR is not on par with human performance. New insight from modern ML methodology shows great promise to advance the state-of-the-art in ASR technology. This overview article provides readers with an overview of modern ML techniques as utilized in the current and as relevant to future ASR research and systems. The intent is to foster further cross-pollination between the ML and ASR communities than has occurred in the past. The article is organized according to the major ML paradigms that are either popular already or have potential for making significant contributions to ASR technology. The paradigms presented and elaborated in this overview include: generative and discriminative learning; supervised, unsupervised, semi-supervised, and active learning; adaptive and multi-task learning; and Bayesian learning. These learning paradigms are motivated and discussed in the context of ASR technology and applications. We finally present and analyze recent developments of deep learning and learning with sparse representations, focusing on their direct relevance to advancing ASR technology.	[Deng, Li; Li, Xiao] Microsoft Res, Redmond, WA 98052 USA	Deng, L (reprint author), Microsoft Res, Redmond, WA 98052 USA.	deng@microsoft.com; mimily@gmail.com			mentor-mentee project	Our earnest thanks go to MSR for the encouragement and support of the "mentor-mentee project" from which this paper grew out of, to Jeff Bilmes for contributions during the very early phase of developing this paper, to Geoff Hinton, John Platt, Mark Gales, Nelson Morgan, Hynek Hermansky, Alex Acero, and Jason Eisner for valuable discussions, to Helen Meng as the then Editor-in-Chief for the encouragement and for handling the reviews of the white paper leading to this paper during 2009, and, finally, to the three anonymous reviewers whose desire for perfection has made various versions of the revision steadily improve the paper's quality as new advances on ML and ASR frequently broke out throughout the writing and revision of this paper over the past 3 years.	Abdel-Hamid O, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4277; Abrash V., 1995, P EUR; Acero Alex, 2000, P ICSLP, P869; Anastasakos T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1137; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Andrew G, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4265; Argyriou A, 2007, P ADV NEUR INF PROC; Bacchiani Michiel, 2003, P INT C AC SPEECH SI, P224; Bahl L. R., 1986, P IEEE INT C AC SPEE, P49; Baker J., 1976, SPEECH RECOGN; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P78, DOI 10.1109/MSP.2009.932707; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Barber D, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.938028; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Baxter J., 1997, MACH LEARN, P7; Baxter J., 1995, P WORKSH COMP LEARN; Ben-David S., 2003, P COMP LEARN THEOR; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bennett K.P., 1998, P NEUR INF PROC SYST, P368; Biem A, 2001, IEEE T SPEECH AUDI P, V9, P96, DOI 10.1109/89.902277; Bilmes J., 2010, IEEE SIGNAL PROCESS, V33, P29; Bilmes J., 2003, MATH FDN SPEECH LANG; Bilmes J., 1997, TR97021 ICSI; Bilmes J., 2004, UWEETR20040016 DEP E; Bilmes JA, 2005, IEEE SIGNAL PROC MAG, V22, P89; Bilmes JA, 2003, COMPUT SPEECH LANG, V17, P213, DOI 10.1016/S0885-2308(03)00010-X; Bilmes JA, 2006, IEICE T INF SYST, VE89D, P869, DOI 10.1093/ietisy/e89-d.3.869; Bishop CM, 2006, PATTERN RECOGNITION; Blitzer J., 2008, P ADV NEUR INF PROC; Blum A., 2001, P INT C MACH LEARN; Blum A, 1998, P WORKSH COMP LEARN; Boulard H., 1993, IEEE T NEURAL NETWOR, V4, P893; Bourlard H., 1994, KLUWER INT SERIES EN, V247; Bourlard H, 1998, LECT NOTES ARTIF INT, V1387, P389; Bridle J., 1998, 1998 WORKSH LANG ENG; Bromberg I., 2007, P INT, P1829; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chang TH, 2008, INT CONF ACOUST SPEE, P4053; Chapelle O., 2006, P INT C MACH LEARN; CHARLET D, 2001, ACOUST SPEECH SIG PR, P357; Chelba C., 2004, P EMNLP JUL; Chengalvarayan R, 1998, IEEE T SPEECH AUDI P, V6, P505, DOI 10.1109/89.725317; Chengalvarayan R, 1997, IEEE T SPEECH AUDI P, V5, P243, DOI 10.1109/89.568731; Chesta C., 1999, P EUR; Chien J.-T., 2011, IEEE AUDIO SPEECH LA, V27, P43; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; COLLOBERT R., 2006, J MACH LEARN RES; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; Dagan I., 1995, P INT C MACH LEARN; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dai W., 2008, P ADV NEUR INF PROC; Daume H., 2006, J ARTIF INTELL RES, V26, P1; Daume H., 2008, P EMNLP; Daume H., 2009, P UNC ART INT; Dean J., 2012, P ADV NEURAL INF PRO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P256, DOI 10.1109/TSA.2005.854107; Deng L, 1997, SPEECH COMMUN, V22, P93, DOI 10.1016/S0167-6393(97)00018-6; Deng L, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2133; Deng L., 2012, IEEE AUDIO SPEECH LA, V20, P2409; Deng L, 2000, J ACOUST SOC AM, V108, P3036, DOI 10.1121/1.1315288; Deng L., 1991, COMPUT SPEECH LANG, V4, P345; DENG L, 1992, SIGNAL PROCESS, V27, P65, DOI 10.1016/0165-1684(92)90112-A; DENG L, 2002, ACOUST SPEECH SIG PR, P829; Deng L, 2006, DYNAMIC SPEECH MODEL; Deng L., 2003, MATH FDN SPEECH LANG, P115; Deng L., 1999, COMPUTATIONAL MODELS, P199; Deng L, 1998, SPEECH COMMUN, V24, P299, DOI 10.1016/S0167-6393(98)00023-5; DENG L, 2000, P ICSLP, P806; Deng L., 1994, IEEE T SPEECH AUDIO, V2, P101; DENG L, 1991, IEEE T SIGNAL PROCES, V39, P1677, DOI 10.1109/78.134406; Deng L, 2004, IEEE T SPEECH AUDI P, V12, P133, DOI 10.1109/TSA.2003.820201; Deng L., 2013, P INT C AC SPEECH SI; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Deng L, 2003, IEEE T SPEECH AUDI P, V11, P568, DOI 10.1109/TSA.2003.818076; DENG L, 1994, J ACOUST SOC AM, V95, P2702, DOI 10.1121/1.409839; Deng L, 2011, ROBUST SPEECH RECOGNITION OF UNCERTAIN OR MISSING DATA: THEORY AND APPLICATIONS, P67, DOI 10.1007/978-3-642-21317-5_4; Deng L., 2010, P INTERSPEECH; De Wachter M, 2007, IEEE T AUDIO SPEECH, V15, P1377, DOI 10.1109/TASL.2007.894524; Droppo J., 2004, P IEEE INT C AC SPEE, V1, pI; Eldar YC, 2010, IEEE SIGNAL PROC MAG, V27, P19, DOI 10.1109/MSP.2010.936016; EPHRAIM Y, 1990, IEEE T INFORM THEORY, V36, P372, DOI 10.1109/18.52483; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Fox EB, 2010, IEEE SIGNAL PROC MAG, V27, P43, DOI 10.1109/MSP.2010.937999; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Frey B., 2000, P EUR; Fu Q., 2007, P INTERSPEECH; Fu Q, 2012, IEEE T AUDIO SPEECH, V20, P780, DOI 10.1109/TASL.2011.2165279; Gales M, 2012, IEEE SIGNAL PROC MAG, V29, P70, DOI 10.1109/MSP.2012.2207140; Gales MJF, 2000, IEEE T SPEECH AUDI P, V8, P417, DOI 10.1109/89.848223; Gales MJF, 1996, IEEE T SPEECH AUDI P, V4, P352, DOI 10.1109/89.536929; Ganapathiraju A., 2000, P ADV NEUR INF PROC; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gauvain J.-L., 1991, P DARPA SPEECH NAT L, P272, DOI 10.3115/112405.112457; Gemmeke J. F., 2010, P INTERSPEECH; Gemmeke JF, 2011, IEEE T AUDIO SPEECH, V19, P2067, DOI 10.1109/TASL.2011.2112350; Gens R., 2012, P ADV NEUR INF PROC; Gibson M, 2010, IEEE T AUDIO SPEECH, V18, P1269, DOI 10.1109/TASL.2009.2032607; Gliozzo A., 2006, P ASS COMP LING; Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138; Goel V, 2004, IEEE T SPEECH AUDI P, V12, P234, DOI 10.1109/TSA.2004.825678; Golovin D., 2010, P INT C LEARN THEOR; Gong Y., 1996, P INT C SPOK LANG PR; Grandvalet Y., 1996, P ADV NEUR INF PROC; Grandvalet Y., 2004, P ADV NEUR INF PROC; Guillory A., 2010, P INT C MACH LEARN H; Gunawardana A, 2005, P INTERSPEECH; HAKKANITUR D, 2002, ACOUST SPEECH SIG PR, P3904; Hakkani-Tur D., 2004, P IEEE INT C AC SPEE, P429; Ham J., 2005, P INT WORKSH ART INT; Hamanaka Y, 2010, INT CONF ACOUST SPEE, P4350, DOI 10.1109/ICASSP.2010.5495650; Hasegawa-Johnson M, 2005, INT CONF ACOUST SPEE, P213; He X., 2011, IEEE SIGNAL PROCESS, V27, P126; He X., 2012, P ANN M ASS COMP LIN, P292; He X., 2008, DISCRIMINATIVE LEARN; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Heigold G, 2011, IEEE T AUDIO SPEECH, V19, P1138, DOI 10.1109/TASL.2010.2082532; Heigold G, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495228; Heintz I, 2009, IEEE T AUDIO SPEECH, V17, P1533, DOI 10.1109/TASL.2009.2022204; Heskes T., 2000, P INT C MACH LEARN; Hifny Y, 2009, IEEE T AUDIO SPEECH, V17, P354, DOI 10.1109/TASL.2008.2010286; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Holmes WJ, 1999, COMPUT SPEECH LANG, V13, P3, DOI 10.1006/csla.1998.0048; Huang J.-T., 2008, P INTERSPEECH; Huang X., HDB NATURAL LANGUAGE; Huang X., 2001, SPOKEN LANGUAGE PROC; Hutchinson B., 2013, IEEE T PATT IN PRESS; Hutchinson B, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4805; Jaakkola T., 1998, ADV NEURAL INF PROCE, V11; Jaakkola T., 1999, AITR1668 MIT ART INT; Russell MJ, 2005, COMPUT SPEECH LANG, V19, P205, DOI 10.1016/j.csl.2004.08.001; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; Jiang H, 2010, IEEE SIGNAL PROC MAG, V27, P115, DOI 10.1109/MSP.2010.936018; Jiang H, 2006, IEEE T AUDIO SPEECH, V14, P1584, DOI 10.1109/TASL.2006.879805; Jiao F., 2006, P ASS COMP LING; Joachims T., 2003, P INT C MACH LEARN; Joachims T., 1999, P INT C MACH LEARN; Joachims T., 2006, SEMISUPERVISED LEARN; Jordan MI, 2010, IEEE SIGNAL PROC MAG, V27, P17, DOI 10.1109/MSP.2010.938115; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257; JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307; Kalinli O, 2010, IEEE T AUDIO SPEECH, V18, P1889, DOI 10.1109/TASL.2010.2040522; Kemp T., 1999, P EUR; King S, 2007, J ACOUST SOC AM, V121, P723, DOI 10.1121/1.2404622; Kingsbury B., 2012, P INTERSPEECH; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Kuhn R., 2000, IEEE T SPEECH AUDIO, V8, P417; Kumar S., 2004, P HLT NAACL; Kuo H.-K. J., 2005, P INTERSPEECH; Kuo J., 2006, IEEE AUDIO SPEECH LA, V14, P873; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lamel L, 2002, COMPUT SPEECH LANG, V16, P115, DOI 10.1006/csla.2001.0186; Lee CH, 2000, P IEEE, V88, P1241; Lee C.-H., 2004, P ICSLP, P109; Lee L., 2003, P IEEE INT C AC SPEE, V1, pI; Leggetter CJ, 1995, COMPUT SPEECH LANG, V9; Lewis D., 1994, P INT C MACH LEARN; Li J, 2007, PROCEEDINGS OF THE 3RD INTERNATIONAL YELLOW RIVER FORUM ON SUSTAINABLE WATER RESOURCES MANAGEMENT AND DELTA ECOSYSTEM MAINTENANCE, VOL VI, P65; Li JY, 2009, COMPUT SPEECH LANG, V23, P389, DOI 10.1016/j.csl.2009.02.001; Li XW, 2007, IEEE T AUDIO SPEECH, V15, P2383, DOI 10.1109/TASL.2007.905151; Li X., 2007, P INT C ART INT STAT; Li X., 2009, P EMNLP; Lin H., 2009, P INTERSPEECH; Lin H, 2009, INT CONF ACOUST SPEE, P4333, DOI 10.1109/ICASSP.2009.4960588; Little R. J. A., 1987, P AAAI; Little Roderick J. A., 1987, STAT ANAL MISSING DA; Liu C, 2011, IEEE T AUDIO SPEECH, V19, P2474, DOI 10.1109/TASL.2011.2144969; Ma JZ, 2000, COMPUT SPEECH LANG, V14, P101, DOI 10.1006/csla.2000.0136; Mak B., 2004, IEEE T SPEECH AUDIO, V12, P28; Mann G., 2008, P ASS COMP LING; Mansour Y., 2009, P WORKSH COMP LEARN; Mansour Y., 2009, P UNC ART INT; McAllester D. A., 1998, P WORKSH COMP LEARN; McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778; Mesot B, 2007, IEEE T AUDIO SPEECH, V15, P1850, DOI 10.1109/TASL.2007.901312; Miguel A, 2011, IEEE T AUDIO SPEECH, V19, P1476, DOI 10.1109/TASL.2010.2092764; Mohamed A., 2010, P INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Morgan N, 2005, IEEE SIGNAL PROC MAG, V22, P81, DOI 10.1109/MSP.2005.1511826; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Morris J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P597; Myrvoll T., 2000, P INT C SPOK LANG PR; Neto J., 1995, P EUR; Ngiam J, 2011, P INT C MACH LEARN; Nguyen H.T., 2004, P 21 INT C MACH LEAR, P623; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Nigam K., 2000, P INT C INF KNOWL MA; Ostendorf M., 1992, P DARPA WORKSH CSR; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Ozkan E, 2009, IEEE T AUDIO SPEECH, V17, P1518, DOI 10.1109/TASL.2009.2022198; Padmanabhan M, 1998, IEEE T SPEECH AUDI P, V6, P71, DOI 10.1109/89.650313; Pernkopf F., 2005, P INT C MACH LEARN B; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; PICONE J, 1999, ACOUST SPEECH SIG PR, P109; Pinto J, 2011, IEEE T AUDIO SPEECH, V19, P225, DOI 10.1109/TASL.2010.2045943; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Pylkkonen J., 2012, IEEE Transactions on Audio, Speech and Language Processing, V20, DOI 10.1109/TASL.2012.2203805; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Rennie S., 2010, IEEE SIGNAL PROCESS, V33, P66; Riccardi G, 2005, IEEE T SPEECH AUDI P, V13, P504, DOI 10.1109/TSA.2005.848882; Rosti A., 2004, P IEEE INT C AC SPEE, V1, pI; Ruping S., 2001, P IEEE INT C DAT MIN; Sainath T. N., 2010, P INTERSPEECH; Sainath TN, 2011, IEEE T AUDIO SPEECH, V19, P2598, DOI 10.1109/TASL.2011.2155060; Sainath TN, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4153; Saon G., 2012, P INTERSPEECH; Saon G, 2012, IEEE T AUDIO SPEECH, V20, P43, DOI 10.1109/TASL.2011.2129911; Scheffer T., 2001, P INT C ADV INT DAT; Schlueter R., 2001, SPEECH COMMUN, V31, P287; Schluter R, 2011, IEEE T AUDIO SPEECH, V19, P1103, DOI 10.1109/TASL.2010.2091635; Settles B., 2008, P EMNLP; Settles B., 2010, 1648 U WISC; Sha F., 2007, ADV NEURAL INFORM PR, V19, P1249; Sha F, 2006, INT CONF ACOUST SPEE, P265; Sim KC, 2007, COMPUT SPEECH LANG, V21, P669, DOI 10.1016/j.csl.2007.03.004; Sindhwani V., 2006, J MACH LEARN RES, V7; Siniscalchi M., 2013, NEUROCOMPUTING; Sivaram G., 2010, P INTERSPEECH; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Sompolinsky H, 1992, P ACM WORKSH COMP LE; Stadermann J., 2004, P INTERSPEECH; Stoyanov V., 2011, P AISTAT; Subramanya A., 2009, P ADV NEUR INF PROC; Sun JP, 2002, J ACOUST SOC AM, V111, P1086, DOI 10.1121/1.1420380; Szummer M., 2001, P ADV NEUR INF PROC, V14; Thrun S., 1998, LEARNING LEARN; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tong S., 2000, P 17 INT C MACH LEAR, P999; Tsochantaridis I., 2004, P INT C MACH LEARN; Tuske Zoltan, 2012, P INTERSPEECH; Vapnik V. N., 1998, STAT LEARNING THEORY; Vinyals O., 2012, P ADV NEUR INF PROC; Wang C., 2009, P 21 INT JOINT C ART; Wessel F, 2005, IEEE T SPEECH AUDI P, V13, P23, DOI 10.1109/TSA.2004.838537; Weston J., 1999, ESANN, P219; Woodland P., 1996, COMPUT SPEECH LANG, V10; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Wu P., 2004, P INT C MACH LEARN; Xiao L, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2010.938085; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yaman S, 2008, IEEE T AUDIO SPEECH, V16, P1207, DOI 10.1109/TASL.2008.2001106; Yarowsky D, 1995, P ACL, P189; Yu D., 2009, COMPUT SPEECH LANG, V24, P433; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4409; Yu D., 2010, P NIPS WORKSH DEEP L; Yu D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2418; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4169; Yu D., 2012, P INTERSPEECH; Yu D, 2013, IEEE T AUDIO SPEECH, V21, P388, DOI 10.1109/TASL.2012.2227738; Yu D., 2009, P INT, P676; Yu D., 2010, P IEEE INT C AC SPEE; Yu D, 2008, COMPUT SPEECH LANG, V22, P415, DOI 10.1016/j.csl.2008.03.002; Yu D, 2009, INT CONF ACOUST SPEE, P4193, DOI 10.1109/ICASSP.2009.4960553; Yu K., 2005, P INT C MACH LEARN; Zavaliagkos G., 1995, P EUR; Zen H., 2004, P ISCA SSW5, P191; Zen H, 2012, IEEE T AUDIO SPEECH, V20, P794, DOI 10.1109/TASL.2011.2165280; Zhang L, 2008, IEEE SIGNAL PROC LET, V15, P245, DOI 10.1109/LSP.2008.917004; Zhang S., 2010, IEEE SIGNAL PROCESS, V17; Zhang SX, 2013, IEEE T AUDIO SPEECH, V21, P544, DOI 10.1109/TASL.2012.2227734; Zhang YD, 2011, INT CONF ACOUST SPEE, P5608; Zhou D., 2003, P ADV NEUR INF PROC; Zhu X., 2003, P INT C MACH LEARN; Zhu Xiaojin, 2002, CMUCALD02; Zweig G., 2010, P INTERSPEECH	273	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	MAY	2013	21	5					1060	1089		10.1109/TASL.2013.2244083		30	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	164ZD	WOS:000320450900001		
J	Narayanan, A; Wang, DL			IEEE	Narayanan, Arun; Wang, DeLiang			IDEAL RATIO MASK ESTIMATION USING DEEP NEURAL NETWORKS FOR ROBUST SPEECH RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Computational Auditory Scene Analysis; instantaneous SNR; noise robust ASR; Aurora-4	SEGREGATION; BINARY; NOISE	We propose a feature enhancement algorithm to improve robust automatic speech recognition (ASR). The algorithm estimates a smoothed ideal ratio mask (IRM) in the Mel frequency domain using deep neural networks and a set of time-frequency unit level features that has previously been used to estimate the ideal binary mask. The estimated IRM is used to filter out noise from a noisy Mel spectrogram before performing cepstral feature extraction for ASR. On the noisy subset of the Aurora-4 robust ASR corpus, the proposed enhancement obtains a relative improvement of over 38% in terms of word error rates using ASR models trained in clean conditions, and an improvement of over 14% when the models are trained using the multi-condition training data. In terms of instantaneous SNR estimation performance, the proposed system obtains a mean absolute error of less than 4 dB in most frequency channels.	[Narayanan, Arun] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Narayanan, A (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	narayaar@cse.ohio-state.edu; dwang@cse.ohio-state.edu					[Anonymous], 2005, 202050 ETSI ES; Barker J., 2000, P ICSLP BEIJ CHIN, P373; Droppo J., 2012, P IEEE ICASSP, P4677; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Garofolo JS, 1993, DARPA TIMIT ACOUSTIC; Hartmann W., 2011, OSUCISRC711TR21 DEP; Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Li JY, 2009, COMPUT SPEECH LANG, V23, P389, DOI 10.1016/j.csl.2009.02.001; Loizou P., 2007, SPEECH ENHANCEMENT T; Moreno PJ, 1996, INT CONF ACOUST SPEE, P733, DOI 10.1109/ICASSP.1996.543225; Parihar N., 2003, P EUROSPEECH GEN SWI, V4, P337; Raj B, 2005, IEEE SIGNAL PROC MAG, V22, P101, DOI 10.1109/MSP.2005.1511828; Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463; Seltzer ML, 2004, SPEECH COMMUN, V43, P379, DOI 10.1016/j.specom.2004.03.006; Srinivasan S, 2006, SPEECH COMMUN, V48, P1486, DOI 10.1016/j.specom.2006.09.003; Tchorz J, 2003, IEEE T SPEECH AUDI P, V11, P184, DOI 10.1109/TSA.2003.811542; van Hout J, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4105; Virtanen T., 2012, TECHNIQUES NOISE ROB; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wang D., 2006, COMPUTATIONAL AUDITO; Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233; Wang Y., 2013, IEEE T AUDI IN PRESS; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459; Young S., 2002, HTK BOOK, P3	25	11	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7092	7096				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507051		
J	Carneiro, G; Nascimento, JC; Freitas, A				Carneiro, Gustavo; Nascimento, Jacinto C.; Freitas, Antonio			The Segmentation of the Left Ventricle of the Heart From Ultrasound Data Using Deep Learning Architectures and Derivative-Based Search Methods	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article							BOUNDARY DETECTION ALGORITHMS; ROBUST SHAPE TRACKING; LEVEL SET APPROACH; ECHOCARDIOGRAPHIC SEQUENCES; AUTOMATIC SEGMENTATION; MAXIMUM-LIKELIHOOD; IMAGE SEGMENTATION; TIME SEGMENTATION; NEURAL-NETWORKS; MEDICAL IMAGES	We present a new supervised learning model designed for the automatic segmentation of the left ventricle (LV) of the heart in ultrasound images. We address the following problems inherent to supervised learning models: 1) the need of a large set of training images; 2) robustness to imaging conditions not present in the training data; and 3) complex search process. The innovations of our approach reside in a formulation that decouples the rigid and nonrigid detections, deep learning methods that model the appearance of the LV, and efficient derivative-based search algorithms. The functionality of our approach is evaluated using a data set of diseased cases containing 400 annotated images (from 12 sequences) and another data set of normal cases comprising 80 annotated images (from two sequences), where both sets present long axis views of the LV. Using several error measures to compute the degree of similarity between the manual and automatic segmentations, we show that our method not only has high sensitivity and specificity but also presents variations with respect to a gold standard (computed from the manual annotations of two experts) within interuser variability on a subset of the diseased cases. We also compare the segmentations produced by our approach and by two state-of-the-art LV segmentation models on the data set of normal cases, and the results show that our approach produces segmentations that are comparable to these two approaches using only 20 training images and increasing the training set to 400 images causes our approach to be generally more accurate. Finally, we show that efficient search methods reduce up to tenfold the complexity of the method while still producing competitive segmentations. In the future, we plan to include a dynamical model to improve the performance of the algorithm, to use semisupervised learning methods to reduce even more the dependence on rich and large training sets, and to design a shape model less dependent on the training set.	[Carneiro, Gustavo] Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia; [Nascimento, Jacinto C.] Inst Super Tecn, Inst Sistemas & Robot, P-1049001 Lisbon, Portugal; [Freitas, Antonio] Fernando Fonseca Hosp, Dept Cardiol, Lisbon, Portugal	Carneiro, G (reprint author), Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia.	gustavo.carneiro@adelaide.edu.au; jan@isr.ist.utl.pt; aeffreitas@gmail.com			ISR/IST; HEARTRACK [PTDC/EEA-CRO/103462/2008]; European Union [PIIF-GA-2009-236173];  [PTDC/EEA-CRO/098550/2008]	This work was supported in part by the FCT project (ISR/IST plurianual funding) through the PIDDAC Program funds, by Project PTDC/EEA-CRO/098550/2008, by project "HEARTRACK" under Project PTDC/EEA-CRO/103462/2008, and by the European Union Project IMASEG3D (PIIF-GA-2009-236173). This work was performed while Dr. Carneiro was with the Instituto Superior Tecnico. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Marios S. Pattichis.	Akgul YS, 2003, IEEE T PATTERN ANAL, V25, P174, DOI 10.1109/TPAMI.2003.1177150; Alberola-Lopez C, 2004, IEEE T MED IMAGING, V23, P658, DOI 10.1109/TMI.2004.826358; Bartels R.H., 1987, INTRO SPLINES USE CO; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bernard O., 2007, P IEEE INT C IM PROC, P157; Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343; BLAND JM, 1986, LANCET, V1, P307; Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427; Boyd S., 2004, CONVEX OPTIMIZATION, V1st; Carneiro G, 2010, I S BIOMED IMAGING, P1085, DOI 10.1109/ISBI.2010.5490181; Carneiro G, 2010, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2010.5540013; Carneiro G, 2008, IEEE T MED IMAGING, V27, P1342, DOI 10.1109/TMI.2008.928917; Carreira-Perpinan M., 2005, P WORKSH ART INT STA; Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755; Chen T, 2008, IEEE T MED IMAGING, V27, P1084, DOI 10.1109/TMI.2008.918327; Cootes T., 1999, P 16 INT C INF PROC, P322; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Corsi C, 2002, IEEE T MED IMAGING, V21, P1202, DOI 10.1109/TMI.2002.804418; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Debreuve E, 2001, IEEE T MED IMAGING, V20, P643, DOI 10.1109/42.932748; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duan Q, 2010, COMPUT METH PROG BIO, V98, P223, DOI 10.1016/j.cmpb.2009.09.001; Duda R, 2001, PATTERN CLASSIFICATI; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga K., 1990, INTRO STAT PATTERN R; Georgescu B, 2005, PROC CVPR IEEE, P429; Gonzalez RC, 2008, DIGITAL IMAGE PROCES, V3rd; Hammoude A., 1988, THESIS U WASHINGTON; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jacob G, 2002, IEEE T MED IMAGING, V21, P226, DOI 10.1109/42.996341; KASS M, 1987, INT J COMPUT VISION, V1, P321; Lang RM, 2006, EUR J ECHOCARDIOGR, V7, P79, DOI 10.1016/j.euje.2005.12.014; Lin N, 2003, MED IMAGE ANAL, V7, P529, DOI 10.1016/S1361-8415(03)00035-5; Lynch M, 2008, IEEE T MED IMAGING, V27, P195, DOI 10.1109/TMI.2007.904681; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mignotte M, 2001, PATTERN ANAL APPL, V4, P256, DOI 10.1007/PL00010988; Mikic I, 1998, IEEE T MED IMAGING, V17, P274, DOI 10.1109/42.700739; Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294; Nascimento JC, 2008, IEEE T IMAGE PROCESS, V17, P392, DOI 10.1109/TIP.2007.915552; Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Paragios N, 2003, IEEE T MED IMAGING, V22, P773, DOI 10.1109/TMI.2003.814785; Reiber JHC, 1996, INT J CARDIAC IMAG, V12, P69, DOI 10.1007/BF01880736; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2007, P AI STAT; SANDLER H, 1968, AM HEART J, V75, P325, DOI 10.1016/0002-8703(68)90089-6; Sarti A, 2005, IEEE T ULTRASON FERR, V52, P947, DOI 10.1109/TUFFC.2005.1504017; Sonka M, 1995, IEEE T MED IMAGING, V14, P719, DOI 10.1109/42.476113; Viola P, 2001, PROC CVPR IEEE, P511; Weng J, 1997, IEEE T MED IMAGING, V16, P378, DOI 10.1109/42.611346; Zagrodsky V, 2005, IEEE T MED IMAGING, V24, P1089, DOI 10.1109/TMI.2005.852057; ZHANG LF, 1984, IEEE T BIO-MED ENG, V31, P441, DOI 10.1109/TBME.1984.325359; Zheng YF, 2008, IEEE T MED IMAGING, V27, P1668, DOI 10.1109/TMI.2008.2004421; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115; Zhu X., 2005, 1530 U WISC MAD	58	11	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149			IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	MAR	2012	21	3					968	982		10.1109/TIP.2011.2169273		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	895QH	WOS:000300510800006	21947526	
J	Zen, H; Gales, MJF; Nankaku, Y; Tokuda, K				Zen, Heiga; Gales, Mark J. F.; Nankaku, Yoshihiko; Tokuda, Keiichi			Product of Experts for Statistical Parametric Speech Synthesis	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Product of experts (PoE); statistical parametric speech synthesis; trajectory hidden Markov model (HMM)	SYNTHESIS SYSTEM; HMM; RECOGNITION; MODELS; ALGORITHM	Multiple acoustic models are often combined in statistical parametric speech synthesis. Both linear and non-linear functions of an observation sequence are used as features to be modeled. This paper shows that this combination of multiple acoustic models can be expressed as a product of experts (PoE); the likelihoods from the models are scaled, multiplied together, and then normalized. Normally these models are individually trained and only combined at the synthesis stage. This paper discusses a more consistent PoE framework where the models are jointly trained. A training algorithm for PoEs based on linear feature functions and Gaussian experts is derived by generalizing the training algorithm for trajectory HMMs. However for non-linear feature functions or non-Gaussian experts this is not possible, so a scheme based on contrastive divergence learning is described. Experimental results show that the PoE framework provides both a mathematically elegant way to train multiple acoustic models jointly and significant improvements in the quality of the synthesized speech.	[Zen, Heiga; Nankaku, Yoshihiko; Tokuda, Keiichi] Nagoya Inst Technol, Nagoya, Aichi 4668555, Japan; [Zen, Heiga; Gales, Mark J. F.] Toshiba Res Europe Ltd, Cambridge CB4 0GZ, England	Zen, H (reprint author), Google UK Ltd, London SW1W 9TQ, England.	heigazen@gmail.com; mark.gales@crl.toshiba.co.uk; nankaku@sp.nitech.ac.jp; tokuda@sp.nitech.ac.jp					Airey S., 2002, THESIS U CAMBRIDGE C; Bishop CM, 2006, PATTERN RECOGNITION; Chen L., 2011, P INT, P1801; Dines J., 2001, ACOUST SPEECH SIG PR, P833; Fukada T., 1992, P ICASSP, P137, DOI 10.1109/ICASSP.1992.225953; FURUI S, 1986, IEEE T ACOUST SPEECH, V34, P52, DOI 10.1109/TASSP.1986.1164788; Gales MJF, 2006, COMPUT SPEECH LANG, V20, P22, DOI 10.1016/j.csl.2004.12.002; Hinton G., 1999, P 9 INT C ART NEUR N, V1, P1; Hinton G., 2003, P NIPS, P417; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Kindermann R, 1980, MARKOV RANDOM FIELDS; Latorre J., 2008, P INT, P2274; Ling Z.-H., 2006, P BLIZZ CHALL WORKSH; Lu H, 2009, INT CONF ACOUST SPEE, P4033; Nagao K., 2009, P SPRINT M ASJ, P427; Neal R. M., 1993, CRGTR931 U TOR; O'Dell J., 1995, THESIS CAMBRIDGE U C; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Qian Y, 2011, IEEE T AUDIO SPEECH, V19, P1702, DOI 10.1109/TASL.2010.2097248; Rue H, 2005, GAUSSIAN MARKOV RAND; Rumelhart D. E, 1986, PARALLEL DISTRIBUTED; Shannon M., 2009, P INT, P400; Shinoda K., 1997, P EUR; Sim K., 2004, P ICASSP, P801; Sun JW, 2009, INT CONF ACOUST SPEE, P4021; Teh YW, 2004, J MACH LEARN RES, V4, P1235; Toda T, 2007, IEICE T INF SYST, VE90D, P816, DOI 10.1093/ietisy/e90-d.5.816; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Vickrey D., 2010, P ICML, P1103; Wang C., 2008, P ISCSLP, P129; Welling M., 2007, SCHOLARPEDIA; Williams CKI, 2005, NEURAL COMPUT, V17, P1, DOI 10.1162/0899766052530884; Yamagishi J., 2008, P BLIZZ CHALL WORKSH; Yamagishi J, 2008, INT CONF ACOUST SPEE, P3957; Yamagishi J., 2010, P BLIZZ CHALL WORKSH; Yoshimura T., 1999, P EUR, P2347; Zen H., 2007, P INT, P2065; Zen H., 2006, P ICASSP, P1173; Zen H, 2007, COMPUT SPEECH LANG, V21, P153, DOI 10.1016/j.csl.2006.01.002; Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825; Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004; Zen H., 2006, P INT, P2274; Zen HG, 2007, IEICE T INF SYST, VE90D, P325, DOI 10.1093/ietisy/e90-d.1.325; Zen HG, 2010, INT CONF ACOUST SPEE, P4242, DOI 10.1109/ICASSP.2010.5495691	46	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	MAR	2012	20	3					794	805		10.1109/TASL.2011.2165280		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	944AL	WOS:000304170300007		
J	Vinyals, O; Ravuri, SV; Povey, D			IEEE	Vinyals, Oriol; Ravuri, Suman V.; Povey, Daniel			REVISITING RECURRENT NEURAL NETWORKS FOR ROBUST ASR	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		Automatic Speech Recognition; Recurrent Neural Networks; Deep Learning		In this paper, we show how new training principles and optimization techniques for neural networks can be used for different network structures. In particular, we revisit the Recurrent Neural Network (RNN), which explicitly models the Markovian dynamics of a set of observations through a non-linear function with a much larger hidden state space than traditional sequence models such as an HMM. We apply pretraining principles used for Deep Neural Networks (DNNs) and second-order optimization techniques to train an RNN. Moreover, we explore its application in the Aurora2 speech recognition task under mismatched noise conditions using a Tandem approach. We observe top performance on clean speech, and under high noise conditions, compared to multi-layer perceptrons (MLPs) and DNNs, with the added benefit of being a "deeper" model than an MLP but more compact than a DNN.	[Vinyals, Oriol; Ravuri, Suman V.] Int Comp Sci Inst, Berkeley, CA 94704 USA	Vinyals, O (reprint author), Int Comp Sci Inst, Berkeley, CA 94704 USA.	vinyals@icsi.berkeley.edu; ravuri@icsi.berkeley.edu; dpovey@microsoft.com					BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Dahl G. E., 2012, IEEE T AUDIO SPEECH; Deng L., 2010, INTERSPEECH; Hermansky H., 2000, ICASSP; Hermansky H., 1999, ICASSP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Mikolov T., 2010, INTERSPEECH; Mohamed A., 2009, NIPS WORKSH; Mohamed A. r., 2010, INTERSPEECH; Pearce D., 2000, ISCA ITRW ASR CHALLE; Robinson T, 1994, ICASSP; Seide Frank, 2011, INTERSPEECH; Sharma S., 2000, ICASSP; Sutskever I., 2011, ICML; Vinyals O., 2012, AISTATS; Vinyals O., 2011, ICASSP	18	11	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							4085	4088				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381404039		
J	Coates, A; Carpenter, B; Case, C; Satheesh, S; Suresh, B; Wang, T; Wu, DJ; Ng, AY			IEEE	Coates, Adam; Carpenter, Blake; Case, Carl; Satheesh, Sanjeev; Suresh, Bipin; Wang, Tao; Wu, David J.; Ng, Andrew Y.			Text Detection and Character Recognition in Scene Images with Unsupervised Feature Learning	11TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR 2011)	Proceedings of the International Conference on Document Analysis and Recognition		English	Proceedings Paper	11th International Conference on Document Analysis and Recognition (ICDAR)	SEP 18-21, 2011	Beijing, PEOPLES R CHINA	Chinese Acad Sci, FOUNDER, NSFC, FUJITSU, Hanvon Technol, Green Apple Data Ctr, ABBYY, Raytheon BBN Technologies, Nuance, A2iA, ITESOFT, Int Assoc Pattern Recognit, TC10 Graph Recognit & TC11 Reading Syst, CAA, Tsinghua Univ, CASIA, HITACHI		Robust reading; character recognition; feature learning; photo OCR		Reading text from photographs is a challenging problem that has received a significant amount of attention. Two key components of most systems are (i) text detection from images and (ii) character recognition, and many recent methods have been proposed to design better feature representations and models for both. In this paper, we apply methods recently developed in machine learning-specifically, large-scale algorithms for learning the features automatically from unlabeled data-and show that they allow us to construct highly effective classifiers for both detection and recognition to be used in a high accuracy end-to-end system.	[Coates, Adam; Carpenter, Blake; Case, Carl; Satheesh, Sanjeev; Suresh, Bipin; Wang, Tao; Wu, David J.; Ng, Andrew Y.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Coates, A (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	acoates@cs.stanford.edu; blakec@cs.stanford.edu; cbcase@cs.stanford.edu; ssanjeev@cs.stanford.edu; bipins@cs.stanford.edu; twangcat@cs.stanford.edu; dwu4@cs.stanford.edu; ang@cs.stanford.edu					Bengio Y., 2006, NEURAL INFORM PROCES; Boureau Y., 2010, COMPUTER VISION PATT; Chen X., 2004, COMPUTER VISION PATT, V2; Coates A., 2011, INT C ART INT STAT; de Campos T. E., 2009, P INT C COMP VIS THE; Fan X., 2009, IEEE SIGNAL PROCESSI, V16; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lee H., 2009, INT C MACH LERN; Li L.-J., 2010, ADV NEURAL INFORM PR; Lucas S., 2003, INT C DOC AN REC; Neumann L., 2010, AS C COMP VIS; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pan Y., 2009, INT C DOC AN REC; Pan Y., 2008, INT WORKSH DOC AN SY; Raina R., 2007, 24 INT C MACH LEARN; Ranzato M., 2010, 13 INT C AI STAT; Ranzato M., 2007, NEURAL INFORM PROCES; Saidane Z., 2007, WORKSH CAM BAS DOC A; Salakhutdinov R., 2009, 12 INT C AI STAT; van Gemert J. C., 2008, EUR C COMP VIS; Weinman J., 2009, T PATTERN ANAL MACHI, V31; Weinman Jerod J, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), DOI 10.1109/ICPR.2010.970; Weinman J. J., 2008, P IAPR INT C PATT RE; Yang J., 2009, COMPUTER VISION PATT; Yokobayashi M, 2006, INT C PATT RECOG, P885	28	11	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1520-5363		978-0-7695-4520-2	PROC INT CONF DOC			2011							440	445		10.1109/ICDAR.2011.95		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BB4XG	WOS:000343450700086		
J	Jakel, F; Scholkopf, B; Wichmann, FA				Jaekel, Frank; Schoelkopf, Bernhard; Wichmann, Felix A.			Does Cognitive Science Need Kernels?	TRENDS IN COGNITIVE SCIENCES			English	Review							EXEMPLAR MODELS; TEMPORAL CORTEX; CATEGORIZATION; INFORMATION; SIMILARITY; TASKS; REPRESENTATION; RECOGNITION; ATTENTION; FEATURES	Kernel methods are among the most successful tools in machine learning and are used in challenging data analysis problems in many disciplines. Here we provide examples where kernel methods have proven to be powerful tools for analyzing behavioral data, especially for identifying features in categorization experiments. We also demonstrate that kernel methods relate to perceptrons and exemplar models of categorization. Hence, we argue that kernel methods have neural and psychological plausibility, and theoretical results concerning their behavior are therefore potentially relevant for human category learning. In particular, we believe kernel methods have the potential to provide explanations ranging from the implementational via the algorithmic to the computational level.	[Jaekel, Frank] MIT, Cambridge, MA 02139 USA; [Schoelkopf, Bernhard] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Wichmann, Felix A.] Tech Univ Berlin, D-10587 Berlin, Germany; [Wichmann, Felix A.] Bernstein Ctr Computat Neurosci, D-10115 Berlin, Germany	Jakel, F (reprint author), MIT, 43 Vassar St, Cambridge, MA 02139 USA.	fjaekel@mit.edu; bernhard.schoelkopf@tuebingen.mpg.de; felix.wichmann@tu-berlin.de	Scholkopf, Bernhard/A-7570-2013		German Federal Ministry of Education and Research; Deutsche Forschungsgemcinschaft	This work was funded in part by the Bernstein Computational Neuroscience Program of the German Federal Ministry of Education and Research and the Deutsche Forschungsgemcinschaft. We would like to thank Yarden Katz, Peter Battaglia and the anonymous reviewers for their helpful comments.	Abbey CK, 2006, J VISION, V6, P335, DOI 10.1167/6.4.4; AHUMADA A, 1971, J ACOUST SOC AM, V49, P1751, DOI 10.1121/1.1912577; Andrews S., 2003, ADV NEURAL INFORM PR, V15, P561; Ashby FG, 1998, PSYCHOL REV, V105, P442, DOI 10.1037/0033-295X.105.3.442; ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Bousquet O., 2003, ADV NEURAL INFORM PR, P415; BRISCOE E, 2006, P 28 ANN C COGN SCI, P1038; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Chapelle O., 2006, SEMISUPERVISED LEARN; Chater N, 2006, TRENDS COGN SCI, V10, P287, DOI 10.1016/j.tics.2006.05.007; Denton SE, 2008, PSYCHON B REV, V15, P780, DOI 10.3758/PBR.15.4.780; De Schryver M, 2009, PSYCHON B REV, V16, P337, DOI 10.3758/PBR.16.2.337; DEVROYE L., 1996, PROBABILISTIC THEORY; Dupuis-Roy N, 2009, J VISION, V9, DOI 10.1167/9.2.10; Edelman S, 1998, BEHAV BRAIN SCI, V21, P449; Erickson MA, 1998, J EXP PSYCHOL GEN, V127, P107, DOI 10.1037//0096-3445.127.2.107; Franz MO, 2006, NEURAL COMPUT, V18, P3097, DOI 10.1162/neco.2006.18.12.3097; GIGERENZER G, 1991, PSYCHOL REV, V98, P254, DOI 10.1037/0033-295X.98.2.254; Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T., 2009, ELEMENTS STAT LEARNI; Haussler D., 1999, UCSCCRL9910 DEP COMP; HEIT E, 1994, J EXP PSYCHOL LEARN, V20, P1264, DOI 10.1037//0278-7393.20.6.1264; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677; Jakel F, 2008, PSYCHON B REV, V15, P256, DOI 10.3758/PBR.15.2.256; Jakel F, 2008, J MATH PSYCHOL, V52, P299, DOI 10.1016/j.jmp.2008.03.001; Jakel F, 2007, J MATH PSYCHOL, V51, P343, DOI 10.1016/j.jmp.2007.06.002; Kienzle W., 2006, ADV NEURAL INFORM PR, V19, P689; KIENZLE W, J VIS, V9, P1; KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037/0033-295X.99.1.22; LAMBERTS K, 1994, J EXP PSYCHOL LEARN, V20, P1003, DOI 10.1037/0278-7393.20.5.1003; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Lee MD, 2008, PSYCHON B REV, V15, P1, DOI 10.3758/PBR.15.1.1; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309; MARLIN B, 2004, COLLABORATIVE FILTER; Marmarelis P, 1978, ANAL PHYSL SYSTEMS W; Marr D., 1982, VISION COMPUTATIONAL; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MINSKY M, 1967, 140 AI MIT; Murphy G. L., 2002, BIG BOOK CONCEPTS; Navarro DJ, 2007, J MATH PSYCHOL, V51, P85, DOI 10.1016/j.jmp.2006.11.003; Neri P, 2006, VISION RES, V46, P2465, DOI 10.1016/j.visres.2006.02.002; Nilsson NJ, 1965, LEARNING MACHINES; Nosofsky R. M., 1992, MULTIDIMENSIONAL MOD, P363; Nosofsky RA, 2002, J EXP PSYCHOL LEARN, V28, P924, DOI 10.1037//0278-7393.28.5.924; Nosofsky RM, 2000, PSYCHON B REV, V7, P375; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Op de Beeck H, 2001, NAT NEUROSCI, V4, P1244, DOI 10.1038/nn767; Palmeri TJ, 2004, NAT REV NEUROSCI, V5, P291, DOI 10.1038/nrn1364; PALMERI TJ, 2004, TRENDS COGN SCI, V8, P286; PALMERI TJ, 2001, SIMILARITY CATEGORIZ, P193; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341; Poggio T, 2004, NATURE, V431, P768, DOI 10.1038/nature03014; POGGIO T, 1990, COLD SH Q B, V55, P899; Poggio T, 1989, 1140 AI MIT; Rodrigues PM, 2007, PSYCHON B REV, V14, P640, DOI 10.3758/BF03196814; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379; Rumelhart D. E, 1986, PARALLEL DISTRIBUTED; Scholkopf B., 2004, KERNEL METHODS COMPU; Scholkopf B., 2002, LEARNING KERNELS; Schyns PG, 1998, BEHAV BRAIN SCI, V21, P1; Sigala N, 2002, NATURE, V415, P318, DOI 10.1038/415318a; SMALE S, 2008, 200870 CSAIL MIT; Smith JD, 2000, J EXP PSYCHOL LEARN, V26, P3; Sutton RS, 1998, REINFORCEMENT LEARNI; Vandist K, 2009, ATTEN PERCEPT PSYCHO, V71, P328, DOI 10.3758/APP.71.2.328; Vanpaemel W, 2008, PSYCHON B REV, V15, P732, DOI 10.3758/PBR.15.4.732; Vapnik V., 2000, NATURE STAT LEARNING; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Wichmann F. A., 2005, ADV NEURAL INFORM PR, V17, P1489; Yovel Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000032; ZHU X, 2007, 22 AAAI C ART INT, P864	79	11	11	ELSEVIER SCIENCE LONDON	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	1364-6613			TRENDS COGN SCI	TRENDS COGN. SCI.	SEP	2009	13	9					381	388		10.1016/j.tics.2009.06.002		8	Behavioral Sciences; Neurosciences; Psychology, Experimental	Behavioral Sciences; Neurosciences & Neurology; Psychology	506GW	WOS:000270764100007	19729333	
J	Shultz, TR				Shultz, Thomas R.			The Bayesian revolution approaches psychological development	DEVELOPMENTAL SCIENCE			English	Article							PROBABILISTIC MODELS; REASONING ABILITIES; LEARNING ALGORITHM; BASE RATES; SENSITIVITY; COGNITION; NETWORKS; CHILDREN; NETS	This commentary reviews five articles that apply Bayesian ideas to psychological development, some with psychology experiments, some with computational modeling, and some with both experiments and modeling. The reviewed work extends the current Bayesian revolution into tasks often studied in children, such as causal learning and word learning, and provides evidence that children's performance can be optimal in a Bayesian sense. There remains much to be done in terms of understanding how representations are created, how development occurs, how Bayesian computation might be neurally implemented, and in reconciling the new work with older evidence that even skilled adults are incompetent Bayesians.	McGill Univ, Dept Psychol, Montreal, PQ H3A 1B1, Canada	Shultz, TR (reprint author), McGill Univ, Dept Psychol, 1205 Penfield Ave, Montreal, PQ H3A 1B1, Canada.	Thomas.shultz@mcgill.ca					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Asoh H., 1989, P INT JOINT C NEUR N, V2, P411; BARHILLEL M, 1981, J PERS SOC PSYCHOL, V41, P671, DOI 10.1037//0022-3514.41.4.671; Baum E.B., 1988, NEURAL INFORMATION P, P52; Chase VM, 1998, TRENDS COGN SCI, V2, P206, DOI 10.1016/S1364-6613(98)01179-6; Chater N., 1998, RATIONAL MODELS COGN, P21; Chater N, 2006, TRENDS COGN SCI, V10, P335, DOI 10.1016/j.tics.2006.05.006; Chater N, 2006, TRENDS COGN SCI, V10, P287, DOI 10.1016/j.tics.2006.05.007; Cohen LB, 2004, INFANT CHILD DEV, V13, P349, DOI 10.1002/icd.355; Colunga E, 2005, PSYCHOL REV, V112, P347, DOI 10.1037/0033-295X.112.2.347; Courville AC, 2006, TRENDS COGN SCI, V10, P294, DOI 10.1016/j.tics.2006.05.004; Dayan P., 2001, THEORETICAL NEUROSCI; Eddy D. M., 1982, JUDGMENT UNCERTAINTY, P249; FISCHHOFF B, 1979, ORGAN BEHAV HUM PERF, V23, P339, DOI 10.1016/0030-5073(79)90002-3; GIGERENZER G, 1988, J EXP PSYCHOL HUMAN, V14, P513, DOI 10.1037/0096-1523.14.3.513; GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037/0033-295X.102.4.684; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; GLUCK MA, 1988, J EXP PSYCHOL GEN, V117, P227, DOI 10.1037/0096-3445.117.3.227; Gopnik A, 2001, DEV PSYCHOL, V37, P620, DOI 10.1037//0012-1649.37.5.620; Haith M, 1998, INFANT BEHAV DEV, V21, P167, DOI 10.1016/S0163-6383(98)90001-7; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jordan M. I., 1995, 9503 COMP COGN SCI; Kahneman D, 1996, PSYCHOL REV, V103, P582, DOI 10.1037//0033-295X.103.3.582; Kahneman D., 1982, JUDGMENT UNCERTAINTY; Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x; Kording KP, 2006, TRENDS COGN SCI, V10, P319, DOI 10.1016/j.tics.2006.05.003; KRUSCHKE JK, IN PRESS PSYCHOL REV; McClelland JL, 2007, DEVELOPMENTAL SCI, V10, P333, DOI 10.1111/j.1467-7687.2007.00586.x; MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Newell A., 1990, UNIFIED THEORIES COG; Read SJ, 1999, J PERS SOC PSYCHOL, V76, P728, DOI 10.1037//0022-3514.76.5.728; Samuel I, 2002, PHYS WORLD, V15, P20; Schulz LE, 2004, DEV PSYCHOL, V40, P162, DOI 10.1037/0012-1649.40.20.162; Schulz LE, 2007, DEVELOPMENTAL SCI, V10, P322, DOI 10.1111/j.1467-7687.2007.00587.x; SHULTZ TR, 1982, MONOGR SOC RES CHILD, V47, P1, DOI 10.2307/1165893; Shultz T. R., 2001, CONNECT SCI, V13, P1; Shultz TR, 2003, COMPUTATIONAL DEVELOPMENTAL PSYCHOLOGY, P1; Shultz TR, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1243; Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403; SOBEL DM, IN PRESS DEV PSYCHOL; Sobel DM, 2007, DEVELOPMENTAL SCI, V10, P298, DOI 10.1111/j.1467-7687.2007.00589.x; Sobel DM, 2004, COGNITIVE SCI, V28, P303, DOI 10.1016/j.cogsci.2003.11.001; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; TVERSKY A, 1981, SCIENCE, V211, P453, DOI 10.1126/science.7455683; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Xu F, 2007, DEVELOPMENTAL SCI, V10, P288, DOI 10.1111/j.1467-7687.2007.00590.x; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002	49	11	11	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1363-755X	1467-7687		DEVELOPMENTAL SCI	Dev. Sci.	MAY	2007	10	3					357	364		10.1111/j.1467-7687.2007.00588.x		8	Psychology, Developmental; Psychology, Experimental	Psychology	158RS	WOS:000245812200007	17444975	
J	Srivastava, N; Hinton, G; Krizhevsky, A; Sutskever, I; Salakhutdinov, R				Srivastava, Nitish; Hinton, Geoffrey; Krizhevsky, Alex; Sutskever, Ilya; Salakhutdinov, Ruslan			Dropout: A Simple Way to Prevent Neural Networks from Overfitting	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						neural networks; regularization; model combination; deep learning		Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.	[Srivastava, Nitish; Hinton, Geoffrey; Krizhevsky, Alex; Sutskever, Ilya; Salakhutdinov, Ruslan] Univ Toronto, Dept Comp Sci, Toronto, ON M5G 3G4, Canada	Srivastava, N (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd,Rm 3302, Toronto, ON M5G 3G4, Canada.	nitish@cs.toronto.edu; hinton@cs.toronto.edu; kriz@cs.toronto.edu; ilya@cs.toronto.edu; rsalakhu@cs.toronto.edu			OGS; NSERC; Early Researcher Award	This research was supported by OGS, NSERC and an Early Researcher Award.	Chen M., 2012, P 29 INT C MACH LEAR, P767; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Dekel O, 2010, MACH LEARN, V81, P149, DOI 10.1007/s10994-009-5124-8; Globerson A., 2006, P 23 INT C MACH LEAR, P353, DOI 10.1145/1143844.1143889; Goodfellow I. J., 2013, P 30 INT C MACH LEAR, P1319; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jarrett K., 2009, P INT C COMP VIS ICC; Krizhevsky A., 2009, TECHNICAL REPORT; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lin Y., 2010, LARGE SCALE VISUAL R; Livnat A, 2010, P NATL ACAD SCI USA, V107, P1452, DOI 10.1073/pnas.0910734106; Mnih V., 2009, 2009004 UTML U TOR D; Mohamed A., 2010, IEEE T AUDIO SPEECH; Neal R. M., 1996, BAYESIAN LEARNING NE; Netzer Y., 2011, NIPS WORKSH DEEP LEA; Nowlan S. J., 1992, NEURAL COMPUTATION, V4; Povey D., 2011, IEEE 2011 WORKSH AUT; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Salakhutdinov R., 2008, P 25 INT C MACH LEAR; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Sermanet P., 2012, INT C PATT REC ICPR; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; Snoek J, 2012, ADV NEURAL INFORM PR, V25, P2960; Srebro N., 2005, P 18 C LEARN THEOR C, P545; Srivastava N., 2013, THESIS U TORONTO; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tikhonov A. N., 1943, DOKL AKAD NAUK SSSR, V39, P195; vander Maaten L., 2013, P 30 INT C MACH LEAR, P410; Vincent P., 2010, P 27 INT C MACH LEAR, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wager S., 2013, ADV NEURAL INFORM PR, V26, P351; Wang S., 2013, P 30 INT C MACH LEAR, P118; Xiong HY, 2011, BIOINFORMATICS, V27, P2554, DOI 10.1093/bioinformatics/btr444; Zeiler M.D., 2013, CORR	36	10	10	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2014	15						1929	1958				30	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	AT0PS	WOS:000344638300002		
J	Siniscalchi, SM; Yu, D; Deng, L; Lee, CH				Siniscalchi, Sabato Marco; Yu, Dong; Deng, Li; Lee, Chin-Hui			Exploiting deep neural networks for detection-based speech recognition	NEUROCOMPUTING			English	Article						Deep neural networks; Multi-layer perceptrons; Articulatory recognition; Speech recognition; Lattice rescoring	ARTICULATORY FEATURES; VERIFICATION; MODELS; NETS	In recent years deep neural networks (DNNs) - multilayer perceptrons (MLPs) with many hidden layers - have been successfully applied to several speech tasks, i.e., phoneme recognition, out of vocabulary word detection, confidence measure, etc. In this paper, we show that DNNs can be used to boost the classification accuracy of basic speech units, such as phonetic attributes (phonological features) and phonemes. This boosting leads to higher flexibility and has the potential to integrate both top-down and bottom-up knowledge into the Automatic Speech Attribute Transcription (ASAT) framework. ASAT is a new family of lattice-based speech recognition systems grounded on accurate detection of speech attributes. In this paper we compare DNNs and shallow MLPs within the ASAT framework to classify phonetic attributes and phonemes. Several DNN architectures ranging from five to seven hidden layers and up to 2048 hidden units per hidden layer will be presented and evaluated. Experimental evidence on the speaker-independent Wall Street Journal corpus clearly demonstrates that DNNs can achieve significant improvements over the shallow MLPs with a single hidden layer, producing greater than 90% frame-level attribute estimation accuracies for all 21 phonetic features tested. Similar improvement is also observed on the phoneme classification task with excellent frame-level accuracy of 86.6% by using DNNs. This improved phoneme prediction accuracy, when integrated into a standard large vocabulary continuous speech recognition (LVCSR) system through a word lattice rescoring framework, results in improved word recognition accuracy, which is better than previously reported word lattice rescoring results. (c) 2012 Elsevier B.V. All rights reserved.	[Siniscalchi, Sabato Marco] Cittadella Univ, Kore Univ Enna, Fac Engn & Architecture, Enna, Sicily, Italy; [Siniscalchi, Sabato Marco; Lee, Chin-Hui] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; [Yu, Dong; Deng, Li] Microsoft Res, Speech Res Grp, Redmond, WA USA	Siniscalchi, SM (reprint author), Cittadella Univ, Kore Univ Enna, Fac Engn & Architecture, Enna, Sicily, Italy.	marco.siniscalchi@unikore.it; dongyu@microsoft.com; deng@mircosoft.com; chl@ece.gatech.edu	Siniscalchi, Sabato/I-3423-2012; Siniscalchi, Sabato Marco/	Siniscalchi, Sabato Marco/0000-0002-0770-0507			Abdou S, 2004, SPEECH COMMUN, V42, P409, DOI 10.1016/j.specom.2003.11.002; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179; Bazzi I., 2000, P ICSLP BEIJ CHIN, P401; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bernardis G., 1998, P ICSLP, P775; Birkenes O, 2010, IEEE T AUDIO SPEECH, V18, P1440, DOI 10.1109/TASL.2009.2035151; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bourlard Ha, 1994, CONNECTIONIST SPEECH; BRIDLE JS, 1990, SPEECH COMMUN, V9, P83, DOI 10.1016/0167-6393(90)90049-F; Chaudhari Upendra V, 2009, Proceedings of the 2009 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU 2009), DOI 10.1109/ASRU.2009.5373326; Chen B., 2004, P ICSLP, P612; CHEN TP, 1995, IEEE T NEURAL NETWOR, V6, P25; Church K., 1986, THESIS MIT; Collobert R., 2008, ICML 08, P160; Dahl G.E., 2010, IEEE T AUDIO SPEECH, V20, P30; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Demange S., 2011, P INT FLOR IT, P2305; Deng L., 2003, SPEECH RPOCESSING DY; DENG L, 1994, J ACOUST SOC AM, V95, P2702, DOI 10.1121/1.409839; Deng L., 1999, COMPUTATIONAL MODELS, P214; Eide E., P EUR 2001 AALB DENM, P1613; Frankel J, 2007, COMPUT SPEECH LANG, V21, P620, DOI 10.1016/j.csl.2007.03.002; Fu Q, 2012, IEEE T AUDIO SPEECH, V20, P780, DOI 10.1109/TASL.2011.2165279; Garofolo JS, 1993, DARPA TIMIT ACOUSTIC; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Gunawardana A., 2005, P INTERSPEECH, V2, P1117; HERMANSKY H, 2000, P ICASSP, P1635; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; JIN Q, 2002, ACOUST SPEECH SIG PR, P145; Kawahara T, 1998, IEEE T SPEECH AUDI P, V6, P558, DOI 10.1109/89.725322; King S, 2000, COMPUT SPEECH LANG, V14, P333, DOI 10.1006/csla.2000.0148; KIRCHHOFF K., 1998, P ICSLP, P891; Kirchhoff K., 1999, THESIS U BIELEFELD; Koo MW, 2001, IEEE T SPEECH AUDI P, V9, P821; Lang K.J., 1990, NEURAL NETWORKS, V3, P24; Layton MI, 2006, INT CONF ACOUST SPEE, P129; Lee CH, 2000, P IEEE, V88, P1241; Lee Chin-Hui, 2007, P INT, P1825; LEVINSON SE, 1985, P IEEE, V73, P1625, DOI 10.1109/PROC.1985.13344; Li J., 2012, P WORKSH SPOK LANG T; Li JY, 2007, IEEE T AUDIO SPEECH, V15, P2393, DOI 10.1109/TASL.2007.906178; Livescu K., 2005, THESIS MIT; Macherey W., 2005, P INT LISB PORT, P2133; Matejka P., 2005, P INT 2005 LISB PORT, P2237; Metze F., 2005, THESIS U KARLSRUHE G; Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16; Mohamed A., 2010, P INTERSPEECH, P1692; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Morris J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P597; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Paul D. B., 1992, P ICSLP; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Richardson M, 2003, SPEECH COMMUN, V41, P511, DOI 10.1016/S0167-6393(03)00031-1; Saenko K, 2009, IEEE T PATTERN ANAL, V31, P1700, DOI 10.1109/TPAMI.2008.303; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Scharenborg O, 2007, SPEECH COMMUN, V49, P811, DOI 10.1016/j.specom.2007.01.005; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Seide F., 2011, P ASRU, P24; Seide F., 2011, P INTERSPEECH, P437; Siniscalchi SM, 2012, IEEE T AUDIO SPEECH, V20, P875, DOI 10.1109/TASL.2011.2167610; Siniscalchi S.M., 2011, P INT FLOR IT, P901; Siniscalchi SM, 2009, SPEECH COMMUN, V51, P1139, DOI 10.1016/j.specom.2009.05.004; Siniscalchi SM, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P168; Siniscalchi SM, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, VOLS 1 AND 2, P566, DOI 10.1109/ASRU.2007.4430174; Sun JP, 2002, J ACOUST SOC AM, V111, P1086, DOI 10.1121/1.1420380; Young S., 2005, HTK BOOK HTK VERSION; Yu D., 2010, P NIPS WORKSH DEEP L; Yu D, 2011, IEEE T AUDIO SPEECH, V19, P2461, DOI 10.1109/TASL.2011.2141988; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4169; Yu D., 2011, P INTERSPEECH, P237	74	10	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	APR 15	2013	106						148	157		10.1016/j.neucom.2012.11.008		10	Computer Science, Artificial Intelligence	Computer Science	120FM	WOS:000317156200016		
J	Clark, A				Clark, Andy			Dreaming the Whole Cat: Generative Models, Predictive Processing, and the Enactivist Conception of Perceptual Experience	MIND			English	Editorial Material							REPRESENTATION; CONSCIOUSNESS; ALGORITHM; VISION; CORTEX; BRAIN; MIND	Does the material basis of conscious experience extend beyond the boundaries of the brain and central nervous system? In Clark 2009 I reviewed a number of 'enactivist' arguments for such a view and found none of them compelling. Ward (2012) rejects my analysis on the grounds that the enactivist deploys an essentially world-involving concept of experience that transforms the argumentative landscape in a way that makes the enactivist conclusion inescapable. I present an alternative (prediction-and-generative-model-based) account that neatly accommodates all the positive evidence that Ward cites on behalf of this enactivist conception, and that (I argue) makes richer and more satisfying contact with the full sweep of human experience.	Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland	Clark, A (reprint author), Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland.	andy.clark@ed.ac.uk					Bach y Rita P., 2003, TRENDS COGN SCI, V7, P541; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Block N, 2005, J PHILOS, V102, P259; BUBIC A, 2010, FRONT HUM NEUROSCI, V4, P1, DOI DOI 10.3389/FNHUM.2010.00025/ABSTRACT.ACCESSED:2012; Cisek P, 2007, PROG BRAIN RES, V165, P1; Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096; Clark A, 2009, MIND, V118, P963, DOI 10.1093/mind/fzp110; Clark A., 1997, BEING THERE PUTTING; Clark A, 1999, ADAPT BEHAV, V7, P5, DOI 10.1177/105971239900700101; Clark A., BEHAV BRAIN IN PRESS; Clark A., 2008, SUPERSIZING MIND EMB; Clark A., 2006, P ARISTOTELIAN SOC S, V80, P43; Corlett PR, 2009, PSYCHOPHARMACOLOGY, V206, P515, DOI 10.1007/s00213-009-1561-0; Cowan J D, 1994, ADV NEURAL INFORM PR, V6; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Eliasmith C, 2007, SYNTHESE, V159, P373, DOI 10.1007/s11229-007-9235-0; Feldman H., 2010, FRONT HUM NEUROSCI, V2, P215; Fletcher PC, 2009, NAT REV NEUROSCI, V10, P48, DOI 10.1038/nrn2536; Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005; Friston KJ, 2011, BIOL CYBERN, V104, P137, DOI 10.1007/s00422-011-0424-z; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; Gendler Tamar S., 2006, PERCEPTUAL EXPERIENC; GREGORY RL, 1980, PHILOS T ROY SOC B, V290, P181, DOI 10.1098/rstb.1980.0090; Grush R, 1997, PHILOS PSYCHOL, V10, P5, DOI 10.1080/09515089708573201; Grush R, 2004, BEHAV BRAIN SCI, V27, P377; Haddock Adrian, 2008, DISJUNCTIVISM PERCEP; Hinton G., 2011, ICANN 11 INT C ART N; Hinton G., 1994, 1994 M AM STAT ASS T; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hohwy J, 2008, COGNITION, V108, P687, DOI 10.1016/j.cognition.2008.05.010; Hohwy J, 2007, SYNTHESE, V159, P315, DOI 10.1007/s11229-007-9240-3; Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142; Koch C, 1994, LARGE SCALE NEURONAL; Millar A, 2007, PHILOS PHENOMEN RES, V74, P176, DOI 10.1111/j.1933-1592.2007.00008.x; Mohan M., PERCEPTION IN PRESS; Neisser U., 1967, COGNITIVE PSYCHOL; Noe A, 2004, ACTION PERCEPTION; O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939; Pettit P., 1986, SUBJECT THOUGHT CONT; Pfeifer R, 2007, LECT NOTES ARTIF INT, V4850, P76; Putnam H., 1999, THREEFOLD CORD MIND; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rieke F, 1999, SPIKES EXPLORING NEU; Sur M, 1999, J NEUROBIOL, V41, P33, DOI 10.1002/(SICI)1097-4695(199910)41:1<33::AID-NEU6>3.0.CO;2-1; Ward D, 2012, MIND, V121, P731, DOI 10.1093/mind/fzs095	48	10	10	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0026-4423			MIND	Mind	JUL	2012	121	483					753	771		10.1093/mind/fzs106		19	Philosophy	Philosophy	139FV	WOS:000318568300007		
J	Swietojanski, P; Ghoshal, A; Renals, S			IEEE	Swietojanski, Pawel; Ghoshal, Arnab; Renals, Steve			UNSUPERVISED CROSS-LINGUAL KNOWLEDGE TRANSFER IN DNN-BASED LVCSR	2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012)			English	Proceedings Paper	IEEE Workshop on Spoken Language Technology (SLT)	DEC 02-05, 2012	Miami, FL	Inst Elect & Elect Engineers (IEEE), IEEE Signal Processing Soc		Cross-lingual ASR; Deep Neural Networks; RBM pretraining; GlobalPhone	SPEECH RECOGNITION; NETS	We investigate the use of cross-lingual acoustic data to initialise deep neural network (DNN) acoustic models by means of unsupervised restricted Boltzmann machine (RBM) pretraining. DNNs for German are pretrained using one or all of German, Portuguese, Spanish and Swedish. The DNNs are used in a tandem configuration, where the network outputs are used as features for a hidden Markov model (HMM) whose emission densities are modeled by Gaussian mixture models (GMMs), as well as in a hybrid configuration, where the network outputs are used as the HMM state likelihoods. The experiments show that unsupervised pretraining is more crucial for the hybrid setups, particularly with limited amounts of transcribed training data. More importantly, unsupervised pretraining is shown to be language-independent.	[Swietojanski, Pawel; Ghoshal, Arnab; Renals, Steve] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland	Swietojanski, P (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland.	p.swietojanski@sms.ed.ac.uk; a.ghoshal@ed.ac.uk; s.renals@ed.ac.uk					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bergstra J, 2010, P SCIPY; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Burget L, 2010, P IEEE ICASSP; Cetin O, 2007, P IEEE ASRU; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Erhan D, 2010, J MACH LEARN RES, V11, P625; GOPINATH RA, 1998, ACOUST SPEECH SIG PR, P661; Grezl F., 2007, P IEEE ICASSP; Grezl F, 2011, P IEEE ASRU; Hermansky H, 2000, P IEEE ICASSP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Imseng D., 2012, P IEEE ICASSP; Lal P., 2011, THESIS U EDINBURGH; Lu L, 2011, P IEEE ASRU; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Povey D., 2011, P IEEE ASRU; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7; Schultz T, 2002, P ICLSP; Schultz T, 2001, P EUR; Seide F, 2011, P IEEE ASRU; Stolcke A, 2006, P IEEE ICASSP; Thomas S, 2012, P IEEE ICASSP; Thomas Samuel, 2010, P INTERSPEECH; Vu NT, 2011, P IEEE ICASSP	28	10	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5126-3				2012							246	251				6	Engineering, Electrical & Electronic	Engineering	BEL18	WOS:000317182800043		
J	McNamara, DS				McNamara, Danielle S.			Computational Methods to Extract Meaning From Text and Advance Theories of Human Cognition	TOPICS IN COGNITIVE SCIENCE			English	Article						Sematic models; Computational techniques; Meaning extraction; Cognition; Memory; Embodiment; Latent representations; LSA	PERCEPTUAL SYMBOL SYSTEMS; LATENT SEMANTIC ANALYSIS; FEATURE PRODUCTION NORMS; LARGE SET; KNOWLEDGE; MEMORY; MODEL; REPRESENTATION; COOCCURRENCE; COHESION	Over the past two decades, researchers have made great advances in the area of computational methods for extracting meaning from text. This research has to a large extent been spurred by the development of latent semantic analysis (LSA), a method for extracting and representing the meaning of words using statistical computations applied to large corpora of text. Since the advent of LSA, researchers have developed and tested alternative statistical methods designed to detect and analyze meaning in text corpora. This research exemplifies how statistical models of semantics play an important role in our understanding of cognition and contribute to the field of cognitive science. Importantly, these models afford large-scale representations of human knowledge and allow researchers to explore various questions regarding knowledge, discourse processing, text comprehension, and language. This topic includes the latest progress by the leading researchers in the endeavor to go beyond LSA.	Univ Memphis, Dept Psychol, Inst Intelligent Syst, Memphis, TN 38152 USA	McNamara, DS (reprint author), Univ Memphis, Dept Psychol, Inst Intelligent Syst, 202 Psychol Bldg, Memphis, TN 38152 USA.	dsmcnamara1@gmail.com					Barsalou LW, 2003, PHILOS T ROY SOC B, V358, P1177, DOI 10.1098/rstb.2003.1319; Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; de Vega M., 2008, SYMBOLS EMBODIMENT D; DENNIS S, 2008, HIGHER LEVEL LANGUAG, P105; Dennis S, 2005, COGNITIVE SCI, V29, P145, DOI 10.1207/s15516709cog0000_9; Dunning T., 1993, Computational Linguistics, V19; FENSON L, 1994, MONOGR SOC RES CHILD, V59, pR5; Firth JR, 1957, STUDIES LINGUISTIC A, P1; Glenberg AM, 1997, BEHAV BRAIN SCI, V20, P1; GRAESSER AC, 2010, TOP COGN SCI, DOI DOI 10.1111/J.1756-8765.2010.01081.X; Church K. W., 1990, Computational Linguistics, V16; Hinton G, 2011, TOP COGN SCI, V3, P74, DOI 10.1111/j.1756-8765.2010.01109.x; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTZMAN DL, 1984, BEHAV RES METH INS C, V16, P96; Howard MW, 2002, J MATH PSYCHOL, V46, P269, DOI 10.1006/jmps.2001.1388; Howard MW, 2011, TOP COGN SCI, V3, P48, DOI 10.1111/j.1756-8765.2010.01112.x; Jones M. N., 2010, TOP COGN SCI, DOI [10.1111/j.1756-8765.2010.01111.x., DOI 10.1111/J.1756-8765.2010.01111.X, 10.1111/j.1756-8765.2010.01111. x]; Jones MN, 2007, PSYCHOL REV, V114, P1, DOI 10.1037/0033-295X.114.1.1; Jones MN, 2006, J MEM LANG, V55, P534, DOI 10.1016/j.jml.2006.07.003; Kintsch W., 1998, COMPREHENSION PARADI; Kintsch W., 2007, HDB LATENT SEMANTIC, P89; Kintsch W, 2001, COGNITIVE SCI, V25, P173, DOI 10.1207/s15516709cog2502_1; Kintsch W., 2008, SYMBOLS EMBODIMENT D, P145; KINTSCH W, 2010, TOP COGN SCI, DOI DOI 10.1111/J.1756-8765.2010.01107.X; Kwantes PJ, 2005, PSYCHON B REV, V12, P703, DOI 10.3758/BF03196761; Landauer T., 2007, HDB LATENT SEMANTIC, P3; Landauer T. K., 2007, HDB LATENT SEMANTIC; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Louwerse M. M., 2010, TOP COGN SCI, DOI [10.1111/j.1756-8765.2010.01106.x, DOI 10.1111/J.1756-8765.2010.01106.X]; Lowe W., 2001, P 23 ANN C COGN SCI, P576; Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766; MacWhinney B., 2000, CHILDES PROJECT TOOL; McNamara D. S., 2007, HDB LATENT SEMANTIC, P227; McNamara D. S., 2007, HDB LATENT SEMANTIC, P379; McNamara D. S., 2009, PSYCHOL LEARN MOTIV, P298; McNamara DS, 1996, DISCOURSE PROCESS, V22, P247; McNamara DS, 2010, DISCOURSE PROCESS, V47, P292, DOI 10.1080/01638530902959943; McRae K, 2005, BEHAV RES METHODS, V37, P547, DOI 10.3758/BF03192726; MURDOCK BB, 1992, LEARNING THEORY CONN, V1, P201; O'Reilly T, 2007, DISCOURSE PROCESS, V43, P121, DOI 10.1207/s15326950dp4302_2; OROURKE ST, 2009, HDB RES WEB 2 0 3 0; Osgood C, 1957, MEASUREMENT MEANING; PAIVIO A, COGNITIVE S IN PRESS; RECCHIA GL, 2009, BEHAV RES METHODS, V41, P657; Rohde D. L. T., 2005, IMPROVED METHO UNPUB; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Shaoul C, 2006, BEHAV RES METHODS, V38, P190, DOI 10.3758/BF03192768; Shapiro AM, 2000, J EDUC COMPUT RES, V22, P1; SMITH EE, 1974, PSYCHOL REV, V81, P214, DOI 10.1037/h0036351; Steyvers M, 2011, TOP COGN SCI, V3, P18, DOI 10.1111/j.1756-8765.2010.01097.x; Steyvers M., 2007, HDB LATENT SEMANTIC, P427; Stone B, 2011, TOP COGN SCI, V3, P92, DOI 10.1111/j.1756-8765.2010.01108.x; Vinson DP, 2008, BEHAV RES METHODS, V40, P183, DOI 10.3758/BRM.40.1.183; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485	54	10	10	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1756-8757			TOP COGN SCI	Top. Cogn. Sci.	JAN	2011	3	1					3	17		10.1111/j.1756-8765.2010.01117.x		15	Psychology, Experimental	Psychology	704LG	WOS:000286053900002	25164173	
J	Linsker, R				Linsker, Ralph			Neural network learning of optimal Kalman prediction and control	NEURAL NETWORKS			English	Article						Kalman filter; Kalman control; Recurrent neural network; Local cortical circuit	VISUAL-CORTEX; BAYESIAN-INFERENCE; CIRCUITS; FILTER; MODEL; INFORMATION; ALGORITHM	Although there are many neural network (NN) algorithms for prediction and for control, and although methods for optimal estimation (including filtering and prediction) and for optimal control in linear systems were provided by Kalman in 1960 (with nonlinear extensions since then), there has been, to my knowledge, no NN algorithm that learns either Kalman prediction or Kalman control (apart from the special case of stationary control). Here we show how optimal Kalman prediction and control (KPC), as well as system identification, can be learned and executed by a recurrent neural network composed of linear-response nodes, using as input only a stream of noisy measurement data. The requirements of KPC appear to impose significant constraints on the allowed NN circuitry and signal flows. The NN architecture implied by these constraints bears certain resemblances to the local-circuit architecture of mammalian cerebral cortex. We discuss these resemblances, as well as caveats that limit Our Current ability to draw inferences for biological function. It has been Suggested that the local cortical circuit (LCC) architecture may perform core functions (as yet unknown) that underlie sensory, motor, and other cortical processing. It is reasonable to conjecture that Such functions may include prediction, the estimation or inference of missing OF noisy sensory data, and the goal-driven generation Of Control signals. The resemblances found between the KPC NN architecture and that of the LCC are consistent with this conjecture. (C) 2008 Elsevier Ltd. All rights reserved.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Linsker, R (reprint author), IBM Corp, Thomas J Watson Res Ctr, Rm 36-110,1101 Kitchawan Rd & Route 134,POB 218, Yorktown Hts, NY 10598 USA.	linsker@us.ibm.com					BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Callaway EM, 1998, ANNU REV NEUROSCI, V21, P47, DOI 10.1146/annurev.neuro.21.1.47; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; George D., 2005, P INT JOINT C NEUR N, V3, P1812, DOI DOI 10.1109/IJCNN.2005.1556155; GILBERT CD, 1983, ANNU REV NEUROSCI, V6, P217, DOI 10.1146/annurev.ne.06.030183.001245; Grossberg S, 2001, CEREB CORTEX, V11, P37, DOI 10.1093/cercor/11.1.37; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; HAYKIN S, 2001, KALMAN FILTERING NEU, P23; Hertz J, 1991, INTRO THEORY NEURAL; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hirsch JA, 1998, J NEUROSCI, V18, P8086; Kalman R.E., 1960, T ASME D, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]; KLIMASAUSKAS C, 2001, Patent No. 6278962; Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lewicki MS, 1997, ADV NEUR IN, V9, P529; Linsker R, 2005, NEURAL NETWORKS, V18, P261, DOI 10.1016/j.neunet.2005.01.002; LINSKER R, 1992, NEURAL COMPUT, V4, P691, DOI 10.1162/neco.1992.4.5.691; Mountcastle V.B., 1998, PERCEPTUAL NEUROSCIE; Murata N, 1997, ADV NEUR IN, V9, P599; Poggio T, 2004, NATURE, V431, P768, DOI 10.1038/nature03014; Raizada RDS, 2001, VIS COGN, V8, P431; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 2004, NEURAL COMPUT, V16, P1, DOI 10.1162/08997660460733976; Rao RPN, 2005, NEUROREPORT, V16, P1843, DOI 10.1097/01.wnr.0000183900.92901.fc; Rao RPN, 1999, VISION RES, V39, P1963, DOI 10.1016/S0042-6989(98)00279-X; Rieke F, 1999, SPIKES EXPLORING NEU; Rivals I, 1998, NEUROCOMPUTING, V20, P279, DOI 10.1016/S0925-2312(98)00021-6; Singhal S., 1989, ADV NEURAL INFORMATI, V1, P133; Szirtes G, 2005, NEUROCOMPUTING, V65, P349, DOI 10.1016/j.neucom.2004.10.028; Szita I, 2004, NEURAL COMPUT, V16, P491, DOI 10.1162/089976604772744884; Todorov E, 2005, NEURAL COMPUT, V17, P1084, DOI 10.1162/0899766053491887; TRESP V, 2001, Patent No. 6272480; Williams R. J., 1992, P IJCNN 92 BALT, P241, DOI 10.1109/IJCNN.1992.227335; Yu A. J., 2005, ADV NEURAL INFORM PR, V17, P1577; Zemel R, 2005, ADV NEURAL INFORM PR, V17, P1609	37	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	NOV	2008	21	9					1328	1343		10.1016/j.neunet.2008.05.002		16	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	381QD	WOS:000261550100014	18602247	
J	Lusci, A; Pollastri, G; Baldi, P				Lusci, Alessandro; Pollastri, Gianluca; Baldi, Pierre			Deep Architectures and Deep Learning in Chemoinformatics: The Prediction of Aqueous Solubility for Drug-Like Molecules	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							CONTACT MAP PREDICTION; NEURAL-NETWORKS; ORGANIC NONELECTROLYTES; PARTITION-COEFFICIENTS; CHEMICAL-REACTIONS; GRADIENT DESCENT; SMALLEST RINGS; GRAPH KERNELS; FREE-ENERGY; ALGORITHM	Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief overview of deep learning methods and show in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties. However, molecules are typically described by undirected cyclic graphs, while recursive approaches typically use directed acyclic graphs. Thus, we develop methods to address this discrepancy, essentially by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph. One advantage of this approach is that it relies only minimally on the identification of suitable molecular descriptors because suitable representations are learned automatically from the data. Several variants of this approach are applied to the problem of predicting aqueous solubility and tested on four benchmark data sets. Experimental results show that the performance of the deep learning methods matches or exceeds the performance of other state-of-the-art methods according to several evaluation metrics and expose the fundamental limitations arising from training sets that are too small or too noisy. A Web-based predictor, AquaSol, is available online through the ChemDB portal (cdb.ics.uci.edu) together with additional material.	[Lusci, Alessandro; Pollastri, Gianluca] Natl Univ Ireland Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 4, Ireland; [Baldi, Pierre] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA	Lusci, A (reprint author), Natl Univ Ireland Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 4, Ireland.	alessandro.lusci@ucdconnect.ie; pfbaldi@uci.edu			Irish Research Council for Science, Engineering, and Technology; NSF [IIS-0513376]; NIH [LM010235]; NIH NLM [T15 LM07443]	A.L. is funded through a GREP Ph.D. scholarship from the Irish Research Council for Science, Engineering, and Technology. P.B.'s research is supported by the following grants: NSF IIS-0513376, NIH LM010235, and NIH NLM T15 LM07443. We acknowledge Open Eye Scientific Software and Chem Axon for academic software licenses and Jordan Hayes and Yuzo Kanomata for computing support.	[Anonymous], 1994, PHYS CHEM PROP DAT P; Azencott CA, 2007, J CHEM INF MODEL, V47, P965, DOI 10.1021/ci600397p; BALDI P, 1995, IEEE T NEURAL NETWOR, V6, P182, DOI 10.1109/72.363438; Baldi P., 2012, CODES CRYPTOGR, V65, P383; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Baldi P., 2003, J MACHINE LEARNING R, V4, P575; Baldi P., 2001, BIOINFORMATICS MACHI; Beans Marvin, CHEMAXON; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bergstrom CAS, 2003, J MED CHEM, V46, P558, DOI 10.1021/jm020986i; Bruneau P, 2006, J CHEM INF MODEL, V46, P1379, DOI 10.1021/ci0504014; Ceroni A, 2007, BIOINFORMATICS, V23, P2038, DOI 10.1093/bioinformatics/btm298; DANNENFELSER RM, 1991, CHEMOSPHERE, V23, P141, DOI 10.1016/0045-6535(91)90103-K; Dearden JC, 2006, EXPERT OPIN DRUG DIS, V1, P31, DOI 10.1517/17460441.1.1.31; Delaney JS, 2004, J CHEM INF COMP SCI, V44, P1000, DOI 10.1021/ci034243x; Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475; Dragon Professional Software for Windows, DRAG PROF SOFTW WIND; Erhan D, 2010, J MACH LEARN RES, V11, P625; Faller B, 2007, ADV DRUG DELIVER REV, V59, P533, DOI 10.1016/j.addr.2007.05.005; FAN BT, 1993, J CHEM INF COMP SCI, V33, P657, DOI 10.1021/ci00015a002; Frohlich H, 2004, QSAR COMB SCI, V23, P311, DOI 10.1002/qsar.200410011; Fuhner H, 1924, BER DTSCH CHEM GES, V57, P510, DOI 10.1002/cber.19240570326; Glomme A, 2005, J PHARM SCI-US, V94, P1, DOI 10.1002/jps.20212; HANSCH C, 1968, J ORG CHEM, V33, P347, DOI 10.1021/jo01265a071; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hewitt M, 2009, J CHEM INF MODEL, V49, P2572, DOI 10.1021/ci900286s; Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huuskonen J, 2000, J CHEM INF COMP SCI, V40, P773, DOI 10.1021/ci9901338; Jain N, 2001, J PHARM SCI, V90, P234, DOI 10.1002/1520-6017(200102)90:2<234::AID-JPS14>3.0.CO;2-V; Jorgensen WL, 2002, ADV DRUG DELIVER REV, V54, P355, DOI 10.1016/S0169-409X(02)00008-X; KAMLET MJ, 1986, J PHARM SCI, V75, P338, DOI 10.1002/jps.2600750405; Kayala MA, 2011, J CHEM INF MODEL, V51, P2209, DOI 10.1021/ci200207y; Kayala MA, 2012, J CHEM INF MODEL, V52, P2526, DOI 10.1021/ci3003039; Kier LB, 1986, MOL CONNECTIVITY STR; Kier LB, 1976, MOL CONNECTIVITY CHE; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; Larochelle H, 2009, J MACH LEARN RES, V10, P1; LeCun Y., 1990, P 10 INT C PATT REC, V2, P35; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ADV NEURAL INFORM PR, P1096; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Leo A, 1993, CHEM REV, P1281; LEO A, 1971, CHEM REV, V71, P525, DOI 10.1021/cr60274a001; Linas A, 2008, J CHEM INF MODEL, V48, P1289; Louis B, 2010, EUR J MED CHEM, V45, P4018, DOI 10.1016/j.ejmech.2010.05.059; Mahe P, 2009, MACH LEARN, V75, P3, DOI 10.1007/s10994-008-5086-2; March J., 1985, ADV ORGANIC CHEM REA, Vthird; Netzeva T. I., 2005, ATLA-ALTERN LAB ANIM, V33, P1; O'Neil MJ, 2001, MERCK INDEX; Pollastri G, 2002, BIOINFORMATICS S1, V18, P62; Ralaivola L, 2005, NEURAL NETWORKS, V18, P1093, DOI 10.1016/j.neunet.2005.07.009; RANDIC M, 1975, J AM CHEM SOC, V97, P6609, DOI 10.1021/ja00856a001; REYNOLDS JA, 1974, P NATL ACAD SCI USA, V71, P2925, DOI 10.1073/pnas.71.8.2925; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Scholkopf B., 2002, LEARNING KERNELS; Schroeter T. S, 2007, ESTIMATING DOMAIN AP; Socher R., 2011, EMNLP, P151; Starita A, 2000, J CHEM INF COMP SCI, V41, P202; Tegge AN, 2009, NUCLEIC ACIDS RES, V37, pW515, DOI 10.1093/nar/gkp305; Tetko IV, 2006, DRUG DISCOV TODAY, V11, P700, DOI 10.1016/j.drudis.2006.06.013; Timmerman H., 2002, HDB MOL DESCRIPTORS; Tropsha A, 2006, ANN REP COMP CHEM, V2, P113, DOI 10.1016/S1574-1400(06)02007-X; Wassvik CM, 2006, EUR J PHARM SCI, V29, P294, DOI 10.1016/j.ejps.2006.05.013; Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192; Wu L, 2008, NEURAL NETWORKS, V21, P1392, DOI 10.1016/j.neunet.2008.02.002; YALKOWSKY SH, 1980, J PHARM SCI, V69, P912, DOI 10.1002/jps.2600690814; Yalkowsky S.H, 1990, ARIZONA DATABASE AQU; ZAMORA A, 1976, J CHEM INF COMP SCI, V16, P40, DOI 10.1021/ci60005a013	73	9	10	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	JUL	2013	53	7					1563	1575		10.1021/ci400187y		13	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	190MY	WOS:000322345400004	23795551	
J	Basseville, M				Basseville, Michele			Divergence measures for statistical data processing-An annotated bibliography	SIGNAL PROCESSING			English	Review						Divergence; Distance; Information; f-Divergence; Bregman divergence; Learning; Estimation; Detection; Classification; Recognition; Compression; Indexing	NONNEGATIVE MATRIX FACTORIZATION; SPECTRAL DISTANCE MEASURES; KULLBACK-LEIBLER APPROXIMATION; DENSITY POWER DIVERGENCE; LINEAR INVERSE PROBLEMS; ALPHA-EM ALGORITHM; GAUSSIAN-PROCESSES; BREGMAN DIVERGENCE; INFORMATION DIVERGENCE; MODEL SELECTION	This paper provides an annotated bibliography for investigations based on or related to divergence measures for statistical data processing and inference problems. (C) 2012 Elsevier B.V. All rights reserved.	[Basseville, Michele] IRISA, F-35042 Rennes, France	Basseville, M (reprint author), CNRS, F-75700 Paris, France.	michele.basseville@irisa.fr					Aczel J., 1975, MATH SCI ENG, V115; Aczel J., 1966, MATH SCI ENG, V19; Aczel J., 1984, AEQUATIONES MATH, V27, P1; Agarwal A, 2010, MACH LEARN, V81, P99, DOI 10.1007/s10994-010-5203-x; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ALI SM, 1966, J ROY STAT SOC B, V28, P131; Altun Y, 2006, LECT NOTES ARTIF INT, V4005, P139, DOI 10.1007/11776420_13; Amari S, 2001, IEEE T INFORM THEORY, V47, P1701, DOI 10.1109/18.930911; Amari S., 2000, TRANSLATIONS MATH MO, V191; Amari S., 1985, LECT NOTES STAT, V28; Amari S, 2009, LECT NOTES COMPUT SC, V5416, P75; Amari SI, 2009, IEEE T INFORM THEORY, V55, P4925, DOI 10.1109/TIT.2009.2030485; Amari SI, 2007, NEURAL COMPUT, V19, P2780, DOI 10.1162/neco.2007.19.10.2780; Amari S.-I., 2010, 3 INT S INF GEOM ITS; ANANTHARAM V, 1990, IEEE T INFORM THEORY, V36, P938, DOI 10.1109/18.53762; Arikan E, 1996, IEEE T INFORM THEORY, V42, P99, DOI 10.1109/18.481781; ARIMOTO S, 1971, INFORM CONTROL, V19, P181, DOI 10.1016/S0019-9958(71)90065-9; Arimoto S., 1977, C MATH SOC J BOLYAI, V16, P41; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Arwini K, 2008, LECT NOTES MATH, V1953; Aslam JA, 2007, LECT NOTES COMPUT SC, V4425, P198; Aviyente S, 2004, IEEE T BIO-MED ENG, V51, P737, DOI 10.1109/TBME.2004.824133; BAHR RK, 1990, IEEE T INFORM THEORY, V36, P597, DOI 10.1109/18.54905; Banerjee A, 2007, J MACH LEARN RES, V8, P1919; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Banerjee A., 2004, ACM INT C P SERIES, V69; BARNDORFFNIELSEN OE, 1986, INT STAT REV, V54, P83, DOI 10.2307/1403260; BASSEVILLE M, 1989, SIGNAL PROCESS, V18, P349, DOI 10.1016/0165-1684(89)90079-0; Basseville M., 1996, 1020 IRISA; Basseville M, 1997, AUTOMATICA, V33, P783, DOI 10.1016/S0005-1098(97)00004-6; Basseville M, 1995, PROCEEDINGS 1995 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, P330, DOI 10.1109/ISIT.1995.550317; BASU A, 1994, ANN I STAT MATH, V46, P683, DOI 10.1007/BF00773476; Basu A, 1998, BIOMETRIKA, V85, P549, DOI 10.1093/biomet/85.3.549; Basu A., 2011, CHAPMAN HALL CRC MON; Basu A, 2004, COMPUT STAT DATA AN, V45, P105, DOI 10.1016/S0167-9473(02)00326-2; Bauschke H.H., 1983, J APPROXIMATION THEO, V121, P1; Bekara M, 2006, SIGNAL PROCESS, V86, P1400, DOI 10.1016/j.sigpro.2005.03.023; BENTAL A, 1989, J MATH ANAL APPL, V139, P537, DOI 10.1016/0022-247X(89)90128-5; Bercher JF, 2008, INFORM SCIENCES, V178, P2489, DOI 10.1016/j.ins.2008.02.003; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; Birge L, 2005, IEEE T INFORM THEORY, V51, P1611, DOI 10.1109/TIT.2005.844101; Blahut R.E., 1987, SERIES ELECT COMPUTE; BLAHUT RE, 1974, IEEE T INFORM THEORY, V20, P405, DOI 10.1109/TIT.1974.1055254; Boets J, 2007, LECT NOTES CONTR INF, V364, P15; BOUGEROL P, 1993, SIAM J CONTROL OPTIM, V31, P942, DOI 10.1137/0331041; Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI 10.1016/0041-5553(67)90040-7; Broniatowski M., KYBERNETIKA IN PRESS, P48; Broniatowski M, 2009, J MULTIVARIATE ANAL, V100, P16, DOI 10.1016/j.jmva.2008.03.011; Broniatowski M, 2006, STUD SCI MATH HUNG, V43, P403, DOI 10.1556/SScMath.43.2006.4.2; Broniatowski M, 2012, J STAT PLAN INFER, V142, P2554, DOI 10.1016/j.jspi.2012.03.013; BURBEA J, 1982, J MULTIVARIATE ANAL, V12, P575, DOI 10.1016/0047-259X(82)90065-3; BURBEA J, 1982, IEEE T INFORM THEORY, V28, P489, DOI 10.1109/TIT.1982.1056497; BURBEA J, 1982, IEEE T INFORM THEORY, V28, P961, DOI 10.1109/TIT.1982.1056573; BURG JP, 1982, P IEEE, V70, P963, DOI 10.1109/PROC.1982.12427; Byrnes CI, 2001, IEEE T AUTOMAT CONTR, V46, P822; Carreira-Perpinan M.A., 2005, P 10 INT WORKSH ART, P59; Cayton L., 2008, P 25 INT C MACH LEAR, P112, DOI 10.1145/1390156.1390171; Cayton L., 2009, ADV NEURAL INFORM PR, V22, P243; CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330; Cichocki A., 2009, NONNEGATIVE MATRIX T; Cichocki A, 2008, IEEE SIGNAL PROC MAG, V25, P142, DOI [10.1109/MSP.2008.4408452, 10.1109/MSP.2007.911394]; Cichocki A, 2006, LECT NOTES COMPUT SC, V3889, P32; Cichocki A, 2010, ENTROPY-SWITZ, V12, P1532, DOI 10.3390/e12061532; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; COURSOL J, 1979, CR ACAD SCI A MATH, V288, P769; Cover T., 1991, WILEY SERIES TELECOM; Cover T. M., 2006, ELEMENTS INFORM THEO; CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385; Csiszar I., 1967, STUD SCI MATH HUNG, V2, P329; Csiszar I, 2003, IEEE T INFORM THEORY, V49, P1474, DOI 10.1109/TIT.2003.810633; Csiszar I., 2009, P IEEE INT THEOR WOR, P96; Csiszar I., 1974, T 7 C INF THEOR STAT, VB, P73; Csiszar I., 1963, MAGYAR TUDOMANYOS AK, V8, P85; Csiszar I., 2012, ARXIV12020666; CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454; Csiszar I., 1967, STUD SCI MATH HUNG, V2, P299; CSISZAR I, 1995, ACTA MATH HUNG, V68, P161, DOI 10.1007/BF01874442; CSISZAR I, 1995, IEEE T INFORM THEORY, V41, P26, DOI 10.1109/18.370121; Csiszar I, 2008, ENTROPY, V10, P261, DOI 10.3390/e10030261; Dembo A., 1998, APPL MATH, V38; Dembo A, 1997, ANN PROBAB, V25, P927; DEMBO A, 1991, IEEE T INFORM THEORY, V37, P1501, DOI 10.1109/18.104312; Devroye L., 1996, STOCHASTIC MODELLING, V31; Dhillon I., 2006, ADV NEURAL INFORM PR, V8, P283; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Dhillon IS, 2007, SIAM J MATRIX ANAL A, V29, P1120, DOI 10.1137/060649021; Donoho D. L., 2004, ADV NEURAL INFORM PR, V16; DONSKER MD, 1975, COMMUN PUR APPL MATH, V28, P1; Dryden IL, 2009, ANN APPL STAT, V3, P1102, DOI 10.1214/09-AOAS249; Eguchi S, 2010, ENTROPY-SWITZ, V12, P262, DOI 10.3390/e12020262; Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506; Esteban M. D., 1997, Applications of Mathematics, V42, DOI 10.1023/A:1022447020419; Fe C., 2009, NEURAL COMPUT, V21, P793; Fedotov AA, 2003, IEEE T INFORM THEORY, V49, P1491, DOI 10.1109/TIT.2003.811927; Ferrante A, 2008, IEEE T AUTOMAT CONTR, V53, P954, DOI 10.1109/TAC.2008.920238; Ferrari D, 2010, ANN STAT, V38, P753, DOI 10.1214/09-AOS687; Fevotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO_a_00168; Finesso L, 2006, LINEAR ALGEBRA APPL, V416, P270, DOI 10.1016/j.laa.2005.11.012; Fischer A, 2010, J MULTIVARIATE ANAL, V101, P2207, DOI 10.1016/j.jmva.2010.05.008; Frigyik BA, 2008, IEEE T INFORM THEORY, V54, P5130, DOI 10.1109/TIT.2008.929943; Fujimoto Y, 2007, ANN I STAT MATH, V59, P3, DOI 10.1007/s10463-006-0097-x; Georgiou TT, 2006, IEEE T INFORM THEORY, V52, P1052, DOI 10.1109/TIT.2005.864422; Georgiou TT, 2007, IEEE T SIGNAL PROCES, V55, P3995, DOI 10.1109/TSP.2007.896119; Georgiou TT, 2003, IEEE T INFORM THEORY, V49, P2910, DOI 10.1109/TIT.2003.819324; Georgiou TT, 2009, IEEE T SIGNAL PROCES, V57, P859, DOI 10.1109/TSP.2008.2010009; Georgiou TT, 2008, IEEE T AUTOMAT CONTR, V53, P1108, DOI 10.1109/TAC.2008.923684; Gibilisco P., 2010, ALGEBRAIC GEOMETRIC; Gilardoni GL, 2010, IEEE T INFORM THEORY, V56, P5377, DOI 10.1109/TIT.2010.2068710; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; Gray R, 1990, ENTROPY INFORM THEOR; Gray R. M., 2010, ENTROPY INFORM THEOR; GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421; Grunwald PD, 2004, ANN STAT, V32, P1367, DOI 10.1214/009053604000000553; Guntuboyina A, 2011, IEEE T INFORM THEORY, V57, P2386, DOI 10.1109/TIT.2011.2110791; GYORFI L, 1978, ANN I STAT MATH, V30, P105, DOI 10.1007/BF02480206; Harremoes P, 2011, IEEE T INFORM THEORY, V57, P3230, DOI 10.1109/TIT.2011.2137353; Harremoes P., 2010, ARXIV10021493; Harremoes P., 2006, P IEEE INT S INF THE, P1827; Havrda M.E., 1975, KYBERNETIKA, V3, P30; He Y, 2003, IEEE T SIGNAL PROCES, V51, P1211, DOI 10.1109/TSP.2003.810305; Hero A. O., 2001, CSPL328 U MICH; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOEFFDING W, 1965, ANN MATH STAT, V36, P369, DOI 10.1214/aoms/1177700150; Huang T.S., 2010, ARXIV10043814; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Hyvarinen A, 2007, COMPUT STAT DATA AN, V51, P2499, DOI 10.1016/j.csda.2006.09.003; James W., 1961, P 4 BERK S MATH STAT, V1, P361; Jiang XH, 2012, IEEE T SIGNAL PROCES, V60, P1064, DOI 10.1109/TSP.2011.2178601; Jiang XH, 2012, IEEE T AUTOMAT CONTR, V57, P1723, DOI 10.1109/TAC.2012.2183171; Johnson O, 2004, PROBAB THEORY REL, V129, P391, DOI 10.1007/s00440-004-0344-0; JOHNSON RW, 1979, IEEE T INFORM THEORY, V25, P709, DOI 10.1109/TIT.1979.1056113; JONES LK, 1990, IEEE T INFORM THEORY, V36, P23, DOI 10.1109/18.50370; Jones MC, 2001, BIOMETRIKA, V88, P865, DOI 10.1093/biomet/88.3.865; Kagan A, 2008, APPL MATH-CZECH, V53, P195, DOI 10.1007/s10492-008-0004-2; Kanamori T, 2012, IEEE T INFORM THEORY, V58, P708, DOI 10.1109/TIT.2011.2163380; Kanamori T., OPTIMIZATIO IN PRESS, P27; Kanamori T., 2010, ARXIV10102846; Karagrigoriou A, 2010, STAT IND TECHNOL, P51, DOI 10.1007/978-0-8176-4799-5_6; Karagrigoriou A, 2008, STAT IND TECHNOL, P503, DOI 10.1007/978-0-8176-4619-6_35; Karlsson J, 2010, IEEE T AUTOMAT CONTR, V55, P405, DOI 10.1109/TAC.2009.2037280; Kass R.E., 1997, SERIES PROBABILITY S; KAZAKOS D, 1980, IEEE T AUTOMAT CONTR, V25, P950, DOI 10.1109/TAC.1980.1102475; KAZAKOS D, 1982, IEEE T INFORM THEORY, V28, P679, DOI 10.1109/TIT.1982.1056521; KAZAKOS D, 1980, IEEE T AUTOMAT CONTR, V25, P294, DOI 10.1109/TAC.1980.1102275; Kim M, 2008, J MULTIVARIATE ANAL, V99, P2453, DOI 10.1016/j.jmva.2008.02.031; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307424; Kivinen J, 2006, IEEE T SIGNAL PROCES, V54, P1782, DOI 10.1109/TSP.2006.872551; KNOCKAERT L, 1993, IEEE T SIGNAL PROCES, V41, P3171, DOI 10.1109/78.257248; Knockaert L, 2003, INFORM SCIENCES, V152, P139, DOI 10.1016/S0020-0255(03)00058-6; Knockaert L., 1994, STAT THERMODYN UNPUB; Kompass R, 2007, NEURAL COMPUT, V19, P780, DOI 10.1162/neco.2007.19.3.780; Kulis B, 2009, J MACH LEARN RES, V10, P341; Kullback S., 1987, LECT NOTES STAT, V42; Lafferty J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307422; Lafferty J., 1997, P CAN WORKSH INF THE, P77; Lafferty J., 2002, CMUCS01109R; Lawson J, 2007, SIAM J CONTROL OPTIM, V46, P930, DOI 10.1137/050637637; Lebanon G., 2001, ADV NEURAL INFORM PR; Le Besnerais G, 1999, IEEE T INFORM THEORY, V45, P1565, DOI 10.1109/18.771159; Lee H, 2008, NONLINEARITY, V21, P857, DOI 10.1088/0951-7715/21/4/011; Lefevre A, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P313, DOI 10.1109/ASPAA.2011.6082314; Leonenko N, 2010, J MULTIVARIATE ANAL, V101, P1981, DOI 10.1016/j.jmva.2010.05.009; Levy BC, 2004, IEEE T INFORM THEORY, V50, P89, DOI 10.1109/TIT.2003.821992; Li K, 2009, IET COMMUN, V3, P1851, DOI 10.1049/iet-com.2008.0586; Liese F, 2006, IEEE T INFORM THEORY, V52, P4394, DOI 10.1109/TIT.2006.881731; Liese F., 1987, TEXTE MATH, V95; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; LINDSAY BG, 1994, ANN STAT, V22, P1081, DOI 10.1214/aos/1176325512; Lutwak E, 2005, IEEE T INFORM THEORY, V51, P473, DOI 10.1109/TIT.2004.840871; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; MacKay D., 2003, INFORM THEORY INFERE; Maji P, 2009, IEEE T BIO-MED ENG, V56, P1063, DOI 10.1109/TBME.2008.2004502; Maji P, 2010, IEEE T KNOWL DATA EN, V22, P854, DOI 10.1109/TKDE.2009.124; Mantalos P, 2010, COMMUN STAT-SIMUL C, V39, P865, DOI 10.1080/03610911003650391; Markatou M, 1998, J AM STAT ASSOC, V93, P740, DOI 10.2307/2670124; Martin N, 2011, J MULTIVARIATE ANAL, V102, P1175, DOI 10.1016/j.jmva.2011.03.011; Mathai AM, 1975, BASIC CONCEPTS INFOR; MATSUYAMA Y, 2000, ACOUST SPEECH SIG PR, P592; Matsuyama Y, 2003, IEEE T INFORM THEORY, V49, P692, DOI 10.1109/TIT.2002.808105; Matsuyama Y., 2001, P 3 INT C IND COMP A, P31; Matsuyama Y, 1998, 1998 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY - PROCEEDINGS, P385; Mattheou K, 2009, J STAT PLAN INFER, V139, P228, DOI 10.1016/j.jspi.2008.04.022; Matus F, 2009, IEEE T INFORM THEORY, V55, P5375, DOI 10.1109/TIT.2009.2032806; Matusita K., 1973, DISCRIMINANT ANAL AP, P213; Merhav N, 2011, IEEE T INFORM THEORY, V57, P4926, DOI 10.1109/TIT.2011.2159052; Minami M., 2002, NEURAL COMPUT, V14, P1859; Minka T., 2005, MSRTR2005173 MICR RE; Mnih A, 2005, IEEE IJCNN, P1302; Moakher M., 2006, VISUALIZATION PROCES, V17, P285; Mollah MNH, 2006, NEURAL COMPUT, V18, P166, DOI 10.1162/089976606774841549; MORIMOTO T, 1963, J PHYS SOC JPN, V18, P328, DOI 10.1143/JPSJ.18.328; Murata N, 2004, NEURAL COMPUT, V16, P1437, DOI 10.1162/089976604323057452; Nascimento ADC, 2010, IEEE T GEOSCI REMOTE, V48, P373, DOI 10.1109/TGRS.2009.2025498; Nason GP, 2001, J ROY STAT SOC B, V63, P551, DOI 10.1111/1467-9868.00298; NATARAJAN S, 1985, IEEE T INFORM THEORY, V31, P360, DOI 10.1109/TIT.1985.1057036; NATH P, 1975, INFORM CONTROL, V29, P234, DOI 10.1016/S0019-9958(75)90404-0; Nguyen X, 2009, ANN STAT, V37, P876, DOI 10.1214/08-AOS595; Nguyen XL, 2010, IEEE T INFORM THEORY, V56, P5847, DOI 10.1109/TIT.2010.2068870; Nielsen F, 2009, IEEE T INFORM THEORY, V55, P2882, DOI 10.1109/TIT.2009.2018176; Nielsen F, 2011, IEEE T INFORM THEORY, V57, P5455, DOI 10.1109/TIT.2011.2159046; Nielsen F, 2009, IEEE INT CON MULTI, P878; Nishimura T, 2008, COMMUN STAT-THEOR M, V37, P1867, DOI 10.1080/03610920801893657; Nock R, 2009, IEEE T PATTERN ANAL, V31, P2048, DOI 10.1109/TPAMI.2008.225; Osterreicher F, 2003, ANN I STAT MATH, V55, P639, DOI 10.1007/BF02517812; Papantoni-Kazakos P., 1990, DETECTION ESTIMATION; Pardo L., 1995, SANKHYA B, V57, P315; Pardo L, 2006, CHAPMAN HALL CRC MON; Pardo MD, 2003, IEEE T INFORM THEORY, V49, P1860, DOI 10.1109/TIT.2003.813509; Patra R. K., 2008, SANKHYA B, V70, P310; Pavon M, 2006, IEEE T AUTOMAT CONTR, V51, P639, DOI 10.1109/TAC.2006.872755; Pavon M., 2011, ARXIV11125529; Pelletier B, 2011, STATISTICS, V45, P223, DOI 10.1080/02331880903546324; Pelletier B, 2005, ANN I STAT MATH, V57, P767, DOI 10.1007/BF02915437; Perez A., 1984, P COMPSTAT, P154; Petz D, 1996, LINEAR ALGEBRA APPL, V244, P81, DOI 10.1016/0024-3795(94)00211-8; Petz D, 2005, SIAM J MATRIX ANAL A, V27, P712, DOI 10.1137/050621906; Pham DT, 2008, IEEE T SIGNAL PROCES, V56, P4611, DOI 10.1109/TSP.2008.928109; Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872; Poczos B., 2012, ARXIV12023758; Principe J.C., 2008, INFORM THEORETIC LEA; Qiao Y, 2010, IEEE T SIGNAL PROCES, V58, P3884, DOI 10.1109/TSP.2010.2047340; Radhakrishna Rao C., 1982, SANKHYA A, V44, P1; Ramponi F, 2009, IEEE T AUTOMAT CONTR, V54, P2376, DOI 10.1109/TAC.2009.2028977; RAO CR, 1982, THEOR POPUL BIOL, V21, P24, DOI 10.1016/0040-5809(82)90004-1; Rao C. R., 1986, ENCY STAT SCI, V7, P614; Rao C.R., 1945, Bulletin of the Calcutta Mathematical Society, V37; RAO CR, 1985, IEEE T INFORM THEORY, V31, P589, DOI 10.1109/TIT.1985.1057082; Rao C.R., 1987, LECT NOTES MONOGRAPH, V10, P217; Rauh J, 2011, IEEE T INFORM THEORY, V57, P3236, DOI 10.1109/TIT.2011.2136230; Ravikumar P, 2010, J MACH LEARN RES, V11, P1043; Read T., 1988, STATISTICS; Reid MD, 2011, J MACH LEARN RES, V12, P731; Reid MD, 2010, J MACH LEARN RES, V11, P2387; Renyi A., 1960, P 4 BERK S MATH STAT, V1, P547; Renyi A., 1967, P 5 BERK S MATH STAT, V1, P531; Roman A., 2012, ARXIV12010418; Sander W., 2002, HDB MEASURE THEORY, V2, P1523; Santos-Rodriguez R, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P551, DOI 10.1109/ICMLA.2009.82; Schutzenberger M.P., 1953, THESIS U PARIS; SCHWEPPE FC, 1967, INFORM CONTROL, V11, P373, DOI 10.1016/S0019-9958(67)90610-9; SCHWEPPE FC, 1967, INFORM CONTROL, V11, P352, DOI 10.1016/S0019-9958(67)90609-2; SHORE JE, 1982, IEEE T PATTERN ANAL, V4, P11; SHORE JE, 1981, IEEE T INFORM THEORY, V27, P472, DOI 10.1109/TIT.1981.1056373; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Sibson R., 1969, PROBABILITY THEORY R, V14, P149; Sriperumbudur B.K., 2009, ARXIV09012698; Srivastava S, 2007, J MACH LEARN RES, V8, P1277; Stoorvogel AA, 1998, SYST CONTROL LETT, V35, P207, DOI 10.1016/S0167-6911(98)00053-X; Stummer W, 2010, STATISTICS, V44, P169, DOI 10.1080/02331880902986919; Stummer W, 2012, IEEE T INFORM THEORY, V58, P1277, DOI 10.1109/TIT.2011.2178139; Sugiyama M, 2012, ANN I STAT MATH, V64, P1009, DOI 10.1007/s10463-011-0343-8; Sung Y, 2006, IEEE T INFORM THEORY, V52, P1354, DOI 10.1109/TIT.2006.871599; Sutskever I., 2010, P 13 INT WORKSH ART, P78; Taneja I. J., 1989, ADV ELEC ELECT PHYS, V76, P327; Taneja I. J., 2001, GEN INFORM MEASURES; Taskar B, 2006, J MACH LEARN RES, V7, P1627; Teboulle M, 2007, J MACH LEARN RES, V8, P65; Teboulle M, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P127, DOI 10.1007/3-540-28349-8_5; Toma A, 2011, J MULTIVARIATE ANAL, V102, P20, DOI 10.1016/j.jmva.2010.07.010; Topsoe F, 2000, IEEE T INFORM THEORY, V46, P1602, DOI 10.1109/18.850703; Torgersen E., 1991, ENCY MATH ITS APPL, V36; Touboul J, 2010, ENTROPY-SWITZ, V12, P1581, DOI 10.3390/e12061581; Tsuda K, 2005, J MACH LEARN RES, V6, P995; Tsukada M., 2009, P IEEE INT S INF THE, P149; Vachery J., 2012, ARXIV12014285; Vajda I, 2009, KYBERNETIKA, V45, P885; Vajda I., 1973, T 6 PRAG C INF THEOR, P873; Vajda I., 2008, 2230 AC SCI CZECH RE; Vajda I., 1989, MATH STAT METHODS B, V11; Vemuri BC, 2011, IEEE T MED IMAGING, V30, P475, DOI 10.1109/TMI.2010.2086464; Vignat C., 2006, P IEEE INT S INF THE, P1822; Vrins F, 2007, LECT NOTES COMPUT SC, V4666, P129; Wang Q, 2009, IEEE T INFORM THEORY, V55, P2392, DOI 10.1109/TIT.2009.2016060; Wang SJ, 2003, LECT NOTES ARTIF INT, V2842, P190; Wu L, 2009, ADV NEURAL INFORM PR, V22, P2089; Wu Y., 2009, SANKHYA INDIAN J S A, V71, P260; Yeung R., 2002, INFORM TECHNOLOGY TR; Yeung RW, 2008, INFORM TECH TRANS PR, P1; Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983; Yu S, 2010, IEEE T AUTOMAT CONTR, V55, P1585, DOI 10.1109/TAC.2010.2042334; Zaripov R. G., 2005, NEW MEASURES METHODS; Zhang J, 2004, NEURAL COMPUT, V16, P159, DOI 10.1162/08997660460734047; ZIV J, 1973, IEEE T INFORM THEORY, V19, P275, DOI 10.1109/TIT.1973.1055015	284	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684	1879-2677		SIGNAL PROCESS	Signal Process.	APR	2013	93	4					621	633		10.1016/j.sigpro.2012.09.003		13	Engineering, Electrical & Electronic	Engineering	095EB	WOS:000315316400001		
J	Eickholt, J; Cheng, JL				Eickholt, Jesse; Cheng, Jianlin			DNdisorder: predicting protein disorder using boosting and deep networks	BMC BIOINFORMATICS			English	Article						Protein disorder prediction; Disordered regions; Deep networks; Deep learning	INTRINSICALLY UNSTRUCTURED PROTEINS; NATIVELY UNFOLDED PROTEINS; ACCURATE PREDICTION; NEURAL-NETWORKS; ENERGY CONTENT; WEB SERVER; REGIONS; SEQUENCE; CLASSIFICATION; DEFINITION	Background: A number of proteins contain regions which do not adopt a stable tertiary structure in their native state. Such regions known as disordered regions have been shown to participate in many vital cell functions and are increasingly being examined as drug targets. Results: This work presents a new sequence based approach for the prediction of protein disorder. The method uses boosted ensembles of deep networks to make predictions and participated in the CASP10 experiment. In a 10 fold cross validation procedure on a dataset of 723 proteins, the method achieved an average balanced accuracy of 0.82 and an area under the ROC curve of 0.90. These results are achieved in part by a boosting procedure which is able to steadily increase balanced accuracy and the area under the ROC curve over several rounds. The method also compared competitively when evaluated against a number of state-of-the-art disorder predictors on CASP9 and CASP10 benchmark datasets. Conclusions: DNdisorder is available as a web service at http://iris.rnet.missouri.edu/dndisorder/.	[Eickholt, Jesse; Cheng, Jianlin] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA; [Cheng, Jianlin] Univ Missouri, Inst Informat, Columbia, MO 65211 USA; [Cheng, Jianlin] Univ Missouri, C Bond Life Sci Ctr, Columbia, MO 65211 USA	Cheng, JL (reprint author), Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.	chengji@missouri.edu			NLM fellowship [5T15LM007089-20]; NIH NIGMS grant [R01GM093123]	The work was partially supported by a NLM fellowship to JE (5T15LM007089-20) and a NIH NIGMS grant (R01GM093123) to JC.	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Atchley WR, 2005, P NATL ACAD SCI USA, V102, P6395, DOI 10.1073/pnas.0408677102; Cheng J, 2005, NUCLEIC ACIDS RES, V33, pW72, DOI 10.1093/nar/gki396; Cheng JL, 2005, DATA MIN KNOWL DISC, V11, P213, DOI 10.1007/s10618-005-0001-y; Cheng Y, 2006, TRENDS BIOTECHNOL, V24, P435, DOI 10.1016/j.tibtech.2006.07.005; Deng X, 2012, MOL BIOSYST, V8, P114, DOI 10.1039/c1mb05207a; Deng X, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-436; Dosztanyi Z, 2005, J MOL BIOL, V347, P827, DOI 10.1016/j.jmb.2005.01.071; Dosztanyi Z, 2005, BIOINFORMATICS, V21, P3433, DOI 10.1093/bioinformatics/bti541; Dunker AK, 2002, BIOCHEMISTRY-US, V41, P6573, DOI 10.1021/bi012159+; Dunker AK, 2010, CURR OPIN PHARMACOL, V10, P782, DOI 10.1016/j.coph.2010.09.005; Eickholt J, 2012, BIOINFORMATICS, V28, P3066, DOI 10.1093/bioinformatics/bts598; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Galzitskaya OV, 2006, BIOINFORMATICS, V22, P2948, DOI 10.1093/bioinformatics/btl504; HANLEY JA, 1982, RADIOLOGY, V143, P29; He B, 2009, CELL RES, V19, P929, DOI 10.1038/cr.2009.87; Hecker J, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-S1-S9; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G, 2011, TOP COGN SCI, V3, P74, DOI 10.1111/j.1756-8765.2010.01109.x; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hinton G.E., 2002, NEURAL COMPUT, V14, P30; Ishida T, 2007, NUCLEIC ACIDS RES, V35, pW460, DOI 10.1093/nar/gkm363; Kinch LN, 2011, PROTEINS, V79, P21, DOI 10.1002/prot.23190; Kozlowski LP, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-111; Monastyrskyy B, 2011, PROTEINS, V79, P107, DOI 10.1002/prot.23161; Noivirt-Brik O, 2009, PROTEINS, V77, P210, DOI 10.1002/prot.22586; Obradovic Z, 2005, PROTEINS, V61, P176, DOI 10.1002/prot.20735; Orosz F, 2011, BIOINFORMATICS, V27, P1449, DOI 10.1093/bioinformatics/btr175; Rice P, 2000, TRENDS GENET, V16, P276, DOI 10.1016/S0168-9525(00)02024-2; Schlessinger A, 2007, BIOINFORMATICS, V23, P2376, DOI 10.1093/bioinformatics/btm349; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tompa P, 2002, TRENDS BIOCHEM SCI, V27, P527, DOI 10.1016/S0968-0004(02)02169-2; Tress ML, 2009, PROTEINS, V77, P10, DOI 10.1002/prot.22497; Uversky VN, 2000, PROTEINS, V41, P415, DOI 10.1002/1097-0134(20001115)41:3<415::AID-PROT130>3.0.CO;2-7; Uversky VN, 2002, PROTEIN SCI, V11, P739, DOI 10.1110/ps.4210102; Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430; Walsh I, 2011, NUCLEIC ACIDS RES, V39, pW190, DOI 10.1093/nar/gkr411; Walsh I, 2012, BIOINFORMATICS, V28, P503, DOI 10.1093/bioinformatics/btr682; Ward JJ, 2004, J MOL BIOL, V337, P635, DOI 10.1016/j.jmb.2004.02.002	41	9	9	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAR 6	2013	14								88	10.1186/1471-2105-14-88		10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	109VE	WOS:000316396400001	23497251	
J	Heigold, G; Vanhoucke, V; Senior, A; Nguyen, P; Ranzato, M; Devin, M; Dean, J			IEEE	Heigold, G.; Vanhoucke, V.; Senior, A.; Nguyen, P.; Ranzato, M.; Devin, M.; Dean, J.			MULTILINGUAL ACOUSTIC MODELS USING DISTRIBUTED DEEP NEURAL NETWORKS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Speech recognition; parameter sharing; deep neural networks; multilingual training; distributed neural networks		Today's speech recognition technology is mature enough to be useful for many practical applications. In this context, it is of paramount importance to train accurate acoustic models for many languages within given resource constraints such as data, processing power, and time. Multilingual training has the potential to solve the data issue and close the performance gap between resource-rich and resource-scarce languages. Neural networks lend themselves naturally to parameter sharing across languages, and distributed implementations have made it feasible to train large networks. In this paper, we present experimental results for cross-and multi-lingual network training of eleven Romance languages on 10k hours of data in total. The average relative gains over the monolingual baselines are 4%/2% (data-scarce/data-rich languages) for cross-and 7%/2% for multi-lingual training. However, the additional gain from jointly training the languages on all data comes at an increased training time of roughly four weeks, compared to two weeks (monolingual) and one week (crosslingual).	[Heigold, G.; Vanhoucke, V.; Senior, A.; Nguyen, P.; Ranzato, M.; Devin, M.; Dean, J.] Google Inc, Mountain View, CA 94043 USA	Heigold, G (reprint author), Google Inc, Mountain View, CA 94043 USA.						Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Bottou L., 1991, NEURONIMES; Bourlard H, 2011, SADHANA-ACAD P ENG S, V36, P885, DOI 10.1007/s12046-011-0050-4; Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Ciresan D., 2012, INT JOINT C NEUR NET, P1; Dahl G., 2011, ICASSP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dean J., 2012, ADV NEURAL IN PRESS; Deng L., 2013, ICASSP; Diehl F., 2007, THESIS U POLITECNICA; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang Jui-Ting, 2013, ICASSP; Jaitly N., 2012, INTERSPEECH; Kovac K., 2005, THESIS U TORONTO; Lin H, 2009, INT CONF ACOUST SPEE, P4333, DOI 10.1109/ICASSP.2009.4960588; Plahl C., 2011, ASRU, P371; Qian Y., 2012, INTERSPEECH; Quoc Le, 2012, INT C MACH LEARN, P81; Schalkwyk J., 2010, ADV SPEECH RECOGNITI, P61, DOI 10.1007/978-1-4419-5951-5_4; Schultz T., 1998, DARPA WORKSH BOR NEW, P259; Seide F., 2011, INTERSPEECH, P437; Stolcke A, 2006, INT CONF ACOUST SPEE, P321; Swietojnski P., 2012, WORKSH SPOK LANG TEC; Thomas S., 2012, INTERSPEECH; Thomas S., 2010, INTERSPEECH; Thrun S, 1996, ADV NEUR IN, V8, P640; Vu N., 2012, INTERSPEECH; Zheng J., 2007, INTERSPEECH, P1573	31	9	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							8619	8623				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611508158		
J	Li, CC; Kowdle, A; Saxena, A; Chen, TH				Li, Congcong; Kowdle, Adarsh; Saxena, Ashutosh; Chen, Tsuhan			Toward Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene understanding; classification; machine learning; robotics	FACE DETECTION; EM ALGORITHM; CLASSIFIERS; ENSEMBLES; IMAGE	Scene understanding includes many related subtasks, such as scene categorization, depth estimation, object detection, etc. Each of these subtasks is often notoriously hard, and state-of-the-art classifiers already exist for many of them. These classifiers operate on the same raw image and provide correlated outputs. It is desirable to have an algorithm that can capture such correlation without requiring any changes to the inner workings of any classifier. We propose Feedback Enabled Cascaded Classification Models (FE-CCM), that jointly optimizes all the subtasks while requiring only a "black box" interface to the original classifier for each subtask. We use a two-layer cascade of classifiers, which are repeated instantiations of the original ones, with the output of the first layer fed into the second layer as input. Our training method involves a feedback step that allows later classifiers to provide earlier classifiers information about which error modes to focus on. We show that our method significantly improves performance in all the subtasks in the domain of scene understanding, where we consider depth estimation, scene categorization, event categorization, object detection, geometric labeling, and saliency detection. Our method also improves performance in two robotic applications: an object-grasping robot and an object-finding robot.	[Li, Congcong; Kowdle, Adarsh; Chen, Tsuhan] Cornell Univ, Dept Elect & Comp Engn, Ithaca, NY 14853 USA; [Saxena, Ashutosh] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Li, CC (reprint author), Cornell Univ, Dept Elect & Comp Engn, Ithaca, NY 14853 USA.	cl758@cornell.edu; apk64@cornell.edu; asaxena@cs.cornell.edu; tsuhan@ece.cornell.edu					Achanta R., 2009, P IEEE C COMP VIS PA; Agarwal A., 2005, P IEEE C COMP VIS PA; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Bengio Y., 2007, LARGE SCALE KERNEL M; Blaschko M. B., 2009, P BRIT MACH VIS C; Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Collobert R, 2008, P 25 INT C MACH LEAR; Dalal N., 2005, P IEEE CS C COMP VIS; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Desai C., 2009, P 12 IEEE INT C COMP; Divvala S.K., 2009, P IEEE C COMP VIS PA; Everingham M., 2012, PASCAL VOC2006 RESUL; Everingham M., 2012, PASCAL VISUAL OBJECT; Fei-Fei L., 2005, P IEEE CS C COMP VIS; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb P.F., 2012, DISCRIMINATIVELY TRA; Fink M., 2004, P ADV NEUR INF PROC; Freund Y., 1993, P IEEE INT C AC SPEE; Freund Y, 1995, P 2 EUR C COMP LEARN; Galleguillos C., 2010, P IEEE C COMP VIS PA; Gibbs MN, 2000, IEEE T NEURAL NETWOR, V11, P1458, DOI 10.1109/72.883477; Goodfellow I., 2009, P NEUR INF PROC SYST; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hedau V., 2009, P 12 IEEE INT C COMP; Heitz G., 2008, P EUR C COMP VIS; Heitz G., 2008, P NEUR INF PROC SYST; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D., 2008, P IEEE C COMP VIS PA; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Koppula H., 2011, P NEUR INF PROC SYST; Kowdle A., 2010, P EUR C COMP VIS WOR; Kumar S., 2005, P 10 IEEE INT C COMP; LeCun Y., 1998, NEURAL NETWORKS TRIC; Li C., 2011, P IEEE INT C ROB AUT; Li C., 2011, P ADV NEUR INF PROC; Li C., 2010, P ADV NEUR INF PROC; Li L., 2007, P 11 IEEE INT C COMP; Li L.J., 2009, P IEEE C COMP VIS PA; Lim J.J., 2009, P 12 IEEE INT C COMP; Mairal J., 2008, P 10 EUR C COMP VIS; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Parikh D., 2008, P IEEE C COMP VIS PA; Park D., 2010, P 11 EUR C COMP VIS; Quattoni A., 2004, P NEUR INF PROC SYST; Rabinovich A., 2007, P 11 IEEE INT C COMP; Saxena A., 2007, P 20 INT JOINT C ART; SAXENA A, 2009, IEEE T PATTERN ANAL, V30, P824; Saxena A., 2005, P NEUR INF PROC SYST; Saxena A, 2008, INT J ROBOT RES, V27, P157, DOI 10.1177/0278364907087172; Saxena A., 2006, P NEUR INF PROC SYST; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; Sudderth E., 2006, P IEEE CS C COMP VIS; Sutton C., 2005, P 9 C COMP NAT LANG; Taskar B., 2003, P ADV NEUR INF PROC; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214; Torralba A., 2012, MIT OUTDOOR SCENE DA; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Torralba A., 2005, P ADV NEUR INF PROC; Toshev A., 2010, P IEEE C COMP VIS PA; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; Tu Z., 2008, P IEEE C COMP VIS PA; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Yao B., 2010, P IEEE C COMP VIS PA; Yu C.-N.J., 2009, P 26 ANN INT C MACH; Zeiler M., 2010, P IEEE C COMP VIS PA	68	9	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1394	1408		10.1109/TPAMI.2011.232		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	943PZ	WOS:000304138300011		
J	Larochelle, H; Mandel, M; Pascanu, R; Bengio, Y				Larochelle, Hugo; Mandel, Michael; Pascanu, Razvan; Bengio, Yoshua			Learning Algorithms for the Classification Restricted Boltzmann Machine	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						restricted Boltzmann machine; classification; discriminative learning; generative learning		Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artificial neural networks. In such settings, the RBM only yields a preprocessing or an initialization for some other model, instead of acting as a complete supervised model in its own right. In this paper, we argue that RBMs can provide a self-contained framework for developing competitive classifiers. We study the Classification RBM (ClassRBM), a variant on the RBM adapted to the classification setting. We study different strategies for training the ClassRBM and show that competitive classification performances can be reached when appropriately combining discriminative and generative training objectives. Since training according to the generative objective requires the computation of a generally intractable gradient, we also compare different approaches to estimating this gradient and address the issue of obtaining such a gradient for problems with very high dimensional inputs. Finally, we describe how to adapt the ClassRBM to two special cases of classification problems, namely semi-supervised and multitask learning.	[Larochelle, Hugo] Univ Sherbrooke, Sherbrooke, PQ J1K 2R1, Canada; [Mandel, Michael; Pascanu, Razvan; Bengio, Yoshua] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J8, Canada	Larochelle, H (reprint author), Univ Sherbrooke, 2500 Boul Univ, Sherbrooke, PQ J1K 2R1, Canada.	HUGO.LAROCHELLE@USHERBROOKE.CA; MANDELM@IRO.UMONTREAL.CA; PASCANUR@IRO.UMONTREAL.CA; BENGIOY@IRO.UMONTREAL.CA					Asuncion Arthur, 2010, P 13 INT C ART INT S, P33; Bengio Y., 2006, SEMISUPERVISED LEARN, P193; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; BESAG J, 1975, STATISTICIAN, V24, P179, DOI 10.2307/2987782; Bouchard G., 2004, IASC INT S COMP STAT, P721; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chapelle O., 2006, SEMISUPERVISED LEARN; Cortes Corinna, 2004, ADV NEURAL INFORM PR, V16; DRUCK G, 2007, P KDD, P280, DOI 10.1145/1281192.1281225; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gehler P. V., 2006, P 23 INT C MACH LEAR, P337, DOI 10.1145/1143844.1143887; Gelfand A., 2010, ADV NEURAL INFORM PR, V23, P694; Glorot X., 2011, P 14 INT C ART INT S; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hyvarinen A, 2006, NEURAL COMPUT, V18, P2283, DOI 10.1162/neco.2006.18.10.2283; Lamere P, 2008, J NEW MUSIC RES, V37, P101, DOI 10.1080/09298210802479284; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Liang P., 2008, P 25 INT C MACH LEAR, P584, DOI 10.1145/1390156.1390230; Lindsay BG, 1988, CONT MATH, V80, P221, DOI DOI 10.1090/CONM/080/999014; Louradour Jerome, 2011, P 27 C UNC IN PRESS; Mandel M., 2011, AUTOTAGGING MUSIC CO; Mandel M, 2008, J NEW MUSIC RES, V37, P151, DOI 10.1080/09298210802479300; Mandel Michael I., 2011, ACM T MULTIMEDIA C S, V7S; Mandel Michael I., 2010, P INT S MUS INF RETR, P399; McCallum Andrew, 2006, 21 NAT C ART INT AAA; Memisevic R., 2010, ADV NEURAL INFORM PR, V23, P1603; Mnih A., 2007, P 24 INT C MACH LEAR, P641, DOI 10.1145/1273496.1273577; Mnih Volodymyr, 2011, P 27 C UNC IN PRESS; Ng AY, 2002, ADV NEUR IN, V14, P841; Pearl J, 1988, PROBABILISTIC REASON; Pretti M, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/11/P11008; Salakhutdinov R., 2007, P 2007 WORKSH INF RE; Schifanella R., 2010, P 3 ACM INT C WEB SE, P271, DOI 10.1145/1718487.1718521; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; van der Maaten Laurens, 2011, P 14 INT C ART INT S, V15; Weiss Y., 2001, ADV MEAN FIELD METHO; Welling M., 2005, ADV NEURAL INFORM PR, V17; Welling Max, 2005, P 10 INT WORKSH ART, P397; Welling Max, 2002, P INT C ART NEUR NET, P351; Xing E. P., 2005, P 21 C UNC ART INT U, P633; Yang Jun, 2007, P 7 SIAM INT C DAT M; Zhu X., 2003, P 20 INT C MACH LEAR, V3, P912, DOI DOI 10.1109/18.850663	50	9	10	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2012	13						643	669				27	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	938ZI	WOS:000303772100006		
J	Spratling, MW				Spratling, M. W.			Unsupervised Learning of Generative and Discriminative Weights Encoding Elementary Image Components in a Predictive Coding Model of Cortical Function	NEURAL COMPUTATION			English	Article							PRIMARY VISUAL-CORTEX; CAT STRIATE CORTEX; NONNEGATIVE MATRIX FACTORIZATION; CLASSICAL RECEPTIVE-FIELD; MACAQUE V1 NEURONS; NATURAL IMAGES; SIMPLE CELLS; BAYESIAN-INFERENCE; INDEPENDENT COMPONENTS; SPARSE REPRESENTATIONS	A method is presented for learning the reciprocal feedforward and feedback connections required by the predictive coding model of cortical function. When this method is used, feedforward and feedback connections are learned simultaneously and independently in a biologically plausible manner. The performance of the proposed algorithm is evaluated by applying it to learning the elementary components of artificial and natural images. For artificial images, the bars problem is employed, and the proposed algorithm is shown to produce state-of-the-art performance on this task. For natural images, components resembling Gabor functions are learned in the first processing stage, and neurons responsive to corners are learned in the second processing stage. The properties of these learned representations are in good agreement with neurophysiological data from V1 and V2. The proposed algorithm demonstrates for the first time that a single computational theory can explain the formation of cortical RFs and also the response properties of cortical neurons once those RFs have been learned.	[Spratling, M. W.] Kings Coll London, Dept Informat, London WCR2 2LS, England; [Spratling, M. W.] Kings Coll London, Div Engn, London WCR2 2LS, England	Spratling, MW (reprint author), Kings Coll London, Dept Informat, London WCR2 2LS, England.	michael.spratling@kcl.ac.uk			Engineering and Physical Sciences Research Council [EP/D062225/1]	Thanks to three anonymous referees for insightful comments on earlier drafts of this letter that have led to significant improvements. This work was funded by the Engineering and Physical Sciences Research Council grant number EP/D062225/1.	Adorjan P, 1999, VISUAL NEUROSCI, V16, P303, DOI 10.1017/S0952523899162114; ALBRECHT DG, 1991, VISUAL NEUROSCI, V7, P531; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow H., 1994, LARGE SCALE NEURONAL, P1; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Berkes P, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000495; Busse L, 2009, NEURON, V64, P931, DOI 10.1016/j.neuron.2009.11.004; Callaway EM, 1998, ANNU REV NEUROSCI, V21, P47, DOI 10.1146/annurev.neuro.21.1.47; Carandini M, 2002, J NEUROSCI, V22, P10053; CARANDINI M, 1994, SCIENCE, V264, P1333, DOI 10.1126/science.8191289; CARANDINI M, 2004, COGNITIVE NEUROSCIEN, V3, P313; Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2530, DOI 10.1152/jn.00692.2001; Dagoi V., 2000, J NEUROPHYSIOL, V83, P1019; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DeAngelis GC, 1999, J NEUROSCI, V19, P4046; De Meyer K, 2009, VISION RES, V49, P553, DOI 10.1016/j.visres.2008.12.017; De Meyer K, 2011, NEURAL COMPUT, V23, P1536, DOI 10.1162/NECO_a_00130; Falconbridge MS, 2006, NEURAL COMPUT, V18, P415, DOI 10.1162/089976606775093891; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Freeman TCB, 2002, NEURON, V35, P759, DOI 10.1016/S0896-6273(02)00819-X; Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; Hamker FH, 2007, NETWORK-COMP NEURAL, V18, P249, DOI 10.1080/09548980701661210; Harpur G. F, 1997, THESIS CAMBRIDGE U; Heeger D. J., 1991, COMPUTATIONAL MODELS, P119; HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Houck CR, 1995, 9509 NCSUIE; Hoyer P. O, 2002, P IEEE WORKSH NEUR N, P557; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Hoyer PO, 2003, NEUROCOMPUTING, V52-4, P547, DOI 10.1016/S0925-2312(02)00782-8; Hoyer PO, 2000, NETWORK-COMP NEURAL, V11, P191, DOI 10.1088/0954-898X/11/3/302; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Jarrett K., 2009, P INT C COMP VIS ICC; Jehee JFM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000373; Jones HE, 2001, J NEUROPHYSIOL, V86, P2011; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233; JONES JP, 1987, J NEUROPHYSIOL, V58, P1187; Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005; LeCun Y., 2010, P INT S CIRC SYST IS; Lee DD, 1999, NATURE, V401, P788; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lehky SR, 2005, VISION RES, V45, P57, DOI 10.1016/j.visres.2004.07.021; Lucke J, 2009, NEURAL COMPUT, V21, P2805, DOI 10.1162/neco.2009.07-07-584; Lucke J., 2007, P INT C ART NEUR NET, P657; Lucke J, 2008, J MACH LEARN RES, V9, P1227; Lucke J., 2009, ADV NEURAL INFORM PR, V22; Lucke J, 2004, NEURAL COMPUT, V16, P501, DOI 10.1162/089976604772744893; Malmir M, 2010, CONNECT SCI, V22, P313, DOI 10.1080/09540091.2010.505975; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; Meila M., 2000, J MACHINE LEARNING R, V1, P1, DOI DOI 10.1162/153244301753344605; Mitchell SJ, 2003, NEURON, V38, P433, DOI 10.1016/S0896-6273(03)00200-9; MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477; Nuding U, 2007, BIOSYSTEMS, V89, P273, DOI 10.1016/j.biosystems.2006.04.025; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014; Perrinet LU, 2010, NEURAL COMPUT, V22, P1812, DOI 10.1162/neco.2010.05-08-795; Priebe NJ, 2006, NAT NEUROSCI, V9, P552, DOI 10.1038/nn1660; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rehn M, 2007, J COMPUT NEUROSCI, V22, P135, DOI 10.1007/s10827-006-0003-9; REID RC, 1995, NATURE, V378, P281; Ringach D, 2004, COGNITIVE SCI, V28, P147, DOI 10.1016/j.cogsci.2003.11.003; Ringach DL, 2002, J NEUROPHYSIOL, V88, P455, DOI 10.1152/jn.00881.2001; Ringach DL, 1997, VISION RES, V37, P2455, DOI 10.1016/S0042-6989(96)00247-7; ROLLS ET, 1995, J NEUROPHYSIOL, V73, P713; Rothman JS, 2009, NATURE, V457, P1015, DOI 10.1038/nature07604; Savin C, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000757; Sceniak MP, 1999, NAT NEUROSCI, V2, P733, DOI 10.1038/11197; Schwabe L, 2006, J NEUROSCI, V26, P9117, DOI 10.1523/JNEUROSCI.1253-06.2006; Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; SKOTTUN BC, 1987, J NEUROPHYSIOL, V57, P773; SOMERS DC, 1995, J NEUROSCI, V15, P5448; Spratling MW, 2003, NEUROCOMPUTING, V52-4, P389, DOI 10.1016/S0925-2-112(02)00847-0; Spratling MW, 2002, NEURAL COMPUT, V14, P2157, DOI 10.1162/089976602320264033; Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008; Spratling M W, 2002, Behav Cogn Neurosci Rev, V1, P219, DOI 10.1177/1534582302001003003; Spratling MW, 2011, VISION RES, V51, P563, DOI 10.1016/j.visres.2011.01.017; Spratling MW, 2010, J NEUROSCI, V30, P3531, DOI 10.1523/JNEUROSCI.4911-09.2010; Spratling M.W., 2009, COMPUT INTELL NEUROS, P1; Spratling MW, 2006, J MACH LEARN RES, V7, P793; Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009; SRINIVASAN MV, 1982, PROC R SOC SER B-BIO, V216, P427, DOI 10.1098/rspb.1982.0085; Stetter M, 2000, BIOL CYBERN, V82, P291, DOI 10.1007/s004220050583; Teh Y. W., 2003, J MACHINE LEARNING R, V4, P1235, DOI 10.1162/jmlr.2003.4.7-8.1235; Tolhurst DJ, 2009, J NEUROSCI, V29, P2355, DOI 10.1523/JNEUROSCI.3869-08.2009; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359; Van Hooser SD, 2007, NEUROSCIENTIST, V13, P639, DOI 10.1177/1073858407306597; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; Wainwright M. J., 2001, STAT THEORIES BRAIN, P203; Weber C, 2008, NEURAL COMPUT, V20, P1261, DOI 10.1162/neco.2007.02-07-472; Willmore B, 2001, NETWORK-COMP NEURAL, V12, P255, DOI 10.1088/0954-898X/12/3/302; Wiltschut J, 2009, VISUAL NEUROSCI, V26, P21, DOI 10.1017/S0952523808080966; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002	108	9	9	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JAN	2012	24	1					60	103				44	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	860FI	WOS:000297933800004	22023197	
J	Bengio, Y; Delalleau, O; Simard, C				Bengio, Yoshua; Delalleau, Olivier; Simard, Clarence			DECISION TREES DO NOT GENERALIZE TO NEW VARIATIONS	COMPUTATIONAL INTELLIGENCE			English	Article						decision trees; curse of dimensionality; parity function	NETWORKS	The family of decision tree learning algorithms is among the most widespread and studied. Motivated by the desire to develop learning algorithms that can generalize when learning highly varying functions such as those presumably needed to achieve artificial intelligence, we study some theoretical limitations of decision trees. We demonstrate formally that they can be seriously hurt by the curse of dimensionality in a sense that is a bit different from other nonparametric statistical methods, but most importantly, that they cannot generalize to variations not seen in the training set. This is because a decision tree creates a partition of the input space and needs at least one example in each of the regions associated with a leaf to make a sensible prediction in that region. A better understanding of the fundamental reasons for this limitation suggests that one should use forests or even deeper architectures instead of trees, which provide a form of distributed representation and can generalize to variations not encountered in the training data.	[Bengio, Yoshua; Delalleau, Olivier; Simard, Clarence] Univ Montreal, Dept IRO, Montreal, PQ H3C 3J7, Canada	Delalleau, O (reprint author), Univ Montreal, Dept IRO, CP 6128,Succ Ctr Ville Montreal, Montreal, PQ H3C 3J7, Canada.	delallea@iro.umontreal.ca			CIFAR; NSERC; MITACS; Canada Research Chairs	The authors would like to thank Aaron Courville for precious feedback and discussions. This work was supported by CIFAR, NSERC, MITACS, and Canada Research Chairs.	AJTAI M, 1983, ANN PURE APPL LOGIC, V24, P1, DOI 10.1016/0168-0072(83)90038-6; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2006, NEURAL COMPUT, V18, P2509, DOI 10.1162/neco.2006.18.10.2509; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P115; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cucker F, 1999, J COMPLEXITY, V15, P499, DOI 10.1006/jcom.1999.0519; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); GRIGORIEV D, 1995, ELECT C COMPUTATIONA, V2, P193; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hinton G. E., 1986, P 8 ANN C COGN SCI S, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Ho T., 1995, 3 INT C DOC AN REC M, P278; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hutter M., 2005, UNIVERSAL ARTIFICIAL; Kolmogorov A.N., 1965, Problems of Information Transmission, V1; Kong E.B., 1995, INT C MACH LEARN, P313; LeCun Y., 2004, P COMP VIS PATT REC, V2, pII, DOI 10.1109/CVPR.2004.1315150; Loh WY, 1997, STAT SINICA, V7, P815; PACCANARO A, 2000, INT JOINT C NEUR NET; PEREZ E, 1996, P 13 INT C MACH LEAR, P391; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; SOLOMONOFF RJ, 1964, CONTROL */* INFORM C, V7, P224; Vilalta R, 1997, P 9 EUR C MACH LEARN, P312; Vitanyi P. M. B., 1997, INTRO KOLMOGOROV COM	32	9	9	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935			COMPUT INTELL	Comput. Intell.	NOV	2010	26	4					449	467		10.1111/j.1467-8640.2010.00366.x		19	Computer Science, Artificial Intelligence	Computer Science	676VZ	WOS:000283948100004		
J	Krueger, KA; Dayan, P				Krueger, Kai A.; Dayan, Peter			Flexible shaping: How learning in small steps helps	COGNITION			English	Article						PFC; Gating; Shaping; Sequence learning; Computational modeling	PREFRONTAL CORTEX; COMPUTATIONAL MODEL; WORKING-MEMORY; STARTING SMALL; BASAL GANGLIA; REINFORCEMENT; STIMULUS; EXTINCTION; PREDICTION; SELECTION	Humans and animals can perform much more complex tasks than they can acquire using pure trial and error learning. This gap is filled by teaching. One important method of instruction is shaping, in which a teacher decomposes a complete task into sub-components, thereby providing an easier path to learning. Despite its importance, shaping has not been substantially studied in the context of computational modeling of cognitive learning. Here we study the shaping of a hierarchical working memory task using an abstract neural network model as the target learner. Shaping significantly boosts the speed of acquisition of the task compared with conventional training, to a degree that increases with the temporal complexity of the task. Further, it leads to internal representations that are more robust to task manipulations such as reversals. We use the model to investigate some of the elements of successful shaping. (C) 2008 Elsevier B.V. All rights reserved	[Krueger, Kai A.; Dayan, Peter] UCL, Gatsby Computat Neurosci Unit, London WC1N 3AR, England	Krueger, KA (reprint author), UCL, Gatsby Computat Neurosci Unit, 17 Queen Sq, London WC1N 3AR, England.	kai.krueger@ucl.ac.uk					Badre D, 2005, NEURON, V47, P907, DOI 10.1016/j.neuron.2005.07.023; BAKKER B, 2004, P 8 C INT AUT SYST, V8, P438; Barto A., 2003, DISCRETE EVENT DYN S, V13, P341, DOI [DOI 10.1023/A:1025696116075, 10.1023/A:1025696116075)00052-1]; BRELAND K, 1961, AM PSYCHOL, V16, P681, DOI 10.1037/h0040090; Brown SL, 2005, NAT NEUROSCI, V8, P1568, DOI 10.1038/nn1559; BUTTER CM, 1969, PHYSIOL BEHAV, V4, P163, DOI 10.1016/0031-9384(69)90075-4; Dahlin E, 2008, SCIENCE, V320, P1510, DOI 10.1126/science.1155466; Dayan P, 2006, NETWORK-COMP NEURAL, V17, P335, DOI 10.1080/09548980601004024; Dayan P, 2006, NEURAL COMPUT, V18, P2293, DOI 10.1162/neco.2006.18.10.2293; Dayan P., 1989, THESIS CAMBRIDGE UK; Dorigo M, 1998, ROBOT SHAPING EXPT B; DUNCAN J, 1995, NEW COGNITIVE NEUROS, P721; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; FRANK MJ, 2001, INTERACTIONS FRONTAL; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Gilbert SJ, 2005, EUR J NEUROSCI, V21, P1423, DOI 10.1111/j.1460-9568.2005.03981.x; GROSSBERG S, 1980, PSYCHOL REV, V87, P1; Haruno M, 2001, NEURAL COMPUT, V13, P2201, DOI 10.1162/089976601750541778; Hazy TE, 2007, PHILOS T R SOC B, V362, P1601, DOI 10.1098/rstb.2007.2055; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; IVERSEN SD, 1970, EXP BRAIN RES, V11, P376; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JONES B, 1972, EXP NEUROL, V36, P362, DOI 10.1016/0014-4886(72)90030-1; Koechlin E, 2003, SCIENCE, V302, P1181, DOI 10.1126/science.1088545; Koechlin E, 2007, TRENDS COGN SCI, V11, P229, DOI 10.1016/j.tics.2007.04.005; McGovern A, 2001, P 18 INT C MACH LEAR, P361; Mcnab F, 2008, NAT NEUROSCI, V11, P103, DOI 10.1038/nn2024; NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1207/s15516709cog1401_2; Newport Elissa L., 1988, LANG SCI, V10, P147, DOI DOI 10.1016/0388-0001(88)90010-1; O'Reilly RC, 2006, NEURAL COMPUT, V18, P283, DOI 10.1162/089976606775093909; Parr R., 1997, ADV NEURAL INFORM PR; Peterson GB, 2004, J EXP ANAL BEHAV, V82, P317, DOI 10.1901/jeab.2004.82-317; PREMACK D, 1983, BEHAV BRAIN SCI, V6, P125; Redish AD, 2007, PSYCHOL REV, V114, P784, DOI 10.1037/0033-295X.114.3.784; REYNOLDS J, 2007, NIPS WORKSH HI UNPUB; Reynolds JR, 2007, COGNITIVE SCI, V31, P613, DOI 10.1080/15326900701399913; Rohde DLT, 1999, COGNITION, V72, P67, DOI 10.1016/S0010-0277(99)00031-1; Saksida LM, 1997, ROBOT AUTON SYST, V22, P231, DOI 10.1016/S0921-8890(97)00041-9; Savage T, 1998, CONNECT SCI, V10, P321, DOI 10.1080/095400998116477; Savage T, 2001, CONNECT SCI, V13, P199, DOI 10.1080/09540090110096196; SHALLICE T, 1991, BRAIN, V114, P727, DOI 10.1093/brain/114.2.727; Sheffield F. D., 1965, CLASSICAL CONDITION, P302; SINGH SP, 1992, MACH LEARN, V8, P323, DOI 10.1007/BF00992700; Skinner B.F., 1938, BEHAV ORGANISMS EXPT; Sowell ER, 1999, NAT NEUROSCI, V2, P859, DOI 10.1038/13154; Thompson RKR, 1997, J EXP PSYCHOL ANIM B, V23, P31, DOI 10.1037/0097-7403.23.1.31; WILLIAMS DR, 1969, J EXP ANAL BEHAV, V12, P511, DOI 10.1901/jeab.1969.12-511; Yu AJ, 2005, NEURON, V46, P681, DOI 10.1016/j.neuron.2005.04.026; Zacks JM, 2007, PSYCHOL BULL, V133, P273, DOI 10.1037/0033-2909.133.2.273	51	9	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0010-0277			COGNITION	Cognition	MAR	2009	110	3					380	394		10.1016/j.cognition.2008.11.014		15	Psychology, Experimental	Psychology	416XX	WOS:000264039900005	19121518	
S	Zhu, L; Lin, CX; Huang, HD; Chen, YH; Yuille, A		Forsyth, D; Torr, P; Zisserman, A		Zhu, Long (Leo); Lin, Chenxi; Huang, Haoda; Chen, Yuanhao; Yuille, Alan			Unsupervised Structure Learning: Hierarchical Recursive Composition, Suspicious Coincidence and Competitive Exclusion	COMPUTER VISION - ECCV 2008, PT II, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	10th European Conference on Computer Vision (ECCV 2008)	OCT 12-18, 2008	Marseille, FRANCE	INRIA, Ville Marseille, Reg Province Alpes-Cote Azur, Deutsch Telekom Lab, Microsoft Res, Orange, INRIA, Microsoft Res, EADS, TOSHIBA, Springer				We describe a new method for unsupervised structure learning of a hierarchical compositional model (HCM) for deformable objects. The learning is unsupervised in the sense that we are given a training dataset of images containing the object in cluttered backgrounds but we do not know the position or boundary of the object. The structure learning is performed by a bottom-up and top-down process. The bottom-up process is a novel form of hierarchical clustering which recursively composes proposals for simple structures to generate proposals for more complex structures. We combine standard clustering with the suspicious coincidence principle and the competitive exclusion principle to prune the number of proposals to a practical number and avoid an exponential explosion of possible structures. The hierarchical clustering stops automatically, when it fails to generate new proposals, and outputs a proposal for the object model. The top-down process validates the proposals and fills in missing elements. We tested our approach by using it to learn a hierarchical compositional model for parsing and segmenting horses on Weizmann dataset. We show that the resulting model is comparable with (or better than) alternative methods. The versatility of our approach is demonstrated by learning models for other objects (e.g., faces, pianos, butterflies, monitors, etc.). It is worth noting that the low-levels of the object hierarchies automatically learn generic image features while the higher levels learn object specific features.	[Zhu, Long (Leo); Yuille, Alan] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Zhu, L (reprint author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.						Ahuja N., 2007, ICCV; Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Borestein E., 2006, CVPR, P969; Chen Y., 2007, NIPS; Cour T., 2007, CVPR; Epshtein B, 2005, IEEE I CONF COMP VIS, P220; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; FERGUS R, 2003, CVPR, P264; Fidler S., 2007, CVPR; Fleuret F., 2001, IJCV; Freeman William T., 2005, LABELME DATABASE WEB; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jin Y., 2006, CVPR, P2145; KUMAR MP, 2005, CVPR, P18; Levin A, 2006, LECT NOTES COMPUT SC, V3954, P581; Ren X., 2005, NIPS; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; SERRE T, 2005, CVPR, P994; Winn J, 2005, IEEE I CONF COMP VIS, P756; ZHU L, 2006, NIPS, P1617	21	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88685-3	LECT NOTES COMPUT SC			2008	5303						759	773				15	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIM01	WOS:000260658500056		
J	Tamilselvan, P; Wang, PF				Tamilselvan, Prasanna; Wang, Pingfeng			Failure diagnosis using deep belief learning based health state classification	RELIABILITY ENGINEERING & SYSTEM SAFETY			English	Article						Fault diagnosis; Artificial intelligence in diagnosis; Classification; Deep belief networks	CONDITION-BASED MAINTENANCE; ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; SELF-ORGANIZING MAP; FAULT-DIAGNOSIS; DETERIORATING SYSTEMS; POWER TRANSFORMERS; GENETIC ALGORITHMS; IN-SERVICE; OPTIMIZATION	Effective health diagnosis provides multifarious benefits such as improved safety, improved reliability and reduced costs for operation and maintenance of complex engineered systems. This paper presents a novel multi-sensor health diagnosis method using deep belief network (DBN). DBN has recently become a popular approach in machine learning for its promised advantages such as fast inference and the ability to encode richer and higher order network structures. The DBN employs a hierarchical structure with multiple stacked restricted Boltzmann machines and works through a layer by layer successive learning process. The proposed multi-sensor health diagnosis methodology using DBN based state classification can be structured in three consecutive stages: first, defining health states and preprocessing sensory data for DBN training and testing; second, developing DBN based classification models for diagnosis of predefined health states; third, validating DBN classification models with testing sensory dataset. Health diagnosis using DBN based health state classification technique is compared with four existing diagnosis techniques. Benchmark classification problems and two engineering health diagnosis applications: aircraft engine health diagnosis and electric power transformer health diagnosis are employed to demonstrate the efficacy of the proposed approach. (C) 2013 Elsevier Ltd. All rights reserved.	[Tamilselvan, Prasanna; Wang, Pingfeng] Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA	Wang, PF (reprint author), Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA.	pxtamilselvan@wichita.edu; pingfeng.wang@wichita.edu	Wang, Pingfeng/D-3764-2011	Wang, Pingfeng/0000-0002-2160-4917	National Science Foundation through award CMMI [1200597]; Wichita State University through the University Research Creative Project Awards (UCRA)	This research is partially supported by National Science Foundation through award CMMI#1200597 and Wichita State University through the University Research Creative Project Awards (UCRA).	Abbasion S, 2007, MECH SYST SIGNAL PR, V21, P2933, DOI 10.1016/j.ymssp.2007.02.003; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; ALGUINDIGUE IE, 1993, IEEE T IND ELECTRON, V40, P209, DOI 10.1109/41.222642; ALLAN D, 1992, IEEE T ELECTR INSUL, V27, P578, DOI 10.1109/14.142722; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Baraldi P, 2011, RELIAB ENG SYST SAFE, V96, P480, DOI 10.1016/j.ress.2010.11.005; Barata J, 2002, RELIAB ENG SYST SAFE, V76, P255, DOI 10.1016/S0951-8320(02)00017-0; Bengio Y, P ADV NEUR INF PROC, P18; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Booth C, 1998, NEUROCOMPUTING, V23, P97, DOI 10.1016/S0925-2312(98)00064-2; Breikin T., 2005, P 16 IFAC WORLD C; Cadini F, 2009, RELIAB ENG SYST SAFE, V94, P752, DOI 10.1016/j.ress.2008.08.003; Cao P, 2005, P 8 INT S SIGN PROC; Cheng SF, 2012, IEEE T DEVICE MAT RE, V12, P420, DOI 10.1109/TDMR.2011.2170689; Cheng SF, 2012, EXPERT SYST APPL, V39, P8467, DOI 10.1016/j.eswa.2012.01.172; Coit DW, 2000, IIE TRANS, V32, P1161, DOI 10.1080/07408170008967470; Dekker R, 1996, RELIAB ENG SYST SAFE, V51, P229, DOI 10.1016/0951-8320(95)00076-3; Ebeling C. E., 1997, INTRO RELIABILITY MA; Elsayed EA, 2000, INT J PROD RES, V38, P1953, DOI 10.1080/002075400188438; Fisher RA, 1936, ANN EUGENIC, V7, P179; Forina M., 1988, PARVUS EXTENDABLE PA; Gebraeel N., 2002, INTELLIGENT ENG SYST, V12, P543; Geramifard O., 2010, P IEEE INT C CONTR A, P1618; Grall A, 2002, RELIAB ENG SYST SAFE, V76, P167, DOI 10.1016/S0951-8320(01)00148-X; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu C., 2010, ANN C PROGN HLTH MAN; Huang RQ, 2007, MECH SYST SIGNAL PR, V21, P193, DOI 10.1016/j.ymssp.2005.11.008; Khomfoi S, 2007, IEEE T POWER ELECTR, V22, P1062, DOI 10.1109/TPEL.2007.897128; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Leibfried T, 1998, IEEE COMPUT APPL POW, V11, P36, DOI 10.1109/67.694934; Li Y, 1999, TRIBOL T, V42, P385, DOI 10.1080/10402009908982232; Licht T., 2003, AM SOC MECH ENG DYN, V71, P1059; Macian V, 2003, TRIBOL INT, V36, P771, DOI 10.1016/S0301-679X(03)00060-4; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Marseguerra M, 2002, RELIAB ENG SYST SAFE, V77, P151, DOI 10.1016/S0951-8320(02)00043-1; MARTIN KF, 1994, INT J MACH TOOL MANU, V34, P527, DOI 10.1016/0890-6955(94)90083-3; Myotyri E, 2006, RELIAB ENG SYST SAFE, V91, P200, DOI 10.1016/j.ress.2005.01.002; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Niu G, 2010, RELIAB ENG SYST SAFE, V95, P786, DOI 10.1016/j.ress.2010.02.016; Pecht M., 2008, PROGNOSTICS HLTH MAN; Rivera HL, 2000, IEEE J SEL TOP QUANT, V6, P788, DOI 10.1109/2944.892619; Saimurugan M, 2011, EXPERT SYST APPL, V38, P3819, DOI 10.1016/j.eswa.2010.09.042; Samanta B, 2004, MECH SYST SIGNAL PR, V18, P625, DOI 10.1016/S0888-3270(03)00020-7; Saxena A., 2008, P INT C PROGN HLTH M; Smidt-Destombes KS, 2004, RELIAB ENG SYST SAFE, V83, P287; Tinga T, 2010, RELIAB ENG SYST SAFE, V95, P1061, DOI 10.1016/j.ress.2010.04.015; van der Weide JAM, 2010, RELIAB ENG SYST SAFE, V95, P236, DOI 10.1016/j.ress.2009.10.004; Wang P., 2010, ANN C PROGN HLTH MAN; Wang TY, 2008, 2008 INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (PHM), P53, DOI 10.1109/PHM.2008.4711421; Weston J, 1998, MULTICLASS SUPPORT V; Widodo A, 2007, MECH SYST SIGNAL PR, V21, P2560, DOI 10.1016/j.ymssp.2006.12.007; Wong MLD, 2006, MECH SYST SIGNAL PR, V20, P593, DOI 10.1016/j.ymssp.2005.01.008; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Zhang L, 2010, EXPERT SYST APPL, V37, P6077, DOI 10.1016/j.eswa.2010.02.118; Zio E, 2010, RELIAB ENG SYST SAFE, V95, P49, DOI 10.1016/j.ress.2009.08.001; Zio E, 2009, RELIAB ENG SYST SAFE, V94, P125, DOI 10.1016/j.ress.2008.06.002	58	8	9	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0951-8320	1879-0836		RELIAB ENG SYST SAFE	Reliab. Eng. Syst. Saf.	JUL	2013	115						124	135		10.1016/j.ress.2013.02.022		12	Engineering, Industrial; Operations Research & Management Science	Engineering; Operations Research & Management Science	133IT	WOS:000318132800012		
J	O'Connor, P; Neil, D; Liu, SC; Delbruck, T; Pfeiffer, M				O'Connor, Peter; Neil, Daniel; Liu, Shih-Chii; Delbruck, Tobi; Pfeiffer, Michael			Real-time classification and sensor fusion with a spiking deep belief network	FRONTIERS IN NEUROSCIENCE			English	Article						deep belief networks; spiking neural network; silicon retina; sensory fusion; silicon cochlea; deep learning; generative model	VISUAL-CORTEX; NEURAL-NETWORKS; AREA 17; RECOGNITION; VISION; FEEDFORWARD; INTEGRATION; PERCEPTION; NEURONS; MACAQUE	Deep Belief Networks (DBNs) have recently shown impressive performance on a broad range of classification problems. Their generative properties allow better understanding of the performance, and provide a simpler solution for sensor fusion tasks. However, because of their inherent need for feedback and parallel update of large numbers of units, DBNs are expensive to implement on serial computers. This paper proposes a method based on the Siegert approximation for Integrate-and-Fire neurons to map an offline-trained DBN onto an efficient event-driven spiking neural network suitable for hardware implementation. The method is demonstrated in simulation and by a real-time implementation of a 3-layer network with 2694 neurons used for visual classification of MNIST handwritten digits with input from a 128 x 128 Dynamic Vision Sensor (DVS) silicon retina, and sensory-fusion using additional input from a 64-channel AER-EAR silicon cochlea. The system is implemented through the open-source software in the jAER project and runs in real-time on a laptop computer. It is demonstrated that the system can recognize digits in the presence of distractions, noise, scaling, translation and rotation, and that the degradation of recognition performance by using an event-based approach is less than 1%. Recognition is achieved in an average of 5.8 ms after the onset of the presentation of a digit. By cue integration from both silicon retina and cochlea outputs we show that the system can be biased to select the correct digit from otherwise ambiguous input.	[Pfeiffer, Michael] Univ Zurich, Inst Neuroinformat, CH-8057 Zurich, Switzerland; ETH, CH-8057 Zurich, Switzerland	Pfeiffer, M (reprint author), Univ Zurich, Inst Neuroinformat, Winterthurerstr 190, CH-8057 Zurich, Switzerland.	pfeiffer@ini.phys.ethz.ch			FP7 SeeBetter [FP7-ICT-2009-6]; Swiss National Foundation EARS [200021_126844]; Samsung Advanced Institute of Technology; University of Zurich	This project was partially supported by the FP7 SeeBetter (FP7-ICT-2009-6), Swiss National Foundation EARS (200021_126844), and the Samsung Advanced Institute of Technology. Michael Pfeiffer has been supported by a Forschungskredit grant of the University of Zurich. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Acero A, 2008, INT CONF ACOUST SPEE, P5256, DOI 10.1109/ICASSP.2008.4518845; Bengio Y., 2006, ADV NEURAL INFORM PR, V19; Bullier J, 2001, BRAIN RES REV, V36, P96, DOI 10.1016/S0165-0173(01)00085-6; Busing L., 2011, PLOS COMPUT BIOL, V7, DOI [10.1371/journal.pcbi.1002211, DOI 10.1371/JOURNAL.PCBI.1002211]; Camunas Mesa L., 2010, PROC IEEE INT S CIRC, P249; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Da Costa NM, 2009, J COMP NEUROL, V516, P264, DOI 10.1002/cne.22133; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DESIMONE R, 1984, J NEUROSCI, V4, P2051; Douglas RJ, 2011, NEUROINFORMATICS, V9, P167, DOI 10.1007/s12021-011-9106-1; Erhan D, 2010, J MACH LEARN RES, V11, P625; Falchier A, 2002, J NEUROSCI, V22, P5749; Farabet C, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00032; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Friston KJ, 2010, NAT REV NEUROSCI, V11, P607, DOI 10.1038/nrn2787-c2; Gerstner W., 2002, SPIKING NEURON MODEL, DOI [10.1017/CBO9780511815706, DOI 10.1017/CBO9780511815706]; Goh H., 2010, NIPS WORKSH DEEP LEA; GROSS CG, 1972, J NEUROPHYSIOL, V35, P96; Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276; Hawkins J., 2004, INTELLIGENCE; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 1986, LEARNING RELEARNING, V1, P282; Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI DOI 10.1109/9780470544037.CH14; Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7; Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073; Jug F., 2012, INT JOINT C NEUR NET, P1; Kayser C, 2007, BRAIN STRUCT FUNCT, V212, P121, DOI 10.1007/s00429-007-0154-0; Kersten D, 2003, CURR OPIN NEUROBIOL, V13, P150, DOI 10.1016/S0959-4388(03)00042-4; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Kosslyn SM, 1999, SCIENCE, V284, P167, DOI 10.1126/science.284.5411.167; Lamme VAF, 1998, CURR OPIN NEUROBIOL, V8, P529, DOI 10.1016/S0959-4388(98)80042-1; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; Le Q. V., 2012, P ICML ED; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; LIU SC, 2010, P IEEE INT S CIRC SY, P2027, DOI 10.1109/ISCAS.2010.5537164; Markov NT, 2014, CEREB CORTEX, V24, P17, DOI 10.1093/cercor/bhs270; Markov NT, 2013, CURR OPIN NEUROBIOL, V23, P187, DOI 10.1016/j.conb.2012.12.008; Merolla P., 2010, ARXIV10095473; MIT Technology Review, 2013, 10 BREAK TECHN 2013; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Murray SO, 2002, P NATL ACAD SCI USA, V99, P15164, DOI 10.1073/pnas.192579399; Nair V., 2010, P 27 INT C MACH LEAR, P807; Nessler B, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003037; Perez-Carrasco JA, 2013, IEEE T PATTERN ANAL, V35, P2706, DOI 10.1109/TPAMI.2013.71; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Seide F., 2011, P INTERSPEECH, P437; SIEGERT AJF, 1951, PHYS REV, V81, P617, DOI 10.1103/PhysRev.81.617; Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; VANESSEN DC, 1983, TRENDS NEUROSCI, V6, P370, DOI 10.1016/0166-2236(83)90167-4	58	8	8	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-453X			FRONT NEUROSCI-SWITZ	Front. Neurosci.		2013	7								178	10.3389/fnins.2013.00178		13	Neurosciences	Neurosciences & Neurology	AW9HF	WOS:000346567300176	24115919	
J	Dura-Bernal, S; Wennekers, T; Denham, SL				Dura-Bernal, Salvador; Wennekers, Thomas; Denham, Susan L.			Top-Down Feedback in an HMAX-Like Cortical Model of Object Perception Based on Hierarchical Bayesian Networks and Belief Propagation	PLOS ONE			English	Article							EARLY VISUAL-CORTEX; ILLUSORY CONTOURS; CAUSAL INDEPENDENCE; PATTERN-RECOGNITION; RECEPTIVE-FIELDS; SPIKING NEURONS; INFERENCE; ACTIVATION; VISION; AREAS	Hierarchical generative models, such as Bayesian networks, and belief propagation have been shown to provide a theoretical framework that can account for perceptual processes, including feedforward recognition and feedback modulation. The framework explains both psychophysical and physiological experimental data and maps well onto the hierarchical distributed cortical anatomy. However, the complexity required to model cortical processes makes inference, even using approximate methods, very computationally expensive. Thus, existing object perception models based on this approach are typically limited to tree-structured networks with no loops, use small toy examples or fail to account for certain perceptual aspects such as invariance to transformations or feedback reconstruction. In this study we develop a Bayesian network with an architecture similar to that of HMAX, a biologically-inspired hierarchical model of object recognition, and use loopy belief propagation to approximate the model operations (selectivity and invariance). Crucially, the resulting Bayesian network extends the functionality of HMAX by including top-down recursive feedback. Thus, the proposed model not only achieves successful feedforward recognition invariant to noise, occlusions, and changes in position and size, but is also able to reproduce modulatory effects such as illusory contour completion and attention. Our novel and rigorous methodology covers key aspects such as learning using a layerwise greedy algorithm, combining feedback information from multiple parents and reducing the number of operations required. Overall, this work extends an established model of object recognition to include high-level feedback modulation, based on state-of-the-art probabilistic approaches. The methodology employed, consistent with evidence from the visual cortex, can be potentially generalized to build models of hierarchical perceptual organization that include top-down and bottom-up interactions, for example, in other sensory modalities.	[Dura-Bernal, Salvador] Suny Downstate Med Ctr, Dept Physiol & Pharmacol, Brooklyn, NY 11203 USA; [Wennekers, Thomas; Denham, Susan L.] Univ Plymouth, Cognit Inst, Plymouth PL4 8AA, Devon, England	Dura-Bernal, S (reprint author), Suny Downstate Med Ctr, Dept Physiol & Pharmacol, Brooklyn, NY 11203 USA.	salvadordura@gmail.com			European Community [231168-SCANDLE]	This research was supported by the European Community's Seventh Framework Programme, grant no. 231168-SCANDLE:"acoustic SCene ANalysis for Detecting Living Entities" (http://www.scandle.eu). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Bishop C.M., 1995, NEURAL NETWORKS PATT; Bradley P. S., 1998, REFINING INITIAL POI, P91; Bullier J, 2001, BRAIN RES REV, V36, P96, DOI 10.1016/S0165-0173(01)00085-6; Cadieu C, 2007, J NEUROPHYSIOL, V98, P1733, DOI 10.1152/jn.01265.2006; Chen SY, 2011, MATH PROBL ENG, V12; Chikkerur S, 2009, 278 MA CBCL MIT; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Das B., 2004, CSAI0411034 CORR; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; Diez FJ, 1993, P 9 ANN C UNC ART IN, P99; DiMaio F, 2006, 061 U WISC DEP COMP; Dura-Bernal S, 2011, 45 INT C INF SCI SYS, P1; Elidan G., 2006, P 22 C UNC AI; Epshtein B, 2008, P NATL ACAD SCI USA, V105, P14298, DOI 10.1073/pnas.0800968105; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Fox C, 2010, LECT NOTES COMPUT SC, V6352, P388, DOI 10.1007/978-3-642-15819-3_52; Friston KJ, 2009, NEURAL NETWORKS, V22, P1093, DOI 10.1016/j.neunet.2009.07.023; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; Fukushima K, 2005, NEURAL NETWORKS, V18, P33, DOI 10.1016/j.neunet.2004.05.001; George D, 2005, IEEE IJCNN, P1812; George D, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000532; Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057; Gilbert CD, 2007, NEURON, V54, P677, DOI 10.1016/j.neuron.2007.05.019; Grossberg S, 2007, PROG BRAIN RES, V165, P79, DOI 10.1016/S0079-6123(06)65006-1; Halgren E, 2003, NEUROIMAGE, V18, P1001, DOI 10.1016/S1053-8119(03)00045-4; Halko MA, 2008, J VISION, V8, DOI 10.1167/8.11.17; Hastie T., 2003, ELEMENTS STAT LEARNI; Heckerman D, 1996, IEEE T SYST MAN CY A, V26, P826, DOI 10.1109/3468.541341; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7; Huang JY, 2007, BRAIN RES, V1138, P111, DOI 10.1016/j.brainres.2006.12.081; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; Knill D.C, 1996, PERCEPTION BAYESIAN; Kording KP, 2004, NATURE, V427, P244, DOI 10.1038/nature02169; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lecun Y., 2004, P CVPR 04; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 2001, P NATL ACAD SCI USA, V98, P1907, DOI 10.1073/pnas.031579998; Lee TS, 2003, J PHYSIOLOGY-PARIS, V97, P121, DOI 10.1016/j.jphysparis.2003.09.015; Lengyel M, 2007, ADV NEURAL INFORM PR, V19, P833; Lewicki MS, 1997, ADV NEUR IN, V9, P529; Liang CK, 2011, IEEE T CIRC SYST VID, V21, P525, DOI 10.1109/TCSVT.2011.2125570; Litvak S, 2009, NEURAL COMPUT, V21, P3010, DOI 10.1162/neco.2009.05-08-783; Maertens M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.002.2008; Maltoni D., 2011, PATTERN RECOGNITION; Masquelier T, 2010, IEEE IJCNN, DOI 10.1109/IJCNN.2010.5596934; Murphy K.P., 1999, P 15 ANN C UNC ART I, V1747, P467; Murray JF, 2007, NEURAL COMPUT, V19, P2301, DOI 10.1162/neco.2007.19.9.2301; Murray MM, 2002, J NEUROSCI, V22, P5055; Murray SO, 2004, NEURAL NETWORKS, V17, P695, DOI 10.1016/j.neunet.2004.03.010; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639; Pearl J, 1988, PROBABILISTIC REASON; Pecevski D, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002294; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 2006, BAYESIAN BRAIN PROBA, P239; Reddy L, 2010, NEUROIMAGE, V50, P818, DOI 10.1016/j.neuroimage.2009.11.084; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Sary G, 2008, EUR J NEUROSCI, V28, P2137, DOI 10.1111/j.1460-9568.2008.06499.x; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Serre T, 2004, 239AI MA CBCL MIT; Singla P, 2010, AAAI WORKSH STAT REL, P92; Slotnick SD, 2005, CEREB CORTEX, V15, P1570, DOI 10.1093/cercor/bhi035; Stanley DA, 2003, NEURON, V37, P323, DOI 10.1016/S0896-6273(02)01148-0; Steimer A, 2009, NEURAL COMPUT, V21, P2502, DOI 10.1162/neco.2009.08-08-837; Summerfield C, 2009, TRENDS COGN SCI, V13, P403, DOI 10.1016/j.tics.2009.06.003; Sutton C., 2007, C UNC ART INT UAI; Walther DB, 2007, PROG BRAIN RES, V165, P57, DOI 10.1016/S0079-6123(06)65005-X; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Williams MA, 2008, NAT NEUROSCI, V11, P1439, DOI 10.1038/nn.2218; Yedidia J. S., 2003, EXPLORING ARTIFICIAL, P239; Yoshino A, 2006, BRAIN RES, V1071, P137, DOI 10.1016/j.brainres.2005.11.089; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002; Zagorecki A, 2006, 3 EUR WORKSH PROB GR, P325; Zhang NL, 1996, J ARTIF INTELL RES, V5, P301	82	8	8	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	NOV 5	2012	7	11							e48216	10.1371/journal.pone.0048216		25	Multidisciplinary Sciences	Science & Technology - Other Topics	032TG	WOS:000310741400042	23139765	
J	Weng, JY				Weng, Juyang			Symbolic Models and Emergent Models: A Review	IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT			English	Review						Agents; attention; brain architecture; complexity; computer vision; emergent representation; graphic models; mental architecture; neural networks; reasoning; regression; robotics; speech recognition; symbolic representation; text understanding	AUTONOMOUS MENTAL-DEVELOPMENT; HIERARCHICAL DISCRIMINANT REGRESSION; ORGANIZING NEURAL NETWORK; PRIMARY VISUAL-CORTEX; TOP-DOWN CONNECTIONS; HIDDEN MARKOV-MODELS; CAT STRIATE CORTEX; OBJECT RECOGNITION; HORIZONTAL CONNECTIONS; AFFERENT CONNECTIVITY	There exists a large conceptual gap between symbolic models and emergent models for the mind. Many emergent models work on low-level sensory data, while many symbolic models deal with high-level abstract (i.e., action) symbols. There has been relatively little study on intermediate representations, mainly because of a lack of knowledge about how representations fully autonomously emerge inside the closed brain skull, using information from the exposed two ends (the sensory end and the motor end). As reviewed here, this situation is changing. A fundamental challenge for emergent models is abstraction, which symbolic models enjoy through human handcrafting. The term abstract refers to properties disassociated with any particular form. Emergent abstraction seems possible, although the brain appears to never receive a computer symbol (e.g., ASCII code) or produce such a symbol. This paper reviews major agent models with an emphasis on representation. It suggests two different ways to relate symbolic representations with emergent representations: One is based on their categorical definitions. The other considers that a symbolic representation corresponds to a brain's outside behaviors observed and handcrafted by other outside human observers; but an emergent representation is inside the brain.	[Weng, Juyang] Michigan State Univ, Dept Comp Sci & Engn, Cognit Sci Program, E Lansing, MI 48824 USA; [Weng, Juyang] Michigan State Univ, Neurosci Program, E Lansing, MI 48824 USA	Weng, JY (reprint author), Michigan State Univ, Dept Comp Sci & Engn, Cognit Sci Program, E Lansing, MI 48824 USA.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Albus JS, 2010, INFORM SCIENCES, V180, P1519, DOI 10.1016/j.ins.2009.12.031; Alexander I. R., 1994, COMMUN ACM, V37, P52; Allport A., 1993, ATTENTION PERFORM, P111; Almassy N, 1998, CEREB CORTEX, V8, P346, DOI 10.1093/cercor/8.4.346; Aloimonos Y., 1992, COMPUT VIS GRAPHICS, V17, P285; Anderson J., 1993, RULES OF THE MIND; Anderson J.R., 2004, PSYCHOL REV, V111, P036, DOI DOI 10.1037/0033-295X.111.4.1036; ARKIN R.C, 1998, BEHAV BASED ROBOTICS; Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702; Ballard D.A., 1982, COMPUTER VISION; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; Balthazart J, 2006, TRENDS NEUROSCI, V29, P241, DOI 10.1016/j.tins.2006.03.004; Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639; Bartoli A., 2004, P 3 INT C DEV LEARN, P1; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bellman R., 1957, DYNAMIC PROGRAMMING; Bi GQ, 2001, ANNU REV NEUROSCI, V24, P139, DOI 10.1146/annurev.neuro.24.1.139; BLAKEMOR.C, 1970, NATURE, V228, P477, DOI 10.1038/228477a0; Bobick A. F., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466914; BONHOEFFER T, 1991, NATURE, V353, P429, DOI 10.1038/353429a0; Breazeal C., 2000, P IEEE INT C HUM ROB; Breazeal C, 2000, ADAPT BEHAV, V8, P49, DOI 10.1177/105971230000800104; Brooks R., 1991, P 12 INT JOINT C ART, P569; Brooks R, 1986, ROBOTICS AUTOMATION, V2, P14, DOI DOI 10.1109/JRA.1986.1087032; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; Buschman TJ, 2007, SCIENCE, V315, P1860, DOI 10.1126/science.1138071; Callaway EM, 2004, NEURAL NETWORKS, V17, P625, DOI 10.1016/j.neunet.2004.04.004; CALLAWAY EM, 1991, P NATL ACAD SCI USA, V88, P745, DOI 10.1073/pnas.88.3.745; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CHEESEMAN P, 1986, INT J ROBOTICS, V5, P56; Cherkassky V., 1998, LEARNING DATA CONCEP; Cho B., 1993, SOAR PAPERS, P1199; Christianini N., 2000, INTRO SUPPORT VECTOR; Cipolla R., 1993, P 4 INT C COMP VIS B, P374; Cohn A. G., 2005, LNCS, P211; Cole M., 1996, DEV CHILDREN; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; Cruse H., 2006, NEURAL NETWORKS CYBE; Cui Y., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547020; Daly J., 2011, P INT JOINT C NEUR N, P1; Dan Y, 2006, PHYSIOL REV, V86, P1033, DOI 10.1152/physrev.00030.2005; Darrell T., 1996, P 10 INT C PATT REC; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), DOI 10.1109/CVPR.1993.341109; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; Deco G, 2000, VISION RES, V40, P2845, DOI 10.1016/S0042-6989(00)00140-1; Deller JR, 1993, DISCRETE TIME PROCES; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Dissanayaka M., 2001, IEEE T ROBOTIC AUTOM, V17, P229241; Domjan M, 1998, PRINCIPLES LEARNING; Doya K, 2000, CURR OPIN NEUROBIOL, V10, P732, DOI 10.1016/S0959-4388(00)00153-7; Dragoi V., 2004, VISUAL NEUROSCIENCES, P1654; Durrant-Whyte H., 2006, IEEE T ROBOT, V17, P99110; Elman J. L., 1997, RETHINKING INNATENES; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Etemad K., 1994, P INT C AC SPEECH SI, P2148; Fahlman S. E., 1990, CMUCS90100 SCH COMP; Fazl A, 2009, COGNITIVE PSYCHOL, V58, P1, DOI 10.1016/j.cogpsych.2008.05.001; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Feller MB, 1996, SCIENCE, V272, P1182, DOI 10.1126/science.272.5265.1182; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; FODOR JA, 1985, BEHAV BRAIN SCI, V8, P1; Froese T., ARTIF INTELL, V173, P466; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; George D, 2009, PLOS COMPUTATIONAL B, V5, P1; GILBERT CD, 1992, NATURE, V356, P150, DOI 10.1038/356150a0; Gilbert S.F., 2006, DEV BIOL, V8th; Goertzel B., 2007, ARTIFICIAL GEN INTEL; Golarai G, 2007, NAT NEUROSCI, V10, P512, DOI 10.1038/nn1865; Grimson W. E. L., 1981, IMAGES SURFACES COMP; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; Grossberg S., 2000, J INT NEUROPSYCH SOC, V6, P579, DOI DOI 10.1017/S135561770065508X; Grossberg S, 2000, VISION RES, V40, P1413, DOI 10.1016/S0042-6989(99)00229-1; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Hahnel D., 2003, P C INT ROB SYST IRO; Harnad S. R., 1987, CATEGORICAL PERCEPTI; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; HELD R, 1963, J COMP PHYSIOL PSYCH, V56, P872, DOI 10.1037/h0040546; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hopcroft J. E., 2006, INTRO AUTOMATA THEOR, V3rd; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Horn BKP, 1986, ROBOT VISION; Hosoya T, 2005, NATURE, V436, P71, DOI 10.1038/nature03689; Hsu FH, 1999, IEEE MICRO, V19, P70; Huang X, 2007, INT J HUM ROBOT, V4, P407, DOI 10.1142/S0219843607001011; Hwang WS, 2000, IEEE T PATTERN ANAL, V22, P1277, DOI 10.1109/34.888712; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Hyvarinen A., 1999, NEURAL COMPUTING SUR, V2, P94; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Itti L., 2005, NEUROBIOLOGY ATTENTI; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; Ji Z., 2010, P IEEE INT JOINT C N, P1; Ji ZP, 2008, INT C DEVEL LEARN, P61, DOI 10.1109/DEVLRN.2008.4640806; Johnson RR, 1996, J COMP NEUROL, V368, P383, DOI 10.1002/(SICI)1096-9861(19960506)368:3<383::AID-CNE5>3.0.CO;2-1; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233; Jordan M., 1997, CRC HDB COMPUTER SCI, P536; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; KARMILOFFSMITH A, 1994, BEHAV BRAIN SCI, V17, P693; Karz L. C., 1996, SCIENCE, V274, P1133; KATZ LC, 1992, ANNU REV NEUROSCI, V15, P31; KENNEDY H, 1985, J NEUROSCI, V5, P2815; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Koenig S, 1998, ARTIFICIAL INTELLIGENCE AND MOBILE ROBOTS, P91; Kohonen T., 1997, SELF ORG MAPS; Kohonen T., 2001, SELF ORG MAPS; Krichmar JL, 2005, ARTIF LIFE, V11, P63, DOI 10.1162/1064546053278946; Krichmar JL, 2008, ADAPT BEHAV, V16, P385, DOI 10.1177/1059712308095775; Laird J. E., 1991, Robotics and Autonomous Systems, V8, DOI 10.1016/0921-8890(91)90017-F; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; Langley P, 2009, COGN SYST RES, V10, P141, DOI 10.1016/j.cogsys.2006.07.004; Langley P, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P779; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; LENAT D, 1995, COMMUN ACM, V38, P45, DOI 10.1145/219717.219757; LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745; Li E, 2002, NAT REV GENET, V3, P662, DOI 10.1038/nrg887; Li L.J., 2007, IEEE INT C COMP VIS; LIN LJ, 1992, MACH LEARN, V8, P293, DOI 10.1007/BF00992699; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Liu Z., 2000, P 3 INT C VIS COMP M, P58; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lovejoy WS, 1991, ANN OPER RES, V28, P47, DOI 10.1007/BF02055574; LOWEL S, 1992, SCIENCE, V255, P209, DOI 10.1126/science.1372754; Luciw M., 2010, P IEEE INT JOINT C N, P4233; Luciw M., 2010, P IEEE 9 INT C DEV L, P311; Luciw M, 2010, IEEE T AUTON MENT DE, V2, P248, DOI 10.1109/TAMD.2010.2072150; Mahadevan S, 1996, MACH LEARN, V22, P159, DOI 10.1007/BF00114727; Mahon BZ, 2007, NEURON, V55, P507, DOI 10.1016/j.neuron.2007.07.011; Marr D., 1982, VISION COMPUTATIONAL; Mataric MJ, 1997, AUTON ROBOT, V4, P73, DOI 10.1023/A:1008819414322; McCane B., 2001, COMPUT VIS IMAGE UND, V84, P765; McClelland J. L., 1994, INT PERSPECTIVES PSY, V1, P57; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V2; MEISTER M, 1991, SCIENCE, V252, P939, DOI 10.1126/science.2035024; MERZENICH MM, 1984, J COMP NEUROL, V224, P591, DOI 10.1002/cne.902240408; MERZENICH MM, 1983, NEUROSCIENCE, V10, P639, DOI 10.1016/0306-4522(83)90208-7; Miikkulainen R, 2005, COMPUTATIONAL MAPS V; MINSKY M, 1991, AI MAG, V12, P34; Miyan K., 2010, P IEEE 9 INT C DEV L, P280; Montemerlo M., 2002, P AAAI NAT C ART INT; Munakata Y, 2003, DEVELOPMENTAL SCI, V6, P413, DOI 10.1111/1467-7687.00296; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Newell A., 1973, VISUAL INFORM PROCES, P283; NEWELL A, 1980, COGNITIVE SCI, V4, P135, DOI 10.1207/s15516709cog0402_2; Nuxoll A. M., 2007, P 22 AAAI C ART INT; O'Rourke J., 1980, IEEE T PATTERN ANAL, V2, P523; Obermayer K., 1990, P INT JOINT C NEUR N, V2, P423; Ohya J. Y. J., 1992, P 1992 IEEE COMP SOC, P379; Omlin CW, 1996, J ACM, V43, P937, DOI 10.1145/235809.235811; Oreback A, 2003, AUTON ROBOT, V14, P33, DOI 10.1023/A:1020975419546; Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271; Oyama S., 2000, ONTOGENY INFORM DEV; Paslaski S., 2011, P INT JOINT C NEUR N, P1; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Penrose R, 1989, EMPERORS NEW MIND CO; Penrose R, 1994, SHADOWS MIND SEARCH; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; PERKEL DJ, 1986, J COMP NEUROL, V253, P374, DOI 10.1002/cne.902530307; Purves WK, 2004, LIFE SCI BIOL; Puterman M. L, 1994, MARKOV DECISION PROC; PYLYSHYN ZW, 1980, BEHAV BRAIN SCI, V3, P111; Quartz SR, 1997, BEHAV BRAIN SCI, V20, P537; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RABINER LR, 1995, AT&T TECH J, V74, P4; RABINER LR, 1989, IEEE T ACOUST SPEECH, V37, P1214, DOI 10.1109/29.31269; REBER AS, 1980, J EXP PSYCHOL-HUM L, V6, P492, DOI 10.1037/0278-7393.6.5.492; Reddy L, 2007, NEUROIMAGE, V38, P730, DOI 10.1016/j.neuroimage.2007.08.006; Reik W, 2001, SCIENCE, V293, P1089, DOI 10.1126/science.1063443; Remage-Healey L, 2010, P NATL ACAD SCI USA, V107, P3852, DOI 10.1073/pnas.0906572107; Rideout WM, 2001, SCIENCE, V293, P1093, DOI 10.1126/science.1063206; Roelfsema PR, 2005, NEURAL COMPUT, V17, P2176, DOI 10.1162/0899766054615699; Rogers TT, 2008, BEHAV BRAIN SCI, V31, P689, DOI 10.1017/S0140525X0800589X; Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1207/s15516709cog2601_4; Russell S, 2003, ARTIFICIAL INTELLIGE; Russell S., 1995, ARTIFICIAL INTELLIGE; SALIN PA, 1995, PHYSIOL REV, V75, P107; Schill K, 2001, J ELECTRON IMAGING, V10, P152, DOI 10.1117/1.1329627; Schwartz A., 1993, P INT JOINT C ART IN, P289; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sharma J, 2000, NATURE, V404, P841, DOI 10.1038/35009043; Shultz TR, 2003, COMPUTATIONAL DEVELOPMENTAL PSYCHOLOGY, P1; Sit YF, 2006, NEUROCOMPUTING, V69, P1309, DOI 10.1016/j.neucom.2005.12.098; Sporns O., 1999, ADAPT BEHAV, V7; Starner T., 1995, P INT WORKSH AUT FAC, P189; Stockman I. J., 2004, MOVEMENT ACTION LEAR; STONE J, 1979, BRAIN RES REV, V1, P345, DOI 10.1016/0165-0173(79)90010-9; Sun R., 2005, PSYCHOL REV, V112, P59192; Sun R, 2007, J EXP THEOR ARTIF IN, V19, P159, DOI 10.1080/0952813070119560; Sun R, 2001, COGNITIVE SCI, V25, P203, DOI 10.1207/s15516709cog2502_2; Sur M, 2005, SCIENCE, V310, P805, DOI 10.1126/science.1112070; Sur M, 2001, NAT REV NEUROSCI, V2, P251, DOI 10.1038/35067562; Surani MA, 2001, NATURE, V414, P122, DOI 10.1038/35102186; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Taylor JG, 2009, IMAGE VISION COMPUT, V27, P1641, DOI 10.1016/j.imavis.2009.03.006; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Theocharous G., 2002, IEEE C ROB AUT WASH; TOMASI C, 1992, INT J COMPUT VISION, V9, P2; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Turing A., 1950, MIND, V49, p[433, 2099], DOI DOI 10.1093/MIND/LIX.236.433; Van Essen DC, 2001, VISION RES, V41, P1359, DOI 10.1016/S0042-6989(01)00045-1; Vernon D, 2008, IMAGE VISION COMPUT, V26, P127, DOI 10.1016/j.imavis.2005.08.009; Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274; von der Malsburg C, 1973, Kybernetik, V14, P85; Waibel A, 1990, READINGS SPEECH RECO; Wang X., 1995, NATURE, V378, P13; Wang Yi, 2011, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/APPEEC.2011.5749162; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1023/A:1022676722315; Weng J., 2006, P IEEE WORLD C COMP; Weng J, 1997, INT J COMPUT VISION, V25, P109, DOI 10.1023/A:1007967800668; Weng J., 2006, P 5 INT C DEV LEARN, P1; Weng J., 2011, AMD NEWSLETTER, V8, P10; Weng J., 2010, P INT JOINT C NEUR N, P1; Weng J, 2007, IEEE T NEURAL NETWOR, V18, P397, DOI 10.1109/TNN.2006.889942; Weng JY, 2009, MIND MACH, V19, P93, DOI 10.1007/s11023-008-9127-1; Weng J, 2009, P IEEE 8 INT C DEV L, P1; Weng J., 2002, AI MAG, V23, P95; Weng J., 2011, P INT JOINT C NEUR N, P1; Weng J., 2011, MSUCSE119 DEP COMP S; Weng J, 1997, IEEE T PATTERN ANAL, V19, P451, DOI 10.1109/34.589205; Weng J., 2007, IEEE CIS AUTONOM MEN, V4, P5; Weng J., 1993, P 4 INT C COMP VIS B, P121; WENG J, 1993, INT J COMPUT VISION, V11, P211, DOI 10.1007/BF01469343; Weng J., 1992, P INT JOINT C NEUR N, V1, P576, DOI 10.1109/IJCNN.1992.287150; Weng JA, 2000, IEEE INTELL SYST APP, V15, P63, DOI 10.1109/5254.889108; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Weng JY, 2007, INT J HUM ROBOT, V4, P281, DOI 10.1142/S0219843607001072; WENG JY, 1992, IEEE T ROBOTIC AUTOM, V8, P362, DOI 10.1109/70.143354; Weng JY, 2008, NEURAL NETWORKS, V21, P150, DOI 10.1016/j.neunet.2007.12.048; Weng JY, 2006, IEEE COMPUT INTELL M, V1, P15; Weng JY, 2007, NEUROCOMPUTING, V70, P2303, DOI 10.1016/j.neucom.2006.07.017; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; White J., 1993, MARKOV DECISION PROC; Wiemer JC, 2003, NEURAL COMPUT, V15, P1143, DOI 10.1162/089976603765202695; Worgotter F, 2009, ROBOT AUTON SYST, V57, P420, DOI 10.1016/j.robot.2008.06.011; Yao B., 2010, P COMP VIS PATT REC, P1; Yu C, 2009, IEEE T AUTON MENT DE, V1, P141, DOI 10.1109/TAMD.2009.2031513; Zhang N., 2002, Proceedings 2nd International Conference on Development and Learning. ICDL 2002, DOI 10.1109/DEVLRN.2002.1011723; Zhang YL, 2007, IEEE T EVOLUT COMPUT, V11, P226, DOI 10.1109/TEVC.2006.890269; Zhang YL, 2005, IEEE T NEURAL NETWOR, V16, P601, DOI 10.1109/TNN.2005.845217; Zhang YL, 2010, IEEE T AUTON MENT DE, V2, P149, DOI 10.1109/TAMD.2010.2051437; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	256	8	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1943-0604			IEEE T AUTON MENT DE	IEEE Trans. Auton. Ment. Dev.	MAR	2012	4	1					29	U1		10.1109/TAMD.2011.2159113		26	Computer Science, Artificial Intelligence; Robotics; Neurosciences	Computer Science; Robotics; Neurosciences & Neurology	908QF	WOS:000301504500003		
J	Ouyang, WL; Wang, XG			IEEE	Ouyang, Wanli; Wang, Xiaogang			A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling	2012 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 16-21, 2012	Providence, RI	IEEE				Part-based models have demonstrated their merit in object detection. However, there is a key issue to be solved on how to integrate the inaccurate scores of part detectors when there are occlusions or large deformations. To handle the imperfectness of part detectors, this paper presents a probabilistic pedestrian detection framework. In this framework, a deformable part-based model is used to obtain the scores of part detectors and the visibilities of parts are modeled as hidden variables. Unlike previous occlusion handling approaches that assume independence among visibility probabilities of parts or manually define rules for the visibility relationship, a discriminative deep model is used in this paper for learning the visibility relationship among overlapping parts at multiple layers. Experimental results on three public datasets (Caltech, ETH and Daimler) and a new CUHK occlusion dataset(1) specially designed for the evaluation of occlusion handling approaches show the effectiveness of the proposed approach.	[Ouyang, Wanli; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Ouyang, WL (reprint author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.	wlouyang@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk	Wang, Xiaogang/L-4369-2014	Wang, Xiaogang/0000-0002-9021-0954			Bar-Hillel A., 2010, ECCV; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergtholdt M, 2010, INT J COMPUT VISION, V87, P93, DOI 10.1007/s11263-009-0209-1; Dai S., 2007, CVPR; Dalal N., 2005, IEEE C COMP VIS PATT; Dollar P., 2011, TPAMI IN PRESS; Dollar P., 2009, BMVC; Dollar P., 2010, BMVC; Duan G., 2010, ECCV; Enzweiler M., 2010, CVPR; Ess A., 2007, ICCV; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jarrett K., 2009, CVPR; Lee H., 2009, ICML; Leibe B., 2005, CVPR; Maji S., 2008, CVPR; Mikolajczyk C., 2004, ECCV; Norouzi M., 2009, CVPR; Pedersoli M., 2010, ECCV; Ranzato M., 2011, CVPR; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Vedaldi A., 2009, ICCV; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Walk S., 2010, CVPR; Wang X., 2009, CVPR; Wang Y., 2011, CVPR; Wojek C., 2009, CVPR; Wu B., 2005, ICCV; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Zhu L., 2010, CVPR	33	8	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4673-1228-8	PROC CVPR IEEE			2012							3258	3265				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BBZ37	WOS:000309166203054		
J	Pan, J; Liu, C; Wang, ZG; Hu, Y; Jiang, H			IEEE	Pan, Jia; Liu, Cong; Wang, Zhiguo; Hu, Yu; Jiang, Hui			INVESTIGATION OF DEEP NEURAL NETWORKS (DNN) FOR LARGE VOCABULARY CONTINUOUS SPEECH RECOGNITION: WHY DNN SURPASSES GMMS IN ACOUSTIC MODELING	2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING			English	Proceedings Paper	8th International Symposium on Chinese Spoken Language Processing (ISCSLP)	DEC 05-08, 2012	Hong Kong, PEOPLES R CHINA	IEEE, Dept Syst Engn & Engn Management, Chinese Univ Hong Kong, IEEE Signal Proc Soc, Hong Kong Chapter, Dolby Labs Int Serv Co Ltd, United Coll, Shun Hing Inst Adv Engn		speech recognition; deep neural networks; pre-training; acoustic modeling		Recently, it has been reported that context-dependent deep neural network (DNN) has achieved some unprecedented gains in many challenging ASR tasks, including the well-known Switchboard task. In this paper, we first investigate DNN for several large vocabulary speech recognition tasks. Our results have confirmed that DNN can consistently achieve about 25-30% relative error reduction over the best discriminatively trained GMMs even in some ASR tasks with up to 700 hours of training data. Next, we have conducted a series of experiments to study where the unprecedented gain of DNN comes from. Our experiments show the gain of DNN is almost entirely attributed to DNN's feature vectors that are concatenated from several consecutive speech frames within a relatively long context window. At last, we have proposed a few ideas to re-configure the DNN input features, such as using logarithm spectrum features or VTLN normalized features in DNN. Our results have shown that each of these methods yields over 3% relative error reduction over the traditional MFCC or PLP features in DNN.	[Pan, Jia; Liu, Cong; Wang, Zhiguo; Hu, Yu] iFlytek Res, Hefei, Anhui, Peoples R China	Pan, J (reprint author), iFlytek Res, Hefei, Anhui, Peoples R China.	jiapan@iflytek.com; congliu2@iflytek.com; zgwang@iflytek.com; yuhu@iflytek.com; hj@cse.yorku.ca					Abdel-Hamid O., 2012, P ICASSP 2012 KYOT J; Dahl G., 2011, IEEE T SPEECH AUDIO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jiang H, 2010, COMPUT SPEECH LANG, V24, P589, DOI 10.1016/j.csl.2009.08.002; Morgan N., 1990, P ICASSP; Seide F., 2011, P INT; Seide F., 2011, P ASRU, P24; Woodland P. C., 2001, P DARPA HUB5E CONV S; Yu D., 2010, P NIPS WORKSH DEEP L	9	8	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-2507-3				2012							301	305				5	Computer Science, Artificial Intelligence	Computer Science	BEJ71	WOS:000316984700070		
J	Taylor, GW; Hinton, GE; Roweis, ST				Taylor, Graham W.; Hinton, Geoffrey E.; Roweis, Sam T.			Two Distributed-State Models For Generating High-Dimensional Time Series	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						unsupervised learning; restricted Boltzmann machines; time series; generative models; motion capture	BOLTZMANN MACHINES; HUMAN MOTION; LEARNING ALGORITHM; NEURAL-NETWORKS; STYLE; DEEP	In this paper we develop a class of nonlinear generative models for high-dimensional time series. We first propose a model based on the restricted Boltzmann machine (RBM) that uses an undirected model with binary latent variables and real-valued "visible" variables. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. This "conditional" RBM (CRBM) makes on-line inference efficient and allows us to use a simple approximate learning procedure. We demonstrate the power of our approach by synthesizing various sequences from a model trained on motion capture data and by performing on-line filling in of data lost during capture. We extend the CRBM in a way that preserves its most important computational properties and introduces multiplicative three-way interactions that allow the effective interaction weight between two variables to be modulated by the dynamic state of a third variable. We introduce a factoring of the implied three-way weight tensor to permit a more compact parameterization. The resulting model can capture diverse styles of motion with a single set of parameters, and the three-way interactions greatly improve its ability to blend motion styles or to transition smoothly among them. Videos and source code can be found at http://www.cs.nyu.edu/(similar to)gwtaylor/publications/ jmlr2011.	[Taylor, Graham W.; Roweis, Sam T.] NYU, Courant Inst Math Sci, New York, NY 10003 USA; [Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G1, Canada	Taylor, GW (reprint author), NYU, Courant Inst Math Sci, 251 Mercer St, New York, NY 10003 USA.	GWTAYLOR@CS.NYU.EDU; HINTON@CS.TORONTO.EDU; ROWEIS@CS.NYU.EDU			NSERC; CIFAR	An earlier version of this work appeared in two conference papers (Taylor et al., 2007; Taylor and Hinton, 2009). The authors thank NSERC and CIFAR for financial support. The authors also thank the anonymous reviewers for their helpful feedback. This work was primarily conducted while the first and third authors were at the University of Toronto.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Arikan O., 2003, P ACM SIGGRAPH, P402; Arikan O., 2002, P 29 ANN C COMP GRAP, P483, DOI 10.1145/566570.566606; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; BENGIO Y, 2008, NEURAL COMPUT, V21, P1; Bissacco A, 2005, PROC CVPR IEEE, P421; Brand M, 2000, COMP GRAPH, P183; Carreira-Perpinan M.A., 2005, P 10 INT WORKSH ART, P59; FREUND Y, 1992, ADV NEUR IN, V4, P912; Gehler P. V., 2006, P 23 INT C MACH LEAR, P337, DOI 10.1145/1143844.1143887; Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168; Grassias FS, 1998, J GRAPHICS TOOLS, V3, P29; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2000, ADV NEUR IN, V12, P122; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; HINTON GE, 2010, 2010000 UTML TR; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsu E., 2005, P ACM SIGGRAPH 05, P1082; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; KOVAR L, 2002, P 29 ANN C COMP GRAP, P473, DOI 10.1145/566570.566605; Kovar L., 2004, P SIGGRAPH 04, P559; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lawrence N., 2007, P 11 INT WORKSH ART, P243; Lawrence N. D., 2007, P 24 INT C MACH LEAR, P481, DOI 10.1145/1273496.1273557; LAWRENCE ND, 2006, CS0605 U SHEFF; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee DD, 1999, NATURE, V401, P788; Lee H., 2008, ADV NEURAL INFORM PR, P873; Lee J., 2002, P ACM SIGGRAPH 2002, P491, DOI 10.1145/566570.566607; Li Y., 2002, P ACM SIGGRAPH, P465, DOI 10.1145/566570.566604; LIU CK, 2005, P SIGGRAPH 2005, P1071; MATSUOKA K, 1992, IEEE T SYST MAN CYB, V22, P436, DOI 10.1109/21.155944; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Memisevic Roland, 2007, P IEEE COMP SOC C CO; Mnih A., 2007, P 24 INT C MACH LEAR, P641, DOI 10.1145/1273496.1273577; Mukai T, 2005, P ACM SIGGRAPH 2005, P1062; Murphy K. P., 2002, THESIS U CALIFORNIA; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; OSINDERO S, 2008, ADV NEURAL INFORM PR, P1121; Park S.I., 2002, P ACM SIGGRAPH S COM, P105; Pavlovic V, 2001, ADV NEUR IN, V13, P981; Pearl J, 1988, PROBABILISTIC REASON; Pullen K., 2002, P 29 ANN C COMP GRAP, P501, DOI 10.1145/566570.566608; Ranzato M, 2006, ADV NEURAL INFORM PR, P1137; Ranzato M., 2008, ADV NEURAL INFORM PR; RANZATO M, 2007, P 11 INT C ART INT S; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; Salakhutdinov RR, 2008, P 25 INT C MACH LEAR, P872, DOI 10.1145/1390156.1390266; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; SUTSKEVER I, 2009, ADV NEURAL INFORM PR, V21; SUTSKEVER I, 2007, P 11 INT C ART INT S; Tanco L. M., 2000, Proceedings Workshop on Human Motion, DOI 10.1109/HUMO.2000.897383; Taylor G., 2007, ADV NEURAL INFORM PR, P1345; Taylor G., 2009, P 26 ANN INT C MACH, P1025; TEH YW, 2001, ADV NEURAL INFORM PR; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; TIELEMAN T, 2009, P 26 INT C MACH LEAR; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; TORRESANI L, 2007, ADV NEURAL INFORM PR, P1393; Urtasun R., 2006, P CVPR, P238; URTASUN R, 2008, P 25 INT C MACH LEAR, P1080, DOI 10.1145/1390156.1390292; Urtasun R., 2004, COMPUT GRAPH FORUM, V23, P1; Wang J. M., 2007, P 24 INT C MACH LEAR, P975, DOI DOI 10.1145/1273496.1273619; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	72	8	8	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAR	2011	12						1025	1068				44	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	751RJ	WOS:000289635000009		
J	Hinton, G; Salakhutdinov, R				Hinton, Geoffrey; Salakhutdinov, Ruslan			Discovering Binary Codes for Documents by Learning Deep Generative Models	TOPICS IN COGNITIVE SCIENCE			English	Article						Deep learning; Semantic hashing; Auto-encoders; Restricted Boltzmann machines; Document retrieval; Binary codes		We describe a deep generative model in which the lowest layer represents the word-count vector of a document and the top layer represents a learned binary code for that document. The top two layers of the generative model form an undirected associative memory and the remaining layers form a belief net with directed, top-down connections. We present efficient learning and inference procedures for this type of generative model and show that it allows more accurate and much faster retrieval than latent semantic analysis. By using our method as a filter for a much slower method called TF-IDF we achieve higher accuracy than TF-IDF alone and save several orders of magnitude in retrieval time. By using short binary codes as addresses, we can perform retrieval on very large document sets in a time that is independent of the size of the document set using only one word of memory to describe each document.	[Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Salakhutdinov, Ruslan] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA	Hinton, G (reprint author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	hinton@cs.toronto.edu					Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Erhan D., 2009, AISTATS 2009, V5, P153; GEHLER P, 2006, P 23 INT C MACH LEAR; Hinton G., 2002, ADV NEURAL INFORM PR, V15, P833; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hofmann T., 1999, P 15 C UNC AI, P286; Jordan M., 1999, LEARNING GRAPHICAL M; McClelland J. L., 1986, PARALLEL DISTRIBUTED, P77; Pearl J., 1988, PROBABILISTIC INFERE; Salakhutdinov R. R., 2007, P SIGIR WORKSH INF R; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sejnowski T. J, 1983, P IEEE C COMP VIS PA; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Xing E. P., 2005, P 21 C UNC ART INT U, P633	20	8	8	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	1756-8757			TOP COGN SCI	Top. Cogn. Sci.	JAN	2011	3	1					74	91		10.1111/j.1756-8765.2010.01109.x		18	Psychology, Experimental	Psychology	704LG	WOS:000286053900005	25164175	
J	Le Roux, N; Bengio, Y				Le Roux, Nicolas; Bengio, Yoshua			Deep Belief Networks Are Compact Universal Approximators	NEURAL COMPUTATION			English	Article								Deep belief networks (DBN) are generative models with many layers of hidden causal variables, recently introduced by Hinton, Osindero, and Teh (2006), along with a greedy layer-wise unsupervised learning algorithm. Building on Le Roux and Bengio (2008) and Sutskever and Hinton (2008), we show that deep but narrow generative networks do not require more parameters than shallow ones to achieve universal approximation. Exploiting the proof technique, we prove that deep but narrow feedforward neural networks with sigmoidal units can represent any Boolean expression.	[Le Roux, Nicolas] Microsoft Res Cambridge, Cambridge CB3 OFB, England; [Bengio, Yoshua] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Le Roux, N (reprint author), Microsoft Res Cambridge, Cambridge CB3 OFB, England.	nicolas.le.roux@umontreal.ca; yoshua.bengio@umontreal.ca					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; FREUND Y, 1991, ADV NEURAL INFORM PR, V4; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; ITU, 2004, ITU-T Rec. G.975.1, Patent No. [2632058, 2,632,058]; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Ranzato M., 2007, ADV NEURAL INFORM PR, V19; ROJAS R, 2003, INT JOINT C NEUR NET, V4, P3124; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; TIELEMAN T, 2008, P INT C MACH LEARN, V25; Vincent P., 2008, P 25 INT C MACH LEAR	15	8	8	M I T PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	AUG	2010	22	8					2192	2207		10.1162/neco.2010.08-09-1081		16	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	615CO	WOS:000279109600010		
B	Deng, L; Seltzer, M; Yu, D; Acero, A; Mohamed, A; Hinton, G			INST SPEECH COMMUN ASSOC	Deng, L.; Seltzer, M.; Yu, D.; Acero, A.; Mohamed, A.; Hinton, G.			Binary Coding of Speech Spectrograms Using a Deep Auto-encoder	11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4			English	Proceedings Paper	11th Annual Conference of the International-Speech-Communication-Association 2010	SEP 26-30, 2010	Makuhari, JAPAN	Japan World Exposit, Commemorat Org, Japan Soc Promot Sci, Telecommunicat Advancement Fdn, KDDI Fdn, Murata Sci Fdn, Adv Telecommunicat Technol Res Fdn, Support Ctr, Chiba Convent Bur & Int Ctr, Renesas Elect Corp, Google, Microsoft Corp, Nuance Commun Inc, Appen Pty Ltd, IBM Res, Sony Corp, Hitachi Ltd, Yahoo Japan Corp, Asahi Kasei Corp, KDDI R & D Lab Inc, Yamaha Corp, Toshiba Corp, Fujitsu Ltd, Mitsubishi Elect Corp, RION Co Ltd, NEC Corp		deep learning; speech feature extraction; neural networks; auto-encoder; binary codes; Boltzmann machine	RECOGNITION; ALGORITHM	This paper reports our recent exploration of the layer-by-layer learning strategy for training a multi-layer generative model of patches of speech spectrograms. The top layer of the generative model learns binary codes that can be used for efficient compression of speech and could also be used for scalable speech recognition or rapid speech content retrieval. Each layer of the generative model is fully connected to the layer below and the weights on these connections are pre-trained efficiently by using the contrastive divergence approximation to the log likelihood gradient. After layer-by-layer pre-training we "unroll" the generative model to form a deep auto-encoder, whose parameters are then fine-tuned using back-propagation. To reconstruct the full-length speech spectrogram, individual spectrogram segments predicted by their respective binary codes are combined using an overlap-and-add method. Experimental results on speech spectrogram coding demonstrate that the binary codes produce a log-spectral distortion that is approximately 2 dB lower than a sub-band vector quantization technique over the entire frequency range of wide-band speech.	[Deng, L.; Seltzer, M.; Yu, D.; Acero, A.] Microsoft Res, Redmond, WA 98052 USA	Deng, L (reprint author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.	deng@microsoft.com; mseltzer@microsoft.com; dongyu@microsoft.com; alexac@microsoft.com; asamir@cs.toronto.edu; hinton@cs.toronto.edu					Baker J., 2009, IEEE SIG PROC MA JUL, V26, P78; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Bell G., 1961, J ACOUST SOC AM, V33, P1725; Deng L., 1999, COMPUTATIONAL MODELS, P199; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Halle M., 1962, IRE T INFORM THEORY; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Mohamed A., 2009, P NIPS WORKSH DEC; Mohamed A., 2010, P INTERSPEECH; Salakhutdinov R. R., 2007, P SIGIR WORKSH INF R; Yu D., 2010, P INTERSPEECH; YU D, 2010, P ICASSP, P5030; Yu D., 2009, P NIPS WORKSH DEC; Yu D, 2009, IEEE SIGNAL PROC MAG, V26, P86, DOI 10.1109/MSP.2009.932793; Yu D, 2009, IEEE T AUDIO SPEECH, V17, P1348, DOI 10.1109/TASL.2009.2020890	17	8	8	ISCA-INST SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-61782-123-3				2010							1692	1695				4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BDG18	WOS:000313086500035		
J	Abdelghani, MN; Lillicrap, TP; Tweed, DB				Abdelghani, M. N.; Lillicrap, T. P.; Tweed, D. B.			Sensitivity derivatives for flexible sensorimotor learning	NEURAL COMPUTATION			English	Article							STOCHASTIC-GRADIENT-DESCENT; PLASTICITY; MODELS; COORDINATION; CEREBELLUM; ALGORITHM; NETWORKS; INPUT; CAT	To learn effectively, an adaptive controller needs to know its sensitivity derivatives-the variables that quantify how system performance depends on the commands from the controller. In the case of biological sensorimotor control, no one has explained how those derivatives themselves might be learned, and some authors suggest they are not learned at all but are known innately. Here we show that this knowledge cannot be solely innate, given the adaptive flexibility of neural systems. And we show how it could be learned using forms of information transport that are available in the brain. The mechanism, which we call implicit supervision, helps explain the flexibility and speed of sensorimotor learning and our ability to cope with high-dimensional work spaces and tools.	[Abdelghani, M. N.] Univ Toronto, Dept Phys, Toronto, ON, Canada; [Lillicrap, T. P.] Queens Univ, Ctr Neurosci Studies, Kingston, ON K7L 3N6, Canada; [Tweed, D. B.] Univ Toronto, Dept Physiol, Toronto, ON M5S 1A8, Canada; [Tweed, D. B.] Univ Toronto, Dept Med, Toronto, ON M5S 1A8, Canada; [Tweed, D. B.] York Univ, Ctr Vis Res, Toronto, ON M3J 1P3, Canada	Abdelghani, MN (reprint author), Univ Toronto, Dept Phys, Toronto, ON, Canada.	mohamed.abdelghani@utoronto.ca; tim@biomed.queensu.ca; douglas.tweed@utoronto.ca					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Astrom K.J., 1995, ADAPTIVE CONTROL; BRINKMAN C, 1983, SCIENCE, V220, P438, DOI 10.1126/science.6836289; CALLIER FM, 1991, LINEAR SYSTEMS THEOR; Dean P, 2002, P ROY SOC B-BIOL SCI, V269, P1895, DOI 10.1098/rspb.2002.2103; Ewert P. W., 1930, GENETIC PSYCH MONOGR, V7, P177; FORSSBERG H, 1983, NEUROSCI LETT, V41, P283, DOI 10.1016/0304-3940(83)90464-0; GARDNER WA, 1984, SIGNAL PROCESS, V6, P113, DOI 10.1016/0165-1684(84)90013-6; Haykin S., 2002, ADAPTIVE FILTER THEO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1; KAWATO M, 1992, TRENDS NEUROSCI, V15, P445, DOI 10.1016/0166-2236(92)90008-V; Koch C., 1999, BIOPHYSICS COMPUTATI; Leffert R D, 1976, J Hand Surg Am, V1, P181; Lewis F. L., 1999, NEURAL NETWORK CONTR; MAZZONI P, 1991, P NATL ACAD SCI USA, V88, P4433, DOI 10.1073/pnas.88.10.4433; MISSIURO W, 1963, ARCH PHYS MED REHAB, V44, P37; Nagumo J., 1967, IEEE T AUTOMAT CONTR, VAC-12, P283; Oztas E., 2003, NEUROANATOMY, V2, P2; Porrill J, 2004, P ROY SOC B-BIOL SCI, V271, P789, DOI 10.1098/rspb.2003.2658; Rolls ET, 2002, COMPUTATIONAL NEUROS; Shibata T, 2005, NEURAL NETWORKS, V18, P213, DOI 10.1016/j.neunet.2005.01.001; Sperry RW, 1943, J EXP ZOOL, V92, P263, DOI 10.1002/jez.1400920303; SPERRY RW, 1945, Q REV BIOL, V20, P311, DOI 10.1086/394990; Stratton G. M., 1897, PSYCHOL REV, V4, P341, DOI 10.1037/h0075482; Sugita Y, 1996, NATURE, V380, P523, DOI 10.1038/380523a0; Sutton RS, 1998, REINFORCEMENT LEARNI; Todorov E, 2002, NAT NEUROSCI, V5, P1226, DOI 10.1038/nn963; TRIPP BY, 2006, COSYNE 2006 ABSTR; TWEED D, 1994, J NEUROPHYSIOL, V72, P1425; VERA CL, 1975, J NEUROSURG, V43, P181, DOI 10.3171/jns.1975.43.2.0181; Werfel J, 2005, NEURAL COMPUT, V17, P2699, DOI 10.1162/089976605774320539; Yamamoto K, 2002, J NEUROPHYSIOL, V87, P1554, DOI 10.1152/jn.00166.2001; YUMIYA H, 1979, BRAIN RES, V177, P566, DOI 10.1016/0006-8993(79)90474-8	34	8	8	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	AUG	2008	20	8					2085	2111		10.1162/neco.2008.04-07-507		27	Computer Science, Artificial Intelligence	Computer Science	315YN	WOS:000256916200008	18336076	
S	Zeiler, MD; Fergus, R		Fleet, D; Pajdla, T; Schiele, B; Tuytelaars, T		Zeiler, Matthew D.; Fergus, Rob			Visualizing and Understanding Convolutional Networks	COMPUTER VISION - ECCV 2014, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	13th European Conference on Computer Vision (ECCV)	SEP 06-12, 2014	Zurich, SWITZERLAND					Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.	[Zeiler, Matthew D.; Fergus, Rob] NYU, Dept Comp Sci, New York, NY 10003 USA	Zeiler, MD (reprint author), NYU, Dept Comp Sci, New York, NY 10003 USA.	zeiler@cs.nyu.edu; fergus@cs.nyu.edu					Bengio Y., 2007, NIPS, V19, P153; Berkes P., 2006, NEURAL COMPUTATION; Bo L., 2013, CVPR; Ciresan D.C., 2012, CVPR; Dalal N., 2005, CVPR; Deng J., 2009, CVPR 2009; Donahue Jeff, 2013, ARXIV13101531; Erhan D., 2009, TECHNICAL REPORT; Fei-fei L., 2006, IEEE T PAMI; Girshick R., 2014, ARXIV13112524; Griffin G., 2006, 256 CALT; Gunji N., 2012, IMAGENET COMPETITION; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Howard A.G., 2013, ARXIV13125402; Jarrett K., 2009, ICCV; Jianchao Y., 2009, CVPR; Krizhevsky A., 2012, NIPS; Le Q. V., 2010, NIPS; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Oquab M., 2014, CVPR; Sande K., 2012, PASCAL VOC CLASSIFIC; Simonyan K., 2013, ARXIV13126034V1; Sohn K., 2011, ICCV; Torralba A., 2011, CVPR; Vincent P., 2008, INT C MACH LEARN, P1096; Yan S, 2012, PASCAL VOC CLASSIFIC; Zeiler M, 2013, CLARIFAI; Zeiler M. D., 2011, ICCV	29	7	8	SPRINGER INT PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743		978-3-319-10590-1; 978-3-319-10589-5	LECT NOTES COMPUT SC			2014	8689						818	833				16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BB7GU	WOS:000345524200047		
J	Humphrey, EJ; Bello, JP; Lecun, Y				Humphrey, Eric J.; Bello, Juan P.; LeCun, Yann			Feature learning and deep architectures: new directions for music informatics	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article						Music informatics; Deep learning; Signal processing	RETRIEVAL; AUDIO; REPRESENTATIONS; SIGNALS; CHORDS	As we look to advance the state of the art in content-based music informatics, there is a general sense that progress is decelerating throughout the field. On closer inspection, performance trajectories across several applications reveal that this is indeed the case, raising some difficult questions for the discipline: why are we slowing down, and what can we do about it? Here, we strive to address both of these concerns. First, we critically review the standard approach to music signal analysis and identify three specific deficiencies to current methods: hand-crafted feature design is sub-optimal and unsustainable, the power of shallow architectures is fundamentally limited, and short-time analysis cannot encode musically meaningful structure. Acknowledging breakthroughs in other perceptual AI domains, we offer that deep learning holds the potential to overcome each of these obstacles. Through conceptual arguments for feature learning and deeper processing architectures, we demonstrate how deep processing models are more powerful extensions of current methods, and why now is the time for this paradigm shift. Finally, we conclude with a discussion of current challenges and the potential impact to further motivate an exploration of this promising research area.	[Humphrey, Eric J.; Bello, Juan P.] NYU, MARL, New York, NY 10003 USA; [LeCun, Yann] NYU, Courant Inst, New York, NY 10003 USA	Humphrey, EJ (reprint author), NYU, MARL, 35 West 4th St, New York, NY 10003 USA.	ejhumphrey@nyu.edu					Anden J., 2011, P 12 INT C MUS INF R; Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998; Bengio Y., 2012, ARXIV12065538; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Berenzweig A, 2004, COMPUT MUSIC J, V28, P63, DOI 10.1162/014892604323112257; Bergstra J., 2010, P PYTH SCI COMP C SC; Bertin-Mahieux T., 2012, P 13 INT C MUS INF R, P241; Bishop CM, 2006, PATTERN RECOGNITION; Cabral G, 2006, LECT NOTES COMPUT SC, V3902, P185; Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370; Cho T., 2011, P 12 INT C MUS INF R; Chordia P, 2011, J NEW MUSIC RES, V40, P105, DOI 10.1080/09298215.2011.576318; Collobert R., 2011, BIGLEARN NIPS WORKSH; Dannenberg R.B., 1984, P 1984 INT COMP MUS, P193; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Dieleman S., 2011, P 12 INT C MUS INF R; Dixon S, 2007, J NEW MUSIC RES, V36, P39, DOI 10.1080/09298210701653310; Edward W., 1994, CONNECT SCI, V6, P177; Flexer A., 2012, P 13 INT C MUS INF R, P175; Fujishima T., 1999, P INT COMP MUS C; Goto M., 1995, P 1995 INT COMP MUS, P171; Grosche P, 2011, IEEE T AUDIO SPEECH, V19, P1688, DOI 10.1109/TASL.2010.2096216; Hadsell R., 2006, P COMP VIS PATT REC; Hamel P., 2009, P 10 INT C MUS INF R; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Humphrey E. J., 2012, P INT C MACH LEARN A; Humphrey E.J., 2010, P ICMLA; Humphrey E.J., 2012, P 13 INT C MUS INF R; Klapuri A., 2006, SIGNAL PROCESSING ME; Le Q., 2012, P INT C MACH LEARN I; Le Q.V., 2010, ADV NEURAL INFORM PR, V23; LeCun Y., 2006, TUTORIAL ENERGY BASE; LeCun Yann, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, DOI 10.1007/978-3-642-33863-2_51; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Leveau P., 2007, P 8 INT C MUS INF RE; Levy M., 2007, 2007 IEEE INT C AC S, V4, P1433; Levy M, 2009, IEEE T MULTIMEDIA, V11, P383, DOI 10.1109/TMM.2009.2012913; Lyon RF, 2010, NEURAL COMPUT, V22, P2390, DOI 10.1162/NECO_a_00011; Mandel M. I., 2005, P 6 INT C MUS INF RE; Mauch M, 2010, IEEE T AUDIO SPEECH, V18, P1280, DOI 10.1109/TASL.2009.2032947; McFee B., 2012, P 13 INT C MUS INF R; Muller M, 2011, IEEE J-STSP, V5, P1088, DOI 10.1109/JSTSP.2011.2112333; Muller M., 2011, P 12 INT C MUS INF R; Nam J., 2011, P 12 INT C MUS INF R; Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129; Schmidt E.M., 2011, P NEUR INF PROC SYST; Sheh A., 2003, P 4 INT C MUS INF RE; Slaney M, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.34; Sumi K, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1997; Zils A., 2004, P AES	52	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902	1573-7675		J INTELL INF SYST	J. Intell. Inf. Syst.	DEC	2013	41	3					461	481		10.1007/s10844-013-0248-5		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	251MI	WOS:000326932800006		
J	Salakhutdinov, R; Tenenbaum, JB; Torralba, A				Salakhutdinov, Ruslan; Tenenbaum, Joshua B.; Torralba, Antonio			Learning with Hierarchical-Deep Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep networks; deep Boltzmann machines; hierarchical Bayesian models; one-shot learning	NEURAL-NETWORKS; OBJECT; INFERENCE	We introduce HD (or "Hierarchical-Deep") models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.	[Salakhutdinov, Ruslan] Univ Toronto, Dept Stat & Comp Sci, Toronto, ON M5S 3G3, Canada; [Tenenbaum, Joshua B.] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA; [Torralba, Antonio] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Salakhutdinov, R (reprint author), Univ Toronto, Dept Stat & Comp Sci, Toronto, ON M5S 3G3, Canada.	rsalakhu@utstat.toronto.edu; jbt@mit.edu; torralba@mit.edu			NSERC; ONR (MURI) [1015GNA126]; ONR [N00014-07-1-0937]; ARO [W911NF-08-1-0242]; Qualcomm	This research was supported by NSERC, ONR (MURI Grant 1015GNA126), ONR N00014-07-1-0937, ARO W911NF-08-1-0242, and Qualcomm.	Babenko B., 2009, P IEEE INT C COMP VI; Bart E., 2008, P IEEE C COMP VIS PA, P1, DOI 10.1080/15614260802381067; Bart E, 2005, PROC CVPR IEEE, P672; Blei D. M., 2010, J ACM, V57; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Canini K.R., 2009, P NIPS WORKSH NONP B; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P271; Chen Bo, 2011, P 28 INT C MACH LEAR, P361; Coates A., 2011, P 11 INT C DOC AN RE; Courville A., 2011, P 28 INT C MACH LEAR, P1145; Fei-Fei Li, 2006, IEEE Trans Pattern Anal Mach Intell, V28, P594; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Lake B., 2011, P 33 ANN C COGN SCI; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lin Y., 2011, P ADV NEUR INF PROC, V23; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, P ADV NEUR INF PROC, V21; Perfors A. Perfors, 2009, P 31 ANN C COGN SCI, P136; Ranzato M.A., 2008, P ADV NEUR INF PROC; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rodriguez A, 2008, J AM STAT ASSOC, V103, P1131, DOI 10.1198/016214508000000553; Salakhutdinov R.R., 2010, P ADV NEUR INF PROC, V22; Salakhutdinov R.R., 2009, P INT C ART INT STAT, V12; Sejnowski T. J, 1983, P IEEE C COMP VIS PA; Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403; Socher R, 2011, P 28 INT C MACH LEAR; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Taylor G., 2006, P ADV NEUR INF PROC; Taylor G.W., 2010, P 11 EUR C COMP VIS; Teh Y.W., 2001, P ADV NEUR INF PROC, V13; Teh YW, 2010, BAYESIAN NONPARAMETR; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Tieleman T., 2008, P 25 INT C MACH LEAR; Torralba A, 2006, LECT NOTES COMPUT SC, V4170, P345; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L., 2000, CONVERGENCE MARKOVIA; Yuille A.L., 2004, P ADV NEUR INF PROC	44	7	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1958	1971		10.1109/TPAMI.2012.269		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	164AP	WOS:000320381400011	23787346	
J	Martinez, HP; Bengio, Y; Yannakakis, GN				Martinez, Hector P.; Bengio, Yoshua; Yannakakis, Georgios N.			Learning Deep Physiological Models of Affect	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							EMOTION RECOGNITION; NEURAL-NETWORK; CLASSIFICATION; PREDICTION; PLAY; FACE; EEG		[Martinez, Hector P.] IT Univ Copenhagen, Copenhagen, Denmark; [Bengio, Yoshua] Univ Montreal, Montreal, PQ H3C 3J7, Canada; [Yannakakis, Georgios N.] Univ Malta, Msida, Malta	Martinez, HP (reprint author), IT Univ Copenhagen, Copenhagen, Denmark.				Ubisoft; NSERC; Canada Research Chairs; ILearnRW [318803]; C2Learn FP7 ICT EU projects [318480]	The authors would like to thank Tobias Mahlmann for his work on the development and administration of the cluster used to run the experiments. Special thanks for proofreading goes to Yana Knight. Thanks also go to the Theano development team, to all participants in our experiments, and to Ubisoft, NSERC and Canada Research Chairs for funding. This work is funded, in part, by the ILearnRW (project no: 318803) and the C2Learn (project no. 318480) FP7 ICT EU projects.	Alain G., 2012, 12114246 ARXIV U MON; AlZoubi O, 2009, LECT NOTES ARTIF INT, V5866, P52, DOI 10.1007/978-3-642-10439-8_6; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bai B, 2010, INFORM RETRIEVAL, V13, P291, DOI 10.1007/s10791-009-9117-9; Bailenson JN, 2008, INT J HUM-COMPUT ST, V66, P303, DOI 10.1016/j.ijhcs.2007.10.011; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3; Bengio Y., 2012, 12065538 ARXIV U MON; Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1; Caridakis G., 2011, P 17 INT C DIG SIGN, P1; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Ekman P., 1988, APPRAISAL EMOTION DI, V12, P271; Farabet C., 2013, IEEE T PATTERN ANAL, P1; Furnkranz J., 2005, KUNSTLICHE INTELLIGE, V19, P60; Giakoumis D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043571; Giakoumis D, 2011, IEEE T AFFECT COMPUT, V2, P119, DOI [10.1109/T-AFFC.2011.4, 10.1109/TAFF-C.2011.4]; Goldberger JJ, 2001, CIRCULATION, V103, P1977; Grafsgaard JF, 2011, LECT NOTES COMPUT SC, V6974, P97, DOI 10.1007/978-3-642-24600-5_13; Grangier D., 2005, P 14 ACM INT C INF K, P359, DOI 10.1145/1099554.1099666; Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007; Hamel P., 2011, P 12 INT C MUS INF R, P729; Hernandez J, 2011, LECT NOTES COMPUT SC, V6974, P125, DOI 10.1007/978-3-642-24600-5_16; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 1994, P NEUR INF PROC SYST, V6, P3; Kaliouby R., 2005, REAL TIME VISION HUM, P181, DOI 10.1007/0-387-27890-7_11; Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003; Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719; Kleinsmith A., 2012, IEEE T AFFECT COMPUT; KOBAYASHI H, 1993, IEEE IJCNN, P155; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P255; Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534; Lesh N., 1999, P 5 ACM SIGKDD INT C, P342, DOI 10.1145/312129.312275; Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011; Martinez H. P., 2010, P IEEE C COMP INT GA, P313, DOI 10.1109/ITW.2010.5593340; Martinez HP, 2011, LECT NOTES COMPUT SC, V6974, P267; Martinez H.P., 2010, P 3 INT WORKSH AFF I, P15, DOI 10.1145/1877826.1877832; Martinez H.P., 2011, P 13 INT C MULT INT, P3; Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7; Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1; McQuiggan SW, 2008, USER MODEL USER-ADAP, V18, P81, DOI 10.1007/s11257-007-9040-y; Mirowski PW, 2008, MACHINE LEARN SIGN P, P244, DOI 10.1109/MLSP.2008.4685487; Morris JD, 1995, J ADVERTISING RES, V35, P63; Picard R. W., 2000, AFFECTIVE COMPUTING; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Ravaja N, 2006, MEDIA PSYCHOL, V8, P343, DOI 10.1207/s1532785xmep0804_2; Rifai S., 2012, P EUR C COMP VIS, P802; Rumelhart D., 1995, BACKPROPAGATION THEO; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37; Susskind Joshua, 2010, 2010001 UTML TR; Tognetti S., 2010, P 3 INT WORKSH AFF I, P3, DOI 10.1145/1877826.1877830; Tognetti Simone, 2010, P IEEE C COMP INT GA, P321, DOI 10.1109/ITW.2010.5593337; Ververidis D, 2004, P 12 EUR SIGN PROC C, P341; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vyzas E., 1998, P EM INT TANGL KNOT, P176; Wagner J., 2005, P IEEE INT C MULT EX, P940; Yannakakis GN, 2008, USER MODEL USER-ADAP, V18, P207, DOI 10.1007/s11257-007-9036-7; Yannakakis G. N., 2009, P INT C AFF COMP INT, P126; Yannakakis G. N., 2011, P 4 INT C AFF COMP I, P437; Yannakakis GN, 2010, USER MODEL USER-ADAP, V20, P313, DOI 10.1007/s11257-010-9078-0; Yannakakis GN, 2008, INT J HUM-COMPUT ST, V66, P741, DOI 10.1016/j.ijhcs.2008.06.004; Zhao W., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670971	68	7	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-603X			IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	MAY	2013	8	2					20	33		10.1109/MCI.2013.2247823		14	Computer Science, Artificial Intelligence	Computer Science	128RY	WOS:000317787700003		
J	Ghoshal, A; Swietojanski, P; Renals, S			IEEE	Ghoshal, Arnab; Swietojanski, Pawel; Renals, Steve			MULTILINGUAL TRAINING OF DEEP NEURAL NETWORKS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Speech recognition; deep learning; neural networks; multilingual modeling	SPEECH RECOGNITION; PHONE RECOGNITION; NETS	We investigate multilingual modeling in the context of a deep neural network (DNN) - hidden Markov model (HMM) hybrid, where the DNN outputs are used as the HMM state likelihoods. By viewing neural networks as a cascade of feature extractors followed by a logistic regression classifier, we hypothesise that the hidden layers, which act as feature extractors, will be transferable between languages. As a corollary, we propose that training the hidden layers on multiple languages makes them more suitable for such cross-lingual transfer. We experimentally confirm these hypotheses on the GlobalPhone corpus using seven languages from three different language families: Germanic, Romance, and Slavic. The experiments demonstrate substantial improvements over a monolingual DNN-HMM hybrid baseline, and hint at avenues of further exploration.	[Ghoshal, Arnab; Swietojanski, Pawel; Renals, Steve] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland	Ghoshal, A (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland.	a.ghoshal@ed.ac.uk; p.swietojanski@ed.ac.uk; s.renals@ed.ac.uk					Bengio Y, ARXIV12065538; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergstra J, 2010, P SCIPY; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646; Byrne W, 2000, INT CONF ACOUST SPEE, P1029; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Grezl F, 2011, P IEEE ASRU; Hermansky H, 2000, P IEEE ICASSP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lu L, 2011, P IEEE ASRU; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Povey D, 2011, P IEEE ASRU DEC; Povey D, 2011, COMPUT SPEECH LANG, V25, P404, DOI 10.1016/j.csl.2010.06.003; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Schultz T., 1998, P DARPA WORKSH BROAD; Schultz T., 2002, P ICSLP, V1, P345; Schultz T, 2001, SPEECH COMMUN, V35, P31, DOI 10.1016/S0167-6393(00)00094-7; Schultz T., 1997, P EUROSPEECH, P371; Sim KC, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P546, DOI 10.1109/ASRU.2009.5372910; Sim KC, 2008, INT CONF ACOUST SPEE, P4309; Siniscalchi SM, 2012, IEEE T AUDIO SPEECH, V20, P875, DOI 10.1109/TASL.2011.2167610; Stolcke A, 2006, P IEEE ICASSP; Swietojanski P, 2012, P IEEE SLT; Thomas S, 2012, P IEEE ICASSP; Thomas Samuel, 2010, P INTERSPEECH; Vu N T, 2010, P INTERSPEECH	28	7	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7319	7323				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507097		
J	Ren, XF; Ramanan, D			IEEE	Ren, Xiaofeng; Ramanan, Deva			Histograms of Sparse Codes for Object Detection	2013 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2013	Portland, OR	IEEE, IEEE Comp Soc			POSE ESTIMATION; ALGORITHM	Object detection has seen huge progress in recent years, much thanks to the heavily-engineered Histograms of Oriented Gradients (HOG) features. Can we go beyond gradients and do better than HOG? We provide an affirmative answer by proposing and investigating a sparse representation for object detection, Histograms of Sparse Codes (HSC). We compute sparse codes with dictionaries learned from data using K-SVD, and aggregate per-pixel sparse codes to form local histograms. We intentionally keep true to the sliding window framework (with mixtures and parts) and only change the underlying features. To keep training (and testing) efficient, we apply dimension reduction by computing SVD on learned models, and adopt supervised training where latent positions of roots and parts are given externally e. g. from a HOG-based detector. By learning and using local representations that are much more expressive than gradients, we demonstrate large improvements over the state of the art on the PASCAL benchmark for both root-only and part-based models.	[Ren, Xiaofeng] Amazon Com, Seattle, WA 98109 USA	Ren, XF (reprint author), Amazon Com, Seattle, WA 98109 USA.	xiaofenr@amazon.com; dramanan@ics.uci.edu					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Azizpour H., 2012, ECCV; Bo L., 2011, ADV NEURAL INFORM PR, V24; Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI DOI 10.1145/1282280.1282340; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Carreira J., 2012, ECCV; Coates A., 2011, DOC AN REC ICDAR 201, P440; Dalal N, 2005, PROC CVPR IEEE, P886; Dikmen M., 2012, CVPR; Divvala Santosh K., 2012, ECCV WORKSH PARTS AT; Dollar P., 2009, BRIT MACH VIS C, P1; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb P. F., DISCRIMINATIVELY TRA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Girshick R., 2011, ADV NEURAL INFORM PR, V24; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hussain S. U., 2010, BRIT MACH VIS C; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23, P1090; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25; Leibe B., 2004, WORKSH STAT LEARN CO, V1, P17; Malisiewicz T, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P89, DOI 10.1109/ICCV.2011.6126229; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; Parikh D, 2011, PROC CVPR IEEE, P1425, DOI 10.1109/CVPR.2011.5995450; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; Pirsiavash H., 2009, ADV NEURAL INFORM PR, V22; Ren X., 2012, ADV NEURAL INFORM PR, V25; Rubinstein R, 2008, TECHNICAL REPORT; Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205; Song H.O., 2012, ECCV; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Vijayanarasimhan S., 2011, COMP VIS PATT REC CV, P1401; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yang JC, 2009, PROC CVPR IEEE, P1794; Yang Y, 2011, PROC CVPR IEEE, P1385; Zhu X., 2012, BMVC; Zhu XX, 2012, PROC CVPR IEEE, P2879	36	7	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-0-7695-4989-7	PROC CVPR IEEE			2013							3246	3253		10.1109/CVPR.2013.417		8	Computer Science, Artificial Intelligence	Computer Science	BA0ER	WOS:000331094303041		
J	Su, H; Li, G; Yu, D; Seide, F			IEEE	Su, Hang; Li, Gang; Yu, Dong; Seide, Frank			ERROR BACK PROPAGATION FOR SEQUENCE TRAINING OF CONTEXT-DEPENDENT DEEP NETWORKS FOR CONVERSATIONAL SPEECH TRANSCRIPTION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc				We investigate back-propagation based sequence training of Context-Dependent Deep-Neural-Network HMMs, or CD-DNN-HMMs, for conversational speech transcription. Theoretically, sequence training integrates with back-propagation in a straight-forward manner. However, we find that to get reasonable results, heuristics are needed that point to a problem with lattice sparseness: The model must be adjusted to the updated numerator lattices by additional iterations of frame-based cross-entropy (CE) training; and to avoid distortions from "runaway" models, we can either add artificial silence arcs to the denominator lattices, or smooth the sequence objective with the frame-based one (F-smoothing). With the 309h Switchboard training set, the MMI objective achieves a relative word-error rate reduction of 11-15% over CE for matched test sets, and 10-17% for mismatched ones. This includes gains of 4-7% from realigned CE iterations. The BMMI and sMBR objectives gain less. With 2000h of data, gains are 2-9% after realigned CE iterations. Using GPGPUs, MMI is about 70% slower than CE training.	[Su, Hang; Li, Gang; Seide, Frank] Microsoft Res Asia, Beijing 100080, Peoples R China	Su, H (reprint author), Microsoft Res Asia, 5 Danling St, Beijing 100080, Peoples R China.	suhang3240@gmail.com; ganl@microsoft.com; dongyu@microsoft.com; fseide@microsoft.com					Albesano D., 2006, INT JOINT C NEUR NET; Dahl G., 2011, IEEE T SPEECH AUDIO; Fiscus J., 2000 NIST EVALUATION; Gibson M., 2006, P INTERSPEECH; Godfrey John J., 1997, SWITCHBOARD 1 RELEAS; GOPALAKRISHNAN PS, 1991, IEEE T INFORM THEORY, V37, P107, DOI 10.1109/18.61108; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, INT 2012; Kaiser J., 2000, ICSLP; Kingsbury B., 2009, ICASSP; Kingsbury B., 2012, INTERSPEECH; Martens J., 2010, ICML; Mohamed A. r., 2010, INTERSPEECH; Povey D., 2008, ICASSP; Povey D., 2003, THESIS CAMBRIDGE U; Rashid R., 2012, MICROSOFT RES SHOWS; Renals S., 1994, IEEE T SPEECH AU JAN; Rosenblatt F., 1961, PRINCIPLES NEURODYNA; Rumelhart D., 1986, NATURE, V323; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Seide F., 2011, P ASRU WAIK VILL; Seide Frank, 2011, INTERSPEECH; Wang G., 2011, INT 2011; Yu D., 2013, ICASSP; Yu D., 2010, NIPS WORKSH DEEP LEA; Zheng J., 2005, EUROSPEECH	26	7	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							6664	6668				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611506166		
S	Suk, HI; Shen, DG		Sakuma, I; Barillot, C; Navab, N		Suk, Heung-Il; Shen, Dinggang			Deep Learning-Based Feature Representation for AD/MCI Classification	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2013, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	16th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)	SEP 22-26, 2013	Nagoya, JAPAN	Nagoya Convent & Visitors Bur, Murata Sci Fdn, Daiko Fdn, Japan Soc Comp Aided Surg, Sci Council Japan, Nagoya Univ, Informat & Commun Headquarters, Nagoya Univ, Grad Sch Informat Sci	Nagoya Univ		ALZHEIMERS-DISEASE; NEURAL-NETWORKS	In recent years, there has been a great interest in computer-aided diagnosis of Alzheimer's Disease (AD) and its prodromal stage, Mild Cognitive Impairment (MCI). Unlike the previous methods that consider simple low-level features such as gray matter tissue volumes from MRI, mean signal intensities from PET, in this paper, we propose a deep learning-based feature representation with a stacked auto-encoder. We believe that there exist latent complicated patterns, e.g., non-linear relations, inherent in the low-level features. Combining latent information with the original low-level features helps build a robust model for AD/MCI classification with high diagnostic accuracy. Using the ADNI dataset, we conducted experiments showing that the proposed method is 95.9%, 85.0%, and 75.8% accurate for AD, MCI, and MCI-converter diagnosis, respectively.	[Suk, Heung-Il] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27515 USA	Suk, HI (reprint author), Univ N Carolina, Dept Radiol, Chapel Hill, NC 27515 USA.	hsuk@med.unc.edu; dgshen@med.unc.edu					Alzheimer's Association, 2012, ALZHEIMERS DEMENT, V8, P131, DOI DOI 10.1016/J.JALZ.2012.02.001; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Davatzikos C, 2011, NEUROBIOL AGING, V32, DOI DOI 10.1016/J.NEUROBIOLAGING.2010.05.023; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101; Hinrichs C, 2011, NEUROIMAGE, V55, P574, DOI 10.1016/j.neuroimage.2010.10.081; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kabani N.J., 1998, NEUROIMAGE, V7, pS717; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Nordberg A, 2010, NAT REV NEUROL, V6, P78, DOI 10.1038/nrneurol.2009.217; Perrin RJ, 2009, NATURE, V461, P916, DOI 10.1038/nature08538; Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069	13	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-40763-5; 978-3-642-40762-8	LECT NOTES COMPUT SC			2013	8150						583	590				8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BB3LH	WOS:000342835100072		
J	Wu, TF; Butko, NJ; Ruvolo, P; Whitehill, J; Bartlett, MS; Movellan, JR				Wu, Tingfan; Butko, Nicholas J.; Ruvolo, Paul; Whitehill, Jacob; Bartlett, Marian S.; Movellan, Javier R.			Multilayer Architectures for Facial Action Unit Recognition	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						Action unit recognition; facial expression recognition; Gabor energy filters (GEFs); local binary patterns (LBPs)	SUPPORT VECTOR MACHINES; LOCAL BINARY PATTERNS	In expression recognition and many other computer vision applications, the recognition performance is greatly improved by adding a layer of nonlinear texture filters between the raw input pixels and the classifier. The function of this layer is typically known as feature extraction. Popular filter types for this layer are Gabor energy filters (GEFs) and local binary patterns (LBPs). Recent work [1] suggests that adding a second layer of nonlinear filters on top of the first layer may be beneficial. However, it is unclear what is the best architecture of layers and selection of filters. In this paper, we present a thorough empirical analysis of the performance of single-layer and dual-layer texture-based approaches for action unit recognition. For the single hidden layer case, GEFs perform consistently better than LBPs, which may be due to their robustness to jitter and illumination noise as well as to their ability to encode texture at multiple resolutions. For dual-layer case, we confirm that, while small, the benefit of adding this second layer is reliable and consistent across data sets. Interestingly for this second layer, LBPs appear to perform better than GEFs.	[Wu, Tingfan; Butko, Nicholas J.; Ruvolo, Paul; Whitehill, Jacob; Bartlett, Marian S.; Movellan, Javier R.] Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA	Wu, TF (reprint author), Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA.	ting@mplab.ucsd.edu; nick@mplab.ucsd.edu; paul@mplab.ucsd.edu; jake@mplab.ucsd.edu; marni@mplab.ucsd.edu; movellan@mplab.ucsd.edu			NSF [IIS-0905622, IIS-1002840-SoCS, NSF IIS-INT2-0808767]	Support for this work was provided by NSF Grants IIS-0905622, IIS-1002840-SoCS and NSF IIS-INT2-0808767. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. This paper was recommended by Associate Editor M. Pantic.	Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007; Banziger T., 2010, BLUEPRINT AFFECTIVE, P271; Bartlett MS, 1999, P 6 JOINT S NEUR COM, P8; Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Ciresan D. C., 2011, IDSIA0111 USISUPSI; De Boner J., 1998, P 1997 C ADV NEUR IN, P866; De la Torre F, 2011, GUIDE VISUAL ANAL HU; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Eckhardt M, 2009, INT J PATTERN RECOGN, V23, P379, DOI 10.1142/S0218001409007247; Ekman P., 1978, FACIAL ACTION CODING; Frank M., 2010, M3 DATABASE SP UNPUB; Freund Y., 1995, COMPUTATIONAL LEARNI, V904, P23, DOI DOI 10.1007/3-540-59119-2_166; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285; Green DM, 1966, SIGNAL DETECTION THE; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kanade T., 2000, P 4 IEEE INT C AUT F, V4, P46; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Littlewort G., IMAGE VISION COMPUTI, V24, P615; Littlewort G., 2008, P AUT FAC GEST REC, P1; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Lucey P., 2010, P 3 INT WORKSH CVPR, P94, DOI DOI 10.1109/CVPRW.2010.5543262; Lucey P, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), DOI 10.1109/DICTA.2010.53; Marks TK, 2010, IEEE T PATTERN ANAL, V32, P348, DOI 10.1109/TPAMI.2008.278; Mason SJ, 2002, Q J ROY METEOR SOC, V128, P2145, DOI 10.1256/003590002320603584; Michel P., 2003, P 5 INT C MULT INT, P258; Moore S., 2009, P BMVC; Movellan J. R., 2005, OPTIMAL CONTROL DYNA; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pantic M., 2005, P IEEE INT C MULT EX, P317; Ryan A, 2009, P IEEE INT CARN C SE, P172; Senechal T, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), DOI 10.1109/FG.2011.5771363; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998; Sun X., 2008, P IEEE C CYB INT SYS, P158; Susskind J., 2009, AFFECT COMPUT EMOTIO, P421; Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710; Valstar Michel F, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), DOI 10.1109/FG.2011.5771374; Vapnik V. N., 1998, STAT LEARNING THEORY; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42; Wu T., 2011, P IEEE INT C AUT FAC, P889; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110	48	7	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419			IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2012	42	4			SI		1027	1038		10.1109/TSMCB.2012.2195170		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	008ZL	WOS:000308995000006		
J	Montavon, G; Braun, ML; Muller, KR				Montavon, Gregoire; Braun, Mikio L.; Mueller, Klaus-Robert			Kernel Analysis of Deep Networks	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						deep networks; kernel principal component analysis; representations	RECEPTIVE-FIELDS; FEATURE SPACES; VISUAL-CORTEX; ARCHITECTURE; RECOGNITION	When training deep networks it is common knowledge that an efficient and well generalizing representation of the problem is formed. In this paper we aim to elucidate what makes the emerging representation successful. We analyze the layer-wise evolution of the representation in a deep network by building a sequence of deeper and deeper kernels that subsume the mapping performed by more and more layers of the deep network and measuring how these increasingly complex kernels fit the learning problem. We observe that deep networks create increasingly better representations of the learning problem and that the structure of the deep network controls how fast the representation of the task is formed layer after layer.	[Montavon, Gregoire; Braun, Mikio L.; Mueller, Klaus-Robert] Tech Univ Berlin, Machine Learning Grp, D-10587 Berlin, Germany; [Mueller, Klaus-Robert] Univ Calif Los Angeles, Inst Pure & Appl Math, Los Angeles, CA 90095 USA	Montavon, G (reprint author), Tech Univ Berlin, Machine Learning Grp, Franklinstr 28-29, D-10587 Berlin, Germany.	GMONTAVON@CS.TU-BERLIN.DE; MIKIO@CS.TU-BERLIN.DE; KLAUS-ROBERT.MUELLER@TU-BERLIN.DE	Muller, Klaus/C-3196-2013				Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop C., 1996, NEURAL NETWORKS PATT; BOTTOU L, 1991, P NEURO NIMES; Bousquet O, 2004, LECT NOTES ARTIF INT, V3176, P169; Braun ML, 2008, J MACH LEARN RES, V9, P1875; Braun ML, 2006, J MACH LEARN RES, V7, P2303; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Cho Y., 2009, ADV NEURAL INFORM PR, V22, P342; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Erhan D, 2010, J MACH LEARN RES, V11, P625; GENEVIEVE B, 1998, LECT NOTES COMPUTER, V1524; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Krizhevsky A., 2009, LEARNING MULTIPLE LA; LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1989, CONNECTIONISM PERSPE; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; MONTAVON G, 2010, ADV NEURAL INFORM PR, V23, P1678; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Nair V., 2010, P 27 INT C MACH LEAR, P807; Ratsch G., 1999, NEURAL NETWORKS SIGN, V9, P41, DOI DOI 10.1109/NNSP.1999.788121; Ringach DL, 2002, J NEUROPHYSIOL, V88, P455, DOI 10.1152/jn.00881.2001; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2007, P INT C ART INT STAT, V11; Scholkopf B., 2002, LEARNING KERNELS SUP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Serre T, 2005, COMP VIS PATT REC 20, V2, P994; Smale S, 2010, FOUND COMPUT MATH, V10, P67, DOI 10.1007/s10208-009-9049-1; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; WIBISONO A, 2010, LEARNING INVARIANCE	38	7	7	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2011	12						2563	2581				19	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	862OQ	WOS:000298102900002		
J	Wulsin, DF; Gupta, JR; Mani, R; Blanco, JA; Litt, B				Wulsin, D. F.; Gupta, J. R.; Mani, R.; Blanco, J. A.; Litt, B.			Modeling electroencephalography waveforms with semi-supervised deep belief nets: fast classification and anomaly measurement	JOURNAL OF NEURAL ENGINEERING			English	Article							HIGH-FREQUENCY OSCILLATIONS; SEIZURE ONSET; EEG PATTERNS; AUTOMATED DETECTION; EPILEPTIC ACTIVITY; SPIKE DETECTION; CRITICALLY-ILL; SCALP EEG; ALGORITHM; FEATURES	Clinical electroencephalography (EEG) records vast amounts of human complex data yet is still reviewed primarily by human readers. Deep belief nets (DBNs) are a relatively new type of multi-layer neural network commonly tested on two-dimensional image data but are rarely applied to times-series data such as EEG. We apply DBNs in a semi-supervised paradigm to model EEG waveforms for classification and anomaly detection. DBN performance was comparable to standard classifiers on our EEG dataset, and classification time was found to be 1.7-103.7 times faster than the other high-performing classifiers. We demonstrate how the unsupervised step of DBN learning produces an autoencoder that can naturally be used in anomaly measurement. We compare the use of raw, unprocessed data-a rarity in automated physiological waveform analysis-with hand-chosen features and find that raw data produce comparable classification and better anomaly measurement performance. These results indicate that DBNs and raw data inputs may be more effective for online automated EEG waveform recognition than other common techniques.	[Wulsin, D. F.; Gupta, J. R.; Blanco, J. A.; Litt, B.] Univ Penn, Dept Bioengn, Philadelphia, PA 19104 USA; [Mani, R.; Litt, B.] Univ Penn, Dept Neurol, Philadelphia, PA 19104 USA	Wulsin, DF (reprint author), Univ Penn, Dept Bioengn, Philadelphia, PA 19104 USA.	wulsin@seas.upenn.edu					Abu-Hanna A, 2003, ARTIF INTELL MED, V29, P5, DOI 10.1016/S0933-3657(03)00047-2; Agarwal R, 1998, ELECTROEN CLIN NEURO, V107, P44, DOI 10.1016/S0013-4694(98)00009-1; ALARCON G, 1995, ELECTROEN CLIN NEURO, V94, P326, DOI 10.1016/0013-4694(94)00286-T; BENGIO Y, 2007, LARGE SCALE KERNEL M, V1, P1; Bishop C. M., 2006, INFORM SCI STAT, V16; Blanco JA, 2010, J NEUROPHYSIOL, V104, P2900, DOI 10.1152/jn.01082.2009; Breiman L., 1984, WADSWORTH STAT PROBA; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chong DJ, 2005, J CLIN NEUROPHYSIOL, V22, P79, DOI 10.1097/01.WNP.0000158699.78529.AF; D'Alessandro M, 2005, CLIN NEUROPHYSIOL, V116, P506, DOI 10.1016/j.clinph.2004.11.014; Demsar J, 2001, INT J MED INFORM, V63, P41, DOI 10.1016/S1386-5056(01)00170-8; Ebersole JS, 2003, CURRENT PRACTICE CLI; Esteller R, 2001, P ANN INT IEEE EMBS, V23, P1707; Flanagan D, 2003, CLIN NEUROPHYSIOL, V114, P38, DOI 10.1016/S1388-2457(02)00296-1; Gardner AB, 2007, CLIN NEUROPHYSIOL, V118, P1134, DOI 10.1016/j.clinph.2006.12.019; GARDNER AB, 2006, J MACH LEARN RES, V7, P1044; Gerber PA, 2008, J CLIN NEUROPHYSIOL, V25, P241, DOI 10.1097/WNP.0b013e318182ed67; GOTMAN J, 1976, ELECTROEN CLIN NEURO, V41, P513, DOI 10.1016/0013-4694(76)90063-8; Greene BR, 2008, CLIN NEUROPHYSIOL, V119, P1248, DOI 10.1016/j.clinph.2008.02.001; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1007/s10462-004-4304-y; LAROCHELLE H, 2007, P 24 INT C MACH LEAR, P480; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; LIU A, 1992, ELECTROEN CLIN NEURO, V82, P30, DOI 10.1016/0013-4694(92)90179-L; Lofhede J, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/1/016007; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Osorio I, 1998, EPILEPSIA, V39, P615, DOI 10.1111/j.1528-1157.1998.tb01430.x; PIETILA T, 1994, ELECTROEN CLIN NEURO, V90, P438, DOI 10.1016/0013-4694(94)90134-1; Polat K, 2007, APPL MATH COMPUT, V187, P1017, DOI 10.1016/j.amc.2006.09.022; Qu H, 1997, IEEE T BIO-MED ENG, V44, P115; Raina R., 2009, INT C MACH LEARN, P1; Shah AK, 2006, NEUROCRIT CARE, V5, P124, DOI 10.1385/Neurocrit.Care2006;05:124-133; van Putten MJAM, 2005, CLIN NEUROPHYSIOL, V116, P2480, DOI 10.1016/j.clinph.2005.06.017; Ver Hoef Lawrence, 2010, J Clin Neurophysiol, V27, P12, DOI 10.1097/WNP.0b013e3181cb4294; Wilson SB, 2002, CLIN NEUROPHYSIOL, V113, P1873, DOI 10.1016/S1388-2457(02)00297-3; WULSIN D, 2010, 9 INT C MACH LEARN A, V9, P436	38	7	7	IOP PUBLISHING LTD	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1741-2560			J NEURAL ENG	J. Neural Eng.	JUN	2011	8	3							036015	10.1088/1741-2560/8/3/036015		13	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	769RE	WOS:000291035100027	21525569	
J	Montufar, G; Ay, N				Montufar, Guido; Ay, Nihat			Refinements of Universal Approximation Results for Deep Belief Networks and Restricted Boltzmann Machines	NEURAL COMPUTATION			English	Article								We improve recently published results about resources of restricted Boltzmann machines (RBM) and deep belief networks (DBN) required to make them universal approximators. We show that any distribution p on the set {0, 1}(n) of binary vectors of length n can be arbitrarily well approximated by an RBM with k - 1 hidden units, where k is the minimal number of pairs of binary vectors differing in only one entry such that their union contains the support set of p. In important cases this number is half the cardinality of the support set of p (given in Le Roux & Bengio, 2008). We construct a DBN with 2(n)/2(n-b), b similar to log n, hidden layers of width n that is capable of approximating any distribution on {0, 1}(n) arbitrarily well. This confirms a conjecture presented in Le Roux and Bengio (2010).	[Montufar, Guido; Ay, Nihat] Max Planck Inst Math Sci, D-04103 Leipzig, Germany; [Ay, Nihat] Santa Fe Inst, Santa Fe, NM 87501 USA	Montufar, G (reprint author), Max Planck Inst Math Sci, D-04103 Leipzig, Germany.	montufar@mis.mpg.de; nay@mis.mpg.de	Montufar Cuartas, Guido F./	Montufar Cuartas, Guido F./0000-0002-0131-2669			Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; MONTUFAR G, 2010, MIXTURE DECOMP UNPUB; Sard A., 1942, B AM MATH SOC, V48, P883, DOI 10.1090/S0002-9904-1942-07811-6; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661	6	7	7	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667	1530-888X		NEURAL COMPUT	Neural Comput.	MAY	2011	23	5					1306	1319		10.1162/NECO_a_00113		14	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	747PU	WOS:000289332700008	21299421	
S	Bengio, Y; Delalleau, O		Kivinen, J; Szepesvari, C; Ukkonen, E; Zeugmann, T		Bengio, Yoshua; Delalleau, Olivier			On the Expressive Power of Deep Architectures	ALGORITHMIC LEARNING THEORY	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	22nd International Conference on Algorithmic Learning Theory (ALT 2011)	OCT 05-07, 2011	Espoo, FINLAND	Aalto Univ, Sch Sci, Dept Informat & Comp Sci, Univ Helsinki, Dept Comp Sci, Helsinki Inst Informat Technol, Algodan - Finish Ctr Excellence Algorithm Data Anal, Journal Artificial Intelligence			DENOISING AUTOENCODERS; REPRESENTATIONS; NETWORKS	Deep architectures are families of functions corresponding to deep circuits. Deep Learning algorithms are based on parametrizing such circuits and tuning their parameters so as to approximately optimize some training objective. Whereas it was thought too difficult to train deep architectures, several successful algorithms have been proposed in recent years. We review some of the theoretical motivations for deep architectures, as well as some of their practical successes, and propose directions of investigations to address some of the remaining challenges.	[Bengio, Yoshua; Delalleau, Olivier] Univ Montreal, Dept IRO, Montreal, PQ H3C 3J7, Canada	Bengio, Y (reprint author), Univ Montreal, Dept IRO, Montreal, PQ H3C 3J7, Canada.						Attwell D, 2001, J CEREBR BLOOD F MET, V21, P1133; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2010, COMPUT INTELL, V26, P449, DOI 10.1111/j.1467-8640.2010.00366.x; Bengio Y., 2011, WORKSH UNS TRANSF LE; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2005, ADV NEURAL INFORMATI, V17, P129; Bengio Y., 2011, JMLR W CP; Bengio Y., 2011, LEARN WORKSH FORT LA; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Braverman M, 2011, COMMUN ACM, V54, P108, DOI 10.1145/1924421.1924446; Breuleux O, 2011, NEURAL COMPUT, V23, P2058, DOI 10.1162/NECO_a_00158; Bromley J., 1993, ADV PATTERN RECOGNIT, P669; Caruana R., 1995, ADV NEURAL INFORMATI, V7, P657; Chopra S., 2005, P COMP VIS PATT REC; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Desjardins G., 2010, P 13 INT C ART INT S, P145; Erhan D, 2010, J MACH LEARN RES, V11, P625; Freund Y., 1994, UCSCCRL9425; Glorot X., 2011, P 28 INT C MACH LEAR; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646; Gutmann M., 2010, P 13 INT C ART INT S; HADSELL R, 2008, P INT ROB SYST IROS, P628; Hadsell R., 2006, P IEEE C COMP VIS PA, P1735; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hinton G. E., 1986, P 8 ANN C COGN SCI S, P1; Hinton G. E., 1994, ADV NEURAL INFORMATI, V6, P3; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; HINTON GE, 1999, P 9 INT C ART NEUR N, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1984, TRCMUCS84119; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; JARRETT K, 2009, P IEEE INT C COMP VI, P2146; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; Kavukcuoglu K., 2008, CBLLTR20081201 NYU C; Kingma D., 2010, ADV NEURAL INFORM PR, V23, P1126; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Larochelle H., 2009, P 12 INT C ART INT S, P312; Lee Honglak, 2009, P 26 INT C MACH LEAR; Lennie P, 2003, CURR BIOL, V13, P493, DOI 10.1016/S0960-9822(03)00135-0; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Mesnil G., 2011, WORKSH UNS TRANSF LE; Mobahi H., 2009, P 26 ANN INT C MACH, P737; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osindero S, 2008, ADV NEURAL INFORM PR, V20, P1121; Poon H., 2011, LEARN WORKSH FL FORT; Poon H., 2010, NIPS WORKSH DEEP LEA; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; Rifai S., 2011, P 28 INT C MACH LEAR; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2007, P 2007 WORKSH INF RE; Salakhutdinov R., 2010, MITCSAILTR2010037; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Welling M., 2009, P 25 C UNC ART INT U; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341; Yao A. C., 1985, P 26 ANN IEEE S FDN, P1; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI 10.1080/17442509908834179	71	7	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-24411-7	LECT NOTES ARTIF INT			2011	6925						18	36				19	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BBF23	WOS:000306675000003		
J	van Gerven, MAJ; de Lange, FP; Heskes, T				van Gerven, Marcel A. J.; de Lange, Floris P.; Heskes, Tom			Neural Decoding with Hierarchical Generative Models	NEURAL COMPUTATION			English	Article							HUMAN BRAIN ACTIVITY; FUNCTIONAL-ANATOMY; MENTAL-IMAGERY; NATURAL IMAGES; VISUAL-CORTEX; RECONSTRUCTION; ACTIVATION; ALGORITHM; PATTERNS	Recent research has shown that reconstruction of perceived images based on hemodynamic response as measured with functional magnetic resonance imaging (fMRI) is starting to become feasible. In this letter, we explore reconstruction based on a learned hierarchy of features by employing a hierarchical generative model that consists of conditional restricted Boltzmann machines. In an unsupervised phase, we learn a hierarchy of features from data, and in a supervised phase, we learn how brain activity predicts the states of those features. Reconstruction is achieved by sampling from the model, conditioned on brain activity. We show that by using the hierarchical generative model, we can obtain good-quality reconstructions of visual images of handwritten digits presented during an fMRI scanning session.	[van Gerven, Marcel A. J.; Heskes, Tom] Radboud Univ Nijmegen, Inst Comp & Informat Sci, NL-6525 AJ Nijmegen, Netherlands; [van Gerven, Marcel A. J.; de Lange, Floris P.; Heskes, Tom] Radboud Univ Nijmegen, Inst Brain Cognit & Behav, NL-6525 EN Nijmegen, Netherlands	van Gerven, MAJ (reprint author), Radboud Univ Nijmegen, Inst Comp & Informat Sci, NL-6525 AJ Nijmegen, Netherlands.	marcelge@cs.ru.nl; florisdelange@gmail.com; t.heskes@science.ru.nl	de Lange, Floris/D-2860-2009; van Gerven, Marcel/D-7800-2012; Heskes, Tom/A-1443-2010	de Lange, Floris/0000-0002-6730-1452; 	Dutch technology foundation STW [07050]; Netherlands Organization for Scientific Research NWO [451.09.001, 639.023.604]; Netherlands Ministry of Economic Affairs; Netherlands Ministry of Education, Culture and Science	We gratefully acknowledge the support of the Dutch technology foundation STW (project number 07050), the Netherlands Organization for Scientific Research NWO (Veni grant 451.09.001 and Vici grant 639.023.604), and the BrainGain Smart Mix Programme of the Netherlands Ministry of Economic Affairs and the Netherlands Ministry of Education, Culture and Science.	Barlow HB, 1961, SENSORY COMMUNICATIO; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; Fujiwara Y., 2009, ADV NEURAL INFORM PR, V22, P576; Hassabis D, 2009, CURR BIOL, V19, P546, DOI 10.1016/j.cub.2009.02.033; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; HEDGE J, 2000, J NEUROSCI, V20, P1; Helmholtz H., 1867, HDB PHYSL OPTIK; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Kay KN, 2009, NAT NEUROSCI, V12, P245, DOI 10.1038/nn0309-245; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Koch C, 2004, QUEST CONSCIOUSNESS; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Mellet E, 1998, NEUROIMAGE, V8, P129, DOI 10.1006/nimg.1998.0355; Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876; Miyawaki Y, 2008, NEURON, V60, P915, DOI 10.1016/j.neuron.2008.11.004; Naselaris T, 2009, NEURON, V63, P902, DOI 10.1016/j.neuron.2009.09.006; Rao R. P., 1998, NAT NEUROSCI, V2, P79; ROLAND PE, 1995, CEREB CORTEX, V5, P79, DOI 10.1093/cercor/5.1.79; SALAKHUTDINOV R, 2007, P 24 INT C MACH LEAR; Sejnowski T. J, 1983, P IEEE C COMP VIS PA; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Stokes M, 2009, J NEUROSCI, V29, P1565, DOI 10.1523/JNEUROSCI.4657-08.2009; TAYLOR GW, 2006, ADV NEURAL INFORM PR, V20; Thirion B, 2006, NEUROIMAGE, V33, P1104, DOI 10.1016/j.neuroimage.2006.06.062; van Gerven MAJ, 2010, NEUROIMAGE, V50, P150, DOI 10.1016/j.neuroimage.2009.11.064; Vinckier F, 2007, NEURON, V55, P143, DOI 10.1016/j.neuron.2007.05.031; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; WELLING M, 2002, ICANN 02, P351; ZEKI S, 1988, NATURE, V335, P311, DOI 10.1038/335311a0	35	7	7	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	DEC	2010	22	12					3127	3142		10.1162/NECO_a_00047		16	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	677PI	WOS:000284003900005	20858128	
S	Fischer, A; Igel, C		Diamantaras, K; Duch, W; Iliadis, LS		Fischer, Asja; Igel, Christian			Empirical Analysis of the Divergence of Gibbs Sampling Based Learning Algorithms for Restricted Boltzmann Machines	ARTIFICIAL NEURAL NETWORKS (ICANN 2010), PT III	Lecture Notes in Computer Science		English	Proceedings Paper	20th International Conference on Artificial Neural Networks	SEP 15-18, 2010	Thessaloniki, GREECE	European Neural Network Soc, Aristotle Univ Thessaloniki, Univ Macedonia, Technol Educ Inst Thess, Hellenic Int Univ, Democritus Univ Thrace, Alexander TEI Thessaloniki		Unsupervised Learning; Restricted Boltzmann Machines; Contrastive Divergence; Gibbs Sampling	CONTRASTIVE DIVERGENCE; NETWORKS	Learning algorithms relying on Gibbs sampling based stochastic approximations of the log-likelihood gradient have become a common way to train Restricted Boltzmann Machines (RBMs). We study three of these methods, Contrastive Divergence (CD) and its refined variants Persistent CD (PCD) and Fast PCD (FPCD). As the approximations are biased, the maximum of the log-likelihood is not necessarily obtained. Recently, it has been shown that CD, PCD, and FPCD can even lead to a steady decrease of the log-likelihood during learning. Taking artificial data sets from the literature we study these divergence effects in more detail. Our results indicate that the log-likelihood seems to diverge especially if the target distribution is difficult to learn for the RBM. The decrease of the likelihood can not be detected by an increase of the reconstruction error, which has been proposed as a stopping criterion for CD learning. Weight-decay with a carefully chosen weight-decay-parameter can prevent divergence.	[Fischer, Asja; Igel, Christian] Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany	Fischer, A (reprint author), Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany.	asja.fischer@ini.rub.de; christian.igel@ini.rub.de	Igel, Christian/B-4091-2009	Igel, Christian/0000-0003-2868-0856			ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Carreira-Perpi nan M.A., 2005, 10 WORKSH ART INT ST, P59; Desjardins G., 2010, J MACHINE LEARNING R, V9, P145; FISCHER A, 2009, FRONTIERS COMPUTATIO; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1986, PARALLEL DISTRIBUTED, V1, P282; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; MacKay D., 2002, INFORM THEORY INFERE; MacKay D.J.C., 2001, FAILURES ONE STEP LE; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, V22, P1598; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Tieleman T., 2008, INT C MACH LEARN ICM, P1064; Tieleman T., 2009, INT C MACH LEARN ICM, P1033; Younes L., 1991, LECT NOTES MONOGRAPH; Yuille AL, 2004, ADV NEURAL INFORM PR, V17, P1593	21	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15824-7	LECT NOTES COMPUT SC			2010	6354		III				208	217				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BUS87	WOS:000290245400026		
J	Byrne, P; Becker, S				Byrne, Patrick; Becker, Suzanna			A principle for learning egocentric-allocentric transformation	NEURAL COMPUTATION			English	Article							HIPPOCAMPAL PLACE CELLS; PARIETAL CORTEX; SPATIAL MEMORY; ENTORHINAL CORTEX; VISUAL SPACE; NEURONS; NAVIGATION; MODEL; DIRECTION; LESIONS	Numerous single-unit recording studies have found mammalian hippocampal neurons that fire selectively for the animal's location in space, independent of its orientation. The population of such neurons, commonly known as place cells, is thought to maintain an allocentric, or orientation-independent, internal representation of the animal's location in space, as well as mediating long-term storage of spatial memories. The fact that spatial information from the environment must reach the brain via sensory receptors in an inherently egocentric, or viewpoint-dependent, fashion leads to the question of how the brain learns to transform egocentric sensory representations into allocentric ones for long-term memory storage. Additionally, if these long-term memory representations of space are to be useful in guiding motor behavior, then the reverse transformation, from allocentric to egocentric coordinates, must also be learned. We propose that orientation-invariant representations can be learned by neural circuits that follow two learning principles: minimization of reconstruction error and maximization of representational temporal inertia. Two different neural network models are presented that adhere to these learning principles, the first by direct optimization through gradient descent and the second using a more biologically realistic circuit based on the restricted Boltzmann machine (Hinton, 2002; Smolensky, 1986). Both models lead to orientation-invariant representations, with the latter demonstrating place-cell-like responses when trained on a linear track environment.	[Becker, Suzanna] McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada	Becker, S (reprint author), McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada.	pbyrne@yorku.ca; becker@mcmaster.ca	Byrne, Patrick/A-4546-2008; Becker, Suzanna/H-8197-2013				ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; BARNES CA, 1988, TRENDS NEUROSCI, V11, P163, DOI 10.1016/0166-2236(88)90143-9; Barry C, 2006, REV NEUROSCIENCE, V17, P71; Battaglia FP, 2004, J NEUROSCI, V24, P4541, DOI 10.1523/JNEUROSCI.4896-03.2004; Becker S, 2001, ADV NEUR IN, V13, P96; Bohbot VD, 1998, NEUROPSYCHOLOGIA, V36, P1217, DOI 10.1016/S0028-3932(97)00161-9; Burgess N, 2001, PHILOS T R SOC B, V356, P1493, DOI 10.1098/rstb.2001.0948; Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9; Byrne P, 2007, PSYCHOL REV, V114, P340, DOI 10.1037/0033-295X.114.2.340; Byrne P, 2004, NEURAL COMPUT, V16, P1851, DOI 10.1162/0899766041336468; Chafee MV, 1998, J NEUROPHYSIOL, V79, P2919; Crane J, 2005, HIPPOCAMPUS, V15, P216, DOI 10.1002/hipo.20043; Deneve S, 2001, NAT NEUROSCI, V4, P826, DOI 10.1038/90541; Egorov AV, 2002, NATURE, V420, P173, DOI 10.1038/nature01171; Ekstrom AD, 2003, NATURE, V425, P184, DOI 10.1038/nature01964; Foster DJ, 2006, NATURE, V440, P680, DOI 10.1038/nature04587; FUNAHASHI S, 1989, J NEUROPHYSIOL, V61, P331; Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721; Hartley T, 2000, HIPPOCAMPUS, V10, P369, DOI 10.1002/1098-1063(2000)10:4<369::AID-HIPO3>3.0.CO;2-0; Hasselmo ME, 2004, PROG BRAIN RES, V145, P207, DOI 10.1016/S0079-6123(03)45015-2; Hasselmo ME, 1999, TRENDS COGN SCI, V3, P351, DOI 10.1016/S1364-6613(99)01365-0; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; JAHR CE, 1990, J NEUROSCI, V10, P3178; JARRARD LE, 1993, BEHAV NEURAL BIOL, V60, P9, DOI 10.1016/0163-1047(93)90664-4; Kali S, 2000, J NEUROSCI, V20, P7463; King JA, 2002, HIPPOCAMPUS, V12, P811, DOI 10.1002/hipo.10070; KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054; LeCun Y., 1985, P COGNITIVA, V85, P599; Martin PD, 2002, HIPPOCAMPUS, V12, P465, DOI 10.1002/hipo.10021; Matsumura N, 1999, J NEUROSCI, V19, P2381; Mazzoni P, 1991, CEREB CORTEX, V1, P293, DOI 10.1093/cercor/1.4.293; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; MCNAUGHTON BL, 1983, EXP BRAIN RES, V52, P41; Milner AD, 1999, P ROY SOC B-BIOL SCI, V266, P2225; MORRIS RGM, 1982, NATURE, V297, P681, DOI 10.1038/297681a0; MULLER RU, 1994, J NEUROSCI, V14, P7235; OKEEFE J, 1976, EXP NEUROL, V51, P78, DOI 10.1016/0014-4886(76)90055-8; OKeefe J, 1996, NATURE, V381, P425, DOI 10.1038/381425a0; O'Keefe J, 2005, HIPPOCAMPUS, V15, P853, DOI 10.1002/hipo.20115; ONO T, 1993, J NEUROPHYSIOL, V70, P1516; PARKER D, 1985, 1 MIT CTR COMP RES E; Pouget A, 1997, J COGNITIVE NEUROSCI, V9, P222, DOI 10.1162/jocn.1997.9.2.222; Redish AD, 2000, NEUROCOMPUTING, V32, P235, DOI 10.1016/S0925-2312(00)00169-7; Reidmiller M, 1993, P IEEE INT C NEUR NE, P586; Rolls ET, 2006, PROG NEUROBIOL, V79, P1, DOI 10.1016/j.pneurobio.2006.04.005; Rolls ET, 1995, HIPPOCAMPUS, V5, P409, DOI 10.1002/hipo.450050504; Salinas E, 1996, P NATL ACAD SCI USA, V93, P11956, DOI 10.1073/pnas.93.21.11956; Sargolini F, 2006, SCIENCE, V312, P758, DOI 10.1126/science.1125572; SHARP PE, 1991, PSYCHOBIOLOGY, V19, P103; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1; Snyder LH, 1998, NATURE, V394, P887; Taube JS, 1998, PROG NEUROBIOL, V55, P225, DOI 10.1016/S0301-0082(98)00004-5; Trullier O, 1997, PROG NEUROBIOL, V51, P483, DOI 10.1016/S0301-0082(96)00060-3; Werbos P., 1974, REGRESSION NEW TOOLS; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Xing J, 2000, J COGNITIVE NEUROSCI, V12, P601, DOI 10.1162/089892900562363; ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0	58	7	7	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	MAR	2008	20	3					709	737		10.1162/neco.2007.10-06-361		29	Computer Science, Artificial Intelligence	Computer Science	260YH	WOS:000253045800005	18045016	
S	Ahmed, A; Yu, K; Xu, W; Gong, YH; Xing, E		Forsyth, D; Torr, P; Zisserman, A		Ahmed, Amr; Yu, Kai; Xu, Wei; Gong, Yihong; Xing, Eric			Training Hierarchical Feed-Forward Visual Recognition Models Using Transfer Learning from Pseudo-Tasks	COMPUTER VISION - ECCV 2008, PT III, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	10th European Conference on Computer Vision (ECCV 2008)	OCT 12-18, 2008	Marseille, FRANCE	INRIA, Ville Marseille, Reg Province Alpes-Cote Azur, Deutsch Telekom Lab, Microsoft Res, Orange, INRIA, Microsoft Res, EADS, TOSHIBA, Springer				Building visual recognition models that adapt across different domains is a challenging task for computer vision. While feature-learning machines in the form of hierarchial feed-forward models (e.g., convolutional neural networks) showed promise in this direction, they are still difficult to train especially when few training examples are available. In this paper, we present a framework for training hierarchical feed-forward models for visual recognition, using transfer learning from pseudo tasks. These pseudo tasks are automatically constructed from data without supervision and comprise a set of simple pattern-matching operations. We show that these pseudo tasks induce an informative inverse-Wishart prior on the functional behavior of the network, offering an effective way to incorporate useful prior knowledge into the network training. In addition to being extremely simple to implement, and adaptable across different domains with little or no extra tuning, our approach achieves promising results on challenging visual recognition tasks, including object recognition, gender recognition, and ethnicity recognition.	[Ahmed, Amr; Xing, Eric] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Ahmed, A (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, DOI 10.1016/0885-064X(90)90006-Y; Ando RK, 2005, J MACH LEARN RES, V6, P1817; BALUJA S, 2007, INT J COMPUTER VISIO; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BOSCH A, 2008, ICCV 2007; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; FEIFEI L, 2006, INT C DEV LEARN ICDL; FUKUSHIMA K, 1982, PATTER RECOGNITION; GRAUMAN K, 2005, CVPR 2005; GRIFFIN G, 2007, 041366 CALITECH; GUTTA S, 2000, IEEE T NEURAL NETWOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Lazebnik S., 2006, CVPR 2006; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe D G, 2004, INT J COMPUTER VISIO, V60; MOGHADDAN B, 2002, IEEE T PATTERN ANAL; MUTCH J, 2006, CVPR 2006; PHILIPS PJ, 2006, P 7 INT C AUT FAC GE; Ranzato M., 2007, CVPR 2007; SERRE T, 2005, CVPR 2005; Torralba A., 2007, IEEE PAMI; WESTON RCJ, 2008, ICML	23	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88689-1	LECT NOTES COMPUT SC			2008	5304		3				69	82				14	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIM02	WOS:000260659800006		
J	Molfese, DL; Molfese, VJ; Beswick, J; Jacobi-Vessels, J; Molfese, PJ; Key, APF; Starkey, G				Molfese, Dennis L.; Molfese, Victoria J.; Beswick, Jennifer; Jacobi-Vessels, Jill; Molfese, Peter J.; Key, Alexandra P. F.; Starkey, Gillian			Dynamic Links Between Emerging Cognitive Skills and Brain Processes	DEVELOPMENTAL NEUROPSYCHOLOGY			English	Article; Proceedings Paper	Annual Meeting of the Society-for-the-Scientific-Studies-of-Reading	JUL 06-08, 2006	Vancouver, CANADA	Soc Sci Studies Reading			EVENT-RELATED POTENTIALS; LATER LANGUAGE-DEVELOPMENT; FAMILIAL RISK; CORTICAL RESPONSES; GENETIC RISK; DYSLEXIA; CHILDREN; INFANTS; DISCRIMINATION; ELECTROPHYSIOLOGY	The goal of the present study was to investigate whether advanced cognitive skills in one domain impact the neural processing of unrelated skills in a different cognitive domain. This question is related to the broader issue of how cognitive-neurodevelopment proceeds as different skills are mastered. To address this goal, event-related brain potentials (ERPs) were used to assess linkages between cognitive skills of preschool children as reflected in their performance on a pre-reading screening test (Get Ready To Read) and their neural responses while engaged in a geometric shape matching task. Sixteen children (10 males) participated in this study. The children ranged from 46 to 60 months (SD = 4.36 months). ERPs were recorded using a 128-electrode high-density array while children attended to presentations of matched and mismatched shapes (triangles, circles, or squares). ERPs indicated that children with more advanced pre-reading skills discriminated between matched and mismatched shapes earlier than children with poorer pre-readings skills. The earlier discrimination effect observed in the advanced group was localized over the occipital electrode sites whereas in the Low Group such effects were present over frontal, parietal, and occipital sites. Modeled magnetic resonance images (MRIs) of the ERP component sources identified differences in neural generators between the two groups. Both sets of findings support the hypothesis that processing in a poorer-performing group is more distributed temporally and spatially across the scalp, and reflects the engagement of more distributed brain regions. These findings are seen as support for a theory of neural-cognitive development that is advanced in the present article.	[Molfese, Dennis L.; Starkey, Gillian] Univ Louisville, Birth Defects Ctr, Louisville, KY 40292 USA; [Molfese, Victoria J.; Beswick, Jennifer; Jacobi-Vessels, Jill] Univ Louisville, Ctr Res Early Childhood, Louisville, KY 40292 USA; [Molfese, Peter J.] Univ Houston, Dept Psychol, Houston, TX 77004 USA; [Key, Alexandra P. F.] Vanderbilt Univ, Kennedy Ctr Res Human Dev, Nashville, TN USA; [Key, Alexandra P. F.] Vanderbilt Univ, Dept Speech & Hearing Sci, Nashville, TN USA	Molfese, DL (reprint author), Univ Louisville, Birth Defects Ctr, Hlth Sci Campus,501 S Preston St,Suite 301, Louisville, KY 40292 USA.	dlmolfese@mac.com					Allison T., 1986, PSYCHOPHYSIOLOGY SYS, P5; Allison T, 1999, CEREB CORTEX, V9, P415, DOI 10.1093/cercor/9.5.415; ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3; [Anonymous], 2001, NO CHILD LEFT; Beauducel A, 2003, J NEUROSCI METH, V124, P103, DOI 10.1016/S0165-0270(02)00381-3; Benasich AA, 2002, DEV PSYCHOBIOL, V40, P278, DOI 10.1002/dev.10032; Blakemore SJ, 2006, J CHILD PSYCHOL PSYC, V47, P296, DOI 10.1111/j.1469-7610.2006.01611.x; Bokura H, 2001, CLIN NEUROPHYSIOL, V112, P2224, DOI 10.1016/S1388-2457(01)00691-5; Boyer Ernest L., 1991, READY LEARN MANDATE; Casey BJ, 2000, BIOL PSYCHOL, V54, P241, DOI 10.1016/S0301-0511(00)00058-2; CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10; CHAPMAN RM, 1995, BRAIN COGNITION, V27, P288, DOI 10.1006/brcg.1995.1024; CTB/McGraw-Hill, 1990, DEV SKILLS CHECKLIST; Curran T, 1999, NEUROPSYCHOLOGIA, V37, P771, DOI 10.1016/S0028-3932(98)00133-X; Denton K., 2002, CHILDRENS READING MA; Elliott CD., 1990, DIFFERENTIAL ABILITY; Espy KA, 2004, ANN DYSLEXIA, V54, P9, DOI 10.1007/s11881-004-0002-3; Ferree TC, 2000, IEEE T BIO-MED ENG, V47, P1584, DOI 10.1109/10.887939; Germino-Hausken E., 2000, 2000070 NCES; Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3; Guttorm TK, 2001, J LEARN DISABIL-US, V34, P534, DOI 10.1177/002221940103400606; Hebb DO, 1949, ORG BEHAV NEUROPSYCH; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOLCOMB PJ, 1985, PSYCHOPHYSIOLOGY, V22, P656, DOI 10.1111/j.1469-8986.1985.tb01663.x; Hopf JM, 2002, J NEUROPHYSIOL, V88, P2088, DOI 10.1152/jn.00860.2001; Key APF, 2005, DEV NEUROPSYCHOL, V27, P183, DOI 10.1207/s15326942dn2702_1; Kline R. B., 1989, J PSYCHOEDUCATIONAL, V7, P4, DOI 10.1177/073428298900700101; Leppanen PHT, 1999, NEUROREPORT, V10, P969, DOI 10.1097/00001756-199904060-00014; Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4; McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.1111/j.1467-8624.1996.tb01831.x; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V2; Menendez RGD, 2004, NEUROIMAGE, V21, P527, DOI 10.1016/j.neuroimage.2003.09.051; Molfese DL, 2006, J LEARN DISABIL-US, V39, P352, DOI 10.1177/00222194060390040801; Molfese DL, 2001, LEARN DISABILITY Q, V24, P177, DOI 10.2307/1511242; MOLFESE DL, 1985, INFANT BEHAV DEV, V8, P197, DOI 10.1016/S0163-6383(85)80006-0; Molfese DL, 1997, DEV NEUROPSYCHOL, V13, P135; Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287; MOLFESE V, 1992, J PSYCHOEDUC ASSESS, V10, P47, DOI 10.1177/073428299201000104; Molfese VJ, 2006, J LEARN DISABIL-US, V39, P296, DOI 10.1177/00222194060390040401; Molfese VJ, 2001, J LEARN DISABIL-US, V34, P545, DOI 10.1177/002221940103400607; *NAT ED GOALS PAN, 1998, NAT ED GOALS REP BUI; Nunez P.L., 1981, ELECT FIELDS BRAIN N; OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4; Ownby R. L., 1988, J PSYCHOEDUCATIONAL, V6, P331, DOI 10.1177/073428298800600401; Pihko E, 1999, NEUROREPORT, V10, P901, DOI 10.1097/00001756-199904060-00002; Pugh KR, 2000, MENT RETARD DEV D R, V6, P207, DOI 10.1002/1098-2779(2000)6:3<207::AID-MRDD8>3.0.CO;2-P; Rockstroh B., 1982, SLOW BRAIN POTENTIAL; Ryynanen ORM, 2006, IEEE T BIO-MED ENG, V53, P1851, DOI 10.1109/TBME.2006.873744; SATTERFIELD JH, 1990, BIOL PSYCHIAT, V28, P879, DOI 10.1016/0006-3223(90)90569-N; Sowell ER, 2002, DEV MED CHILD NEUROL, V44, P4, DOI 10.1017/S0012162201001591; Starkey P, 2004, EARLY CHILD RES Q, V19, P99, DOI 10.1016/j.ecresq.2004.01.002; TAYLOR MJ, 1990, PSYCHOPHYSIOLOGY, V27, P318, DOI 10.1111/j.1469-8986.1990.tb00389.x; THORNDIKE RM, 1990, J PSYCHOEDUC ASSESS, V8, P223; Toga AW, 2006, TRENDS NEUROSCI, V29, P148, DOI 10.1016/j.tins.2006.01.007; WESTBERG L, 2007, 16 ANN NAT C FAM LIT; WHITEHURST G, 2001, DO PRESCHOOLERS NEED; WOOD CC, 1984, ELECTROEN CLIN NEURO, V59, P249, DOI 10.1016/0168-5597(84)90064-9	57	7	7	PSYCHOLOGY PRESS	HOVE	27 CHURCH RD, HOVE BN3 2FA, EAST SUSSEX, ENGLAND	8756-5641			DEV NEUROPSYCHOL	Dev. Neuropsychol.		2008	33	6					682	706	PII 905443351	10.1080/87565640802418647		25	Psychology, Developmental; Psychology; Psychology, Experimental	Psychology	371SR	WOS:000260852100003	19005911	
J	Langkvist, M; Karlsson, L; Loutfi, A				Langkvist, Martin; Karlsson, Lars; Loutfi, Amy			A review of unsupervised feature learning and deep learning for time-series modeling	PATTERN RECOGNITION LETTERS			English	Review						Time-series; Unsupervised feature learning; Deep learning	DELAY NEURAL-NETWORKS; ELECTRONIC NOSE SYSTEM; BOLTZMANN MACHINES; PREDICTION; CLASSIFICATION; IDENTIFICATION; RECOGNITION; OLFACTION; QUALITY; SPEECH	This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems. While these techniques have shown promise for modeling static data, such as computer vision, applying them to time-series data is gaining increasing attention. This paper overviews the particular challenges present in time-series data and provides a review of the works that have either applied time-series data to unsupervised feature learning algorithms or alternatively have contributed to modifications of feature learning algorithms to take into account the challenges present in time-series data. (C) 2014 Elsevier B.V. All rights reserved.	[Langkvist, Martin; Karlsson, Lars; Loutfi, Amy] Univ Orebro, Sch Sci & Technol, Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden	Langkvist, M (reprint author), Univ Orebro, Sch Sci & Technol, Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden.	martin.langkvist@oru.se; lars.karlsson@oru.se; amy.loutfi@oru.se	Loutfi, Amy/	Loutfi, Amy/0000-0002-3122-693X			Agrawal J.G., 2013, INT J ADV RES ELECT, V2, P1360; Amft O, 2011, IEEE INT SYM WRBL CO, P83, DOI 10.1109/ISWC.2011.37; Atsalakis GS, 2009, EXPERT SYST APPL, V36, P5932, DOI 10.1016/j.eswa.2008.07.006; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2012, TECHNICAL REPORT; Bengio Y., 2007, 1312 U MONTR DEP IRO; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Bengio Y., 2013, CORR; Bennetts V.H., 2011, FRONT NEUROENG, V4; Bhattacharya N, 2008, SENSOR ACTUAT B-CHEM, V131, P110, DOI 10.1016/j.snb.2007.12.032; Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007; Bottou L., 2010, P 19 INT C COMP STAT, P177, DOI 10.1007/978-3-7908-2604-3_16; Brand M, 2000, COMP GRAPH, P183; Carmona M, 2006, EUR FOOD RES TECHNOL, V223, P96, DOI 10.1007/s00217-005-0144-5; Chang K., 2010, P 11 INT C MUS INF R, P387; Chen Bo, 2010, NIPS 2010 DEEP LEARN; Cheung YM, 2001, NEUROCOMPUTING, V41, P145, DOI 10.1016/S0925-2312(00)00358-1; Chiappa S., 2009, ADV NEURAL INFORM PR, V21, P297; Coates A., 2010, ENGINEERING, P1; Dahl G., 2010, ADV NEURAL INFORM PR, V23, P469; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dalal N., 2005, CVPR; Dieleman S., 2011, AUDIO BASED MUSIC CL; Dietterich T. G., 2002, SSSPR, V2396, P15, DOI 10.1007/3-540-70659-3_2; Duckett T, 2001, IEEE INT CONF ROBOT, P4017; Dutta Ritaban, 2002, Biomed Eng Online, V1, P4, DOI 10.1186/1475-925X-1-4; Erhan D, 2010, J MACH LEARN RES, V11, P625; FAMA EF, 1965, J BUS, V38, P34, DOI 10.1086/294743; Flash T, 2005, CURR OPIN NEUROBIOL, V15, P660, DOI 10.1016/j.conb.2005.10.011; Furui S, 2004, IEEE T SPEECH AUDI P, V12, P401, DOI 10.1109/TSA.2004.828699; Gardner J, 1999, ELECT NOSES PRINCIPL; Gardner JW, 2000, SENSOR ACTUAT B-CHEM, V70, P19, DOI 10.1016/S0925-4005(00)00548-7; Gardner JW, 2000, SENSOR ACTUAT B-CHEM, V69, P336, DOI 10.1016/S0925-4005(00)00482-2; Gartner T., 2003, ACM SIGKDD EXPLORATI, V5, P49, DOI 10.1145/959242.959248; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Gleicher M., 2000, SIGGRAPH COMPUT GRAP, V33, P51; Goldberger AL, 2000, CIRCULATION, V101, pE215; Grassias FS, 1998, J GRAPHICS TOOLS, V3, P29; Graves A., 2013, 38 INT C AC SPEECH S; Grosse R., 2007, C UNC ART INT UAI; Gruhl D., 2005, P 11 ACM SIGKDD INT, P78, DOI 10.1145/1081870.1081883; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; Hamel P., 2010, 11 INT SOC MUS INF R; Henaff M., 2011, P INT S MUS INF RETR; Hines EL, 1999, IEE P-CIRC DEV SYST, V146, P297, DOI 10.1049/ip-cds:19990670; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hinton G.E., 2010, LECT NOTES COMPUTER, V7700, P599; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hsieh TJ, 2011, APPL SOFT COMPUT, V11, P2510, DOI 10.1016/j.asoc.2010.09.007; Humphrey EJ, 2013, J INTELL INF SYST, V41, P461, DOI 10.1007/s10844-013-0248-5; Husken M, 2003, NEUROCOMPUTING, V50, P223, DOI 10.1016/S0925-2312(01)00706-8; Hyvarinen A, 2010, NEUROIMAGE, V49, P257, DOI 10.1016/j.neuroimage.2009.08.028; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Hyvarinen A, 2003, J OPT SOC AM A, V20, P1237, DOI 10.1364/JOSAA.20.001237; Jaitly N, 2011, INT CONF ACOUST SPEE, P5884; Kamyshanska H., 2013, P 30 INT C MACH LEAR, P720; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; Keogh E., 2002, P 8 ACM SIGKDD INT C, P102; Kim SS, 1998, NEUROCOMPUTING, V20, P253, DOI 10.1016/S0925-2312(98)00018-6; Lafferty J., 2001, MACH LEARN, V951, P282; Langkvist M., 2012, ADV ARTIF NEURAL SYS, DOI [10.1155/2012/107046, DOI 10.1155/2012/107046]; Langkvist M., 2012, NIPS WORKSH DEEP LEA; Langkvist M, 2013, SENSORS-BASEL, V13, P1578, DOI 10.3390/s130201578; Langkvist M., 2011, NIPS WORKSH DEEP LEA; Le Q.V., 2011, COMPUTER VISION PATT; LeCun Y., 2010, P INT S CIRC SYST IS; Lee H., 2009, 26 INT C MACH LEARN; Lee H., 2009, ADV NEURAL INFORM PR, V22, P1096; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Li Y., 2010, P INT S COMP INT DES, V1, P211; Lin XW, 2009, EXPERT SYST APPL, V36, P7313, DOI 10.1016/j.eswa.2008.09.049; Lowe D.G., 1999, ICCV; Luenberger David, 1979, INTRO DYNAMIC SYSTEM; Lutkepohl H., 2005, NEW INTRO MULTIPLE T; Malkiel B., 2003, J ECON PERSPECT, V17, DOI DOI 10.2307/3216840; Markov K, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1929; Martens J., 2012, LECT NOTES COMPUTER, V7700; Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Memisevic R., 2007, IEEE COMP SOC C COMP, P1; Mirowski P, 2009, LECT NOTES ARTIF INT, V5782, P128; Mirowski P., 2007, ASS ADV ART INT C; Mirowski PW, 2008, MACHINE LEARN SIGN P, P244, DOI 10.1109/MLSP.2008.4685487; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2010, INT CONF ACOUST SPEE, P4354, DOI 10.1109/ICASSP.2010.5495651; Nam J., 2012, LEARNING SPARSE FEAT, P565; Nam J., 2012, THESIS STANFORD U; Nanopoulos A., 2001, INT J COMPUTER RES, V10, P49; Ngiam J, 2011, P 28 INT C MACH LEAR; Osuna G.R., 2003, HDB MACHINE OLFACTIO, P105; Pan S.J., 2010, IEEE T KNOWL DATA EN, V22, P56; Pan W., 2009, P 26 ANN INT C MACH, P785; Parris ES, 1996, INT CONF ACOUST SPEE, P685, DOI 10.1109/ICASSP.1996.543213; Pascanu R., 2012, ABS12115063 CORR; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; Raina R., 2007, P 24 INT C MACH LEAR; Ranzato M., 2010, P INT C ART INT STAT; Ranzato M., 2010, P COMP VIS PATT REC; Ranzato M. A., 2006, ADV NEURAL INFORM PR; Saxe AM, 2011, P 28 INT C MACH LEAR; Schoerkhuber C., 2010, 7 SOUND MUS COMP C; Smith E., 2005, ADV NEURAL INFORM PR; Stavens D, 2010, PROC CVPR IEEE, P1649, DOI 10.1109/CVPR.2010.5539773; Sugiyama M., 1991, IEEE INT S CIRC SYST, V1, P582; Sutskever I., 2008, ADV NEURAL INFORM PR, V20, P1601; Sutskever I., 2006, TECHNICAL REPORT; Sutskever I, 2012, THESIS U TORONTO; Taylor G., 2010, P EUR C COMP VIS ECC; Taylor G., 2009, P 26 INT C MACH LEAR; Taylor G., 2007, ADV NEURAL INFORM PR; Taylor G.W., 2009, THESIS U TORONTO; Trincavelli M, 2010, IEEE T BIO-MED ENG, V57, P2884, DOI 10.1109/TBME.2010.2049492; Tsai CF, 2010, DECIS SUPPORT SYST, V50, P258, DOI 10.1016/j.dss.2010.08.028; Tucker C. A., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), DOI 10.1109/IJCNN.1999.836246; van Kasteren T., 2008, P 14 ANN C ADV SCH C; Vembu S, 2012, SENSOR ACTUAT B-CHEM, V174, P535, DOI 10.1016/j.snb.2012.06.070; Vito S.D., 2007, SENSOR ACTUAT B-CHEM, V124, P309; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Wang D., 2013, INT J INF ED TECHNOL, V3; Wang J. M., 2007, INT C MACH LEARN, P975; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Wulsin D, 2011, J NEURAL ENG, V8, P1741; Yamazaki A, 2001, ELECTRON LETT, V37, P1466, DOI 10.1049/el:20010985; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; Zampolli S, 2004, SENSOR ACTUAT B-CHEM, V101, P39, DOI [10.1016/j.snb.2004.02.024, 10.1016/j.sub.2004.02.024]; Zhang HX, 2003, SENSOR ACTUAT B-CHEM, V96, P385, DOI 10.1016/S0925-4005(03)00574-4; Zhu XT, 2008, EXPERT SYST APPL, V34, P3043, DOI 10.1016/j.eswa.2007.06.023; Zou W., 2011, NIPS 2011 WORKSH DEE	135	6	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN 1	2014	42						11	24		10.1016/j.patrec.2014.01.008		14	Computer Science, Artificial Intelligence	Computer Science	AD7NQ	WOS:000333451300002		
J	Huang, X; Lu, QK; Zhang, LP				Huang, Xin; Lu, Qikai; Zhang, Liangpei			A multi-index learning approach for classification of high-resolution remotely sensed images over urban areas	ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING			English	Article						High spatial resolution; Classification; SVM; Morphological; Texture; Feature extraction	MULTISCALE SEGMENTATION; MULTISPECTRAL IMAGERY; SATELLITE IMAGERY; SENSING IMAGES; EXTRACTION; FEATURES; INDEX; OBJECTS	In recent years, it has been widely agreed that spatial features derived from textural, structural, and object-based methods are important information sources to complement spectral properties for accurate urban classification of high-resolution imagery. However, the spatial features always refer to a series of parameters, such as scales, directions, and statistical measures, leading to high-dimensional feature space. The high-dimensional space is almost impractical to deal with considering the huge storage and computational cost while processing high-resolution images. To this aim, we propose a novel multi-index learning (MIL) method, where a set of low-dimensional information indices is used to represent the complex geospatial scenes in high-resolution images. Specifically, two categories of indices are proposed in the study: (1) Primitive indices (PI): High-resolution urban scenes are represented using a group of primitives (e.g., building/shadow/vegetation) that are calculated automatically and rapidly; (2) Variation indices (VI): A couple of spectral and spatial variation indices are proposed based on the 3D wavelet transformation in order to describe the local variation in the joint spectral-spatial domains. In this way, urban landscapes can be decomposed into a set of low-dimensional and semantic indices replacing the high-dimensional but low-level features (e.g., textures). The information indices are then learned via the multi-kernel support vector machines. The proposed MIL method is evaluated using various high-resolution images including GeoEye-1, QuickBird, WorldView-2, and ZY-3, as well as an elaborate comparison to the state-of-the-art image classification algorithms such as object-based analysis, and spectral-spatial approaches based on textural and morphological features. It is revealed that the MIL method is able to achieve promising results with a low-dimensional feature space, and, provide a practical strategy for processing large-scale high-resolution images. (C) 2014 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS) Published by Elsevier B.V. All rights reserved.	[Huang, Xin; Lu, Qikai; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China	Huang, X (reprint author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.	huang_whu@163.com	Huang, Xin/C-8355-2014; Ma, Lei/I-4597-2014		Natural Science Foundation of China [41101336, 91338111]; Program for New Century Excellent Talents in University of China [NCET-11-0396]; Foundation for the Author of National Excellent Doctoral Dissertation of PR China (FANEDD) [201348]	This work was supported in part by the Natural Science Foundation of China (41101336 and 91338111), in part by the Program for New Century Excellent Talents in University of China (NCET-11-0396), and in part by the Foundation for the Author of National Excellent Doctoral Dissertation of PR China (FANEDD) under Grant 201348.	Aguera F, 2008, ISPRS J PHOTOGRAMM, V63, P635, DOI 10.1016/j.isprsjprs.2008.03.003; Awrangjeb M, 2010, ISPRS J PHOTOGRAMM, V65, P457, DOI 10.1016/j.isprsjprs.2010.06.001; Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004; Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P2587, DOI 10.1109/TGRS.2006.875360; Dell'Acqua F, 2009, ISPRS J PHOTOGRAMM, V64, P482, DOI 10.1016/j.isprsjprs.2008.09.006; Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035; Guo L, 2011, ISPRS J PHOTOGRAMM, V66, P56, DOI 10.1016/j.isprsjprs.2010.08.007; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang X, 2008, IEEE T GEOSCI REMOTE, V46, P4173, DOI 10.1109/TGRS.2008.2002577; Huang X, 2007, IEEE GEOSCI REMOTE S, V4, P260, DOI 10.1109/LGRS.2006.890540; Huang X, 2012, IEEE J-STARS, V5, P161, DOI 10.1109/JSTARS.2011.2168195; Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912; Huang X, 2011, PHOTOGRAMM ENG REM S, V77, P721; Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006; Inglada J, 2007, ISPRS J PHOTOGRAMM, V62, P236, DOI 10.1016/j.isprsjprs.2007.05.011; Jing LH, 2012, ISPRS J PHOTOGRAMM, V70, P88, DOI 10.1016/j.isprsjprs.2012.04.003; Johnson B, 2011, ISPRS J PHOTOGRAMM, V66, P473, DOI 10.1016/j.isprsjprs.2011.02.006; Liu Y, 2012, ISPRS J PHOTOGRAMM, V68, P144, DOI 10.1016/j.isprsjprs.2012.01.007; Mathieu R, 2007, LANDSCAPE URBAN PLAN, V81, P179, DOI 10.1016/j.landurbplan.2006.11.009; Ouma YO, 2008, ISPRS J PHOTOGRAMM, V63, P333, DOI 10.1016/j.isprsjprs.2007.10.006; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pesaresi M, 2008, IEEE J-STARS, V1, P180, DOI 10.1109/JSTARS.2008.2002869; Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239; Pingel J.T., 2013, ISPRS J PHOTOGRAMM, V77, P21; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Reis S, 2011, ISPRS J PHOTOGRAMM, V66, P652, DOI 10.1016/j.isprsjprs.2011.04.006; Richards J. A., 1999, REMOTE SENSING DIGIT, P240; Sebari I, 2013, ISPRS J PHOTOGRAMM, V79, P171, DOI 10.1016/j.isprsjprs.2013.02.006; Tuia D, 2010, IEEE T GEOSCI REMOTE, V48, P3780, DOI 10.1109/TGRS.2010.2049496; Tuia D, 2011, IEEE J-STSP, V5, P606, DOI 10.1109/JSTSP.2011.2139193; Tzotsos A, 2011, ISPRS J PHOTOGRAMM, V66, P2, DOI 10.1016/j.isprsjprs.2010.07.001; Waske B, 2007, IEEE T GEOSCI REMOTE, V45, P3858, DOI 10.1109/TGRS.2007.898446; Yang GJ, 2013, ISPRS J PHOTOGRAMM, V77, P79, DOI 10.1016/j.isprsjprs.2012.11.008; Yoo HY, 2009, INT J REMOTE SENS, V30, P6219, DOI 10.1080/01431160902842359; Zhang LP, 2006, IEEE T GEOSCI REMOTE, V44, P2950, DOI 10.1109/TGRS.2006.876704; Zhang XL, 2013, ISPRS J PHOTOGRAMM, V78, P15, DOI 10.1016/j.isprsjprs.2013.01.002	36	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0924-2716	1872-8235		ISPRS J PHOTOGRAMM	ISPRS-J. Photogramm. Remote Sens.	APR	2014	90						36	48		10.1016/j.isprsjprs.2014.01.008		13	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	AE6FW	WOS:000334087000004		
J	Neftci, E; Das, S; Pedroni, B; Kreutz-Delgado, K; Cauwenberghs, G				Neftci, Emre; Das, Srinjoy; Pedroni, Bruno; Kreutz-Delgado, Kenneth; Cauwenberghs, Gert			Event-driven contrastive divergence for spiking neuromorphic systems	FRONTIERS IN NEUROSCIENCE			English	Article						synaptic plasticity; neuromorphic cognition; Markov chain monte carlo; recurrent neural network; generative model	NEURAL-NETWORKS; FIRE NEURONS; RECOGNITION; INFERENCE; COGNITION; RATES; MODEL; VLSI	Restricted Boltzmann Machines (RBMs) and Deep Belief Networks have been demonstrated to perform efficiently in a variety of applications, such as dimensionality reduction, feature learning, and classification. Their implementation on neuromorphic hardware platforms emulating large-scale networks of spiking neurons can have significant advantages from the perspectives of scalability, power dissipation and real-time interfacing with the environment. However, the traditional RBM architecture and the commonly used training algorithm known as Contrastive Divergence (CD) are based on discrete updates and exact arithmetics which do not directly map onto a dynamical neural substrate. Here, we present an event-driven variation of CD to train a RBM constructed with Integrate & Fire (I&F) neurons, that is constrained by the limitations of existing and near future neuromorphic hardware platforms. Our strategy is based on neural sampling, which allows us to synthesize a spiking neural network that samples from a target Boltzmann distribution. The recurrent activity of the network replaces the discrete steps of the CD algorithm, while Spike Time Dependent Plasticity (STDP) carries out the weight updates in an online, asynchronous fashion. We demonstrate our approach by training an RBM composed of leaky l&F neurons with STDP synapses to learn a generative model of the MNIST hand-written digit dataset, and by testing it in recognition, generation and cue integration tasks. Our results contribute to a machine learning-driven approach for synthesizing networks of spiking neurons capable of carrying out practical, high-level functionality.	[Neftci, Emre; Das, Srinjoy; Kreutz-Delgado, Kenneth; Cauwenberghs, Gert] Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA; [Das, Srinjoy; Kreutz-Delgado, Kenneth] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; [Pedroni, Bruno; Cauwenberghs, Gert] Univ Calif San Diego, Dept Bioengn, La Jolla, CA 92093 USA	Neftci, E (reprint author), Univ Calif San Diego, Inst Neural Computat, 9500 Gilman Dr 0523, La Jolla, CA 92093 USA.	nemre@ucsd.edu	Neftci, Emre/	Neftci, Emre/0000-0002-0332-3273	National Science Foundation [NSF EFRI-1137279, CCF-1317560]; Office of Naval Research [ONR MURI 14-13-1-0205]; Swiss National Science Foundation [PA00P2_142058]	This work was partially funded by the National Science Foundation (NSF EFRI-1137279, CCF-1317560), the Office of Naval Research (ONR MURI 14-13-1-0205), and the Swiss National Science Foundation (PA00P2_142058).	Amit DJ, 1997, CEREB CORTEX, V7, P237, DOI 10.1093/cercor/7.3.237; Arthur J. V., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252637; Bartolozzi C, 2007, NEURAL COMPUT, V19, P2581, DOI 10.1162/neco.2007.19.10.2581; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergstra J., 2010, P PYTH SCI COMP C SC, V4; Brea J, 2013, J NEUROSCI, V33, P9565, DOI 10.1523/JNEUROSCI.4098-12.2013; Buesing L, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002211; Carreira-Perpinan M. A., 2005, ARTIF INTELL STAT, V17; Chicca E., 2001, ARGESIM REPORTS, P468; Corneil D., 2012, INT JOINT C NEUR NET, P2990, DOI [10.1109/IJCNN.2012.6252780, DOI 10.1109/IJCNN.2012.6252780]; Cox D. R., 1962, RENEWAL THEORY, V1; Cruz-Albrecht JM, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/384011; Deiss Sr, 1998, PULSED NEURAL NETWORKS, P157; Deneve S, 2008, NEURAL COMPUT, V20, P91, DOI 10.1162/neco.2008.20.1.91; Deneve S, 2001, NAT NEUROSCI, V4, P826, DOI 10.1038/90541; Destexhe A., 1998, METHODS NEURONAL MOD, P1; Doya K., 2006, BAYESIAN BRAIN PROBA, DOI [10.7551/mitpress/9780262042383.001.0001, DOI 10.7551/MITPRESS/9780262042383.001.0001]; Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Fusi S, 1999, NEURAL COMPUT, V11, P633, DOI 10.1162/089976699300016601; Gardiner C. W., 2012, HDB STOCHASTIC METHO, DOI [10.1007/978-3-662-02377-8, DOI 10.1007/978-3-662-02377-8]; Gerstner W., 2002, SPIKING NEURON MODEL, DOI [10.1017/CBO9780511815706, DOI 10.1017/CBO9780511815706]; Goodman Dan, 2008, Front Neuroinform, V2, P5, DOI 10.3389/neuro.11.005.2008; Griffiths TL, 2010, TRENDS COGN SCI, V14, P357, DOI 10.1016/j.tics.2010.05.004; Haykin S., 1998, NEURAL NETWORKS COMP; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073; Joshi S., 2010, 12 INT WORKSH CELL N, P1, DOI [10.1109/CNNA.2010.5430296, DOI 10.1109/CNNA.2010.5430296]; Kempter R, 2001, NEURAL COMPUT, V13, P2709, DOI 10.1162/089976601317098501; Kuzum D., 2011, NANO LETT, V12, P2179, DOI DOI 10.1021/NL201040Y; Le Q. V., 2011, ARXIV11126209; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Liu SC, 2010, CURR OPIN NEUROBIOL, V20, P288, DOI 10.1016/j.conb.2010.03.007; Mead C., 1989, ANALOG VLSI NEURAL S, DOI [10.1007/978-1-4613-1639-8, DOI 10.1007/978-1-4613-1639-8]; Merolla P., 2010, CORR; Murray JF, 2007, NEURAL COMPUT, V19, P2301, DOI 10.1162/neco.2007.19.9.2301; Neftci E, 2013, P NATL ACAD SCI USA, V110, pE3468, DOI 10.1073/pnas.1212083110; Neftci EO, 2012, NEURAL COMPUT, V24, P1669, DOI 10.1162/NECO_a_00293; O'Connor P, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00178; Park J., 2012, CIRC SYST ISCAS 2012, P707, DOI [10.1109/ISCAS.2012.6272133, DOI 10.1109/ISCAS.2012.6272133]; Pedroni B., 2013, INT JOINT C NEUR NET; Petrovici M. A., 2013, ARXIV13113211; Plesser HE, 2000, NEURAL COMPUT, V12, P367, DOI 10.1162/089976600300015835; Renart A, 2003, NEURON, V38, P473, DOI 10.1016/S0896-6273(03)00255-1; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Schemmel J, 2010, IEEE INT SYMP CIRC S, P1947, DOI 10.1109/ISCAS.2010.5536970; Serrano-Gotarredona T, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00002; Silver R, 2007, J NEUROSCI, V27, P11807, DOI 10.1523/JNEUROSCI.3575-07.2007; Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932; Tang Y., 2010, P 27 ANN INT C MACH, P1055; vanVreeswijk C, 1996, SCIENCE, V274, P1724; Yu T., 2012, BIOM CIRC SYST C BIO, P21, DOI [10.1109/BioCAS.2012.6418479, DOI 10.1109/BIOCAS.2012.6418479]	55	6	6	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-453X			FRONT NEUROSCI-SWITZ	Front. Neurosci.	JAN 30	2014	7								272	10.3389/fnins.2013.00272		14	Neurosciences	Neurosciences & Neurology	AW7BC	WOS:000346418400001		
J	Zorzi, M; Testolin, A; Stoianov, IP				Zorzi, Marco; Testolin, Alberto; Stoianov, Ivilin P.			Modeling language and cognition with deep unsupervised learning: a tutorial overview	FRONTIERS IN PSYCHOLOGY			English	Article						neural networks; connectionist modeling; deep learning; hierarchical generative models; unsupervised learning; visual word recognition	PROBABILISTIC MODELS; OBJECT RECOGNITION; GENERATIVE MODELS; BAYESIAN MODELS; READING ALOUD; CONNECTIONIST; REPRESENTATIONS; WORDS; ORGANIZATION; ACQUISITION	Deep unsupervised learning in stochastic recurrent neural networks with many layers of hidden units is a recent breakthrough in neural computation research. These networks build a hierarchy of progressively more complex distributed representations of the sensory data by fitting a hierarchical generative model. In this article we discuss the theoretical foundations of this approach and we review key issues related to training, testing and analysis of deep networks for modeling language and cognitive processing. The classic letter and word perception problem of McClelland and Rumelhart (1981) is used as a tutorial example to illustrate how structured and abstract representations may emerge from deep generative learning. We argue that the focus on deep architectures and generative (rather than discriminative) learning represents a crucial step forward for the connectionist modeling enterprise, because it offers a more plausible model of cortical learning as well as a way to bridge the gap between emergentist connectionist models and structured Bayesian models of cognition.	[Zorzi, Marco; Testolin, Alberto; Stoianov, Ivilin P.] Univ Padua, Dept Gen Psychol, Computat Cognit Neurosci Lab, I-35131 Padua, Italy; [Zorzi, Marco] IRCCS San Camillo Neurorehabil Hosp, Venice, Italy; [Stoianov, Ivilin P.] CNR, Inst Cognit Sci & Technol, Rome, Italy	Zorzi, M (reprint author), Univ Padua, Dept Gen Psychol, Computat Cognit Neurosci Lab, Via Venezia 12, I-35131 Padua, Italy.	marco.zorzi@unipd.it					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Albert A., 1972, REGRESSION MOORE PEN; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Baldi P., 2012, J MACH LEARN RES P T, V27, P37; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2012, ARXIV12065538V2, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Catrambone R., 2010, P 32 ANN M COGN SCI, P623; Chater N, 2006, TRENDS COGN SCI, V10, P335, DOI 10.1016/j.tics.2006.05.006; Chater N, 2006, TRENDS COGN SCI, V10, P287, DOI 10.1016/j.tics.2006.05.007; Clark A., 1992, Connection Science, V4, DOI 10.1080/09540099208946615; Clark Andy, 2013, Behav Brain Sci, V36, P181, DOI 10.1017/S0140525X12000477; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; De Grazia MD, 2012, COGN PROCESS, V13, pS141, DOI 10.1007/s10339-012-0478-4; Dean J., 2012, ADV NEURAL INFORM PR, V24, P1; Dehaene S, 2005, TRENDS COGN SCI, V9, P335, DOI 10.1016/j.tics.2005.05.004; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Dorronsoro J., 2002, LECT NOTES COMPUTER, P277; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Erhan D., 2009, TECHNICAL REPORT, P1; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Ghahramani Z, 1999, IEE CONF PUBL, P13, DOI 10.1049/cp:19991077; Griffiths TL, 2008, CAMB HANDB PSYCHOL, P59; Griffiths TL, 2010, TRENDS COGN SCI, V14, P357, DOI 10.1016/j.tics.2010.05.004; Harm MW, 2004, PSYCHOL REV, V111, P662, DOI 10.1037/0033-295X.111.3.662; Harm MW, 1999, PSYCHOL REV, V106, P491, DOI 10.1037//0033-295X.106.3.491; Hertz J, 1991, INTRO THEORY NEURAL; Hinton G., 2013, COGNITIVE SCI, DOI [10.1111/cogs.12049, DOI 10.1111/COGS.12049.]; Hinton G, 1999, UNSUPERVISED LEARNIN; Hinton G. E., 2010, 2010003 UTML TR U TO, p[9, 1]; Hinton G. E., 2002, LECT NOTES COMPUTER, P351; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142; JONES M, 2011, BEHAV BRAIN SCI, V34, P169, DOI DOI 10.1017/S0140525X10003134; Jones M., 2011, BEHAV BRAIN SCI, V34, P188; Jordan M. I., 2001, GRAPHICAL MODELS FDN; KIRSH D, 1990, VANC ST COG, P340; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V24; Le Q., 2012, INT C MACH LEARN ED; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Love BC, 2002, PSYCHON B REV, V9, P829, DOI 10.3758/BF03196342; Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309; Marr D., 1982, VISION COMPUTATIONAL; McClelland J. L., 1986, PARALLEL DISTRIBUTED, P77; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002; MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375; Minsky M., 1969, PERCEPTRONS INTRO CO; Mirman D., COGN SCI IN PRESS; Nair V., 2009, ADV NEURAL INF PROCE, V21, P1339; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; O'Reilly RC, 2000, COMPUTATIONAL EXPLOR; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; O'Reilly RC, 1998, TRENDS COGN SCI, V2, P455, DOI 10.1016/S1364-6613(98)01241-8; O'Reilly RC, 2001, NEURAL COMPUT, V13, P1199, DOI 10.1162/08997660152002834; Pearl J, 1988, PROBABILISTIC REASON; Perry C, 2007, PSYCHOL REV, V114, P273, DOI 10.1037/0033-295X.114.2.273; Perry C, 2013, COGNITIVE SCI, V37, P800, DOI 10.1111/cogs.12030; Perry C, 2010, COGNITIVE PSYCHOL, V61, P106, DOI 10.1016/j.cogpsych.2010.04.001; PLAUT DC, 1993, COGNITIVE NEUROPSYCH, V10, P377, DOI 10.1080/02643299308253469; Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56; Raina R., 2009, INT C MACH LEARN, P1; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHAR.DE, 1974, PSYCHOL REV, V81, P99, DOI 10.1037/h0036117; RUMELHART DE, 1993, ATTENTION PERFORM, V14, P3; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2009, INT C ART INT STAT, P448; Schyns PG, 1998, BEHAV BRAIN SCI, V21, P1; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Sperduti A., 2012, EUR S ART NEUR NETW, P275; Stoianov I, 2012, NAT NEUROSCI, V15, P194, DOI 10.1038/nn.2996; Stoianov Ivilin, 2004, Cortex, V40, P194, DOI 10.1016/S0010-9452(08)70948-1; Sutskever I., 2008, ADV NEURAL INFORM PR, V20, P1601; Sutton RS, 1998, REINFORCEMENT LEARNI; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Testolin A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00251; Vinckier F, 2007, NEURON, V55, P143, DOI 10.1016/j.neuron.2007.05.031; Zorzi M., 2005, HDB MATH COGNITION, P67; Zorzi M, 1998, J EXP PSYCHOL HUMAN, V24, P1131, DOI 10.1037/0096-1523.24.4.1131	94	6	6	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	AUG 20	2013	4								515	10.3389/fpsyg.2013.00515		14	Psychology, Multidisciplinary	Psychology	AA6FQ	WOS:000331194600001	23970869	
J	Zhang, XL; Wu, J				Zhang, Xiao-Lei; Wu, Ji			Deep Belief Networks Based Voice Activity Detection	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep learning; information fusion; voice activity detection	SUPPORT VECTOR MACHINE; STATISTICAL-MODEL; SPEECH SEGREGATION; AMPLITUDE-MODULATION; MULTIPITCH TRACKING; REVERBERANT SPEECH; ALGORITHM; RATIO; CLASSIFICATION; INFORMATION	Fusing the advantages of multiple acoustic features is important for the robustness of voice activity detection (VAD). Recently, the machine-learning-based VADs have shown a superiority to traditional VADs on multiple feature fusion tasks. However, existing machine-learning-based VADs only utilize shallow models, which cannot explore the underlying manifold of the features. In this paper, we propose to fuse multiple features via a deep model, called deep belief network (DBN). DBN is a powerful hierarchical generative model for feature extraction. It can describe highly variant functions and discover the manifold of the features. We take the multiple serially-concatenated features as the input layer of DBN, and then extract a new feature by transferring these features through multiple nonlinear hidden layers. Finally, we predict the class of the new feature by a linear classifier. We further analyze that even a single-hidden-layer-based belief network is as powerful as the state-of-the-art models in the machine-learning-based VADs. In our empirical comparison, ten common features are used for performance analysis. Extensive experimental results on the AURORA2 corpus show that the DBN-based VAD not only outperforms eleven referenced VADs, but also can meet the real-time detection demand of VAD. The results also show that the DBN-based VAD can fuse the advantages of multiple features effectively.	[Zhang, Xiao-Lei; Wu, Ji] Tsinghua Univ, Dept Elect Engn, Multimedia Signal & Intelligent Informat Proc Lab, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Zhang, XL (reprint author), Tsinghua Univ, Dept Elect Engn, Multimedia Signal & Intelligent Informat Proc Lab, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	huoshan6@126.com; wuji_ee@tsinghua.edu.cn			National High-Tech. R&D Program of China (863 Program) [2012AA011004]; National Natural Science Funds of China [61170197]; Planned Science and Technology Project of Tsinghua University [20111081023]; China Postdoctoral Science Foundation [2012M520278]	Manuscript received June 26, 2012; revised October 02, 2012; accepted November 19, 2012. Date of publication November 27, 2012; date of current version January 11, 2013. This work was supported in part by the National High-Tech. R&D Program of China (863 Program) under Grant 2012AA011004, in part by the National Natural Science Funds of China under Grant 61170197, in part by the Planned Science and Technology Project of Tsinghua University under Grant 20111081023, and in part by the China Postdoctoral Science Foundation funded project under Grant 2012M520278. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. DeLiang Wang.	[Anonymous], 2004, TIAEIAIS127 3GPP2 CS; [Anonymous], ETSI ES, V202; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2011, P ICML WORKSH UNS TR, V7, P1; Benyassine A, 1997, IEEE COMMUN MAG, V35, P64, DOI 10.1109/35.620527; Bregman Albert, 1994, AUDITORY SCENE ANAL; Carreira-Perpinan M. A., 2005, P INT C ART INT STAT, P17; Chang JH, 2006, IEEE T SIGNAL PROCES, V54, P1965, DOI 10.1109/TSP.2006.874403; Chen M., 2012, P AS C SIGN SYST COM, P1; Coates A., 2011, P ADV NEUR INF PROC, V24, P2528; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Cournapeau D, 2010, IEEE J-STSP, V4, P1071, DOI 10.1109/JSTSP.2010.2080821; D Yu, 2012, P 29 INT C MACH LEAR, P1; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Ellis D. P. W., 2005, PLP RASTA MFCC INVER; Enqing D., 2002, P INT C SIGN PROC, V2, P1124; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gazor S, 2003, IEEE T SPEECH AUDI P, V11, P498, DOI 10.1109/TSA.2003.815518; Han K., 2012, IEEE T AUDIO SPEECH, V21, P1; Hinton G., 2012, IEEE SIGNAL PROCESS, V11, P229; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsu CL, 2012, IEEE T AUDIO SPEECH, V20, P1482, DOI 10.1109/TASL.2011.2182510; Hsu C.-W., 2003, PRACTICAL GUIDE SUPP; Hu GN, 2010, IEEE T AUDIO SPEECH, V18, P2067, DOI 10.1109/TASL.2010.2041110; Hu GN, 2004, IEEE T NEURAL NETWOR, V15, P1135, DOI 10.1109/TNN.2004.832812; Hu K, 2011, IEEE T AUDIO SPEECH, V19, P1600, DOI 10.1109/TASL.2010.2093893; Jin ZZ, 2011, IEEE T AUDIO SPEECH, V19, P1091, DOI 10.1109/TASL.2010.2077280; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Jin ZZ, 2011, IEEE T AUDIO SPEECH, V19, P2328, DOI 10.1109/TASL.2011.2134086; Jo QH, 2009, IET SIGNAL PROCESS, V3, P205, DOI 10.1049/iet-spr.2008.0128; Joachims T, 2009, MACH LEARN, V76, P179, DOI 10.1007/s10994-009-5126-6; K Hu, 2013, IEEE T AUDIO SPEECH, V21, P122; Kang SI, 2008, IEEE SIGNAL PROC LET, V15, P170, DOI 10.1109/LSP.2007.913595; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Le Q. T., 2011, P 29 INT C MACH LEAR, P1; Mohamed A., 2010, P INTERSPEECH, P2846; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pearce D., 2000, P ICSLP, V4, P29; Petsatodis T, 2011, IEEE T AUDIO SPEECH, V19, P2314, DOI 10.1109/TASL.2011.2131131; Ramirez J, 2004, SPEECH COMMUN, V42, P271, DOI 10.1016/j.specom.2003.10.002; Ramirez J, 2005, IEEE SIGNAL PROC LET, V12, P689, DOI 10.1109/LSP.2005.855551; Ramirez J, 2007, IEEE T AUDIO SPEECH, V15, P2177, DOI 10.1109/TASL.2007.903937; Ramirez J, 2006, ELECTRON LETT, V42, P426, DOI 10.1049/el:20064068; Sha F., 2012, TUTORIAL INTERSPEECH, P1; Shin JW, 2010, COMPUT SPEECH LANG, V24, P515, DOI 10.1016/j.csl.2009.02.003; Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1; Suh Y, 2012, IEEE SIGNAL PROC LET, V19, P507, DOI 10.1109/LSP.2012.2204978; SUN XJ, 2002, ACOUST SPEECH SIG PR, P333; Tahmasbi R, 2007, IEEE T AUDIO SPEECH, V15, P1129, DOI 10.1109/TASL.2007.894521; Tchorz J, 2003, IEEE T SPEECH AUDI P, V11, P184, DOI 10.1109/TSA.2003.811542; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang D., 2006, COMPUTATIONAL AUDITO; WANG DL, 1995, IEEE T NEURAL NETWOR, V6, P283; Wang DL, 2005, IEEE T NEURAL NETWOR, V16, P1401, DOI 10.1109/TNN.2005.852235; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459; Wang Y, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION 2010, VOL 11, P1; Wu J., 2010, P INTERSPEECH, P3090; Wu J, 2011, IEEE SIGNAL PROC LET, V18, P283, DOI 10.1109/LSP.2011.2119482; Wu J, 2011, IEEE SIGNAL PROC LET, V18, P466, DOI 10.1109/LSP.2011.2159374; Wu J, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-18; Wu MY, 2003, IEEE T SPEECH AUDI P, V11, P229, DOI 10.1109/TSA.2003.811539; Xu Z., 2010, P 27 INT C MACH LEAR, P1175; Ying DW, 2011, IEEE T AUDIO SPEECH, V19, P2624, DOI 10.1109/TASL.2011.2125953; Yu D., 2009, P NIPS WORKSH, P1; Yu D., 2010, P INTERSPEECH, P2986; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Yu T, 2010, IEEE SIGNAL PROC LET, V17, P897, DOI 10.1109/LSP.2010.2066561; Zhang XL, 2012, IEEE T SYST MAN CY B, V42, P1669, DOI 10.1109/TSMCB.2012.2197824	73	6	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	APR	2013	21	4					697	710		10.1109/TASL.2012.2229986		14	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	072ZB	WOS:000313711600002		
J	Scherer, R; Faller, J; Balderas, D; Friedrich, EVC; Proll, M; Allison, B; Muller-Putz, G				Scherer, Reinhold; Faller, Josef; Balderas, David; Friedrich, Elisabeth V. C.; Proell, Markus; Allison, Brendan; Mueller-Putz, Gernot			Brain-computer interfacing: more than the sum of its parts	SOFT COMPUTING			English	Article						Hybrid context-aware brain-computer interface (BCI); Electroencephalogram (EEG); Mental imagery; Restricted Boltzmann machine; World of Warcraft; BCI-based gaming	SINGLE-TRIAL EEG; SPATIAL FILTERS; CLASSIFICATION; PERFORMANCE; COMMUNICATION; ALGORITHM; MOVEMENT; IMAGERY; TASK; BCI	The performance of non-invasive electroencephalogram-based (EEG) brain-computer interfaces (BCIs) has improved significantly in recent years. However, remaining challenges include the non-stationarity and the low signal-to-noise ratio of the EEG, which limit the bandwidth and hence the available applications. Optimization of both individual components of BCIs and the interrelationship between them is crucial to enhance bandwidth. In other words, neuroscientific knowledge and machine learning need to be optimized by considering concepts from human-computer interaction research and usability. In this paper, we present results of ongoing relevant research in our lab that addresses several important issues for BCIs based on the detection of transient changes in oscillatory EEG activity. First, we report on the long-term stability and robustness of detection of oscillatory EEG components modulated by distinct mental tasks, and show that the use of mental task pairs "mental subtraction versus motor imagery" achieves robust and reliable performance (Cohen's kappa > 0.6) in seven out of nine subjects over a period of 4 days. Second, we report on restricted Boltzmann machines (RBMs) as promising tools for the recognition of oscillatory EEG patterns. In an off-line BCI simulation we computed average peak accuracies, averaged over ten subjects, of 80.8 +/- A 7.2 %. Third, we present the basic framework of the context-aware hybrid Graz-BCI that allows interacting with the massive multiplayer online role playing game World of Warcraft. We show how a more integrated design approach that considers all components of BCIs, their interrelationships, other input signals and contextual information can increase interaction efficacy.	[Scherer, Reinhold; Faller, Josef; Balderas, David; Proell, Markus; Mueller-Putz, Gernot] Graz Univ Technol, Inst Knowledge Discovery, A-8010 Graz, Austria; [Friedrich, Elisabeth V. C.] Graz Univ, Dept Psychol, A-8010 Graz, Austria; [Allison, Brendan] Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92122 USA	Scherer, R (reprint author), Graz Univ Technol, Inst Knowledge Discovery, Krenngasse 37, A-8010 Graz, Austria.	reinhold.scherer@tugraz.at; josef.faller@tugraz.at; dc.balderassilva@gmail.com; elisabeth.friedrich@uni-graz.at; proell.max@gmail.com; ballison@ucsd.edu; gernot.mueller@tugraz.at	Muller-Putz, Gernot/	Muller-Putz, Gernot/0000-0002-0087-3720	ICT Collaborative Project BrainAble [247447]; GaLA project [258169]; Wings for Life Spinal Cord Foundation; ARO [W911NF-11-1-0307]	This work was supported in part by the ICT Collaborative Project BrainAble (247447), the GaLA project (258169), the Wings for Life Spinal Cord Foundation, and ARO award W911NF-11-1-0307.	Allison BZ, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026007; Allison BZ, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/1/013001; Balderas D, 2011, P 5 INT BRAIN COMP I, P68; Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI [10.1109/MSP.2008.4408441, 10.1109/MSP.200790.900,9]; Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Chung M, 2011, P 22 INT JOINT C ART, P1647; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Darvas F., 2009, NEUROIMAGE, V49, P930, DOI DOI 10.1016/J.NEUROIMAGE.2009.08.041; Fatourechi M, 2007, CLIN NEUROPHYSIOL, V118, P480, DOI 10.1016/j.clinph.2006.10.019; Fazli S, 2012, NEUROIMAGE, V59, P519, DOI 10.1016/j.neuroimage.2011.07.084; Friedrich EVC, 2012, INT J PSYCHOPHYSIOL, V84, P86, DOI 10.1016/j.ijpsycho.2012.01.014; Gevins A, 1997, CEREB CORTEX, V7, P374, DOI 10.1093/cercor/7.4.374; Grozea C, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025008; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HJORTH B, 1975, ELECTROEN CLIN NEURO, V39, P526, DOI 10.1016/0013-4694(75)90056-5; Johnson RR, 2011, BIOL PSYCHOL, V87, P241, DOI 10.1016/j.biopsycho.2011.03.003; Krauledat M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002967; Larochelle H., 2008, ICML 08 P 25 INT C M; Leeb Robert, 2007, Comput Intell Neurosci, P79642, DOI 10.1155/2007/79642; Leeb R, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025011; Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/R01; Mason SG, 2007, ANN BIOMED ENG, V35, P137, DOI 10.1007/s10439-006-9170-0; Millan JD, 2003, IEEE T NEUR SYS REH, V11, P159, DOI 10.1109/TNSRE.2003.814435; Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8; Muller-Putz GR, 2008, J NEUROSCI METH, V168, P174, DOI 10.1016/j.jneumeth.2007.09.024; Muller-Putz GR, 2010, FRONT NEUROSCI, V4, DOI [10.3389/fnins.2010.00034, DOI 10.3389/FNINS.2010.00034]; Navarro NA, 2011, LECT NOTES COMPUTER, P216; Navdeep J, 2011, P 12 INT C ART INT S; Neuper C, 2005, COGNITIVE BRAIN RES, V25, P668, DOI 10.1016/j.cogbrainres.2005.08.014; Pfurtscheller Gert, 2010, Front Neurosci, V4, P30, DOI 10.3389/fnpro.2010.00003; Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8; Pfurtscheller G, 2008, EUR J NEUROSCI, V28, P1419, DOI 10.1111/j.1460-9568.2008.06441.x; Popescu F, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000637; Pregenzer M, 1996, NEUROCOMPUTING, V11, P19, DOI 10.1016/0925-2312(94)00071-9; Pregenzer M, 1999, IEEE Trans Rehabil Eng, V7, P413, DOI 10.1109/86.808944; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Rao R. P. N., 2010, IEEE SIGNAL PROC MAG, V27, P150; Scherer R, 2007, COMPUT INTELL NEUROS, V2007, P79; Scherer R, 2008, P GRAZ BRAIN COMP IN; Scherer R, 2009, INT REV NEUROBIOL, V86, P119, DOI [10.1016/S0074-7742(09)86009-1, 10.1016/S0074-7742(09)86009-I]; Scherer R., 2011, LECT NOTES COMPUT SC, V6691, P362; Scherer R, 2004, IEEE T BIO-MED ENG, V51, P979, DOI 10.1109/TBME.2004.827062; Scherer R, 2008, IEEE T BIO-MED ENG, V55, P675, DOI 10.1109/TBME.2007.903709; Schlogl A., 2007, BRAIN COMPUTER INTER; Shenoy P., 2006, J NEURAL ENG, V3, P13; Trejo L, 2005, SPIE C P; Usakli AB, 2009, C P IEEE ENG MED BIO; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005; Zander TO, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/1/016003	53	6	8	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1432-7643	1433-7479		SOFT COMPUT	Soft Comput.	FEB	2013	17	2					317	331		10.1007/s00500-012-0895-4		15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	076PN	WOS:000313969400011		
J	Deng, L; Hinton, G; Kingsbury, B			IEEE	Deng, Li; Hinton, Geoffrey; Kingsbury, Brian			NEW TYPES OF DEEP NEURAL NETWORK LEARNING FOR SPEECH RECOGNITION AND RELATED APPLICATIONS: AN OVERVIEW	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		deep neural network; convolutional neural network; recurrent neural network; optimization; spectrogram features; multitask; multilingual; speech recognition; music processing	OPTIMIZATION; NETS	In this paper, we provide an overview of the invited and contributed papers presented at the special session at ICASSP-2013, entitled "New Types of Deep Neural Network Learning for Speech Recognition and Related Applications," as organized by the authors. We also describe the historical context in which acoustic models based on deep neural networks have been developed. The technical overview of the papers presented in our special session is organized into five ways of improving deep learning methods: (1) better optimization; (2) better types of neural activation function and better network architectures; (3) better ways to determine the myriad hyper-parameters of deep neural networks; (4) more appropriate ways to preprocess speech for deep neural networks; and (5) ways of leveraging multiple languages or dialects that are more easily achieved with deep neural networks than with Gaussian mixture models.	[Deng, Li] Microsoft Res, Redmond, WA 98052 USA	Deng, L (reprint author), Microsoft Res, Redmond, WA 98052 USA.						Abdel-Hamid O., 2012, ICASSP; Abdel-Hamid O., 2013, INT UNPUB; Bengio Y., 2013, ICASSP; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bottou L., 2004, NIPS; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Dahl G., 2011, ICASSP; Dahl G.E., 2013, ICASSP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dean J., 2012, NIPS; Deng L., 2010, INTERSPEECH; Deng L., 2012, IEEE SLT; Deng L., 2013, ICASSP; Deng L., 2009, NIPS WORKSH; Deng L, 2006, IEEE T AUDIO SPEECH, V14, P1492, DOI 10.1109/TASL.2006.878265; Deng L., 2007, ICASSP; Deng L., 2012, ICASSP; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Graves A., 2013, ICASSP; Heigold G., 2013, ICASSP; Hinton G., 2012, ARXIV12070580V1; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang Jui-Ting, 2013, ICASSP; Jaitly N., 2012, INTERSPEECH; Kingsbury B., 2012, INTERSPEECH; Krizhevsky A., 2012, NIPS; LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L; Larochelle H., 2011, ICML; Le Q.V., 2012, ICML; LeCun Y., P IEEE, V86, P2278; Lin H, 2009, INT CONF ACOUST SPEE, P4333, DOI 10.1109/ICASSP.2009.4960588; Markoff John, 2012, NY TIMES; Martens J., 2010, ICML; Martens J., 2011, ICML; Mikolov T., 2010, INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Ngiam J., 2011, ICML; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Sainath T.N., 2013, ICASSP; Sainath T.N., 2011, P ASRU, P30; Seide F., 2011, INTERSPEECH, P437; Snoek J., 2012, NIPS; Sutskever I., 2013, THESIS U TORONTO; Yu D., 2010, NIPS WORKSH DEEP LEA; Zeiler M.D., 2013, ICASSP	51	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							8599	8603				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611508154		
J	Fernando, C; Szathmary, E; Husbands, P				Fernando, Chrisantha; Szathmary, Eoers; Husbands, Phil			Selectionist and evolutionary approaches to brain function: a critical appraisal	FRONTIERS IN COMPUTATIONAL NEUROSCIENCE			English	Article						neural Darwinism; neuronal group selection; neuronal replicator hypothesis; Darwinian neurodynamics; Izhikevich spiking networks; causal inference; price equation; hill-climbers	SYNAPTIC PLASTICITY; NEURONAL NETWORKS; DEPENDENT PLASTICITY; ROBOT CONTROL; IN-VITRO; DYNAMICS; RNA; ALGORITHM; MEMORY; MODELS	We consider approaches to brain dynamics and function that have been claimed to be Darwinian. These include Edelman's theory of neuronal group selection, Changeux's theory of synaptic selection and selective stabilization of pre-representations, Seung's Darwinian synapse, Loewenstein's synaptic melioration, Adam's selfish synapse, and Calvin's replicating activity patterns. Except for the last two, the proposed mechanisms are selectionist but not truly Darwinian, because no replicators with information transfer to copies and hereditary variation can be identified in them. All of them fit, however, a generalized selectionist framework conforming to the picture of Price's covariance formulation, which deliberately was not specific even to selection in biology, and therefore does not imply an algorithmic picture of biological evolution. Bayesian models and reinforcement learning are formally in agreement with selection dynamics. A classification of search algorithms is shown to include Darwinian replicators (evolutionary units with multiplication, heredity, and variability) as the most powerful mechanism for search in a sparsely occupied search space. Examples are given of cases where parallel competitive search with information transfer among the units is more efficient than search without information transfer between units. Finally, we review our recent attempts to construct and analyze simple models of true Darwinian evolutionary units in the brain in terms of connectivity and activity copying of neuronal groups. Although none of the proposed neuronal replicators include miraculous mechanisms, their identification remains a challenge but also a great promise.	[Fernando, Chrisantha] Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England; [Fernando, Chrisantha; Husbands, Phil] Univ Sussex, Dept Informat, Brighton, E Sussex, England; [Szathmary, Eoers] Eotvos Lorand Univ, Dept Plant Systemat Ecol & Theoret Biol, Budapest, Hungary; [Szathmary, Eoers] Conceptual Fdn Sci, Parmenides Ctr, Pullach, Germany	Fernando, C (reprint author), Univ London, Sch Elect Engn & Comp Sci, Mile End Road, London E1 4NS, England.	ctf20@sussex.ac.uk			FP-7FET OPEN Project E-Flux; Hungarian research project [NAP 2005/KCKHA005]	We work was funded by an FP-7FET OPEN Project E-Flux, and the Hungarian research project (NAP 2005/KCKHA005).	Adams P, 1998, J THEOR BIOL, V195, P419, DOI 10.1006/jtbi.1997.0620; Arnold DV, 2003, COMPUT OPTIM APPL, V24, P135, DOI 10.1023/A:1021810301763; Aunger Robert, 2002, ELECT MEME NEW THEOR; Barnett L, 2001, IEEE C EVOL COMPUTAT, P30, DOI 10.1109/CEC.2001.934367; Bi GQ, 1998, J NEUROSCI, V18, P10464; Borgers T, 1997, J ECON THEORY, V77, P1, DOI 10.1006/jeth.1997.2319; Buchanan Katherine A, 2010, Front Synaptic Neurosci, V2, P11, DOI 10.3389/fnsyn.2010.00011; Bush D, 2010, FRONT COMPUT NEUROSC, V4, DOI 10.3389/fncom.2010.00142; Butz M, 2009, BRAIN RES REV, V60, P287, DOI 10.1016/j.brainresrev.2008.12.023; Calvin W., 1996, CEREBRAL CODE; CALVIN WH, 1987, NATURE, V330, P33, DOI 10.1038/330033a0; Changeux J. P., 1984, BIOL LEARNING, P115; Changeux J. P, 1985, NEURONAL MAN BIOL MI; CHANGEUX JP, 1989, COGNITION, V33, P63, DOI 10.1016/0010-0277(89)90006-1; CHANGEUX JP, 1973, P NATL ACAD SCI USA, V70, P2974, DOI 10.1073/pnas.70.10.2974; Chklovskii DB, 2004, NATURE, V431, P782, DOI 10.1038/nature03012; CRICK F, 1989, TRENDS NEUROSCI, V12, P240, DOI 10.1016/0166-2236(89)90019-2; CRICK F, 1990, TRENDS NEUROSCI, V13, P13, DOI 10.1016/0166-2236(90)90055-F; DAMUTH J, 1988, BIOL PHILOS, V3, P407, DOI 10.1007/BF00647962; Dawkins R., 1976, SELFISH GENE; DE JONG K. A., 2006, EVOLUTIONARY COMPUTA; Dehaene S, 1998, P NATL ACAD SCI USA, V95, P14529, DOI 10.1073/pnas.95.24.14529; Dehaene S, 1997, P NATL ACAD SCI USA, V94, P13293, DOI 10.1073/pnas.94.24.13293; DEHAENE S, 1987, P NATL ACAD SCI USA, V84, P2727, DOI 10.1073/pnas.84.9.2727; Dennett D. C., 1995, DARWINS DANGEROUS ID; Duda R, 2001, PATTERN CLASSIFICATI; Edelman G. M., 1987, NEURAL DARWINISM THE; Edelman GM, 2001, P NATL ACAD SCI USA, V98, P13763, DOI 10.1073/pnas.231499798; EIGEN M, 1971, NATURWISSENSCHAFTEN, V58, P465; Ellington AD, 2009, INT J BIOCHEM CELL B, V41, P254, DOI 10.1016/j.biocel.2008.08.015; Fernando C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003775; Fernando Chrisantha, 2010, P209; Fernando C., 2009, THEORY THINKING, P291; Fernando C, 2010, NEURAL COMPUT, V22, P2809, DOI 10.1162/NECO_a_00031; Fernando Chrisantha, 2011, Evolutionary Intelligence, V4, DOI 10.1007/s12065-011-0055-2; Fernando C, 2011, J THEOR BIOL, V275, P29, DOI 10.1016/j.jtbi.2011.01.009; Fernando C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023534; Fisher R. A., 1930, GENETICAL THEORY NAT; Flajnik MF, 2010, NAT REV GENET, V11, P47, DOI 10.1038/nrg2703; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Fox R., 1975, ASA STUDIES, V4, P133; Friston KJ, 2000, P NATL ACAD SCI USA, V97, P7591, DOI 10.1073/pnas.97.13.7591; Friston KJ, 2000, PHILOS T R SOC B, V355, P215, DOI 10.1098/rstb.2000.0560; Ganti T., 2003, PRINCIPLES LIFE; Gardner A, 2008, CURR BIOL, V18, pR198, DOI 10.1016/j.cub.2008.01.005; George D, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000532; Gopnik A, 2004, TRENDS COGN SCI, V8, P371, DOI 10.1016/j.tics.2004.06.005; Gopnik A, 2004, PSYCHOL REV, V111, P3, DOI 10.1037/0033-295X.111.1.3; Harman M., 2007, INT S SOFTW TEST AN, P73; HARPER M, 2009, ARXIV09111763; Hasselmo ME, 2006, CURR OPIN NEUROBIOL, V16, P710, DOI 10.1016/j.conb.2006.09.002; Hebb D. O., 1949, ORG BEHAV, P378; HEIDMANN A, 1984, CR ACAD SCI III-VIE, V299, P839; HEISLER IL, 1987, AM NAT, V130, P582, DOI 10.1086/284732; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hofbauer J., 1998, THEORY EVOLUTION DYN; Holland J. H., 1986, INDUCTION PROCESSES; Holland J. H., 1977, ACM SIGART B, V63, P43; Holland J.H., 1975, ADAPTATION NATURAL A, VOriginal; Hollander M, 1999, NONPARAMETRIC STAT M, V1st; Holtmaat A, 2009, NAT REV NEUROSCI, V10, P647, DOI 10.1038/nrn2699; Huda S, 2009, PATTERN RECOGN LETT, V30, P1301, DOI 10.1016/j.patrec.2009.06.006; Husbands P, 2010, COMPLEXITY, V16, P35, DOI 10.1002/cplx.20336; Husbands P, 1998, CONNECT SCI, V10, P185; Isaac JTR, 2009, J NEUROSCI, V29, P6840, DOI 10.1523/JNEUROSCI.0731-09.2009; Izhikevich EM, 2009, INT J BIFURCAT CHAOS, V19, P1733, DOI 10.1142/S0218127409023809; Izhikevich EM, 2003, NEURAL COMPUT, V15, P1511, DOI 10.1162/089976603321891783; Izhikevich EM, 2004, CEREB CORTEX, V14, P933, DOI 10.1093/cercor/bhh053; Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152; Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882; Izquierdo E., 2008, P 11 INT C ART LIF, P265; Jakobi N, 1997, ADAPT BEHAV, V6, P325, DOI 10.1177/105971239700600205; James W, 1890, PRINCIPLES PSYCHOL; Jansen T., 2001, P GEN EV COMP C GECC, P1034; Jin Y, 2005, IEEE T EVOLUT COMPUT, V9, P303, DOI 10.1109/TEVC.2005.846356; Johnson HA, 2010, NAT NEUROSCI, V13, P917, DOI 10.1038/nn.2579; Keane AJ, 2005, COMPUTATIONAL APPROACHES FOR AEROSPACE DESIGN: THE PURSUIT OF EXCELLENCE, P1, DOI 10.1002/0470855487; Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105; Knight R, 2005, NUCLEIC ACIDS RES, V33, P5924, DOI 10.1093/nar/gki886; Kwok N. M., 2005, P IEEE RSJ INT C INT, P1053; Lieberman E, 2005, NATURE, V433, P312, DOI 10.1038/nature03204; Loewenstein Y, 2010, FRONT COMPUT NEUROSC, V4, DOI 10.3389/fncom.2010.00017; Majerfeld I, 2010, RNA, V16, P1915, DOI 10.1261/rna.2220210; Marshall JAR, 2011, TRENDS ECOL EVOL, V26, P325, DOI 10.1016/j.tree.2011.04.008; Maynard Smith J, 1995, MAJOR TRANSITIONS EV; Maynard Smith J., 1986, PROBLEMS BIOL, P144; Maynard Smith J., 1996, GENES MEMES MINDS; Maynard Smith J., 1998, EVOLUTIONARY GENETIC; Maynard Smith J., 2008, 45 PRICES THEOREM SC; Mazzoni A, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000439; McIlhagga M., 1996, 4 INT C PAR PROBL SO, P614; McIlhagga M., 1996, 4 INT C PAR PROBL SO, P604; MICHOD R, 1990, TRENDS NEUROSCI, V13, P12, DOI 10.1016/0166-2236(90)90054-E; Michod R. E., 1988, EVOLUTION, V43, P694; MILES R, 1990, J PHYSIOL-LONDON, V428, P61; Mitchell M, 1994, ADV NEURAL INFORMATI, V6, P51; Muruzaball J, 2007, STUD FUZZ SOFT COMP, V213, P193; Myers J. W., 1999, 15 C UNC ART INT TOR; Nadel L, 1997, CURR OPIN NEUROBIOL, V7, P217, DOI 10.1016/S0959-4388(97)80010-4; Nadel L, 2000, HIPPOCAMPUS, V10, P352, DOI 10.1002/1098-1063(2000)10:4<352::AID-HIPO2>3.0.CO;2-D; Nadel Lynn, 2007, Neural Plasticity, P1, DOI 10.1155/2007/90472; Nessler B., 2009, P NIPS ADV NEUR INF; Nilsson N., 2007, LECT NOTES ARTIF INT, P9; Okasha S., 2006, EVOLUTION LEVELS SEL, P288; ORGEL LE, 1980, NATURE, V284, P604, DOI 10.1038/284604a0; PARKER GA, 1990, NATURE, V348, P27, DOI 10.1038/348027a0; Parter M, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000206; Perin R, 2011, P NATL ACAD SCI USA, V108, P5419, DOI 10.1073/pnas.1016051108; Philippides A, 2005, ARTIF LIFE, V11, P139, DOI 10.1162/1064546053279044; Poli Riccardo, 2007, Swarm Intelligence, V1, DOI 10.1007/s11721-007-0002-0; PRICE GR, 1995, J THEOR BIOL, V175, P389, DOI 10.1006/jtbi.1995.0149; PRICE GR, 1970, NATURE, V227, P520, DOI 10.1038/227520a0; Prugel-Bennett A, 2004, THEOR COMPUT SCI, V320, P135, DOI 10.1016/j.tcs.2004.03.038; Sanborn AN, 2010, PSYCHOL REV, V117, P1144, DOI 10.1037/a0020511; Seung S, 2003, NEURON, V40, P1063; Shalizi CR, 2009, ELECTRON J STAT, V3, P1039, DOI 10.1214/09-EJS485; Skinner B. F., 1976, BEHAVIOURISM; SMITH JM, 1988, NATURE, V332, P492, DOI 10.1038/332492a0; Smith JM, 2000, PHILOS SCI, V67, P177, DOI 10.1086/392768; Smith T, 2002, ADAPT BEHAV, V10, P161; Smith T., 2002, EVOL COMPUT, V1, P1; Smith T, 2003, BIOSYSTEMS, V69, P223, DOI 10.1016/S0303-2647(02)00139-9; Song S, 2000, NAT NEUROSCI, V3, P919; Song S, 2001, NEURON, V32, P339, DOI 10.1016/S0896-6273(01)00451-2; Sporns O, 2004, PLOS BIOL, V2, P1910, DOI 10.1371/journal.pbio.0020369; SPORNS O, 1993, CHILD DEV, V64, P960, DOI 10.1111/j.1467-8624.1993.tb04182.x; Stich M, 2011, J THEOR BIOL, V280, P117, DOI 10.1016/j.jtbi.2011.03.010; Strens M. J. A., 2003, P 20 INT C MACH LEAR; Sutton S. R., 1998, REINFORCEMENT LEARNI, P322; Szathmary E, 2006, PHILOS T R SOC B, V361, P1761, DOI 10.1098/rstb.2006.1912; Szathmary E, 2000, PHILOS T ROY SOC B, V355, P1669, DOI 10.1098/rstb.2000.0730; Szathmary E., 2011, SCIENCE, V324, P1648; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Thorndike E. L., 1911, ANIMAL INTELLIGENCE; Toussaint M., 2003, EVOLUTION GENETIC RE, P117; Van Belle Terry, 1997, Artificial Life, V3, P41, DOI 10.1162/artl.1997.3.1.41; Wagner A., 2007, ROBUSTNESS EVOLVABIL; Wallace A. R., 1916, AR WALLACE LETT REMI, V1, P170; Weiss A. P., 1994, THEORETICAL BASIS HU; WRIGHT SEWALL, 1932, PROC SIXTH INTERNAT CONGR GENETICS ITHACA NEW YORK, V1, P356; Young JM, 2007, NAT NEUROSCI, V10, P887, DOI 10.1038/nn1913; Zachar I, 2010, BMC BIOL, V8, DOI 10.1186/1741-7007-8-21; Zhang B.-T., 1999, 1999 C EV COMP CEC99, P722	143	6	6	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5188			FRONT COMPUT NEUROSC	Front. Comput. Neurosci.	APR 26	2012	6								24	10.3389/fncom.2012.00024		28	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	933ZW	WOS:000303408400001	22557963	
J	Keck, C; Savin, C; Lucke, J				Keck, Christian; Savin, Cristina; Luecke, Joerg			Feedforward Inhibition and Synaptic Scaling - Two Sides of the Same Coin?	PLOS COMPUTATIONAL BIOLOGY			English	Article							WINNER-TAKE-ALL; VISUAL-CORTEX; GAIN-CONTROL; HOMEOSTATIC PLASTICITY; NORMALIZATION MODEL; CORTICAL ACTIVITY; POPULATION CODES; AUDITORY-CORTEX; NEURAL-NETWORK; EM ALGORITHM	Feedforward inhibition and synaptic scaling are important adaptive processes that control the total input a neuron can receive from its afferents. While often studied in isolation, the two have been reported to co-occur in various brain regions. The functional implications of their interactions remain unclear, however. Based on a probabilistic modeling approach, we show here that fast feedforward inhibition and synaptic scaling interact synergistically during unsupervised learning. In technical terms, we model the input to a neural circuit using a normalized mixture model with Poisson noise. We demonstrate analytically and numerically that, in the presence of lateral inhibition introducing competition between different neurons, Hebbian plasticity and synaptic scaling approximate the optimal maximum likelihood solutions for this model. Our results suggest that, beyond its conventional use as a mechanism to remove undesired pattern variations, input normalization can make typical neural interaction and learning rules optimal on the stimulus subspace defined through feedforward inhibition. Furthermore, learning within this subspace is more efficient in practice, as it helps avoid locally optimal solutions. Our results suggest a close connection between feedforward inhibition and synaptic scaling which may have important functional implications for general cortical processing.	[Keck, Christian; Luecke, Joerg] Frankfurt Inst Adv Studies, Frankfurt, Germany; [Savin, Cristina] Univ Cambridge, Dept Engn, Computat & Biol Learning Lab, Cambridge CB2 1PZ, England; [Luecke, Joerg] Goethe Univ Frankfurt, Dept Phys, Frankfurt, Germany	Keck, C (reprint author), Frankfurt Inst Adv Studies, Frankfurt, Germany.	luecke@fias.uni-frankfurt.de			German Ministry of Research and Education (BMBF) [01GQ0840]; BFNT Frankfurt; German Research Foundation (DFG) [LUsimilar to1196/4-1]; Wellcome Trust	This work was supported by grants German Ministry of Research and Education (BMBF) under grant 01GQ0840, BFNT Frankfurt, (CK), the German Research Foundation (DFG) under grant LU similar to 1196/4-1 (JL) and the Wellcome Trust (CS). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453; Assisi C, 2007, NAT NEUROSCI, V10, P1176, DOI 10.1038/nn1947; Bacci A, 2005, TRENDS NEUROSCI, V28, P602, DOI 10.1016/j.tins.2005.08.007; Baccus SA, 2002, NEURON, V36, P909, DOI 10.1016/S0896-6273(02)01050-4; Berkes P, 2011, SCIENCE, V331, P83, DOI 10.1126/science.1195870; Bruna J, 2010, COMPUTING RES REPOSI, Vabs/1011.3023; Carandini M, 1997, J NEUROSCI, V17, P8621; Chance FS, 2002, NEURON, V35, P773, DOI 10.1016/S0896-6273(02)00820-6; Dayan P., 2001, THEORETICAL NEUROSCI; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deneve S, 1999, NAT NEUROSCI, V2, P740; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Duda R, 2001, PATTERN CLASSIFICATI; Echegoyen J, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000700; Elfadel IM, 1994, ADV NEURAL INFORMATI, V6, P882; Fellous JM, 2003, NEUROSCIENCE, V122, P811, DOI 10.1016/j.neuroscience.2003.08.027; Finn IM, 2007, NEURON, V54, P137, DOI 10.1016/j.neuron.2007.02.029; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Fukai T, 1997, NEURAL COMPUT, V9, P77, DOI 10.1162/neco.1997.9.1.77; Gerstner W, 2002, BIOL CYBERN, V87, P404, DOI 10.1007/s00422-002-0353-y; HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hofer SB, 2011, NAT NEUROSCI, V14, P1045, DOI 10.1038/nn.2876; Isaacson JS, 2011, NEURON, V72, P231, DOI 10.1016/j.neuron.2011.09.027; Klinkenberg I, 2011, BEHAV BRAIN RES, V221, P430, DOI 10.1016/j.bbr.2010.11.033; Kuo SP, 2011, NEURON, V71, P306, DOI 10.1016/j.neuron.2011.05.039; Kwok T, 2005, NEURAL COMPUT, V17, P2454, DOI 10.1162/0899766054796860; LeCun Y., MNIST DATABASE HANDW; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leslie KR, 2001, J NEUROSCI, V21, P1; Liu SC, 1999, ADV NEURAL INF PROCE, V12, P717; Lochmann T, 2011, CURR OPIN NEUROBIOL, V21, P774, DOI 10.1016/j.conb.2011.05.018; Lucke J, 2008, J MACH LEARN RES, V9, P1227; Mante V, 2005, NAT NEUROSCI, V8, P1690, DOI 10.1038/nn1556; Mao ZH, 2007, IEEE T NEURAL NETWOR, V18, P55, DOI 10.1109/TNN.2006.883724; Marr D., 1982, VISION COMPUTATIONAL; Mittmann W, 2005, J PHYSIOL-LONDON, V563, P369, DOI 10.1113/jphysiol.2004.075028; Neal RM, 1998, NATO ADV SCI I D BEH, P355; Ohshiro T, 2011, NAT NEUROSCI, V14, P775, DOI 10.1038/nn.2815; Olsen SR, 2010, NEURON, V66, P287, DOI 10.1016/j.neuron.2010.04.009; Olsen SR, 2008, NATURE, V452, P956, DOI 10.1038/nature06864; Pouille F, 2001, SCIENCE, V293, P1159, DOI 10.1126/science.1060342; Pouille F, 2009, NAT NEUROSCI, V12, P1577, DOI 10.1038/nn.2441; Rabinowitz NC, 2011, NEURON, V70, P1178, DOI 10.1016/j.neuron.2011.04.030; Ranzato M, 2007, 2007 IEEE C COMP VIS; Rao RPN, PROBABILISTIC MODELS; Reynolds JH, 2000, NEURON, V26, P703, DOI 10.1016/j.neuron.2009.01.002; Ringach DL, 2010, VISION RES, V50, P2223, DOI 10.1016/j.visres.2009.12.007; Rust NC, 2005, NEURON, V46, P945, DOI 10.1016/j.neuron.2005.05.021; Sahani M., 1999, THESIS CALTECH PASAD; Schwartz O, 2000, ADV NEURAL INF PROCE, P166; Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526; SCLAR G, 1990, VISION RES, V30, P1, DOI 10.1016/0042-6989(90)90123-3; Shu YS, 2003, J NEUROSCI, V23, P10388; Stopfer M, 2003, NEURON, V39, P991, DOI 10.1016/j.neuron.2003.08.011; Swadlow HA, 2003, CEREB CORTEX, V13, P25, DOI 10.1093/cercor/13.1.25; Turrigiano GG, 2004, NAT REV NEUROSCI, V5, P97, DOI 10.1038/nrn1327; Turrigiano GG, 1998, NATURE, V391, P892, DOI 10.1038/36103; Turrigiano GG, 2008, CELL, V135, P422, DOI 10.1016/j.cell.2008.10.008; Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0; Watt AJ, 2000, NEURON, V26, P659, DOI 10.1016/S0896-6273(00)81202-7; Wehr M, 2005, NEURON, V47, P437, DOI 10.1016/j.neuron.2005.06.009; Yuille A. L., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.334; Yuille A. L., 2003, HDB BRAIN THEORY NEU, P1228	64	6	6	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-7358			PLOS COMPUT BIOL	PLoS Comput. Biol.	MAR	2012	8	3							e1002432	10.1371/journal.pcbi.1002432		15	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	918IY	WOS:000302244000040	22457610	
J	Chen, K; Salman, A				Chen, Ke; Salman, Ahmad			Learning Speaker-Specific Characteristics With a Deep Neural Architecture	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Deep neural architecture; hybrid learning strategy; overcomplete representation; speaker comparison; speaker segmentation; speaker verification; speaker-specific characteristics	IDENTIFICATION; RECOGNITION; MODELS; SEGMENTATION; VERIFICATION; NETWORKS	Speech signals convey various yet mixed information ranging from linguistic to speaker-specific information. However, most of acoustic representations characterize all different kinds of information as whole, which could hinder either a speech or a speaker recognition (SR) system from producing a better performance. In this paper, we propose a novel deep neural architecture (DNA) especially for learning speaker-specific characteristics from mel-frequency cepstral coefficients, an acoustic representation commonly used in both speech recognition and SR, which results in a speaker-specific overcomplete representation. In order to learn intrinsic speaker-specific characteristics, we come up with an objective function consisting of contrastive losses in terms of speaker similarity/dissimilarity and data reconstruction losses used as regularization to normalize the interference of non-speaker-related information. Moreover, we employ a hybrid learning strategy for learning parameters of the deep neural networks: i.e., local yet greedy layerwise unsupervised pretraining for initialization and global supervised learning for the ultimate discriminative goal. With four Linguistic Data Consortium (LDC) benchmarks and two non-English corpora, we demonstrate that our overcomplete representation is robust in characterizing various speakers, no matter whether their utterances have been used in training our DNA, and highly insensitive to text and languages spoken. Extensive comparative studies suggest that our approach yields favorite results in speaker verification and segmentation. Finally, we discuss several issues concerning our proposed approach.	[Chen, Ke; Salman, Ahmad] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	Chen, K (reprint author), Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England.	chen@cs.manchester.ac.uk; salmanaa@cs.manchester.ac.uk					Bengio Y., 2007, P ADV NEUR INF PROC, V19, P1; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BROMLEY J, 1993, P ADV NEUR INF PROC, V5, P1; Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714; Campbell JP, 2009, IEEE SIGNAL PROC MAG, V26, P95, DOI 10.1109/MSP.2008.931100; CAMPBELL W, 2010, P ADV NEUR INF PROC, V22, P1; Chen K, 2003, PATTERN RECOGN, V36, P329; Chen S. S., 1998, P DARPA BROADC NEWS, P127; Chopra S., 2005, P COMPUTER VISION PA, V1, P539; Delacourt P, 2000, SPEECH COMMUN, V32, P111, DOI 10.1016/S0167-6393(00)00027-3; Erhan D, 2010, J MACH LEARN RES, V11, P625; GOLDBERGER J, 2005, P ADV NEUR INF PROC, V17, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang X., 2001, SPOKEN LANGUAGE PROC; JARRETT K, 2009, P IEEE INT C COMP VI, P2146; Jin Q., 2007, THESIS CARNEGIE MELL; KAJAREKAR S, 2002, THESIS SCH SCI ENG P; Kotti M, 2008, SIGNAL PROCESS, V88, P1091, DOI 10.1016/j.sigpro.2007.11.017; Laparra V, 2011, IEEE T NEURAL NETWOR, V22, P537, DOI 10.1109/TNN.2011.2106511; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; LeCun Y., 2004, P COMP VIS PATT REC, V2, pII, DOI 10.1109/CVPR.2004.1315150; LECUN Y, 2005, P ART INT STAT, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEE H, 2010, P ADV NEUR INF PROC, V22, P1; MAMMONE R, 1996, IEEE SIGNAL PROCESS, V13, P1; Martin A. F., 1997, P EUR 97 RHOD GREEC, V4, P1899; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D; Reynolds D. A., 1995, Lincoln Laboratory Journal, V8; Salakhutdinov R, 2007, P ART INT STAT, V2, P412; VINCENT P, 2007, P IEEE INT C SYST SY, P1; Wang L., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587704; Wang L, 2002, IEEE T NEURAL NETWOR, V13, P436, DOI 10.1109/72.991429; Zhang SX, 2011, IEEE T NEURAL NETWOR, V22, P173, DOI 10.1109/TNN.2010.2090893; RUSSIAN SPEECH CORPU	40	6	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	NOV	2011	22	11					1744	1756		10.1109/TNN.2011.2167240		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	840VM	WOS:000296469500006	21954206	
J	Theis, L; Gerwinn, S; Sinz, F; Bethge, M				Theis, Lucas; Gerwinn, Sebastian; Sinz, Fabian; Bethge, Matthias			In All Likelihood, Deep Belief Is Not Enough	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						deep belief network; restricted Boltzmann machine; likelihood estimation; natural image statistics; potential log-likelihood	NETWORKS	Statistical models of natural images provide an important tool for researchers in the fields of machine learning and computational neuroscience. The canonical measure to quantitatively assess and compare the performance of statistical models is given by the likelihood. One class of statistical models which has recently gained increasing popularity and has been applied to a variety of complex data is formed by deep belief networks. Analyses of these models, however, have often been limited to qualitative analyses based on samples due to the computationally intractable nature of their likelihood. Motivated by these circumstances, the present article introduces a consistent estimator for the likelihood of deep belief networks which is computationally tractable and simple to apply in practice. Using this estimator, we quantitatively investigate a deep belief network for natural image patches and compare its performance to the performance of other models for natural image patches. We find that the deep belief network is outperformed with respect to the likelihood even by very simple mixture models.	[Theis, Lucas; Gerwinn, Sebastian; Sinz, Fabian; Bethge, Matthias] Max Planck Inst Biol Cybernet, Werner Reichardt Ctr Integrat Neurosci, Bernstein Ctr Computat Neurosci, D-72076 Tubingen, Germany	Theis, L (reprint author), Max Planck Inst Biol Cybernet, Werner Reichardt Ctr Integrat Neurosci, Bernstein Ctr Computat Neurosci, Spemannstr 41, D-72076 Tubingen, Germany.	LUCAS.THEIS@TUEBINGEN.MPG.DE; SEBASTIAN.GERWINN@TUEBINGEN.MPG.DE; FABIAN.SINZ@TUEBINGEN.MPG.DE; MATTHIAS.BETHGE@TUEBINGEN.MPG.DE	Bethge, Matthias/B-1554-2008; Sinz, Fabian/E-6708-2010	Sinz, Fabian/0000-0002-1348-9736	German Ministry of Education, Science, Research and Technology (BMBF) [FKZ: 01GQ0601]; Max Planck Society	We would like to thank the anonymous reviewers for helpful comments and suggestions. We also thank Iain Murray for providing us with a binarized version of the MNIST data set. This work is supported by the German Ministry of Education, Science, Research and Technology through the Bernstein award to Matthias Bethge (BMBF, FKZ: 01GQ0601) and the Max Planck Society.	Bethge M, 2007, Patent, Patent No. [WO/2009/146933, 2009146933]; Chen S. S., 2001, Advances in Neural Information Processing Systems, P13; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Eichhorn J., 2009, PLoS Computational Biology, V5; Felleman D. J., 1991, Cerebral Cortex; Fukushima K., 1980, Biological Cybernetics; Guerrero-Colon JA, 2008, P 15 IEEE INT C IM P; Gutmann M., 2010, P 13 INT C ART INT S; Hinton G. E., 1995, Science; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hosseini R., 2009, Frontiers in Computational Neuroscience; Karklin Y., 2009, Nature; KONG A, 1994, J AM STAT ASSOC, V89, P278, DOI 10.2307/2291224; Le Roux N., 2010, Microsoft Research Technical Report (MSR-TR-2010-7); LeCun Y., 1989, NEURAL COMPUTATION; Lee H, 2007, ADV NEURAL INFORM PR, V19; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Long P., 2010; MacKay D., 2003, INFORM THEORY INFERE; MINKA T., 2005, MSRTR2005173; Mohamed A.R., 2009, NIPS 22 WORKSH DEEP; Murray I., 2009, ADV NEURAL INFORM PR, V21; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Ngiam J, 2011, P 28 INT C MACH LEAR; Osindero S., 2008, ADV NEURAL INFORM PR, V20; Ranzato M., 2010, P1; Ranzato M., 2010, ADV NEURAL INFORM PR, V23; Ranzato M., 2010, P 13 INT C ART INT S; Ranzato M. A., 2011; Salakhutdinov R., 2009, THESIS U TORONTO; Salakhutdinov R., 2008, P 25 INT C MACH LEAR; Selfridge O. G., 1958, P115; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sohl-Dickstein J., 2009, ARXIV09064779; Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; Taylor G.W., 2007, ADV NEURAL INFORM PR, V19; Tieleman T., 2008, P 25 INT C MACH LEAR; van Hateren JH, 1998, P ROYAL SOC B, V265; Welling M., 2005, ADV NEURAL INFORM PR, V17; Welling M., 2002; Younes L., 1989, Probability Theory and Related Fields	44	6	6	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	NOV	2011	12						3071	3096				26	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	862OW	WOS:000298103700001		
J	Vincent, P				Vincent, Pascal			A Connection Between Score Matching and Denoising Autoencoders	NEURAL COMPUTATION			English	Article							CONTRASTIVE DIVERGENCE	Denoising autoencoders have been previously shown to be competitive alternatives to restricted Boltzmann machines for unsupervised pretraining of each layer of a deep architecture. We show that a simple denoising autoencoder training criterion is equivalent to matching the score (with respect to the data) of a specific energy-based model to that of a nonparametric Parzen density estimator of the data. This yields several useful insights. It defines a proper probabilistic model for the denoising autoencoder technique, which makes it in principle possible to sample from them or rank examples by their energy. It suggests a different way to apply score matching that is related to learning to denoise and does not require computing second derivatives. It justifies the use of tied weights between the encoder and decoder and suggests ways to extend the success of denoising autoencoders to a larger family of energy-based models.	Univ Montreal, Dept Informat, Montreal, PQ H3C 3J7, Canada	Vincent, P (reprint author), Univ Montreal, Dept Informat, Montreal, PQ H3C 3J7, Canada.	vincentp@iro.umontreal.ca			NSERC; MITACS; FQRNT	I thank Yoshua Bengio, Olivier Delalleau, and the other members of the Lisa Lab who provided timely feedback, as well as two anonymous referees whose thoughtful comments and suggestions helped improve this note. This research was supported by NSERC, MITACS, and FQRNT.	Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Erhan D, 2010, J MACH LEARN RES, V11, P625; GALLINARI P, 1987, P COGNITIVA 87 PAR C; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2008, NEURAL COMPUT, V20, P3087, DOI 10.1162/neco.2008.10-06-384; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Hyvarinen A, 2007, IEEE T NEURAL NETWOR, V18, P1529, DOI 10.1109/TNN.2007.895819; Hyvarinen A, 2007, COMPUT STAT DATA AN, V51, P2499, DOI 10.1016/j.csda.2006.09.003; Kingma D., 2010, ADV NEURAL INFORM PR, V23, P1126; LeCun Y., 1987, THESIS U PARIS 6; LYU S, 2010, P 25 C UNC ART INT U; Marlin B., 2010, P 13 INT C ART INT S, V9, P509; Movellan JR, 2008, NEURAL COMPUT, V20, P2238, DOI 10.1162/neco.2008.01-07-430; SEUNG SH, 1998, ADV NEURAL INFORM PR, V10, P654; Sohl-Dickstein J., 2009, ARXIV09064779; Swersky K., 2010, THESIS U BRIT COLUMB; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; WELLING M, 2002, ICANN 02, P351	22	6	7	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	JUL	2011	23	7					1661	1674				14	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	767YT	WOS:000290897100001	21492012	
J	Harmeling, S; Williams, CKI				Harmeling, Stefan; Williams, Christopher K. I.			Greedy Learning of Binary Latent Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised learning; latent variable model; hierarchical latent class model; greedy methods	NETWORKS; MODELS	Inferring latent structures from observations helps to model and possibly also understand underlying data generating processes. A rich class of latent structures is the latent trees, i.e., tree-structured distributions involving latent variables where the visible variables are leaves. These are also called hierarchical latent class (HLC) models. Zhang and Kocka [21] proposed a search algorithm for learning such models in the spirit of Bayesian network structure learning. While such an approach can find good solutions, it can be computationally expensive. As an alternative, we investigate two greedy procedures: The BIN-G algorithm determines both the structure of the tree and the cardinality of the latent variables in a bottom-up fashion. The BIN-A algorithm first determines the tree structure using agglomerative hierarchical clustering, and then determines the cardinality of the latent variables as for BIN-G. We show that even with restricting ourselves to binary trees, we obtain HLC models of comparable quality to Zhang's solutions (in terms of cross-validated log-likelihood), while being generally faster to compute. This claim is validated by a comprehensive comparison on several data sets. Furthermore, we demonstrate that our methods are able to estimate interpretable latent structures on real-world data with a large number of variables. By applying our method to a restricted version of the 20 newsgroups data, these models turn out to be related to topic models, and on data from the PASCAL Visual Object Classes (VOC) 2007 challenge, we show how such tree-structured models help us understand how objects co-occur in images. For reproducibility of all experiments in this paper, all code and data sets (or links to data) are available at http://people.kyb.tuebingen.mpg.de/harmeling/code/ltt-1.4.tar.	[Harmeling, Stefan] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Williams, Christopher K. I.] Univ Edinburgh, Inst Adapt & Neural Computat, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Harmeling, S (reprint author), Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	stefan.harmeling@tuebingen.mpg.de; ckiw@inf.ed.ac.uk			European Community, under the PASCAL Network of Excellence [IST-2002-506778]	The authors thank Nevin L. Zhang for making compiled code of the algorithm in Zhang and Kocka [22] available, and Christoph Lampert for generating the vision data sets. They thank the anonymous reviewers for their comments that helped improve the paper; in particular, they thank the reviewer who pushed them to formalize the BIN-A algorithm and compare it with BIN-G. Furthermore, Stefan Harmeling thanks Dominik Janzing and Hannes Nickisch for general discussion. This work is supported in part by the IST Programme of the European Community, under the PASCAL Network of Excellence, IST-2002-506778. This publication reflects only the authors' views.	Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bollen Kenneth A., 1989, STRUCTURAL EQUATIONS; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CONNOLLY D, 1993, P 10 INT C MACH LEAR, P65; Duda R.O., 1973, PATTERN CLASSIFICATI; Felsenstein J, 2004, INFERRING PHYLOGENIE; Feng XJ, 2002, IEEE T PATTERN ANAL, V24, P467; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1007/BF00114265; FRIEDMAN N, 2003, 80 HEBR U; Heller K. A., 2005, P 22 INT C MACH LEAR, P297, DOI 10.1145/1102351.1102389; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105; Kohlmann T., 1997, APPL LATENT TRAIT LA; Kojadinovic I, 2004, COMPUT STAT DATA AN, V46, P269, DOI 10.1016/S0167-9473(03)00153-1; Lazarsfeld P. F., 1968, LATENT STRUCTURE ANA; Neal R. M., 2003, BAYESIAN STAT, V7, P619; Pearl J, 1988, PROBABILISTIC REASON; Teh Y. W., 2008, ADV NEURAL INFORM PR, V20; Wang Y, 2008, J ARTIF INTELL RES, V32, P879; WILLIAMS CKI, 2000, ADV NEURAL INFORM PR, V12; Zhang NL, 2004, J MACH LEARN RES, V5, P697; Zhang NL, 2004, P 16 IEEE INT C TOOL	22	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1087	1097		10.1109/TPAMI.2010.145		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	750DE	WOS:000289524000002	20714018	
J	Vinyals, O; Ravuri, SV			IEEE	Vinyals, Oriol; Ravuri, Suman V.			COMPARING MULTILAYER PERCEPTRON TO DEEP BELIEF NETWORK TANDEM FEATURES FOR ROBUST ASR	2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 22-27, 2011	Prague, CZECH REPUBLIC	Inst Elect & Elect Engineers Signal Processing Soc, IEEE	Prague Congress Ctr	Automatic Speech Recognition; Deep Belief Network; Multilayer Perceptron		In this paper, we extend the work done on integrating multilayer perceptron (MLP) networks with HMM systems via the Tandem approach. In particular, we explore whether the use of Deep Belief Networks (DBN) adds any substantial gain over MLPs on the Aurora2 speech recognition task under mismatched noise conditions. Our findings suggest that DBNs outperform single layer MLPs under the clean condition, but the gains diminish as the noise level is increased. Furthermore, using MFCCs in conjunction with the posteriors from DBNs outperforms merely using single DBNs in low to moderate noise conditions. MFCCs, however, do not help for the high noise settings.	[Vinyals, Oriol; Ravuri, Suman V.] Int Comp Sci Inst, Berkeley, CA 94704 USA	Vinyals, O (reprint author), Int Comp Sci Inst, Berkeley, CA 94704 USA.	vinyals@icsi.berkeley.edu; ravuri@icsi.berkeley.edu					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Deng L., 2010, P INT; HERMANSKY H, 1999, P ICASSP, P289; Hermansky H., 2000, P ICASSP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Mohamed A., 2009, NIPS WORKSH; Mohamed A.-R., 2010, P INT; Pearce D., 2000, ISCA ITRW ASR CHALLE; SHARMA S, 2000, P ICASSP IST JUN, P1117; QUICKNET	11	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4577-0539-7	INT CONF ACOUST SPEE			2011							4596	4599				4	Acoustics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Engineering; Imaging Science & Photographic Technology	BXG36	WOS:000296062405051		
J	Luciw, M; Weng, JY				Luciw, Matthew; Weng, Juyang (John)			Top-Down Connections in Self-Organizing Hebbian Networks: Topographic Class Grouping	IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT			English	Article						Autonomous feature extraction; deep networks; Hebbian learning; self-organization; top-down connections	COMPONENT ANALYSIS; CORTEX; EMERGENCE; MACAQUE	We investigate the effects of top-down input connections from a later layer to an earlier layer in a biologically inspired network. The incremental learning method combines optimal Hebbian learning for stable feature extraction, competitive lateral inhibition for sparse coding, and neighborhood-based self-organization for topographic map generation. The computational studies reported indicate top-down connections encourage features that reduce uncertainty at the lower layer with respect to the features in the higher layer, enable relevant information to be uncovered at the lower layer so that irrelevant information can preferentially be discarded [a necessary property for autonomous mental development (AMD)], and cause topographic class grouping. Class groups have been observed in cortex, e. g., in the fusiform face area and parahippocampal place area. This paper presents the first computational account, as far as we know, explaining these three phenomena by a single biologically inspired network. Visual recognition experiments show that top-down-enabled networks reduce error rates for limited network sizes, show class grouping, and can refine lower layer representation after new conceptual information is learned. These findings may shed light on how the brain self-organizes cortical areas, and may contribute to computational understanding of how autonomous agents might build and maintain an organized internal representation over its lifetime of experiences.	[Weng, Juyang (John)] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Luciw, M (reprint author), Dalle Molle Inst Artificial Intelligence IDSIA, CH-6928 Manno Lugano, Switzerland.	matthew@idsia.ch; weng@cse.msu.edu					Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow H. B., 1961, P331; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Braquelaire JP, 1997, IEEE T IMAGE PROCESS, V6, P1048, DOI 10.1109/83.597280; BULLIER J, 2004, PRIMATE VISUAL SYSTE, P181; Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; DAVAN P, 2001, THEORETICAL NEUROSCI; DESIMONE R, 1984, J NEUROSCI, V4, P2051; DOUGLAS RJ, 1995, SCIENCE, V269, P981, DOI 10.1126/science.7638624; Epstein R, 1998, NATURE, V392, P598, DOI 10.1038/33402; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Heskes T, 1999, KOHONEN MAPS, P303, DOI 10.1016/B978-044450270-4/50024-3; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hubel D. H., 1962, J PHYSL, V160, P107; Hyvarinen A, 2001, INDEPENDENT COMPONEN; JI Z, 2010, P IEEE WORLD C COMP; Kohonen T, 2001, SELF ORGANIZING MAPS; Kohonen T., 1997, SELF ORGANIZING MAPS; Kohonen T., 1998, NEURAL NETWORKS, V1, P3; Lampinen J, 2002, STUD FUZZ SOFT COMP, V78, P75; LeCun Y., 2004, P IEEE C COMP VIS PA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lehmann E. L, 1983, THEORY POINT ESTIMAT; LUCIW M, 2010, P IEEE WORLD C COMP; LUCIW M, 2009, P 9 INT C DEV LEARN; LUCIW MD, 2008, P INT JOINT C NEUR N; MAUNSELL JHR, 1983, J NEUROSCI, V3, P2563; Miikkulainen R, 2005, COMPUTATIONAL MAPS V; NAIR V, 2010, ADV NEURAL INFORM PR; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pan SM, 2007, PATTERN RECOGN, V40, P476, DOI 10.1016/j.patcog.2005.11.021; Schaal S, 1998, NEURAL COMPUT, V10, P2047, DOI 10.1162/089976698300016963; Sit YF, 2006, NEUROCOMPUTING, V69, P1309, DOI 10.1016/j.neucom.2005.12.098; Solgi M, 2009, IEEE T AUTON MENT DE, V1, P238, DOI 10.1109/TAMD.2009.2038360; Tanaka K, 1996, ANNU REV NEUROSCI, V19, P109, DOI 10.1146/annurev.ne.19.030196.000545; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; WU X, 1991, P DATA COMPRESSION C, P392	43	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1943-0604			IEEE T AUTON MENT DE	IEEE Trans. Auton. Ment. Dev.	SEP	2010	2	3					248	261		10.1109/TAMD.2010.2072150		14	Computer Science, Artificial Intelligence; Robotics; Neurosciences	Computer Science; Robotics; Neurosciences & Neurology	820JQ	WOS:000294902200006		
J	Mohamed, AR; Hinton, G			IEEE	Mohamed, Abdel-rahman; Hinton, Geoffrey			PHONE RECOGNITION USING RESTRICTED BOLTZMANN MACHINES	2010 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	2010 IEEE International Conference on Acoustics, Speech, and Signal Processing	MAR 14-19, 2010	Dallas, TX	IEEE Signal Proc Soc		phone recognition; restricted Boltzmann machines; distributed representations	NETS	For decades, Hidden Markov Models (HMMs) have been the state-of-the-art technique for acoustic modeling despite their unrealistic independence assumptions and the very limited representational capacity of their hidden states. Conditional Restricted Boltzmann Machines (CRBMs) have recently proved to be very effective for modeling motion capture sequences and this paper investigates the application of this more powerful type of generative model to acoustic modeling. On the standard TIMIT corpus, one type of CRBM outperforms HMMs and is comparable with the best other methods, achieving a phone error rate (PER) of 26.7% on the TIMIT core test set.	[Mohamed, Abdel-rahman; Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada	Mohamed, AR (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.						Deng L, 2007, INT CONF ACOUST SPEE, P445; Gillick L., 1989, P ICASSP, P532; Halberstadt A., 1998, P ICSLP; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HY, 2009, IEEE T AUDIO SPEECH, V17, P354; Lee K.F., 1989, IEEE T AUDIO SPEECH, V37, P16411648; MORIS J, 2006, P INT, P597; NAIR V, 2009, P NIPS; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Sha F, 2007, INT CONF ACOUST SPEE, P313; TAYLOR GW, 2007, P NIPS; WELLING M, 2005, P NIPS	14	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4244-4296-6	INT CONF ACOUST SPEE			2010							4354	4357		10.1109/ICASSP.2010.5495651		4	Acoustics; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Acoustics; Computer Science; Engineering	BTJ55	WOS:000287096004071		
J	Zhen, XT; Shao, L; Li, XL				Zhen, Xiantong; Shao, Ling; Li, Xuelong			Action recognition by spatio-temporal oriented energies	INFORMATION SCIENCES			English	Article						Action recognition; Steerable filters; Spatio-temporal oriented energies; Spatio-temporal Laplacian pyramid	SCENE CLASSIFICATION; VISUAL-ATTENTION; REPRESENTATION; MOTION; MODELS	In this paper, we present a unified representation based on the spatio-temporal steerable pyramid (STSP) for the holistic representation of human actions. A video sequence is viewed as a spatio-temporal volume preserving all the appearance and motion information of an action in it. By decomposing the spatio-temporal volumes into band-passed sub-volumes, the spatio-temporal Laplacian pyramid provides an effective technique for multi-scale analysis of video sequences, and spatio-temporal patterns with different scales could be well localized and captured. To efficiently explore the underlying local spatio-temporal orientation structures at multiple scales, a bank of three-dimensional separable steerable filters are conducted on each of the sub-volume from the Laplacian pyramid. The outputs of the quad-rature pair of steerable filters are squared and summed to yield a more robust oriented energy representation. To be further invariant and compact, a spatio-temporal max pooling operation is performed between responses of the filtering at adjacent scales and over spatio-temporal neighbourhoods. In order to capture the appearance, local geometric structure and motion of an action, we apply the STSP on the intensity, 3D gradients and optical flow of video sequences, yielding a unified holistic representation of human actions. Taking advantage of multi-scale, multi-orientation analysis and feature pooling, STSP produces a compact but informative and invariant representation of human actions. We conduct extensive experiments on the KTH, UCF Sports and HMDB51 datasets, which shows the unified STSP achieves comparable results with the state-of-the-art methods. (C) 2014 Elsevier Inc. All rights reserved.	[Zhen, Xiantong; Shao, Ling] Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China; [Zhen, Xiantong; Shao, Ling] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, State Key Lab Transient Opt & Photon, Xian 710119, Shaanxi, Peoples R China	Shao, L (reprint author), Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.	ling.shao@ieee.org			University of Sheffield; China Scholarship Council (CSC); National Natural Science Foundation of China [61125106]; Shaanxi Key Innovation Team of Science and Technology [2012KCT-04]	The authors acknowledge the support of the University of Sheffield, the China Scholarship Council (CSC), the National Natural Science Foundation of China (Grant No: 61125106), and Shaanxi Key Innovation Team of Science and Technology (Grant No: 2012KCT-04).	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008; Bobick A., 2002, IEEE T PATTERN ANAL, V23, P257; Boureau Y., 2010, INT C MACH LEARN; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; Cannons KJ, 2010, LECT NOTES COMPUT SC, V6314, P511, DOI 10.1007/978-3-642-15561-1_37; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Dalai N., 2005, INT C COMP VIS PATT, V1, P886, DOI DOI 10.1109/CVPR.2005.177; Deng X., 2012, NEUROCOMPUTING; Derpanis K., 2005, IEEE C IM PROC, V3, pIII; Derpanis KG, 2010, PROC CVPR IEEE, P1990, DOI 10.1109/CVPR.2010.5539874; Derpanis KG, 2009, PROC CVPR IEEE, P232; Dollar P, 2005, 2 JOINT IEEE INT WOR, P65, DOI DOI 10.1109/VSPETS.2005.1570899; Efros A.A., 2003, ICCV, V2, P726; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jhuang H, 2007, ICCV, P1, DOI [DOI 10.1109/ICCV.2007.4408988, 10.1109/ICCV.2007.4408988]; Ji S., 2010, INT C MACH LEARN; Jiang Y.G., 2012, EUR C COMP VIS, P425; Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018; Kliper-Gross O., 2012, ECCV, P256; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Kuehne H., 2011, IEEE INT C COMP VIS; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432; Laptev I., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587756; Lu ZW, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1503; Lucas B, 1981, P 7 INT JOINT C ART; Matikainen P, 2010, LECT NOTES COMPUT SC, V6311, P508, DOI 10.1007/978-3-642-15549-9_37; Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rodriguez M.D., 2008, IEEE C COMP VIS PATT, P1, DOI 10.1109/GLOCOM.2008.ECP.666; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Schindler K., 2008, IEEE C COMP VIS PATT, P1; Schuldt C., 2004, INT C PATT REC; Scovanner P., 2007, P 15 INT C MULT, P357, DOI 10.1145/1291233.1291311; Shao L, 2007, INFORM SCIENCES, V177, P1088, DOI 10.1016/j.ins.2006.09.003; Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939; Sun J, 2009, PROC CVPR IEEE, P2004; Taylor G.W., 2010, EUR C COMP VIS; Uemura H., 2008, P BMVA BRIT MACH VIS; Wang F., 2008, P 16 ACM INT C MULT, P239, DOI 10.1145/1459359.1459392; Wang H., 2011, IEEE C COMP VIS PATT, P3169; Wiles R., 2000, ECCV, P768; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201; Yilmaz A, 2005, PROC CVPR IEEE, P984; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212; Zhen X., 2013, P 10 IEEE INT C AUT; Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916	55	5	5	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255	1872-6291		INFORM SCIENCES	Inf. Sci.	OCT 10	2014	281						295	309		10.1016/j.ins.2014.05.021		15	Computer Science, Information Systems	Computer Science	AN1AR	WOS:000340315600019		
J	Peleg, T; Elad, M				Peleg, Tomer; Elad, Michael			A Statistical Prediction Model Based on Sparse Representations for Single Image Super-Resolution	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						Dictionary learning; feedforward neural networks; MMSE estimation; nonlinear prediction; single image super-resolution; sparse representations; statistical models; restricted Boltzmann machine; zooming deblurring	DICTIONARY; RECONSTRUCTION; INTERPOLATION; ESTIMATORS; REGRESSION; ALGORITHM	We address single image super-resolution using a statistical prediction model based on sparse representations of low-and high-resolution image patches. The suggested model allows us to avoid any invariance assumption, which is a common practice in sparsity-based approaches treating this task. Prediction of high resolution patches is obtained via MMSE estimation and the resulting scheme has the useful interpretation of a feedforward neural network. To further enhance performance, we suggest data clustering and cascading several levels of the basic algorithm. We suggest a training scheme for the resulting network and demonstrate the capabilities of our algorithm, showing its advantages over existing methods based on a low-and high-resolution dictionary pair, in terms of computational complexity, numerical criteria, and visual appearance. The suggested approach offers a desirable compromise between low computational complexity and reconstruction quality, when comparing it with state-of-the-art methods for single image super-resolution.	[Peleg, Tomer] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; [Elad, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Peleg, T (reprint author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	tomerfa@tx.technion.ac.il; elad@cs.technion.ac.il			European Research Council under EU; ERC [320649]; Intel Collaborative Research Institute for Computational Intelligence	This work was supported in part by the European Research Council under EU's 7th Framework Program, in part by ERC under Grant 320649, and in part by Intel Collaborative Research Institute for Computational Intelligence. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Brendt Wohlberg.	Adler A, 2010, LECT NOTES COMPUT SC, V6312, P622, DOI 10.1007/978-3-642-15552-9_45; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704; Burger H. C., 2012, P IEEE C COMP VIS PA, P4321; Cevher V., 2009, P ADV NEUR INF PROC, P257; Dong Weisheng, 2013, IEEE Trans Image Process, V22, P1620, DOI 10.1109/TIP.2012.2235847; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086; Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306; Elad M, 2009, IEEE T INFORM THEORY, V55, P4701, DOI 10.1109/TIT.2009.2027565; Farisu S., 2004, INT J IMAG SYST TECH, V14, P47; Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852; Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482; Garrigues P, 2008, P ADV NEURAL INFORM, V20, P505; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Hawe S, 2013, IEEE T IMAGE PROCESS, V22, P2138, DOI 10.1109/TIP.2013.2246175; He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; Peleg T, 2012, IEEE T SIGNAL PROCES, V60, P2286, DOI 10.1109/TSP.2012.2188520; Smolensky P., 1986, INFORM PROCESSING DY; Sun J., 2008, P IEEE C COMP VIS PA, P1, DOI 10.1145/1509315.1509373; Wang SL, 2012, PROC CVPR IEEE, P2216; Wolfe PJ, 2004, J ROY STAT SOC B, V66, P575, DOI 10.1111/j.1467-9868.2004.02052.x; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127; Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141; Yang Jack Y., 2008, International Journal of Functional Informatics and Personalised Medicine, V1, P1, DOI 10.1504/IJFIPM.2008.018289; Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743; Zeyde R., 2010, P 7 INT C CURV SURF, V6920, P711; Zhang KB, 2012, PROC CVPR IEEE, P1114; Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977; Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279	37	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149	1941-0042		IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	JUN	2014	23	6					2569	2582		10.1109/TIP.2014.2305844		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	AH3RA	WOS:000336041500008	24815620	
J	Hassanien, AE; Al-Shammari, ET; Ghali, NI				Hassanien, Aboul Ella; Al-Shammari, Eiman Tamah; Ghali, Neveen I.			Computational intelligence techniques in bioinformatics	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Review							MULTIPLE SEQUENCE ALIGNMENT; GENE-EXPRESSION DATA; PROTEIN-INTERACTION NETWORKS; NEURAL-NETWORKS; MICROARRAY DATA; FUZZY SETS; ROUGH SETS; PREDICTION; ALGORITHM; SELECTION	Computational intelligence (CI) is a well-established paradigm with current systems having many of the characteristics of biological computers and capable of performing a variety of tasks that are difficult to do using conventional techniques. It is a methodology involving adaptive mechanisms and/or an ability to learn that facilitate intelligent behavior in complex and changing environments, such that the system is perceived to possess one or more attributes of reason, such as generalization, discovery, association and abstraction. The objective of this article is to present to the CI and bioinformatics research communities some of the state-of-the-art in CI applications to bioinformatics and motivate research in new trend-setting directions. In this article, we present an overview of the CI techniques in bioinformatics. We will show how CI techniques including neural networks; restricted Boltzmann machine, deep belief network, fuzzy logic, rough sets, evolutionary algorithms (EA), genetic algorithms (GA), swarm intelligence, artificial immune systems and support vector machines, could be successfully employed to tackle various problems such as gene expression clustering and classification, protein sequence classification, gene selection, DNA fragment assembly, multiple sequence alignment, and protein function prediction and its structure. We discuss some representative methods to provide inspiring examples to illustrate how CI can be utilized to address these problems and how bioinformatics data can be characterized by CI. Challenges to be addressed and future directions of research are also presented and an extensive bibliography is included. (C) 2013 Elsevier Ltd. All rights reserved.	[Hassanien, Aboul Ella] Cairo Univ, Fac Comp & Informat, Giza, Egypt; [Al-Shammari, Eiman Tamah] Kuwait Univ, Fac Comp Sci & Engn, Kuwait, Kuwait; [Ghali, Neveen I.] Al Azhar Univ, Fac Sci, Cairo, Egypt; [Hassanien, Aboul Ella; Ghali, Neveen I.] Sci Res Grp Egypt, Giza, Egypt	Hassanien, AE (reprint author), Cairo Univ, Fac Comp & Informat, 5 Ahmed Zewal St, Giza, Egypt.	aboitcairo@fci-cu.edu.eg; eiman.tamah@gmail.com; dr.eiman@ku.edu.kw					Aaron M.N., 2010, BMC BIOINFORMATICS, P11; Abohamad W., 2010, 10 INT C INT SYST DE, P3; Altman RB, 2001, IEEE INTELL SYST, V16, P14, DOI 10.1109/5254.972065; AMIN II, 2012, 12 INT C INT SYST DE, P764; Angeleri E, 1999, Int J Neural Syst, V9, P523, DOI 10.1142/S0129065799000563; [Anonymous], 2002, IEEE COMPUTER, P35; Arenas M.G., 2011, IWANN, V1, P433; Arima C, 2008, J BIOSCI BIOENG, V105, P273, DOI 10.1263/jbb.105.273; Back T., 1996, EVOLUTIONARY ALGORIT; Banerjee M, 2007, IEEE T SYST MAN CY C, V37, P622, DOI 10.1109/TSMCC.2007.897498; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blanco A, 2002, INT J INTELL SYST, V17, P629, DOI 10.1002/int.10042; Blum C, 2005, PHYS LIFE REV, V2, P353, DOI 10.1016/j.plrev.2005.10.001; Bo Li, 2010, Computers in Biology and Medicine, V40, DOI 10.1016/j.compbiomed.2010.08.003; Brunak S., 1998, BIOINFORMATICS MACHI; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Busa-Fekete, 2008, STUDIES COMPUTATIONA, V94, P165; CARRILLO H, 1988, SIAM J APPL MATH, V48, P1073, DOI 10.1137/0148063; Chen S.-M., 2005, INT J APPL SCI ENG, V3, P89; Chen Y., 2006, P 20 INT C ADV INF N, P618; Chuang HY, 2007, MOL SYSTEMS BIOL, V3; Cios KJ, 2005, ARTIF INTELL MED, V35, P1, DOI 10.1016/j.artmed.2005.07.001; Cohen J, 2004, ACM COMPUT SURV, V36, P122, DOI 10.1145/1031120.1031122; Das, 2008, STUDIES COMPUTATIONA, V94, P113; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Enrique A., 2007, LECT NOTES COMPUTER, P1; Erten S, 2011, LECT N BIOINFORMAT, V6577, P54, DOI 10.1007/978-3-642-20036-6_7; Ezziane Z, 2006, EXPERT SYST APPL, V30, P2, DOI 10.1016/j.eswa.2005.09.042; Fasheng X., 2009, LECT NOTES COMPUTER, V5755, P965; Feng C., 2004, IEEE ANN M FUZZ INF, V2, P555; FENG DF, 1987, J MOL EVOL, V25, P351, DOI 10.1007/BF02603120; Fernando D., 2006, LNCS, V4224, P1087; Fogel D.B., 1999, EVOLUTIONARY COMPUTA; Fogel L.J., 1967, ARTIFICIAL INTELLIGE; Futschik M., 2002, P 2002 IEEE INT C, V1, P414; GLEN RC, 1995, J COMPUT AID MOL DES, V9, P181, DOI 10.1007/BF00124408; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Gruzdz A, 2006, INFORM SYST FRONT, V8, P21, DOI 10.1007/s10796-005-6100-x; Gusfield D., 2004, IEEE ACM T COMPUTATI, V1; Hai-Xia L., 2009, P 5 INT C NAT COMP I; Hassanien A., 2006, INT J HYBRID INTELLI, V3, P205; Hassanien A, 2007, IMAGE VISION COMPUT, V25, P172, DOI 10.1016/j.imavis.2006.01.026; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; He Y., 2006, 6 IEEE INT C DAT MIN, P153, DOI 10.1109/ICDMW.2006.84; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holland J.H., 1975, ADAPTATION NATURAL A, VOriginal; Horng JT, 2009, EXPERT SYST APPL, V36, P9072, DOI 10.1016/j.eswa.2008.12.037; Hu X., 2004, P 2 AS PAC BIOINF C, P297; Huawen Liu, 2010, Pattern Recognition, V43, DOI 10.1016/j.patcog.2010.02.008; Hwang K.B., 2000, P 1 C CRIT ASS MICR; Imade H, 2003, IEEE C EVOL COMPUTAT, P623; Jiao CY, 2008, INT CONF BIOMED, P302, DOI 10.1109/BMEI.2008.360; Juliusdottir T, 2005, Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology, P1; Kelemen A, 2008, STUD COMPUT INTELL, V85, P1; Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE, P1931; Kentzoglanakis K., 2011, IEEE ACM T COMPUT BI, P29; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Koza J.R., 1992, GENETIC PROGRAMMING; Larochelle H., 2008, P 25 INT C MACH LEAR, V307, P536; Layeb A, 2007, I C COMP SYST APPLIC, P336, DOI 10.1109/AICCSA.2007.370903; Li DF, 2006, LECT NOTES ARTIF INT, V4062, P778; Liang Kelemen, 2008, STUDIES COMPUTATIONA, V94, P149; Lin TC, 2006, PATTERN RECOGN, V39, P2426, DOI 10.1016/j.patcog.2006.01.004; Luscombe N. M., 2001, YB MED INFORM, P83; Mahanta MS, 2012, PATTERN RECOGN, V45, P821, DOI 10.1016/j.patcog.2011.07.024; Mahony S, 2006, NEURAL NETWORKS, V19, P950, DOI 10.1016/j.neunet.2006.05.023; Marchette D, 1999, PROCEEDINGS OF THE WORKSHOP ON INTRUSION DETECTION AND NETWORK MONITORING (ID '99), P119; Marcio D., 2010, EXPERT SYSTEMS APPL, V37, P7497; Midelfart H, 2002, FUND INFORM, V53, P155; Mitra S, 2006, IEEE T SYST MAN CY C, V36, P616, DOI 10.1109/TSMCC.2006.879384; Mitra S, 2004, PATTERN RECOGN LETT, V25, P1439, DOI [10.1016/j.patrec.2004.05.007, 10.1016/patrec.2004.05.007]; Mohamed A.R., 2009, NIPS 22 WORKSH DEEP; Morgado L., 2011, COMPUTATIONAL INTELL, V46, P90; Motsinger F.A., 2006, EVOWORKSHOPS 2006, V2006, P103; Nasser S, 2007, IEEE S COMP INT BIOI, P304; Nepomuceno J.A., 2011, BIODATA MINING, V4; Nguyen CD, 2011, J BIOMED INFORM, V44, P824, DOI 10.1016/j.jbi.2011.04.010; Nguyen H.T., 1999, 1 COURSE FUZZY LOGIC, V2nd; Noulas A.K., 2008, BELG DUTCH C ART INT; Okada Y, 2005, ARTIF INTELL MED, V35, P171, DOI 10.1016/j.artmed.2005.02.007; Pan Y., 2005, IEEE INT C GRAN COMP, V1, P13; Papageorgiou EI, 2012, NEUROCOMPUTING, V92, P28, DOI 10.1016/j.neucom.2011.08.034; Parpinelli RS, 2011, INT J BIO-INSPIR COM, V3, P1, DOI 10.1504/IJBIC.2011.038700; Pawlak Z., 1995, Communications of the ACM, V38, DOI 10.1145/219717.219791; Pawlak Z., 1991, ROUGH SETS THEORETIC; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PERELSON AS, 1979, J THEOR BIOL, V81, P645, DOI 10.1016/0022-5193(79)90275-3; Peterson DA, 2004, PROCEEDINGS OF THE 2004 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P56; Polkowski L., 2003, ROUGH SETS MATH FDN; Pradipta M., 2011, INT J APPROX REASON, V52, P408; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Ritchie MD, 2007, APPL SOFT COMPUT, V7, P471, DOI 10.1016/j.asoc.2006.01.013; Roberto A., 2009, ARTIF INTELL, V45, P173; Ruffino F, 2007, LECT NOTES ARTIF INT, V4578, P557; Shahla N., 2009, EXPERT SYSTEMS APPL, V36, P12086; Shan-Wen Zhang, 2010, Computers in Biology and Medicine, V40, DOI 10.1016/j.compbiomed.2010.02.007; Shen Q, 2009, COMPUT BIOL MED, V39, P646, DOI 10.1016/j.compbiomed.2009.04.008; Slezak D., 2006, 2006 INT C HYBR INF, V2, P265, DOI 10.1109/ICHIT.2006.253621; Slezak D, 2007, LECT NOTES ARTIF INT, V4481, P316; Smolinski T.G., 2008, STUDIES COMPUTATIONA, P122; Sun L., 2007, 4 INT C FUZZ SYST KN, V3, P167; Tang YC, 2005, ARTIF INTELL MED, V35, P121, DOI 10.1016/j.artmed.2005.02.003; Tasoulis D.K., 2008, COMPUTATIONAL INTELL; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Timmis J, 2000, BIOSYSTEMS, V55, P143, DOI 10.1016/S0303-2647(99)00092-1; Unger R, 2004, STRUCT BOND, V110, P153, DOI 10.1007/b13936; Valentini G, 2009, ARTIF INTELL MED, V45, P91, DOI 10.1016/j.artmed.2008.08.014; Vapnik V. N., 1998, STAT LEARNING THEORY; VENKATASUBRAMANIAN V, 1995, J CHEM INF COMP SCI, V35, P188, DOI 10.1021/ci00024a003; Wang W, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 6, PROCEEDINGS, P597, DOI 10.1109/ICNC.2008.263; Wannasak W., 2006, LECT NOTES COMPUTER, P1008; Weyde T., 2004, MATHWARE SOFT COMPUT, V11, P197; Xiao X., 2003, P 17 INT S PAR DISTR; Yang WY, 2011, J EXP THEOR ARTIF IN, V23, P79, DOI 10.1080/0952813X.2010.506303; Yu ZW, 2007, BIOINFORMATICS, V23, P2888, DOI 10.1093/bioinformatics/btm463; Yuhui Y., 2002, P 9 INT C INF PROC I, V5, P2228; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zhang GZ, 2004, IEEE IJCNN, P1179; Zhihua Du, 2008, Computational Biology and Chemistry, V32, DOI 10.1016/j.compbiolchem.2008.03.020; Zhou XW, 2009, CCDC 2009: 21ST CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-6, PROCEEDINGS, P1366	122	5	5	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271	1476-928X		COMPUT BIOL CHEM	Comput. Biol. Chem.	DEC	2013	47						37	47		10.1016/j.compbiolchem.2013.04.007		11	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	283TU	WOS:000329270700007	23891719	
J	Siniscalchi, SM; Li, JY; Lee, CH				Siniscalchi, Sabato Marco; Li, Jinyu; Lee, Chin-Hui			Hermitian Polynomial for Speaker Adaptation of Connectionist Speech Recognition Systems	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Artificial neural networks; model adaptation; speech processing	DEEP NEURAL-NETWORKS; MIXTURE OBSERVATIONS; MARKOV-CHAINS; MAXIMUM; TRANSFORMATIONS; MODELS	Model adaptation techniques are an efficient way to reduce the mismatch that typically occurs between the training and test condition of any automatic speech recognition (ASR) system. This work addresses the problem of increased degradation in performance when moving from speaker-dependent (SD) to speaker-independent (SI) conditions for connectionist (or hybrid) hidden Markov model/artificial neural network (HMM/ANN) systems in the context of large vocabulary continuous speech recognition (LVCSR). Adapting hybrid HMM/ANN systems on a small amount of adaptation data has been proven to be a difficult task, and has been a limiting factor in the widespread deployment of hybrid techniques in operational ASR systems. Addressing the crucial issue of speaker adaptation (SA) for hybrid HMM/ANN system can thereby have a great impact on the connectionist paradigm, which will play a major role in the design of next-generation LVCSR considering the great success reported by deep neural networks-ANNs with many hidden layers that adopts the pre-training technique-on many speech tasks. Current adaptation techniques for ANNs based on injecting an adaptable linear transformation network connected to either the input, or the output layer are not effective especially with a small amount of adaptation data, e. g., a single adaptation utterance. In this paper, a novel solution is proposed to overcome those limits and make it robust to scarce adaptation resources. The key idea is to adapt the hidden activation functions rather than the network weights. The adoption of Hermitian activation functions makes this possible. Experimental results on an LVCSR task demonstrate the effectiveness of the proposed approach.	[Siniscalchi, Sabato Marco] Kore Univ Enna, Dept Comp Engn, I-94100 Enna, Italy; [Siniscalchi, Sabato Marco; Lee, Chin-Hui] Georgia Inst Technol, Dept Elect & Comp Engn, Atlanta, GA 30332 USA; [Li, Jinyu] Microsoft Corp, Rendmond, WA 98052 USA	Siniscalchi, SM (reprint author), Kore Univ Enna, Dept Comp Engn, I-94100 Enna, Italy.	marco.siniscalchi@unikore.it; jinyli@microsoft.com; chl@ece.gatech.edu	Siniscalchi, Sabato Marco/	Siniscalchi, Sabato Marco/0000-0002-0770-0507			Abrash V., 1995, P EUROSPEECH 1995, P2183; Afify M, 2002, IEEE T SPEECH AUDI P, V10, P79, DOI 10.1109/89.985545; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P78, DOI 10.1109/MSP.2009.932707; Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DIGALAKIS VV, 1995, IEEE T SPEECH AUDI P, V3, P357, DOI 10.1109/89.466659; Duda R.O., 1973, PATTERN CLASSIFICATI; Gaglio S., 1999, P AI IA BOL IT SEP, P226; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Gales MJF, 1996, COMPUT SPEECH LANG, V10, P249, DOI 10.1006/csla.1996.0013; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gemello R, 2007, SPEECH COMMUN, V49, P827, DOI 10.1016/j.specom.2006.11.005; GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J; Gunawardana A., 2001, P EUR; Haykin S., 1994, NEURAL NETWORKS COMP; He X., 2006, P MMSP VICT BC CAN O; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huo Q, 1998, IEEE T SPEECH AUDI P, V6, P386; JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307; Kharin Y., 1996, ROBUSTNESS STAT PATT; Lee CH, 1998, SPEECH COMMUN, V25, P29, DOI 10.1016/S0167-6393(98)00028-4; Lee CH, 2000, P IEEE, V88, P1241; Lee L, 1996, INT CONF ACOUST SPEE, P353; Legetter C. J., 1995, COMPUTER SPEECH LANG, P171; Li B., 2010, P INTERSPEECH; Li X, 2006, INT CONF ACOUST SPEE, P237; Ma LY, 2005, IEEE T NEURAL NETWOR, V16, P821, DOI 10.1109/TNN.2005.851786; Neto J., 1995, P EUROSPEECH 1995, P2171; Paul D., 1992, P ICSLP, P899; Povey D., 2003, P INTERSPEECH; Rabiner L., 1993, FUNDAMENTALS SPEECH; Ripley BD, 1996, PATTERN RECOGNITION; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Seide F., 2011, P ASRU, P24; Shinoda K, 2001, IEEE T SPEECH AUDI P, V9, P276, DOI 10.1109/89.906001; Siniscalchi S. M., 2012, P INTERSPEECH; Siniscalchi SM, 2012, IEEE T AUDIO SPEECH, V20, P875, DOI 10.1109/TASL.2011.2167610; SINISCALCHI SM, 2007, P ASRU KYOT JAP, P566; Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008; Siniscalchi SM, 2010, INT CONF ACOUST SPEE, P4882, DOI 10.1109/ICASSP.2010.5495120; Siohan O, 2001, IEEE T SPEECH AUDI P, V9, P417, DOI 10.1109/89.917687; Tsakalidis S., 2002, P ICSLP; Vanhoucke V., 2013, P ICASSP; Wiesler S., 2010, P INTERSPEECH; Xue J., 2013, P INTERSPEECH; Yu D., 2013, P ICASSP; ZAVALIAGKOS G, 1995, INT CONF ACOUST SPEE, P676, DOI 10.1109/ICASSP.1995.479688	48	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	OCT	2013	21	10					2152	2161		10.1109/TASL.2013.2270370		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	190JE	WOS:000322334900014		
J	Koch, CP; Perna, AM; Weissmuller, S; Bauer, S; Pillong, M; Baleeiro, RB; Reutlinger, M; Folkers, G; Walden, P; Wrede, P; Hiss, JA; Waibler, Z; Schneider, G				Koch, Christian P.; Perna, Anna M.; Weissmueller, Sabrina; Bauer, Stefanie; Pillong, Max; Baleeiro, Renato B.; Reutlinger, Michael; Folkers, Gerd; Walden, Peter; Wrede, Paul; Hiss, Jan A.; Waibler, Zoe; Schneider, Gisbert			Exhaustive Proteome Mining for Functional MHC-I Ligands	ACS CHEMICAL BIOLOGY			English	Article							SUPPORT VECTOR MACHINES; VACCINE DESIGN; PREDICTION; IMMUNOINFORMATICS; CHALLENGE; MOLECULES; PEPTIDES; NETWORKS; MODELS; SYSTEM	We present the development and application of a new machine-learning approach to exhaustively and reliably identify major histocompatibility complex class I (MHC-I) ligands among all 20(8) octapeptides and in genome-derived proteomes of Mus musculus, influenza A H3N8, and vesicular stomatitis virus (VSV). Focusing on murine H-2K(b), we identified potent octapeptides exhibiting direct MHC-I binding and stabilization on the surface of TAP-deficient RMA-S cells. Computationally identified VSV-derived peptides induced CD8(+) T-cell proliferation after VSV-infection of mice. The study demonstrates that high-level machine-learning models provide a unique access to rationally designed peptides and a promising approach toward "reverse vaccinology".	[Koch, Christian P.; Perna, Anna M.; Pillong, Max; Reutlinger, Michael; Folkers, Gerd; Hiss, Jan A.; Schneider, Gisbert] ETH, Dept Chem & Appl Biosci, CH-8093 Zurich, Switzerland; [Weissmueller, Sabrina; Bauer, Stefanie; Waibler, Zoe] Paul Ehrlich Inst, D-63225 Langen, Germany; [Baleeiro, Renato B.; Walden, Peter] Charite Univ Med Berlin, Dept Dermatol Venerol & Allergol, D-10117 Berlin, Germany; [Folkers, Gerd] Coll Helveticum, CH-8092 Zurich, Switzerland; [Wrede, Paul] Charite Univ Med Berlin, D-14195 Berlin, Germany	Schneider, G (reprint author), ETH, Dept Chem & Appl Biosci, Wolfgang Pauli Str 10, CH-8093 Zurich, Switzerland.	gisbert.schneider@pharma.ethz.ch			ETH Zurich; Swiss National Science Foundation (SNF) [205321-134783]; Deutsche Forschungsgemeinschaft (DFG) [SFB 852]; BMBF [13N9197, 13N11455]; EU-FP7 (LEISHDNAVAX); DAAD, Germany; FAPESP, Brazil	The authors thank M. Bastian for helpful discussion and S. Haller for technical support. This research was supported by the ETH Zurich and the Swiss National Science Foundation (SNF, Grant No. 205321-134783 to G. Schneider). P. Wrede was supported by the Deutsche Forschungsgemeinschaft (DFG, SFB 852); P. Walden by the BMBF (13N9197 and 13N11455) and EU-FP7 (LEISHDNAVAX). R. B. Baleeiro received support from DAAD, Germany, and FAPESP, Brazil.	Agrafiotis DK, 2003, J COMPUT CHEM, V24, P1215, DOI 10.1002/jcc.10234; [Anonymous], 2012, MODLAB SLID TOOL MHC; Arens R, 2010, IMMUNOL REV, V235, P190, DOI 10.1111/j.0105-2896.2010.00899.x; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y, 2007, PROG BRAIN RES, V165, P521, DOI 10.1016/S0079-6123(06)65033-4; BOUVIER M, 1994, SCIENCE, V265, P398, DOI 10.1126/science.8023162; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chryssolouris G, 1996, IEEE T NEURAL NETWOR, V7, P229, DOI 10.1109/72.478409; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; De Groot AS, 2004, METHODS, V34, P425, DOI 10.1016/j.ymeth.2004.06.004; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Fridman A, 2012, ONCOIMMUNOLOGY, V1, P1258, DOI 10.4161/onci.21355; Givehchi A, 2005, MOL DIVERS, V9, P371, DOI 10.1007/s11030-005-6293-4; Hall M., 2009, ACM SIGKDD EXPLORATI, V11, P10, DOI DOI 10.1145/1656274.1656278; He Y, 2010, J BIOMED BIOTECHNOL, V2010, DOI DOI 10.1155/2010/218590; HILDEMANN WH, 1977, IMMUNOGENETICS, V5, P193, DOI 10.1007/BF01570476; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hiss JA, 2007, PROTEIN ENG DES SEL, V20, P99, DOI 10.1093/protein/gz1054; Hoof I, 2009, IMMUNOGENETICS, V61, P1, DOI 10.1007/s00251-008-0341-z; Iurescia S, 2012, BIOTECHNOL ADV, V30, P372, DOI 10.1016/j.biotechadv.2011.06.020; Janeway C.A., 2001, IMMUNOBIOLOGY IMMUNE; Koch CP, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003088; Koch CP, 2013, MOL INFORM, V32, P326, DOI 10.1002/minf.201300042; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mishra S, 2009, J BIOMOL STRUCT DYN, V27, P293; Ning X, 2012, J CHEM INF MODEL, V52, P38, DOI 10.1021/ci200346b; Peters B, 2005, PLOS BIOL, V3, P379, DOI 10.1371/journal.pbio.0030091; RAMMENSEE HG, 1993, ANNU REV IMMUNOL, V11, P213, DOI 10.1146/annurev.iy.11.040193.001241; Rammensee HG, 1999, IMMUNOGENETICS, V50, P213, DOI 10.1007/s002510050595; Rappuoli R, 2001, VACCINE, V19, P2688, DOI 10.1016/S0264-410X(00)00554-5; Riberdy JM, 1999, J VIROL, V73, P1453; Roberts A, 1999, J VIROL, V73, P3723; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schneider G, 1998, PROG BIOPHYS MOL BIO, V70, P175, DOI 10.1016/S0079-6107(98)00026-1; Senisterra G, 2012, ASSAY DRUG DEV TECHN, V10, P128, DOI 10.1089/adt.2011.0390; SESARDIC D, 1993, J MED MICROBIOL, V39, P241; Sharpe AH, 2009, IMMUNOL REV, V229, P5, DOI 10.1111/j.1600-065X.2009.00784.x; Tropsha A, 2010, MOL INFORM, V29, P476, DOI 10.1002/minf.201000061; UDAKA K, 1995, J EXP MED, V181, P2097, DOI 10.1084/jem.181.6.2097; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zhang H, 2009, BIOINFORMATICS, V25, P83, DOI 10.1093/bioinformatics/btn579	41	5	5	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1554-8929	1554-8937		ACS CHEM BIOL	ACS Chem. Biol.	SEP	2013	8	9					1876	1881		10.1021/cb400252t		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	294BF	WOS:000330016700004	23772559	
J	Si, ZZ; Zhu, SC				Si, Zhangzhang; Zhu, Song-Chun			Learning AND-OR Templates for Object Recognition and Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deformable templates; object recognition; image grammar; information projection	MODELS; SEGMENTATION	This paper presents a framework for unsupervised learning of a hierarchical reconfigurable image template-the AND-OR Template (AOT) for visual objects. The AOT includes: 1) hierarchical composition as "AND" nodes, 2) deformation and articulation of parts as geometric "OR" nodes, and 3) multiple ways of composition as structural "OR" nodes. The terminal nodes are hybrid image templates (HIT) [17] that are fully generative to the pixels. We show that both the structures and parameters of the AOT model can be learned in an unsupervised way from images using an information projection principle. The learning algorithm consists of two steps: 1) a recursive block pursuit procedure to learn the hierarchical dictionary of primitives, parts, and objects, and 2) a graph compression procedure to minimize model structure for better generalizability. We investigate the factors that influence how well the learning algorithm can identify the underlying AOT. And we propose a number of ways to evaluate the performance of the learned AOTs through both synthesized examples and real-world images. Our model advances the state of the art for object detection by improving the accuracy of template matching.	[Si, Zhangzhang; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Si, ZZ (reprint author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	zzsi@stat.ucla.edu; sczhu@stat.ucla.edu			US Defense Advanced Research Projects Agency (DARPA) [FA 8650-11-1-7149]; US National Science Foundation (NSF) [IIS1018751]; MURI [ONR N00014-10-1-0933]	The authors thank Dr. Ying Nian Wu for detailed suggestions on both the theory and experiments for this paper. This work was supported by the US Defense Advanced Research Projects Agency (DARPA) Grant FA 8650-11-1-7149, US National Science Foundation (NSF) IIS1018751, and MURI Grant ONR N00014-10-1-0933.	Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Chang LB, 2011, INT J COMPUT VISION, V93, P117, DOI 10.1007/s11263-010-0391-1; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dalai N., 2005, P IEEE C COMP VIS PA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fidler S., 2010, P 11 EUR C COMP VIS; Guillaumin M., 2009, P 12 IEEE INT C COMP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jin Y., 2006, P IEEE C COMP VIS PA; Leonardis A., 2007, P IEEE C COMP VIS PA; Pietra S. D., 1997, IEEE T PATTERN ANAL, V19, P380; Schiele B., 2009, P IEEE C COMP VIS PA; Schwarz G., 1978, ANN STAT, V6, P464; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Si ZZ, 2012, IEEE T PATTERN ANAL, V34, P1354, DOI 10.1109/TPAMI.2011.227; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0; Yang Y., 2011, P IEEE C COMP VIS PA; Zhu L., 2010, P IEEE C COMP VIS PA; Zhu L, 2009, IEEE T PATTERN ANAL, V31, P114, DOI 10.1109/TPAMI.2008.67; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	25	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2189	2205		10.1109/TPAMI.2013.35		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	186GB	WOS:000322029000011	23868779	
J	Shin, HC; Orton, MR; Collins, DJ; Doran, SJ; Leach, MO				Shin, Hoo-Chang; Orton, Matthew R.; Collins, David J.; Doran, Simon J.; Leach, Martin O.			Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4D Patient Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Edge and feature detection; object recognition; pixel classification; machine learning; biomedical image processing	TUMOR SEGMENTATION; CLASSIFICATION; IMAGES; REPRESENTATIONS; OPTIMIZATION; CATEGORIES; STRATEGIES; ALGORITHM; NETWORKS; CT	Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection, with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images, despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets.	[Shin, Hoo-Chang; Orton, Matthew R.; Collins, David J.; Doran, Simon J.; Leach, Martin O.] Inst Canc Res, Sutton, Surrey, England; [Shin, Hoo-Chang; Orton, Matthew R.; Collins, David J.; Doran, Simon J.; Leach, Martin O.] Royal Marsden NHS Fdn Trust, Sutton, Surrey, England	Shin, HC (reprint author), Inst Canc Res, Sutton, Surrey, England.	hoo.shin@icr.ac.uk; matthew.orton@icr.ac.uk; david.collins@icr.ac.uk; simon.doran@icr.ac.uk; martin.leach@icr.ac.uk	leach, martin/C-2248-2008	leach, martin/0000-0002-0756-5368	CRUK; EPSRC Cancer Imaging Centre; MRC; Department of Health (England) [C1060/A10334]; NHS	The authors would like to acknowledge the support received from the CRUK and EPSRC Cancer Imaging Centre in association with the MRC and the Department of Health (England) grant C1060/A10334 and also NHS funding to the NIHR Biomedical Research Centre and the NIHR Clinical Research Facility.	and L. Li, 2011, P INT C MACH LEARN, P185; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404; Bazzani L., 2011, P 28 INT C MACH LEAR, P937; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bernstein EJ, 2005, PROC CVPR IEEE, P734; Clark MC, 1998, IEEE T MED IMAGING, V17, P187, DOI 10.1109/42.700731; Coates A., 2011, P 14 INT C ART INT S, V15, P215; Collins DJ, 2004, IEEE ENG MED BIOL, V23, P65, DOI 10.1109/MEMB.2004.1360410; Corso JJ, 2008, IEEE T MED IMAGING, V27, P629, DOI 10.1109/TMI.2007.912817; Dalal N, 2005, PROC CVPR IEEE, P886; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Farhangfar A., 2009, P 26 ANN INT C MACH, P305; Fei-Fei Li, 2006, IEEE Trans Pattern Anal Mach Intell, V28, P594; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fergus R, 2003, PROC CVPR IEEE, P264; Geremia E, 2010, LECT NOTES COMPUT SC, V6361, P111; Glorot X., 2011, P 28 INT C MACH LEAR, P513; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646; Griffin G., 2007, TECHNICAL REPORT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; Iglesias JE, 2011, LECT NOTES COMPUT SC, V6801, P25, DOI 10.1007/978-3-642-22092-0_3; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lazebnik S., 2006, P IEEE C COMP VIS PA, P2169; Le Q, 2011, ADV NEURAL INFORM PR, V24, P1017; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Linguraru MG, 2008, I S BIOMED IMAGING, P45, DOI 10.1109/ISBI.2008.4540928; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Marc'Aurelio R., 2007, ADV NEURAL INFORM PR, V20; Ngiam J, 2011, P INT C MACH LEARN; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Okada T, 2008, LECT NOTES COMPUT SC, V5241, P502, DOI 10.1007/978-3-540-85988-8_60; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Orton MR, 2009, PHYS MED BIOL, V54, P2197, DOI 10.1088/0031-9155/54/7/023; Padhani Anwar R, 2009, Neoplasia, V11, P102; Pauly O, 2011, LECT NOTES COMPUT SC, V6893, P239, DOI 10.1007/978-3-642-23626-6_30; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Rumelhart D.E., 1986, INFORM PROCESSING DY, V1, P194; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Shin H., 2011, P IEEE INT C MACH LE, P259; Shin H.-C., 2012, P WORKSH CHALL MED I; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Snoek J., 2012, P ADV NEUR INF PROC; Sohn K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2643; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Weber M, 2000, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2000.854754; Yu K., 2008, ADV NEURAL INFORM PR, V21, P1889; Zeiler MD, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2018, DOI 10.1109/ICCV.2011.6126474	59	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1930	1943		10.1109/TPAMI.2012.277		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	164AP	WOS:000320381400009	23787345	
J	Bo, LF; Ren, XF; Fox, D			IEEE	Bo, Liefeng; Ren, Xiaofeng; Fox, Dieter			Multipath Sparse Coding Using Hierarchical Matching Pursuit	2013 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2013	Portland, OR	IEEE, IEEE Comp Soc			ALGORITHM	Complex real-world signals, such as images, contain discriminative structures that differ in many aspects including scale, invariance, and data channel. While progress in deep learning shows the importance of learning features through multiple layers, it is equally important to learn features through multiple paths. We propose Multipath Hierarchical Matching Pursuit (M-HMP), a novel feature learning architecture that combines a collection of hierarchical sparse features for image classification to capture multiple aspects of discriminative structures. Our building blocks are MI-KSVD, a codebook learning algorithm that balances the reconstruction error and the mutual incoherence of the codebook, and batch orthogonal matching pursuit (OMP); we apply them recursively at varying layers and scales. The result is a highly discriminative image representation that leads to large improvements to the state-of-the-art on many standard benchmarks, e. g., Caltech-101, Caltech-256, MIT-Scenes, Oxford-IIIT Pet and Caltech-UCSD Bird-200.			liefeng.bo@intel.com; xren@cs.washington.edu; fox@cs.washington.edu					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bo L., 2010, NIPS; Bo L., 2011, NIPS; Bo L, 2012, ISER; Boureau Y., 2011, ICCV; Branson S., 2010, ECCV; Candes E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008; Chatfield K., 2011, BMVC; Coates A., 2011, ICML; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gehler P., 2009, ICCV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jiang Z., 2011, CVPR; Khan F., 2011, NIPS; Krizhevsky A., 2012, NIPS; Lazebnik S., 2006, CVPR; Le Q.V., 2012, ICML; Lee H., 2009, ICML; Mairal J., 2008, CVPR; McCann S., 2012, CVPR; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pandey M., 2011, ICCV; Parizi S. N., 2012, CVPR; Parkhi O., 2012, CVPR; Pati Y. C., 1993, P 27 AS C SIGN SYST, V1, P40, DOI DOI 10.1109/ACSSC.1993.342465; Ramirez I., 2010, CVPR; Sohn K., 2011, ICCV; Wang J., 2010, CVPR; Yang J., 2009, CVPR; Yang S., 2012, NIPS; Yao B., 2011, CVPR; Yu K., 2011, CVPR; Zeiler M. D., 2011, ICCV; Zhang N., 2012, CVPR	34	5	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-0-7695-4989-7	PROC CVPR IEEE			2013							660	667		10.1109/CVPR.2013.91		8	Computer Science, Artificial Intelligence	Computer Science	BA0ER	WOS:000331094300084		
J	Gehring, J; Miao, YJ; Metze, F; Waibel, A			IEEE	Gehring, Jonas; Miao, Yajie; Metze, Florian; Waibel, Alex			EXTRACTING DEEP BOTTLENECK FEATURES USING STACKED AUTO-ENCODERS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Bottleneck features; Deep learning; Auto-encoders		In this work, a novel training scheme for generating bottleneck features from deep neural networks is proposed. A stack of denoising auto-encoders is first trained in a layer-wise, unsupervised manner. Afterwards, the bottleneck layer and an additional layer are added and the whole network is fine-tuned to predict target phoneme states. We perform experiments on a Cantonese conversational telephone speech corpus and find that increasing the number of auto-encoders in the network produces more useful features, but requires pre-training, especially when little training data is available. Using more unlabeled data for pre-training only yields additional gains. Evaluations on larger datasets and on different system setups demonstrate the general applicability of our approach. In terms of word error rate, relative improvements of 9.2% (Cantonese, ML training), 9.3% (Tagalog, BMMI-SAT training), 12% (Tagalog, confusion network combinations with MFCCs), and 8.7% (Switchboard) are achieved.	[Gehring, Jonas; Waibel, Alex] Karlsruhe Inst Technol, Interact Syst Lab, D-76021 Karlsruhe, Germany	Gehring, J (reprint author), Karlsruhe Inst Technol, Interact Syst Lab, D-76021 Karlsruhe, Germany.	jonas.gehring@kit.edu; ymiao@cs.cmu.edu	Metze, Florian/N-4661-2014	Metze, Florian/0000-0002-6663-8600			Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bergstra J., 2010, P PYTH SCI COMP C SC; Bourlard H., 1994, CONNECTIONIST SPEECH, V247; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Finke M, 1997, INT CONF ACOUST SPEE, P83, DOI 10.1109/ICASSP.1997.599552; Godfrey J.J., 1992, AC SPEECH SIGN PROC, V1, P517; Grezl F, 2008, INT CONF ACOUST SPEE, P4729, DOI 10.1109/ICASSP.2008.4518713; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G., 2012, IEEE SIGNAL PROCESSI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lippmann R. P., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.1; Mangu L., 2011, AUT SPEECH REC UND A, P272; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; Ranzato M, 2007, COMPUTER VISION PATT, P1; Sainath TN, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4153; Schaaf T., 2010, P INTERSPEECH; Seide F., 2011, P INTERSPEECH, P437; Soltau H, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P214; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Yu D., 2011, P INTERSPEECH, P237	21	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							3377	3381				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611503107		
J	Kim, Y; Lee, H; Provost, EM			IEEE	Kim, Yelin; Lee, Honglak; Provost, Emily Mower			DEEP LEARNING FOR ROBUST FEATURE GENERATION IN AUDIOVISUAL EMOTION RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		emotion classification; deep learning; multimodal features; unsupervised feature learning; deep belief networks	FEATURE-SELECTION; CLASSIFICATION; SPEECH	Automatic emotion recognition systems predict high-level affective content from low-level human-centered signal cues. These systems have seen great improvements in classification accuracy, due in part to advances in feature selection methods. However, many of these feature selection methods capture only linear relationships between features or alternatively require the use of labeled data. In this paper we focus on deep learning techniques, which can overcome these limitations by explicitly capturing complex non-linear feature interactions in multimodal data. We propose and evaluate a suite of Deep Belief Network models, and demonstrate that these models show improvement in emotion classification performance over baselines that do not employ deep learning. This suggests that the learned high-order non-linear relationships are effective for emotion recognition.	[Kim, Yelin; Lee, Honglak; Provost, Emily Mower] Univ Michigan, Ann Arbor, MI 48109 USA	Kim, Y (reprint author), Univ Michigan, Ann Arbor, MI 48109 USA.	yelinkim@umich.edu; honglak@umich.edu; emilykmp@umich.edu					Anagnostopoulos C.N., 2012, ARTIF INTELL, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Brueckner R., 2012, P INTERSPEECH; Busso C, 2007, IEEE T AUDIO SPEECH, V15, P2331, DOI 10.1109/TASL.2007.905145; Busso C., 2007, P INT 07 EUR ANTW BE, P2225; Busso C., 2004, P 6 INT C MULT INT, P205, DOI 10.1145/1027933.1027968; Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6; Duch W, 2003, ADV SOFT COMP, P173; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lu Y., 2007, P 15 INT C MULT, P301, DOI 10.1145/1291233.1291297; Metallinou A, 2010, INT CONF ACOUST SPEE, P2462, DOI 10.1109/ICASSP.2010.5494890; Metallinou A, 2010, INT CONF ACOUST SPEE, P2474, DOI 10.1109/ICASSP.2010.5494893; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Mower E, 2011, IEEE T AUDIO SPEECH, V19, P1057, DOI 10.1109/TASL.2010.2076804; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Pantic M, 2011, COGN TECHNOL, P115, DOI 10.1007/978-3-642-15184-2_8; Polzehl T, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P340; Schuller B., 2012, INT 2012 SPEAK TRAIT; Schuller B., 2009, P INTERSPEECH, P312; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sohn K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2643; Steidl S, 2005, INT CONF ACOUST SPEE, P317; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Tang Y., 2010, INT C MACH LEARN CIT, V28; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Ververidis D, 2008, SIGNAL PROCESS, V88, P2956, DOI 10.1016/j.sigpro.2008.07.001; Vogt T, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P474, DOI 10.1109/ICME.2005.1521463; Wimmer M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P145; WOLLMER M, 2010, P INTERSPEECH C, P2362	37	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							3687	3691				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611503169		
J	Le Roux, N; Heess, N; Shotton, J; Winn, J				Le Roux, Nicolas; Heess, Nicolas; Shotton, Jamie; Winn, John			Learning a Generative Model of Images by Factoring Appearance and Shape	NEURAL COMPUTATION			English	Article							NATURAL IMAGES; DYNAMIC TREES; ALGORITHM; SEGMENTATION; RECOGNITION; LIKELIHOOD; EMERGENCE; TEXTURE	Computer vision has grown tremendously in the past two decades. Despite all efforts, existing attempts at matching parts of the human visual system's extraordinary ability to understand visual scenes lack either scope or power. By combining the advantages of general low-level generative models and powerful layer-based and hierarchical models, this work aims at being a first step toward richer, more flexible models of images. After comparing various types of restricted Boltzmann machines (RBMs) able to model continuous-valued data, we introduce our basic model, the masked RBM, which explicitly models occlusion boundaries in image patches by factoring the appearance of any patch region from its shape. We then propose a generative model of larger images using a field of such RBMs. Finally, we discuss how masked RBMs could be stacked to form a deep model able to generate more complicated structures and suitable for various tasks such as segmentation or object recognition.	[Le Roux, Nicolas; Shotton, Jamie; Winn, John] Microsoft Res Cambridge, Machine Learning & Percept, Cambridge CB3 0FB, England; [Heess, Nicolas] Univ Edinburgh, Sch Informat, Inst Adapt & Neural Computat, Neuroinformat & Computat Neurosci Doctoral Traini, Edinburgh EH8 9AB, Midlothian, Scotland	Le Roux, N (reprint author), Microsoft Res Cambridge, Machine Learning & Percept, Cambridge CB3 0FB, England.	nicolas@le-roux.name; n.m.o.heess@sms.ed.ac.uk; jamiesho@microsoft.com; jwinn@microsoft.com			Neuroinformatics and Computational Neuroscience Doctoral Training Centre at the University of Edinburgh	We thank Chris Williams for his support and help and lain Murray for insightful comments. N.H. is supported by an Engineering and Physical Sciences Research Council/Medical Research Council scholarship from the Neuroinformatics and Computational Neuroscience Doctoral Training Centre at the University of Edinburgh.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; BIENENSTOCK E, 1997, NEURAL INFORM PROCES, P838; BOUCHARD G, 2005, CVPR, V1, P710; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; FIDLER S, 2007, 2007 IEEE COMP SOC C; Freund Y., 1994, UCSCCRL9425; FREY BJ, 2003, P IEEE C COMP VIS PA; Guo CE, 2003, INT J COMPUT VISION, V53, P5, DOI 10.1023/A:1023023207396; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2000, ADV NEUR IN, V12, P463; Hyvarinen A, 2001, NEURAL COMPUT, V13, P1527, DOI 10.1162/089976601750264992; Jin Y., 2006, CVPR, P2145; KANNAN A, 2006, ADV NEURAL INFORM PR, V19; KANNAN A, 2005, P 10 ANN WOR ART INT; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Larochelle H., 2007, 24 INT C MACH LEARN, P473; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; Lee H., 2008, ADV NEURAL INFORM PR, V20; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587; LUETTGEN MR, 1995, IEEE T IMAGE PROCESS, V4, P194, DOI 10.1109/83.342185; NAIR V, 2010, 27 INT C MACH LEARN; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ommer B, 2010, IEEE T PATTERN ANAL, V32, P501, DOI 10.1109/TPAMI.2009.22; OSINDERO S, 2008, NEURAL INFORM PROCES, V20; Raina R., 2009, ICML 09, P873; Roth S., 2005, P IEEE C COMP VIS PA, V2, P860; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, V22; Salakhutdinov R., 2008, P 25 ANN INT C MACH; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Storkey AJ, 2003, IEEE T PATTERN ANAL, V25, P859, DOI 10.1109/TPAMI.2003.1206515; TIELEMAN T, 2008, P INT C MACH LEARN, V25; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Welling M., 2005, ADV NEURAL INFORM PR, V17; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096; Williams CKI, 1999, ADV NEUR IN, V11, P634; WINN J, 2005, IEEE INT C COMP VIS, V1, P756; ZHU LL, 2008, ECCV, P759; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	42	5	5	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	MAR	2011	23	3					593	650		10.1162/NECO_a_00086		58	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	716YD	WOS:000287008500001	21162663	
J	Dines, J; Yamagishi, J; King, S				Dines, John; Yamagishi, Junichi; King, Simon			Measuring the Gap Between HMM-Based ASR and TTS	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING			English	Article						Speech recognition; speech synthesis; unified models	HIDDEN MARKOV-MODELS; SPEECH SYNTHESIS; SPEAKER ADAPTATION; RECOGNITION; REPRESENTATIONS; ALGORITHM; SYSTEMS; ERROR; TIME	The EMIME European project is conducting research in the development of technologies for mobile, personalized speech-to-speech translation systems. The hidden Markov model (HMM) is being used as the underlying technology in both automatic speech recognition (ASR) and text-to-speech synthesis (TTS) components; thus, the investigation of unified statistical modeling approaches has become an implicit goal of our research. As one of the first steps towards this goal, we have been investigating commonalities and differences between HMM-based ASR and TTS. In this paper, we present results and analysis of a series of experiments that have been conducted on English ASR and TTS systems measuring their performance with respect to phone set and lexicon, acoustic feature type and dimensionality, HMM topology, and speaker adaptation. Our results show that, although the fundamental statistical model may be essentially the same, optimal ASR and TTS performance often demands diametrically opposed system designs. This represents a major challenge to be addressed in the investigation of such unified modeling approaches.	[Dines, John] Idiap Res Inst, CH-1920 Martigny, Switzerland; [Yamagishi, Junichi; King, Simon] Univ Edinburgh, CSTR, Edinburgh EH8 9AB, Midlothian, Scotland	Dines, J (reprint author), Idiap Res Inst, CH-1920 Martigny, Switzerland.	john.dines@idiap.ch; jyamagis@inf.ed.ac.uk; simon.king@ed.ac.uk			European Community [FP7/2007-2013, 213845]; EPSRC	The research leading to these results was supported in part by the European Community's Seventh Framework Program (FP7/2007-2013) under Grant Agreement 213845 (the EMIME project). S. King holds an EPSRC Advanced Research Fellowship. The work of J. Yamagishi was supported in part by EPSRC.	Anastasakos T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1137; BARNWELL TP, 1980, P IEEE INT C AC SPEE, P706; Bengio Y., 2007, 1312 U MONTR; BENGIO Y, 2006, 1304 U MONTR; BISANI M, 1994, P ICASSP 94 MONTR QC, V1, P409; BROWN P, 1987, THESIS CARNEGGIE MEL; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; DENG L, 1999, P EUR C SPEECH COMM, P1499; DENG L, 1992, SIGNAL PROCESS, V27, P65, DOI 10.1016/0165-1684(92)90112-A; Digalakis VV, 1996, IEEE T SPEECH AUDI P, V4, P294, DOI 10.1109/89.506933; Dines J., 2009, P INT BRIGHT UK SEP, P1395; Dines J., 2009, P INT 09 BRIGHT UK S, P1391; Dines J., 2001, ACOUST SPEECH SIG PR, P833; Dupont S, 1997, INT CONF ACOUST SPEE, P1767, DOI 10.1109/ICASSP.1997.598872; FITT S, 1999, P EUR, V2, P823; Fukada T., 1992, P ICASSP, P137, DOI 10.1109/ICASSP.1992.225953; FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530; Gales Mark, 2007, Foundations and Trends in Signal Processing, V1, DOI 10.1561/2000000004; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Garau G, 2008, IEEE T AUDIO SPEECH, V16, P508, DOI 10.1109/TASL.2008.916519; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gibson M., 2009, P INT BRIGHT UK SEP, P1791; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; HAIN T, 2001, THESIS CAMBRIDGE U C; HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; IRINO T, 2002, P ICSLP, P2545; Karaiskos V., 2008, P BLIZZ CHALL WORKSH; Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5; King S, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1869; Kitamura T., 1986, Electronics and Communications in Japan, Part 1 (Communications), V69, DOI 10.1002/ecja.4410691006; Koishida K., 1994, P ICSLP YOK JAP SEP, V3, P1043; Kubichek R., 1993, P IEEE PAC RIM C COM, V1, P125, DOI 10.1109/PACRIM.1993.407206; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Leggetter C. J., 1995, P ARPA SPOK LANG TEC, P104; Liang H., 2010, P ICASSP DALL TX, P4598; Mesot B, 2007, IEEE T AUDIO SPEECH, V15, P1850, DOI 10.1109/TASL.2007.901312; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Nakano Y, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2286; Nankaku Y, 2008, INT CONF ACOUST SPEE, P4469; Odell J. J., 1995, THESIS U CAMBRIDGE C; Ostendorf M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON SPEECH SYNTHESIS, P99, DOI 10.1109/WSS.2002.1224382; Oura K, 2006, INT CONF ACOUST SPEE, P33; PALLET D, 1992, P WORKSH SPEECH NAT, P382, DOI 10.3115/1075527.1075620; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Prahallad K, 2006, INT CONF ACOUST SPEE, P853; QIAN Y, 2006, P ISCSLP, P223; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Reynolds DA, 1994, IEEE T SPEECH AUDI P, V2, P639, DOI 10.1109/89.326623; SHANNON M, 2009, P INT BRIGHT UK; SHANNON M, 2010, P INT MAK JAP; Shinoda K., 2000, Journal of the Acoustical Society of Japan (E), V21, DOI 10.1250/ast.21.79; Shinoda K., 1997, P EUROSPEECH, V1, P99; Siohan O, 2002, COMPUT SPEECH LANG, V16, P5, DOI 10.1006/csla.2001.0181; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Toda T, 2007, IEICE T INF SYST, VE90D, P816, DOI 10.1093/ietisy/e90-d.5.816; Tokuda K., HMM BASED SPEECH SYN; Tokuda K., 2003, P EUR, P865; Tokuda K., 2004, TEXT SPEECH SYNTHESI; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Verola M., 1989, P EUROSPEECH, P187; Wellekens C., 1987, P INT C AC SPEECH SI, V12, P384; Wu YJ, 2006, INT CONF ACOUST SPEE, P89; Yamagishi J., 2008, P BLIZZ CHALL WORKSH; Yamagishi J, 2009, IEEE T AUDIO SPEECH, V17, P66, DOI 10.1109/TASL.2008.2006647; Yamagishi J, 2010, IEEE T AUDIO SPEECH, V18, P984, DOI 10.1109/TASL.2010.2045237; Yamagishi J., 2009, P INT BRIGHT UK SEP, P420; Yamagishi J, 2007, IEICE T INF SYST, VE90D, P533, DOI 10.1093/ietisy/e90-d.2.533; Yamagishi J, 2009, IEEE T AUDIO SPEECH, V17, P1208, DOI 10.1109/TASL.2009.2016394; Yoshimura T., 1999, P EUR, P2347; Young S., 2006, HTK BOOK; Yu SZ, 2009, ARTIF INTELL, V174, P215; Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825; Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004; CMU PRONOUNCING DICT	75	5	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1932-4553			IEEE J-STSP	IEEE J. Sel. Top. Signal Process.	DEC	2010	4	6					1046	1058		10.1109/JSTSP.2010.2079315		13	Engineering, Electrical & Electronic	Engineering	681XW	WOS:000284358700013		
S	Cueto, MA; Morton, J; Sturmfels, B		Viana, MAG; Wynn, HP		Cueto, Maria Angelica; Morton, Jason; Sturmfels, Bernd			Geometry of the Restricted Boltzmann Machine	ALGEBRAIC METHODS IN STATISTICS AND PROBABILITY II	Contemporary Mathematics		English	Proceedings Paper	AMS Special Session on Algebraic Methods in Statistics and Probability	MAR 27-29, 2009	Champaign, IL	AMS	Univ Illinois Urbana Champaign	Algebraic statistics; tropical geometry; deep belief network; Hadamard product; secant variety; Segre variety; inference function; linear threshold function	STATISTICAL-MODELS; SECANT VARIETIES; NETWORKS	The restricted Boltzmann machine is a graphical model for binary random variables. Based on a complete bipartite graph separating hidden and observed variables, it is the binary analog to the factor analysis model. We study this graphical model from the perspectives of algebraic statistics and tropical geometry, starting with the observation that its Zariski closure is a Hadamard power of the first secant variety of the Segre variety of projective lines. We derive a dimension formula for the tropicalized model, and we use it to show that the restricted Boltzmann machine is identifiable in many cases. Our methods include coding theory and geometry of linear threshold functions.	[Cueto, Maria Angelica; Sturmfels, Bernd] Univ Calif Berkeley, Dept Math, Berkeley, CA 94720 USA	Cueto, MA (reprint author), Univ Calif Berkeley, Dept Math, Berkeley, CA 94720 USA.	macueto@math.berkeley.edu; morton@math.psu.edu; bernd@math.berkeley.edu					Aichholzer O, 1996, SIAM J DISCRETE MATH, V9, P225, DOI 10.1137/S089548019426348X; BEST MR, 1977, DISCRETE MATH, V17, P235, DOI 10.1016/0012-365X(77)90158-3; Bogart T, 2007, J SYMB COMPUT, V42, P54, DOI 10.1016/j.jsc.2006.02.004; BROUWER AE, ARXIV09081530; CATALISANO MV, ARXIV08091701; Cohen G., 2005, COVERING CODES; Cover T. M., 2006, ELEMENTS INFORM THEO; CUETO MA, 2009, MEGA 2009 EFF METH A; Develin M., 2005, MATH SCI RES I PUBL, V52, P213; Develin M, 2006, DISCRETE COMPUT GEOM, V35, P117, DOI 10.1007/s00454-005-1182-2; Draisma J, 2010, ADV MATH, V223, P243, DOI 10.1016/j.aim.2009.08.008; Draisma J, 2008, J PURE APPL ALGEBRA, V212, P349, DOI 10.1016/j.jpaa.2007.05.022; DRTON M, 2009, OBERWOLFACH SEMINARS, V40; Drton M, 2007, STAT SINICA, V17, P1273; Drton M, 2007, PROBAB THEORY REL, V138, P463, DOI 10.1007/s00440-006-0033-2; Elizalde S, 2007, STAT SINICA, V17, P1395; Garcia LD, 2005, J SYMB COMPUT, V39, P331, DOI 10.1016/j.jsc.2004.11.007; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huffman W. C., 2003, FUNDAMENTALS ERROR C; Jensen A. N., 2011, GFAN SOFTWARE SYSTEM; Landsberg JM, 2004, FOUND COMPUT MATH, V4, P397, DOI 10.1007/s10208-003-0115-9; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Litsyn S., TABLE NONLINEAR BINA; Markwig H, 2009, COLLECT MATH, V60, P63; Minsky M., 1969, PERCEPTRONS INTRO CO; Ojha PC, 2000, IEEE T NEURAL NETWOR, V11, P839, DOI 10.1109/72.857765; Pachter L., 2005, ALGEBRAIC STAT COMPU; Pachter L, 2004, P NATL ACAD SCI USA, V101, P16132, DOI 10.1073/pnas.0406010101; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Sloane N. J. A., 2008, ONLINE ENCY INTEGER; Speyer D., 2009, MATH MAG, V82, P163; WUNDERLING R, 1996, 9609 ZIB TR; ZWIERNIK P, ARXIV09041980	34	5	6	AMER MATHEMATICAL SOC	PROVIDENCE	P.O. BOX 6248, PROVIDENCE, RI 02940 USA	0271-4132		978-0-8218-4891-3	CONTEMP MATH			2010	516						135	153				19	Mathematics; Statistics & Probability	Mathematics	BQI94	WOS:000281135400011		
J	Fuke, S; Ogino, M; Asada, M				Fuke, Sawa; Ogino, Masaki; Asada, Minoru			Acquisition of the Head-Centered Peri-Personal Spatial Representation Found in VIP Neuron	IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT			English	Article						Body representation; learning and adaptive system; sensor fusion; ventral intraparietal (VIP) neuron	PARIETAL CORTEX; TOOL-USE; SPACE; MOTOR; LOCATION; MACAQUE; IMAGES; MONKEY; AREA; FORM	Both body and visuo-spatial representations are supposed to be gradually acquired during the developmental process as described in cognitive and brain sciences. A typical example is face representation in a neuron (found in the ventral intraparietal (VIP) area) of which the function is not only to code for the location of visual stimuli in the head-centered reference frame, but also to connect visual sensation with tactile sensation. This paper presents a model that enables a robot to acquire such representation. The proprioception of arm posture is utilized as reference data through the "hand regard behavior," that is, the robot moves its hand in front of its face, and the self-organizing map (SOM) and Hebbian learning methods are applied. The simulation results are shown and discussions on the limitation of the current model and future issues are given.	[Fuke, Sawa; Asada, Minoru] Osaka Univ, Dept Adapt Machine Syst, Grad Sch Engn, Osaka 5560017, Japan	Fuke, S (reprint author), Osaka Univ, Dept Adapt Machine Syst, Grad Sch Engn, Osaka 5560017, Japan.	sawa.fuke@ams.eng.osaka-u.ac.jp; ogino@jeap.org; asada@ams.eng.osaka-u.ac.jp					Aflalo TN, 2006, J NEUROSCI, V26, P6288, DOI 10.1523/JNEUROSCI.0768-06.2006; ANDERSEN RA, 1995, CEREB CORTEX, V5, P457, DOI 10.1093/cercor/5.5.457; Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702; Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237; BRATT GJ, 1990, J COMP NEUROL, V299, P421; COWEY A, 1994, NEUROPSYCHOLOGIA, V32, P1069; Duhamel JR, 1998, J NEUROPHYSIOL, V79, P126; FEATHERSTONE R, 1983, INT J ROBOT RES, V2, P13, DOI 10.1177/027836498300200102; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Freedman DJ, 2006, NATURE, V443, P85, DOI 10.1038/nature05078; Fuke S, 2007, INT J HUM ROBOT, V4, P347, DOI 10.1142/S0219843607001096; GILMORE RO, 1997, COGNITION, V65, P1; Graziano MSA, 2006, NEUROPSYCHOLOGIA, V44, P845, DOI 10.1016/j.neuropsychologia.2005.09.009; HALLIGAN PW, 1991, NATURE, V352, P673; Head H, 1911, BRAIN, V34, P102, DOI 10.1093/brain/34.2-3.102; Hebb DO, 1949, ORG BEHAV; HERSCH M, 2008, INT J HUMAN ROBOT, V5; HIKITA M, 2008, P 7 INT C DEV LEARN, P157; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Iriki A, 2001, NEUROSCI RES, V40, P163, DOI 10.1016/S0168-0102(01)00225-5; Jellema T, 2004, CEREB CORTEX, V14, P781, DOI 10.1093/cercor/bhh038; Kohonen T., 1995, SELF ORG MAPS; Maxim S. I., 2005, BODY IMAGE BODY SCHE; Mullette-Gillman OA, 2005, J NEUROPHYSIOL, V94, P2331, DOI 10.1152/jn.00021.2005; Nabeshima C, 2006, ADV ROBOTICS, V20, P1105, DOI 10.1163/156855306778522550; NATALE L, 2001, ROBOT AUTON SYST, V37, P185; Piaget J., 1936, NAISSANCE INTELLIGEN; Pitti A, 2009, IEEE T AUTON MENT DE, V1, P86, DOI 10.1109/TAMD.2009.2021506; Pouget A, 2002, NAT REV NEUROSCI, V3, P741, DOI 10.1038/nrn914; RAMACHANDRAN VS, 1998, PHANTOMS BRAIN PROBI, V2; Rizzolatti G., 2007, MIRRORS BRAIN OUR MI; Rizzolatti G, 2003, EXP BRAIN RES, V153, P146, DOI 10.1007/s00221-003-1588-0; Sereno MI, 2006, NAT NEUROSCI, V9, P1337, DOI 10.1038/nn1777; Stoytchev A., 2007, P 7 INT C EP ROB, P165; Stratton G. M., 1897, PSYCHOL REV, V4, P463, DOI 10.1037/h0071173; von der Maslburg, 1973, KYBERNETIC, V14, P85; YOSHIKAWA Y, 2005, THESIS OSAKA U OSAKA	37	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1943-0604			IEEE T AUTON MENT DE	IEEE Trans. Auton. Ment. Dev.	AUG	2009	1	2					131	140		10.1109/TAMD.2009.2031013		10	Computer Science, Artificial Intelligence; Robotics; Neurosciences	Computer Science; Robotics; Neurosciences & Neurology	V19JE	WOS:000208067900004		
S	Burfoot, D; Lungarella, M; Kuniyoshi, Y		Asada, M; Hallam, JCT; Meyer, JA; Tani, J		Burfoot, Daniel; Lungarella, Max; Kuniyoshi, Yasuo			Toward a theory of embodied statistical learning	FROM ANIMALS TO ANIMATS 10, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	10th International Conference on Simulation of Adaptive Behavior	JUL 07-12, 2008	Osaka, JAPAN					The purpose of this paper is to outline a new formulation of statistical learning that will be more useful and relevant to the field of robotics. The primary motivation for this new perspective is the mismatch between the form of data assumed by current statistical learning algorithms, and the form of data that is actually generated by robotic systems. Specifically, robotic systems generate a vast unlabeled data stream, while most current algorithms are designed to handle limited numbers of discrete, labeled, independent and identically distributed samples. We argue that there is only one meaningful unsupervised learning process that can be applied to a vast data stream: adaptive compression. The compression rate can be used to compare different techniques, and statistical models obtained through adaptive compression should also be useful for other tasks.	[Burfoot, Daniel; Kuniyoshi, Yasuo] Univ Tokyo, Bunkyo Ku, Tokyo 1138656, Japan	Burfoot, D (reprint author), Univ Tokyo, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.						ATICK JJ, 1992, NETWORK-COMP NEURAL, V3, P213, DOI 10.1088/0954-898X/3/2/009; Brooks R. A., 1990, Robotics and Autonomous Systems, V6, DOI 10.1016/S0921-8890(05)80025-9; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; BURFOOT D, 2007, P S LANG ROB, P107; FRANCESCHINI N, 1992, PHILOS T ROY SOC B, V337, P283, DOI 10.1098/rstb.1992.0106; Hawkins J., 2004, INTELLIGENCE TIMES B; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; KUNIYOSHI Y, 2007, PROGR BRAIN RES, V164, P435; LUNGARELLA M, 2005, INT C DEV LEARN; MAHONEY M, 2006, RATIONALE LARGE TEXT; Pfeifer R, 2007, SCIENCE, V318, P1088, DOI 10.1126/science.1145803; Pfeifer R., 2006, INT C SERIES, V1291, P22, DOI DOI 10.1016/J.ICS.2005.12.080; Pfeifer R., 1999, UNDERSTANDING INTELL; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011; STEELS L, 2003, EMBODIED ARTIFICIAL, P231; SUTTON R. S., 1997, REINFORCEMENT LEARNI; Tani J, 1999, NEURAL NETWORKS, V12, P1131, DOI 10.1016/S0893-6080(99)00060-X; Tong S., 2001, J MACHINE LEARNING R, V2, P45, DOI DOI 10.1162/153244302760185243; Vapnik V., 1998, NATURE STAT LEARNING, V1st; Vapnik V., 1996, ADV NEURAL INFORM PR, P281	21	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-69133-4	LECT NOTES ARTIF INT			2008	5040						270	279				10	Computer Science, Artificial Intelligence	Computer Science	BHZ32	WOS:000257643500027		
J	Schmidhuber, J				Schmidhuber, Juergen			Deep learning in neural networks: An overview	NEURAL NETWORKS			English	Review						Deep learning; Supervised learning; Unsupervised learning; Reinforcement learning; Evolutionary computation	SHORT-TERM-MEMORY; PRINCIPAL COMPONENT ANALYSIS; INFERIOR TEMPORAL CORTEX; HIGH-DIMENSIONAL DATA; SLOW FEATURE ANALYSIS; RESTRICTED BOLTZMANN MACHINES; GENERALIZED CROSS-VALIDATION; NONLINEAR DYNAMICAL-SYSTEMS; TRAINED RECURRENT NETWORKS; CONTACT MAP PREDICTION	In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks. (C) 2014 Published by Elsevier Ltd.	[Schmidhuber, Juergen] Univ Lugano, Ist Dalle Molle Studi Intelligenza Artificialale, Swiss AI Lab IDSIA, CH-6928 Manno Lugano, Switzerland; [Schmidhuber, Juergen] SUPSI, CH-6928 Manno Lugano, Switzerland	Schmidhuber, J (reprint author), Univ Lugano, Ist Dalle Molle Studi Intelligenza Artificialale, Swiss AI Lab IDSIA, Galleria 2, CH-6928 Manno Lugano, Switzerland.	juergen@idsia.ch			SNF; DFG; European Commission	Since 16 April 2014, drafts of this paper have undergone massive open online peer review through public mailing lists including connectionists@cs.cmu.edu, ml-news@googlegroups.com, compneuro@neuroinf. org, genetic_programming@yahoogroups.com, rllist@googlegroups.com, imageworld@diku.dk, Google+ machine learning forum. Thanks to numerous NN/DL experts for valuable comments. Thanks to SNF, DFG, and the European Commission for partially funding my DL research group in the past quarter-century. The contents of this paper may be used for educational and non-commercial purposes, including articles for Wikipedia and similar sites.	Aberdeen D., 2003, THESIS; Abounadi J, 2001, SIAM J CONTROL OPTIM, V40, P681, DOI 10.1137/S0363012999361974; Akaike H, 1973, SECOND INTERNATIONAL, P267; AKAIKE H, 1970, ANN I STAT MATH, V22, P203, DOI 10.1007/BF02506337; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; ALLENDER A, 1992, EATCS MONOGRAPHS ON, P6; ALMEIDA L, 1987, IEEE INT C NEUR NETW, V2, P609; ALMEIDA LB, 1997, TECHNICAL REPORT; AMARI S, 1967, IEEE TRANS ELECTRON, VEC16, P299, DOI 10.1109/PGEC.1967.264665; AMARI S, 1993, NEURAL COMPUT, V5, P140, DOI 10.1162/neco.1993.5.1.140; AMARI S, 1996, ADVANCES IN NEURAL I, V8; Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Amit DJ, 1997, NETWORK-COMP NEURAL, V8, P373, DOI 10.1088/0954-898X/8/4/003; An G., 1996, NEURAL COMPUT, V674, P643; ANDRADE MA, 1993, PROTEIN ENG, V6, P383, DOI 10.1093/protein/6.4.383; Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Anguita D, 1996, MICROPROC MICROPROG, V41, P757, DOI 10.1016/0165-6074(96)00012-9; ANGUITA D, 1994, NEUROCOMPUTING, V6, P57, DOI 10.1016/0925-2312(94)90034-5; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Ash T., 1989, Connection Science, V1, DOI 10.1080/09540098908915647; ATICK JJ, 1992, NEURAL COMPUT, V4, P559, DOI 10.1162/neco.1992.4.4.559; Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741; BA J, 2013, ADVANCES IN NEURAL I, P3084; BAIRD H, 1990, PROCEDDINGS IAPR WOR; Baird L, 1999, ADV NEUR IN, V11, P968; Baird L., 1995, INT C MACH LEARN, P30; BAKKER B, 2004, P 8 C INT AUT SYST I, P438; Bakker B., 2003, Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453); Bakker B, 2002, ADV NEUR IN, V14, P1475; Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004; Baldi P., 2012, J MACH LEARN RES P T, V27, P37; BALDI P, 1995, IEEE T NEURAL NETWOR, V6, P182, DOI 10.1109/72.363438; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Baldi P., 2003, J MACHINE LEARNING R, V4, P575; Baldi P, 1996, NEURAL COMPUT, V8, P1541, DOI 10.1162/neco.1996.8.7.1541; BALDI P, 1993, NEURAL COMPUT, V5, P402, DOI 10.1162/neco.1993.5.3.402; BALDI PF, 1995, IEEE T NEURAL NETWOR, V6, P837, DOI 10.1109/72.392248; BALLARD DH, 1987, P NATIONAL C IA SEAT, P279; BALUJA S, 1994, TECHNICAL REPORT CMU; BALZER R, 1985, IEEE T SOFTWARE ENG, V11, P1257, DOI 10.1109/TSE.1985.231877; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.412; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Barrow H. G, 1987, P IEEE 1 ANN C NEUR, VIV, P115; Barto A., 2003, DISCRETE EVENT DYN S, V13, P341, DOI [DOI 10.1023/A:1025696116075, 10.1023/A:1025696116075)00052-1]; Barto A. G., 2004, P 3 INT C DEV LEARN, P112; BARTO AG, 1983, IEEE T SYST MAN CYB, V13, P834; Battiti R., 1989, COMPLEX SYSTEMS, V3, P331; BATTITI T, 1992, NEURAL COMPUT, V4, P141; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BAUM LE, 1966, THE ANNALS OF MATHEM, P1554; Baxter J, 2001, J ARTIF INTELL RES, V15, P319; Bayer J, 2009, LECT NOTES COMPUT SC, V5769, P755, DOI 10.1007/978-3-642-04277-5_76; BAYER J, 2013, ARXIV PREPRINT ARXIV; BAYER J, 2014, ARXIV PREPRINT ARXIV; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; Becker S., 1989, P 1988 CONN MOD SUMM, P29; Becker S., 1991, International Journal of Neural Systems, V2, DOI 10.1142/S0129065791000030; Behnke S., 2001, International Journal of Computational Intelligence and Applications, V1, DOI 10.1142/S1469026801000342; Behnke S, 2005, NEURAL COMPUT APPL, V14, P97, DOI 10.1007/s00521-004-0444-x; Behnke S, 2002, LECT NOTES COMPUT SC, V2415, P1319; BEHNKE S, 1999, PROCEEDINGS OF THE I, V2, P1356; BEHNKE S, 1998, P INT JOINT C NEUR N, V2, P820; Behnke S, 2003, IEEE IJCNN, P2758; BEHNKE S, 2003, LNCS, V2766; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bellman R., 1957, DYNAMIC PROGRAMMING; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; BENGIO Y, 1991, THESIS; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Beringer N, 2005, LECT NOTES COMPUT SC, V3696, P575; Bertsekas D., 2001, DYNAMIC PROGRAMMING; Bertsekas D. P., 1996, NEURO DYNAMIC PROGRA; Bichot NP, 2005, SCIENCE, V308, P529, DOI 10.1126/science.1109676; BIEGLERKONIG F, 1993, NEURAL NETWORKS, V6, P127, DOI 10.1016/S0893-6080(05)80077-2; Bishop CM, 2006, PATTERN RECOGNITION; BISHOP CM, 1993, IEEE T NEURAL NETWOR, V4, P882, DOI 10.1109/72.248466; Blair AD, 1997, NEURAL COMPUT, V9, P1127, DOI 10.1162/neco.1997.9.5.1127; Blondel VD, 2000, AUTOMATICA, V36, P1249, DOI 10.1016/S0005-1098(00)00050-9; BLUCHE T, 2014, INTERNATIONAL WORKSH; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BOBROWSKI L, 1978, BIOL CYBERN, V31, P1, DOI 10.1007/BF00337365; Boden M, 2000, CONNECT SCI, V12, P197; Bodenhausen U., 1991, ADV NEURAL INFORMATI, V3, P155; Bohte SM, 2002, NEUROCOMPUTING, V48, P17, DOI 10.1016/S0925-2312(01)00658-0; Boltzmann L., 1909, WISSENSCHAFTLICHE AB; BOTTOU L, 1991, THESIS; BOURLARD H, 1994, CONNNECTIONIST SPEEC; BOUTILIER C, 1996, PROCEEDINGS OF THE A; BRADTKE SJ, 1996, MACH LEARN, V22, P22; Brafman R., 2002, J MACHINE LEARNING R, V3, P213; Brea J, 2013, J NEUROSCI, V33, P9565, DOI 10.1523/JNEUROSCI.4098-12.2013; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brette R, 2007, J COMPUT NEUROSCI, V23, P349, DOI 10.1007/s10827-007-0038-6; BREUEL TM, 2013, 12TH INTERNATIONAL C, P683; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000339; Broyden C. G., 1965, MATH COMPUT, V19, P577, DOI 10.2307/2003941; BRUECKNER R, 2014, PROCEEDINGS 39TH IEE, P4856; Brunel N, 2000, J COMPUT NEUROSCI, V8, P183, DOI 10.1023/A:1008925309027; Bryson A. E., 1969, APPLIED OPTIMAL CONT; BRYSON AE, 1961, PROC HARVARD UNIV SY; BRYSON AE, 1961, TECHNICAL REPORT BR; Buhler J, 2001, BIOINFORMATICS, V17, P419, DOI 10.1093/bioinformatics/17.5.419; Buntine W. L., 1991, Complex Systems, V5; Burgess N, 1994, Int J Neural Syst, V5, P59, DOI 10.1142/S0129065794000074; Cardoso J F, 1994, P EUSIPCO, P776; CARREIRAPERPINA.MA, 2001, THESIS; CARTER MJ, 1990, ADV NEURAL INFORMATI, V2, P340; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Casey M, 1996, NEURAL COMPUT, V8, P1135, DOI 10.1162/neco.1996.8.6.1135; Cauwenberghs G., 1993, ADV NEURAL INFORMATI, V5, P244; CHAITIN GJ, 1966, J ACM, V13, P547, DOI 10.1145/321356.321363; Chalup SK, 2003, NEURAL NETWORKS, V16, P955, DOI 10.1016/S0893-6080(03)00054-6; CHELLAPILLA K, 2006, INTERNATIONAL WORKSH; Chen K, 2011, IEEE T NEURAL NETWOR, V22, P1744, DOI 10.1109/TNN.2011.2167240; Cho K, 2013, NEURAL COMPUT, V25, P805, DOI 10.1162/NECO_a_00397; CHO K, 2012, INTL CONF ON ARTIFIC, P81; CHO K, 2014, THESIS; Church A, 1936, AM J MATH, V58, P345, DOI 10.2307/2371045; Ciresan D., 2011, P 22 INT JOINT C ART, V2, P1237; Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023; Ciresan D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1918, DOI 10.1109/IJCNN.2011.6033458; Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51; CIRESAN DC, 2012, INTERNATIONAL JOINT, P1301; CIRESAN DC, 2012, ARXIV 1202 2745V1 CS; CIRESAN DC, 2012, ADVANCES IN NEURAL I, P2852; CIRESAN DC, 2013, TECHNICAL REPORT; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Cliff D. T., 1993, Artificial Neural Nets and Genetic Algorithms. Proceedings of the International Conference; Clune J, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2012.2863; Clune J, 2011, IEEE T EVOLUT COMPUT, V15, P346, DOI 10.1109/TEVC.2010.2104157; COATES A, 2013, PROC INTERNATIONAL C; COCHOCKI A, 1993, NEURAL NETWORKS FOR; Collobert R., 2008, ICML, V307, P160, DOI DOI 10.1145/1390156.1390177; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Connor CE, 2007, CURR OPIN NEUROBIOL, V17, P140, DOI 10.1016/j.conb.2007.03.002; CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188; Cook S. A., 1971, Proceedings of the 3rd annual ACM symposium on theory of computing, DOI 10.1145/800157.805047; CRAMER NL, 1985, PROCEEDINGS OF AN IN; CRAVEN P, 1979, NUMER MATH, V31, P377; CUCCU G, 2011, PROCEEDINGS OF THE 2, V2, P1; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; D'Ambrosio DB, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P974; Datar M., 2004, P 20 ANN S COMP GEOM, P253, DOI 10.1145/997817.997857; DAYAN P, 1995, NEURAL COMPUT, V7, P565, DOI 10.1162/neco.1995.7.3.565; Dayan P., 1993, ADV NEURAL INFORMATI, V5, P271; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Deco G, 1997, NEURAL NETWORKS, V10, P683, DOI 10.1016/S0893-6080(96)00110-4; DEFREITAS JFG, 2003, THESIS; DeJong G. F., 1986, MACH LEARN, V1, P145; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; DEMPSTER AP, 1977, JOURNAL OF THE ROYAL, V39; DENG L, 2014, THE JOURNAL OF NEURO, V4, P2051; DESOUTO MC, 1999, ELECTRONIC JOURNAL O; DEVALOIS RL, 1982, VISION RES, V22, P545, DOI 10.1016/0042-6989(82)90113-4; DEVILLE Y, 1994, J LOGIC PROGRAM, V20, P321; DEVRIES B, 1991, ADV NEURAL INFORMATI, V3, P162; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; DICKMANNS D, 1987, TECHNICAL REPORT; Dickmanns E. D., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), DOI 10.1109/IVS.1994.639472; Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475; DIRECTOR SW, 1969, IEEE T CIRCUITS SYST, VCT16, P330, DOI 10.1109/TCT.1969.1082967; DITTENBACH M, 2000, IEEE INNS ENNS INTER, V6, P6015; DONAHUE J, 2013, ARXIV PREPRINT ARXIV; Dorffner G, 1996, NEURAL NETWORK WORLD; Doya K, 2002, NEURAL COMPUT, V14, P1347, DOI 10.1162/089976602753712972; DREYFUS S, 1962, J MATH ANAL APPL, V5, P30, DOI 10.1016/0022-247X(62)90004-5; DREYFUS SE, 1973, IEEE T AUTOMAT CONTR, VAC18, P383, DOI 10.1109/TAC.1973.1100330; Duchi J, 2011, J MACH LEARN RES, V12, P2121; EGOROVA A, 2004, ROBOCUP 2004 SYMPOSI; Elfwing S, 2010, LECT NOTES COMPUT SC, V6443, P215, DOI 10.1007/978-3-642-17537-4_27; Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266; Eliasmith C., 2013, HOW TO BUILD A BRAIN; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Erhan D, 2010, J MACH LEARN RES, V11, P625; Escalante-B AN, 2013, J MACH LEARN RES, V14, P3683; EUBANK RL, 1988, SELF ORGANIZING METH; Euler L, 1744, METHODUS INVENIENDI; Eyben F, 2013, INT CONF ACOUST SPEE, P483, DOI 10.1109/ICASSP.2013.6637694; FAGGIN F, 1992, INTERNATIONAL JOINT, V1, P153; FAHLMAN SE, 1988, TECHNICAL REPORT CMU; Fahlman S.E., 1991, ADV NEURAL INFORMATI, V3, P190; Falconbridge MS, 2006, NEURAL COMPUT, V18, P415, DOI 10.1162/089976606775093891; FAN Y, 2014, PROC INTERSPEECH; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Farlow S. J., 1984, GMDH TYPE ALGORITHMS, V54; Feldkamp LA, 1998, NONLINEAR MODELING, P29; Feldkamp LA, 1998, P IEEE, V86, P2259, DOI 10.1109/5.726790; Feldkamp LA, 2003, NEURAL NETWORKS, V16, P683, DOI 10.1016/S0893-6080(03)00127-8; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; FERNANDEZ R, 2014, PROC INTERSPEECH; FERNANDEZ S, 2007, PROCEEDINGS OF THE 2; Fernandez S, 2007, LECT NOTES COMPUT SC, V4669, P220; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; Fieres J, 2008, IEEE IJCNN, P969, DOI 10.1109/IJCNN.2008.4633916; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025; FITZHUGH R, 1961, BIOPHYS J, V1, P445; FLETCHER R, 1963, COMPUT J, V6, P163; FOGEL DB, 1990, BIOL CYBERN, V63, P487, DOI 10.1007/BF00199581; Fogel L.J., 1966, ARTIFICIAL INTELLIGE; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Foldiak P., 1995, HDB BRAIN THEORY NEU, P895; FORSTER A, 2007, 15TH EUROPEAN SYMPOS, P537; FRANZIUS M, 2007, PUBLIC LIB SCI PLOS, V3, P166; FRIEDMAN J, 2001, SPRINGER SERIES IN S, V1; Frinken V, 2012, INT C PATT RECOG, P701; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; Fu KS, 1977, SYNTACTIC PATTERN RE; Fukada T., 1999, Systems and Computers in Japan, V30, DOI 10.1002/(SICI)1520-684X(199904)30:4<20::AID-SCJ3>3.0.CO;2-E; FUKUSHIMA K, 1979, T IECE JAPAN A, V62, P658; Fukushima K, 2013, NEURAL NETWORKS, V40, P18, DOI 10.1016/j.neunet.2013.01.001; Fukushima K, 2011, NEURAL NETWORKS, V24, P767, DOI 10.1016/j.neunet.2011.03.017; Fukushima K, 2013, NEURAL NETWORKS, V37, P103, DOI 10.1016/j.neunet.2012.09.016; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gabor D., 1946, ELECT ENG 3, V93, P429; GALLANT SI, 1988, COMMUN ACM, V31, P152, DOI 10.1145/42372.42377; Gauss C., 1809, THEORIA MOTUS CORPOR; GAUSS CF, 1821, THEORIA COMBINATIONI; Ge S, 2010, STABLE ADAPTIVE NEUR; GEIGER JT, 2014, PROC INTERSPEECH; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Gers F. A., 2002, J MACHINE LEARNING R, V3, P115; Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Gers FA, 2000, IEEE IJCNN, P189; Gerstner W., 2002, SPIKING NEURON MODEL; GERSTNER W, 1992, NETWORK-COMP NEURAL, V3, P139, DOI 10.1088/0954-898X/3/2/004; GHAVAMZADEH M, 2003, P 20 INT C MACH LEAR, P226; GHERRITY M, 1989, IJCNN 89 WASHINGTON, V1, P643; GIRSHICK R, 2013, TECHNICAL REPORT; GISSLEN L, 2011, PROC FOURTH CONFEREN, P31; GIUSTI A, 2013, PROC ICIP; Glackin B, 2005, LECT NOTES COMPUT SC, V3512, P552; GLASMACHERS T, 2010, P 12 ANN C GEN EV CO, P393, DOI 10.1145/1830483.1830557; Glorot X., 2011, P 14 INT C ART INT S, V15, P315; GLOYE A, 2005, IT INFORMATION TECHN, V47; Godel K., 1931, MONATSHEFTE MATH PHY, V38, P173, DOI DOI 10.1007/BF01700692; Goldberg DE, 1989, GENETIC ALGORITHMS I; GOLDFARB D, 1970, MATH COMPUT, V24, P23, DOI 10.2307/2004873; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Gomez F, 2008, J MACH LEARN RES, V9, P937; GOMEZ FJ, 2005, PROC OF THE 2005 CON; GOMEZ FJ, 2003, PROC GECCO 2003; GOMEZ FJ, 2003, THESIS; GOMI H, 1993, NEURAL NETWORKS, V6, P933; Gomi T., 2001, LNCS, V2217, P38; GONZALEZDOMINGU.J, 2014, PROC INTERSPEECH; GOODFELLOW I, 2014, ARXIV 1312 6211V2; GOODFELLOW IJ, 2014, ARXIV PREPRINT ARXIV; GOODFELLOW IJ, 2011, NIPS WORKSHOP ON CHA; GOODFELLOW IJ, 2012, PROCEEDINGS OF THE 2; GOODFELLOW IJ, 2013, INTERNATIONAL CONFER; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; GRAVES A, 2014, PROC 31ST INTERNATIO, P1764; Graves A., 2008, ADV NEURAL INFORM PR, V20, P577; GRAVES A, 2003, FIRST INTERNATIONAL; Graves A., 2009, ADV NEURAL INFORM PR, V22, P545; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; GRAVES A, 2009, IEEE TRANSACTIONS ON, V31; Graves A., 2006, INT C MACH LEARN, P369; Graves Alex, 2011, ADV NEURAL INFORM PR, V24, P2348; Graziano MS, 2009, THE INTELLIGENT MOVE; GRIEWANK A, 2012, DOCUMENTA MATHEMATIC, P389; Grondman I, 2012, IEEE T SYST MAN CY C, V42, P1291, DOI 10.1109/TSMCC.2012.2218595; GROSSBERG S, 1976, BIOLOGICAL CYBERNETI, V23; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; GROSSBER.S, 1969, J MATH MECH, V19, P53; GRUAU F, 1996, NEUROCOLT TECHNICAL; GRUNWALD PD, 2005, ADVANCES IN MINIMUM; GRUTTNER M, 2010, PROCEEDINGS OF THE I, V6353, P114; GUO X, 2014, ADVANCES IN NEURAL I, V27; GUYON I, 1992, ADV NEUR IN, V4, P471; HADAMARD J, 1908, MEMOIRES PRESENTES P; HADSELL R, 2006, PROC COMPUTER VISION; Hagras H, 2004, IEEE INT CONF ROBOT, P4620, DOI 10.1109/ROBOT.2004.1302446; Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398; Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970; HANSON SJ, 1990, PHYSICA D, V42, P265, DOI 10.1016/0167-2789(90)90081-Y; HANSON SJ, 1989, ADV NEURAL INFORMATI, V1, P177; HAPPEL BLM, 1994, NEURAL NETWORKS, V7, P985, DOI 10.1016/S0893-6080(05)80155-8; HASHEM S, 1995, IEEE T NEURAL NETWOR, V6, P792, DOI 10.1109/72.377990; Hassibi B., 1993, ADV NEURAL INFORMATI, V5, P164; Hastie T, 2009, THE ELEMENTS OF STAT; HASTIE TJ, 1990, MONOGRAPHS ON STATIS, V43; Hawkins J., 2006, HIERARCHICAL TEMPORA; Haykin SS, 2001, KALMAN FILTERING AND; Hebb D. O., 1949, THE ORGANIZATION OF; Hecht-Nielsen R, 1989, INT JOINT C NEURAL N, V1, P593; HEEMSKERK JN, 1995, NEUROCOMPUTERS FOR B; HEESS N, 2012, PROC EUROPEAN WORKSH, P43; Heidrich-Meisner V, 2009, J ALGORITHMS, V64, P152, DOI 10.1016/j.jalgor.2009.04.002; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Hertz J, 1991, INTRODUCTION TO THE; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; HIHI SE, 1996, ADV NEURAL INFORMATI, V8, P493; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Dayan P, 1996, NEURAL NETWORKS, V9, P1385, DOI 10.1016/S0893-6080(96)00009-3; Hinton G. E., 2012, TECHNICAL REPORT; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 1993, P INT C ART NEUR NET, P11; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1986, PARALLEL DISTRIBUTED, V1, P282; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S., 2001, FIELD GUIDE DYNAMICA; HOCHREITER S, 2005, SNOWBIRD WORKSHOP SN; HOCHREITER S, 1996, FRONTIERS ARTIFICIAL, V37, P65; Hochreiter S, 2001, LECT NOTES COMPUT SC, V2130, P87; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; HOCHREITER S, 1991, THESIS; Hochreiter S, 1999, NEURAL COMPUT, V11, P679, DOI 10.1162/089976699300016629; Hochreiter S, 1997, NEURAL COMPUT, V9, P1, DOI 10.1162/neco.1997.9.1.1; Hoerzer GM, 2014, CEREB CORTEX, V24, P677, DOI 10.1093/cercor/bhs348; HOLDEN SB, 1994, THESIS; Holland JH, 1975, ADAPTATION IN NATURA; HONAVAR V, 1988, P CONN MOD SUMM SCH, P472; HONAVAR V, 1993, INFORM SCIENCES, V70, P75, DOI 10.1016/0020-0255(93)90049-R; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; Hung CP, 2005, SCIENCE, V310, P863, DOI 10.1126/science.1117593; Hutter M., 2002, International Journal of Foundations of Computer Science, V13, DOI 10.1142/S0129054102001199; Hutter M., 2005, UNIVERSAL ARTIFICIAL; Hyvarinen A, 2001, INDEPENDENT COMPONEN; HYVARINEN A, 1999, ADVANCES IN NEURAL I, V12; *ICPR, 2012, CONTEST ON MITOSIS D; Igel C, 2003, IEEE C EVOL COMPUTAT, P2588; Igel C, 2003, NEUROCOMPUTING, V50, P105, DOI 10.1016/S0925-2312(01)00700-7; IKEDA S, 1976, IEEE T SYST MAN CYB, V6, P473, DOI 10.1109/TSMC.1976.4309532; Indermuhle E, 2012, INT CONF FRONT HAND, P302, DOI 10.1109/ICFHR.2012.232; INDERMUHLE E, 2011, DOCUMENT ANALYSIS AN, P73; Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073; Ivakhenko A. G., 1968, SOVIET AUTOMATIC CON, V13, P43; Ivakhnenko A. G., 1995, Pattern Recognition and Image Analysis, V5; IVAKHNEN.AG, 1971, IEEE T SYST MAN CYB, VSMC1, P364, DOI 10.1109/TSMC.1971.4308320; IVAKHNENKO AG, 1967, CYBERNETICS AND FORE; IVAKHNENKO AG, 1965, CYBERNETIC PREDICTIN; Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440; Jaakkola T., 1995, ADV NEURAL INFORMATI, V7, P345; JACKEL L, 1990, IEEE INT COMPUT, P320; JACOB C, 1994, LECTURE NOTES IN COM; JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2; JAEGER H, 2001, TECHNICAL REPORT GMD; Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277; Jain V., 2009, ADV NEURAL INFORM PR, V21, P769; JAMESON J, 1991, NEURAL NETWORKS FOR; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; JIM K, 1995, ADV NEURAL INFORMATI, V7, P649; Jin X, 2010, COMPUT SCI ENG, V12, P91; Jodogne S, 2007, J ARTIF INTELL RES, V28, P349; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233; JORDAN MI, 1997, ADV PSYCHOL, V121, P471; JORDAN MI, 1986, TECHNICAL REPORT ICS; JORDAN MI, 1990, TECHNICAL REPORT OCC; JORDAN MI, 2001, GRAPHICAL MODELS FOU; JORDAN MI, 1988, SUPERVISED LEARNING; JOSEPH RD, 1961, THESIS; Juang CF, 2004, IEEE T SYST MAN CY B, V34, P997, DOI 10.1109/TSMCB.2003.818557; Judd J. S., 1990, NEURAL NETWORK MODEL; Jutten C., 1991, SIGNAL PROCESS, V41, P1, DOI DOI 10.1016/0165-1684(91)90079-X; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; KAELBLING LP, 1995, TECHNICAL REPORT; KAK S, 2010, AMCIS 2010 PROCEEDIN; KALINKE Y, 1998, LNAI, V1502; Kalman R., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552; KARHUNEN J, 1995, NEURAL NETWORKS, V8, P549, DOI 10.1016/0893-6080(94)00098-7; KARPATHY A, 2014, IEEE CONFERENCE ON C; KASABOV NK, 2014, NEURAL NETWORKS; KELLEY HJ, 1960, ARSJ-AM ROCKET SOC J, V30, P947; Kempter R, 1999, PHYS REV E, V59, P4498, DOI 10.1103/PhysRevE.59.4498; KERLIRZIN P, 1993, NEURAL COMPUT, V5, P473, DOI 10.1162/neco.1993.5.3.473; Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199; Khan MF, 2010, STUD ISLAM FINANC AC, P1, DOI 10.1109/CEC.2010.5586547; KHAN SH, 2014, IEEE CONFERENCE ON C; KIMURA H, 1997, ICML, V97, P152; Kistler WM, 1997, NEURAL COMPUT, V9, P1015, DOI 10.1162/neco.1997.9.5.1015; Kitano H., 1990, Complex Systems, V4; Klampfl S, 2013, J NEUROSCI, V33, P11515, DOI 10.1523/JNEUROSCI.5044-12.2013; Klapper-Rybicka M, 2001, LECT NOTES COMPUT SC, V2130, P684; KOBATAKE E, 1994, J NEUROPHYSIOL, V71, P856; Kohl N, 2004, IEEE INT CONF ROBOT, P2619, DOI 10.1109/ROBOT.2004.1307456; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353; KOHONEN T, 1988, SELFORGANIZATION AND; Koikkalainen P., 1990, P INT JOINT C NEUR N, VII, P279; Kolmogorov A.N., 1965, Problems of Information Transmission, V1; Kolmogorov A. N., 1957, DOKL AKAD NAUK, V114, P679; Kompella VR, 2012, NEURAL COMPUT, V24, P2994, DOI 10.1162/NECO_a_00344; Kondo T, 2008, INT J INNOV COMPUT I, V4, P175; KONDO T, 1998, P 37 SICE ANN C INT, P1143, DOI 10.1109/SICE.1998.742993; KORDIK P, 2003, CONTROL SYSTEMS COMP, V2, P68; KORKIN M, 1997, CBM CAM BRAIN MACHIN; Kosko B., 1990, IEEE T NEURAL NETWOR, V1, P1; Koutnik J, 2013, GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1061; KOUTNIK J, 2010, P 12 ANN C GEN EV CO, P619, DOI 10.1145/1830483.1830596; KOUTNIK J, 2014, PROCEEDINGS OF THE 3, V32, P1845; Koza J.R., 1992, GENETIC PROGRAMMING; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; KREMER SC, 2001, FIELD GUIDE TO DYNAM; Kriegeskorte N, 2008, NEURON, V60, P1126, DOI 10.1016/j.neuron.2008.10.043; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V1, P4; Krogh A., 1992, NEURAL INFORM PROCES, P950; Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272; Kurzweil R, 2012, HOW TO CREATE A MIND; Lagoudakis M. G., 2003, J MACHINE LEARNING R, V4, P1107, DOI DOI 10.1162/JMLR.2003.4.6.1107; Lampinen J., 1992, Journal of Mathematical Imaging and Vision, V2, DOI 10.1007/BF00118594; LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L; LANGE S, 2010, NEUR NETW IJCNN 2010, P1; LAPEDES A, 1986, PHYSICA D, V22, P247, DOI 10.1016/0167-2789(86)90244-7; Laplace P.-S., 1774, MEMOIRES ACAD ROYALE, V6, P621; LARRAANAGA P, 2001, ESTIMATION OF DISTRI; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; Le Cun Y, 1988, CONNECTIONIST MODELS, V1, P21; Le Cun Y., 1990, ADV NEURAL INFORM PR, P396; LE QV, 2012, PROC ICML12; LECUN Y, 1993, ADVANCES IN NEURAL I, V5; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LECUN Y, 2006, ADVANCES IN NEURAL I; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1985, P COGNITIVA, V85, P599; Lee H., 2007, ADV NEURAL INFORM PR, V20, P873; Lee H., 2009, P 23 ANN C NEUR INF, V9, P1096; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; LEE L, 1996, TECHNICAL REPORT TR; LEE S, 1991, NEURAL NETWORKS, V4, P207, DOI 10.1016/0893-6080(91)90005-P; LEGENDRE AM, 1805, NOUVELLES METHODES P; LEGENSTEIN R, 2010, PLOS COMPUTATIONAL B, V6; Legenstein RA, 2002, THEOR COMPUT SCI, V287, P239, DOI 10.1016/S0304-3975(02)00097-X; Leibler R. A., 1951, THE ANNALS OF MATHEM, P79; LEIBNIZ GW, 1684, ACTA ERUDITORUM, P467; LENAT DB, 1983, MACHINE LEARNING, V21; LENAT DB, 1984, ARTIF INTELL, V23, P269, DOI 10.1016/0004-3702(84)90016-X; Lennie P, 2005, J OPT SOC AM A, V22, P2013, DOI 10.1364/JOSAA.22.002013; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; Levin AU, 1996, IEEE T NEURAL NETWOR, V7, P30, DOI 10.1109/72.478390; Levin A. U., 1994, ADV NEURAL INFORMATI, V6, P35; Levin L. A., 1973, Problems of Information Transmission, V9; Levin L. A., 1973, SOV MATH DOKL, V14, P1413; Lewicki MS, 1998, ADV NEUR IN, V10, P815; LHOPITAL GFA, 1696, ANALYSE DES INFINIME; LI M, 1997, AN INTRODUCTION TO K; LI R, 2014, PROC MICCAI; Lin L.-J., 1993, THESIS; Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329; LINDENMA.A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9; LINDSTADT S, 1993, P 1993 CONN MOD SUMM, P308; LINNAINMAA S, 1970, THESIS; Linnainmaa S., 1976, BIT (Nordisk Tidskrift for Informationsbehandling), V16, DOI 10.1007/BF01931367; LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36; Littman M. L., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; Liu SC, 2001, NEURAL NETWORKS, V14, P629, DOI 10.1016/S0893-6080(01)00054-5; Ljung L, 1998, SYSTEM IDENTIFICATIO; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; LOIACONO D, 2011, TECHNICAL REPORT; LOIACONO D, 2009, THE 2009 SIMULATED C; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUCIW M, 2013, FRONTIERS IN NEURORO, V7; Lusci A, 2013, J CHEM INF MODEL, V53, P1563, DOI 10.1021/ci400187y; MAAS AL, 2013, INTERNATIONAL CONFER; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Maass W, 1996, NEURAL COMPUT, V8, P1, DOI 10.1162/neco.1996.8.1.1; Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7; Maass W, 2000, NEURAL COMPUT, V12, P2519, DOI 10.1162/089976600300014827; MacKay D., 1990, NEURAL COMPUT, V2, P173, DOI [10.1162/neco.1990.2.2.173, DOI 10.1162/NEC0.1990.2.2.173]; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MACLIN R, 1993, MACH LEARN, V11, P195; Maclin R, 1995, INT JOINT CONF ARTIF, P524; Madala H.R., 1994, INDUCTIVE LEARNING A; Madani O, 2003, ARTIF INTELL, V147, P5, DOI 10.1016/S0004-3702(02)00378-8; Maei H. R., 2010, PROCEEDINGS OF THE T, V1, P91; Maex R, 1996, J NEUROPHYSIOL, V75, P1515; Mahadevan S, 1996, MACH LEARN, V22, P159, DOI 10.1007/BF00114727; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MANIEZZO V, 1994, IEEE T NEURAL NETWOR, V5, P39, DOI 10.1109/72.265959; MANOLIOS P, 1994, NEURAL COMPUT, V6, P1155, DOI 10.1162/neco.1994.6.6.1155; MARCHI E, 2014, PROC 39TH IEEE INTER, P2183; Markram H, 2012, SCI AM, V306, P50; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431; Martens J., 2011, P 28 INT C MACH LEAR, P1033; Martens J., 2010, P 27 INT C MACH LEAR, V951, P2010; Martinetz T M, 1990, IEEE Trans Neural Netw, V1, P131, DOI 10.1109/72.80212; Masci J, 2013, IEEE IMAGE PROC, P2713, DOI 10.1109/ICIP.2013.6738559; MATSUOKA K, 1992, IEEE T SYST MAN CYB, V22, P436, DOI 10.1109/21.155944; Mayer H, 2008, ADV ROBOTICS, V22, P1521, DOI 10.1163/156855308X360604; 2012, IEEE INTERNATIONAL S; Rezende DJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00038; MCCALLUM R, 1996, FROM ANIMALS TO ANIM, P315; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Melnik O., 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium, DOI 10.1109/IJCNN.2000.861532; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; MENACHE I, 2002, P 13 EUR C MACH LEAR, V2430, P295; Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642; MESNIL G, 2011, JMLR W CP PROC UNSUP, V7; MEULEAU N, 1999, 15 C UNC ART INT AAA, P427; Miglino O, 1995, Artif Life, V2, P417, DOI 10.1162/artl.1995.2.4.417; MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379; Miller JF, 2000, LECT NOTES COMPUT SC, V1802, P121; MILLER JF, 2009, P 11 ANN C COMP GEN, P3489, DOI 10.1145/1570256.1570428; MILLER KD, 1994, J NEUROSCI, V14, P409; MILLER WT, 1995, NEURAL NETWORKS FOR; MINAI AA, 1994, NEURAL NETWORKS, V7, P783, DOI 10.1016/0893-6080(94)90100-7; Minsky M, 1969, PERCEPTRONS; MINSKY M, 1963, COMPUT THOUGHT, P406; MINTON S, 1989, ARTIF INTELL, V40, P63, DOI 10.1016/0004-3702(89)90047-7; Mitchell T. M., 1997, MACHINE LEARNING; Mitchell T. M., 1986, Machine Learning, V1, DOI 10.1007/BF00116250; MNIH V, 2013, ARXIV 1312 5602 CS L; Mohamed AR, 2010, INT CONF ACOUST SPEE, P4354, DOI 10.1109/ICASSP.2010.5495651; MOLGEDEY L, 1994, PHYS REV LETT, V72, P3634, DOI 10.1103/PhysRevLett.72.3634; MOLLER MF, 1993, TECHNICAL REPORT PB; Montana DJ, 1989, P 11 INT JOINT C ART, V1, P762; Montavon G., 2012, LNCS, V7700; MOODY J, 1989, ADV NEURAL INFORMATI, V1, P29; MOODY JE, 1994, NEURAL NETWORKS IN T; MOODY JE, 1992, ADV NEUR IN, V4, P847; MOORE AW, 1993, MACH LEARN, V13, P103, DOI 10.1023/A:1022635613229; Moore AW, 1995, MACH LEARN, V21, P199, DOI 10.1007/BF00993591; Moriarty DE, 1996, MACH LEARN, V22, P11, DOI 10.1007/BF00114722; MORIARTY DE, 1997, THESIS; MORIMOTO J, 2000, ADVANCES IN NEURAL I, V13, P1061; MOSTELLER F, 1968, HANDBOOK OF SOCIAL P, V2; Mozer M. C., 1989, ADV NEURAL INFORMATI, VI, P107; MOZER MC, 1989, COMPLEX SYSTEMS, V3, P349; MOZER MC, 1991, ADV NEURAL INFORMATI, V3, P627; MOZER MC, 1992, ADV NEUR IN, V4, P275; MULLER UA, 1995, IEEE T NEURAL NETWOR, V6, P203, DOI 10.1109/72.363436; MUNRRO PW, 1987, P 9 ANN C COGN SCI S, P165; MURRAY A, 1993, ADV NEURAL INFORMATI, V5, P491; NADAL JP, 1994, NETWORK-COMP NEURAL, V5, P565, DOI 10.1088/0954-898X/5/4/008; NAGUMO J, 1962, P IRE, V50, P2061, DOI 10.1109/JRPROC.1962.288235; NAIR V, 2010, INTERNATIONAL CONFER; Saito K, 1997, NEURAL COMPUT, V9, P123, DOI 10.1162/neco.1997.9.1.123; Narendra KS, 1990, J IEEE T NEURAL NETW, V1, P4; NARENDRA KS, 1974, IEEE T SYST MAN CYB, VSMC4, P323; Neal RM, 2006, LECT NOTES ARTIF INT, V3944, P28; Neal RM, 2006, STUD FUZZ SOFT COMP, V207, P265; NEAL RM, 1995, THESIS; NEFTCI E, 2014, FRONTIERS IN NEUROSC, V7; Neil D., 2014, IEEE TRANSACTIONS ON, VPP, P1; Nessler B, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003037; NETI C, 1992, IEEE T NEURAL NETWOR, V3, P14, DOI 10.1109/72.105414; NEUNEIER R, 1996, LECTURE NOTES IN COM, V1524, P373; NEWTON I, 1687, PHILOSOPHIAE NATURAL; NGUYEN N, 1989, PROCEEDINGS OF THE I, P357; Nilsson N. J., 1980, PRINCIPLES OF ARTIFI; NOLFI S, 1994, FOURTH INTERNATIONAL, P190; NOLFI S, 1994, ADAPT BEHAV, V3, P5, DOI 10.1177/105971239400300102; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Nowlan S. J., 1992, NEURAL COMPUT, V4, P173; O'Reilly RC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00124; OCONNOR P, 2013, FRONTIERS IN NEUROSC, V7; Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013; OJA E, 1991, ARTIFICIAL NEURAL NE, V1, P737; Oja E., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000475; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Omlin CW, 1996, NEURAL NETWORKS, V9, P41, DOI 10.1016/0893-6080(95)00086-0; OQUAB M, 2013, LEARNING AND TRANSFE; OREILLY R, 2003, MAKING WORKING MEMOR; OReilly RC, 1996, NEURAL COMPUT, V8, P895, DOI 10.1162/neco.1996.8.5.895; ORR G, 1998, LNCS, V1524; OSTROVSKII GM, 1971, WISSENSCHAFTLICHE Z, V13, P382; OTSUKA M, 2010, PROC ESANN; OTSUKA M, 2010, THESIS; Otte S, 2012, INT CONF FRONT HAND, P533, DOI 10.1109/ICFHR.2012.229; OUDEYER PY, 2013, INTRINSICALLY MOTIVA; PACHITARIU M, 2013, ARXIV PREPRINT ARXIV; PALM G, 1980, BIOLOGICAL CYBERNETI, V36; PALM G, 1992, NEURAL COMPUT, V4, P703, DOI 10.1162/neco.1992.4.5.703; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013; PARKER DB, 1985, TECHNICAL REPORT TR; PASCANU R, 2013, ICML13 JMLR W CP, V28; PASCANU R, 2013, ARXIV PREPRINT ARXIV; PASEMANN F, 1999, P C EV COMP JUL 6 9, V3, P1973; PEARLMUTTER BA, 1986, NETWORKS COMPUTING A, V151, P333; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; PEARLMUTTER BA, 1995, IEEE T NEURAL NETWOR, V6, P1212, DOI 10.1109/72.410363; Pearlmutter B. A., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.263; Peng J, 1996, MACH LEARN, V22, P283, DOI 10.1007/BF00114731; Perez-Ortiz JA, 2003, NEURAL NETWORKS, V16, P241, DOI 10.1016/S0893-6080(02)00219-8; PERRETT DI, 1992, PHILOS T ROY SOC B, V335, P23, DOI 10.1098/rstb.1992.0003; PERRETT DI, 1982, EXP BRAIN RES, V47, P329; Peters J, 2008, NEUROCOMPUTING, V71, P1180, DOI 10.1016/j.neucom.2007.11.026; Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003; PETERS J, 2010, SCHOLARPEDIA, V5, P3698, DOI 10.4249/scholarpedia.3698; PHAM V, 2013, ARXIV PREPRINT ARXIV; PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229; PLATE TA, 1993, ADV NEURAL INFORMATI, V5, P34; PLUMBLEY MD, 1991, THESIS; POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K; POLLACK JB, 1988, PROC NIPS, P527; PONTRYAGIN LS, 1961, THE MATHEMATICAL THE; POON H, 2011, IEEE INT COMPUT, P689; POST EL, 1936, THE JOURNAL OF SYMBO, V1, P103; Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31; Precup D, 1998, ADV NEUR IN, V10, P1050; Prokhorov D, 2010, IEEE T NEURAL NETWOR, V21, P858, DOI 10.1109/TNN.2010.2044802; PROKHOROV D, 2001, FIELD GUIDE DYNAMICA, P23; Prokhorov DV, 2002, IEEE IJCNN, P2018, DOI 10.1109/IJCNN.2002.1007449; Prokhorov DV, 1997, IEEE T NEURAL NETWOR, V8, P997, DOI 10.1109/72.623201; PUSKORIUS GV, 1994, IEEE T NEURAL NETWOR, V5, P279, DOI 10.1109/72.279191; RAIKO T, 2012, INTERNATIONAL CONFER, P924; Raina R, 2009, 26 ANN INT C MACH LE, V382, P873; RAMACHER U, 1993, INT J NEURAL SYST, V4, P333, DOI 10.1142/S0129065793000274; RANZATO M, 2006, ADVANCES IN NEURAL I; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Rauber A, 2002, IEEE T NEURAL NETWOR, V13, P1331, DOI 10.1109/TNN.2002.804221; RAZAVIAN AS, 2014, ARXIV PREPRINT ARXIV; RECHENBERG I, 1971, THESIS; REDLICH AN, 1993, NEURAL COMPUT, V5, P289, DOI 10.1162/neco.1993.5.2.289; REFENES NA, 1994, NEURAL NETWORKS, V7, P375; Riedmiller M., 1993, IEEE INT C NEUR NETW, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; Riedmiller M, 2005, LECT NOTES ARTIF INT, V3720, P317; RIEDMILLER M, 2012, INTERNATIONAL JOINT, P1; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rifai S., 2011, P 28 INT C MACH LEAR, P833; RING M, 2011, PROCEEDINGS OF THE F; RING M, 1991, MACHINE LEARNING, P343; RING MB, 1994, THESIS; RING MB, 1993, ADV NEURAL INFORMATI, V5, P115; RISI S, 2012, INTERNATIONAL JOINT, P1; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; ROBINSON AJ, 1987, TECHNICAL REPORT CUE; ROBINSON T, 1989, PROCEEDINGS OF THE 1, P836; Rodriguez P, 1999, CONNECT SCI, V11, P5, DOI 10.1080/095400999116340; Rodriguez P, 1998, ADV NEUR IN, V10, P87; ROGGEN D, 2003, P 2003 NASA DOD C EV, P189; ROHWER R, 1989, PROCEEDINGS OF DISTR; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rosenblatt F., 1962, PRINCIPLES OF NEUROD; Roux Ludovic, 2013, J Pathol Inform, V4, P8, DOI 10.4103/2153-3539.112693; RUBNER J, 1990, BIOL CYBERN, V62, P193, DOI 10.1007/BF00198094; Ruckstiess T, 2008, LECT NOTES ARTIF INT, V5212, P234, DOI 10.1007/978-3-540-87481-2_16; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1, P151; RUMMERY G, 1994, TECHNICAL REPORT CUE; Russell S., 1995, ARTIFICIAL INTELLIGE, V2; SAK H, 2014, PROC INTERSPEECH; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Sallans B, 2004, J MACH LEARN RES, V5, P1063; Salustowicz R, 1997, EVOL COMPUT, V5, P123, DOI 10.1162/evco.1997.5.2.123; Samejima K, 2003, NEURAL NETWORKS, V16, P985, DOI 10.1016/S0893-6080(02)00235-6; Samuel A.L., 1959, IBM Journal of Research and Development, V3; Sanger T. D., 1989, ADV NEURAL INFORMATI, V1, P11; Santamaria JC, 1997, ADAPT BEHAV, V6, P163, DOI 10.1177/105971239700600201; SARAVANAN N, 1995, IEEE EXPERT, P23; SAUND E, 1994, ADV NEURAL INFORMATI, V6, P27; SCHABACK R, 1992, NUMERISCHE MATHEMATI, V4; Schafer AM, 2006, LECT NOTES COMPUT SC, V4131, P71; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schaul T., 2010, SCHOLARPEDIA, V6, P4650; SCHAUL T, 2013, PROC 30TH INTERNATIO; Schemmel J, 2006, IEEE IJCNN, P1; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Schmidhuber J., 1989, Connection Science, V1, DOI 10.1080/09540098908915650; SCHMIDHUBER J, 1993, P INT C ART NEUR NET, P191; SCHMIDHUBER J, 2002, LECT NOTES ARTIF INT, P216; SCHMIDHUBER J, 1992, P 2 INT C SIM AD BEH, P196; SCHMIDHUBER J, 1997, LEARNING LEARN, P293; Schmichuber J, 2007, NEURAL COMPUT, V19, P757, DOI 10.1162/neco.2007.19.3.757; SCHMIDHUBER J, 1991, IEEE IJCNN, P1458, DOI 10.1109/IJCNN.1991.170605; SCHMIDHUBER J, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P967; SCHMIDHUBER J, 2012, TECHNICAL REPORT IDS; Schmidhuber J, 1991, INT J NEURAL SYST, V2, P135, DOI DOI 10.1142/S012906579100011X; SCHMIDHUBER J, 2013, TECHNICAL REPORT; SCHMIDHUBER J, 2011, PROC FOURTH CONFEREN, P243; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P863, DOI 10.1162/neco.1992.4.6.863; SCHMIDHUBER J, 1989, CONNECTIONISM IN PERSPECTIVE, P429; SCHMIDHUBER J, 1990, P IEEE INNS INT JOIN, V2, P253; Schmidhuber J, 1997, MACH LEARN, V28, P105, DOI 10.1023/A:1007383707642; SCHMIDHUBER J, 2013, FRONTIERS IN PSYCHOL; SCHMIDHUBER J, 1993, NEURAL COMPUT, V5, P625, DOI 10.1162/neco.1993.5.4.625; Schmidhuber J, 2004, MACH LEARN, V54, P211, DOI 10.1023/B:MACH.0000015880.99707.b2; Schmidhuber J, 1997, NEURAL NETWORKS, V10, P857, DOI 10.1016/S0893-6080(96)00127-X; SCHMIDHUBER J, 1993, THESIS; Schmidhuber J, 1996, NEURAL COMPUT, V8, P773, DOI 10.1162/neco.1996.8.4.773; SCHMIDHUBER J, 2006, ARTIFICIAL GEN INTEL, P199; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234; Schmidhuber J, 2007, SCIENCE, V316, P688; SCHMIDHUBER J, 1990, THESIS; SCHMIDHUBER J, 1987, THESIS; SCHMIDHUBER J, 1990, PROC OF THE 1990 CON, P52; SCHMIDHUBER J, 1990, ALSO PUBLISHED AT TH, V1, P194; Schmidhuber J, 2006, CONNECT SCI, V18, P173, DOI 10.1080/09540090600768658; Schmidhuber J., 1991, ADV NEURAL INFORMATI, V3, P500; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P243, DOI 10.1162/neco.1992.4.2.243; SCHMIDHUBER JH, 1993, P INT WKSHP NEURAL N, P87; SCHOLKOPF B, 1998, ADVANCES IN KERNEL M; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; Schraudolph NN, 1996, ADV NEUR IN, V8, P563; SCHRAUDOLPH NN, 1993, ADV NEURAL INFORMATI, V5, P499; Schrauwen B, 2007, P 15 EUR S ART NEUR, P471; SCHUSTER HG, 1992, PHYS REV A, V46, P2131, DOI 10.1103/PhysRevA.46.2131; SCHUSTER M, 1999, THESIS; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Schwartz A., 1993, P 10 INT C MACH LEAR, P298; Schwefel H.P., 1974, THESIS; Sehnke F, 2010, NEURAL NETWORKS, V23, P551, DOI 10.1016/j.neunet.2009.12.004; Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589; SERMANET P, 2013, ARXIV PREPRINT ARXIV; Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653; Serre T, 2002, LECT NOTES COMPUT SC, V2525, P387; Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X; SHAN H, 2014, PROC INTERNATIONAL C; Shan H, 2007, ADV NEURAL INFORM PR, V19, P1273; SHANNO DF, 1970, MATH COMPUT, V24, P647, DOI 10.2307/2004840; SHANNON CE, 1948, AT&T TECH J, V27, P623; SHAO L, 2014, IEEE TRANSACTIONS ON; SHAVLIK JW, 1989, CONNECT SCI, V1, P233; SHAVLIK JW, 1994, MACH LEARN, V14, P321, DOI 10.1023/A:1022665814563; SIEGELMANN H, 1992, THESIS; SIEGELMANN HT, 1991, APPL MATH LETT, V4, P77, DOI 10.1016/0893-9659(91)90080-F; SILVA FM, 1990, ADVANCED NEURAL COMPUTERS, P151; SIMA J, 1994, NEURAL COMPUT, V6, P842, DOI 10.1162/neco.1994.6.5.842; Simard P., 2003, INT C DOC AN REC, V2, P958, DOI DOI 10.1109/ICDAR.2003.1227801; SIMS K, 1994, ANN C SERIES, P15; Simsek O, 2008, ADV NEURAL INFORM PR, V21, P1497; SINGH S, 2005, ADVANCES IN NEURAL I, V17; SINGH SP, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P700; SMITH SF, 1980, THESIS; Smolensky P., 1986, INFORM PROCESSING DY, V1, P194; Solla S. A., 1988, Complex Systems, V2; SOLOMONOFF RJ, 1978, IEEE T INFORM THEORY, V24, P422, DOI 10.1109/TIT.1978.1055913; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2; SOLOWAY E, 1986, COMMUN ACM, V29, P850, DOI 10.1145/6592.6594; Song S, 2000, NAT NEUROSCI, V3, P919; SPEELPENNING B, 1980, THESIS; Srivastava R. K., 2013, ADVANCES IN NEURAL I, P2310; Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395; Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016; Stanley KO, 2009, ARTIF LIFE, V15, P185, DOI 10.1162/artl.2009.15.2.15202; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; STEIJVERS M, 1996, PROCEEDINGS OF THE 1; Steil JJ, 2007, NEURAL NETWORKS, V20, P353, DOI 10.1016/j.neunet.2007.04.011; Stemmler M, 1996, NETWORK-COMP NEURAL, V7, P687, DOI 10.1088/0954-898X/7/4/005; Stoianov I, 2012, NAT NEUROSCI, V15, P194, DOI 10.1038/nn.2996; STONE M, 1974, J R STAT SOC B, V36, P111; Stoop R, 2000, NEUROSCI RES, V36, P81, DOI 10.1016/S0168-0102(99)00108-X; Stratonovich R. L., 1960, THEOR PROBAB APPL, V5, P156, DOI DOI 10.1137/1105015; SUN G, 1993, ADV NEURAL INFORMATI, V5, P180; SUN GZ, 1993, TECHNICAL REPORT CS; SUN Y, 2013, PROCEEDINGS OF THE G, P61; SUN Y, 2009, P 11 ANN C GEN EV CO, P539, DOI 10.1145/1569901.1569976; Sutskever I., 2008, NIPS, V21, P2008; Sutskever I., 2014, TECHNICAL REPORT; Sutton R. S., 2008, ADV NEURAL INFORM PR, V21, P1609; Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1; SUTTON R.S., 1999, NIPS, V99, P1057; Sutton RS, 1998, REINFORCEMENT LEARNI; Szabo Z, 2006, LECT NOTES COMPUT SC, V3889, P909; SZEGEDY C, 2014, TECHNICAL REPORT; SZEGEDY C, 2013, DEEP NEURAL NETWORKS, P2553; TAYLOR G, 2011, CVPR, P2729; Tegge AN, 2009, NUCLEIC ACIDS RES, V37, pW515, DOI 10.1093/nar/gkp305; Teichmann M, 2012, NEURAL COMPUT, V24, P1271, DOI 10.1162/NECO_a_00268; Teller A, 1994, ADV GENETIC PROGRAMM, P199; TENENBERG J, 1993, COM ADAP SY, P337; TESAURO G, 1994, NEURAL COMPUT, V6, P215, DOI 10.1162/neco.1994.6.2.215; Tieleman T., 2012, COURSERA NEURAL NETW; TIKHONOV AN, 1977, SOLUTIONS OF ILL POS; TING KM, 1997, PROC INTERNATIONAL J; Tino P, 2003, NEURAL COMPUT, V15, P1931, DOI 10.1162/08997660360675099; TONKES B, 1997, PROCEEDINGS OF THE F; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Tsitsiklis JN, 1996, MACH LEARN, V22, P59, DOI 10.1007/BF00114724; Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502; Tsodyks MV, 1996, HIPPOCAMPUS, V6, P271, DOI 10.1002/(SICI)1098-1063(1996)6:3<271::AID-HIPO5>3.3.CO;2-Q; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881; Turing A., 1936, P LOND MATH SOC, V42, P230, DOI DOI 10.1112/PLMS/S2-42.1.230; Turner AJ, 2013, GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1005; Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759; URLBE AP, 1999, THESIS; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319; Vahed A, 2004, NEURAL COMPUT, V16, P59, DOI 10.1162/08997660460733994; VAILLANT R, 1994, IEE P-VIS IMAGE SIGN, V141, P245, DOI 10.1049/ip-vis:19941301; Wiering M, 2012, ADAPT LEARN OPTIM, V12, P1, DOI 10.1007/978-3-642-27645-3; van den Berg T, 2013, GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P759; van Hasselt H, 2012, ADAPT LEARN OPTIM, V12, P207; Vapnik VN, 1995, THE NATURE OF STATIS; VAPNIK V, 1992, ADV NEUR IN, V4, P831; VERSINO C, 1996, P ICANN 96 INT C ART, P221; VETA M, 2013, MICCAI 2013 GRAND CH; Vieira A, 2003, NEUROCOMPUTING, V50, P461, DOI 10.1016/S0925-2312(02)00635-5; VIGLIONE S, 1970, ADAPTIVE LEARNING AN; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; VLASSIS N, 2012, ACM TRANSACTIONS ON, V4, P12; VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914; von der Malsburg C, 1973, Kybernetik, V14, P85; WALDINGER RJ, 1969, P INT J C ARTIFICIAL, P241; WALLACE CS, 1968, COMPUT J, V11, P185; WAN EA, 1994, TIME SERIES PREDICTI, P265; WANG C, 1994, ADV NEURAL INFORMATI, V6, P303; Wang S., 2013, P 30 INT C MACH LEAR, P118; WATANABE O, 1992, EATCS MONOGRAPHS ON; Watanabe S., 1985, PATTERN RECOGNITION; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1023/A:1022676722315; Watkins C. J. C. H., 1989, THESIS; WATROUS RL, 1992, ADV NEUR IN, V4, P309; Waydo S, 2008, NEURAL COMPUT, V20, P1165, DOI 10.1162/neco.2007.03-07-493; Weigend A.S., 1990, ADV NEURAL INFORMATI, V3, P875; WEIGEND AS, 1993, NEUR NETW IEEE INT C, P1786; WEISS G, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1335; Weng J, 1997, INT J COMPUT VISION, V25, P109, DOI 10.1023/A:1007967800668; Weng J., 1992, INTERNATIONAL JOINT, V1, P576; Werbos P. J., 1974, THESIS; WERBOS PJ, 2006, AUTOMATIC DIFFERENTI, P15; Werbos P.J., 1988, NEURAL NETWORKS, V1; WERBOS PJ, 1981, P IFIP C, P762; WERBOS PJ, 1989, PROCEEDINGS OF IEEE; WERBOS PJ, 1992, HDB INTELLIGENT CONT, P283; WERBOS PJ, 1987, IEEE TRANSACTIONS ON, V17; WERBOS PJ, 1989, IJCNN INT C NEURAL N, V1, P209; WEST AHL, 1995, NIPS, P323; White H., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.425; WHITEHEAD S, 1992, THESIS; Whiteson S, 2005, MACH LEARN, V59, P5, DOI 10.1007/s10994-005-0460-9; Whiteson S, 2006, J MACH LEARN RES, V7, P877; Whiteson S, 2012, ADAPT LEARN OPTIM, V12, P325; WIDROW B, 1962, BIOL PROTOTYPES SYNT, V1, P160; WIDROW B, 1994, COMMUN ACM, V37, P93, DOI 10.1145/175247.175257; WIELAND AP, 1991, INT JOINT C NEUR NET, V2, P667; Wiering M, 1997, ADAPT BEHAV, V6, P219, DOI 10.1177/105971239700600202; Wierling M, 1998, MACH LEARN, V33, P105, DOI 10.1023/A:1007562800292; Wiering M., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Wierstra D, 2010, LOG J IGPL, V18, P620, DOI 10.1093/jigpal/jzp049; WIERSTRA D, 2008, CONGRESS OF EVOLUTIO; WIESEL DH, 1959, J PHYSL, V148, P574; WILES J, 1995, P 17 ANN C COGN SCI, P482; WILKINSON JH, 1965, THE ALGEBRAIC EIGENV; WILLIAMS R, 1992, INT JOINT C NEUR NET, V4, P241; Williams R. J., 1989, Connection Science, V1, DOI 10.1080/09540098908915631; WILLIAMS RJ, 1988, TECHNICAL REPORT NU; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; WILLIAMS RJ, 1989, TECHNICAL REPORT NU; WILLIAMS RJ, 1986, TECHNICAL REPORT 860; WILLIAMS RJ, 1988, TECHNICAL REPORT ICS; WILLIAMS RJ, 1990, NEURAL COMPUT, V2, P491; WILLSHAW DJ, 1976, PROC R SOC SER B-BIO, V194, P431, DOI 10.1098/rspb.1976.0087; Windisch D, 2005, NEURAL COMPUT, V17, P487, DOI 10.1162/0899766053011519; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Witczak M, 2006, CONTROL ENG PRACT, V14, P671, DOI 10.1016/j.conengprac.2005.04.007; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1023/A:1022672621406; Wollmer M, 2011, IEEE T INTELL TRANSP, V12, P574, DOI 10.1109/TITS.2011.2119483; Wollmer M, 2013, SPEECH COMMUN, V55, P252, DOI 10.1016/j.specom.2012.08.006; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; WOLPERT DH, 1994, ADV NEURAL INFORMATI, V6, P200; WU D, 2014, PROC CONFERENCE ON C; Wu L, 2008, NEURAL NETWORKS, V21, P1392, DOI 10.1016/j.neunet.2008.02.002; Wyatte D, 2012, J COGNITIVE NEUROSCI, V24, P2248; Wysoski SG, 2010, NEURAL NETWORKS, V23, P819, DOI 10.1016/j.neunet.2010.04.009; Yamauchi Brian M., 1994, Adaptive Behavior, V2, P219, DOI 10.1177/105971239400200301; YAMINS D, 2013, ADVANCES IN NEURAL I, P1; YANG M, 2009, TREC VIDEO RETRIEVAL; Yao X, 1993, Int J Neural Syst, V4, P203, DOI 10.1142/S0129065793000171; Yin F., 2013, 12TH INTERNATIONAL C, P1464; Yin J, 2012, IEEE T AUTON MENT DE, V4, P273, DOI 10.1109/TAMD.2012.2182765; Young SR, 2014, PATTERN RECOGN LETT, V37, P115, DOI 10.1016/j.patrec.2013.07.013; YU XH, 1995, IEEE T NEURAL NETWOR, V6, P669; Zamora-Martinez F, 2014, PATTERN RECOGN, V47, P1642, DOI 10.1016/j.patcog.2013.10.020; ZEILER MD, 2012, CORR; ZEILER MD, 2013, TECHNICAL REPORT; ZEMEL RS, 1993, THESIS; ZEMEL RS, 1994, ADV NEURAL INFORMATI, V6, P11; ZENG Z, 1994, IEEE TRANSACTIONS ON, V5; Zimmermann HG, 2012, LECT NOTES COMPUTER, V7700, P687; ZIPSER D, 1993, J NEUROSCI, V13, P3406	882	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	JAN	2015	61						85	117		10.1016/j.neunet.2014.09.003		33	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AY5EH	WOS:000347595400010	25462637	
J	Tran, VT; AlThobiani, F; Ball, A				Van Tung Tran; AlThobiani, Faisal; Ball, Andrew			An approach to fault diagnosis of reciprocating compressor valves using Teager-Kaiser energy operator and deep belief networks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Fault diagnosis; Teager-Kaiser energy operator; Deep belief networks; Reciprocating compressor	CLASSIFICATION	This paper presents an approach to implement vibration, pressure, and current signals for fault diagnosis of the valves in reciprocating compressors. Due to the complexity of structure and motion of such compressor, the acquired vibration signal normally involves transient impacts and noise. This causes the useful information to be corrupted and difficulty in accurately diagnosing the faults with traditional methods. To reveal the fault patterns contained in this signal, the Teager-Kaiser energy operation (TKEO) is proposed to estimate the amplitude envelopes. In case of pressure and current, the random noise is removed by using a demising method based on wavelet transform. Subsequently, statistical measures are extracted from all signals to represent the characteristics of the valve conditions. In order to classify the faults of compressor valves, a new type of learning architecture for deep generative model called deep belief networks (DBNs) is applied. DBN employs a hierarchical structure with multiple stacked restricted Boltzmann machines (RBMs) and works through a greedy layer-by-layer learning algorithm. In pattern recognition research areas, DBN has proved to be very effective and provided with high performance for binary values. However, for implementing DBN to fault diagnosis where most of signals are real-valued, RBM with Bernoulli hidden units and Gaussian visible units is considered in this study. The proposed approach is validated with the signals from a two-stage reciprocating air compressor under different valve conditions. To confirm the superiority of DBN in fault classification, its performance is compared with that of relevant vector machine and back propagation neuron networks. The achieved accuracy indicates that the proposed approach is highly reliable and applicable in fault diagnosis of industrial reciprocating machinery. (C) 2013 Elsevier Ltd. All rights reserved.	[Van Tung Tran; AlThobiani, Faisal; Ball, Andrew] Univ Huddersfield, Sch Comp & Engn, Huddersfield HD1 3DH, W Yorkshire, England	Tran, VT (reprint author), Univ Huddersfield, Sch Comp & Engn, Huddersfield HD1 3DH, W Yorkshire, England.	V.T.Tran@hud.ac.uk	Ball, Andrew/	Ball, Andrew/0000-0001-7540-8965			Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bin GF, 2012, MECH SYST SIGNAL PR, V27, P696, DOI 10.1016/j.ymssp.2011.08.002; Cexus J.C., 2004, INT J SIGNAL PROCESS, V1, P1; Cui HX, 2009, J LOSS PREVENT PROC, V22, P864, DOI 10.1016/j.jlp.2009.08.012; Elhaj M, 2008, MECH SYST SIGNAL PR, V22, P374, DOI 10.1016/j.ymssp.2007.08.003; Feng K, 2011, EXPERT SYST APPL, V38, P12721, DOI 10.1016/j.eswa.2011.04.060; Griffith W. A., 2001, P 30 TURB S TEX HOUS; Gu F, 2011, MECH SYST SIGNAL PR, V25, P360, DOI 10.1016/j.ymssp.2010.07.004; Hinton G. E., 2010, MOMENTUM; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kaiser J., 1990, AC SPEECH SIGN PROC, V1, P381; Kaiser J.F., 1993, P INT C AC SPEECH SI, V3, P149; Leonard SM, 1996, HYDROCARB PROCESS, V75, P67; Li H., 2010, INT J ROTATING MACHI, V9; Li Hui, 2009, INT C MEAS TECHN MEC, P594; Liang M, 2010, MECH SYST SIGNAL PR, V24, P1473, DOI 10.1016/j.ymssp.2009.12.007; Lin J., 2010, INT C INF SCI ENG, P3701; Liu HM, 2013, MATH PROBL ENG, DOI 10.1155/2013/498385; MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P3024, DOI 10.1109/78.277799; MARAGOS P, 1993, IEEE T SIGNAL PROCES, V41, P1532, DOI 10.1109/78.212729; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Nair V., 2009, P ADV NEUR INF PROC; Pichler K, 2011, IEEE INT SYMP SIGNAL, P224; Postalcioglu S., 2005, IEEE P NEURAL NETWOR, V2, P951, DOI 10.1109/ICNNB.2005.1614777; Qin Q, 2012, MEASUREMENT, V45, P897, DOI 10.1016/j.measurement.2012.02.005; Rodriguez PH, 2013, ISA T, V52, P278, DOI 10.1016/j.isatra.2012.12.006; Salakhutdinov R., 2009, THESIS U TORONTO; Salakhutdinov RR, 2008, P 25 INT C MACH LEAR, P872, DOI 10.1145/1390156.1390266; Senoussaoui M., 2012, SPEAK LANG REC WORKS, P117; Solnik S, 2010, EUR J APPL PHYSIOL, V110, P489, DOI 10.1007/s00421-010-1521-8; Tamilselvan P, 2013, RELIAB ENG SYST SAFE, V115, P124, DOI 10.1016/j.ress.2013.02.022; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Verma N. K., 2011, IEEE P REC ADV INT C, P242; Wang F., 2010, IEEE P INT S INF SCI, P255; Wang G.-W., 2010, IEEE P 7 INT C FUZZ, P2652; Wang YS, 2009, IEEE INT VEH SYM, P129; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Youfu T., 2013, INFORM TECHNOLOGY J, V12, P287; Zhen D, 2013, MECH SYST SIGNAL PR, V34, P191, DOI 10.1016/j.ymssp.2012.07.018	41	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2014	41	9					4113	4122		10.1016/j.eswa.2013.12.026		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	AE2BJ	WOS:000333778000007		
J	Zhou, YX; Yu, F; Duong, T				Zhou, Yongxia; Yu, Fang; Duong, Timothy			Multiparametric MRI Characterization and Prediction in Autism Spectrum Disorder Using Graph Theory and Machine Learning	PLOS ONE			English	Article							INFERIOR FRONTAL GYRUS; FUNCTIONAL CONNECTIVITY; CORTICAL THICKNESS; FEATURE-SELECTION; BRAIN; CHILDREN; CORTEX; AGE; FLUCTUATIONS; PERFORMANCE	This study employed graph theory and machine learning analysis of multiparametric MRI data to improve characterization and prediction in autism spectrum disorders (ASD). Data from 127 children with ASD (13.5 +/- 6.0 years) and 153 age- and gender-matched typically developing children (14.5 +/- 5.7 years) were selected from the multi-center Functional Connectome Project. Regional gray matter volume and cortical thickness increased, whereas white matter volume decreased in ASD compared to controls. Small-world network analysis of quantitative MRI data demonstrated decreased global efficiency based on gray matter cortical thickness but not with functional connectivity MRI (fcMRI) or volumetry. An integrative model of 22 quantitative imaging features was used for classification and prediction of phenotypic features that included the autism diagnostic observation schedule, the revised autism diagnostic interview, and intelligence quotient scores. Among the 22 imaging features, four (caudate volume, caudate-cortical functional connectivity and inferior frontal gyrus functional connectivity) were found to be highly informative, markedly improving classification and prediction accuracy when compared with the single imaging features. This approach could potentially serve as a biomarker in prognosis, diagnosis, and monitoring disease progression.	[Zhou, Yongxia] Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA; [Yu, Fang; Duong, Timothy] Univ Texas Hlth Sci Ctr San Antonio, Res Imaging Inst, South Texas Vet Hlth Care Syst, Dept Vet Affairs,Dept Ophthalmol, San Antonio, TX 78229 USA	Duong, T (reprint author), Univ Texas Hlth Sci Ctr San Antonio, Res Imaging Inst, South Texas Vet Hlth Care Syst, Dept Vet Affairs,Dept Ophthalmol, San Antonio, TX 78229 USA.	duongt@uthscsa.edu					Anderson JS, 2011, CEREB CORTEX, V21, P1134, DOI 10.1093/cercor/bhq190; Assaf M, 2010, NEUROIMAGE, V53, P247, DOI 10.1016/j.neuroimage.2010.05.067; Bastiaansen JA, 2011, BIOL PSYCHIAT, V69; Buitelaar JK, 1999, J CHILD PSYCHOL PSYC, V40, P869, DOI 10.1017/S0021963099004321; Depretto M, 2006, NAT NEUROSCI, V9, P28; Di Martino A., 2013, MOL PSYCHIATR, DOI [10.1038/mp.2013.78, DOI 10.1038/MP.2013.78]; Di Martino A, 2009, BIOL PSYCHIAT, V65, P63, DOI 10.1016/j.biopsych.2008.09.022; Di Martino A, 2011, BIOL PSYCHIAT, V69, P847, DOI 10.1016/j.biopsych.2010.10.029; Duchesnay E, 2011, NEUROIMAGE, V57, P1003, DOI 10.1016/j.neuroimage.2011.05.011; Ebisch SJH, 2011, HUM BRAIN MAPP, V32, P1013, DOI 10.1002/hbm.21085; Ecker C, 2009, NEUROREPORT, V20, P1155, DOI 10.1097/WNR.0b013e32832ec181; Ecker C, 2013, JAMA PSYCHIAT, V70, P59, DOI 10.1001/jamapsychiatry.2013.265; Elliott MA, 1999, MAGNET RESON MED, V41, P450, DOI 10.1002/(SICI)1522-2594(199903)41:3<450::AID-MRM4>3.3.CO;2-0; Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797; Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021; Fletcher PT, 2010, NEUROIMAGE, V51, P1117, DOI 10.1016/j.neuroimage.2010.01.083; Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201; Frith U, 2001, NEURON, V32, P969, DOI 10.1016/S0896-6273(01)00552-9; Gagliardi F, 2011, ARTIF INTELL MED, V52, P123, DOI 10.1016/j.artmed.2011.04.002; Gallese V, 2013, DEV MED CHILD NEUROL, V55, P15, DOI 10.1111/j.1469-8749.2012.04398.x; Geva S, BRAIN, V134, P3071; Greenlee JDW, 2007, J COMP NEUROL, V503, P550, DOI 10.1002/cne.21405; Hamilton AFD, 2013, DEV COGN NEUROS-NETH, V3, P91, DOI 10.1016/j.dcn.2012.09.008; Hardan AY, 2006, AM J PSYCHIAT, V163, P1290, DOI 10.1176/appi.ajp.163.7.1290; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsieh L, 2001, BRAIN LANG, V76, P227, DOI 10.1006/brln.2000.2382; Huang Y Y, 1983, Sheng Li Ke Xue Jin Zhan, V14, P356; Jakab A, 2013, PLOS ONE, V8, P1; Kang S, 2013, RES DEV DISABIL, V34, P739, DOI 10.1016/j.ridd.2012.10.007; Kennedy DP, 2006, P NATL ACAD SCI USA, V103, P8275, DOI 10.1073/pnas.0600674103; Khan S, 2013, P NATL ACAD SCI USA, V110, P3107, DOI 10.1073/pnas.1214533110; Lange N, 2010, AUTISM RES, V3, P350, DOI 10.1002/aur.162; Langen M, 2007, BIOL PSYCHIAT, V62, P262, DOI 10.1016/j.biopsych.2006.09.040; Langen M, 2009, BIOL PSYCHIAT, V66, P327, DOI 10.1016/j.biopsych.2009.03.017; Lee PS, 2009, CEREB CORTEX, V19, P1787, DOI 10.1093/cercor/bhn209; Nixon P, 2004, J COGNITIVE NEUROSCI, V16, P289, DOI 10.1162/089892904322984571; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Peters JM, 2013, BMC MED, V11, DOI 10.1186/1741-7015-11-54; Rapin I, 2008, PEDIATR CLIN N AM, V55, P1129, DOI 10.1016/j.pcl.2008.07.005; Rizzolatti G, 2010, EXP BRAIN RES, V200, P223, DOI 10.1007/s00221-009-2002-3; Rudie JD, CEREB CORTEX, V22, P1025; Sahyoun CP, 2010, NEUROPSYCHOLOGIA, V48, P86, DOI 10.1016/j.neuropsychologia.2009.08.013; Sivaswamy L, 2010, J CHILD NEUROL, V25, P1223, DOI 10.1177/0883073809358765; Sowell ER, 2007, CEREB CORTEX, V17, P1550, DOI 10.1093/cercor/bhl066; Stark DE, 2008, J NEUROSCI, V28, P13754, DOI 10.1523/JNEUROSCI.4544-08.2008; Travers BG, 2012, AUTISM RES, V5, P289, DOI 10.1002/aur.1243; Turner Katherine C, 2006, Behav Brain Funct, V2, P34, DOI 10.1186/1744-9081-2-34; Uddin LQ, 2013, FRONT HUM NEUROSCI, V7, P1; van der Zande FHR, 2005, NEURORADIOLOGY, V47, P114, DOI 10.1007/s00234-004-1274-3; Villalobos ME, 2005, NEUROIMAGE, V25, P916, DOI 10.1016/j.neuroimage.2004.12.022; Vissers ME, 2012, NEUROSCI BIOBEHAV R, V36, P604, DOI 10.1016/j.neubiorev.2011.09.003; Walsh CA, 2008, CELL, V135, P396, DOI 10.1016/j.cell.2008.10.015; WANG H, 2012, PLOS ONE, V0007; Zhou Y, 2013, AM J NEURORADIOL, V34, P1180, DOI 10.3174/ajnr.A3386; Zhou Y, 2013, ISRN GERIATRICS, V2013; Zhou YX, 2014, J MAGN RESON IMAGING, V39, P1558, DOI 10.1002/jmri.24310	56	4	4	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	JUN 12	2014	9	6							e90405	10.1371/journal.pone.0090405		10	Multidisciplinary Sciences	Science & Technology - Other Topics	AK8TP	WOS:000338701300001	24922325	
J	Graff, P; Feroz, F; Hobson, MP; Lasenby, A				Graff, Philip; Feroz, Farhan; Hobson, Michael P.; Lasenby, Anthony			SkyNet: an efficient and robust neural network training tool for machine learning in astronomy	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods: data analysis; methods: statistical	COSMOLOGICAL PARAMETER-ESTIMATION; DEEP; CLASSIFICATION; RECOGNITION; NETS	We present the first public release of our generic neural network training algorithm, called SkyNet. This efficient and robust machine learning tool is able to train large and deep feed-forward neural networks, including autoencoders, for use in a wide range of supervised and unsupervised learning applications, such as regression, classification, density estimation, clustering and dimensionality reduction. SkyNet uses a 'pre-training' method to obtain a set of network parameters that has empirically been shown to be close to a good solution, followed by further optimization using a regularized variant of Newton's method, where the level of regularization is determined and adjusted automatically; the latter uses second-order derivative information to improve convergence, but without the need to evaluate or store the full Hessian matrix, by using a fast approximate method to calculate Hessian-vector products. This combination of methods allows for the training of complicated networks that are difficult to optimize using standard backpropagation techniques. SkyNet employs convergence criteria that naturally prevent overfitting, and also includes a fast algorithm for estimating the accuracy of network outputs. The utility and flexibility of SkyNet are demonstrated by application to a number of toy problems, and to astronomical problems focusing on the recovery of structure from blurred and noisy images, the identification of gamma-ray bursters, and the compression and denoising of galaxy images. The SkyNet software, which is implemented in standard ANSI c and fully parallelized using MPI, is available at http://www.mrao.cam.ac.uk/software/skynet/.	[Graff, Philip] NASA, Gravitat Astrophys Lab, Goddard Space Flight Ctr, Greenbelt, MD 20771 USA; [Feroz, Farhan; Hobson, Michael P.; Lasenby, Anthony] Univ Cambridge, Cavendish Lab, Astrophys Grp, Cambridge CB3 0HE, England; [Lasenby, Anthony] Kavli Inst Cosmol, Cambridge CB3 0HA, England	Graff, P (reprint author), NASA, Gravitat Astrophys Lab, Goddard Space Flight Ctr, 8800 Greenbelt Rd, Greenbelt, MD 20771 USA.	philip.b.graff@nasa.gov			SGI/Intel; HEFCE; PPARC; Higher Education Funding Council for England; NASA Postdoctoral Fellowship from the Oak Ridge Associated Universities; Gates Cambridge Scholarship at the University of Cambridge; Leverhulme Trust; Newton Trust	The authors thank John Skilling for providing very useful advice in the early stages of algorithm development. We also thank Amy Lien for providing the data used in Section 5.2. This work utilized three different high-performance computing facilities at different times: initial work was performed on COSMOS VIII, an SGI Altix UV1000 supercomputer, funded by SGI/Intel, HEFCE and PPARC, and the authors thank Andrey Kaliazin for assistance; early work also utilized the Darwin Supercomputer of the University of Cambridge High Performance Computing Service (http://www.hpc.cam.ac.uk/), provided by Dell Inc. using Strategic Research Infrastructure Funding from the Higher Education Funding Council for England; later work utilized the Discover system of the NASA Center for Climate Simulation at NASA Goddard Space Flight Center. PG is currently supported by a NASA Postdoctoral Fellowship from the Oak Ridge Associated Universities and completed a portion of this work while funded by a Gates Cambridge Scholarship at the University of Cambridge. FF is supported by a Research Fellowship from the Leverhulme and Newton Trusts.	Andreon S., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), DOI 10.1109/IJCNN.1999.830761; Andreon S, 2000, MON NOT R ASTRON SOC, V319, P700, DOI 10.1046/j.1365-8711.2000.03700.x; Auld T, 2008, MON NOT R ASTRON SOC, V387, P1575, DOI 10.1111/j.1365-2966.2008.13279.x; Auld T, 2007, MON NOT R ASTRON SOC, V376, pL11, DOI 10.1111/j.1745-3933.2006.00276.x; Ball NM, 2010, INT J MOD PHYS D, V19, P1049, DOI 10.1142/S0218271810017160; Bergstra J., 2009, 1337 U MONTR DEP DIN; Bertin E, 1996, ASTRON ASTROPHYS SUP, V117, P393, DOI 10.1051/aas:1996164; Bonnett C., 2013, ARXIV13121287; Bridges M, 2011, J HIGH ENERGY PHYS, DOI 10.1007/JHEP03(2011)012; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Fendt WA, 2007, ASTROPHYS J, V654, P2, DOI 10.1086/508342; Feroz F., 2008, ARXIV08100781; Feroz F., 2013, ARXIV13062144; Feroz F, 2009, MON NOT R ASTRON SOC, V398, P1601, DOI 10.1111/j.1365-2966.2009.14548.x; Feroz F, 2008, MON NOT R ASTRON SOC, V384, P449, DOI 10.1111/j.1365-2966.2007.12353.x; Fynbo JPU, 2009, ASTROPHYS J SUPPL S, V185, P526, DOI 10.1088/0067-0049/185/2/526; Gehrels N, 2004, ASTROPHYS J, V611, P1005, DOI 10.1086/422091; GEVA S, 1992, IEEE T NEURAL NETWOR, V3, P621, DOI 10.1109/72.143376; Glorot X., 2011, J MACHINE LEARNING R, V15, P315; Glorot X., 2010, J MACH LEARN RES P T, V9, P249; Graff P, 2012, MON NOT R ASTRON SOC, V421, P169, DOI 10.1111/j.1365-2966.2011.20288.x; Gull S.F., 1999, QUANTIFIED MAXIMUM E; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hobson MP, 1998, MON NOT R ASTRON SOC, V300, P1, DOI 10.1046/j.1365-8711.1998.01777.x; Hornik K., 1990, NEURAL NETWORKS, V3, P359; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Karpenka NV, 2013, MON NOT R ASTRON SOC, V429, P1278, DOI 10.1093/mnras/sts412; Kendall MG, 1957, COURSE MULTIVARIATE; Kitching T., 2012, NEW ASTRON REV; Kitching T, 2011, ANN APPL STAT, V5, P2231, DOI 10.1214/11-AOAS484; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lien A, 2014, ASTROPHYS J, V783, DOI 10.1088/0004-637X/783/1/24; Longo G., 2001, P MPA ESO MPE WORKSH, P379; MacKay D., 2003, INFORM THEORY INFERE; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Mandic D.P., 2001, RECURRENT NEURAL NET; Martens J, 2010, P 27 INT C MACH LEAR, P735; Murtagh F., 1991, NEUROCOMPUTING, V2, P183, DOI 10.1016/0925-2312(91)90023-5; Pascanu R., 2013, ARXIV13013584; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; SERRARICART M, 1993, ASTRON J, V106, P1685, DOI 10.1086/116758; Skilling J, 2004, AIP CONF PROC, V735, P395; Tagliaferri R, 2003, NEURAL NETWORKS, V16, P297, DOI 10.1016/S0893-6080(03)00028-5; Tagliaferri R., 2003, 14 IT WORKSH NEUR NE, P226; Wanderman D, 2010, MON NOT R ASTRON SOC, V406, P1944, DOI 10.1111/j.1365-2966.2010.16787.x; Way MJ, 2012, CH CRC DATA MIN KNOW, pXIII	53	4	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0035-8711	1365-2966		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	JUN	2014	441	2					1741	1759		10.1093/mnras/stu642		19	Astronomy & Astrophysics	Astronomy & Astrophysics	AH9WC	WOS:000336494800061		
J	Shang, C; Yang, F; Huang, DX; Lyu, WX				Shang, Chao; Yang, Fan; Huang, Dexian; Lyu, Wenxiang			Data-driven soft sensor development based on deep learning technique	JOURNAL OF PROCESS CONTROL			English	Article						Deep neural network; Nonlinear regression; Soft sensor; Data-driven technique	NEURAL-NETWORKS; DISTILLATION-COLUMNS; REGRESSION	In industrial process control, some product qualities and key variables are always difficult to measure online due to technical or economic limitations. As an effective solution, data-driven soft sensors provide stable and reliable online estimation of these variables based on historical measurements of easy-to-measure process variables. Deep learning, as a novel training strategy for deep neural networks, has recently become a popular data-driven approach in the area of machine learning. In the present study, the deep learning technique is employed to build soft sensors and applied to an industrial case to estimate the heavy diesel 95% cut point of a crude distillation unit (CDU). The comparison of modeling results demonstrates that the deep learning technique is especially suitable for soft sensor modeling because of the following advantages over traditional methods. First, with a complex multi-layer structure, the deep neural network is able to contain richer information and yield improved representation ability compared with traditional data-driven models. Second, deep neural networks are established as latent variable models that help to describe highly correlated process variables. Third, the deep learning is semi-supervised so that all available process data can be utilized. Fourth, the deep learning technique is particularly efficient dealing with massive data in practice. (C) 2014 Elsevier Ltd. All rights reserved.	[Shang, Chao; Yang, Fan; Huang, Dexian; Lyu, Wenxiang] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Shang, Chao; Yang, Fan; Huang, Dexian; Lyu, Wenxiang] Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Huang, DX (reprint author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	huangdx@tsinghua.edu.cn	Yang, Fan/B-1219-2012	Yang, Fan/0000-0002-0254-9000	National Basic Research Program of China [2012CB720505]; National Natural Science Foundation of China [21276137]; Tsinghua University Initiative Scientific Research Program	This work was supported by the National Basic Research Program of China (2012CB720505), the National Natural Science Foundation of China (21276137) and Tsinghua University Initiative Scientific Research Program.	Bengio Y, 2007, LARGE SCALE KERNEL M, P34; Bengio Y., 2012, ARXIV12065538HEPTH; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Carreira-Perpinan M. A., 2005, ARTIF INTELL, P17; Cichocki A., 1993, NEURAL NETWORKS OPTI, V1st; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Desai K, 2006, BIOCHEM ENG J, V27, P225, DOI 10.1016/j.bej.2005.08.002; Dong D, 1996, COMPUT CHEM ENG, V20, P65, DOI 10.1016/0098-1354(95)00003-K; Fortuna L, 2005, CONTROL ENG PRACT, V13, P499, DOI 10.1016/j.conengprac.2004.04.013; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Qin S. J., 1997, Neural systems for control, DOI 10.1016/B978-012526430-3/50009-X; Kadlec P, 2009, COMPUT CHEM ENG, V33, P795, DOI 10.1016/j.compchemeng.2008.12.012; Kadlec P, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2, P243, DOI 10.1109/CIMCA.2008.66; Kano M, 2010, J PROCESS CONTR, V20, P969, DOI 10.1016/j.jprocont.2010.06.013; Mnih A., 2009, ADV NEURAL INFORM PR, V21, P1081; Park S, 2000, COMPUT CHEM ENG, V24, P871, DOI 10.1016/S0098-1354(00)00343-4; Pearson K, 1901, PHILOS MAG, V2, P559; QIN SJ, 1992, COMPUT CHEM ENG, V16, P379, DOI 10.1016/0098-1354(92)80055-E; Qin SJ, 1998, COMPUT CHEM ENG, V22, P503; Tang YC, 2012, PROC CVPR IEEE, P2264; Tham M. T., 1991, Journal of Process Control, V1, DOI 10.1016/0959-1524(91)87002-F; Vapnik V. N., 1998, STAT LEARNING THEORY; Wold H., 1966, MULTIVARIATE ANAL, V1, P391; Yan WW, 2004, COMPUT CHEM ENG, V28, P1489, DOI 10.1016/j.compchemeng.2003.11.004	29	4	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0959-1524	1873-2771		J PROCESS CONTR	J. Process Control	MAR	2014	24	3					223	233		10.1016/j.jprocont.2014.012		11	Automation & Control Systems; Engineering, Chemical	Automation & Control Systems; Engineering	AH3EI	WOS:000336006000018		
J	Sainath, TN; Kingsbury, B; Soltau, H; Ramabhadran, B				Sainath, Tara N.; Kingsbury, Brian; Soltau, Hagen; Ramabhadran, Bhuvana			Optimization Techniques to Improve Training Speed of Deep Neural Networks for Large Speech Tasks	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Speech recognition; deep neural networks; parallel optimization techniques		While Deep Neural Networks (DNNs) have achieved tremendous success for large vocabulary continuous speech recognition (LVCSR) tasks, training these networks is slow. Even to date, the most common approach to train DNNs is via stochastic gradient descent, serially on one machine. Serial training, coupled with the large number of training parameters (i.e., 10-50 million) and speech data set sizes (i.e., 20-100 million training points) makes DNN training very slow for LVCSR tasks. In this work, we explore a variety of different optimization techniques to improve DNN training speed. This includes parallelization of the gradient computation during cross-entropy and sequence training, as well as reducing the number of parameters in the network using a low-rank matrix factorization. Applying the proposed optimization techniques, we show that DNN training can be sped up by a factor of 3 on a 50-hour English Broadcast News (BN) task with no loss in accuracy. Furthermore, using the proposed techniques, we are able to train DNNs on a 300-hr Switchboard (SWB) task and a 400-hr English BN task, showing improvements between 9-30% relative over a state-of-the art GMM/HMM system while the number of parameters of the DNN is smaller than the GMM/HMM system.	[Sainath, Tara N.; Kingsbury, Brian; Soltau, Hagen] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10567 USA; [Ramabhadran, Bhuvana] IBM Res, Multilingual Analyt, Yorktown Hts, NY 10598 USA	Sainath, TN (reprint author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10567 USA.	tsainath@us.ibm.com; bedk@us.ibm.com; hsoltau@us.ibm.com; bhuvana@us.ibm.com			RATS program [D11PC20192 DOI/NBC]	This work was supported in part by Contract No. D11PC20192 DOI/NBC under the RATS program. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. Approved for Public Release, Distribution Unlimited. The guest editor coordinating the review of this manuscript and approving it for publication was Dr. Dimitri Kanevsky.	Byrd RH, 2011, SIAM J OPTIMIZ, V21, P977, DOI 10.1137/10079923X; Chen SF, 2006, IEEE T AUDIO SPEECH, V14, P1596, DOI 10.1109/TASL.2006.879814; Chu C. T., 2007, P NIPS; Dean J., 2012, P NIPS; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Glorot X., 2010, P AISTATS, P249; Hinton G., 2010, 2010003 U TOR MACH L; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, P INTERSPEECH; KINGSBURY B, 2009, P ICASSP, P3761; Kingsbury B., 2012, P INTERSPEECH; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H., 2008, P ICML; Le Q., 2011, P ICML; LeCun Y., 1995, HDB BRAIN THEORY NEU; LeCun Y., 1990, P ADV NEUR INF PROC, V2; Martens J., 2010, P INT C MACH LEARN I; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Raina R., 2009, P ICML; Recht B, 2013, MATH PROGRAM, V5, P201; Sainath T., 2012, IMPROVEMENTS USING D; Sainath T., 2011, P ASRU; Sainath T. N., 2012, P NIPS WORKSH LOG LI; Sainath T. N., 2013, P ICASSP, P706; Sainath T.N., 2013, P ICASSP UNPUB; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; Seide F., 2011, P INTERSPEECH; Seide F., 2011, P ASRU, P24; Soltau H, 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), DOI 10.1109/SLT.2010.5700829; Strang G., 2009, INTRO LINEAR ALGEBRA; Vesely K., 2010, P INTERSPEECH; Vinyals O., 2011, P NIPS WORKSH OPT HI; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4409; Yu D., 2010, P NIPS WORKSH DEEP L; Yuan M, 2007, J ROY STAT SOC B, V69, P329, DOI 10.1111/j.1467-9868.2007.00591.x; Zinkevich M. A., 2010, P NIPS	38	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916	1558-7924		IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	NOV	2013	21	11					2267	2276		10.1109/TASL.2013.2284378		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	238KI	WOS:000325944800005		
J	Triefenbach, F; Jalalvand, A; Demuynck, K; Martens, JP				Triefenbach, Fabian; Jalalvand, Azarakhsh; Demuynck, Kris; Martens, Jean-Pierre			Acoustic Modeling With Hierarchical Reservoirs	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Acoustic modeling; automatic speech recognition; recurrent neural networks; reservoir computing	AUTOMATIC SPEECH RECOGNITION; HIDDEN MARKOV-MODELS; ECHO STATE NETWORKS; NEURAL-NETWORKS; PHONEME RECOGNITION; REPRESENTATIONS; NEURONS; NETS; TIME	Accurate acoustic modeling is an essential requirement of a state-of-the-art continuous speech recognizer. The Acoustic Model (AM) describes the relation between the observed speech signal and the non-observable sequence of phonetic units uttered by the speaker. Nowadays, most recognizers use Hidden Markov Models (HMMs) in combination with Gaussian Mixture Models (GMMs) to model the acoustics, but neural-based architectures are on the rise again. In this work, the recently introduced Reservoir Computing (RC) paradigm is used for acoustic modeling. A reservoir is a fixed-and thus non-trained-Recurrent Neural Network (RNN) that is combined with a trained linear model. This approach combines the ability of an RNN to model the recent past of the input sequence with a simple and reliable training procedure. It is shown here that simple reservoir-based AMs achieve reasonable phone recognition and that deep hierarchical and bi-directional reservoir architectures lead to a very competitive Phone Error Rate (PER) of 23.1% on the well-known TIMIT task.	[Triefenbach, Fabian; Jalalvand, Azarakhsh; Demuynck, Kris; Martens, Jean-Pierre] Ghent Univ iMinds, ELIS Multimedia Lab, B-9000 Ghent, Belgium	Triefenbach, F (reprint author), Ghent Univ iMinds, ELIS Multimedia Lab, B-9000 Ghent, Belgium.	fabian.triefenbach@elis.ugent.be; azarakhsh.jalal-vand@elis.ugent.be; kris.demuynck@elis.ugent.be; martens@elis.ugent.be			European Community [231267]; Research Foundation Flanders (FWO) [G.0088.09N]	This work was supported by the European Community's Seventh Framework Program (FP7) under grant agreement 231267 "Self-organized recurrent neural learning of language processing" (ORGANIC) and from the Research Foundation Flanders (FWO) under grant agreement G.0088.09N (RECAP). The associate editor coordinating the review of this manuscript and approving it for publication was Dr. James Glass.	Bengio Y., 2007, P ADV NEUR INF PROC, P153; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Bourlard H., 1994, KLUWER INT SERIES EN, V247; BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605; Correa DC, 2008, CSE 2008:11TH IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING, PROCEEDINGS, P293; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Deng L, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2133; Deng L, 2011, P INTERSPEECH, P2285; Deng L, 2007, INT CONF ACOUST SPEE, P445; Fernandez S., 2008, IDSIA0408; Garofolo JS, 1993, DARPA TIMIT ACOUSTIC; Graves A., 2008, THESIS TU MUNCHEN MU; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Holzmann G, 2010, NEURAL NETWORKS, V23, P244, DOI 10.1016/j.neunet.2009.07.004; Hutchinson B, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4805; Jaeger H., 2002, 159 GMD GERM NAT RES; Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016; Jaeger H., 2001, 148 GMD GERM NAT RES; Jaitly N., 2012, P INTERSPEECH; Jalalvand A., 2012, P INTERSPEECH; Jalalvand A., 2011, P INTERSPEECH, P1725; Jiang H, 2010, COMPUT SPEECH LANG, V24, P589, DOI 10.1016/j.csl.2009.08.002; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Lukosevicius Mantas, 2012, KI-Kunstliche Intelligenz, V26, DOI 10.1007/s13218-012-0204-5; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; MARQUARDT DW, 1975, AM STAT, V29, P3, DOI 10.2307/2683673; Merialdo B., 1988, P IEEE INT C AC SPEE, P111; MING J, 1998, ACOUST SPEECH SIG PR, P409; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844; Morgan N., 1990, P IEEE INT C AC SPEE, P413; Penrose R., 1955, P CAMBRIDGE PHILOS S, V51, P406, DOI DOI 10.1017/S0305004100030401; Pinto J, 2011, IEEE T AUDIO SPEECH, V19, P225, DOI 10.1109/TASL.2010.2045943; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Robinson T., 1991, Computer Speech and Language, V5, DOI 10.1016/0885-2308(91)90010-N; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath T.N., 2011, P ASRU, P30; Schrauwen B, 2008, NEUROCOMPUTING, V71, P1159, DOI 10.1016/j.neucom.2007.12.020; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Skowronski MD, 2007, NEURAL NETWORKS, V20, P414, DOI 10.1016/j.neunet.2007.04.006; Toth L, 2011, INT CONF ACOUST SPEE, P5040; TRIEFENBACH F, 2010, P NIPS, P2307; Triefenbach F, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P107, DOI 10.1109/SLT.2012.6424206; Triefenbach F., 2011, Proceedings of the 2011 First International Conference on Informatics and Computational Intelligence (ICI 2011), DOI 10.1109/ICI.2011.50; Tuske Z., 2012, P INT; Verstraeten D, 2007, NEURAL NETWORKS, V20, P391, DOI 10.1016/j.neunet.2007.04.003; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270	60	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916	1558-7924		IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	NOV	2013	21	11					2439	2450		10.1109/TASL.2013.2280209		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	238KI	WOS:000325944800019		
J	Siniscalchi, SM; Yu, D; Deng, L; Lee, CH				Siniscalchi, Sabato Marco; Yu, Dong; Deng, Li; Lee, Chin-Hui			Speech Recognition Using Long-Span Temporal Patterns in a Deep Network Model	IEEE SIGNAL PROCESSING LETTERS			English	Article						Automatic speech recognition; deep neural networks; large vocabulary continuous speech recognition	NEURAL-NETWORKS; ASR	In recent years, there has been a renewed interest in the use of artificial neural networks (ANNs) for speech applications, and it seems that a new trend to move the speech technology forward has begun. Two main contributions have triggered such a new trend: 1) a major advance has been made in training the weights in deep neural networks (DNNs), and a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture has outperformed a conventional Gaussian mixture model hidden Markov model (GMM-HMM) automatic speech recognition (ASR) system on a challenging business search dataset, and 2) it has been shown that phoneme classification can be boosted by using a hierarchical structure of multi-layer perceptrons (MLPs) trained to model long-span temporal patterns with beneficial effects on language recognition tasks. In this work, we combine these two lines of research and demonstrate that word recognition accuracy can be significantly enhanced by arranging DNNs in a hierarchical structure to model long-term energy trajectories. The proposed solution has been evaluated on the 5000-word Wall Street Journal task, resulting in consistent and significant improvements in both phone and word recognition accuracy rates. We have also analyzed the effects of various modeling choices on the system performance, and several architectural solutions have been compared.	[Siniscalchi, Sabato Marco] Univ Enna Kore, Fac Engn & Architecture, I-94100 Enna, Italy; [Yu, Dong; Deng, Li] Microsoft Res, Speech Res Grp, Redmond, WA 98052 USA; [Lee, Chin-Hui] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Siniscalchi, SM (reprint author), Univ Enna Kore, Fac Engn & Architecture, I-94100 Enna, Italy.	marco.siniscalchi@unikore.it; dong.yu@microsoft.com; li.deng@mi-crosoft.com; chl@ece.gatech.edu	Siniscalchi, Sabato/I-3423-2012; Siniscalchi, Sabato Marco/	Siniscalchi, Sabato Marco/0000-0002-0770-0507			Bahl L. R., 1986, P IEEE INT C AC SPEE, P49; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Bromberg I, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P1633; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Erhan D, 2009, P 12 INT C ART INT S, P153; Fousek P, 2006, INT CONF ACOUST SPEE, P433; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Hermansky H., 1999, P ASRU KEYST CO US D; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hwang M.-Y., 1993, IEEE T SPEECH AUDIO, V1, P441; Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257; Matejka P., 2005, P INT 2005 LISB PORT, P2237; Paul D., 1992, P ICSLP, P899; POVEY D, 2002, P ICASSP, P105; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Siniscalchi SM, 2012, IEEE T AUDIO SPEECH, V20, P875, DOI 10.1109/TASL.2011.2167610; Siniscalchi SM, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P168; Siniscalchi SM, 2013, COMPUT SPEECH LANG, V27, P209, DOI 10.1016/j.csl.2012.05.001; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4169	23	4	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9908			IEEE SIGNAL PROC LET	IEEE Signal Process. Lett.	MAR	2013	20	3					201	204		10.1109/LSP.2013.2237901		4	Engineering, Electrical & Electronic	Engineering	079PN	WOS:000314183500002		
J	Langkvist, M; Coradeschi, S; Loutfi, A; Rayappan, JBB				Langkvist, Martin; Coradeschi, Silvia; Loutfi, Amy; Rayappan, John Bosco Balaguru			Fast Classification of Meat Spoilage Markers Using Nanostructured ZnO Thin Films and Unsupervised Feature Learning	SENSORS			English	Article						electronic nose; sensor material; representational learning; fast multi-label classification	SENSING PROPERTIES; ELECTRONIC-NOSE; SHEAR FORCE; BEEF; TENDERNESS; QUALITY; MUSCLE; SPECTROSCOPY; PECTORALIS; ALGORITHM	This paper investigates a rapid and accurate detection system for spoilage in meat. We use unsupervised feature learning techniques (stacked restricted Boltzmann machines and auto-encoders) that consider only the transient response from undoped zinc oxide, manganese-doped zinc oxide, and fluorine-doped zinc oxide in order to classify three categories: the type of thin film that is used, the type of gas, and the approximate ppm-level of the gas. These models mainly offer the advantage that features are learned from data instead of being hand-designed. We compare our results to a feature-based approach using samples with various ppm level of ethanol and trimethylamine (TMA) that are good markers for meat spoilage. The result is that deep networks give a better and faster classification than the feature-based approach, and we thus conclude that the fine-tuning of our deep models are more efficient for this kind of multi-label classification task.	[Langkvist, Martin; Coradeschi, Silvia; Loutfi, Amy] Univ Orebro, Ctr Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden; [Rayappan, John Bosco Balaguru] SASTRA Univ, Ctr Nanotechnol & Adv Biomat CeNTAB, Thanjavur 613401, Tamil Nadu, India; [Rayappan, John Bosco Balaguru] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, Tamil Nadu, India	Langkvist, M (reprint author), Univ Orebro, Ctr Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden.	martin.langkvist@oru.se; silvia.coradeschi@oru.se; amy.loutfi@oru.se; rjbosco@ece.sastra.edu	Rayappan, John Bosco Balaguru/K-6842-2013; Loutfi, Amy/	Rayappan, John Bosco Balaguru/0000-0003-4641-9870; Loutfi, Amy/0000-0002-3122-693X	Department of Science & Technology, India; VINNOVA, Sweden [INT/SWD/VINN/P-04/2011]	The authors wish to express their sincere thanks to Department of Science & Technology, India and VINNOVA, Sweden for their financial support (Project ID: INT/SWD/VINN/P-04/2011). They also wish to acknowledge SASTRA University, Thanjavur, India and Orebro University, Orebro, Sweden for extending infrastructural support to carry out the study.	Abouelkaram S, 2000, FOOD CHEM, V69, P447, DOI 10.1016/S0308-8146(00)00067-4; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Barbri N. E., 2009, SENSOR ACTUAT B-CHEM, V141, P538; Bengio Y., UNSUPERVISED FEATURE; Bengio Y., PRACTICAL RECOMMENDA; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Carmel L, 2003, SENSOR ACTUAT B-CHEM, V93, P67, DOI 10.1016/S0925-4005(03)00247-8; Danilo E., 2009, APPL ENVIRON MICROB, V75, P1990; EDWARDS RA, 1987, J APPL BACTERIOL, V62, P403, DOI 10.1111/j.1365-2672.1987.tb02669.x; Egelandsdal B, 2002, MEAT SCI, V60, P187, DOI 10.1016/S0309-1740(01)00121-8; Ferguson D., 1993, P AUSTR MEAT IND RES, V82, P1; Frost JA, 2001, J APPL MICROBIOL, V90, p85S, DOI 10.1046/j.1365-2672.2001.01357.x; Haugen JE, 2006, SENSOR ACTUAT B-CHEM, V116, P72, DOI 10.1016/j.snb.2005.12.064; Herrero AM, 2008, FOOD CHEM, V107, P1642, DOI 10.1016/j.foodchem.2007.10.014; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hongsith N, 2010, IEEE SENS J, V10, P34, DOI 10.1109/JSEN.2009.2035746; Janotti A., 2009, REP PROG PHYS, V72; Jia S., 2010, IEEE T KNOWL DATA EN, V22, P1345; Kempen T. van, 2001, World's Poultry Science Journal, V57, P29, DOI 10.1079/WPS20010004; Langkvist M, 2011, P NIPS 2011 WORKSH D; Lilienthal AJ, 2006, SENSORS-BASEL, V6, P1616, DOI 10.3390/s6111616; Loutfi A, 2009, ROBOTICA, V27, P311, DOI 10.1017/S0263574708004694; Loutfi A., 2002, P IEEE INT S VIRT IN, P46; Mayr D, 2003, APPL ENVIRON MICROB, V69, P4697, DOI 10.1128/AEM.69.8.4697-4705.2003; Meullenet JF, 2004, J TEXTURE STUD, V35, P573, DOI 10.1111/j.1745-4603.2004.35510.x; Mnih V., 2011, P UNC ART INT BARC S; Musatov V. Yu., 2010, SENSOR ACTUAT B-CHEM, V144, P99; Xing J, 2007, J FOOD ENG, V82, P135, DOI 10.1016/j.jfoodeng.2007.01.020; OPHIR J, 1994, MEAT SCI, V36, P239, DOI 10.1016/0309-1740(94)90043-4; Oshima I, 2007, ANIM SCI J, V78, P619, DOI 10.1111/j.1740-0929.2007.00483.x; Raina R., 2007, P 24 INT C MACH LEAR; Schlundt J, 2001, BIOMED ENVIRON SCI, V14, P44; Shackelford SD, 1999, J ANIM SCI, V77, P2693; Sivalingam D, 2012, SENSOR ACTUAT B-CHEM, V166, P624, DOI 10.1016/j.snb.2012.03.023; Sivalingam Durgajanani, 2011, International Journal of Nanoscience, V10, DOI 10.1142/S0219581X1100943X; Sivalingam D., 2011, CRYST RES TECHNOL, V46, P685; Stephens JW, 2004, J ANIM SCI, V82, P2077; Swatland HJ, 2001, MEAT SCI, V57, P209, DOI 10.1016/S0309-1740(00)00095-4; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Timm RR, 2003, J ANIM SCI, V81, P1721; Trincavelli M, 2009, SENSOR ACTUAT B-CHEM, V139, P265, DOI 10.1016/j.snb.2009.03.018; Trincavelli M, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P4110, DOI 10.1109/IROS.2008.4650713; Venturi L, 2007, J AGR FOOD CHEM, V55, P10572, DOI 10.1021/jf072874b; Wei A, 2011, MATER SCI ENG B-ADV, V176, P1409, DOI 10.1016/j.mseb.2011.09.005; Wilson AD, 2009, SENSORS-BASEL, V9, P5099, DOI 10.3390/s90705099; Yarmand M. S., 2000, Journal of Agricultural Science and Technology, V2, P217	46	4	4	MDPI AG	BASEL	POSTFACH, CH-4005 BASEL, SWITZERLAND	1424-8220			SENSORS-BASEL	Sensors	FEB	2013	13	2					1578	1592		10.3390/s130201578		15	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	096KS	WOS:000315403300012	23353140	
J	Cardoso, A; Wichert, A				Cardoso, Angelo; Wichert, Andreas			Handwritten digit recognition using biologically inspired features	NEUROCOMPUTING			English	Article						Image recognition; Simple and complex cells; Handwritten digits; Feature extraction	VISUAL-PATTERN RECOGNITION; MONKEY STRIATE CORTEX; NEURAL NETWORK; OBJECT RECOGNITION; RECEPTIVE-FIELDS; NEOCOGNITRON; SUPPORT	Image recognition problems are usually difficult to solve using raw pixel data. To improve the recognition it is often needed some form of feature extraction to represent the data in a feature space. We use the output of a biologically inspired model for visual recognition as a feature space. The output of the model is a binary code which is used to train a linear classifier for recognizing handwritten digits using the MNIST and USPS datasets. We evaluate the robustness of the approach to a variable number of training samples and compare its performance on these popular datasets to other published results. We achieve competitive error rates on both datasets while greatly improving relatively to related networks using a linear classifier. (C) 2012 Elsevier B.V. All rights reserved.	[Cardoso, Angelo] Univ Tecn Lisboa, INESC ID Lisboa, P-2744016 Porto Salvo, Portugal; Univ Tecn Lisboa, Inst Super Tecn, P-2744016 Porto Salvo, Portugal	Cardoso, A (reprint author), Univ Tecn Lisboa, INESC ID Lisboa, Av Prof Dr Anibal Cavaco Silva, P-2744016 Porto Salvo, Portugal.	angelo.cardoso@ist.utl.pt; andreas.wichert@ist.utl.pt	Wichert, Andreas/E-2494-2012; Cardoso, Angelo/K-5922-2014	Wichert, Andreas/0000-0002-2179-4378; Cardoso, Angelo/0000-0003-4155-3827	Fundacao para a Ciencia e Tecnologia (INESC-ID) through the PIDDAC;  [SFRH/BD/61513/2009]	The authors would like to thank Joao Sacramento for much helpful comments. This work was supported by Fundacao para a Ciencia e Tecnologia (INESC-ID multiannual funding) through the PIDDAC Program funds and through an individual doctoral grant awarded to the first author (Contract SFRH/BD/61513/2009).	BLAKEMOR.C, 1972, EXP BRAIN RES, V15, P439; Booth MCA, 1998, CEREB CORTEX, V8, P510, DOI 10.1093/cercor/8.6.510; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; Cardoso A, 2010, NEURAL NETWORKS, V23, P74, DOI 10.1016/j.neunet.2009.09.004; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Friedman J. H., 1996, ANOTHER APPROACH POL; FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; Fukushima K, 2011, NEURAL NETWORKS, V24, P767, DOI 10.1016/j.neunet.2011.03.017; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HUBEL DH, 1974, J COMP NEUROL, V158, P295, DOI 10.1002/cne.901580305; Hubel DH, 1988, EYE BRAIN VISION; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229; HUBEL DH, 1974, J COMP NEUROL, V158, P267, DOI 10.1002/cne.901580304; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kavukcuoglu K., 2008, TECHNICAL REPORT; Keysers D, 2000, INT C PATT RECOG, P38; KOBATAKE E, 1994, J NEUROPHYSIOL, V71, P856; Kressel U.H.-G., 1999, ADV KERNEL METHODS S, P255; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lazebnik S., 2006, CVPR, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y.A., 1995, P INT C ART NEUR NET, V2, P53; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3206(03)00085-2; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; Lowe D., 2000, BIOL MOTIVATED COMPU, P141; Miikkulainen R, 2005, COMPUTATIONAL MAPS V; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Ranzato M., 2007, IEEE C COMP VIS PATT, P1; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Riesenhuber M., 2000, THESIS; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Scholkopf B., 1995, P 1 INT C KNOWL DISC; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Serre T., 2004, REALISTIC MODELING S; Simard P., 1998, NEURAL NETWORKS TRIC; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; SIROSH J, 1994, BIOL CYBERN, V71, P65, DOI 10.1007/BF00198912; Tipping ME, 2000, ADV NEUR IN, V12, P652; Vapnik V. N., 1995, NATURE STAT LEARNING; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; WICHERT A, 1993, WCNN'93 - PORTLAND, WORLD CONGRESS ON NEURAL NETWORKS, VOL IV, P59; Yu K., 2009, ADV NEURAL INFORM PR, V22, P2223	48	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	JAN 1	2013	99						575	580		10.1016/j.neucom.2012.07.027		6	Computer Science, Artificial Intelligence	Computer Science	037TL	WOS:000311129300057		
J	Fernandez, R; Rendel, A; Ramabhadran, B; Hoory, R			IEEE	Fernandez, Raul; Rendel, Asaf; Ramabhadran, Bhuvana; Hoory, Ron			F0 CONTOUR PREDICTION WITH A DEEP BELIEF NETWORK-GAUSSIAN PROCESS HYBRID MODEL	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		speech synthesis; intonation generation; neural networks; Gaussian processes	GENERATION	In this work we look at using non-parametric, exemplar-based regression for the prediction of prosodic contour targets from textual features in a speech synthesis system. We investigate the performance of Gaussian Process regression on this task when the covariance kernel operates on a variety of input feature spaces. In particular, we consider non-linear features extracted via Deep Belief Networks. We motivate the use of this hybrid model by considering the initial deep-layer model as a feature extractor that can summarize high-level structure from the raw inputs to improve the regression of an exemplar-based model in the second part of the approach. By looking at both objective metrics and perceptual listening tests, we evaluate these proposals against each other, and against the standard clustering-tree techniques implemented in parametric synthesis for the prediction of prosodic targets.	[Fernandez, Raul; Ramabhadran, Bhuvana] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	Fernandez, R (reprint author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.						Henter GE, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4505; Hinton G., 2010, 2010003 U TOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Park H., 2011, NIPS 2011; Pilkington N., 2011, INTERSPEECH, P2761; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Sainath T. N., 2011, P ASRU HAW; SAKURAI A, 2001, ACOUST SPEECH SIG PR, P817; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Vishnubhotlan S., 2010, ICASSP, V2, P4614; Yamagishi Y., 2007, BLIZZARD 2007; Young S. J., 2006, HTK BOOK VERSION 3 4	13	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							6885	6889				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507009		
J	Kang, SY; Qian, XJ; Meng, HL			IEEE	Kang, Shiyin; Qian, Xiaojun; Meng, Helen			MULTI-DISTRIBUTION DEEP BELIEF NETWORK FOR SPEECH SYNTHESIS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Speech synthesis; Deep belief network	HMM	Deep belief network (DBN) has been shown to be a good generative model in tasks such as hand-written digit image generation. Previous work on DBN in the speech community mainly focuses on using the generatively pre-trained DBN to initialize a discriminative model for better acoustic modeling in speech recognition (SR). To fully utilize its generative nature, we propose to model the speech parameters including spectrum and F0 simultaneously and generate these parameters from DBN for speech synthesis. Compared with the predominant HMM-based approach, objective evaluation shows that the spectrum generated from DBN has less distortion. Subjective results also confirm the advantage of the spectrum from DBN, and the overall quality is comparable to that of context-independent HMM.	[Kang, Shiyin; Qian, Xiaojun; Meng, Helen] Chinese Univ Hong Kong, Human Comp Commun Lab, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China	Kang, SY (reprint author), Chinese Univ Hong Kong, Human Comp Commun Lab, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.						Black AW, 2007, INT CONF ACOUST SPEE, P1229; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478; Fukada T., 1992, ICASSP, V1, P137; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Shuang Z., 2009, INTERSPEECH, P1767; Susskind Joshua M., 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition; Taylor GW, 2011, J MACH LEARN RES, V12, P1025; Tokuda K., 1994, ICSLP; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Tokuda K, 2002, IEICE T INF SYST, VE85D, P455; Yoshimura T., 1999, EUROSPEECH, P2347	13	4	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							8012	8016				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611508035		
S	Liao, S; Gao, YZ; Oto, A; Shen, DG		Sakuma, I; Barillot, C; Navab, N		Liao, Shu; Gao, Yaozong; Oto, Aytekin; Shen, Dinggang			Representation Learning: A Unified Deep Learning Framework for Automatic Prostate MR Segmentation	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2013, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	16th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)	SEP 22-26, 2013	Nagoya, JAPAN	Nagoya Convent & Visitors Bur, Murata Sci Fdn, Daiko Fdn, Japan Soc Comp Aided Surg, Sci Council Japan, Nagoya Univ, Informat & Commun Headquarters, Nagoya Univ, Grad Sch Informat Sci	Nagoya Univ			Image representation plays an important role in medical image analysis. The key to the success of different medical image analysis algorithms is heavily dependent on how we represent the input data, namely features used to characterize the input image. In the literature, feature engineering remains as an active research topic, and many novel hand-crafted features are designed such as Haar wavelet, histogram of oriented gradient, and local binary patterns. However, such features are not designed with the guidance of the underlying dataset at hand. To this end, we argue that the most effective features should be designed in a learning based manner, namely representation learning, which can be adapted to different patient datasets at hand. In this paper, we introduce a deep learning framework to achieve this goal. Specifically, a stacked independent subspace analysis (ISA) network is adopted to learn the most effective features in a hierarchical and unsupervised manner. The learnt features are adapted to the dataset at hand and encode high level semantic anatomical information. The proposed method is evaluated on the application of automatic prostate MR segmentation. Experimental results show that significant segmentation accuracy improvement can be achieved by the proposed deep learning method compared to other state-of-the-art segmentation approaches.	[Liao, Shu; Gao, Yaozong; Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27514 USA	Liao, S (reprint author), Univ N Carolina, Dept Radiol, Chapel Hill, NC 27514 USA.	dgshen@med.unc.edu					Bengio Y., 2006, NIPS, P153; Coupe P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018; Dalal N, 2005, PROC CVPR IEEE, P886; Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Klein S, 2008, MED PHYS, V35, P1407, DOI 10.1118/1.2842076; Le Q., 2011, CVPR, P3361; Liao S., 2012, LNCS, V7512, P385; Mallat G, 1989, IEEE T PATTERN ANAL, V11, P674; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Rousseau F, 2011, IEEE T MED IMAGING, V30, P1852, DOI 10.1109/TMI.2011.2156806; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Zhang ST, 2012, MED IMAGE ANAL, V16, P265, DOI 10.1016/j.media.2011.08.004	14	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-40763-5; 978-3-642-40762-8	LECT NOTES COMPUT SC			2013	8150						254	261				8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BB3LH	WOS:000342835100032		
J	Ling, ZH; Deng, L; Yu, D			IEEE	Ling, Zhen-Hua; Deng, Li; Yu, Dong			MODELING SPECTRAL ENVELOPES USING RESTRICTED BOLTZMANN MACHINES FOR STATISTICAL PARAMETRIC SPEECH SYNTHESIS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Speech synthesis; hidden Markov model; restricted Boltzmann machine; spectral envelope	NEURAL-NETWORKS	This paper presents a new spectral modeling method for statistical parametric speech synthesis. In contrast to the conventional methods in which high-level spectral parameters, such as mel-cepstra or line spectral pairs, are adopted as the features for hidden Markov model (HMM) based parametric speech synthesis, our new method directly models the distribution of the lower-level, un-transformed or raw spectral envelopes. Instead of using single Gaussian distributions, we adopt restricted Boltzmann machines (RBM) to represent the distribution of the spectral envelopes at each HMM state. We anticipate these will give superior performance in modeling the joint distribution of high-dimensional stochastic vectors. The spectral parameters are derived from the spectral envelope corresponding to the estimated mode of each context-dependent RBM and act as the Gaussian mean vector in the parameter generation procedure at synthesis time. Our experimental results show that the RBM is able to model the distribution of the spectral envelopes with better accuracy and generalization ability than the Gaussian mixture model. As a result, our proposed method can significantly improve the naturalness of the conventional HMM-based speech synthesis system using mel-cepstra.	[Ling, Zhen-Hua] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China	Ling, ZH (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China.	zhling@ustc.edu.cn; deng@microsoft.com; dongyu@microsoft.com					Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5; Ling Z.-H, 2006, BLIZZ CHALL WORKSH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Salakhutdinov R., 2009, THESIS U TORONTO; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Uria B., 2011, NIPS 2011 WORKSH DEE; Yoshimura T., 1999, EUROSPEECH, P2347; Zen HG, 2007, IEICE T INF SYST, VE90D, P325, DOI 10.1093/ietisy/e90-d.1.325	15	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7825	7829				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507200		
J	Bohmer, W; Grunewalder, S; Nickisch, H; Obermayer, K				Boehmer, Wendelin; Gruenewaelder, Steffen; Nickisch, Hannes; Obermayer, Klaus			Generating feature spaces for linear algorithms with regularized sparse kernel slow feature analysis	MACHINE LEARNING			English	Article						Time series; Latent variables; Unsupervised learning; Slow feature analysis; Sparse kernel methods; Linear classification		Without non-linear basis functions many problems can not be solved by linear algorithms. This article proposes a method to automatically construct such basis functions with slow feature analysis (SFA). Non-linear optimization of this unsupervised learning method generates an orthogonal basis on the unknown latent space for a given time series. In contrast to methods like PCA, SFA is thus well suited for techniques that make direct use of the latent space. Real-world time series can be complex, and current SFA algorithms are either not powerful enough or tend to over-fit. We make use of the kernel trick in combination with sparsification to develop a kernelized SFA algorithm which provides a powerful function class for large data sets. Sparsity is achieved by a novel matching pursuit approach that can be applied to other tasks as well. For small data sets, however, the kernel SFA approach leads to over-fitting and numerical instabilities. To enforce a stable solution, we introduce regularization to the SFA objective. We hypothesize that our algorithm generates a feature space that resembles a Fourier basis in the unknown space of latent variables underlying a given real-world time series. We evaluate this hypothesis at the example of a vowel classification task in comparison to sparse kernel PCA. Our results show excellent classification accuracy and demonstrate the superiority of kernel SFA over kernel PCA in encoding latent variables.	[Boehmer, Wendelin; Obermayer, Klaus] Tech Univ Berlin, Neural Informat Proc Grp, Berlin, Germany; [Gruenewaelder, Steffen] UCL, Ctr Computat Stat & Machine Learning, London, England; [Nickisch, Hannes] Philips Res Labs, Hamburg, Germany	Bohmer, W (reprint author), Tech Univ Berlin, Neural Informat Proc Grp, Berlin, Germany.	wendelin@ni.tu-berlin.de; steffen@cs.ucl.ac.uk; hannes.nickisch@philips.com; klaus.obermayer@tu-berlin.de			Integrated Graduate Program on Human-Centric Communication at Technische Universitat Berlin; German Research Foundation [DFG SPP 1527]; German Federal Ministry of Education and Research [01GQ0850]; EPSRC [EP/H017402/1]	This work has been supported by the Integrated Graduate Program on Human-Centric Communication at Technische Universitat Berlin, the German Research Foundation (DFG SPP 1527 autonomous learning), the German Federal Ministry of Education and Research (grant 01GQ0850) and EPSRC grant #EP/H017402/1 (CARDyAL). We want to thank Matthias Franzius, who gave us a sound introduction into non-linear SFA, and Roland Vollgraf for his contribution to an earlier version of RSK-SFA.	Assmann Peter F, 2008, Canadian Acoustics, V36; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Berkes P., 2005, 4104 COGN SCI EPRINT; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; Bishop CM, 2006, PATTERN RECOGNITION; Bohmer W., 2011, ECML PKDD 2011, VI, P235; Bray A., 2002, NEURAL INFORM PROCES, V15, P253; Csato L, 2002, NEURAL COMPUT, V14, P641, DOI 10.1162/089976602317250933; Duda R.O., 1973, PATTERN CLASSIFICATI; Einhauser W, 2005, BIOL CYBERN, V93, P79, DOI 10.1007/s00422-005-0585-8; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fletcher R., 1987, PRACTICAL METHODS OP; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Franzius M, 2007, PLOS COMPUT BIOL, V3, P1605, DOI 10.1371/journal.pcbi.0030166; Fukumizu K, 2007, J MACH LEARN RES, V8, P361; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huke J. P., 2006, D91 SECURESCM; Hussain Z., 2008, ADV NEURAL INFORM PR, V21, P721; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rubin D. B., 1983, ENCY STATISTICAL SCI, V4, P272; Scholkopf B., 1997, ARTIFICIAL NEURAL NE; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shawe-Taylor John, 2004, KERNEL METHODS PATTE; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; Stone JV, 2001, NEURAL COMPUT, V13, P1559, DOI 10.1162/089976601750265009; Takens F., 1981, LECT NOTES MATH, V898, P366, DOI DOI 10.1007/BFB0091924; Tweedie R. L., 1993, MARKOV CHAINS STOCHA; Wahba G., 1990, SPLINE MODELS OBSERV; Wiskott L, 2003, NEURAL COMPUT, V15, P2147, DOI 10.1162/089976603322297331; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Wyss R, 2006, PLOS BIOL, V4, P836, DOI 10.1371/journal.pbio.0040120	34	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125			MACH LEARN	Mach. Learn.	OCT	2012	89	1-2			SI		67	86		10.1007/s10994-012-5300-0		20	Computer Science, Artificial Intelligence	Computer Science	991QU	WOS:000307717100004		
J	Deselaers, T; Gass, T; Heigold, G; Ney, H				Deselaers, Thomas; Gass, Tobias; Heigold, Georg; Ney, Hermann			Latent Log-Linear Models for Handwritten Digit Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Log-linear models; latent variables; conditional random fields; OCR; image classification	SUPPORT VECTOR MACHINES; RECOGNITION; KERNELS	We present latent log-linear models, an extension of log-linear models incorporating latent variables, and we propose two applications thereof: log-linear mixture models and image deformation-aware log-linear models. The resulting models are fully discriminative, can be trained efficiently, and the model complexity can be controlled. Log-linear mixture models offer additional flexibility within the log-linear modeling framework. Unlike previous approaches, the image deformation-aware model directly considers image deformations and allows for a discriminative training of the deformation parameters. Both are trained using alternating optimization. For certain variants, convergence to a stationary point is guaranteed and, in practice, even variants without this guarantee converge and find models that perform well. We tune the methods on the USPS data set and evaluate on the MNIST data set, demonstrating the generalization capabilities of our proposed models. Our models, although using significantly fewer parameters, are able to obtain competitive results with models proposed in the literature.	[Deselaers, Thomas] Google Switzerland, CH-8002 Zurich, Switzerland; [Gass, Tobias] ETH, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Heigold, Georg] Google Inc, Mountain View, CA 94043 USA; [Ney, Hermann] Rhein Westfal TH Aachen, Lehrstuhl Informat 6, D-52056 Aachen, Germany; [Deselaers, Thomas; Gass, Tobias; Heigold, Georg; Ney, Hermann] Univ Aachen, RWTH, Dept Comp Sci, Human Language Technol & Pattern Recognit Grp, Aachen, Germany	Deselaers, T (reprint author), Google Switzerland, Brandschenkestr 110, CH-8002 Zurich, Switzerland.	deselaers@gmail.com; gasst@vision.ee.ethz.ch; heigold_stadelmann@hotmail.com; ney@cs.rwth-aachen.de	Gass, Tobias/C-2244-2013				Anderson J., 1982, HDB STATISTICS, P169, DOI 10.1016/S0169-7161(82)02010-0; Barndorff-Nielsen O., 1988, ANN I STAT MATH, V41, P247; Bender O., 2003, P CONLL 2003 EDM CAN, P148; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gass T., 2009, P 31 DAGM S PATT REC; Gehler P., 2009, P IEEE C COMP VIS PA; Gunawardana A, 2005, J MACH LEARN RES, V6, P2049; Gunawardana A., 2005, P INT C SPOK LANG PR, P117; Haasdonk B, 2002, INT C PATT RECOG, P864; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Haasdonk B., 2005, THESIS ALBERT LUDWIG; Heigold G., 2008, P INT SEPT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jebara T., 2003, MACHINE LEARNING DIS; Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153; Keysers D, 2004, IEEE T PATTERN ANAL, V26, P269, DOI 10.1109/TPAMI.2004.1262198; Kullback S., 1971, ESTIMATING TES UNPUB; Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282; Landauer T. K., 2007, HDB LATENT SEMANTIC; LeCun Y., 2011, MNIST DATABASE HANDW; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Memisevic R., 2007, P IEEE C COMP VIS PA; Minka T.P., 2004, COMP NUMERICAL OPTIM; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386; Och F. J., 2002, P 40 ANN M ASS COMP, P295; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Saul LK, 2002, ADV NEUR IN, V14, P897; Scholkopf B., 2010, USPS DATA SET; Scholkopf B., 2002, LEARNING KERNELS; Simard P .Y, 2003, P INT C DOC AN REC, P958; Uchida S, 2005, IEICE T INF SYST, VE88D, P1781, DOI 10.1093/ietisy/e88-d.8.1781; Weyand T., 2009, P BRIT MACH VIS C	38	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1105	1117		10.1109/TPAMI.2011.218		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	927OE	WOS:000302916600006	22064798	
J	Fleuret, F; Li, T; Dubout, C; Wampler, EK; Yantis, S; Geman, D				Fleuret, Francois; Li, Ting; Dubout, Charles; Wampler, Emma K.; Yantis, Steven; Geman, Donald			Comparing machines and humans on a visual categorization test	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						abstract reasoning; human learning; pattern recognition	OBJECT RECOGNITION; PICTORIAL STRUCTURES; FACE DETECTION; MODELS	Automated scene interpretation has benefited from advances in machine learning, and restricted tasks, such as face detection, have been solved with sufficient accuracy for restricted settings. However, the performance of machines in providing rich semantic descriptions of natural scenes from digital images remains highly limited and hugely inferior to that of humans. Here we quantify this "semantic gap" in a particular setting: We compare the efficiency of human and machine learning in assigning an image to one of two categories determined by the spatial arrangement of constituent parts. The images are not real, but the category-defining rules reflect the compositional structure of real images and the type of "reasoning" that appears to be necessary for semantic parsing. Experiments demonstrate that human subjects grasp the separating principles from a handful of examples, whereas the error rates of computer programs fluctuate wildly and remain far behind that of humans even after exposure to thousands of examples. These observations lend support to current trends in computer vision such as integrating machine learning with parts-based modeling.	[Fleuret, Francois; Dubout, Charles] Idiap Res Inst, CH-1920 Martigny, Switzerland; [Fleuret, Francois; Dubout, Charles] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland; [Li, Ting; Geman, Donald] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; [Wampler, Emma K.; Yantis, Steven] Johns Hopkins Univ, Dept Psychol & Brain Sci, Baltimore, MD 21218 USA	Fleuret, F (reprint author), Idiap Res Inst, CH-1920 Martigny, Switzerland.	francois.fleuret@idiap.ch	Geman, Donald/A-3325-2010		European Union [247022-MASH]; Swiss National Science Foundation [200021-124822-VELASH]; National Institutes of Health [R01-DA013165]; Office of Naval Research [N00014-07-1-1002]; National Science Foundation [0427223]	F.F. was supported by European Union Grant Agreement 247022-MASH; C.D. by the Swiss National Science Foundation under Grant 200021-124822-VELASH; S.Y. by National Institutes of Health Grant R01-DA013165; and D.G. by Office of Naval Research Contract N00014-07-1-1002 and National Science Foundation Grant 0427223.	Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Chang LB, 2010, INT J COMPUT VISION, V93, P117; Dalal N, 2005, PROC CVPR IEEE, P886; Duda R.O., 1973, PATTERN CLASSIFICATI; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Grenander U, 1980, ABSTRACT INFERENCE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LeCun Y, 1994, P 12 ICPR JER, VII, P88, DOI 10.1109/ICPR.1994.576881; Li F, 2003, P IEEE INT C COMP VI, V2, P1134; Metzger W., 1936, GESETZE SEHENS; Ommer B, 2010, IEEE T PATTERN ANAL, V32, P501, DOI 10.1109/TPAMI.2009.22; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Vapnik V. N., 1995, NATURE STAT LEARNING; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	21	4	4	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	OCT 25	2011	108	43					17621	17625		10.1073/pnas.1109168108		5	Multidisciplinary Sciences	Science & Technology - Other Topics	839OU	WOS:000296378100021	22006295	
J	Liu, Y; Zhou, SS; Chen, QC				Liu, Yan; Zhou, Shusen; Chen, Qingcai			Discriminative deep belief networks for visual data classification	PATTERN RECOGNITION			English	Article						Semi-supervised learning; Discriminative deep belief networks; Deep learning; Visual data classification	NEURAL-NETWORKS; NEURONS; CORTEX	Visual data classification using insufficient labeled data is a well-known hard problem. Semi-supervise learning, which attempts to exploit the unlabeled data in additional to the labeled ones, has attracted much attention in recent years. This paper proposes a novel semi-supervised classifier called discriminative deep belief networks (DDBN). DDBN utilizes a new deep architecture to integrate the abstraction ability of deep belief nets (DBN) and discriminative ability of backpropagation strategy. For unsupervised learning, DDBN inherits the advantage of DBN, which preserves the information well from high-dimensional features space to low-dimensional embedding. For supervised learning, through a well designed objective function, the backpropagation strategy directly optimizes the classification results in training dataset by refining the parameter space. Moreover, we apply DDBN to visual data classification task and observe an important fact that the learning ability of deep architecture is seriously underrated in real-world applications, especially in visual data analysis. The comparative experiments on standard datasets of different types and different scales demonstrate that the proposed algorithm outperforms both representative semi-supervised classifiers and existing deep learning techniques. For visual dataset, we can further improve the DDBN performance with much larger and deeper architecture. (C) 2010 Elsevier Ltd. All rights reserved.	[Chen, Qingcai] Harbin Inst Technol, Shenzhen Grad Sch, Comp Sci & Technol Dept, Shenzhen, Peoples R China; [Liu, Yan; Zhou, Shusen] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China	Chen, QC (reprint author), Harbin Inst Technol, Shenzhen Grad Sch, Comp Sci & Technol Dept, Shenzhen, Peoples R China.	csyliu@comp.polyu.edu.hk; zhoushusen@hitsz.edu.cn; qingcai.chen@gmail.com			Hong Kong RGC [PolyU 5204/09E]; National Natural Science Foundation of China [60703015, 60973076]	The work is partly supported by Hong Kong RGC General Research Fund PolyU 5204/09E, National Natural Science Foundation of China (No. 60703015 and No. 60973076).	Adams R, 2009, ITI, P1; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2006, ADV NEURAL INFORM PR, P153; Bishop CM, 2006, PATTERN RECOGNITION; Blum A., 2001, P 18 INT C MACH LEAR, P19; Blum A., 1998, 11 ANN C COMP LEARN, P92; Chapelle O., 2006, SEMISUPERVISED LEARN; Chapelle O., 2005, INT WORKSH ART INT S, P57; Chen EK, 2008, INT CONF ACOUST SPEE, P829, DOI 10.1109/ICASSP.2008.4517738; Collobert R, 2006, J MACH LEARN RES, V7, P1687; Cottrell GW, 2006, SCIENCE, V313, P454, DOI 10.1126/science.1129813; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Horster E., 2008, P 16 ACM INT C MULT, P643, DOI 10.1145/1459359.1459449; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; LEE H, 2007, ADV NEURAL INFORM PR, P1416; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; LEUBA G, 1994, ANAT EMBRYOL, V190, P351; Li F., 2004, CVPR WORKSH; Mitchell T. M., 1997, MACHINE LEARNING; Mobahi H., 2009, INT C MACH LEARN, P737; PATEL A, 2009, INT JOINT C ART INT, P1193; Raina R., 2009, ICML 09, P873; Rosenberg C., 2005, 7 IEEE WORKSH APPL C, P29; Roux N. L., 2008, NEURAL COMPUT, V20, P1631; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R. R., 2007, P 11 INT C ART INT S; Salakhutdinov RR, 2008, P 25 INT C MACH LEAR, P872, DOI 10.1145/1390156.1390266; Schiller PH, 1996, BEHAV BRAIN RES, V76, P21, DOI 10.1016/0166-4328(95)00186-7; Sindhwani V, 2005, ICML 05, P824, DOI DOI 10.1145/1102351.1102455; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Vincent P., 2008, INT C MACH LEARN, P1096; Weston J., 2008, ICML 08, P1168; YU K, 2008, ADV NEURAL INFORM PR, P1889; Zhou Z. H., 2007, 22 AAAI C ART INT, P675; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529; Zhu X, 2007, 1530 TR U WISC MAD	40	4	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	OCT-NOV	2011	44	10-11			SI		2287	2296		10.1016/j.patcog.2010.12.012		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	793UI	WOS:000292849000007		
J	Zhu, L; Chen, YH; Yuille, A				Zhu, Long (Leo); Chen, Yuanhao; Yuille, Alan			Recursive Compositional Models for Vision: Description and Review of Recent Work	JOURNAL OF MATHEMATICAL IMAGING AND VISION			English	Review						Computer vision; Image processing; Machine learning; Object detection; Image parsing	PICTORIAL STRUCTURES; OBJECT RECOGNITION; SEGMENTATION; EXTRACTION; TEXTURE	This paper describes and reviews a class of hierarchical probabilistic models of images and objects. Visual structures are represented in a hierarchical form where complex structures are composed of more elementary structures following a design principle of recursive composition. Probabilities are defined over these structures which exploit properties of the hierarchy-e.g. long range spatial relationships can be represented by local potentials at the upper levels of the hierarchy. The compositional nature of this representation enables efficient learning and inference algorithms. In particular, parts can be shared between different object models. Overall the architecture of Recursive Compositional Models (RCMs) provides a balance between statistical and computational complexity. The goal of this paper is to describe the basic ideas and common themes of RCMs, to illustrate their success on a range of vision tasks, and to gives pointers to the literature. In particular, we show that RCMs generally give state of the art results when applied to a range of different vision tasks and evaluated on the leading benchmarked datasets.	[Chen, Yuanhao; Yuille, Alan] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Zhu, Long (Leo)] NYU, Dept Comp Sci, New York, NY USA; [Yuille, Alan] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Yuille, A (reprint author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	yuille@stat.ucla.edu			NSF [IIS-0917141, 0613563]; AFOSR [FA9550-08-1-0489]; Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]; NGA [NEGI-1582-04-0004]; MURI [N00014-06-1-0734]	We acknowledge funding from NSF with grants IIS-0917141 and 0613563 and from AFOSR FA9550-08-1-0489. This research was also supported by the WCU (World Class University) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008). For the work in Sect. 5.5 the first author was partially supported by NGA NEGI-1582-04-0004 and MURI Grant N00014-06-1-0734. We thank George Papandreou for giving feedback on a draft of the paper and for drawing some of the figures. We thank our collaborators in our referenced paper for their many contributions.	Ahuja N., 2007, ICCV; Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Altun Y., 2003, ICML, P3; Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Blake A, 1987, VISUAL RECONSTRUCTIO; Borenstein E., 2006, CVPR, V1, P969; BORENSTEIN E, 2002, ECCV, V2, P109; Boykov Yuri, 2001, IEEE T PATTERN ANAL, V26, P359; Chen H., 2006, CVPR, V1, P943; CHEN Y, 2010, P 12 EUR C COMP VIS; Chen Y., 2007, NIPS; Chui H., 2000, CVPR, P2044; Collins M, 2002, EMNLP 02, P1; Cootes T.F., 1998, LECT NOTES COMPUTER, V1407, P484; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; Coughlan JM, 2002, NEURAL COMPUT, V14, P1929, DOI 10.1162/089976602760128072; Cour T., 2007, CVPR; DESAI C, 2009, P INT C COMP VIS; FELZENSWALB P, 2004, EFFICIENT BELIEF PRO; FELZENSZWALB PF, 2009, PAMI; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R., 2005, CVPR, V1, P380; Fidler S., 2007, CVPR; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; GEIGER D, 1995, OCCLUSIONS BINOCULAR; GEIGER D, 1991, COMMON FRAMEWORK IMA; GEMAN S, 1984, STOCHASTIC RELAXATIO; Grenander U., 1976, LECT PATTERN THEORY, V1; Grenander U., 1978, LECT PATTERN THEORY, V2; HE C, 2008, THESIS UCLA; He X., 2004, CVPR, V2, pII; Heckerman D., 1999, TUTORIAL LEARNING BA, P301; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jensen FV, 1990, COMPUTATIONAL STATIS, V4, P269; JIN Y, 2006, CVPR, V2, P2145; Kokkinos I., 2009, CVPR; Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946; KUMAR MP, 2005, CVPR, V1, P18; Kumar S., 2003, ICCV, P1150; Lee H., 2009, INT C MACH LEARN ICM; Leibe B., 2004, ECCV 04 WORKSH STAT, P17; LEVIN A, 2006, EUR C COMP VIS, V4, P581; Li H, 2005, J COMPUT SCI TECHNOL, V20, P849, DOI 10.1007/s11390-005-0849-8; MAGEE DR, 2002, IMAGE VISION COMPUT, V20, P2002; Manning C. D., 1999, FDN STAT NATURAL LAN; Mori G., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Pearl J, 1988, PROBABILISTIC REASON; Ranzato M., 2007, NIPS; Ren X., 2005, NIPS; Riesenhuber M, 2000, LECT NOTES COMPUT SC, V1811, P1; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Russell B. C., 2008, IJCV; Russell S, 2003, ARTIFICIAL INTELLIGE; Serre T, 2005, COMP VIS PATT REC 20, V2, P994; SHARON E, 2000, CVPR, P1070; Shotton J., 2006, ECCV, P1; Srinivasan P., 2007, CVPR; TASKAR B, 2004, EMNLP; TASKAR B., 2003, NIPS; TENENBAUM J, 2007, IPAM SUMMER SCH MATH; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Thorpe SJ, 2001, SCIENCE, V291, P260, DOI 10.1126/science.1058249; Tsochantaridis I., 2004, ICML; TU Z, 2004, ECCV, V3, P195; TU Z, 2008, P IEEE COMP SOC C CO; Tu Z., 2003, ICCV, P18; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657; VANGOOL EML, 2007, PASCAL VISUAL OBJECT; Verbeek J., 2007, CVPR; Viola P., 2001, INT J COMPUTER VISIO; Willsky AS, 2002, P IEEE, V90, P1396, DOI 10.1109/JPROC.2002.800717; Winn J, 2005, IEEE I CONF COMP VIS, P756; WU S, 2010, NIPS; WU YN, 2007, P INT C COMP VIS; Yu C.N.J., 2009, INT C MACH LEARN ICM; Yuille A., 2001, NIPS, P1033; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhu L., 2010, CVPR; Zhu L., 2008, ADV NEURAL INFORM PR; Zhu L., 2008, CVPR; ZHU L, 2009, T PATTERN ANAL MACHI; ZHU L, 2005, NIPS; ZHU L, 2008, P IEEE COMP SOC C CO; ZHU L, 2008, P 10 EUR C COMP VIS; ZHU S, 2006, STOCHASTIC GRAMMAR I, V2, P259; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	89	4	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-9907			J MATH IMAGING VIS	J. Math. Imaging Vis.	SEP	2011	41	1-2					122	146		10.1007/s10851-011-0282-2		25	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	800AE	WOS:000293328100008		
J	Hermundstad, AM; Brown, KS; Bassett, DS; Carlson, JM				Hermundstad, Ann M.; Brown, Kevin S.; Bassett, Danielle S.; Carlson, Jean M.			Learning, Memory, and the Role of Neural Network Architecture	PLOS COMPUTATIONAL BIOLOGY			English	Article							HUMAN BRAIN; FUNCTIONAL CONNECTIVITY; NERVOUS-SYSTEM; NEURONS; MODELS; ORGANIZATION; RECOGNITION; INTEGRATION; PLASTICITY; NEOCORTEX	The performance of information processing systems, from artificial neural networks to natural neuronal ensembles, depends heavily on the underlying system architecture. In this study, we compare the performance of parallel and layered network architectures during sequential tasks that require both acquisition and retention of information, thereby identifying tradeoffs between learning and memory processes. During the task of supervised, sequential function approximation, networks produce and adapt representations of external information. Performance is evaluated by statistically analyzing the error in these representations while varying the initial network state, the structure of the external information, and the time given to learn the information. We link performance to complexity in network architecture by characterizing local error landscape curvature. We find that variations in error landscape structure give rise to tradeoffs in performance; these include the ability of the network to maximize accuracy versus minimize inaccuracy and produce specific versus generalizable representations of information. Parallel networks generate smooth error landscapes with deep, narrow minima, enabling them to find highly specific representations given sufficient time. While accurate, however, these representations are difficult to generalize. In contrast, layered networks generate rough error landscapes with a variety of local minima, allowing them to quickly find coarse representations. Although less accurate, these representations are easily adaptable. The presence of measurable performance tradeoffs in both layered and parallel networks has implications for understanding the behavior of a wide variety of natural and artificial learning systems.	[Hermundstad, Ann M.; Brown, Kevin S.; Bassett, Danielle S.; Carlson, Jean M.] Univ Calif Santa Barbara, Dept Phys, Santa Barbara, CA 93106 USA	Hermundstad, AM (reprint author), Univ Calif Santa Barbara, Dept Phys, Santa Barbara, CA 93106 USA.	ann@physics.ucsb.edu			David and Lucile Packard Foundation; U.S. Army Research Office [W911NF-09-D-0001]	This work was supported by the David and Lucile Packard Foundation and the Institute for Collaborative Biotechnologies through contract no. W911NF-09-D-0001 from the U.S. Army Research Office. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453; Achard S, 2006, J NEUROSCI, V26, P63, DOI 10.1523/JNEUROSCI.3874-05.2006; Allred RP, 2008, J NEUROSCI METH, V170, P229, DOI 10.1016/j.jneumeth.2008.01.015; Alstott J, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000408; Atallah HE, 2004, NEUROBIOL LEARN MEM, V82, P253, DOI 10.1016/j.nlm.2004.06.004; ATENCIO CA, 2007, PLOS ONE, V5, pE9521; AUER P, 1996, ADV NEURAL INFORM PR, V8, P315; Bakoglu H., 1990, CIRCUITS INTERCONNEC; Bassett DS, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000748; Bassett DS, 2011, NEUROIMAGE, V54, P1262, DOI 10.1016/j.neuroimage.2010.09.006; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bettencourt LMA, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.021915; Bogacz Rafal, 2010, Trends Neurosci, V33, P10, DOI 10.1016/j.tins.2009.09.002; Bousquet O, 2004, LECT NOTES ARTIF INT, V3176, P169; Brown KS, 2004, PHYS BIOL, V1, P184, DOI 10.1088/1478-3967/1/3/006; Brown KS, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.021904; Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; Bush P, 1996, J COMPUT NEUROSCI, V3, P91, DOI 10.1007/BF00160806; Chen ZJ, 2008, CEREB CORTEX, V18, P2374, DOI 10.1093/cercor/bhn003; Chittka L, 2009, CURR BIOL, V19, pR995, DOI 10.1016/j.cub.2009.08.023; COHEN IL, 1994, BIOL PSYCHIAT, V36, P5, DOI 10.1016/0006-3223(94)90057-4; Cucker F., 2001, B AM MATH SOC, V39, P1, DOI 10.1090/S0273-0979-01-00923-5; Dominguez D, 2009, PHYS REV E, V79, DOI 10.1103/PhysRevE.79.021909; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; ERSOY OK, 1995, IEEE T NEURAL NETWOR, V6, P1037, DOI 10.1109/72.410348; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fletcher R., 1987, PRACTICAL METHODS OP; FLETCHER R, 1964, COMPUT J, V7, P149, DOI 10.1093/comjnl/7.2.149; Fu HC, 2001, IEEE T NEURAL NETWOR, V12, P250, DOI 10.1109/72.914522; Fukumizu K, 2000, NEURAL NETWORKS, V13, P317, DOI 10.1016/S0893-6080(00)00009-5; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; Gaiteri C, 2011, FRONT COMPUT NEUROSC, V5, P1, DOI 10.3389/fncom.2011.00010; Galushkin A. I., 2007, NEURAL NETWORKS THEO; Hagmann P, 2008, PLOS BIOL, V6, P1479, DOI 10.1371/journal.pbio.0060159; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Honey CJ, 2008, HUM BRAIN MAPP, V29, P802, DOI 10.1002/hbm.20579; Honey CJ, 2009, P NATL ACAD SCI USA, V106, P2035, DOI 10.1073/pnas.0811168106; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kaiser M, 2010, FRONT NEUROINFORMATI, V4, P1; Kenet T, 2003, NATURE, V425, P954, DOI 10.1038/nature02078; Kim H, 2010, NEUROIMAGE, V50, P1648, DOI 10.1016/j.neuroimage.2010.01.051; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Marder E, 1996, P NATL ACAD SCI USA, V93, P13481, DOI 10.1073/pnas.93.24.13481; Markram H, 1996, NATURE, V382, P807, DOI 10.1038/382807a0; McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109; McIntosh AR, 2003, J NEUROSCI, V23, P6520; Mello P. A., 2004, QUANTUM TRANSPORT ME; Meunier D, 2009, NEUROIMAGE, V44, P715, DOI 10.1016/j.neuroimage.2008.09.062; Meunier D., 2010, FRONT NEUROSCI, V4; Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701; Oshima H, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036114; Polak E., 1969, REV FRANCAISE INFORM, V16, P35; POWELL MJD, 1986, SIAM REV, V28, P487, DOI 10.1137/1028154; RATCLIFF R, 1990, PSYCHOL REV, V97, P285, DOI 10.1037//0033-295X.97.2.285; Reid AT, 2009, NEUROIMAGE, V47, P611, DOI 10.1016/j.neuroimage.2009.04.061; Ress D, 2007, NEUROIMAGE, V34, P74, DOI 10.1016/j.neuroimage.2006.08.020; Robins A, 1998, CONNECT SCI, V10, P121; Robins A., 1995, Connection Science, V7, DOI 10.1080/09540099550039318; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Roelfsema PR, 1997, NATURE, V385, P157, DOI 10.1038/385157a0; Rojas R, 1996, NEURAL NETWORKS SYST; RUBINOV M, 2009, BMC NEUROSCI, V10, P1; Sanchez-Vives MV, 2000, NAT NEUROSCI, V3, P1027; Scholz J, 2009, NAT NEUROSCI, V12, P1370, DOI 10.1038/nn.2412; Sharkey N. E., 1995, Connection Science, V7, DOI 10.1080/09540099550039264; TONONI G, 1994, P NATL ACAD SCI USA, V91, P5033, DOI 10.1073/pnas.91.11.5033; Tort ABL, 2009, P NATL ACAD SCI USA, V106, P20942, DOI 10.1073/pnas.0911331106; Turrigiano GG, 2004, NAT REV NEUROSCI, V5, P97, DOI 10.1038/nrn1327; Turrigiano GG, 1998, NATURE, V391, P892, DOI 10.1038/36103; van Veen V, 2008, J COGNITIVE NEUROSCI, V20, P1952, DOI 10.1162/jocn.2008.20146; Vogels TP, 2005, J NEUROSCI, V25, P10786, DOI 10.1523/JNEUROSCI.3508-05.2005; Xu TH, 2009, NATURE, V462, P915, DOI 10.1038/nature08389; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7	74	4	4	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	185 BERRY ST, STE 1300, SAN FRANCISCO, CA 94107 USA	1553-734X			PLOS COMPUT BIOL	PLoS Comput. Biol.	JUN	2011	7	6							e1002063	10.1371/journal.pcbi.1002063		12	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	787MW	WOS:000292381900010	21738455	
J	Rifai, S; Mesnil, G; Vincent, P; Muller, X; Bengio, Y; Dauphin, Y; Glorot, X		Gunopulos, D; Hofmann, T; Malerba, D; Vazirgiannis, M		Rifai, Salah; Mesnil, Gregoire; Vincent, Pascal; Muller, Xavier; Bengio, Yoshua; Dauphin, Yann; Glorot, Xavier			Higher Order Contractive Auto-Encoder	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 05-09, 2011	Athens, GREECE	Google, Pascal2 Network, Xerox, Yahoo Labs, COST-MOVE Act (Knowledge Discovery Movin, Objects), Rapid-I, FP7-MODAP Project (Mobil, Data Min, & Privacy), Athena RIC/Inst Management Informat Syst (IMIS), Hellen Artificial Intelligence Soc (EETN), Marathon Data Syst (MDS), Transinsight, Springer, SONY, UNESCO Privacy Chair, Univ Studi Bari Aldo Moro, Athens Univ Econ & Business, Dept Informat, Univ Ioannina, Dept Comp Sci, Natl & Kapodistrian Univ Athens, Univ Piraeus, Dept Informat, Univ Athens, Dept Informat & Telecommunicat, Google Inc, Univ degli Studi Bari Aldo Moro, Dipartimento Informatica		Unsupervised feature learning; deep learning; manifold	LEARNING ALGORITHM	We propose a novel regularizer when training an auto-encoder for unsupervised feature extraction. We explicitly encourage the latent representation to contract the input space by regularizing the norm of the Jacobian (analytically) and the Hessian (stochastically) of the encoder's output with respect to its input, at the training points. While the penalty on the Jacobian's norm ensures robustness to tiny corruption of samples in the input space, constraining the norm of the Hessian extends this robustness when moving further away from the sample. From a manifold learning perspective, balancing this regularization with the auto-encoder's reconstruction objective yields a representation that varies most when moving along the data manifold in input space, and is most insensitive in directions orthogonal to the manifold. The second order regularization, using the Hessian, penalizes curvature, and thus favors smooth manifold. We show that our proposed technique, while remaining computationally efficient, yields representations that are significantly better suited for initializing deep architectures than previously proposed approaches, beating state-of-the-art performance on a number of datasets.	[Rifai, Salah; Mesnil, Gregoire; Vincent, Pascal; Muller, Xavier; Bengio, Yoshua; Dauphin, Yann; Glorot, Xavier] Univ Montreal, Dept IRO, Montreal, PQ H2C 3J7, Canada	Rifai, S (reprint author), Univ Montreal, Dept IRO, Montreal, PQ H2C 3J7, Canada.						Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2006, NIPS, V18; Bengio Y., 2007, NIPS, V19, P153; BISHOP CM, 1993, IEEE T NEURAL NETWOR, V4, P882, DOI 10.1109/72.248466; Chapelle O., 2006, SEMISUPERVISED LEARN; Cho Y., 2010, NIPS 2009 NIPS FDN, P342; Coates A., 2011, P 13 INT C ART INT S; Goodfellow I., 2009, NIPS 2009, P646; Hastie T., 1990, GEN ADDITIVE MODELS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kavukcuoglu K., 2009, P COMP VIS PATT REC; Larochelle H., 2007, ICML 2007, V227, P473; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2007, NIPS 2006, P1137; Ranzato M., 2007, NIPS 2006; Rifai S., 2011, P 28 INT C MACH LEAR; Rifai S., 2011, 1360 U MONTR DEP INF; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Simard P., 1992, NIPS 1991, P895; Swersky K., 2011, P ICML 2011; Tikhonov AN, 1977, SOLUTIONS ILL POSED; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, INT C MACH LEARN, P1096; Wahba G., 1990, CBMS NSF REGIONAL C, V59; Weston J., 2008, ICML 08, P1168	25	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-23783-6	LECT NOTES ARTIF INT			2011	6912						645	660				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEH08	WOS:000316551300041		
J	Schmidt, EM; Kim, YE			IEEE	Schmidt, Erik M.; Kim, Youngmoo E.			LEARNING EMOTION-BASED ACOUSTIC FEATURES WITH DEEP BELIEF NETWORKS	2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA)			English	Proceedings Paper	IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	OCT 16-19, 2011	New Paltz, NY	IEEE, IEEE Signal Proc Soc		Emotion recognition; feature learning; regression; deep belief networks		The medium of music has evolved specifically for the expression of emotions, and it is natural for us to organize music in terms of its emotional associations. But while such organization is a natural process for humans, quantifying it empirically proves to be a very difficult task, and as such no dominant feature representation for music emotion recognition has yet emerged. Much of the difficulty in developing emotion-based features is the ambiguity of the ground-truth. Even using the smallest time window, opinions on the emotion are bound to vary and reflect some disagreement between listeners. In previous work, we have modeled human response labels to music in the arousal-valence (A-V) representation of affect as a time-varying, stochastic distribution. Current methods for automatic detection of emotion in music seek performance increases by combining several feature domains (e. g. loudness, timbre, harmony, rhythm). Such work has focused largely in dimensionality reduction for minor classification performance gains, but has provided little insight into the relationship between audio and emotional associations. In this new work we seek to employ regression-based deep belief networks to learn features directly from magnitude spectra. While the system is applied to the specific problem of music emotion recognition, it could be easily applied to any regression-based audio feature learning problem.	[Schmidt, Erik M.; Kim, Youngmoo E.] Drexel Univ, Mus & Entertainment Technol Lab MET Lab, Philadelphia, PA 19104 USA	Schmidt, EM (reprint author), Drexel Univ, Mus & Entertainment Technol Lab MET Lab, Philadelphia, PA 19104 USA.	eschmidt@drexel.edu; ykim@drexel.edu					Bengio Y., 2007, NIPS; Hamel P., 2010, ISMIR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; KIM YE, 2010, ISMIR UTR NETH; KIM YE, 2008, ISMIR PHIL PA SEPT; Lee H, 2009, NIPS; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Schmidt E. M., 2010, P 9 IEEE INT C MACH; SCHMIDT EM, 2010, ACM MIR; SCHMIDT EM, 2010, ISMIR UTR NETH; Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485	12	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4577-0693-6				2011							65	68				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BYE98	WOS:000298302900017		
S	Tang, J; Zhang, J		Theeramunkong, T; Kijsirikul, B; Cercone, N; Ho, TB		Tang, Jie; Zhang, Jing			A Discriminative Approach to Topic-Based Citation Recommendation	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th Pacific-Asia Conference on Knowledge and Data Mining	APR 27-30, 2009	Bangkok, THAILAND	Sirindhorn Int Inst Technol, Thammasat Univ, Chulalonkorn Univ, Asian Inst Technol, Natl Elect & Comp Technol Ctr, Thailand Convent & Exhibit Bureau, AF Off Sci Res, Asian Off Aerosp Res & Dev				In this paper, we present a study of a novel problem, i.e. topic-based citation recommendation, which involves recommending papers to be referred to. Traditionally, this problem is usually treated as an engineering issue and dealt with using heuristics. This paper gives a formalization of topic-based citation recommendation and proposes a discriminative approach to this problem. Specifically, it proposes a two-layer Restricted Boltzmann Machine model, called RBM-CS, which can discover topic distributions of paper content and citation relationship simultaneously. Experimental results demonstrate that RBM-CS can significantly outperform baseline methods for citation recommendation.	[Tang, Jie; Zhang, Jing] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Tang, J (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	jietang@tsinghua.edu.cn; zhangjing@keg.cs.tsinghua.edu.cn					Buckley C., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1008992.1009000; Craswell N., 2005, TREC 2005 C NOT, P199; GARFIELD E, 1972, SCIENCE, V178, P471, DOI 10.1126/science.178.4060.471; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; KESSLER MM, 1963, AM DOC, V14, P10, DOI 10.1002/asi.5090140103; McNee S. M., 2002, CSCW 02, P116, DOI DOI 10.1145/587078.587096; SMOLENSKY P, 1986, INFORM PROCESSING DY, P194; Strohman Trevor, 2007, P 30 ANN INT ACM SIG, P705, DOI DOI 10.1145/1277741.1277868; Tang J., 2008, KDD 08, P990, DOI DOI 10.1145/1401890.1402008; WELLING M, 2005, P 17 NEUR INF PROC S; Xing E. P., 2005, P 21 C UNC ART INT U, P633	12	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01306-5	LECT NOTES ARTIF INT			2009	5476						572	579				8	Computer Science, Artificial Intelligence	Computer Science	BKN07	WOS:000268632000052		
J	Cortes-Ciriano, I; Ul Ain, Q; Subramanian, V; Lenselink, EB; Mendez-Lucio, O; IJzerman, AP; Wohlfahrt, G; Prusis, P; Malliavin, TE; van Westen, GJP; Bender, A				Cortes-Ciriano, Isidro; Ul Ain, Qurrat; Subramanian, Vigneshwari; Lenselink, Eelke B.; Mendez-Lucio, Oscar; IJzerman, Adriaan P.; Wohlfahrt, Gerd; Prusis, Peteris; Malliavin, Therese E.; van Westen, Gerard J. P.; Bender, Andreas			Polypharmacology modelling using proteochemometrics (PCM): recent methodological developments, applications to target families, and future prospects	MEDCHEMCOMM			English	Review							PROTEIN-COUPLED RECEPTORS; SUPPORT VECTOR MACHINES; LIGAND-BINDING-SITES; KINASE INHIBITOR SELECTIVITY; LARGE-SCALE PREDICTION; ACID DESCRIPTOR SETS; DRUG DISCOVERY; MOLECULAR DESCRIPTORS; RANDOM FOREST; FUNCTIONAL CLASSIFICATION	Proteochemometric (PCM) modelling is a computational method to model the bioactivity of multiple ligands against multiple related protein targets simultaneously. Hence it has been found to be particularly useful when exploring the selectivity and promiscuity of ligands on different proteins. In this review, we will firstly provide a brief introduction to the main concepts of PCM for readers new to the field. The next part focuses on recent technical advances, including the application of support vector machines (SVMs) using different kernel functions, random forests, Gaussian processes and collaborative filtering. The subsequent section will then describe some novel practical applications of PCM in the medicinal chemistry field, including studies on GPCRs, kinases, viral proteins (e.g. from HIV) and epigenetic targets such as histone deacetylases. Finally, we will conclude by summarizing novel developments in PCM, which we expect to gain further importance in the future. These developments include adding three-dimensional protein target information, application of PCM to the prediction of binding energies, and application of the concept in the fields of pharmacogenomics and toxicogenomics. This review is an update to a related publication in 2011 and it mainly focuses on developments in the field since then.	[Cortes-Ciriano, Isidro; Malliavin, Therese E.] Inst Pasteur, Unite Bioinformat Struct, F-75724 Paris, France; [Cortes-Ciriano, Isidro; Malliavin, Therese E.] CNRS, UMR 3825, Struct Biol & Chem Dept, F-75724 Paris, France; [Ul Ain, Qurrat; Mendez-Lucio, Oscar; Bender, Andreas] Univ Cambridge, Dept Chem, Unilever Ctr Mol Informat, Cambridge CB2 1EW, England; [Subramanian, Vigneshwari] Univ Helsinki, Fac Pharm, FIN-00014 Helsinki, Finland; [Lenselink, Eelke B.; IJzerman, Adriaan P.] Leiden Acad Ctr Drug Res, Div Med Chem, NL-2333 CC Leiden, Netherlands; [Wohlfahrt, Gerd; Prusis, Peteris] Orion Pharma, Comp Aided Drug Design, FIN-02101 Espoo, Finland; [van Westen, Gerard J. P.] European Bioinformat Inst, European Mol Biol Lab, Cambridge CB10 1SD, England	Malliavin, TE (reprint author), Inst Pasteur, Unite Bioinformat Struct, 25-28 Rue Dr Roux, F-75724 Paris, France.		Bender, Andreas/C-6942-2009; van Westen, Gerard/D-7432-2011	Bender, Andreas/0000-0002-6683-7546; van Westen, Gerard/0000-0003-0717-1817	Pasteur-Paris International PhD Program; Institut Pasteur Paris; Islamic Development Bank; Cambridge Commonwealth Trust; Finnish National Doctoral Program; Helsinki University Research Foundation; Dutch Research Council (NWO) [714.011.001]; CONACyT [217442/312933]; Cambridge Overseas Trust; CNRS; EMBL (EIPOD); Marie Curie (COFUND); Unilever; European Research Commission [ERC-2013-StG 336159 MIXTURE]	ICC thanks the Pasteur-Paris International PhD Program and Institut Pasteur Paris for funding. QUA thanks the Islamic Development Bank and Cambridge Commonwealth Trust for funding. VS thanks the Finnish National Doctoral Program in Informational and Structural Biology for organizing graduate studies and Helsinki University Research Foundation for funding. API and EBL thank the Dutch Research Council (NWO) for financial support (NWO-TOP #714.011.001). OML is grateful to CONACyT (no. 217442/312933) and Cambridge Overseas Trust for funding. TM thanks the Institut Pasteur Paris and CNRS for funding. GJPvW thanks EMBL (EIPOD) and Marie Curie (COFUND) for funding. AB thanks Unilever and the European Research Commission (Starting Grant ERC-2013-StG 336159 MIXTURE) for funding.	Ain QU, 2014, INTEGR BIOL-UK, V6, P1023, DOI 10.1039/c4ib00175c; Akella LB, 2010, CURR OPIN CHEM BIOL, V14, P325, DOI 10.1016/j.cbpa.2010.03.017; Andersson CD, 2010, PROTEINS, V78, P1408, DOI 10.1002/prot.22655; Andersson CR, 2011, CURR TOP MED CHEM, V11, P1978; Andrea Mauri V. C., 2006, MATCH-COMMUN MATH CO, V56, P237; [Anonymous], 2013, QIKPROP VERSION 3 8; Arrowsmith CH, 2012, NAT REV DRUG DISCOV, V11, P384, DOI 10.1038/nrd3674; Artemenko N, 2008, J CHEM INF MODEL, V48, P569, DOI 10.1021/ci700224e; Bahar I, 2007, CURR OPIN STRUC BIOL, V17, P633, DOI 10.1016/j.sbi.2007.09.011; Ballester PJ, 2010, BIOINFORMATICS, V26, P1169, DOI 10.1093/bioinformatics/btq112; O'Boyle NM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-33; Barretina J, 2012, NATURE, V483, P603, DOI 10.1038/nature11003; Basu A, 2013, CELL, V154, P1151, DOI 10.1016/j.cell.2013.08.003; Bellucci M, 2011, NAT METHODS, V8, P444, DOI 10.1038/nmeth.1611; Bender A, 2007, CHEMMEDCHEM, V2, P861, DOI 10.1002/cmdc.200700026; Bender A, 2004, ORG BIOMOL CHEM, V2, P3204, DOI 10.1039/b409813g; Ben-Hur A, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000173; Bianchi Matt T., 2010, BMC Pharmacology, V10, P3, DOI 10.1186/1471-2210-10-3; Bieler M, 2012, DRUG DEVELOP RES, V73, P357, DOI 10.1002/ddr.21026; Bock J. R., 2005, J CHEM INF MODEL, V45, P1114; Borisy AA, 2003, P NATL ACAD SCI USA, V100, P7977, DOI 10.1073/pnas.1337088100; Bosnic Z, 2009, INTELL DATA ANAL, V13, P385, DOI 10.3233/IDA-2009-0371; Bredel M, 2004, NAT REV GENET, V5, P262, DOI 10.1038/nrg1317; Breese JS, 1998, EMPIRICAL ANAL PREDI, P43; Brown J. B., 2014, J COMPUT AID MOL DES, P1; Bruce CL, 2007, J CHEM INF MODEL, V47, P219, DOI [10.1021/ci600332j, 10.1021/ci600322j]; Cao DS, 2013, ANAL CHIM ACTA, V792, P10, DOI 10.1016/j.aca.2013.07.003; Cao DS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057680; Cao DS, 2013, BIOINFORMATICS, V29, P960, DOI 10.1093/bioinformatics/btt072; Cheng FX, 2011, J CHEM INF MODEL, V51, P996, DOI 10.1021/ci200028n; Cheng TJ, 2012, AAPS J, V14, P133, DOI 10.1208/s12248-012-9322-0; Chung CW, 2011, J BIOMOL SCREEN, V16, P1170, DOI 10.1177/1087057111421372; Cohen P, 2002, NAT REV DRUG DISCOV, V1, P309, DOI 10.1038/nrd773; Collobert R, 2006, J MACH LEARN RES, V7, P1687; Cortes-Ciriano I., IN PRESS; Cortes-Ciriano I., 2014, IN PRESS; Cortes-Ciriano I, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/1758-2946-6-35; Cowan-Jacob SW, 2007, ACTA CRYSTALLOGR D, V63, P80, DOI 10.1107/S0907444906047287; Cruciani G., 2000, J MOL STRUC-THEOCHEM, V503, P17; Dakshanamurthy S, 2012, J MED CHEM, V55, P6832, DOI 10.1021/jm300576q; Das S, 2010, J CHEM INF MODEL, V50, P298, DOI 10.1021/ci9004139; Davis MI, 2011, NAT BIOTECHNOL, V29, P1046, DOI 10.1038/nbt.1990; De Bruyn T, 2013, MOL PHARMACOL, V83, P1257, DOI 10.1124/mol.112.084152; Delmore JE, 2011, CELL, V146, P903, DOI 10.1016/j.cell.2011.08.017; Deng W, 2004, J CHEM INF COMP SCI, V44, P699, DOI 10.1021/ci034246; Desaphy J, 2012, J CHEM INF MODEL, V52, P2287, DOI 10.1021/ci300184x; Dimitrov I, 2010, EUR J MED CHEM, V45, P236, DOI 10.1016/j.ejmech.2009.09.049; Doddareddy MR, 2009, STAT ANAL DATA MININ, V2, P149; Doherty KM, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-477; Eklund M, 2014, J CHEM INF MODEL, V54, P837, DOI 10.1021/ci400573c; Eklund M, 2012, MOL INFORM, V31, P173, DOI 10.1002/minf.201100142; Erhan D, 2006, J CHEM INF MODEL, V46, P626, DOI 10.1021/ci050367t; Fernandez M, 2010, J CHEM INF MODEL, V50, P1179, DOI 10.1021/ci1000532; Floyd SR, 2013, NATURE, V498, P246, DOI 10.1038/nature12147; Frimurer TM, 2005, BIOORG MED CHEM LETT, V15, P3707, DOI 10.1016/j.bmcl.2005.05.102; Gao J, 2013, GENE, V518, P124, DOI 10.1016/j.gene.2012.11.061; Gao J, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-186; Garnett MJ, 2012, NATURE, V483, P570, DOI 10.1038/nature11005; Gaulton A, 2012, NUCLEIC ACIDS RES, V40, pD1100, DOI 10.1093/nar/gkr777; Geppert H, 2009, J CHEM INF MODEL, V49, P767, DOI 10.1021/ci900004a; Gibbons DL, 2012, CANCER-AM CANCER SOC, V118, P293, DOI 10.1002/cncr.26225; Glen RC, 2006, IDRUGS, V9, P199; Glinca S, 2013, J CHEM INF MODEL, V53, P2082, DOI 10.1021/ci300550a; Gloriam DE, 2009, J MED CHEM, V52, P4429, DOI 10.1021/jm900319e; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; Gottlieb A, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.26; Gregori-Puigjane E, 2008, COMB CHEM HIGH T SCR, V11, P669, DOI 10.2174/138620708785739952; Gregori-Puigjane E, 2008, CURR OPIN CHEM BIOL, V12, P359, DOI 10.1016/j.cbpa.2008.03.015; Gruetter M, 2012, NATURE, V491, P40, DOI 10.1038/491040d; Gujral TS, 2014, P NATL ACAD SCI USA, V111, P5048, DOI 10.1073/pnas.1403080111; Haibe-Kains B, 2013, NATURE, V504, P389, DOI 10.1038/nature12831; Hamosh A, 2002, NUCLEIC ACIDS RES, V30, P52, DOI 10.1093/nar/30.1.52; Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472; Heijne WHM, 2005, EXPERT REV PROTEOMIC, V2, P767, DOI 10.1586/14789450.2.5.767; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong HX, 2008, J CHEM INF MODEL, V48, P1337, DOI 10.1021/ci800038f; Hoppe C, 2006, J MOL GRAPH MODEL, V24, P328, DOI 10.1016/j.jmgm.2005.09.013; Horuk R, 2009, NAT REV DRUG DISCOV, V8, P23, DOI 10.1038/nrd2734; Huang Q, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041698; Huang ZM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039917; Jacob L, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-363; Jacoby E., 2013, COMPUTATIONAL CHEMOG; Jarl M. L., 2004, CHEMOGENOMICS DRUG D; Junaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014353; Kagan L, 2010, PHARM RES-DORDR, V27, P920, DOI 10.1007/s11095-010-0098-6; Kalinina OV, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002043; Kalliokoski T, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061007; Karaman MW, 2008, NAT BIOTECHNOL, V26, P127, DOI 10.1038/nbt1358; Karelson M., 2000, MOL DESCRIPTORS QSAR, V1; Keiser MJ, 2007, NAT BIOTECHNOL, V25, P197, DOI 10.1038/nbt1284; Kellenberger E, 2006, J CHEM INF MODEL, V46, P717, DOI 10.1021/ci050372x; Khan S. R., 2013, DRUG DISCOV TODAY, V19, P562; Kinnings SL, 2009, J CHEM INF MODEL, V49, P318, DOI 10.1021/ci800289y; Kuhn D, 2007, CHEMMEDCHEM, V2, P1432, DOI 10.1002/cmdc.200700075; Knapp S., 2013, CHEMMEDCHEM, P1885; Kondratovich E, 2013, MOL INFORM, V32, P261, DOI 10.1002/minf.201200135; Kontijevskis A, 2009, BIOORGAN MED CHEM, V17, P5229, DOI 10.1016/j.bmc.2009.05.045; Koonin EV, 2005, ANNU REV GENET, V39, P309, DOI 10.1146/annurev.genet.39.073003.114725; Koppisetty CAK, 2013, J CHEM INF MODEL, V53, P2559, DOI 10.1021/ci400321r; Kramer C, 2011, J CHEM INF MODEL, V51, P707, DOI 10.1021/ci100473d; Kramer C, 2012, J MED CHEM, V55, P5165, DOI 10.1021/jm300131x; Kramer C, 2011, J CHEM INF MODEL, V51, P2139, DOI 10.1021/ci200030h; Kramer C, 2012, CURR TOP MED CHEM, V12, P1896; Krstajic D, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/1758-2946-6-10; Kruger FA, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002333; Kubinyi H, 1998, J MED CHEM, V41, P2553, DOI 10.1021/jm970732a; Kufareva I, 2012, NUCLEIC ACIDS RES, V40, pD535, DOI 10.1093/nar/gkr825; Laine E, 2010, P NATL ACAD SCI USA, V107, P11277, DOI 10.1073/pnas.0914611107; Lapins M, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-181; Lapins M, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-339; Lapins M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066566; Lapinsh M, 2002, MOL PHARMACOL, V61, P1465, DOI 10.1124/mol.61.6.1465; Lapinsh M, 2005, MOL PHARMACOL, V67, P50, DOI 10.1124/mol.104.002857; Lapinsh M, 2001, BBA-GEN SUBJECTS, V1525, P180, DOI 10.1016/S0304-4165(00)00187-2; Li QL, 2009, BIOINFORMATICS, V25, P3310, DOI 10.1093/bioinformatics/btp589; Lin H, 2013, NAT METHODS, V10, P140, DOI [10.1038/nmeth.2324, 10.1038/NMETH.2324]; Liu TQ, 2007, NUCLEIC ACIDS RES, V35, pD198, DOI 10.1093/nar/gkl999; Liu Zhi-Ping, 2008, Int J Bioinform Res Appl, V4, P445, DOI 10.1504/IJBRA.2008.021179; Lounkine E, 2012, NATURE, V486, P361, DOI 10.1038/nature11159; Lowe R, 2011, J CHEM INF MODEL, V51, P1539, DOI 10.1021/ci200128w; Manning G, 2002, SCIENCE, V298, P1912, DOI 10.1126/science.1075762; Marc R. W., 2001, J MACH LEARN RES, P299; McHale CM, 2010, MUTAT RES-REV MUTAT, V705, P172, DOI 10.1016/j.mrrev.2010.04.001; Meinshausen N, 2006, J MACH LEARN RES, V7, P983; Melnikova I, 2004, NAT REV DRUG DISCOV, V3, P993, DOI 10.1038/nrd1582; Menden MP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061318; Mendez-Lucio O., 2013, UNPUB; Mendez-Lucio O., UNPUB; Meslamani J, 2011, J CHEM INF MODEL, V51, P1593, DOI 10.1021/ci200166t; Mestres J, 2009, MOL BIOSYST, V5, P1051, DOI 10.1039/b905821b; Mestres J, 2008, NAT BIOTECHNOL, V26, P983, DOI 10.1038/nbt0908-983; Metz JT, 2011, NAT CHEM BIOL, V7, P200, DOI [10.1038/nchembio.530, 10.1038/NCHEMBIO.530]; Mysinger MM, 2012, J MED CHEM, V55, P6582, DOI 10.1021/jm300687e; Netzeva TI, 2005, ATLA-ALTERN LAB ANIM, V33, P155; Niijima S, 2012, J CHEM INF MODEL, V52, P901, DOI 10.1021/ci200607f; Ning X, 2009, J CHEM INF MODEL, V49, P2444, DOI 10.1021/ci900182q; Nisius B, 2012, J CHEM INF MODEL, V52, P2339, DOI [10.1021/ci300244yi, 10.1021/ci300244y]; Norinder U, 2014, J CHEM INF MODEL, V54, P1596, DOI 10.1021/ci5001168; Norman TC, 2011, SCI TRANSL MED, V3, DOI 10.1126/scitranslmed.3002678; Okuno Y, 2006, NUCLEIC ACIDS RES, V34, pD673, DOI 10.1093/nar/gkj028; Overington JP, 2006, NAT REV DRUG DISCOV, V5, P993, DOI 10.1038/nrd2199; Pahikkala T., 2014, BRIEF BIOINFORM, DOI [10.1093/bib/bbu010, DOI 10.1093/BIB/BBU010]; Paolini GV, 2006, NAT BIOTECHNOL, V24, P805, DOI 10.1038/nbt1228; Paricharak S., IN PRESS; Park Y, 2012, NAT METHODS, V9, P1134, DOI 10.1038/nmeth.2259; Pastor M, 2000, J MED CHEM, V43, P3233, DOI 10.1021/jm000941m; Paul SM, 2010, NAT REV DRUG DISCOV, V9, P203, DOI 10.1038/nrd3078; Prinjha RK, 2012, TRENDS PHARMACOL SCI, V33, P146, DOI 10.1016/j.tips.2011.12.002; Prusis P, 2013, BIOCHEM BIOPH RES CO, V434, P767, DOI 10.1016/j.bbrc.2013.03.139; Prusis P, 2008, BIOORGAN MED CHEM, V16, P9369, DOI 10.1016/j.bmc.2008.08.081; Prusis P, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-167; Prusis P, 2001, BBA-PROTEIN STRUCT M, V1544, P350, DOI 10.1016/S0167-4838(00)00249-1; Rao HB, 2011, NUCLEIC ACIDS RES, V39, pW385, DOI 10.1093/nar/gkr284; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Reutlinger M, 2014, ANGEW CHEM INT EDIT, V53, P582, DOI 10.1002/anie.201307786; Rhee SY, 2003, NUCLEIC ACIDS RES, V31, P298, DOI 10.1093/nar/gkg100; Robinson DD, 2010, CHEMMEDCHEM, V5, P618, DOI 10.1002/cmdc.200900501; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; Rognan D, 2007, BRIT J PHARMACOL, V152, P38, DOI 10.1038/sj.bjp.0707307; Sandberg M, 1998, J MED CHEM, V41, P2481, DOI 10.1021/jm9700575; Schlkopf B., 2001, LEARNING KERNELS SUP; Scholkopf B., 2004, KERNEL METHODS COMPU; Schwaighofer A, 2007, J CHEM INF MODEL, V47, P407, DOI 10.1021/ci600205g; Shandar A. S. Ahmad, 2003, GENOME INFORM, V14, P537; Sheinerman FB, 2005, J MOL BIOL, V352, P1134, DOI 10.1016/j.jmb.2005.07.074; Shen JW, 2007, P NATL ACAD SCI USA, V104, P4337, DOI 10.1073/pnas.0607879104; Sheridan RP, 2012, J CHEM INF MODEL, V52, P814, DOI 10.1021/ci300004n; Sheridan RP, 2013, J CHEM INF MODEL, V53, P2837, DOI 10.1021/ci400482e; Shiraishi A, 2013, J CHEM INF MODEL, V53, P1253, DOI 10.1021/ci300515z; Shoemaker RH, 2006, NAT REV CANCER, V6, P813, DOI 10.1038/nrc1951; Shoshan M. C., 2004, CANC THER, V2, P297; Sievers F, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.75; Sippl MJ, 2008, BIOINFORMATICS, V24, P426, DOI 10.1093/bioinformatics/btm622; Sotriffer CA, 2008, PROTEINS, V73, P395, DOI 10.1002/prot.22058; Spjuth O, 2011, BIOINFORMATICS, V27, P1719, DOI 10.1093/bioinformatics/btr192; Stolovitzky G, 2007, ANN NY ACAD SCI, V1115, P1, DOI 10.1196/annals.1407.021; Strombergsson H, 2006, PROTEINS, V65, P568, DOI 10.1002/prot.21163; Subrarnanian V, 2013, J CHEM INF MODEL, V53, P3021, DOI 10.1021/ci400369z; Surgand JS, 2006, PROTEINS, V62, P509, DOI 10.1002/prot.20768; Suter L, 2004, CHEM BIOL, V11, P161, DOI 10.1016/j.chembiol.2004.02.003; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tang J, 2014, J CHEM INF MODEL, V54, P735, DOI 10.1021/ci400709d; Tetko IV, 2006, DRUG DISCOV TODAY, V11, P700, DOI 10.1016/j.drudis.2006.06.013; Tiikkainen P, 2013, J CHEM INF MODEL, V53, P2499, DOI 10.1021/ci400099q; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Todeschini R., 2008, HDB MOL DESCRIPTORS; Tomic S, 2000, J MED CHEM, V43, P1780, DOI 10.1021/jm9911175; Ustun B, 2006, CHEMOMETR INTELL LAB, V81, P29, DOI 10.1016/j.chemolab.2005.09.003; van Westen GJP, 2013, J CHEMINFORMATICS, V5, DOI 10.1186/1758-2946-5-41; van Westen GJP, 2013, J CHEMINFORMATICS, V5, DOI 10.1186/1758-2946-5-42; van Westen GJP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027518; van Westen GJP, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002899; van der Horst E, 2011, CURR TOP MED CHEM, V11, P1964; van Westen GJP, 2011, MEDCHEMCOMM, V2, P16, DOI 10.1039/c0md00165a; van Westen GJP, 2012, J MED CHEM, V55, P7010, DOI 10.1021/jm3003069; van Westen GJP, 2013, NAT METHODS, V10, P116, DOI 10.1038/nmeth.2339; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91; Vidler LR, 2012, J MED CHEM, V55, P7346, DOI 10.1021/jm300346w; Vieth M, 2005, DRUG DISCOV TODAY, V10, P839, DOI 10.1016/S1359-6446(05)03477-X; Vita R, 2010, NUCLEIC ACIDS RES, V38, pD854, DOI 10.1093/nar/gkp1004; Vroling B, 2011, NUCLEIC ACIDS RES, V39, pD309, DOI 10.1093/nar/gkq1009; Wang J., 2007, J CONT MAT; Wang RX, 2004, J MED CHEM, V47, P2977, DOI 10.1021/jm0305801; Wang Y., 2012, NUCLEIC ACIDS RES, V40, P400; Wassermann AM, 2009, J CHEM INF MODEL, V49, P2155, DOI 10.1021/ci9002624; Weill N, 2011, CURR TOP MED CHEM, V11, P1944; Weill N, 2009, J CHEM INF MODEL, V49, P1049, DOI 10.1021/ci800447g; Weill N, 2010, J CHEM INF MODEL, V50, P123, DOI 10.1021/ci900349y; Weill N, 2011, MOL INFORM, V30, P521, DOI 10.1002/minf.201100026; Weinstein JN, 2013, NATURE, V504, P381, DOI 10.1038/nature12839; Willett P, 2009, ANNU REV INFORM SCI, V43, P3; Willighagen E. L., 2011, J BIOMED SEMANT S1, V2, P1; Wu DF, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-212; Yabuuchi H, 2011, MOL SYST BIOL, V7, DOI 10.1038/msb.2011.5; Yang WJ, 2013, NUCLEIC ACIDS RES, V41, pD955, DOI 10.1093/nar/gks1111; Yap CW, 2011, J COMPUT CHEM, V32, P1466, DOI 10.1002/jcc.21707; Yun CH, 2007, CANCER CELL, V11, P217, DOI 10.1016/j.ccr.2006.12.017; Yuriev E, 2013, J MOL RECOGNIT, V26, P215, DOI 10.1002/jmr.2266; Yuriev E, 2011, J MOL RECOGNIT, V24, P149, DOI 10.1002/jmr.1077; Zhang D., 2012, ADME ENABLING TECHNO; Zhang GT, 2013, J MED CHEM, V56, P9251, DOI 10.1021/jm401334s; Zhang SX, 2006, J MED CHEM, V49, P2713, DOI 10.1021/jm050260x; ZILLIACUS J, 1992, J BIOL CHEM, V267, P24941	223	3	3	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	2040-2503	2040-2511		MEDCHEMCOMM	MedChemComm		2015	6	1					24	50		10.1039/c4md00216d		27	Biochemistry & Molecular Biology; Chemistry, Medicinal	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	CB5XD	WOS:000349700400003		
J	Khaligh-Razavi, SM; Kriegeskorte, N				Khaligh-Razavi, Seyed-Mahdi; Kriegeskorte, Nikolaus			Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation	PLOS COMPUTATIONAL BIOLOGY			English	Article							INFERIOR TEMPORAL CORTEX; INVARIANT OBJECT REPRESENTATION; HUMAN BRAIN ACTIVITY; RECEPTIVE-FIELDS; VISUAL-CORTEX; FUNCTIONAL ARCHITECTURE; INFEROTEMPORAL CORTEX; NEURONAL POPULATION; HIERARCHICAL-MODELS; RECOGNITION	Inferior temporal (IT) cortex in human and nonhuman primates serves visual object recognition. Computational object-vision models, although continually improving, do not yet reach human performance. It is unclear to what extent the internal representations of computational models can explain the IT representation. Here we investigate a wide range of computational model representations (37 in total), testing their categorization performance and their ability to account for the IT representational geometry. The models include well-known neuroscientific object-recognition models (e. g. HMAX, VisNet) along with several models from computer vision (e. g. SIFT, GIST, self-similarity features, and a deep convolutional neural network). We compared the representational dissimilarity matrices (RDMs) of the model representations with the RDMs obtained from human IT (measured with fMRI) and monkey IT (measured with cell recording) for the same set of stimuli (not used in training the models). Better performing models were more similar to IT in that they showed greater clustering of representational patterns by category. In addition, better performing models also more strongly resembled IT in terms of their within-category representational dissimilarities. Representational geometries were significantly correlated between IT and many of the models. However, the categorical clustering observed in IT was largely unexplained by the unsupervised models. The deep convolutional network, which was trained by supervision with over a million categorylabeled images, reached the highest categorization performance and also best explained IT, although it did not fully explain the IT data. Combining the features of this model with appropriate weights and adding linear combinations that maximize the margin between animate and inanimate objects and between faces and other objects yielded a representation that fully explained our IT data. Overall, our results suggest that explaining IT requires computational features trained through supervised learning to emphasize the behaviorally important categorical divisions prominently reflected in IT.	[Khaligh-Razavi, Seyed-Mahdi; Kriegeskorte, Nikolaus] MRC, Cognit & Brain Sci Unit, Cambridge, England	Khaligh-Razavi, SM (reprint author), MRC, Cognit & Brain Sci Unit, Cambridge, England.	Seyed.KalighRazavi@mrc-cbu.cam.ac.uk; nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk			Cambridge Overseas Trust; Yousef Jameel Scholarship; Medical Research Council of the UK [MC-A060-5PR20]; European Research Council [ERC-2010-StG 261352]	This work was funded by Cambridge Overseas Trust and Yousef Jameel Scholarship to SMKR; and by the Medical Research Council of the UK (programme MC-A060-5PR20) and a European Research Council Starting Grant (ERC-2010-StG 261352) to NK. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Baldassi C, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003167; Bell AH, 2009, J NEUROPHYSIOL, V101, P688, DOI 10.1152/jn.90657.2008; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Berg AC, 2005, PROC CVPR IEEE, P26; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI DOI 10.1145/1282280.1282340; Cadieu CF, 2014, ARXIV14063284CSQBIO; Carlson T, 2013, J VISION, V13, DOI 10.1167/13.10.1; Carlson TA, 2014, J COGNITIVE NEUROSCI, V26, P120, DOI 10.1162/jocn_a_00458; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Chatfield Ken, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, DOI 10.1109/ICCVW.2009.5457691; Cichy RM, 2014, NAT NEUROSCI, V17, P455, DOI 10.1038/nn.3635; Clarke A, 2014, J NEUROSCI, V34, P4766, DOI 10.1523/JNEUROSCI.2828-13.2014; Connolly AC, 2012, J NEUROSCI, V32, P2608, DOI 10.1523/JNEUROSCI.5547-11.2012; Deng J, 2009, PROC CVPR IEEE, P248; Deselaers T, 2010, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2010.5539775; DESIMONE R, 1984, J NEUROSCI, V4, P2051; Devereux BJ, 2013, J NEUROSCI, V33, P18906, DOI 10.1523/JNEUROSCI.3809-13.2013; DiCarlo JJ, 2007, TRENDS COGN SCI, V11, P333, DOI 10.1016/j.tics.2007.06.010; Donahue Jeff, 2013, ARXIV13101531; Dumoulin SO, 2008, NEUROIMAGE, V39, P647, DOI 10.1016/j.neuroimage.2007.09.034; Efron B, 1986, STAT SCI, V1, P54, DOI DOI 10.1214/SS/1177013815; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Ganguli S, 2012, ANNU REV NEUROSCI, V35, P485, DOI 10.1146/annurev-neuro-062111-150410; Ghodrati M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032357; Ghodrati M, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00074; GROSS CG, 1994, CEREB CORTEX, V4, P455, DOI 10.1093/cercor/4.5.455; Grossberg S, 1988, ADAPTIVE PATTERN CLA, P243; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hung CP, 2005, SCIENCE, V310, P863, DOI 10.1126/science.1117593; Huth AG, 2012, NEURON, V76, P1210, DOI 10.1016/j.neuron.2012.10.014; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Johnson W, 1984, CONT MATH, V26, P1; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Khaligh-Razavi S-M, 2014, ARXIV14072776CSQBIO; Khaligh-Razavi S-M, 2013, OBJECT VISION MODELS; Kiani R, 2007, J NEUROPHYSIOL, V97, P4296, DOI 10.1152/jn.00024.2007; Konkle T, 2012, NEURON, V74, P1114, DOI 10.1016/j.neuron.2012.04.036; Kriegeskorte Nikolaus, 2009, Front Neurosci, V3, P363, DOI 10.3389/neuro.01.035.2009; Kriegeskorte N, 2013, TRENDS COGN SCI, V17, P401, DOI 10.1016/j.tics.2013.06.007; Kriegeskorte Nikolaus, 2008, Front Syst Neurosci, V2, P4, DOI 10.3389/neuro.06.004.2008; Kriegeskorte N, 2011, NEUROIMAGE, V56, P411, DOI 10.1016/j.neuroimage.2011.01.061; Kriegeskorte N, 2008, NEURON, V60, P1126, DOI 10.1016/j.neuron.2008.10.043; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Krizhevsky A., 2012, IMAGENET CLASSIFICAT; Lawson C. L., 1974, SOLVING LEAST SQUARE, V161; Lazebnik S., 2006, CVPR, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; LeCun Y, 1995, HDB BRAIN THEORY NEU, P3361; Leeds DD, 2013, J VISION, V13, DOI 10.1167/13.13.25; Li N, 2012, J NEUROSCI, V32, P6611, DOI 10.1523/JNEUROSCI.3786-11.2012; Li N, 2010, NEURON, V67, P1062, DOI 10.1016/j.neuron.2010.08.029; Lowe DG, 1999, OBJECT RECOGNITION L, P1150; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahon BZ, 2007, NEURON, V55, P507, DOI 10.1016/j.neuron.2007.07.011; Majaj N, 2012, UNIFIED NEUROANAL PO; Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876; Mur M, 2012, J NEUROSCI, V32, P8649, DOI 10.1523/JNEUROSCI.2334-11.2012; Mur M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00128; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Naselaris T, J PHYSL PARIS; Nili H, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003553; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ojala T, 2001, ADV PATT REC ICAPR 2, V2001, P399; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oliva A, 2006, PROGR BRAIN RES, P2006; PietikAoinen M, 2010, SCHOLARPEDIA, V5, DOI [10.4249/scholarpedia.9775, DOI 10.4249/SCH0LARPEDIA.9775]; Pillow JW, 2008, NATURE, V454, P995, DOI 10.1038/nature07140; Rajaei K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038478; Riesenhuber M, 2007, NEURON, V55, P341, DOI 10.1016/j.neuron.2007.07.017; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rust NC, 2010, J NEUROSCI, V30, P12978, DOI 10.1523/JNEUROSCI.0179-10.2010; Sato T, 2009, CEREB CORTEX, V19, P1870, DOI 10.1093/cercor/bhn218; Schultz J, 2005, NEURON, V45, P625, DOI 10.1016/j.neuron.2004.12.052; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Sountsov P, 2011, FRONT COMPUT NEUROSC, V5, DOI 10.3389/fncom.2011.00053; Stork D. G., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), DOI 10.1109/IJCNN.1989.118705; Stringer SM, 2007, NETWORK-COMP NEURAL, V18, P161, DOI 10.1080/09548980701556055; Tanaka K, 1996, ANNU REV NEUROSCI, V19, P109, DOI 10.1146/annurev.ne.19.030196.000545; Tromans JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025616; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Wallis G, 1997, PROG NEUROBIOL, V51, P167, DOI 10.1016/S0301-0082(96)00054-8; Yamins DL, 2013, ADV NEURAL INFORM PR, V26, P3093; Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111; Zabbah S, 2014, VISION RES, V101, P82, DOI 10.1016/j.visres.2014.05.006; Zeiler MD, 2013, ARXIV13112901CS; Zhang H., 2006, COMPUTER VISION PATT, V2, P2126, DOI 10.1109/CVPR.2006.301; Zoccolan D, 2007, J NEUROSCI, V27, P12292, DOI 10.1523/JNEUROSCI.1897-07.2007	91	3	3	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-734X	1553-7358		PLOS COMPUT BIOL	PLoS Comput. Biol.	NOV	2014	10	11							e1003915	10.1371/journal.pcbi.1003915		29	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	AU2NE	WOS:000345454400012	25375136	
J	Hinton, G				Hinton, Geoffrey			Where Do Features Come From?	COGNITIVE SCIENCE			English	Article						Backpropagation; Boltzmann machines; Learning features; Learning graphical models; Distributed representations; Deep learning; Variational learning; Contrastive divergence	NEURAL-NETWORKS; BELIEF NETWORKS; EM ALGORITHM; TIME; REPRESENTATIONS; RECOGNITION; MODELS; SLEEP	It is possible to learn multiple layers of non-linear features by backpropagating error derivatives through a feedforward neural network. This is a very effective learning procedure when there is a huge amount of labeled training data, but for many learning tasks very few labeled examples are available. In an effort to overcome the need for labeled data, several different generative models were developed that learned interesting features by modeling the higher order statistical structure of a set of input vectors. One of these generative models, the restricted Boltzmann machine ( RBM), has no connections between its hidden units and this makes perceptual inference and learning much simpler. More significantly, after a layer of hidden features has been learned, the activities of these features can be used as training data for another RBM. By applying this idea recursively, it is possible to learn a deep hierarchy of progressively more complicated features without requiring any labeled data. This deep hierarchy can then be treated as a feedforward neural network which can be discriminatively fine-tuned using backpropagation. Using a stack of RBMs to initialize the weights of a feedforward neural network allows backpropagation to work effectively in much deeper networks and it leads to much better generalization. A stack of RBMs can also be used to initialize a deep Boltzmann machine that has many hidden layers. Combining this initialization method with a new method for fine-tuning the weights finally leads to the first efficient way of training Boltzmann machines with many hidden layers and millions of weights.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Hinton, G (reprint author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	hinton@cs.toronto.edu					Baum L. E., 1972, INEQUALITIES, V3, P1; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Buesing L, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002211; CRICK F, 1983, NATURE, V304, P111, DOI 10.1038/304111a0; Dahl G. E., 2010, ADV NEURAL INFORM PR, V24, P469; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Erhan D, 2010, J MACH LEARN RES, V11, P625; Friston KJ, 2006, J PHYSIOL-PARIS, V100, P70, DOI 10.1016/j.jphysparis.2006.10.001; HECHTNIELSEN R, 1995, SCIENCE, V269, P1860, DOI 10.1126/science.269.5232.1860; Heckerman D., 1986, UNCERTAINTY ARTIFICI, P167; Hinton G. E., 1994, ADV NEURAL INFORMATI, V6, P3; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1986, PARALLEL DISTRIBUTED, V1, P282; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; Jordan M. I., 1999, LEARNING GRAPHICAL M, P105; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1985, P COGNITIVA, V85, P599; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; MacKay D., 2003, INFORM THEORY INFERE; Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213; Martens J, 2010, P 27 INT C MACH LEAR, P735; MCCLELLAND JL, 1981, PSYCHOL REV, V88, P375, DOI 10.1037/0033-295X.88.5.375; Nair V., 2010, P 27 INT C MACH LEAR, P807; Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355; Neal R. M, 1994, THESIS U TORONTO; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; OKEEFE J, 1993, HIPPOCAMPUS, V3, P317, DOI 10.1002/hipo.450030307; Pearl J., 1988, PROBABILISTIC INFERE; Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; REICHERT DP, 2010, ADV NEURAL INFORM PR, V23, P2020; Rifai S., 2011, P 28 INT C MACH LEAR, P833; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P77; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Taylor GW, 2011, J MACH LEARN RES, V12, P1025; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Vincent P, 2010, J MACH LEARN RES, V11, P3371; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Werbos P., 1974, THESIS HARVARD U; Yao X, 1999, P IEEE, V87, P1423	56	3	3	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0364-0213	1551-6709		COGNITIVE SCI	Cogn. Sci.	AUG	2014	38	6			SI		1078	1101		10.1111/cogs.12049		24	Psychology, Experimental	Psychology	AN4KQ	WOS:000340557000003	23800216	
J	Zhao, XJ; Wang, YX; Wang, DL				Zhao, Xiaojia; Wang, Yuxuan; Wang, DeLiang			Robust Speaker Identification in Noisy and Reverberant Conditions	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep neural network; ideal binary mask; noise; reverberation; robust speaker identification	AUTOMATIC SPEECH RECOGNITION; INTELLIGIBILITY; VERIFICATION; SEGREGATION; LISTENERS; FEATURES; SEPARATION; ALGORITHM; MODELS	Robustness of speaker recognition systems is crucial for real-world applications, which typically contain both additive noise and room reverberation. However, the combined effects of additive noise and convolutive reverberation have been rarely studied in speaker identification (SID). This paper addresses this issue in two phases. We first remove background noise through binary masking using a deep neural network classifier. Then we perform robust SID with speaker models trained in selected reverberant conditions, on the basis of bounded marginalization and direct masking. Evaluation results show that the proposed system substantially improves SID performance over related systems in a wide range of reverberation time and signal-to-noise ratios.	[Zhao, Xiaojia; Wang, Yuxuan; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA	Zhao, XJ (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	zhaox@cse.ohio-state.edu; wangyuxu@cse.ohio-state.edu			Air Force Office of Scientific Research (AFOSR) [FA9550-12-1-0130]	This work was supported in part by the Air Force Office of Scientific Research (AFOSR) under Grant FA9550-12-1-0130. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Rodrigo Capobianco Guido.	AKULA A, 2009, P IEEE DSP WORKSH, P37; ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599; Borgstrom BJ, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4065; Cooke M, 2001, SPEECH COMMUN, V34, P267, DOI 10.1016/S0167-6393(00)00034-0; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P90, DOI 10.1109/TASL.2009.2023679; Garcia-Romero D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4257; Gelbart D., 2004, SOME RESOURCES NOISE; Gonzalez-Rodriguez J., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607859; Habets EAP, ROOM IMPULSE RESPONS; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; Hartmann W, 2013, IEEE T AUDIO SPEECH, V21, P1993, DOI 10.1109/TASL.2013.2263802; Hazrati O, 2012, INT J AUDIOL, V51, P437, DOI 10.3109/14992027.2012.658972; Hendriks RC, 2010, INT CONF ACOUST SPEE, P4266, DOI 10.1109/ICASSP.2010.5495680; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Jin ZZ, 2011, IEEE T AUDIO SPEECH, V19, P2328, DOI 10.1109/TASL.2011.2134086; Kenny P., 2005, CRIM060813; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Krishnamoorthy P, 2009, SADHANA-ACAD P ENG S, V34, P729, DOI 10.1007/s12046-009-0043-8; Kuttruff H., 2000, ROOM ACOUSTICS; Li YP, 2009, SPEECH COMMUN, V51, P230, DOI 10.1016/j.specom.2008.09.001; Mandel MI, 2010, IEEE T AUDIO SPEECH, V18, P1872, DOI 10.1109/TASL.2010.2052252; May T, 2012, IEEE T AUDIO SPEECH, V20, P2016, DOI 10.1109/TASL.2012.2193391; May T, 2012, IEEE T AUDIO SPEECH, V20, P108, DOI 10.1109/TASL.2011.2158309; Ming J, 2007, IEEE T AUDIO SPEECH, V15, P1711, DOI 10.1109/TASL.2007.899278; NABELEK AK, 1974, J SPEECH HEAR RES, V17, P724; Narayanan A, 2013, J ACOUST SOC AM, V133, P3083, DOI 10.1121/1.4798661; Peer I, 2008, INT CONF ACOUST SPEE, P4829, DOI 10.1109/ICASSP.2008.4518738; REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Roman N, 2011, J ACOUST SOC AM, V130, P2153, DOI 10.1121/1.3631668; Sadjadi SO, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4225; Shao Y, 2007, INT CONF ACOUST SPEE, P277; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wang D., 2006, COMPUTATIONAL AUDITO; Wang Lan, 2009, Proceedings of the 2009 WRI World Congress on Software Engineering. WCSE 2009, DOI 10.1109/WCSE.2009.368; Wang N, 2011, IEEE T AUDIO SPEECH, V19, P196, DOI 10.1109/TASL.2010.2045800; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; Ward W.C., 1994, P WALL CLEM SAB CENT, P343; Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803	43	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	APR	2014	22	4					836	845		10.1109/TASLP.2014.2308398		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AD5YZ	WOS:000333330900007		
J	Fischer, A; Igel, C				Fischer, Asja; Igel, Christian			Training restricted Boltzmann machines: An introduction	PATTERN RECOGNITION			English	Article						Restricted Boltzmann machines; Markov random fields; Markov chains; Gibbs sampling; Neural networks; Contrastive divergence learning; Parallel tempering	CONTRASTIVE DIVERGENCE; LEARNING ALGORITHM; RECOGNITION; NETWORKS	Restricted Boltzmann machines (RBMs) are probabilistic graphical models that can be interpreted as stochastic neural networks. They have attracted much attention as building blocks for the multi-layer learning systems called deep belief networks, and variants and extensions of RBMs have found application in a wide range of pattern recognition tasks. This tutorial introduces RBMs from the viewpoint of Markov random fields, starting with the required concepts of undirected graphical models. Different learning algorithms for RBMs, including contrastive divergence learning and parallel tempering, are discussed. As sampling from RBMs, and therefore also most of their learning algorithms, are based on Markov chain Monte Carlo (MCMC) methods, an introduction to Markov chains and MCMC techniques is provided. Experiments demonstrate relevant aspects of RBM training. (C) 2013 Elsevier Ltd. All rights reserved.	[Fischer, Asja] Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany; [Fischer, Asja; Igel, Christian] Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark	Igel, C (reprint author), Univ Copenhagen, Dept Comp Sci, Univ Pk 1, DK-2100 Copenhagen, Denmark.	asja.fischer@rub.de; c.igel@ieee.org	Igel, Christian/B-4091-2009	Igel, Christian/0000-0003-2868-0856	German Federal Ministry of Education and Research within the National Network Computational Neuroscience [01GQ0951]; European Commission through project AKMI [PCIG10-GA-2011-303655]	This article extends our tutorial in Ref. [16]. We thank Jan Melchior for providing Fig. 11. This work has been supported by the German Federal Ministry of Education and Research within the National Network Computational Neuroscience under Grant number 01GQ0951 (Bernstein Fokus "Learning behavioral models: From human experiment to technical assistance"). Christian Igel gratefully acknowledges support from the European Commission through project AKMI (PCIG10-GA-2011-303655).	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2009, FDN TRENDS MACHINE L, V21, P1601; Bishop CM, 2006, PATTERN RECOGNITION; Brakel P., 2012, EUR S ART NEUR NETW, P287; Bremaud P., 1999, MARKOV CHAINS GIBBS; Brugge K., 2013, MACH LEARN, DOI [10.1007/s10994-013-5390-3, DOI 10.1007/S10994-013-5390-3)]; Carreira-Perpi nan M.A., 2005, 10 WORKSH ART INT ST, P59; Cho K., 2010, P INT JOINT C NEUR N, P3246; Desjardins G., 2010, J MACHINE LEARNING R, V9, P145; Desjardins G., 2010, NIPS 2010 WORKSH DEE; Fischer A., 2012, LNCS, V7441, P14; Fischer A, 2011, NEURAL COMPUT, V23, P664, DOI 10.1162/NECO_a_00085; Fischer A., 2011, 5 WORKSH THEOR RAND; Fischer A, 2010, LECT NOTES COMPUT SC, V6354, P208, DOI 10.1007/978-3-642-15825-4_26; Gehler P. V., 2006, P 23 INT C MACH LEAR, P337, DOI 10.1145/1143844.1143887; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hinton G., 2010, 2010003 UTML TR DEP; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton G.E., 2007, SCHOLARPEDIA, V2, P1668; Hinton G.E., 1986, PARALLEL DISTRIBUTED, V1, P282; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Igel C, 2008, J MACH LEARN RES, V9, P993; Kivinen J., 2012, JMLR W CP AISTATS, V22, P638; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Krause O., 2013, JMLR W CP ICML 2013, V28, P419; Larochelle H., 2008, ICML, P536; Lauritzen S.L., 1996, GRAPHICAL MODELS; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Le Roux N, 2011, NEURAL COMPUT, V23, P593, DOI 10.1162/NECO_a_00086; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lingenheil N.M., 2009, CHEM PHYS LETT, V478, P80; MacKay D.J.C., 2001, FAILURES ONE STEP LE; MacKay D.J.C., 2002, INFORM THEORY INFERE; Mnih V., 2011, P 27 C UNC ART INT U, P514; Mohamed AR, 2010, INT CONF ACOUST SPEE, P4354, DOI 10.1109/ICASSP.2010.5495651; Montufar G, 2011, NEURAL COMPUT, V23, P1306, DOI 10.1162/NECO_a_00113; Neal R., 1993, CRGTR931 U TOR DEP C; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, P1607; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, P1598; Salakhutdinov R., 2009, JMLR W CP AISTATS 20, V5, P448; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Swersky K., 2010, INF THEOR APPL WORKS, P1; Tang YC, 2012, PROC CVPR IEEE, P2264; Taylor G., 2007, ADV NEURAL INFORM PR, P1345; Taylor G., 2009, P 26 ANN INT C MACH, P1025; Tieleman T., 2008, INT C MACH LEARN ICM, P1064; Tieleman T., 2009, INT C MACH LEARN ICM, P1033; Wang N., 2012, EUR S ART NEUR NETW, P287; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Welling M., 2007, SCHOLARPEDIA, V2, P3879; Xing E.P., 2005, P 21 C UNC ART INT U; Younes L., 1991, LECT NOTES MONOGRAPH; Yuille A.L., 2005, ADV NEURAL PROCESSIN, V17, P1593	61	3	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	JAN	2014	47	1			SI		25	39		10.1016/j.patcog.2013.05.025		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	251BT	WOS:000326903500003		
J	Ranzato, M; Mnih, V; Susskind, JM; Hinton, GE				Ranzato, Marc'Aurelio; Mnih, Volodymyr; Susskind, Joshua M.; Hinton, Geoffrey E.			Modeling Natural Images Using Gated MRFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gated MRF; natural images; deep learning; unsupervised learning; density estimation; energy-based model; Boltzmann machine; factored 3-way model; generative model; object recognition; denoising; facial expression recognition	COMPONENT ANALYSIS; DEEP BELIEF; RECOGNITION; REPRESENTATION; GAUSSIANS; FEATURES; OBJECT; SCENE; SET	This paper describes a Markov Random Field for real-valued image modeling that has two sets of latent variables. One set is used to gate the interactions between all pairs of pixels, while the second set determines the mean intensities of each pixel. This is a powerful model with a conditional distribution over the input that is Gaussian, with both mean and covariance determined by the configuration of latent variables, which is unlike previous models that were restricted to using Gaussians with either a fixed mean or a diagonal covariance matrix. Thanks to the increased flexibility, this gated MRF can generate more realistic samples after training on an unconstrained distribution of high-resolution natural images. Furthermore, the latent variables of the model can be inferred efficiently and can be used as very effective descriptors in recognition tasks. Both generation and discrimination drastically improve as layers of binary latent variables are added to the model, yielding a hierarchical model called a Deep Belief Network.	[Ranzato, Marc'Aurelio; Mnih, Volodymyr; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Susskind, Joshua M.] Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA	Ranzato, M (reprint author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	ranzato@cs.toronto.edu			NSERC; CFI; CIFAR	The research was funded by Grants from NSERC, CFI, and CIFAR and by gifts from Google and Microsoft.	Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Bosch A., 2007, P 6 ACM INT C IM VID; Buades A., 2005, P IEEE COMP VIS PATT; Carreira-Perpignan M. A., 2005, P INT WORKSH ART INT; Ciresan D., 2011, P 28 INT JOINT C ART; Dabov K., 2006, P SPIE ELECT IMAGING; Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177; Dalai N., 2005, P IEEE C COMP VIS PA; Deng J., 2009, P IEEE C COMP VIS PA; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Elad Michael, 2006, P IEEE C COMP VIS PA; Fasel B., 2005, COMPUTER VISION IMAG, V98, P182; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gregor K., 2010, ARXIV10060448; Hinton G., 2011, P INT C ART NEUR NET; Hinton G., 2001, P 17 C UNC ART INT; Hinton G., 1999, P 9 INT C ART NEUR N; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Jarrett K., 2009, P IEEE INT C COMP VI; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Koster U., 2007, P 17 INT C ART NEUR; Krizhevsky A., 2009, THESIS U TORONTO; Lazebnik S., 2006, P IEEE C COMP VIS PA; Le Q., 2010, P ADV NEUR INF PROC; Le Q.V., 2011, P IEEE C COMP VIS PA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P INT C MACH LEARN; Littlewort G., 2004, P IEEE C COMP VIS PA, V5, P80; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MacKay D., 1999, MAXIMUM LIKELIHOOD C; Mairal J., 2009, P IEEE INT C COMP VI; Memisevic R., 2009, NEURAL COMPUT, V22, P1473; Murray I., 2009, P ADV NEUR INF PROC; Neal R. M., 1996, BAYESIAN LEARNING NE; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osindero S., 2008, P ADV NEUR INF PROC; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Raina R, 2007, P INT C MACH LEARN; Ranzato M., 2007, P IEEE C COMP VIS PA; Ranzato M., 2009, THESIS; Ranzato M., 2010, P C ART INT STAT; Ranzato M., 2010, P ADV NEUR INF PROC; Ranzato M., 2010, P IEEE C COMP VIS PA; Ranzato M.A., 2011, P IEEE C COMP VIS PA; Roth S., 2005, P IEEE C COMP VIS PA; Schmidt U., 2010, P IEEE C COMP VIS PA; Sejnowski T., 1986, P AIP C NEUR NETW CO; Simoncelli EP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P431, DOI 10.1016/B978-012119792-6/50089-9; Susskind J. M., 2010, TECHNICAL REPORT; Taylor G., 2007, P ADV NEUR INF PROC; Teh Y. W., 2003, J MACHINE LEARNING R, V4, P1235, DOI 10.1162/jmlr.2003.4.7-8.1235; Theis L, 2011, J MACH LEARN RES, V12, P3071; Tieleman T., 2009, P INT C MACH LEARN; Tieleman T., 2008, P INT C MACH LEARN; Tipping ME, 1999, J ROY STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vincent P., 2008, P INT C MACH LEARN; Wainwright M., 2000, P ADV NEUR INF PROC; Weiss Y., 2007, P IEEE C COMP VIS PA; Welling M., 2003, P ADV NEUR INF PROC; Welling M., 2002, P INT C ART NEUR NET; Welling M., 2005, P ADV NEUR INF PROC; Williams CKI, 2002, NEURAL COMPUT, V14, P1169, DOI 10.1162/089976602753633439; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Young G., 1940, PSYCHOMETRIKA, V6, P49; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236; Zontak M., 2011, P IEEE C COMP VIS PA	71	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2206	2222		10.1109/TPAMI.2013.29		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	186GB	WOS:000322029000012	23868780	
J	Goodfellow, IJ; Courville, A; Bengio, Y				Goodfellow, Ian J.; Courville, Aaron; Bengio, Yoshua			Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neural nets; pattern recognition; computer vision		We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.	[Goodfellow, Ian J.; Courville, Aaron; Bengio, Yoshua] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Goodfellow, IJ (reprint author), Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada.	goodfeli@iro.umontreal.ca			US Defense Advanced Research Projects Agency (DARPA); NSERC	This work was supported by the US Defense Advanced Research Projects Agency (DARPA) and NSERC. The authors would like to thank Pascal Vincent for helpful discussions. The computation done for this work was conducted in part on computers of RESMIQ, Clumeq, and SharcNet. The authors would like to thank the developers of Theano (Bergstra et al. [3]) and pylearn2 (Warde-Farley et al. [39]).	Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergstra J., 2010, P PYTH SCI COMP C; Coates A., 2011, P 13 INT C ART INT S; Coates A., 2011, P INT C MACH LEARN; Courville A, 2011, P 28 INT C MACH LEAR; Courville A., 2011, P 13 INT C ART INT S; Deng L., 2010, P INTERSPEECH, V10; Desjardins G., 2012, ABS12034416 CORR; Douglas SC, 2000, IEEE T SIGNAL PROCES, V48, P1843, DOI 10.1109/78.845952; Garrigues P., 2008, P ADV NEUR INF PROC, P505; Hinton G.E., 2000, 2000004 GCNU TR GATS; Hinton G.E., 2010, 2010003 UTML TR DEP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvaarinen A., 2009, NATURAL IMAGE STAT P; Jia Y., 2011, P NEUR INF PROC SYST; Kavukcuoglu K., 2010, P NEUR INF PROC SYST; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Krizhevsky A., 2009, TECHNICAL REPORT; Le Q. V., 2011, P ADV NEUR INF PROC, V24, P1017; Le Q.V., 2011, P NEUR INF PROC SYST; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lucke J., 2011, ARXIV11052493; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; Mohamed S., 2012, P INT C MACH LEARN; Montavon G., 2012, CORR; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Salakhutdinov R., 2009, P INT C ART INT STAT; Saul L.K., 1996, P ADV NEUR INF PROC; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Titsias M.K., 2011, P ADV NEUR INF PROC; Titterington DM, 1985, STAT ANAL FINITE MIX; Vincent P., 2008, P INT C MACH LEARN; Warde-Farley D., 2011, PYLEARN2; Younes L., 1998, STOCHASTICS STOCHAST, P177; Yu K., 2011, P IEEE C COMP VIS PA; Zeiler M., 2011, P INT C MACH LEARN; Zhou M., 2009, P ADV NEUR INF PROC, P2295	43	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1902	1914		10.1109/TPAMI.2012.273		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	164AP	WOS:000320381400007	23787343	
J	Reichert, DP; Series, P; Storkey, AJ				Reichert, David P.; Series, Peggy; Storkey, Amos J.			Charles Bonnet Syndrome: Evidence for a Generative Model in the Cortex?	PLOS COMPUTATIONAL BIOLOGY			English	Article							COMPLEX VISUAL HALLUCINATIONS; NEURAL-NETWORKS; LEARNING ALGORITHM; BAYESIAN-INFERENCE; BRAIN; SCHIZOPHRENIA; CONSCIOUSNESS; RECOGNITION; PLASTICITY; ATTENTION	Several theories propose that the cortex implements an internal model to explain, predict, and learn about sensory data, but the nature of this model is unclear. One condition that could be highly informative here is Charles Bonnet syndrome (CBS), where loss of vision leads to complex, vivid visual hallucinations of objects, people, and whole scenes. CBS could be taken as indication that there is a generative model in the brain, specifically one that can synthesise rich, consistent visual representations even in the absence of actual visual input. The processes that lead to CBS are poorly understood. Here, we argue that a model recently introduced in machine learning, the deep Boltzmann machine (DBM), could capture the relevant aspects of (hypothetical) generative processing in the cortex. The DBM carries both the semantics of a probabilistic generative model and of a neural network. The latter allows us to model a concrete neural mechanism that could underlie CBS, namely, homeostatic regulation of neuronal activity. We show that homeostatic plasticity could serve to make the learnt internal model robust against e. g. degradation of sensory input, but overcompensate in the case of CBS, leading to hallucinations. We demonstrate how a wide range of features of CBS can be explained in the model and suggest a potential role for the neuromodulator acetylcholine. This work constitutes the first concrete computational model of CBS and the first application of the DBM as a model in computational neuroscience. Our results lend further credence to the hypothesis of a generative model in the brain.	[Reichert, David P.; Series, Peggy; Storkey, Amos J.] Univ Edinburgh, Inst Adapt & Neural Computat, Edinburgh, Midlothian, Scotland; [Reichert, David P.] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA	Reichert, DP (reprint author), Univ Edinburgh, Inst Adapt & Neural Computat, Edinburgh, Midlothian, Scotland.	david_reichert@brown.edu			UK Engineering and Physical Sciences Research Council (EPSRC) [EP/F500385/1, BB/F529254/1]; UK Biotechnology and Biological Sciences Research Council (BBSRC); UK Medical Research Council (MRC); German Academic Exchange Service (DAAD)	This work was supported in part by grants EP/F500385/1 and BB/F529254/1 for the University of Edinburgh School of Informatics Doctoral Training Centre in Neuroinformatics and Computational Neuroscience (www.anc.ed.ac.uk/dtc) from the UK Engineering and Physical Sciences Research Council (EPSRC), UK Biotechnology and Biological Sciences Research Council (BBSRC), and the UK Medical Research Council (MRC). It was also supported by a fellowship within the Postdoc-Programme of the German Academic Exchange Service (DAAD). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Aakerlund L, 1998, BIOL PSYCHIAT, V43, P471, DOI 10.1016/S0006-3223(97)00489-7; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Bengio Y, 2009, FDN TRENDS MACHINE L, V2, P1127; Bishop CM, 2006, PATTERN RECOGNITION; Bowers JS, 2012, PSYCHOL BULL, V138, P389, DOI 10.1037/a0026450; Bowers JS, 2012, PSYCHOL BULL, V138, P423, DOI 10.1037/a0027750; Burke W, 2002, J NEUROL NEUROSUR PS, V73, P535, DOI 10.1136/jnnp.73.5.535; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Collerton D, 2005, BEHAV BRAIN SCI, V28, P737; Corlett PR, 2009, PSYCHOPHARMACOLOGY, V206, P515, DOI 10.1007/s00213-009-1561-0; Courville A, 2011, P 28 INT C MACH LEAR; CRICK F, 1983, NATURE, V304, P111, DOI 10.1038/304111a0; Daw N., 2008, ADV NEURAL INFORM PR, V20, P369; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Dayan P, 1998, NEURAL COMPUT, V10, P1119, DOI 10.1162/089976698300017377; Desai NS, 2003, J PHYSIOLOGY-PARIS, V97, P391, DOI 10.1016/j.jphysparis.2004.01.005; Durstewitz D, 2000, NAT NEUROSCI, V3, P1184, DOI 10.1038/81460; Eslami S. M., 2012, IEEE C COMP VIS PATT; Ffytche Dominic H, 2007, Dialogues Clin Neurosci, V9, P173; ffytche DH, 1999, BRAIN, V122, P1247, DOI 10.1093/brain/122.7.1247; Ffytche DH, 1998, NAT NEUROSCI, V1, P738, DOI 10.1038/3738; ffytche DH, 2005, BEHAV BRAIN SCI, V28, P763; Finkel LH, 2000, ANNU REV BIOMED ENG, V2, P577, DOI 10.1146/annurev.bioeng.2.1.577; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Friston KJ, 2005, BEHAV BRAIN SCI, V28, P764; Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300; Griffiths T, 2008, CAMBRIDGE HDB COMPUT, p59C; Griffiths TL, 2012, PSYCHOL BULL, V138, P415, DOI 10.1037/a0026884; Grossberg S, 2000, J INT NEUROPSYCH SOC, V6, P583, DOI 10.1017/S135561770065508X; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton G.E., 2010, 2010003 UTML TR DEP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; HOFFMAN RE, 1989, SCHIZOPHRENIA BULL, V15, P477; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Hoyer P. O., 2003, ADV NEURAL INFORM PR, V15, P277; Jardri R, 2013, NEUROSCIENCE HALLUCI, P289; JONES M, 2011, BEHAV BRAIN SCI, V34, P169, DOI DOI 10.1017/S0140525X10003134; Jones M, 2011, BEHAV BRAIN SCI, V34, P215, DOI [10.1017/S0140525X10003134, 10.1017/S0140525X11001439]; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Lamme VAF, 2006, TRENDS COGN SCI, V10, P494, DOI 10.1016/j.tics.2006.09.001; Lee H., 2008, ADV NEURAL INFORM PR, V20; Lee HJ, 2009, GEOL SOC AM SPEC PAP, V454, P1, DOI 10.1130/2009.2454(00); Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Levy R., 2009, ADV NEURAL INFORM PR, V21, P937; MacKay DJC, 2002, INFORM THEORY INFERE; Manford M, 1998, BRAIN, V121, P1819, DOI 10.1093/brain/121.10.1819; Marder E, 2006, NAT REV NEUROSCI, V7, P563, DOI 10.1038/nrn1949; Mason OJ, 2009, J NERV MENT DIS, V197, P783, DOI 10.1097/NMD.0b013e3181b9760b; Menon GJ, 2003, SURV OPHTHALMOL, V48, P58, DOI 10.1016/S0039-6257(02)00414-9; Merabet LB, 2003, NEUROCASE, V9, P436, DOI 10.1076/neur.9.5.436.16557; Morrison J, 2005, BEHAV BRAIN SCI, V28, P770; MUESER KT, 1990, ACTA PSYCHIAT SCAND, V82, P26, DOI 10.1111/j.1600-0447.1990.tb01350.x; MUMFORD D, 1994, LARGE SCALE NEURONAL, P125; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nair V., 2010, P 27 INT C MACH LEAR, P807; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osindero S, 2008, ADV NEURAL INFORM PR, V20, P1121; PERRY EK, 1995, BRAIN COGNITION, V28, P240, DOI 10.1006/brcg.1995.1255; Plummer C, 2007, J CLIN NEUROSCI, V14, P709, DOI 10.1016/j.jocn.2006.08.006; Pozo K, 2010, NEURON, V66, P337, DOI 10.1016/j.neuron.2010.04.028; Ranzato M, 2011, 2011 IEEE C COMP VIS, DOI [10.1109/CVPR.2011.5995710, DOI 10.1109/CVPR.2011.5995710]; Ranzato M., 2010, P 13 INT C ART INT S; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Reichert D, 2011, ADV NEURAL INFORM PR, V24, P2357; Reichert DP, 2011, ARTIFICIAL NEURAL NE, V6791, p; REICHERT DP, 2010, ADV NEURAL INFORM PR, V23, P2020; Reichert DP, 2012, THESIS U EDINBURGH E; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rifai S, 2012, P 29 INT C MACH LEAR; Rolls ET, 2008, NAT REV NEUROSCI, V9, P696, DOI 10.1038/nrn2462; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Ruppin E, 1996, SCHIZOPHRENIA BULL, V22, P105; Salakhutdinov R, 2009, P 12 INT C ART INT S; Salakhutdinov R., 2007, P INT C ART INT STAT; Sanborn AN, 2010, PSYCHOL REV, V117, P1144, DOI 10.1037/a0020511; Santhouse AM, 2000, BRAIN, V123, P2055, DOI 10.1093/brain/123.10.2055; Sarter M, 2005, BRAIN RES REV, V48, P98, DOI 10.1016/j.brainresrev.2004.08.006; Saxe A., 2011, ADV NEURAL INFORM PR, V24, P1971; SCHULTZ G, 1991, PERCEPTION, V20, P809, DOI 10.1068/p200809; Self MW, 2012, P NATL ACAD SCI USA, V109, P11031, DOI 10.1073/pnas.1119527109; Spencer KM, 2005, BEHAV BRAIN SCI, V28, P774; Teunisse RJ, 1996, LANCET, V347, P794, DOI 10.1016/S0140-6736(96)90869-7; Tononi G, 2008, BIOL BULL-US, V215, P216; Turrigiano GG, 2000, CURR OPIN NEUROBIOL, V10, P358, DOI 10.1016/S0959-4388(00)00091-X; Turrigiano GG, 2008, CELL, V135, P422, DOI 10.1016/j.cell.2008.10.008; Vilares I, 2011, ANN NY ACAD SCI, V1224, P22, DOI 10.1111/j.1749-6632.2011.05965.x; Vul E., 2009, P 31 ANN C COGN SCI; Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858; Yu AJ, 2002, NEURAL NETWORKS, V15, P719, DOI 10.1016/S0893-6080(02)00058-8; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002	94	3	3	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-7358			PLOS COMPUT BIOL	PLoS Comput. Biol.	JUL	2013	9	7							e1003134	10.1371/journal.pcbi.1003134		19	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	190DZ	WOS:000322320200022	23874177	
J	Thom, M; Palm, G				Thom, Markus; Palm, Guenther			Sparse Activity and Sparse Connectivity in Supervised Learning	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						supervised learning; sparseness projection; sparse activity; sparse connectivity	NONNEGATIVE MATRIX FACTORIZATION; ASSOCIATIVE MEMORY; PYRAMIDAL NEURONS; RECEPTIVE-FIELDS; NEURAL NETWORKS; VISUAL-CORTEX; ALGORITHM; REPRESENTATIONS; CODE; PROJECTIONS	Sparseness is a useful regularizer for learning in a wide range of applications, in particular in neural networks. This paper proposes a model targeted at classification tasks, where sparse activity and sparse connectivity are used to enhance classification capabilities. The tool for achieving this is a sparseness-enforcing projection operator which finds the closest vector with a pre-defined sparseness for any given vector. In the theoretical part of this paper, a comprehensive theory for such a projection is developed. In conclusion, it is shown that the projection is differentiable almost everywhere and can thus be implemented as a smooth neuronal transfer function. The entire model can hence be tuned end-to-end using gradient-based methods. Experiments on the MNIST database of handwritten digits show that classification performance can be boosted by sparse activity or sparse connectivity. With a combination of both, performance can be significantly better compared to classical non-sparse approaches.	[Thom, Markus] Univ Ulm, DriveU Inst Measurement Control & Microtechnol, D-89081 Ulm, Germany; [Palm, Guenther] Univ Ulm, Inst Neural Informat Proc, D-89081 Ulm, Germany	Thom, M (reprint author), Univ Ulm, DriveU Inst Measurement Control & Microtechnol, D-89081 Ulm, Germany.	MARKUS.THOM@UNI-ULM.DE; GUENTHER.PALM@UNI-ULM.DE			Daimler AG, Germany	The authors wish to thank Patrik O. Hoyer and Xiaojing Ye for sharing the source code of their algorithms. The authors are also grateful to the anonymous reviewers for their valuable comments and feedback. This work was supported by Daimler AG, Germany.	Acion L, 2006, STAT MED, V25, P591, DOI 10.1002/sim.2256; BAUM EB, 1988, BIOL CYBERN, V59, P217, DOI 10.1007/BF00332910; Bertsekas D. P., 1999, NONLINEAR PROGRAMMIN; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blumensath T, 2009, INT CONF ACOUST SPEE, P3357, DOI 10.1109/ICASSP.2009.4960344; Bottou L., 2004, ADV NEURAL INFORM PR, V16, P217; Bradley D. M., 2009, ADV NEURAL INFORM PR, V21, P113; Chen Y., 2011, ARXIV11016081V2 U FL; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Demsar J, 2006, J MACH LEARN RES, V7, P1; Deutsch F., 2001, BEST APPROXIMATION I; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; DOWNTON F, 1973, TECHNOMETRICS, V15, P551, DOI 10.2307/1266860; Duchi J., 2008, P 25 INT C MACH LEAR, P272, DOI DOI 10.1145/1390156.1390191; Dunne R. A., 1997, Proceedings of the Eighth Australian Conference on Neural Networks (ACNN'97); DYKSTRA RL, 1983, J AM STAT ASSOC, V78, P837, DOI 10.2307/2288193; DYKSTRA RL, 1987, J STAT PLAN INFER, V15, P391, DOI 10.1016/0378-3758(86)90111-4; Friedman J., 2010, ARXIV10010736V1 STAN; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Glorot Xavier, 2011, P AISTATS, P315; Gregor K., 2010, P INT C MACH LEARN, P399; GRISSOM RJ, 1994, J APPL PSYCHOL, V79, P314, DOI 10.1037//0021-9010.79.2.314; Heiler M, 2006, J MACH LEARN RES, V7, P1385; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HIRIARTURRUTY JB, 1982, AM MATH MON, V89, P456, DOI 10.2307/2321379; Hochberg Yosef, 1987, MULTIPLE COMP PROCED; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527; Hyvarinen A, 1999, ADV NEUR IN, V11, P473; Karbowski J, 2003, J COMPUT NEUROSCI, V15, P347, DOI 10.1023/A:1027467911225; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353; KRUSKAL WILLIAM H., 1952, JOUR AMER STATIST ASSOC, V47, P583, DOI 10.2307/2280779; Laub A. J, 2004, MATRIX ANAL SCI ENG; Laughlin SB, 2003, SCIENCE, V301, P1870, DOI 10.1126/science.1089662; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; LeCun Y., 1998, MNIST DATABASE HANDW; Lee DD, 1999, NATURE, V401, P788; Levene H., 1960, CONTRIBUTIONS PROBAB, P278; Li SZ, 2001, PROC CVPR IEEE, P207; Liu J., 2009, P 26 ANN INT C MACH, P657; Liu J., 2010, ARXIV10094766V1 AR S; Mairal J., 2009, ADV NEURAL INFORM PR, V21, P1033; Mairal J, 2010, J MACH LEARN RES, V11, P19; Markram H, 1997, J PHYSIOL-LONDON, V500, P409; MASON A, 1991, J NEUROSCI, V11, P72; MICHELOT C, 1986, J OPTIMIZ THEORY APP, V50, P195, DOI 10.1007/BF00938486; Mutch J., 2006, P IEEE C COMP VIS PA, P11; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; NEUDECKE.H, 1969, J AM STAT ASSOC, V64, P953, DOI 10.2307/2283476; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; PALM G, 1980, BIOL CYBERN, V36, P19, DOI 10.1007/BF00337019; Pizarro J, 2002, NEUROCOMPUTING, V48, P155, DOI 10.1016/S0925-2312(01)00653-1; Quattoni A., 2009, P 26 INT C MACH LEAR, P857; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Rehn M, 2007, J COMPUT NEUROSCI, V22, P135, DOI 10.1007/s10827-006-0003-9; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Scholkopf B., 1997, THESIS TU BERLIN; SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709; Simard P .Y, 2003, P INT C DOC AN REC, P958; Sra S, 2012, DATA MIN KNOWL DISC, V25, P358, DOI 10.1007/s10618-012-0277-7; Theis F. J., 2005, P EUR SIGN PROC C, P1672; Theis FJ, 2006, INT CONF ACOUST SPEE, P709; Thom M., 2011, LECT NOTES COMPUTER, V6835, P356; Thom M, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P973, DOI 10.1109/IJCNN.2011.6033328; van den Berg E., 2008, TR200809 U BRIT COL; VETTER WJ, 1970, IEEE T AUTOMAT CONTR, VAC15, P241, DOI 10.1109/TAC.1970.1099409; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; von Neumann J., 1950, FUNCTIONAL OPERATORS, V2; Weston J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753751; Wilson DR, 2003, NEURAL NETWORKS, V16, P1429, DOI 10.1016/S0893-6080(03)00138-2; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	81	3	3	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	APR	2013	14						1091	1143				53	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	139NU	WOS:000318590500011		
J	Jern, A; Kemp, C				Jern, Alan; Kemp, Charles			A probabilistic account of exemplar and category generation	COGNITIVE PSYCHOLOGY			English	Article						Categorization; Generation; Sampling; Bayesian modeling	PLUS-EXCEPTION MODEL; HUMAN CATEGORIZATION; DECISION RULES; CLASSIFICATION; KNOWLEDGE; INFERENCE; PERCEPTION; CREATIVITY; SIMILARITY; INDUCTION	People are capable of imagining and generating new category exemplars and categories. This ability has not been addressed by previous models of categorization, most of which focus on classifying category exemplars rather than generating them. We develop a formal account of exemplar and category generation which proposes that category knowledge is represented by probability distributions over exemplars and categories, and that new exemplars and categories are generated by sampling from these distributions. This sampling account of generation is evaluated in two pairs of behavioral experiments. In the first pair of experiments, participants were asked to generate novel exemplars of a category. In the second pair of experiments, participants were asked to generate a novel category after observing exemplars from several related categories. The results suggest that generation is influenced by both structural and distributional properties of the observed categories, and we argue that our data are better explained by the sampling account than by several alternative approaches. (C) 2012 Elsevier Inc. All rights reserved.	[Jern, Alan; Kemp, Charles] Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA	Jern, A (reprint author), Carnegie Mellon Univ, Dept Psychol, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	ajern@cmu.edu; ckemp@cmu.edu			NSF [CDI-0835797]; Pittsburgh Life Sciences Greenhouse Opportunity Fund	Preliminary data from Experiments 1 and 2 were presented at the 31st Annual Conference of the Cognitive Science Society. We thank Faye Han for helping to collect the data for Experiments 1 and 2 and Meghan Reese and Jessica Lee for helping to collect the data for Experiments 3 and 4. We thank Art Markman and three anonymous reviewers for feedback on the manuscript, and John Anderson and David Rakison for feedback throughout the development of this work. This work was supported by NSF Grant CDI-0835797 and the Pittsburgh Life Sciences Greenhouse Opportunity Fund.	Anderson JR, 1996, J EXP PSYCHOL LEARN, V22, P259; ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409; Ashby FG, 1998, PSYCHOL REV, V105, P442, DOI 10.1037/0033-295X.105.3.442; ASHBY FG, 1988, J EXP PSYCHOL LEARN, V14, P33, DOI 10.1037/0278-7393.14.1.33; Ashby F Gregory, 2005, Annu Rev Psychol, V56, P149, DOI 10.1146/annurev.psych.56.091103.070217; ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021; ASHBY FG, 1992, J EXP PSYCHOL HUMAN, V18, P50, DOI 10.1037//0096-1523.18.1.50; Barsalou L. W., 1997, CREATIVE THOUGHT INV, P267, DOI 10.1037/10227-011; BARSALOU LW, 1985, J EXP PSYCHOL LEARN, V11, P629, DOI 10.1037/0278-7393.11.1-4.629; Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; Berti A. E., 1997, COGNITIVE DEV, V12, P501, DOI [10.1016/S0885-2014(97)90020-4, DOI 10.1016/S0885-2014(97)90020-4]; Bishop CM, 2006, PATTERN RECOGNITION; Boden MA, 1998, ARTIF INTELL, V103, P347, DOI 10.1016/S0004-3702(98)00055-1; Cobb Sally Wright, 1996, BROWN DERBY RESTAURA; Colunga E, 2008, NEW IDEAS PSYCHOL, V26, P174, DOI 10.1016/j.newideapsych.2007.07.012; Daeschler EB, 2006, NATURE, V440, P757, DOI 10.1038/nature04639; Feldman J, 1997, J MATH PSYCHOL, V41, P145, DOI 10.1006/jmps.1997.1154; Fiser J, 2010, TRENDS COGN SCI, V14, P119, DOI 10.1016/j.tics.2010.01.003; Fiser J, 2001, PSYCHOL SCI, V12, P499, DOI 10.1111/1467-9280.00392; FRIED LS, 1984, J EXP PSYCHOL LEARN, V10, P234, DOI 10.1037/0278-7393.10.2.234; Gasarch W. I., 2002, SIGACT NEWS, V33, P34; Gelman A, 2004, BAYESIAN DATA ANAL, V2nd; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoyer P. O., 2003, ADV NEURAL INFORM PR, V16; Hsu A., 2009, ADV NEURAL INFORM PR, V22; Hsu A. S., 2010, P 32 ANN C COGN SCI; Jakel F, 2008, PSYCHON B REV, V15, P256, DOI 10.3758/PBR.15.2.256; JONES SS, 1991, CHILD DEV, V62, P499, DOI 10.1111/j.1467-8624.1991.tb01547.x; KAHNEMAN D, 1972, COGNITIVE PSYCHOL, V3, P430, DOI 10.1016/0010-0285(72)90016-3; Keil FC, 1998, COGNITION, V65, P103, DOI 10.1016/S0010-0277(97)00041-3; Kemp C., 2005, P 27 ANN C COGN SCI; Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x; Kemp C., 2009, P 31 ANN C COGN SCI; Kleinberg J, 2005, ALGORITHM DESIGN; KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037/0033-295X.99.1.22; LANDAU B, 1988, COGNITIVE DEV, V3, P299, DOI 10.1016/0885-2014(88)90014-7; Love BC, 2005, CURR DIR PSYCHOL SCI, V14, P195, DOI 10.1111/j.0963-7214.2005.00363.x; Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309; LUCE R. D., 1959, INDIVIDUAL CHOICE BE; MACARIO JF, 1991, COGNITIVE DEV, V6, P17, DOI 10.1016/0885-2014(91)90004-W; Markman AB, 2003, PSYCHOL BULL, V129, P592, DOI 10.1037/0033-2909.129.4.592; Marsh RL, 1999, MEM COGNITION, V27, P94, DOI 10.3758/BF03201216; Marsh RL, 1996, MEM COGNITION, V24, P669, DOI 10.3758/BF03201091; Moreno-Bote R, 2011, P NATL ACAD SCI USA, V108, P12491, DOI 10.1073/pnas.1101430108; Ng A., 2002, P NEUR INF PROC SYST, V14; Nosofsky RM, 1998, PSYCHON B REV, V5, P345, DOI 10.3758/BF03208813; NOSOFSKY RM, 1994, PSYCHOL REV, V101, P53, DOI 10.1037/0033-295X.101.1.53; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; OSHERSON DN, 1990, PSYCHOL REV, V97, P185, DOI 10.1037/0033-295X.97.2.185; Perfors A., 2009, P 31 ANN C COGN SCI; Pothos E. M., 2011, FORMAL APPROACHES CA; Pothos EM, 2009, J EXP PSYCHOL LEARN, V35, P1062, DOI 10.1037/a0015903; Pothos EM, 2002, COGNITIVE SCI, V26, P303, DOI 10.1016/S0364-0213(02)00064-2; Rakison DH, 2010, WIRES COGN SCI, V1, P894, DOI 10.1002/wcs.81; Ramscar M, 2010, COGNITIVE SCI, V34, P909, DOI 10.1111/j.1551-6709.2009.01092.x; Ratcliff R, 2004, PSYCHOL REV, V111, P333, DOI 10.1037/0033-295X.111.2.333; Rehder B, 2003, COGNITIVE SCI, V27, P709, DOI 10.1016/S0364-0213(03)00068-5; Rehder B, 2006, J EXP PSYCHOL LEARN, V32, P659, DOI 10.1037/0278-7393.32.4.659; Rehder B, 2003, PSYCHON B REV, V10, P759, DOI 10.3758/BF03196543; Rehling J, 2004, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON COGNITIVE MODELING, P249; Rehling J. A., 2001, THESIS INDIANA U; Ross BH, 1999, J EXP PSYCHOL LEARN, V25, P743, DOI 10.1037/0278-7393.25.3.743; Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379; Sakamoto Y, 2010, J EXP PSYCHOL-APPL, V16, P361, DOI 10.1037/a0021610; Sanborn AN, 2010, PSYCHOL REV, V117, P1144, DOI 10.1037/a0020511; SHELTON JA, 2011, ADV NEURAL INFORM PR, V24; Shi L., 2009, P NEURAL INFORM PROC, V22; Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403; SMITH SM, 1993, MEM COGNITION, V21, P837, DOI 10.3758/BF03202751; Stewart N, 2006, COGNITIVE PSYCHOL, V53, P1, DOI 10.1016/j.cogpsych.2005.10.003; Tenenbaum J.B., 1999, P NEURAL INFORM PROC, V11; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104; Vul E, 2008, PSYCHOL SCI, V19, P645, DOI 10.1111/j.1467-9280.2008.02136.x; Waldmann MR, 2006, COGNITIVE PSYCHOL, V53, P27, DOI 10.1016/j.cogpsych.2006.01.001; Ward T, 1995, CREATIVE COGNITION A; Ward TB, 2002, MEM COGNITION, V30, P199, DOI 10.3758/BF03195281; Ward TB, 2004, CREATIVITY RES J, V16, P1, DOI 10.1207/s15326934crj1601_1; Williams JJ, 2010, COGNITIVE SCI, V34, P776, DOI 10.1111/j.1551-6709.2010.01113.x; Wills AJ, 2012, PSYCHOL BULL, V138, P102, DOI 10.1037/a0025715; Xue JH, 2008, NEURAL PROCESS LETT, V28, P169, DOI 10.1007/s11063-008-9088-7; Yamauchi T, 2000, J EXP PSYCHOL LEARN, V26, P776, DOI 10.1037//0278-7393.26.3.776; Yamauchi T, 1998, J MEM LANG, V39, P124, DOI 10.1006/jmla.1998.2566; Yamauchi T, 2008, MEM COGNITION, V36, P544, DOI 10.3758/MC.36.3.544; Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002	85	3	3	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0010-0285			COGNITIVE PSYCHOL	Cogn. Psychol.	FEB	2013	66	1					85	125		10.1016/j.cogpsych.2012.09.003		41	Psychology; Psychology, Experimental	Psychology	085LX	WOS:000314617400004	23108001	
S	Brosch, T; Tam, R		Sakuma, I; Barillot, C; Navab, N		Brosch, Tom; Tam, Roger		Alzheimer's Dis Neuroimaging Initi	Manifold Learning of Brain MRIs by Deep Learning	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2013, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	16th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)	SEP 22-26, 2013	Nagoya, JAPAN	Nagoya Convent & Visitors Bur, Murata Sci Fdn, Daiko Fdn, Japan Soc Comp Aided Surg, Sci Council Japan, Nagoya Univ, Informat & Commun Headquarters, Nagoya Univ, Grad Sch Informat Sci	Nagoya Univ	Manifold Learning; Machine Learning; Brain Imaging; MRI; Deep Learning; Deep Belief Networks	DIMENSIONALITY REDUCTION	Manifold learning of medical images plays a potentially important role for modeling anatomical variability within a population with applications that include segmentation, registration, and prediction of clinical parameters. This paper describes a novel method for learning the manifold of 3D brain images that, unlike most existing manifold learning methods, does not require the manifold space to be locally linear, and does not require a predefined similarity measure or a prebuilt proximity graph. Our manifold learning method is based on deep learning, a machine learning approach that uses layered networks (called deep belief networks, or DBNs) and has received much attention recently in the computer vision field due to their success in object recognition tasks. DBNs have traditionally been too computationally expensive for application to 3D images due to the large number of trainable parameters. Our primary contributions are 1) a much more computationally efficient training method for DBNs that makes training on 3D medical images with a resolution of up to 128 x 128 x 128 practical, and 2) the demonstration that DBNs can learn a low-dimensional manifold of brain volumes that detects modes of variations that correlate to demographic and disease parameters.	[Brosch, Tom] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V5Z 1M9, Canada	Brosch, T (reprint author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V5Z 1M9, Canada.						Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Etyngier P., 2007, 11 INT C COMP VIS IE, P1; Gerber S, 2010, MED IMAGE ANAL, V14, P643, DOI 10.1016/j.media.2010.05.008; Hamm J, 2010, MED IMAGE ANAL, V14, P633, DOI 10.1016/j.media.2010.06.001; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Nair V., 2010, P 27 INT C MACH LEAR, P807; Petersen RC, 2010, NEUROLOGY, V74, P201, DOI 10.1212/WNL.0b013e3181cb3e25; Saul L., 2003, J MACHINE LEARNING R, V4, P119; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Wolz R, 2011, I S BIOMED IMAGING, P1637, DOI 10.1109/ISBI.2011.5872717; Wolz R, 2010, NEUROIMAGE, V49, P1316, DOI 10.1016/j.neuroimage.2009.09.069	12	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-40763-5; 978-3-642-40762-8	LECT NOTES COMPUT SC			2013	8150						633	640				8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BB3LH	WOS:000342835100078		
J	Cai, M; Shi, YZ; Liu, J			IEEE	Cai, Meng; Shi, Yongzhe; Liu, Jia			DEEP MAXOUT NEURAL NETWORKS FOR SPEECH RECOGNITION	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Maxout networks; acoustic modeling; neuron nonlinearity; speech recognition		A recently introduced type of neural network called maxout has worked well in many domains. In this paper, we propose to apply maxout for acoustic models in speech recognition. The maxout neuron picks the maximum value within a group of linear pieces as its activation. This nonlinearity is a generalization to the rectified nonlinearity and has the ability to approximate any form of activation functions. We apply maxout networks to the Switchboard phone-call transcription task and evaluate the performances under both a 24-hour low-resource condition and a 300-hour core condition. Experimental results demonstrate that maxout networks converge faster, generalize better and are easier to optimize than rectified linear networks and sigmoid networks. Furthermore, experiments show that maxout networks reduce underfitting and are able to achieve good results without dropout training. Under both conditions, maxout networks yield relative improvements of 1.1-5.1% over rectified linear networks and 2.6-14.5% over sigmoid networks on benchmark test sets.	[Cai, Meng; Shi, Yongzhe; Liu, Jia] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing 100084, Peoples R China	Cai, M (reprint author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing 100084, Peoples R China.	cai-m10@mails.tsinghua.edu.cn; shiyz09@gmail.com; liuj@tsinghua.edu.cn					Cai M., 2013, P CHINASIP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Glorot Xavier, 2011, P AISTATS, P315; Goodfellow I., 2013, P ICML; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Maas A. L., 2013, P ICML; Mnih V., 2009, 2009004 UTML TR DEP; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; Nair V., 2010, P ICML; Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301; Prabhavalkar R, 2013, INT CONF ACOUST SPEE, P7165, DOI 10.1109/ICASSP.2013.6639053; Seide F., 2011, P ASRU, P24; Seide F., 2011, P INTERSPEECH, P437; Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312	18	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							291	296				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800050		
J	Huang, J; Kingsbury, B			IEEE	Huang, Jing; Kingsbury, Brian			AUDIO-VISUAL DEEP LEARNING FOR NOISE ROBUST SPEECH RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Audio-visual speech recognition; Deep belief networks; Noise robustness		Deep belief networks (DBN) have shown impressive improvements over Gaussian mixture models for automatic speech recognition. In this work we use DBNs for audio-visual speech recognition; in particular, we use deep learning from audio and visual features for noise robust speech recognition. We test two methods for using DBNs in a multimodal setting: a conventional decision fusion method that combines scores from single-modality DBNs, and a novel feature fusion method that operates on mid-level features learned by the single-modality DBNs. On a continuously spoken digit recognition task, our experiments show that these methods can reduce word error rate by as much as 21% relative over a baseline multi-stream audio-visual GMM/HMM system.	[Huang, Jing; Kingsbury, Brian] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA	Huang, J (reprint author), IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.	jghg@us.ibm.com; bedk@us.ibm.com					Chen T, 1998, P IEEE, V86, P837; Chibelushi CC, 2002, IEEE T MULTIMEDIA, V4, P23, DOI 10.1109/6046.985551; Duchnowski P., 1994, P ICSLP; Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479; Garg A., 2003, INT C AC SPEECH SIGN; Heckmann M, 2002, EURASIP J APPL SIG P, V2002, P1260, DOI 10.1155/S1110865702206150; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang J., 2005, P INT; Huang J, 2004, SPEECH COMMUN, V44, P83, DOI 10.1016/j.specom.2004.10.007; Huang J., 2009, P INT; Janin A., 1999, P 6 EUR C SPEECH COM, P591; Kim M., 2005, ADV NATURAL COMPUTAT; Lewis T., 2003, J RES PRACTICE INFOR; Marcheret E., 2004, INT C SPEECH LANG PR; Meier U., 1996, P ICASSP; Mohamed A., 2012, P ICASSP; Ngiam J., 2011, INT C MACH LEARN; Pitsikalis V., 2006, P ICSLP; Potamianos G., 2006, ENCY LANGUAGE LINGUI; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; Povey D., 2005, P ICASSP; Povey D., 2002, P ICASSP; SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309	24	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7596	7599				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507153		
J	Ouyang, WL; Zeng, XY; Wang, XG			IEEE	Ouyang, Wanli; Zeng, Xingyu; Wang, Xiaogang			Modeling Mutual Visibility Relationship in Pedestrian Detection	2013 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2013	Portland, OR	IEEE, IEEE Comp Soc				Detecting pedestrians in cluttered scenes is a challenging problem in computer vision. The difficulty is added when several pedestrians overlap in images and occlude each other. We observe, however, that the occlusion/visibility statuses of overlapping pedestrians provide useful mutual relationship for visibility estimation - the visibility estimation of one pedestrian facilitates the visibility estimation of another. In this paper, we propose a mutual visibility deep model that jointly estimates the visibility statuses of overlapping pedestrians. The visibility relationship among pedestrians is learned from the deep model for recognizing co-existing pedestrians. Experimental results show that the mutual visibility deep model effectively improves the pedestrian detection results. Compared with existing image-based pedestrian detection approaches, our approach has the lowest average miss rate on the Caltech-Train dataset, the Caltech-Test dataset and the ETH dataset. Including mutual visibility leads to 4%- 8% improvements on multiple benchmark datasets.	[Ouyang, Wanli; Wang, Xiaogang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Comp Vis & Pat Rec, Beijing, Peoples R China	Ouyang, WL (reprint author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Comp Vis & Pat Rec, Beijing, Peoples R China.	wlouyang@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk	Wang, Xiaogang/L-4369-2014	Wang, Xiaogang/0000-0002-9021-0954			Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Dai S., 2007, CVPR; Dalal N., 2005, CVPR; DENG J, 2009, CVPR; Desai C., 2009, ICCV; Ding Y., 2012, CVPR; Dollar P., 2012, ECCV; Dollar P., 2010, BMVC; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Duan G., 2010, ECCV; Enzweiler M., 2010, CVPR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Ess A., 2007, ICCV; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jarrett K., 2009, CVPR; Krizhevsky A., 2012, NIPS; Lee H., 2009, ICML; Leibe B., 2005, CVPR; Lin Z., 2007, ICCV; Luo P., 2012, CVPR; Norouzi M., 2009, CVPR; Ouyang W., 2012, CVPR; Ouyang W., 2013, CVPR; Park D., 2010, ECCV; Ranzato M., 2011, CVPR; Shet V. D., 2007, CVPR, P2; Tang S., 2012, BMVC; Walk S., 2010, CVPR; Wang X., 2009, CVPR; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; Wu B., 2005, ICCV; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Yan J., 2012, CVPR; Yang Y., 2011, CVPR; Yang Y., 2012, CVPR; Yao B., 2010, CVPR; Zhu L., 2010, CVPR	40	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-0-7695-4989-7	PROC CVPR IEEE			2013							3222	3229		10.1109/CVPR.2013.414		8	Computer Science, Artificial Intelligence	Computer Science	BA0ER	WOS:000331094303038		
J	Schmidt, U; Rother, C; Nowozin, S; Jancsary, J; Roth, S			IEEE	Schmidt, Uwe; Rother, Carsten; Nowozin, Sebastian; Jancsary, Jeremy; Roth, Stefan			Discriminative Non-blind Deblurring	2013 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2013	Portland, OR	IEEE, IEEE Comp Soc			IMAGE; RESTORATION; RECOVERY	Non-blind deblurring is an integral component of blind approaches for removing image blur due to camera shake. Even though learning-based deblurring methods exist, they have been limited to the generative case and are computationally expensive. To this date, manually-defined models are thus most widely used, though limiting the attained restoration quality. We address this gap by proposing a discriminative approach for non-blind deblurring. One key challenge is that the blur kernel in use at test time is not known in advance. To address this, we analyze existing approaches that use half-quadratic regularization. From this analysis, we derive a discriminative model cascade for image deblurring. Our cascade model consists of a Gaussian CRF at each stage, based on the recently introduced regression tree fields. We train our model by loss minimization and use synthetically generated blur kernels to generate training data. Our experiments show that the proposed approach is efficient and yields state-of-the-art restoration quality on images corrupted with synthetic and real blur	[Schmidt, Uwe; Roth, Stefan] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany	Schmidt, U (reprint author), Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.						Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Barbu A., 2009, CVPR 2009; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Burger H. C., CVPR 2012; Charbonnier P., ICIP 1994; Cho S., 2009, ACM T GRAPHIC, V28, P5; Cho S., ICCV 2011; Fergus R., 2006, ACM T GRAPHIC, V25, P3; Frohlich B., PATT REC DAGM 2012; Gao Q., PATT REC DAGM 2012; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jancsary J., CVPR 2012; Jancsary J., ECCV 2012; Kohler R., ECCV 2012; Krishnan D., NIPS 2009; Levin A., 2011, CVPR 2011; Levin A., 2009, CVPR 2009; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Palmer J. A., 2005, NIPS 2005; RICHARDS.WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Schmidt U., 2011, CVPR 2011; Tai Y.-W., CVPR 2012; Tappen M., CVPR 2007; Tu Z., CVPR 2008; Wainwright M. J., NIPS 1999; Xu L., ECCV 2010; Yuan L., 2008, ACM T GRAPHICS, V27	31	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-0-7695-4989-7	PROC CVPR IEEE			2013							604	611		10.1109/CVPR.2013.84		8	Computer Science, Artificial Intelligence	Computer Science	BA0ER	WOS:000331094300077		
J	Lemme, A; Reinhart, RF; Steil, JJ				Lemme, Andre; Reinhart, Rene Felix; Steil, Jochen Jakob			Online learning and generalization of parts-based image representations by non-negative sparse autoencoders	NEURAL NETWORKS			English	Article						Autoencoder; Non-negativity; Sparse coding	MATRIX FACTORIZATION; OBJECT RECOGNITION; FEATURES	We present an efficient online learning scheme for non-negative sparse coding in autoencoder neural networks. It comprises a novel synaptic decay rule that ensures non-negative weights in combination with an intrinsic self-adaptation rule that optimizes sparseness of the non-negative encoding. We show that non-negativity constrains the space of solutions such that overfitting is prevented and very similar encodings are found irrespective of the network initialization and size. We benchmark the novel method on real-world datasets of handwritten digits and faces. The autoencoder yields higher sparseness and lower reconstruction errors than related offline algorithms based on matrix factorization. It generalizes to new inputs both accurately and without costly computations, which is fundamentally different from the classical matrix factorization approaches. (C) 2012 Elsevier Ltd. All rights reserved.	[Lemme, Andre; Reinhart, Rene Felix; Steil, Jochen Jakob] Univ Bielefeld, Res Inst Cognit & Robot CoR Lab, D-33615 Bielefeld, Germany	Lemme, A (reprint author), Univ Bielefeld, Res Inst Cognit & Robot CoR Lab, Univ Str 25, D-33615 Bielefeld, Germany.	alemme@CoR-Lab.Uni-Bielefeld.de; freinhar@CoR-Lab.Uni-Bielefeld.de; jsteil@CoR-Lab.Uni-Bielefeld.de					Bax I., 2006, OPTICAL ENG, V45; Bengio Y., 2007, NIPS, P153; Cao B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2689; Dornbusch D., 2010, P FIAIRS 23, P398; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Frank A, 2005, NAV RES LOG, V52, P2, DOI 10.1002/nav.20056; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoyer P.O., 2002, NEURAL NETWORKS SIGN, P557; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee DD, 1999, NATURE, V401, P788; Lee H., 2008, NIPS, P873; Lemme A., 2010, P ESANN, P1; Mairal J, 2010, J MACH LEARN RES, V11, P19; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Ranzato M., 2008, NIPS, P1185; Shastri BJ, 2007, MACH VISION APPL, V18, P107, DOI 10.1007/s00138-006-0052-0; Spratling MW, 2006, J MACH LEARN RES, V7, P793; Steil J. J., 2004, P IJCNN, V1, P843; Tanaka K, 2003, CEREB CORTEX, V13, P90, DOI 10.1093/cercor/13.1.90; Triesch J, 2005, LECT NOTES COMPUT SC, V3696, P65; Wersing H, 2003, NEURAL COMPUT, V15, P1559, DOI 10.1162/089976603321891800	23	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	SEP	2012	33						194	203		10.1016/j.neunet.2012.05.003		10	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	987PZ	WOS:000307430900018	22706093	
J	De Grazia, MD; Cutini, S; Lisi, M; Zorzi, M				De Grazia, Michele De Filippo; Cutini, Simone; Lisi, Matteo; Zorzi, Marco			Space coding for sensorimotor transformations can emerge through unsupervised learning	COGNITIVE PROCESSING			English	Article						Neural network; Generative model; Sensorimotor transformations; Gain modulation; Parietal cortex	POSTERIOR PARIETAL NEURONS; NEURAL-NETWORKS; CORTEX	The posterior parietal cortex (PPC) is fundamental for sensorimotor transformations because it combines multiple sensory inputs and posture signals into different spatial reference frames that drive motor programming. Here, we present a computational model mimicking the sensorimotor transformations occurring in the PPC. A recurrent neural network with one layer of hidden neurons (restricted Boltzmann machine) learned a stochastic generative model of the sensory data without supervision. After the unsupervised learning phase, the activity of the hidden neurons was used to compute a motor program (a population code on a bidimensional map) through a simple linear projection and delta rule learning. The average motor error, calculated as the difference between the expected and the computed output, was less than 3 degrees. Importantly, analyses of the hidden neurons revealed gain-modulated visual receptive fields, thereby showing that space coding for sensorimotor transformations similar to that observed in the PPC can emerge through unsupervised learning. These results suggest that gain modulation is an efficient coding strategy to integrate visual and postural information toward the generation of motor commands.	[De Grazia, Michele De Filippo; Cutini, Simone; Lisi, Matteo; Zorzi, Marco] Univ Padua, Ctr Cognit Sci, Dept Gen Psychol, Padua, Italy	Cutini, S (reprint author), Univ Padua, Ctr Cognit Sci, Dept Gen Psychol, Padua, Italy.	simone.cutini@unipd.it					ANDERSEN RA, 1985, SCIENCE, V230, P456, DOI 10.1126/science.4048942; BROTCHIE PR, 1995, NATURE, V375, P232, DOI 10.1038/375232a0; Buneo CA, 2006, NEUROPSYCHOLOGIA, V44, P2594, DOI 10.1016/j.neuropsychologia.2005.10.011; Colby CL, 1999, ANNU REV NEUROSCI, V22, P319, DOI 10.1146/annurev.neuro.22.1.319; Galletti C, 2001, EUR J NEUROSCI, V13, P1572, DOI 10.1046/j.0953-816x.2001.01538.x; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; MAZZONI P, 1991, P NATL ACAD SCI USA, V88, P4433, DOI 10.1073/pnas.88.10.4433; MOUNTCASTLE VB, 1975, J NEUROPHYSIOL, V38, P871; Pouget A, 2000, NAT NEUROSCI, V3, P1192, DOI 10.1038/81469; Sakata Hideo, 1994, Current Opinion in Neurobiology, V4, P847, DOI 10.1016/0959-4388(94)90133-3; Salinas E, 2001, NEUROSCIENTIST, V7, P430; Stoianov I, 2012, NAT NEUROSCI, V15, P194, DOI 10.1038/nn.2996; ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0	15	3	3	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1612-4782			COGN PROCESS	Cogn. Process.	AUG	2012	13			1	SI		S141	S146		10.1007/s10339-012-0478-4		6	Psychology, Experimental	Psychology	006NA	WOS:000308824700271		
J	Weng, JY; Luciw, M				Weng, Juyang; Luciw, Matthew			Brain-Like Emergent Spatial Processing	IEEE TRANSACTIONS ON AUTONOMOUS MENTAL DEVELOPMENT			English	Article						Attention; behavior; cognition; complexity; computer vision; cortical representation; mental architecture; perception; reasoning; regression; text understanding	PRIMARY VISUAL-CORTEX; NONLINEAR DIMENSIONALITY REDUCTION; AUTONOMOUS MENTAL-DEVELOPMENT; TOP-DOWN CONNECTIONS; OBJECT RECOGNITION; NEURAL MECHANISMS; RECEPTIVE-FIELD; CEREBRAL-CORTEX; ATTENTION; CIRCUITS	This is a theoretical, modeling, and algorithmic paper about the spatial aspect of brain-like information processing, modeled by the developmental network (DN) model. The new brain architecture allows the external environment (including teachers) to interact with the sensory ends S and the motor ends M of the skull-closed brain B through development. It does not allow the human programmer to hand-pick extra-body concepts or to handcraft the concept boundaries inside the brain B. Mathematically, the brain spatial processing performs real-time mapping from S(t) x B(t) x M(t) to S(t+1) x B(t+1) x M(t+1), through network updates, where the contents of S, B, M all emerge from experience. Using its limited resource, the brain does increasingly better through experience. A new principle is that the effector ends M serve as hubs for concept learning and abstraction. The effector ends M serve also as input and the sensory ends S serve also as output. As DN embodiments, the Where-What Networks (WWNs) present three major function novelties-new concept abstraction, concept as emergent goals, and goal-directed perception. The WWN series appears to be the first general purpose emergent systems for detecting and recognizing multiple objects in complex backgrounds. Among others, the most significant new mechanism is general-purpose top-down attention.	[Weng, Juyang] Michigan State Univ, Cognit Sci Program, Dept Comp Sci Engn, E Lansing, MI 48824 USA; [Weng, Juyang] Michigan State Univ, Neurosci Program, E Lansing, MI 48824 USA; [Luciw, Matthew] Dalle Molle Inst Artificial Intelligence IDSIA, Manno Lugano, Switzerland	Weng, JY (reprint author), Michigan State Univ, Cognit Sci Program, Dept Comp Sci Engn, E Lansing, MI 48824 USA.	weng@cse.msu.edu; luciwmat@gmail.com					Albanese M, 2010, IEEE T PATTERN ANAL, V32, P2246, DOI 10.1109/TPAMI.2010.33; Almassy N, 1998, CEREB CORTEX, V8, P346, DOI 10.1093/cercor/8.4.346; ANDERSON CH, 1987, P NATL ACAD SCI USA, V84, P6297, DOI 10.1073/pnas.84.17.6297; Anderson J., 1993, RULES OF THE MIND; Ansari D, 2008, NAT REV NEUROSCI, V9, P278, DOI 10.1038/nrn2334; Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702; Bi GQ, 2001, ANNU REV NEUROSCI, V24, P139, DOI 10.1146/annurev.neuro.24.1.139; BLAKEMOR.C, 1970, NATURE, V228, P477, DOI 10.1038/228477a0; Callaway EM, 1998, ANNU REV NEUROSCI, V21, P47, DOI 10.1146/annurev.neuro.21.1.47; Carey S, 2011, BEHAV BRAIN SCI, V34, P113, DOI 10.1017/S0140525X10000919; Cole M., 1996, DEV CHILDREN; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; Crair MC, 1998, SCIENCE, V279, P566, DOI 10.1126/science.279.5350.566; Dan Y, 2006, PHYSIOL REV, V86, P1033, DOI 10.1152/physrev.00030.2005; Deco G, 2000, VISION RES, V40, P2845, DOI 10.1016/S0042-6989(00)00140-1; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Domjan M, 1998, PRINCIPLES LEARNING; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Dubuisson Jolly M.-P., 1996, IEEE Transactions on Pattern Analysis and Machine Intelligence, V18, DOI 10.1109/34.485557; Elman J. L., 1997, RETHINKING INNATENES; Fahlman S. E., 1990, CMUCS90100; Fazl A, 2009, COGNITIVE PSYCHOL, V58, P1, DOI 10.1016/j.cogpsych.2008.05.001; Fei-Fei Li, 2006, IEEE Trans Pattern Anal Mach Intell, V28, P594; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Feller MB, 1996, SCIENCE, V272, P1182, DOI 10.1126/science.272.5265.1182; Fitzpatrick D, 2000, CURR OPIN NEUROBIOL, V10, P438, DOI 10.1016/S0959-4388(00)00113-6; Flavell J. H., 1993, COGNITIVE DEV; Flavell J. H., 2000, CHILD COGNITIVE DEV, P7; Fox MD, 2006, P NATL ACAD SCI USA, V103, P10046, DOI 10.1073/pnas.0604187103; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; Green JT, 1999, PSYCHOL SCI, V10, P19, DOI 10.1111/1467-9280.00100; Grossberg S, 2000, VISION RES, V40, P1413, DOI 10.1016/S0042-6989(99)00229-1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu FH, 1999, IEEE MICRO, V19, P70; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Itti L., 2005, NEUROBIOLOGY ATTENTI; Ji Z., 2010, P IEEE INT JOINT C N, P1; Ji ZP, 2008, INT C DEVEL LEARN, P61, DOI 10.1109/DEVLRN.2008.4640806; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256; Koch C., 2011, SCI AM           MAR, P18; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee TS, 2002, NAT NEUROSCI, V5, P589, DOI 10.1038/nn860; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; LIPPE WR, 1994, J NEUROSCI, V14, P1486; Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045; Luciw M., 2010, P IEEE INT JOINT C N, P4233; Luciw M, 2010, IEEE T AUTON MENT DE, V2, P248, DOI 10.1109/TAMD.2010.2072150; Luciw M., 2009, P IEEE 8 INT C DEV L, P1; Luciw M., 2008, P IEEE INT C DEV LEA, P1; Miikkulainen R, 2005, COMPUTATIONAL MAPS V; MINSKY M, 1991, AI MAG, V12, P34; MISHKIN M, 1983, TRENDS NEUROSCI, V6, P414, DOI 10.1016/0166-2236(83)90190-X; Miyan K., 2010, P IEEE 9 INT C DEV L, P280; O'Donovan MJ, 1999, CURR OPIN NEUROBIOL, V9, P94, DOI 10.1016/S0959-4388(99)80012-9; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700; Osherson D. N., 1990, COGNITIVE DEV, P147; PARSONS LM, 1987, COGNITIVE PSYCHOL, V19, P178, DOI 10.1016/0010-0285(87)90011-9; Piaget J., 1954, CONSTRUCTION REALITY; Purves WK, 2004, LIFE SCI BIOL; Quartz SR, 1997, BEHAV BRAIN SCI, V20, P537; Quiroga RQ, 2009, CURR BIOL, V19, P1308, DOI 10.1016/j.cub.2009.06.060; RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7; REBER AS, 1980, J EXP PSYCHOL-HUM L, V6, P492, DOI 10.1037/0278-7393.6.5.492; Riesenhuber M, 2002, CURR OPIN NEUROBIOL, V12, P162, DOI 10.1016/S0959-4388(02)00304-5; Roelfsema PR, 2005, NEURAL COMPUT, V17, P2176, DOI 10.1162/0899766054615699; Rosenbloom P. S., 1993, SOAR PAPERS; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Russell S, 2003, ARTIFICIAL INTELLIGE; Sejnowski T. J., 2006, 23 PROBLEMS SYSTEMS, P394; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sharma J, 2000, NATURE, V404, P841, DOI 10.1038/35009043; SHEPARD RN, 1971, SCIENCE, V171, P701, DOI 10.1126/science.171.3972.701; Sit YF, 2006, NEUROCOMPUTING, V69, P1309, DOI 10.1016/j.neucom.2005.12.098; Solgi M, 2009, IEEE T AUTON MENT DE, V1, P238, DOI 10.1109/TAMD.2009.2038360; Song X., 2011, P INT JOINT C NEUR N, P1; Steinmetz AB, 2009, LEARN BEHAV, V37, P349, DOI 10.3758/LB.37.4.349; Sun R., 2005, PSYCH REV, V112, P59; Sun R, 2006, J EXP THEOR ARTIF IN, V18, P169, DOI 10.1080/09528130600557713; Sur M, 2005, SCIENCE, V310, P805, DOI 10.1126/science.1112070; Sur M, 1999, J NEUROBIOL, V41, P33, DOI 10.1002/(SICI)1097-4695(199910)41:1<33::AID-NEU6>3.0.CO;2-1; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Wang Yi, 2011, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/APPEEC.2011.5749162; Weng J, 1997, INT J COMPUT VISION, V25, P109, DOI 10.1023/A:1007967800668; Weng J., 2006, P 5 INT C DEV LEARN, P1; Weng J., 2010, P INT JOINT C NEUR N, P1; Weng JY, 2009, MIND MACH, V19, P93, DOI 10.1007/s11023-008-9127-1; Weng J, 2009, P IEEE 8 INT C DEV L, P1; Weng J., 2011, P INT JOINT C NEUR N, P1; Weng J., 1992, P INT JOINT C NEUR N, V1, P576, DOI 10.1109/IJCNN.1992.287150; Weng J., 2012, IEEE T AUTON MENT DE, V3, P1; Weng JA, 2000, IEEE INTELL SYST APP, V15, P63, DOI 10.1109/5254.889108; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Weng JY, 2008, NEURAL NETWORKS, V21, P150, DOI 10.1016/j.neunet.2007.12.048; Weng JY, 2006, IEEE COMPUT INTELL M, V1, P15; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Werbos P. J., 1994, ROOTS BACKPROPAGATIO; Westermann G, 2006, TRENDS COGN SCI, V10, P227, DOI 10.1016/j.tics.2006.03.009; Wiser AK, 1996, J NEUROSCI, V16, P2724; Yao B., 2010, P COMP VIS PATT REC, P1; Yu YC, 2009, NATURE, V458, P501, DOI 10.1038/nature07722	106	3	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1943-0604			IEEE T AUTON MENT DE	IEEE Trans. Auton. Ment. Dev.	JUN	2012	4	2					161	185		10.1109/TAMD.2011.2174636		25	Computer Science, Artificial Intelligence; Robotics; Neurosciences	Computer Science; Robotics; Neurosciences & Neurology	960NT	WOS:000305395900005		
J	Zhang, YD; Salakhutdinov, R; Chang, HA; Glass, J			IEEE	Zhang, Yaodong; Salakhutdinov, Ruslan; Chang, Hung-An; Glass, James			RESOURCE CONFIGURABLE SPOKEN QUERY DETECTION USING DEEP BOLTZMANN MACHINES	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		spoken query detection; posteriorgram; Deep Boltzmann Machines		In this paper we present a spoken query detection method based on posteriorgrams generated from Deep Boltzmann Machines (DBMs). The proposed method can be deployed in both semi-supervised and unsupervised training scenarios. The DBM-based posteriorgrams were evaluated on a series of keyword spotting tasks using the TIMIT speech corpus. In unsupervised training conditions, the DBM-approach improved upon our previous best unsupervised keyword detection performance using Gaussian mixture model-based posteriorgrams by over 10%. When limited amounts of labeled data were incorporated into training, the DBM-approach required less than one third of the annotated data in order to achieve a comparable performance of a system that used all of the annotated data for training.	[Zhang, Yaodong; Chang, Hung-An; Glass, James] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Zhang, YD (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	ydzhang@csail.mit.edu; rsalakhu@utstat.toronto.edu; hung_an@csail.mit.edu; glass@csail.mit.edu					Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Garcia A, 2006, INT CONF ACOUST SPEE, P949; Hazen TJ, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P421, DOI 10.1109/ASRU.2009.5372889; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jansen A., 2010, P INTERSPEECH 2010 M, P1676; Kintzley K., 2011, P INTERSPEECH, P1905; Lin H, 2009, INT CONF ACOUST SPEE, P4877, DOI 10.1109/ICASSP.2009.4960724; Mohamed A.-R., 2009, P INT C COMP GRAPH I, P1; Salakhutdinov R., 2009, THESIS U TORONTO; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Zhang YD, 2011, INT CONF ACOUST SPEE, P5660; Zhang YD, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P398	12	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							5161	5164				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381405059		
J	Yu, D; Li, JY; Deng, L				Yu, Dong; Li, Jinyu; Deng, Li			Calibration of Confidence Measures in Speech Recognition	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Confidence calibration; confidence measure; deep belief network; distribution constraint; maximum entropy; word distribution	DISCRIMINATIVE UTTERANCE VERIFICATION; MAXIMUM-ENTROPY APPROACH; HIDDEN MARKOV-MODELS; ALGORITHM; SYSTEMS	Most speech recognition applications in use today rely heavily on confidence measure for making optimal decisions. In this paper, we aim to answer the question: what can be done to improve the quality of confidence measure if we cannot modify the speech recognition engine? The answer provided in this paper is a post-processing step called confidence calibration, which can be viewed as a special adaptation technique applied to confidence measure. Three confidence calibration methods have been developed in this work: the maximum entropy model with distribution constraints, the artificial neural network, and the deep belief network. We compare these approaches and demonstrate the importance of key features exploited: the generic confidence-score, the application-dependent word distribution, and the rule coverage ratio. We demonstrate the effectiveness of confidence calibration on a variety of tasks with significant normalized cross entropy increase and equal error rate reduction.	[Yu, Dong; Li, Jinyu; Deng, Li] Microsoft Res, Redmond, WA 98052 USA	Yu, D (reprint author), Microsoft Res, Redmond, WA 98052 USA.	dongyu@microsoft.com; jinyli@microsoft.com; deng@microsoft.com					ACERO A, 2008, P ICASSP, P5256; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Chen S.F., 1999, CMUCS99108 CARN MELL; Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452; CHIGIER B, 1992, P ICASSP92, P93, DOI 10.1109/ICASSP.1992.226112; EIDE E, 1995, P IEEE INT C AC SPEE, P221; EVERMANN G, 2000, P ICASSP, P1655; Gillick L., 1997, P IEEE INT C AC SPEE, P879; GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J; Goodman J., 2004, P HLT NAACL, P305; Guiasu S., 1985, MATH INTELLIGENCER, V7; Hillard D., 2006, P ICASSP, V1, P1153; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jiang H, 2005, SPEECH COMMUN, V45, P455, DOI 10.1016/j.specrom.2004.12.004; Kazama J, 2005, MACH LEARN, V60, P159, DOI 10.1007/s10994-005-0911-3; KAZAMA JJ, 2004, THESIS U TOKYO TOKYO; Kemp T., 1997, P EUR C SPEECH COMM, P827; MA C, 2007, P ICASSP, V4, P261; MALOUF R, 2002, P CONLL, V2, P1; Martin A, 1997, P EUROSPEECH, V4, P1895; MATHAN L., 1991, P INT C AC SPEECH SI, P93, DOI 10.1109/ICASSP.1991.150286; Mohamed A., 2009, P NIPS WORKSH DEC; Mohamed A.-R., 2010, P INT; MORENO PJ, 2001, P EUR; NETI CV, 1997, P INT C AC SPEECH SI, P883; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Och F. J., 2002, P 40 ANN M ASS COMP, P295; Rahim MG, 1997, IEEE T SPEECH AUDI P, V5, P266, DOI 10.1109/89.568733; Riedmiller M., 1993, IEEE INT C NEUR NETW, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; ROSE RC, 1995, P INT C AC SPEECH SI, P281; Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011; RUEBER BB, 1997, P EUR; Sarikaya R, 2005, IEEE T SPEECH AUDI P, V13, P534, DOI 10.1109/TSA.2005.848879; Siu MH, 1999, COMPUT SPEECH LANG, V13, P299, DOI 10.1006/csla.1999.0126; STOLCKE A, 2000, P SPEECH TRANSCR WOR; Sukkar RA, 1996, IEEE T SPEECH AUDI P, V4, P420, DOI 10.1109/89.544527; SUKKAR RA, 1994, P INT C AC SPEECH SI, P393; VANLEEUWEN D, 2006, P IEEE OD SPEAK LANG, P1; Wang Y.-Y., 2008, IEEE SIGNAL PROCESSI, V25, P28; WEINTRAUB M, 1997, P IEEE INT C AC SPEE, P887; Wessel F., 1999, P EUR C SPEECH COMM, P315; Wessel F, 2001, IEEE T SPEECH AUDI P, V9, P288, DOI 10.1109/89.906002; Wessel F, 1998, INT CONF ACOUST SPEE, P225, DOI 10.1109/ICASSP.1998.674408; WHITE C, 2007, P ICASSP, V4, P809; WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088; XUE J, 2006, P ICASSP, V1, P1149; YU D, 2010, P ICASSP, P5030; YU D, 2010, P ICASSP, P4446; YU D, 2006, P ICASSP, V1, P565; YU D, 2010, P ICASSP, P4450; Yu D, 2009, PATTERN RECOGN LETT, V30, P1295, DOI 10.1016/j.patrec.2009.06.005; Yu D, 2009, IEEE SIGNAL PROC MAG, V26, P86, DOI 10.1109/MSP.2009.932793; YU D, 2005, P ICASSP 2005, V1, P597; Yu D., 2009, P INT, P676; Yu D., 2007, P INT, P2709; Yu D, 2009, IEEE T AUDIO SPEECH, V17, P1348, DOI 10.1109/TASL.2009.2020890	57	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1558-7916			IEEE T AUDIO SPEECH	IEEE Trans. Audio Speech Lang. Process.	NOV	2011	19	8					2461	2473		10.1109/TASL.2011.2141988		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	846IH	WOS:000296889900020		
J	Khan, GM; Miller, JF; Halliday, DM				Khan, Gul Muhammad; Miller, Julian F.; Halliday, David M.			Evolution of Cartesian Genetic Programs for Development of Learning Neural Architecture	EVOLUTIONARY COMPUTATION			English	Article						Cartesian genetic programming (CGP); artificial neural networks; coevolution; generative and developmental approaches; learning and memory	DEPENDENT SYNAPTIC PLASTICITY; COMPETITIVE COEVOLUTION; ARMS RACES; NETWORKS; ROBOTS; NEURONS; SYNAPSES; BEHAVIOR; SYSTEMS	Although artificial neural networks have taken their inspiration from natural neurological systems, they have largely ignored the genetic basis of neural functions. Indeed, evolutionary approaches have mainly assumed that neural learning is associated with the adjustment of synaptic weights. The goal of this paper is to use evolutionary approaches to find suitable computational functions that are analogous to natural sub-components of biological neurons and demonstrate that intelligent behavior can be produced as a result of this additional biological plausibility. Our model allows neurons, dendrites, and axon branches to grow or die so that synaptic morphology can change and affect information processing while solving a computational problem. The compartmental model of a neuron consists of a collection of seven chromosomes encoding distinct computational functions inside the neuron. Since the equivalent computational functions of neural components are very complex and in some cases unknown, we have used a form of genetic programming known as Cartesian genetic programming (CGP) to obtain these functions. We start with a small random network of soma, dendrites, and neurites that develops during problem solving by repeatedly executing the seven chromosomal programs that have been found by evolution. We have evaluated the learning potential of this system in the context of a well-known single agent learning problem, known as Wumpus World. We also examined the harder problem of learning in a competitive environment for two antagonistic agents, in which both agents are controlled by independent CGP computational networks (CGPCN). Our results show that the agents exhibit interesting learning capabilities.	[Khan, Gul Muhammad] NWFP UET Peshawar, Dept Elect Engn, Peshawar, Pakistan; [Miller, Julian F.; Halliday, David M.] Univ York, Dept Elect, York YO10 5DD, N Yorkshire, England	Khan, GM (reprint author), NWFP UET Peshawar, Dept Elect Engn, Peshawar, Pakistan.	gk502@nwfpuet.edu.pk; jfm7@ohm.york.ac.uk; dh20@ohm.york.ac.uk	Halliday, David/A-3848-2009	Halliday, David/0000-0001-9957-0983			Alberts B, 2002, MOL BIOL CELL; Arel I., 2009, P NIPS 2009 WORKSH D; Becerra JA, 2002, LECT NOTES COMPUT SC, V2415, P837; Blynel J., 2002, ANIMALS ANIMATS, P272; BOERS EJW, 1992, THESIS LEIDEN U; CANGELOSI A, 1994, NETWORK-COMP NEURAL, V5, P497, DOI 10.1088/0954-898X/5/4/005; CHALUP SK, 2001, P 5 BIANN C ART NEUR, P40; CHEN X, 1982, IEEE T COMPUT, V31, P140; Cunningham P, 2000, ARTIF INTELL MED, V20, P217, DOI 10.1016/S0933-3657(00)00065-8; DALAERT E, 1994, P 4 C ART LIF; DAWKINS R, 1979, PROC R SOC SER B-BIO, V205, P489, DOI 10.1098/rspb.1979.0081; Debanne D, 2003, J PHYSIOLOGY-PARIS, V97, P403, DOI 10.1016/j.jphysparis.2004.01.004; Downing KL, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P990; FEDERICI D, 2005, P CEC 2005 IEEE C EV, P543; Floreano D, 2000, NEURAL NETWORKS, V13, P431, DOI 10.1016/S0893-6080(00)00032-0; Frey U, 1997, NATURE, V385, P533, DOI 10.1038/385533a0; Gaiarsa JL, 2002, TRENDS NEUROSCI, V25, P564, DOI 10.1016/S0166-2236(02)02269-5; George D., 2005, P INT JOINT C NEUR N, V3, P1812, DOI DOI 10.1109/IJCNN.2005.1556155; Graham B, 2002, LECT NOTES COMPUT SC, V2415, P45; GRUAU F, 1994, ADAPT BEHAV, V3, P151, DOI 10.1177/105971239400300202; Harding S, 2010, GENET PROGRAM EVOL M, V11, P397, DOI 10.1007/s10710-010-9114-1; Hebb DO, 1949, ORG BEHAV; HILLIS WD, 1990, PHYSICA D, V42, P228, DOI 10.1016/0167-2789(90)90076-2; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hornby GS, 2003, IEEE T ROBOTIC AUTOM, V19, P703, DOI 10.1109/TRA.2003.814502; Jakobi N., 1995, 423 COGS U SUSS; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; Kleim JA, 1998, NEUROBIOL LEARN MEM, V69, P274, DOI 10.1006/nlme.1998.3827; Koch C, 2000, NAT NEUROSCI, V3, P1171, DOI 10.1038/81444; Koza J.R., 1992, GENETIC PROGRAMMING; Kumar S., 2003, GROWTH FORM COMPUTER; LINDENMA.A, 1968, J THEOR BIOL, V18, P280, DOI 10.1016/0022-5193(68)90079-9; London M, 2005, ANNU REV NEUROSCI, V28, P503, DOI 10.1146/annurev.neuro.28.061604.135703; MALENKA RC, 1994, CELL, V78, P535, DOI 10.1016/0092-8674(94)90517-7; Marcus Gary F., 2004, BIRTH MIND; Marcus GF, 2001, LECT NOTES ARTIF INT, V2036, P368; McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109; Miller JF, 2004, LECT NOTES COMPUT SC, V3102, P129; Miller J. F., 1997, GENETIC ALGORITHMS E, P105; Miller JF, 2000, LECT NOTES COMPUT SC, V1802, P121; Miller JF, 2006, IEEE T EVOLUT COMPUT, V10, P167, DOI 10.1109/TEVC.2006.871253; MILLER JF, 2000, GENETIC PROGRAMMING, P7; Nguyen QT, 1996, CURR OPIN NEUROBIOL, V6, P104, DOI 10.1016/S0959-4388(96)80015-8; Nolfi S, 1998, ARTIF LIFE, V4, P311, DOI 10.1162/106454698568620; Nolfi S., 1994, Proceedings. From Perception to Action Conference, DOI 10.1109/FPA.1994.636092; Panchev C, 2002, LECT NOTES COMPUT SC, V2415, P896; Paredis Jan, 1996, Artificial Life, V2, P355, DOI 10.1162/artl.1995.2.4.355; Parisi D, 1997, BRAIN COGNITION, V34, P160, DOI 10.1006/brcg.1997.0911; PARISI D, 2001, ADV EVOLUTIONARY SYN; Penn AA, 1999, PEDIATR RES, V45, P447, DOI 10.1203/00006450-199904010-00001; Quartz SR, 1997, BEHAV BRAIN SCI, V20, P537; Ratcliff R., 1990, PSYCHOL REV, V97, P205, DOI [10.1037/0033-295X.97.2.285, DOI 10.1037/0033-295X.97.2.285]; Risi S, 2010, ADAPT BEHAV, V18, P470, DOI 10.1177/1059712310379923; Roberts PD, 2002, BIOL CYBERN, V87, P392, DOI 10.1007/s00422-002-0361-y; Roggen D, 2007, GENET PROGRAM EVOL M, V8, P61, DOI 10.1007/s10710-006-9019-1; Rose S, 2003, MAKING MEMORY MOL MI; Rosin CD, 1997, EVOL COMPUT, V5, P1, DOI 10.1162/evco.1997.5.1.1; Russell S., 1995, ARTIFICIAL INTELLIGE; RUST AG, 1997, P 4 EUR C ART LIF EC, P224; RUST AG, 2000, P ALIFE7, P146; RUST AG, 1999, P 9 INT C ART NEUR N, V1, P383; Shepherd G., 1990, SYNAPTIC ORG BRAIN; Sims K., 1994, ARTIF LIFE, P28; Smythies J, 2002, DYNAMIC NEURON; Soltoggio A., 2008, ARTIF LIFE, VXI, P569; Song S, 2000, NAT NEUROSCI, V3, P919; Spector L., 1996, ADV GENETIC PROGRAMM, V2, P137; Spector L., 1996, Genetic Programming. Proceedings of the First Annual Conference 1996; Stanley KO, 2004, J ARTIF INTELL RES, V21, P63; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; STUART G, 2001, ITERATIVE BROADENING; SUTSKEVER I, 2006, LEARNING MULTILEVEL; Taylor GW, 2006, ADV NEURAL INFORM PR, P1345; Terje L., 2003, PHILOS T R SOC B, V358, P617, DOI [10.1098/rstb.2002.1226, DOI 10.1098/RSTB.2002.1226]; TRAUB RD, 1977, BIOL CYBERN, V25, P163, DOI 10.1007/BF00365213; Urzelai J, 2001, EVOL COMPUT, V9, P495, DOI 10.1162/10636560152642887; VANOOYEN A, 1994, J THEOR BIOL, V167, P27, DOI 10.1006/jtbi.1994.1047; van Rossum MCW, 2000, J NEUROSCI, V20, P8812; VANVALEN LM, 1973, EVOL THEORY, V1, P130; Vassilev VK, 2000, LECT NOTES COMPUT SC, V1801, P252; YAMAUCHI B, 1994, ANIMALS ANIMATS, V3, P382; YOB G, 1975, CREATIVE COMPUT, V5, P51; YU T, 2001, P 4 EUR C GEN PROGR, P204	83	3	3	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	1063-6560	1530-9304		EVOL COMPUT	Evol. Comput.	FAL	2011	19	3					469	523				55	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	807BV	WOS:000293869300005	21591889	
J	Cecotti, H				Cecotti, Hubert			A time-frequency convolutional neural network for the offline classification of steady-state visual evoked potential responses	PATTERN RECOGNITION LETTERS			English	Article						Neural network; Convolution; Fourier transform; Spatial filters; Steady-state visual evoked potential (SSVEP) Electroencephalogram (EEG)	BRAIN-COMPUTER INTERFACES; SINGLE-TRIAL EEG; COMMUNICATION; BCI	A new convolutional neural network architecture is presented. It includes the fast Fourier transform between two hidden layers to switch the signal analysis from the time domain to the frequency domain inside the network. This technique allows the signal classification without any special pre-processing and uses knowledge from the problem in the network topology. The first step allows the creation of different spatial and time filters. The second step is dedicated to the signal transformation in the frequency domain. The last step is the classification. The system is tested offline on the classification of EEG signals that contain steady-state visual evoked potential (SSVEP) responses. The mean recognition rate of the classification of five different types of SSVEP response is 95.61% on a time segment length of 1 s. The proposed strategy outperforms other classical neural network architecures. (C) 2011 Elsevier B.V. All rights reserved.	[Cecotti, Hubert] Univ Bremen, Inst Automat IAT, D-28359 Bremen, Germany	Cecotti, H (reprint author), Univ Calif Santa Barbara, Dept Psychol, Santa Barbara, CA 93106 USA.	hub20xx@hotmail.com			European Community [MTKD-CT-2004-014211]	This research was supported by a Marie Curie European Transfer of Knowledge grant BrainRobot, MTKD-CT-2004-014211, within the 6th European Community Framework Program. The data were collected at the Institute of Automation, University of Bremen, Bremen, Germany.	ANDERSON CW, 1995, IEEE WORKSH NEUR NET, P475; Barreto AB, 1996, PROCEEDINGS OF THE 1996 FIFTEENTH SOUTHERN BIOMEDICAL ENGINEERING CONFERENCE, P73, DOI 10.1109/SBEC.1996.493116; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI [10.1109/MSP.2008.4408441, 10.1109/MSP.200790.900,9]; Blankertz B, 2008, ADV NEURAL INFORM PR, V20; Blankertz B, 2002, ADV NEUR IN, V14, P157; Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P147, DOI 10.1109/TNSRE.2006.875557; Brunner C, 2007, PATTERN RECOGN LETT, V28, P957, DOI 10.1016/j.patrec.2007.01.002; Burkitt GR, 2000, CLIN NEUROPHYSIOL, V111, P246, DOI 10.1016/S1388-2457(99)00194-7; Cecotti H., 2008, P 19 INT C PATT REC; Chatrian G. E., 1985, American Journal of EEG Technology, V25; FELZER T, 2003, IEEE T NEURAL SYSTEM, V11; Friman O, 2007, IEEE T BIO-MED ENG, V54, P742, DOI 10.1109/TBME.2006.889160; Haselsteiner E, 2000, IEEE T REHABIL ENG, V8, P457, DOI 10.1109/86.895948; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, NEURAL NETWORKS TRIC; Lecun Y., 2004, P CVPR 04; Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/R01; Luth T., 2007, ICORR 2007 IEEE 10 I, P721; Martinez P., 2007, COMPUT INTELL NEUROS; MASIC N, 1995, NEUROCOMPUTING, V7, P259, DOI 10.1016/0925-2312(95)00025-2; MEUTH RJ, 2007, P INT JOINT C NEUR N; Muller KR, 2008, J NEUROSCI METH, V167, P82, DOI 10.1016/j.jneumeth.2007.09.022; Muller-Putz GR, 2008, IEEE T BIO-MED ENG, V55, P361, DOI 10.1109/TBME.2007.897815; Müller-Putz Gernot R, 2005, J Neural Eng, V2, P123, DOI 10.1088/1741-2560/2/4/008; Obermaier B, 2001, PATTERN RECOGN LETT, V22, P1299, DOI 10.1016/S0167-8655(01)00075-7; PFURTSCHELLER G, 1999, INT WORK C ART NAT N, V2, P248; Rakotomarnonjy A, 2008, IEEE T BIO-MED ENG, V55, P1147, DOI 10.1109/TBME.2008.915728; Sejnowski T. J., 2007, BRAIN COMPUTER INTER; Simard PY, 2003, SEVENTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P958; TOMIOKA R, 2006, WORKSH INF BAS IND S, P6; Trejo L., 2006, IEEE T NEURAL SYSTEM, V14; Wang Yijun, 2006, IEEE T NEURAL SYSTEM, V14; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; Zhong S., 2002, P IEEE INT JOINT C N, V2, P1154	37	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN 1	2011	32	8					1145	1153		10.1016/j.patrec.2011.02.022		9	Computer Science, Artificial Intelligence	Computer Science	765YK	WOS:000290745100008		
J	Sarikaya, R; Hinton, GE; Ramabhadran, B			IEEE	Sarikaya, Ruhi; Hinton, Geoffrey E.; Ramabhadran, Bhuvana			DEEP BELIEF NETS FOR NATURAL LANGUAGE CALL-ROUTING	2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 22-27, 2011	Prague, CZECH REPUBLIC	Inst Elect & Elect Engineers Signal Processing Soc, IEEE	Prague Congress Ctr	Call-Routing; Deep Learning; DBN; RBM		This paper considers application of Deep Belief Nets (DBNs) to natural language call routing. DBNs have been successfully applied to a number of tasks, including image, audio and speech classification, thanks to the recent discovery of an efficient learning technique. DBNs learn a multi-layer generative model from unlabeled data and the features discovered by this model are then used to initialize a feed-forward neural network which is fine-tuned with backpropagation. We compare a DBN-initialized neural network to three widely used text classification algorithms; Support Vector machines (SVM), Boosting and Maximum Entropy (MaxEnt). The DBN-based model gives a call-routing classification accuracy that is equal to the best of the other models even though it currently uses an impoverished representation of the input.	[Sarikaya, Ruhi] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Sarikaya, R (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	sarikaya@us.ibm.com; hinton@cs.toronto.edu; bhuvana@us.ibm.com					Chen S., 2001, IEEE T SAP, V8, P37; Dahl G., 2010, ADV NEURAL INFORM PR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton G. E., 2002, NEURAL COMPUT, V14, P1527; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 2010003 UTML; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ng A. Y., 2002, ADV NEURAL INFORM PR, V11; Pietra S. D., 1997, IEEE T PATTERN ANAL, V19, P380; SALAKHUTDINOV RR, 2007, ADV NEURAL INFORM PR, V22; SARIKAYA R, 2005, P INT LISB PORT SEPT; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Vapnik V. N., 1995, NATURE STAT LEARNING; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	16	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4577-0539-7	INT CONF ACOUST SPEE			2011							5680	5683				4	Acoustics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Engineering; Imaging Science & Photographic Technology	BXG36	WOS:000296062406097		
J	Cho, YM; Saul, LK				Cho, Youngmin; Saul, Lawrence K.			Large-Margin Classification in Infinite Neural Networks	NEURAL COMPUTATION			English	Article								We introduce a new family of positive-definite kernels for large margin classification in support vector machines (SVMs). These kernels mimic the computation in large neural networks with one layer of hidden units. We also show how to derive new kernels, by recursive composition, that may be viewed as mapping their inputs through a series of nonlinear feature spaces. These recursively derived kernels mimic the computation in deep networks with multiple hidden layers. We evaluate SVMs with these kernels on problems designed to illustrate the advantages of deep architectures. Compared to previous benchmarks, we find that on some problems, these SVMs yield state-of-the-art results, beating not only other SVMs but also deep belief nets.	[Cho, Youngmin; Saul, Lawrence K.] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA	Cho, YM (reprint author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.	yoc002@cs.ucsd.edu; saul@cs.ucsd.edu			National Science Foundation [0957560]	This work was supported by award number 0957560 from the National Science Foundation. We are tremendously grateful to the reviewers, whose many knowledgeable comments and thoughtful suggestions helped to improve all parts of this letter. We also benefited from many personal discussions at a Gatsby Unit workshop on deep learning.	Bach F., 2009, ADV NEURAL INFORM PR, V21, P105; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P123; Bengio Y., 2007, SCALING LEARNING ALG; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Carrier GF, 2005, CLASS APPL MATH, V49, P1, DOI 10.1137/1.9780898719116; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cho Y., 2009, ADV NEURAL INFORM PR, V22, P342; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; Cristianini N., 2000, INTRO SUPPORT VECTOR; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Hahnloser RHR, 2003, NEURAL COMPUT, V15, P621, DOI 10.1162/089976603321192103; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LeCun Y., 1998, MNIST DATABASE HANDW; Lee WS, 1996, IEEE T INFORM THEORY, V42, P2118; Neal R. M., 1996, BAYESIAN LEARNING NE; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435; PRICE R, 1958, IRE T INFORM THEOR, V4, P69, DOI 10.1109/TIT.1958.1057444; Rahimi A., 2009, ADV NEURAL INFORM PR, V21, P1313; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Scholkopf B., 2001, LEARNING KERNELS SUP; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHOLKOPF B, 1996, 44 MAX PLANCK I BIOL; WATKIN TLH, 1993, REV MOD PHYS, V65, P499, DOI 10.1103/RevModPhys.65.499; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; Williams CKI, 1998, NEURAL COMPUT, V10, P1203, DOI 10.1162/089976698300017412; Zhang T, 2003, IEEE T INFORM THEORY, V49, P682, DOI 10.1109/TIT.2002.808136	35	3	3	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	OCT	2010	22	10					2678	2697		10.1162/NECO_a_00018		20	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	645ID	WOS:000281445100010	20608866	
J	Rodrigues, R		Murray, A		Rodrigues, Rui			Filling in the Gap: a General Method Using Neural Networks	COMPUTING IN CARDIOLOGY 2010, VOL 37	Computers in Cardiology Series		English	Proceedings Paper	37th Annual Conference of the Computing-in-Cardiology	SEP 26-29, 2010	Belfast, NORTH IRELAND	Comp Cardiol, EMB, IEEE, Univ Ulster, Medtronic, HeartSine, Drager, GE Healthcare, Mortara, Univ Rochester, Telemetr & Holter ECG Warehouse Project, Zoll, Inst Phys, IBM				When a set of medical signals has redundant information, it is sometimes possible to recover one signal, from its past and the information provided by the other signals. In this work, we present a general method to realize that task. It has been known for a long time that multilayered networks are universal approximators, but, even with the backprop algorithm, it was not possible to train such a network, to realize complex real life tasks. In the last years, Geoffrey Hinton presented a training strategy that allows to overcome the previous difficulties. We describe a way of adapting Hinton's strategy to our task. An example of a situation considered here, consists on training a Multilayered perceptron to take ECG leads II and I as input and produce as output missing lead V. This method got the best scores among participants in the Physionet/ Computing in Cardiology Challenge 2010.	Fac Ciencias & Tecnol, Dep Matemat, P-2829516 Caparica, Portugal	Rodrigues, R (reprint author), Fac Ciencias & Tecnol, Dep Matemat, P-2829516 Caparica, Portugal.	rapr@fct.unl.pt					Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Carreira-Perpinan M. A., 2005, ARTIF INTELL, P33; Goldberger AL, 2000, CIRCULATION, V101, pE215; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton G.E., 2007, SCHOLARPEDIA, V2, P1668; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 1983, COMPUTATIONAL NEUROS, P400; Moody GB, 2010, COMPUTING C IN PRESS, V37	11	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0276-6574		978-1-4244-7318-2	COMPUT CARDIOL			2010	37						453	456				4	Cardiac & Cardiovascular Systems; Engineering, Biomedical; Mathematical & Computational Biology	Cardiovascular System & Cardiology; Engineering; Mathematical & Computational Biology	BJL83	WOS:000328956000114		
J	Bengio, Y		Cisek, P; Drew, T; Kalaska, JF		Bengio, Yoshua			On the challenge of learning complex functions	COMPUTATIONAL NEUROSCIENCE: THEORETICAL INSIGHTS INTO BRAIN FUNCTION	Progress in Brain Research		English	Review; Book Chapter						theory of learning algorithms; artificial intelligence; template matching; deep neural networks; kernel machines; deep belief networks; multi-layer neural networks; learning abstractions	LONG-TERM DEPENDENCIES; NEURAL-NETWORKS	A common goal of computational neuroscience and of artificial intelligence research based on statistical learning algorithms is the discovery and understanding of computational principles that could explain what we consider adaptive intelligence, in animals as well as in machines. This chapter focuses on what is required for the learning of complex behaviors. We believe it involves the learning of highly varying functions, in a mathematical sense. We bring forward two types of arguments which convey the message that many currently popular machine learning approaches to learning flexible functions have fundamental limitations that render them inappropriate for learning highly varying functions. The first issue concerns the representation of such functions with what we call shallow model architectures. We discuss limitations of shallow architectures, such as so-called kernel machines, boosting algorithms, and one-hidden-layer artificial neural networks. The second issue is more focused and concerns kernel machines with a local kernel (the type used most often in practice) that act like a collection of template-matching units. We present mathematical results on such computational architectures showing that they have a limitation similar to those already proved for older non-parametric methods, and connected to the so-called curse of dimensionality. Though it has long been believed that efficient learning in deep architectures is difficult, recently proposed computational principles for learning in deep architectures may offer a breakthrough.	Univ Montreal, Dept IRO, Downtown Branch, Montreal, PQ H3C 3J7, Canada	Bengio, Y (reprint author), Univ Montreal, Dept IRO, Downtown Branch, POB 6128, Montreal, PQ H3C 3J7, Canada.	bengioy@iro.umontreal.ca					AJTAI M, 1983, ANN PURE APPL LOGIC, V24, P48; Allender E., 1996, LECT NOTES COMPUTER, V1180, P1; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P107; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Bengio Y., 2006, ADV NEURAL INFORM PR, V18, P123; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; BENGIO Y, 1995, J ARTIFICIAL INTELLI, V3, P223; Bishop CM, 2006, PATTERN RECOGNITION; Boser B., 1992, 5 ANN ACM WORKSH COL, P144; COHN D, 1995, ADV NEURAL INFORM PR, V7; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Duda R, 2001, PATTERN CLASSIFICATI; ElHihi S, 1996, ADV NEUR IN, V8, P493; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FUKUMIZU K, 1996, ADV NEURAL INFORM PR, V8; Guillery RW, 2005, TRENDS NEUROSCI, V28, P512, DOI 10.1016/j.tins.2005.08.006; HASTAD JOHAN, 1987, COMPUTATIONAL LIMITA; Hastie T., 2001, ELEMENTS STAT LEARNI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jordan M. I., 1998, LEARNING GRAPHICAL M; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Minsky M, 1969, PERCEPTRONS; Piaget J, 1952, ORIGINS INTELLIGENCE; Ranzato M. A., 2006, ADV NEURAL INFORM PR; Rosenblatt F., 1957, 854601 CORN AER LAB; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schmitt M, 2002, NEURAL COMPUT, V14, P2997, DOI 10.1162/089976602760805386; SCHOKOPF B, 1999, ADV KERNEL METHODS S; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319; Vapnik V., 1998, LECT NOTES EC MATH S, V454; Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341	35	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0079-6123		978-0-444-52823-0	PROG BRAIN RES	Prog. Brain Res.		2007	165						521	534		10.1016/S0079-6123(06)65033-4		14	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	BQC07	WOS:000280608900034	17925268	
J	Schuld, M; Sinayskiy, I; Petruccione, F				Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco			An introduction to quantum machine learning	CONTEMPORARY PHYSICS			English	Article						quantum machine learning; quantum computing; artificial intelligence; machine learning	NEURAL-NETWORKS; INFORMATION	Machine learning algorithms learn a desired input-output relation from examples in order to interpret new inputs. This is important for tasks such as image and speech recognition or strategy optimisation, with growing applications in the IT industry. In the last couple of years, researchers investigated if quantum computing can help to improve classical machine learning algorithms. Ideas range from running computationally costly algorithms or their subroutines efficiently on a quantum computer to the translation of stochastic methods into the language of quantum theory. This contribution gives a systematic overview of the emerging field of quantum machine learning. It presents the approaches as well as technical details in an accessible way, and discusses the potential of a future theory of quantum learning.	[Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco] Univ KwaZulu Natal, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Durban, South Africa; [Sinayskiy, Ilya; Petruccione, Francesco] Natl Inst Theoret Phys NITheP, Kwa Zulu, South Africa	Schuld, M (reprint author), Univ KwaZulu Natal, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Durban, South Africa.	schuld@ukzn.ac.za			South African Research Chair Initiative of the Department of Science and Technology; National Research Foundation	This work was supported by the South African Research Chair Initiative of the Department of Science and Technology and the National Research Foundation.	Aimeur E, 2013, MACH LEARN, V90, P261, DOI 10.1007/s10994-012-5316-5; Aimeur E, 2006, LECT NOTES ARTIF INT, V4013, P431; Alpaydin E, 2004, INTRO MACHINE LEARNI; Barry J, 2014, PHYS REV A, V90, DOI 10.1103/PhysRevA.90.032311; Behrman E. C., 2013, IEEE S SER COMP INT; Bishop Christopher M., 2006, PATTERN RECOGNITION, V1; Bisio A, 2010, PHYS REV A, V81, DOI 10.1103/PhysRevA.81.032324; Brassard G., 2000, ARXIVQUANTPH0005055; Breuer H. P., 2002, THEORY OPEN QUANTUM; Briegel H. J., 2012, SCI REP, V2, P1; Buhrman H, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.167902; Clark L. A., 2015, ISCS 2014, V14, P143; Dayan P., 2001, THEORETICAL NEUROSCI, V31; Du JF, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.137902; Duda R.O., 2012, PATTERN CLASSIFICATI; Durr C., 1996, QUANTPH9607014 ARXIV; Eisert J, 1999, PHYS REV LETT, V83, P3077, DOI 10.1103/PhysRevLett.83.3077; Faber J., 2002, QUANTUM MODELS ARTIF; Gammelmark S., 2009, NEW J PHYS, V11; Gammelmark S, 2013, PHYS REV A, V87, DOI 10.1103/PhysRevA.87.032115; Georgescu IM, 2014, REV MOD PHYS, V86, DOI 10.1103/RevModPhys.86.153; Giovannetti V, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.160501; Gu M., 2010, NEW J PHYS, V12; Gupta S, 2001, J COMPUT SYST SCI, V63, P355, DOI 10.1006/jcss.2001.1769; HAMMING RW, 1950, AT&T TECH J, V29, P147; Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502; Hechenbichler K., 2004, 399 SFB LUDW MAX U; Hentschel A, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.063603; Hertz J, 1991, INTRO THEORY NEURAL, V1; Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Horn D, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.018702; Hunziker M, 2010, QUANTUM INF PROCESS, V9, P321, DOI 10.1007/s11128-009-0129-6; Landsburg S.E., 2011, WILEY ENCY OPERATION; Lloyd S., 2013, ARXIV13070411; Lu SF, 2014, QUANTUM INF PROCESS, V13, P757, DOI 10.1007/s11128-013-0687-5; Monras A., 2010, APPL MATH COMPUT SCI, V3, P93; Neigovzen R, 2009, PHYS REV A, V79, DOI 10.1103/PhysRevA.79.042321; Neven H., 2009, ARXIV09120779; Nielsen M. A., 2010, QUANTUM COMPUTATION; Panella M, 2011, INT J CIRC THEOR APP, V39, P61, DOI 10.1002/cta.619; Piotrowski EW, 2003, INT J THEOR PHYS, V42, P1089, DOI 10.1023/A:1025443111388; Plenio MB, 2001, CONTEMP PHYS, V42, P25, DOI 10.1080/00107510010018916; Pudenz KL, 2013, QUANTUM INF PROCESS, V12, P2027, DOI 10.1007/s11128-012-0506-4; Purushothaman G, 1997, IEEE T NEURAL NETWOR, V8, P679, DOI 10.1109/72.572106; Rabbiner L. R., 1989, P IEEE, V77, P257; Rebentrost P, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.130503; Rigatos GG, 2007, INTEGR COMPUT-AID E, V14, P225; Rogers S., 2012, 1 COURSE MACHINE LEA; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russell S. J., 2010, ARTIFICIAL INTELLIGE, V3; Samuel A. L., 2000, IBM Journal of Research and Development, V44; Sasaki M, 2002, PHYS REV A, V66, DOI 10.1103/PhysRevA.66.022303; Sasaki M, 2001, PHYS REV A, V64, part. no., DOI 10.1103/PhysRevA.64.022317; Schuld M, 2014, QUANTUM INF PROCESS, V13, P2567, DOI 10.1007/s11128-014-0809-8; Schutzhold R, 2003, PHYS REV A, V67, DOI 10.1103/PhysRevA.67.062311; Sentis G., 2012, SCI REP, V2, P1; Silvada A. J., 2012, NEUROCOMPUTING, V75, P52; Toth G, 1996, SUPERLATTICE MICROST, V20, P473, DOI 10.1006/spmi.1996.0104; Trugenberger CA, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.067901; Trugenberger CA, 2002, QUANTUM INF PROCESS, V1, P471, DOI 10.1023/A:1024022632303; Ventura D, 2000, INFORM SCIENCES, V124, P273, DOI 10.1016/S0020-0255(99)00101-2; Wiebe N, 2014, PHYS REV A, V89, DOI 10.1103/PhysRevA.89.042314; Wiebe N., 2014, ARXIV14012142; Wiesner K, 2008, PHYSICA D, V237, P1173, DOI 10.1016/j.physd.2008.01.021	66	2	2	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0010-7514	1366-5812		CONTEMP PHYS	Contemp. Phys.	APR 3	2015	56	2					172	185		10.1080/00107514.2014.964942		14	Physics, Multidisciplinary	Physics	CH0OW	WOS:000353722300005		
J	Suk, HI; Lee, SW; Shen, DG				Suk, Heung-Il; Lee, Seong-Whan; Shen, Dinggang		Alzheimer's Dis Neuroimaging	Latent feature representation with stacked auto-encoder for AD/MCI diagnosis	BRAIN STRUCTURE & FUNCTION			English	Article						Alzheimer's disease (AD); Mild cognitive impairment (MCI); Multi-modal classification; Deep learning; Latent feature representation	MILD COGNITIVE IMPAIRMENT; POSITRON-EMISSION-TOMOGRAPHY; TEMPORAL-LOBE ATROPHY; MR BRAIN IMAGES; ALZHEIMERS-DISEASE; FUNCTIONAL CONNECTIVITY; NEURAL-NETWORKS; REGISTRATION; CLASSIFICATION; SEGMENTATION	Recently, there have been great interests for computer-aided diagnosis of Alzheimer's disease (AD) and its prodromal stage, mild cognitive impairment (MCI). Unlike the previous methods that considered simple low-level features such as gray matter tissue volumes from MRI, and mean signal intensities from PET, in this paper, we propose a deep learning-based latent feature representation with a stacked auto-encoder (SAE). We believe that there exist latent non-linear complicated patterns inherent in the low-level features such as relations among features. Combining the latent information with the original features helps build a robust model in AD/MCI classification, with high diagnostic accuracy. Furthermore, thanks to the unsupervised characteristic of the pre-training in deep learning, we can benefit from the target-unrelated samples to initialize parameters of SAE, thus finding optimal parameters in fine-tuning with the target-related samples, and further enhancing the classification performances across four binary classification problems: AD vs. healthy normal control (HC), MCI vs. HC, AD vs. MCI, and MCI converter (MCI-C) vs. MCI non-converter (MCI-NC). In our experiments on ADNI dataset, we validated the effectiveness of the proposed method, showing the accuracies of 98.8, 90.7, 83.7, and 83.3 % for AD/HC, MCI/HC, AD/MCI, and MCI-C/MCI-NC classification, respectively. We believe that deep learning can shed new light on the neuroimaging data analysis, and our work presented the applicability of this method to brain disease diagnosis.	[Suk, Heung-Il; Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA; [Suk, Heung-Il; Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA; [Lee, Seong-Whan; Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea	Shen, DG (reprint author), Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.	hsuk@med.unc.edu; dgshen@med.unc.edu			NIH [EB006733, EB008374, EB009634, AG041721, MH100217, AG042599]; National Research Foundation - Korean government [2012-005741]	This work was supported in part by NIH grants EB006733, EB008374, EB009634, AG041721, MH100217, and AG042599, and also by the National Research Foundation grant (No. 2012-005741) funded by the Korean government.	Alzheimer's Association, 2012, ALZHEIMERS DEMENT, V8, P131, DOI DOI 10.1016/J.JALZ.2012.02.001; Aston JAD, 2002, J CEREBR BLOOD F MET, V22, P1019; Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bokde ALW, 2006, BRAIN, V129, P1113, DOI 10.1093/brain/awl051; BRAAK H, 1991, ACTA NEUROPATHOL, V82, P239; Buckner RL, 2005, J NEUROSCI, V25, P7709, DOI 10.1523/JNEUROSCI.2177-05.2005; Burton EJ, 2009, BRAIN, V132, P195, DOI 10.1093/brain/awn298; Collins DL, 1997, INT J PATTERN RECOGN, V11, P1271, DOI 10.1142/S0218001497000597; Copenhaver BR, 2006, PSYCHIAT RES-NEUROIM, V147, P93, DOI 10.1016/j.pscychresns.2006.01.015; Cui Y, 2011, PLOS ONE, V6, P896; Cui Y, 2011, PLOS ONE, V6, pe21; Dai WY, 2009, RADIOLOGY, V250, P856, DOI 10.1148/radiol.2503080751; Davatzikos C, 2011, NEUROBIOL AGING, V32, DOI DOI 10.1016/J.NEUROBIOLAGING.2010.05.023; Desikan RS, 2009, BRAIN, V132, P2048, DOI 10.1093/brain/awp123; Devanand DP, 2007, NEUROLOGY, V68, P828, DOI 10.1212/01.wnl.0000256697.20968.d7; Dickerson BC, 2009, CEREB CORTEX, V19, P497, DOI 10.1093/cercor/bhn113; Erhan D, 2010, J MACH LEARN RES, V11, P625; Ewers M, 2012, NEUROBIOL AGING, V33, P1203, DOI 10.1016/j.neurobiolaging.2010.10.019; Fan Y, 2007, NEUROIMAGE, V36, P1189, DOI 10.1016/j.neuroimage.2007.04.009; FRISTON KJ, 1995, HUMAN BRAIN MAPPING, V2, P165; Fukushima K., 1980, BIOL CYBERN, V36, P93; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Gray KR, 2013, NEUROIMAGE, V65, P167, DOI 10.1016/j.neuroimage.2012.09.065; Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101; Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243; Hinrichs C, 2011, NEUROIMAGE, V55, P574, DOI 10.1016/j.neuroimage.2010.10.081; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jia HJ, 2010, NEUROIMAGE, V51, P1057, DOI 10.1016/j.neuroimage.2010.03.010; Kabani N.J., 1998, NEUROIMAGE, V7, pS717; Kloppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319; Kohannim O, 2010, NEUROBIOL AGING, V31, P1429, DOI 10.1016/j.neurobiolaging.2010.04.022; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee ACH, 2006, J NEUROSCI, V26, P5198, DOI 10.1523/JNEUROSCI.3157-05.2006; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Li Y, 2012, NEUROBIOL AGING, V33, DOI [DOI 10.1016/J.NEUROBIOLAGING.2010.11.008, 10.1016/j.neurobiolaging.2010.11.008]; Liu F, 2013, LECT NOTES COMPUT SC, V8150, P311; Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055; Loewenstein DA, 2012, ALZHEIMERS DEMENT, V8, P172, DOI 10.1016/j.jalz.2011.03.002; Mark R.E., 2013, REV CLIN GERONTOL, V23, P61; Mosconi L, 2008, J NUCL MED, V49, P390, DOI 10.2967/jnumed.107.045385; Nettiksimmons J, 2010, NEUROBIOL AGING, V31, P1419, DOI 10.1016/j.neurobiolaging.2010.04.025; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Nobili F, 2010, J ALZHEIMERS DIS, V22, P993, DOI 10.3233/JAD-2010-100423; Nordberg A, 2010, NAT REV NEUROL, V6, P78, DOI 10.1038/nrneurol.2009.217; Perrin RJ, 2009, NATURE, V461, P916, DOI 10.1038/nature08538; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Schroeter ML, 2009, NEUROIMAGE, V47, P1196, DOI 10.1016/j.neuroimage.2009.05.037; Serre T, 2005, PROC CVPR IEEE, P994; Shen DG, 1999, IMAGE VISION COMPUT, V17, P489, DOI 10.1016/S0262-8856(98)00141-3; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277; Singh V, 2006, BRAIN, V129, P2885, DOI 10.1093/brain/awl256; Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; Suk HI, 2013, LECT NOTES COMPUT SC, V8184, P131; Suk HI, 2013, IEEE T PATTERN ANAL, V35, P286, DOI 10.1109/TPAMI.2012.69; Tang SY, 2009, NEUROIMAGE, V47, P1277, DOI 10.1016/j.neuroimage.2009.02.043; Tapiola T, 2009, ARCH NEUROL-CHICAGO, V66, P382, DOI 10.1001/archneurol.2008.596; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040; Visser PJ, 2002, J NEUROL NEUROSUR PS, V72, P491; Walhovd KB, 2010, AM J NEURORADIOL, V31, P347, DOI 10.3174/ajnr.A1809; Wang YP, 2011, LECT NOTES COMPUT SC, V6893, P635; Wee CY, 2012, NEUROIMAGE, V59, P2045, DOI 10.1016/j.neuroimage.2011.10.015; Wee CY, 2011, NEUROIMAGE, V54, P1812, DOI 10.1016/j.neuroimage.2010.10.026; Westman E, 2012, NEUROIMAGE, V62, P229, DOI 10.1016/j.neuroimage.2012.04.056; Wu GR, 2006, IEEE T MED IMAGING, V25, P1145, DOI 10.1109/TMI.2006.879320; Xue Z, 2006, NEUROIMAGE, V33, P855, DOI 10.1016/j.neuroimage.2006.08.007; Xue Z, 2006, MED IMAGE ANAL, V10, P740, DOI 10.1016/j.media.2006.06.007; Yang JZ, 2008, LECT NOTES COMPUT SC, V5242, P905; Yao Z, 2012, PLOS ONE, V7; Yu K, 2011, PROC CVPR IEEE, P1713; Yuan L, 2012, NEUROIMAGE, V61, P622, DOI 10.1016/j.neuroimage.2012.03.059; Yuan M, 2006, J ROY STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008; Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069; Zhang Y, 2009, BRAIN, V132, P2579, DOI 10.1093/brain/awp071; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; Zhou LP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021935	84	2	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1863-2653	1863-2661		BRAIN STRUCT FUNCT	Brain Struct. Funct.	MAR	2015	220	2					841	859		10.1007/s00429-013-0687-3		19	Anatomy & Morphology; Neurosciences	Anatomy & Morphology; Neurosciences & Neurology	CC4UU	WOS:000350350300015	24363140	
J	Ma, JS; Sheridan, RP; Liaw, A; Dahl, GE; Svetnik, V				Ma, Junshui; Sheridan, Robert P.; Liaw, Andy; Dahl, George E.; Svetnik, Vladimir			Deep Neural Nets as a Method for Quantitative Structure-Activity Relationships	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							COMPOUND CLASSIFICATION; RANDOM FOREST; NETWORKS; CLASSIFIERS; TOOL	Neural networks were widely used for quantitative structure-activity relationships (QSAR) in the 1990s. Because of various practical issues (e.g., slow on large problems, difficult to train, prone to overfitting, etc.), they were superseded by more robust methods like support vector machine (SVM) and random forest (RF), which arose in the early 2000s. The last 10 years has witnessed a revival of neural networks in the machine learning community thanks to new methods for preventing overfitting, more efficient training algorithms, and advancements in computer hardware. In particular, deep neural nets (DNNs), i.e. neural nets with more than one hidden layer, have found great successes in many applications, such as computer vision and natural language processing. Here we show that DNNs can routinely make better prospective predictions than RF on a set of large diverse QSAR data sets that are taken from Mercks drug discovery effort. The number of adjustable parameters needed for DNNs is fairly large, but our results show that it is not necessary to optimize them for individual data sets, and a single set of recommended parameters can achieve better performance than RF for most of the data sets we studied. The usefulness of the parameters is demonstrated on additional data sets not used in the calibration. Although training DNNs is still computationally intensive, using graphical processing units (GPUs) can make this issue manageable.	[Ma, Junshui; Liaw, Andy; Svetnik, Vladimir] Merck Res Labs, Biometr Res Dept, Rahway, NJ 07065 USA; [Sheridan, Robert P.] Merck Res Labs, Dept Struct Chem, Rahway, NJ 07065 USA; [Dahl, George E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S, Canada	Ma, JS (reprint author), Merck Res Labs, Biometr Res Dept, Rahway, NJ 07065 USA.	junshui_ma@merck.com					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruce CL, 2007, J CHEM INF MODEL, V47, P219, DOI [10.1021/ci600332j, 10.1021/ci600322j]; Burden FR, 2001, J CHEM INF COMP SCI, V41, P830, DOI 10.1021/ci000459c; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Chen B, 2012, J CHEM INF MODEL, V52, P792, DOI 10.1021/ci200615h; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dahl G.E., 2014, MULTITASK NEURAL NET; Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kearsley SK, 1996, J CHEM INF COMP SCI, V36, P118, DOI 10.1021/ci950274j; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Mnih V., 2009, TR2009004 UTML; Nair V., 2010, P 27 INT C MACH LEAR, P807; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sheridan RP, 2013, J CHEM INF MODEL, V53, P783, DOI 10.1021/ci400084k; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Tieleman T., 2010, TR2010002 UTML; Wager S., 2013, ADV NEURAL INFORM PR, P351	21	2	2	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	FEB	2015	55	2					263	274		10.1021/ci5000747n		12	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	CB9HR	WOS:000349943100007	25635324	
J	Zhang, Y; Cheng, Y; Jia, KB; Zhang, AD				Zhang Yuan; Cheng Yue; Jia KeBin; Zhang AiDong			A generative model of identifying informative proteins from dynamic PPI networks	SCIENCE CHINA-LIFE SCIENCES			English	Article						dynamic protein-protein interaction network; abnormal detection; multi-view data; deep belief network	MODULAR ARCHITECTURE; SELECTION; MEDICINE; CYCLE; DATE; HUBS	Informative proteins are the proteins that play critical functional roles inside cells. They are the fundamental knowledge of translating bioinformatics into clinical practices. Many methods of identifying informative biomarkers have been developed which are heuristic and arbitrary, without considering the dynamics characteristics of biological processes. In this paper, we present a generative model of identifying the informative proteins by systematically analyzing the topological variety of dynamic protein-protein interaction networks (PPINs). In this model, the common representation of multiple PPINs is learned using a deep feature generation model, based on which the original PPINs are rebuilt and the reconstruction errors are analyzed to locate the informative proteins. Experiments were implemented on data of yeast cell cycles and different prostate cancer stages. We analyze the effectiveness of reconstruction by comparing different methods, and the ranking results of informative proteins were also compared with the results from the baseline methods. Our method is able to reveal the critical members in the dynamic progresses which can be further studied to testify the possibilities for biomarker research.	[Zhang Yuan; Cheng Yue; Jia KeBin] Beijing Univ Technol, Dept Elect Informat & Control Engn, Beijing 100124, Peoples R China; [Zhang AiDong] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	Jia, KB (reprint author), Beijing Univ Technol, Dept Elect Informat & Control Engn, Beijing 100124, Peoples R China.	kebnj@bjut.edu.cn			National Natural Science Foundation of China [30970780, 81370038]; Ph.D. Programs Foundation of Ministry of Education of China [20091103110005]; Project for the Innovation Team of Beijing; Beijing Natural Science Foundation [7142012]; Beijing Municipal Education Commission [km201410005003]; Beijing University of Technology [2013-RX-L04]; Beijing University of Technology	This work was supported by National Natural Science Foundation of China (30970780), Ph.D. Programs Foundation of Ministry of Education of China (20091103110005), the Project for the Innovation Team of Beijing, National Natural Science Foundation of China (81370038), the Beijing Natural Science Foundation (7142012), the Science and Technology Project of Beijing Municipal Education Commission (km201410005003), the Rixin Fund of Beijing University of Technology (2013-RX-L04), and the Basic Research Fund of Beijing University of Technology.	Arnau V, 2005, BIOINFORMATICS, V21, P364, DOI 10.1093/bioinformatics/bti021; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bhardwaj N, 2005, BIOINFORMATICS, V21, P2730, DOI 10.1093/bioinformatics/bti398; Chang X, 2013, SCI REP-UK, V3, DOI 10.1038/srep01691; de Lichtenberg U, 2005, SCIENCE, V307, P724, DOI 10.1126/science.1105103; Ge L, 2012, IEEE DATA MINING, P876, DOI 10.1109/ICDM.2012.151; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Handcock MS, 2003, ASSESSING DEGENERACY, P39; He XL, 2006, PLOS GENET, V2, P826, DOI 10.1371/journal.pgen.0020088; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hood L, 2012, NEW BIOTECHNOL, V29, P613, DOI 10.1016/j.nbt.2012.03.004; Komurov K, 2007, MOL SYST BIOL, V3, DOI 10.1038/msb4100149; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; Olson S, 2012, INTEGRATING LARGE SC; Overby CL, 2013, PERS MED, V10, P453, DOI 10.2217/pme.13.30; Pan W, 2002, BIOINFORMATICS, V18, P546, DOI 10.1093/bioinformatics/18.4.546; Pu SY, 2009, NUCLEIC ACIDS RES, V37, P825, DOI 10.1093/nar/gkn1005; Sutskever I, 2010, INT C ART INT STAT, P789; Taylor IW, 2009, NAT BIOTECHNOL, V27, P199, DOI 10.1038/nbt.1522; Tomlins SA, 2007, NAT GENET, V39, P41, DOI 10.1038/ng1935; Tu BP, 2005, SCIENCE, V310, P1152, DOI 10.1126/science.1120499; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P10515; Wang H, 2011, LECT N BIOINFORMAT, V6674, P87; Wang JX, 2013, PROTEOM CLIN APPL, V7, P181, DOI 10.1002/prca.201200068; Wang ZX, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-153; Yuille A., 2005, ADV NEURAL INFORM PR, V17, P1593; Zhang Y, 2013, TSINGHUA SCI TECHNOL, V18, P530	31	2	2	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1674-7305	1869-1889		SCI CHINA LIFE SCI	Sci. China-Life Sci.	NOV	2014	57	11					1080	1089		10.1007/s11427-014-4744-9		10	Biology	Life Sciences & Biomedicine - Other Topics	AU3AF	WOS:000345484700005	25331593	
J	Srivastava, N; Salakhutdinov, R				Srivastava, Nitish; Salakhutdinov, Ruslan			Multimodal Learning with Deep Boltzmann Machines	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Boltzmann machines; unsupervised learning; multimodal learning; neural networks; deep learning	AUDIOVISUAL SPEECH RECOGNITION; DESCRIPTORS; EXTRACTION	Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bi-modal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.	[Srivastava, Nitish] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Salakhutdinov, Ruslan] Univ Toronto, Dept Comp Sci & Stat, Toronto, ON M5S 3G4, Canada	Srivastava, N (reprint author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd,Rm 3302, Toronto, ON M5S 3G4, Canada.	NITISH@CS.TORONTO.EDU; RSALAKHU@CS.TORONTO.EDU			Google; Samsung; ONR [N00014-14-1-0232]	This research was supported by Google, Samsung, and ONR Grant N00014-14-1-0232.	Bastan M, 2010, IEEE MULTIMEDIA, V17, P62, DOI 10.1109/MMUL.2010.5692184; Bosch A., 2007, IEEE 11 INT C COMP V, V23, P1; Cox S., 2008, INT C AUD VIS SPEECH, P179; Dalal N, 2005, PROC CVPR IEEE, P886; Fisher W. M., 1986, P DARPA WORKSH SPEEC, P93; Freund Y., 1994, TECHNICAL REPORT; Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120; Gurban M, 2009, IEEE T SIGNAL PROCES, V57, P4765, DOI 10.1109/TSP.2009.2026513; Hinton G. E., 2012, CORR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huiskes M. J., 2010, 11 ACM INT C MULT IN, P527; Huiskes M. J., 2008, ACM INT C MULTIMEDIA; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lucey P., 2006, P HCSNET WORKSH US V, V56, P79; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900; Mohamed A., 2011, IEEE T AUDIO SPEECH; Ngiam J, 2011, P 28 INT C MACH LEAR; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Papandreou George, 2007, IEEE 9th Workshop on Multimedia Signal Processing, 2007. MMSP 2007; Papandreou G, 2009, IEEE T AUDIO SPEECH, V17, P423, DOI 10.1109/TASL.2008.2011515; PATTERSON EK, 2002, ACOUST SPEECH SIG PR, P2017; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, V22, P1607; Salakhutdinov R. R., 2009, P INT C ARTIFICIAL I, V12; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Taylor G. W., 2010, EURPEAN C COMPUTER V; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Verbeek J., 2010, 11 ACM MULT INF RETR, P537; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Xing E.P., 2005, UAI, P633; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L., 1998, STOCHASTICS STOCHAST, P177; Yuille A. L., 2004, ADV NEURAL INFORM PR, V17; Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637	41	2	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	OCT	2014	15						2949	2980				32	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	AT0PY	WOS:000344638800004		
J	Siniscalchi, SM; Svendsen, T; Lee, CH				Siniscalchi, Sabato Marco; Svendsen, Torbjorn; Lee, Chin-Hui			An artificial neural network approach to automatic speech processing	NEUROCOMPUTING			English	Article						Artificial neural networks; Deep neural networks; Acoustic feature modeling; Connectionist automatic speech recognition; Automatic language recognition	LANGUAGE IDENTIFICATION; TEMPORAL PATTERNS; MARKOV-CHAINS; RECOGNITION; INFORMATION; PREDICTION; MODEL; NETS; ASR	An artificial neural network (ANN) is a powerful mathematical framework used to either model complex relationships between inputs and outputs or find patterns in data. It is based on an interconnected group of artificial neurons, and it employs a connectionist approach to computation when processing information. ANNs have been successfully used for a great variety of applications, such as decision making, quantum chemistry, radar systems, face identification, gesture recognition, handwritten text recognition, medical diagnosis, financial applications, robotics, data mining, and e-spam filtering. In the speech community, neural architectures have been used since the beginning of the 1980s, and ANNs have been proven useful to accomplish several speech processing tasks, e.g., to extract linguistically motivated features, to perform speech detection, and to generate local scores to be used for different goals. In recent years, there has been a renewed interest in the use of ANNs for speech applications due to a major advance made in pre-training the weights in deep neural networks (DNNs). It seems that a new trend to move the speech technology forward through the use of NNs has begun, and it can therefore be instructive to review key ANN applications to automatic speech processing. In this paper, several ANN-based applications for speech processing will be presented, ranging from speech attribute extraction to phoneme estimation and/or classification. Furthermore, it will be shown that ANNs play a key role in several important speech applications, such as large vocabulary continuous speech recognition (LVCSR) and automatic language recognition. The goal of the paper is to summarize chief ANN approaches to speech processing using the experience gathered in the last seven years in our laboratories. (C) 2014 Elsevier B.V. All rights reserved.	[Siniscalchi, Sabato Marco] Kore Univ Enna, Fac Engn & Architecture, Enna, Sicily, Italy; [Siniscalchi, Sabato Marco; Lee, Chin-Hui] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; [Svendsen, Torbjorn] NTNU, Dept Elect & Telecommun, Trondheim, Norway	Siniscalchi, SM (reprint author), Kore Univ Enna, Fac Engn & Architecture, Cittadella Univ, Enna, Sicily, Italy.	marco.siniscalchi@unikore.it; torbjorn@ietmtnu.no; chl@ece.gatech.edu	Siniscalchi, Sabato Marco/	Siniscalchi, Sabato Marco/0000-0002-0770-0507			BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Bazzi I., 2000, P ICSLP BEIJ CHIN, P401; Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bourlard Ha, 1994, CONNECTIONIST SPEECH; BRIDLE JS, 1990, SPEECH COMMUN, V9, P83, DOI 10.1016/0167-6393(90)90049-F; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Craven MW, 1997, FUTURE GENER COMP SY, V13, P211, DOI 10.1016/S0167-739X(97)00022-8; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Demange S., 2011, P INT FLOR IT, P2305; Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692; Duda R, 2001, PATTERN CLASSIFICATI; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Fousek P, 2006, INT CONF ACOUST SPEE, P433; Fu Q, 2007, P ASRU KYOT JAP; Gemello R, 2007, SPEECH COMMUN, V49, P827, DOI 10.1016/j.specom.2006.11.005; Ghazali R, 2009, NEUROCOMPUTING, V72, P2359, DOI 10.1016/j.neucom.2008.12.005; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Haykin S., 1994, NEURAL NETWORKS COMP; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hwang M.-Y., 1993, THESIS CARNEGIE MELL; JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307; Kirchhoff K., 1999, THESIS U BIELEFELD G; KIRCHHOFF K., 1998, P ICSLP, P891; Lahnajarvi JJT, 2004, NEUROCOMPUTING, V56, P345, DOI 10.1016/j.neucom.2003.03.001; Lam M, 2004, DECIS SUPPORT SYST, V37, P567, DOI 10.1016/S0167-9236(03)00088-5; Lang K.J., 1990, NEURAL NETWORKS, V3, P24; Lee CH, 2013, P IEEE, V101, P1089, DOI 10.1109/JPROC.2013.2238591; Li HZ, 2007, IEEE T AUDIO SPEECH, V15, P271, DOI 10.1109/TASL.2006.876860; Li JY, 2007, IEEE T AUDIO SPEECH, V15, P2393, DOI 10.1109/TASL.2007.906178; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; Lisboa PJ, 2006, NEURAL NETWORKS, V19, P408, DOI 10.1016/j.neunet.2005.10.007; Macherey W., 2005, P INT LISB PORT, P2133; Martin A., 2003, P EUROSPEECH, P1341; Matejka P., 2005, P INT 2005 LISB PORT, P2237; Metze F., 2002, P INT C SPOK LANG PR, P2133; Mnih V., 2010, P ECCV CRET GREEC, P2010; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Morris J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P597; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Paul D., 1992, P ICSLP, P899; Rajamanohar M., 2005, P IEEE ASRU WORKSH, P59; Ramesh P., 1998, P ICSLP SYDN AUSTR; Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schwarz P, 2006, INT CONF ACOUST SPEE, P325; Seide F., 2011, THESIS CARNEGIE MELL, P437; Siniscalchi SM, 2012, IEEE T AUDIO SPEECH, V20, P875, DOI 10.1109/TASL.2011.2167610; Siniscalchi S.M., 2011, P INT FLOR IT, P901; Siniscalchi SM, 2013, IEEE T AUDIO SPEECH, V21, DOI 10.1109/TASL.2012.2234115; Siniscalchi SM, 2009, INT CONF ACOUST SPEE, P3865, DOI 10.1109/ICASSP.2009.4960471; Siniscalchi SM, 2009, SPEECH COMMUN, V51, P1139, DOI 10.1016/j.specom.2009.05.004; Siniscalchi S.M., 2010, P ICASSP DALL TX US; Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008; Siniscalchi SM, 2013, IEEE SIGNAL PROC LET, V20, P201, DOI 10.1109/LSP.2013.2237901; Siniscalchi SM, 2013, COMPUT SPEECH LANG, V27, P209, DOI 10.1016/j.csl.2012.05.001; Siniscalchi SM, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, VOLS 1 AND 2, P566, DOI 10.1109/ASRU.2007.4430174; Siniscalchi S.M., 2012, P INT PORTL OR US; Surendran AC, 1999, IEEE T SPEECH AUDI P, V7, P643, DOI 10.1109/89.799689; Young S., 2005, HTK BOOK HTK VERSION; Yu D., 2013, P ICLR SCOTTSD AZ US; Zissman MA, 1996, IEEE T SPEECH AUDI P, V4, P31, DOI 10.1109/TSA.1996.481450	67	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	SEP 22	2014	140						326	338		10.1016/j.neucom.2014.03.005		13	Computer Science, Artificial Intelligence	Computer Science	AJ6BT	WOS:000337775400032		
J	Xu, JG; Li, H; Zhou, SL				Xu, Jungang; Li, Hui; Zhou, Shilong			Improving mixing rate with tempered transition for learning restricted Boltzmann machines	NEUROCOMPUTING			English	Article						Restricted Boltzmann machines; Tempered transition; Mixing rate; Deep learning	CONTRASTIVE DIVERGENCE; NEURAL-NETWORKS; DEEP; PRODUCTS; EXPERTS	Recently, as the building block of deep generative models such as Deep Belief Networks (DBNs), Restricted Boltzmann Machines (RBMs) have attracted much attention. RBM is a Markov Random Field (MRF) associated with a bipartite undirected graph which is famous for powerful expression and tractable inference. While training an RBM, we need to sample from the model. The larger the mixing rate is, the smaller the bias of the samples is. However, neither Gibbs sampling based training methods such as Contrastive Divergence (CD) nor Parallel Tempering based training methods can achieve satisfying mixing rate, which causes poor rendering of the diversity of the modes captured by these trained models. This property may hinder the existing methods to approximate the likelihood gradient. In order to alleviate this problem, we attempt to introduce Tempered Transition, an advanced tempered Markov Chain Monte Carlo method, into training RBMs to replace Gibbs sampling or Parallel Tempering for sampling from RBMs. Experimental results show that our proposed method outperforms the existing methods to achieve better mixing rate and to help approximate the likelihood gradient. (C) 2014 Elsevier B.V. All rights reserved.	[Xu, Jungang; Li, Hui; Zhou, Shilong] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China	Xu, JG (reprint author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China.	xujg@ucas.ac.cn; lihui211@mails.ucas.ac.cn; zhoushilong12@mails.ucas.ac.cn			National Natural Science Foundation of China [61372171]; National Key Technology R&D Program of China [2012 BAH23B03]	Our work is supported in part by the National Natural Science Foundation of China under Grant no. 61372171 and the National Key Technology R&D Program of China under Contract no. 2012 BAH23B03.	Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3; Bengio Y., 2012, ARXIV12074404; Cho K. H., 2010, P 2010 INT JOINT C N, P1; Desjardins G., 2010, P 13 INT C ART INT S, P145; Earl DJ, 2005, PHYS CHEM CHEM PHYS, V7, P3910, DOI 10.1039/b509983h; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fischer A., 2012, LNCS, V7441, P14; Fischer A, 2010, LECT NOTES COMPUT SC, V6354, P208, DOI 10.1007/978-3-642-15825-4_26; Freund Y., 1994, UNSUPERVISED LEARNIN; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Iba Y, 2001, INT J MOD PHYS C, V12, P623, DOI 10.1142/S0129183101001912; Krizhevsky A., 2009, THESIS U TORONTO; Krizhevsky A, 2011, P 19 EUR S ART NEUR; LeCun Y., MNIST DATABASE HANDW; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Mohamed A., 2011, IEEE T AUDIO SPEECH, V20, P14; Neal RM, 1996, STAT COMPUT, V6, P353, DOI 10.1007/BF00143556; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R., 2009, P INT C ART INT STAT, P448; Salakhutdinov R., 2009, P ADV NEUR INF PROC, P1598; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Welling M., 2005, P 2005 C NEUR INF PR, P1481	32	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	SEP 2	2014	139				SI		328	335		10.1016/j.neucom.2014.02.024		8	Computer Science, Artificial Intelligence	Computer Science	AJ4QV	WOS:000337661800031		
J	Frasconi, P; Silvestri, L; Soda, P; Cortini, R; Pavone, FS; Iannello, G				Frasconi, Paolo; Silvestri, Ludovico; Soda, Paolo; Cortini, Roberto; Pavone, Francesco S.; Iannello, Giulio			Large-scale automated identification of mouse brain cells in confocal light sheet microscopy images	BIOINFORMATICS			English	Article							ELECTRON-MICROSCOPY; VISUALIZATION; ROBUST; MICE; RECONSTRUCTION; NEUROANATOMY; TOMOGRAPHY; RESOLUTION; CIRCUITS	Motivation: Recently, confocal light sheet microscopy has enabled high-throughput acquisition of whole mouse brain 3D images at the micron scale resolution. This poses the unprecedented challenge of creating accurate digital maps of the whole set of cells in a brain. Results: We introduce a fast and scalable algorithm for fully automated cell identification. We obtained the whole digital map of Purkinje cells in mouse cerebellum consisting of a set of 3D cell center coordinates. The method is accurate and we estimated an F-1 measure of 0.96 using 56 representative volumes, totaling 1.09 GVoxel and containing 4138 manually annotated soma centers.	[Frasconi, Paolo; Cortini, Roberto] Univ Florence, Dept Informat Engn DINFO, I-50139 Florence, Italy; [Silvestri, Ludovico; Pavone, Francesco S.] Univ Florence, LENS, I-50019 Sesto Fiorentino, Italy; [Soda, Paolo; Iannello, Giulio] Univ Campus Biomed Roma, Integrated Res Ctr, I-00128 Rome, Italy	Frasconi, P (reprint author), Univ Florence, Dept Informat Engn DINFO, I-50139 Florence, Italy.		pavone, francesco/F-4945-2015		E.U [FP7 228334, FP7 284464]; FET flagship HBP [604102]	The work of L.S. and F.P. was supported by E.U. grants FP7 228334, FP7 284464 and FET flagship HBP (604102).	Becker K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033916; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Biamonte F, 2009, NEUROBIOL DIS, V36, P103, DOI 10.1016/j.nbd.2009.07.001; Bohland JW, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000334; Bria A, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-316; Briggman K L, 2011, CURR OPIN NEUROBIOL, V22, P154, DOI DOI 10.1016/J.C0NB.2011.10.022; Briggman KL, 2011, NATURE, V471, P183, DOI 10.1038/nature09818; Buggenthin F, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-297; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chung K, 2013, NATURE, V497, P332, DOI 10.1038/nature12107; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dodt HU, 2007, NAT METHODS, V4, P331, DOI 10.1038/NMETH1036; Forero MG, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010557; Gong H, 2013, NEUROIMAGE, V74, P87, DOI 10.1016/j.neuroimage.2013.02.005; Goodfellow IJ, 2013, ARXIV13084214; Helmstaedter M, 2011, NAT NEUROSCI, V14, P1081, DOI 10.1038/nn.2868; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jain V., 2007, P IEEE INT C COMP VI, P1; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; Kasthuri N, 2007, NAT METHODS, V4, P307, DOI 10.1038/nmeth0407-307; Keller PJ, 2012, CURR OPIN NEUROBIOL, V22, P138, DOI 10.1016/j.conb.2011.08.003; Kleinfeld D, 2011, J NEUROSCI, V31, P16125, DOI 10.1523/JNEUROSCI.4077-11.2011; Knott G, 2008, J NEUROSCI, V28, P2959, DOI 10.1523/JNEUROSCI.3189-07.2008; LaTorre A, 2013, FRONT NEUROANAT, V7, DOI 10.3389/fnana.2013.00049; Li AA, 2010, SCIENCE, V330, P1404, DOI 10.1126/science.1191776; Lichtman JW, 2011, SCIENCE, V334, P618, DOI 10.1126/science.1209168; Mayerich D, 2008, J MICROSC-OXFORD, V231, P134, DOI 10.1111/j.1365-2818.2008.02024.x; Navlakha S, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-294; Oh SW, 2014, NATURE, V508, P207, DOI 10.1038/nature13186; Osten P, 2013, NAT METHODS, V10, P515, DOI [10.1038/nmeth.2477, 10.1038/NMETH.2477]; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Peng HC, 2014, NAT PROTOC, V9, P193, DOI 10.1038/nprot.2014.011; Peng HC, 2010, NAT BIOTECHNOL, V28, P348, DOI 10.1038/nbt.1612; Quan TW, 2013, SCI REP-UK, V3, DOI 10.1038/srep01414; Ragan T, 2012, NAT METHODS, V9, P255, DOI [10.1038/nmeth.1854, 10.1038/NMETH.1854]; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Schmitz C, 2005, NEUROSCIENCE, V130, P813, DOI 10.1016/j.neuroscience.2004.08.050; Silvestri L, 2012, OPT EXPRESS, V20, P20582, DOI 10.1364/OE.20.020582; Sporns O, 2005, PLOS COMPUT BIOL, V1, P245, DOI 10.1371/journal.pcbi.0010042; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tomomura M, 2001, EUR J NEUROSCI, V14, P57, DOI 10.1046/j.0953-816x.2001.01624.x; Woodruff-Pak DS, 2006, NEUROSCIENCE, V141, P233, DOI 10.1016/j.neuroscience.2006.03.070; Zhou K., 2004, P 2004 EUR ACM SIGGR, P45, DOI 10.1145/1057432.1057439	44	2	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803	1460-2059		BIOINFORMATICS	Bioinformatics	SEP 1	2014	30	17					I587	I593		10.1093/bioinformatics/btu469		7	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	AQ6HW	WOS:000342912400034	25161251	
J	Bianchini, M; Scarselli, F				Bianchini, Monica; Scarselli, Franco			On the Complexity of Neural Network Classifiers: A Comparison Between Shallow and Deep Architectures	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Betti numbers; deep neural networks; function approximation; topological complexity; Vapnik-Chervonenkis dimension (VC-dim)	APPROXIMATION; CAPABILITIES; DIMENSION; NETS; TIME	Recently, researchers in the artificial neural network field have focused their attention on connectionist models composed by several hidden layers. In fact, experimental results and heuristic considerations suggest that deep architectures are more suitable than shallow ones for modern applications, facing very complex problems, e. g., vision and human language understanding. However, the actual theoretical results supporting such a claim are still few and incomplete. In this paper, we propose a new approach to study how the depth of feedforward neural networks impacts on their ability in implementing high complexity functions. First, a new measure based on topological concepts is introduced, aimed at evaluating the complexity of the function implemented by a neural network, used for classification purposes. Then, deep and shallow neural architectures with common sigmoidal activation functions are compared, by deriving upper and lower bounds on their complexity, and studying how the complexity depends on the number of hidden units and the used activation function. The obtained results seem to support the idea that deep networks actually implements functions of higher complexity, so that they are able, with the same number of resources, to address more difficult problems.	[Bianchini, Monica; Scarselli, Franco] Univ Siena, I-53100 Siena, Italy	Bianchini, M (reprint author), Univ Siena, Via Laterina 8, I-53100 Siena, Italy.	monica@dii.unisi.it; franco@dii.unisi.it					Bandinelli N., 2010, P IJCNN, P1; Bartlett P. L., 2003, HDB BRAIN THEORY NEU, P1188; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Bengio Y., 2011, P ADV NEUR INF PROC, V24, P666; Bengio Y., 2007, P DEEP LEARN WORKSH; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bianchini M, 2005, PATTERN RECOGN LETT, V26, P1885, DOI 10.1016/j.patrec.2005.03.010; Bianchini M, 2005, NEURAL NETWORKS, V18, P1040, DOI 10.1016/j.neunet.2005.07.003; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Bredon G. E., 1993, TOPOLOGY GEOMETRY GR; Castelli I., 2011, P 1 IAPR WORKSH PSL, P52; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Delalleau O., 2011, P 22 INT C ALG LEARN, P18; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Fahlman S. E., 1990, ADV NEURAL INFORMATI, P524; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Fung HK, 2001, NEURAL COMPUT, V13, P319, DOI 10.1162/089976601300014556; Ghrist R., 2005, P 4 INT S INF PROC S, P254; Hammer B., 1999, P ESANN 99 BRUG BELG, P33; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hatcher A., 2002, ALGEBRAIC TOPOLOGY; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Kaczynski T, 2004, COMPUTATIONAL HOMOLO, V157; Karpinski M, 1997, J COMPUT SYST SCI, V54, P169, DOI 10.1006/jcss.1997.1477; Khovanskii A. G., 1991, FEWNOMIALS, V88; Lawrence S, 2000, IEEE T KNOWL DATA EN, V12, P126, DOI 10.1109/69.842255; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; Lee H., 2010, P DEEP LEARN UNS FEA; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Milnor J., 1964, P AM MATH SOC, V15, P275, DOI 10.2307/2034050; Nakahara M., 2003, GEOMETRY TOPOLOGY PH, V2nd; Park J., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.246; Pearlmutter B. A., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.263; Pucci A., 2006, SYST SCI, V32, P17; Rojas R, 1996, NEURAL NETWORKS SYST; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Scarselli F, 1998, NEURAL NETWORKS, V11, P15, DOI 10.1016/S0893-6080(97)00097-X; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P81, DOI 10.1109/TNN.2008.2005141; Serre T, 2007, PROG BRAIN RES, V165, P33, DOI 10.1016/S0079-6123(06)65004-8; Sontag E. D., 1998, Neural Networks and Machine Learning. Proceedings; SONTAG ED, 1992, J COMPUT SYST SCI, V45, P20, DOI 10.1016/0022-0000(92)90039-L; Sottile F., 2011, REAL SOLUTIONS EQUAT, V57; Su H.-T., 1991, P AM CONTR C, P2311; Tsoi A. C., 2006, ACM Transactions on Internet Technology, V6, DOI 10.1145/1183463.1183466; Wegener I, 1987, COMPLEXITY BOOLEAN F; Yao A. C., 1985, P 26 ANN IEEE S FDN, P1; Yu K., 2009, P WORKSH LEARN FEAT; Zell T, 1999, J PURE APPL ALGEBRA, V139, P323, DOI 10.1016/S0022-4049(99)00017-1; Zell T., 2004, THESIS GEORGIA I TEC; Zimmerman S., 2001, COLL MATH J, V32, P126, DOI 10.2307/2687119	54	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	AUG	2014	25	8					1553	1565		10.1109/TNNLS.2013.2293637		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	AN0ST	WOS:000340295000011	25050951	
J	Guo, Y; Zhang, HZ				Guo, Yue; Zhang, Heng Zhen			Oil spill detection using synthetic aperture radar images and feature selection in shape space	INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION			English	Article						SAR; Oil-spill; Lookalikes; Feature selection; Shape space	NEURAL-NETWORKS; SAR IMAGES	The major goal of the present study is to describe a method by which synthetic aperture radar (SAR) images of oil spills can be discriminated from other phenomena of similar appearance. The optimal features of these dark formations are here identified. Because different materials have different physical properties, they form different shapes. In this case, oil films and lookalike materials have different fluid properties. In this paper, 9 shape features with a total of 95 eigenvalues were selected. Using differential evolution feature selection (DEFS), similar eigenvalues were extracted from total space of oil spills and lookalike phenomena. This process assumes that these similar eigenvalues impair classification. These similar eigenvalues are removed from the total space, and the important eigenvalues (IEs), those useful to the discrimination of the targets, are identified. At least 30 eigenvalues were found to be inappropriate for classification of our shape spaces. The proposed method was found to be capable of facilitating the selection of the top 50 IEs. This allows more accurate classification. Here, accuracy reached 94%. The results of the experiment show that this novel method performs well. It could also be made available to teams across the world very easily. (C) 2014 Elsevier B.V. All rights reserved.	[Guo, Yue; Zhang, Heng Zhen] Shanghai Maritime Univ, Coll Informat Engn, Shanghai 201306, Peoples R China	Guo, Y (reprint author), Shanghai Maritime Univ, Coll Informat Engn, Shanghai 201306, Peoples R China.	yueguo@shmtu.edu.cn					Ai-Bin J., 2009, RES VISUAL FEATURE A; Brekke C, 2005, REMOTE SENS ENVIRON, V95, P1, DOI 10.1016/j.rse.2004.11.015; Brekke C, 2005, LECT NOTES COMPUT SC, V3540, P75; CONGALTON R. G., 1998, ASSESSING ACCURACY R; Danisi A, 2007, INT GEOSCI REMOTE SE, P1314; Del Frate F, 2000, IEEE T GEOSCI REMOTE, V38, P2282, DOI 10.1109/36.868885; Espedal A., 2000, INT J REMOTE SENS, V21, P2141; Ferraro G, 2007, MAR POLLUT BULL, V54, P403, DOI 10.1016/j.marpolbul.2006.11.022; Ferraro G, 2009, INT J REMOTE SENS, V30, P627, DOI 10.1080/01431160802339464; Fiscella B, 2000, INT J REMOTE SENS, V21, P3561, DOI 10.1080/014311600750037589; GIARDINA CR, 1977, COMPUT VISION GRAPH, V6, P277, DOI 10.1016/S0146-664X(77)80029-4; Gonzalez R.C., 2004, DIGITAL IMAGE PROCES; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HU M, 1962, IRE T INFORM THEOR, V8, P179; Karathanassi V, 2006, INT J REMOTE SENS, V27, P5235, DOI 10.1080/01431160600693575; Keramitsoglou I, 2006, ENVIRON MODELL SOFTW, V21, P640, DOI 10.1016/j.envsoft.2004.11.010; Khushaba RN, 2011, EXPERT SYST APPL, V38, P11515, DOI 10.1016/j.eswa.2011.03.028; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; Lena C., 2008, PATTERN RECOGN, V29, P1915; Miao J., 2009, J CHANGCHUN U SCI TE, V32, P126; Migliaccio M., 2004, US BALT INT S KLAIP; Montali A., 2006, SEASAR 2006 WORKSH E; Nirchio F, 2005, INT J REMOTE SENS, V26, P1157, DOI 10.1080/01431160512331326558; Price K.V., 2005, DIFFERENTIAL EVOLUTI; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rami K.N., 2007, P 19 INT C PATT REC; Solberg R., 1997, P 4 THEM C REM SENS, P3; Stathakis D., 2006, P 13 SPIE S REM SENS, V6365; Topouzelis K, 2008, INT J REMOTE SENS, V29, P4705, DOI 10.1080/01431160801891770; Topouzelis K, 2009, INT J REMOTE SENS, V30, P611, DOI 10.1080/01431160802339456; Topouzelis K, 2002, P SOC PHOTO-OPT INS, V4880, P77; van der Werff HMA, 2008, ISPRS J PHOTOGRAMM, V63, P251, DOI 10.1016/j.isprsjprs.2007.09.007; Wang SY, 2006, LECT NOTES COMPUT SC, V3972, P646; Woods K, 1997, IEEE T MED IMAGING, V16, P329, DOI 10.1109/42.585767; Yue G., 2011, 4 INT C MACH VIS ICM, V83490B, P1; Yue G., 2011, INT P COMPUTER SCI I, V17, P187	37	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0303-2434			INT J APPL EARTH OBS	Int. J. Appl. Earth Obs. Geoinf.	AUG	2014	30						146	157		10.1016/j.jag.2014.01.011		12	Remote Sensing	Remote Sensing	AG7UT	WOS:000335625000014		
J	Chen, YS; Lin, ZH; Zhao, X; Wang, G; Gu, YF				Chen, Yushi; Lin, Zhouhan; Zhao, Xing; Wang, Gang; Gu, Yanfeng			Deep Learning-Based Classification of Hyperspectral Data	IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			English	Article						Autoencoder (AE); deep learning; feature extraction; hyperspectral data classification; logistic regression; stacked autoencoder (SAE); support vector machine (SVM)	SUPPORT VECTOR MACHINES; REMOTE-SENSING IMAGES; DIMENSIONALITY REDUCTION; UNIVERSAL APPROXIMATORS; SPATIAL CLASSIFICATION; FEATURE-SELECTION; BELIEF NETWORKS; REPRESENTATION; ALGORITHM	Classification is one of the most popular topics in hyperspectral remote sensing. In the last two decades, a huge number of methods were proposed to deal with the hyperspectral data classification problem. However, most of them do not hierarchically extract deep features. In this paper, the concept of deep learning is introduced into hyperspectral data classification for the first time. First, we verify the eligibility of stacked autoencoders by following classical spectral information-based classification. Second, a new way of classifying with spatial-dominated information is proposed. We then propose a novel deep learning framework to merge the two features, from which we can get the highest classification accuracy. The framework is a hybrid of principle component analysis (PCA), deep learning architecture, and logistic regression. Specifically, as a deep learning architecture, stacked autoencoders are aimed to get useful high-level features. Experimental results with widely-used hyperspectral data indicate that classifiers built in this deep learning-based framework provide competitive performance. In addition, the proposed joint spectral-spatial deep neural network opens a new window for future research, showcasing the deep learning-based methods' huge potential for accurate hyperspectral data classification.	[Chen, Yushi; Lin, Zhouhan; Zhao, Xing; Gu, Yanfeng] Harbin Inst Technol, Inst Image & Informat Technol, Harbin 150001, Peoples R China; [Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Chen, YS (reprint author), Harbin Inst Technol, Inst Image & Informat Technol, Harbin 150001, Peoples R China.	chenyushi@hit.edu.cn; lin.zhouhan@gmail.com; zhaoxing@hit.edu.cn; wanggang@ntu.edu.sg; yfgu@hit.edu.cn	Wang, Gang/B-7027-2013; Gu, Yanfeng/F-7781-2015	Gu, Yanfeng/0000-0003-1625-7989	Fundamental Research Funds for the Central Universities [HIT.NSRIF.2013028]; National Natural Science Foundation of China [61301206, 61371180]	This work was supported in part by the Fundamental Research Funds for the Central Universities under Grant HIT.NSRIF.2013028 and in part by National Natural Science Foundation of China under Grant 61301206 and Grant 61371180.	Ambikapathi A., 2013, P IEEE WHISP GAIN FL; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bioucas-Dias J., 2013, GEOSCI REMOTE SE FEB, V1, P6; Bruce LM, 2002, IEEE T GEOSCI REMOTE, V40, P2331, DOI 10.1109/TGRS.2002.804721; Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154; Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631; Egerton R. F., 1996, ELECT ENERGY LOSS SP, V2nd; Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gowen AA, 2007, TRENDS FOOD SCI TECH, V18, P590, DOI 10.1016/j.tifs.2007.06.001; Gualtieri JA, 2000, INT GEOSCI REMOTE SE, P813, DOI 10.1109/IGARSS.2000.861712; HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007; Hecht-Nielsen R, 1989, INT JOINT C NEURAL N, V1, P593; Hege E. K., 2004, P SPIES 48 ANN M OPT, P380; Hinton G. E., 2010, TR2010003 UTML DEP C; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P2653, DOI 10.1109/36.803413; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272; Lacar F. M., 2001, P INT GEOSCIENCE REM, V6, P2875; Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718; Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Li J, 2013, IEEE T GEOSCI REMOTE, V51, P844, DOI 10.1109/TGRS.2012.2205263; Liu JJ, 2013, IEEE J-STARS, V6, P2462, DOI 10.1109/JSTARS.2013.2252150; Malthus TJ, 2003, INT J REMOTE SENS, V24, P2805, DOI 10.1080/0143116031000066954; Meer F. V. D., 2004, INT J APPL EARTH OBS, V5, P55; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Plaza A., 2009, P 1 WORKSH HYP IM SI, P1, DOI DOI 10.1109/WHISPERS.2009.5289024; Rajan S, 2008, IEEE T GEOSCI REMOTE, V46, P1231, DOI 10.1109/TGRS.2007.910220; Richards J. A., 2013, REMOTE SENSING DIGIT; Salakhutdinov R., 2009, P INT C ART INT STAT, P448; Samadzadegan F, 2012, CAN J REMOTE SENS, V38, P139; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; Tarabalka Y, 2009, IEEE T GEOSCI REMOTE, V47, P2973, DOI 10.1109/TGRS.2009.2016214; THOMPSON WD, 1988, J CLIN EPIDEMIOL, V41, P949, DOI 10.1016/0895-4356(88)90031-5; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Yu D., 2009, P NIPS WORKSH, P1; Yuen PWT, 2010, IMAGING SCI J, V58, P241, DOI 10.1179/174313110X12771950995716; Zhen Zuo, 2014, IEEE Signal Processing Letters, V21, DOI 10.1109/LSP.2014.2298888; Zhu Z, 2012, REMOTE SENS ENVIRON, V117, P72, DOI 10.1016/j.rse.2011.07.020; Zhuo L., 2008, P GEOINF JOINT C GIS	47	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1939-1404	2151-1535		IEEE J-STARS	IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.	JUN	2014	7	6			SI		2094	2107		10.1109/JSTARS.2014.2329330		14	Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology	Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology	AN5HK	WOS:000340621200022		
J	Narayanan, A; Wang, DL				Narayanan, Arun; Wang, DeLiang			Investigation of Speech Separation as a Front-End for Noise Robust Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Aurora-4; deep neural networks; feature mapping; robust ASR; time-frequency masking	INTELLIGIBILITY; SEGREGATION; BINARY; ALGORITHM; FEATURES; MASKING	Recently, supervised classification has been shown to work well for the task of speech separation. We perform an in-depth evaluation of such techniques as a front-end for noise-robust automatic speech recognition (ASR). The proposed separation front-end consists of two stages. The first stage removes additive noise via time-frequency masking. The second stage addresses channel mismatch and the distortions introduced by the first stage; a non-linear function is learned that maps the masked spectral features to their clean counterpart. Results show that the proposed front-end substantially improves ASR performance when the acoustic models are trained in clean conditions. We also propose a diagonal feature discriminant linear regression (dFDLR) adaptation that can be performed on a per-utterance basis for ASR systems employing deep neural networks and HMM. Results show that dFDLR consistently improves performance in all test conditions. Surprisingly, the best average results are obtained when dFDLR is applied to models trained using noisy log-Mel spectral features from the multi-condition training set. With no channel mismatch, the best results are obtained when the proposed speech separation front-end is used along with multi-condition training using log-Mel features followed by dFDLR adaptation. Both these results are among the best on the Aurora-4 dataset.	[Narayanan, Arun; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA	Narayanan, A (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	narayaar@cse.ohio-state.edu; dwang@cse.ohio-state.edu			Air Force Office of Scientific Research [FA9550-08-1-0155]; Ohio Supercomputer Center	This work was supported in part by the Air Force Office of Scientific Research under Grant (FA9550-08-1-0155) and in part by the Ohio Supercomputer Center. A preliminary version of this work was presented at ICASSP-2013 [29]. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Brian Kingsbury.	[Anonymous], 2005, 202050 ES ETSI; Astudillo RF, 2013, IEEE T AUDIO SPEECH, V21, P1023, DOI 10.1109/TASL.2013.2244085; Bottou L, 2008, ADV NEURAL INFORM PR, V20, P161; Chen CP, 2007, IEEE T AUDIO SPEECH, V15, P257, DOI 10.1109/TASL.2006.876717; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Delcroix M., 2013, P INTERSPEECH, P2992; Deng L, 2005, IEEE T SPEECH AUDI P, V13, P412, DOI 10.1109/TSA.2005.845814; DENG L, 2001, ACOUST SPEECH SIG PR, P301; Droppo J., 2012, TECHNIQUES NOISE ROB, P229; Du J, 2010, INT CONF ACOUST SPEE, P4570, DOI 10.1109/ICASSP.2010.5495569; Duchi J., 2010, J MACHINE LEARNING R, V12, P2121; Ellis D. P. W., 2005, PLP RASTA MFCC INVER; Flego F, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P170, DOI 10.1109/ASRU.2009.5373266; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Goodfellow I. J., 2013, J MACH LEARN RES WOR, V28, P1319; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; Hartmann W, 2013, IEEE T AUDIO SPEECH, V21, P1993, DOI 10.1109/TASL.2013.2263802; Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Kim W, 2011, SPEECH COMMUN, V53, P1, DOI 10.1016/j.specom.2010.08.005; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Maas A., 2012, P INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2010, P ICML, P807; Narayanan A, 2013, INT CONF ACOUST SPEE, P6817, DOI 10.1109/ICASSP.2013.6638982; Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038; Parihar N., 2003, P EUROSPEECH GEN SWI, V4, P337; Prabhavalkar R, 2013, INT CONF ACOUST SPEE, P7165, DOI 10.1109/ICASSP.2013.6639053; Raj B, 2005, IEEE SIGNAL PROC MAG, V22, P101, DOI 10.1109/MSP.2005.1511828; Roman N, 2011, J ACOUST SOC AM, V130, P2153, DOI 10.1121/1.3631668; Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463; Seide F., 2011, P ASRU, P24; Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100; Seltzer ML, 2004, SPEECH COMMUN, V43, P379, DOI 10.1016/j.specom.2004.03.006; Srinivasan S, 2006, SPEECH COMMUN, V48, P1486, DOI 10.1016/j.specom.2006.09.003; Vertanen K., 2005, HTK WALL STREET J TR; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233; Wang YQ, 2012, IEEE T AUDIO SPEECH, V20, P2149, DOI 10.1109/TASL.2012.2198059; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459; Wang YX, 2013, INT CONF ACOUST SPEE, P7472; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; Weninger F., 2013, P 2 CHIME WORKSH MAC, P86; Young S., 2002, HTK BOOK, P3; Yu D., 2013, P ICLR	48	2	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	APR	2014	22	4					826	835		10.1109/TASLP.2014.2305833		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AD5YZ	WOS:000333330900006		
J	Sarikaya, R; Hinton, GE; Deoras, A				Sarikaya, Ruhi; Hinton, Geoffrey E.; Deoras, Anoop			Application of Deep Belief Networks for Natural Language Understanding	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Call-Routing; DBN; Deep Learning; Deep Neural Nets; Natural language Understanding; RBM	HELP	Applications of Deep Belief Nets (DBN) to various problems have been the subject of a number of recent studies ranging from image classification and speech recognition to audio classification. In this study we apply DBNs to a natural language understanding problem. The recent surge of activity in this area was largely spurred by the development of a greedy layer-wise pretraining method that uses an efficient learning algorithm called Contrastive Divergence (CD). CD allows DBNs to learn a multi-layer generative model from unlabeled data and the features discovered by this model are then used to initialize a feed-forward neural network which is fine-tuned with backpropagation. We compare a DBN-initialized neural network to three widely used text classification algorithms: Support Vector Machines (SVM), boosting and Maximum Entropy (MaxEnt). The plain DBN-based model gives a call-routing classification accuracy that is equal to the best of the other models. However, using additional unlabeled data for DBN pre-training and combining DBN-based learned features with the original features provides significant gains over SVMs, which, in turn, performed better than both MaxEnt and Boosting.	[Sarikaya, Ruhi; Deoras, Anoop] Microsoft Corp, Redmond, WA 98052 USA; [Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Sarikaya, R (reprint author), Microsoft Corp, Redmond, WA 98052 USA.	ruhi.sarikaya@microsoft.com; hinton@cs.toronto.edu; anoop.deoras@microsoft.com					Chen S., 2001, IEEE T SAP, V8, P37; Dahl G., 2010, ADV NEURAL INFORM PR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X; Haffner P., 2003, P IEEE INT C AC SPEE, P632; Hinton G. E., 2002, NEURAL COMPUT, V14, P1527; Hinton G. E., 2010003 UTML TR; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Lafferty J., 2001, P INT C MACH LEARN; Ng A. Y., 2002, ADV NEURAL INFORM PR, V11; Pietra S. D., 1997, IEEE T PATTERN ANAL, V19, P380; Price P. J., 1990, P DARPA WORKSH SPEEC; Raymond C., 2007, P INTERSPEECH; Sarikaya R, 2011, INT CONF ACOUST SPEE, P5680; Sarikaya R., 2005, P INTERSPEECH; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Tur G., 2011, SPOKEN LANGUAGE UNDE; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang Y.-Y., 2006, P ICSLP; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	22	2	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	APR	2014	22	4					778	784		10.1109/TASLP.2014.2303296		7	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AD5YZ	WOS:000333330900002		
J	Young, SR; Davis, A; Mishtal, A; Arel, I				Young, S. R.; Davis, A.; Mishtal, A.; Arel, I.			Hierarchical spatiotemporal feature extraction using recurrent online clustering	PATTERN RECOGNITION LETTERS			English	Article						Deep machine learning; Online clustering; Recurrent clustering; Unsupervised feature extraction; Spatiotemporal signals; Pattern recognition	RECOGNITION; FACE	Deep machine learning offers a comprehensive framework for extracting meaningful features from complex observations in an unsupervised manner. The majority of deep learning architectures described in the literature primarily focus on extracting spatial features. However, in real-world settings, capturing temporal dependencies in observations is critical for accurate inference. This paper introduces an enhancement to DeSTIN - a compositional deep learning architecture in which each layer consists of multiple instantiations of a common node - that learns to represent spatiotemporal patterns in data based on a novel recurrent clustering algorithm. Contrary to mainstream deep architectures, such as deep belief networks where layer-by-layer training is assumed, each of the nodes in the proposed architecture is trained independently and in parallel. Moreover, top-down and bottom-up information flows facilitate rich feature formation. A semi-supervised setting is demonstrated achieving state-of-the-art results on the MNIST classification benchmarks. A GPU implementation is discussed further accentuating the scalability properties of the proposed framework. (C) 2013 Elsevier B.V. All rights reserved.	[Young, S. R.; Davis, A.; Mishtal, A.; Arel, I.] Univ Tennessee, Dept Elect Engn & Comp Sci, Machine Intelligence Lab, Knoxville, TN 37996 USA	Young, SR (reprint author), Univ Tennessee, Dept Elect Engn & Comp Sci, Machine Intelligence Lab, Knoxville, TN 37996 USA.	syoung22@utk.edu; adavis72@utk.edu; amishtal@utk.edu; itamar@ieee.org			Intelligence Advanced Research Projects Activity (IARPA) via Army Research Office (ARO) [W911NF-12-1-0017]	This work was supported by the Intelligence Advanced Research Projects Activity (IARPA) via Army Research Office (ARO) agreement No. W911NF-12-1-0017. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.	Arel I, 2009, P AAAI WORKSH BIOL I, P1150; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Chen YN, 2006, INT C PATT RECOG, P552; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Cuturi M., 2011, P 28 INT C MACH LEAR, P929; Cuturi M., 2011, AUTOREGRESSIVE KERNE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Karnowski T., 2010, 19 INT C MACH LEARN, P883, DOI DOI 10.1109/1CMLA.2010.138; Karnowski TP, 2011, FRONT ARTIF INTEL AP, V233, P174, DOI 10.3233/978-1-60750-959-2-174; Karnowski T.P., 2012, THESIS U TENNESSEE K; Kegl B., 2009, P 26 ANN INT C MACH, V26, P497, DOI DOI 10.1145/1553374.1553439; Krizhevsky A., 2009, THESIS U TORONTO TOR; LeCun Y., 1998, MNIST DATABASE HANDW; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lockett A.J., 2009, AI0904 U TEX AUST DE; Mobahi H., 2009, P 26 ANN INT C MACH, P737; NVIDIA, 2012, NVIDIA CUDA PROGR GU; Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757; Salakhutdinov R, 2007, J MACH LEARN RES, V2, P412; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; Sutskever I., 2007, LEARNING MULTILEVEL; Wallis G, 1997, PROG NEUROBIOL, V51, P167, DOI 10.1016/S0301-0082(96)00054-8; Wallis G., 1999, TRENDS COGN SCI, V3, P23; Young S., 2010, 7 INT C INF TECHN NE, P204, DOI DOI 10.1109/ITNG.2010.148	27	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB 1	2014	37				SI		115	123		10.1016/j.patrec.2013.07.013		9	Computer Science, Artificial Intelligence	Computer Science	AA5RJ	WOS:000331157000013		
J	Scarselli, F; Tsoi, AC; Hagenbuchner, M; Di Noi, L				Scarselli, Franco; Tsoi, Ah Chung; Hagenbuchner, Markus; Di Noi, Lucia			Solving graph data issues using a layered architecture approach with applications to web spam detection	NEURAL NETWORKS			English	Article						Graph neural network; Probability Mapping GraphSOM; Layered architecture; Web spam detection	RECURSIVE NEURAL-NETWORKS; STRUCTURED DATA; CLASSIFICATION; ALGORITHM; LEARN; MODEL; MAP	This paper proposes the combination of two state-of-the-art algorithms for processing graph input data, viz., the probabilistic mapping graph self organizing map, an unsupervised learning approach, and the graph neural network, a supervised learning approach. We organize these two algorithms in a cascade architecture containing a probabilistic mapping graph self organizing map, and a graph neural network. We show that this combined approach helps us to limit the long-term dependency problem that exists when training the graph neural network resulting in an overall improvement in performance. This is demonstrated in an application to a benchmark problem requiring the detection of spam in a relatively large set of web sites. It is found that the proposed method produces results which reach the state of the art when compared with some of the best results obtained by others using quite different approaches. A particular strength of our method is its applicability towards any input domain which can be represented as a graph. (C) 2013 Elsevier Ltd. All rights reserved.	[Scarselli, Franco; Di Noi, Lucia] Univ Siena, I-53100 Siena, Italy; [Tsoi, Ah Chung] Macau Univ Sci & Technol, Taipa, Macau, Peoples R China; [Hagenbuchner, Markus] Univ Wollongong, Wollongong, NSW, Australia	Scarselli, F (reprint author), Univ Siena, Via Laterina 8, I-53100 Siena, Italy.	franco@ing.unisi.it			Australian Research Council [DP0774168, LX0882106]; Fundo para o Desenvolvimento das Ciencias e da Tecnologia, Macau SAR Government [059/2010/A3]	This project received financial support from the Australian Research Council, Discovery Project grant DP0774168 and Linkage International Award grant LX0882106. Moreover, partial financial support was received from Fundo para o Desenvolvimento das Ciencias e da Tecnologia, Macau SAR Government, Grant No. 059/2010/A3. The authors wish to acknowledge the assistance of the action editor, and the anonymous reviewers for their helpful and constructive comments, which make this paper more readable.	Abernethy J, 2010, MACH LEARN, V81, P207, DOI 10.1007/s10994-010-5171-1; ALMEIDA L, 1987, IEEE INT C NEUR NETW, V2, P609; Baldi P, 2004, J MACH LEARN RES, V4, P575, DOI 10.1162/153244304773936054; Bandinelli N., 2010, 2010 INT JOINT C NEU, P1, DOI 10.1109/IJCNN.2010.5596634; Benczur A., 2010, ECML PKDD DISCOVERY; Bengio Y., 2007, LARGE SCALE KERNEL M; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y., 2007, DEEP LEARN WORKSH FD; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2007, NIPS; Bharat K., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290972; Bianchini M, 2004, IEEE IJCNN, P1911; Bianchini M, 2005, PATTERN RECOGN LETT, V26, P1885, DOI 10.1016/j.patrec.2005.03.010; Bianchini M., 2003, P 1 ANNPR WORKSH FLO; Bianchini M, 2005, NEURAL NETWORKS, V18, P1040, DOI 10.1016/j.neunet.2005.07.003; Bloehdorn S., 2006, P INT WORKSH INT INF; Brin S., 1999, 199966 STANF U; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Castelli I., 2011, P 1 IAPR WORKSH PART; Castillo C., 2008, P 4 INT WORKSH ADV I; Castillo C., 2006, SIGIR Forum, V40, DOI 10.1145/1189702.1189703; Castillo C., 2007, P 30 ANN INT ACM SIG, P423, DOI 10.1145/1277741.1277814; Castillo C., 2011, FDN TRENDS R INFORM; Challenge, 2007, WEB SPAM CHALL; Cho SY, 2003, IEEE T NEURAL NETWOR, V14, P781, DOI 10.1109/TNN.2003.813831; Davison B. D., 2000, ARTIF INTELL, P23; Di Massa V, 2006, IEEE IJCNN, P778; Fahlman S. E., 1990, ADV NEURAL INFORMATI, P524; Fetterly D, 2004, P 7 INT WORKSH WEB D, P1, DOI 10.1145/1017074.1017077; Francesconi E, 1998, LECT NOTES COMPUT SC, V1389, P104; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Gleich D., 2004, YRL2004, P38; Goller C., 1999, P EUR S ART NEUR NET; Gori M., 2005, P IJCNN 2005, V2, P729, DOI 10.1109/IJCNN.2005.1555942; Gyongyi Z., 2004, P 30 INT C VER LARG, V30, P587; Gyongyi Z., 2005, ADVERSARIAL INFORM R; Hagenbuchner M, 2009, NEUROCOMPUTING, V72, P1419, DOI 10.1016/j.neucom.2008.12.021; Hagenbuchner M, 2006, LECT NOTES COMPUT SC, V3977, P481; Hagenbuchner M., 2005, LECT NOTES COMPUTER, V3720, P46; Hagenbuchner M, 2003, IEEE T NEURAL NETWOR, V14, P491, DOI 10.1109/TNN.2003.810735; Hagenbuchner M., 2009, EUR S ART NEUR NETW, P22; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Khamsi MA, 2001, INTRO METRIC SPACES; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Kohonen T, 1989, SELF ORG ASS MEMORY; Krishnan V., 2006, AIR WEB 06, P37; Le Q. V., 2012, INT C MACH LEARN; Lee H., 2010, DEEP LEARN UNS FEAT; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Manning C.D., 2008, INTRO INFORM RETRIEV; Micheli A, 2009, IEEE T NEURAL NETWOR, V20, P498, DOI 10.1109/TNN.2008.2010350; Micheli A, 2004, IEEE T NEURAL NETWOR, V15, P1396, DOI 10.1109/TNN.2004.837783; Micheli A, 2001, J CHEM INF COMP SCI, V41, P202, DOI 10.1021/ci0000399; Money C., 2009, PROTEIN-STRUCT FUNCT, V77, P181; Monfardini G, 2006, FR ART INT, V141, P665; Ntoulas A., 2006, P 15 INT C WORLD WID, P83, DOI DOI 10.1145/1135777.1135794.URL; PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229; POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155; Riedmiller M., 1992, P 7 INT S COMP INF S, P1; Rodriguez P, 2001, NEURAL COMPUT, V13, P2093, DOI 10.1162/089976601750399326; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Scarselli F., 2005, Proceedings. The 2005 IEEE/WIC/ACM International Conference on Web Intelligence; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P81, DOI 10.1109/TNN.2008.2005141; Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108; Spirin N., 2011, TEHNICAL REPORT U IL; Sturt P, 2003, COGNITION, V88, P133, DOI 10.1016/S0010-0277(03)00026-X; Trentini F., 2006, P WCCI; Urvoy T., 2006, AIRWEB 2006, P25; Uwents W., 2006, MLG 2006, P213; Uwents W, 2011, MACH LEARN, V82, P315, DOI 10.1007/s10994-010-5196-5; Wang W, 2007, LECT NOTES COMPUT SC, V4537, P299; Wang Z, 2002, IEEE IJCNN, P1918; Wu B., 2005, 14 INT C WORLD WID W, P820; Yong S., 2006, LECT NOTES COMPUTER, V4518, P458; Yu K., 2009, WORKSH LEARN FEAT HI	75	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	DEC	2013	48						78	90		10.1016/j.neunet.2013.07.007		13	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	278XS	WOS:000328923800010	23973870	
J	Li, P; Cheng, J; Lu, HQ				Li, Peng; Cheng, Jian; Lu, Hanqing			Hashing with dual complementary projection learning for fast image retrieval	NEUROCOMPUTING			English	Article						Hashing; Complementary projection learning; Binary codes; Fast image retrieval	APPROXIMATE NEAREST-NEIGHBOR; ALGORITHM; DIMENSIONS	Due to explosive growth of visual content on the web, there is an emerging need of fast similarity search to efficiently exploit such enormous web contents from very large databases. Recently, hashing has become very popular for efficient nearest neighbor search in large scale applications. However, many traditional hashing methods learn the binary codes in a single shot or only employ a single hash table, thus they usually cannot achieve both high precision and recall simultaneously. In this paper, we propose a novel dual complementary hashing (DCH) approach to learn the codes with multiple hash tables. In our method, not only the projection for each bit inside a hash table has the property of error-correcting but also the different hash tables complement each other. Therefore, the binary codes learned by our approach are more powerful for fast similarity search. Extensive experiments on publicly available datasets demonstrate the effectiveness of our approach. (c) 2013 Elsevier B.V. All rights reserved.	[Li, Peng; Cheng, Jian; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Cheng, J (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.	jcheng@nlpr.ia.ac.cn			973 Program [2010CB327905]; National Natural Science Foundation of China [61170127, 60975010, 60833006, 61070104]	This work was supported in part by the 973 Program under Project 2010CB327905, by the National Natural Science Foundation of China under Grants 61170127, 60975010, 60833006, and 61070104.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Chung F. R. K., 1997, SPECTRAL GRAPH THEOR; Cormen T. H., 2001, INTRO ALGORITHMS, V2nd; Datar M., 2004, P 20 ANN S COMP GEOM, P253, DOI 10.1145/997817.997857; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Krizhevsky A., 2009, TECHNICAL REPORT; Kumar N, 2008, LECT NOTES COMPUT SC, V5303, P364, DOI 10.1007/978-3-540-88688-4_27; Liu W., 2011, P 28 INT C MACH LEAR; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Oliva A., 2001, IJCV; Pang YW, 2012, NEUROCOMPUTING, V85, P6, DOI 10.1016/j.neucom.2011.12.006; Pang YW, 2011, COMPUT VIS IMAGE UND, V115, P352, DOI 10.1016/j.cviu.2010.10.010; Pang YW, 2012, NEUROCOMPUTING, V83, P64, DOI 10.1016/j.neucom.2011.11.008; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shakhnarovich G, 2006, NEAREST NEIGHBOR MET; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Silpa-Anan C., 2008, P IEEE C COMP VIS PA, P1, DOI [DOI 10.1109/CVPR.2008.4587638, 10.1109/CVPR.2008.4587638]; Stein B., 2007, P 30 ANN INT ACM SIG, P527, DOI 10.1145/1277741.1277832; Torralba A, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2008.4587633; Wang J., 2010, P INT C MACH LEARN; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400; Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919; Wang S., 2010, P ACM INT C MULT; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Weiss Y., 2008, P NEUR INF PROC SYST, P1753; Xu H., 2011, P 13 IEEE INT C COMP; Zhang D., 2010, P 33 INT ACM SIGIR C	33	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	NOV 23	2013	120				SI		83	89		10.1016/j.neucom.2012.07.053		7	Computer Science, Artificial Intelligence	Computer Science	223XZ	WOS:000324847100010		
J	Ruiz-Rodriguez, JC; Ruiz-Sanmartin, A; Ribas, V; Caballero, J; Garcia-Roche, A; Riera, J; Nuvials, X; de Nadal, M; de Sola-Morales, O; Serra, J; Rello, J				Ruiz-Rodriguez, Juan C.; Ruiz-Sanmartin, Adolf; Ribas, Vicent; Caballero, Jesus; Garcia-Roche, Alejandra; Riera, Jordi; Nuvials, Xavier; de Nadal, Miriam; de Sola-Morales, Oriol; Serra, Joaquim; Rello, Jordi			Innovative continuous non-invasive cuffless blood pressure monitoring based on photoplethysmography technology	INTENSIVE CARE MEDICINE			English	Article						Non-invasive hemodynamic monitoring; Blood pressure; Photoplethysmography; Critical care; Machine learning	ACCURACY; DEVICE	To develop and validate a continuous non-invasive blood pressure (BP) monitoring system using photoplethysmography (PPG) technology through pulse oximetry (PO). This prospective study was conducted at a critical care department and post-anesthesia care unit of a university teaching hospital. Inclusion criteria were critically ill adult patients undergoing invasive BP measurement with an arterial catheter and PO monitoring. Exclusion criteria were arrhythmia, imminent death condition, and disturbances in the arterial or the PPG curve morphology. Arterial BP and finger PO waves were recorded simultaneously for 30 min. Systolic arterial pressure (SAP), mean arterial pressure (MAP), and diastolic arterial pressure (DAP) were extracted from computer-assisted arterial pulse wave analysis. Inherent traits of both waves were used to construct a regression model with a Deep Belief Network-Restricted Boltzmann Machine (DBN-RBM) from a training cohort of patients and in order to infer BP values from the PO wave. Bland-Altman analysis was performed. A total of 707 patients were enrolled, of whom 135 were excluded. Of the 572 studied, 525 were assigned to the training cohort (TC) and 47 to the validation cohort (VC). After data processing, 53,708 frames were obtained from the TC and 7,715 frames from the VC. The mean prediction biases were -2.98 +/- A 19.35, -3.38 +/- A 10.35, and -3.65 +/- A 8.69 mmHg for SAP, MAP, and DAP respectively. BP can be inferred from PPG using DBN-RBM modeling techniques. The results obtained with this technology are promising, but its intrinsic variability and its wide limits of agreement do not allow clinical application at this time.	[Ruiz-Rodriguez, Juan C.; Ruiz-Sanmartin, Adolf; Caballero, Jesus; Garcia-Roche, Alejandra; Riera, Jordi; Serra, Joaquim; Rello, Jordi] Vall dHebron Univ Hosp, Crit Care Dept, Barcelona, Spain; [Ruiz-Rodriguez, Juan C.; Ruiz-Sanmartin, Adolf; Caballero, Jesus; Serra, Joaquim] Univ Autonoma Barcelona, Vall dHebron Res Inst VHIR, Shock Organ Dysfunct & Resuscitat SODIR Res Grp, E-08193 Barcelona, Spain; [Ruiz-Rodriguez, Juan C.; Riera, Jordi; de Nadal, Miriam; Serra, Joaquim; Rello, Jordi] Univ Autonoma Barcelona, Dept Med, E-08193 Barcelona, Spain; [Ribas, Vicent] Ctr Recerca Matemat, Barcelona, Spain; [Nuvials, Xavier] Arnau de Vilanova Univ Hosp IRB, Crit Care Dept, Lleida, Spain; [de Nadal, Miriam] Vall dHebron Univ Hosp, Dept Anaesthesiol, Barcelona, Spain; [de Sola-Morales, Oriol] Inst Invest Sanitaria Pere Virgili, Tarragona, Spain; [Rello, Jordi] Univ Autonoma Barcelona, Vall dHebron Res Inst VHIR, E-08193 Barcelona, Spain; [Rello, Jordi] CIBERES, Barcelona, Spain; [Ruiz-Rodriguez, Juan C.] Hosp Univ Vall dHebron, Serv Med Intens, Area Gen, Barcelona 08035, Spain	Ruiz-Rodriguez, JC (reprint author), Hosp Univ Vall dHebron, Serv Med Intens, Area Gen, Pg Vall dHebron 119-129, Barcelona 08035, Spain.	jcruiz@vhebron.net	Ruiz-Rodriguez, Juan Carlos/H-7703-2012; de Nadal, Miriam/; , Vicent/; Rello, Jordi/	de Nadal, Miriam/0000-0002-4559-2463; , Vicent/0000-0002-7266-6106; Rello, Jordi/0000-0003-0676-6210	Sabirmedical SL (Parc Cientific de Barcelona, Barcelona, Spain); Ministry of Industry, Tourism and Trade, Government of Spain [TSI-020100-2009-204, TSI-020100-2010-625]	This work was supported in part by Sabirmedical SL (Parc Cientific de Barcelona, Barcelona, Spain), and by "Avanza" grants (Ministry of Industry, Tourism and Trade, Government of Spain, TSI-020100-2009-204 and TSI-020100-2010-625).	Allen J, 2007, PHYSIOL MEAS, V28, pR1, DOI 10.1088/0967-3334/28/3/R01; ANDERSON RR, 1981, J INVEST DERMATOL, V77, P13, DOI 10.1111/1523-1747.ep12479191; Belani K, 1999, ANESTHESIOLOGY, V91, P686, DOI 10.1097/00000542-199909000-00021; Belani KG, 1999, CAN J ANAESTH, V46, P488; Bur A, 2000, CRIT CARE MED, V28, P371, DOI 10.1097/00003246-200002000-00014; Dueck R, 2012, J CLIN MONIT COMPUT, V26, P75, DOI 10.1007/s10877-012-9336-2; Findlay JY, 2006, ANESTH ANALG, V102, P690, DOI 10.1213/01.ane.0000196512.96019.e4; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Janelle GM, 2006, ANESTH ANALG, V102, P484, DOI 10.1213/01.ane.0000194873.52453.bd; Jones DW, 2003, JAMA-J AM MED ASSOC, V289, P1027, DOI 10.1001/jama.289.8.1027; Laurent C, 2005, MED BIOL ENG COMPUT, V43, P131, DOI 10.1007/BF02345134; Lehman LWH, 2013, CRIT CARE MED, V41, P34, DOI 10.1097/CCM.0b013e318265ea46; Lorente L, 2003, MED INTENSIVA, V27, P224; McCann ME, 2005, ANESTH ANALG, V101, P978, DOI 10.1213/01.ane.0000171231.29328.9f; Monte-Moreno E, 2011, ARTIF INTELL MED, V53, P127, DOI 10.1016/j.artmed.2011.05.001; Panerai RB, 2007, BLOOD PRESS MONIT, V12, P369; Penaz J., 1973, 10 INT C MED BIOL EN, P104; Saugel B, 2012, INTENS CARE MED, V38, P1471, DOI 10.1007/s00134-012-2617-x; Scheer BV, 2002, CRIT CARE, V6, P198; STOLT M, 1993, AM J HYPERTENS, V6, P66; Suzuki S, 2008, IEEE ENG MED BIO, P1327, DOI 10.1109/IEMBS.2008.4649409; Suzuki S, 2009, IEEE ENG MED BIO, P6765, DOI 10.1109/IEMBS.2009.5332505; Szmuk P, 2008, ANAESTHESIA, V63, P307, DOI 10.1111/j.1365-2044.2007.05369.x; Warren DK, 2006, CRIT CARE MED, V34, P2084, DOI 10.1097/01.CCM.0000227648.15804.2D	25	2	2	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0342-4642			INTENS CARE MED	Intensive Care Med.	SEP	2013	39	9					1618	1625		10.1007/s00134-013-2964-2		8	Critical Care Medicine	General & Internal Medicine	195BD	WOS:000322675500012	23740275	
J	Wilbert, N; Zito, T; Schuppner, RB; Jedrzejewski-Szmek, Z; Wiskott, L; Berkes, P				Wilbert, Niko; Zito, Tiziano; Schuppner, Rike-Benjamin; Jedrzejewski-Szmek, Zbigniew; Wiskott, Laurenz; Berkes, Pietro			Building extensible frameworks for data processing: The case of MDP, Modular toolkit for Data Processing	JOURNAL OF COMPUTATIONAL SCIENCE			English	Article						Machine learning; Python; Scientific computing; Computational neuroscience	SLOW FEATURE ANALYSIS; RECOGNITION	Data processing is a ubiquitous task in scientific research, and much energy is spent on the development of appropriate algorithms. It is thus relatively easy to find software implementations of the most common methods. On the other hand, when building concrete applications, developers are often confronted with several additional chores that need to be carried out beside the individual processing steps. These include for example training and executing a sequence of several algorithms, writing code that can be executed in parallel on several processors, or producing a visual description of the application. The Modular toolkit for Data Processing (MDP) is an open source Python library that provides an implementation of several widespread algorithms and offers a unified framework to combine them to build more complex data processing architectures. In this paper we concentrate on some of the newer features of MOP, focusing on the choices made to automatize repetitive tasks for users and developers. In particular, we describe the support for parallel computing and how this is implemented via a flexible extension mechanism. We also briefly discuss the support for algorithms that require bi-directional data flow. (C) 2011 Elsevier B.V. All rights reserved.	[Wilbert, Niko; Wiskott, Laurenz] Humboldt Univ, Inst Theoret Biol, Frankfurt, Germany; [Wilbert, Niko; Zito, Tiziano; Schuppner, Rike-Benjamin; Wiskott, Laurenz] Bernstein Ctr Computat Neurosci, Berlin, Germany; [Zito, Tiziano] Berlin Inst Technol, Berlin, Germany; [Jedrzejewski-Szmek, Zbigniew] Univ Warsaw, Inst Expt Phys, PL-00325 Warsaw, Poland; [Wiskott, Laurenz] Ruhr Univ Bochum, Inst Neuroinformat, Bochum, Germany; [Berkes, Pietro] Brandeis Univ, Natl Volen Ctr Complex Syst, Waltham, MA USA	Wilbert, N (reprint author), Humboldt Univ, Inst Theoret Biol, Frankfurt, Germany.	mail@nikowilbert.de	Jedrzejewski-Szmek, Zbigniew/	Jedrzejewski-Szmek, Zbigniew/0000-0002-6548-7951			Bengio Y., 2009, LEARNING DEEP ARCHIT; Bergstra J., 2010, P PYTH SCI COMP C SC; Berkes P, 2005, LECT NOTES COMPUT SC, V3697, P285; Bryson AE, 1969, APPL OPTIMAL CONTROL; Chang C. C., 2011, ACM T INTELLIGENT SY, V2; DEMSAR J, 2004, KNOWLEDGE DISCOVERY, V3202, P537, DOI 10.1007/978-3-540-30116-5_58; Fisher RA, 1936, ANN EUGENIC, V7, P179; Foster I., 1995, DESIGNING BUILDING P; Franzius M, 2011, NEURAL COMPUT, V23, P2289, DOI 10.1162/NECO_a_00171; Franzius M, 2007, PLOS COMPUT BIOL, V3, P1605, DOI 10.1371/journal.pcbi.0030166; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; Garcia Samuel, 2009, Front Neuroinform, V3, P14, DOI 10.3389/neuro.11.014.2009; Hanke M., FRONTIERS NEUROINFOR, V3, DOI [10.3389/neuro.11.003.2009, DOI 10.3389/NEUR0.11.003.2009]; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Jones E., 2001, SCIPY OPEN SOURCE SC; Kickzales G., 1997, P ECOOP IEEE FINL, P220; Klockner A., CORR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schaul T, 2010, J MACH LEARN RES, V11, P743; Seljebotn D., 2009, P 8 PYTH SCI C; Sole VA, 2007, SPECTROCHIM ACTA B, V62, P63, DOI 10.1016/j.sab.2006.12.002; Sonnenburg S, 2010, J MACH LEARN RES, V11, P1799; Sutter H, 2005, DR DOBBS J, V30, P16; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Zito T., 2008, FRONTIERS NEUROINFOR, V2, DOI [10.3389/neuro.11.008.2008, DOI 10.3389/NEUR0.11.008.2008]	28	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1877-7503			J COMPUT SCI-NETH	J. Comput. Sci.	SEP	2013	4	5			SI		345	351		10.1016/j.jocs.2011.10.005		7	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	270CS	WOS:000328297100005		
J	Li, P; Cheng, J; Lu, HQ				Li, Peng; Cheng, Jian; Lu, Hanqing			Dual local consistency hashing with discriminative projections selection	SIGNAL PROCESSING			English	Article						Image search; Hashing; Dual local consistency; PCA; Discriminative projection selection	APPROXIMATE NEAREST-NEIGHBOR; ALGORITHM; DIMENSIONS; IMAGES	Semantic hashing is a promising way to accelerate similarity search, which designs compact binary codes for a large number of images so that semantically similar images are mapped to close codes. Retrieving similar neighbors is then simply accomplished by retrieving images that have codes within a small Hamming distance of the code of the query. However, most of the existing hashing approaches, such as spectral hashing (SH), learn the binary codes by preserving the global similarity, which do not have full discriminative power. In this paper, we propose a dual local consistency hashing method which not only makes the similar images have the same codes but also dissimilar images with different codes. Moreover, we propose a PCA projection selecting scheme that choose the most discriminative projection for each bit of the codes. Therefore, the binary codes learned by our approach are more powerful and discriminative for similarity search. Extensive experiments are conducted on publicly available datasets and the comparison results demonstrate that our approach can outperform the state-of-art methods. (C) 2012 Elsevier B.V. All rights reserved.	[Li, Peng; Cheng, Jian; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Cheng, J (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.	jcheng@nlpr.ia.ac.cn			973 Programm [2010CB327905]; National Natural Science Foundation of China [61170127, 60975010, 60833006, 61070104]	This work was supported in part by the 973 Programm under Project 2010CB327905, by the National Natural Science Foundation of China under Grant 61170127, 60975010, 60833006, and 61070104.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Chung F. R. K., 1997, SPECTRAL GRAPH THEOR; Cormen T. H., 2001, INTRO ALGORITHMS, V2nd; Datar M., 2004, P 20 ANN S COMP GEOM, P253, DOI 10.1145/997817.997857; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jiang Y., 2011, PROCEEDINGS OF THE 1; Krizhevsky A., 2009, TECHNICAL REPORT; Kumar N, 2008, LECT NOTES COMPUT SC, V5303, P364, DOI 10.1007/978-3-540-88688-4_27; Liu W., 2011, PROCEEDINGS OF THE 2; Mu Y., 2011, PROCEEDINGS OF THE 1; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Oliva A., 2001, IJCV; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schapire R.E., 2002, PROCEEDINGS OF MSRI; Shakhnarovich G, 2006, NEAREST NEIGHBOR MET; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Silpa-Anan C., 2008, P IEEE C COMP VIS PA, P1, DOI [DOI 10.1109/CVPR.2008.4587638, 10.1109/CVPR.2008.4587638]; Stein B., 2007, P 30 ANN INT ACM SIG, P527, DOI 10.1145/1277741.1277832; Torralba A, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2008.4587633; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang J., 2010, PROCEEDINGS OF INTER; Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400; Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045; Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Weiss Y., 2008, P NEUR INF PROC SYST, P1753; Yang J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/ICPR.2008.4761824; Zhang D., 2010, PROCEEDINGS OF THE 3	33	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684	1879-2677		SIGNAL PROCESS	Signal Process.	AUG	2013	93	8			SI		2256	2264		10.1016/j.sigpro.2012.05.035		9	Engineering, Electrical & Electronic	Engineering	139KP	WOS:000318581900015		
J	Canevari, C; Badino, L; D'Ausilio, A; Fadiga, L; Metta, G				Canevari, Claudia; Badino, Leonardo; D'Ausilio, Alessandro; Fadiga, Luciano; Metta, Giorgio			Modeling speech imitation and ecological learning of auditory-motor maps	FRONTIERS IN PSYCHOLOGY			English	Article						speech imitation; mirror neurons; automatic speech classification; phone classification; acoustic-to-articulatory mapping; speaker normalization; deep neural networks	PREMOTOR CORTEX; PERCEPTION; LANGUAGE; RECOGNITION; SYSTEM; SOUNDS; BRAIN; IDENTIFICATION; ACQUISITION; MECHANISMS	Classical models of speech consider an antero-posterior distinction between perceptive and productive functions. However, the selective alteration of neural activity in speech motor centers, via transcranial magnetic stimulation, was shown to affect speech discrimination. On the automatic speech recognition (ASR) side, the recognition systems have classically relied solely on acoustic data, achieving rather good performance in optimal listening conditions. The main limitations of current ASR are mainly evident in the realistic use of such systems. These limitations can be partly reduced by using normalization strategies that minimize inter speaker variability by either explicitly removing speakers peculiarities or adapting different speakers to a reference model. In this paper we aim at modeling a motor-based imitation learning mechanism in ASR. We tested the utility of a speaker normalization strategy that uses motor representations of speech and compare it with strategies that ignore the motor domain. Specifically, we first trained a regressor through state-of-the-art machine learning techniques to build an auditory-motor mapping, in a sense mimicking a human learner that tries to reproduce utterances produced by other speakers. This auditory-motor mapping maps the speech acoustics of a speaker into the motor plans of a reference speaker. Since, during recognition, only speech acoustics are available, the mapping is necessary to "recover" motor information. Subsequently, in a phone classification task, we tested the system on either one of the speakers that was used during training or a new one. Results show that in both cases the motor-based speaker normalization strategy slightly but significantly outperforms all other strategies where only acoustics is taken into account.	[Canevari, Claudia; Badino, Leonardo; D'Ausilio, Alessandro; Fadiga, Luciano; Metta, Giorgio] Ist Italiano Tecnol, Robot Brain & Cognit Sci Dept, Mirror Neurons & Int Lab, I-16163 Genoa, Italy; [Fadiga, Luciano] Univ Ferrara, Sect Human Physiol, Dipartimento Sci Biomed & Terapie Avanzate, I-44100 Ferrara, Italy; [Metta, Giorgio] Univ Plymouth, Ctr Robot & Neural Syst, Plymouth PL4 8AA, Devon, England	Badino, L (reprint author), Ist Italiano Tecnol, Robot Brain & Cognit Sci Dept, Via Morego 30, I-16163 Genoa, Italy.	leonardo.badino@iit.it					Anastasakos T., 1994, P IEEE INT C AC SPEE, P433; Anastasakos T., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607807; Badino L., TOPICS COGN IN PRESS; Badino L., 2012, DEEP LEVEL ACOUSTIC; Badino L., 2012, P IEEE SPOK LANG TEC, P370, DOI [10.1109/SLT.2012.6424252, DOI 10.1109/SLT.2012.6424252]; Ben Youssef A., 2012, P INT PORTL OR; Bernal B, 2009, BRAIN, V132, P2309, DOI 10.1093/brain/awp206; Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198; Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006; Canevari C., 2013, P INT LION; Castellini C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024055; Catani M, 2005, BRAIN, V128, P2224, DOI 10.1093/brain/awh622; Cox S. J., 1989, P ICASSP GLASG; D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017; D'Ausilio A, 2011, BRAIN LANG, V118, P9, DOI 10.1016/j.bandl.2011.02.007; Eide H., 1996, P IEEE INT C AC SPEE, P346; Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x; Fogassi L., 2010, WIRES COGN SCI, V2, P22, DOI DOI 10.1002/WCS.89; FOWLER CA, 1986, J PHONETICS, V14, P3; Fridriksson J, 2010, J NEUROSCI, V30, P11057, DOI 10.1523/JNEUROSCI.1120-10.2010; Friston KJ, 2011, BIOL CYBERN, V104, P137, DOI 10.1007/s00422-011-0424-z; Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857; Garagnani M, 2008, EUR J NEUROSCI, V27, P492, DOI 10.1111/j.1460-9568.2008.06015.x; Ghosh P. K., 2011, P ICASSP PRAG; Grimaldi M., 2008, P LANG TEACH ROM; Grush R., 2004, BEHAV BRAIN SCI, V27, P396, DOI DOI 10.1017/S0140525X04000093; Grush R, 2004, BEHAV BRAIN SCI, V27, P377; Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013; GUENTHER FH, 1995, PSYCHOL REV, V102, P594; Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393; Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI [10.1038/nrn3158, 10.1038/nrn2158]; Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang X., 2001, SPOKEN LANGUAGE PROC; Huang X., 1992, P ICASSP, P465, DOI 10.1109/ICASSP.1992.225871; Iacoboni M, 2008, J PHYSIOLOGY-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003; Iacoboni M, 1999, SCIENCE, V286, P2526, DOI 10.1126/science.286.5449.2526; King S, 2007, J ACOUST SOC AM, V121, P723, DOI 10.1121/1.2404622; Kroger BJ, 2009, SPEECH COMMUN, V51, P793, DOI 10.1016/j.specom.2008.08.002; Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533; Londei A, 2010, HUM BRAIN MAPP, V31, P567, DOI 10.1002/hbm.20888; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064; Mitra V, 2012, J ACOUST SOC AM, V131, P2270, DOI 10.1121/1.3682038; Mohamed A., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288863; MOHAMED AR, 2012, P IEEE T AUDIO SPEEC, V20, P14, DOI DOI 10.1109/TASL.2011.2109382; Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009; Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103; Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811; Raichle Marcus E, 2010, Trends Cogn Sci, V14, P180, DOI 10.1016/j.tics.2010.01.008; Richmond K., 2011, P INTERSPEECH, P1505; Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230; Rudzicz F, 2011, IEEE T AUDIO SPEECH, V19, P947, DOI 10.1109/TASL.2010.2072499; Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002; Shahin AJ, 2009, NEUROIMAGE, V44, P1133, DOI 10.1016/j.neuroimage.2008.09.045; Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147; Sroka JJ, 2005, SPEECH COMMUN, V45, P401, DOI 10.1016/j.specom.2004.11.009; Uria B., 2011, P NIPS 2011 WORKSH D; Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0; WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037//0012-1649.24.5.672; Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263	61	2	2	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	JUN 27	2013	4								364	10.3389/fpsyg.2013.00364		12	Psychology, Multidisciplinary	Psychology	AA4ER	WOS:000331048600001	23818883	
J	Testolin, A; Stoianov, I; De Grazia, MD; Zorzi, M				Testolin, Alberto; Stoianov, Ivilin; De Grazia, Michele De Filippo; Zorzi, Marco			Deep unsupervised learning on a desktop PC: a primer for cognitive scientists	FRONTIERS IN PSYCHOLOGY			English	Article						deep neural networks; unsupervised learning; hierarchical generative models; cognitive modeling; parallel-computing architectures; GPUs; MPI; computer cluster	GENERATIVE MODELS; NEURAL-NETWORKS; RECOGNITION; EMERGENCE; ALGORITHM; NETS	Deep belief networks hold great promise for the simulation of human cognition because they show how structured and abstract representations may emerge from probabilistic unsupervised learning. These networks build a hierarchy of progressively more complex distributed representations of the sensory data by fitting a hierarchical generative model. However, learning in deep networks typically requires big datasets and it can involve millions of connection weights, which implies that simulations on standard computers are unfeasible. Developing realistic, medium-to-large-scale learning models of cognition would therefore seem to require expertise in programing parallel-computing hardware, and this might explain why the use of this promising approach is still largely confined to the machine learning community. Here we show how simulations of deep unsupervised learning can be easily performed on a desktop PC by exploiting the processors of low cost graphic cards (graphic processor units) without any specific programing effort, thanks to the use of high-level programming routines (available in MATLAB or Python). We also show that even an entry-level graphic card can outperform a small high-performance computing cluster in terms of learning time and with no loss of learning quality. We therefore conclude that graphic card implementations pave the way for a widespread use of deep learning among cognitive scientists for modeling cognition and behavior.	[Testolin, Alberto; Stoianov, Ivilin; De Grazia, Michele De Filippo; Zorzi, Marco] Univ Padua, Dept Gen Psychol, Computat Cognit Neurosci Lab, I-35131 Padua, Italy; [Zorzi, Marco] IRCCS San Camillo Neurorehabil Hosp, Venice Lido, Italy	Testolin, A (reprint author), Univ Padua, Dept Gen Psychol, Via Venezia 12, I-35131 Padua, Italy.	alberto.testolin@gmail.com; marco.zorzi@unipd.it	Zorzi, Marco/B-7863-2008				ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Aisa B, 2008, NEURAL NETWORKS, V21, P1146, DOI 10.1016/j.neunet.2008.06.016; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2011, P ICML WORKSH UNS TR, V7, P1; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Clark A., 2012, BEHAV BRAIN SCI, P1; De Grazia MD, 2012, COGN PROCESS, V13, pS141, DOI 10.1007/s10339-012-0478-4; Dean J., 2012, ADV NEURAL INFORM PR, V25, P1232; Fernandez J, 2006, LECT NOTES COMPUT SC, V3992, P518; Hertz J, 1991, INTRO THEORY NEURAL; Hinton G., 2012, ADV NEURAL INF PROCE, V25, P2456; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 1997, PHILOS T ROY SOC B, V352, P1177; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Honglak L., 2008, ADV NEURAL INF PROCE, V20, P873; Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Le Q. V., 2012, INT C MACH LEARN NEW; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Lee Victor W, 2010, Computer Architecture News, V38; Margaris A, 2007, INFORMATICA-LITHUAN, V18, P79; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mutch Jim, 2010, MITCSAILTR2010013; Nickolls J., 2008, QUEUE, V6, P40, DOI DOI 10.1145/1365490.1365500; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; O'Reilly RC, 1998, TRENDS COGN SCI, V2, P455, DOI 10.1016/S1364-6613(98)01241-8; Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Plesser HE, 2007, LECT NOTES COMPUT SC, V4641, P672; Raina R., 2009, INT C MACH LEARN, P1; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Share D. L., 1995, COGNITION, V55, P219; SHARE DL, 1995, COGNITION, V55, P151, DOI 10.1016/0010-0277(94)00645-2; Sharma G, 2008, INT J PARALLEL PROG, V37, P3; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Stoianov I, 2012, NAT NEUROSCI, V15, P194, DOI 10.1038/nn.2996; Stoianov I., 2012, EUR S ART NEUR NETW; Tieleman T., 2010, 2010002 UTML TR; Wilson DR, 2003, NEURAL NETWORKS, V16, P1429, DOI 10.1016/S0893-6080(03)00138-2; Yu D, 2012, IEEE T AUDIO SPEECH, V20, P4, DOI 10.1109/TASL.2011.2173371; Zorzi M, 2010, EUR J COGN PSYCHOL, V22, P836, DOI 10.1080/09541440903435621	48	2	2	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	MAY 6	2013	4								251	10.3389/fpsyg.2013.00251		10	Psychology, Multidisciplinary	Psychology	AA2RH	WOS:000330941300001	23653617	
J	Fosler-Lussier, E; He, YZ; Jyothi, P; Prabhavalkar, R				Fosler-Lussier, Eric; He, Yanzhang; Jyothi, Preethi; Prabhavalkar, Rohit			Conditional Random Fields in Speech, Audio, and Language Processing	PROCEEDINGS OF THE IEEE			English	Article						Automatic speech recognition (ASR); natural language processing (NLP); random fields; statistical learning	RECOGNITION; MODELS; ALGORITHM; ERROR; CLASSIFICATION; OPTIMIZATION	Conditional random fields (CRFs) are probabilistic sequence models that have been applied in the last decade to a number of applications in audio, speech, and language processing. In this paper, we provide a tutorial overview of CRF technologies, pointing to other resources for more in-depth discussion; in particular, we describe the common linear-chain model as well as a number of common extensions within the CRF family of models. An overview of the mathematical techniques used in training and evaluating these models is also provided, as well as a discussion of the relationships with other probabilistic models. Finally, we survey recent work in speech, audio, and language processing to show how the same CRF technology can be deployed in different scenarios.	[Fosler-Lussier, Eric; He, Yanzhang; Jyothi, Preethi; Prabhavalkar, Rohit] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	Fosler-Lussier, E (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	fosler@cse.ohio-state.edu; hey@cse.ohio-state.edu; jyothi@cse.ohio-state.edu; prabhava@cse.ohio-state.edu			National Science Foundation (NSF) [IIS-0643901, IIS-0905420]	Manuscript received April 6, 2012; revised September 3, 2012; accepted December 27, 2012. Date of publication April 12, 2013; date of current version April 17, 2013. This work was supported by the National Science Foundation (NSF) CAREER Grant IIS-0643901 and the NSF Grant IIS-0905420. The opinions and conclusions expressed in this work are those of the authors and not of any funding agency.	Abdel-Haleem Y. H., 2006, THESIS U SHEFFIELD S; Andrew G., 2006, P 2006 C EMP METH NA, P465, DOI 10.3115/1610075.1610140; Benetos E, 2011, IEEE J-STSP, V5, P1111, DOI 10.1109/JSTSP.2011.2162394; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bottou L., 1991, THESIS U PARIS 9 PAR; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Bridle J. S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Chien JT, 2010, SPEECH COMMUN, V52, P223, DOI 10.1016/j.specom.2009.10.003; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Finkel J., 2009, P HUM LANG TECHN 200, P326, DOI 10.3115/1620754.1620802; Finkel J. R., 2008, P 46 ANN M ASS COMP, P959; Finkel J. R., 2009, P 2009 C EMP METH NA, P141; Finkel J.R., 2005, P 43 ANN M ASS COMP, P363, DOI 10.3115/1219840.1219885; Fujii Y, 2011, INT CONF ACOUST SPEE, P5036; Gales M, 2012, IEEE SIGNAL PROC MAG, V29, P70, DOI 10.1109/MSP.2012.2207140; Gunawardana A., 2005, P INTERSPEECH, V2, P1117; Hahn S, 2011, IEEE T AUDIO SPEECH, V19, P1569, DOI 10.1109/TASL.2010.2093520; Hammersley J. M., 1971, MARKOV FIELDS FINITE; Hastie T., 2001, ELEMENTS STAT LEARNI; He XD, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2008.926652; He Y., 1898, P ANN C INT SPEECH C; Heigold G, 2011, IEEE T AUDIO SPEECH, V19, P1138, DOI 10.1109/TASL.2010.2082532; HEIGOLD G, 2008, P ANN C INT SPEECH C, P273; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hifny Y, 2009, IEEE T AUDIO SPEECH, V17, P354, DOI 10.1109/TASL.2008.2010286; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang X., 2001, SPOKEN LANGUAGE PROC; Joder C, 2011, IEEE T AUDIO SPEECH, V19, P2385, DOI 10.1109/TASL.2011.2134092; Johnson D., 2004, ICSI QUICKNET SOFTWA; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Kim M, 2010, PATTERN RECOGN, V43, P3683, DOI 10.1016/j.patcog.2010.05.013; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Klein D., 2007, P HUM LANG TECHN C N; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Konig Y., 1995, P ADV NEUR INF PROC, P388; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kubo Y., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288844; Kudo T., 2004, P 2004 C EMP METH NA, V2004, P230; Lafferty J., 2004, P 21 INT C MACH LEAR; Lafferty J.D., 2001, IEEE INT C MACH LEAR, V18, P282; Layton M., 2006, THESIS CAMBRIDGE U C; Layton MI, 2006, INT CONF ACOUST SPEE, P129; Lee C.-H., 2010, INT TUT SESS MAK CHI; Lehr M, 2011, IEEE T AUDIO SPEECH, V19, P1360, DOI 10.1109/TASL.2010.2090518; Liang P., 2005, THESIS MIT CAMBRIDGE; McCallum A., 2000, P 17 INT C MACH LEAR, P591; McCallum A, 2003, P 7 C NAT LANG LEARN, V4, P188, DOI DOI 10.3115/1119176.1119206; McDermott E., 1997, THESIS WASEDA U TOKY; Minka T., 2001, 758 CARN MELL U STAT; Morris J., 2010, THESIS OHIO STATE U; Morris J, 2008, IEEE T AUDIO SPEECH, V16, P617, DOI 10.1109/TASL.2008.916057; Morris J., 2009, P INTERSPEECH, P3063; Murphy K. P., 2002, THESIS U CALIFORNIA; Murphy K.P., 1999, LNCS, V1747, P467; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Peng F., 2004, P HUM LANG TECHN C N, P329; Peng J., 2009, ADV NEURAL INFORM PR, V22, P1419; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Prabhavalkar R, 2010, INT CONF ACOUST SPEE, P5534, DOI 10.1109/ICASSP.2010.5495222; Prabhavalkar R., 2011, P IEEE WORKSH AUT SP, P77; Prabhavalkar R., 2009, P ANN C INT SPEECH C, P856; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ragni A., 2011, P IEEE WORKSH AUT SP, P119; Ratnaparkhi A, 1996, P C EMP METH NAT LAN, P133; Riedmiller M., 1993, P IEEE INT C NEUR NE, V1, P586, DOI DOI 10.1109/ICNN.1993.298623; Roark B., 2004, P ACL, P47, DOI 10.3115/1218955.1218962; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Sarawagi S., 2004, P 17 NEUR INF PROC S, P1185; Sha F., 2003, P 2003 C N AM CHAPT, V1, P134, DOI 10.3115/1073445.1073473; Shi YX, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1707; Smith N. A., 2005, P HUM LANG TECHN C C, P475, DOI 10.3115/1220575.1220635; SUNG YH, 2009, P IEEE ASRU, P107; Sutton C, 2007, J MACH LEARN RES, V8, P693; Sutton C., 2004, COLLECTIVE SEGMENTAT; Sutton Charles, 2007, INTRO STAT RELATIONA, P93; SUZUKI J, 2006, P 21 INT C COMP LING, P217, DOI 10.3115/1220175.1220203; Taskar B., 2003, ADV NEURAL INFORM PR, P25; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vapnik V. N., 1995, NATURE STAT LEARNING; Wainwright Martin J, 2008, Foundations and Trends in Machine Learning, V1, DOI 10.1561/2200000001; Wallach H., 2002, THESIS U EDINBURGH E; Wang D, 2011, IEEE SIGNAL PROC LET, V18, P122, DOI 10.1109/LSP.2010.2098440; Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12; Wiesler S., 2011, P ADV NEUR INF PROC, P657; Xiong Y, 2009, INFORM SCIENCES, V179, P169, DOI 10.1016/j.ins.2008.09.018; Yu D., 2010, P INTERSPEECH, P2986; Yu D, 2010, IEEE J-STSP, V4, P965, DOI 10.1109/JSTSP.2010.2075990; Zweig G, 2011, INT CONF ACOUST SPEE, P5044; Zweig G, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P152, DOI 10.1109/ASRU.2009.5372916; Zweig G., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288835	93	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219	1558-2256		P IEEE	Proc. IEEE	MAY	2013	101	5			SI		1054	1075		10.1109/JPROC.2013.2248112		22	Engineering, Electrical & Electronic	Engineering	133SK	WOS:000318159900004		
J	Chen, F; Yu, HM; Hu, R; Zeng, XX			IEEE	Chen, Fei; Yu, Huimin; Hu, Roland; Zeng, Xunxun			Deep Learning Shape Priors for Object Segmentation	2013 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2013	Portland, OR	IEEE, IEEE Comp Soc			KERNEL DENSITY-ESTIMATION; LEVEL SET SEGMENTATION; ACTIVE CONTOURS	In this paper we introduce a new shape-driven approach for object segmentation. Given a training set of shapes, we first use deep Boltzmann machine to learn the hierarchical architecture of shape priors. This learned hierarchical architecture is then used to model shape variations of global and local structures in an energetic form. Finally, it is applied to data-driven variational methods to perform object extraction of corrupted data based on shape probabilistic representation. Experiments demonstrate that our model can be applied to dataset of arbitrary prior shapes, and can cope with image noise and clutter, as well as partial occlusions.	[Chen, Fei; Yu, Huimin; Hu, Roland] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China	Chen, F (reprint author), Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.						Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen F, 2013, IEEE T IMAGE PROCESS, V22, P992, DOI 10.1109/TIP.2012.2226044; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Cremers D., 2008, CVPR; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Eslami S., 2012, CVPR; Fundana K, 2008, INT J COMPUT VISION, V80, P289, DOI 10.1007/s11263-008-0160-6; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Latecki L. J., 2000, CVPR; Lee H., 2009, CONVOLUTIONAL DEEP B; Leventon M., 2000, CVPR; Mohamed A., 2010, NIPS; Prisacariu Victor Adrian, 2011, CVPR; Rathi Y, 2007, IEEE T IMAGE PROCESS, V16, P1370, DOI 10.1109/TIP.2007.894244; Rousson M., 2002, ECCV; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757; Salakhutdinov R., 2009, 12 INT C AI STAT; Salakhutdinov R., 2010, 13 INT C AI STAT; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355	22	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-0-7695-4989-7	PROC CVPR IEEE			2013							1870	1877		10.1109/CVPR.2013.244		8	Computer Science, Artificial Intelligence	Computer Science	BA0ER	WOS:000331094301118		
J	Dahl, GE; Stokes, JW; Deng, L; Yu, D			IEEE	Dahl, George E.; Stokes, Jack W.; Deng, Li; Yu, Dong			LARGE-SCALE MALWARE CLASSIFICATION USING RANDOM PROJECTIONS AND NEURAL NETWORKS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Malware Classification; Random Projections; Neural Network	MALICIOUS EXECUTABLES	Automatically generated malware is a significant problem for computer users. Analysts are able to manually investigate a small number of unknown files, but the best large-scale defense for detecting malware is automated malware classification. Malware classifiers often use sparse binary features, and the number of potential features can be on the order of tens or hundreds of millions. Feature selection reduces the number of features to a manageable number for training simpler algorithms such as logistic regression, but this number is still too large for more complex algorithms such as neural networks. To overcome this problem, we used random projections to further reduce the dimensionality of the original input space. Using this architecture, we train several very large-scale neural network systems with over 2.6 million labeled samples thereby achieving classification results with a two-class error rate of 0.49% for a single neural network and 0.42% for an ensemble of neural networks.	[Dahl, George E.] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	Dahl, GE (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.						Arnold William, 2000, P 2000 INT VIR B C, P5; Bayer Ulrich, 2006, P 15 ANN C EUR I COM; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Idika N., 2007, SURVEY MALWARE DETEC; KEPHART JO, 1995, P IJCAI 95 MONTR AUG, P985; Kolter JZ, 2006, J MACH LEARN RES, V7, P2721; Li P, 2006, P 12 ACM SIGKDD INT, P287, DOI 10.1145/1150402.1150436; Li Ping, 2006, P 19 ANN C LEARN THE, P635; Manning C.D., 2009, INTRO INFORM RETRIEV; Mehdi SB, 2009, P 11 ANN C GEN EV CO, P1553, DOI 10.1145/1569901.1570109; Menahem E, 2009, COMPUT STAT DATA AN, V53, P1483, DOI 10.1016/j.csda.2008.10.015; Moser A, 2007, P IEEE S SECUR PRIV, P231, DOI 10.1109/SP.2007.17; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schultz MG, 2001, P IEEE S SECUR PRIV, P38, DOI 10.1109/SECPRI.2001.924286; Seide F., 2011, P INTERSPEECH, P437; Tesauro GJ, 1996, IEEE EXPERT, V11, P5, DOI 10.1109/64.511768	17	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							3422	3426				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611503116		
J	Gao, JB; Guo, Y; Yin, M			IEEE	Gao, Junbin; Guo, Yi; Yin, Ming			RESTRICTED BOLTZMANN MACHINE APPROACH TO COUPLE DICTIONARY TRAINING FOR IMAGE SUPER-RESOLUTION	2013 20TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP 2013)	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	20th IEEE International Conference on Image Processing (ICIP)	SEP 15-18, 2013	Melbourne, AUSTRALIA	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Restricted Boltzmann Machine; Image Super-resolution; Dictionary Learning; Sparse Modelling	NEURAL-NETWORKS	Image super-resolution means forming high-resolution images from low-resolution images. In this paper, we develop a new approach based on the deep Restricted Boltzmann Machines (RBM) for image super-resolution. The RBM architecture has ability of learning a set of visual patterns, called dictionary elements from a set of training images. The learned dictionary will be then used to synthesize high resolution images. We test the proposed algorithm on both benchmark and natural images, comparing with several other techniques. The visual quality of the results has also been assessed by both human evaluation and quantitative measurement.	[Gao, Junbin] Charles Sturt Univ, Sch Comp & Math, Bathust, NSW 2795, Australia; [Guo, Yi] CSIRO Math Informat & Stat, N Ryde, NSW 1670, Australia; [Yin, Ming] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Guangdong, Peoples R China	Gao, JB (reprint author), Charles Sturt Univ, Sch Comp & Math, Bathust, NSW 2795, Australia.	jbgao@csu.edu.au; yi.guo@csiro.au; yiming@gdut.edu.cn					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chang H, 2004, PROC CVPR IEEE, P275; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669; Geoffrey Hinton, 2010, 2010003 UTML TR U TO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Lee H., 2008, ADV NEURAL INFORM PR, V20; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190; Sun J., 2008, P IEEE C COMP VIS PA, P1, DOI 10.1145/1509315.1509373; Tipping M. E., 2003, ADV NEURAL INFORM PR, V16; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang Jianchao, 2010, SUPER RESOLUTION IMA, P3; Yang Jianchao, 2012, IEEE T IMAG IN PRESS, Vxxx	16	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		978-1-4799-2341-0	IEEE IMAGE PROC			2013							499	503				5	Imaging Science & Photographic Technology	Imaging Science & Photographic Technology	BC3FD	WOS:000351597600101		
J	McCoppin, R; Koester, N; Rude, HN; Rizki, M; Tamburino, L; Freeman, A; Mendoza-Schrock, O		Blowers, M; MendozaSchrock, O		McCoppin, Ryan; Koester, Nathan; Rude, Howard N.; Rizki, Mateen; Tamburino, Louis; Freeman, Andrew; Mendoza-Schrock, Olga			Electro-optical seasonal weather and gender data collection	MACHINE INTELLIGENCE AND BIO-INSPIRED COMPUTATION: THEORY AND APPLICATIONS VII	Proceedings of SPIE		English	Proceedings Paper	Conference on Machine Intelligence and Bio-inspired Computation - Theory and Applications VII	MAY 02, 2013	Baltimore, MD	SPIE		gender recognition; SWAG; electro-optical; operating conditions; boosting; unsupervised feature learning	RECOGNITION	This paper describes the process used to collect the Seasonal Weather And Gender (SWAG) dataset; an electro-optical dataset of human subjects that can be used to develop advanced gender classification algorithms. Several novel features characterize this ongoing effort (1) the human subjects self-label their gender by performing a specific action during the data collection and (2) the data collection will span months and even years resulting in a dataset containing realistic levels and types of clothing corresponding to the various seasons and weather conditions. It is envisioned that this type of data will support the development and evaluation of more robust gender classification systems that are capable of accurate gender recognition under extended operating conditions.	[McCoppin, Ryan; Koester, Nathan; Rude, Howard N.; Rizki, Mateen; Tamburino, Louis] Wright State Univ, Dept Comp Sci & Engr, Dayton, OH 45435 USA	McCoppin, R (reprint author), Wright State Univ, Dept Comp Sci & Engr, Dayton, OH 45435 USA.						Abdi H., 2010, WILEY INTERDISCIP RE, V2, P433, DOI DOI 10.1002/WICS.101; BAY H, 2006, P EUR C COMP VIS, P404; Bengio Y., 2012, ARXIV12065538; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Collins M., 2009, P COMP VIS IEEE, P1235; Collins R. T., 2000, SYSTEM VIDEP SURVEIL, V102; Dalal N, 2005, PROC CVPR IEEE, P886; Fouts A, 2012, PROC SPIE, V8402, DOI 10.1117/12.921880; Guo G., 2009, COMP VIS ACCV, P236; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang F.J., 2006, P COMP VIS PATT REC, V1, P284; Le Q., 2012, P ICML 2012; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; McCoppin R., 2012, P IEEE NAT AER EL C; Mendoza-Schrock O., 2010, P SOC PHOTO-OPT INS, V7704; MIT, PED DAT; Opitz D., 1999, POPULAR ENSEMBLE MET, V11, P169; Price R., 2012, P IEEE NAT AER EL C; Sakla W., 2012, P IEEE APPL IM PATT; Schapire R. E., 1998, COLT, V98, P80; van de Sande K. E. A., 2010, PAMI, V32, P1582, DOI DOI 10.1109/TPAMI.2009.154; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/ICCV.2009.5459207; Zhai S., 2012, P J MACHINE LEARNING, V14, P1; Zheng YH, 2011, NEUROCOMPUTING, V74, P3158, DOI 10.1016/j.neucom.2011.04.020	25	2	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-9542-6	PROC SPIE			2013	8751								UNSP 87510H	10.1117/12.2018903		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	BGM83	WOS:000323523400012		
J	Swietojanski, P; Ghoshal, A; Renals, S			IEEE	Swietojanski, Pawel; Ghoshal, Arnab; Renals, Steve			HYBRID ACOUSTIC MODELS FOR DISTANT AND MULTICHANNEL LARGE VOCABULARY SPEECH RECOGNITION	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Distant Speech Recognition; Deep Neural Networks; Microphone Arrays; Beamforming; Meeting recognition	MEETINGS	We investigate the application of deep neural network (DNN)-hidden Markov model (HMM) hybrid acoustic models for far-field speech recognition of meetings recorded using microphone arrays. We show that the hybrid models achieve significantly better accuracy than conventional systems based on Gaussian mixture models (GMMs). We observe up to 8% absolute word error rate (WER) reduction from a discriminatively trained GMM baseline when using a single distant microphone, and between 4-6% absolute WER reduction when using beamforming on various combinations of array channels. By training the networks on audio from multiple channels, we find the networks can recover significant part of accuracy difference between the single distant microphone and beamformed configurations. Finally, we show that the accuracy of a network recognising speech from a single distant microphone can approach that of a multi-microphone setup by training with data from other microphones.	[Swietojanski, Pawel; Ghoshal, Arnab; Renals, Steve] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland	Swietojanski, P (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland.	p.swietojanski@ed.ac.uk; a.ghoshal@ed.ac.uk; s.renals@ed.ac.uk					Adami A, 2002, P ICSLP, P21; Anguera X, 2007, IEEE T AUDIO SPEECH, V15, P2011, DOI 10.1109/TASL.2007.902460; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bergstra J, 2010, P SCIPY; Bitzer J, 2001, DIGITAL SIGNAL PROC, P19; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Fiscus J. G., 2006, P LREC; Fiscus JG, 2008, LECT NOTES COMPUT SC, V4625, P373; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Ghoshal A, 2013, INT CONF ACOUST SPEE, P7319, DOI 10.1109/ICASSP.2013.6639084; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Hain T, 2012, IEEE T AUDIO SPEECH, V20, P486, DOI 10.1109/TASL.2011.2163395; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hori T, 2012, IEEE T AUDIO SPEECH, V20, P499, DOI 10.1109/TASL.2011.2164527; KNAPP CH, 1976, IEEE T ACOUST SPEECH, V24, P320, DOI 10.1109/TASSP.1976.1162830; Kumatani K, 2009, IEEE T AUDIO SPEECH, V17, P994, DOI 10.1109/TASL.2009.2015090; Kumatani K, 2012, IEEE SIGNAL PROC MAG, V29, P127, DOI 10.1109/MSP.2012.2205285; Marino D., 2011, INTERSPEECH, P1281; Povey D., 2011, P IEEE ASRU; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; Bourlard H, 2012, MULTIMODAL SIGNAL PROCESSING: HUMAN INTERACTIONS IN MEETINGS, P232; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Seide F, 2011, P IEEE ASRU; Seltzer M., 2013, P ICASSP; Seltzer ML, 2006, IEEE T AUDIO SPEECH, V14, P2109, DOI 10.1109/TASL.2006.872614; Stolcke A, 2008, LECT NOTES COMPUTER, V4625, P373; Stolcke A., 2011, P IEEE ICASSP; Swietojanski P, 2012, P IEEE WORKSH SPOK L; Vesely K., 2013, P INTERSPEECH; Wolfel M., 2009, DISTANT SPEECH RECOG; Wolfel M, 2006, P ICSLP	33	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							285	290				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800049		
J	Zhou, P; Liu, C; Liu, QF; Dai, LR; Jiang, H			IEEE	Zhou, Pan; Liu, Cong; Liu, Qingfeng; Dai, Lirong; Jiang, Hui			A CLUSTER-BASED MULTIPLE DEEP NEURAL NETWORKS METHOD FOR LARGE VOCABULARY CONTINUOUS SPEECH RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		LVCSR; DNN; state clustering; cluster-based multi-DNN; parallelization among GPUs		Recently a pre-trained context-dependent hybrid deep neural network (DNN) and HMM method has achieved significant performance gain in many large-scale automatic speech recognition (ASR) tasks. However, the error back-propagation (BP) algorithm for training neural networks is sequential in nature and is hard to parallelize into multiple computing threads. Therefore, training a deep neural network is extremely time-consuming even with a modern GPU board. In this paper we have proposed a new acoustic modelling framework to use multiple DNNs instead of a single DNN to compute the posterior probabilities of tied HMM states. In our method, all tied states of context-dependent HMMs are first grouped into several disjoined clusters based on the training data associated with these HMM states. Then, several hierarchically structured DNNs are trained separately for these disjoined clusters of data using multiple GPUs. In decoding, the final posterior probability of each tied HMM state can be calculated based on output posteriors from multiple DNNs. We have evaluated the proposed method on a 64-hour Mandarin transcription task and 309-hour Switchboard Hub5 task. Experimental results have shown that the new method using cluster-based multiple DNNs can achieve over 5 times reduction in total training time with only negligible performance degradation (about 1-2% in average) when using 3 or 4 GPUs respectively.	[Zhou, Pan; Dai, Lirong] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China	Zhou, P (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China.	pan2005@mail.ustc.edu.cn; congliu2@iflytek.com; qfliu@iflytek.com; lrdai@ustc.edu.cn; hj@cse.yorku.ca					Bengio Y., 2006, NIPS, P153; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Chen X., 2012, INTERSPEECH; Dahl G., 2011, ICASSP; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng Li, 2011, P AS PAC SIGN INF PR; Farber P., 1997, QUICKNET MULTISPERT; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, INTERSPEECH; Kontar Stanislav, 2006, 12 INT C SOFT COMP M; Le Q.V., 2012, ICML; Mohamed A., 2012, IEEE T AUDIO SPEECH; Pan J., 2012, 8 INT S CHIN SPOK LA; Park J., 2009, INTERSPEECH; Scanzio S., 2010, ICASSP; Seide F., 2011, INTERSPEECH, P437; Vesely K., 2010, INTERSPEECH; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zhu Q., 2005, INTERSPEECH 2005, P2141	20	2	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							6650	6654				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611506163		
J	Calitoiu, D; Oommen, BJ; Nussbaum, D				Calitoiu, Dragos; Oommen, B. John; Nussbaum, Doron			Large-scale neuro-modeling for understanding and explaining some brain-related chaotic behavior	SIMULATION-TRANSACTIONS OF THE SOCIETY FOR MODELING AND SIMULATION INTERNATIONAL			English	Article						brain modeling; large-scale models; controlling chaos	SMALL-WORLD NETWORKS; GRAPH-THEORETICAL ANALYSIS; STRANGE ATTRACTORS; OLFACTORY CORTEX; PIRIFORM CORTEX; SURROGATE-DATA; SYSTEMS; SCHIZOPHRENIA; EEG; INTERDEPENDENCE	Numerous studies, and in particular the works of Freeman and others, have shown the possible relevance of chaos to various functions of the brain. The verification of these claims has mostly been experimental in nature, since a formal mathematical analysis is often intractable because of the sheer magnitude of the number (billions) of neurons in the brain. Consequently, a formal analysis of such models has only been achieved for 'small-scale systems' of neural networks (NNs). As opposed to this, the aim of this paper is to understand how we can model the brain as a so-called 'large-scale system' for analyzing various neurological conditions such as epilepsy, schizophrenia, etc. In particular, we explore a large-scale NN model suitable for the piriform cortex which is acclaimed for its chaotic behavior from clinical experiments. In addition, the piriform cortex is easy to model because it appears to be 'almost independent' of other portions of the brain. To achieve this, we describe its behavior by moving the analysis from the time space into the phase space of the electroencephalogram (EEG) signals. Although the model of the piriform cortex contains hundreds of variables, we utilize the concept that useful information can be extracted from a single EEG signal which, in turn, can be perceived as a time series computed from the artificial electrodes. Indeed, this transformation, i.e. from the time space of a time series to its corresponding phase space, is considered mandatory to extract the nonlinear characteristics related with chaos. By studying the piriform cortex model in this manner, we demonstrate that we can generate certain desirable phenomena by modifying some of the underlying control parameters. More specifically, we investigate the problem of density and strength, the problem of connectivity and the problem of stimulus frequency, and show their relevance to neurological conditions such as epilepsy and schizophrenia.	[Calitoiu, Dragos; Oommen, B. John; Nussbaum, Doron] Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5B6, Canada; [Oommen, B. John] Univ Agder, Grimstad, Norway	Oommen, BJ (reprint author), Carleton Univ, Sch Comp Sci, 1125 Colonel Dr, Ottawa, ON K1S 5B6, Canada.	oommen@scs.carleton.ca			NSERC, the Natural Sciences and Engineering Research Council of Canada	This work was partially supported by NSERC, the Natural Sciences and Engineering Research Council of Canada.	Abbott LF, 1999, NEURAL CODES DISTRIB; Amaral LAN, 2004, EUR PHYS J B, V38, P147, DOI 10.1140/epjb/e2004-00110-5; Amaral LAN, 2000, P NATL ACAD SCI USA, V97, P11149, DOI 10.1073/pnas.200327197; Arnold J, 1999, PHYSICA D, V134, P419; Babloyantz A., 1998, DIMENSIONS ENTROPIES; Baldi P, 1998, J COMPUT NEUROSCI, V5, P285, DOI 10.1023/A:1008887028637; Barabasi AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bessar E., 1960, BIOPHYSICAL PHYSL SY; BHALLA US, 1993, J NEUROPHYSIOL, V69, P1948; Bhalla US, 1997, J COMPUT NEUROSCI, V4, P221, DOI 10.1023/A:1008819818970; Bondarenko VE, 2005, P IEEE INT C NEUR NE, V2, P774; Bower JM, 1995, INTRO NEURAL ELECT N, P3; Bower J.M., 1998, BOOK GENESIS; Bradley E., 1999, INTELLIGENT DATA ANA; Breakspear M, 2002, NEUROIMAGE, V16, P822, DOI 10.1006/nimg.2002.1106; BRESSLER SL, 1995, BRAIN RES REV, V20, P288, DOI 10.1016/0165-0173(94)00016-I; Brette R, 2007, J COMPUT NEUROSCI, V23, P349, DOI 10.1007/s10827-007-0038-6; Brunel J., 2000, J COMPUTAT NEUROSCI, V8, P183; Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; Buzsaki G., 2006, RHYTHMS BRAIN; Catani M, 2005, BRAIN, V128, P2224, DOI 10.1093/brain/awh622; Claverol ET, 2002, IEEE T BIO-MED ENG, V49, P921, DOI 10.1109/TBME.2002.801986; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Deco G, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000092; de Garis H, 2010, NEUROCOMPUTING, V74, P3, DOI 10.1016/j.neucom.2010.08.004; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fell A, 2001, UC DAVIS MAGAZINE, V19, P1; Freeman W. J., 1992, International Journal of Bifurcation and Chaos in Applied Sciences and Engineering, V2, DOI 10.1142/S0218127492000653; Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011; GRASSBERGER P, 1983, PHYS REV LETT, V50, P346, DOI 10.1103/PhysRevLett.50.346; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; HABERLY LB, 1985, CHEM SENSES, V10, P219, DOI 10.1093/chemse/10.2.219; HABERLY LB, 1989, TRENDS NEUROSCI, V12, P258, DOI 10.1016/0166-2236(89)90025-8; Haken H., 2008, SPRINGER SERIES SYNE; HASSELMO ME, 1993, TRENDS NEUROSCI, V16, P218, DOI 10.1016/0166-2236(93)90159-J; He Y, 2008, J NEUROSCI, V28, P8148, DOI 10.1523/JNEUROSCI.2433-08.2008; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Holden AV, 1986, CHAOS NONLINEAR SCI; Izhikevich EM, 2008, P NATL ACAD SCI USA, V105, P3593, DOI 10.1073/pnas.0712231105; Jardri R, 2011, AM J PSYCHIAT, V168, P73, DOI 10.1176/appi.ajp.2010.09101522; Kaplan J. L, 1979, LECT NOTES MATH, V730, P204; Kramer MA, 2008, EPILEPSY RES, V79, P173, DOI 10.1016/j.eplepsyres.2008.02.002; Lamberts J, 2000, NEUROPSYCHOBIOLOGY, V41, P149, DOI 10.1159/000026647; Linden H, 2011, NEURON, V72, P859, DOI 10.1016/j.neuron.2011.11.006; Luders H, 2003, DEEP BRAIN STIMULATI; McIntyre DC, 2002, EPILEPSY RES, V50, P79, DOI 10.1016/S0920-1211(02)00071-2; Micheloyannis S, 2006, SCHIZOPHR RES, V87, P60, DOI 10.1016/j.schres.2006.06.028; Miikkulainen R, 2005, COMPUTATIONAL MAPS V; Natarajah K, 2004, BIOMEDICAL ENG ONLIN, V7, P31; Neville KR, 2004, SYNAPTIC ORG BRAIN, P415; Olabi B, 2011, BIOL PSYCHIAT, V70, P88, DOI 10.1016/j.biopsych.2011.01.032; Pecora LM, 1998, PHYS REV E, V58, P347, DOI 10.1103/PhysRevE.58.347; Ponten SC, 2007, CLIN NEUROPHYSIOL, V118, P918, DOI 10.1016/j.clinph.2006.12.002; PRITCHARD WS, 1995, PSYCHOPHYSIOLOGY, V32, P486, DOI 10.1111/j.1469-8986.1995.tb02100.x; Quiroga RQ, 2000, PHYS REV E, V61, P5142, DOI 10.1103/PhysRevE.61.5142; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; RAPP P E, 1989, Brain Topography, V2, P99, DOI 10.1007/BF01128848; Rapp PE, 1993, BIOLOGIST, V40, P89; Rubinov M, 2007, HUMAN BRAIN MAPPING, V30, P403; Sanchez-Vives MV, 2008, CEREB CORTEX, V18, P1179, DOI 10.1093/cercor/bhm152; Schiff SJ, 1996, PHYS REV E, V54, P6708, DOI 10.1103/PhysRevE.54.6708; Schindler KA, 2008, CHAOS, V18, DOI 10.1063/1.2966112; Singer W, 1999, NEURON, V24, P49, DOI 10.1016/S0896-6273(00)80821-1; Soltesz I, 2008, COMPUTATIONAL NEUROSCIENCE IN EPILEPSY, P1; Stam CJ, 2005, CLIN NEUROPHYSIOL, V116, P2266, DOI 10.1016/j.clinph.2005.06.011; Stam C J, 2007, Cereb Cortex, V17, P92, DOI 10.1093/cercor/bhj127; THEILER J, 1992, PHYSICA D, V58, P77, DOI 10.1016/0167-2789(92)90102-S; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang L, 2009, HUM BRAIN MAPP, V30, P638, DOI 10.1002/hbm.20530; Weinberger DR, 2002, ARCH GEN PSYCHIAT, V59, P553, DOI 10.1001/archpsyc.59.6.553; Wilson M, 1989, METHODS NEURONAL MOD, P291; Wilson M, 1988, NEURAL INFORMATION P, P114; Wilson M., 1990, THESIS CALTECH PASAD; Wright JJ, 1996, BEHAV BRAIN SCI, V19, P285	77	2	2	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0037-5497	1741-3133		SIMUL-T SOC MOD SIM	Simul.-Trans. Soc. Model. Simul. Int.	NOV	2012	88	11					1316	1337		10.1177/0037549712450331		22	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	025BY	WOS:000310160200003		
J	Baldi, P; Lu, ZQ				Baldi, Pierre; Lu, Zhiqin			Complex-valued autoencoders	NEURAL NETWORKS			English	Article						Autoencoders; Unsupervised learning; Complex numbers; Complex neural networks; Critical points; Linear networks; Principal component analysis; EM algorithm; Deep architectures; Differential geometry	NEURAL-NETWORKS; ALGORITHM	Autoencoders are unsupervised machine learning circuits, with typically one hidden layer, whose learning goal is to minimize an average distortion measure between inputs and outputs. Linear autoencoders correspond to the special case where only linear transformations between visible and hidden variables are used. While linear autoencoders can be defined over any field, only real-valued linear autoencoders have been studied so far. Here we study complex-valued linear autoencoders where the components of the training vectors and adjustable matrices are defined over the complex field with the L-2 norm. We provide simpler and more general proofs that unify the real-valued and complex-valued cases, showing that in both cases the landscape of the error function is invariant under certain groups of transformations. The landscape has no local minima, a family of global minima associated with Principal Component Analysis, and many families of saddle points associated with orthogonal projections onto sub-space spanned by sub-optimal subsets of eigenvectors of the covariance matrix. The theory yields several iterative, convergent, learning algorithms, a clear understanding of the generalization properties of the trained autoencoders, and can equally be applied to the hetero-associative case when external targets are provided. Partial results on deep architecture as well as the differential geometry of autoencoders are also presented. The general framework described here is useful to classify autoencoders and identify general properties that ought to be investigated for each class, illuminating some of the connections between autoencoders, unsupervised learning, clustering, Hebbian learning, and information theory. (C) 2012 Elsevier Ltd. All rights reserved.	[Baldi, Pierre] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA; [Lu, Zhiqin] Univ Calif Irvine, Dept Math, Irvine, CA 92697 USA	Baldi, P (reprint author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.	pfbaldi@ics.uci.edu			 [NSF IIS-0513376];  [NIH LM010235];  [NIH-NLM T15 LM07443];  [NSF DMS-09-04653]	Work in part supported by grants NSF IIS-0513376, NIH LM010235, and NIH-NLM T15 LM07443 to PB, and NSF DMS-09-04653 to ZL. We wish to acknowledge Sholeh Forouzan for running the simulation for Fig. 3.	Amari S., 1990, DIFFERENTIAL GEOMETR; Amari SI, 2007, METHODS INFORM GEOME; Baldi P., 2012, J MACHINE L IN PRESS; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Bell Robert M., 2007, ACM SIGKDD EXPLORATI, V9, P75, DOI DOI 10.1145/1345448.1345465; Bengio Y., 2007, LARGE SCALE KERNEL M; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hirose Akira, 2003, COMPLEX VALUED NEURA, V5; Lang S., 1984, ALGEBRA; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; McEliece R. J., 1977, THEORY INFORM CODING; MEYER C. D., 2000, MATRIX ANAL APPL LIN; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Oja E., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000475; OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9; Roux N.L., 2010, NEURAL COMPUT, V22, P2192; Spivak M., 1999, COMPREHENSIVE INTRO, V1; Takacs G, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P267; Vincent P., 2011, NEURAL COMPUT, P1; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294	26	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	SEP	2012	33						136	147		10.1016/j.neunet.2012.04.011		12	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	987PZ	WOS:000307430900013	22622264	
J	Dai, ZW; Lucke, J			IEEE	Dai, Zhenwen; Luecke, Joerg			Unsupervised Learning of Translation Invariant Occlusive Components	2012 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 16-21, 2012	Providence, RI	IEEE			GRAPHICAL MODELS; EM ALGORITHM; IMAGES; CLASSIFICATION; SYNERGIES; LAYERS	We study unsupervised learning of occluding objects in images of visual scenes. The derived learning algorithm is based on a probabilistic generative model which parameterizes object shapes, object features and the background. No assumptions are made for the object orders in depth or the objects' planar positions. Parameter optimization is thus subject to the large combinatorics of depth orders and positions. Previous approaches constrained this combinatorics but were still only able to learn a very small number of objects. By applying a novel variational EM approach, we show that even without constraints on the object combinatorics, a relatively large number of objects can be learned. In different numerical experiments, our unsupervised approach extracts explicit object representations with object masks and object features closely aligned with the true objects in the scenes. We investigate the robustness of the approach and the use of the learned representations for inference. Furthermore, we demonstrate generality of the approach by applying it to grayscale images, color-vector images, and Gabor-vector images as well as to motion trajectory data for which the extracted components correspond to motion primitives.	[Dai, Zhenwen; Luecke, Joerg] Goethe Univ Frankfurt, Dept Phys, Frankfurt Inst Adv Studies, D-6000 Frankfurt, Germany	Dai, ZW (reprint author), Goethe Univ Frankfurt, Dept Phys, Frankfurt Inst Adv Studies, D-6000 Frankfurt, Germany.	dai@fias.uni-frankfurt.de; luecke@fias.uni-frankfurt.de					Barthelemy Q, 2012, IEEE T SIGNAL PROCES, V60, P1597, DOI 10.1109/TSP.2012.2183129; Conner D. C., 2006, ROBOTICS SCI SYSTEMS; d'Avella A, 2005, P NATL ACAD SCI USA, V102, P3076, DOI 10.1073/pnas.0500199102; Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861; Frank A, 2010, UCI MACHINE LEARNING; Frey B. J., 2003, CVPR; Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Ghahramani Z., 2000, NATURE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jackson JD, 2008, INT J COMPUT VISION, V79, P71, DOI 10.1007/s11263-007-0097-1; Jepson AD, 2002, LECT NOTES COMPUT SC, V2350, P692; Jojic N., 2001, CVPR; Kannan A., 2007, IJCV, V77, P87; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253; Lee H., 2007, NIPS, P801; Lucke J, 2010, J MACH LEARN RES, V11, P2855; Lucke J., 2009, NIPS, V22, P1069; Nene S.A., 1996, CUCS00696; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Roux N. L., 2011, NEURAL COMPUT, V23, P593; Schoenemann T., 2008, CVPR; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Todorov E, 2004, P ANN INT IEEE EMBS, V26, P4637; Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0; Vecchio D. D., 2003, AUTOMATICA; Wang CH, 2009, IEEE I CONF COMP VIS, P747; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Williams B. H., 2008, THESIS; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096	31	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4673-1228-8	PROC CVPR IEEE			2012							2400	2407				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BBZ37	WOS:000309166202071		
J	Gaida, D; Wolf, C; Meyer, C; Stuhlsatz, A; Lippel, J; Back, T; Bongards, M; McLoone, S				Gaida, D.; Wolf, C.; Meyer, C.; Stuhlsatz, A.; Lippel, J.; Back, T.; Bongards, M.; McLoone, S.			State estimation for anaerobic digesters using the ADM1	WATER SCIENCE AND TECHNOLOGY			English	Article						ADM1; anaerobic digestion; GerDA; optimal control; pattern recognition; state estimation	GRASS-SILAGE; PLANTS; MANURE; BIOGAS	The optimization of full-scale biogas plant operation is of great importance to make biomass a competitive source of renewable energy. The implementation of innovative control and optimization algorithms, such as Nonlinear Model Predictive Control, requires an online estimation of operating states of biogas plants. This state estimation allows for optimal control and operating decisions according to the actual state of a plant. In this paper such a state estimator is developed using a calibrated simulation model of a full-scale biogas plant, which is based on the Anaerobic Digestion Model No. 1. The use of advanced pattern recognition methods shows that model states can be predicted from basic online measurements such as biogas production, CH4 and CO2 content in the biogas, pH value and substrate feed volume of known substrates. The machine learning methods used are trained and evaluated using synthetic data created with the biogas plant model simulating over a wide range of possible plant operating regions. Results show that the operating state vector of the modelled anaerobic digestion process can be predicted with an overall accuracy of about 90%. This facilitates the application of state-based optimization and control algorithms on full-scale biogas plants and therefore fosters the production of eco-friendly energy from biomass.	[Gaida, D.; Wolf, C.; Bongards, M.] Cologne Univ Appl Sci, Inst Automat & Ind IT, D-51643 Gummersbach, Germany; [Gaida, D.; Back, T.] Leiden Univ, Leiden Inst Adv Comp Sci, NL-2333 CA Leiden, Netherlands; [Meyer, C.] Dusseldorf Univ Appl Sci, Dept Elect Engn, D-40474 Dusseldorf, Germany; [Stuhlsatz, A.; Lippel, J.] Dusseldorf Univ Appl Sci, Dept Mech & Proc Engn, D-40474 Dusseldorf, Germany; [Wolf, C.; McLoone, S.] Natl Univ Ireland Maynooth, Dept Elect Engn, Maynooth, Kildare, Ireland	Gaida, D (reprint author), Cologne Univ Appl Sci, Inst Automat & Ind IT, Steinmullerallee 1, D-51643 Gummersbach, Germany.	daniel.gaida@fh-koeln.de					Batstone D.J., 2002, 13 IWA TASK GROUP MA; Bernard O, 2001, WATER SCI TECHNOL, V43, P175; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Duda RO, 2000, PATTERN CLASSIFICATI; Etzkorn C., 2008, THESIS COLOGNE U APP; Fortuna L, 2007, ADV IND CONTROL, P1, DOI 10.1007/978-1-84628-480-9; Gaida D., 2011, ISSC 2011, V1, P219; Gaida D., 2011, PROGR BIOGAS, V2, P67; Gerardi M.H., 2003, WASTEWATER MICROBIOL; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaiantilal A., 2010, RANDOMFOREST MATLAB; Koch K, 2010, BIORESOURCE TECHNOL, V101, P8158, DOI 10.1016/j.biortech.2010.06.009; Lange Hach, 2011, AN ISE SC COMB SENS; Lubken M, 2007, WATER RES, V41, P4085, DOI 10.1016/j.watres.2007.05.061; Page DI, 2008, WATER SCI TECHNOL, V58, P689, DOI 10.2166/wst.2008.678; Rawlings JB, 2006, COMPUT CHEM ENG, V30, P1529, DOI 10.1016/j.compchemeng.2006.05.031; Schmitz, 2004, LANDWIRTSCHAFTSKAMME; Schoen MA, 2009, BIORESOURCE TECHNOL, V100, P5648, DOI 10.1016/j.biortech.2009.06.033; Stuhlsatz A, 2010, P INT C PATT REC ICP; Stuhlsatz A, 2010, P 2010 INT JOINT C N; Wichern M, 2009, BIORESOURCE TECHNOL, V100, P1675, DOI 10.1016/j.biortech.2008.09.030; Wichern M., 2007, GULZOWER FACHGESPRAC, V27, P172; Wiese J, 2009, WATER SCI TECHNOL, V60, P321, DOI 10.2166/wst.2009.337; Wolf C., 2010, MODELLBASIERTE PROZE	24	2	2	IWA PUBLISHING	LONDON	ALLIANCE HOUSE, 12 CAXTON ST, LONDON SW1H0QS, ENGLAND	0273-1223			WATER SCI TECHNOL	Water Sci. Technol.		2012	66	5					1088	1095		10.2166/wst.2012.286		8	Engineering, Environmental; Environmental Sciences; Water Resources	Engineering; Environmental Sciences & Ecology; Water Resources	988GQ	WOS:000307477600024	22797239	
B	Kingsbury, B; Sainath, TN; Soltau, H			International Speech Communications Association	Kingsbury, Brian; Sainath, Tara N.; Soltau, Hagen			Scalable Minimum Bayes Risk Training of Deep Neural Network Acoustic Models Using Distributed Hessian-free Optimization	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		deep learning; discriminative training; second-order optimization; distributed computing	SPEECH	Training neural network acoustic models with sequence-discriminative criteria, such as state-level minimum B ayes risk (sMBR), been shown to produce large improvements in performance over cross-entropy. However, because they entail the processing of lattices, sequence criteria are much more computationally intensive than cross-entropy. We describe a distributed neural network training algorithm, based on Hessian-free optimization, that scales to deep networks and large data sets. For the sMBR criterion, this training algorithm is faster than stochastic gradient descent by a factor of 5.5 and yields a 4.4% relative improvement in word error rate on a 50-hour broadcast news task. Distributed Hessian-free sMBR training yields relative reductions in word error rate of 7-13% over cross-entropy training with stochastic gradient descent on two larger tasks: Switchboard and DARPA RATS noisy Levantine Arabic. Our best Switchboard DBN achieves a word error rate of 16.4% on rt03-FSH.	[Kingsbury, Brian; Sainath, Tara N.; Soltau, Hagen] IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Kingsbury, B (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	bedk@us.ibm.com; tsainath@us.ibm.com; hsoltau@us.ibm.com					Bahl L. R., 1986, P ICASSP; Byrd RH, 2011, SIAM J OPTIMIZ, V21, P977, DOI 10.1137/10079923X; Chen SF, 2006, IEEE T AUDIO SPEECH, V14, P1596, DOI 10.1109/TASL.2006.879814; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Glorot X., 2010, P AISTATS, P249; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kaiser J., 2000, P ICSLP; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Martens J., 2010, P INT C MACH LEARN I; MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Povey D, 2007, INT CONF ACOUST SPEE, P321; Povey D., 2002, P ICASSP; Sainath T., 2012, IMPROVEMENTS USING D; Sainath T.N., 2011, P ASRU, P30; Schraudolph NN, 2002, NEURAL COMPUT, V14, P1723, DOI 10.1162/08997660260028683; Seide F., 2011, P ASRU, P24; Seide F., 2011, P INTERSPEECH, P437; Soltau H, 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), DOI 10.1109/SLT.2010.5700829; Vinyals O., 2011, P NIPS WORKSH OPT HI; Wang G., 2011, P INTERSPEECH, P441	21	2	2	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							10	13				4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BFO97	WOS:000320827200003		
J	Plahl, C; Sainath, TN; Ramabhadran, B; Nahamoo, D			IEEE	Plahl, Christian; Sainath, Tara N.; Ramabhadran, Bhuvana; Nahamoo, David			IMPROVED PRE-TRAINING OF DEEP BELIEF NETWORKS USING SPARSE ENCODING SYMMETRIC MACHINES	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		Deep belief network; pre-training; neural network feature extraction; sparse representation		Restricted Boltzmann Machines (RBM) continue to be a popular methodology to pre-train weights of Deep Belief Networks (DBNs). However, the RBM objective function cannot be maximized directly. Therefore, it is not clear what function to monitor when deciding to stop the training, leading to a challenge in managing the computational costs. The Sparse Encoding Symmetric Machine (SESM) has been suggested as an alternative method for pre-training. By placing a sparseness term on the NN output codebook, SESM allows the objective function to be optimized directly and reliably be monitored as an indicator to stop the training. In this paper, we explore SESM to pre-train DBNs and apply this the first time to speech recognition. First, we provide a detailed analysis comparing the behavior of SESM and RBM. Second, we compare the performance of SESM pre-trained and RBM pre-trained DBNs on TIMIT and a 50 hour English Broadcast News task. Results indicate that pre-trained DBNs using SESM and RBMs achieve comparable performance and outperform randomly initialized DBNs with SESM providing a much easier stopping criterion relative to RBM.	[Plahl, Christian] Rhein Westfal TH Aachen, Dept Comp Sci, Lehrstuhl Informat 6, Aachen, Germany	Plahl, C (reprint author), Rhein Westfal TH Aachen, Dept Comp Sci, Lehrstuhl Informat 6, Aachen, Germany.	plahl@cs.rwth-aachen.de; tsainath@us.ibm.com; bhuvana@us.ibm.com; nahamoo@us.ibm.com					Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lamel L. F., 1986, P DARPA SPEECH REC W, P100; Mohamed Abdel-rahman, 2010, INTERSPEECH, P1692; Ranzato Marc'Aurelio, 2007, ADV NEURAL INFORM PR; Sainath T., 2011, P IEEE AUT SPEECH RE; Seide F., 2011, INTERSPEECH, P437; Soltau H., 2010, IEEE WORKSH SPOK LAN, P97; SUNDERMEYER M, 2011, P IEEE INT C AC SPEE, P2212	9	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							4165	4168				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381404059		
J	Wang, LW; Li, Y; Jia, JY; Sun, J; Wipf, D; Rehg, JM			IEEE	Wang, Liwei; Li, Yin; Jia, Jiaya; Sun, Jian; Wipf, David; Rehg, James M.			Learning Sparse Covariance Patterns for Natural Scenes	2012 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 16-21, 2012	Providence, RI	IEEE				For scene classification, patch-level linear features do not always work as well as handcrafted features. In this paper, we present a new model to greatly improve the usefulness of linear features in classification by introducing covariance patterns. We analyze their properties, discuss the fundamental importance, and present a generative model to properly utilize them. With this set of covariance information, in our framework, even the most naive linear features that originally lack the vital ability in classification become powerful. Experiments show that the performance of our new covariance model based on linear features is comparable with or even better than handcrafted features in scene classification.	[Wang, Liwei; Jia, Jiaya] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China	Wang, LW (reprint author), Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.						Bengio Y., 2007, ANN C NEUR INF PROC; Boureau Y.L., 2010, CVPR; Coates A., 2011, INT C MACH LEARN ICM; Dalal N., 2005, CVPR; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Eltoft T, 2006, IEEE SIGNAL PROC LET, V13, P300, DOI 10.1109/LSP.2006.870353; Fei-Fei L., 2005, CVPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong Y., 2011, ICCV; Huang K., 2007, ANN C NEUR INF PROC; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Karklin Y., 2008, NATURE, V457, P83; Karklin Y., 2006, ANN C NEUR INF PROC; Lazebnik S., 2006, CVPR; Lee H., 2009, INT C MACH LEARN ICM; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lowe D.G., 1999, ICCV; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pandey M., 2011, ICCV; Quattoni A., 2009, CVPR; Rigamonti R., 2011, CVPR; Schmid Cordelia, 2006, CVPR; Serre T., 2005, CVPR; Sivalingam R., 2011, ICCV; Sivalingam R., 2010, ECCV; Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O., 2006, ECCV; Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; Wang J., 2010, CVPR; Wang S., 2009, INT C ART INT STAT A; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xiao J., 2010, CVPR; Yang J., 2008, CVPR; Yang J., 2009, CVPR; Yu K., 2011, CVPR; Zeiler M., 2010, CVPR	38	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4673-1228-8	PROC CVPR IEEE			2012							2767	2774				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BBZ37	WOS:000309166202118		
J	Fu, LT; Kara, LB				Fu, Luoting; Kara, Levent Burak			Neural network-based symbol recognition using a few labeled samples	COMPUTERS & GRAPHICS-UK			English	Article						Sketch recognition; Symbol recognition; Deep Belief Network; Unsupervised training; Neural nets; Synthetic training samples	MODELS	The recognition of pen-based visual patterns such as sketched symbols is amenable to supervised machine learning models such as neural networks. However, a sizable, labeled training corpus is often required to learn the high variations of freehand sketches. To circumvent the costs associated with creating a large training corpus, improve the recognition accuracy with only a limited amount of training samples and accelerate the development of sketch recognition system for novel sketch domains, we present a neural network training protocol that consists of three steps. First, a large pool of unlabeled, synthetic samples are generated from a small set of existing, labeled training samples. Then, a Deep Belief Network (DBN) is pre-trained with those synthetic, unlabeled samples. Finally, the pre-trained DBN is fine-tuned using the limited amount of labeled samples for classification. The training protocol is evaluated against supervised baseline approaches such as the nearest neighbor classifier and the neural network classifier. The benchmark data sets used are partitioned such that there are only a few labeled samples for training, yet a large number of labeled test cases featuring rich variations. Results suggest that our training protocol leads to a significant error reduction compared to the baseline approaches. (C) 2011 Elsevier Ltd. All rights reserved.	[Fu, Luoting; Kara, Levent Burak] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA	Kara, LB (reprint author), Carnegie Mellon Univ, Dept Mech Engn, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	luoting.fu@cmu.edu; lkara@cmu.edu	Kara, Levent Burak/D-5472-2013	Kara, Levent Burak/0000-0002-2203-4020			Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Banko M., 2001, P 1 INT C HUM LANG T, P1, DOI 10.3115/1072133.1072204; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Bouveyron C, 2009, PATTERN RECOGN, V42, P2649, DOI 10.1016/j.patcog.2009.03.027; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Chen J, 2009, PATTERN RECOGN, V42, P2828, DOI 10.1016/j.patcog.2009.02.006; Ciresan D., 2010, ARXIV10030358; COWANS PJ, 2005, P 10 INT WORKSH ART, P73; Davis R, 2007, COMPUTER, V40, P34, DOI 10.1109/MC.2007.324; Fei-Fei L, 2006, IEEE T PATTERN ANAL, V8, P594; Field M, 2010, COMPUT GRAPH-UK, V34, P499, DOI 10.1016/j.cag.2010.07.001; Fu L., 2009, P ASME 2009 INT DES, P1; Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97; Gennari L, 2005, COMPUT GRAPH-UK, V29, P547, DOI 10.1016/j.cag.2005.05.007; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; HINTON GE, 2010, 2010003 UTML U TOR D; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067; Hse Heloise, 2004, P 17 INT C PATT REC, V1, P367; Kara LB, 2008, J MECH DESIGN, V130, DOI 10.1115/1.2965595; Kara LB, 2005, COMPUT GRAPH-UK, V29, P501, DOI 10.1016/j.cag.2005.05.004; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Memisevic R., 2007, IEEE COMP SOC C COMP, P1; NAIR V, 2009, ADV NEURAL INFORM PR, P1339; Niels R., 2008, 11 INT C FRONT HANDW; NONNEMAKER J, 2009, DOCUMENT RECOGNITION, V7247; Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; OUYANG TY, 2009, ADV NEURAL INFORM PR, P1401; OUYANG TY, 2009, P 21 INT JOINT C ART, P1463; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALAKHUTDINOV R, 2008, ADV NEURAL INFORM PR, P1249; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Sezgin TM, 2008, COMPUT GRAPH-UK, V32, P500, DOI 10.1016/j.cag.2008.05.008; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; THOMAS A, 2008, P 11 INT C FRONT HAN; Vapnik V. N., 1998, STAT LEARNING THEORY; Varga T., 2004, Proceedings. Ninth International Workshop on Frontiers in Handwriting Recognition; Wang J, 2006, PATTERN RECOGN, V39, P1746, DOI 10.1016/j.patcog.2006.03.010; Weston J., 2006, P 23 INT C MACH LEAR, P1009, DOI 10.1145/1143844.1143971; Yaeger L, 1997, ADV NEUR IN, V9, P807	49	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0097-8493			COMPUT GRAPH-UK	Comput. Graph.-UK	OCT	2011	35	5					955	966		10.1016/j.cag.2011.07.001		12	Computer Science, Software Engineering	Computer Science	831ZM	WOS:000295769600002		
J	Zhang, L; Zeng, Z; Ji, Q				Zhang, Lei; Zeng, Zhi; Ji, Qiang			Probabilistic Image Modeling With an Extended Chain Graph for Human Activity Recognition and Image Segmentation	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						Activity recognition; Bayesian networks (BNs); chain graph (CG); factor graph (FG); graphical model learning and inference; image segmentation; Markov random fields (MRFs)	ALGORITHM	Chain graph (CG) is a hybrid probabilistic graphical model (PGM) capable of modeling heterogeneous relationships among random variables. So far, however, its application in image and video analysis is very limited due to lack of principled learning and inference methods for a CG of general topology. To overcome this limitation, we introduce methods to extend the conventional chain-like CG model to CG model with more general topology and the associated methods for learning and inference in such a general CG model. Specifically, we propose techniques to systematically construct a generally structured CG, to parameterize this model, to derive its joint probability distribution, to perform joint parameter learning, and to perform probabilistic inference in this model. To demonstrate the utility of such an extended CG, we apply it to two challenging image and video analysis problems: human activity recognition and image segmentation. The experimental results show improved performance of the extended CG model over the conventional directed or undirected PGMs. This study demonstrates the promise of the extended CG for effective modeling and inference of complex real-world problems.	[Zhang, Lei] UtopiaCompress Corp, Los Angeles, CA 90064 USA; [Zeng, Zhi; Ji, Qiang] Rensselaer Polytech Inst, Troy, NY 12180 USA	Zhang, L (reprint author), UtopiaCompress Corp, Los Angeles, CA 90064 USA.	leizhang2009@gmail.com; zengz@rpi.edu; qji@ecse.rpi.edu					Abbeel P, 2006, J MACH LEARN RES, V7, P1743; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Bishop CM, 2006, PATTERN RECOGNITION; Borenstein E., 2004, P IEEE C COMP VIS PA, P46; BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641; BUNTINE W, 1995, P 11 ANN C UNC ART I, P46; Buntine W. L., 1994, J ARTIFICIAL INTELLI, V2, P159; Carreira-Perpinan M.A., 2005, P 10 INT WORKSH ART, P59; Chardin A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790353; Cour T., 2007, P IEEE C COMP VIS PA, P1; Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Hammersley J. M., 1971, MARKOV FIELDS FINITE; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 2005, P 10 INT WORKSH ART, P128; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUTTER F, 2005, P 19 INT JOINT C ART, P169; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lauritzen S.L., 1996, GRAPHICAL MODELS; Laxton B., 2007, P IEEE C COMP VIS PA, P1; LIU F, 2006, P IEEE INT S BIOM IM, P141; MACKAY DJC, 2001, TR200118 MERL; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MURINO V, 1993, P I ELECTR ENG COMMU, V140, P46; Neapolitan RE, 2003, LEARNING BAYESIAN NE; OSINDERO S, 2008, P ADV NEUR IF PROC S, V20; Park J. D., 2002, P AAAI 02, P682; Pearl J, 1988, PROBABILISTIC REASON; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; REN X, 2005, P ADV NEUR INF PROC, P1121; Sutton C, 2005, P UAI, P568; Welling Max, 2005, P 10 INT WORKSH ART, P397; Winn J., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Wu J., 2007, P 11 INT C COMP VIS, P1, DOI DOI 10.1109/APMC.2007.4554719; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), DOI 10.1109/CVPR.1992.223161; Zhang L, 2010, IEEE T PATTERN ANAL, V32, P1406, DOI 10.1109/TPAMI.2009.145	38	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149			IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	SEP	2011	20	9					2401	2413		10.1109/TIP.2011.2128332		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	810NU	WOS:000294132800001	21421443	
J	Breuleux, O; Bengio, Y; Vincent, P				Breuleux, Olivier; Bengio, Yoshua; Vincent, Pascal			Quickly Generating Representative Samples from an RBM-Derived Process	NEURAL COMPUTATION			English	Article							CONTRASTIVE DIVERGENCE	Two recently proposed learning algorithms, herding and fast persistent contrastive divergence (FPCD), share the following interesting characteristic: they exploit changes in the model parameters while sampling in order to escape modes and mix better during the sampling process that is part of the learning algorithm. We justify such approaches as ways to escape modes while keeping approximately the same asymptotic distribution of the Markov chain. In that spirit, we extend FPCD using an idea borrowed from Herding in order to obtain a pure sampling algorithm, which we call the rates-FPCD sampler. Interestingly, this sampler can improve the model as we collect more samples, since it optimizes a lower bound on the log likelihood of the training data. We provide empirical evidence that this new algorithm displays substantially better and more robust mixing than Gibbs sampling.	[Breuleux, Olivier; Bengio, Yoshua; Vincent, Pascal] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J8, Canada	Breuleux, O (reprint author), Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J8, Canada.	breuleux@gmail.com; yoshua.bengio@umontreal.ca; vincentp@iro.umontreal.ca					Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Borkar V. S., 2008, STOCHASTIC APPROXIMA; Breuleux O., 2010, 1349 DIRO U MONTR; Desjardins G., 2010, P 13 INT C ART INT S, P145; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 1999, P 9 INT C ART NEUR N, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1984, TRCMUCS84119; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; WELLING M, 2009, P 26 INT C MACH LEAR; Welling M., 2009, P 25 C UNC ART INT U; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI 10.1080/17442509908834179	13	2	2	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	AUG	2011	23	8					2058	2073				16	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	777OS	WOS:000291633200007		
J	Fischer, A; Igel, C				Fischer, Asja; Igel, Christian			Bounding the Bias of Contrastive Divergence Learning	NEURAL COMPUTATION			English	Article								Optimization based on k-step contrastive divergence (CD) has become a common way to train restricted Boltzmann machines (RBMs). The k-step CD is a biased estimator of the log-likelihood gradient relying on Gibbs sampling. We derive a new upper bound for this bias. Its magnitude depends on k, the number of variables in the RBM, and the maximum change in energy that can be produced by changing a single variable. The last reflects the dependence on the absolute values of the RBM parameters. The magnitude of the bias is also affected by the distance in variation between the modeled distribution and the starting distribution of the Gibbs chain.	[Fischer, Asja] Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany; [Igel, Christian] Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen O, Denmark	Fischer, A (reprint author), Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany.	asja.fischer@ini.rub.de; igel@diku.dk	Igel, Christian/B-4091-2009	Igel, Christian/0000-0003-2868-0856	German Federal Ministry of Education and Research within the National Network Computational Neuroscience [01GQ0951]	We acknowledge support from the German Federal Ministry of Education and Research within the National Network Computational Neuroscience under grant number 01GQ0951 (Bernstein Fokus "Learning Behavioral Models: From Human Experiment to Technical Assistance").	Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bremaud P., 1999, MARKOV CHAINS GIBBS; Carreira-Perpi nan M.A., 2005, 10 WORKSH ART INT ST, P59; Desjardins G., 2010, J MACHINE LEARNING R, V9, P145; FISCHER A, 2010, LNCS, V6354, P208; FISCHER A, 2009, FRONTIERS COMPUTATIO, DOI DOI 10.3389/CONF.NEURO.10.2009.14.121; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; MacKay D.J.C., 2001, FAILURES ONE STEP LE; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Yuille A., 2005, ADV NEURAL INFORM PR, V17, P1593	14	2	3	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	MAR	2011	23	3					664	673		10.1162/NECO_a_00085		10	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	716YD	WOS:000287008500004	21162669	
J	Kang, Y; Choi, S		Gunopulos, D; Hofmann, T; Malerba, D; Vazirgiannis, M		Kang, Yoonseop; Choi, Seungjin			Restricted Deep Belief Networks for Multi-view Learning	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 05-09, 2011	Athens, GREECE	Google, Pascal2 Network, Xerox, Yahoo Labs, COST-MOVE Act (Knowledge Discovery Movin, Objects), Rapid-I, FP7-MODAP Project (Mobil, Data Min, & Privacy), Athena RIC/Inst Management Informat Syst (IMIS), Hellen Artificial Intelligence Soc (EETN), Marathon Data Syst (MDS), Transinsight, Springer, SONY, UNESCO Privacy Chair, Univ Studi Bari Aldo Moro, Athens Univ Econ & Business, Dept Informat, Univ Ioannina, Dept Comp Sci, Natl & Kapodistrian Univ Athens, Univ Piraeus, Dept Informat, Univ Athens, Dept Informat & Telecommunicat, Google Inc, Univ degli Studi Bari Aldo Moro, Dipartimento Informatica				Deep belief network (DBN) is a probabilistic generative model with multiple layers of hidden nodes and a layer of visible nodes, where parameterizations between layers obey harmonium or restricted Boltzmann machines (RBMs). In this paper we present restricted deep belief network (RDBN) for multi-view learning, where each layer of hidden nodes is composed of view-specific and shared hidden nodes, in order to learn individual and shared hidden spaces from multiple views of data. View-specific hidden nodes are connected to corresponding view-specific hidden nodes in the lower-layer or visible nodes involving a specific view, whereas shared hidden nodes follow inter-layer connections without restrictions as in standard DBNs. RDBN is trained using layer-wise contrastive divergence learning. Numerical experiments on synthetic and real-world datasets demonstrate the useful behavior of the RDBN, compared to the multi-wing harmonium (MWH) which is a two-layer undirected model.	[Kang, Yoonseop; Choi, Seungjin] Pohang Univ Sci & Technol, Dept Comp Sci, Pohang 790784, South Korea	Kang, Y (reprint author), Pohang Univ Sci & Technol, Dept Comp Sci, San 31 Hyoja Dong, Pohang 790784, South Korea.	e0en@postech.ac.kr; seungjin@postech.ac.kr					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Blum A., 1998, P ANN C LEARN THEOR; Chen N., 2010, ADV NEURAL INFORM PR, V23; Choi H., 2008, P AAAI NAT C ART INT; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hotelling H., 1936, BIOMETRIKA, V28, P312; Lawrence N. D., 2004, ADV NEURAL INFORM PR, V16; LeCun Y., 2004, P IEEE INT C COMP VI; Lee H., 2009, P INT C ART INT STAT; Nair V., 2010, P INT C MACH LEARN I; Salzmann M., 2010, P INT C ART INT STAT; Shon A.P., 2006, ADV NEURAL INFORM PR, V17; Sinha P., 2008, P ACM INT C IM VID R; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Welling M., 2005, ADV NEURAL INFORM PR, V17; Xing E. P., 2005, P ANN C UNC ART INT; Yang J., 2007, P SIAM INT C DAT MIN	19	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-23783-6	LECT NOTES ARTIF INT			2011	6912						130	145				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEH08	WOS:000316551300009		
J	Karayev, S; Fritz, M; Fidler, S; Darrell, T			IEEE	Karayev, Sergey; Fritz, Mario; Fidler, Sanja; Darrell, Trevor			A Probabilistic Model for Recursive Factorized Image Features	2011 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 20-25, 2011	Colorado Springs, CO	IEEE				Layered representations for object recognition are important due to their increased invariance, biological plausibility, and computational benefits. However, most of existing approaches to hierarchical representations are strictly feedforward, and thus not well able to resolve local ambiguities. We propose a probabilistic model that learns and infers all layers of the hierarchy jointly. Specifically, we suggest a process of recursive probabilistic factorization, and present a novel generative model based on Latent Dirichlet Allocation to this end. The approach is tested on a standard recognition dataset, outperforming existing hierarchical approaches and demonstrating performance on par with current single-feature state-of-the-art models. We demonstrate two important properties of our proposed model: 1) adding an additional layer to the representation increases performance over the flat model; 2) a full Bayesian approach outperforms a feedforward implementation of the model.	[Karayev, Sergey; Fritz, Mario; Fidler, Sanja; Darrell, Trevor] Univ Calif Berkeley, Berkeley, CA 94720 USA	Karayev, S (reprint author), Univ Calif Berkeley, Berkeley, CA 94720 USA.	sergeyk@icsi.berkeley.edu; mfritz@icsi.berkeley.edu; sanja@icsi.berkeley.edu; trevor@icsi.berkeley.edu					Agarwal A., 2008, INT J COMPUTER VISIO; Ahmed A., 2008, ECCV; Blei D. M., 2009, J MACHINE LEARNING R; Blei D. M., 2010, ADV NEURAL INFORM PR; Boureau Y.-L., 2010, CVPR 2010; Connor CE, 2007, CURR OPIN NEUROBIOL, V17, P140, DOI 10.1016/j.conb.2007.03.002; Fei-Fei L., 2004, CVPR 2004 WORKSH GEN; Fidler S., 2008, CVPR; Fidler S., 2007, CVPR 2007; Fritz Mario, 2009, NIPS; Heinrich G., 2008, PARAMETER ESTIMATION; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Jarrett K., 2009, CVPR; Kanan C., 2010, CVPR; Kavukcuoglu K., 2010, NIPS; Lazebnik S., 2006, CVPR 2006; Lee H., 2009, P 26 ANN INT C MACH; Lee T. S., 2003, J OPTICAL SOC AM ASS; Li W., 2006, ICML 2006; Lowe D., 2004, INT J COMPUTER VISIO; Mutch J., 2008, INT J COMPUTER VISIO; Olshausen B. A., 2003, VISION RES; Ommer B., 2007, CVPR; Ranzato M. A., 2008, CVPR; Rolls ET, 2002, COMPUTATIONAL NEUROS; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sivic J., 2003, COMP VIS 2003 P 9 IE; Sivic J., 2005, ICCV; Ullman S., 2006, TRENDS COGNITIVE SCI; Wang J., 2010, CVPR 2010; Yang J., 2009, P IEEE C COMP VIS PA; Zhu L. L., 2008, ECCV 2008; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	34	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4577-0393-5	PROC CVPR IEEE			2011							401	408				8	Computer Science, Artificial Intelligence	Computer Science	BXB85	WOS:000295615800052		
J	Pape, L; Gomez, F; Ring, M; Schmidhuber, J			IEEE	Pape, Leo; Gomez, Faustino; Ring, Mark; Schmidhuber, Juergen			Modular Deep Belief Networks that do not Forget	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			RECOGNITION; MODEL; NETS	Deep belief networks (DBNs) are popular for learning compact representations of high-dimensional data. However, most approaches so far rely on having a single, complete training set. If the distribution of relevant features changes during subsequent training stages, the features learned in earlier stages are gradually forgotten. Often it is desirable for learning algorithms to retain what they have previously learned, even if the input distribution temporarily changes. This paper introduces the M-DBN, an unsupervised modular DBN that addresses the forgetting problem. M-DBNs are composed of a number of modules that are trained only on samples they best reconstruct. While modularization by itself does not prevent forgetting, the M-DBN additionally uses a learning method that adjusts each module's learning rate proportionally to the fraction of best reconstructed samples. On the MNIST handwritten digit dataset module specialization largely corresponds to the digits discerned by humans. Furthermore, in several learning tasks with changing MNIST digits, M-DBNs retain learned features even after those features are removed from the training data, while monolithic DBNs of comparable size forget feature mappings learned before.	[Pape, Leo; Gomez, Faustino; Ring, Mark; Schmidhuber, Juergen] Univ Lugano, IDSIA, SUPSI, Lugano, Switzerland	Pape, L (reprint author), Univ Lugano, IDSIA, SUPSI, Lugano, Switzerland.	pape@idsia.ch; tino@idsia.ch; mark@idsia.ch; juergen@idsia.ch					Ando H., 1999, NEURAL NETWORKS, V7-8, P1037; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Erkan A., 2007, ADV NEURAL INFORM PR; French R. M., 2001, PSEUDOPATTERNS DUAL, P13; Hinton G. E., 1995, ADV NEURAL INFORMATI, V7, P1015; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jacobs R., 1995, NEURAL COMPUT, V3, P79; Kurtz KJ, 2007, PSYCHON B REV, V14, P560, DOI 10.3758/BF03196806; Lange S., 2010, INT JOINT C NEUR NET; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Ranzato M., 2007, P COMP VIS PATT REC; Ring M. B., 1994, THESIS U TEXAS AUSTI, P78712; Robins A., 2004, Intelligent Data Analysis, V8; Salakhutdinov R., 2007, AISTATS, V11; Sutskever I., 2007, AI STAT; Taylor G.W., 2007, ADV NEURAL INFORM PR, V19; Zhang BL, 2001, PATTERN RECOGN, V34, P203, DOI 10.1016/S0031-3203(00)00009-1	22	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-9636-5				2011							1191	1198				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541201046		
S	Salama, MA; Eid, HF; Ramadan, RA; Darwish, A; Hassanien, AE		GasparCunha, A; Takahashi, R; Schaefer, G; Costa, L		Salama, Mostafa A.; Eid, Heba F.; Ramadan, Rabie A.; Darwish, Ashraf; Hassanien, Aboul Ella			Hybrid Intelligent Intrusion Detection Scheme	SOFT COMPUTING IN INDUSTRIAL APPLICATIONS	Advances in Intelligent and Soft Computing		English	Proceedings Paper	15th Online World Conference on Soft Computing in Industrial Applications	NOV 15-17, 2010	ELECTR NETWORK			Deep Belief Network (DBN); Network Intrusion detection system; Support Vector Machines (SVMs); Dimensional reduction		This paper introduces a hybrid scheme that combines the advantages of deep belief network and support vector machine. An application of intrusion detection imaging has been chosen and hybridization scheme have been applied to see their ability and accuracy to classify the intrusion into two outcomes: normal or attack, and the attacks fall into four classes; R2L, DoS, U2R, and Probing. First, we utilize deep belief network to reduct the dimensionality of the feature sets. This is followed by a support vector machine to classify the intrusion into five outcome; Normal, R2L, DoS, U2R, and Probing. To evaluate the performance of our approach, we present tests on NSL-KDD dataset and show that the overall accuracy offered by the employed approach is high.	[Salama, Mostafa A.] British Univ Egypt, Dept Comp Sci, Cairo, Egypt	Salama, MA (reprint author), British Univ Egypt, Dept Comp Sci, Cairo, Egypt.	mostafa.salama@gmail.com; heba.fathy@yahoo.com; rabieramadan@gmail.com; amodarwish@yahoo.com; aboitcairo@gmail.com	Hassanien, Aboul Ella/; Salama, Mostafa/	Hassanien, Aboul Ella/0000-0002-9989-6681; Salama, Mostafa/0000-0003-2559-8056			Anderson J.P., 1980, COMPUTER SECURITY TH; [Anonymous], WEKA DATA MINING SOF; Biermann E, 2001, COMPUT SECUR, V20, P676, DOI 10.1016/S0167-4048(01)00806-9; COHEN I, 2007, P 15 INT C MULT AUGS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; ILGUN K, 1995, IEEE T SOFTWARE ENG, V21, P181, DOI 10.1109/32.372146; *KDD, 2010, KDD 1999 DAT IRV CA; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Larochelle H., 2008, P 25 INT C MACH LEAR, V307, P536; Lundin E, 2000, COMPUT NETW, V34, P623, DOI 10.1016/S1389-1286(00)00134-1; Marchette D, 1999, PROCEEDINGS OF THE WORKSHOP ON INTRUSION DETECTION AND NETWORK MONITORING (ID '99), P119; MCAFEE L, 2008, DOCUMENT CLASSIFICAT; Mohamed A.R., 2009, NIPS 22 WORKSH DEEP; Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774; Noulas A.K., 2008, BELG DUTCH C ART INT; Shon T, 2007, INFORM SCIENCES, V177, P3799, DOI 10.1016/j.ins.2007.03.025; Stallings W., 2006, CRYPTOGRAPHY NETWORK; Tavallaee M, 2009, P IEEE S COMP INT SE; Tsai CF, 2009, EXPERT SYST APPL, V36, P11994, DOI 10.1016/j.eswa.2009.05.029; Verwoerd T, 2002, COMPUT COMMUN, V25, P1356, DOI 10.1016/S0140-3664(02)00037-3; Wu SX, 2010, APPL SOFT COMPUT, V10, P1, DOI 10.1016/j.asoc.2009.06.019	21	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1867-5662		978-3-642-20504-0	ADV INTEL SOFT COMPU			2011	96						293	303				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BVR98	WOS:000292618100026		
J	Weng, JY			IEEE	Weng, Juyang			Three Theorems: Brain-Like Networks Logically Reason and Optimally Generalize	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			INTELLIGENCE; RECOGNITION; MECHANISMS; ATTENTION; CORTEX	Finite Automata (FA) is a base net for many sophisticated probability-based systems of artificial intelligence. However, an FA processes symbols, instead of images that the brain senses and produces (e. g., sensory images and motor images). Of course, many recurrent artificial neural networks process images. However, their non-calibrated internal states prevent generalization, let alone the feasibility of immediate and error-free learning. I wish to report a general-purpose Developmental Program (DP) for a new type of, brain-anatomy inspired, networks - Developmental Networks (DNs). The new theoretical results here are summarized by three theorems. (1) From any complex FA that demonstrates human knowledge through its sequence of the symbolic inputs-outputs, the DP incrementally develops a corresponding DN through the image codes of the symbolic inputs-outputs of the FA. The DN learning from the FA is incremental, immediate and error-free. (2) After learning the FA, if the DN freezes its learning but runs, it generalizes optimally for infinitely many image inputs and actions based on the embedded inner-product distance, state equivalence, and the principle of maximum likelihood. (3) After learning the FA, if the DN continues to learn and run, it "thinks" optimally in the sense of maximum likelihood based on its past experience.	Michigan State Univ, Dept Comp Sci & Engn, Cognit Sci Program, E Lansing, MI 48824 USA	Weng, JY (reprint author), Michigan State Univ, Dept Comp Sci & Engn, Cognit Sci Program, E Lansing, MI 48824 USA.	weng@cse.msu.edu					Anderson J., 1993, RULES OF THE MIND; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Fazl A, 2009, COGNITIVE PSYCHOL, V58, P1, DOI 10.1016/j.cogpsych.2008.05.001; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Gallistel CR, 1999, SCIENCE, V285, P842; George D, 2009, PLOS COMPUTATIONAL B, V5, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Iverson JM, 2010, J CHILD LANG, V37, P229, DOI 10.1017/S0305000909990432; Jordan M., 1997, CRC HDB COMPUTER SCI, P536; Karmarkar UR, 2007, NEURON, V53, P427, DOI 10.1016/j.neuron.2007.01.006; LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6; Luciw M., 2008, IEEE INT C DEV LEARN, P1; Luciw M., 2010, P IEEE INT JOINT C N, P4233; Luciw M., 2010, P IEEE 9 INT C DEV L, P311; Luciw M, 2010, IEEE T AUTON MENT DE, V2, P248, DOI 10.1109/TAMD.2010.2072150; Mauk MD, 2004, ANNU REV NEUROSCI, V27, P307, DOI 10.1146/annurev.neuro.27.070203.144247; MINSKY M, 1991, AI MAG, V12, P34; Miyan K., 2010, P IEEE 9 INT C DEV L, P280; Muller V., 2010, AMD NEWSLETTER, V7, P8; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Rogers TT, 2008, BEHAV BRAIN SCI, V31, P689, DOI 10.1017/S0140525X0800589X; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vygotsky L.S., 1962, THOUGHT AND LANGUAGE; Wang Yi, 2011, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/APPEEC.2011.5749162; Weng J., 2001, P INT JOINT C NEUR N, P1; Weng J, 2009, P IEEE 8 INT C DEV L, P1; Weng J., 2011, MSUCSE119 DEP COMP S; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220	33	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-9636-5				2011							2983	2990				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541203017		
J	Le Ly, D; Chow, P				Le Ly, Daniel; Chow, Paul			High-Performance Reconfigurable Hardware Architecture for Restricted Boltzmann Machines	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Boltzmann machines; computer architecture; field-programmable gate arrays; neural network hardware; parallel processing	FPGA IMPLEMENTATION; NEURAL-NETWORKS; ALGORITHM	Despite the popularity and success of neural networks in research, the number of resulting commercial or industrial applications has been limited. A primary cause for this lack of adoption is that neural networks are usually implemented as software running on general-purpose processors. Hence, a hardware implementation that can exploit the inherent parallelism in neural networks is desired. This paper investigates how the restricted Boltzmann machine (RBM), which is a popular type of neural network, can be mapped to a high-performance hardware architecture on field-programmable gate array (FPGA) platforms. The proposed modular framework is designed to reduce the time complexity of the computations through heavily customized hardware engines. A method to partition large RBMs into smaller congruent components is also presented, allowing the distribution of one RBM across multiple FPGA resources. The framework is tested on a platform of four Xilinx Virtex II-Pro XC2VP70 FPGAs running at 100 MHz through a variety of different configurations. The maximum performance was obtained by instantiating an RBM of 256 x 256 nodes distributed across four FPGAs, which resulted in a computational speed of 3.13 billion connection-updates-per-second and a speedup of 145-fold over an optimized C program running on a 2.8-GHz Intel processor.	[Le Ly, Daniel; Chow, Paul] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G4, Canada	Le Ly, D (reprint author), Cornell Univ, Dept Mech & Aerosp Engn, Ithaca, NY 14850 USA.	dll73@cornell.edu; pc@eecg.toronto.edu			Canadian Microelectronics Corporation/System-on-Chip Research Network; Natural Sciences and Engineering Research Council; Xilinx	Manuscript received March 3, 2010; revised May 24, 2010; accepted August 13, 2010. Date of current version November 3, 2010. This work was supported in part by Canadian Microelectronics Corporation/System-on-Chip Research Network, Natural Sciences and Engineering Research Council, and Xilinx.	Bharkhada BK, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P843; Chang C, 2005, IEEE DES TEST COMPUT, V22, P114, DOI 10.1109/MDT.2005.30; Dias FM, 2004, ENG APPL ARTIF INTEL, V17, P945, DOI 10.1016/j.engappai.2004.08.011; Ferreira P, 2007, NEUROCOMPUTING, V71, P71, DOI 10.1016/j.neucom.2006.11.028; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Goto K, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1377603.1377607; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kim SK, 2009, I C FIELD PROG LOGIC, P367; LEcuyer P, 1996, MATH COMPUT, V65, P203, DOI 10.1090/S0025-5718-96-00696-5; Lindsey C. S., 1995, Proceedings of the SPIE - The International Society for Optical Engineering; LY D, 2009, P ACM SIGDA INT S FI, P73, DOI 10.1145/1508128.1508140; Ly Daniel L, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), DOI 10.1109/FPT.2009.5377688; Ly DL, 2009, I C FIELD PROG LOGIC, P168; Omondi A. R., 2006, FPGA IMPLEMENTATIONS; Raina R., 2009, P 26 ANN INT C MACH, P873; Saldana M., 2008, P 2 INT WORKSH HIGH, P1; Savich AW, 2007, IEEE T NEURAL NETWOR, V18, P240, DOI 10.1109/TNN.2006.883002; SUTTON P., 2003, P 13 INT C FIELD PRO, P1062; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Tommiska MT, 2003, IEE P-COMPUT DIG T, V150, P403, DOI 10.1049/ip-cdt:20030965	21	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	NOV	2010	21	11					1780	1792		10.1109/TNN.2010.2073481		13	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	676UM	WOS:000283944100008		
J	Gandrakota, R; Chakravarthy, VS; Pradhan, RK				Gandrakota, Rohit; Chakravarthy, V. S.; Pradhan, Ranjan K.			A Model of Indispensability of a Large Glial Layer in Cerebrovascular Circulation	NEURAL COMPUTATION			English	Article							COMPUTATIONAL MODEL; SPREADING DEPRESSION; CYTOCHROME-OXIDASE; SKELETAL-MUSCLE; NITRIC-OXIDE; CORTEX; BRAIN; OSCILLATIONS; OXYGENATION; VASOMOTION	We formulate the problem of oxygen delivery to neural tissue as a problem of association. Input to a pool of neurons in one brain area must be matched in space and time with metabolic inputs from the vascular network via the glial network. We thus have a model in which neural, glial, and vascular layers are connected bidirectionally, in that order. Connections between neuro-glial and glial-vascular stages are trained by an unsupervised learning mechanism such that input to the neural layer is sustained by the precisely patterned delivery of metabolic inputs from the vascular layer via the glial layer. Simulations show that the capacity of such a system to sustain patterns is weak when the glial layer is absent. Capacity is higher when a glial layer is present and increases with the layer size. The proposed formulation of neurovascular interactions raises many intriguing questions about the role of glial cells in cerebral circulation.	[Gandrakota, Rohit; Chakravarthy, V. S.] Indian Inst Technol, Dept Biotechnol, Madras 600036, Tamil Nadu, India; [Pradhan, Ranjan K.] Med Coll Wisconsin, Biotechol & Bioengn Ctr, Milwaukee, WI 53226 USA	Gandrakota, R (reprint author), Indian Inst Technol, Dept Biotechnol, Madras 600036, Tamil Nadu, India.	grohiit@gmail.com; schakra@ee.iitm.ac.in; pkranjan@gmail.com	Pradhan, Ranjan/E-7442-2010; Chakravarthy, Srinivasa/A-7472-2012				Barrett D, 2003, J NEUROSCI, V23, P5740; Boas DA, 2008, NEUROIMAGE, V40, P1116, DOI 10.1016/j.neuroimage.2007.12.061; Carmeliet P, 2005, NATURE, V436, P193, DOI 10.1038/nature03875; Charles A, 2005, SCI STKE, V2005, ppe6; DIAMOND MC, 1964, J COMP NEUROL, V123, P111, DOI 10.1002/cne.901230110; Fellin T, 2004, J PHYSIOL-LONDON, V559, P3, DOI 10.1113/jphysiol.2004.063214; Filosa JA, 2004, CIRC RES, V95, P73; Gangadhar G, 2008, NEURAL COMPUT, V20, P2491, DOI 10.1162/neco.2008.03-07-498; Gangadhar G, 2007, INT J DOC ANAL RECOG, V10, P69, DOI 10.1007/s10032-007-0046-0; GIBSON WG, 2007, NEUROCOMPUTING, V7, P1674; GONZALEZLIMA F, 1991, NEUROSCI LETT, V123, P251, DOI 10.1016/0304-3940(91)90943-N; Goodall S, 1997, STROKE, V28, P101; Haydon PG, 2006, PHYSIOL REV, V86, P1009, DOI 10.1152/physrev.00049.2005; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kager H, 2000, J NEUROPHYSIOL, V84, P495; Kasischke KA, 2004, SCIENCE, V305, P99, DOI 10.1126/science.1096485; Kosko B., 1992, NEURAL NETWORKS FUZZ; Lee TJF, 2000, J BIOMED SCI, V7, P16; MAGISTRETTI PJ, 2006, J EXP BIOL, V209, P2301; Nadkarni S, 2004, PHYS BIOL, V1, P35, DOI 10.1088/1478-3967/1/1/004; Nadkarni S, 2003, PHYS REV LETT, V91, DOI 10.1103/PhysRevLett.91.268101; Nadkarni S, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000088; Nilsson Holger, 2003, Mol Interv, V3, P79, DOI 10.1124/mi.3.2.79; Parri HR, 2001, NAT NEUROSCI, V4, P803, DOI 10.1038/90507; Pellerin L, 1998, DEV NEUROSCI-BASEL, V20, P291, DOI 10.1159/000017324; Postnov DE, 2007, BIOSYSTEMS, V89, P84, DOI 10.1016/j.biosystems.2006.04.012; Pradhan RK, 2007, MICROVASC RES, V74, P51, DOI 10.1016/j.mvr.2007.02.004; Pradhan RK, 2007, MATH BIOSCI, V209, P486, DOI 10.1016/j.mbs.2007.02.010; PRADHAN RK, 2009, J THEOR BIOL, V259, P241; Reggia JA, 1996, COMPUT BIOL MED, V26, P133, DOI 10.1016/0010-4825(95)00051-8; Revett K, 1998, J CEREBR BLOOD F MET, V18, P998; Rose CR, 2001, NAT NEUROSCI, V4, P773, DOI 10.1038/90464; Schummers J, 2008, SCIENCE, V320, P1638, DOI 10.1126/science.1156120; Secomb TW, 2002, MICROCIRCULATION, V9, P377, DOI 10.1038/sj.mn.7800146; Sherwood CC, 2006, P NATL ACAD SCI USA, V103, P13606, DOI 10.1073/pnas.0605843103; Somjen GG, 2008, J COMPUT NEUROSCI, V25, P349, DOI 10.1007/s10827-008-0083-9; SZELIGO F, 1977, J COMP NEUROL, V172, P247, DOI 10.1002/cne.901720205; THEODOSIS DT, 1993, NEUROSCIENCE, V57, P501, DOI 10.1016/0306-4522(93)90002-W; Tsacopoulos M, 1996, J NEUROSCI, V16, P877; Zhang CY, 1999, J NEUROCYTOL, V28, P525, DOI 10.1023/A:1007053204929	40	2	2	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	APR	2010	22	4					949	968		10.1162/neco.2009.01-09-945		20	Computer Science, Artificial Intelligence	Computer Science	566JT	WOS:000275367000004	20028221	
J	Zhou, SS; Chen, QC; Wang, XL			IEEE	Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong			DISCRIMINATIVE DEEP BELIEF NETWORKS FOR IMAGE CLASSIFICATION	2010 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	IEEE International Conference on Image Processing	SEP 26-29, 2010	Hong Kong, PEOPLES R CHINA	IEEE, IEEE Signal Process Soc		Discriminative Deep Belief Networks (DDBN); semi-supervised learning; image classification; deep learning	ALGORITHM; EM	This paper presents a novel semi-supervised learning algorithm called Discriminative Deep Belief Networks (DDBN), to address the image classification problem with limited labeled data. We first construct a new deep architecture for classification using a set of Restricted Boltzmann Machines (RBM). The parameter space of the deep architecture is initially determined using labeled data together with abundant of unlabeled data, by greedy layerwise unsupervised learning. Then, we fine-tune the whole deep networks using an exponential loss function to maximize the separability of the labeled data, by gradient-descent based supervised learning. Experiments on the artificial dataset and real image datasets show that DDBN outperforms most semi-supervised algorithm and deep learning techniques, especially for the hard classification tasks.	[Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China	Zhou, SS (reprint author), Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.	zhoushusen@hitsz.edu.cn; qingcai.chen@hitsz.edu.cn; wangxl@insun.hit.edu.cn					Bengio Y., 2007, LEARNING DEEP ARCHIT; BLUM, 1998, P 11 ANN C COMP LEAR; Blum A., 2001, P 18 INT C MACH LEAR, P19; Chapelle O., 2006, SEMISUPERVISED LEARN; Chapelle O., 2005, P 10 INT WORKSH ART, P57; Collobert R, 2006, J MACH LEARN RES, V7, P1687; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; SALAKHUTDINOV R, 2007, INT C ART INT STAT; Salakhutdinov R., 2008, INT C MACH LEARN HEL, P872; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Weston J., 2008, ICML 08, P1168; Wu Y, 2000, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2000.855823; YAROWSKY, 1995, P ACL95, P189; ZHOU ZH, 2007, AAAI C ART INT, P675; Zhu X., 2007, SEMISUPERVISED LEARN	19	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		978-1-4244-7994-8	IEEE IMAGE PROC			2010							1561	1564		10.1109/ICIP.2010.5649922		4	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BTP82	WOS:000287728001163		
S	Min, RQ; Stanley, DA; Yuan, ZN; Bonner, A; Zhang, ZL		Wang, W; Kargupta, H; Ranka, S; Yu, PS; Wu, XD		Min, Renqiang; Stanley, David A.; Yuan, Zineng; Bonner, Anthony; Zhang, Zhaolei			A Deep Non-Linear Feature Mapping for Large-Margin kNN Classification	2009 9TH IEEE INTERNATIONAL CONFERENCE ON DATA MINING	IEEE International Conference on Data Mining		English	Proceedings Paper	9th IEEE International Conference on Data Mining	DEC 06-09, 2009	Miami Beach, FL	Knime, Mitre, CRC Press				KNN is one of the most popular data mining methods for classification, but it often fails to work well with inappropriate choice of distance metric or due to the presence of numerous class-irrelevant features. Linear feature transformation methods have been widely applied to extract class-relevant information to improve kNN classification, which is very limited in many applications. Kernels have also been used to learn powerful non-linear feature transformations, but these methods fail to scale to large datasets. In this paper, we present a scalable non-linear feature mapping method based on a deep neural network pretrained with Restricted Boltzmann Machines for improving kNN classification in a large-margin framework, which we call DNet-kNN. DNet-kNN can be used for both classification and for supervised dimensionality reduction. The experimental results on two benchmark handwritten digit datasets and one newsgroup text dataset show that DNet-kNN has much better performance than large-margin kNN using a linear mapping and kNN based on a deep autoencoder pretrained with Restricted Boltzmann Machines.	[Min, Renqiang; Bonner, Anthony] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada	Min, RQ (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.	minrq@cs.toronto.edu; davearthur.stanley@gmail.com; zineng.yuan@utoronto.ca; bonner@cs.toronto.edu; zhaolei.zhang@utoronto.ca					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; CARREIRAPERPIGN.MA, 2005, P INT C ART INT STAT, V10; Chopra S., 2005, COMP VIS PATT REC IE, V1, P539; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Globerson A., 2005, NIPS, V18, P451; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HINTON G, ADV NEURAL INFORM PR, V15, P833; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Larochelle Hugo, 2007, ICML, P473; MIN R, 2005, THESIS U TORONTO; Salakhutdinov R., 2007, P INT C ART INT STAT, V11; TEH YW, 2000, NIPS, P908; TORRESANI L, 1919, NIPS, V19; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; WANG H, 2002, MINIST DATABASE HAND; WEINBERGER JBK, NIPS, V18; WESTON J, 2008, DEEP LEARNING VIA SE; XING EP, NIPS, V15	22	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-1-4244-5242-2	IEEE DATA MINING			2009							357	366		10.1109/ICDM.2009.27		10	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTL37	WOS:000287216600037		
B	Yasuda, M; Tanaka, K		Mohammadian, M		Yasuda, Muneki; Tanaka, Kazuyuki			Approximate Learning Algorithm for Restricted Boltzmann Machines	2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2			English	Proceedings Paper	International Conference on Computational Intelligence for Modelling, Control and Automation	DEC 10-12, 2008	Vienna, AUSTRIA				MODEL	A restricted Boltzmann machine consists of a layer of visible units and a layer of hidden units with no visible-visible or hidden-hidden connections. The restricted Boltzmann machine is the main component used in building up the deep belief network and has been studied by many researchers. However, the learning algorithm for the restricted Boltzmann machine is a NP-hard problem in general. In this paper we propose a new approximate learning algorithm for the restricted Boltzmann machines using the EM algorithm and the loopy belief propagation.	[Yasuda, Muneki; Tanaka, Kazuyuki] Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, Sendai, Miyagi 9808579, Japan	Yasuda, M (reprint author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, Aramaki Aza Aoba 6-3-09, Sendai, Miyagi 9808579, Japan.	muneki@smapip.is.tohoku.ac.jp; kazu@smapip.is.tohoku.ac.jp					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362; Chen H, 2006, IEEE T NEURAL NETWOR, V17, P755, DOI 10.1109/TNN.2006.873278; Dempster A, 1977, J ROYAL STAT SOC B, V39, P38, DOI DOI 10.2307/2984875; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1983, IEEE C COMP VIS PATT, P448; HORIGUCHI T, 1981, PHYSICA A, V107, P360, DOI 10.1016/0378-4371(81)90095-9; Opper M, 2001, ADV MEAN FIELD METHO; Pearl J, 1988, PROBABILISTIC REASON; Pelizzola A, 2005, J PHYS A-MATH GEN, V38, pR309, DOI 10.1088/0305-4470/38/33/R01; SALAKHUTDINOV R, 2007, ACM INT C P SERIES, V227, P791; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1; Tang TB, 2007, NEUROCOMPUTING, V70, P1198, DOI 10.1016/j.neucom.2006.11.014; TEH YW, 2001, ADV NEURAL INFORM PR, V13; YASUDA M, 2006, PHYSICA A, V836, P83	15	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3329-2				2008							692	697		10.1109/CIMCA.2008.57		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BON50	WOS:000277076500120		
J	Czarnecki, WM; Tabor, J				Czarnecki, Wojciech Marian; Tabor, Jacek			Multithreshold Entropy Linear Classifier: Theory and applications	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Classification; Renyi's entropy; Density estimation; Multithreshold classifier	SUPPORT VECTOR MACHINES; ALGORITHM; SELECTION	This paper proposes a new multithreshold linear classifier (MELC) based on the Renyi's quadratic entropy and Cauchy-Schwarz divergence, combined with the adaptive kernel density estimation in the one dimensional projections space. Due to its nature MELC is especially well adapted to deal with unbalanced data. As the consequence of both used model and the applied density regularization technique, it shows strong regularization properties and therefore is almost unable to overfit. Moreover, contrary to SVM, in its basic form it has no free parameters, however, at the cost of being a non-convex optimization problem which results in the existence of local optima and the possible need for multiple initializations. In practice, MELC obtained similar or higher scores than the ones given by SVM on both synthetic and real data from the UCI repository. We also perform experimental evaluation of proposed method as a part of expert system designed for drug discovery problem. It appears that not only MELC achieves better results than SVM but also gives some additional insights into data structure, resulting in more complex decision support system. (C) 2015 Elsevier Ltd. All rights reserved.	[Czarnecki, Wojciech Marian; Tabor, Jacek] Jagiellonian Univ, Fac Math & Comp Sci, PL-30348 Krakow, Poland	Czarnecki, WM (reprint author), Jagiellonian Univ, Fac Math & Comp Sci, Prof Stanislawa Lojasiewicza 6, PL-30348 Krakow, Poland.	wojciech.czarnecki@uj.edu.pl; jacek.tabor@uj.edu.pl			National Science Centre, Poland [2013/09/N/ST6/03015, 2014/13/B/ST6/01792]	The work of the first author was partially founded by National Science Centre, Poland Grant No. 2013/09/N/ST6/03015, while the work of the second one by National Science Centre, Poland Grant No. 2014/13/B/ST6/01792.	Anthony M, 2003, LEARNING MULTIVALUED; Anthony M, 2004, J MACH LEARN RES, V5, P189; Asuncion A., 2007, UCI MACHINE LEARNING; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; CAO R, 1994, COMPUT STAT DATA AN, V17, P153, DOI 10.1016/0167-9473(92)00066-Z; Cha M, 2014, EXPERT SYST APPL, V41, P3343, DOI 10.1016/j.eswa.2013.11.025; Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Czarnecki WM, 2014, EXPERT SYST APPL, V41, P8211, DOI 10.1016/j.eswa.2014.07.015; Danenas P, 2015, EXPERT SYST APPL, V42, P3194, DOI 10.1016/j.eswa.2014.12.001; Das G, 2014, EXPERT SYST APPL, V41, P3491, DOI 10.1016/j.eswa.2013.10.053; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Hammann F., 2009, MOL PHARM, V33; Haykin S. S., 2009, NEURAL NETWORKS LEAR, V3; Hegde C., 2007, NIPS, V7; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y; Huang KZ, 2008, IEEE T NEURAL NETWOR, V19, P260, DOI 10.1109/TNN.2007.905855; Jozefowicz R., 2015, SCHEDAE INFORM; Karlsson B., 2005, C STANDARD LIB INTRO; OLAFSSON S, 1988, IEEE T PATTERN ANAL, V10, P277, DOI 10.1109/34.3890; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Principe J. C., 2000, INFORM THEORETIC LEA; Principe J. C., 2000, INFORM THEORETIC LEA, P263; Principe J.C., 2000, UNSUPERVISED ADAPTIV, V1, P265; Quevedo CV, 2014, EXPERT SYST APPL, V41, P7608, DOI 10.1016/j.eswa.2014.05.038; Rezghi M, 2014, EXPERT SYST APPL, V41, P7797, DOI 10.1016/j.eswa.2014.06.024; Santos J. M., 2004, INT C RECENT ADV SOF, P92; Silverman B., 1986, DENSITY ESTIMATION S, V26; Smieja M., 2014, IMA J MATH CONTROL I; Smusz S., 2013, J CHEMINFORMATICS, V5, P1; Subasi A, 2013, COMPUT BIOL MED, V43, P576, DOI 10.1016/j.compbiomed.2013.01.020; TAKIYAMA R, 1978, PATTERN RECOGN, V10, P27, DOI 10.1016/0031-3203(78)90045-6; Thammasiri D, 2014, EXPERT SYST APPL, V41, P321, DOI 10.1016/j.eswa.2013.07.046; Timm N. H., 2002, APPL MULTIVARIATE AN; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Van Kerm P., 2003, STATA J, V3, P148; Vapnik V., 2000, NATURE STAT LEARNING; Yap CW, 2011, J COMPUT CHEM, V32, P1466, DOI 10.1002/jcc.21707; Zhang XY, 2013, ENG APPL ARTIF INTEL, V26, P2574, DOI 10.1016/j.engappai.2013.04.008; Zhang YH, 2014, EXPERT SYST APPL, V41, P2372, DOI 10.1016/j.eswa.2013.09.035	44	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	AUG 1	2015	42	13					5591	5606		10.1016/j.eswa.2015.03.007		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	CI8QN	WOS:000355036900017		
J	Patel, VM; Gopalan, R; Li, RN; Chellappa, R				Patel, Vishal M.; Gopalan, Raghuraman; Li, Ruonan; Chellappa, Rama			Visual Domain Adaptation	IEEE SIGNAL PROCESSING MAGAZINE			English	Article							FACE RECOGNITION; OBJECT RECOGNITION; KERNEL; CLASSIFICATION; ATTRIBUTES; ALGORITHMS; MODEL		[Li, Ruonan] Harvard Univ, Cambridge, MA 02138 USA; [Chellappa, Rama] Univ Maryland UMD, Engn, College Pk, MD USA; [Chellappa, Rama] Univ Maryland UMD, Elect & Commun Engn Dept, College Pk, MD USA; [Chellappa, Rama] Int Assoc Pattern Recognit, Adelaide, SA, Australia; [Chellappa, Rama] Opt Soc Amer, Washington, DC USA; [Chellappa, Rama] Amer Assoc Advancement Sci, Cambridge, MA USA; [Chellappa, Rama] Assoc Comp Machinery, New York, NY USA		pvishalm@umd.edu; raghuram@research.att.com; ruonanli@seas.harvard.edu; rama@umiacs.umd.edu	Magazine, Signal Processing/E-9947-2015		multidisciplinary university research initiative from the Office of Naval Research [1141221258513]	This work was partially supported by a multidisciplinary university research initiative from the Office of Naval Research under grant 1141221258513.	Aytar Y, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2252, DOI 10.1109/ICCV.2011.6126504; Baktashmotlagh M., 2013, P IEEE INT C COMP VI, P769; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Bo L., 2011, P NEUR INF PROC SYST, P2115; Boyd S., 2004, CONVEX OPTIMIZATION, V1st; Branson S., P EUR C COMP VIS, P438; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chapelle O., 2006, SEMISUPERVISED LEARN; Chen M., 2012, P 29 INT C MACH LEAR, P767; Chopra S., 2013, P ICML WORKSH CHALL, P1; Dai W., 2007, P 22 AAAI C ART INT, P540; Dai W, 2008, P 25 INT C MACH LEAR, P200, DOI DOI 10.1145/1390156.1390182; Daume III H., 2007, P 45 ANN M ASS COMP, P256; Davis J. V., 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.127352; Donahue J., 2013, P INT C MACH LEARN, P647; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Duan L., 2009, P 26 ANN INT C MACH, P289; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P1667, DOI 10.1109/TPAMI.2011.265; Duan LX, 2009, PROC CVPR IEEE, P1375; Duan LX, 2012, PROC CVPR IEEE, P1338; Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; Farhadi A, 2009, PROC CVPR IEEE, P1778; Fernando B., 2013, P IEEE INT C COMP VI, P2960; Gallivan KA, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P315; Glorot X., 2011, P 28 INT C MACH LEAR, P513; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Gong B., 2012, P NEUR INF PROC SYST, P1; Gong B., 2013, P INT C MACH LEARN, P222; Gong B., 2013, P NIPS, P1286; Gong BQ, 2014, INT J COMPUT VISION, V109, P3, DOI 10.1007/s11263-014-0718-4; Gong BQ, 2012, PROC CVPR IEEE, P2066; Gopalan R, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P999, DOI 10.1109/ICCV.2011.6126344; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Griffin G., 2007, 7694 CALTECH; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Guo ZY, 2013, IEEE T IMAGE PROCESS, V22, P3108, DOI 10.1109/TIP.2013.2259836; HECKMAN JJ, 1979, ECONOMETRICA, V47, P153, DOI 10.2307/1912352; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ho HT, 2014, INT J COMPUT VISION, V109, P110, DOI 10.1007/s11263-014-0720-x; Hoffman J., 2012, P ECCV, P702; Hoffman J., 2013, P INT C LEARN REPR, P1; Huang G. B., 2007, 0749 LFW U MASS; Huang J., 2007, ADV NEURAL INFORM PR, V19, P601; Jain S. S. F. V., 2013, P IEEE INT C COMP VI, P105; Japkowicz N., 2002, Intelligent Data Analysis, V6; Jhuo IH, 2012, PROC CVPR IEEE, P2168; Jia Y., 2010, ADV NEURAL INFORM PR, P982; Jia YQ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2407; Jiang J., 2007, P 45 ANN M ASS COMP, P264; Jiang J., 2008, THESIS U ILLINOIS UR; JIANG W, 2008, IEEE IMAGE PROC, P161; Khosla A., 2012, P ECCV, P158; Kovashka A., 2013, P IEEE INT C COMP VI, P3432; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Lin Z., 2009, UILUENG092214 UIUC; Lin Z., 2009, UILUENG092215 UIUC; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Ma A. J., 2013, P IEEE INT C COMP VI, P3567; Nguyen H. V., 2012, P 12 EUR C COMP VIS, P414; Ni J, 2013, PROC CVPR IEEE, P692, DOI 10.1109/CVPR.2013.95; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Qiu Q., 2012, P EUR C COMP VIS, V7575, P631; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Raina R., 2009, THESIS STANFORD U; Rasiwasia Nikhil, 2010, P INT C MULT, P251, DOI 10.1145/1873951.1873987; Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551; Rubinstein R., 2008, CS200808 TECHN COMP; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53; Shi Y., 2012, P INT C MACH LEARN, P1079; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Shrivastava A., 2014, P IEEE WINT C APPL C, P277; Sugiyama M., 2005, STAT DECISIONS, V23, P249, DOI 10.1524/stnd.2005.23.4.249; Tommasi T., 2013, P IEEE INT C COMP VI, P897; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Van Nguyen H., 2013, THESIS U MARYLAND; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang H., 2013, P INT C MACH LEARN, V28, P298; Wang K., 2013, P INT C COMP VIS, P2088; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222; Wang Y, 2010, LECT NOTES COMPUT SC, V6315, P155; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Xing DK, 2007, LECT NOTES ARTIF INT, V4702, P324; Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292; Yang J., 2007, P 15 INT C MULT, P188, DOI 10.1145/1291233.1291276; Yang M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P543; Zadrozny B., 2004, P 21 INT C MACH LEAR, P114; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zheng J., 2012, P ICPR, P2095; Zheng J., 2013, P 25 S FUS ENG JUN, P1	103	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888	1558-0792		IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	MAY	2015	32	3					53	69		10.1109/MSP.2014.2347059		17	Engineering, Electrical & Electronic	Engineering	CF4DL	WOS:000352498800007		
J	Ohzeki, M				Ohzeki, Masayuki			Statistical-Mechanical Analysis of Pre-training and Fine Tuning in Deep Learning	JOURNAL OF THE PHYSICAL SOCIETY OF JAPAN			English	Article							ALGORITHM	In this paper, we present a statistical-mechanical analysis of deep learning. We elucidate some of the essential components of deep learning-pre-training by unsupervised learning and fine tuning by supervised learning. We formulate the extraction of features from the training data as a margin criterion in a high-dimensional feature-vector space. The self-organized classifier is then supplied with small amounts of labelled data, as in deep learning. Although we employ a simple single-layer perceptron model, rather than directly analyzing a multi-layer neural network, we find a nontrivial phase transition that is dependent on the number of unlabelled data in the generalization error of the resultant classifier. In this sense, we evaluate the efficacy of the unsupervised learning component of deep learning. The analysis is performed by the replica method, which is a sophisticated tool in statistical mechanics. We validate our result in the manner of deep learning, using a simple iterative algorithm to learn the weight vector on the basis of belief propagation.	Kyoto Univ, Grad Sch Informat, Dept Syst Sci, Kyoto 6068501, Japan	Ohzeki, M (reprint author), Kyoto Univ, Grad Sch Informat, Dept Syst Sci, Kyoto 6068501, Japan.	mohzeki@i.kyoto-u.ac.jp			JST-CREST; MEXT KAKENHI [25120008, 24740263]; Kayamori Foundation of Informational Science Advancement	The author would like to thank Muneki Yasuda, Jun-ichi Inoue, and Tomoyuki Obuchi for fruitful discussions. The present work has been performed with financial support from the JST-CREST, MEXT KAKENHI Grant Numbers 25120008 and 24740263, and the Kayamori Foundation of Informational Science Advancement.	Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop Christopher M., 2006, PATTERN RECOGNITION, V1; Decelle A, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.070603; Erhan D, 2010, J MACH LEARN RES, V11, P625; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kabashima Y, 2003, J PHYS A-MATH GEN, V36, P11111, DOI 10.1088/0305-4470/36/43/030; Kohonen T, 2001, SELF ORGANIZING MAPS; Mehta P., ARXIV14103831; Nishimori H., 2001, STAT PHYS SPIN GLASS; Nishimori H., 2011, PHASE TRANSITIONS CR; Seeger M., 2000, LEARNING LABELED UNL; Sohl-Dickstein J, 2011, PHYS REV LETT, V107, DOI 10.1103/PhysRevLett.107.220601; Tanaka K., ARXIV150100834; Tanaka T, 2013, J PHYS CONF SER, V473, DOI 10.1088/1742-6596/473/1/012001; Xu YY, 2014, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2014/11/P11015; Yamanaka S, 2015, J PHYS SOC JPN, V84, DOI 10.7566/JPSJ.84.024801; Zhu X., 2008, SEMISUPERVISED LEARN	18	1	1	PHYSICAL SOC JAPAN	TOKYO	YUSHIMA URBAN BUILDING 5F, 2-31-22 YUSHIMA, BUNKYO-KU, TOKYO, 113-0034, JAPAN	0031-9015			J PHYS SOC JPN	J. Phys. Soc. Jpn.	MAR 15	2015	84	3							034003	10.7566/JPSJ.84.034003		6	Physics, Multidisciplinary	Physics	CC6OG	WOS:000350484400015		
J	Yasuda, M				Yasuda, Muneki			Monte Carlo Integration Using Spatial Structure of Markov Random Field	JOURNAL OF THE PHYSICAL SOCIETY OF JAPAN			English	Article							PHASE-TRANSITIONS; ISING-MODEL; LEARNING ALGORITHM; BOLTZMANN MACHINES	Monte Carlo integration (MCI) techniques are important in various fields. In this study, a new MCI technique for Markov random fields (MRFs) is proposed. MCI consists of two successive parts: the first involves sampling using a technique such as the Markov chain Monte Carlo method, and the second involves an averaging operation using the obtained sample points. In the averaging operation, a simple sample averaging technique is often employed. The method proposed in this paper improves the averaging operation by addressing the spatial structure of the MRF and is mathematically guaranteed to statistically outperform standard MCI using the simple sample averaging operation. Moreover, the proposed method can be improved in a systematic manner and is numerically verified by numerical simulations using planar Ising models. In the latter part of this paper, the proposed method is applied to the inverse Ising problem and we observe that it outperforms the maximum pseudo-likelihood estimation.	Yamagata Univ, Grad Sch Sci & Engn, Yonezawa, Yamagata 9928510, Japan	Yasuda, M (reprint author), Yamagata Univ, Grad Sch Sci & Engn, Yonezawa, Yamagata 9928510, Japan.	muneki@yz.yamagata-u.ac.jp			Ministry of Education, Culture, Sports, Science and Technology, Japan [24700220]	This work was supported by a Grant-In-Aid (No. 24700220) for Scientific Research from the Ministry of Education, Culture, Sports, Science and Technology, Japan.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Aurell E, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.090201; BERG BA, 1991, PHYS LETT B, V267, P249, DOI 10.1016/0370-2693(91)91256-U; BERG BA, 1992, PHYS REV LETT, V68, P9, DOI 10.1103/PhysRevLett.68.9; Besag J., 1975, J R STAT SOC D-STAT, V24, P179; Cocco S, 2011, PHYS REV LETT, V106, DOI 10.1103/PhysRevLett.106.090601; FISHER ME, 1966, J MATH PHYS, V7, P1776, DOI 10.1063/1.1704825; Furtlehner C., 2013, J STAT MECH-THEORY E, V2013; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang HP, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.062129; Hukushima K, 1996, J PHYS SOC JPN, V65, P1604, DOI 10.1143/JPSJ.65.1604; KAC M, 1952, PHYS REV, V88, P1332, DOI 10.1103/PhysRev.88.1332; Kappen HJ, 1998, NEURAL COMPUT, V10, P1137, DOI 10.1162/089976698300017386; KASTELEYN PW, 1963, J MATH PHYS, V4, P287, DOI 10.1063/1.1703953; Liu J. S., 2001, MONTE CARLO STRATEGI; Marinari E, 2010, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2010/02/P02008; MORITA T, 1993, J PHYS SOC JPN, V62, P873, DOI 10.1143/JPSJ.62.873; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Nguyen HC, 2012, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2012/03/P03004; Ravikumar P, 2010, ANN STAT, V38, P1287, DOI 10.1214/09-AOS691; Ricci-Tersenghi F, 2012, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2012/08/P08015; Sejnowski T. J., 1986, AIP C P, V151, P398; Sessak V, 2009, J PHYS A-MATH THEOR, V42, DOI 10.1088/1751-8113/42/5/055001; SHERMAN S, 1960, J MATH PHYS, V1, P202, DOI 10.1063/1.1703653; Tanaka T, 1998, PHYS REV E, V58, P2302, DOI 10.1103/PhysRevE.58.2302; Yasuda M, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.012134; Yasuda M, 2009, NEURAL COMPUT, V21, P3130, DOI 10.1162/neco.2009.08-08-844	27	1	1	PHYSICAL SOC JAPAN	TOKYO	YUSHIMA URBAN BUILDING 5F, 2-31-22 YUSHIMA, BUNKYO-KU, TOKYO, 113-0034, JAPAN	0031-9015			J PHYS SOC JPN	J. Phys. Soc. Jpn.	MAR 15	2015	84	3							034001	10.7566/JPSJ.84.034001		7	Physics, Multidisciplinary	Physics	CC6OG	WOS:000350484400013		
J	Liu, H; Ma, BP; Qin, L; Pang, JB; Zhang, CJ; Huang, QM				Liu, Hao; Ma, Bingpeng; Qin, Lei; Pang, Junbiao; Zhang, Chunjie; Huang, Qingming			Set-label modeling and deep metric learning on person re-identification	NEUROCOMPUTING			English	Article						Person re-identification; Mutual-information; Metric learning; Deep learning; Neighborhood component analysis		Person re-identification aims at matching individuals across multiple non-overlapping adjacent cameras. By condensing multiple gallery images of a person as a whole, we propose a novel method named Set-Label Model (SLM) to improve the performance of person re-identification under the multi-shot setting. Moreover, we utilize mutual-information to measure the relevance between query image and gallery sets. To decrease the computational complexity, we apply a Naive-Bayes Nearest-Neighbor algorithm to approximate the mutual-information value. To overcome the limitations of traditional linear metric learning, we further develop a deep non-linear metric learning (DeepML) approach based on Neighborhood Component Analysis and Deep Belief Network To evaluate the effectiveness of our proposed approaches, SLM and DeepML, we have carried out extensive experiments on two challenging datasets LIDS and ETHZ. The experimental results demonstrate that the proposed methods can obtain better performances compared with the state-of-the-art methods. (C) 2014 Elsevier B.V. All rights reserved.	[Liu, Hao; Ma, Bingpeng; Zhang, Chunjie; Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100190, Peoples R China; [Qin, Lei; Huang, Qingming] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China; [Pang, Junbiao] Beijing Univ Technol, Coll Metropolitan Transportat, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China	Qin, L (reprint author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.	h-liu14@mails.tsinghua.edu.cn; bpma@ucas.ac.cn; qinlei@ict.ac.cn; jbpang@jdl.ac.cn; zhangcj@ucas.ac.cn; qmhuang@ict.ac.cn			National Basic Research Program of China (973 Program) [2012CB316400]; National Natural Science Foundation of China [61025011, 61133003, 61332016, 61390510, 61303154]	This work was supported in part by National Basic Research Program of China (973 Program): 2012CB316400, in part by National Natural Science Foundation of China: 61025011, 61133003, 61332016, 61390510, 61303154.	Avraham T., 2012, ECCV LECT NOTES COMP, V7583, P381; Bazzani L, 2010, INT C PATT REC; Boiman O., 2008, IEEE C COMP VIS PATT; Davis J., 2007, INT C MACH LEARN; Donahue J., 2014, INT C MACH LEARN; Farenzena M., 2010, IEEE C COMP VIS PATT; Girshick R.B., 2014, IEEE C COMP VIS PATT; Globerson A., 2005, ADV NEURAL INFORM PR; Gray D., 2008, EUR C COMP VIS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hirzer M., 2012, EUR C COMP VIS; Khan S.H., 2014, IEEE C COMP VIS PATT; Kostinger M., 2012, IEEE C COMP VIS PATT; Layne R., 2012, BRIT MACH VIS C; Liu Y., 2014, IEEE INT C IM PROC; Ma B., 2012, BRIT MACH VIS C; Ma B., 2012, LECT NOTES COMPUTER, V7583, P413; Oquab M., 2014, IEEE C COMP VIS PATT; Prosser B., 2010, BRIT MACH VIS C; Qin L., 2005, IEEE INT C IM PROC, V3, P77; Razavian A.S., 2014, IEEE C COMP VIS PATT; Salakhutdinov R., 2004, INT C ART INT STAT; Salakhutdinov R., 2009, INT C ART INT STAT; Salakhutdinov R., 2010, INT C MACH LEARN; Schwartz W., 2009, COMPUTER GRAPHICS IM; Sermanet P., 2014, INT C LEARN REPR; Weinberger K., 2005, ADV NEURAL INFORM PR, V18, P1473; Xing E., 2002, ADV NEURAL INFORM PR; Yuan J., 2009, IEEE C COMP VIS PATT; Zheng W., 2012, IEEE C COMP VIS PATT; Zheng W., 2011, IEEE C COMP VIS PATT; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138	33	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAR 3	2015	151		3				1283	1292		10.1016/j.neucom.2014.11.002		10	Computer Science, Artificial Intelligence	Computer Science	AY7QG	WOS:000347753600034		
J	Kim, IJ; Xie, XH				Kim, In-Jung; Xie, Xiaohui			Handwritten Hangul recognition using deep convolutional neural networks	INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION			English	Article						Handwritten Hangul recognition; Character recognition; Deep convolutional neural network; Deep learning; Gradient-based learning	ALGORITHM	In spite of the advances in recognition technology, handwritten Hangul recognition (HHR) remains largely unsolved due to the presence of many confusing characters and excessive cursiveness in Hangul handwritings. Even the best existing recognizers do not lead to satisfactory performance for practical applications and have much lower performance than those developed for Chinese or alphanumeric characters. To improve the performance of HHR, here we developed a new type of recognizers based on deep neural networks (DNNs). DNN has recently shown excellent performance in many pattern recognition and machine learning problems, but have not been attempted for HHR. We built our Hangul recognizers based on deep convolutional neural networks and proposed several novel techniques to improve the performance and training speed of the networks. We systematically evaluated the performance of our recognizers on two public Hangul image databases, SERI95a and PE92. Using our framework, we achieved a recognition rate of 95.96 % on SERI95a and 92.92 % on PE92. Compared with the previous best records of 93.71 % on SERI95a and 87.70 % on PE92, our results yielded improvements of 2.25 and 5.22 %, respectively. These improvements lead to error reduction rates of 35.71 % on SERI95a and 42.44 % on PE92, relative to the previous lowest error rates. Such improvement fills a significant portion of the large gap between practical requirement and the actual performance of Hangul recognizers.	[Kim, In-Jung] Handong Global Univ, Sch CSEE, Pohang 791708, Gyeongbuk, South Korea; [Xie, Xiaohui] Univ Calif Irvine, Sch Informat & Comp Sci, Dept Comp Sci, Irvine, CA 92697 USA	Kim, IJ (reprint author), Handong Global Univ, Sch CSEE, Pohang 791708, Gyeongbuk, South Korea.	ijkim@handong.edu; xhx@ics.uci.edu					Bae H.J., 1990, P KOR INF SCI AUT C, V17, P251; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Boureau Y., 2010, P INT C MACH LEARN I; Ciresan Dan Claudiu, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_31; Ciresan D.C., 2013, IDSIA0513; Ciresan D.C., 2012, IEEE C COMP VIS PATT; Everitt B. S, 1992, ANAL CONTINGENCY TAB; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Glorot X., 2011, P 14 INT C ART INT S, V15; GOODHILL GJ, 1994, NEURAL COMPUT, V6, P255, DOI 10.1162/neco.1994.6.2.255; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Jang S.I., 2002, THESIS KAIST; Jeong S.H., 2002, HANDWRITTEN HANGUL R; Kang KW, 2004, IEEE T PATTERN ANAL, V26, P1185; Kim D. H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), DOI 10.1109/ICDAR.1993.395693; Kim D.-I., 1998, P 6 INT WORKSH FRONT, P455; Kim HY, 2001, PATTERN RECOGN, V34, P187, DOI 10.1016/S0031-3203(99)00222-8; Kim M.W., 1992, TECHNICAL REPORT; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu C.-L., 2011, ICDAR 2011 CHINESE H; Liu H., 2005, P 8 INT C DOC AN REC; Nair V., 2010, P 27 INT C MACH LEAR; Ozkan C, 2003, PHOTOGRAMM ENG REM S, V69, P1225; Park GR, 2013, INT J DOC ANAL RECOG, V16, P273, DOI 10.1007/s10032-012-0191-y; Platt J. C., 2003, P INT C DOC AN REC I, P958; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294	28	1	1	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1433-2833	1433-2825		INT J DOC ANAL RECOG	Int. J. Doc. Anal. Recognit.	MAR	2015	18	1					1	13		10.1007/s10032-014-0229-4		13	Computer Science, Artificial Intelligence	Computer Science	CC2XL	WOS:000350208300001		
J	Tang, JX; Deng, CW; Huang, GB; Zhao, BJ				Tang, Jiexiong; Deng, Chenwei; Huang, Guang-Bin; Zhao, Baojun			Compressed-Domain Ship Detection on Spaceborne Optical Image Using Deep Neural Network and Extreme Learning Machine	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						Compressed domain; deep neural network (DNN); extreme learning machine (ELM); JPEG2000; optical spaceborne image; remote sensing; ship detection	SATELLITE IMAGERY; TEXTURE FEATURES; JPEG2000; ALGORITHM; CLASSIFICATION; TRACKS	Ship detection on spaceborne images has attracted great interest in the applications of maritime security and traffic control. Optical images stand out from other remote sensing images in object detection due to their higher resolution and more visualized contents. However, most of the popular techniques for ship detection from optical spaceborne images have two shortcomings: 1) Compared with infrared and synthetic aperture radar images, their results are affected by weather conditions, like clouds and ocean waves, and 2) the higher resolution results in larger data volume, which makes processing more difficult. Most of the previous works mainly focus on solving the first problem by improving segmentation or classification with complicated algorithms. These methods face difficulty in efficiently balancing performance and complexity. In this paper, we propose a ship detection approach to solving the aforementioned two issues using wavelet coefficients extracted from JPEG2000 compressed domain combined with deep neural network (DNN) and extreme learning machine (ELM). Compressed domain is adopted for fast ship candidate extraction, DNN is exploited for high-level feature representation and classification, and ELM is used for efficient feature pooling and decision making. Extensive experiments demonstrate that, in comparison with the existing relevant state-of-the-art approaches, the proposed method requires less detection time and achieves higher detection accuracy.	[Tang, Jiexiong; Deng, Chenwei; Zhao, Baojun] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China; [Huang, Guang-Bin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Deng, CW (reprint author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.	cwdeng@bit.edu.cn			National Natural Science Foundation of China [61301090]; Beijing Excellent Talent Fund [2013D009011000001]; Excellent Young Scholars Research Fund of Beijing Institute of Technology [2013YR0508]	This work was supported in part by the National Natural Science Foundation of China under Grant 61301090, by the Beijing Excellent Talent Fund under Grant 2013D009011000001, and by the Excellent Young Scholars Research Fund of Beijing Institute of Technology under Grant 2013YR0508.	Adams M. D., 2001, JPEG 2000 STILL IMAG; [Anonymous], 2009, IMAGE VIS COMPUT, V27, P1108; Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, DOI 10.1007/978-3-642-25446-8_4; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404; Bengio Y., 2005, P ADV NEUR INF PROC, P107; Bengio Y., 2013, HDB NEURAL INFORM PR, P1; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P1; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2007, LARGE SCALE KERNEL M, V31, P1; Bi F, 2010, ADV NEURAL NETWORK R, P729; BURGESS DW, 1993, PHOTOGRAMM ENG REM S, V59, P229; Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_30; Corbane C, 2010, INT J REMOTE SENS, V31, P5837, DOI 10.1080/01431161.2010.512310; Corbane C, 2008, SENSORS-BASEL, V8, P2959, DOI 10.3390/s8052959; Dalal N, 2005, PROC CVPR IEEE, P886; Delac K, 2005, LECT NOTES COMPUT SC, V3687, P136; DeSilva C., 1995, P EL TECHN DIR YEAR, P194; Erhan D, 2010, J MACH LEARN RES, V11, P625; Erhan D, 2009, P 12 INT C ART INT S, P153; Gonzalez R. C., 2007, DIGITAL IMAGE PROCES, P742; Hinton G., 2010, MOMENTUM, V9; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2005, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, P232; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Jolliffe I., 2005, PRINCIPAL COMPONENT; Jong A. N. de, 1993, P SOC PHOTO-OPT INS, P216; Kohavi R., 1995, P INT JOINT C ART IN, V14, P1137; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu J.-W., 2006, P IEEE INT C AUT SCI, P165; LURE FYM, 1994, INT GEOSCI REMOTE SE, P1401, DOI 10.1109/IGARSS.1994.399451; MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727; Netzer Y., 2011, P NIPS WORKSH DEEP L, V2011, P1; Ni L., 2003, P ICICS, V3, P1591; Pal M, 2013, REMOTE SENS LETT, V4, P853, DOI 10.1080/2150704X.2013.805279; Sahin M., 2013, INT J REMOTE SENS, V34, P7508; Shalabi LA, 2006, J COMPUTER SCI, V2, P735; Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485; Sonka M., 1999, IMAGE PROCESSING ANA; Srivastava N., 2013, THESIS U TORONTO TOR; Tello M, 2005, IEEE GEOSCI REMOTE S, V2, P201, DOI [10.1109/LGRS.2005.845033, 10.1109/lGRS.2005.845003]; Teynor A, 2006, LECT NOTES COMPUT SC, V3736, P132; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Weiss JM, 1997, INT GEOSCI REMOTE SE, P160, DOI 10.1109/IGARSS.1997.615827; Wu GF, 2009, INT J APPL EARTH OBS, V11, P54, DOI 10.1016/j.jag.2008.07.001; Xiong ZY, 2002, IEEE IMAGE PROC, P481; You X., 2011, P CISP, V3, P1155; Zargari F, 2008, IEEE T CONSUM ELECTR, V54, P1886, DOI 10.1109/TCE.2008.4711250; Zhu CR, 2010, IEEE T GEOSCI REMOTE, V48, P3446, DOI 10.1109/TGRS.2010.2046330	53	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892	1558-0644		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAR	2015	53	3					1174	1185		10.1109/TGRS.2014.2335751		12	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	AR9MZ	WOS:000343900600004		
J	Shen, W; Wang, JY; Han, JW				Shen, Wei; Wang, Jianyong; Han, Jiawei			Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Entity linking; entity disambiguation; knowledge base	WIKIPEDIA; WEB	The large number of potential applications from bridging web data with knowledge bases have led to an increase in the entity linking research. Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base. Potential applications include information extraction, information retrieval, and knowledge base population. However, this task is challenging due to name variations and entity ambiguity. In this survey, we present a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.	[Shen, Wei] Nankai Univ, Coll Comp & Control Engn, Tianjin 300071, Peoples R China; [Wang, Jianyong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [Han, Jiawei] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Shen, W (reprint author), Nankai Univ, Coll Comp & Control Engn, Tianjin 300071, Peoples R China.	shenwei@nankai.edu.cn; jianyong@tsinghua.edu.cn; hanj@cs.uiuc.edu			National Key Basic Research Program of China (973 Program) [2014CB340505]; National Natural Science Foundation of China [61272088]; Samsung; Tsinghua University Initiative Scientific Research Program; US Army Research Laboratory [W911NF-09-2-0053]; US Army Research Office [W911NF-13-1-0193]; U.S. National Science Foundation [CNS-0931975, IIS-1017362, IIS-1320617, IIS-1354329]; DTRA; NASA [NRA-NNH10ZDA001N]; MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC	This work was supported in part by National Key Basic Research Program of China (973 Program) under Grant No. 2014CB340505, National Natural Science Foundation of China under Grant No. 61272088, a Samsung Research Grant, Tsinghua University Initiative Scientific Research Program, the US Army Research Laboratory under Cooperative Agreement No. W911NF-09-2-0053 (NS-CTA), the US Army Research Office under Cooperative Agreement No. W911NF-13-1-0193, U.S. National Science Foundation grants CNS-0931975, IIS-1017362, IIS-1320617, IIS-1354329, DTRA, NASA NRA-NNH10ZDA001N, and MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC.	Adeva G. J. J., 2005, CLEI ELECT J, V9; Agichtein E., 2000, P 5 ACM INT C DIG LI, P85, DOI 10.1145/336597.336644; Agirrey E., 2009, P TEXT AN C WORKSH; Artiles J., 2007, P 4 INT WORKSH SEM E, P64, DOI 10.3115/1621474.1621486; Auer S., 2007, P 6 INT SEM WEB C, P11; Bagga A, 1998, P 36 ANN M ASS COMP, P79; Balog K., 2010, P 19 TEXT RETRIEVAL; Bentivogli L., 2010, P COL WORKSH PEOPL W, P19; Berners-Lee T, 2001, SCI AM, V284, P34; Bilenko M, 2003, IEEE INTELL SYST, V18, P16, DOI 10.1109/MIS.2003.1234765; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bollacker K., 2008, P 2008 ACM SIGMOD IN, P1247, DOI DOI 10.1145/1376616.1376746; Bordino I., 2013, P 22 ACM INT C INF K, P109; Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Brinker K., 2003, P 20 INT C MACH LEAR, V3, P59; Bunescu R., 2006, P EACL, V6, P9; Cafarella M.J., 2008, P VLDB ENDOW, V1, P538; Can Z., 2007, P 24 INT C MACH LEAR, P129, DOI 10.1145/1273496.1273513; Carlson A, 2010, P 3 ACM INT C WEB SE, P101, DOI 10.1145/1718487.1718501; Cassidy T., 2011, P TEXT AN C WORKSH; Ceccarelli D., 2013, P ACM INT C INF KNOW, P139; Chakrabarti K., 2012, P INT C KNOWL DISC D, P1384; Chen Z., 2012, P JOINT C EMP METH N, P105; Chen Z., 2010, P TEXT AN C WORKSH; Cheng T, 2012, IEEE T KNOWL DATA EN, V24, P1862, DOI 10.1109/TKDE.2011.168; Cheng T., 2007, P 33 INT C VER LARG, P387; Christen P, 2012, IEEE T KNOWL DATA EN, V24, P1537, DOI 10.1109/TKDE.2011.127; Christen P., 2006, P 6 IEEE INT C DAT M, P290; Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48; Cornolti M., 2013, P 22 INT C WORLD WID, P249; Cucerzan S., 2011, P TEXT AN C WORKSH; Cucerzan S., 2007, P 2007 JOINT C EMP M, P708; Dai H.-J., 2011, P 5 INT JOINT C NAT, P846; Dalvi N., 2012, P 5 ACM INT C WEB SE, P43; Daroczy B., 2009, P EV SYST MULT MULT; Daume H, 2007, P 45 ANN M ASS COMP, V45, P256; Demartini G., 2012, P 21 INT C WORLD WID, P469, DOI DOI 10.1145/2187836.2187900; Demartini G., 2009, P FOC RETR EV 8 INT, P254; Deorowicz S., 2005, International Journal of Applied Mathematics and Computer Science, V15; Dong X., 2005, P ACM SIGMOD INT C M, P85, DOI 10.1145/1066157.1066168; Dredze M., 2010, P 23 INT C COMP LING, P277; Dreyer M., 2008, P C EMP METH NAT LAN, P1080, DOI 10.3115/1613715.1613856; Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581; Elmeleegy H., 2009, P VLDB ENDOWMENT, V2, P1078; Etzioni O., 2004, P 13 INT C WORLD WID, P100, DOI 10.1145/988672.988687; Fellbaum C., 1998, WORDNET ELECT LEXICA; Ferragina P., 2010, P 19 ACM INT C INF K, P1625, DOI 10.1145/1871437.1871689; Finkel J.R., 2005, P 43 ANN M ASS COMP, P363, DOI 10.3115/1219840.1219885; Fumarola F, 2011, P 24 INT C IND ENG O, P285; Gattani A., 2013, P VLDB ENDOW, V6, P1126; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Gottipati S., 2011, P 2011 C EMP METH NA, P804; Guo JF, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/1571941.1571989; Guo S., 2013, P C N AM CHAPT ASS C, P1020; Guo Y., 2013, P C EMP METH NAT LAN, P863; Hachey B, 2013, ARTIF INTELL, V194, P130, DOI 10.1016/j.artint.2012.04.005; Hadjieleftheriou M., 2011, FDN TRENDS DATAB, V2, P267; Han X., 2011, P 34 INT ACM SIGIR C, P765; Han X., 2012, EMNLP; Han X., 2009, P 18 ACM C INF KNOWL, P215, DOI DOI 10.1145/1645953.1645983; Han X., 2011, P 49 ANN M ASS COMP, V1, P945; Han X., 2009, P TEXT AN C WORKSH; Hasegawa T., 2004, P 42 ANN M ASS COMP, P415, DOI 10.3115/1218955.1219008; Hassanzadeh O., 2007, P 5 INT WORKSH QUAL; Haveliwala T. H., 2002, P 11 INT C WORLD WID, P517, DOI DOI 10.1145/511446.511513; He Z., 2013, P ANN M ASS COMP LIN, P30; HERBRICH R, 2000, ADV LARGE MARGIN CLA, V88, P115; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffart J., 2011, P C EMP METH NAT LAN, P782; Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001; Hoffart J., 2012, P 21 ACM INT C INF K, P545; Isele R., 2012, PVLDB, V5, P1638; Jain A., 2007, P IEEE INT C INF REU, P209; Ji H., 2011, P 49 ANN M ASS COMP, V1, P1148; Ji H., 2011, P TEXT AN C WORKSH; Ji H., 2010, P TEXT AN C WORKSH; Jiang LL, 2009, IEEE DATA MINING, P199, DOI 10.1109/ICCSIT.2009.5234744; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067; Klein D, 2003, P 7 C NAT LANG LEARN, V4, P180, DOI 10.3115/1119176.1119204; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Kopcke H, 2010, DATA KNOWL ENG, V69, P197, DOI 10.1016/j.datak.2009.10.003; Kulkarni S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P457; Lehmann J., 2007, P AUT CONT EXT C; Lehmann J., 2010, P TEXT AN C WORKSH; Li F., 2009, P TEXT AN C WORKSH; Li Y., 2013, P 19 ACM SIGKDD INT, P1070; Limaye G., 2010, PVLDB, V3, P1338; Lin T., 2012, P JOINT WORKSH AUT K, P84; Lin T., 2012, P JOINT C EMP METH N, P893; Ling X., 2012, P 26 C ART INT, P94; Liu J, 2010, IUI 2010, P31; Liu T.-Y., 2009, FOUND TRENDS INF RET, V3, P225, DOI [DOI 10.1561/1500000016, 10.1561/1500000016]; Liu X., 2013, 51 ANN M ASS COMP LI; Liu X., 2011, P 49 ANN M ASS COMP, V1, P359; Mann G. S., 2003, P 7 C NAT LANG LEARN, P33; McNamee P., 2009, P TEXT AN C WORKSH; McNamee P., 2010, P TEXT AN C WORKSH; Meij E., 2012, P 5 ACM INT C WEB SE, P563; Michelson M., 2010, P 4 WORKSH AN NOIS U, P73, DOI 10.1145/1871840.1871852; Mikheev A., 1999, P 9 C EUR CHAPT ASS, P1, DOI 10.3115/977035.977037; Milne D., 2008, P 17 ACM C INF KNOWL, P509, DOI DOI 10.1145/1458082.1458150; Milne D, 2013, ARTIF INTELL, V194, P222, DOI 10.1016/j.artint.2012.06.007; Monahan S., 2011, P TEXT AN C WORKSH; Nadeau D., 2007, LINGVISTICAE INVESTI, V30, P3, DOI DOI 10.1075/1I.30.1.03NAD; Nakashole N., 2013, P ANN M ASS COMP LIN, P1488; Nakashole N., 2012, JOINT C EMP METH NAT, P1135; Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355; Nemeskey D., 2010, P TEXT AN C WORKSH; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Pantel P., 2011, 49 ANN M ASS COMP LI, P83; Phelan O., 2009, P 3 ACM C REC SYST R, P385, DOI 10.1145/1639714.1639794; Pilz A., 2011, P ACM INT C INF KNOW, P857; Pu K. Q., 2010, P 19 ACM INT C INF K, P29, DOI 10.1145/1871437.1871446; Ratinov L., 2011, COMPUTATIONAL LINGUI, V1, P1375; Ritter A, 2011, P 2011 C EMP METH NA, P1524; Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Shen D, 2004, P 42 ANN M ASS COMP, P589, DOI 10.3115/1218955.1219030; Shen LB, 2005, MACH LEARN, V60, P73, DOI 10.1007/s10994-005-0918-9; Shen W., 2011, P 20 INT C COMP WORL, P121; Shen W., 2013, P 19 ACM SIGKDD INT, P68; Shen W., 2012, P 18 ACM SIGKDD INT, P1424, DOI DOI 10.1145/2339530.2339753; Shen W., 2012, P 21 ACM INT C INF K, P345; Shen W., 2014, SIGMOD, P1199; Shen W., 2012, P 21 INT C WORLD WID, P449; Sil A., 2013, P 22 ACM INT C INF K, P2369; Singh S., 2012, UMCS2012015; Sozio M., 2010, P 16 ACM SIGKDD INT, P939, DOI DOI 10.1145/1835804; STAJNER T, 2009, P 4 AS C SEM WEB, V5926, P91; Suchanek F. M., 2007, P 16 INT C WORLD WID, P697, DOI DOI 10.1145/1242572.1242667; Taneva B., 2013, P 22 INT C WORLD WID, P1261; Varga Daniel, 2007, Acta Cybernetica, V18; Varma V., 2009, P TEXT AN C WORKSH; Varma V., 2010, P TEXT AN C WORKSH; Volz J, 2009, LECT NOTES COMPUT SC, V5823, P650, DOI 10.1007/978-3-642-04930-9_41; Wang J., 2012, PVLDB, V5, P1483; Welty C., 2012, LNCS, V7650, P243; Weng J., 2010, P 3 ACM INT C WEB SE, P261, DOI DOI 10.1145/1718487.1718520; Wu W., 2012, P 2012 ACM SIGMOD IN, P481, DOI DOI 10.1145/2213836.2213891; Yin X., 2007, P IEEE 23 INT C DAT, P1242; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205; Zhai C., 2001, P 10 INT C INF KNOWL, P403, DOI DOI 10.1145/502585.502654; Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322; Zhang T., 2013, P 23 INT JOINT C ART, P2218; Zhang W., 2010, 23 INT C COMP LING, P1290; Zhang W., 2011, P TEXT AN C WORKSH; Zhang W., 2011, 22 INT JOINT C ART I, P1909; Zhang W., 2010, P TEXT AN C WORKSH; Zhang Z., 2012, P 18 ACM SIGKDD INT, P1560; Zheng Z., 2010, P 11 ANN C N AM CHAP, P483	150	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347	1558-2191		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2015	27	2					443	460		10.1109/TKDE.2014.2327028		18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	AX5QU	WOS:000346982900010		
S	Mobahi, H; Fisher, JW	Tai, XC	Bae, E; Chan, TF; Lysaker, M		Mobahi, Hossein; Fisher, John W., III	Tai, XC		On the Link between Gaussian Homotopy Continuation and Convex Envelopes	ENERGY MINIMIZATION METHODS IN COMPUTER VISION AND PATTERN RECOGNITION, EMMCVPR 2015	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR)	JAN 13-16, 2015	Hong Kong, PEOPLES R CHINA	Hong Kong Univ Sci & Technol, Hong Kong Univ Sci & Technol, Jockey Club Inst Adv Study		Continuation Method; Diffusion Equation; Nonconvex Optimization; Vese's PDE	STATISTICAL PHYSICS; RECONSTRUCTION; ALGORITHM; OPTIMIZATION; RECOGNITION; CONSTRAINTS; STEREO	The continuation method is a popular heuristic in computer vision for nonconvex optimization. The idea is to start from a simplified problem and gradually deform it to the actual task while tracking the solution. It was first used in computer vision under the name of graduated nonconvexity. Since then, it has been utilized explicitly or implicitly in various applications. In fact, state-of-the-art optical flow and shape estimation rely on a form of continuation. Despite its empirical success, there is little theoretical understanding of this method. This work provides some novel insights into this technique. Specifically, there are many ways to choose the initial problem and many ways to progressively deform it to the original task. However, here we show that when this process is constructed by Gaussian smoothing, it is optimal in a specific sense. In fact, we prove that Gaussian smoothing emerges from the best affine approximation to Vese's nonlinear PDE. The latter PDE evolves any function to its convex envelope, hence providing the optimal convexification.	[Mobahi, Hossein; Fisher, John W., III] MIT, Comp Sci & Artificial Intelligence Lab CSAIL, Cambridge, MA 02139 USA	Mobahi, H (reprint author), MIT, Comp Sci & Artificial Intelligence Lab CSAIL, Cambridge, MA 02139 USA.	hmobahi@csail.mit.edu; fisher@csail.mit.edu					Balzer J., 2012, CVPR; Barron J., 2013, THESIS U CALIFORNIA; Bengio Y., 2009, ICML; Bengio Y., 2009, LEARNING DEEP ARCHIT; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Blake A, 1987, VISUAL RECONSTRUCTIO; BLAKE A, 1989, IEEE T PATTERN ANAL, V11, P2, DOI 10.1109/34.23109; Boccuto A., 2002, GNC ALGORITHM DEBLUR; Brox T., 2005, THESIS SAARLAND U GE; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; BURGERS J. M., 1974, NONLINEAR DIFFUSION; Chapelle O, 2010, INFORM RETRIEVAL, V13, P216, DOI 10.1007/s10791-009-9110-3; Chapelle O., 2006, ICML, P185; Chapelle O, 2008, J MACH LEARN RES, V9, P203; Chaudhuri S, 2010, ACM SIGPLAN NOTICES, V45, P279; Chaudhuri S., 2011, LECT NOTES COMPUTER, V6806, P277; Chaudhuri S, 2014, ACM SIGPLAN NOTICES, V49, P207, DOI 10.1145/2535838.2535859; Cohen L.D., 1995, SNAKES CONVEXITE FON; Coupe P, 2013, NEUROIMAGE, V83, P245, DOI 10.1016/j.neuroimage.2013.06.030; Dai ZW, 2012, PROC CVPR IEEE, P2400; Dhillon P.S., 2012, AISTATS 2012, V15; Dufour RM, 2002, IEEE T IMAGE PROCESS, V11, P1385, DOI 10.1109/TIP.2002.806245; Dvijotham K., 2014, UNIVERSAL CONVEXIFIC; Erhan D., 2009, J MACHINE LEARNING R, V5, P153; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Frank M, 2012, J MACH LEARN RES, V13, P459; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; Gehler P., 2007, AISTATS 2007 MICR BR, P123; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; Geiger D., 1989, NIPS, P660; Gold S., 1994, NIPS, P713; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Held D., 2014, RSS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong B.W., 2013, CVPR; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kim M., 2010, GAUSSIAN PROCESSES M, P535; KOSOWSKY JJ, 1994, NEURAL NETWORKS, V7, P477, DOI 10.1016/0893-6080(94)90081-7; Leich A., 2004, 12 EUR SIGN PROC C E; Leordeanu M., 2008, CVPR; Li X, 2011, IEEE T IMAGE PROCESS, V20, P971, DOI 10.1109/TIP.2010.2081681; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; Loog M, 2001, LECT NOTES COMPUT SC, V2106, P183; Mairal J., 2009, ICML, V382, P87; Malek-Mohammadi M, 2014, IEEE T SIGNAL PROCES, V62, P981, DOI 10.1109/TSP.2013.2295557; Mobahi H., 2009, PICT COD S; Mobahi H., 2012, CVPR; Mohimani G.H., 2010, CORR; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nielsen M., 1993, P BRIT MACH VIS C, P601; Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275; Pretto A., 2010, P WORKSH OMN ROB VIS; Price BL, 2010, PROC CVPR IEEE, P2157, DOI 10.1109/CVPR.2010.5539895; Rangarajan A., 1990, GEN GRADUATED NONCON, pII; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; Rossi F, 2010, NEUROCOMPUTING, V73, P1142, DOI 10.1016/j.neucom.2009.11.023; Saragih J., 2013, DEFORMABLE FACE ALIG, P187; Shroff N., 2011, NIPS, P154; Sindhwani V., 2006, INT C MACH LEARN 200, P841, DOI DOI 10.1145/1143844.1143950; Smith N.A., 2004, ACL 2004, P486; Stoll M, 2013, IEEE IMAGE PROC, P3845, DOI 10.1109/ICIP.2013.6738792; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Tirthapura S, 1998, P SOC PHOTO-OPT INS, V3527, P25, DOI 10.1117/12.325825; Trzasko J, 2009, IEEE T MED IMAGING, V28, P106, DOI 10.1109/TMI.2008.927346; Vese L, 1999, COMMUN PART DIFF EQ, V24, P1573, DOI 10.1080/03605309908821476; Vural E, 2013, SIAM J IMAGING SCI, V6, P2310, DOI 10.1137/130909858; Widder D V, 1975, THE HEAT EQUATION; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu Z, 2013, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2013.197; Wu ZJ, 1996, SIAM J OPTIMIZ, V6, P748, DOI 10.1137/S1052623493254698; Yuille A., 1987, ENERGY FUNCTIONS EAR; Yuille A., 1990, LNCS, V427, P71; Yuille A. L., 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1; YUILLE AL, 1994, NEURAL COMPUT, V6, P334, DOI 10.1162/neco.1994.6.2.334; Yuille A.L., 1991, DEFORMABLE TEMPLATES, P166; Zaslavskiy M., 2009, IEEE PAMI; ZERUBIA J, 1993, IEEE T NEURAL NETWOR, V4, P703, DOI 10.1109/72.238324	78	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-14612-6; 978-3-319-14611-9	LECT NOTES COMPUT SC			2015	8932						43	56				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BD0ON	WOS:000357502000004		
J	Spencer, M; Eickholt, J; Cheng, JL				Spencer, Matt; Eickholt, Jesse; Cheng, Jianlin			A Deep Learning Network Approach to ab initio Protein Secondary Structure Prediction	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						Machine learning; neural nets; protein structure prediction; deep learning	SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; FOLD RECOGNITION; SERVER; SEQUENCE; PROFILES; GENERATION; ACCURACY; DISORDER; CONTACTS	Ab initio protein secondary structure (SS) predictions are utilized to generate tertiary structure predictions, which are increasingly demanded due to the rapid discovery of proteins. Although recent developments have slightly exceeded previous methods of SS prediction, accuracy has stagnated around 80 percent and many wonder if prediction cannot be advanced beyond this ceiling. Disciplines that have traditionally employed neural networks are experimenting with novel deep learning techniques in attempts to stimulate progress. Since neural networks have historically played an important role in SS prediction, we wanted to determine whether deep learning could contribute to the advancement of this field as well. We developed an SS predictor that makes use of the position-specific scoring matrix generated by PSI-BLAST and deep learning network architectures, which we call DNSS. Graphical processing units and CUDA software optimize the deep network architecture and efficiently train the deep networks. Optimal parameters for the training process were determined, and a workflow comprising three separately trained deep networks was constructed in order to make refined predictions. This deep learning network approach was used to predict SS for a fully independent test dataset of 198 proteins, achieving a Q(3) accuracy of 80.7 percent and a Sov accuracy of 74.2 percent.	[Spencer, Matt] Univ Missouri, Inst Informat, Columbia, MO 65211 USA; [Eickholt, Jesse] Cent Michigan Univ, Dept Comp Sci, Mt Pleasant, MI 48859 USA; [Cheng, Jianlin] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA	Spencer, M (reprint author), Univ Missouri, Inst Informat, Columbia, MO 65211 USA.	mcsgx2@mail.missouri.edu; eickh1jl@cmich.edu; chengji@missouri.edu	Cheng, Jianlin/N-8209-2013		National Institutes of Health [R01GM093123]	The work of M. Spencer, J. Eickholt, and J. Cheng was supported by the National Institutes of Health under Grant R01GM093123.	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Atchley WR, 2005, P NATL ACAD SCI USA, V102, P6395, DOI 10.1073/pnas.0408677102; Aydin Z, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-178; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Cheng J, 2005, NUCLEIC ACIDS RES, V33, pW72, DOI 10.1093/nar/gki396; CHOU PY, 1974, BIOCHEMISTRY-US, V13, P211, DOI 10.1021/bi00699a001; Cole C, 2008, NUCLEIC ACIDS RES, V36, pW197, DOI 10.1093/nar/gkn238; Cuff JA, 2000, PROTEINS, V40, P502, DOI 10.1002/1097-0134(20000815)40:3<502::AID-PROT170>3.0.CO;2-Q; Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475; Dor O, 2007, PROTEINS, V66, P838, DOI 10.1002/prot.21298; Eickholt J, 2012, BIOINFORMATICS, V28, P3066, DOI 10.1093/bioinformatics/bts598; Eickholt J, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-88; Faraggi E, 2012, J COMPUT CHEM, V33, P259, DOI 10.1002/jcc.21968; Floudas CA, 2006, CHEM ENG SCI, V61, P966, DOI 10.1016/j.ces.2005.04.009; Garnier J, 1996, METHOD ENZYMOL, V266, P540; Guo J, 2004, PROTEINS, V54, P738, DOI 10.1002/prot.10634; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; JONES DT, 1992, NATURE, V358, P86, DOI 10.1038/358086a0; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Joosten RP, 2011, NUCLEIC ACIDS RES, V39, pD411, DOI 10.1093/nar/gkq1105; Kallberg M, 2012, NAT PROTOC, V7, P1511, DOI 10.1038/nprot.2012.085; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Kopp J, 2004, PHARMACOGENOMICS, V5, P405, DOI 10.1517/14622416.5.4.405; Lesk AM, 2001, PROTEINS, P98; Lin HN, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-S4-S4; Marsella L, 2009, BIOINFORMATICS, V25, pI289, DOI 10.1093/bioinformatics/btp232; McGuffin LJ, 2000, BIOINFORMATICS, V16, P404, DOI 10.1093/bioinformatics/16.4.404; Meiler J, 2001, J MOL MODEL, V7, P360, DOI 10.1007/s008940100038; Mnih V., 2009, CUDAMAT CUDA BASED M, V4; Moult J., 2012, PROTEINS STRUCT FUNC; Moult J, 2003, PROTEINS, V53, P334, DOI 10.1002/prot.10556; Moult J, 2011, PROTEINS, V79, P1, DOI 10.1002/prot.23200; Petersen TN, 2000, PROTEINS, V41, P17, DOI 10.1002/1097-0134(20001001)41:1<17::AID-PROT40>3.0.CO;2-F; Pollastri G, 2005, BIOINFORMATICS, V21, P1719, DOI 10.1093/bioinformatics/bti203; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Przybylski D, 2004, J MOL BIOL, V341, P255, DOI 10.1016/j.jmb.2004.05.041; Qi YJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032235; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Smolensky P., 1986, INFORM PROCESSING DY, V1; Stork D. G., 1992, P INT JOINT C NEUR N, P289; Walsh I, 2012, BIOINFORMATICS, V28, P503, DOI 10.1093/bioinformatics/btr682; Wang ZY, 2011, PROTEOMICS, V11, P3786, DOI 10.1002/pmic.201100196; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Yao XQ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-49; Zemla A., 1999, PROTEINS, V34, P3; Zhou J., 2014, 31 INT C MACH LEARN	51	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963	1557-9964		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JAN-FEB	2015	12	1					103	112		10.1109/TCBB.2014.2343960		10	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	CB5MN	WOS:000349671700011		
J	Layher, G; Schrodt, F; Butz, MV; Neumann, H				Layher, Georg; Schrodt, Fabian; Butz, Martin V.; Neumann, Heiko			Adaptive learning in a compartmental model of visual cortex-how feedback enables stable category learning and refinement	FRONTIERS IN PSYCHOLOGY			English	Article						neural model; category learning; subcategory learning; unsupervised learning; feedforward and feedback processing	FIGURE-GROUND SEGREGATION; NEURAL-NETWORKS; PATTERN-RECOGNITION; OBJECT RECOGNITION; BIASED COMPETITION; MECHANISMS; ATTENTION; MOTION; V1; FEEDFORWARD	The categorization of real world objects is often reflected in the similarity of their visual appearances. Such categories of objects do not necessarily form disjunct sets of objects, neither semantically nor visually. The relationship between categories can often be described in terms of a hierarchical structure. For instance, tigers and leopards build two separate mammalian categories, both of which are subcategories of the category Felidae. In the last decades, the unsupervised learning of categories of visual input stimuli has been addressed by numerous approaches in machine learning as well as in computational neuroscience. However, the question of what kind of mechanisms might be involved in the process of subcategory learning, or category refinement, remains a topic of active investigation. We propose a recurrent computational network architecture for the unsupervised learning of categorial and subcategorial visual input representations. During learning, the connection strengths of bottom-up weights from input to higher-level category representations are adapted according to the input activity distribution. In a similar manner, top-down weights learn to encode the characteristics of a specific stimulus category. Feedforward and feedback learning in combination realize an associative memory mechanism, enabling the selective top-down propagation of a category's feedback weight distribution. We suggest that the difference between the expected input encoded in the projective field of a category node and the current input pattern controls the amplification of feedforward-driven representations. Large enough differences trigger the recruitment of new representational resources and the establishment of additional (sub-) category representations. We demonstrate the temporal evolution of such learning and show how the proposed combination of an associative memory with a modulatory feedback integration successfully establishes category and subcategory representations.	[Layher, Georg; Neumann, Heiko] Univ Ulm, Inst Neural Informat Proc, D-89069 Ulm, Germany; [Schrodt, Fabian; Butz, Martin V.] Univ Tubingen, Dept Comp Sci, Tubingen, Germany	Neumann, H (reprint author), Univ Ulm, Inst Neural Informat Proc, D-89069 Ulm, Germany.	heiko.neumann@uni-ulm.de					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038; Bayerl P, 2004, NEURAL COMPUT, V16, P2041, DOI 10.1162/0899766041732404; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bi GQ, 2001, ANNU REV NEUROSCI, V24, P139, DOI 10.1146/annurev.neuro.24.1.139; Borenstein E, 2008, IEEE T PATTERN ANAL, V30, P2109, DOI 10.1109/TPAMI.2007.70840; Bouecke JD, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/781561; Brosch T, 2014, NEURAL NETWORKS, V54, P11, DOI 10.1016/j.neunet.2014.02.005; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; Carandini M., 1999, MODELS CORTICAL CIRC, V13, P401, DOI [10.1007/978-1-4615-4903-1_7, DOI 10.1007/978-1-4615-4903-1_7]; CARANDINI M, 1994, SCIENCE, V264, P1333, DOI 10.1126/science.8191289; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; CARPENTER GA, 1990, NEURAL NETWORKS, V3, P129, DOI 10.1016/0893-6080(90)90085-Y; Carpenter G. A., 2003, HDB BRAIN THEORY NEU, P87; CARPENTER GA, 1989, NEURAL NETWORKS, V2, P243, DOI 10.1016/0893-6080(89)90035-X; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Crick F, 1998, NATURE, V391, P245, DOI 10.1038/34584; Dayan P., 2005, THEORETICAL NEUROSCI; De Pasquale R, 2013, J NEUROPHYSIOL, V109, P2618, DOI 10.1152/jn.01083.2012; Desimone R, 1998, PHILOS T ROY SOC B, V353, P1245, DOI 10.1098/rstb.1998.0280; Doya K, 2007, HFSP J, V1, P30, DOI 10.2976/1.2732246/10.2976/1; Eckhorn R., 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293; Eckhorn R, 1999, VIS COGN, V6, P231, DOI 10.1080/135062899394975; EDELMAN GM, 1993, NEURON, V10, P115, DOI 10.1016/0896-6273(93)90304-A; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Gerstner W, 1996, NATURE, V383, P76, DOI 10.1038/383076a0; Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057; GIRARD P, 1989, J NEUROPHYSIOL, V62, P1287; GROSSBERG S, 1988, NEURAL NETWORKS, V1, P17, DOI 10.1016/0893-6080(88)90021-4; Grossberg S., 2013, SCHOLARPEDIA, V8, P1569, DOI [10.4249/scholarpedia.1569, DOI 10.4249/SCHOLARPEDIA.1569]; GROSSBER.S, 1973, STUD APPL MATH, V52, P213; GROSSBERG S, 1980, PSYCHOL REV, V87, P1; Grossberg S, 2013, NEURAL NETWORKS, V37, P1, DOI 10.1016/j.neunet.2012.09.017; GROSSBERG S, 1987, COGNITIVE SCI, V11, P23; Hebb DO, 1949, ORG BEHAV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; JOHANSSO.G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kouh M, 2008, NEURAL COMPUT, V20, P1427, DOI 10.1162/neco.2008.02-07-466; Lamme VAF, 2000, TRENDS NEUROSCI, V23, P571, DOI 10.1016/S0166-2236(00)01657-X; Larkum M, 2013, TRENDS NEUROSCI, V36, P141, DOI 10.1016/j.tins.2012.11.006; Larkum ME, 2004, CEREB CORTEX, V14, P1059, DOI 10.1093/cercor/bhh065; Layher G, 2014, TOP COGN SCI, V6, P170, DOI 10.1111/tops.12075; Lazar A, 2009, FRONT COMPUT NEUROSC, V3, DOI 10.3389/neuro.10.023.2009; LeCun Y., 1990, CHAPTER HANDWRITTEN, P396; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEHKY SR, 1988, NATURE, V333, P452, DOI 10.1038/333452a0; LEHKY SR, 1990, PROC R SOC SER B-BIO, V240, P251, DOI 10.1098/rspb.1990.0037; Lui JH, 2011, CELL, V146, P18, DOI 10.1016/j.cell.2011.06.030; Markov NT, 2013, CURR OPIN NEUROBIOL, V23, P187, DOI 10.1016/j.conb.2012.12.008; Markov NT, 2014, J COMP NEUROL, V522, P225, DOI 10.1002/cne.23458; Raijmakers MEJ, 1997, NEURAL NETWORKS, V10, P649, DOI 10.1016/S0893-6080(96)00111-6; Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Neumann H, 2007, PHYS LIFE REV, V4, P189, DOI 10.1016/j.plrev.2007.09.001; Brosch T, 2014, NEURAL COMPUT, V26, P2735, DOI 10.1162/NECO_a_00675; Neumann H, 1999, BIOL CYBERN, V81, P425, DOI 10.1007/s004220050573; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9; Poort J, 2012, NEURON, V75, P143, DOI 10.1016/j.neuron.2012.04.032; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Raudies F, 2011, NEURAL COMPUT, V23, P2868, DOI 10.1162/NECO_a_00193; Rauss K, 2011, NEUROSCI BIOBEHAV R, V35, P1237, DOI 10.1016/j.neubiorev.2010.12.011; Reynolds JH, 2000, NEURON, V26, P703, DOI 10.1016/j.neuron.2009.01.002; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Roelfsema PR, 2006, ANNU REV NEUROSCI, V29, P203, DOI 10.1146/annurev.neuro.29.051605.112939; Roelfsema PR, 2007, NEURON, V56, P785, DOI 10.1016/j.neuron.2007.10.006; Roelfsema PR, 2005, NEURAL COMPUT, V17, P2176, DOI 10.1162/0899766054615699; Roelfsema PR, 2002, J COGNITIVE NEUROSCI, V14, P525, DOI 10.1162/08989290260045756; Rolfe J. T., 2013, ARXIV13013775; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; Self MW, 2012, P NATL ACAD SCI USA, V109, P11031, DOI 10.1073/pnas.1119527109; Self MW, 2013, CURR BIOL, V23, P2121, DOI 10.1016/j.cub.2013.09.013; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Serre T, 2010, COMMUN ACM, V53, P54, DOI 10.1145/1831407.1831425; Sherman SM, 1998, P NATL ACAD SCI USA, V95, P7121, DOI 10.1073/pnas.95.12.7121; Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008; Spratling MW, 2014, J COMPUT NEUROSCI, V36, P97, DOI 10.1007/s10827-013-0471-7; SUTTON RS, 1981, PSYCHOL REV, V88, P135, DOI 10.1037/0033-295X.88.2.135; Tetzlaff C, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00036; Tsotsos John K., 2005, P3, DOI 10.1016/B978-012375731-9/50005-7; Tsotsos J. K., 1988, COMPUTATIONAL PROCES, P286; ULLMAN S, 1995, CEREB CORTEX, V5, P1, DOI 10.1093/cercor/5.1.1; Ullman S, 2007, TRENDS COGN SCI, V11, P58, DOI 10.1016/j.tics.2006.11.009; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; von der Malsburg C, 1973, Kybernetik, V14, P85	90	1	1	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	DEC 5	2014	5								1287	10.3389/fpsyg.2014.01287		19	Psychology, Multidisciplinary	Psychology	AX2TN	WOS:000346797500001	25538637	
J	Bhattacharya, S; Nurmi, P; Hammerla, N; Poltz, T				Bhattacharya, Sourav; Nurmi, Petteri; Hammerla, Nils; Poeltz, Thomas			Using unlabeled data in a sparse-coding framework for human activity recognition	PERVASIVE AND MOBILE COMPUTING			English	Article						Activity recognition; Sparse-coding; Machine learning; Unsupervised learning	CLASSIFICATION; TRACKING	We propose a sparse-coding framework for activity recognition in ubiquitous and mobile computing that alleviates two fundamental problems of current supervised learning approaches. (i) It automatically derives a compact, sparse and meaningful feature representation of sensor data that does not rely on prior expert knowledge and generalizes well across domain boundaries. (ii) It exploits unlabeled sample data for bootstrapping effective activity recognizers, i.e., substantially reduces the amount of ground truth annotation required for model estimation. Such unlabeled data is easy to obtain, e. g., through contemporary smartphones carried by users as they go about their everyday activities. Based on the self-taught learning paradigm we automatically derive an over-complete set of basis vectors from unlabeled data that captures inherent patterns present within activity data. Through projecting raw sensor data onto the feature space defined by such over-complete sets of basis vectors effective feature extraction is pursued. Given these learned feature representations, classification backends are then trained using small amounts of labeled training data. We study the new approach in detail using two datasets which differ in terms of the recognition tasks and sensor modalities. Primarily we focus on a transportation mode analysis task, a popular task in mobile-phone based sensing. The sparse-coding framework demonstrates better performance than the state-of-the-art in supervised learning approaches. More importantly, we show the practical potential of the new approach by successfully evaluating its generalization capabilities across both domain and sensor modalities by considering the popular Opportunity dataset. Our feature learning approach outperforms state-of-the-art approaches to analyzing activities of daily living. (C) 2014 Elsevier B.V. All rights reserved.	[Bhattacharya, Sourav; Nurmi, Petteri] Univ Helsinki, Dept Comp Sci, HIIT, FIN-00014 Helsinki, Finland; [Hammerla, Nils; Poeltz, Thomas] Newcastle Univ, Sch Comp Sci, Culture Lab, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England	Bhattacharya, S (reprint author), Univ Helsinki, Dept Comp Sci, HIIT, FIN-00014 Helsinki, Finland.	sourav.bhattacharya@cs.helsinki.fi			Future Internet Graduate School (FIGS); Foundation of Nokia Corporation; RCUK Research Hub on Social Inclusion through the Digital Economy (SiDE) [EP/G066019/1]; EPSRC [EP/K004689/1]	S. Bhattacharya received funding from Future Internet Graduate School (FIGS) and the Foundation of Nokia Corporation. Parts of this work have been funded by the RCUK Research Hub on Social Inclusion through the Digital Economy (SiDE; EP/G066019/1), and by a grant from the EPSRC (EP/K004689/1).	Alemar H., 2011, P INT JOINT C AMB IN; Amar R.A., 2001, P INT C MACH LEARN I; Amft O., 2011, P INT S WEAR COMP IS; Atallah L, 2009, PERVASIVE MOB COMPUT, V5, P447, DOI 10.1016/j.pmcj.2009.06.009; Bao L., 2004, P INT C PERV COMP PE; Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25, DOI 10.1007/3-540-28349-8_2; Bhattacharya S., 2014, IEEE T MOBILE COMPUT, VPP, P1; Bishop C. M., 2007, PATTERN RECOGNITION; Brezmes T., 2009, WORKSH P 10 INT WORK; Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chapelle O., 2010, SEMISUPERVISED LEARN; Coates A., 2011, P INT C ART INT STAT; Consolvo S., 2008, P ACM SIGCHI C HUM F; Figo D, 2010, PERS UBIQUIT COMPUT, V14, P645, DOI 10.1007/s00779-010-0293-9; Frank J., 2010, P AAAI C ART INT AAA; Grosse R., 2007, P INT C UNC ART INT; Guan D., 2007, P IEEE INT C EMB REA; Hammerla N., 2013, P INT S WEAR COMP IS; Hemminki S., 2013, EMBEDDED NETWORKED S; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoey J, 2011, PERVASIVE MOB COMPUT, V7, P299, DOI 10.1016/j.pmcj.2010.11.007; Hoyer P.O., 2002, P IEEE WORKSH NEUR N; Hu DH, 2011, PERVASIVE MOB COMPUT, V7, P344, DOI 10.1016/j.pmcj.2010.11.005; Huynh T., 2005, P JOINT C SMART OBJ; Huynh T., 2008, P 10 INT C UB COMP, P10, DOI DOI 10.1145/1409635.1409638.URL; Joliffe I. T., 1986, PRINCIPAL COMPONENT; Kjaergaard M.B., 2011, 9 INT C MOB SYST APP, P307; Kononen V, 2010, PERVASIVE MOB COMPUT, V6, P181, DOI 10.1016/j.pmcj.2009.07.001; Lane N. D., 2011, P 13 INT C UB COMP U, P355; Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598; Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742; Lee H., 2007, P INT C NEUR INF P S; Lester J., 2006, P INT C PERV COMP PE; Liao L., 2007, ARTIFICIAL INTELLIGE, V171; Logan B., 2007, P ACM C UB COMP UBIC; Lu Hong, 2010, P 8 ACM C EMB NETW S, P71; Lukowicz P., 2010, ARCS WORKSH, P161; Mantyjarvi J., 2001, P IEEE INT C SYST MA, V2, P747; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Minnen D., 2006, P INT S WEAR COMP IS; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Parkka J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863; Pham C., 2009, P INT C AMB INT AML; Plotz T, 2011, ATL AMB PERVAS INTEL, V4, P313; Plotz T., 2011, P INT JOINT C ART IN; Ploz Thomas, 2012, P 2012 ACM C UB COMP, P391, DOI DOI 10.1145/2370216.2370276; Rabbi M., 2011, P ACM C UB COMP UBIC; Raina R., 2007, P INT C MACH LEARN I; Reddy S, 2010, ACM T SENSOR NETWORK, V6, DOI 10.1145/1689239.1689243; Roggen D., 2010, NETW SENS SYST INSS, P233; Sagha Hesam, 2011, IEEE INT C SYST MAN; Soper D, 2012, COMMUN ACM, V55, P35, DOI 10.1145/2133806.2133819; Stiefmeier T, 2008, IEEE PERVAS COMPUT, V7, P42, DOI 10.1109/MPRV.2008.40; Stikic M., 2009, P INT S LOC CONT AW; Stikic M., 2008, P INT S WEAR COMP IS; Stikic M, 2011, IEEE T PATTERN ANAL, V33, P2521, DOI 10.1109/TPAMI.2011.36; Tan P.-N., 2005, INTRO DATA MINING; van Kasteren T.L.M., 2010, P INT C PERV COMP PE; Wang S., P AS PAC C WEAR COMP; Zheng Y., 2011, P ACM C UB COMP UBIC	62	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1574-1192	1873-1589		PERVASIVE MOB COMPUT	Pervasive Mob. Comput.	DEC	2014	15				SI		242	262		10.1016/j.pmcj.2014.05.006		21	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	AU3OT	WOS:000345523900017		
J	Hung, C; Xu, Z; Sukkarieh, S				Hung, Calvin; Xu, Zhe; Sukkarieh, Salah			Feature Learning Based Approach for Weed Classification Using High Resolution Aerial Images from a Digital Camera Mounted on a UAV	REMOTE SENSING			English	Article						weed classification; UAV remote sensing; serrated tussock; tropical soda apple; water hyacinth	VEGETATION; TEXTURE; FOREST	The development of low-cost unmanned aerial vehicles (UAVs) and light weight imaging sensors has resulted in significant interest in their use for remote sensing applications. While significant attention has been paid to the collection, calibration, registration and mosaicking of data collected from small UAVs, the interpretation of these data into semantically meaningful information can still be a laborious task. A standard data collection and classification work-flow requires significant manual effort for segment size tuning, feature selection and rule-based classifier design. In this paper, we propose an alternative learning-based approach using feature learning to minimise the manual effort required. We apply this system to the classification of invasive weed species. Small UAVs are suited to this application, as they can collect data at high spatial resolutions, which is essential for the classification of small or localised weed outbreaks. In this paper, we apply feature learning to generate a bank of image filters that allows for the extraction of features that discriminate between the weeds of interest and background objects. These features are pooled to summarise the image statistics and form the input to a texton-based linear classifier that classifies an image patch as weed or background. We evaluated our approach to weed classification on three weeds of significance in Australia: water hyacinth, tropical soda apple and serrated tussock. Our results showed that collecting images at 5-10 m resulted in the highest classifier accuracy, indicated by F1 scores of up to 94%.	[Hung, Calvin; Xu, Zhe; Sukkarieh, Salah] Univ Sydney, Australian Ctr Field Robot, Sydney, NSW 2006, Australia	Hung, C (reprint author), Univ Sydney, Australian Ctr Field Robot, Rose St Bldg J04, Sydney, NSW 2006, Australia.	c.hung@acfr.usyd.edu.au; z.xu@acfr.usyd.edu.au; salah@acfr.usyd.edu.au			Australian Centre for Field Robotics at the University of Sydney; Northern Inlands Weed Advisory Committee (NIWAC) through the "Integrated Aerial Surveillance, Thermal Imaging and Mapping" pilot program	This work is supported in part by the Australian Centre for Field Robotics at the University of Sydney and the Northern Inlands Weed Advisory Committee (NIWAC) through the "Integrated Aerial Surveillance, Thermal Imaging and Mapping" pilot program funded under the NSW Weeds Action Program.	Ayres L., SERRATED TUSSOCK IDE; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bo L., 2013, EXPT ROBOTICS, P387; Boureau Y.-L., 2010, P 27 INT C MACH LEAR, P111; Bryson M, 2010, J FIELD ROBOT, V27, P632, DOI 10.1002/rob.20343; Burton J., WATER HYACINTH EICHH; Caltabiano D., 2005, J NAME, V1, P739; Carleer AP, 2005, PHOTOGRAMM ENG REM S, V71, P1285; Casbeer DW, 2006, INT J SYST SCI, V37, P351, DOI 10.1080/00207720500438480; Coates A., 2011, P 2011 INT C MACH LE; Csurhes S, RISK WEED ASSESSMENT; Davis S., 1978, REMOTE SENSING QUANT, V1, P405; Eisenbeiss H., 2006, INT ARCH PHOTOGRAMME, V36, P90; Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3; Goodfellow I., 2009, ADV NEURAL INFORM PR, V22, P646; Grenzdorffer G., 2008, INT ARCH PHOTOGRAM R, V31, P1207; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUETE A, 1994, REMOTE SENS ENVIRON, V49, P224, DOI 10.1016/0034-4257(94)90018-3; Hung C, 2012, ISPRS J PHOTOGRAMM, V68, P170, DOI 10.1016/j.isprsjprs.2012.01.009; Kim M, 2011, INT J REMOTE SENS, V32, P2825, DOI 10.1080/01431161003745608; Krizhevsky A., 2009, TECHNICAL REPORT; Laliberte AS, 2011, GISCI REMOTE SENS, V48, P4, DOI 10.2747/1548-1603.48.1.4; Laliberte AS, 2010, PHOTOGRAMM ENG REM S, V76, P661; Lambers K, 2007, J ARCHAEOL SCI, V34, P1702, DOI 10.1016/j.jas.2006.12.008; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Marc Aurelio Ranzato C., 2006, ADV NEURAL INFORM PR, V19, P1137; Nilsback M.-E., 2006, P IEEE C COMP VIS PA, V2, P1447; Ouma YO, 2008, INT J REMOTE SENS, V29, P3417, DOI 10.1080/01431160701601782; Pena JM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077151; Reis S, 2011, ISPRS J PHOTOGRAMM, V66, P652, DOI 10.1016/j.isprsjprs.2011.04.006; Sauerbier M, 2010, INT ARCH PHOTOGRAMM, V38, P526; Serre T, 2005, PROC CVPR IEEE, P994; Spiess T, 2007, METEOROL Z, V16, P159, DOI 10.1127/0941-2948/2007/0195; TUCKER CJ, 1979, REMOTE SENS ENVIRON, V8, P127, DOI 10.1016/0034-4257(79)90013-0; Turner D, 2014, REMOTE SENS-BASEL, V6, P4003, DOI 10.3390/rs6054003; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Yang J., 2010, COMPUT VIS 2010, V5, P113; Zhang NQ, 2002, COMPUT ELECTRON AGR, V36, P113, DOI 10.1016/S0168-1699(02)00096-0	39	1	1	MDPI AG	BASEL	POSTFACH, CH-4005 BASEL, SWITZERLAND	2072-4292			REMOTE SENS-BASEL	Remote Sens.	DEC	2014	6	12					12037	12054		10.3390/rs61212037		18	Remote Sensing	Remote Sensing	AX2ST	WOS:000346795300017		
J	Subelj, L; Zitnik, S; Blagus, N; Bajec, M				Subelj, Lovro; Zitnik, Slavko; Blagus, Neli; Bajec, Marko			NODE MIXING AND GROUP STRUCTURE OF COMPLEX SOFTWARE NETWORKS	ADVANCES IN COMPLEX SYSTEMS			English	Article						Software networks; node mixing; node groups; software engineering	COMMUNITY STRUCTURE; FRACTAL DIMENSION; WORLD NETWORKS; DESIGN; MODULARITY; EVOLUTION; DYNAMICS; SYSTEMS	Large software projects are among most sophisticated human-made systems consisting of a network of interdependent parts. Past studies of software systems from the perspective of complex networks have already led to notable discoveries with different applications. Nevertheless, our comprehension of the structure of software networks remains to be only partial. Here we investigate correlations or mixing between linked nodes and show that software networks reveal dichotomous node degree mixing similar to that recently observed in biological networks. We further show that software networks also reveal characteristic clustering profiles and mixing. Hence, node mixing in software networks significantly differs from that in, e.g., the Internet or social networks. We explain the observed mixing through the presence of groups of nodes with common linking pattern. More precisely, besides densely linked groups known as communities, software networks also consist of disconnected groups denoted modules, core/periphery structures and other. Moreover, groups coincide with the intrinsic properties of the underlying software projects, which promotes practical applications in software engineering.	[Subelj, Lovro; Zitnik, Slavko; Blagus, Neli; Bajec, Marko] Univ Ljubljana, Fac Comp & Informat Sci, SI-1000 Ljubljana, Slovenia	Subelj, L (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, SI-1000 Ljubljana, Slovenia.	lovro.subelj@fri.uni-lj.si; slavko.zitnik@fri.uni-lj.si; neli.blagus@fri.uni-lj.si; marko.bajec@fri.uni-lj.si			Slovenian Research Agency Program [P2-0359]; Slovenian Ministry of Education, Science and Sport [430-168/2013/91]; European Union, European Social Fund	This work has been supported in part by the Slovenian Research Agency Program No. P2-0359, by the Slovenian Ministry of Education, Science and Sport Grant No. 430-168/2013/91, and by the European Union, European Social Fund.	Baeza-Yates R., 1999, MODERN INFORM RETREI; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Baxter G, 2006, ACM SIGPLAN NOTICES, V41, P397, DOI 10.1145/1167515.1167507; Blagus N, 2012, PHYSICA A, V391, P2794, DOI 10.1016/j.physa.2011.12.055; Cai KY, 2009, INFORM SCIENCES, V179, P1903, DOI 10.1016/j.ins.2009.01.011; CHIDAMBER SR, 1994, IEEE T SOFTWARE ENG, V20, P476, DOI 10.1109/32.295895; Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111; Concas G, 2007, IEEE T SOFTWARE ENG, V33, P687, DOI 10.1109/TSE.2007.1016; Concas G, 2006, EUROPHYS LETT, V76, P1221, DOI 10.1209/epl/i2006-10384-1; Danon L, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/09/P09008; Erdos P., 1959, PUBL MATH-DEBRECEN, V6, P290; Fortuna MA, 2011, P NATL ACAD SCI USA, V108, P19985, DOI 10.1073/pnas.1115960108; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Foster JG, 2010, P NATL ACAD SCI USA, V107, P10815, DOI 10.1073/pnas.0912671107; Gao Y., 2010, P IEEE INT C PROGR I, P1000; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; Glover F., 1989, ORSA Journal on Computing, V1; Han JDJ, 2004, NATURE, V430, P88, DOI 10.1038/nature02555; Hao DP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028322; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyland-Wood D., 2006, P 16 AAS AIAA SPAC F, P1; Jaccard P., 1901, B SOC VAUD SCI NAT, V37, P547; Kohring GA, 2009, ADV COMPLEX SYST, V12, P565, DOI 10.1142/S0219525909002362; LaBelle N., 2006, P INT C COMPL SYST B, P1; Lancichinetti A, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011976; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI DOI 10.1145/1081870.1081893; Li H, 2013, PHYSICA A, V392, P2025, DOI 10.1016/j.physa.2013.01.035; Lorrain F., 1971, J MATH SOCIOL, V1, P49, DOI [DOI 10.1080/0022250X.1971.9989788), 10.1080/0022250X.1971.9989788]; Maslov S, 2002, SCIENCE, V296, P910, DOI 10.1126/science.1065103; Myers CR, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.046116; Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701; Newman MEJ, 2007, P NATL ACAD SCI USA, V104, P9564, DOI 10.1073/pnas.0610537104; Newman MEJ, 2012, NAT PHYS, V8, P25, DOI 10.1038/nphys2162; Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104; Newman MEJ, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.036122; Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607; Pastor-Satorras R, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.258701; Pinkert S, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000659; Porter M. A., 2009, NOT AM MATH SOC, V56, P1082, DOI DOI 10.1063/1.3194108; Ravasz E, 2002, SCIENCE, V297, P1551, DOI 10.1126/science.1073374; Schaeffer SE, 2007, COMPUTER SCI REV, V1, P27, DOI DOI 10.1016/J.C0SREV.2007.05.001; Soffer SN, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.057101; Sole R. V., 2003, J COMPLEXITY, V8, P20; Stevens WP, 1999, IBM SYST J, V38, P231; Subelj L., 2012, P KDD WORKSH SOFTW M, P9; Subelj L., 2013, P INT C NETW SCI COP, P152; Subelj L, 2012, EUR PHYS J B, V85, DOI 10.1140/epjb/e2011-20448-7; Subelj L, 2011, PHYSICA A, V390, P2968, DOI 10.1016/j.physa.2011.03.036; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Turnu I, 2013, INFORM SCIENCES, V245, P290, DOI 10.1016/j.ins.2013.05.014; Valverde S, 2005, EUROPHYS LETT, V72, P858, DOI 10.1209/epl/i2005-10314-9; VALVERDE S, 2007, DYNAM CONT DIS SE S6, V14, P1; Valverde S, 2002, EUROPHYS LETT, V60, P512, DOI 10.1209/epl/i2002-00248-2; Valverde S, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026107; Vazquez A., 2002, PHYS REV E 2, V65, DOI DOI 10.1103/PHYSREVE.65.066130; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; WHITE HC, 1976, AM J SOCIOL, V81, P730, DOI 10.1086/226141; Zhao YP, 2011, P NATL ACAD SCI USA, V108, P7321, DOI 10.1073/pnas.1006642108	58	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-5259	1793-6802		ADV COMPLEX SYST	Adv. Complex Syst.	DEC	2014	17	7-8							1450022	10.1142/S0219525914500222		26	Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences	Mathematics; Science & Technology - Other Topics	CI5RB	WOS:000354815400007		
J	Xue, SF; Abdel-Hamid, O; Jiang, H; Dai, LR; Liu, QF				Xue, Shaofei; Abdel-Hamid, Ossama; Jiang, Hui; Dai, Lirong; Liu, Qingfeng			Fast Adaptation of Deep Neural Network Based on Discriminant Codes for Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Condition code; cross entropy (CE); deep neural network (DNN); fast adaptation; maximum mutual information (MMI); speaker code	HIDDEN MARKOV-MODELS; SPEAKER ADAPTATION; NORMALIZATION; FEATURES	Fast adaptation of deep neural networks (DNN) is an important research topic in deep learning. In this paper, we have proposed a general adaptation scheme for DNN based on discriminant condition codes, which are directly fed to various layers of a pre-trained DNN through a new set of connection weights. Moreover, we present several training methods to learn connection weights from training data as well as the corresponding adaptation methods to learn new condition code from adaptation data for each new test condition. In this work, the fast adaptation scheme is applied to supervised speaker adaptation in speech recognition based on either frame-level cross-entropy or sequence-level maximum mutual information training criterion. We have proposed three different ways to apply this adaptation scheme based on the so-called speaker codes: i) Nonlinear feature normalization in feature space; ii) Direct model adaptation of DNN based on speaker codes; iii) Joint speaker adaptive training with speaker codes. We have evaluated the proposed adaptation methods in two standard speech recognition tasks, namely TIMIT phone recognition and large vocabulary speech recognition in the Switchboard task. Experimental results have shown that all three methods are quite effective to adapt large DNN models using only a small amount of adaptation data. For example, the Switchboard results have shown that the proposed speaker-code-based adaptation methods may achieve up to 8-10% relative error reduction using only a few dozens of adaptation utterances per speaker. Finally, we have achieved very good performance in Switchboard (12.1% in WER) after speaker adaptation using sequence training criterion, which is very close to the best performance reported in this task ("Deep convolutional neural networks for LVCSR," T. N. Sainath et al., Proc. IEEE Acoust., Speech, Signal Process., 2013).	[Xue, Shaofei; Dai, Lirong; Liu, Qingfeng] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China; [Abdel-Hamid, Ossama; Jiang, Hui] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada	Xue, SF (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China.	xuesf@mail.ustc.edu.cn; ossama@cse.yorku.ca; hj@cse.yorku.ca; lrdai@ustc.edu.cn; qliu@iflytek.com			National Nature Science Foundation of China [61273264]; National 973 program of China [2012CB326405]; Natural Sciences and Engineering Research Council of Canada (NSERC)	This work was supported in part by the National Nature Science Foundation of China under Grant No. 61273264 and the National 973 program of China under Grant 2012CB326405, as well as a discovery grant from Natural Sciences and Engineering Research Council of Canada (NSERC). The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Dong Yu.	Abdel-Hamid O, 2013, INT CONF ACOUST SPEE, P7942, DOI 10.1109/ICASSP.2013.6639211; Abdel-Hamid O., 2013, P INTERSPEECH; Anastasakos T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1137; Anastasakos T, 1997, INT CONF ACOUST SPEE, P1043, DOI 10.1109/ICASSP.1997.596119; Bao YB, 2012, INT CONF SIGN PROCES, P562; Bao YB, 2013, INT CONF ACOUST SPEE, P6980; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bridle J. S., 1991, ADV NEURAL INFORMATI, V3, P234; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; DIGALAKIS VV, 1995, IEEE T SPEECH AUDI P, V3, P357, DOI 10.1109/89.466659; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gemello R, 2007, SPEECH COMMUN, V49, P827, DOI 10.1016/j.specom.2006.11.005; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Jiang H, 2002, IEEE T SPEECH AUDI P, V10, P9; Jiang H., 2001, P ISCA INT WORKSH HA; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Lee L, 1996, INT CONF ACOUST SPEE, P353; LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010; Li B., 2010, P INTERSPEECH; Liao H, 2013, INT CONF ACOUST SPEE, P7947; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Neto J., 1995, P EUR; Pan J., 2012, P INT S CHIN SPOK LA; Sainath T.N., 2011, P ASRU, P30; Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347; Saon G, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P55, DOI 10.1109/ASRU.2013.6707705; Seide F., 2011, P ASRU, P24; Seide F., 2011, P INTERSPEECH, P437; Siniscalchi SM, 2013, IEEE T AUDIO SPEECH, V21, P2152, DOI 10.1109/TASL.2013.2270370; Stadermann J, 2005, INT CONF ACOUST SPEE, P977; Su H, 2013, INT CONF ACOUST SPEE, P6664; TUSKEA Z, 2013, P IEEE INT C AC SPEE, P6970; Xue S., 2014, P IEEE INT C AC SPEE, P6369; Yao KS, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P366; Yu D, 2013, INT CONF ACOUST SPEE, P7893; Zhang S., 2014, P IEEE INT C AC SPEE, P6849; Zhou P., 2013, IEEE T ACOUST UNPUB; Zhou P., 2014, P IEEE INT C AC SPEE, P5627	40	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	DEC	2014	22	12					1713	1725		10.1109/TASLP.2014.2346313		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AO8TJ	WOS:000341627500003		
J	Chrol-Cannon, J; Jin, YC				Chrol-Cannon, Joseph; Jin, Yaochu			Computational modeling of neural plasticity for self-organization of neural networks	BIOSYSTEMS			English	Review						Neural plasticity; Neural networks; Gene regulatory networks; Learning; Neural self-organization	TIMING-DEPENDENT PLASTICITY; GENE REGULATORY NETWORKS; SYNAPTIC PLASTICITY; INTRINSIC PLASTICITY; BINOCULAR INTERACTION; NEURONAL NETWORKS; NERVOUS-SYSTEM; VISUAL-CORTEX; ADULT MONKEYS; POLYCHRONIZATION	Self-organization in biological nervous systems during the lifetime is known to largely occur through a process of plasticity that is dependent upon the spike-timing activity in connected neurons. In the field of computational neuroscience, much effort has been dedicated to building up computational models of neural plasticity to replicate experimental data. Most recently, increasing attention has been paid to understanding the role of neural plasticity in functional and structural neural self-organization, as well as its influence on the learning performance of neural networks for accomplishing machine learning tasks such as classification and regression. Although many ideas and hypothesis have been suggested, the relationship between the structure, dynamics and learning performance of neural networks remains elusive. The purpose of this article is to review the most important computational models for neural plasticity and discuss various ideas about neural plasticity's role. Finally, we suggest a few promising research directions, in particular those along the line that combines findings in computational neuroscience and systems biology, and their synergetic roles in understanding learning, memory and cognition, thereby bridging the gap between computational neuroscience, systems biology and computational intelligence. (C) 2014 Elsevier Ireland Ltd. All rights reserved.	[Chrol-Cannon, Joseph; Jin, Yaochu] Univ Surrey, Dept Comp, Guildford GU2 7XH, Surrey, England	Jin, YC (reprint author), Univ Surrey, Dept Comp, Guildford GU2 7XH, Surrey, England.	yaochu.jin@surrey.ac.uk					Abraham WC, 1996, TRENDS NEUROSCI, V19, P126, DOI 10.1016/S0166-2236(96)80018-X; AMARI SI, 1983, IEEE T SYST MAN CYB, V13, P741; Babinec S, 2007, LECT NOTES COMPUT SC, V4668, P19; BARLOW H, 1989, COMP NEUR S, P54; Bell CC, 1997, NATURE, V387, P278, DOI 10.1038/387278a0; Benuskova L, 2006, INT J NEURAL SYST, V16, P215, DOI 10.1142/S0129065706000627; Benuskova L, 2008, COGN NEURODYNAMICS, V2, P319, DOI 10.1007/s11571-008-9061-1; Bi GQ, 1998, J NEUROSCI, V18, P10464; BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32; Bohte SM, 2007, NEURAL COMPUT, V19, P371, DOI 10.1162/neco.2007.19.2.371; Brown JT, 2009, J PHYSIOL-LONDON, V587, P1265, DOI 10.1113/jphysiol.2008.167007; Bush D., 2014, BMC NEUROSCI S1, V12, pP161; Bush D, 2012, J COMPUT NEUROSCI, V33, P495, DOI 10.1007/s10827-012-0397-5; Chapelle O., 2006, SEMISUPERVISED LEARN; Chrol-Cannon J., 2012, IJCNN, P1; Citri A, 2008, NEUROPSYCHOPHARMACOL, V33, P18, DOI 10.1038/sj.npp.1301559; Clopath C, 2010, NAT NEUROSCI, V13, P344, DOI 10.1038/nn.2479; Cortes-Mendoza J, 2013, INT J DEV NEUROSCI, V31, P359, DOI 10.1016/j.ijdevneu.2013.04.003; DAMMASCH IE, 1986, BIOL CYBERN, V54, P211, DOI 10.1007/BF00318417; DAMMASCH IE, 1988, BIOL CYBERN, V58, P149, DOI 10.1007/BF00364134; Debanne D., 2014, FRONT SYNAP NEUROSCI, V2; ERDI P, 1984, BIOL CYBERN, V51, P93, DOI 10.1007/BF00357922; Feldman DE, 2000, NEURON, V27, P45, DOI 10.1016/S0896-6273(00)00008-8; Flavell SW, 2008, ANNU REV NEUROSCI, V31, P563, DOI 10.1146/annurev.neuro.31.060407.125631; Geard N, 2009, BIRTH DEFECTS RES C, V87, P131, DOI 10.1002/bdrc.20150; Ghysen A, 2003, INT J DEV BIOL, V47, P555; Gilson M, 2009, BIOL CYBERN, V101, P103, DOI 10.1007/s00422-009-0320-y; Gilson M, 2009, BIOL CYBERN, V101, P411, DOI 10.1007/s00422-009-0343-4; Gilson M, 2009, BIOL CYBERN, V101, P427, DOI 10.1007/s00422-009-0346-1; Gilson M, 2009, BIOL CYBERN, V101, P81, DOI [10.1007/s00422-009-0319-4, 10.1007/S00422-009-0319-4]; Gilson M., 2014, FRONT COMPUT NEUROSC, V4; Graupner M., 2013, BMC NEUROSCI, V14, P1; Graupner M, 2012, P NATL ACAD SCI USA, V109, P3991, DOI 10.1073/pnas.1109359109; Hasty J, 2001, NAT REV GENET, V2, P268, DOI 10.1038/35066056; Hebb DO, 1949, ORG BEHAV; Hennequin G., 2014, FRONT COMPUT NEUROSC, V4; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holtmaat A, 2009, NAT REV NEUROSCI, V10, P647, DOI 10.1038/nrn2699; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Izhikevich E., 2007, BMC NEUROSCI S2, V8, P1; Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882; Jaeger H, 2005, IJCNN 05 P, V3, P1460; Jaeger H., 2001, 148 GMD FORSCH INF; Jin YC, 2009, LECT NOTES COMPUT SC, V5506, P48; Jones B, 2010, LECT NOTES ARTIF INT, V6226, P587, DOI 10.1007/978-3-642-15193-4_55; Jones B., 2008, ARTIF LIFE, P305; Joshi P, 2009, LECT NOTES COMPUT SC, V5768, P239; Kitano H., 1995, ARTIF LIFE, V2, P79; Knoblauch A., 2011, BMC NEUROSCI, V12, P1; Kudo M, 1999, PATTERN RECOGN LETT, V20, P1103, DOI 10.1016/S0167-8655(99)00077-X; Lazar A, 2007, NEURAL NETWORKS, V20, P312, DOI 10.1016/j.neunet.2007.04.020; Le Novere N., 2007, BMC SYST BIOL, V1, P1; Legenstein R.A., 2014, PLOS COMPUT BIOL, V4; Li Y., 2014, PLOS ONE, V8; Lisman John, 2010, Front Synaptic Neurosci, V2, P140, DOI 10.3389/fnsyn.2010.00140; Lisman J, 2005, NAT NEUROSCI, V8, P839, DOI 10.1038/nn0705-839; Lukosevicius Mantas, 2012, KI-Kunstliche Intelligenz, V26, DOI 10.1007/s13218-012-0204-5; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; MALSBURG CV, 1973, KYBERNETIK, V14, P85, DOI 10.1007/BF00288907; Markram H., 2014, FRONT SYNAP NEUROSCI, V4; Meng Y, 2011, IEEE T NEURAL NETWOR, V22, P1952, DOI 10.1109/TNN.2011.2171044; MERZENICH MM, 1984, J COMP NEUROL, V224, P591, DOI 10.1002/cne.902240408; MERZENICH MM, 1983, NEUROSCIENCE, V8, P33, DOI 10.1016/0306-4522(83)90024-6; Norton D, 2006, IEEE IJCNN, P4243; Nowotny T, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.011908; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Paugam-Moisy H, 2008, NEUROCOMPUTING, V71, P1143, DOI 10.1016/j.neucom.2007.12.027; Schramm L, 2012, ARTIF LIFE, V18, P425, DOI [10.1162/ARTL_a_00075, 10.1162/artl_a_00075]; Schrauwen B, 2008, NEUROCOMPUTING, V71, P1159, DOI 10.1016/j.neucom.2007.12.020; Shepherd JD, 2006, NEURON, V52, P475, DOI 10.1016/j.neuron.2006.08.034; Shouval H.Z., 2010, FRONT COMPUT NEUROSC, V1, P19; Song S, 2000, NAT NEUROSCI, V3, P919; Steil JJ, 2007, NEURAL NETWORKS, V20, P353, DOI 10.1016/j.neunet.2007.04.011; Toyoizumi T, 2005, P NATL ACAD SCI USA, V102, P5239, DOI 10.1073/pnas.0500495102; Toyoizumi T, 2007, NEURAL COMPUT, V19, P639, DOI 10.1162/neco.2007.19.3.639; VanOoyen A, 2003, DEV COGN NEUROSCI, P1; van Ooyen A, 2011, NAT REV NEUROSCI, V12, P311, DOI 10.1038/nrn3031; van Rossum MCW, 2001, NEUROCOMPUTING, V38, P409, DOI 10.1016/S0925-2312(01)00360-5; Waddington A., 2014, FRONT COMPUT NEUROSC, V6; WILLSHAW DJ, 1976, PROC R SOC SER B-BIO, V194, P431, DOI 10.1098/rspb.1976.0087; WILLSHAW DJ, 1979, PHILOS T ROY SOC B, V287, P203, DOI 10.1098/rstb.1979.0056; Wittenberg GM, 2006, J NEUROSCI, V26, P6610, DOI 10.1523/JNEUROSCI.5388-05.2006; Xue FZ, 2013, NEUROCOMPUTING, V122, P324, DOI 10.1016/j.neucom.2013.06.019; Yin J, 2012, IEEE T AUTON MENT DE, V4, P273, DOI 10.1109/TAMD.2012.2182765; Zhang LI, 1998, NATURE, V395, P37	87	1	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0303-2647	1872-8324		BIOSYSTEMS	Biosystems	NOV	2014	125						43	54		10.1016/j.biosystems.2014.04.003		12	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	AT8KX	WOS:000345183300005	24769242	
J	Suk, HI; Lee, SW; Shen, DG				Suk, Heung-Il; Lee, Seong-Whan; Shen, Dinggang		Alzheimer's Dis Neuroimaging Initi	Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis	NEUROIMAGE			English	Article						Alzheimer's Disease; Mild Cognitive Impairment; Multimodal data fusion; Deep Boltzmann Machine; Shared feature representation	MILD COGNITIVE IMPAIRMENT; VOXEL-BASED MORPHOMETRY; TEMPORAL-LOBE ATROPHY; ALZHEIMERS-DISEASE; FUNCTIONAL CONNECTIVITY; BOLTZMANN MACHINES; NEURAL-NETWORKS; MRI; CLASSIFICATION; PATTERNS	For the last decade, it has been shown that neuroimaging can be a potential tool for the diagnosis of Alzheimer's Disease (AD) and its prodromal stage, Mild Cognitive Impairment (MCI), and also fusion of different modalities can further provide the complementary information to enhance diagnostic accuracy. Here, we focus on the problems of both feature representation and fusion of multimodal information from Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET). To our best knowledge, the previous methods in the literature mostly used hand-crafted features such as cortical thickness, gray matter densities from MRI, or voxel intensities from PET, and then combined these multimodal features by simply concatenating into a long vector or transforming into a higher-dimensional kernel space. In this paper, we propose a novel method for a high-level latent and shared feature representation from neuroimaging modalities via deep learning. Specifically, we use Deep Boltzmann Machine (DBM)(2), a deep network with a restricted Boltzmann machine as a building block, to find a latent hierarchical feature representation from a 3D patch, and then devise a systematic method for a joint feature representation from the paired patches of MRI and PET with a multimodal DBM. To validate the effectiveness of the proposed method, we performed experiments on ADNI dataset and compared with the state-of-the-art methods. In three binary classification problems of AD vs. healthy Normal Control (NC), MCI vs. NC, and MCI converter vs. MCI non-converter, we obtained the maximal accuracies of 95.35%, 85.67%, and 74.58%, respectively, outperforming the competing methods. By visual inspection of the trained model, we observed that the proposed method could hierarchically discover the complex latent patterns inherent in both MRI and PET. (C) 2014 Elsevier Inc. All rights reserved.	[Suk, Heung-Il; Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC USA; [Suk, Heung-Il; Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC USA; [Lee, Seong-Whan; Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Shen, DG (reprint author), Univ N Carolina, Dept Radiol, Chapel Hill, NC USA.	dgshen@med.unc.edu			NIH grants [EB006733, EB008374, EB009634, AG041721, MH100217, AG042599]; National Research Foundation grant - Korean Government [2012-005741]	This work was supported in part by NIH grants EB006733, EB008374, EB009634, AG041721, MH100217, and AG042599, and also by the National Research Foundation grant (No. 2012-005741) funded by the Korean Government.	Alzheimer's Association, 2012, ALZHEIMERS DEMENT, V8, P131, DOI DOI 10.1016/J.JALZ.2012.02.001; Baron JC, 2001, NEUROIMAGE, V14, P298, DOI 10.1006/nimg.2001.0848; Belleville S, 2011, BRAIN, V134, P1623, DOI 10.1093/brain/awr037; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bokde ALW, 2006, BRAIN, V129, P1113, DOI 10.1093/brain/awl051; BRAAK H, 1991, ACTA NEUROPATHOL, V82, P239; Burton EJ, 2009, BRAIN, V132, P195, DOI 10.1093/brain/awn298; Catana C, 2012, J NUCL MED, V53, P1916, DOI 10.2967/jnumed.112.105346; Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51; Cui Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021896; Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013; Dai WY, 2009, RADIOLOGY, V250, P856, DOI 10.1148/radiol.2503080751; Davatzikos C, 2011, NEUROBIOL AGING, V32, DOI DOI 10.1016/J.NEUROBIOLAGING.2010.05.023; Davatzikos C, 2001, NEUROIMAGE, V14, P1361, DOI 10.1006/nimg.2001.0937; de Jong LW, 2008, BRAIN, V131, P3277, DOI 10.1093/brain/awn278; Desikan RS, 2009, BRAIN, V132, P2048, DOI 10.1093/brain/awp123; Devanand DP, 2007, NEUROLOGY, V68, P828, DOI 10.1212/01.wnl.0000256697.20968.d7; Dinov ID, 2005, NEUROINFORMATICS, V3, P319, DOI 10.1385/NI:03:04:1; Ewers M, 2012, NEUROBIOL AGING, V33, P1203, DOI 10.1016/j.neurobiolaging.2010.10.019; Fan Y, 2007, NEUROIMAGE, V36, P1189, DOI 10.1016/j.neuroimage.2007.04.009; Fan Y, 2007, IEEE T MED IMAGING, V26, P93, DOI 10.1109/TMI.2006.886812; Friston Karl J., 1994, Human Brain Mapping, V2, P56, DOI 10.1002/hbm.460020107; Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101; Hackmack K, 2012, NEUROIMAGE, V62, P48, DOI 10.1016/j.neuroimage.2012.05.022; Hinrichs C, 2011, NEUROIMAGE, V55, P574, DOI 10.1016/j.neuroimage.2010.10.081; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hjelm RD, 2014, NEUROIMAGE, V96, P245, DOI 10.1016/j.neuroimage.2014.03.048; Ishii K, 2005, AM J NEURORADIOL, V26, P333; Jia HJ, 2010, NEUROIMAGE, V51, P1057, DOI 10.1016/j.neuroimage.2010.03.010; Johnson NA, 2005, RADIOLOGY, V234, P851, DOI 10.1148/radiol.2343040197; Kabani N.J., 1998, NEUROIMAGE, V7, pS717; Kohannim O, 2010, NEUROBIOL AGING, V31, P1429, DOI 10.1016/j.neurobiolaging.2010.04.022; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee ACH, 2006, J NEUROSCI, V26, P5198, DOI 10.1523/JNEUROSCI.3157-05.2006; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Li Y, 2012, NEUROBIOL AGING, V33, DOI [DOI 10.1016/J.NEUROBIOLAGING.2010.11.008, 10.1016/j.neurobiolaging.2010.11.008]; Liao S, 2013, LECT NOTES COMPUT SC, V8150, P254; LIU M, 2013, HUMAN BRAIN MAPPING, V35, P1305; Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055; Loewenstein DA, 2012, ALZHEIMERS DEMENT, V8, P172, DOI 10.1016/j.jalz.2011.03.002; Mark R.E., 2013, REV CLIN GERONTOL, V23, P61; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Montavon G., 2012, J MACHINE LEARNING R, V22, P798; Mosconi L, 2005, EUR J NUCL MED MOL I, V32, P486, DOI 10.1007/s00259-008-1039-z; Nair V., 2008, ADV NEURAL INFORM PR, P1145; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Nordberg A, 2010, NAT REV NEUROL, V6, P78, DOI 10.1038/nrneurol.2009.217; Perrin RJ, 2009, NATURE, V461, P916, DOI 10.1038/nature08538; Pichler BJ, 2010, J NUCL MED, V51, P333, DOI 10.2967/jnumed.109.061853; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2009, P INT C ART INT STAT, P448; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277; Singh V, 2006, BRAIN, V129, P2885, DOI 10.1093/brain/awl256; Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; Suk HI, 2013, LECT NOTES COMPUT SC, V8150, P583; Suk HI, 2013, LECT NOTES COMPUT SC, V8184, P131; Tanaka T., 1998, ADV NEURAL INFORM PR, P351; Tang SY, 2009, NEUROIMAGE, V47, P1277, DOI 10.1016/j.neuroimage.2009.02.043; Visser PJ, 2002, J NEUROL NEUROSUR PS, V72, P491; Walhovd KB, 2010, AM J NEURORADIOL, V31, P347, DOI 10.3174/ajnr.A1809; Wang YP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0077810; Ward A, 2012, ALZHEIMERS DEMENT, V8, P14, DOI 10.1016/j.jalz.2011.01.002; Wee CY, 2012, NEUROIMAGE, V59, P2045, DOI 10.1016/j.neuroimage.2011.10.015; Wee CY, 2011, NEUROIMAGE, V54, P1812, DOI 10.1016/j.neuroimage.2010.10.026; Westman E, 2012, NEUROIMAGE, V62, P229, DOI 10.1016/j.neuroimage.2012.04.056; Xue Z, 2006, MED IMAGE ANAL, V10, P740, DOI 10.1016/j.media.2006.06.007; Yang JZ, 2008, LECT NOTES COMPUT SC, V5242, P905; Yuan L, 2012, NEUROIMAGE, V61, P622, DOI 10.1016/j.neuroimage.2012.03.059; Zhang DQ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033182; Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008; Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; Zhou LP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021935	78	1	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119	1095-9572		NEUROIMAGE	Neuroimage	NOV 1	2014	101						569	582		10.1016/j.neuroimage.2014.06.077		14	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	AT4SJ	WOS:000344931800052	25042445	
J	Chavez, M; Garcia, S; Cabrera, E; Ashworth, M; Perea, N; Salazar, A; Chavez, E; Saborio-Ulloa, J; Saborio-Ortega, J				Chavez, M.; Garcia, S.; Cabrera, E.; Ashworth, M.; Perea, N.; Salazar, A.; Chavez, E.; Saborio-Ulloa, J.; Saborio-Ortega, J.			Site Effects and Peak Ground Accelerations Observed in Guadalajara, Mexico, for the 9 October 1995 M-w 8 Colima-Jalisco, Earthquake	BULLETIN OF THE SEISMOLOGICAL SOCIETY OF AMERICA			English	Article							NEURAL-NETWORKS; SUBDUCTION ZONE	On 3 June 1932, an M-s 8.2 shallow thrust subduction earthquake struck the Colima-Jalisco (CJ) region of Mexico at an epicentral distance of similar to 250 km from Guadalajara, the second largest town in Mexico. The return period of these CJ earthquakes has been estimated from 77 to 126 years, which suggests the next is likely to occur between 2009 and 2058. As a step toward estimating the seismic hazard posed by potential M-s 8.2+ events on Guadalajara, we present a study consisting of the following: (1) the analysis of the strong ground motions recorded at Guadalajara on 11 free-field accelerographs for the CJ 9 October 1995 M-w 8 earthquake; (2) the analysis of the site effects in Guadalajara observed for this earthquake; and (3) the estimation of the spatial distribution of peak ground acceleration (PGA) in Guadalajara for this event. We propose, validate, and apply a recurrent neural network (RNN) technique to the recorded PGA. Important site effects were identified (using the horizontal-to-vertical and H/H-rocksite techniques) on Guadalajara's sandy soil layers with thicknesses h > 20 m to the basaltic rock basement. The estimated PGAs in Guadalajara for the CJ 1995 earthquake varied from similar to 2 to similar to 27 cm/s(2) for soil layers with h <= 5 m and h > 50 m, respectively. We expect the hybrid technique to obtain broadband synthetics (Chavez et al., 2011) and the proposed RNN methodology can be used to estimate Guadalajara's seismic hazard for M-w 8+ CJ scenario earthquakes.	[Chavez, M.; Garcia, S.; Perea, N.] Univ Nacl Autonoma Mexico, Inst Ingn, Mexico City 04510, DF, Mexico; [Cabrera, E.] Univ Durham, Sch Engn & Comp Sci, Inst Adv Res Comp, Durham DH1 3LE, England; [Ashworth, M.] SERC, Daresbury Lab, Sci & Technol Facil Council, Dept Comp, Warrington WA4 4AD, Cheshire, England; [Salazar, A.] Univ Nacl Autonoma Mexico, Inst Geofis, Mexico City 04510, DF, Mexico; [Chavez, E.] Univ London Imperial Coll Sci Technol & Med, Dept Civil & Environm Engn, London SW7 2AZ, England; [Saborio-Ulloa, J.] Ctr Univ Ciencias Exactas & Ingn, Dept Ingn Civil & Topog, Guadalajara 44430, Jalisco, Mexico; [Saborio-Ortega, J.] City Toronto, Engn & Construct Serv, Toronto, ON M5V 3C6, Canada; [Chavez, M.] SERC, Daresbury Lab, Sci & Technol Facil Council, Warrington WA4 4AD, Cheshire, England; [Chavez, E.] Univ London Imperial Coll Sci Technol & Med, Sch Business, Dept Finance, London SW7 2AZ, England	Chavez, M (reprint author), Univ Nacl Autonoma Mexico, Inst Ingn, Ciudad Univ,Circuito Escolar S-N, Mexico City 04510, DF, Mexico.	chavez@unam.mx; sgab@pumas.iingen.unam.mx; eduardo.cabrera@durham.ac.uk; mike.ashworth@stfc.ac.uk; nperea68@gmail.com; alejandrocof@hotmail.com; erik.chavez07@imperial.ac.uk; jsabori@toronto.ca			Direccion General de Computo y de Tecnologias de Informacion y Comunicacion-Universidad Nacional Autonoma de Mexico (DGTIC-UNAM), Mexico; Scientific and Technology Facilities Council (STFC) Hartree Center; STFC Daresbury Laboratory, of the Daresbury Science and Innovation Campus, United Kingdom	We thank the participation of D. Almora, J. M. Velazco, R. Vazquez, and R. Ramirez and A. Martinez, in the different stages of the deployment, and for the maintenance and operation of the Guadalajara Accelerographic Network from 1991 to 1993 and from 1992 to 1997, respectively. We thank S. Custodio and S. Ma for sharing modeling information about the 2004 M<INF>w</INF> 6 Parkfield earthquake. We thank J. Anderson for his helpful comments and suggestions on the first version of the manuscript. We thank M. Rodri-guez and Horacio Mijares for fruitful discussions on the frequency responses of the Guadalajara Accelerographic Network. We thank two anonymous reviewers for their comments which significantly improved the manuscript. We thank the Direccion General de Computo y de Tecnologias de Informacion y Comunicacion-Universidad Nacional Autonoma de Mexico (DGTIC-UNAM), Mexico and the Scientific and Technology Facilities Council (STFC) Hartree Center and the STFC Daresbury Laboratory, of the Daresbury Science and Innovation Campus, United Kingdom, for their support in allowing us to use their supercomputers.	Bandy W., 1999, GEOFIS INT, V38, P127; Campos-Enriquez J. O., 1998, GEOFIS INT, V37, P263; Chavez M., 1993, MEM 10 C NAC ING SIS, P294; Chavez M, 2011, B SEISMOL SOC AM, V101, P1979, DOI 10.1785/0120100200; Chavez M., 2000, 12 WORLD C EARTHQ EN; Chavez M, 2010, B SEISMOL SOC AM, V100, P2561, DOI 10.1785/0120090240; Chavez M., 1995, 10 PAN C SOIL MECH F, V4, P33; Courboulex F, 1997, GEOPHYS RES LETT, V24, P1019, DOI 10.1029/97GL00945; Custodio S, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2005GL024417; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Escobedo D, 1998, GEOPHYS RES LETT, V25, P547, DOI 10.1029/98GL00061; Garcia Acosta V., 1996, SISMOS HIST MEXICO; Garcia SR, 2007, GEOFIS INT, V46, P51; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI DOI 10.1109/9780470544037.CH14; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; KANAMORI H, 1975, B SEISMOL SOC AM, V65, P1073; KLITGORD KD, 1982, J GEOPHYS RES, V87, P6725, DOI 10.1029/JB087iB08p06725; KOSTOGLODOV V, 1995, J GEOPHYS RES-SOL EA, V100, P17977, DOI 10.1029/95JB01484; Nakamura Y, 1989, QR RTRI, V30, P25; NISHENKO SP, 1987, B SEISMOL SOC AM, V77, P2095; Pacheco J., 1999, SEISMICITY MEXICO 19; Serrano A., 2009, THESIS U VALENCIA SP; Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1; TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141	27	1	1	SEISMOLOGICAL SOC AMER	ALBANY	400 EVELYN AVE, SUITE 201, ALBANY, CA 94706-1375 USA	0037-1106	1943-3573		B SEISMOL SOC AM	Bull. Seismol. Soc. Amer.	OCT	2014	104	5					2430	2455		10.1785/0120130144		26	Geochemistry & Geophysics	Geochemistry & Geophysics	AR5TG	WOS:000343645700023		
J	Huang, WH; Song, GJ; Hong, HK; Xie, KQ				Huang, Wenhao; Song, Guojie; Hong, Haikun; Xie, Kunqing			Deep Architecture for Traffic Flow Prediction: Deep Belief Networks With Multitask Learning	IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS			English	Article						Deep learning; multitask learning (MTL); task grouping; traffic flow prediction	INTELLIGENT TRANSPORTATION SYSTEMS; NEURAL-NETWORKS	Traffic flow prediction is a fundamental problem in transportation modeling and management. Many existing approaches fail to provide favorable results due to being: 1) shallow in architecture; 2) hand engineered in features; and 3) separate in learning. In this paper we propose a deep architecture that consists of two parts, i.e., a deep belief network (DBN) at the bottom and a multitask regression layer at the top. A DBN is employed here for unsupervised feature learning. It can learn effective features for traffic flow prediction in an unsupervised fashion, which has been examined and found to be effective for many areas such as image and audio classification. To the best of our knowledge, this is the first paper that applies the deep learning approach to transportation research. To incorporate multitask learning (MTL) in our deep architecture, a multitask regression layer is used above the DBN for supervised prediction. We further investigate homogeneous MTL and heterogeneous MTL for traffic flow prediction. To take full advantage of weight sharing in our deep architecture, we propose a grouping method based on the weights in the top layer to make MTL more effective. Experiments on transportation data sets show good performance of our deep architecture. Abundant experiments show that our approach achieved close to 5% improvements over the state of the art. It is also presented that MTL can improve the generalization performance of shared tasks. These positive results demonstrate that deep learning and MTL are promising in transportation research.	[Huang, Wenhao; Song, Guojie; Hong, Haikun; Xie, Kunqing] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Song, Guojie] Peking Univ, Res Ctr Intelligent Informat Proc, Beijing 100871, Peoples R China; [Xie, Kunqing] Peking Univ, Res Ctr Intelligent Traff Syst, Beijing 100871, Peoples R China	Song, GJ (reprint author), Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.	gjsong@pku.edu.cn			National High Technology Research and Development Program of China [2014AA015103]; National Science and Technology Support Plan [2014BAG01B02]	This work was supported in part by the National High Technology Research and Development Program of China under Grant 2014AA015103 and in part by the National Science and Technology Support Plan under Grant 2014BAG01B02.	Caruana R., 1998, MULTITASK LEARNING; Castro-Neto M, 2009, EXPERT SYST APPL, V36, P6164, DOI 10.1016/j.eswa.2008.07.069; Chan KY, 2012, IEEE T INTELL TRANSP, V13, P644, DOI 10.1109/TITS.2011.2174051; Clark S, 2003, J TRANSP ENG-ASCE, V129, P161, DOI 10.1061/(ASCE)0733-947X(2003)129:2(161); Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Dean J., 2012, P NIPS, P1232; Deng L, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2133; Ghosh B, 2007, J TRANSP ENG-ASCE, V133, P180, DOI 10.1061/(ASCE)0733-947X(2007)133:3(180); Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jin F, 2008, IEEE IJCNN, P1897; Krizhevsky A., 2012, P ADV NEUR INF PROC, V25, P1106; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Mohamed A.-R., 2009, P INT C COMP GRAPH I, P1; Moorthy C. K., 1988, TRANSPORT PLAN TECHN, V12, P45, DOI 10.1080/03081068808717359; Morris BT, 2012, IEEE T INTELL TRANSP, V13, P1667, DOI 10.1109/TITS.2012.2208222; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Pan TL, 2013, IEEE T INTELL TRANSP, V14, P1242, DOI 10.1109/TITS.2013.2258916; Salakhutdinov R., 2008, P ADV NEUR INF PROC, V20, P1249; Shuai M., 2008, P 16 ACM SIGSPATIAL, P45; Smith B.L., 1994, TRANSPORT RES REC, V1453, P98; Sun SL, 2007, IEEE T INTELL TRANSP, V8, P367, DOI 10.1109/TITS.2006.888603; Sun SL, 2006, IEEE T INTELL TRANSP, V7, P124, DOI 10.1109/TITS.2006.869623; Sun SL, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P961; Sun SL, 2011, IEEE T INTELL TRANSP, V12, P466, DOI 10.1109/TITS.2010.2093575; Tan MC, 2009, IEEE T INTELL TRANSP, V10, P60, DOI 10.1109/TITS.2008.2011693; Teh YW, 2001, ADV NEUR IN, V13, P908; Thomas T, 2010, IEEE T INTELL TRANSP, V11, P71, DOI 10.1109/TITS.2009.2028149; Transportation Research Board, 2000, HIGHW CAP MAN; vanderVoort M, 1996, TRANSPORT RES C-EMER, V4, P307, DOI 10.1016/S0968-090X(97)82903-8; Wang FY, 2010, IEEE T INTELL TRANSP, V11, P630, DOI 10.1109/TITS.2010.2060218; Ye Q, 2012, IEEE T INTELL TRANSP, V13, P1727, DOI 10.1109/TITS.2012.2203122; Yu G., 2003, P IEEE INT VEH S, P208; Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001; Zheng WZ, 2006, J TRANSP ENG-ASCE, V132, P114, DOI 10.1061/(ASCE)0733-947X(2006)132:2(114)	37	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1524-9050	1558-0016		IEEE T INTELL TRANSP	IEEE Trans. Intell. Transp. Syst.	OCT	2014	15	5					2191	2201		10.1109/TITS.2014.2311123		11	Engineering, Civil; Engineering, Electrical & Electronic; Transportation Science & Technology	Engineering; Transportation	AQ7MR	WOS:000343002400029		
J	Calhoun, VD				Calhoun, Vince D.			Brain networks: The next steps Comment on. "Understanding brain networks and brain organization" by Luiz Pessoa	PHYSICS OF LIFE REVIEWS			English	Editorial Material									[Calhoun, Vince D.] Mind Res Network, Albuquerque, NM 87131 USA; [Calhoun, Vince D.] Univ New Mexico, Dept ECE, Albuquerque, NM 87131 USA	Calhoun, VD (reprint author), Mind Res Network, 1101 Yale Blvd NE, Albuquerque, NM 87131 USA.	vcalhoun@unm.edu					Erhardt E. B., 2011, BRAIN CONNECT, V1, P1, DOI DOI 10.1089/BRAIN.2011.0022; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hutchison RM, 2013, NEUROIMAGE, V80, P360, DOI 10.1016/j.neuroimage.2013.05.079; PASCUALMARQUI RD, 1995, IEEE T BIO-MED ENG, V42, P658, DOI 10.1109/10.391164; Pessoa L, 2014, PHYS LIFE REV, V11, P400, DOI 10.1016/j.plrev.2014.03.005; Plis SM, 2014, NEUROIMAGE IN PRESS; Plis SM, 2011, COMPUT BIOL MED, V41, P1156, DOI 10.1016/j.compbiomed.2011.04.011; Plis SM, 2014, INT C LEARN REPR ICL; Sui J, 2012, J NEUROSCI METH, V204, P68, DOI 10.1016/j.jneumeth.2011.10.031; Tang J, 2010, PHYS REV E, V81, DOI 10.1103/PhysRevE.81.055101; Yu QB, 2013, SCHIZOPHR RES, V150, P450, DOI 10.1016/j.schres.2013.09.016	11	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1571-0645	1873-1457		PHYS LIFE REV	Phys. Life Rev.	SEP	2014	11	3					440	441		10.1016/j.plrev.2014.06.014		2	Biology; Biophysics	Life Sciences & Biomedicine - Other Topics; Biophysics	AQ1KW	WOS:000342541300016	24957289	
J	Swietojanski, P; Ghoshal, A; Renals, S				Swietojanski, Pawel; Ghoshal, Arnab; Renals, Steve			Convolutional Neural Networks for Distant Speech Recognition	IEEE SIGNAL PROCESSING LETTERS			English	Article						AMI corpus; convolutional neural networks; deep neural networks; distant speech recognition; meetings	MEETINGS; MODELS	We investigate convolutional neural networks (CNNs) for large vocabulary distant speech recognition, trained using speech recorded from a single distant microphone (SDM) and multiple distant microphones (MDM). In the MDM case we explore a beamformed signal input representation compared with the direct use of multiple acoustic channels as a parallel input to the CNN. We have explored different weight sharing approaches, and propose a channel-wise convolution with two-way pooling. Our experiments, using the AMI meeting corpus, found that CNNs improve the word error rate (WER) by 6.5% relative compared to conventional deep neural network (DNN) models and 15.7% over a discriminatively trained Gaussian mixture model (GMM) baseline. For cross-channel CNN training, the WER improves by 3.5% relative over the comparable DNN structure. Compared with the best beamformed GMM system, cross-channel convolution reduces the WER by 9.7% relative, and matches the accuracy of a beamformed DNN.	[Swietojanski, Pawel; Renals, Steve] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland; [Ghoshal, Arnab] Univ Edinburgh, Edinburgh EH8 9AB, Midlothian, Scotland	Swietojanski, P (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland.	p.swietojanski@ed.ac.uk; aghoshal@apple.com; s.renals@ed.ac.uk			EPSRC [EP/I031022/1]; European Union [287872]	This work was supported by EPSRC Programme Grant EP/I031022/1 (Natural Speech Technology), and by the European Union under FP7 project Grant Agreement 287872 (inEvent). The work of A. Ghoshal was performed while he was with the University of Edinburgh, Edinburgh, U.K. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Murat Akbacak.	Abdel-Hamid O, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4277; Abdel-Hamid O., 2013, P INTERSPEECH; Anguera X, 2007, IEEE T AUDIO SPEECH, V15, P2011, DOI 10.1109/TASL.2007.902460; Bourlard Ha, 1994, CONNECTIONIST SPEECH; Carletta J, 2007, LANG RESOUR EVAL, V41, P181, DOI 10.1007/s10579-007-9040-x; Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128; Cieri C., 2003, P EUR; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Fiscus J. G., 2006, P LREC; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Goodfellow I. J., ARXIV130842142013; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Hain T, 2012, IEEE T AUDIO SPEECH, V20, P486, DOI 10.1109/TASL.2011.2163395; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kumatani K, 2012, IEEE SIGNAL PROC MAG, V29, P127, DOI 10.1109/MSP.2012.2205285; LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ADV NEURAL INFORM PR, V22, P1096; Li JY, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P131; MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844; Palaz D., 2013, P INTERSPEECH; Povey D., 2008, P ICASSP, P4057; Povey D., 2011, P IEEE ASRU     12; Ranzato M. A., 2007, IEEE CVPR; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Robinson AJ, 2002, SPEECH COMMUN, V37, P27, DOI 10.1016/S0167-6393(01)00058-9; Sainath T. N., 2011, P IEEE ASRU; Sainath T. N., 2013, P IEEE ASRU; Sainath T. N., 2013, P IEEE ICASSP; Sainath T. N., 2012, P IEEE ICASSP; Stolcke A., 2011, P IEEE ICASSP; Sukittanon S., 2004, P ICSLP; Swietojanski P., 2013, P IEEE ASRU     12; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Wolfel M., 2009, DISTANT SPEECH RECOG; Zeppenfeld T., 1993, P ICASSP 93, V2, P475; Zhu Q., 2005, P EUR	42	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9908	1558-2361		IEEE SIGNAL PROC LET	IEEE Signal Process. Lett.	SEP	2014	21	9					1120	1124		10.1109/LSP.2014.2325781		5	Engineering, Electrical & Electronic	Engineering	AI7SX	WOS:000337099800001		
J	Kuremoto, T; Kimura, S; Kobayashi, K; Obayashi, M				Kuremoto, Takashi; Kimura, Shinsuke; Kobayashi, Kunikazu; Obayashi, Masanao			Time series forecasting using a deep belief network with restricted Boltzmann machines	NEUROCOMPUTING			English	Article						Time series forecasting; Deep belief nets; Restricted Boltzmann machine; Multi-layer perceptron; CATS benchmark; Chaos	LEARNING ALGORITHM; PREDICTION	Multi-layer perceptron (MLP) and other artificial neural networks (ANNs) have been widely applied to time series forecasting since 1980s. However, for some problems such as initialization and local optima existing in applications, the improvement of ANNs is, and still will be the most interesting study for not only time series forecasting but also other intelligent computing fields. In this study, we propose a method for time series prediction using Hinton and Salakhutdinov's deep belief nets (DBN) which are probabilistic generative neural network composed by multiple layers of restricted Boltzmann machine (RBM). We use a 3-layer deep network of RBMs to capture the feature of input space of time series data, and after pretraining of RBMs using their energy functions, gradient descent training, i.e., back-propagation learning algorithm is used for fine-tuning connection weights between "visible layers" and "hidden layers" of RBMs. To decide the sizes of neural networks and the learning rates, Kennedy and Eberhart's particle swarm optimization (PSO) is adopted during the training processes. Furthermore, "trend removal", a preprocessing to the original data, is also approached in the forecasting experiment using CATS benchmark data. Additionally, approximating and short-term prediction of chaotic time series such as Lorenz chaos and logistic map were also applied by the proposed method. (C) 2013 Elsevier B.V. All rights reserved.	[Kuremoto, Takashi; Kimura, Shinsuke; Obayashi, Masanao] Yamaguchi Univ, Grad Sch Sci & Engn, Ube, Yamaguchi 7558611, Japan; [Kobayashi, Kunikazu] Aichi Prefectural Univ, Sch Informat Sci & Technol, Nagakute, Aichi 4801198, Japan	Kuremoto, T (reprint author), Yamaguchi Univ, Grad Sch Sci & Engn, Tokiwadai 2-16-1, Ube, Yamaguchi 7558611, Japan.	wu@yamaguchi-u.ac.jp; kobayashi@ist.aichi-pu.ac.jp; m.obayas@yamaguchi-u.ac.jp			JSPS [23500181]	A part of this work was supported by Grant-in-Aid for Scientific Research (JSPS 23500181).	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P1; Box G. E. P., 1976, TIME SERIES ANAL FOR, V2nd; Chen K., 2011, IEEE T NEURAL NETW, V22; Crone S., 2007, P 27 INT S FOR PROGR, P129; GARDNER ES, 1989, MANAGE SCI, V35, P372, DOI 10.1287/mnsc.35.3.372; Hecht-Nielsen R, 1989, INT JOINT C NEURAL N, V1, P593; Hinton G, 1986, PARALLEL DISTRIBUTED, V1; Hinton G. E., 2006, SUPPORTING ONLINE MA; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/ICNN.1995.488968; Kuremoto T., 2003, P 2 INT C COMP INT R; Kuremoto T., 2008, REINFORCEMENT LEARNI, P1; Kuremoto T, 2005, LECT NOTES COMPUT SC, V3644, P1085; Kuremoto T., 2007, P 27 ANN INT S FOR I, P99; Lendasse A., 2004, P IJCNN 2004 INT JOI, V2, P1615; Lendasse A, 2007, NEUROCOMPUTING, V70, P2325, DOI 10.1016/j.neucom.2007.02.013; LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2; Pacelli Vincenzo, 2011, J INTELLIGENT LEARNI, V3.2A, P57; Panchal G, 2011, INT J COMPUTER THEOR, V3, P332; Roux N. L., 2008, NEURAL COMPUT, V20, P1631; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0	24	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	AUG 5	2014	137				SI		47	56		10.1016/j.neucom.2013.03.047		10	Computer Science, Artificial Intelligence	Computer Science	AH9PN	WOS:000336474400006		
J	Guclu, U; van Gerven, MAJ				Guclu, Umut; van Gerven, Marcel A. J.			Unsupervised Feature Learning Improves Prediction of Human Brain Activity in Response to Natural Images	PLOS COMPUTATIONAL BIOLOGY			English	Article							MONKEY STRIATE CORTEX; PRIMARY VISUAL-CORTEX; RECEPTIVE-FIELDS; STATISTICAL-MODELS; SPATIAL-FREQUENCY; FUNCTIONAL ARCHITECTURE; REPRESENTATION; FMRI; RECONSTRUCTION; SELECTIVITY	Encoding and decoding in functional magnetic resonance imaging has recently emerged as an area of research to noninvasively characterize the relationship between stimulus features and human brain activity. To overcome the challenge of formalizing what stimulus features should modulate single voxel responses, we introduce a general approach for making directly testable predictions of single voxel responses to statistically adapted representations of ecologically valid stimuli. These representations are learned from unlabeled data without supervision. Our approach is validated using a parsimonious computational model of (i) how early visual cortical representations are adapted to statistical regularities in natural images and (ii) how populations of these representations are pooled by single voxels. This computational model is used to predict single voxel responses to natural images and identify natural images from stimulus-evoked multiple voxel responses. We show that statistically adapted low-level sparse and invariant representations of natural images better span the space of early visual cortical representations and can be more effectively exploited in stimulus identification than hand-designed Gabor wavelets. Our results demonstrate the potential of our approach to better probe unknown cortical representations.	[Guclu, Umut; van Gerven, Marcel A. J.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, NL-6525 ED Nijmegen, Netherlands	Guclu, U (reprint author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, NL-6525 ED Nijmegen, Netherlands.	u.guclu@donders.ru.nl	van Gerven, Marcel/D-7800-2012		Huygens Scholarship Programme of the Netherlands organisation for international cooperation in higher education; Academy Assistants Programme of the Royal Netherlands Academy of Arts and Sciences	The first author was supported by the Huygens Scholarship Programme of the Netherlands organisation for international cooperation in higher education (http://www.nuffic.nl/) and the Academy Assistants Programme of the Royal Netherlands Academy of Arts and Sciences (http://www.knaw.nl/). No further funding was received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Barlow H.B., 1961, SENS COMMUN, P217; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; BLASDEL GG, 1992, J NEUROSCI, V12, P3139; Boyd S., 2004, CONVEX OPTIMIZATION, V1st; Brown EN, 2004, NAT NEUROSCI, V7, P456, DOI 10.1038/nn1228; Cukur T, 2013, NAT NEUROSCI, V16, P763, DOI 10.1038/nn.3381; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Dayan P., 2005, THEORETICAL NEUROSCI; DeAngelis GC, 1999, J NEUROSCI, V19, P4046; DEVALOIS RL, 1982, VISION RES, V22, P545, DOI 10.1016/0042-6989(82)90113-4; Dumoulin SO, 2008, NEUROIMAGE, V39, P647, DOI 10.1016/j.neuroimage.2007.09.034; Duyn JH, 2012, NEUROIMAGE, V62, P1241, DOI 10.1016/j.neuroimage.2011.10.065; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Furmanski CS, 2000, NAT NEUROSCI, V3, P535, DOI 10.1038/75702; Gutmann MU, 2012, J MACH LEARN RES, V13, P307; Gutmann MU, 2013, J PHYSIOL-PARIS, V107, P369, DOI [10.1016/j.jphysparis.2013.01.001, 10.1016/jjphysparis.2013.01.001]; Hastie T., 2009, ELEMENTS STAT LEARNI; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; Hyvarinen A, 2010, TOP COGN SCI, V2, P251, DOI 10.1111/j.1756-8765.2009.01057.x; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Hyvarinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233; Kamitani Y, 2005, NAT NEUROSCI, V8, P679, DOI 10.1038/nn1444; Kay KN, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003079; Kay K.N., 2011, FMRI HUMAN VISUAL AR; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Kay KN, 2013, J NEUROPHYSIOL, V110, P481, DOI 10.1152/jn.00105.2013; Knowles D, 2011, ANN APPL STAT, V5, P1534, DOI 10.1214/10-AOAS435; Kok P, 2013, J NEUROSCI, V33, P16275, DOI 10.1523/JNEUROSCI.0742-13.2013; Koster U, 2010, NEURAL COMPUT, V22, P2308, DOI 10.1162/NECO_a_00010; Le Q. V., 2012, INT C MACH LEARN; Le QV, 2011, C COMP VIS PATT REC; Lee H., 2009, INT C MACH LEARN; Lee H., 2007, NEURAL INFORM PROCES; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959; MANSFIEL.RJ, 1974, SCIENCE, V186, P1133, DOI 10.1126/science.186.4169.1133; Mitchell TM, 2008, SCIENCE, V320, P1191, DOI 10.1126/science.1152876; Miyawaki Y, 2008, NEURON, V60, P915, DOI 10.1016/j.neuron.2008.11.004; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073; Naselaris T, 2009, NEURON, V63, P902, DOI 10.1016/j.neuron.2009.09.006; Nishimoto S, 2011, CURR BIOL, V21, P1641, DOI 10.1016/j.cub.2011.08.031; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PARKER AJ, 1988, J OPT SOC AM A, V5, P598, DOI 10.1364/JOSAA.5.000598; Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251; Quiroga RQ, 2005, NATURE, V435, P1102, DOI 10.1038/nature03687; Saxe AM, 2011, NEURAL INFORM PROCES; Schoenmakers S, 2013, NEUROIMAGE, V83, P951, DOI 10.1016/j.neuroimage.2013.07.043; Smith AT, 2001, CEREB CORTEX, V11, P1182, DOI 10.1093/cercor/11.12.1182; Swisher JD, 2010, J NEUROSCI, V30, P325, DOI 10.1523/JNEUROSCI.4811-09.2010; Thirion B, 2006, NEUROIMAGE, V33, P1104, DOI 10.1016/j.neuroimage.2006.06.062; TOOTELL RBH, 1988, J NEUROSCI, V8, P1610; van Gerven MAJ, 2010, NEURAL COMPUT, V22, P3127, DOI 10.1162/NECO_a_00047; Vu VQ, 2011, ANN APPL STAT, V5, P1159, DOI 10.1214/11-AOAS476; Yacoub E, 2008, P NATL ACAD SCI USA, V105, P10607, DOI 10.1073/pnas.0804110105; Yamins DLK, 2014, P NATL ACAD SCI US	61	1	1	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1553-734X	1553-7358		PLOS COMPUT BIOL	PLoS Comput. Biol.	AUG	2014	10	8							e1003724	10.1371/journal.pcbi.1003724		12	Biochemical Research Methods; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Mathematical & Computational Biology	AO8AE	WOS:000341573600002	25101625	
J	Huijse, P; Estevez, PA; Protopapas, P; Principe, JC; Zegers, P				Huijse, Pablo; Estevez, Pablo A.; Protopapas, Pavlos; Principe, Jose C.; Zegers, Pablo			Computational Intelligence Challenges and Applications on Large-Scale Astronomical Time Series Databases	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							PERIODIC VARIABLE-STARS; AUTOMATED SUPERVISED CLASSIFICATION; STELLAR LIGHT CURVES; DIGITAL SKY SURVEY; SPECTRAL-ANALYSIS; ALGORITHM; SELECTION; METHODOLOGY; INFORMATION; GALAXIES	Time-domain astronomy (TDA) is facing a paradigm shift caused by the exponential growth of the sample size, data complexity and data generation rates of new astronomical sky surveys. For example, the Large Synoptic Survey Telescope (LSST), which will begin operations in northern Chile in 2022, will generate a nearly 150 Petabyte imaging dataset of the southern hemisphere sky. The LSST will stream data at rates of 2 Terabytes per hour, effectively capturing an unprecedented movie of the sky. The LSST is expected not only to improve our understanding of time-varying astrophysical objects, but also to reveal a plethora of yet unknown faint and fast-varying phenomena. To cope with a change of paradigm to data-driven astronomy, the fields of astroinformatics and astrostatistics have been created recently. The new data-oriented paradigms for astronomy combine statistics, data mining, knowledge discovery, machine learning and computational intelligence, in order to provide the automated and robust methods needed for the rapid detection and classification of known astrophysical objects as well as the unsupervised characterization of novel phenomena. In this article we present an overview of machine learning and computational intelligence applications to TDA. Future big data challenges and new lines of research in TDA, focusing on the LSST, are identified and discussed from the viewpoint of computational intelligence/machine learning. Interdisciplinary collaboration will be required to cope with the challenges posed by the deluge of astronomical data coming from the LSST.	[Huijse, Pablo; Estevez, Pablo A.] Millennium Inst Astrophys, Santiago, Chile; [Estevez, Pablo A.] Univ Chile, Dept Elect Engn, Santiago, Chile; [Protopapas, Pavlos] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Principe, Jose C.] Univ Florida, Computat NeuroEngineering Lab, Gainesville, FL 32611 USA; [Zegers, Pablo] Univ Los Andes, Fac Ingn & Ciencias Aplicadas, Santiago, Chile	Huijse, P (reprint author), Millennium Inst Astrophys, Santiago, Chile.		Estevez, Pablo/A-9377-2008		CONICYT-CHILE [FONDECYT 1110701, 1140816]; Ministry of Economy, Development, and Tourism's Millennium Science Initiative [IC12009]	This work was funded by CONICYT-CHILE under grant FONDECYT 1110701 and 1140816, and its Doctorate Scholarship program. Pablo Estevez acknowledges support from the Ministry of Economy, Development, and Tourism's Millennium Science Initiative through grant IC12009, awarded to The Millennium Institute of Astrophysics, MAS.	Alcock C, 2000, ASTROPHYS J, V542, P281, DOI 10.1086/309512; Bengio Y., 2007, LARGE SCALE KERNEL M; Berriman G. B., 2010, ARXIV E PRINTS; Blomme J, 2011, MON NOT R ASTRON SOC, V418, P96, DOI 10.1111/j.1365-2966.2011.19466.x; Borne K., 2012, LEARNING BIG DATA AS; Borne K., 2013, PLANETS STARS STELLA, V2, P404; Borne KD, 2010, EARTH SCI INFORM, V3, P5, DOI 10.1007/s12145-010-0055-2; Brett DR, 2004, MON NOT R ASTRON SOC, V353, P369, DOI 10.1111/j.1365-2966.2004.08093.x; Chu Cheng-Tao, 2006, NIPS, P281; Das K, 2012, CH CRC DATA MIN KNOW, P595; Dean J., 2004, P 6 C S OP SYST DES, V6, P10, DOI DOI 10.HTTP://DL.ACM.0RG/CITATI0N.CFM?; Debosscher J, 2007, ASTRON ASTROPHYS, V475, P1159, DOI 10.1051/0004-6361:20077638; Djorgovski S. G., 2011, P CIDU 2011 C ASA, P174; Djorgovski S. G., 2006, P 18 INT C PATT REC, P865; Donalek C., 2013, P IEEE INT C BIG DAT, P35; Dubath P, 2011, MON NOT R ASTRON SOC, V414, P2602; Eyer L, 2008, J PHYS CONF SER, V118, DOI 10.1088/1742-6596/118/1/012010; Fabian A. C, 2009, ARXIV E PRINTS; Fan J., 2013, ARXIV E PRINTS; Feigelson E., 2012, SIGNIFICANCE, V9, P22; Graham MJ, 2012, DISTRIB PARALLEL DAT, V30, P371, DOI 10.1007/s10619-012-7101-7; Graham MJ, 2013, MON NOT R ASTRON SOC, V434, P2629, DOI 10.1093/mnras/stt1206; Graham MJ, 2013, MON NOT R ASTRON SOC, V434, P3423, DOI 10.1093/mnras/stt1264; Greene G., 2007, ASTRONOMICAL SOC PAC, V382, P111; HERNANDEZPAJARES M, 1994, MON NOT R ASTRON SOC, V268, P444; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huijse P, 2012, IEEE T SIGNAL PROCES, V60, P5135, DOI 10.1109/TSP.2012.2204260; Ivezic Z., 2011, LSST SCI DRIVERS REF; Kaiser N, 2002, P SOC PHOTO-OPT INS, V4836, P154, DOI 10.1117/12.457365; Kim DW, 2011, ASTROPHYS J, V735, DOI 10.1088/0004-637X/735/2/68; Kindratenko V, 2011, COMPUT SCI ENG, V13, P92, DOI 10.1109/MCSE.2011.52; Kulkarni GV, 2007, MON NOT R ASTRON SOC, V378, P1196, DOI 10.1111/j.1365-2966.2007.11872.x; Larson S., 2003, BAAS, V35, P982; Long J., 2012, SPRINGER SERIES ASTR, V2, P163; LSST Science Collaborations and LSST Project, 2013, ARXIV09120201; March WB, 2012, CH CRC DATA MIN KNOW, P463; Olivares F. E., 2011, CORE COLLAPSE SUPERN; Pedrycz W., 2008, HDB GRANULAR COMPUTI; Percy J. R., 2007, UNDERSTANDING VARIAB; Petit M., 1987, VARIABLE STARS; Pichara K, 2013, ASTROPHYS J, V777, DOI 10.1088/0004-637X/777/2/83; POPPER DM, 1980, ANNU REV ASTRON ASTR, V18, P115, DOI 10.1146/annurev.aa.18.090180.000555; Principe JC, 2010, INFORM SCI STAT, P1, DOI 10.1007/978-1-4419-1570-2; Protopapas P., 2014, ASTROPHYS J IN PRESS; Protopapas P, 2006, MON NOT R ASTRON SOC, V369, P677, DOI 10.1111/j.1365-2966.2006.10327.x; Rahal YR, 2009, ASTRON ASTROPHYS, V500, P1027, DOI 10.1051/0004-6361/200811515; Rebbapragada U, 2009, MACH LEARN, V74, P281, DOI 10.1007/s10994-008-5093-3; Richards JW, 2012, ASTROPHYS J, V744, DOI 10.1088/0004-637X/744/2/192; Richards JW, 2011, ASTROPHYS J, V733, DOI 10.1088/0004-637X/733/1/10; Richards JW, 2012, MON NOT R ASTRON SOC, V419, P1121, DOI 10.1111/j.1365-2966.2011.19768.x; Samus N.N., 2012, GEN CATALOGUE VARIAB; Sarro LM, 2009, ASTRON ASTROPHYS, V506, P535, DOI 10.1051/0004-6361/200912009; Sart Doruk, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.21; SCARGLE JD, 1982, ASTROPHYS J, V263, P835, DOI 10.1086/160554; Tagliaferri R, 1999, ASTRON ASTROPHYS SUP, V137, P391, DOI 10.1051/aas:1999254; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Tyson JA, 2012, CH CRC DATA MIN KNOW, P161; Udalski A, 1997, ACTA ASTRONOM, V47, P319; Varon C, 2011, ASTRON ASTROPHYS, V531, DOI 10.1051/0004-6361/201016419; Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0; Wachman G, 2009, LECT NOTES ARTIF INT, V5782, P489; Walker AR, 2003, LECT NOTES PHYS, V635, P265; Wiley K, 2011, PUBL ASTRON SOC PAC, V123, P366, DOI 10.1086/658877; Yankov D, 2008, KNOWL INF SYST, V17, P241, DOI 10.1007/s10115-008-0131-9; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513	65	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-603X	1556-6048		IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	AUG	2014	9	3					27	39		10.1109/MCI.2014.2326100		13	Computer Science, Artificial Intelligence	Computer Science	AN0JW	WOS:000340271800003		
J	Baldi, P; Sadowski, P; Whiteson, D				Baldi, P.; Sadowski, P.; Whiteson, D.			Searching for exotic particles in high-energy physics with deep learning	NATURE COMMUNICATIONS			English	Article							ALGORITHM; BOSON; NETS; LHC	Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine-learning approaches are often used. Standard approaches have relied on 'shallow' machine-learning models that have a limited capacity to learn complex nonlinear functions of the inputs, and rely on a painstaking search through manually constructed nonlinear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Here, using benchmark data sets, we show that deep-learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8% over the best current approaches. This demonstrates that deep-learning approaches can improve the power of collider searches for exotic particles.	[Baldi, P.; Sadowski, P.] UC Irvine, Dept Comp Sci, Irvine, CA 92617 USA; [Whiteson, D.] UC Irvine, Dept Phys & Astron, Irvine, CA 92617 USA	Baldi, P (reprint author), UC Irvine, Dept Comp Sci, Irvine, CA 92617 USA.	pbaldi@uci.edu; daniel@uci.edu			NVIDIA	We are grateful to Kyle Cranmer, Chris Hays, Chase Shimmin, Davide Gerbaudo, Bo Jayatilaka, Jahred Adelman and Shimon Whiteson for their insightful comments. We wish to acknowledge a hardware grant from NVIDIA.	Aad G, 2012, PHYS LETT B, V716, P1, DOI 10.1016/j.physletb.2012.08.020; Aad G, 2014, PHYS REV D, V89, DOI 10.1103/PhysRevD.89.032002; Aaltonen T, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.152001; Aaltonen T, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.121801; Alwall J., 2011, JHEP, V1106, P128, DOI DOI 10.1007/JHEP06(2011)128; Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004; Barr A, 2003, J PHYS G NUCL PARTIC, V29, P2343, DOI 10.1088/0954-3899/29/10/304; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bergstra J., 2010, P PYTH SCI COMP C SC; Buckley M. R., 2013, SUPER RAZOR SEARCHES; Chatrchyan S, 2012, PHYS LETT B, V716, P30, DOI 10.1016/j.physletb.2012.08.021; Cheng H.-C., 2008, J HIGH ENERGY PHYS, V0812, P063, DOI DOI 10.1088/1126-6708/2008/12/063; Dawson S., 2013, HIGGS WORKING GROUP; Goodfellow I. J., 2013, PYLEARN2 MACHINE LEA; Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094; Hocker A., 2007, POS ACAT, P040; Hornik K., 1989, NEURAL NETWORKS, V2; Neyman J., 1933, PHILOS T R SOC LON A, V231, P694; Ovyn S., 2009, DELPHES FRAMEWORK FA; Rogan C., 2010, KINEMATICAL VARIABLE; Sjostrand T, 2006, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2006/05/026; Whiteson S., 2007, P 19 ANN INN APPL AR, P1819	25	1	1	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	2041-1723			NAT COMMUN	Nat. Commun.	JUL	2014	5								4308	10.1038/ncomms5308		9	Multidisciplinary Sciences	Science & Technology - Other Topics	AN5GI	WOS:000340618300002	24986233	
J	Gao, XY; Shang, C; Jiang, YH; Huang, DX; Chen, T				Gao, Xiaoyong; Shang, Chao; Jiang, Yongheng; Huang, Dexian; Chen, Tao			Refinery scheduling with varying crude: A deep belief network classification and multimodel approach	AICHE JOURNAL			English	Article						deep belief network; refinery scheduling; multimodel; varying crude	OPTIMIZATION; OPERATIONS; UNCERTAINTY; MODELS	In model-based refinery scheduling, the varying composition of the crude being refined is a major challenge, especially for those reaction processes. A classification based, multimodel approach is proposed to handle the frequently varying crude. The idea is to build a scheduling model for each type of feed crude, and the type can be determined using an online classifier. The recently emerged deep belief network is introduced to develop the classifier, which provides more accurate classification than the traditional neural network. The proposed method is demonstrated through modeling a fluidized catalytic cracking unit (the mostly affected by varying crude), and then the scheduling of a refinery that was carefully simulated to mimic the actual operation of a refinery in northern China. The results reveal that the multimodel approach is effective in handling varying crude. (c) 2014 American Institute of Chemical Engineers	[Gao, Xiaoyong; Shang, Chao; Jiang, Yongheng; Huang, Dexian] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Huang, Dexian] Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China; [Chen, Tao] Univ Surrey, Dept Chem & Proc Engn, Guildford GU2 7XH, Surrey, England	Chen, T (reprint author), Univ Surrey, Dept Chem & Proc Engn, Guildford GU2 7XH, Surrey, England.	t.chen@surrey.ac.uk	Chen, Tao/B-7692-2008		National Basic Research Program of China [2012CB720500]; National Natural Science Foundation of China [21276137, 61273039]; Santander Universities through a Santander Postgraduate Research Award	This research was supported by the National Basic Research Program of China (2012CB720500) and the National Natural Science Foundation of China (No. 21276137, No. 61273039). Xiaoyong Gao's visit to the University of Surrey was funded by the Santander Universities through a Santander Postgraduate Research Award.	Bai L, 2012, IND ENG CHEM RES, V51, P9078, DOI 10.1021/ie202224w; Balabin RM, 2010, ANAL CHIM ACTA, V671, P27, DOI 10.1016/j.aca.2010.05.013; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bishop CM, 2006, PATTERN RECOGNITION; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Cuiwen C, 2013, AICHE J, V59, P1160; Ge ZQ, 2014, AICHE J, V60, P533, DOI 10.1002/aic.14270; Gothe-Lundgren M, 2002, INT J PROD ECON, V78, P255, DOI 10.1016/S0925-5273(00)00162-6; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; KBC Advanced Technologies, 2012, PETR SIM US GUID; Kelly JD, 2004, CHEM ENG PROG, V100, P44; Kotsiantis SB, 2006, ARTIF INTELL REV, V26, P159, DOI 10.1007/S10462-007-9052-3; Li J, 2012, AICHE J, V58, P205, DOI 10.1002/aic.12623; Li WK, 2005, COMPUT CHEM ENG, V29, P2010, DOI 10.1016/j.compchemeng.2005.05.010; Li WK, 2004, IND ENG CHEM RES, V43, P6742, DOI 10.1021/ie049737d; Luo CP, 2007, IND ENG CHEM RES, V46, P3656, DOI 10.1021/ie061354n; Ma LW, 2012, ENERG POLICY, V45, P43, DOI 10.1016/j.enpol.2012.01.023; Michie D., 1994, MACHINE LEARNING NEU; Mouret S, 2009, IND ENG CHEM RES, V48, P8515, DOI 10.1021/ie8019592; Pinto JM, 2000, COMPUT CHEM ENG, V24, P2259, DOI 10.1016/S0098-1354(00)00571-8; Sadeghbeigi R, 2012, FLUID CATALYTIC CRACKING HANDBOOK: AN EXPERT GUIDE TO THE PRACTICAL OPERATION, DESIGN, AND OPTIMIZATION OF FCC UNITS, 3RD EDITION, P1; Shah N, 2009, COMPUT CHEM ENG, V33, P2091, DOI 10.1016/j.compchemeng.2009.06.010; Shah NK, 2011, AICHE J, V57, P1570, DOI 10.1002/aic.12359; Shang C, 2014, J PROCESS CONTR, V24, P223, DOI 10.1016/j.jprocont.2014.012; Yu L, 2004, PET PROCESS PETROCHE, V35, P5; Zhang J, 2012, IND ENG CHEM RES, V51, P8453, DOI 10.1021/ie102499p; Zhang J, 2001, IND ENG CHEM RES, V40, P1528, DOI 10.1021/ie990854w	29	1	1	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0001-1541	1547-5905		AICHE J	AICHE J.	JUL	2014	60	7					2525	2532		10.1002/aic.14455		8	Engineering, Chemical	Engineering	AJ5BL	WOS:000337695500012		
J	Ladicky, L; Russell, C; Kohli, P; Torr, PHS				Ladicky, L'ubor; Russell, Chris; Kohli, Pushmeet; Torr, Philip H. S.			Associative Hierarchical Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Conditional random fields; discrete energy minimisation; object recognition and segmentation	EFFICIENT BELIEF PROPAGATION; IMAGE SEGMENTATION; ENERGY MINIMIZATION; GRAPH CUTS; ALGORITHM; CONTEXT	This paper makes two contributions: the first is the proposal of a new model-The associative hierarchical random field (AHRF), and a novel algorithm for its optimization; the second is the application of this model to the problem of semantic segmentation. Most methods for semantic segmentation are formulated as a labeling problem for variables that might correspond to either pixels or segments such as super-pixels. It is well known that the generation of super pixel segmentations is not unique. This has motivated many researchers to use multiple super pixel segmentations for problems such as semantic segmentation or single view reconstruction. These super-pixels have not yet been combined in a principled manner, this is a difficult problem, as they may overlap, or be nested in such a way that the segmentations form a segmentation tree. Our new hierarchical random field model allows information from all of the multiple segmentations to contribute to a global energy. MAP inference in this model can be performed efficiently using powerful graph cut based move making algorithms. Our framework generalizes much of the previous work based on pixels or segments, and the resulting labelings can be viewed both as a detailed segmentation at the pixel level, or at the other extreme, as a segment selector that pieces together a solution like a jigsaw, selecting the best segments from different segmentations as pieces. We evaluate its performance on some of the most challenging data sets for object class segmentation, and show that this ability to perform inference using multiple overlapping segmentations leads to state-of-the-art results.	[Ladicky, L'ubor] ETH, Comp Vis & Geometry Lab, CH-8092 Zurich, Switzerland; [Russell, Chris] Univ London, Univ Coll London, Dept Comp Sci, London WC1E 6BT, England; [Kohli, Pushmeet] Microsoft Res, Cambridge CB1 2FB, England; [Torr, Philip H. S.] Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England	Ladicky, L (reprint author), ETH, Comp Vis & Geometry Lab, CH-8092 Zurich, Switzerland.	lubor.ladicky@inf.ethz.ch; chrisr@eecs.qmul.ac.uk; pkohli@microsoft.com; philiptorr@brookes.ac.uk			EPSRC research grants; HMGCC; IST Programme of the European Community, under the PASCAL2 Network of Excellence [IST-2007-216886]	This work is supported by EPSRC research grants, HMGCC, the IST Programme of the European Community, under the PASCAL2 Network of Excellence, IST-2007-216886. P. H. S. Torr is in receipt of Royal Society Wolfson Research Merit Award.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Alahari K, 2010, PROC CVPR IEEE, P895, DOI 10.1109/CVPR.2010.5540123; [Anonymous], 2004, P SIGGRAPH; Batra D., 2008, P IEEE WORKSH MOT VI, P1, DOI DOI 10.1109/WMVC.2008.4544051; Besag J., 1986, J ROY STAT SOC, V48; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Boix X., 2012, INT J COMPUT VISION, V91, P83; Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI DOI 10.1145/1282280.1282340; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y., 2001, P INT C COMP VIS, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N, 2005, PROC CVPR IEEE, P886; Everingham M., PASCAI VISUAL OBJECT; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Finley T., 2008, P 25 INT C MACH LEAR, P304, DOI 10.1145/1390156.1390195; FIX A, 2011, P INT C COMP VIS BAR, P1020; Gallagher C., 2008, P IEEE C COMP VIS PA, P1; Gould S., 2009, P ADV NEUR INF PROC, P655; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; He XM, 2006, LECT NOTES COMPUT SC, V3951, P338; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D., 2006, P COMP VIS PATT REC, P2137; Ishikawa H, 2011, IEEE T PATTERN ANAL, V33, P1234, DOI 10.1109/TPAMI.2010.91; Ishikawa H., 2009, P IEEE C COMP VIS PA, P2993; Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175; Kohli P., 2008, P IEEE C COMP VIS PA, P1; Kohli P., 2007, P IEEE C COMP VIS PA, P1; Kolmogorov V, 2006, LECT NOTES COMPUT SC, V3952, P1; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Komodakis N., 2009, P IEEE C COMP VIS PA, P2985; Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072; Kumar MP, 2011, J MACH LEARN RES, V12, P31; Kumar S., 2005, P IEEE INT C COMP VI, V2, P1284; LADICKY L, 2010, P ECCV, V6315, P239; Lafferty J. D., 2001, ICML, P282; Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269; Larlus D., 2008, P IEEE C COMP VIS PA, P1; Lempitsky V. S., 2011, P ADV NIPS, P1485; Lim JJ, 2009, IEEE I CONF COMP VIS, P1978, DOI 10.1109/ICCV.2009.5459436; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Munoz D., 2010, P ECCV; Nowozin S., 2010, P ECCV; Ojala T., 1994, P C COMP VIS IM PROC; Pantofaru C., 2008, P ECCV; Potetz B, 2008, COMPUT VIS IMAGE UND, V112, P39, DOI 10.1016/j.cviu.2008.05.007; Rabinovich A., 2007, P INT C COMP VIS; Ramalingam S., 2011, ARXIV11092304; Ren X., 2003, P INT C COMP VIS; Reynolds J., 2007, P CAN C COMP ROB VIS; Rother C., 2005, P C COMP VIS PATT RE; Russell B., 2006, P IEEE C COMP VIS PA, P1605; Schlesinger D., 2006, TRANSFORMING ARBITRA; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Shotton J., 2008, P IEEE C COMP VIS PA, P1; Socher R., 2011, P 28 INT C MACH LEAR, P129; Sontag D., 2008, P UNCERTAINITY ARTIF; Szeliski R., 2006, P EUR C COMP VIS; Szummer M., 2008, P EUR C COMP VIS MAR; Tao H., 2001, P INT C COMP VIS VAN; Tarlow D., 2010, P ARTIFICIAL INTELLI; Tarlow D., 2008, P C UNC ART INT; Taskar B., 2004, P INT C MACH LEARN B; Tighe J., 2010, P EUR C COMP VIS CRE; Torralba A., 2004, P C COMP VIS PATT RE; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tu Z., 2003, P INT C COMP VIS NIC; van de Sande K. E. A, 2008, P C COMP VIS PATT RE; Veksler O., 2007, P C COMP VIS PATT RE; Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; Werner T., 2009, P C COMP VIS PATT RE; Yang L., 2007, P C COMP VIS PATT RE; Zhang Y., 2011, P INT C COMP VIS BAR; Zhu L., 2008, P ADV NIPS; Zhu L., 2005, P ADV NIPS	79	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1056	1077		10.1109/TPAMI.2013.165		22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	AI8AJ	WOS:000337124200002		
J	Manju, A; Nigam, MJ				Manju, A.; Nigam, M. J.			Applications of quantum inspired computational intelligence: a survey	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						Quantum computing; Quantum mechanics; Computational intelligence	PARTICLE SWARM OPTIMIZATION; SUPPORT VECTOR REGRESSION; ECONOMIC LOAD DISPATCH; QTRON NEURAL-NETWORKS; ADIABATIC EVOLUTION ALGORITHM; FREQUENCY ATOM DECOMPOSITION; MULTIPLE SEQUENCE ALIGNMENT; HYALURONIC-ACID PRODUCTION; HYBRID GENETIC ALGORITHM; IMMUNE CLONAL ALGORITHM	This paper makes an exhaustive survey of various applications of Quantum inspired computational intelligence (QCI) techniques proposed till date. Definition, categorization and motivation for QCI techniques are stated clearly. Major Drawbacks and challenges are discussed. The significance of this work is that it presents an overview on applications of QCI in solving various problems in engineering, which will be very much useful for researchers on Quantum computing in exploring this upcoming and young discipline.	[Manju, A.; Nigam, M. J.] Indian Inst Technol Roorkee, Dept Elect & Comp Engn, Roorkee 247667, Uttar Pradesh, India	Manju, A (reprint author), Indian Inst Technol Roorkee, Dept Elect & Comp Engn, Roorkee 247667, Uttar Pradesh, India.	manju.senthil@gmail.com; mkndnfec@iitr.ernet.in					Aarabi A, 2007, CLIN NEUROPHYSIOL, V118, P2781, DOI 10.1016/j.clinph.2007.08.012; Akbarzadeh M, 2009, ADV COMPUTER SCI ENG, V6, P741, DOI 10.1007/978-3-540-89985-3_93; Akbarzadeh-T MR, 2005, IEEE SYS MAN CYBERN, P3077; Alfares F, 2004, P ACDM, P377; Alfares F., 2003, P 7 WORLD C INT DES, P669; Alfares FS, 2006, 2 ITN S LEV APPL FOR, P169, DOI 10.1109/ISoLA.2006.12; Allauddin R, 2008, QUANTUM INSPIRED INT, P57; Al-Othman AK, 2007, INT J ELECT COMPUT S, V1, P4; Altaisky MV, 2001, Quatum neural network, Patent No. 6578018; Altman C, 2004, INT J THEOR PHYS, V43, P2435, DOI 10.1007/s10773-004-7709-0; Altman C, 2010, INT J THEOR PHYS, V49, P2991, DOI 10.1007/s10773-009-0103-1; Amjady N, 2010, EXPERT SYST APPL, V37, P5239, DOI 10.1016/j.eswa.2009.12.084; Amo del IG, 2010, IEEEE C EV COMP, P1, DOI 10.1109/CEC.2010.5586051; Andrecut M, 2002, INT J MOD PHYS C, V13, P75, DOI 10.1142/S0129183102002948; Araujo R, 2010, 2010 INT JOINT C NEU, P1; Araujo R, 2010, INT J INTELLIGENT CO, V3, P24; Araujo RD, 2008, IEEE C EVOL COMPUTAT, P1348; Aziz M, 2010, 4 AS INT C MATH AN M, P133; Babaei E, 2010, 9 INT POW EN C IPEC, P467; Baida Q, 2008, COMPUTER ENG APPL, V44, P72; Barkan U, 2006, NEUROCOMPUTING, V69, P1108, DOI 10.1016/j.neucom.2005.12.121; Behera L, 2006, FRONT COLLECT, P327, DOI 10.1007/3-540-36723-3_9; Behera L, 1998, IEE P-CONTR THEOR AP, V145, P135, DOI 10.1049/ip-cta:19981704; Behera L, 2005, FOUND PHYS LETT, V18, P357, DOI 10.1007/s10702-005-7125-6; Behera L, 1996, IEEE T NEURAL NETWOR, V7, P1401, DOI 10.1109/72.548168; Behera L, 2005, IEEE SYS MAN CYBERN, P2161; Behera L, 2004, STUD FUZZ SOFT COMP, V141, P479; Benatchba K, 2006, P 32 ANN C IEEE IND, P3556; Bi X, 2007, IEEE INT C INT TECHN, P403; Blackwell T, 2006, IEEE T EVOLUT COMPUT, V10, P459, DOI 10.1109/TEVC.2005.857074; Cai YJ, 2008, J THEOR BIOL, V254, P123, DOI 10.1016/j.jtbi.2008.05.010; Cao M, 2010, 2 INT WORKSH ED TECH, V1, P19; Cao MJ, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 2, PROCEEDINGS, P160, DOI 10.1109/WCSE.2009.127; Caprihan R, 2009, IN C IND ENG ENG MAN, P125, DOI 10.1109/IEEM.2009.5373408; Chai ZL, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P886; Chang BR, 2006, FUZZY SET SYST, V157, P1832, DOI 10.1016/j.fss.2006.01.011; Chang BR, 2008, FUZZY SET SYST, V159, P3183, DOI 10.1016/j.fss.2008.04.003; Chang BR, 2009, EXPERT SYST APPL, V36, P3388, DOI 10.1016/j.eswa.2008.02.011; Chang BR, 2008, EXPERT SYST APPL, V34, P2612, DOI 10.1016/j.eswa.2007.05.001; Chang BR, 2008, P IEEE 8 INT C INT S, V1, P3; Chang BR, 2007, LECT NOTES COMPUT SC, V4493, P357; Chang BR, 2009, APPL SOFT COMPUT, V9, P1177, DOI 10.1016/j.asoc.2009.03.003; Chang BR, 2007, INT J INNOV COMPUT I, V3, P1251; Chang BR, 2010, EXPERT SYST APPL, V37, P2439, DOI 10.1016/j.eswa.2009.07.036; Chang BR, 2005, INT J FUZZY SYST, V7, P110; Chang C, 2010, TRIBOL INT, P1; CHANG JL, 2010, CHIN CONTR DEC C, P179; Changqing G, 2007, IEEE INT S MICR ANT, P1134; Changsheng G, 2009, J BIOSCI BIOENG, P98; Changsheng G, 2009, REC ADV BIOL BIOMED, P93; Chen C, 2002, METHODOL APPL, V12, P567; Chen CL, 2008, IEEE INT C NETW SENS, P1599; Chen Hui, 2005, Control and Decision, V20; Chen H., 2004, P INT C COMM CIRC SY, V2, P1108; Chen J, 2010, 6 INT C NAT COMP, V8, P3887; Chen L, 2009, AUTOM INSTRUM, V1, P5; Chen L, 2010, INT C FUT INF TECHN, V3, P419; Chen M, 2007, 2007 SECOND INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P17, DOI 10.1109/BICTA.2007.4806409; Chen P, 2007, J POWER ENG, V27, P569; Chen Q, 2010, 2 INT C COMP INT NAT, P252; Chen RC, 2010, LECT NOTES ARTIF INT, V5990, P339; Chen W, 2008, LECT NOTES ARTIF INT, V5027, P388; Chen X, 2005, NEURAL INFORM PROCES, V9, P1; Cheng Z, 2010, 29 CHIN CONTR C, P5134; Chi Y, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P6187; Chi Y, 2009, COMMUN TECHNOL, V42, P204; Chiang CH, 2008, IEEE C EVOL COMPUTAT, P1356; Chou YH, 2010, IEEE SYS MAN CYBERN, P3211; Chung CY, 2011, IEEE T POWER SYST, V26, P847, DOI 10.1109/TPWRS.2010.2059716; Cleaver R, 2009, CICA: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN CONTROL AND AUTOMATION, P62; Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692; Coelho L, 2008, QUANTUM INSPIRED INT, V121, P1, DOI 10.1007/978-3-540-78532-3_1; Coelho LD, 2008, IEEE T MAGN, V44, P1074, DOI 10.1109/TMAG.2007.916032; Coelho LD, 2008, ENERG CONVERS MANAGE, V49, P3080, DOI 10.1016/j.enconman.2008.06.009; Coelho LD, 2008, CHAOS SOLITON FRACT, V37, P1409, DOI 10.1016/j.chaos.2006.10.028; Coelho L.D.S., 2008, IEEE INT C SYST MAN, P3708; Coelho LS, 2007, IET SCI MEAS TECHNOL, V1, P290, DOI 10.1049/iet-smt:20060124; da Cruz A, 2006, P EV COMP IEEE C VAN, P2630; da Cruz A, 2005, LNCS, V3562, P181; da Cruz A, 2008, QUANTUM INSPIRED INT, V121, P115; da Cruz AVA, 2004, LECT NOTES COMPUT SC, V3316, P212; da Cruz AVA, 2007, STUD COMPUT INTELL, V75, P19; Dai H, 2008, P 1 INT C INT NETW I, P35; Dai J, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 3, PROCEEDINGS, P408, DOI 10.1109/IITA.2009.454; Dalla Chiara Maria Luisa, 2007, Natural Computing, V6, P113, DOI 10.1007/s11047-006-9020-x; Dawes RL, 1993, RETHINKING NEURAL NE; Dawes RL, 1992, INT JOINT C NEUR NET, V1, P133; de Oliveira LD, 2006, ISSSTA 06 IEEE INT S, P133; Dicaro G., 2004, THESIS U LIBRE BRUXE; Ding LL, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P296, DOI 10.1109/ICNC.2008.578; Dirac P A M, 1958, PRINCIPLES QUANTUM M, V4th; Dong J, 2009, 9 INT C EL MEAS INST; Draa A, 2010, INT ARAB J INF TECHN, V7, P21; Draa A, 2004, INT C COMP INT ICCI, P408; Du J, 2009, 2 INT C POW EL INT T, V1, P133; Du ZY, 2010, 2010 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-5, P3335; Duan HB, 2009, ADV INTELL SOFT COMP, V61, P269; Duan Q, 2010, 2 INT AS C INF CONTR, P109; Durr C, 2005, QUANTUM ALGORITHM FI; EVERETT H, 1957, REV MOD PHYS, V29, P454, DOI 10.1103/RevModPhys.29.454; Ezhov AA, 2000, INFORM SCIENCES, V128, P271, DOI 10.1016/S0020-0255(00)00057-8; Ezhov AA, 2000, STUD FUZZ SOFT COMP, V45, P213; Fan K, 2007, LECT NOTES COMPUT SC, V4448, P189; Fan K, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P1983; Fan K, 2008, LECT NOTES COMPUT SC, V4974, P133; Fan K, 2008, STUD COMP INTELL, V100, P89; Fang W, 2006, 6 WORLD C INT CONTR, P3396; Fang W, 2006, LECT NOTES COMPUT SC, V4222, P637; Fang W, 2009, NEW MATH NAT COMPUT, V05, P487; Fang Wei, 2008, Systems Engineering and Electronics, V30; Fang W, 2006, IIH-MSP: 2006 International Conference on Intelligent Information Hiding and Multimedia Signal Processing, Proceedings, P240; Fang W, 2010, ACTA PHYS SIN-CH ED, V59, P3686; Fang W, 2006, 1 INT C INN COMP INF, P615; Feng B, 2004, IEEE C CYB INT SYST, V1, P291; Feng B, 2008, COMPUTER ENG DESIGN, V29, P3429; Feng B, 2004, 8 CONTR AUT ROB VIS, V2, P1454; Feng B, 2009, COMPUTER APPL SOFTWA, V26, P50; Feng X, 2008, INT C COMP SCI SOFTW, V1, P333; Feng XY, 2006, Computational Methods, Pts 1 and 2, P1363, DOI 10.1007/978-1-4020-3953-9_55; Feynman R. P., 1965, QUANTUM MECH PATH IN; Fu LH, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL II, PROCEEDINGS, P477, DOI 10.1109/AICI.2009.60; Futuyma DJ, 1998, EVOLUTIONARY BIOL, V3rd; Gao F, 2009, CHAOS SOLITON FRACT, V42, P2450, DOI 10.1016/j.chaos.2009.03.119; Gao Hui, 2008, Control and Decision, V23; Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931; Gao H, 2007, IEEE INT S INT SIGN, P1; Gao H, 2006, 6 WORLD C INT CONTR, V1, P3638; Gao HY, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL II, PROCEEDINGS, P132, DOI 10.1109/AICI.2009.469; Gao JQ, 2011, APPL MATH COMPUT, V217, P4754, DOI 10.1016/j.amc.2010.11.030; Gao K, 2010, 2010 IEEE 10TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS (ICSP2010), VOLS I-III, P1068; Gao Y, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT, INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL 3, PROCEEDINGS, P371, DOI 10.1109/ICIII.2009.398; Garavaglia SB, 2002, P INT JOINT C NEUR N, V2, P1779; Geravanchizadeh M, 2010, 4 INT S COMM CONTR S, P1; Ghavami B, 2008, 11TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN - ARCHITECTURES, METHODS AND TOOLS : DSD 2008, PROCEEDINGS, P274, DOI 10.1109/DSD.2008.89; Gong C, 2009, P AS PAC POW EN ENG, P1; Gou XM, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P1285; Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237866; Gu J, 2008, P 17 IFAC WORLD C, P63; Gu J, 2008, P 7 WORLD C INT CONT, P4148; Gu JW, 2010, COMPUT OPER RES, V37, P927, DOI 10.1016/j.cor.2009.07.002; Gu JW, 2009, J MATH ANAL APPL, V355, P63, DOI 10.1016/j.jmaa.2008.12.065; Guowei C, 2010, INT C COMP MECH CONT, V4, P396; Haiyan G, 2005, J SW U SCI TECHNOL, V20, P1; Hamed HNA, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P695, DOI 10.1109/SoCPaR.2009.139; Han K, 2006, P 2006 IEEE C EV COM, P2622; Han K, 2003, THESIS KORA ADV I SC; Han K, 2002, P 2002 FIRA ROB WORL, P243; Han KH, 2003, LECT NOTES COMPUT SC, V2723, P427; Han KH, 2004, IEEE T EVOLUT COMPUT, V8, P156, DOI 10.1109/TEVC.2004.823467; Han KH, 2002, IEEE T EVOLUT COMPUT, V6, P580, DOI 10.1109/TEVC.2002.804320; Han KH, 2000, IEEE C EVOL COMPUTAT, P1354; Han KH, 2001, IEEE C EVOL COMPUTAT, P1422; Han KH, 2003, IEEE C EVOL COMPUTAT, P178; Han Kuk-Hyun, 2001, P 2001 INT C ART INT, V2, P727; Hannachi MS, 2007, INT J COMPUT INTELL, V2, P242; Hannachi MS, 2007, ICCC 2007: 5TH IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL CYBERNETICS, PROCEEDINGS, P39, DOI 10.1109/ICCCYB.2007.4402017; Hannachi MS, 2007, ISCIII '07: 3rd International Symposium on Computational Intelligence and Intelligent Informatics, Proceedings, P89; Hannachi MS, 2005, INT S COMP INT INT I, P14; Haykin S, 1999, NEURAL NETWORK COMPR; He J, 2010, INT C E BUS E GOV, P2599; He Z, 2009, AS PAC POW EN ENG C, P1; Hey T, 1999, COMPUT CONTROL ENG J, V10, P105, DOI 10.1049/cce:19990303; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirvensalo M., 2004, QUANTUM COMPUTING; Holland J.H., 1975, ADAPTATION NATURAL A, VOriginal; Horn D, 2003, BIOINFORMATICS, V19, P1110, DOI 10.1093/bioinformatics/btg053; Horn D., 2002, Physical Review Letters, V88, DOI 10.1103/PhysRevLett.88.018702; Hossain MA, 2009, 12 IKNT C COMP INF T, P13; Hossain MA, 2010, 13 INT C COMP INF TE, P21; Hou Y, 2007, NEURAL NETWORKS; Hou Y, 2010, INT C SYST SCI ENG D, V2, P110; Hu FJ, 2009, IEEE DECIS CONTR P, P5097, DOI 10.1109/CDC.2009.5399632; Hu SY, 2004, LECT NOTES COMPUT SC, V3174, P669; Huang CC, 2009, EXPERT SYST APPL, V36, P9580, DOI 10.1016/j.eswa.2008.07.063; Huang J, 2006, J COMPUT APPL, V12, P3015; Huang XS, 2009, 2009 INTERNATIONAL ASIA SYMPOSIUM ON INTELLIGENT INTERACTION AND AFFECTIVE COMPUTING, P67, DOI 10.1109/ASIA.2009.15; Huang Y, 2007, INT C COMP INT SEC W, P208; Huang Y, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P701; Huang YR, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 6, PROCEEDINGS, P401, DOI 10.1109/ICNC.2008.458; Huang Z, 2009, IEEE C IND EL APPL, P1560; Igelnik B, 2001, IEEE T NEURAL NETWOR, V12, P236, DOI 10.1109/72.914521; Igelnik B, 1999, IEEE T NEURAL NETWOR, V10, P19, DOI 10.1109/72.737490; Igelnik B, 1999, P 2 INT C INT PROC M, V1, P367; IGELNIK B, 1995, IEEE T NEURAL NETWOR, V6, P1320, DOI 10.1109/72.471375; Izadinia H, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P724, DOI 10.1109/SoCPaR.2009.146; Jalilzadeh S, 2009, 6 INT C EL ENG EL CO, P28; Jang JS, 2004, PATTERN RECOGN LETT, V25, P1857, DOI 10.1016/j.patrec.2004.08.013; Jang JS, 2004, IEEE C EVOL COMPUTAT, P2100; Jang JS, 2003, LECT NOTES COMPUT SC, V2724, P2147; Jankowski S, 1996, IEEE T NEURAL NETWOR, V7, P1491, DOI 10.1109/72.548176; Jeong YW, 2010, IEEE T POWER SYST, V25, P1486, DOI 10.1109/TPWRS.2010.2042472; Jeong YW, 2009, ELECTR POW COMPO SYS, V37, P770, DOI 10.1080/15325000902762331; Jeong Y.W., 2009, 15 INT C INT SYST AP, P1; Jiao B, 2010, INT C INT COMP TECHN, P531; Jiao B, 2009, IEEE INT CONF CON AU, P1235, DOI 10.1109/ICCA.2009.5410616; Jiao L, 2005, IEE EITN C NEUR NETW, P461; Jiao LC, 2008, IEEE T SYST MAN CY B, V38, P1234, DOI 10.1109/TSMCB.2008.927271; KAK S, 1995, INFORM SCIENCES, V83, P143, DOI 10.1016/0020-0255(94)00095-S; Karayiannis NB, 2006, CLIN NEUROPHYSIOL, V117, P1585, DOI 10.1016/j.clinph.2005.12.030; Karayiannis NB, 2005, P 30 IEEE C LOC COMP, P1; Karayiannis NB, 2006, SOFT COMPUT, V10, P382, DOI 10.1007/s00500-005-0498-4; Karayiannis NB, 2001, PATTERN RECOGN, P301, DOI 10.1142/9789812386533_0011; Karayiannis NB, 2004, P ANN INT IEEE EMBS, V26, P423; Karayiannis NB, 2006, IEEE T NEURAL NETWOR, V17, P1222, DOI 10.1109/TNN.2006.877538; Karayiannis NB, 1994, IEEE INT C NEUR NETW, V3, P127; Kasabov Nikola, 2009, Natural Computing, V8, P199, DOI 10.1007/s11047-008-9066-z; Kasabov N, 2007, STUD COMPUT INTELL, V63, P193; Kasabov N, 2010, STUD COMPUT INTELL, V263, P415; Kasabov N, 2007, EVOLVING CONNECTIONI, V2nd; Kasabov N, 2010, NEURAL NETWORKS, V23, P16, DOI 10.1016/j.neunet.2009.08.010; Kaye P., 2007, INTRO QUANTUM COMPUT; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Khorsand AR, 2005, IEEE SYS MAN CYBERN, P3055; Kim J, 2011, IEEE T EVOLUT COMPUT, V16, P20; Kim SS, 2010, IEEE T SYST MAN CY B, V40, P91, DOI 10.1109/TSMCB.2009.2015671; Kim Y, 2006, P 2006 IEEE C EV COM, P2601; Kim YH, 2009, IEEE C EVOL COMPUTAT, P1185, DOI 10.1109/CEC.2009.4983080; Kima K, 2003, IEICE T INF SYST, VE86-D, P645; Kinjo M, 2003, LECT NOTES COMPUT SC, V2714, P951; Kinjo M, 2005, PHYS REV A, V72, DOI 10.1103/PhysRevA.72.052328; Kinjo M, 2008, LECT NOTES COMPUT SC, V4985, P730; Kinjo M, 2006, IEEE IJCNN, P203; Klusch M, 2004, LNCS, V2969; Kong XH, 2007, LECT NOTES COMPUT SC, V4487, P278; Kouda N, 2002, NEURAL PROCESS LETT, V16, P67, DOI 10.1023/A:1019708909383; Kouda N, 2002, SICE ANN C, V2, P805; Kouda N, 2003, LECT NOTES ARTIF INT, V2774, P304; Kouda N, 2005, NEURAL PROCESS LETT, V22, P277, DOI 10.1007/s11063-005-8337-2; Kouda N, 2005, NEURAL COMPUT APPL, V14, P114, DOI 10.1007/S00521-004-0446-8; Kouda N., 2004, Systems and Computers in Japan, V35, DOI 10.1002/scj.10342; Kreinovich V, 2008, ANN M N AM FUZZ INF, P1; Kumar N, 2004, NEURAL PROCESS LETT, V20, P11, DOI 10.1023/B:NEPL.0000039429.89321.07; Lau TW, 2009, IEEE T POWER SYST, V24, P1503, DOI 10.1109/TPWRS.2009.2021220; Layeb A., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860); Layeb A, 2009, ADV COMPUT SCI ENG, V6, P942, DOI 10.1007/978-3-540-89985-3_139; Layeb A, 2008, P IEEE 2 AS INT C MO, P873; Lebensztajn L, 2010, 14 BIENN IEEE C EL F, P1; Lee CD, 2004, IEEE SYS MAN CYBERN, P3291; Lee DL, 2001, IEEE T NEURAL NETWOR, V12, P1260, DOI 10.1109/72.950156; Lee JC, 2011, INT J ELEC POWER, V33, P189, DOI 10.1016/j.ijepes.2010.08.014; Lei B, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P546; Lei XJ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P692, DOI 10.1109/ICNC.2008.822; Li B, 2003, IEEE INT C NEUR NET, V1, P399, DOI 10.1109/ICNNSP.2003.1279293; Li BB, 2007, IEEE T SYST MAN CY B, V37, P576, DOI 10.1109/TSMCB.2006.887946; Li CY, 2010, LECT N BIOINFORMAT, V6330, P358, DOI 10.1007/978-3-642-15615-1_43; Li CY, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P92, DOI 10.1109/DCABES.2010.26; Li F, 2005, LECT NOTES COMPUT SC, V3498, P338; Li F, 2002, P IEEE INT C SIGN PR, V2, P1267; Li F, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P539; Li F, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P867; Li F, 2009, AS PAC C COMP INT IN, V2, P389; Li F, 2006, IEEE IJCNN, P2967; Li F, 2004, P INT C SIGN PROC, V2, P1538; Li F, 2010, INT C INT CONTR INF, P439; Li F, 2008, P 9 INT C SIGN PROC, P1951; Li H, 2010, INT C INF SCI MAN EN, V1, P567; Li H, 2010, 6 INT C WICOM, P1; Li N, 2005, INT GEOSCI REMOTE SE, P4323; Li P, 2010, 6 INT C NAT COMP, P2994; Li P, 2010, 6 INT C NAT COMP, V6, P2989; Li Panchi, 2008, J SYST ENG ELECTRON, V19, P167; Li PC, 2008, NEUROCOMPUTING, V72, P581, DOI 10.1016/j.neucom.2007.11.017; Li R, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P327; Li S, 2010, 5 INT C CRIT INFR, P1; Li SS, 2006, LECT NOTES COMPUT SC, V3971, P551; Li SY, 2011, IEEE T SYST MAN CY B, V41, P1015, DOI 10.1109/TSMCB.2010.2103056; Li SY, 2007, ADV SOFT COMP, V40, P355; Li SY, 2008, J HARBIN I TECHNOL, V38, P1216; Li W, 2000, ENTANGLED NEURAL NET; Li W, 2010, IEEE 5 INT C BIOINSP, P313; Li W, 2010, INT J CHEM ENG, P1; Li W, 2010, 14 BIENN IEEE C EL F, P1, DOI 10.1109/ICELMACH.2010.5608324; Li X, 2008, SECOND INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING: WGEC 2008, PROCEEDINGS, P480, DOI 10.1109/WGEC.2008.76; Li Y, 2010, INT C COPMP APPL SYS, V13; Li Y, 2005, J ELECT CHINA, V22, P371, DOI 10.1007/BF02687924; Li Y, 2004, INT C MACH LEARN CYB, V7, P4062; Li Y, 2004, IEEE SYS MAN CYBERN, P3301; Li Y., 2004, P INT C SIGN PROC IC, V2, P1550; Li Y, 2003, INT C MACH LEARN CYB, V3, P1780; Li YS, 2010, IFERA AT CHINA 2010 FAMILY BUSINESS FORUM: OPPORTUNITIES AND CHALLENGES OF FAMILY BUSINESS, P1; Li YY, 2009, IEEE SYS MAN CYBERN, P1496, DOI 10.1109/ICSMC.2009.5346265; Li YY, 2005, LECT NOTES COMPUT SC, V3627, P304; Li YY, 2007, LECT NOTES COMPUT SC, V4426, P672; Li Z, 2007, P 2007 INT C WAV AN, V3, P1045; Li ZY, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P672, DOI 10.1109/ICNC.2008.785; Li ZY, 2007, COMM COM INF SC, V2, P245; Li ZY, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P908; Li ZY, 2009, COMPUT MATH APPL, V57, P1843, DOI 10.1016/j.camwa.2008.10.046; Liao G, 2010, INT C POW SYST TECHN, P1; Liao GC, 2011, ENERGY, V36, P1018, DOI 10.1016/j.energy.2010.12.006; Liao R, 2010, 2 INT C INT HUM MACH, V2, P192; Lin CJ, 2004, IEEE IJCNN, P3263; Lin CJ, 2007, NEUROCOMPUTING, V70, P2502, DOI 10.1016/j.neucom.2006.08.008; Lin H, 2010, WASE INT C INF ENG, V4, P189; Lin J, 2005, INF REUS INT C 2005, P380; Litvintseva L, 2006, WORLD AUT C, P1; Litvintseva LV, 2009, J COMPUT SYS SC INT+, V48, P946, DOI 10.1134/S1064230709060112; Litvintseva LV, 2006, J COMPUT SYS SC INT+, V45, P744, DOI 10.1134/S106423070605008X; Liu C, 2010, ITN C COMP APPL SYST, V7; Liu CH, 2010, IFIP ADV INF COMM TE, V317, P1; Liu F, 2003, ACTA ELECT SINICA, V31, P2066; Liu F, 2009, 2 AS PAC C SYNTH AP, P809, DOI 10.1109/APSAR.2009.5374179; Liu F, 2006, IEICE T FUND ELECTR, VE89A, P648, DOI 10.1093/ietfec/e89-a.3.648; Liu FJ, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P4452, DOI 10.1109/WCICA.2010.5554072; Liu HW, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 2, PROCEEDINGS, P477, DOI 10.1109/ISCID.2009.265; Liu HW, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P486; Liu HW, 2009, PROCEEDINGS OF 2009 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS TECHNOLOGY AND APPLICATIONS, P652; Liu HY, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P531, DOI 10.1109/IITA.Workshops.2008.56; Liu J, 2006, IEEE INT C INF ACQ A, P1219; Liu J, 2006, IEEE INT C GRAN COMP, P453; Liu J, 2006, LECT NOTES COMPUT SC, V4115, P130; Liu J, 2006, LECT NOTES ARTIF INT, V4203, P77; Liu J, 2006, LECT NOTES COMPUT SC, V4233, P1042; Liu J, 2006, LECT NOTES COMPUT SC, V4221, P959; Liu J., 2005, 17 IEEE INT C TOOLS, P240; Liu K, 2010, 2010 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-5, P2941; Liu K, 2010, IEEE 5 INT C BIOINSP, P766; Liu L, 2009, ENZYME MICROB TECH, V44, P24, DOI 10.1016/j.enzmictec.2008.09.015; Liu L., 2009, P IEEE INT C COMM IC, P1, DOI DOI 10.1109/ICC.2009.5199019; Liu L, 2009, 5 INT C WIR COMM NET, P1; Liu L, 2009, J BIOSCI BIOENG, V108, pS126, DOI 10.1016/j.jbiosc.2009.08.368; Liu M, 2006, P IEEE WUH CIT CHIN, P1; Liu M, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-5, P2023, DOI 10.1109/ROBIO.2007.4522478; Liu N, 2009, 4 IEEE C IND EL APPL, P3732; Liu S, 2009, LECT NOTES ARTIF INT, V5855, P69; Liu Y, 2008, SECOND INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING: WGEC 2008, PROCEEDINGS, P451, DOI 10.1109/WGEC.2008.108; Liu Z, 2007, 3 INT C NAT COMP, V3, P137; Liu Z, 2010, 3 INT S INT INF TECH, P212; Liu Z, 2007, C IND ELECT APPL, P476; Liu ZG, 2009, ELE COM ENG, P422; Loo CK, 2004, OPEN SYST INF DYN, V11, P277, DOI 10.1023/B:OPSY.0000047571.17774.8d; Lu KZ, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P8968; Lu KZ, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P4677; Lu KZ, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P5653; Lu KZ, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 1, PROCEEDINGS, P21, DOI 10.1109/FSKD.2008.369; Lu P, 2010, 2 WRI GLOB C INT SYS, V1, P302; Lu S., 2008, PAC AS WORKSH COMP I, P109; Lu SF, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P593, DOI 10.1109/KAM.2008.19; Lu Y, 2007, INT C WAV AN PATT RE, P484; Luitel B., 2008, IEEE SWARM INT S, P1; Luitel B, 2009, IEEE IJCNN, P3492; Luitel B, 2010, 1 C INN SMART GRID T, P1; Luitel B, 2010, ENG APPL ARTIF INTEL, V23, P635, DOI 10.1016/j.engappai.2010.01.022; Lukac M, 2009, ISMVL: 2009 39TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIPLE-VALUED LOGIC, P92; Luo J, 2010, 8 IEEE INT C CONTR A, P1169; Luo W, 2010, IEEE INT C SOFTW ENG, P37; Luo W, 2010, INT C INT COMP INT S, P854; Luo Y, 2009, IRMMW2009, P1; Luo YX, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL I, PROCEEDINGS, P535, DOI 10.1109/AICI.2009.58; Luo YX, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON LOGISTICS SYSTEMS AND INTELLIGENT MANAGEMENT, VOLS 1-3, P1861; Luo Z, 2008, IEEE C CYB INT SYST, P324; Luo ZY, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, P278, DOI 10.1109/ISCID.2008.93; Lv Y, 2009, 5 INT C NAT COMP, V4, P336; Lv Y. J., 2007, P IEEE INT C GRAN CO, P728; Lv YB, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS, P460, DOI 10.1109/ICNC.2008.22; Lv YB, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 4, P279, DOI 10.1109/ICCSIT.2009.5234580; Ma RH, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P442; Ma RH, 2008, IEEE INT C NETW SENS, P1284; MA Y, 2009, 2 INT WORKSH KNOWL D, P825, DOI 10.1109/WKDD.2009.145; Ma Y., 2009, IEEE WORLD NONGR CON, P1; Maeda M, 2005, LECT NOTES COMPUT SC, V3610, P283; Mahajan R, 2011, 13 INT C ADV COMM TE, P1353; Mahdabi P, 2009, P 11 ANN C GEN EV CO, P1807, DOI 10.1145/1569901.1570172; MATSUDA S, 1993, IEEE IJCNN, P1610; Matsui N, 1999, P 7 LASTED INT C APP; Matsui N, 2000, ELECTRON COMM JPN 3, V83, P67, DOI 10.1002/(SICI)1520-6440(200010)83:10<67::AID-ECJC8>3.0.CO;2-H; Matsui N, 2000, IEEE IJCNN, P247; Matsui N, 1998, IEICE J, VJ81-A, P1687; MChen CY, 2007, 2 ITN C INN COMP INF, P269, DOI 10.1109/ICICIC.2007.191; Melo M, 2008, INT ARCH PHOTOGRAMME; Meng K, 2010, IEEE T POWER SYST, V25, P215, DOI 10.1109/TPWRS.2009.2030359; Meng K, 2010, IEEE T POWER SYST, V25, P1350, DOI 10.1109/TPWRS.2010.2040491; Meng Q, 2010, 2 INT C SIGN PROC SY, V2; Meng XP, 2007, LECT NOTES COMPUT SC, V4688, P28; Menneer T, 1998, THESIS U EXETER UK; Meshoul S, 2010, IEEE C EV COMP, P1, DOI 10.1109/CEC.2010.5585954; Meshoul S, 2005, LECT NOTES ARTIF INT, V3808, P260; Meshoul S, 2005, LECT NOTES ARTIF INT, V3808, P190; Mikki S, 2005, P IEEE ANT PROP SO A, V2A, P45; Mikki S, 2006, IEEE AUT PROP SOC IN, P3285; Mikki SM, 2006, IEEE T ANTENN PROPAG, V54, P2764, DOI 10.1109/TAP.2006.882165; Mikki SM, 2007, IEEE T ANTENN PROPAG, V55, P1325, DOI 10.1109/TAP.2007.895625; Mishra D, 2006, LECT NOTES COMPUT SC, V4232, P608; Mitrpanont JL, 2002, P 9 INT C NEUR INF P, V1, P462, DOI 10.1109/ICONIP.2002.1202213; Mo Z, 2010, INT C MEAS TECHN MEC, V2, P964; Mo Z, 2010, 6 INT C NAT COMP, V5, P2429; Moore M, 1995, TECHNICAL REPORT; Moore P, 2005, 2005 NASA/DOD CONFERENCE ON EVOLVABLE HARDWARE (EH-2005), PROCEEDINGS, P97, DOI 10.1109/EH.2005.28; Mori K, 2006, IEEE IJCNN, P224; Muezzinoglu MK, 2003, IEEE T NEURAL NETWOR, V14, P891, DOI 10.1109/TNN.2003.813844; Nakamiya Y, 2006, JPN J APPL PHYS 1, V45, P8030, DOI 10.1143/JJAP.45.8030; Nan DX, 2008, Proceedings of the 27th Chinese Control Conference, Vol 6, P654; Nan DX, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P769; Narayanan A., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.785552; Narayanan A, 2000, INFORM SCIENCES, V128, P231, DOI 10.1016/S0020-0255(00)00055-4; Narayanan A, 1996, IEEE C EVOL COMPUTAT, P61; Nasios N, 2005, P IEEE INT C IM PROC, V3, P820; Neto JXV, 2011, ENERG CONVERS MANAGE, V52, P8, DOI 10.1016/j.enconman.2010.05.023; Ni H, 2010, 6 INT C NAT COMP, V5, P2239; Niansheng C, 2007, P INT C NETW PAR COM, P683; Nicolau AD, 2011, PROG NUCL ENERG, V53, P86, DOI 10.1016/j.pnucene.2010.08.004; Nie R, 2010, 6 ITN C NAT COMP, V5, P2556; NITTA T, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P269, DOI 10.1109/ICNN.1994.374173; NITTA T, 1993, IEEE IJCNN, P1649; Niu Q, 2009, J UNIVERS COMPUT SCI, V15, P765; Nodehi A, 2009, 14 INT CSI COMP C, P564; Nowotniak R, 2010, ARXIV10074221V2CSNE; Oliveira W., 2008, 10 BRAZ S NEUR NETW, P147; Omkar SN, 2009, EXPERT SYST APPL, V36, P11312, DOI 10.1016/j.eswa.2009.03.006; Omran MGH, 2009, CHAOS SOLITON FRACT, V42, P662, DOI 10.1016/j.chaos.2009.01.039; Pan G, 2007, 3 INT C NAT COMP HAI, V2, P606; Panella M, 2009, IEEE T FUZZY SYST, V17, P698, DOI 10.1109/TFUZZ.2008.928603; Pant M., 2008, P 10 ANN C GEN EV CO, P87, DOI 10.1145/1389095.1389108; Pant Millie, 2009, International Journal of Recent Trends in Engineering, V1; Pao Y.H., 1989, ADAPTIVE PATTERN REC; Park C.-S., 2010, P IEEE RSJ INT C INT, P160; Park IW, 2010, IEEE C EV COMP, P1, DOI 10.1109/CEC.2010.5586053; Patvardhan C, 2007, LECT NOTES COMPUT SC, V4815, P252; Peng SH, 2009, 2009 INTERNATIONAL ASIA SYMPOSIUM ON INTELLIGENT INTERACTION AND AFFECTIVE COMPUTING, P41, DOI 10.1109/ASIA.2009.20; Peng X, 2008, PAC AS WORKSH COMP I, V1, P342; Perus M, 2000, APPL MATH LETT, V13, P31, DOI 10.1016/S0893-9659(00)00092-6; Platel MD, 2009, IEEE T EVOLUT COMPUT, V13, P1218, DOI 10.1109/TEVC.2008.2003010; Platel MD, 2007, IEEE C EVOL COMPUTAT, P423; Popa R, 2010, 2010 3RD INTERNATIONAL SYMPOSIUM ON ELECTRICAL AND ELECTRONICS ENGINEERING (ISEEE), P64; Purushothaman G, 1995, INTELLIGENT ENG SYST, V5, P253; Purushothaman G, 2006, J APPL FUNCT ANAL, V1, P9; Purushothaman G, 1998, INT J SMART ENG SYST, V1, P163; Qian J, 2010, P 2 INT C COMP INT N, V1, P41; Qin C, 2008, IEEE C CYB INT SYST, P1160; Qin CY, 2007, LECT N BIOINFORMAT, V4689, P380, DOI 10.1007/978-3-540-74771-0_43; Qu H, 2008, INT SEMIN BUS INF MA, V2, P23; Qu HJ, 2009, FIRST INTERNATIONAL WORKSHOP ON DATABASE TECHNOLOGY AND APPLICATIONS, PROCEEDINGS, P468, DOI 10.1109/DBTA.2009.78; Radha T, 2010, INT C NETW SENS CONT, P38; Rakovic D, 2002, 6 SEM NEUR NETW APPL, P171; Resconi G, 2008, APPL SOFT COMPUT, V8, P1164, DOI 10.1016/j.asoc.2007.02.018; Ricks B, 2004, ADV NEUR IN, V16, P1019; Rigatos GG, 2002, IEEE T FUZZY SYST, V10, P451, DOI 10.1109/TFUZZ.2002.800690; Rigatos GG, 2006, FUZZY SET SYST, V157, P1797, DOI 10.1016/j.fss.2006.02.012; Rylander B, 2001, P GEN EV COMP C GECC, P1005; Sabat SL, 2010, MICROELECTRON RELIAB, V50, P199, DOI 10.1016/j.microrel.2009.10.005; Sabat SL, 2009, MICROELECTRON RELIAB, V49, P660, DOI 10.1016/j.microrel.2009.03.005; Babu GSS, 2008, IET GENER TRANSM DIS, V2, P22, DOI 10.1049/iet-gtd:20060495; Sarangi A, 2011, EXPERT SYST APPL, V38, P10966, DOI 10.1016/j.eswa.2011.02.140; Sato S, 2003, JPN J APPL PHYS 1, V42, P7169, DOI 10.1143/JJAP.42.7169; Schliebs S, 2010, IEEE INT JOINT C NEU, P1; Schliebs S, 2009, NEURAL NETWORKS, V22, P623, DOI 10.1016/j.neunet.2009.06.038; Schliebs S, 2009, LECT NOTES COMPUT SC, V5506, P1229, DOI 10.1007/978-3-642-02490-0_149; Schliebs S, 2009, IEEE INT JOINT C NEU, P2833; Seising R, 2006, P ANN M N AM FUZZ IN, P414; Seising R, 2008, P ANN M N AM FUZZ IN, P1; Shang RH, 2010, CHINESE PHYS LETT, V27, DOI 10.1088/0256-307X/27/1/010308; Shayeghi H, 2010, ENERG CONVERS MANAGE, V51, P2299, DOI 10.1016/j.enconman.2010.04.002; Shen CY, 2008, SENSOR ACTUAT A-PHYS, V147, P464, DOI 10.1016/j.sna.2008.05.025; Shen SH, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P7893; Shen SH, 2006, LECT NOTES COMPUT SC, V3907, P525; Shi W, 2010, INT C MICR MILL WAV, P1386; Shi Y, 2010, 1 ITN C PERV COMP SI, P483; Shi Z, 2009, INF ENG COMP SCI 200, P1; Shu W, 2008, COMPUTER ENG, V7, P191; Shuyan W, 2008, INT CONF BIOMED, P306, DOI 10.1109/BMEI.2008.19; Sienko W, 2004, INT J COMPUT ANTICIP, V14, P224; Sienko W, 2004, LECT NOTES ARTIF INT, V3070, P266; Sienko W, 2003, ADV SOFT COMP, P268; Sienko W, 2002, 28 ANN C IEEE IND EL, V4, P3201; Sierocinski T, 2008, STUD COMPUT INTELL, V129, P431; Sierocinski T, 2008, 1 INT S APPL SCI BIO, P1; Storn R., 1996, BIENN C N AM FUZZ IN, P519, DOI DOI 10.1109/NAFIPS.1996.534789; Su DB, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND INFORMATION SYSTEMS, P399, DOI 10.1109/WNIS.2009.74; Su HJ, 2011, EXPERT SYST APPL, V38, P6447, DOI 10.1016/j.eswa.2010.11.107; Su HJ, 2010, EXPERT SYST APPL, V37, P1216, DOI 10.1016/j.eswa.2009.06.029; Su HJ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 1, PROCEEDINGS, P341, DOI 10.1109/ICNC.2008.607; Su XP, 2009, WISM: 2009 INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND MINING, PROCEEDINGS, P475, DOI 10.1109/WISM.2009.102; Sun C, 2010, ENERG CONVERS MANAGE, V51, P561; Sun CF, 2010, EXPERT SYST APPL, V37, P4232, DOI 10.1016/j.eswa.2009.11.079; Sun J, 2006, LECT NOTES COMPUT SC, V4247, P497; Sun J, 2007, LECT NOTES COMPUT SC, V4431, P394; Sun J, 2011, ENG APPL ARTIF INTEL, V24, P123, DOI 10.1016/j.engappai.2010.08.001; Sun J., 2004, P IEEE C CYB INT SYS, P111; Sun J, 2007, LECT NOTES COMPUT SC, V4431, P376; Sun J, 2010, IEEE T CIRCUITS-II, V57, P141, DOI 10.1109/TCSII.2009.2038514; Sun J, 2006, LECT NOTES ARTIF INT, V4114, P1158; Sun J, 2007, LECT NOTES COMPUT SC, V4487, P294; Sun J, 2009, ENERG CONVERS MANAGE, V50, P2967, DOI 10.1016/j.enconman.2009.07.015; Sun J, 2006, LECT NOTES ARTIF INT, V4259, P736; Sun J, 2006, LECT NOTES COMPUT SC, V3993, P847; Sun J, 2006, LECT NOTES COMPUT SC, V4233, P1156; Sun J, 2011, EVOLUT COMPUT, DOI [10.1162/EVCO-a-00049, DOI 10.1162/EVCO-A-00049]; Sun J, 2004, IEEE C EVOL COMPUTAT, P325; Sun Jie, 2009, 2009 Second International Workshop on Knowledge Discovery and Data Mining. WKDD 2009, DOI 10.1109/WKDD.2009.193; Sun J, 2007, INT J COMPUT MATH, V84, P261, DOI 10.1080/00207160601170254; Sun J, 2012, INFORM SCIENCES, V182, P93, DOI 10.1016/j.ins.2010.11.014; Sun J, 2006, LECT NOTES ARTIF INT, V4099, P737; Sun J, 2005, LECT NOTES COMPUT SC, V3612, P543; Sun J, 2008, P AMER CONTR CONF, P2603; Sun J, 2006, LECT NOTES COMPUT SC, V4247, P261; Sun J, 2006, LECT NOTES ARTIF INT, V4093, P340; Takai M, 1998, ANN S P SZCE KANS A, VJ81-A, P154; Talbi H., 2004, Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications (IEEE Cat. No.04EX852), DOI 10.1109/ICTTA.2004.1307798; Talbi H, 2006, INT ARAB J INF TECHN, V3, P9; Talbi H, 2004, LECT NOTES COMPUT SC, V3211, P147; LI X, 2008, INT C INTELL COMPUT, V1, P96; Talbi H, 2004, P IEEE INT C IND TEC, V3, P1192; Talbi H., 2007, INT J MATH PHYS ENG, V1, P109; Tan JWJ, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P1759; Tan Q, 2008, 9 INT C SIGN PROC, P2429; Tang L, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P624; Tang Q, 2008, IEEE/SOLI'2008: PROCEEDINGS OF 2008 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, VOLS 1 AND 2, P1658; TANK DW, 1986, IEEE T CIRCUITS SYST, V33, P533, DOI 10.1109/TCS.1986.1085953; Tao F, 2010, CIRP ANN-MANUF TECHN, V59, P485, DOI 10.1016/j.cirp.2010.03.120; Tao L, 2009, J SW U NATIONALITIES, V35, P603; Tao L, 2009, APPL RES COMPUTERS, V26, P496; Tayarani M, 2008, IEEE INT C CYB INT S, P1165; Tayarani M, 2009, APPL SOFT COMPUT, V58, P389; Tayarani MHN, 2008, IEEE C EVOL COMPUTAT, P2665, DOI 10.1109/CEC.2008.4631156; Teng H, 2007, P INT C INT SYST KNO, V10, P130; Teng H, 2010, 2 INT C COMP ENG TEC, V4; Teng H, 2010, INT C INT COMP TECHN, V1, P922; Teng H, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 6, PROCEEDINGS, P301, DOI 10.1109/ICNC.2008.739; Teng H, 2008, 2008 CHINESE CONTROL AND DECISION CONFERENCE, VOLS 1-11, P1547; Teng J-F, 2007, P 6 INT C MACH LEARN, V7, P19; Thangaraj R, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON DEVELOPMENTS IN ESYSTEMS ENGINEERING (DESE 2009), P329, DOI 10.1109/DeSE.2009.48; Tian S, 2009, AS PAC POW EN ENG C, P1; Tian Y, 2010, INT C COMP INF SCI, P1150; Tsai HF, 2008, EXPERT SYST APPL, V34, P2656, DOI 10.1016/j.eswa.2007.05.026; Tsai HF, 2007, 3 INT C NAT COMP, V5, P292; Ulyanov S, 2004, WORLD AUT C P, V17, P99; Ulyanov SV, 2005, IEEE SYS MAN CYBERN, P3835; Venayagamoorthy GK, 2005, J COMPUT THEOR NANOS, V2, P561, DOI 10.1166/jctn.2005.011; Ventura D, 1998, P IEEE WORLD C COMPU, V1, P509; Ventura D, 2000, INFORM SCIENCES, V124, P273, DOI 10.1016/S0020-0255(99)00101-2; Vlachoglannis JG, 2008, IEEE T POWER SYST, V23, P1627, DOI 10.1109/TPWRS.2008.2004743; Vlachogiannis JG, 2009, EXPERT SYST APPL, V36, P6118, DOI 10.1016/j.eswa.2008.07.070; Wang D, 2009, IEEE INT C COMM ICC, P1, DOI DOI 10.1109/GLOCOM.2009.5425514; Wang F, 2010, INT C MEAS TECHN MEC, V1, P273; Wang H, 2010, 7 ITN C FUZZ SYST KN, V1, P483; Wang H, 2007, 4 INT C FUZZ SYST KN, V2, P261; Wang H, 2010, INT C MEAS TECHN MEC, V2, P740; Wang JH, 2007, LECT NOTES ARTIF INT, V4682, P851; Wang JH, 2008, IEEE C EVOL COMPUTAT, P897; Wang JM, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, P233, DOI 10.1109/ISCID.2008.31; Wang L, 2008, T I MEAS CONTROL, V30, P313, DOI 10.1177/0142331207088191; Wang L, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P545; Wang L, 2005, APPL MATH COMPUT, V171, P1141, DOI 10.1016/j.amc.2005.01.115; Wang L, 2010, EXPERT SYST APPL, V37, P1279, DOI 10.1016/j.eswa.2009.06.013; Wang L, 2007, LECT NOTES COMPUT SC, V4688, P277; Wang L, 2008, QUANTUM INSPIRED INT, V121, P17, DOI 10.1007/978-3-540-78532-3_2; Wang L, 2005, LECT NOTES COMPUT SC, V3645, P636; Wang X, 2010, INT C COMP CONTR IND, V2, P304; Wang X., 2006, P INT C EL MAT PACK, P1, DOI 10.1109/INFOCOM.2006.235; Wang XH, 2007, Proceedings of the 26th Chinese Control Conference, Vol 5, P759; Wang X, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5050; Wang X, 2009, WRI WORLD C COMP SCI, V4, P831; Wang X P, 2010, INT C ULTR TEL CONTR, P416, DOI 10.1109/ICUMT.2010.5676603; Wang XF, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 7, PROCEEDINGS, P186, DOI 10.1109/ICNC.2008.176; Wang XW, 2007, C IND ELECT APPL, P2371; Wang Y, 2005, LNCS, V3611, P433; Wang Y, 2007, NEUROCOMPUTING, V70, P633, DOI 10.1016/j.neucom.2006.10.001; Wang Y, 2010, INT C ENV SCI INF AP, V2, P330; Wang Y, 2010, INT C EL CONTR ENG, P3089; WANG ZC, 2010, 8 WORLD C INT CONTR, P3281; Wenlong X, 2007, J COMPUTER APPL, V27, P2147; Wu D, 2010, IEEE INT C EM MAN MA, P75; Wu J, 2010, LECT NOTES COMPUT SC, V6329, P138, DOI 10.1007/978-3-642-15597-0_16; Wu J., 2010, INT J DENT, P1, DOI 10.1109/ICCME.2010.5558882; Wu Q, 2008, INT C COMP SCI SOFTW, V6, P513; Wu QY, 2009, PROG NAT SCI, V19, P1341, DOI 10.1016/j.pnsc.2009.02.007; Wu R, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P4468; Wu R, 2008, INT C WAVEL ANAL PAT, P821; Wu R, 2007, COMPUTER ENG DESIGNX, P328; Wu WJ, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P279, DOI 10.1109/IITA.2008.430; Xi ML, 2008, APPL MATH COMPUT, V205, P751, DOI 10.1016/j.amc.2008.05.135; Xi ML, 2007, DYNAM CONT DIS SER B, V14, P1643; Xi ML, 2007, DYNAM CONT DIS SER B, V14, P603; Xi Q, 1999, PHYS LETT A, V254, P355, DOI 10.1016/S0375-9601(99)00139-5; Xia KW, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P1869; Xianwen R, 2010, AS PAC POW EN ENG C, P1; Xiao B, 2009, AS PAC POW EN ENG C, P1; Xiao J, 2009, 4 INT C BIOINSP COMP, P1; Xiao J, 2010, EXPERT SYST APPL, V37, P4966, DOI 10.1016/j.eswa.2009.12.017; Xiao J, 2008, IEEE C EVOL COMPUTAT, P1513; Xiao JH, 2009, LECT NOTES COMPUT SC, V5553, P704; Xiao JH, 2009, COMPUT MATH APPL, V57, P1949, DOI 10.1016/j.camwa.2008.10.021; Xiao W, 2006, P ITST, P1323; Xiao WX, 2007, I C WIREL COMM NETW, P2029, DOI 10.1109/WICOM.2007.507; Xie JH, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL I, PROCEEDINGS, P412, DOI 10.1109/AICI.2009.433; Xin W, 2010, 2 INT C COMP AUT ENG, V2, P281; Xin Z, 2010, 3 IEEE INT C COMP SC, V8, P247; Xing H, 2008, 4 INT C SEM KNOWL GR, P453; Xing H., 2008, J CHINA U POSTS TELE, V15, P95; Xing HL, 2009, COMPUT COMMUN, V32, P386, DOI 10.1016/j.comcom.2008.11.009; Xing HL, 2010, AEU-INT J ELECTRON C, V64, P1105, DOI 10.1016/j.aeue.2009.11.012; Xing HL, 2009, COMPUT COMMUN, V32, P1086, DOI 10.1016/j.comcom.2008.12.036; Xiong Yan, 2004, Acta Electronica Sinica, V32; Xu C, 2010, INT C INT COMP INT S, P660; Xu C., 2008, IEDM, P1, DOI 10.1109/GLOCOM.2008.ECP.66; Xu L, 2008, 4 INT C NAT COMP, P136; Xu Q, 2010, LNCS, V8, P420; Xu X, 2010, INT C COMP ASP SOC N, P307; Xu X, 2009, 2 ITN C IM SIGN PROC, P1; Xue Y, 2006, J COMPUT APPL, V9, P2068; Yan L, 2009, INT S COMP NETW MULT, P1; Yang C, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P4568; Yang G, 2010, 8 IEEE INT C CONTR A, P1103; Yang Geng-huang, 2008, Proceedings of the CSEE, V28; Yang J, 2010, 1 INT C PERV COMP SI, P944; Yang Jia, 2010, 2010 29th Chinese Control Conference (CCC 2010); Yang J., 2003, P INT C NEUR NETW SI, V1, P393; Yang J, 2010, 2 INT AS C INF CONTR, V2, P159; Yang JA, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P835; Yang JP, 2009, ADV INTELL SOFT COMP, V56, P799; Yang K, 2010, IEICE T INF SYST, V91, P1963; [杨青 YANG Qing], 2006, [武汉大学学报. 理学版, Journal of Wuhan University. Natural Science Edition], V52, P21; Yang Q, 2007, P 3 INT C NAT COMP, V5, P634; Yang S, 2001, ACTA ELECT SINICA, V29, P1873; Yang S, 2003, P ICCIMA, P362; Yang SY, 2004, P IEEE INT C SIGN PR, P1622; Yang SY, 2004, IEEE C EVOL COMPUTAT, P820; Yang SY, 2004, IEEE C EVOL COMPUTAT, P320; Yang SY, 2010, PATTERN RECOGN LETT, V31, P1894, DOI 10.1016/j.patrec.2009.12.016; Yang T, 2010, 2 INT C COMP INT NAT, V2, P105; Yanguang C, 2010, INT COMP INT SYST IC, V2, P771; Yao M, 2009, P 11 ANN C COMP GEN, P2685, DOI 10.1145/1570256.1570383; Yasin ZM, 2010, 4 INT C POW ENG OPT, P468; Yin Q, 2010, IEEE INT C INT COMP, V3, P364; Yin Q, 2010, IEEE 5 INT C BIOINSP, P1231; Ykhlef M, 2011, J KING SAUD U COMPUT, V23, P1, DOI 10.1016/j.jksuci.2010.03.001; You X, 2006, 6 IKNT C INT SYST DE, V1, P908, DOI 10.1109/ISDA.2006.209; You X, 2006, 6 WORLD C INT CONTR, V1, P3410; You X, 2008, INT C COMP SCI SOFTW, V1, P403; You X, 2007, J PETROCHEMICAL U, V9, P45; You X, 2008, 1 INT C INT NETW INT, P99; You X, 2009, 2KNT C POW EL INT TR, V3, P359; You XM, 2006, LECT NOTES COMPUT SC, V4221, P903; You XM, 2009, 2009 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT, VOL III, P249, DOI 10.1109/CCCM.2009.5267898; Yu G, 2010, P SICE ANN C, P48; Yu G, 2009, 4 INT C INN COMP INF, P1110; Yu HY, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 1, PROCEEDINGS, P530, DOI 10.1109/FSKD.2008.454; Yu SC, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P499, DOI 10.1109/ICNC.2008.466; Yu SN, 2007, PATTERN RECOGN LETT, V28, P1142, DOI 10.1016/j.patrec.2007.01.017; Yu Y-S, 2006, 14 IEEE INT C NETW S, P1; Yu Z, 2009, P 21 ANN INT C CHIN, P681; Yue C, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P117, DOI 10.1109/IITA.Workshops.2008.36; Yue TW, 2002, P IASTED INT C ART C, P60; Yue TW, 2006, LECT NOTES COMPUT SC, V4113, P943, DOI 10.1007/11816157_115; Yue TW, 2004, P 4 INT C HYBR INT S, P398; Yue TW, 2005, LECT NOTES COMPUT SC, V3644, P1023; Yue TW, 1992, THESIS NATL TAIWAN U; Yue TW, 2002, P IASTED INT C ART C, P54; Yue TW, 2007, J NETW COMPUT APPL, V30, P24, DOI 10.1016/j.jnca.2005.08.003; Zak M, 2000, CHAOS SOLITON FRACT, V11, P2325, DOI 10.1016/S0960-0779(99)00153-8; Zak M, 2000, INFORM SCIENCES, V128, P199, DOI 10.1016/S0020-0255(00)00053-0; Zak M, 1999, CHAOS SOLITON FRACT, V10, P1583, DOI 10.1016/S0960-0779(98)00215-X; Zhang G, 2003, P IEEE INT C ROB INT, V2, P1339; Zhang GX, 2003, PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PDCAT'2003, PROCEEDINGS, P693; Zhang GX, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL, P703; Zhang G, 2003, P INT C COMM TECHN P, V2, P1484; Zhang G., 2003, P IEEE 6 INT C INT T, V2, P1600; Zhang GX, 2007, LECT NOTES COMPUT SC, V4490, P989; Zhang GX, 2004, LECT NOTES COMPUT SC, V3245, P155; Zhang GX, 2004, LECT NOTES ARTIF INT, V3131, P92; Zhang GX, 2007, LECT NOTES ARTIF INT, V4481, P484; Zhang GX, 2008, FUND INFORM, V87, P93; Zhang GX, 2010, CIRC SYST SIGNAL PR, V29, P209, DOI 10.1007/s00034-009-9142-3; Zhang GX, 2007, LECT NOTES ARTIF INT, V4481, P492; Zhang GX, 2007, LECT NOTES COMPUT SC, V4490, P243; Zhang GX, 2011, J HEURISTICS, V17, P303, DOI 10.1007/s10732-010-9136-0; Zhang H, 2009, ACM INT C MULT, P1, DOI 10.1109/AFRCON.2009.5308303; Zhang L, 2010, 5 INT C COMP SCI ED, P457; Zhang Q, 2010, 6 INT C NAT COMP, V5, P2581; Zhang Q, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P7917; Zhang W, 2010, 3 INT C ADV COMP THE, V6; Zhang X, 2008, INT SEM BUS INF MAN, V1, P323; Zhang XP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS ( ICAL 2009), VOLS 1-3, P1699, DOI 10.1109/ICAL.2009.5262696; Zhang XP, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P233, DOI 10.1109/ICICTA.2009.64; Zhang XP, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL I, PROCEEDINGS, P154, DOI 10.1109/AICI.2009.166; Zhang Y, 2010, IEEE INT C SYST MAN, P1912; Zhang ZS, 2010, EXPERT SYST APPL, V37, P1800, DOI 10.1016/j.eswa.2009.07.042; Zhao D, 2008, PAC AS WORKSH COMP I, P667; Zhao J, 2009, 5 INT C NAT COMP, V6, P86; Zhao J, 2004, P 3 INT C MACH LEARN, V5, P3197; Zhao J, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 2, PROCEEDINGS, P186, DOI 10.1109/ISCID.2009.194; Zhao Jun, 2009, Instrument Techniques and Sensor, DOI 10.1109/INTLEC.2009.5351911; Zhao J, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL II, P103, DOI 10.1109/GCIS.2009.205; Zhao SF, 2009, COMPUT MATH APPL, V57, P2009, DOI 10.1016/j.camwa.2008.10.048; Zhao S, 2006, 8 INT C SIGN PROC, V3, DOI [10.1109/ICOSP.2006.345748, DOI 10.1109/ICOSP.2006.345748]; Zhao W, 2010, 3 INT S SYST CONTR A, P996; Zhao X, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P10, DOI 10.1109/DCABES.2010.8; Zhao Y, 2010, 2010 2ND IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND FINANCIAL ENGINEERING (ICIFE), P41, DOI 10.1109/ICIFE.2010.5609250; Zhao Y, 2007, 8 ACIS INT C SOFTW E, P65, DOI 10.1109/SNPD.2007.85; [赵燕伟 ZHAO Yan-wei], 2009, [系统工程理论与实践, Systems Engineering-Theory & Practice], V29, P159; Zhao ZJ, 2009, IEEE T WIREL COMMUN, V8, P4421, DOI 10.1109/TWC.2009.080939; Zhao ZJ, 2007, ACTA PHYS SIN-CH ED, V56, P6760; Zheng T, 2010, INT C EL INF ENG, V1; Zheng X, 2010, INT C COMP DES APPL, V2; Zhong Q, 2010, INT C IM AN SIGN PRO, P276; Zhou D, 2010, 3 INT ADV COMP INT, P344; Zhou Di, 2007, Journal of Computer Applications, V27; Zhou J, 1999, ADV HANDWRITING RECO, P368; Zhou J, 1999, INT J DOC ANAL RECOG, V2, P30, DOI 10.1007/s100320050034; Zhou J, 2002, PATTERN RECOGN, V35, P1179, DOI 10.1016/S0031-3203(01)00109-1; Zhou J, 2003, THIRD IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING - BIBE 2003, PROCEEDINGS, P169; Zhou LC, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P130, DOI 10.1109/ICNC.2008.410; Zhou R, 2007, P 3 INT C NAT COMP, V1, P261; Zhou RG, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P510, DOI 10.1109/ICNC.2008.160; Zhou RG, 2007, LECT NOTES COMPUT SC, V4681, P25; Zhou RG, 2007, INT J THEOR PHYS, V46, P3209, DOI 10.1007/s10773-007-9437-8; Zhou RG, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 2, P347, DOI 10.1109/IMSCCS.2006.215; Zhou RG, 2006, IEEE IJCNN, P1067; Zhou RG, 2006, LECT NOTES COMPUT SC, V4131, P651; Zhou S, 2010, 20 INT C INT C PATT, P2885, DOI 10.1109/ICPR.2010.707; Zhou SD, 2005, LECT NOTES COMPUT SC, V3612, P141; Zhou W, 2009, NEUROCOMPUTING, V72, P3782, DOI 10.1016/j.neucom.2009.05.015; Zhou WG, 2006, Computational Methods, Pts 1 and 2, P1351, DOI 10.1007/978-1-4020-3953-9_53; Zhou WG, 2005, LECT NOTES ARTIF INT, V3642, P383; Zhu D, 2007, 3 INT C NAT COMP; Zhu Da-qi, 2006, Proceedings of the CSEE, V26; Zhu Da-qi, 2006, Acta Electronica Sinica, V34; Zhu HD, 2009, LECT NOTES COMPUT SC, V5678, P796; Zhu KC, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1; Zhu KC, 2010, 2010 IEEE 10TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS (ICSP2010), VOLS I-III, P1425; Zhu M, 2007, C IND ELECT APPL, P1785; Zhu M, 2006, P 2006 IEEE INT C CO, V1, P615; Zhu XQ, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3530; Zou B, 2010, INT GEOSCI REMOTE SE, P1573, DOI 10.1109/IGARSS.2010.5653650	724	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821	1573-7462		ARTIF INTELL REV	Artif. Intell. Rev.	JUN	2014	42	1					79	156		10.1007/s10462-012-9330-6		78	Computer Science, Artificial Intelligence	Computer Science	AH2VO	WOS:000335980100004		
J	Rosenstein, M; Diaz-Asper, C; Foltz, PW; Elvevag, B				Rosenstein, Mark; Diaz-Asper, Catherine; Foltz, Peter W.; Elvevag, Brita			A computational language approach to modeling prose recall in schizophrenia	CORTEX			English	Article						Episodic memory; Wechsler memory scale; Text analysis; Latent semantic analysis	LATENT SEMANTIC ANALYSIS; COGNITIVE IMPAIRMENTS; MEMORY IMPAIRMENT; RELATIVE RISK; VERBAL MEMORY; DISORDER; POLYMORPHISM; METHODOLOGY; MEDICATIONS; MECHANISMS	Many cortical disorders are associated with memory problems. In schizophrenia, verbal memory deficits are a hallmark feature. However, the exact nature of this deficit remains elusive. Modeling aspects of language features used in memory recall have the potential to provide means for measuring these verbal processes. We employ computational language approaches to assess time-varying semantic and sequential properties of prose recall at various retrieval intervals (immediate, 30 min and 24 h later) in patients with schizophrenia, unaffected siblings and healthy unrelated control participants. First, we model the recall data to quantify the degradation of performance with increasing retrieval interval and the effect of diagnosis (i.e., group membership) on performance. Next we model the human scoring of recall performance using an n-gram language sequence technique, and then with a semantic feature based on Latent Semantic Analysis. These models show that automated analyses of the recalls can produce scores that accurately mimic human scoring. The final analysis addresses the validity of this approach by ascertaining the ability to predict group membership from models built on the two classes of language features. Taken individually, the semantic feature is most predictive, while a model combining the features improves accuracy of group membership prediction slightly above the semantic feature alone as well as over the human rating approach. We discuss the implications for cognitive neuroscience of such a computational approach in exploring the mechanisms of prose recall. (C) 2014 Elsevier Ltd. All rights reserved.	[Rosenstein, Mark; Foltz, Peter W.] Pearson Knowledge Technol, Boulder, CO USA; [Diaz-Asper, Catherine] NIMH, Clin Brain Disorders Branch, NIH, Bethesda, MD 20892 USA; [Foltz, Peter W.] Univ Colorado, Inst Cognit Sci, Boulder, CO 80309 USA; [Elvevag, Brita] Univ Tromso, Dept Clin Med, Psychiat Res Grp, N-9001 Tromso, Norway; [Elvevag, Brita] Univ Hosp North Norway, Norwegian Ctr Integrated Care & Telemed NST, Tromso, Norway	Rosenstein, M (reprint author), Pearson, 4940 Pearl East Circle,Suite 200, Boulder, CO 80301 USA.	mark.rosenstein@pearson.com			Intramural Research Program of the National Institute of Mental Health, National Institutes of Health, USA; Northern Norwegian Regional Health Authority, Helse Nord RHF	We gratefully acknowledge Daniel R. Weinberger M.D., for making the data available, which were collected via the Clinical Brain Disorders (NIMH) Schizophrenia Sibling Study (D.R. Weinberger, PI). This research was supported by the Intramural Research Program of the National Institute of Mental Health, National Institutes of Health, USA. We are also thankful for assistance from Julia Longenecker M. Phil. and Krista Wisner B.A. Brita Elvevag was funded by the Northern Norwegian Regional Health Authority, Helse Nord RHF, and Peter Foltz and Mark Rosenstein are employees of Pearson, the publisher of the Wechsler test utilized in the paper, which partially supported their work as part of their employment. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Agresti A., 2007, AN INTRODUCTION TO C; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Aleman A, 1999, AM J PSYCHIAT, V156, P1358; Armstrong-Warwick S., 1994, P INT WORKSH SHAR NA, P97; Baddeley A, 2002, NEUROPSYCHOLOGIA, V40, P1737, DOI 10.1016/S0028-3932(01)00146-4; Baitz HA, 2012, J INT NEUROPSYCH SOC, V18, P717, DOI 10.1017/S1355617712000343; Barch DM, 2005, ANNU REV CLIN PSYCHO, V1, P321, DOI 10.1146/annurev.clinpsy.1.102803.143959; Bates D., 2012, IME4 LINEAR MIXED EF; Bates D. M., 2010, LME4 MIXEDEFFECTS MO; Brebion G, 2004, PSYCHOL MED, V34, P369, DOI 10.1017/S0033291703008900; Cabana A, 2011, SCHIZOPHR RES, V131, P157, DOI 10.1016/j.schres.2011.04.026; Cavnar W.B., 1994, P 3 ANN S DOC AN INF, P161; Cirillo MA, 2003, NEUROPSYCHOL REV, V13, P43, DOI 10.1023/A:1023870821631; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dunn JC, 2002, J CLIN EXP NEUROPSYC, V24, P26, DOI 10.1076/jcen.24.1.26.965; Ebbinghaus H., 2013, MEMORY A CONTRIBUTIO; Egan MF, 2000, AM J PSYCHIAT, V157, P1309, DOI 10.1176/appi.ajp.157.8.1309; Egan MF, 2001, BIOL PSYCHIAT, V50, P98, DOI 10.1016/S0006-3223(01)01133-7; Egan MF, 2003, CELL, V112, P257, DOI 10.1016/S0092-8674(03)00035-7; Elvevag B, 2010, J NEUROLINGUIST, V23, P270, DOI 10.1016/j.jneuroling.2009.05.002; Elvevag B, 2000, CRIT REV NEUROBIOL, V14, P1; Elvevag B, 2007, SCHIZOPHR RES, V93, P304, DOI 10.1016/j.schres.2007.03.001; First MB, 1997, USERS GUIDE FOR THE; Foltz P. W., 1999, P WORLD C ED MULT HY, P939; GOLDBERG TE, 1995, SCHIZOPHR RES, V17, P77, DOI 10.1016/0920-9964(95)00032-H; Hastie T, 2009, THE ELEMENTS OF STAT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ho BC, 2006, ARCH GEN PSYCHIAT, V63, P731, DOI 10.1001/archpsyc.63.7.731; Hoffman R., 2010, BIOL PSYCHIAT, V69, P997; Hofmann H., 2005, INTERACTIVE GRAPHICS; Hornik K., 2012, TEXTCAT N GRAM BASED; Jastak S., 1984, THE WIDE RANGE ACHIE; Jurafsky D, 2009, SPEECH AND LANGUAGE; Kalkstein S, 2010, CURR TOP BEHAV NEURO, V4, P373, DOI 10.1007/7854_2010_42; Kintsch W., 1998, COMPREHENSION A PARA; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Lautenschlager NT, 2006, J CLIN EXP NEUROPSYC, V28, P1381, DOI 10.1080/13803390500409617; Lezak M, 2004, NEUROPSYCHOLOGICAL A, V4; Lim KO, 2006, AM J PSYCHIAT, V163, P2008, DOI 10.1176/appi.ajp.163.11.2008; Longenecker J, 2010, SCHIZOPHR RES, V119, P240, DOI 10.1016/j.schres.2010.03.023; Longenecker J, 2010, NEUROPSYCHOLOGY, V24, P625, DOI 10.1037/a0019368; Matsui M, 2007, PSYCHIAT CLIN NEUROS, V61, P437, DOI 10.1111/j.1440-1819.2007.01675.x; MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109; MISSAR CD, 1994, SCHIZOPHR RES, V12, P247, DOI 10.1016/0920-9964(94)90034-5; Mori K, 2004, PROG NEURO-PSYCHOPH, V28, P659, DOI 10.1016/j.pnpbp.2004.01.019; Munro Cullum C., 1990, ARCH CLIN NEUROPSYCH, V5, P23, DOI DOI 10.1093/ARCLIN/5.1.23; O'Driscoll GA, 2001, PSYCHIAT RES-NEUROIM, V107, P75, DOI 10.1016/S0925-4927(01)00095-6; Pinheiro JC, 2000, MIXED EFFECTS MODELS; R Core Team, 2012, R LANG ENV STAT COMP; Rabin LA, 2005, ARCH CLIN NEUROPSYCH, V20, P33, DOI 10.1016/j.acn.2004.02.005; Robinson ES, 1922, J EXP PSYCHOL, V5, P428, DOI 10.1037/h0075024; RUSSELL EW, 1988, J CLIN EXP NEUROPSYC, V10, P235, DOI 10.1080/01688638808408238; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Skelley SL, 2008, SCHIZOPHR RES, V105, P78, DOI 10.1016/j.schres.2008.05.027; Toulopoulou T, 2003, SCHIZOPHR RES, V63, P261, DOI 10.1016/S0920-9964(02)00324-9; TROSTER AI, 1993, J CLIN EXP NEUROPSYC, V15, P773, DOI 10.1080/01688639308402595; Vassos E, 2010, J PSYCHIATR RES, V44, P795, DOI 10.1016/j.jpsychires.2010.01.012; Venables WN, 2002, MODERN APPLIED STATI; Wechsler D., 2009, WECHSLER MEMORY SCAL; Wechsler D, 1987, WECHSLER MEMORY SCAL; Wechsler D, 1997, WECHSLER MEMORY SCAL; Wechsler D, 1945, J PSYCHOL, V19, P87; Weickert TW, 2000, ARCH GEN PSYCHIAT, V57, P907, DOI 10.1001/archpsyc.57.9.907; WIENS AN, 1993, CLIN NEUROPSYCHOL, V7, P70, DOI 10.1080/13854049308401889; Zeno S., 1995, THE EDUCATORS WORD F; Zipf G. K., 1935, THE PSYCHOBIOLOGY OF	69	1	1	ELSEVIER MASSON	MILANO	VIA PALEOCAPA 7, 20121 MILANO, ITALY	0010-9452	1973-8102		CORTEX	Cortex	JUN	2014	55				SI		148	166		10.1016/j.cortex.2014.01.021		19	Behavioral Sciences; Neurosciences	Behavioral Sciences; Neurosciences & Neurology	AJ5ZY	WOS:000337770700013	24709122	
J	Bongard, J; Lipson, H				Bongard, Josh; Lipson, Hod			Evolved Machines Shed Light on Robustness and Resilience	PROCEEDINGS OF THE IEEE			English	Article						Embodied cognition; evolutionary robotics	NEURAL-NETWORKS; MORPHOLOGICAL COMPLEXITY; INFORMATION-THEORY; MIRROR NEURONS; BODY SCHEMA; EVOLUTION; MODULARITY; ALGORITHM; ROBOTICS; SYSTEMS	In biomimetic engineering, we may take inspiration from the products of biological evolution: we may instantiate biologically realistic neural architectures and algorithms in robots, or we may construct robots with morphologies that are found in nature. Alternatively, we may take inspiration from the process of evolution: we may evolve populations of robots in simulation and then manufacture physical versions of the most interesting or more capable robots that evolve. If we follow this latter approach and evolve both the neural and morphological subsystems of machines, we can perform controlled experiments that provide unique insight into how bodies and brains can work together to produce adaptive behavior, regardless of whether such bodies and brains are instantiated in a biological or technological substrate. In this paper, we review selected projects that use such methods to investigate the synergies and tradeoffs between neural architecture, morphology, action, and adaptive behavior.	[Bongard, Josh] Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA; [Lipson, Hod] Cornell Univ, Sibley Sch Mech & Aerosp Engn, Ithaca, NY 14853 USA	Bongard, J (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA.	josh.bongard@uvm.edu; hod.lipson@cornell.edu			National Science Foundation (NSF) Presidential Early Career Award for Scientists and Engineers (PECASE) [0953837]; Defense Advanced Research Projects Agency (DARPA) M3 [W911NF-1-11-0076]; DARPA MSEE [FA8650-11-1-7155]; Vermont Advanced Computing Core; National Aeronautics and Space Administration (NASA) [NNX06AC88G]; DARPA [W911NF-12-1-0449]; NSF Cyber Enabled Discovery [0941561]	The work of J. Bongard was supported by the National Science Foundation (NSF) Presidential Early Career Award for Scientists and Engineers (PECASE) under Grant 0953837; by the Defense Advanced Research Projects Agency (DARPA) M3 under Grant W911NF-1-11-0076; by DARPA MSEE under Grant FA8650-11-1-7155; and by Vermont Advanced Computing Core, which is supported by the National Aeronautics and Space Administration (NASA) under Grant NNX06AC88G. The work of H. Lipson was supported by DARPA under Open Manufacturing Grant W911NF-12-1-0449; and by NSF Cyber Enabled Discovery under Grant 0941561.	Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702; Auerbach JE, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003399; Barrett HC, 2006, PSYCHOL REV, V113, P628, DOI 10.1037/0033-295X.113.3.628; Beer RD, 2006, NEURAL COMPUT, V18, P3009, DOI 10.1162/neco.2006.18.12.3009; Bernstein N. A., 1967, COORDINATION REGULAT; Berthouze L, 2004, ADAPT BEHAV, V12, P47, DOI 10.1177/105971230401200104; Bongard J, 2011, P NATL ACAD SCI USA, V108, P1234, DOI 10.1073/pnas.1015390108; Bongard J, 2006, SCIENCE, V314, P1118, DOI 10.1126/science.1133687; Bongard J, 2010, ARTIF LIFE, V16, P201, DOI 10.1162/artl.2010.Bongard.024; Bongard JC, 2009, IEEE T EVOLUT COMPUT, V13, P321, DOI 10.1109/TEVC.2008.927236; Bongard JC, 2011, GECCO-2011: PROCEEDINGS OF THE 13TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P251; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; Calvin W. H., 2000, CEREBRAL CODE THINKI; Carroll SB, 2001, NATURE, V409, P1102, DOI 10.1038/35059227; Clark A, 2013, BEHAV BRAIN SCI, V36, P233, DOI [10.1017/S0140525X12000477, 10.1017/S0140525X12002440]; Clark Andy, 1998, BEING THERE PUTTING; Cliff Dave, 1993, Adaptive Behavior, V2, P73, DOI 10.1177/105971239300200104; Clune J., 2013, PROCEEDINGS OF THE R, V280, DOI DOI 10.1098/RSPB.2012.2863; Collins S, 2005, SCIENCE, V307, P1082, DOI 10.1126/science.1107799; DORIGO M, 1994, ARTIF INTELL, V71, P321, DOI 10.1016/0004-3702(94)90047-7; Consoulas C, 2000, BRAIN RES BULL, V53, P571, DOI 10.1016/S0361-9230(00)00391-9; CRICK F, 1989, TRENDS NEUROSCI, V12, P240, DOI 10.1016/0166-2236(89)90019-2; DE JONG K. A., 2006, EVOLUTIONARY COMPUTA; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; de Vignemont F, 2010, NEUROPSYCHOLOGIA, V48, P669, DOI 10.1016/j.neuropsychologia.2009.09.022; Diedrichsen J, 2010, TRENDS COGN SCI, V14, P31, DOI 10.1016/j.tics.2009.11.004; Dimitrov AG, 2011, J COMPUT NEUROSCI, V30, P1, DOI 10.1007/s10827-011-0314-3; Edelman G. M., 1987, NEURAL DARWINISM THE; Espinosa-Soto C, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000719; Fernando C, 2010, NEURAL COMPUT, V22, P2809, DOI 10.1162/NECO_a_00031; Floreano D, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000292; Franceschini N, 2014, P IEEE, V102, P751, DOI 10.1109/JPROC.2014.2312916; Freeling M, 2006, GENOME RES, V16, P805, DOI 10.1101/gr.3681406; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5; George D, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000532; Gomez G., 2004, P 4 INT WORKSH EP RO, P119; Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, DOI 10.1561/1100000005; Gopnik A, 2004, TRENDS COGN SCI, V8, P371, DOI 10.1016/j.tics.2004.06.005; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffmann M, 2010, IEEE T AUTON MENT DE, V2, P304, DOI 10.1109/TAMD.2010.2086454; Iacoboni M, 2009, ANNU REV PSYCHOL, V60, P653, DOI 10.1146/annurev.psych.60.110707.163604; Imamizu H, 2003, P NATL ACAD SCI USA, V100, P5461, DOI 10.1073/pnas.0835746100; Irie B., 1988, P IEEE INT C NEUR NE, V1, P641, DOI [10.1109/ICNN.1988.23901, DOI 10.1109/ICNN.1988.23901]; Jakobi N, 1995, LECT NOTES ARTIF INT, V929, P704; Jorgensen TD, 2008, INT J NEURAL SYST, V18, P389, DOI 10.1142/S012906570800166X; Kanda T., 2008, P 10 INT C UB COMP, P380, DOI 10.1145/1409635.1409686; Kashtan N, 2005, P NATL ACAD SCI USA, V102, P13773, DOI 10.1073/pnas.0503610102; Kim K.-J., 2009, P 11 ANN C COMP GEN, P2071, DOI 10.1145/1570256.1570278; Krishnanand K. N., 2010, NEURAL NETWORKS, V23, P1113; Lipson H, 2002, EVOLUTION, V56, P1549, DOI 10.1111/j.0014-3820.2002.tb01466.x; Maass W, 2014, P IEEE, V102, P860, DOI 10.1109/JPROC.2014.2310593; Massera G., 2007, FRONT NEUROROBOTICS, V1, P1; McShea D., 2010, BIOL 1 LAW TENDENCY; Meltzoff AN, 2007, DEVELOPMENTAL SCI, V10, P126, DOI 10.1111/j.1467-7687.2007.00574.x; Meunier David, 2009, Front Neuroinform, V3, P37, DOI 10.3389/neuro.11.037.2009; Miall RC, 2003, NEUROREPORT, V14, P2135, DOI 10.1097/01.wnr.0000098751.87269.77; Miconi T, 2008, ARTIF LIFE, V14, P325, DOI 10.1162/artl.2008.14.3.14307; Minsky M, 1988, SOC MIND; Murata S, 2002, IEEE-ASME T MECH, V7, P431, DOI 10.1109/TMECH.2002.806220; Nehaniv CL, 2007, IMITATION AND SOCIAL LEARNING IN ROBOTS, HUMANS AND ANIMALS: BEHAVIOURAL, SOCIAL AND COMMUNICATIVE DIMENSIONS, P1, DOI 10.1017/CBO9780511489808; Page DL, 2003, IEEE IMAGE PROC, P229; Passy SI, 2002, FUNCT ECOL, V16, P690, DOI 10.1046/j.1365-2435.2002.00671.x; Pfeifer R., 2006, BODY SHAPES WAY THIN; Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811; Quiroga RQ, 2009, NAT REV NEUROSCI, V10, P173, DOI 10.1038/nrn2578; Reil T, 2002, IEEE T EVOLUT COMPUT, V6, P159, DOI 10.1109/4235.996015; SAEGUSA R, 2009, P IEEE INT C ROB BIO, P794; Schmidt M, 2011, GENET EVOL COMPUT, P129; Seth AK, 2004, ADAPT BEHAV, V12, P5, DOI 10.1177/105971230401200103; Seung H. S., 1992, P WORKSH COMP LEARN, V5, P287; Shepherd RF, 2011, P NATL ACAD SCI USA, V108, P20400, DOI 10.1073/pnas.1116564108; Sims K., 1994, ARTIF LIFE, P28; Stanley KO, 2007, GENET PROGRAM EVOL M, V8, P131, DOI 10.1007/s10710-007-9028-8; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Sukumar S. R., 2008, P IEEE COMP SOC C CO, DOI [10.1109/CVPRW.2008.4562975, DOI 10.1109/CVPRW.2008.4562975]; Tedrake R., 2005, P 14 YAL WORKSH AD L, P1; Todorov E, 2002, NAT NEUROSCI, V5, P1226, DOI 10.1038/nn963; TONONI G, 1994, P NATL ACAD SCI USA, V91, P5033, DOI 10.1073/pnas.91.11.5033; Valiant L.G., 2009, J ACM, V56, P1, DOI DOI 10.1145/1462153.1462156; Vaughan E., 2004, P 9 INT C SIM SYNTH, P139; Wagner GP, 1996, EVOLUTION, V50, P967, DOI 10.2307/2410639; Wagner GP, 2007, NAT REV GENET, V8, P921, DOI 10.1038/nrg2267; Wolpert DM, 1998, NEURAL NETWORKS, V11, P1317, DOI 10.1016/S0893-6080(98)00066-5; Wolpert DM, 2011, NAT REV NEUROSCI, V12, P739, DOI 10.1038/nrn3112; WOOD D, 1976, J CHILD PSYCHOL PSYC, V17, P89, DOI 10.1111/j.1469-7610.1976.tb00381.x; Wysoski SG, 2010, NEURAL NETWORKS, V23, P819, DOI 10.1016/j.neunet.2010.04.009; Yamashita Y, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000220; Yim M, 2007, IEEE ROBOT AUTOM MAG, V14, P43, DOI 10.1109/MRA.2007.339623; Yim M, 2002, IEEE SPECTRUM, V39, P30, DOI 10.1109/6.981854; Zagal Juan Cristobal, 2011, Advances in Artificial Life. Darwin Meets von Neumann. 10th European Conference, ECAL 2009. Revised Selected Papers, DOI 10.1007/978-3-642-21283-3_20	92	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219	1558-2256		P IEEE	Proc. IEEE	MAY	2014	102	5			SI		899	914		10.1109/JPROC.2014.2312844		16	Engineering, Electrical & Electronic	Engineering	AI5NR	WOS:000336915700017		
J	Zucker, SW				Zucker, Steven W.			Stereo, Shading, and Surfaces: Curvature Constraints Couple Neural Computations	PROCEEDINGS OF THE IEEE			English	Article						Boundary detection; computational vision; constraint satisfaction; neural computation; shading analysis; stereo	PRIMARY VISUAL-CORTEX; HORIZONTAL CONNECTIONS; MACAQUE MONKEY; ORIENTATION SELECTIVITY; FUNCTIONAL ARCHITECTURE; INTRINSIC CONNECTIONS; TEXTURE SEGMENTATION; CONTEXTUAL INFERENCE; ENERGY MINIMIZATION; NATURAL SCENES	Vision problems are inherently ambiguous: Do abrupt brightness changes correspond to object boundaries? Are smooth intensity changes due to shading or material properties? For stereo: Which point in the left image corresponds to which point in the right one? What is the role of color in visual information processing? To answer these (seemingly different) questions we develop an analogy between the role of orientation in organizing visual cortex and tangents in differential geometry. Machine learning experiments suggest using geometry as a surrogate for high-order statistical interactions. The cortical columnar architecture becomes a bundle structure in geometry. Connection forms within these bundles suggest answers to the above questions, and curvatures emerge in key roles. More generally, our path through these questions suggests an overall strategy for solving the inverse problems of vision: decompose the global problems into networks of smaller ones and then seek constraints from these coupled problems to reduce ambiguity. Neural computations thus amount to satisfying constraints rather than seeking uniform approximations. Even when no global formulation exists one may be able to find localized structures on which ambiguity is minimal; these can then anchor an overall approximation.	[Zucker, Steven W.] Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA; [Zucker, Steven W.] Yale Univ, Dept Biomed Engn, New Haven, CT 06520 USA	Zucker, SW (reprint author), Yale Univ, Dept Comp Sci, POB 2158, New Haven, CT 06520 USA.	steven.zucker@yale.edu			U.S. Air Force Office of Scientific Research (AFOSR); National Institutes of Health (NIH); National Science Foundation (NSF); Paul G. Allen Family Foundation	This work was supported by the U.S. Air Force Office of Scientific Research (AFOSR), the National Institutes of Health (NIH), the National Science Foundation (NSF), and The Paul G. Allen Family Foundation.	Adini Y, 1997, P NATL ACAD SCI USA, V94, P10426, DOI 10.1073/pnas.94.19.10426; Angelucci A, 2002, J NEUROSCI, V22, P8633; August J, 2000, SPRING INT SER ENG C, V546, P265; Barron J., 2013, SHAPE ILLMINATION RE; Barrow H. G., 1978, COMPUTER VISION SYST; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Ben-Shahar O, 2006, P NATL ACAD SCI USA, V103, P15704, DOI 10.1073/pnas.0604410103; Ben-Shahar O, 2004, VISION RES, V44, P257, DOI 10.1016/j.visres.2003.08.018; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Ben-Shahar O, 2004, NEURAL NETWORKS, V17, P753, DOI 10.1016/j.neunet.2004.03.011; Ben-Shahar O, 2004, NEURAL COMPUT, V16, P445, DOI 10.1162/089976604772744866; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Bishop C. M., 2006, INFORM SCI STAT; Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1; Bosking WH, 1997, J NEUROSCI, V17, P2112; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breton P, 1996, PROC CVPR IEEE, P782, DOI 10.1109/CVPR.1996.517161; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; Casagrande Vivien A., 1994, Cerebral Cortex, V10, P201; Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P376, DOI 10.1109/83.661188; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354; Dieft P., 1981, J MATH ANAL APPL, V84, P235; Dorsey J, 2008, MKS COMP GRAPH GEOME, P1; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Elder J. H., 1998, P IEEE WORKSH PERC O; Elder J. H., 2013, OXFORD HDB PERCEPTUA; Elder JH, 2002, J VISION, V2, DOI 10.1167/2.4.5; ERENS RGF, 1993, PERCEPT PSYCHOPHYS, V54, P145, DOI 10.3758/BF03211750; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; FREEMAN WT, 1994, NATURE, V368, P542, DOI 10.1038/368542a0; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; Geman D., 1996, 2757 INRIA; GILBERT CD, 1983, J NEUROSCI, V3, P1116; HALMOS PR, 1963, AM MATH MON, V70, P241, DOI 10.2307/2313117; Hess R. F., 2013, OXFORD HDB PERCEPTUA; Hinkle DA, 2002, NAT NEUROSCI, V5, P665, DOI 10.1038/nn875; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition; Holtmann-Rice D., 2013, J VIS, V13, DOI [10.1167/13.9.467, DOI 10.1167/13.9.467]; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; Horn B. K. P., 1989, SHAPE SHADING; Huang P-C, 2012, J VIS, V12, p[29, 1]; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; Huggins P. S., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937618; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267; Hunt JJ, 2012, VISION RES, V64, P49, DOI 10.1016/j.visres.2012.05.007; KAPADIA MK, 1995, NEURON, V15, P843, DOI 10.1016/0896-6273(95)90175-2; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI DOI 10.1007/BF00133570; Koenderink J. J., 2004, VISUAL NEUROSCIENCES, P1090; KOENDERINK JJ, 1994, PATTERN RECOGN LETT, V15, P439, DOI 10.1016/0167-8655(94)90134-1; Koenderink JJ, 2001, PERCEPTION, V30, P431, DOI 10.1068/p3030; Koenderink J. J., 1990, SOLID SHAPE; KOENDERINK JJ, 1980, OPT ACTA, V27, P981; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Kravitz DJ, 2013, TRENDS COGN SCI, V17, P26, DOI 10.1016/j.tics.2012.10.011; Kruger N, 1998, NEURAL PROCESS LETT, V8, P117, DOI 10.1023/A:1009688428205; Kunsberg B., 2013, CHARACERIZING AMBIGU; Kunsberg B., 2014, NEUROGEOMETRY VISION; Kunsberg B., 2012, P IEEE C COMP VIS PA, P39; Kunsberg B., 2014, SIAM J IMAGING SCI; Langer MS, 1997, COMPUT VIS IMAGE UND, V65, P322, DOI 10.1006/cviu.1996.0574; Lawlor M., 2013, ADV NEURAL INFORM PR, V26, P1763; Lawlor M, 2009, J PHYSIOLOGY-PARIS, V103, P18, DOI 10.1016/j.jphysparis.2009.05.005; LeCun Y., 1995, HDB BRAIN THEORY NEU; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; LEHKY SR, 1988, NATURE, V333, P452, DOI 10.1038/333452a0; Lenglet C, 2009, NEUROIMAGE, V45, pS111, DOI 10.1016/j.neuroimage.2008.10.054; Li G, 2010, IEEE T PATTERN ANAL, V32, P72, DOI 10.1109/TPAMI.2008.270; Li G, 2006, INT J COMPUT VISION, V69, P59, DOI 10.1007/s11263-006-6853-9; Li SZ, 2009, MARKOV RANDOM FIELD; LIONS PL, 1993, NUMER MATH, V64, P323, DOI 10.1007/BF01388692; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MILLER DA, 1992, NEURAL COMPUT, V4, P167, DOI 10.1162/neco.1992.4.2.167; Miller DA, 1999, NEURAL COMPUT, V11, P21, DOI 10.1162/089976699300016782; Miller KD, 2003, CEREB CORTEX, V13, P73, DOI 10.1093/cercor/13.1.73; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; NOTHDURFT HC, 1985, VISION RES, V25, P551, DOI 10.1016/0042-6989(85)90159-2; O'Neill B., 2006, ELEMENTARY DIFFERENT; OLIENSIS J, 1991, INT J COMPUT VISION, V6, P75, DOI 10.1007/BF00128151; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Pasupathy A, 2002, NAT NEUROSCI, V5, P1332, DOI 10.1038/nn972; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170; Piuze E, 2011, COMPUT GRAPH FORUM, V30, P247, DOI 10.1111/j.1467-8659.2011.01856.x; Poggio G. F., 1977, J NEUROPHYSIOL, V40, P392; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106; Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23; Qian Ning, 1997, Neuron, V18, P359, DOI 10.1016/S0896-6273(00)81238-6; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; RATLIFF F., 1965, MACH BANDS QUANTITAT; ROCKLAND KS, 1982, SCIENCE, V215, P1532, DOI 10.1126/science.7063863; Roe AW, 1997, CEREBR CORT, V12, P295; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SALIN PA, 1995, PHYSIOL REV, V75, P107; Samonds JM, 2009, J NEUROSCI, V29, P15780, DOI 10.1523/JNEUROSCI.2305-09.2009; Samonds JM, 2013, J NEUROSCI, V33, P2934, DOI 10.1523/JNEUROSCI.2952-12.2013; Sarti A, 2008, BIOL CYBERN, V98, P33, DOI 10.1007/s00422-007-0194-9; Savadjiev P, 2012, P NATL ACAD SCI USA, V109, P9248, DOI 10.1073/pnas.1120785109; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Shapley R, 2011, VISION RES, V51, P701, DOI 10.1016/j.visres.2011.02.012; Shevell SK, 2008, ANNU REV PSYCHOL, V59, P143, DOI 10.1146/annurev.psych.59.103006.093619; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Sincich LC, 2002, SCIENCE, V295, P1734, DOI 10.1126/science.1067902; Sompolinsky H, 1997, CURR OPIN NEUROBIOL, V7, P514, DOI 10.1016/S0959-4388(97)80031-1; STEVENS KA, 1978, BIOL CYBERN, V29, P19, DOI 10.1007/BF00365232; Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563; Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185; Tkacik G, 2010, P NATL ACAD SCI USA, V107, P18149, DOI 10.1073/pnas.0914916107; Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273; ROCKLAND KS, 1989, J COMP NEUROL, V285, P54, DOI 10.1002/cne.902850106; Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333; Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), DOI 10.1109/CVPR.1993.341105; Weiss Y, 2001, P IEEE INT C COMP VI, VII, P68, DOI 10.1109/ICCV.2001.937606; Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640; Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; Zucker S. W., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.68	127	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219	1558-2256		P IEEE	Proc. IEEE	MAY	2014	102	5			SI		812	829		10.1109/JPROC.2014.2314723		18	Engineering, Electrical & Electronic	Engineering	AI5NR	WOS:000336915700012		
J	Sarwate, AD; Plis, SM; Turner, JA; Arbabshirani, MR; Calhoun, VD				Sarwate, Anand D.; Plis, Sergey M.; Turner, Jessica A.; Arbabshirani, Mohammad R.; Calhoun, Vince D.			Sharing privacy-sensitive access to neuroimaging and genetics data: a review and preliminary validation	FRONTIERS IN NEUROINFORMATICS			English	Review						collaborative research; data sharing; privacy; data integration; neuroimaging	GENOME-WIDE ASSOCIATION; DIFFERENTIAL PRIVACY; BRAIN NETWORKS; SCHIZOPHRENIA; RISK; IDENTIFICATION; CONNECTIVITY; TECHNOLOGY; CONSORTIUM; CHALLENGES	The growth of data sharing initiatives for neuroimaging and genomics represents an exciting opportunity to confront the "small N" problem that plagues contemporary neuroimaging studies while further understanding the role genetic markers play in the function of the brain. When it is possible, open data sharing provides the most benefits. However, some data cannot be shared at all due to privacy concerns and/or risk of re-identification. Sharing other data sets is hampered by the proliferation of complex data use agreements (DUAs) which preclude truly automated data mining. These DUAs arise because of concerns about the privacy and confidentiality for subjects; though many do permit direct access to data, they often require a cumbersome approval process that can take months. An alternative approach is to only share data derivatives such as statistical summaries the challenges here are to reformulate computational methods to quantify the privacy risks associated with sharing the results of those computations. For example, a derived map of gray matter is often as identifiable as a fingerprint. Thus alternative approaches to accessing data are needed. This paper reviews the relevant literature on differential privacy, a framework for measuring and tracking privacy loss in these settings, and demonstrates the feasibility of using this framework to calculate statistics on data distributed at many sites while still providing privacy.	[Sarwate, Anand D.] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08855 USA; [Plis, Sergey M.; Turner, Jessica A.; Arbabshirani, Mohammad R.; Calhoun, Vince D.] Mind Res Network, Albuquerque, NM 87106 USA; [Turner, Jessica A.] Georgia State Univ, Dept Psychol, Atlanta, GA 30303 USA; [Turner, Jessica A.] Georgia State Univ, Inst Neurosci, Atlanta, GA 30303 USA; [Arbabshirani, Mohammad R.; Calhoun, Vince D.] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA	Calhoun, VD (reprint author), Mind Res Network, 1101 Yale Blvd NE, Albuquerque, NM 87106 USA.	vcalhoun@mrn.org	Turner, Jessica/H-7282-2015	Turner, Jessica/0000-0003-0076-8434	National Institutes of Health [NIMH U01MH097435, NIBIB R01EB005846, COBRE 5P20RR021938/P20GM103472]	This work was supported by the National Institutes of Health via awards NIMH U01MH097435 (Lei Wang, PI) to Jessica A. Turner and NIBIB R01EB005846 and COBRE 5P20RR021938/P20GM103472 to Vince D. Calhoun.	Allen Elena A, 2011, Front Syst Neurosci, V5, P2, DOI 10.3389/fnsys.2011.00002; [Anonymous], 2013, C LEARN THEOR JMLR W, V30, P1; Arbabshirani MR, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00133; Biessmann Felix, 2011, IEEE Rev Biomed Eng, V4, P26, DOI 10.1109/RBME.2011.2170675; Bridwell DA, 2013, NEUROIMAGE, V69, P101, DOI 10.1016/j.neuroimage.2012.12.024; Chaudhuri K, 2006, LECT NOTES COMPUT SC, V4117, P198; Chaudhuri K, 2011, J MACH LEARN RES, V12, P1069; Chaudhuri K, 2013, J MACH LEARN RES, V14, P2905; Chen JY, 2013, NEUROIMAGE, V83, P384, DOI 10.1016/j.neuroimage.2013.05.073; Couzin J, 2008, SCIENCE, V321, P1278, DOI 10.1126/science.321.5894.1278; Deshpande G, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00670; Dinur I., 2003, P 22 ACM SIGACT SIGM, P202, DOI DOI 10.1145/773153.773173; Duchi J., 2013, ADV NEURAL INFORM PR, V26, P1529; Duchi J., 2012, ADV NEURAL INFORM PR, V25, P1439; Dwork C., 2009, J PRIVACY CONFIDENTI, V1, P135; Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265; Dwork C, 2009, ACM S THEORY COMPUT, P371; Dwork C, 2010, ANN IEEE SYMP FOUND, P51, DOI 10.1109/FOCS.2010.12; Fan L., 2012, P 21 ACM INT C INF K, P2169; Fennema-Notestine C, 2007, NEUROINFORMATICS, V5, P235, DOI 10.1007/s12021-007-9003-9; Fung B.C.M., 2010, ACM COMPUT SURV, V42, DOI [DOI 10.1145/1749603.1749605, 10.1201/9781420091502]; Gabay D., 1976, Computers & Mathematics with Applications, V2, DOI 10.1016/0898-1221(76)90003-1; Ganta S. R., 2008, P 14 ACM SIGKDD INT, P265, DOI DOI 10.1145/1401890.1401926; Geng Q., 2013, ARXIV13051330; Geng Q., 2012, ARXIV12121186; Ghosh A, 2012, SIAM J COMPUT, V41, P1673, DOI 10.1137/09076828X; Ghosh A., 2011, P 12 ACM C EL COMM E, P199; Girirajan S, 2013, AM J HUM GENET, V92, P221, DOI 10.1016/j.ajhg.2012.12.016; Gupte M, 2010, PODS 2010: PROCEEDINGS OF THE TWENTY-NINTH ACM SIGMOD-SIGACT-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P135, DOI 10.1145/1807085.1807105; Gymrek M, 2013, SCIENCE, V339, P321, DOI 10.1126/science.1229566; Haeberlen A., 2011, P 20 USENIX C SEC; Hardt M., 2012, P 44 ANN ACM S THEOR, P1255, DOI DOI 10.1145/2213977.2214088; Hardt M., 2013, P 45 ANN ACM S THEOR, P331, DOI [10.1145/2488608.2488650, DOI 10.1145/2488608.2488650]; Hardt M., 2012, ADV NEURAL INFORM PR, V25, P2348; Hilbar D., 2013, 19 ANN M ORG HUM BRA; Hinton G., 2000, NEURAL COMPUT, V14, P2002, DOI DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Homer N, 2008, PLOS GENET, V4, DOI 10.1371/journal.pgen.1000167; Huang Y., 2011, P 18 NETW DISTR SYST; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Jain P., 2012, P 25 ANN C LEARN THE, V23; Jain P., 2014, P 31 INT C MACH LEAR; Jain P., 2013, P 30 INT C MACH LEAR, V28, P118; Jiang XQ, 2013, MED CARE, V51, pS58, DOI 10.1097/MLR.0b013e31829b1d10; Karwa V., 2011, P VLDB ENDOW, V4, P1146; Kasiviswanathan S., 2013, P 10 THEOR CRYPT C T, P457, DOI [10.1007/978-3-642-36594-2_26, DOI 10.1007/978-3-642-36594-2_26]; Kifer D., 2012, P 25 ANN C LEARN THE, V23; Kifer D., 2011, P ACM SIGMOD INT C M, P193, DOI [DOI 10.1145/1989323.1989345, 10.1145/1989323.1989345]; Le Ny J., 2012, P 50 ANN ALL C COMM, P1618; Lei Jing, 2011, ADV NEURAL INFORM PR, V24, P361; Le Ny J, 2012, IEEE DECIS CONTR P, P3398, DOI 10.1109/CDC.2012.6426355; Li N, 2007, ICDE 2007, V2, P106; Lindell Y., 2009, J PRIVACY CONFIDENTI, V1, P59; Liu JY, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00021; Lowe Henry J, 2009, AMIA Annu Symp Proc, V2009, P391; Ludman EJ, 2010, J EMPIR RES HUM RES, V5, P9, DOI 10.1525/jer.2010.5.3.9; Machanavajjhala A, 2007, ACM T KNOWL DISCOV D, V1, P1, DOI DOI 10.1145/1217299.1217302; Machanavajjhala A, 2008, PROC INT CONF DATA, P277, DOI 10.1109/ICDE.2008.4497436; Malin B, 2008, DATA KNOWL ENG, V64, P294, DOI 10.1016/j.datak.2007.06.016; McGuire AL, 2011, GENOME RES, V21, P1001, DOI 10.1101/gr.120329.111; McSherry F, 2010, COMMUN ACM, V53, P89, DOI 10.1145/1810891.1810916; McSherry F., 2010, P SIGCOMM NEW DELH; Meda SA, 2008, SCHIZOPHR RES, V101, P95, DOI 10.1016/j.schres.2008.02.007; Mennes M, 2013, NEUROIMAGE, V82, P683, DOI 10.1016/j.neuroimage.2012.10.064; Mohan P., 2012, P 2012 ACM SIGMOD IN, P349, DOI [10.1145/2213836.2213876, DOI 10.1145/2213836.2213876]; Murphy S. N., 2006, P AMIA ANN S, P1040; Murphy SN, 2002, P AMIA S, V2002, P552; Narayanan A, 2008, P IEEE S SECUR PRIV, P111; National Research Council, 1997, COMPUTER BASED PATIE; Nikolaenko V, 2013, P IEEE S SECUR PRIV, P334, DOI 10.1109/SP.2013.30; Nissim K., 2010, IEEE S FDN COMP SCI; Nissim K, 2007, ACM S THEORY COMPUT, P75; Oh S., 2013, ARXIV13110776CSDS; Plis S. M., 2010, FRONT NEUROINFORM, V4, P12, DOI [10.3389/fninf.2010.00114, DOI 10.3389/FNINF.2010.00114]; Poldrack RA, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00012; Poline JB, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00009; Potkin SG, 2009, SCHIZOPHRENIA BULL, V35, P15, DOI 10.1093/schbul/sbn159; Rastogi V, 2009, PODS'09: PROCEEDINGS OF THE TWENTY-EIGHTH ACM SIGMOD-SIGACT-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P107, DOI 10.1145/1559795.1559812; Reed J., 2010, ACM SIGPLAN INT C FU; Ripke S, 2013, NAT GENET, V45, P1150, DOI 10.1038/ng.2742; Roy I., 2010, P 7 USENIX C NETW SY; Rubinstein B. I. P., 2012, J PRIVACY CONFIDENTI, V4, P65; Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229; Sarwate AD, 2013, IEEE SIGNAL PROC MAG, V30, P86, DOI 10.1109/MSP.2013.2259911; Schadt EE, 2012, NAT GENET, V44, P603, DOI 10.1038/ng.2248; Schelenz PD, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00729; Smith A, 2011, P 43 ANN ACM S THEOR, P813; Sweeney L, 1997, J LAW MED ETHICS, V25, P98, DOI 10.1111/j.1748-720X.1997.tb01885.x; Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648; Thakurta A. G., 2013, ADV NEURAL INFORM PR, V26, P2733; Turner JA, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00016; van Erp T.G., 2013, BIOL PSYCHIAT, V75, P398, DOI DOI 10.1016/J.BI0PSYCH.2013.06.016; Vinterbo SA, 2012, J AM MED INFORM ASSN, V19, P750, DOI 10.1136/amiajnl-2011-000459; Wasserman L, 2010, J AM STAT ASSOC, V105, P375, DOI 10.1198/jasa.2009.tm08651; Williams O., 2010, ADV NEURAL INFORM PR, V23, P2451; Wolfson M, 2010, INT J EPIDEMIOL, V39, P1372, DOI 10.1093/ije/dyq111; Xiao X., 2007, P 2007 ACM SIGMOD IN, P689, DOI DOI 10.1145/1247480.1247556; Zhang C., 2012, J MACHINE LEARNING R, V22, P1398; Zhang J., 2012, P VLDB ENDOWMENT, V5, P1364	99	1	1	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5196			FRONT NEUROINFORM	Front. Neuroinformatics	APR 7	2014	8								35	10.3389/fninf.2014.00035		12	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	AZ3DO	WOS:000348108100001	24778614	
J	Zhong, GQ; Cheriet, M				Zhong, Guoqiang; Cheriet, Mohamed			Large Margin Low Rank Tensor Analysis	NEURAL COMPUTATION			English	Letter							NONLINEAR DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; COMPONENT ANALYSIS; MATRIX COMPLETION; NEURAL-NETWORKS; REPRESENTATION; RECOGNITION; FRAMEWORK	We present a supervised model for tensor dimensionality reduction, which is called large margin low rank tensor analysis (LMLRTA). In contrast to traditional vector representation-based dimensionality reduction methods, LMLRTA can take any order of tensors as input. And unlike previous tensor dimensionality reduction methods, which can learn only the low-dimensional embeddings with a priori specified dimensionality, LMLRTA can automatically and jointly learn the dimensionality and the low-dimensional representations from data. Moreover, LMLRTA delivers low rank projection matrices, while it encourages data of the same class to be close and of different classes to be separated by a large margin of distance in the low-dimensional tensor space. LMLRTA can be optimized using an iterative fixed-point continuation algorithm, which is guaranteed to converge to a local optimal solution of the optimization problem. We evaluate LMLRTA on an object recognition application, where the data are represented as 2D tensors, and a face recognition application, where the data are represented as 3D tensors. Experimental results show the superiority of LMLRTA over state-of-the-art approaches.	[Zhong, Guoqiang; Cheriet, Mohamed] Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 1K3, Canada	Zhong, GQ (reprint author), Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 1K3, Canada.	guoqiang.zhong@synchromedia.ca; mohamed.cheriet@etsmtl.ca					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y., 2003, ADV NEURAL INFORM PR, V16; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bondy J. A., 1976, GRAPH THEORY APPL; Candes E, 2012, COMMUN ACM, V55, P111, DOI 10.1145/2184319.2184343; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Chung F. R. K., 1997, SPECTRAL GRAPH THEOR; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Dai G., 2006, P NAT C ART INT, P330; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; de Silva V, 2008, SIAM J MATRIX ANAL A, V30, P1084, DOI 10.1137/06066518X; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203; Fukunnaga K., 1991, INTRO STAT PATTERN R; Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7; He X., 2003, ADV NEURAL INFORM PR, V16; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; LeCun Y., 2001, INTELLIGENT SIGNAL P, P306; Lee DD, 1999, NATURE, V401, P788; Liu J, 2012, PATTERN RECOGN, V45, P649, DOI 10.1016/j.patcog.2011.05.015; Liu Y, 2010, IEEE T NEURAL NETWOR, V21, P1848, DOI 10.1109/TNN.2010.2066574; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; Northcott D. G., 1984, MULTILINEAR ALGEBRA; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; ROSCH EH, 1973, COGNITIVE PSYCHOL, V4, P328, DOI 10.1016/0010-0285(73)90017-0; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; Sugiyama M, 2007, J MACH LEARN RES, V8, P1027; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang H., 2007, P 20 INT JOINT C ART; Weinberger K. Q., 2005, ADV NEURAL INFORM PR, V18; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131; Ye J., 2004, ADV NEURAL INFORM PR, V17; Zhong G., 2010, P 24 AAAI C ART INT	45	1	1	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667	1530-888X		NEURAL COMPUT	Neural Comput.	APR	2014	26	4					761	780		10.1162/NECO_a_00570		20	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AC3ZA	WOS:000332459100006	24479778	
J	Triefenbach, F; Demuynck, K; Martens, JP				Triefenbach, Fabian; Demuynck, Kris; Martens, Jean-Pierre			Large Vocabulary Continuous Speech Recognition With Reservoir-Based Acoustic Models	IEEE SIGNAL PROCESSING LETTERS			English	Article						Acoustic modeling; large vocabulary continuous speech recognition; reservoir computing; recurrent neural networks	SHORT-TERM-MEMORY; NETS	Thanks to research in neural network based acoustic modeling, progress in Large Vocabulary Continuous Speech Recognition (LVCSR) seems to have gained momentum recently. In search for further progress, the present letter investigates Reservoir Computing (RC) as an alternative new paradigm for acoustic modeling. RC unifies the appealing dynamical modeling capacity of a Recurrent Neural Network (RNN) with the simplicity and robustness of linear regression as a model for training the weights of that network. In previous work, an RC-HMM hybrid yielding very good phone recognition accuracy on TIMIT could be designed, but no proof was offered yet that this success would also transfer to LVCSR. This letter describes the development of an RC-HMM hybrid that provides good recognition on the Wall Street Journal benchmark. For the WSJ0 5k word task, word error rates of 6.2% (bigram language model) and 3.9% (trigram) are obtained on the Nov-92 evaluation set. Given that RC-based acoustic modeling is a fairly new approach, these results open up promising perspectives.	[Triefenbach, Fabian; Demuynck, Kris; Martens, Jean-Pierre] Univ Ghent, iMinds, ELIS Multimedia Lab, B-9000 Ghent, Belgium	Triefenbach, F (reprint author), Univ Ghent, iMinds, ELIS Multimedia Lab, B-9000 Ghent, Belgium.	fabian.triefenbach@elis.ugent.be; kris.demuynck@elis.ugent.be; martens@elis.ugent.be			European Community [231267]; Research Foundation Flanders (FWO) [G.0088.09N]	Manuscript received November 08, 2013; accepted January 15, 2014. Date of publication January 22, 2014; date of current version January 29, 2014. This work was supported by the European Community's Seventh Framework Program (FP7) under Grant 231267 "Self-organized recurrent neural learning of language processing" (ORGANIC) and from the Research Foundation Flanders (FWO) under Grant G.0088.09N (RECAP). The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Paris Smaragdis.	BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bourlard H., 1994, KLUWER INT SERIES EN, V247; Carnegie Mellon Univ, 2007, CMU PRON DICT V0 7A; DAHL GE, 2013, P ICASSP, P8609; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Demuynck K, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P495; Deng L., 2013, P ICASSP, P8599; Gemello R, 2007, SPEECH COMMUN, V49, P827, DOI 10.1016/j.specom.2006.11.005; Graves A., P ASRU WORKSH; GRAVES A, 2013, P ICASSP, P6645; Hardcastle WJ, 1999, COARTICULATION THEOR; Heigold G, 2010, INT CONF ACOUST SPEE, P5546, DOI 10.1109/ICASSP.2010.5495228; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hutchinson B, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4805; Jaeger H., 2002, 159 GERM NAT RES CTR; Jaeger H., 2001, ECHO STATE APPROACH; Jaitly N., 2012, P INTERSPEECH; Jalalvand A., COMPUTER SP IN PRESS; Jurafsky D, 2001, INT CONF ACOUST SPEE, P577, DOI 10.1109/ICASSP.2001.940897; LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P599, DOI 10.1109/29.52701; Leuven KU, 2010, SPEECH PROC REC AUT; MARQUARDT DW, 1975, AM STAT, V29, P3, DOI 10.2307/2683673; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; PAUL DB, 1992, HLT 91, P357; Penrose R., 1955, P CAMBRIDGE PHILOS S, V51, P406, DOI DOI 10.1017/S0305004100030401; Pinto J, 2011, IEEE T AUDIO SPEECH, V19, P225, DOI 10.1109/TASL.2010.2045943; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192; Robinson T., 1991, Computer Speech and Language, V5, DOI 10.1016/0885-2308(91)90010-N; SAINATH TN, 2013, P ICASSP, P8614; Sainath T.N., 2011, P ASRU, P30; Saon G, 2012, IEEE SIGNAL PROC MAG, V29, P18, DOI 10.1109/MSP.2012.2197156; Siniscalchi SM, 2013, IEEE T AUDIO SPEECH, V21, DOI 10.1109/TASL.2012.2234115; Siniscalchi SM, 2013, IEEE SIGNAL PROC LET, V20, P201, DOI 10.1109/LSP.2013.2237901; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Skowronski MD, 2007, NEURAL NETWORKS, V20, P414, DOI 10.1016/j.neunet.2007.04.006; TRIEFENBACH F, 2010, P NIPS, P2307; Triefenbach F, 2013, IEEE T AUDIO SPEECH, V21, P2439, DOI 10.1109/TASL.2013.2280209; Triefenbach F., 2011, Proceedings of the 2011 First International Conference on Informatics and Computational Intelligence (ICI 2011), DOI 10.1109/ICI.2011.50; Triefenbach F., 2013, P INTERSPEECH, P3342; Uebel L. F., 1999, P ESCA EUR 99 BUD HU, P2527; Verstraeten D, 2007, NEURAL NETWORKS, V20, P391, DOI 10.1016/j.neunet.2007.04.003; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; Wollmer M, 2013, COMPUT SPEECH LANG, V27, P780, DOI 10.1016/j.csl.2012.05.002; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4409	49	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9908	1558-2361		IEEE SIGNAL PROC LET	IEEE Signal Process. Lett.	MAR	2014	21	3					311	315		10.1109/LSP.2014.2302080		5	Engineering, Electrical & Electronic	Engineering	AB5ED	WOS:000331810800003		
J	Bottou, L				Bottou, Leon			From machine learning to machine reasoning An essay	MACHINE LEARNING			English	Article						Machine learning; Reasoning; Recursive networks	NETWORKS; SYSTEMS	A plausible definition of "reasoning" could be "algebraically manipulating previously acquired knowledge in order to answer a new question". This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated "all-purpose" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up.	Microsoft Res, Redmond, WA 98052 USA	Bottou, L (reprint author), Microsoft Res, Redmond, WA 98052 USA.	leon@bottou.org					Ahmed A., 2008, P 10 EUR C COMP VIS; Aiello M, 2007, HANDBOOK OF SPATIAL LOGICS, P1, DOI 10.1007/978-1-4020-5587-4; Bakir G. H., 2007, PREDICTING STRUCTURE; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bordes A., 2011, P 25 C ART INT AAAI; Bottou L., 2008, SEM PRES U MONTR JUN; Bottou L., 1991, ADV NEURAL INFORM PR, V3; Bottou L., 2011, ARXIV11021808V3; Bottou L, 1997, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.1997.609370; Buntine W. L., 1994, J ARTIFICIAL INTELLI, V2, P159; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Collobert R., 2011, P ART INT STAT AISTA; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Collobert R., 2007, P 45 ANN M ASS COMP, P560; Etter V., 2009, THESIS EPFL; Friedman N., 1999, P 16 INT JOINT C ART, P1300; Grangier D., 2009, ICML 2009 DEEP LEARN; Harris Z., 1968, MATH STRUCTURES LANG; HILBERT DAVID, 1928, GRUNDZUGE THEORETISC; HINTON GE, 1990, ARTIF INTELL, V46, P47, DOI 10.1016/0004-3702(90)90004-J; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D., 2007, P INT C COMP VIS CVP; Khardon R, 1997, J ACM, V44, P697, DOI 10.1145/265910.265918; LeCun Y., 2004, P COMP VIS PATT REC; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lighthill J., 1973, ARTIFICIAL INTELLIGE; Lonardi S., 1994, P NEUR NETW SIGN PRO; Mairal J., 2010, J MACH LEARN RES, V11, P10; Miller G. A., 1956, PSYCHOL REV, V63, P343; Miller M., 2006, COMMUNICATION; Minsky M, 1969, PERCEPTRONS; Neville J., 2003, P 2 INT WORKSH MULT, P77; NIPS, 1987, ADV NEUR PROC INF SY; Paccanaro A., 2001, ADV NEURAL INFORM PR, V14; Pearl J., 2000, CAUSALITY MODELS REA; Pearl J, 1988, PROBABILISTIC REASON; Piaget J., 1937, CONSTRUCTION REEL CH; Plate Tony, 1994, THESIS U TORONTO; POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K; Ponce J., 2006, P COMP VIS PATT REC, VII, P2169; Popper KR, 1959, LOGIC SCI DISCOVERY; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Riesenhuber M., 2003, VISUAL NEUROSCIENCES, V2, P1640; Robinson J. A., 1965, COMMUN ACM, V5, P23; Roth D, 1996, ARTIF INTELL, V82, P273, DOI 10.1016/0004-3702(94)00092-1; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M; Socher R, 2011, P 28 INT C MACH LEAR; Socher R., 2010, NIPS DEEP LEARN WORK; Sperduti A., 1994, ADV NEURAL INFORM PR, V5; Vapnik V. N., 1995, NATURE STAT LEARNING; von Ahn L, 2006, COMPUTER, V39, P92, DOI 10.1109/MC.2006.196; Welling M., 2009, P 26 ANN INT C MACH, P1121; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; Wiesel T. N., 1962, J PHYSL, V160, P106	55	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125	1573-0565		MACH LEARN	Mach. Learn.	FEB	2014	94	2			SI		133	149		10.1007/s10994-013-5335-x		17	Computer Science, Artificial Intelligence	Computer Science	302PH	WOS:000330616900002		
J	Kim, LW; Asaad, S; Linsker, R				Kim, Lok-Won; Asaad, Sameh; Linsker, Ralph			A Fully Pipelined FPGA Architecture of a Factored Restricted Boltzmann Machine Artificial Neural Network	ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS			English	Article						Design; Restricted Boltzmann Machine; FPGA based system design; hardware acceleration of Neural Network; pipelined and parallel hardware architecture	HARDWARE; IMPLEMENTATION	Artificial neural networks (ANNs) are a natural target for hardware acceleration by FPGAs and GPGPUs because commercial-scale applications can require days to weeks to train using CPUs, and the algorithms are highly parallelizable. Previous work on FPGAs has shown how hardware parallelism can be used to accelerate a "Restricted Boltzmann Machine" (RBM) ANN algorithm, and how to distribute computation across multiple FPGAs. Here we describe a fully pipelined parallel architecture that exploits "mini-batch" training (combining many input cases to compute each set of weight updates) to further accelerate ANN training. We implement on an FPGA, for the first time to our knowledge, a more powerful variant of the basic RBM, the "Factored RBM" (fRBM). The fRBM has proved valuable in learning transformations and in discovering features that are present across multiple types of input. We obtain (in simulation) a 100-fold acceleration (vs. CPU software) for an fRBM having N = 256 units in each of its four groups (two input, one output, one intermediate group of units) running on a Virtex-6 LX760 FPGA. Many of the architectural features we implement are applicable not only to fRBMs, but to basic RBMs and other ANN algorithms more broadly.	[Kim, Lok-Won] Cisco Syst Inc, San Jose, CA 95134 USA; [Asaad, Sameh; Linsker, Ralph] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	Kim, LW (reprint author), Cisco Syst Inc, San Jose, CA 95134 USA.	knoublok@ucla.edu; asaad@us.ibm.com; linsker@us.ibm.com					Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587; Boser B., 2002, IEEE J SOLID-ST CIRC, V26, P2017; Dias FM, 2004, ENG APPL ARTIF INTEL, V17, P945, DOI 10.1016/j.engappai.2004.08.011; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOLT JL, 1993, IEEE T COMPUT, V42, P281; Holt J., 1991, P INT JOINT C NEUR N, V2, P121; Jung S, 2007, IEEE T IND ELECTRON, V54, P265, DOI 10.1109/TIE.2006.888791; Kim S., 2010, P 2010 18 IEEE INT S, P201; Larkin D, 2006, LECT NOTES COMPUT SC, V3973, P1319; Lindsey C., 1994, P 3 WORKSH NEUR NETW, P26; Ly Daniel Le, 2010, IEEE Trans Neural Netw, V21, P1780, DOI 10.1109/TNN.2010.2073481; Maeda Y, 2003, IEEE T NEURAL NETWOR, V14, P688, DOI 10.1109/TNN.2003.811357; Memisevic R., 2010, NEURAL INF PROC SYST, V23, P1603; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Memisevic R., 2007, P S COMP VIS PATT RE; Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013; Raina R., 2009, P 26 ANN INT C MACH, P873; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; TAUSWORT.RC, 1965, MATH COMPUT, V19, P201, DOI 10.2307/2003345; Taylor G., 2009, P 26 INT C MACH LEAR; Zhu JH, 2003, LECT NOTES COMPUT SC, V2778, P1062	21	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1936-7406	1936-7414		ACM T RECONFIG TECHN	ACM T. Reconfigurable Technol. Syst.	FEB	2014	7	1							5	10.1145/2539125		23	Computer Science, Hardware & Architecture	Computer Science	AC4HV	WOS:000332482800005		
J	Zhang, CX; Zhang, JS; Ji, NN; Guo, G				Zhang, Chun-Xia; Zhang, Jiang-She; Ji, Nan-Nan; Guo, Gao			Learning ensemble classifiers via restricted Boltzmann machines	PATTERN RECOGNITION LETTERS			English	Article						Ensemble classifier; Bagging; Restricted Boltzmann machine; Deep learning; Majority voting; Diversity	COMBINING CLASSIFIERS; DATA SETS; CLASSIFICATION; ALGORITHMS	Recently, restricted Boltzmann machines (RBMs) have attracted considerable interest in machine learning field due to their strong ability to extract features. Given some training data, an RBM or a stack of several RBMs can be used to extract informative features. Meanwhile, ensemble learning is an active research area in machine learning owing to their potential to greatly increase the prediction accuracy of a single classifier. However, RBMs have not been studied to work with ensemble learning so far. In this study, we present several methods for integrating RBMs with bagging to generate diverse and accurate individual classifiers. Taking a classification tree as the base learning algorithm, a thoroughly experimental study conducted on 31 real-world data sets yields some promising conclusions. When using the features extracted by RBMs in ensemble learning, the best way is to perform model combination respectively on the original feature set and the one extracted by a single RBM. However, the prediction performance becomes worse when the features detected by a stack of 2 RBMs are also considered. As for the features detected by RBMs, good classification can be obtained only when they are used together with the original features. (C) 2013 Elsevier B.V. All rights reserved.	[Zhang, Chun-Xia; Zhang, Jiang-She; Ji, Nan-Nan] Xi An Jiao Tong Univ, Fac Math & Stat, Inst Stat Decis & Machine Learning, Xian 710049, Shaanxi, Peoples R China; [Guo, Gao] Xian Univ Technol, Sch Sci, Dept Appl Math, Xian 710054, Shaanxi, Peoples R China	Zhang, CX (reprint author), Xi An Jiao Tong Univ, Fac Math & Stat, Inst Stat Decis & Machine Learning, Xian 710049, Shaanxi, Peoples R China.	cxzhang@mail.xjtu.edu.cn			National Basic Research Program of China (973 Program) [2013CB329406]; National Natural Science Foundations of China [11201367, 61075006]; Major Research Project of the National Natural Science Foundation of China [91230101]; Research Fund for the Doctoral Program of Higher Education of China [20100201120048]; Fundamental Research Funds for the Central Universities of China; Foundation of Shaanxi Provincial Department of Education in China [09JK615]	This research was supported by the National Basic Research Program of China (973 Program, No. 2013CB329406), the National Natural Science Foundations of China (Nos. 11201367, 61075006), the Major Research Project of the National Natural Science Foundation of China (No. 91230101), the Research Fund for the Doctoral Program of Higher Education of China (No. 20100201120048), the Fundamental Research Funds for the Central Universities of China and the Foundation of Shaanxi Provincial Department of Education in China (No. 09JK615).	Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Baumgartner D, 2012, INTELL DATA ANAL, V16, P233, DOI 10.3233/IDA-2012-0521; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2012, COMPUT INTELL-US, V28, P261, DOI 10.1111/j.1467-8640.2012.00419.x; Bengio Y., 2012, LECT NOTES COMPUTER, V7700, P437; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brugge K, 2013, MACH LEARN, V93, P53, DOI 10.1007/s10994-013-5390-3; Cai X.G., 2012, P IEEE INT C COMP SC, P80; Cheng J, 2006, PATTERN RECOGN, V39, P81, DOI 10.1016/j.patcog.2005.06.018; Crawford M, 2009, LECT NOTES COMPUT SC, V5519, P519, DOI 10.1007/978-3-642-02326-2_52; De Bock KW, 2011, EXPERT SYST APPL, V38, P12293, DOI 10.1016/j.eswa.2011.04.007; Demsar J, 2006, J MACH LEARN RES, V7, P1; Duin R., 2007, PRTOOLS4 MATLAB TOOL; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025; Fischer A., 2012, LNCS, V7441, P14; Frank A, 2010, UCI MACHINE LEARNING; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Garcia-Pedrajas N, 2007, J MACH LEARN RES, V8, P1; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hothorn T, 2003, PATTERN RECOGN, V36, P1303, DOI 10.1016/S0031-3203(02)00169-3; Kuncheva LI, 2004, COMBINING PATTERN CL; Larochelle H, 2012, J MACH LEARN RES, V13, P643; Loeff N., 2008, P 25 INT C MACH LEAR, P600, DOI 10.1145/1390156.1390232; Plumpton CO, 2012, PATTERN RECOGN, V45, P2101, DOI 10.1016/j.patcog.2011.04.023; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Rodriguez JJ, 2011, LECT NOTES COMPUT SC, V6713, P76, DOI 10.1007/978-3-642-21557-5_10; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7; Rokach L, 2009, COMPUT STAT DATA AN, V53, P4046, DOI 10.1016/j.csda.2009.07.017; Sammut C, 2011, ENCY MACHINE LEARNIN; Sun ZL, 2012, IEEE SIGNAL PROC LET, V19, P455, DOI 10.1109/LSP.2012.2202317; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Ting K.M., 1999, J KNOWL INF SYST, V1; Tran T., 2011, J MACH LEARN RES, V20, P213; Wang GW, 2012, MATH PROBL ENG, DOI 10.1155/2012/346951; Wang Z, 2013, KNOWL-BASED SYST, V37, P388, DOI 10.1016/j.knosys.2012.08.017; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Zhang CX, 2010, PATTERN ANAL APPL, V13, P59, DOI 10.1007/s10044-009-0168-8; Zhang CX, 2011, PATTERN RECOGN LETT, V32, P1756, DOI 10.1016/j.patrec.2011.07.009; Zhang CX, 2009, LECT NOTES COMPUT SC, V5519, P478; Zhang ML, 2013, DATA MIN KNOWL DISC, V26, P98, DOI 10.1007/s10618-011-0243-9; Zhang Y, 2010, IEEE T PATTERN ANAL, V32, P1758, DOI 10.1109/TPAMI.2009.195; Zhou Z.-H., 2012, ENSEMBLE METHODS FDN; Zhu D, 2010, DECIS SUPPORT SYST, V48, P480, DOI 10.1016/j.dss.2009.06.007	54	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 15	2014	36						161	170		10.1016/j.patrec.2013.10.009		10	Computer Science, Artificial Intelligence	Computer Science	282BO	WOS:000329145400020		
S	Tran, HN; Huynh, T; Do, T		Nguyen, NT; Attachoo, B; Trawinski, B; Somboonviwat, K		Hung Nghiep Tran; Tin Huynh; Tien Do			Author Name Disambiguation by Using Deep Neural Network	INTELLIGENT INFORMATION AND DATABASE SYSTEMS, PT 1	Lecture Notes in Computer Science		English	Proceedings Paper	6th Asian Conference on Intelligent Information and Database Systems (ACIIDS)	APR 07-09, 2014	Bangkok, THAILAND	King Mongkuts Inst Technol Ladkrabang, Wroclaw Univ Technol, IEEE SMC Tech Comm Computat Collect Intelligence, Hue Univ, Univ Informat Technol HCM, Quang Binh Univ		Digital Library; Bibliographic Data; Author Name Disambiguation; Machine Learning; Feature Learning; Deep Neural Network		Author name ambiguity is one of the problems that decrease the quality and reliability of information retrieved from digital libraries. Existing methods have tried to solve this problem by predefining a feature set based on expert's knowledge for a specific dataset. In this paper, we propose a new approach which uses deep neural network to learn features automatically for solving author name ambiguity. Additionally, we propose the general system architecture for author name disambiguation on any dataset. We evaluate the proposed method on a dataset containing Vietnamese author names. The results show that this method significantly outperforms other methods that use predefined feature set. The proposed method achieves 99.31% in terms of accuracy. Prediction error rate decreases from 1.83% to 0.69%, i.e., it decreases by 1.14%, or 62.3% relatively compared with other methods that use predefined feature set (Table 3).	[Hung Nghiep Tran; Tin Huynh; Tien Do] Univ Informat Technol Vietnam, Linh Trung Ward, Ho Chi Minh City, Vietnam	Tran, HN (reprint author), Univ Informat Technol Vietnam, Linh Trung Ward, Ho Chi Minh City, Vietnam.	nghiepth@uit.edu.vn; tinhn@uit.edu.vn; tiendv@uit.edu.vn					Bhattacharya I., 2007, ACM T KNOWL DISCOV D, V1; Bilenko M, 2003, IEEE INTELL SYST, V18, P16, DOI 10.1109/MIS.2003.1234765; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Cohen W.W., 2003, IIWEB, P73; Ferreira AA, 2012, SIGMOD REC, V41, P15, DOI 10.1145/2350036.2350040; Glorot X., 2011, AISTATS, P315; Glorot X., 2010, J MACH LEARN RES P T, V9, P249; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huynh T, 2013, LECT NOTES COMPUT SC, V7802, P226; Krizhevsky A., 2012, NIPS, V25, P1106; Ranzato M., 2007, NIPS; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Torvik Vetle I., 2009, ACM T KNOWL DISCOV D, V3; Torvik VI, 2005, J AM SOC INF SCI TEC, V56, P140, DOI [10.1002/asi.20105, 10.1002/asi/20105]; Yu D., 2013, CORRABS13013605	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-05476-6; 978-3-319-05475-9	LECT NOTES COMPUT SC			2014	8397						123	132				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BA6XT	WOS:000337302600013		
S	Schlegl, T; Ofner, J; Langs, G		Menze, B; Langs, G; Montillo, A; Kelm, M; Muller, H; Zhang, S; Cai, W; Metaxas, D		Schlegl, Thomas; Ofner, Joachim; Langs, Georg			Unsupervised Pre-training Across Image Domains Improves Lung Tissue Classification	MEDICAL COMPUTER VISION: ALGORITHMS FOR BIG DATA	Lecture Notes in Computer Science		English	Proceedings Paper	International Workshop on Medical Computer Vision - Algorithms for Big Data ((MICCAI-bigMCV)	SEP 18, 2014	Cambridge, MA	European Commiss 7 th Framework Programme, VISCERAL, Khresmoi			RECOGNITION	The detection and classification of anomalies relevant for disease diagnosis or treatment monitoring is important during computational medical image analysis. Often, obtaining sufficient annotated training data to represent natural variability well is unfeasible. At the same time, data is frequently collected across multiple sites with heterogeneous medical imaging equipment. In this paper we propose and evaluate a semi-supervised learning approach that uses data from multiple sites (domains). Only for one small site annotations are available. We use convolutional neural networks to capture spatial appearance patterns and classify lung tissue in high-resolution computed tomography data. We perform domain adaptation via unsupervised pre-training of convolutional neural networks to inject information from sites or image classes for which no annotations are available. Results show that across site pre-training as well as pre-training on different image classes improves classification accuracy compared to random initialisation of the model parameters.	[Schlegl, Thomas; Ofner, Joachim; Langs, Georg] Med Univ Vienna, Dept Biomed Imaging & Image Guided Therapy, Computat Imaging Res Lab, Vienna, Austria	Schlegl, T (reprint author), Med Univ Vienna, Dept Biomed Imaging & Image Guided Therapy, Computat Imaging Res Lab, Vienna, Austria.	thomas.schlegl@meduniwien.ac.at; joachim.ofner@meduniwien.ac.at; georg.langs@meduniwien.ac.at					Bengio Y., 2012, JMLR WORKSHOPS C P, V27, P17; Bergstra J., 2010, P PYTH SCI COMP C SC, V4; Brosch T, 2013, LECT NOTES COMPUT SC, V8150, P633, DOI 10.1007/978-3-642-40763-5_78; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51; Coates A, 2011, INT C ART INT STAT, P215; Depeursinge A., 2007, 29 ANN INT C IEEE EM, P6259, DOI 10.1109/IEMBS.2007.4353786; Erhan D, 2010, J MACH LEARN RES, V11, P625; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holmes III D., 2006, INSIGHT J MICCAI OPE; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V1, P4; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Nair V., 2010, P 27 INT C MACH LEAR, P807; Ryu JH, 2007, MAYO CLIN PROC, V82, P976; Zavaletta VA, 2007, ACAD RADIOL, V14, P772, DOI 10.1016/j.acra.2007.03.009	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-13972-2; 978-3-319-13971-5	LECT NOTES COMPUT SC			2014	8848						82	93		10.1007/978-3-319-13972-2_8		12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC7DP	WOS:000354780800008		
J	Ban, JC; Chang, CH				Ban, Jung-Chao; Chang, Chih-Hung			The learning problem of multi-layer neural networks	NEURAL NETWORKS			English	Article						Multi-layer neural networks; Topological entropy; Sofic shift; Learning problem; Linear separation	PATTERN-RECOGNITION; ALGORITHM; NETS	This manuscript considers the learning problem of multi-layer neural networks (MNNs) with an activation function which comes from cellular neural networks. A systematic investigation of the partition of the parameter space is provided. Furthermore, the recursive formula of the transition matrix of an MNN is obtained. By implementing the well-developed tools in the symbolic dynamical systems, the topological entropy of an MNN can be computed explicitly. A novel phenomenon, the asymmetry of a topological diagram that was seen in Ban, Chang, Lin, and Lin (2009) [J. Differential Equations 246, pp. 552-580,2009], is revealed. (C) 2013 Elsevier Ltd. All rights reserved.	[Ban, Jung-Chao] Natl Dong Hwa Univ, Dept Appl Math, Hualien 970003, Taiwan; [Chang, Chih-Hung] Feng Chia Univ, Dept Appl Math, Taichung 40724, Taiwan	Chang, CH (reprint author), Feng Chia Univ, Dept Appl Math, Taichung 40724, Taiwan.	jcban@mail.ndhu.edu.tw; chihhung@mail.fcu.edu.tw			National Science Council, ROC [NSC 100-2115-M-259-009-MY2, NSC 101-2115-M-035-002-]	Ban is partially supported by the National Science Council, ROC (Contract No NSC 100-2115-M-259-009-MY2). Chang is grateful for the partial support of the National Science Council, ROC (Contract No NSC 101-2115-M-035-002-).	Alsultanny YA, 2003, NEUROCOMPUTING, V51, P237, DOI 10.1016/S0925-2312(02)00619-7; Ban JC, 2012, J DIFFER EQUATIONS, V252, P4563, DOI 10.1016/j.jde.2012.01.006; Ban JC, 2009, J DIFFER EQUATIONS, V246, P552, DOI 10.1016/j.jde.2008.05.004; Ban J.-C., 2011, DIAMOND MULTIL UNPUB; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; CHUA LO, 1988, IEEE T CIRCUITS SYST, V35, P1257, DOI 10.1109/31.7600; Chua LO, 1998, WORLD SCI SERIES N A, V31; Freund Y., 1994, UCSCCRL9425; Fukushima K., 2013, NEURAL NETWORKS, V37, P107; Fukushima K, 2013, NEURAL NETWORKS, V40, P18, DOI 10.1016/j.neunet.2013.01.001; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hsu CH, 2000, INT J BIFURCAT CHAOS, V10, P1645, DOI 10.1142/S0218127400001031; Juang J, 2000, SIAM J APPL MATH, V60, P891, DOI 10.1137/S0036139997323607; Kurkova V, 2013, LECT NOTES COMPUT SC, V7824, P30, DOI 10.1007/978-3-642-37213-1_4; Lay R., 1992, CONVEX SETS THEIR AP; Lind D., 1995, INTRO SYMBOLIC DYNAM; Peterson C., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000414; Serre T, 2007, PROG BRAIN RES, V165, P33, DOI 10.1016/S0079-6123(06)65004-8; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319; WIDROW B, 1988, IEEE T ACOUST SPEECH, V36, P1109, DOI 10.1109/29.1638; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323	24	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	OCT	2013	46						116	123		10.1016/j.neunet.2013.05.006		8	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	230AL	WOS:000325308900012	23727442	
J	Brakel, P; Stroobandt, D; Schrauwen, B				Brakel, Philemon; Stroobandt, Dirk; Schrauwen, Benjamin			Training Energy-Based Models for Time-Series Imputation	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						neural networks; energy-based models; time-series; missing values; optimization	EXPERTS	Imputing missing values in high dimensional time-series is a difficult problem. This paper presents a strategy for training energy-based graphical models for imputation directly, bypassing difficulties probabilistic approaches would face. The training strategy is inspired by recent work on optimization-based learning (Domke, 2012) and allows complex neural models with convolutional and recurrent structures to be trained for imputation tasks. In this work, we use this training strategy to derive learning rules for three substantially different neural architectures. Inference in these models is done by either truncated gradient descent or variational mean-field iterations. In our experiments, we found that the training methods outperform the Contrastive Divergence learning algorithm. Moreover, the training methods can easily handle missing values in the training data itself during learning. We demonstrate the performance of this learning scheme and the three models we introduce on one artificial and two real-world data sets.	[Brakel, Philemon; Stroobandt, Dirk; Schrauwen, Benjamin] Univ Ghent, Dept Elect & Informat Syst, B-9000 Ghent, Belgium	Brakel, P (reprint author), Univ Ghent, Dept Elect & Informat Syst, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.	PHILEMON.BRAKEL@UGENT.BE; DIRK.STROOBANDT@UGENT.BE; BENJAMIN.SCHRAUWEN@UGENT.BE			FWO Flanders [G.0088.09]	This article was written under partial support by the FWO Flanders project G.0088.09.	Barbu A, 2009, IEEE T IMAGE PROCESS, V18, P2451, DOI 10.1109/TIP.2009.2028254; Bengio Y, 1996, ADV NEUR IN, V8, P395; Bergstra J., 2010, P PYTH SCI COMP C, P3; Bertalmio M, 2000, COMP GRAPH, P417; Bertsekas D. P., 1999, NONLINEAR PROGRAMMIN; Bishop CM, 2006, PATTERN RECOGNITION; Boulanger-Lewandowski N., 2012, P 29 INT C MACH LEAR; Brakel P., 2012, LECT NOTES COMPUTER, V7553, P92; Desjardins G., 2010, P 13 INT C ART INT S, P145; Domke J., 2011, P 2011 IEEE C COMP V, P2937, DOI [10.1109/CVPR.2011.5995320, DOI 10.1109/CVPR.2011.5995320]; Domke J., 2012, P INT C ART INT STAT, P318; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Frank A, 2010, UCI MACHINE LEARNING; Freire A. L., 2009, 6 LAT AM ROB S, P1, DOI DOI 10.1109/LARS.2009.5418323; Freund Y., 1994, TECHNICAL REPORT; Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087; Ghahramani Z., 1999, ADV NEURAL INFORMATI, P599; Gupta A., 1996, J OPERATIONAL RES SO, P229; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Jain V., 2007, INT C COMP VIS, P1; Koller D., 2009, PROBABILISTIC GRAPHI, Vfirst; Larochelle H., 2011, JMLR W CP, V15, P29; Lawrence N. D., 2003, ADV NEURAL INFORM PR; Lawrence N. D., 2007, P 11 INT C ART INT S, P21; LeCun Y., 2005, P 10 INT C ART INT S; LeCun Y., 2006, PREDICTING STRUCTURE; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Mirowski P., 2009, P EUR C MACH LEARN; Nelwamondo F. V., 2007, MISSING DATA COMP NE; Pearl J, 1988, PROBABILISTIC REASON; PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147; Polyak B. T., 1964, USSR COMP MATH MATH, V4, P1, DOI 10.1016/0041-5553(64)90137-5; Roth S, 2005, PROC CVPR IEEE, P860; Salakhutdinov R., 2009, P INT C ART INT STAT; Salakhutdinov R., 2010, P INT C ART INT STAT; Stoyanov V., 2011, P 14 INT C ART INT S, V15, P725; Sutskever I., 2008, ADV NEURAL INFORM PR, V21; Tappen M. F., 2007, CVPR; Taylor G, 2007, PROF ENG, V20, P19; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P INT C MACH LEARN; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Wainwright M. J., 2008, GRAPHICAL MODELS EXP; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Williams C. K., 1991, CONNECTIONIST MODELS, P18	48	1	1	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	SEP	2013	14						2771	2797				27	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	252LW	WOS:000327007400009		
J	Memisevic, R				Memisevic, Roland			Learning to Relate Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Learning image relations; spatiotemporal features; mapping units; energy models; complex cells	NATURAL IMAGES; BINOCULAR DISPARITY; STEREO DISPARITY; NEURAL-NETWORKS; ENERGY MODELS; COMPUTATION; STATISTICS; EMERGENCE; MOTION	A fundamental operation in many vision tasks, including motion understanding, stereopsis, visual odometry, or invariant recognition, is establishing correspondences between images or between images and data from other modalities. Recently, there has been increasing interest in learning to infer correspondences from data using relational, spatiotemporal, and bilinear variants of deep learning methods. These methods use multiplicative interactions between pixels or between features to represent correlation patterns across multiple images. In this paper, we review the recent work on relational feature learning, and we provide an analysis of the role that multiplicative interactions play in learning to encode relations. We also discuss how square-pooling and complex cell models can be viewed as a way to represent multiplicative interactions and thereby as a way to encode relations.	Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada	Memisevic, R (reprint author), Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada.	memisevr@iro.umontreal.ca			German Federal Ministry of Education and Research (BMBF) [01GQ0841]	The author thanks Felix Bauer, Yoshua Bengio, Taco Cohen, Georgios Exarchakis, Geoffrey Hinton, Kishore Konda, Christoph von der Malsburg, Joshua Susskind and Christopher Zach for useful discussions and the reviewers for their useful suggestions. This work was supported in part by the German Federal Ministry of Education and Research (BMBF) in the project 01GQ0841 (BFNT Frankfurt).	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Archie KA, 2000, NAT NEUROSCI, V3, P54, DOI 10.1038/71125; Bauer F., 2012, THESIS I INFORM; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Bethge M., 2007, P SPIE HUMAN VISION, VXII, P1; Cadieu C.F., 2011, NEURAL COMPUT, V24, P827; Coates A., 2011, P 14 INT C ART INT S; Courville A., 2011, P C ART INT STAT; Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312; Fleet DJ, 1996, VISION RES, V36, P1839, DOI 10.1016/0042-6989(95)00313-4; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Gallant J.L., 1993, SCIENCE, V259, P1001; GILES CL, 1987, APPL OPTICS, V26, P4972, DOI 10.1364/AO.26.004972; Gray R. M., 2005, COMMUN INF THEORY, V2, P155; Grimes DB, 2005, NEURAL COMPUT, V17, P47, DOI 10.1162/0899766052530893; Hartley R., 2004, MULTIPLE VIEW GEOMET; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, TECHNICAL REPORT; Hinton G.F., 1981, P 7 INT JOINT C ART, V2, P683; Hofstadter D.R., 1984, 755 AI MIT; Horn R. A., 1990, MATRIX ANAL; Hoyer PO, 2002, VISION RES, V42, P1593, DOI 10.1016/S0042-6989(02)00017-2; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A, 2009, NATURAL IMAGE STAT P; Hyvarinen A, 2000, LECT NOTES COMPUT SC, V1811, P535; Karklin Y., 2006, P ADV NEUR INF PROC, V18; Kohonen T., 1995, P ICANN 95, VI, P3; Krizhevsky A., 2012, P ADV NEUR INF PROC; Larochelle H., 2010, P ADV NEUR INF PROC, P1243; Le Q.V., 2011, P IEEE C COMP VIS PA; Memisevic R., 2011, P IEEE INT C COMP VI; Memisevic R., 2008, THESIS U TORONTO; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Memisevic R., 2007, P IEEE C COMP VIS PA; Memisevic R., 2010, P ADV NEUR INF PROC, P22; Memisevic R., 2012, P INT C MACH LEARN J; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; OHZAWA I, 1990, SCIENCE, V249, P1037, DOI 10.1126/science.2396096; Olshausen B., 2007, P SPIE HUMAN VISION, V6492; Olshausen B., 1994, THESIS CALIFORNIA I; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Plate T. A., 1991, P 12 INT JOINT C ART, P30; QIAN N, 1994, NEURAL COMPUT, V6, P390, DOI 10.1162/neco.1994.6.3.390; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Ranzato M., 2010, P 13 INT C ART INT S; Ross D.A., 2006, P 23 INT C MACH LEAR, P761, DOI 10.1145/1143844.1143940; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1, P45; SANGER TD, 1988, BIOL CYBERN, V59, P405, DOI 10.1007/BF00336114; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M; Susskind J., 2011, P IEEE C COMP VIS PA; Sutskever I., 2011, P 28 INT C MACH LEAR, P1017; Tang Y., 2012, P IEEE C COMP VIS PA; Taylor G., 2009, P 26 ANN INT C MACH, P1025; Taylor G., 2010, P IEEE C COMP VIS PA; Taylor G.W., 2010, P EUR C COMP VIS; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Troje NF, 1996, VISION RES, V36, P1761, DOI 10.1016/0042-6989(95)00230-8; Vincent P., 2008, P 25 INT C MACH LEAR; Von Der Malsburg C., 1994, MODELS NEURAL NETWOR, V2, P95, DOI 10.1007/978-1-4612-4320-5_2; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; Welling M., 2002, P ADV NEUR INF PROC; Zetzsche C, 2005, NETWORK-COMP NEURAL, V16, P191, DOI 10.1080/09548980500463982; Zou W.Y., 2012, P ADV NEUR INF PROC, V25	65	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1829	1846		10.1109/TPAMI.2013.53		18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	164AP	WOS:000320381400003	23787339	
J	Tamilselvan, P; Wang, PF; Pecht, M				Tamilselvan, Prasanna; Wang, Pingfeng; Pecht, Michael			A multi-attribute classification fusion system for insulated gate bipolar transistor diagnostics	MICROELECTRONICS RELIABILITY			English	Article; Proceedings Paper	13th EuroSimE International Conference on Thermal, Mechanical and Multi-Physics Simulation and Experiments in Micro-Electronics and Micro-Systems	APR 16-18, 2012	Cascais, PORTUGAL				ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; SELF-ORGANIZING MAP; FAULT-DIAGNOSIS; ENSEMBLE; PROPAGATION; ALGORITHMS; SURROGATES; PREDICTION; WEAR	Effective health diagnosis provides benefits such as improved safety, improved reliability, and reduced costs for the operation and maintenance of complex engineered systems. This paper presents a multi-attribute classification fusion system which leverages the strengths provided by multiple membership classifiers to form a robust classification model for insulated gate bipolar transistor (IGBT) health diagnostics. The developed diagnostic system employs a k-fold cross-validation model for the evaluation of membership classifiers, and develops a multi-attribute classification fusion approach based on a weighted majority voting with dominance scheme. An experimental study of IGBT degradation was first carried out for the identification of failure precursor parameters, and classification techniques (e.g., supervised learning, unsupervised learning, and statistical inference) were then employed as the member algorithms for the development of a robust IGBT classification fusion system. In this study, the developed classification fusion model based on multiple member classification algorithms outperformed each stand-alone method for IGBT health diagnostics by providing better diagnostic accuracy and robustness. The developed multi-attribute classification fusion system provides an effective tool for the continuous monitoring of IGBT health conditions and enables the development of IGBT failure prognostics systems. (C) 2013 Elsevier Ltd. All rights reserved.	[Tamilselvan, Prasanna; Wang, Pingfeng] Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA; [Pecht, Michael] Univ Maryland, CALCE, College Pk, MD 20742 USA	Wang, PF (reprint author), Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA.	pingfeng.wang@wichita.edu	Wang, Pingfeng/D-3764-2011	Wang, Pingfeng/0000-0002-2160-4917			Abbasion S, 2007, MECH SYST SIGNAL PR, V21, P2933, DOI 10.1016/j.ymssp.2007.02.003; Acar E, 2009, STRUCT MULTIDISCIP O, V37, P279, DOI 10.1007/s00158-008-0230-y; ALGUINDIGUE IE, 1993, IEEE T IND ELECTRON, V40, P209, DOI 10.1109/41.222642; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Baraldi P, 2011, RELIAB ENG SYST SAFE, V96, P480, DOI 10.1016/j.ress.2010.11.005; Bishop CM, 2005, NEURAL NETWORKS PATT; Booth C, 1998, NEUROCOMPUTING, V23, P97, DOI 10.1016/S0925-2312(98)00064-2; Breikin T, 2005, 16 IFAC WORLD C; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chen SY, 2009, EXPERT SYST APPL, V36, P10976, DOI 10.1016/j.eswa.2009.02.039; Coit DW, 2000, IIE TRANS, V32, P1161, DOI 10.1080/07408170008967470; Dekker R, 1996, RELIAB ENG SYST SAFE, V51, P229, DOI 10.1016/0951-8320(95)00076-3; Ebeling C. E., 1997, INTRO RELIABILITY MA; Elsayed EA, 2000, INT J PROD RES, V38, P1953, DOI 10.1080/002075400188438; Evensen G., 2003, OCEAN DYNAM, V53, P343, DOI DOI 10.1007/S10236-003-0036-9; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; Gao J., 2010, TUT SIAM DAT MIN C S; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Geramifard O, 2010, 8 IEEE INT C CONTR A, P1618; Goel T, 2007, STRUCT MULTIDISCIP O, V33, P199, DOI 10.1007/s00158-006-0051-9; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu C, 2012, RELIAB ENG SYST SAFE, V103, P120, DOI 10.1016/j.ress.2012.03.008; Hu JJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-342; Huang RQ, 2007, MECH SYST SIGNAL PR, V21, P193, DOI 10.1016/j.ymssp.2005.11.008; Kohavi R, 1995, P INT JOINT C ART IN; Li Y, 1999, TRIBOL T, V42, P385, DOI 10.1080/10402009908982232; Licht T., 2003, AM SOC MECH ENG DYN, V71, P1059; Macian V, 2003, TRIBOL INT, V36, P771, DOI 10.1016/S0301-679X(03)00060-4; MARTIN KF, 1994, INT J MACH TOOL MANU, V34, P527, DOI 10.1016/0890-6955(94)90083-3; Patil N, 2009, 10 INT C THERM MECH; Patil N, 2009, IEEE T RELIAB, V58, P271, DOI 10.1109/TR.2009.2020134; Patil N, 2010, P 17 INT C CONC ENG, P583; Patil N, 2010, INT C REL SAF HAZ IC; Pawar PM, 2007, MECH SYST SIGNAL PR, V21, P2212, DOI 10.1016/j.ymssp.2006.09.006; Pecht M., 2008, PROGNOSTICS HLTH MAN; Perrone MP, 1993, NEURAL NETWORKS SPEE; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Saimurugan M, 2010, EXPERT SYSTEMS APPL, V115, P24; Samanta B, 2004, MECH SYST SIGNAL PR, V18, P625, DOI 10.1016/S0888-3270(03)00020-7; Saxena A, 2007, APPL SOFT COMPUT, V7, P441, DOI 10.1016/j.asoc.2005.10.001; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Srinivasan S, 2007, IRAN J ELECT COMPUTE, V6, P62; Sun J, 2004, INT J MACH TOOL MANU, V44, P1179, DOI 10.1016/j.ijmachtools.2004.04.003; Tamilselvan P, 2013, RELIAB ENG SYST SAFE, V115, P124, DOI 10.1016/j.ress.2013.02.022; Wang P., 2010, ANN C PROGN HLTH MAN; Wong MLD, 2006, MECH SYST SIGNAL PR, V20, P593, DOI 10.1016/j.ymssp.2005.01.008; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Zerpa LE, 2005, J PETROL SCI ENG, V47, P197, DOI 10.1016/j.petrol.2005.03.002; Zhang L, 2010, EXPERT SYST APPL, V37, P6077, DOI 10.1016/j.eswa.2010.02.118; Zhao XL, 2007, SMART MATER STRUCT, V16, P1208, DOI 10.1088/0964-1726/16/4/032	53	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0026-2714			MICROELECTRON RELIAB	Microelectron. Reliab.	AUG	2013	53	8					1117	1129		10.1016/j.microrel.2013.04.011		13	Engineering, Electrical & Electronic; Nanoscience & Nanotechnology; Physics, Applied	Engineering; Science & Technology - Other Topics; Physics	189TV	WOS:000322292100010		
J	Banerjee, B; Dutta, JK		Ding, W; Washio, T; Xiong, H; Karypis, G; Thuraisingham, B; Cook, D; Wu, X		Banerjee, Bonny; Dutta, Jayanta K.			An Online Clustering Algorithm that Ignores Outliers: Application to Hierarchical Feature Learning from Sensory Data	2013 IEEE 13TH INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS (ICDMW)	IEEE International Conference on Data Mining		English	Proceedings Paper	IEEE 13th International Conference on Data Mining (ICDM)	DEC 07-10, 2013	Dallas, TX	IEEE, IEEE Comp Soc, NSF, Toshiba, KNIME, TechMatrix, Univ Texas Dallas, Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Dept Comp Sci		outlier; spherical clustering; Hebbian rule	DEEP BELIEF; AREA V2; ARCHITECTURE; RECOGNITION; STIMULI; SHAPES	Surveillance sensors are a major source of unstructured Big Data. Discovering and recognizing spatiotemporal objects (e.g., events) in such data is of paramount importance to the security and safety of facilities and individuals. Hierarchical feature learning is at the crux to the problems of discovery and recognition. We present a multilayered convergent neural architecture for storing repeating spatially and temporally coincident patterns in data at multiple levels of abstraction. The bottom-up weights in each layer are learned to encode a hierarchy of overcomplete and sparse feature dictionaries from space- and time-varying sensory data by recursive layer-by-layer spherical clustering. This densitybased clustering algorithm ignores outliers by the use of a unique adaptive threshold in each neuron's transfer function. The model scales to full-sized high-dimensional input data and also to an arbitrary number of layers, thereby possessing the capability to capture features at any level of abstraction. It is fully-learnable with only two manually tunable parameters. The model was deployed to learn meaningful feature hierarchies from audio, images and videos which can then be used for recognition and reconstruction. Besides being online, operations in each layer of the model can be implemented in parallelized hardware, making it very efficient for real world Big Data applications.	[Banerjee, Bonny] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA	Banerjee, B (reprint author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.	bbnerjee@memphis.edu; jkdutta@memphis.edu					Aloise D, 2009, MACH LEARN, V75, P245, DOI 10.1007/s10994-009-5103-0; Balboa RM, 2000, VISUAL NEUROSCI, V17, P77; Banerjee A, 2004, IEEE T NEURAL NETWOR, V15, P702, DOI 10.1109/TNN.2004.824416; Berkhin P., 2002, SURVEY CLUSTERING DA; Blake C., 1998, UCI REPOSITORY MACHI; Bouvrie J, 2008, INT CONF ACOUST SPEE, P4733, DOI 10.1109/ICASSP.2008.4518714; Dasgupta S, 2009, IEEE T INFORM THEORY, V55, P3229, DOI 10.1109/TIT.2009.2021326; Datta A, 2001, PATTERN RECOGN, V34, P617, DOI 10.1016/S0031-3203(00)00013-3; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Einhauser W, 2002, EUR J NEUROSCI, V15, P475, DOI 10.1046/j.0953-816x.2001.01885.x; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; George D., 2008, THESIS STANFORD U CA; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hegde J, 2000, J NEUROSCI, V20, part. no.; Hermansky H., 2003, IEEE WORKSH AUT SPEE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hubel D, 1995, EYE BRAIN VISION; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Ji S., 2010, INT C MACH LEARN, P221; Le Q. V., 2011, IEEE C COMP VIS PATT, P3361; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2010, ADV NEURAL INFORM PR, V22; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Mahajan M, 2009, LECT NOTES COMPUT SC, V5431, P274; Mailhe B., 2008, P EUR SIGN PROC C LA; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Mitchell T. M., 1997, MACHINE LEARNING; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485; Strehl A., 2000, AAAI WORKSH AI WEB S, P58; Theis L, 2011, J MACH LEARN RES, V12, P3071; Vincent P., 2008, INT C MACH LEARN, P1096; Zhong S, 2003, J MACHINE LEARNING R, V4, P1001, DOI 10.1162/jmlr.2003.4.6.1001; Zhong S, 2005, IEEE IJCNN, P3180; Zhu L, 2008, LECT NOTES COMPUT SC, V5303, P759	38	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-4786		978-0-7695-5109-8	IEEE DATA MINING			2013							505	512		10.1109/ICDMW.2013.135		8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BB5AQ	WOS:000343602800068		
J	Bengio, Y; Boulanger-Lewandowski, N; Pascanu, R			IEEE	Bengio, Yoshua; Boulanger-Lewandowski, Nicolas; Pascanu, Razvan			ADVANCES IN OPTIMIZING RECURRENT NETWORKS	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Recurrent networks; deep learning; representation learning; long-term dependencies	OPTIMIZATION	After a more than decade-long period of relatively little research activity in the area of recurrent neural networks, several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks. These advances have been motivated by and related to the optimization issues surrounding deep learning. Although recurrent networks are extremely powerful in what they can in principle represent in terms of modeling sequences, their training is plagued by two aspects of the same issue regarding the learning of long-term dependencies. Experiments reported here evaluate the use of clipping gradients, spanning longer time ranges with leaky integration, advanced momentum techniques, using more powerful output probability models, and encouraging sparser gradients to help symmetry breaking and credit assignment. The experiments are performed on text and music data and show off the combined effects of these techniques in generally improving both training and test error.	[Bengio, Yoshua; Boulanger-Lewandowski, Nicolas; Pascanu, Razvan] U Montreal, Montreal, PQ, Canada	Bengio, Y (reprint author), U Montreal, Montreal, PQ, Canada.						Bengio Y., 1994, IEEE T NEURAL NETS; Bengio Y., 2012, ARXIV12065538; Bengio Y., 2009, LEARNING DEEP ARCHIT; Bengio Y., 2007, NIPS 2006; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Boulanger-Lewandowski N., 2012, ICML 2012; ElHihi S., 1996, NIPS 1995; Erhan D., 2010, J MACHINE LEARNING R; Glorot X., 2011, AISTATS 2011; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hochreiter S, 1991, THESIS TU MUNICH; Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016; Krizhevsky A., 2012, NIPS 2012; Larochelle H., 2011, AISTATS 2011; Le Q., 2012, ICML 2012; Lin T., 1995, UMICASTR9578 U MAR; Martens J., 2011, ICML 2011; Martens J., 2010, ICML 2010, P735; Mikolov T, 2012, THESIS BRNO U TECHNO; Mikolov T., 2011, ICASSP 2011; Mikolov Tomas, 2012, WORKSH SPOK LANG TEC; Mikolov Tomas, 2011, P 2011 IEEE INT C AC; Nair V., 2010, ICML 2010; Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269; Pascanu Razvan, 2012, ARXIV12115063 U MONT; Ranzato M., 2007, NIPS 2006; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Siewert Udo, 2007, ECHO STATE NETWORKS; Sutskever I., 2010, NEURAL NETWORKS, V23, P2; Sutskever I, 2012, THESIS U TORONTO; Sutskever I., 2009, NIPS 2008	32	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							8624	8628				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611508159		
S	Bernecker, D; Riess, C; Christlein, V; Angelopoulou, E; Hornegger, J		Weickert, J; Hein, M; Schiele, B		Bernecker, David; Riess, Christian; Christlein, Vincent; Angelopoulou, Elli; Hornegger, Joachim			Representation Learning for Cloud Classification	PATTERN RECOGNITION, GCPR 2013	Lecture Notes in Computer Science		English	Proceedings Paper	35th German Conference on Pattern Recognition (GCPR)	SEP 03-06, 2013	Saarbrucken, GERMANY	Robert Bosch GmbH, Fraunhofer ITWM, Google Res, Intel GmbH, Visual Comp Inst, MVTec Software GmbH, Toyota Motor Europe, Ersatzteile 24 com				Proper cloud segmentation can serve as an important precursor to predicting the output of solar power plants. However, due to the high variability of cloud appearance, and the high dynamic range between different sky regions, cloud segmentation is a surprisingly difficult task. In this paper, we present an approach to cloud segmentation and classification that is based on representation learning. Texture primitives of cloud regions are represented within a restricted Boltzmann Machine. Quantitative results are encouraging. Experimental results yield a relative improvement of the unweighted average (pixelwise) precision on a three-class problem by 11% to 94% in comparison to prior work.	[Bernecker, David; Riess, Christian; Christlein, Vincent; Angelopoulou, Elli; Hornegger, Joachim] Univ Erlangen Nurnberg, Dept Comp Sci, Pattern Recognit Lab, D-91054 Erlangen, Germany	Bernecker, D (reprint author), Univ Erlangen Nurnberg, Dept Comp Sci, Pattern Recognit Lab, D-91054 Erlangen, Germany.	david.bernecker@cs.fau.de; christian.riess@cs.fau.de; vincent.christlein@cs.fau.de; elli.angelopoulou@cs.fau.de; joachim.hornegger@cs.fau.de					Bengio Y., 2012, ARXIV12065538; Bernecker D., 2012, COMP VIS APPL WORKSH; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chow CW, 2011, SOL ENERGY, V85, P2881, DOI 10.1016/j.solener.2011.08.025; Daugman J. G., 1985, OPTICAL SOC AM J A, V2, P1160; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Maenpaa T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011; Marquez R, 2013, SOL ENERGY, V91, P327, DOI 10.1016/j.solener.2012.09.018; Richards K., 1992, BRIT MACH VIS C; Shields J.E., 2009, 274 U CAL SAN DIEG S; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Vinciarelli A., 2012, P INTERSPEECH; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-40601-0; 978-3-642-40602-7	LECT NOTES COMPUT SC			2013	8142						395	404				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BJN38	WOS:000329236100042		
J	Fousek, P; Rennie, S; Dognin, P; Goel, V			IEEE	Fousek, Petr; Rennie, Steven; Dognin, Pierre; Goel, Vaibhava			DIRECT PRODUCT BASED DEEP BELIEF NETWORKS FOR AUTOMATIC SPEECH RECOGNITION	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		Kronecker Product; Deep Belief Networks; Multi-Layer Perceptron; Back-Propagation; Matrix Factorization		In this paper, we present new methods for parameterizing the connections of neural networks using sums of direct products. We show that low rank parameterizations of weight matrices are a subset of this set, and explore the theoretical and practical benefits of representing weight matrices using sums of Kronecker products. ASR results on a 50 hr subset of the English Broadcast News corpus indicate that the approach is promising. In particular, we show that a factorial network with more than 150 times less parameters in its bottom layer than its standard unconstrained counterpart suffers minimal WER degradation, and that by using sums of Kronecker products, we can close the gap in WER performance while maintaining very significant parameter savings. In addition, direct product DBNs consistently outperform standard DBNs with the same number of parameters. These results have important implications for research on deep belief networks (DBNs). They imply that we should be able to train neural networks with thousands of neurons and minimal restrictions much more rapidly than is currently possible, and that by using sums of direct products, it will be possible to train neural networks with literally millions of neurons tractably-an exciting prospect.	[Fousek, Petr; Rennie, Steven; Dognin, Pierre; Goel, Vaibhava] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Fousek, P (reprint author), IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	petr_fousek@cz.ibm.com; pdognin@us.ibm.com; vgoel@us.ibm.com					Chin Jullian, 2013, IEEE T AUDIO S UNPUB, V20; Hinton G., 2012, IEEE SIGNAL PROCESSI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Leskovec J, 2010, J MACH LEARN RES, V11, P985; MarcAurelio Ranzato Y., 2007, ADV NEURAL INFORM PR, V20, P1185; Mohamed A., 2010, ICASSP; Sainath T. N., 2012, NIPS WORKSH LOGL MOD; Sainath Tara N., 2011, AUT SPEECH REC UND A, P30; SALAKHUTDINOV R, 2007, ACM INT C P SERIES, V227, P791; Van Loan C.F., 1992, TECHNICAL REPORT	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							3148	3152				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611503062		
J	Hung, C; Nieto, J; Taylor, Z; Underwood, J; Sukkarieh, S		Amato, N		Hung, Calvin; Nieto, Juan; Taylor, Zachary; Underwood, James; Sukkarieh, Salah			Orchard Fruit Segmentation using Multi-spectral Feature Learning	2013 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS)	IEEE International Conference on Intelligent Robots and Systems		English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	NOV 03-08, 2013	Tokyo, JAPAN	IEEE, IEEE Robot & Automat Soc, IEEE Ind Elect Soc, Robot Soc Japan, New Technol Fdn, Soc Instrument & Control Engineers, Kawada Robot, Reflexxes GmbH, Telecommunicat Advancement Fdn, Tateisi Sci & Technol Fdn			IMAGE	This paper presents a multi-class image segmentation approach to automate fruit segmentation. A feature learning algorithm combined with a conditional random field is applied to multi-spectral image data. Current classification methods used in agriculture scenarios tend to use hand crafted application-based features. In contrast, our approach uses unsupervised feature learning to automatically capture most relevant features from the data. This property makes our approach robust against variance in canopy trees and therefore has the potential to be applied to different domains. The proposed algorithm is applied to a fruit segmentation problem for a robotic agricultural surveillance mission, aiming to provide yield estimation with high accuracy and robustness against fruit variance. Experimental results with data collected in an almond farm are shown. The segmentation is performed with features extracted from multi-spectral (colour and infrared) data. We achieve a global classification accuracy of 88%.	[Hung, Calvin; Nieto, Juan; Taylor, Zachary; Underwood, James; Sukkarieh, Salah] Univ Sydney, Australian Ctr Field Robot, Sch Aerosp Mech & Mechatron Engn, Sydney, NSW 2006, Australia	Hung, C (reprint author), Univ Sydney, Australian Ctr Field Robot, Sch Aerosp Mech & Mechatron Engn, Sydney, NSW 2006, Australia.	c.hung@acfr.usyd.edu.au; j.nieto@acfr.usyd.edu.au; z.taylor@acfr.usyd.edu.au; j.underwood@acfr.usyd.edu.au; s.sukkarieh@acfr.usyd.edu.au					Aggelopoulou AD, 2011, PRECIS AGRIC, V12, P448, DOI 10.1007/s11119-010-9187-0; Bo L., 2012, ISER JUN; BOYKOV YY, 2001, 8 IEEE INT C COMP VI, V1, P105; Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637; Bulanon DM, 2009, BIOSYST ENG, V103, P12, DOI 10.1016/j.biosystemseng.2009.02.009; Ciresan Dan C., 2011, INT JOINT C ART INT; Dey D., 2012, APPL COMP VIS WACV 2, P329; Domke J., BEATING LIKELIHOOD M; GRID-Arendal, ENV FOOD CRIS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Jimenez AR, 2000, T ASAE, V43, P1911; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Lee H, 2007, ADV NEURAL INFORM PR, V19; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Ng A., 2010, CS294A LECT NOTES SP; Nuske S, 2011, INT ROB SYST IROS 20, P2352; Payne AB, 2013, COMPUT ELECTRON AGR, V91, P57, DOI 10.1016/j.compag.2012.11.009; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Singh S., 2010, INTELL SERVICE ROBOT, V3, P245; Szeliski R., 2007, IEEE T PATTERN ANAL, P1068; Taylor Z., AUSTR C ROB AUT; U. Nations, FOOD PROD MUST DOUBL; Wang Q., 2012, 13 INT S EXP ROB	24	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0858		978-1-4673-6358-7	IEEE INT C INT ROBOT			2013							5314	5320				7	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Robotics	Computer Science; Robotics	BA0HU	WOS:000331367405057		
J	Kanda, N; Takeda, R; Obuchi, Y			IEEE	Kanda, Naoyuki; Takeda, Ryu; Obuchi, Yasunari			ELASTIC SPECTRAL DISTORTION FOR LOW RESOURCE SPEECH RECOGNITION WITH DEEP NEURAL NETWORKS	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Deep neural network; speech recognition; elastic distortion		An acoustic model based on hidden Markov models with deep neural networks (DNN-HMM) has recently been proposed and achieved high recognition accuracy. In this paper, we investigated an elastic spectral distortion method to artificially augment training samples to help DNN-HMMs acquire enough robustness even when there are a limited number of training samples. We investigated three distortion methods-vocal tract length distortion, speech rate distortion, and frequency-axis random distortion and evaluated those methods with Japanese lecture recordings. In a large vocabulary continuous speech recognition task with only 10 hours of training samples, a DNN-HMM trained with the elastic spectral distortion method achieved a 10.1% relative word error reduction compared with a normally trained DNN-HMM.	[Kanda, Naoyuki; Takeda, Ryu; Obuchi, Yasunari] Hitachi Ltd, Cent Res Lab, Kokubunji, Tokyo 1858601, Japan	Kanda, N (reprint author), Hitachi Ltd, Cent Res Lab, 1-280 Higashi Koigakubo, Kokubunji, Tokyo 1858601, Japan.	naoyuki.kanda.kn@hitachi.com; ryu.takeda.qh@hitachi.com; yasunari.obuchi.jx@hitachi.com					Boersma P, 2001, GLOT INT, V5, P341; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Duchi J., 2010, J MACHINE LEARNING R, V12, P2121; Hinton G., 2010, MOMENTUM, V9, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly Navdeep, 2013, P ICML WORKSH DEEP L; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Li JY, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P131; Matsuda S, 2013, INT CONF ACOUST SPEE, P7359, DOI 10.1109/ICASSP.2013.6639092; Mohamed A., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), DOI 10.1109/ICASSP.2012.6288863; Mohamed A-R, 2012, AUDIO SPEECH LANGUAG, V20, P14; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Seide F., 2011, P ASRU, P24; Seide F., 2011, P INTERSPEECH, P437; Senior A, 2013, INT CONF ACOUST SPEE, P6724, DOI 10.1109/ICASSP.2013.6638963; Simard P., 2003, P 7 INT C DOC AN REC, V2, P958, DOI DOI 10.1109/1CDAR.2003.1227801; Swietojanski P, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P246, DOI 10.1109/SLT.2012.6424230; Thomas S, 2013, INT CONF ACOUST SPEE, P6704, DOI 10.1109/ICASSP.2013.6638959; Young S., 2002, HTK BOOK HTK VERSION; Zhan P, 1997, CMULTI97150	20	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							309	314				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800053		
J	Le, D; Provost, EM			IEEE	Le, Duc; Provost, Emily Mower			EMOTION RECOGNITION FROM SPONTANEOUS SPEECH USING HIDDEN MARKOV MODELS WITH DEEP BELIEF NETWORKS	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		emotion classification; deep belief networks; spontaneous speech; FAU Aibo; dynamic modeling		Research in emotion recognition seeks to develop insights into the temporal properties of emotion. However, automatic emotion recognition from spontaneous speech is challenging due to non-ideal recording conditions and highly ambiguous ground truth labels. Further, emotion recognition systems typically work with noisy high-dimensional data, rendering it difficult to find representative features and train an effective classifier. We tackle this problem by using Deep Belief Networks, which can model complex and non-linear high-level relationships between low-level features. We propose and evaluate a suite of hybrid classifiers based on Hidden Markov Models and Deep Belief Networks. We achieve state-of-the-art results on FAU Aibo, a benchmark dataset in emotion recognition [1]. Our work provides insights into important similarities and differences between speech and emotion.	[Le, Duc; Provost, Emily Mower] Univ Michigan, Ann Arbor, MI 48109 USA	Le, D (reprint author), Univ Michigan, Ann Arbor, MI 48109 USA.	ducle@umich.edu; emilykmp@umich.edu					Attabi Y., 2013, IEEE INT C AC SPEECH; Bergstra J., 2010, P PYTH SCI COMP C SC; Brueckner R., 2012, P 13 ANN C INT SPEEC; Busso C., 2007, P 8 ANN C INT SPEECH; Cao H., 2012, P 13 ANN C INT SPEEC; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Hassan A, 2013, IEEE T AUDIO SPEECH, V21, P1458, DOI 10.1109/TASL.2013.2255278; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jeon JH, 2011, INT CONF ACOUST SPEE, P4940; Kim Y., IEEE INT C AC SPEECH; Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009; Kockmann M, 2009, P INT BRIGHT, P348; Krizhevsky A, 2012, P ADV NEUR INF PROC, P1106; Lee H., 2008, P 22 ANN C NEUR INF; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Mower E, 2011, INT CONF ACOUST SPEE, P2372; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072; Schmidt EM, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P65, DOI 10.1109/ASPAA.2011.6082328; Schuller B., 2012, 13 ANN C INT SPEECH; Schuller B., 2009, P INTERSPEECH, P312; Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P801; Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Steidl S., 2009, THESIS; Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688; Tang Y., 2010, P 27 ANN INT C MACH, P1055; Togneri R, 2011, IEEE CIRC SYST MAG, V11, P23, DOI 10.1109/MCAS.2011.941079	33	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							216	221				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800037		
J	Li, J; Wang, XR; Xu, B			IEEE	Li, Jie; Wang, Xiaorui; Xu, Bo			UNDERSTANDING THE DROPOUT STRATEGY AND ANALYZING ITS EFFECTIVENESS ON LVCSR	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		dropout; deep neural networks; LVCSR		The work by Hinton et al shows that the dropout strategy can greatly improve the performance of neural networks as well as reducing the influence of over-fitting. Nevertheless, there is still not a more detailed study on this strategy. In addition, the effectiveness of dropout on the task of LVCSR has not been analyzed. In this paper, we attempt to make a further discussion on the dropout strategy. The impacts on performance of different dropout probabilities for phone recognition task are experimented on TIMIT. To get an in-depth understanding of dropout, experiments of dropout testing are designed from the perspective of model averaging. The effectiveness of dropout is analyzed on a LVCSR task. Results show that the method of dropout fine-tuning combined with standard back-propagation gives significant performance improvements.	[Li, Jie; Wang, Xiaorui; Xu, Bo] Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China	Li, J (reprint author), Chinese Acad Sci, Inst Automat, Interact Digital Media Technol Res Ctr, Beijing, Peoples R China.	jie.li@ia.ac.cn; xiaorui.wang@ia.ac.cn; xubo@ia.ac.cn					Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Hinton G. E., 2012, CORR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; rahman Mohamed Abdel, 2011, ICASSP, P5060; Seide F., 2011, INTERSPEECH, P437; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, INT C MACH LEARN, P1096; Zhang Shanshan, 2013, ICASSP IN PRESS	10	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							7614	7618				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611507157		
J	Liu, RS; Lin, ZC; Zhang, W; Tang, KW; Su, ZX				Liu, Risheng; Lin, Zhouchen; Zhang, Wei; Tang, Kewei; Su, Zhixun			Toward designing intelligent PDEs for computer vision: An optimal control approach	IMAGE AND VISION COMPUTING			English	Article						Optimal control; PDEs; Computer vision; Image processing	IMAGE; REMOVAL	Many computer vision and image processing problems can be posed as solving partial differential equations (PDEs). However, designing a PDE system usually requires high mathematical skills and good insight into the problems. In this paper, we consider designing PDEs for various problems arising in computer vision and image processing in a lazy manner: learning PDEs from training data via an optimal control approach. We first propose a general intelligent PDE system which holds the basic translational and rotational invariance rule for most vision problems. By introducing a PDE-constrained optimal control framework, it is possible to use the training data resulting from multiple ways (ground truth, results from other methods, and manual results from humans) to learn PDEs for different computer vision tasks. The proposed optimal control based training framework aims at learning a PDE-based regressor to approximate the unknown (and usually nonlinear) mapping of different vision tasks. The experimental results show that the learnt PDEs can solve different vision problems reasonably well. In particular, we can obtain PDEs not only for problems that traditional PDEs work well but also for problems that PDE-based methods have never been tried before, due to the difficulty in describing those problems in a mathematical way. (C) 2012 Elsevier B.V. All rights reserved.	Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Zhang, Wei] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Liu, Risheng; Tang, Kewei; Su, Zhixun] Dalian Univ Technol, Sch Math Sci, Dalian, Peoples R China	Lin, ZC (reprint author), Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	rsliu0705@gmail.com; zlin@pku.edu.cn; wzhang009@gmail.com; tkwliaoning@gmail.com; zxsu@dlut.edu.cn			National Natural Science Foundation of China [61272341, 61231002, 61173103]; Training Program of the Major Research Plan of the National Natural Science Foundation of China [U0935004, 91230103]; Fundamental Research Funds for the Central Universities	This work is partially supported by the National Natural Science Foundation of China (Grant Nos. 61272341, 61231002, and 61173103), (Grant No. U0935004), the Training Program of the Major Research Plan of the National Natural Science Foundation of China (Grant No. 91230103) and the Fundamental Research Funds for the Central Universities. The first author would also like to thank the support from China Scholarship Council.	Ababnah A, 2011, IEEE T SYST MAN CY A, V41, P97, DOI 10.1109/TSMCA.2010.2049992; Ambrosio L., 1992, COMMUN PURE APPL MAT, V7, P105; [Anonymous], COR PHOT LIB; Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2006, NIPS; Bertalmio M., 2000, SIGGRAPH; Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297; Chen T., 2005, IMAGE PROCESSING ANA; Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241; Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI [10.1109/TIP.2002.801121, 10.1109/TIP/2002.801121]; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; JAIN AK, 1977, J OPTIMIZ THEORY APP, V23, P65, DOI 10.1007/BF00932298; Kim G., 2011, ICCV; Kirk D., 1971, OPTIMAL CONTROL THEO; KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961; Li C., 2005, CVPR; Li X., 2005, IEEE T IMAGE PROCESS, V14, P267; Lions Jacques-Louis, 1971, OPTIMAL CONTROL SYST; Liu Risheng, 2010, ECCV; Martin D., 2001, ICCV; Menon D, 2007, IEEE T IMAGE PROCESS, V16, P132, DOI 10.1109/TIP.2006.884928; Mila N., 2004, J MATH IMAGING VIS, V20, P99; Mumford D., 1985, CVPR; Olver P.J., 1993, APPL LIE GROUPS DIFF; OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053; Parker J. R., 1997, ALGORITHMS IMAGE PRO; Pietro P., 1990, IEEE T PATTERN ANAL, V12, P629; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Stoer J., 1998, INTRO NUMERICAL ANAL; Strong D., 2003, INVERSE PROBL, V19, P165; ter Haar Romeny B. M., 1994, GEOMETRY DRIVEN DIFF; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Wazwaz AM, 2009, NONLINEAR PHYS SCI, P1, DOI 10.1007/978-3-642-00251-9	35	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856			IMAGE VISION COMPUT	Image Vis. Comput.	JAN	2013	31	1					43	56		10.1016/j.imavis.2012.09.004		14	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	084RP	WOS:000314557100004		
B	Nguyen, QB; Gehring, J; Kilgour, K; Waihel, A		Thuy, NT; Ogawa, M; Piuri, V; Tran, XT; Ho, TB		Nguyen, Quoc Bao; Gehring, Jonas; Kilgour, Kevin; Waihel, Alex			Optimizing Deep Bottleneck Feature Extraction	PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF)			English	Proceedings Paper	IEEE RIVF International Conference on Computing and Communication Technologies - Research, Innovation, and Vision for the Future (RIVF)	NOV 10-13, 2013	Hanoi, VIETNAM	IEEE, Inst Francophonie Informatique, Japan Adv Inst Sci & Technol, IEEE Vietnam Sect, FPT Corp, AF Off Sci Res, Asian Off Aerosp Res & Dev, US Off Naval Res Global, IEEE Commun Soc, IEEE Computat Intelligence Soc, Truong Dai Hoc Cong Nghe, HNUE, Dai Hoc Khoa Hoc TU Nhien				We investigate several optimizations to a recently published architecture for extracting bottleneck features for large-vocabulary speech recognition with deep neural networks. We are able to improve recognition performance of first-pass systems from a 12% relative word error rate reduction reported previously to 21%, compared to MFCC baselines on a Tagalog conversational telephone speech corpus. This is achieved by using different input features, training the network to predict context-dependent targets, employing an efficient learning rate schedule and varying several architectural details. Evaluations on two larger German and French speech transcription tasks show that the optimizations proposed are universally applicable and yield comparable gains on other corpora (19.9% and 22.8%, respectively).	[Nguyen, Quoc Bao; Gehring, Jonas; Kilgour, Kevin; Waihel, Alex] Karlsruhe Inst Technol, Inst Anthropomat, Int Ctr Adv Commun Technol InterACT, D-76021 Karlsruhe, Germany	Nguyen, QB (reprint author), Karlsruhe Inst Technol, Inst Anthropomat, Int Ctr Adv Commun Technol InterACT, D-76021 Karlsruhe, Germany.	quoc.nguyen@kit.edu; jonas.gehring@kit.edu					Bengio Y., 2007, NIPS; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Erhan D., 2010, P AISTATS 2010 MAY, V9, P201; Gehring J, 2013, INT CONF ACOUST SPEE, P3377, DOI 10.1109/ICASSP.2013.6638284; Glorot X., 2011, P 28 INT C MACH LEAR, P513; Grezl F, 2007, INT CONF ACOUST SPEE, P757; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Intelligence Advanced Research Projects Activity, 2011, IARPABAA1102; Kilgour K., 2013, AC SPEECH SIGN PROC; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Plahl C., 2011, INTERSPEECH, P1237; Sainath TN, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4153; Seide F., 2011, P INTERSPEECH, P437; Soltau H, 2001, ASRU 2001: IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, CONFERENCE PROCEEDINGS, P214; Tuske Z., 2013, DEEP HIERARCHICAL BO; Vincent P., 2008, INT C MACH LEARN, P1096; Wolfel M., 2005, SIGNAL PROCESSING MA, V22, P117; Yu D, 2011, INTERSPEECH, P237	18	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-1349-7; 978-1-4799-1350-3				2013							152	156				5	Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BB8GR	WOS:000346566300030		
J	Ouyang, WL; Wang, XG			IEEE	Ouyang, Wanli; Wang, Xiaogang			Joint Deep Learning for Pedestrian Detection	2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	DEC 01-08, 2013	Sydney, AUSTRALIA	IEEE, CVF, IEEE Comp Soc, APRS, Australiasn Natl Univ, NICTA, FACE++, Natl Robot Engn Ctr, Google, Disney Res, nVIDIA, Raytheon BBN Technologies, Facebook, Adobe, Kitware, OMRON, SRI Int			RECOGNITION; FEATURES	Feature extraction, deformation handling, occlusion handling, and classification are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture(1). By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.	[Ouyang, Wanli; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Ouyang, WL (reprint author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.	wlouyang@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk					Bar-Hillel A., 2010, ECCV; Barinova O., 2010, CVPR; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bourdev L., 2009, ICCV; Dalal N., 2005, CVPR; Desai C., 2012, ECCV; Dikmen M., 2012, CVPR; Ding Y., 2012, CVPR; Dollar P., 2009, P BRIT MACH VIS C BM, V2, P5; Dollar P., 2012, ECCV; Dollar P., 2010, BMVC; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Enzweiler M., 2010, CVPR; Erhan D, 2009, VISUALIZING HIGHER L; Ess A., 2007, ICCV; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; FELZENSZWALB PF, 2010, PATTERN ANAL MACHINE, V32, P1627, DOI DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gao T., 2011, CVPR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hoiem D., 2006, CVPR; Jarrett K., 2009, CVPR; Krizhevsky A., 2012, NIPS; Le Q.V., 2012, ICML; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leibe B., 2005, CVPR; Lin Z., 2008, ECCV; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo P., 2012, CVPR; Maji S., 2008, CVPR; Mikolajczyk K., 2006, CVPR; Norouzi M., 2009, CVPR; Ouyang W., 2012, CVPR; Ouyang W., 2013, CVPR; Park D., 2010, ECCV; Poon H., 2011, UAI; Ramanan D., 2007, NIPS; Ranzato M., 2007, CVPR; Sabzmeydani P., 2007, CVPR; Schwartz W., 2009, ICCV; Sermanet P, 2013, CVPR; Shet V. D., 2007, CVPR, P2; Sun Y., 2013, ICCV, P2; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Vedaldi A., 2009, ICCV; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Walk S., 2010, CVPR; WANG XZ, 2009, STUD FUZZINESS SOFT, V245, P1; Wojek C., 2008, DAGM; Wu B., 2005, ICCV; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Yang Y., 2011, CVPR; Zeiler M. D., 2011, ICCV; Zeng X., 2013, ICCV; Zhu L., 2010, CVPR	56	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5499		978-1-4799-2839-2	IEEE I CONF COMP VIS			2013							2056	2063		10.1109/ICCV.2013.257		8	Computer Science, Artificial Intelligence	Computer Science	BC3PE	WOS:000351830500257		
J	Solgi, M; Liu, TS; Weng, JY				Solgi, Mojtaba; Liu, Taosheng; Weng, Juyang			A computational developmental model for specificity and transfer in perceptual learning	JOURNAL OF VISION			English	Article						perceptual learning; computational modeling; transfer; specificity; Vernier discrimination task	PRIMARY VISUAL-CORTEX; ORIENTATION; DISCRIMINATION; FEEDBACK; NEURONS; V1; HYPERACUITY; CONNECTIONS; PRINCIPLES; DIRECTION	How and under what circumstances the training effects of perceptual learning (PL) transfer to novel situations is critical to our understanding of generalization and abstraction in learning. Although PL is generally believed to be highly specific to the trained stimulus, a series of psychophysical studies have recently shown that training effects can transfer to untrained conditions under certain experimental protocols. In this article, we present a brain-inspired, neuromorphic computational model of the Where-What visuomotor pathways which successfully explains both the specificity and transfer of perceptual learning. The major architectural novelty is that each feature neuron has both sensory and motor inputs. The network of neurons is autonomously developed from experience, using a refined Hebbian-learning rule and lateral competition, which altogether result in neuronal recruitment. Our hypothesis is that certain paradigms of experiments trigger two-way (descending and ascending) off-task processes about the untrained condition which lead to recruitment of more neurons in lower feature representation areas as well as higher concept representation areas for the untrained condition, hence the transfer. We put forward a novel proposition that gated self-organization of the connections during the off-task processes accounts for the observed transfer effects. Simulation results showed transfer of learning across retinal locations in a Vernier discrimination task in a double-training procedure, comparable to previous psychophysical data (Xiao et al., 2008). To the best of our knowledge, this model is the first neurally-plausible model to explain both transfer and specificity in a PL setting.	[Solgi, Mojtaba; Weng, Juyang] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Liu, Taosheng] Michigan State Univ, Dept Psychol, E Lansing, MI 48824 USA	Solgi, M (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	solgi@cse.msu.edu; weng@cse.msu.edu	Liu, Taosheng/K-9148-2013		Michigan State University's Cognitive Science Program	This project was supported in part by funding from Michigan State University's Cognitive Science Program. We thank an anonymous reviewer for detailed and insightful comments which greatly improved the clarity of our manuscript.	Aberg KC, 2009, VISION RES, V49, P2087, DOI 10.1016/j.visres.2009.05.020; Adini Y, 2002, NATURE, V415, P790; Ahissar M, 1997, NATURE, V387, P401, DOI 10.1038/387401a0; Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011; BALL K, 1987, VISION RES, V27, P953, DOI 10.1016/0042-6989(87)90011-3; Callaway EM, 2004, NEURAL NETWORKS, V17, P625, DOI 10.1016/j.neunet.2004.04.004; Dosher BA, 1998, P NATL ACAD SCI USA, V95, P13988, DOI 10.1073/pnas.95.23.13988; DREVER J, 1960, ANNU REV PSYCHOL, V11, P131, DOI 10.1146/annurev.ps.11.020160.001023; FAHLE M, 1993, VISION RES, V33, P397, DOI 10.1016/0042-6989(93)90094-D; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fine I, 2002, J VISION, V2, P190, DOI 10.1167/2.2.5; FIORENTINI A, 1980, NATURE, V287, P43, DOI 10.1038/287043a0; Fukai T, 1997, NEURAL COMPUT, V9, P77, DOI 10.1162/neco.1997.9.1.77; Ghose GM, 2004, CURR OPIN NEUROBIOL, V14, P513, DOI 10.1016/j.conb.2004.07.003; Ghose GM, 2002, J NEUROPHYSIOL, V87, P1867, DOI 10.1152/jn.00690.2001; Gibson E. J., 1969, PRINCIPLES PERCEPTUA; GIBSON EJ, 1963, ANNU REV PSYCHOL, V14, P29, DOI 10.1146/annurev.ps.14.020163.000333; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochstein S., 2011, J VISION, V11, P1, DOI DOI 10.1167/11.1.8.; Jeter P. E., 2007, J OF VISION, V<IT>7</IT>, P84, DOI 10.1167/7.9.84; Jeter PE, 2010, VISION RES, V50, P1928, DOI 10.1016/j.visres.2010.06.016; Ji ZP, 2008, INT C DEVEL LEARN, P61, DOI 10.1109/DEVLRN.2008.4640806; Kandel E.R., 2000, PRINCIPLES NEURAL SC, Vfourth; KARNI A, 1991, P NATL ACAD SCI USA, V88, P4966, DOI 10.1073/pnas.88.11.4966; Kempermann G, 2002, J NEUROSCI, V22, P635; KIRN J, 1994, P NATL ACAD SCI USA, V91, P7844, DOI 10.1073/pnas.91.17.7844; Kohonen T., 2001, SELF ORG MAPS; Law CT, 2008, NAT NEUROSCI, V11, P505, DOI 10.1038/nn2070; Lee TS, 2002, NAT NEUROSCI, V5, P589, DOI 10.1038/nn860; Li RJ, 2009, NAT NEUROSCI, V12, P549, DOI 10.1038/nn.2296; Li W, 2004, NAT NEUROSCI, V7, P651, DOI 10.1038/nn1255; LINSKER R, 1986, P NATL ACAD SCI USA, V83, P7508, DOI 10.1073/pnas.83.19.7508; Liu JJ, 2010, J VISION, V10, DOI 10.1167/10.10.29; Liu Jia-Ni, 2010, Journal of Insect Science (Tucson), V10, P1, DOI 10.1673/031.010.5201; Lu Z. L, 2009, VISION RES, V<IT>50</IT>, P375; Luciw M., 2010, INT JOINT C NEUR NET, P4233; MISHKIN M, 1983, TRENDS NEUROSCI, V6, P414, DOI 10.1016/0166-2236(83)90190-X; Nottebohm F, 2002, BRAIN RES BULL, V57, P737, DOI 10.1016/S0361-9230(02)00750-5; O'Reilly RC, 1998, TRENDS COGN SCI, V2, P455, DOI 10.1016/S1364-6613(98)01241-8; OTOOLE AJ, 1992, PERCEPTION, V21, P227, DOI 10.1068/p210227; Paslaski S, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P3016, DOI 10.1109/IJCNN.2011.6033618; Pavlovskaya M, 2011, J VISION, V11, DOI 10.1167/11.1.8; Petrov A. A., 2003, J VISION, V3, P670, DOI [10.1167/3.9.670, DOI 10.1167/3.9.670.]; Petrov AA, 2005, PSYCHOL REV, V112, P715, DOI 10.1037/0033-295X.112.4.715; POGGIO T, 1992, SCIENCE, V256, P1018, DOI 10.1126/science.1589770; Raiguel S, 2006, J NEUROSCI, V26, P6589, DOI 10.1523/JNEUROSCI.0457-06.2006; RAMACHAN.VS, 1973, PERCEPTION, V2, P371, DOI 10.1068/p020371; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Schoups A, 2001, NATURE, V412, P549, DOI 10.1038/35087601; Shi N. B., 2003, IEEE T SYST MAN CYB, V36, P172; Solgi M., 2010, IEEE T AUTON MENT DE, V1, P238; Tartaglia EM, 2009, CURR BIOL, V19, P2081, DOI 10.1016/j.cub.2009.10.060; Teich AF, 2003, J NEUROPHYSIOL, V89, P2086, DOI 10.1152/jn.00970.2002; Tsodyks M, 2004, NATURE, V431, P775, DOI 10.1038/nature03013; VAINA LM, 1995, COGNITIVE BRAIN RES, V2, P155, DOI 10.1016/0926-6410(95)90004-7; WEISS Y, 1993, NEURAL COMPUT, V5, P695, DOI 10.1162/neco.1993.5.5.695; Weng J, 2010, IEEE 9 INT C DEV LEA, P280; Weng J., 2010, P INT JOINT C NEUR N, P1; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544; Xiao LQ, 2008, CURR BIOL, V18, P1922, DOI 10.1016/j.cub.2008.10.030; Yu AJ, 2005, NEURON, V46, P681, DOI 10.1016/j.neuron.2005.04.026; Yu C, 2004, J VISION, V4, P169, DOI 10.1167/4.3.4; Zhang JY, 2010, J NEUROSCI, V30, P12323, DOI 10.1523/JNEUROSCI.0704-10.2010; Zhang T, 2010, VISION RES, V50, P368, DOI 10.1016/j.visres.2009.08.024; Zhaoping L, 2003, NETWORK-COMP NEURAL, V14, P233, DOI 10.1088/0954-898X/14/2/304; Zhaoping L., 2003, NETWORK, V14, P790	68	1	1	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	1534-7362			J VISION	J. Vision		2013	13	1							7	10.1167/13.1.7		23	Ophthalmology	Ophthalmology	084DM	WOS:000314516900007	23291647	
J	Sun, Y; Wang, XG; Tang, XO			IEEE	Sun, Yi; Wang, Xiaogang; Tang, Xiaoou			Hybrid Deep Learning for Face Verification	2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	DEC 01-08, 2013	Sydney, AUSTRALIA	IEEE, CVF, IEEE Comp Soc, APRS, Australiasn Natl Univ, NICTA, FACE++, Natl Robot Engn Ctr, Google, Disney Res, nVIDIA, Raytheon BBN Technologies, Facebook, Adobe, Kitware, OMRON, SRI Int			RECOGNITION	This paper proposes a hybrid convolutional network (ConvNet)-Restricted Boltzmann Machine (RBM) model for face verification in wild conditions. A key contribution of this work is to directly learn relational visual features, which indicate identity similarities, from raw pixels of face pairs with a hybrid deep network. The deep ConvNets in our model mimic the primary visual cortex to jointly extract local relational visual features from two face images compared with the learned filter pairs. These relational features are further processed through multiple layers to extract high-level and global features. Multiple groups of ConvNets are constructed in order to achieve robustness and characterize face similarities from different aspects. The top-layer RBM performs inference from complementary high-level features extracted from different ConvNet groups with a two-level average pooling hierarchy. The entire hybrid deep network is jointly fine-tuned to optimize for the task of face verification. Our model achieves competitive face verification performance on the LFW dataset.	[Sun, Yi; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China; [Wang, Xiaogang; Tang, Xiaoou] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 100864, Peoples R China	Sun, Y (reprint author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	sy011@ie.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk; xtang@ie.cuhk.edu.hk					Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Berg T., 2013, P CVPR; Berg T., 2012, P BRIT MACH VIS C; Cao Z., 2010, P CVPR, P1; Chen D., 2012, P ECCV; Chen DX, 2013, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2013-125; Chopra S., 2005, P CVPR; Ciresan D., 2012, P CVPR; Guillaumin M., 2009, P ICCV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang C., 2011, TELECOMMUN SYST; Huang G., 2012, Proceedings of the 2012 International Symposium on VLSI Design, Automation and Test (VLSI-DAT), DOI 10.1109/VLSI-DAT.2012.6212580; Huang G. B., 2007, 0749 U MASS; Krizhevsky A., 2012, P NIPS; Kumar N., 2009, P ICCV; Larochelle H, 2012, J MACH LEARN RES, V13, P643; LeCun Y., 1998, P IEEE; Lee H., 2009, P ICML; Li P., 2012, PAMI, V34, P144; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nguyen H. V., 2010, P ACCV, p[1, 2]; Ojala T., 2002, PATTERN ANAL MACHINE, V24, P971; Pinto N., 2011, FG, p[1, 2]; Simonyan K, 2013, P BMVC; Sun Y., 2013, P CVPR; Taigman Y., 2009, P BMVC; Wang X., 2004, PAMI, V26, P1222; Wang X., 2004, P CVPR; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Wiskott L., 1997, PAMI, V19, P775; Wolf L., 2008, WORKSH FAC REAL LIF; Yin Q., 2011, P CVPR; Zhu Z., 2013, P ICCV	34	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5499		978-1-4799-2839-2	IEEE I CONF COMP VIS			2013							1489	1496		10.1109/ICCV.2013.188		8	Computer Science, Artificial Intelligence	Computer Science	BC3PE	WOS:000351830500186		
J	Wang, GS; Sim, KC			IEEE	Wang, Guangsen; Sim, Khe Chai			CONTEXT-DEPENDENT MODELLING OF DEEP NEURAL NETWORK USING LOGISTIC REGRESSION	2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU)			English	Proceedings Paper	IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	DEC 08-13, 2013	Olomouc, CZECH REPUBLIC	Inst Elect & Elect Engineers, IEEE Signal Proc Soc		Context-Dependent Modelling; Deep Neural Network; Logistic Regression; Canonical State Modelling; Articulatory Features	SPEECH RECOGNITION	The data sparsity problem of context-dependent acoustic modelling in automatic speech recognition is addressed by using the decision tree state clusters as the training targets in the standard context-dependent (CD) deep neural network (DNN) systems. As a result, the CD states within a cluster cannot be distinguished during decoding. This problem, referred to as the clustering problem, is not explicitly addressed in the current literature. In this paper, we formulate the CD DNN as an instance of the canonical state modelling technique based on a set of broad phone classes to address both the data sparsity and the clustering problems. The triphone is clustered into multiple sets of shorter biphones using broad phone contexts to address the data sparsity issue. A DNN is trained to discriminate the biphones within each set. The canonical states are represented by the concatenated log posteriors of all the broad phone DNNs. Logistic regression is used to transform the canonical states into the triphone state output probability. Clustering of the regression parameters is used to reduce model complexity while still achieving unique acoustic scores for all possible triphones. The experimental results on a broadcast news transcription task reveal that the proposed regression-based CD DNN significantly outperforms the standard CD DNN. The best system provides a 2.7% absolute WER reduction compared to the best standard CD DNN system.	[Wang, Guangsen; Sim, Khe Chai] Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117548, Singapore	Wang, GS (reprint author), Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117548, Singapore.						Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L., J ACOU SOC AM, V95, P2702; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Gales M. J. F., 1996, GENERATION USE REGRE; Gales MJF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P58; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Lee C.-H., 2007, P INTERSPEECH; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; MORGAN N, 1995, P IEEE, V83, P742, DOI 10.1109/5.381844; Povey D., 2011, IEEE 2011 WORKSH AUT; Povey D, 2011, COMPUT SPEECH LANG, V25, P404, DOI 10.1016/j.csl.2010.06.003; Sainath T. N., 2011, ASRU, P30; Schwarz P., 2008, THESIS BRNO U TECHNO; Seide F., 2011, ASRU, P24; Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008; Valtchev V, 1997, SPEECH COMMUN, V22, P303, DOI 10.1016/S0167-6393(97)00029-0; Wang G., 2011, INTERSPEECH, P457; Wang G., 2011, INTERSPEECH, P441; Young S. J., 1994, HLT, P307; Yu K, 2011, SPEECH COMMUN, V53, P914, DOI 10.1016/j.specom.2011.03.003	22	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4799-2756-2				2013							338	343				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BA4DR	WOS:000335410800058		
S	Zabkar, J; Leonardis, A		Tucker, A; Hoppner, F; Siebes, A; Swift, S		Zabkar, Jure; Leonardis, Ales			Learning Compositional Hierarchies of a Sensorimotor System	ADVANCES IN INTELLIGENT DATA ANALYSIS XII	Lecture Notes in Computer Science		English	Proceedings Paper	12th International Symposium on Intelligent Data Analysis (IDA)	OCT 17-19, 2013	London, ENGLAND	Brunel Univ, Heilbronn Inst, Artificial Intelligence Journal, SMESH	Royal Stat Soc	compositional hierarchy; sensorimotor representation; computational modeling	PERCEPTION; TASK; PRIMITIVES; COGNITION; DISCRETE	We address the problem of learning static spatial representation of a robot motor system and the environment to solve a general forward/inverse kinematics problem. The latter proves complex for high degree-of-freedom systems. The proposed architecture relates to a recent research in cognitive science, which provides a solid evidence that perception and action share common neural architectures. We propose to model both a motor system and an environment with compositional hierarchies and develop an algorithm for learning them together with a mapping between the two. We show that such a representation enables efficient learning and inference of robot states. We present our experiments in a simulated environment and with a humanoid robot Nao.	[Zabkar, Jure] Univ Ljubljana, Fac Comp & Informat Sci, AI Lab, SI-1000 Ljubljana, Slovenia	Zabkar, J (reprint author), Univ Ljubljana, Fac Comp & Informat Sci, AI Lab, Trzaska 25, SI-1000 Ljubljana, Slovenia.	jure.zabkar@fri.uni-lj.si					Ben Amor H, 2012, P 25 INT C INT ROB S; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Braun DA, 2009, CURR BIOL, V19, P352, DOI 10.1016/j.cub.2009.01.036; Braun D.A., 2010, PLOS ONE, V5; D'Souza A., 2001, P IEEE RSJ INT C INT, V1, P298, DOI DOI 10.1109/IROS.2001.973374; Degallier S, 2011, AUTON ROBOT, V31, P155, DOI 10.1007/s10514-011-9235-2; Demiris Y, 2006, NEURAL NETWORKS, V19, P272, DOI 10.1016/j.neunet.2006.02.005; Fidler S, 2008, P CVPR; Fuster JM, 2009, J COGNITIVE NEUROSCI, V21, P2047, DOI 10.1162/jocn.2009.21280; Green CS, 2006, COGNITION, V101, P217, DOI 10.1016/j.cognition.2005.10.004; Green S.C., 2003, NATURE, V423; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103; Ijspeert A. J., 2002, ADV NEURAL INFORM PR, V15, P1547; Jackson PL, 2004, CURR OPIN NEUROBIOL, V14, P259, DOI 10.1016/j.conb.2004.01.020; Knoblich G, 2001, PSYCHOL SCI, V12, P467, DOI 10.1111/1467-9280.00387; Kober J, 2012, AUTON ROBOT, V33, P361, DOI 10.1007/s10514-012-9290-3; Kruger V, 2010, IEEE ROBOT AUTOM MAG, V17, P30, DOI 10.1109/MRA.2010.936961; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; McClelland JL, 2003, NAT REV NEUROSCI, V4, P310, DOI 10.1038/nrn1076; Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4; Nakanishi J, 2004, ROBOT AUTON SYST, V47, P79, DOI 10.1016/j.robot.2004.03.003; Nishtala R., 2009, P IEEE INT PAR DISTR, P1, DOI DOI 10.1109/IPDPS.2009.5161076; Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003; Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551; Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001; Sailer U, 2005, J NEUROSCI, V25, P8833, DOI 10.1523/JNEUROSCI.2658-05.2005; Schaal S., 2003, INT S AD MOT AN MACH; Schaal S, 2007, PROG BRAIN RES, V165, P425, DOI 10.1016/S0079-6123(06)65027-9; Schaal S., 2002, LEARNING ROBOT CONTR, P983; Sperry R.W., 1952, AM SCI, V40; Tamosiunaite M, 2011, ROBOT AUTON SYST, V59, P910, DOI 10.1016/j.robot.2011.07.004; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Ude A, 2010, IEEE T ROBOT, V26, P800, DOI 10.1109/TRO.2010.2065430; Wolpert DM, 2011, NAT REV NEUROSCI, V12, P739, DOI 10.1038/nrn3112; Wolpert DM, 2010, CURR BIOL, V20, pR467, DOI 10.1016/j.cub.2010.04.035	36	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-41397-1; 978-3-642-41398-8	LECT NOTES COMPUT SC			2013	8207						450	461				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BJS29	WOS:000329968500039		
J	Zhang, SS; Zhang, C; You, Z; Zheng, R; Xu, B			IEEE	Zhang, Shanshan; Zhang, Ce; You, Zhao; Zheng, Rong; Xu, Bo			ASYNCHRONOUS STOCHASTIC GRADIENT DESCENT FOR DNN TRAINING	2013 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 26-31, 2013	Vancouver, CANADA	Inst Elect & Elect Engineers, Inst Elect & Elect Engineers Signal Proc Soc		deep neural network; speech recognition; asynchronous SGD; GPU parallelization		It is well known that state-of-the-art speech recognition systems using deep neural network (DNN) can greatly improve the system performance compared with conventional GMM-HMM. However, what we have to pay correspondingly is the immense training cost due to the enormous parameters of DNN. Unfortunately, it is difficult to achieve parallelization of the minibatch-based back-propagation (BP) algorithm used in DNN training because of the frequent model updates. In this paper we describe an effective approach to achieve an approximation of BP - asynchronous stochastic gradient descent (ASGD), which is used to parallelize computing on multi-GPU. This approach manages multiple GPUs to work asynchronously to calculate gradients and update the global model parameters. Experimental results show that it achieves a 3.2 times speed-up on 4 GPUs than the single one, without any recognition performance loss.	[Zhang, Shanshan; Zhang, Ce; You, Zhao; Zheng, Rong; Xu, Bo] Chinese Acad Sci, Interact Digital Media Technol Res Ctr, Inst Automat, Beijing, Peoples R China	Zhang, SS (reprint author), Chinese Acad Sci, Interact Digital Media Technol Res Ctr, Inst Automat, Beijing, Peoples R China.	shanshan.zhang@ia.ac.cn; ce.zhang@ia.ac.cn; zhao.you@ia.ac.cn; rong.zheng@ia.ac.cn; xubo@ia.ac.cn					Bishop C. M., 2006, PATTERN RECOGNITION, V4; Chen X., 2012, P INTERSPEECH; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Garofolo JS, 1993, TIMIT ACOUSTIC PHONE; Hinton G., 1986, NATURE, V323; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Nedic A., 2001, STUD COMPUT MATH, V8, P381; Ormandi R., 2011, LNCS, V6852, P528, DOI DOI 10.1007/978-3-642-23400-2; Rosenblatt F., 1961, PRINCIPLES NEURODYNA; Seide F., 2011, P INTERSPEECH	10	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-0356-6	INT CONF ACOUST SPEE			2013							6660	6663				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BJQ19	WOS:000329611506165		
J	Zhu, ZY; Luo, P; Wang, XG; Tang, XO			IEEE	Zhu, Zhenyao; Luo, Ping; Wang, Xiaogang; Tang, Xiaoou			Deep Learning Identity-Preserving Face Space	2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	DEC 01-08, 2013	Sydney, AUSTRALIA	IEEE, CVF, IEEE Comp Soc, APRS, Australiasn Natl Univ, NICTA, FACE++, Natl Robot Engn Ctr, Google, Disney Res, nVIDIA, Raytheon BBN Technologies, Facebook, Adobe, Kitware, OMRON, SRI Int			RECOGNITION	Face recognition with large pose and illumination variations is a challenging problem in computer vision. This paper addresses this challenge by proposing a new learningbased face representation: the face identity-preserving (FIP) features. Unlike conventional face descriptors, the FIP features can significantly reduce intra-identity variances, while maintaining discriminativeness between identities. Moreover, the FIP features extracted from an image under any pose and illumination can be used to reconstruct its face image in the canonical view. This property makes it possible to improve the performance of traditional descriptors, such as LBP [2] and Gabor [31], which can be extracted from our reconstructed images in the canonical view to eliminate variations. In order to learn the FIP features, we carefully design a deep network that combines the feature extraction layers and the reconstruction layer. The former encodes a face image into the FIP features, while the latter transforms them to an image in the canonical view. Extensive experiments on the large MultiPIE face database [7] demonstrate that it significantly outperforms the state-of-the-art face recognition methods.	[Zhu, Zhenyao; Luo, Ping; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China; [Luo, Ping; Tang, Xiaoou] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 100864, Peoples R China	Zhu, ZY (reprint author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	zz012@ie.cuhk.edu.hk; pluo.lhi@gmail.com; xgwang@ee.cuhk.edu.hk; xtang@ie.cuhk.edu.hk					Abdi H, 2007, ENCY MEASUREMENT STA; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Asthana A., 2011, ICCV; Cao Z., 2010, CVPR; Castillo C. D., 2011, CVPR; Chopra S., 2005, CVPR; Gross R., 2008, INT C AUT FAC GEST R; Guo Y., 2010, ACCV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang G. B., 2012, CVPR; Jolliffe IT, 1986, PRINCIPAL COMPONENT, V487; Krizhevsky A., 2012, NIPS; Le Q. V., 2010, NIPS; LeCun Y., 1998, P IEEE; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Lei Z., 2012, CVPR; Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957; Li S., 2012, ECCV; Nair V., 2010, P 27 INT C MACH LEAR; Qian N., 1999, NEURAL NETWORKS; Ranzato M., 2011, CVPR; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Schroff F., 2011, ICCV; Sun Y., 2013, ICCV, P2; Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wang X., 2004, CVPR; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zeiler M. D., 2011, ICCV; Zhang W., 2005, ICCV; Zhang W., 2011, CVPR; Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017	36	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1550-5499		978-1-4799-2839-2	IEEE I CONF COMP VIS			2013							113	120		10.1109/ICCV.2013.21		8	Computer Science, Artificial Intelligence	Computer Science	BC3PE	WOS:000351830500015		
J	Do, TMT; Artieres, T				Trinh-Minh-Tri Do; Artieres, Thierry			Regularized Bundle Methods for Convex and Non-Convex Risks	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						optimization; non-convex; non-smooth; cutting plane; bundle method; regularized risk	NONSMOOTH OPTIMIZATION; RECOGNITION	Machine learning is most often cast as an optimization problem. Ideally, one expects a convex objective function to rely on efficient convex optimizers with nice guarantees such as no local optima. Yet, non-convexity is very frequent in practice and it may sometimes be inappropriate to look for convexity at any price. Alternatively one can decide not to limit a priori the modeling expressivity to models whose learning may be solved by convex optimization and rely on non-convex optimization algorithms. The main motivation of this work is to provide efficient and scalable algorithms for non-convex optimization. We focus on regularized unconstrained optimization problems which cover a large number of modern machine learning problems such as logistic regression, conditional random fields, large margin estimation, etc. We propose a novel algorithm for minimizing a regularized objective that is able to handle convex and non-convex, smooth and non-smooth risks. The algorithm is based on the cutting plane technique and on the idea of exploiting the regularization term in the objective function. It may be thought as a limited memory extension of convex regularized bundle methods for dealing with convex and non convex risks. In case the risk is convex the algorithm is proved to converge to a stationary solution with accuracy epsilon with a rate O(1/lambda epsilon) where lambda is the regularization parameter of the objective function under the assumption of a Lipschitz empirical risk. In case the risk is not convex getting such a proof is more difficult and requires a stronger and more disputable assumption. Yet we provide experimental results on artificial test problems, and on five standard and difficult machine learning problems that are cast as convex and non-convex optimization problems that show how our algorithm compares well in practice with state of the art optimization algorithms.	[Trinh-Minh-Tri Do] Idiap Res Inst, CH-1920 Martigny, Switzerland; [Artieres, Thierry] Univ Paris 06, LIP6, F-75016 Paris, France	Do, TMT (reprint author), Idiap Res Inst, Rue Marconi 19, CH-1920 Martigny, Switzerland.	TRI.DO@IDIAP.CH; THIERRY.ARTIERES@LIP6.FR					Argyriou A., 2006, P 23 INT C MACH LEAR, P41, DOI 10.1145/1143844.1143850; Bengio Y., 2007, SCALING LEARNING ALG; Bertsekas D. P., 2003, CONVEX ANAL OPTIMIZA; Bottou Leon, 2008, STOCHASTIC GRADIENT; Chapelle O., 2006, SEMISUPERVISED LEARN; Collobert R., 2006, P 23 INT C MACH LEAR, P201, DOI 10.1145/1143844.1143870; Do T. M. T., 2010, P 13 INT C ART INT S; Do T. M. T., 2012, LIP6 PIERR M CUR U; DO TMT, 2008, P 2008 EUR C MACH LE, V5211, P272; Do Trinh-Minh-Tri, 2009, P 26 INT C MACH LEAR, P265; Franc V., 2008, P 25 INT C MACH LEAR, P320, DOI 10.1145/1390156.1390197; Gaudioso M., 1992, Optimization, V25, DOI 10.1080/02331939208843808; Haarala M, 2004, OPTIM METHOD SOFTW, V19, P673, DOI 10.1080/10556780410001689225; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Horst R, 1999, J OPTIMIZ THEORY APP, V103, P1, DOI 10.1023/A:1021765131316; Hu JY, 2000, PATTERN RECOGN, V33, P133, DOI 10.1016/S0031-3203(99)00043-6; Jarrett K, 2009, P 12 INT C COMP VIS; Jiang H, 2007, INT CONF ACOUST SPEE, P629; Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI DOI 10.1145/1150402.1150429; Joachims T., 1999, P 16 INT C MACH LEAR, V99, P200; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Kassel R. H., 1995, THESIS CAMBRIDGE; Kiwiel K. C., 1985, METHODS DESCENT NOND, V1133; KIWIEL KC, 1983, MATH PROGRAM, V27, P320, DOI 10.1007/BF02591907; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Makela M. M., 1992, NONSMOOTH OPTIMIZATI; Makela MM, 2002, OPTIM METHOD SOFTW, V17, P1, DOI 10.1080/10556780290027828; Rabiner L.R., 1990, TUTORIAL HIDDEN MARK; Schramm H., 1992, SIAM J OPTIMIZ, V2, P121, DOI 10.1137/0802008; Sha F., 2007, ADV NEURAL INFORM PR, V1, P1249; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598; Smola A.J., 2008, ADV NEURAL INFORM PR, V20, P1377; Taskar B., 2004, ADV NEURAL INFORM PR, V16; Teo CH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727; Vicek J., 2000, TECHNICAL REPORT; Weimer M., ADV NEURAL INFORM PR, V20; Xu L., 2004, ADV NEURAL INFORM PR, V17, P1537; Xu L., 2006, P 23 INT C MACH LEAR, P1057, DOI 10.1145/1143844.1143977; Xu Z., 2008, ADV NEURAL INFORM PR, V20, P1641; Yu D, 2007, P IEEE INT C SEM COM, P429; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhao B., 2008, P 25 INT C MACH LEAR, P1248, DOI 10.1145/1390156.1390313	42	1	1	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	DEC	2012	13						3539	3583				45	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	084HI	WOS:000314529000004		
J	Chen, JF; Huang, ZY; Jin, QJ				Chen Junfei; Huang Zeyuan; Jin Qiongji			SPI-based drought characteristics analysis and prediction for Xiqiao Station in Yunnan Province, China	DISASTER ADVANCES			English	Article						Standardized Precipitation Index (SPI); Drought prediction; Deep Belief Networks (DBN); Back Propagation Neural Network (BPNN); Autoregressive Integrated Moving Average (ARIMA)	NEURAL-NETWORK; TIME	Standardized Precipitation Index is an important drought characterization index which can measure drought duration, magnitude and spatial extent. Accurate forecasting of Standardized Precipitation Index is an important issue for drought disaster monitoring and risk management. A drought forecast model based on deep belief network was proposed for forecasting Standardized Precipitation Index. Four different scale SPI series were computed at Xiqiao station in Yunnan Province during the period 1961-2009 and the drought grade frequency statistics of different scale SPI are analyzed. The three models (DBN, BPNN, ARIMA) with various input structures are constructed for the purpose of identification of the best structure and the models were used to forecast the SPI of Xiqiao Station. The performances of the three models in training and testing sets are compared and show that the DBN model is preferable because it provides high accuracy and reliability for forecasting different time scales SPI.	[Chen Junfei; Huang Zeyuan; Jin Qiongji] Hohai Univ, State Key Lab Hydrol Water Resources & Hydraul En, Nanjing 210098, Jiangsu, Peoples R China	Chen, JF (reprint author), Hohai Univ, State Key Lab Hydrol Water Resources & Hydraul En, Nanjing 210098, Jiangsu, Peoples R China.	chenjunfei@hhu.edu.cn			National Society Science Fund of China [09CJY020, 10AJY005]; National Nature Science Foundation of China [90924027]; Special Fund of State Key Laboratory of China [2011585312]; Science and Technology Projects of Yunnan Province [2010CA013]	This work was supported in partially by the National Society Science Fund of China (09CJY020, 10AJY005), the National Nature Science Foundation of China (90924027), the Special Fund of State Key Laboratory of China (2011585312) and the Science and Technology Projects of Yunnan Province (2010CA013).	Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Box G., 1970, TIME SERIES ANAL FOR; [曹升乐 CAO Shengle], 2006, [山东大学学报. 工学版, Journal of Shandong University (Engineering Science)], V36, P58; Chen Y. C., 2005, SHANDONG METEOROLOGI, V25, P24; Duan C. Q., 2011, J N CHINA I WATER CO, V32, P39; Fang G. F., 2011, CHINESE J AGROMETEOR, V32, P475; Faruk DO, 2010, ENG APPL ARTIF INTEL, V23, P586, DOI 10.1016/j.engappai.2009.09.015; Feng P, 2000, SYSTEMS ENG THEORY P, V20, P141; Han Y. P., 2003, J INNER MONGOLIA NOR, V32, P65; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; [侯姗姗 Hou Shanshan], 2011, [干旱地区农业研究, Agricultural Research in the Arid Areas], V29, P224; IPCC, 2007, 4 IPCC, P781; IPCC, 2007, 4 ASS REP INT PAN CL, P1; Jiang LH, 2011, J IRON STEEL RES INT, V18, P25, DOI 10.1016/S1006-706X(11)60099-X; [景毅刚 JING Yi-gang], 2010, [中国农业气象, Chinese Journal of Agrometeorology], V31, P115; JORDAN MI, 1992, COGNITIVE SCI, V16, P307, DOI 10.1207/s15516709cog1603_1; Kim S, 2011, DISASTER ADV, V4, P53; Liang YH, 2009, NEURAL COMPUT APPL, V18, P833, DOI 10.1007/s00521-008-0216-0; Liu W. B., 2008, J NANCHANG I TECHNOL, V28, P64; Liu YinGe, 2004, Arid Land Geography, V27, P564; McKee T.B., 1993, P 8 C APPL CLIM 17 2, P179; Mishra AK, 2006, ECOL MODEL, V198, P127, DOI 10.1016/j.ecolmodel.2006.04.017; [祁宦 QI Huan], 2009, [中国农业气象, Chinese Journal of Agrometeorology], V30, P596; Rojas R, 1996, NEURAL NETWORKS SYST; [孙惠合 SUN Hui-he], 2009, [中国农业气象, Chinese Journal of Agrometeorology], V30, P271; Tang Y. G., 2001, J NW U, V31, P259; Taylor G.W., 2007, ADV NEURAL INFORM PR, V19; [滕卫平 TENG Weiping], 2008, [浙江大学学报. 理学版, Journal of Zhejiang University. Sciences Edition], V35, P343; Wang Y. J., 2007, J AGR RES ARID AREAS, V25, P198; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Wu H, 2007, INT J CLIMATOL, V27, P65, DOI 10.1002/joe.1371; Yang Z. Y., 2009, J EEC WATER RESOURCE, V29, P12; Yoshua B., 2007, NIPS; Zhang G, 1998, OMEGA-INT J MANAGE S, V26, P495, DOI 10.1016/S0305-0483(98)00003-6; [张遇春 ZHANG Yuchun], 2008, [干旱区资源与环境, Journal of Arid Land Resources and Environment], V22, P84; Zhang Y. F., 2010, ANHUI AGR SCI, V19, P10154; Zhou XY, 2010, DISASTER ADV, V3, P35; Zou Xukai, 2008, J APPL METEOROLOGICA, V19, P679	39	1	1	DISASTER ADVANCES	INDORE	SECTOR AG-80, SCHEME NO 54, VIJAY NAGAR, A B RD, INDORE, 452010, INDIA	0974-262X			DISASTER ADV	Disaster Adv.	OCT	2012	5	4					1260	1268				9	Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources	Geology; Meteorology & Atmospheric Sciences; Water Resources	064UE	WOS:000313100100214		
J	Bengio, Y; Chapados, N; Delalleau, O; Larochelle, H; Saint-Mleux, X; Hudon, C; Louradour, J				Bengio, Yoshua; Chapados, Nicolas; Delalleau, Olivier; Larochelle, Hugo; Saint-Mleux, Xavier; Hudon, Christian; Louradour, Jerome			DETONATION CLASSIFICATION FROM ACOUSTIC SIGNATURE WITH THE RESTRICTED BOLTZMANN MACHINE	COMPUTATIONAL INTELLIGENCE			English	Article						discriminative restricted Boltzmann machine; support vector machine; detonation classification	SUPPORT VECTOR MACHINES	We compare the recently proposed Discriminative Restricted Boltzmann Machine (DRBM) to the classical Support Vector Machine (SVM) on a challenging classification task consisting in identifying weapon classes from audio signals. The three weapon classes considered in this work (mortar, rocket, and rocket-propelled grenade), are difficult to reliably classify with standard techniques because they tend to have similar acoustic signatures. In addition, specificities of the data available in this study make it challenging to rigorously compare classifiers, and we address methodological issues arising from this situation. Experiments show good classification accuracy that could make these techniques suitable for fielding on autonomous devices. DRBMs appear to yield better accuracy than SVMs, and are less sensitive to the choice of signal preprocessing and model hyperparameters. This last property is especially appealing in such a task where the lack of data makes model validation difficult.	[Bengio, Yoshua] Univ Montreal, DIRO, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada; [Larochelle, Hugo] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Saint-Mleux, Xavier; Hudon, Christian] ApSTAT Technol, Montreal, PQ, Canada; [Louradour, Jerome] A2iA SA, Paris, France	Bengio, Y (reprint author), Univ Montreal, DIRO, Dept Comp Sci & Operat Res, POB 6128,Ctr Ville Branch, Montreal, PQ H3C 3J7, Canada.				US Army Research Laboratory, Acoustic & EM Sensing Branch [W911NF-07-D-0001]	This work was supported by the US Army Research Laboratory, Acoustic & EM Sensing Branch, contract no. W911NF-07-D-0001.	Bedard J, 2003, P SOC PHOTO-OPT INS, V5071, P497, DOI 10.1117/12.498503; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bogert B., 1963, P S TIM SER AN, P209; Bouchard G., 2004, IASC INT S COMP STAT, P721; Box G.E.P., 2005, STAT EXPT DESIGN INN; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Chang C.C., 2001, LIBSVM LIB SUPPORT V; CHILDERS DG, 1977, P IEEE, V65, P1428, DOI 10.1109/PROC.1977.10747; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Croarkin C., NIST SEMATECH E HDB; Desai S., 2006, INDEPENDENT COMPONEN, V6247; Desai S., 2007, P 19 INT C AC MADR S; Engelberg S, 2008, AM MATH MON, V115, P499; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Graps A., 1995, COMPUTING SCI ENG, V2, P50, DOI DOI 10.1109/99.388960; Grosse R., 2007, P 23 C UNC ART INT V; Hansen J. H. L., 1999, DISCRETE TIME PROCES; Hinton G. E., 2002, NEURAL COMPUT, V14, P1171; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Hsu J, 1996, MULTIPLE COMP THEORY; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Lasserre J. A., 2006, CVPR 06, P8794; Lee H., 2009, ADV NEURAL INFORM PR, V22, P1096; Marin-Jimenez M., 2009, INT WORKSH IM AN MUL, P5; McCulloch C.E., 2008, WILEY SERIES PROBABI; Morcos A., 2008, UNATTENDED GROUND SE, V6963; Naz P., 2006, UNATTENDED GROUND SE, V6231; Ng AY, 2002, ADV NEUR IN, V14, P841; Pinheiro JC, 2000, MIXED EFFECTS MODELS; Quatieri T. F., 2001, DISTRETE TIME SPEECH; Ranzato M., 2007, ADV NEURAL INFORM PR, V19; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Smith B., 2006, FEATURE EXTRACTION T; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Tukey J W, 1977, EXPLORATORY DATA ANA; Vapnik V. N., 1998, STAT LEARNING THEORY; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481	42	1	1	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935			COMPUT INTELL-US	Comput. Intell.	MAY	2012	28	2					261	288		10.1111/j.1467-8640.2012.00419.x		28	Computer Science, Artificial Intelligence	Computer Science	939XK	WOS:000303854000006		
J	Bell, PJ; Gales, MJF; Lanchantin, P; Liu, X; Long, Y; Renals, S; Swietojanski, P; Woodland, PC			IEEE	Bell, P. J.; Gales, M. J. F.; Lanchantin, P.; Liu, X.; Long, Y.; Renals, S.; Swietojanski, P.; Woodland, P. C.			TRANSCRIPTION OF MULTI-GENRE MEDIA ARCHIVES USING OUT-OF-DOMAIN DATA	2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012)			English	Proceedings Paper	IEEE Workshop on Spoken Language Technology (SLT)	DEC 02-05, 2012	Miami, FL	Inst Elect & Elect Engineers (IEEE), IEEE Signal Processing Soc		speech recognition; tandem; cross-domain adaptation; media archives		We describe our work on developing a speech recognition system for multi-genre media archives. The high diversity of the data makes this a challenging recognition task, which may benefit from systems trained on a combination of in-domain and out-of-domain data. Working with tandem HMMs, we present Multi-level Adaptive Networks (MLAN), a novel technique for incorporating information from out-of-domain posterior features using deep neural networks. We show that it provides a substantial reduction in WER over other systems, with relative WER reductions of 15% over a PLP baseline, 9% over in-domain tandem features and 8% over the best out-of-domain tandem features.	[Bell, P. J.; Renals, S.; Swietojanski, P.] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland	Bell, PJ (reprint author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9AB, Midlothian, Scotland.	peter.bell@ed.ac.uk; mjfg@eng.cam.ac.uk; pk127@eng.cam.ac.uk; x1207@eng.cam.ac.uk; y1467@eng.cam.ac.uk; s.renals@ed.ac.uk; p.swietojanski@sms.ed.ac.uk; pcw@eng.cam.ac.uk					Alberti C, 2009, INT CONF ACOUST SPEE, P4873, DOI 10.1109/ICASSP.2009.4960723; BRAUNSCHWEILER N, 2010, P INTERSPEECH, P2222; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Hain T, 2012, IEEE T AUDIO SPEECH, V20, P486, DOI 10.1109/TASL.2011.2163395; HERMANSKY H, 2000, P ICASSP, P1635; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Larson M, 2011, P MEDIAEVAL 2011 WOR; Le VB, 2010, INT CONF ACOUST SPEE, P4866, DOI 10.1109/ICASSP.2010.5495116; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Ogata J., 2009, P INTERSPEECH; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Raimond Y., 2012, P WWW 2012; Sainath T.N., 2012, P ICASSP; Sivadas S., 2004, P ICASSP; Stolcke Andreas, 2006, P ICASSP; Thomas S., 2012, P ICASSP IN PRESS; Thomas Samuel, 2010, P INTERSPEECH; Tranter S. E., P FALL 2004 RICH TRA; Yang J., 2012, CUEDFINFENGTR676; Zheng J., 2007, P ICASSP	22	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-5126-3				2012							324	329				6	Engineering, Electrical & Electronic	Engineering	BEL18	WOS:000317182800057		
J	Hradis, M; Kolar, M; Lanik, A; Kral, J; Zemcik, P; Smrz, P		BlancTalon, J; Philips, W; Popescu, D; Scheunders, P; Zemcik, P		Hradis, Michal; Kolar, Martin; Lanik, Ales; Kral, Jiri; Zemcik, Pavel; Smrz, Pavel			Annotating Images with Suggestions User - Study of a Tagging System	ADVANCED CONCEPTS FOR INTELLIGENT VISION SYSTEMS (ACIVS 2012)	Lecture Notes in Computer Science		English	Proceedings Paper	14th International Conference on Advanced Concepts for Intelligent Vision Systems (ACIVS)	SEP 04-07, 2012	Brno, CZECH REPUBLIC	Brno Univ Technol, Camea, Ghent Univ, Honeywell, Redhat, Unis, Zoner		Restricted Boltzmann Machine; human-assisted learning; user interface; image tagging; crowdsourcing; image classification		This paper explores the concept of image-wise tagging. It introduces a web-based user interface for image annotation, and a novel method for modeling dependencies of tags using Restricted Boltzmann Machines which is able to suggest probable tags for an image based on previously assigned tags. According to our user study, our tag suggestion methods improve both user experience and annotation speed. Our results demonstrate that large datasets with semantic labels (such as in TRECVID Semantic Indexing) can be annotated much more efficiently with the proposed approach than with current class-domain-wise methods, and produce higher quality data.	[Hradis, Michal; Kolar, Martin; Lanik, Ales; Kral, Jiri; Zemcik, Pavel; Smrz, Pavel] VUT Brno Univ Technol, Fac Informat Technol, Brno, Czech Republic	Hradis, M (reprint author), VUT Brno Univ Technol, Fac Informat Technol, Brno, Czech Republic.						Ayache S, 2007, SIGNAL PROCESS-IMAGE, V22, P692, DOI 10.1016/j.image.2007.05.010; Ayache S, 2008, 30 EUR P IR RES; Carreira-Perpinan M., 2005, ARTIF INTELL, V2005, P17; Deng J., IMAGENET LARGE SCALE, P2; Everingham M., 2009, INT J COMPUT VISION, V88, P303; Griffin G., 2007, CALTECH 256 OBJECT C; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Over P., 2011, P TRECVID 2011; Salakhutdinov R., 2007, P 24 INT C MACH LEAR, V227, P791, DOI DOI 10.1145/1273496.1273596; Smith J.R., 2006, EVALUATION, P86; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128	12	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-33140-4	LECT NOTES COMPUT SC			2012	7517						155	166				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BC8FF	WOS:000355595900014		
J	Mrazova, I; Kukacka, M		Dagli, CH		Mrazova, Iveta; Kukacka, Marek			Can Deep Neural Networks Discover Meaningful Pattern Features?	COMPLEX ADAPTIVE SYSTEMS 2012	Procedia Computer Science		English	Proceedings Paper	Conference on Complex Adaptive Systems	NOV 14-16, 2012	Washington, DC	Missouri Univ Sci & Technol, Lockheed Martin, Mocana, Tata Consultancy Serv, GAK3, Drexel Univ Online, Hark.com		convolutional neural networks; image classification; self-organization; feature extraction; pruning; generalization		Recent advances in the area of deep neural networks brought a lot of attention to some of the key issues important for their design. In particular for 2D-shapes, their accuracy has been shown to outperform all other classifiers -e.g., in the German Traffic Sign competition run by IJCNN 2011. On the other hand, their training may be quite cumbersome and the structure of the network has to be chosen beforehand. This paper introduces a new sensitivity-based approach capable of picking the right image features from a pre-trained SOM-like feature detector. Experimental results obtained so far for hand-written digit recognition show that pruned network architectures impact a transparent representation of the features actually present in the data while improving network robustness.	[Mrazova, Iveta; Kukacka, Marek] Charles Univ Prague, Fac Math & Phys, Dept Theoret Comp Sci & Mathem Log, Prague, Czech Republic	Mrazova, I (reprint author), Charles Univ Prague, Fac Math & Phys, Dept Theoret Comp Sci & Mathem Log, Prague, Czech Republic.	iveta.mrazova@mff.cuni.cz; mkukacka@gmail.com					Bengio Y., 2009, FDN TRENDS MACHINE L, V2, P2; Castillo E, 2006, J MACH LEARN RES, V7, P1159; Ciresan D. C., 2011, P IEEE INT JOINT C N, P1918; Erhan D., 2010, P AISTATS, P201; Fritzke B., 1995, ADV NEURAL INFORMATI, V7, P625; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Mrazova I., 2010, P ICMV 2010, P223; PAPE L, 2011, P IJCNN 2011, P1191; Sermanet P., 2011, P IEEE INT JOINT C N, P2809; Zurada J. M., 1994, P IEEE INT S CIRC SY, P447	11	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1877-0509			PROCEDIA COMPUT SCI			2012	12						194	199		10.1016/j.procs.2012.09.053		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BDU80	WOS:000314992600029		
J	Singh, L; Chetty, G; Sharma, D		Shibuya, T; Kashima, H; Sese, J; Ahmad, S		Singh, Lavneet; Chetty, Girija; Sharma, Dharmendra			A Novel Machine Learning Approach for Detecting the Brain Abnormalities from MRI Structural Images	PATTERN RECOGNITION IN BIOINFORMATICS	Lecture Notes in Computer Science		English	Proceedings Paper	7th International-Association-for-Pattern-Recognition (IAPR) International Conference on Pattern Recognition in Bioinformatics (PRIB)	NOV 08-10, 2012	Tokyo, JAPAN	Int Assoc Pattern Recognit, Tokyo Inst Technol, Japanese Soc Bioinformat		Deep Machine Learning; Extreme Machine Learning; MRI; PCA	NEURAL-NETWORKS; CLASSIFICATION	In this study, we present the investigations being pursued in our research laboratory on magnetic resonance images ( MRI) of various states of brain by extracting the most significant features, and to classify them into normal and abnormal brain images. We propose a novel method based ondeep and extreme machine learning on wavelet transform to initially decompose the images, and then use various features selection and search algorithms to extract the most significant features of brain from the MRI images. By using a comparative study with different classifiers to detect the abnormality of brain images from publicly available neuro-imaging dataset, we found that a principled approach involving wavelet based feature extraction, followed by selection of most significant features using PCA technique, and the classification using deep and extreme machine learning based classifiers results in a significant improvement in accuracy and faster training and testing time as compared to previously reported studies.	[Singh, Lavneet; Chetty, Girija; Sharma, Dharmendra] Univ Canberra, Fac Informat Sci & Engn, Canberra, ACT 2601, Australia	Singh, L (reprint author), Univ Canberra, Fac Informat Sci & Engn, Canberra, ACT 2601, Australia.	Lavneet.singh@canberra.edu.au; Girija.chetty@canberra.edu.au; Dharmendra.sharma@canberra.edu.au	Chetty, Girija/C-2221-2008	Chetty, Girija/0000-0001-6264-8644			Abdolmaleki P, 1997, CANCER LETT, V118, P69, DOI 10.1016/S0304-3835(97)00233-4; Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002; Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9; Fletcher-Heath LM, 2001, ARTIF INTELL MED, V21, P43, DOI 10.1016/S0933-3657(00)00073-7; Gorunescu F, 2007, PROC WRLD ACAD SCI E, V25, P427; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Kara S, 2007, EXPERT SYST APPL, V32, P632, DOI 10.1016/j.eswa.2006.01.043; Lin M.B., 2005, NEUROCOMPUTING, V68, P306; Maitra M, 2008, MED ENG PHYS, V30, P615, DOI 10.1016/j.medengphy.2007.06.009; Mishra A., 2012, P IEEE WORLD C COMP; Rosenbaum T, 1999, BRAIN DEV-JPN, V21, P268, DOI 10.1016/S0387-7604(99)00024-8; Serre D., 2002, MATRICES THEORY APPL; Singh L., 2012, LNCS, V7376, P660; Singh Lavneet, 2012, P INT C NEUR EV INT	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-34123-6	LECT NOTES COMPUT SC			2012	7632						94	105				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BA3VK	WOS:000334930400009		
J	Sun, M; Van Hamme, H			IEEE	Sun, Meng; Van Hamme, Hugo			TRI-FACTORIZATION LEARNING OF SUB-WORD UNITS WITH APPLICATION TO VOCABULARY ACQUISITION	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		semi-supervised learning; vocabulary acquisition; pattern discovery; spectral embedding		In prior work, we proposed a method for vocabulary acquisition based on a co-occurrence model and non-negative matrix factorization. The vocabulary is described in terms of co-occurrence statistics of frame-level acoustic descriptions and suffers from poor scalability to larger vocabularies. Much like whole-word HMM models, there is no reuse of a sub-word units such as phone models. In this paper, we apply the co-occurrence framework to learn a set of sub-word units unsupervisedly using a matrix tri-factorization and propose a method for computing their posteriorgram and finally show vocabulary acquisition from the posteriorgram. The method outperforms our prior work in that it can learn from a smaller set of labeled data and shows a better recognition accuracy.	[Sun, Meng; Van Hamme, Hugo] Katholieke Univ Leuven, Dept Elect Engn, ESAT, B-3001 Louvain, Belgium	Sun, M (reprint author), Katholieke Univ Leuven, Dept Elect Engn, ESAT, Kasteelpk Arenberg 10,Bus 2441, B-3001 Louvain, Belgium.	mengsun@esat.kuleuven.be; hugo.vanhamme@esat.kuleuven.be	Van hamme, Hugo/D-6581-2012				Aimetti G., 2009, INTERSPEECH; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu D., 2011, J COMPUTER IN PRESS; Park AS, 2008, IEEE T AUDIO SPEECH, V16, P186, DOI 10.1109/TASL.2007.909282; Roy D, 2003, IEEE T MULTIMEDIA, V5, P197, DOI 10.1109/TMM.2003.811618; Sun M., 2011, ICASSP; ten Bosch L., 2008, INTERSPEECH; Vanluyten B, 2008, LINEAR ALGEBRA APPL, V429, P1409, DOI [10.1016/j.laa.2008.03.010, 10.1016/j.laa.2008.03.01]	8	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							5177	5180				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381405063		
J	Tur, G; Deng, L; Hakkani-Tur, D; He, XD			IEEE	Tur, Gokhan; Deng, Li; Hakkani-Tuer, Dilek; He, Xiaodong			TOWARDS DEEPER UNDERSTANDING: DEEP CONVEX NETWORKS FOR SEMANTIC UTTERANCE CLASSIFICATION	2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing	MAR 25-30, 2012	Kyoto, JAPAN	Inst Elect & Elect Engineers, Signal Processing Soc, IEEE		deep convex networks; spoken language understanding; domain detection; semantic utterance classification; deep learning		Following the recent advances in deep learning techniques, in this paper, we present the application of special type of deep architecture - deep convex networks (DCNs) - for semantic utterance classification (SUC). DCNs are shown to have several advantages over deep belief networks (DBNs) including classification accuracy and training scalability. However, adoption of DCNs for SUC comes with non-trivial issues. Specifically, SUC has an extremely sparse input feature space encompassing a very large number of lexical and semantic features. This is about a few thousand times larger than the feature space for acoustic modeling, yet with a much smaller number of training samples. Experimental results we obtained on a domain classification task for spoken language understanding demonstrate the effectiveness of DCNs. The DCN-based method produces higher SUC accuracy than the Boosting-based discriminative classifier with word trigrams.			gokhan.tur@ieee.org; deng@microsoft.com; dilek@ieee.org; xiaohe@microsoft.com					Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Chu-Carroll J, 1999, COMPUT LINGUIST, V25, P361; Dahl G.E., 2012, IEEE T AUDIO SPE JAN; Deng L., 2011, P INT FLOR IT; Deng L., 2012, P ICASSP; Deng L., 2010, P INTERSPEECH; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gilbert M, 2005, IEEE SIGNAL PROC MAG, V22, P32, DOI 10.1109/MSP.2005.1511822; Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X; Haffner P., 2003, P ICASSP HONG KONG A; He X., 2011, P ICASSP; He X. D., 2011, IEEE SIGNAL PROCESSI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2011, P ICASSP PRAG CZECH; Karahan M., 2003, P IEEE ASRU WORKSH U; Mohamed A., 2010, P INTERSPEECH; Sarikaya R., 2011, P ICASSP PRAG CZECH; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Tur G., 2011, INTENT DETERMINATION; Yaman S, 2008, IEEE T AUDIO SPEECH, V16, P1207, DOI 10.1109/TASL.2008.2001106; Yang Y., 1997, P ICML; Yu D., 2010, NIPS WORKSH DEEP LEA; Zhang Y., 2011, P ICASSP	23	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4673-0046-9				2012							5045	5048				4	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BDA84	WOS:000312381405030		
S	Zhou, P; Dai, LR; Liu, QF; Jiang, H		Baozong, Y; Qiuqi, R; Xiaofang, T		Zhou, Pan; Dai, Lirong; Liu, Qingfeng; Jiang, Hui			Combining Information from Multi-Stream Features Using Deep Neural Network in Speech Recognition	PROCEEDINGS OF 2012 IEEE 11TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING (ICSP) VOLS 1-3	International Conference on Signal Processing		English	Proceedings Paper	IEEE 11th International Conference on Signal Processing (ICSP)	OCT 21-25, 2012	Beijing, PEOPLES R CHINA	IEEE, Chinese Inst Elect, Institut Engn & Technol, Union Radio Sci Int, Natl Nat Sci Fdn China, IEEE Beijing Sect, IEEE Signal Proc Soc Beijing Chapter, IEEE Comp Soc Beijing Chapter, Japan China Sci & Technol Exchange Assoc, Shenzhen Univ, Intelligent Informat Inst, CIC Commun & Signal Proc Soc, Beijing Jiaotong Univ, CIE Signal Proc Soc		multi-stream combination; deep learning; phoneme recognition; DNN-HMM; intermediate integration		The subject of the paper is the integration of multi-stream features in the framework of hybrid artificial neural network (ANN) - hidden Markov model (HMM). We investigate the use of log filter bank and MFCC features in multi-stream combination for phoneme recognition. An intermediate integration method is proposed to fuse the information from different sets of features. By exploiting deep learning algorithm to train the deep neural network (DNN), we explore different stream combination methods. Results of recognition experiments using DNN-HMM system on the TIMIT speech data show that the proposed approach is not only superior to the single best stream, which is relative 6.1% phone error rate (PER) reduction, but outperforms the other fusion strategies as well.	[Zhou, Pan; Dai, Lirong] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China	Zhou, P (reprint author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Peoples R China.	pan2005@mail.ustc.edu.cn; lrdai@ustc.edu.cn; qfliu@iflytek.com; hj@cse.yorku.ca					Bourlard H.A., 1993, CONNECTIONIST SPEECH; Dahl G. E., 2012, IEEE T AUDIO SPEECH; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; MISRA H, 2003, ACOUST SPEECH SIG PR, P741; Mohamed A., 2012, IEEE T AUDIO SPEECH; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Pinto J, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2414; Seide F., 2011, INTERSPEECH, P437	13	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2164-5221		978-1-4673-2197-6; 978-1-4673-2196-9	INT CONF SIGN PROCES			2012							557	561				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BC0JG	WOS:000349102800128		
J	Shet, V; Singh, M; Bahlmann, C; Ramesh, V; Neumann, J; Davis, L				Shet, Vinay; Singh, Maneesh; Bahlmann, Claus; Ramesh, Visvanathan; Neumann, Jan; Davis, Larry			Predicate Logic Based Image Grammars for Complex Pattern Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Stochastic image grammars; Logical reasoning; Human detection; Object detection and classification; Bilattice; Back propagation; Aerial image analysis	SEGMENTATION; ALGORITHMS	Predicate logic based reasoning approaches provide a means of formally specifying domain knowledge and manipulating symbolic information to explicitly reason about different concepts of interest. Extension of traditional binary predicate logics with the bilattice formalism permits the handling of uncertainty in reasoning, thereby facilitating their application to computer vision problems. In this paper, we propose using first order predicate logics, extended with a bilattice based uncertainty handling formalism, as a means of formally encoding pattern grammars, to parse a set of image features, and detect the presence of different patterns of interest. Detections from low level feature detectors are treated as logical facts and, in conjunction with logical rules, used to drive the reasoning. Positive and negative information from different sources, as well as uncertainties from detections, are integrated within the bilattice framework. We show that this approach can also generate proofs or justifications (in the form of parse trees) for each hypothesis it proposes thus permitting direct analysis of the final solution in linguistic form. Automated logical rule weight learning is an important aspect of the application of such systems in the computer vision domain. We propose a rule weight optimization method which casts the instantiated inference tree as a knowledge-based neural network, interprets rule uncertainties as link weights in the network, and applies a constrained, back-propagation algorithm to converge upon a set of rule weights that give optimal performance within the bilattice framework. Finally, we evaluate the proposed predicate logic based pattern grammar formulation via application to the problems of (a) detecting the presence of humans under partial occlusions and (b) detecting large complex man made structures as viewed in satellite imagery. We also evaluate the optimization approach on real as well as simulated data and show favorable results.	[Shet, Vinay; Singh, Maneesh; Bahlmann, Claus; Ramesh, Visvanathan] Siemens Corp Res, Princeton, NJ 08540 USA; [Neumann, Jan] Streamsage Comcast, Washington, DC 20005 USA; [Davis, Larry] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Shet, V (reprint author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	vinay.shet@siemens.com; maneesh.singh@siemens.com; claus.bahlmann@siemens.com; visvanathan.ramesh@siemens.com; jan_neumann@cable.comcast.com; lsd@umiacs.umd.edu			US Government [NBCHC080029]	Application and experimental validation of the reasoning framework on aerial images has been funded by US Government contract # NBCHC080029. Aerial images provided by DigiGlobe.	Arieli O, 2005, LECT NOTES COMPUT SC, V3571, P563; Arieli O, 2006, LECT NOTES ARTIF INT, V3885, P22; BINFORD TO, 2003, IEEE T PATTERN ANAL, V25; *CAV DAT, 2003, CAV DAT; Csurka G., 2004, ECCV SLCV WORKSH; CUSSENS J, 1999, P 15 C UNC ART INT; Dalal N, 2005, PROC CVPR IEEE, P886; Felzenszwalb PF, 2001, PROC CVPR IEEE, P1056; FERN A, 2005, INT JOINT C ART INT; Fitting M.C., 1990, 20 INT S MULT VAL LO, P238; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman N., 1999, P 16 INT JOINT C ART; GAVRILA, 1999, IEEE INT C COMP VIS; Gavrila D. M., 2000, EUR C COMP VIS ECCV, P37; GEMAN S, 2003, MATH FDN SPEECH LANG, P1; GINSBERG ML, 1988, COMPUTATIONAL INTELL; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jin Y., 2006, CVPR, P2145; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; Kersting K., 2001, P 11 INT C IND LOG P; Kokkinos I., 2009, P IEEE C COMP VIS PA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, EFFICIENT BACKPROP N; Leibe B, 2005, PROC CVPR IEEE, P878; Leonardis A., 2007, P IEEE C COMP VIS PA; LEUNG T, 2001, INT J COMPUT VISION, P43; Lin Luo, 2007, IEEE Global Telecommunications Conference Workshops. GLOBECOM Workshops 2007; LIN Z, 2007, HIERARCHICAL PART TE, P1; MAHONEY JJ, 1993, ADV NEURAL INFORM PR, V5, P107; MANN WB, 1995, THESIS STANFORD U; Papageorgiou C, 1998, INTELLIGENT VEHICLES, P241; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; RAMESH V, THESIS U WASHINGTON; Rumelhart D. E, 1986, PARALLEL DISTRIBUTED; Sato T., 1997, P 15 INT JOINT C ART; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHWEIZER B, 1963, PUBL MATH DEBRECEN; SHET V, 2009, 1 INT WORKSH STOCH I; Shet V. D., 2006, ECCV, P119; Shet V. D., 2007, CVPR, P2; Shet VD, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P224; Sochman J, 2005, PROC CVPR IEEE, P150; Taskar B., 2002, P 18 C UNC ART INT; TODOROVIC S, 2008, CVPR08; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657; Vapnik V. N., 1995, NATURE STAT LEARNING; VARMA M, 2005, INT J COMPUTER VISIO; Viola P., 2001, INT J COMPUTER VISIO; Viola P, 2001, P IEEE C COMP VIS PA; Walker L., 2004, VISION RES, V44, P2301; Wang W, 2006, IEEE T IMAGE PROCESS, V15, P3033, DOI 10.1109/TIP.2006.877496; WU, 2005, IEEE INT C COMP VIS; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; ZHU L, 2008, COMPUTER VISION ECCV; Zhu Q., 2006, CVPR, P1491; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	58	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2011	93	2					141	161		10.1007/s11263-010-0343-9		21	Computer Science, Artificial Intelligence	Computer Science	740PD	WOS:000288806000003		
J	Schulz, H; Muller, A; Behnke, S				Schulz, Hannes; Mueller, Andreas; Behnke, Sven			Exploiting local structure in Boltzmann machines	NEUROCOMPUTING			English	Article						Restricted Boltzmann machines; Low-level vision; Generative models		Restricted Boltzmann machines (RBM) are well-studied generative models. For image data, however, standard RBMs are suboptimal, since they do not exploit the local nature of image statistics. We modify RBMs to focus on local structure by restricting visible-hidden interactions. We model long-range dependencies using direct or indirect lateral interaction between hidden variables. While learning in our model is much faster, it retains generative and discriminative properties of RBMs of similar complexity. (C) 2011 Elsevier B.V. All rights reserved.	[Schulz, Hannes; Mueller, Andreas; Behnke, Sven] Univ Bonn Comp Sci VI, Autonomous Intelligent Syst Grp, D-53117 Bonn, Germany	Schulz, H (reprint author), Univ Bonn Comp Sci VI, Autonomous Intelligent Syst Grp, Romerstr 164, D-53117 Bonn, Germany.	schulz@ais.uni-bonn.de; mueller@ais.uni-bonn.de; behnke@cs.uni-bonn.de	Behnke, Sven/B-5509-2013	Behnke, Sven/0000-0002-5040-7525	NRW State within the B-IT Research School	This work was supported in part by NRW State within the B-IT Research School.	Behnke S., 2003, HIERARCHICAL NEURAL; BENGIO Y, 2008, ADV NEURAL INFORM PR, V20, P841; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUANG J, 1999, IEEE C COMPUTER VISI, P1541; Hyvarinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN ICM, V77; Norouzi M., 2009, IEEE C COMP VIS PATT, P2735; Osindero S, 2008, ADV NEURAL INFORM PR, V20, P1121; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; SALAKHUTDINOV R, 2008, LEARNING EVALUATING; Salakhutdinov R., 2009, THESIS U TORONTO; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T., 2008, INT C MACH LEARN ICM, P1064; UETZ R, 2009, P IEEE INT C INT COM; Welling Max, 2002, ADV NEURAL INFORM PR, P1359	18	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	APR	2011	74	9			SI		1411	1417		10.1016/j.neucom.2010.12.014		7	Computer Science, Artificial Intelligence	Computer Science	757IL	WOS:000290078600012		
J	Tajima, S; Watanabe, M				Tajima, Satohiro; Watanabe, Masataka			Acquisition of nonlinear forward optics in generative models: Two-stage "downside-up" learning for occluded vision	NEURAL NETWORKS			English	Article						Vision; Generative model; Predictive coding; Neural network; Occlusion; Learning; Developmental stage	PRIMARY VISUAL-CORTEX; STRIATE CORTEX; RESPONSE PROPERTIES; INFANTS PERCEPTION; NEURAL-NETWORKS; BRIGHTNESS; SURFACE; MACAQUE; AREAS; REPRESENTATION	We propose a two-stage learning method which implements occluded visual scene analysis into a generative model, a type of hierarchical neural network with bi-directional synaptic connections. Here, top-down connections simulate forward optics to generate predictions for sensory driven low-level representation, whereas bottom-up connections function to send the prediction error, the difference between the sensory based and the predicted low-level representation, to higher areas. The prediction error is then used to update the high-level representation to obtain better agreement with the visual scene. Although the actual forward optics is highly nonlinear and the accuracy of simulated forward optics is crucial for these types of models, the majority of previous studies have only investigated linear and simplified cases of forward optics. Here we take occluded vision as an example of nonlinear forward optics, where an object in front completely masks out the object behind. We propose a two-staged learning method inspired by the staged development of infant visual capacity. In the primary learning stage, a minimal set of object basis is acquired within a linear generative model using the conventional unsupervised learning scheme. In the secondary learning stage, an auxiliary multi-layer neural network is trained to acquire nonlinear forward optics by supervised learning. The important point is that the high-level representation of the linear generative model serves as the input and the sensory driven low-level representation provides the desired output. Numerical simulations show that occluded visual scene analysis can indeed be implemented by the proposed method. Furthermore, considering the format of input to the multi-layer network and analysis of hidden-layer units leads to the prediction that whole object representation of partially occluded objects, together with complex intermediate representation as a consequence of nonlinear transformation from non-occluded to occluded representation may exist in the low-level visual system of the brain. (C) 2010 Elsevier Ltd. All rights reserved.	[Tajima, Satohiro] NHK Japan Broadcasting Corp, Nagano Stn, Nagano 3808502, Japan; [Tajima, Satohiro] Univ Tokyo, Grad Sch Frontier Sci, Kashiwa, Chiba 2778561, Japan; [Watanabe, Masataka] Univ Tokyo, Fac Engn, Bunkyo Ku, Tokyo 1130033, Japan	Tajima, S (reprint author), NHK Japan Broadcasting Corp, Nagano Stn, 210-2 Inaba, Nagano 3808502, Japan.	tajima.s-iu@nhk.or.jp; watanabe@bs.t.u-tokyo.ac.jp			Ministry of Education, Culture, Sports, Science and Technology (MEXT) [17022015]	The second author's work is supported by grants from the Ministry of Education, Culture, Sports, Science and Technology (MEXT), No. 17022015. We thank the reviewers for many suggestions to improve the paper. We also thank Dr. T. Melano for discussion and comments on the earlier version of the manuscript.	ATKINSON J, 2000, J NEUROSCI, V20, P8188; BAN H, 2004, 104100 IEICE HIP, P1; BARTLETT JR, 1974, J NEUROPHYSIOL, V37, P621; BURKHALTER A, 1993, CEREB CORTEX, V3, P476, DOI 10.1093/cercor/3.5.476; Caplovitz GP, 2006, PERCEPTION, V35, P993, DOI 10.1068/p5568; Craton LG, 1996, CHILD DEV, V67, P890, DOI 10.1111/j.1467-8624.1996.tb01771.x; Csibra G, 2001, DEVELOPMENTAL SCI, V4, pF7, DOI 10.1111/1467-7687.00179; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; Fukushima K, 2005, NEURAL NETWORKS, V18, P33, DOI 10.1016/j.neunet.2004.05.001; Gori M, 2009, NEURAL NETWORKS, V22, P1035, DOI 10.1016/j.neunet.2009.06.048; GROSSBERG S, 1985, PERCEPT PSYCHOPHYS, V38, P41; HEITGER F, 1994, IEEE P PERC ACT C, V18, P181; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hung CP, 2001, VISION RES, V41, P1389, DOI 10.1016/S0042-6989(01)00075-X; Hung CP, 2007, NAT NEUROSCI, V10, P1185, DOI 10.1038/nn1948; JAAKKOLA T, 1996, ADV NEURAL INFORM PR, V8; KAWATO M, 1993, NETWORK-COMP NEURAL, V4, P415, DOI 10.1088/0954-898X/4/4/001; KAYAMA Y, 1979, J NEUROPHYSIOL, V42, P1495; Kinoshita M, 2001, J NEUROPHYSIOL, V86, P2559; Lee TS, 2001, P NATL ACAD SCI USA, V98, P1907, DOI 10.1073/pnas.031579998; MacEvoy SP, 2001, P NATL ACAD SCI USA, V98, P8827, DOI 10.1073/pnas.161280398; MacEvoy SP, 1998, NAT NEUROSCI, V1, P616; Marr D., 1982, COMPUTATIONAL INVEST; MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Otsuka Y, 2006, PERCEPTION, V35, P1251, DOI 10.1068/p5258; Rao RPN, 1997, NEURAL COMPUT, V9, P721, DOI 10.1162/neco.1997.9.4.721; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Roe AW, 2005, P NATL ACAD SCI USA, V102, P3869, DOI 10.1073/pnas.0500097102; Rossi AF, 1996, SCIENCE, V273, P1104, DOI 10.1126/science.273.5278.1104; Rossi AF, 1999, J NEUROSCI, V19, P6145; SAJDA P, 1995, J COGNITIVE NEUROSCI, V7, P267, DOI 10.1162/jocn.1995.7.2.267; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Slater A, 1996, INFANT BEHAV DEV, V19, P145, DOI 10.1016/S0163-6383(96)90052-1; SQUATRITO S, 1990, BRAIN RES, V536, P261, DOI 10.1016/0006-8993(90)90034-9; Sugita Y, 1999, NATURE, V401, P269, DOI 10.1038/45785; ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0	39	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	MAR	2011	24	2					148	158		10.1016/j.neunet.2010.10.004		11	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	728YJ	WOS:000287910100002	21094592	
J	Berry, J; Fasel, I			IEEE	Berry, Jeff; Fasel, Ian			DYNAMICS OF TONGUE GESTURES EXTRACTED AUTOMATICALLY FROM ULTRASOUND	2011 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	MAY 22-27, 2011	Prague, CZECH REPUBLIC	Inst Elect & Elect Engineers Signal Processing Soc, IEEE	Prague Congress Ctr	Deep Belief Networks; Ultrasound		We describe a system for automatically extracting dynamics of tongue gestures from ultrasound images of the tongue using translational deep belief networks (tDBNs). In tDBNs, a joint model of the input and output vectors are learned during a generative pretraining stage, and then a translation step is used to transform input-only vectors into this joint representation. A final fine-tuning stage is then used to reconstruct the desired outputs given input vectors. We show that this technique dramatically improves performance on segmenting ultrasound image sequences of continuous speech into individual consonant gestures compared with the original DBN method of [1] as well as alternative methods using PCA and support vector machines.	[Berry, Jeff; Fasel, Ian] Univ Arizona, Tucson, AZ 85721 USA	Berry, J (reprint author), Univ Arizona, Tucson, AZ 85721 USA.						Bresch E., 2008, IEEE SIGNAL PROCESSI; BROWMAN CP, 1992, PHONETICA, V49, P155; Chang C.C., 2001, LIBSVM LIB SUPPORT V; FASEL I, 2010, INT C PATT REC; Gick B, 2006, J PHONETICS, V34, P49, DOI 10.1016/j.wocn.2005.03.005; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hueber T, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2032; Larochelle H., 2008, ICML, P536; Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616; MOVELLAN JR, 2008, NEURAL COMPUTATION, V20; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; XING E, 2005, P UNC ART INT	13	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4577-0539-7	INT CONF ACOUST SPEE			2011							557	560				4	Acoustics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Engineering; Imaging Science & Photographic Technology	BXG36	WOS:000296062400140		
J	Chao, J; Shen, FR; Zhao, JX			IEEE	Chao, Jing; Shen, Furao; Zhao, Jinxi			Forecasting Exchange Rate with Deep Belief Networks	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			NEURAL-NETWORKS; FEEDFORWARD; ALGORITHM	Forecasting exchange rates is an important financial problem which has received much attention. Nowadays, neural network has become one of the effective tools in this research field. In this paper, we propose the use of a deep belief network (DBN) to tackle the exchange rate forecasting problem. A DBN is applied to predict both British Pound/US dollar and Indian rupee/US dollar exchange rates in our experiments. We use six evaluation criteria to evaluate its performance. We also compare our method to a feedforward neural network (FFNN), which is the state-of-the-art method for forecasting exchange rate with neural networks. Experiments indicate that deep belief networks (DBNs) are applicable to the prediction of foreign exchange rate, since they achieve better performance than feedforward neural networks (FFNNs).	[Chao, Jing; Shen, Furao; Zhao, Jinxi] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Chao, J (reprint author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	yoyo72-@163.com; frshen@nju.edu.cn; jxzhao@nju.edu.cn					Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362; Chen H., 2002, P 12 INT C ART NEUR, P358; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Emam A., 2008, P 46 AN SE REG C 20, P63, DOI 10.1145/1593105.1593121; Frey BJ, 1997, ADV NEUR IN, V9, P452; Gioqinang Z., 1998, INT J MANAGEMENT SXI, V26, P495; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; KUAN CM, 1995, J APPL ECONOMET, V10, P347, DOI 10.1002/jae.3950100403; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Murray AF, 2001, NEURAL NETWORKS, V14, P1257, DOI 10.1016/S0893-6080(01)00097-1; Nag AK, 2002, J FORECASTING, V21, P501, DOI 10.1002/for.838; Panda C, 2007, J POLICY MODEL, V29, P227, DOI 10.1016/j.jpolmod.2006.01.005; Weigend A. S., 1992, NONLINEAR MODELING F, P395; Weigend A.S., 1990, ADV NEURAL INFORMATI, V3, P875; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; White H, 1988, P IEEE INT C NEUR NE, P451, DOI DOI 10.1109/ICNN.1988.23959	19	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-9636-5				2011							1259	1266				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541201055		
S	Heess, N; Le Roux, N; Winn, J		Honkela, T; Duch, W; Girolami, M; Kaski, S		Heess, Nicolas; Le Roux, Nicolas; Winn, John			Weakly Supervised Learning of Foreground-Background Segmentation Using Masked RBMs	ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2011, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	21st International Conference on Artificial Neural Networks, ICANN 2011	JUN 14-17, 2011	Espoo, FINLAND	Aalto Univ Sch Sci, Dept Informat & Comp Sci	Aalto Univ Sch Sci	RBM; segmentation; weakly supervised learning	IMAGES	We propose an extension of the Restricted Boltzmann Machine (RBM) that allows the joint shape and appearance of foreground objects in cluttered images to be modeled independently of the background. We present a learning scheme that learns this representation directly from cluttered images with only very weak supervision. The model generates plausible samples and performs foreground-background segmentation. We demonstrate that representing foreground objects independently of the background can be beneficial in recognition tasks.	[Heess, Nicolas] Univ Edinburgh, IANC, Edinburgh, Midlothian, Scotland	Heess, N (reprint author), Univ Edinburgh, IANC, Edinburgh, Midlothian, Scotland.						Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang G. B., 2007, 0749 U MASS; Lee H., 2009, ICML; Le Roux N, 2011, NEURAL COMPUT, V23, P593, DOI 10.1162/NECO_a_00086; Ranzato M., 2010, CVPR; Salakhutdinov R., 2009, AISTATS; Tang Y., 2010, NIPS WORKSH TRANSF L; TIELEMAN T, 2008, ICML; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096; Wolf L, 2010, LECT NOTES COMPUT SC, V5995, P88; SUPPL MAT	13	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-21737-1	LECT NOTES COMPUT SC			2011	6792						9	16				8	Automation & Control Systems; Computer Science, Interdisciplinary Applications	Automation & Control Systems; Computer Science	BXN31	WOS:000296487200002		
J	Hollesen, P; Connors, WA; Trappenberg, T		Butz, C; Lingras, P		Hollesen, Paul; Connors, Warren A.; Trappenberg, Thomas			Comparison of Learned versus Engineered Features for Classification of Mine Like Objects from Raw Sonar Images	ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	24th Canadian Conference on Artificial Intelligence (AI) / 37th Graphics Interface Conference (GI) / 8th Canadian Conference on Computer and Robot Vision (CRV)	MAY 25-27, 2011	St Johns, CANADA	Canadian Artificial Intelligence Assoc (CAIAC), Mem Univ, Compusult, Palomino Syst Innovat Inc, Univ Regina, St Marys Univ, NLP Technologies Inc, Springer				Advances in high frequency sonar have provided increasing resolution of sea bottom objects, providing higher fidelity sonar data for automated target recognition tools. Here we investigate if advanced techniques in the field of visual object recognition and machine learning can be applied to classify mine-like objects from such sonar data. In particular, we investigate if the recently popular Scale-Invariant Feature Transform (SIFT) can be applied for such high-resolution sonar data. We also follow up our previous approach in applying the unsupervised learning of deep belief networks, and advance our methods by applying a convolutional Restricted Boltzmann Machine (cRBM). Finally, we now use Support Vector Machine (SVM) classifiers on these learned features for final classification. We find that the cRBM-SVM combination slightly outperformed the SIFT features and yielded encouraging performance in comparison to state-of-the-art, highly engineered template matching methods.	[Hollesen, Paul; Trappenberg, Thomas] Dalhousie Univ, Dept Comp Sci, Halifax, NS B3H 3J5, Canada	Hollesen, P (reprint author), Dalhousie Univ, Dept Comp Sci, Halifax, NS B3H 3J5, Canada.	hollense@cs.dal.ca; warren.connors@drdc-rddc.gc.ca; tt@cs.dal.ca					[Anonymous], 2008, NIPS, P1145; Bellettini A., 2008, IEEE J OCEANIC ENG, V34, P285; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chapple P., 2008, TECHNICAL REPORT; Connors W., 2007, P 23 CAN C AI; Fawcett J., 2007, 2007162 TM DEF RES D; Fawcett J., 2006, 2006115 TM DEF RES D; Geoffrey Hinton, 2010, 2010003 UTML TR U TO; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lazebnik S., 2006, 2006 IEEE COMP SOC C, P2169; Lee H., 2009, CONVOLUTIONAL DEEP B; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Myers V., 2009, P UAM 2009 C NAFPL G; Myers V, 2010, IEEE SIGNAL PROC LET, V17, P683, DOI 10.1109/LSP.2010.2051574	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-21042-6	LECT NOTES ARTIF INT			2011	6657						174	185				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCX79	WOS:000311897300021		
S	Marin-Jimenez, MJ; de la Blanca, NP; Mendoza, MA		Vitria, J; Sanches, JM; Hernandez, M		Jesus Marin-Jimenez, Manuel; Perez de la Blanca, Nicolas; Angeles Mendoza, Maria			Learning Features for Human Action Recognition Using Multilayer Architectures	PATTERN RECOGNITION AND IMAGE ANALYSIS: 5TH IBERIAN CONFERENCE, IBPRIA 2011	Lecture Notes in Computer Science		English	Proceedings Paper	5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA)	JUN 08-10, 2011	Las Palmas, SPAIN	Asociacion Espanola Reconocimiento Formas Analisis Imagenes (AERFAI), Assoc Portuguesa Reconhecimento Padroes (APRP)	Univ Las Palmas Gran Canaria (ULPGC)		MOTION	This paper presents an evaluation of two multilevel architectures in the human action recognition (HAR) task. By combining low level features with multi-layer learning architectures, we infer discriminative semantic features that highly improve the classification performance. This approach eliminates the difficult process of selecting good mid-level feature descriptors, changing the feature selection and extraction process by a learning stage. The data probability distribution is modeled by a multi-layer graphical model. In this way, this approach is different to the standard ones. Experiments on KTH and Weizmann video sequence databases are carried out in order to evaluate the performance of the proposal. The results show that the new learnt features offer a classification performance comparable to the state-of-the-art on these databases.	[Jesus Marin-Jimenez, Manuel] Univ Cordoba, Cordoba, Spain	Marin-Jimenez, MJ (reprint author), Univ Cordoba, Cordoba, Spain.	mjmarin@uco.es; nicolas@ugr.es; nines@decsai.ugr.es	Marin-Jimenez, Manuel J./	Marin-Jimenez, Manuel J./0000-0001-9294-6714			Bengio Y., 2007, 1312 U MONTR DEP IRO; Blank M., 2005, ICCV, V2, P1395; Fathi A., 2008, CVPR; Hastie T., 2001, ELEMENTS STAT LEARNI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jhuang H., 2007, P IEEE INT C COMP VI, P1; Kovashka A., 2010, CVPR; Laptev I., 2008, P CVPR 2008; Lin Z., 2009, INT C COMP VIS; Lui Y.M., 2010, COMP VISION PATT REC, P833; Marin-Jimenez M., 2009, WIAMIS 2009, P5; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Schindler K, 2008, LECT NOTES COMPUT SC, V5096, P122, DOI 10.1007/978-3-540-69321-5_13; Schuldt C., 2004, ICPR, V3, P32, DOI DOI 10.1109/ICPR.2004.1334462; Torralba A., 2008, COMP VISION PATT REC; Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-21256-7	LECT NOTES COMPUT SC			2011	6669						338	346				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BYU85	WOS:000300552200042		
S	Karnowski, TP; Arel, I; Young, S		Samsonovich, AV; Johannsdottir, KR		Karnowski, Thomas P.; Arel, Itamar; Young, Steven			Modeling Temporal Dynamics with Function Approximation in Deep Spatio-Temporal Inference Network	BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES 2011	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	2nd Annual Meeting of the Biologically-Inspired-Cognitive-Architectures-Society (BICA)	NOV 04-06, 2011	Arlington, VA	Biologically Inspired Cognit Architectures Soc		feature extraction; unsupervised learning; cortical	VISUAL-CORTEX	Biologically inspired deep machine learning is an emerging framework for dealing with complex high-dimensional data. An unsupervised feature extraction deep learning architecture called Deep Spatio-Temporal Inference Network (DeSTIN) utilizes a hierarchy of computational nodes, where each node features a common algorithm for inference of temporal patterns. The nodes all are geared to online learning and offer a generalization component which uses clustering and mixture models, as well as a temporal dynamics module. The latter is designed for tabular representation but such techniques are notoriously ill-suited for scaling as they impose an O(N-3) memory complexity. Instead, function approximation methods such as neural networks can serve as a more concise representation. In this work we present the results of DeSTIN on a popular problem, the MNIST data set of handwritten digits, using mixture models and function approximation to create a temporally evolving feature representation. We compare the results of the extracted features from DeSTIN under the tabular method and the function approximation method and contrast these results with our past work in this area.	[Karnowski, Thomas P.] Oak Ridge Natl Lab, ISML Grp, Oak Ridge, TN USA	Karnowski, TP (reprint author), ORNL, Knoxville, TN 37919 USA.	tkarnows@utk.edu					Arel I., 2009, NIPS 2009 WORKSH DEE; Arel I., 2009, P AAAI 2009 FALL S B; Bengio Y., 2009, LEARNING DEEP ARCHIT; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; George D., 2008, THESIS STANFORD U; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hornik Maxwell K., 1989, NEURAL NETWORKS, V2, P359; Karnowski T., 2010, MACH LEARN APPL ICML, P883; Keysers D., 2007, ARXIV07102231; LeCun Y., MNIST DATABASE HANDW; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Nissen S., 2003, REPORT DEP COMPUTER, V31; Young S., 2010, 2010 7 INT C INF TEC, P204, DOI 10.1109/ITNG.2010.148	15	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389		978-1-60750-959-2; 978-1-60750-958-5	FRONT ARTIF INTEL AP			2011	233						174	179		10.3233/978-1-60750-959-2-174		6	Computer Science, Artificial Intelligence; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BC0DP	WOS:000348931200029		
S	Kivinen, JJ; Williams, CKI		Honkela, T; Duch, W; Girolami, M; Kaski, S		Kivinen, Jyri J.; Williams, Christopher K. I.			Transformation Equivariant Boltzmann Machines	ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2011, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	21st International Conference on Artificial Neural Networks, ICANN 2011	JUN 14-17, 2011	Espoo, FINLAND	Aalto Univ Sch Sci, Dept Informat & Comp Sci	Aalto Univ Sch Sci	Boltzmann machines; transformation equivariant representations; convolutional structures; transformation invariance; steerable filters; image modeling	NEURAL NETWORKS; RECOGNITION; IMAGES	We develop a novel modeling framework for Boltzmann machines, augmenting each hidden unit with a latent transformation assignment variable which describes the selection of the transformed view of the canonical connection weights associated with the unit. This enables the inferences of the model to transform in response to transformed input data in a stable and predictable way, and avoids learning multiple features differing only with respect to the set of transformations. Extending prior work on translation equivariant (convolutional) models, we develop translation and rotation equivariant restricted Boltzmann machines (RBMs) and deep belief nets (DBNs), and demonstrate their effectiveness in learning frequently occurring statistical structure from artificial and natural images.	[Kivinen, Jyri J.; Williams, Christopher K. I.] Univ Edinburgh, Sch Informat, Inst Adapt & Neural Computat, Edinburgh EH8 9YL, Midlothian, Scotland	Kivinen, JJ (reprint author), Univ Edinburgh, Sch Informat, Inst Adapt & Neural Computat, Edinburgh EH8 9YL, Midlothian, Scotland.	j.j.kivinen@sms.ed.ac.uk; ckiw@inf.ed.ac.uk					Fidler S., 2007, CVPR; Hammond DK, 2008, IEEE T IMAGE PROCESS, V17, P2089, DOI 10.1109/TIP.2008.2004796; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ICML; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; MOZER MC, 1992, NEURAL COMPUT, V4, P650, DOI 10.1162/neco.1992.4.5.650; Nair V., 2009, NIPS; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ranzato M., 2010, NIPS; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; ZEMEL RS, 1995, NEURAL NETWORKS, V8, P503, DOI 10.1016/0893-6080(94)00094-3; Zhu L., 2008, ECCV	15	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-21734-0	LECT NOTES COMPUT SC			2011	6791						1	9				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BXM21	WOS:000296364500001		
J	Salman, A; Chen, K			IEEE	Salman, Ahmad; Chen, Ke			Exploring Speaker-Specific Characteristics with Deep Learning	2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)			English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUL 31-AUG 05, 2011	San Jose, CA	Int Neural Network Soc (INNS), IEEE Computat Intelligence Soc (CIS), Natl Sci Fdn (NSF), Cognimem Technol, Inc, Univ Cincinnati Coll Engn & Appl Sci, Toyota Res Inst N Amer, Univ Cincinnati, Sch Elect & Compu Syst			VERIFICATION; MODELS; RECOGNITION; IDENTIFICATION	Speech signals convey different types of information which vary from linguistic to speaker-specific and should be used in different tasks. However, it is hard to extract a special type of information such that nearly all acoustic representations of speech present all kinds of information as a whole. The use of the same representation in different tasks creates a difficulty in achieving good performance in either speech or speaker recognition. In this paper, we present a deep neural architecture to explore speaker-specific characteristics from popular Mel-frequency cepstral coefficients. For learning, we propose an objective function consisting of contrastive cost in terms of speaker similarity and dissimilarity as well as data reconstruction cost used as regularization to normalize non-speaker related information. Learning deep architecture is done by a greedy layerwise local unsupervised training for initialization and a global supervised discriminative training for extracting a speaker-specific representation. By means of two narrow-band benchmark corpora, we demonstrate that our deep architecture generates a robust overcomplete speech representation in characterizing various speakers and the use of this new representation yields a favorite performance in speaker verification.	[Salman, Ahmad; Chen, Ke] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	Salman, A (reprint author), Univ Manchester, Sch Comp Sci, Kilburn Bldg,Oxford Rd, Manchester M13 9PL, Lancs, England.	salmanaa@cs.manchester.ac.uk; chen@cs.manchester.ac.uk					Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y., 2007, ADV NEURAL INFORM PR, V19; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bromley J., 1993, ADV NEURAL INFORM PR; Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714; Campbell WM, 2007, IEEE T AUDIO SPEECH, V15, P2085, DOI 10.1109/TASL.2007.902874; Chen K, 2003, PATTERN RECOGN, V36, P329; Chopra S, 2005, PROC CVPR IEEE, P539; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gori M, 1996, PATTERN RECOGN LETT, V17, P241, DOI 10.1016/0167-8655(95)00101-8; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang X., 2001, SPOKEN LANGUAGE PROC; Jang G., 2001, P ICASP; Jarrett K., 2009, P INT C COMP VIS; Jin Q., 2007, THESIS CARNEGIE MELL; Kim H., 2003, P EUR; Larochelle H., 2009, J MACHINE LEARNING R, V17, P1; LeCun Y., 2004, P IEEE CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, NEURAL INFORM PROCES; Mammone RJ, 1996, IEEE SIGNAL PROC MAG, V13, P58, DOI 10.1109/79.536825; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D; Reynolds D. A., 1995, Lincoln Laboratory Journal, V8; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Salakhutdinov R., 2007, AISTATS; Vincent P., 2007, P AISTATS; Wang L, 2002, IEEE T NEURAL NETWOR, V13, P436, DOI 10.1109/72.991429; Weinberger K., 2006, ADV NEURAL INFORM PR, V18; Yegnanarayana B, 2002, NEURAL NETWORKS, V15, P459, DOI 10.1016/S0893-6080(02)00019-9	32	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-9636-5				2011							103	110				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BXX80	WOS:000297541200017		
J	Spiliopoulou, A; Storkey, A		Gunopulos, D; Hofmann, T; Malerba, D; Vazirgiannis, M		Spiliopoulou, Athina; Storkey, Amos			Comparing Probabilistic Models for Melodic Sequences	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PT III	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 05-09, 2011	Athens, GREECE	Google, Pascal2 Network, Xerox, Yahoo Labs, COST-MOVE Act (Knowledge Discovery Movin, Objects), Rapid-I, FP7-MODAP Project (Mobil, Data Min, & Privacy), Athena RIC/Inst Management Informat Syst (IMIS), Hellen Artificial Intelligence Soc (EETN), Marathon Data Syst (MDS), Transinsight, Springer, SONY, UNESCO Privacy Chair, Univ Studi Bari Aldo Moro, Athens Univ Econ & Business, Dept Informat, Univ Ioannina, Dept Comp Sci, Natl & Kapodistrian Univ Athens, Univ Piraeus, Dept Informat, Univ Athens, Dept Informat & Telecommunicat, Google Inc, Univ degli Studi Bari Aldo Moro, Dipartimento Informatica		melody modeling; music feature extraction; time convolutional restricted Boltzmann machine; variable length Markov model; Dirichlet prior	LEARNING ALGORITHM	Modelling the real world complexity of music is a challenge for machine learning. We address the task of modeling melodic sequences from the same music genre. We perform a comparative analysis of two probabilistic models; a Dirichlet Variable Length Markov Model (Dirichlet-VMM) and a Time Convolutional Restricted Boltzmann Machine (TC-RBM). We show that the TC-RBM learns descriptive music features, such as underlying chords and typical melody transitions and dynamics. We assess the models for future prediction and compare their performance to a VMM, which is the current state of the art in melody generation. We show that both models perform significantly better than the VMM, with the Dirichlet-VMM marginally outperforming the TC-RBM. Finally, we evaluate the short order statistics of the models, using the Kullback-Leibler divergence between test sequences and model samples, and show that our proposed methods match the statistics of the music genre significantly better than the VMM.	[Spiliopoulou, Athina; Storkey, Amos] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland	Spiliopoulou, A (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.	a.spiliopoulou@ed.ac.uk; a.storkey@ed.ac.uk					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Dubnov S, 2003, COMPUTER, V36, P73, DOI 10.1109/MC.2003.1236474; Eck D, 2002, LECT NOTES COMPUT SC, V2415, P284; Eck D., 2008, TECHNICAL REPORT; Eerola T., 2004, MIDI TOOLBOX MATLAB; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jackendoff R., 1983, GENERATIVE THEORY TO; Lavrenko V., 2003, P 11 ACM INT C MULT, P120; Lee H., 2008, ADV NIPS, V20; Lee H., 2009, ACM ICPS, V382, P77; Norouzi M., 2009, IEEE C COMP VIS PATT, P2735; Paiement J.-F., 2008, THESIS ECOLE POLYTEC; Ron D., 1994, ADV NEURAL INFORMATI, V6, P176; Sutskever I., 2007, J ML RES P TRACK, V2, P548; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Taylor G.W., 2009, ACM ICPS, V382, P129; Weiland M., 2005, TECHNICAL REPORT; Welling M., 2004, ADV NIPS, V17; Wood F., 2009, ACM ICPS, V382, P142	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-23808-6	LECT NOTES ARTIF INT			2011	6913						289	304				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEH14	WOS:000316556000019		
S	Wu, Y; Doyle, TK; Fyfe, C		Yin, H; Wang, W; RaywardSmith, V		Wu, Ying; Doyle, Thomas K.; Fyfe, Colin			Multi-layer Topology Preserving Mapping for K-Means Clustering	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2011	Lecture Notes in Computer Science		English	Proceedings Paper	12th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2011)	SEP 07-09, 2011	Norwich, UNITED KINGDOM	IEEE Syst, Man & Cybernet Soc, Norwich Res Park, Univ E Anglia, SYS CONSULTING, CMP	Univ E Anglia		LEATHERBACK TURTLES	In this paper, we investigate the multi-layer topology preserving mapping for K-means. We present a Multi-layer Topology Preserving Mapping (MTPM) based on the idea of deep architectures. We demonstrate that the MTPM output can be used to discover the number of clusters for K-means and initialize the prototypes of K-means more reasonably. Also, K-means clusters the data based on the discovered underlying structure of the data by the MTPM. The standard wine data set is used to test our algorithm. We finally analyse a real biological data set with no prior clustering information available.	[Wu, Ying; Doyle, Thomas K.] Natl Univ Ireland Univ Coll Cork, ERI, Coastal & Marine Res Ctr, Glucksman Marine Facil,Naval Base, Haulbowline, Ireland	Wu, Y (reprint author), Natl Univ Ireland Univ Coll Cork, ERI, Coastal & Marine Res Ctr, Glucksman Marine Facil,Naval Base, Haulbowline, Ireland.	y.wu@ucc.ie; t.doyle@ucc.ie; colin.fyfe@uws.ac.uk					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2007, SCALING LEARNING ALG; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bottou L., 1995, ADV NEURAL INFORMATI, P585; De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z; Doyle Thomas K., 2008, Endangered Species Research, V4, P23, DOI 10.3354/esr00076; Fedak M, 2002, INTEGR COMP BIOL, V42, P3, DOI 10.1093/icb/42.1.3; Fyfe C, 2007, DATA MIN KNOWL DISC, V14, P207, DOI 10.1007/s10618-006-0047-5; Hays GC, 2004, ANIM BEHAV, V67, P733, DOI 10.1016/j.anbehav.2003.08.011; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E, 2000, 2000004 U COLL GATSB; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kohonen T., 1995, SELF ORG MAPS; MacQueen J, 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Rubinstein RY, 1997, EUR J OPER RES, V99, P89, DOI 10.1016/S0377-2217(96)00385-2; Wu Y., 2008, INT C ART INT KNOWL; Wu Y., 2007, WSEAS T MATH, V6, P865	17	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-23877-2	LECT NOTES COMPUT SC			2011	6936						84	91				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BBD23	WOS:000306498500011		
J	Steedman, M				Steedman, Mark			Embodied compositionality Comment on "Embodied language, best-fit analysis, and formal compositionality" by J Feldman	PHYSICS OF LIFE REVIEWS			English	Editorial Material																ARTHUR P, 1967, PAST PRESENT FUTURE; Bergen B, 2010, BRAIN LANG, V112, P150, DOI 10.1016/j.bandl.2009.07.002; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; DAVID D, 1991, WORD MEANING MONTAGU; DAVID H, 2000, DYNAMIC LOGIC; EVE S, 1999, COGN LINGUIST, P129; GILES F, 2002, WAY WE THINK CONCEPT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; JERRY F, 2010, PHYS LIFE LETT, V7, P385; JOHN M, 1969, MACH INTELL, V4, P473; MICHAEL T, 1999, CULTURAL ORIGINS HUM; Pulvermuller F, 2005, NAT REV NEUROSCI, V6, P576, DOI 10.1038/nrn1706; RAYMOND R, 2001, KNOWLEDGE ACTION LOG; Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060; TIMOTHY F, 2005, J SEMANT, V22, P211; Vardi MY, 2008, LECT NOTES COMPUT SC, V5000, P150	17	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1571-0645			PHYS LIFE REV	Phys. Life Rev.	DEC	2010	7	4					418	420		10.1016/j.plrev.2010.11.005		3	Biology; Biophysics	Life Sciences & Biomedicine - Other Topics; Biophysics	701IP	WOS:000285811900005	21115165	
J	Larochelle, H; Bengio, Y; Turian, J				Larochelle, Hugo; Bengio, Yoshua; Turian, Joseph			Tractable Multivariate Binary Density Estimation and the Restricted Boltzmann Forest	NEURAL COMPUTATION			English	Article								We investigate the problem of estimating the density function of multivariate binary data. In particular, we focus on models for which computing the estimated probability of any data point is tractable. In such a setting, previous work has mostly concentrated on mixture modeling approaches. We argue that for the problem of tractable density estimation, the restricted Boltzmann machine (RBM) provides a competitive framework for multivariate binary density modeling. With this in mind, we also generalize the RBM framework and present the restricted Boltzmann forest (RBForest), which replaces the binary variables in the hidden layer of RBMs with groups of tree-structured binary variables. This extension allows us to obtain models that have more modeling capacity but remain tractable. In experiments on several data sets, we demonstrate the competitiveness of this approach and study some of its properties.	[Larochelle, Hugo] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Bengio, Yoshua; Turian, Joseph] Univ Montreal, Dept IRO, Montreal, PQ H3T 1J4, Canada	Larochelle, H (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.	larocheh@cs.toronto.edu; yoshua.bengio@umontreal.ca; turian@iro.umontreal.ca					AITCHISON J, 1976, BIOMETRIKA, V63, P413, DOI 10.1093/biomet/63.3.413; Everitt B. S., 1981, FINITE MIXTURE DISTR; Hinton G. E., 2000, 2000004 GCNU TR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; JUAN A, 2001, PRIS 01, P118; JUAN A, 2004, ICPR 04, V3, P367; Kassel Robert H., 1995, THESIS MIT; LOWD D, 2005, MACH LEARN, V529, P536; Nair V, 2009, ADV NEURAL INFORM PR, V21, P1145; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Ng AY, 2002, ADV NEUR IN, V14, P841; Carreira-Perpinan MA, 2000, NEURAL COMPUT, V12, P141, DOI 10.1162/089976600300015925; SALAKHUTDINOV R, 2008, MACH LEARN, P872; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290	16	1	1	M I T PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	0899-7667			NEURAL COMPUT	Neural Comput.	SEP	2010	22	9					2285	2307		10.1162/NECO_a_00014		23	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	634EX	WOS:000280563600002	20569177	
S	Liu, T		Wong, KW; Mendis, BSU; Bouzerdoum, A		Liu, Tao			A Novel Text Classification Approach Based on Deep Belief Network	NEURAL INFORMATION PROCESSING: THEORY AND ALGORITHMS, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	17th International Conference on Neural Information Processing	NOV 22-25, 2010	Sydney, AUSTRALIA	Asia Pacific Neural Network Assembly		text classification; deep belief network; support vector machine		A novel text classification approach is proposed in this paper based on deep belief network. Deep belief network constructs a deep architecture to obtain the high level abstraction of input data, which can be used to model the semantic correlation among words of documents. After basic features are selected by statistical feature selection measures, a deep belief network with discriminative fine tuning strategy is built on basic features to learn high level deep features. A support vector machine is then trained on the learned deep features. The proposed method outperforms traditional classifier based on support vector machine. As a dimension reduction strategy, the deep belief network also outperforms the traditional latent semantic indexing method. Detailed experiments are also made to show the effect of different fine tuning strategies and network structures on the performance of deep belief network.	Renmin Univ China, MOE, Key Lab Data Engn & Knowledge Engn, Beijing 100872, Peoples R China	Liu, T (reprint author), Renmin Univ China, MOE, Key Lab Data Engn & Knowledge Engn, Beijing 100872, Peoples R China.	tliuruc@google.com					Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2009, FDN TRENDS MACHINE L, V2, P121; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Joachimss T., 1998, 10 EUR C MACH LEARN, P137; Kwok JTY, 1998, ICONIP'98: THE FIFTH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING JOINTLY WITH JNNS'98: THE 1998 ANNUAL CONFERENCE OF THE JAPANESE NEURAL NETWORK SOCIETY - PROCEEDINGS, VOLS 1-3, P347; LIU T, 2005, 8 JOINT C INF SCI, P1481; MANNA S, 2009, 4 INT S COMP INT INT, P135; Mnih A., 2008, ADV NEURAL INFORM PR, P1081; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Yang Y., 1997, 14 INT C MACH LEARN, P412; YANG Y, 1999, 9 TEXT RETRIEVAL C T, P127; Yang Y., 1999, 22 ANN INT ACM SIGIR, P42	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17536-7	LECT NOTES COMPUT SC			2010	6443						314	321				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BUV43	WOS:000290457000039		
S	Liu, Y; Shao, JA		Qiu, GP; Lam, KM; Kiya, H; Xue, XY; Kuo, CCJ; Lew, MS		Liu, Yang; Shao, Jian			High Dimensionality Reduction Using CUR Matrix Decomposition and Auto-encoder for Web Image Classification	ADVANCES IN MULTIMEDIA INFORMATION PROCESSING-PCM 2010, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	11th Pacific Rim Conference on Multimedia	SEP 21-24, 2010	Shanghai, PEOPLES R CHINA		Fudan Univ	Dimensionality Reduction; Deep Auto-encoder; CUR Matrix Decomposition; Image Classification		Reducing the dimensionality of image with high-dimensional feature plays a significant role in image retrieval and classification. Recently, two methods have been proposed to improve the efficiency and accuracy of dimensionality reduction, one uses CUR matrix decompositions to construct low rank matrix approximations and another approach for dimension reduction trains an auto-encoder with deep architecture to learn low-dimensional codes. In this paper, after above two mentioned methods are respectively utilized to reduce the high-dimensional features of images, we train individual classifiers on both original and reduced feature space for image classification. This paper compares these two approaches with other approaches in image classification. At the same, we also study the effects of the depth of layers on the performance of dimensionality reduction using auto-encoder.	[Liu, Yang; Shao, Jian] Zhejiang Univ, Collage Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China	Liu, Y (reprint author), Zhejiang Univ, Collage Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China.						Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BUCIU I, 2007, NONNEGATIVE MATRIX F; Chatfield C, 1980, INTRO MULTIVARIATE A; Chua T.-S., 2009, P ACM C IM VID RETR; Drineas P, 2008, SIAM J MATRIX ANAL A, V30, P844, DOI 10.1137/07070471X; He X., 2002, LOCALITY PRESERVING; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hyvrinen A., 1999, NEURAL COMPUTING SUR, V2, P94; Li H., 2009, INT C DAT MIN WORKSH, P164; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205106, 10.1073/pnas.0803205105]; MCCLELLAND JL, 1986, PARALLEL DISTRIBUTED, V1, P282; MIKA S, 1999, KERNEL PCA DENOISING; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9	17	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15695-3	LECT NOTES COMPUT SC			2010	6298		II				1	12				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTC26	WOS:000286441900001		
S	Wolf, C; Gaida, D; Stuhlsatz, A; McLoone, S; Bongards, M		Li, K; Ma, S; Irwin, GW		Wolf, Christian; Gaida, Daniel; Stuhlsatz, Andre; McLoone, Sean; Bongards, Michael			Organic Acid Prediction in Biogas Plants Using UV/vis Spectroscopic Online-Measurements	LIFE SYSTEM MODELING AND INTELLIGENT COMPUTING, PT I	Communications in Computer and Information Science		English	Proceedings Paper	International Conference on Life System Modeling and Simulation/International Conference on Intelligent Computing for Sustainable Energy and Environment	SEP 17-20, 2010	Wuxi, PEOPLES R CHINA	Shanghai Univ, Queens Univ, Jiangnan Univ, CASS, Syst Modeling & Simulat Techn Comm, China Instrument & Control Soc, Embedded Instrument & Syst Techn Comm		LDA; GerDA; SVM; classification; UV/vis spectroscopy; organic acids; online-measurement; anaerobic digestion		The concentration of organic acids in anaerobic digesters is one of the most critical parameters for monitoring and advanced control of anaerobic digestion processes, making a reliable online-measurement system absolutely necessary. This paper introduces a novel approach to obtaining these measurements indirectly and online using UV/vis spectroscopic probes, in conjunction with powerful pattern recognition methods. An UV/vis spectroscopic probe from S::CAN is used in combination with a custom-built dilution system to monitor the absorption of fully fermented sludge at a spectrum from 200nm to 750nm. Advanced pattern recognition methods, like LDA, Generalized Discriminant Analysis (GerDA) and SVM, are then used to map the measured absorption spectra to laboratory measurements of organic acid concentrations. The validation of the approach at a full-scale 1.3MW industrial biogas plant shows that more than 87% of the measured organic acid concentrations can be detected correctly.	[Wolf, Christian; McLoone, Sean] Natl Univ Ireland Maynooth, Dept Elect Engn, Maynooth, Kildare, Ireland	Wolf, C (reprint author), Natl Univ Ireland Maynooth, Dept Elect Engn, Maynooth, Kildare, Ireland.	christian.wolf@fh-koeln.de; daniel.gaida@fh-koeln.de; andre.stuhlsatz@fh-duesseldorf.de; sean.mcloone@eeng.nium.ie; michael.bongards@fh-koeln.de					Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cristianini N., 2000, INTRO SUPPORT VECTOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Mathworks, MATL; PUNAL A, 2002, IWA 7 LAT AM WORKSH, P119; Schmidt H, 2008, THESIS COLOGNE U APP; Stuhlsatz A., 2010, P INT C PATT REC ICP, P23; STUHLSATZ A, 2010, P 2010 INT JOINT C N, P18	8	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-642-15852-0	COMM COM INF SC			2010	97						200	206				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Mathematical & Computational Biology	Computer Science; Mathematical & Computational Biology	BUC72	WOS:000288890900025		
S	Kim, SK; McAfee, LC; McMahon, PL; Olukotun, K		Danek, M; Kadlec, J		Kim, Sang Kyun; McAfee, Lawrence C.; McMahon, Peter L.; Olukotun, Kunle			A HIGHLY SCALABLE RESTRICTED BOLTZMANN MACHINE FPGA IMPLEMENTATION	FPL: 2009 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND APPLICATIONS	International Conference on Field Programmable and Logic Applications		English	Proceedings Paper	19th International Conference on Field Programmable Logic and Applications	AUG 31-SEP 02, 2009	Prague, CZECH REPUBLIC	UTIA, AV, CR	ASCR, Informat Theory & Automat			Restricted Boltzmann Machines (RBMs) - the building block for newly popular Deep Belief Networks (DBNs) - are a promising new tool for machine learning practitioners. However, future research in applications of DBNs is hampered by the considerable computation that training requires. In this paper, we describe a novel architecture and FPGA implementation that accelerates the training of general RBMs in a scalable manner, with the goal of producing a system that machine learning researchers can use to investigate ever-larger networks. Our design uses a highly efficient, fully-pipelined architecture based on 16-bit arithmetic for performing RBM training on an FPGA. We show that only 16-bit arithmetic precision is necessary, and we consequently use embedded hardware multiply-and-add (MADD) units. We present performance results to show that a speedup of 25-30X can be achieved over an optimized software implementation on a high-end CPU.	[Kim, Sang Kyun; McAfee, Lawrence C.; McMahon, Peter L.; Olukotun, Kunle] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA	Kim, SK (reprint author), Stanford Univ, Dept Elect Engn, 353 Serra Mall Stanford, Stanford, CA 94305 USA.	skkim38@stanford.edu; lcmcafee@stanford.edu; pmcmahon@stanford.edu; kunle@stanford.edu					Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587; COX CE, 1992, IEEE J SOLID STATE C, V28, P288; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holt J., 1991, P INT JOINT C NEUR N, V2, P121; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; LY D, 2009, P ACM SIGDA INT S FI, P73, DOI 10.1145/1508128.1508140; LYSAGHT P, 1994, FIELD PROGRAMMABLE L, V849, P421; SUTTON P., 2003, P 13 INT C FIELD PRO, P1062; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Tkacik TE, 2002, LECT NOTES COMPUT SC, V2523, P450; ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1946-1488		978-1-4244-3891-4	I C FIELD PROG LOGIC			2009							367	372				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BOT08	WOS:000277506300056		
J	Gutstein, S; Fuentes, O; Freudenthal, E				Gutstein, Steven; Fuentes, Olac; Freudenthal, Eric			Knowledge transfer in deep convolutional neural nets	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	20th International-Florida-AI-Research-Society Conference	MAY, 2007	Key West, FL	Int Florida Artificial Intelligence Res Soc		knowledge transfer; deep neural nets; inductive transfer; neural nets		Knowledge transfer is widely held to be a primary mechanism that enables humans to quickly learn new complex concepts when given only small training sets. In this paper, we apply knowledge transfer to deep convolutional neural nets, which we argue are particularly well suited for knowledge transfer. Our initial results demonstrate that components of a trained deep convolutional neural net can constructively transfer information to another such net. Furthermore, this transfer is completed in such a way that one can envision creating a net that could learn new concepts throughout its lifetime. The experiments we performed involved training a Deep Convolutional Neural Net (DCNN) on a large training set containing 20 different classes of handwritten characters from the NIST Special Database 19. This net was then used as a foundation for training a new net on a set of 20 different character classes from the NIST Special Database 19. The new net would keep the bottom layers of the old net (i.e. those nearest to the input) and only allow the top layers to train on the new character classes. We purposely used small training sets for the new net to force it to rely as much as possible upon transferred knowledge as opposed to a large and varied training set to learn the new set of hand written characters. Our results show a clear advantage in relying upon transferred knowledge to learn new tasks when given small training sets, if the new tasks are sufficiently similar to the previously mastered one. However, this advantage decreases as training sets increase in size.	[Gutstein, Steven; Fuentes, Olac; Freudenthal, Eric] Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA	Gutstein, S (reprint author), Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA.	sgutstein@utep.edu; ofuentes@utep.edu; efreudenthal@utep.edu					ABUMOSTAFA Y, 1994, J COMPLEXITY, V10; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Baxter J, 1998, ADV NEUR IN, V10, P245; Behnke Sven, 2003, LECT NOTES COMPUTER, V2766; Bengio Y., 2007, LARGE SCALE KERNEL M; BROMLEY J, 1993, ADV NEURAL INFORM PR, V6; Caruana R., 1995, ADV NEURAL INFORMATI, V7, P657; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chopra S., 2005, P COMP VIS PATT REC; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Fahlman S. E., 1990, ADV NEURAL INFORMATI, P524; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; LeCun Y., 1999, Shape, contour and grouping in computer vision; LeCun Y., 1990, ADV NEURAL INFORM PR, V2; Mitchell T. M., 1997, MACHINE LEARNING; Pratt L. Y., 1993, ADV NEURAL INFORMATI, P204; SCHULTZ TR, 2000, P IEEE INNS ENNS INT, V5, pV641; Silver D. L., 1996, Connection Science, V8, DOI 10.1080/095400996116929; THRUN S, 1996, INT C MACH LEARN, P489; Thrun S, 1996, ADV NEUR IN, V8, P640; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319	22	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130			INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	JUN	2008	17	3					555	567		10.1142/S0218213008004059		13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	327XQ	WOS:000257762200010		
J	Lee, AB; Nadler, B; Wasserman, L				Lee, Ann B.; Nadler, Boaz; Wasserman, Larry			REJOINDER OF: TREELETS - AN ADAPTIVE MULTI-SCALE BASIS FOR SPARE UNORDERED DATA	ANNALS OF APPLIED STATISTICS			English	Editorial Material									[Lee, Ann B.; Wasserman, Larry] Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15206 USA; [Nadler, Boaz] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Lee, AB (reprint author), Carnegie Mellon Univ, Dept Stat, Pittsburgh, PA 15206 USA.	annlee@stat.cmu.edu; boaz.nadler@weizmann.ac.il; larry@stat.cmu.edu	Nadler, Boaz/C-7217-2008				ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; FAN J, 2008, J ROY STA B IN PRESS; HARTIGAN JA, 1981, J AM STAT ASSOC, V76, P388, DOI 10.2307/2287840; Hastie T., 2001, GENOME BIOL, V2; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Murtagh F, 2007, J CLASSIF, V24, P3, DOI 10.1007/s00357-007-0007-9; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	8	1	1	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	1932-6157			ANN APPL STAT	Ann. Appl. Stat.	JUN	2008	2	2					494	500		10.1214/08-AOAS137REJ		7	Statistics & Probability	Mathematics	374QC	WOS:000261057800008		
B	Hadsell, R; Erkan, A; Sermanet, P; Scoffier, M; Muller, U; LeCun, Y		Chatila, R; Kelly, A; Merlet, JP		Hadsell, Raia; Erkan, Ayse; Sermanet, Pierre; Scoffier, Marco; Muller, Urs; LeCun, Yann			Deep Belief Net Learning in a Long-Range Vision System for Autonomous Off-Road Driving	2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS			English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems	SEP 22-26, 2008	Nice, FRANCE	IEEE, Robot Soc Japan, IEEE Robot & Automat Soc, IEEE Ind Elect Soc, Soc Instrument & Control Engineers, Inst Natl Rech Informat & Automat, CNRS, Inst Control, Roibot & Syst				We present a learning-based approach for long-range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing high-level strategic planning. A deep belief network is trained with unsupervised data and a reconstruction criterion to extract features from an input image, and the features are used to train a realtime classifier to predict traversability. The online supervision is given by a stereo module that provides robust labels for nearby areas up to 12 meters distant. The approach was developed and tested on the LAGR mobile robot.	[Hadsell, Raia; Erkan, Ayse; Sermanet, Pierre; LeCun, Yann] NYU, Courant Inst Math Sci, New York, NY 10003 USA	Hadsell, R (reprint author), NYU, Courant Inst Math Sci, New York, NY 10003 USA.						DAHLKAMP H, 2006, P ROB SCI SYST RSS J; Goldberg S., 2002, IEEE AER C; GRUDIC G, 2006, P ROB SCI SYST RSS A; HADSELL R, 2007, P ROB SCI SYST RSS; Happold M, 2006, P ROB SCI SYST RSS; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong T., 2002, P SPIE AER C; Kelly A, 1998, INT C ROB AUT WORKSH; KIM D, 2006, P INT C ROB AUT ICRA; KRIEGMAN DJ, 1989, IEEE T ROBOTIC AUTOM, V5, P792, DOI 10.1109/70.88100; LEIB D, 2005, P ROB SCI SYST RSS J; RANZATO M, 2007, P C COMP VIS PATT RE; SERMANET P, 2008, P INT C INT ROB SYST; SOFMAN B, 2006, P ROB SCI SYST RSS J; STAVENS D, 2006, P C UNC AI UAI; WELLINGTON C, 2004, P INT C ROB AUT ICRA	16	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2057-5				2008							628	633		10.1109/IROS.2008.4651217		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BIJ26	WOS:000259998200099		
J	Winther, O; Petersen, KB				Winther, Ole; Petersen, Kaare Brandt			Bayesian independent component analysis: Variational methods and non-negative decompositions	DIGITAL SIGNAL PROCESSING			English	Article							MATRIX FACTORIZATION; GRAPHICAL MODELS; ALGORITHMS	In this paper we present an empirical Bayesian framework for independent component analysis. The framework provides estimates of the sources, the mixing matrix and the noise parameters, and is flexible with respect to choice of source prior and the number of sources and sensors. Inside the engine of the method are two mean field techniques-the variational Bayes and the expectation consistent framework-and the cost function relating to these methods are optimized using the adaptive overrelaxed expectation maximization (EM) algorithm and the easy gradient recipe. The entire framework, implemented in a Matlab toolbox, is demonstrated for non-negative decompositions and compared with non-negative matrix factorization. (C) 2007 Elsevier Inc. All rights reserved.	Tech Univ Denmark, DK-2800 Lyngby, Denmark	Winther, O (reprint author), Tech Univ Denmark, Bldg 321, DK-2800 Lyngby, Denmark.	owi@imm.dtu.dk					Attias H, 2000, ADV NEUR IN, V12, P209; BERMOND O, 1999, P ICA C; EBLOUCHRANI A, 1994, P EUSIPCO, V2, P768; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hojen-Sorensen PADFR, 2002, NEURAL COMPUT, V14, P889, DOI 10.1162/089976602317319009; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; Minka T., 2005, DIVERGENCE MEASURES; Minka T., 2001, THESIS MIT MEDIA LAB; MISKIN J, 2001, INDEPENDENT COMPONEN; MOULINES E, 1997, MAXIMUM LIKELIHOOD B; OLSSON RK, 2007, NEURAL COMPUT, V19; Opper M, 2005, J MACH LEARN RES, V6, P2177; Opper M, 2001, PHYS REV E, V64, part. no., DOI 10.1103/PhysRevE.64.056131; Opper M, 2000, NEURAL COMPUT, V12, P2655, DOI 10.1162/089976600300014881; Petersen KB, 2005, NEURAL COMPUT, V17, P1921, DOI 10.1162/0899766054322991; Pontoppidan NH, 2005, MECH SYST SIGNAL PR, V19, P1337, DOI 10.1016/j.ymssp.2005.07.005; SALAKHUTDINOV S, 2003, P INT C MACH LEARN I; WINTDHER O, 2007, UNPUB NEUROCOMPUTING	20	1	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1051-2004			DIGIT SIGNAL PROCESS	Digit. Signal Prog.	SEP	2007	17	5					858	872		10.1016/j.dsp.2007.01.003		15	Engineering, Electrical & Electronic	Engineering	207ER	WOS:000249234900002		
S	Crowley, M; Boerlage, B; Poole, D		Kobti, Z; Wu, D		Crowley, Mark; Boerlage, Brent; Poole, David			Adding local constraints to Bayesian networks	Advances in Artificial Intelligence	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	20th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2007	Montreal, CANADA	Canadian Soc Computat Studies Intelligence		Bayesian networks; constraints; mixed networks; chain graphs; graphical models; Bayesian modelling; complementary priors	MODELS	When using Bayesian networks, practitioners often express constraints among variables by conditioning a common child node to induce the desired distribution. For example, an 'or' constraint can be easily expressed by a node modelling a logical 'or' of its parents' values being conditioned to true. This has the desired effect that at least one parent must be true. However, conditioning also alters the distributions of further ancestors in the network. In this paper we argue that these side effects are undesirable when constraints are added during model design. We describe a method called shielding to remove these side effects while remaining within the directed language of Bayesian networks. This method is then compared to chain graphs which allow undirected and directed edges and which model equivalent distributions. Thus, in addition to solving this common modelling problem, shielded Bayesian networks provide a novel method for implementing chain graphs with existing Bayesian network tools.	Univ British Columbia, Vancouver, BC V5Z 1M9, Canada	Crowley, M (reprint author), Univ British Columbia, Vancouver, BC V5Z 1M9, Canada.						CROWLEY M, 2005, THESIS U BRIT COLUMB; Dechter R., 2004, P 20 C UNC ART INT U, P120; Dechter R, 1996, P 12 C UNC ART INT U, P211; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; JENSEN FV, 1988, JUNCTION TREES DECOM; LAURITZEN SL, 1989, ANN STAT, V17, P31, DOI 10.1214/aos/1176347003; Lauritzen S.L., 1996, GRAPHICAL MODELS; Lauritzen SL, 2002, J R STAT SOC B, V64, P321, DOI 10.1111/1467-9868.00340; Pearl J, 1988, PROBABILISTIC REASON; PEARL J, 1993, STAT SCI, V8, P266, DOI 10.1214/ss/1177010894; Zhang NL, 1996, J ARTIF INTELL RES, V5, P301	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-72664-7	LECT NOTES COMPUT SC			2007	4509						344	355				12	Computer Science, Artificial Intelligence	Computer Science	BGG73	WOS:000246691800030		
B	Ranzato, M; Lecun, Y		Werner, B		Ranzato, Marc'Aurelio; Lecun, Yann			A sparse and locally shift invariant feature extractor applied to document images	ICDAR 2007: NINTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS			English	Proceedings Paper	9th International Conference on Document Analysis and Recognition	SEP   23, 2007-SEP 26, 2009	Curitiba, BRAZIL	Int Assoc Pattern Recognit TC 10, Int Assoc Pattern Recognit TC 11			RECOGNITION; ALGORITHM	We describe an unsupervised learning algorithm for extracting sparse and locally shift-invariant features. We also devise a principled procedure for learning hierarchies of invariant features. Each feature detector is composed of a set of trainable convolutionalfiltersfollowed by a max-pooling layer over non-overlapping windows, and a point-wise sigmoid non-linearity. A second stage of more invariant features is fed with patches provided by the first stage feature extractor, and is trained in the same way. The method is used to pre-train the first four layers of a deep convolutional network, which achieves state-of-the-art performance on the MNIST dataset of handwritten digits. The final testing error rate is equal to 0.42%. Preliminary experiments on compression of bitonal document images show very promising results in terms of compression ratio and reconstruction error.	[Ranzato, Marc'Aurelio; Lecun, Yann] NYU, Courant Inst Math Sci, New York, NY 10003 USA	Ranzato, M (reprint author), NYU, Courant Inst Math Sci, 251 Mercer St, New York, NY 10003 USA.						Bengio Y., 2007, NIPS; Bottou L, 1998, J ELECTRON IMAGING, V7, P410, DOI 10.1117/1.482609; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUANG FJ, 2006, CVPR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mutch J., 2006, CVPR; Ranzato M., 2006, NIPS; Serre T., 2005, CVPR; Simard P. Y., 2003, ICDAR	11	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-2822-9				2007							1213	1217				5	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BHC21	WOS:000252162600243		
J	Gu, Y; Chen, YQ; Liu, JF; Jiang, XL				Gu, Yang; Chen, Yiqiang; Liu, Junfa; Jiang, Xinlong			Semi-supervised deep extreme learning machine for Wi-Fi based localization	NEUROCOMPUTING			English	Article						Wi-Fi indoor localization; Semi-supervised learning; Deep learning; Extreme Learning Machine (ELM)	LOCATION ESTIMATION; NEURAL-NETWORKS	Along with the proliferation of mobile devices and wireless signal coverage, indoor localization based on Wi-Fi gets great popularity. Fingerprint based method is the mainstream approach for Wi-Fi indoor localization, for it can achieve high localization performance as long as labeled data are sufficient. However, the number of labeled data is always limited due to the high cost of data acquisition. Nowadays, crowd sourcing becomes an effective approach to gather large number of data; meanwhile, most of them are unlabeled. Therefore, it is worth studying the use of unlabeled data to improve localization performance. To achieve this goal, a novel algorithm Semi-supervised Deep Extreme Learning Machine (SDELM) is proposed, which takes the advantages of semi-supervised learning, Deep Leaning (DL), and Extreme Learning Machine (ELM), so that the localization performance can be improved both in the feature extraction procedure and in the classifier. The experimental results in real indoor environments show that the proposed SDELM not only outperforms other compared methods but also reduces the calibration effort with the help of unlabeled data. (C) 2015 Elsevier B.V. All rights reserved.	[Gu, Yang; Chen, Yiqiang; Liu, Junfa; Jiang, Xinlong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; [Gu, Yang; Chen, Yiqiang; Liu, Junfa; Jiang, Xinlong] Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China; [Gu, Yang; Jiang, Xinlong] Univ Chinese Acad Sci, Beijing, Peoples R China	Chen, YQ (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.				Natural Science Foundation of China [61173066, 61070110]; Beijing Natural Science Foundation [4144085]	This work is supported by Natural Science Foundation of China (No.61173066, No.61070110), and Beijing Natural Science Foundation (No.4144085).	Bahl P., 2000, P IEEE INFOCOM 2000, V2, P775, DOI DOI 10.1109/INFCOM.2000.832252; Bahl P., 2000, MSRTR200012; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Chapelle O., 2006, SEMISUPERVISED LEARN, P1; Chatzimilioudis G, 2012, IEEE INTERNET COMPUT, V16, P36, DOI 10.1109/MIC.2012.70; Chen Y., 2005, MODELING ANAL SIMULA, P118; Chen YQ, 2006, IEEE T KNOWL DATA EN, V18, P877; Fang SH, 2012, IEEE T MOBILE COMPUT, V11, P100, DOI 10.1109/TMC.2011.30; Fet N., 2013, UBICOMP ACM, P499; Haeberlen A., 2004, ACM MOBICOM, P70; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang GB, 2004, IEEE IJCNN, P985; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Huang G.B., 2005, INT J INFORM TECHNOL, V11, P16; Huang G-B, 2004, IEEE T CIRCUITS SYST, V2, P1029; Kaemarungsi K., 2006, 1 INT S WIR PERV COM; Kaemarungsi K, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P14; Kasun LLC, 2013, IEEE INTELL SYST, V28, P31; Kjaergaard MB, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, P110, DOI 10.1109/PERCOM.2008.75; Laoudias C., 2013, INT C IND POS IND NA, P25; Ledlie J., 2011, 2011 INT C IND POS I, P1; Lee H., 2007, P ADV NEUR INF PROC, V19, P801; Lin Quan, 2011, Acta Automatica Sinica, V37, DOI 10.3724/SP.J.1004.2011.00316; Liu JF, 2011, NEUROCOMPUTING, V74, P2566, DOI 10.1016/j.neucom.2010.12.043; Moraes L, 2006, MOBIWAC, P92; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Mundo L.B.D., 2011, 2011 INT C ICT CONV, P20; Pan JJ, 2012, IEEE T PATTERN ANAL, V34, P587, DOI 10.1109/TPAMI.2011.165; Pulkkinen T, 2011, LECT NOTES COMPUT SC, V6791, P355, DOI 10.1007/978-3-642-21735-7_44; Quoc V., 2012, P 29 INT MACH LEARN; Yang Q, 2008, IEEE INTELL SYST, V23, P8, DOI 10.1109/MIS.2008.4; Youssef MA, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P143, DOI 10.1109/PERCOM.2003.1192736; Yu K, 2011, PROC CVPR IEEE, P1713; Zeinalipour-Yazti D, 2013, IEEE T KNOWL DATA EN, V25, P1240, DOI 10.1109/TKDE.2012.55; Zhang Yong, 2010, Computer Engineering, V36; Zheng VW, 2008, P 23 NAT C ART INT C, V3, P1421; Zhu Jian, 2007, Journal of Northeastern University (Natural Science), V28	39	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	OCT 20	2015	166						282	293		10.1016/j.neucom.2015.04.011		12	Computer Science, Artificial Intelligence	Computer Science	CM5TI	WOS:000357751200028		
J	Kim, S; Choi, Y; Lee, M				Kim, Sangwook; Choi, Yonghwa; Lee, Minho			Deep learning with support vector data description	NEUROCOMPUTING			English	Article						Support vector data description; Deep learning; Pattern recognition; Generalization	BOLTZMANN MACHINES; CROSS-VALIDATION; NETWORKS; PARAMETER; ALGORITHM	One of the most critical problems for machine learning methods is overfitting. The overfitting problem is a phenomenon in which the accuracy of the model on unseen data is poor whereas the training accuracy is nearly perfect. This problem is particularly severe in complex models that have a large set of parameters. In this paper, we propose a deep learning neural network model that adopts the support vector data description (SVDD). The SVDD is a variant of the support vector machine, which has high generalization performance by acquiring a maximal margin in one-class classification problems. The proposed model strives to obtain the representational power of deep learning. Generalization performance is maintained using the SVDD. The experimental results showed that the proposed model can learn multiclass data without severe overfitting problems. (C) 2015 Elsevier B.V. All rights reserved.	[Kim, Sangwook; Choi, Yonghwa; Lee, Minho] Kyungpook Natl Univ, Sch Elect Engn, Taegu 702701, South Korea	Lee, M (reprint author), Kyungpook Natl Univ, Sch Elect Engn, 1370 Sankyuk Dong, Taegu 702701, South Korea.	mholee@gmail.com			ICT R&D program of MSIP/IITP [10041826]; Industrial Strategic Technology Development Program - Ministry of Knowledge Economy (MKE, Korea) [10044009]	This work was partly supported by the ICT R&D program of MSIP/IITP. [10041826, Development of emotional features sensing, diagnostics and distribution s/w platform for measurement of multiple intelligence from young children] and by the Industrial Strategic Technology Development Program [10044009] funded by the Ministry of Knowledge Economy (MKE, Korea) (50%).	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Amari S, 1997, IEEE T NEURAL NETWOR, V8, P985, DOI 10.1109/72.623200; Arel I., 2010, COMPUTATIONAL INTELL, V5, P13; Banerjee A., 2007, P IEEE ICIP, pIV; Bartlett P, 1999, ADVANCES IN KERNEL METHODS, P43; Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop CM, 2006, PATTERN RECOGNITION; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Erhan D, 2010, J MACH LEARN RES, V11, P625; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Ge ZQ, 2011, J PROCESS CONTR, V21, P949, DOI 10.1016/j.jprocont.2011.02.004; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Goodfellow I.J., 2013, ARXIV13024389; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Kim S., 2013, NEURAL INFORM PROCES, P458; LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361; LeCun Y., 1989, CONNECTIONS PERSPECT; Lee SW, 2006, PATTERN RECOGN, V39, P1809, DOI 10.1016/j.patcog.2006.04.033; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Lichman M., UCI MACHINE LEARNING; Lucas DD, 2013, GEOSCI MODEL DEV, V6, P1157, DOI 10.5194/gmd-6-1157-2013; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Moody J., 1995, ADV NEURAL INFORM PR, V4, P950; NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473; Scholkopf B., 1995, P 1 INT C KNOWL DISC; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Sigillito V., 1990, PIMA INDIANS DIABETE, V9; Smolensky P., 1986, INFORM PROCESSING DY; Tax D., 2014, DDTOOLS DATA DESCRIT; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tesauro G., 1992, REINFORCEMENT LEARNI, P33; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N., 1974, THEORY PATTERN RECOG; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wan L., 2013, JMLR WORKSHOP C P, V28, P1058; Weston J., 1998, CSDTR9804 U LOND	41	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	OCT 1	2015	165						111	117		10.1016/j.neucom.2014.09.086		7	Computer Science, Artificial Intelligence	Computer Science	CL2BD	WOS:000356747700014		
J	Liu, FY; Lin, GS; Shen, CH				Liu, Fayao; Lin, Guosheng; Shen, Chunhua			CRF learning with CNN features for image segmentation	PATTERN RECOGNITION			English	Article						Conditional random field (CRF); Convolutional neural network (CNN); Structured support vector machine (SSVM); Co-occurrence		Conditional Random Rields (CRF) have been widely applied in image segmentations. While most studies rely on hand-crafted features, we here propose to exploit a pre-trained large convolutional neural network (CNN) to generate deep features for CRF learning. The deep CNN is trained on the ImageNet dataset and transferred to image segmentations here for constructing potentials of superpixels. Then the CRF parameters are learnt using a structured support vector machine (SSVM). To fully exploit context information in inference, we construct spatially related co-occurrence pairwise potentials and incorporate them into the energy function. This prefers labelling of object pairs that frequently co-occur in a certain spatial layout and at the same time avoids implausible labellings during the inference. Extensive experiments on binary and multi-class segmentation benchmarks demonstrate the promise of the proposed method. We thus provide new baselines for the segmentation performance on the Weizmann horse, Graz-02, MSRC-21, Stanford Background and PASCAL VOC 2011 datasets. (C) 2015 Elsevier Ltd. All rights reserved.	[Liu, Fayao; Lin, Guosheng; Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Lin, Guosheng; Shen, Chunhua] ARC Ctr Excellence Robot Vis, Adelaide, SA, Australia	Shen, CH (reprint author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	chhshen@gmail.com					Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Aldavert D., 2010, P IEEE C COMP VIS PA; Bengio Y., 2007, P ADV NEUR INF PROC; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bertelli L., 2011, P IEEE C COMP VIS PA; Carreira J., 2014, IEEE T PATTERN ANAL, V1, P1; Coates A., 2011, P INT C MACH LEARN; Donahue J., 2014, P INT C MACH LEARN; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Fulkerson B., 2009, P IEEE INT C COMP VI; Fulkerson B., 2008, P EUR C COMP VIS; Girshick R., 2014, P IEEE C COMP VIS PA; Gonfaus J.M., 2010, P IEEE C COMP VIS PA; Gould S., 2009, P IEEE INT C COMP VI; Grangier D., 2009, ICML DEEP LEARN WORK; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jia Y., 2013, CAFFE OPEN SOURCE CO; Joulin A., 2010, P IEEE C COMP VIS PA; Krizhevsky A., 2012, P ADV NEUR INF PROC; Kuettel D., 2012, P IEEE C COMP VIS PA; Ladicky L, 2009, P IEEE INT C COMP VI; Ladicky L, 2013, INT J COMPUT VISION, V103, P213, DOI 10.1007/s11263-012-0583-y; Lafferty J., 2001, P INT C MACH LEARN; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lempitsky V.S., 2011, P ADV NEUR INF PROC; Levin A., 2006, P EUR C COMP VIS; Lucchi A., 2013, P IEEE C COMP VIS PA; Lucchi A., 2012, P EUR C COMP VIS; Marszalek M., 2007, P IEEE C COMP VIS PA; Munoz D., 2010, P EUR C COMP VIS; Nowozin S., 2010, P EUR C COMP VIS; Rabinovich A., 2007, P IEEE INT C COMP VI; Roy A., 2014, P IEEE C COMP VIS PA; Schulz H., 2012, P EUR S ART NEUR NET; Shotton J., 2008, P IEEE C COMP VIS PA; Szummer M., 2008, P EUR C COMP VIS; Yao J., 2012, P IEEE C COMP VIS PA; Zhang Z., CONSTRAINT REDUCTION	39	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	OCT	2015	48	10					2983	2992		10.1016/j.patcog.2015.04.019		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CL8TD	WOS:000357246100003		
J	Mansanet, J; Albiol, A; Paredes, R; Albiol, A				Mansanet, Jordi; Albiol, Alberto; Paredes, Roberto; Albiol, Antonio			Mask selective regularization for restricted Boltzmann machines	NEUROCOMPUTING			English	Article						Restricted Boltzmann machine; Deep belief networks; Regularization	RECOGNITION	In the present work, we propose to deal with two important issues regarding to the RBM's learning capabilities. First, the topology of the input space, and second, the sparseness of the RBM obtained. One problem of RBMs is that they do not take advantage of the topology of the input space. In order to alleviate this lack, we propose to use a surrogate of the mutual information of the input representation space to build a set of binary masks. This approach is general and not only applicable to images, thus it can be extended to other layers in the standard layer-by-layer unsupervised learning. On the other hand, we propose a selective application of two different regularization terms, L-1 and L-2, in order to ensure the sparseness of the representation and the generalization capabilities. Additionally, another interesting capability of our approach is the adaptation of the topology of the network during the learning phase by means of selecting the best set of binary masks that fit the current weights configuration. The performance of these new ideas is assessed with a set of experiments on different well-known corpus. (C) 2015 Elsevier B.V. All rights reserved.	[Mansanet, Jordi; Albiol, Alberto; Paredes, Roberto; Albiol, Antonio] Univ Politecn Valencia, E-46022 Valencia, Spain	Albiol, A (reprint author), Univ Politecn Valencia, E-46022 Valencia, Spain.	alalbiol@iteam.upv.es			FPI Grant [BES-2010-032945]; Ministerio de Ciencia e Innovacion (Spain), Plan Nacional de I+D+i [TEC2009-09146]	This work was financially supported by the Ministerio de Ciencia e Innovacion (Spain), Plan Nacional de I+D+i, Grant TEC2009-09146, and the FPI Grant BES-2010-032945.	Bengio Y., 2013, LECT NOTES COMPUTER, V7978, P1; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Coates A., 2011, AISTATS; Glorot X., 2011, DEEP SPARSE RECTIFIE; Glorot X., 2011, P 14 INT C ART INT S, V15, P315; Goodfellow I.J., 2013, ICML 3, P1319; Gregor K., 2011, ADV NEURAL INFORM PR, P1116; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, TECHNICAL REPORT; Hinton G.E., ABS12070580 CORR; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Krizhevsky A., 2009, TECHNICAL REPORT; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Larochelle H., 2008, ICML, P536; Le Cun Y., 1990, ADV NEURAL INFORM PR, P396; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; LI WT, 1990, J STAT PHYS, V60, P823, DOI 10.1007/BF01025996; Lin Song, 2012, BMC BIOINFORMATICS, V13; Maas A.L., 2012, P INTERSPEECH ISCA; Muller A., 2010, IEEE VTC SPRING MAY, P1; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Schulz H, 2011, NEUROCOMPUTING, V74, P1411, DOI 10.1016/j.neucom.2010.12.014; Tang Y., 2010, P 27 ANN INT C MACH, P1055; Tang YC, 2012, PROC CVPR IEEE, P2264; Thom M, 2013, J MACH LEARN RES, V14, P1091; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Wan L., 2013, JMLR P, V28; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	32	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	OCT 1	2015	165						375	383		10.1016/j.neucom.2015.03.026		9	Computer Science, Artificial Intelligence	Computer Science	CL2BD	WOS:000356747700040		
J	Song, HA; Kim, BK; Xuan, TL; Lee, SY				Song, Hyun Ah; Kim, Bo-Kyeong; Xuan, Thanh Luong; Lee, Soo-Young			Hierarchical feature extraction by multi-layer non-negative matrix factorization network for classification task	NEUROCOMPUTING			English	Article						Hierarchical feature extraction; Multi-layer network; Unsupervised learning; Non-negative matrix factorization	ALGORITHM	In this paper, we propose multi-layer non-negative matrix factorization (NMF) network for classification task, which provides intuitively understandable hierarchical feature learning process. The layer-by-layer learning strategy was adopted through stacked NMF layers, which enforced non-negativity of both features and their coefficients. With the non-negativity constraint, the learning process revealed latent feature hierarchies in the complex data in intuitively understandable manner. The multi-layer NMF networks was investigated for classification task by studying various network architectures and nonlinear functions. The proposed multilayer NMF network was applied to document classification task, and demonstrated that our proposed multi-layer NMF network resulted in much better classification performance compared to single-layered network, even with the small number of features. Also, through intuitive learning process, the underlying structure of feature hierarchies was revealed for the complex document data. (C) 2015 Elsevier B.V. All rights reserved.	[Song, Hyun Ah; Kim, Bo-Kyeong; Xuan, Thanh Luong; Lee, Soo-Young] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea; [Lee, Soo-Young] Korea Adv Inst Sci & Technol, Dept Bio & Brain Engn, Taejon 305701, South Korea	Lee, SY (reprint author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea.	sylee@kaist.ac.kr			Brain Research Program through the National Research Foundation of Korea - Ministry of Science, ICT Future Planning [2013-035100, 2014-028269]	This research was supported by the Brain Research Program through the National Research Foundation of Korea funded by the Ministry of Science, ICT &Future Planning (2013-035100 and 2014-028269).	Ahn J.-H., 2004, P 21 INT C MACH LEAR, P3; Ahn J.-H., 2004, P AS C COMP VIS, P1009; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Cichocki A, 2007, INT J NEURAL SYST, V17, P431, DOI 10.1142/S0129065707001275; Cichocki A, 2006, ELECTRON LETT, V42, P947, DOI 10.1049/el:20060983; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Lee DD, 1999, NATURE, V401, P788; Oh JH, 1998, ADV NEUR IN, V10, P605; Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60; Poultney C., 2006, ADV NEURAL INFORM PR, P1137; Rebhan S, 2007, LECT NOTES COMPUT SC, V4668, P894; Seung H. S., 2000, NIPS, V13, P556; Song H.A., 2013, NEURAL INFORM PROCES, P466	15	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	OCT 1	2015	165						63	74		10.1016/j.neucom.2014.08.095		12	Computer Science, Artificial Intelligence	Computer Science	CL2BD	WOS:000356747700009		
J	Zuo, Z; Wang, G; Shuai, B; Zhao, LF; Yang, QX				Zuo, Zhen; Wang, Gang; Shuai, Bing; Zhao, Lifan; Yang, Qingxiong			Exemplar based Deep Discriminative and Shareable Feature Learning for scene image classification	PATTERN RECOGNITION			English	Article						Deep feature learning; Information sharing; Discriminative training; Scene image classification	RECOGNITION; SCALE	In order to encode the class correlation and class specific information in image representation, we propose a new local feature learning approach named Deep Discriminative and Shareable Feature Learning (DDSFL). DDSFL aims to hierarchically learn feature transformation filter banks to transform raw pixel image patches to features. The learned filter banks are expected to (1) encode common visual patterns of a flexible number of categories; (2) encode discriminative information; and (3) hierarchically extract patterns at different visual levels. Particularly, in each single layer of DDSFL, shareable filters are jointly learned for classes which share the similar patterns. Discriminative power of the filters is achieved by enforcing the features from the same category to be close, while features from different categories to be far away from each other. Furthermore, we also propose two exemplar selection methods to iteratively select training data for more efficient and effective learning. Based on the experimental results, DDSFL can achieve very promising performance, and it also shows great complementary effect to the state-of-the-art Caffe features. (C) 2015 Elsevier Ltd. All rights reserved.	[Zuo, Zhen; Wang, Gang; Shuai, Bing; Zhao, Lifan] Nanyang Technol Univ, Singapore 639798, Singapore; [Wang, Gang] Adv Digital Sci Ctr, Singapore, Singapore; [Yang, Qingxiong] City Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China	Wang, G (reprint author), Nanyang Technol Univ, Sch EEE, Room S1-B1c-88,50 Nanyang Ave, Singapore 639798, Singapore.	ZZU01@e.ntu.edu.sg; wanggang@ntu.edu.sg; BSHUAI001@e.ntu.edu.sg; ZHAO0145@e.ntu.edu.sg; qiyang@cityu.edu.hk			Singapore Ministry of Education (MOE) Tier 1 [RG84/12]; Singapore Ministry of Education(MOE) Tier 2 [ARC28/14]; Singapore A*STAR Science and Engineering Research Council [PSF1321202099]	The research is supported by Singapore Ministry of Education (MOE) Tier 1 RG84/12, Singapore Ministry of Education(MOE) Tier 2 ARC28/14, and Singapore A*STAR Science and Engineering Research Council PSF1321202099.	Boiman O., 2008, CVPR; Boureau Y.L., 2010, CVPR; Coates A., 2011, AI STAT; Dalai N., 2005, CVPR; Deng J., 2010, ECCV; Doersch C., 2013, NIPS; Donahue J., 2014, ICML; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63; Girshick R., ARXIV13112524; Gong Y., 2014, ECCV; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jiang Z., 2011, CVPR; Juneja M., 2013, CVPR; Kong S., 2012, ECCV; Krizhevsky A., 2012, NIPS; Lazebnik S., 2006, CVPR; Le Q.V., 2011, CVPR; Le Q.V., 2012, ICML; Le Q.V., 2011, NIPS; Li L.-J., 2010, NIPS; Li L.-J., 2007, ICCV; Li Q., 2013, CVPR; Li X., 2014, ICML; Lin D., 2014, CVPR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, NIPS; Malisiewicz T., 2011, ICCV; Margolin R., 2014, ECCV; McCann S., 2012, CVPR; Muja M., 2009, VISSAPP; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Pandey M., 2011, ICCV; Quattoni A., 2009, CVPR; Sermanet P., ARXIV13126229; Singh S., 2012, ECCV; Sohn K., 2011, ICCV; Song H.O., 2012, ECCV; Song H.O., 2013, ICML; Sun J., 2013, ICCV; Wang A., 2014, ECCV; Wang G, 2012, IEEE T PATTERN ANAL, V34, P2177, DOI 10.1109/TPAMI.2012.29; Wang J., 2010, CVPR; Wang X., 2013, ICML; Wang ZL, 2013, IEEE T IMAGE PROCESS, V22, P537, DOI 10.1109/TIP.2012.2218826; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xiao J., 2010, CVPR; Yang M., 2011, ICCV; Yao B., 2012, ECCV; Zou W.Y., 2012, NIPS; Zuo Z., 2014, ECCV; Zuo Z, 2014, IEEE SIGNAL PROC LET, V21, P1159, DOI 10.1109/LSP.2014.2298888	54	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	OCT	2015	48	10					3004	3015		10.1016/j.patcog.2015.02.003		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CL8TD	WOS:000357246100005		
J	Ji, ZP; Weng, JY				Ji, Zhengping; Weng, Juyang			A developmental where-what network for concurrent and interactive visual attention and recognition	ROBOTICS AND AUTONOMOUS SYSTEMS			English	Article						Developmental learning; Where-what sensorimotor pathways; Attention; Recognition; Brain-inspired neural network	OBJECT RECOGNITION; RECEPTIVE-FIELDS; SCENE ANALYSIS; TOP-DOWN; MODEL; ALGORITHM; CORTEX; REPRESENTATION; MECHANISMS; SYSTEM	This paper presents a brain-inspired developmental architecture called Where-What Network (WWN). In this second version of WWN, WWN-2 is learned for concurrent and interactive visual attention and recognition, via complementary pathways guided by "type" motor and "location" motor. The motor-driven top-down signals, together with bottom-up excitatory activities from the visual input, shape three possible information flows through a Y-shaped network. Using l(0) constrained sparse coding scheme, the top-down and bottom-up co-firing leads to a non-iterative cell-centered synaptic update model, entailing the strict entropy reduction from early to later layers, as well as a dual optimization of update directions and step sizes that dynamically depend on the firing ages of the neurons. Three operational modes for cluttered scenes emerge from the learning process, depending on what is available in the motor area: context-free mode for detection and recognition from a cluttered scene for a learned object, location-context mode for doing object recognition, and type-context mode for doing object search, all by a single network. To demonstrate the attention capabilities along with their interaction of visual processing, the proposed network is in the presence of complex backgrounds, learns on the fly, and produces engineering graded performance regarding attended pixel errors and recognition accuracy. As the proposed architecture is developmental, meaning that the internal representations are learned from pairs of input and motor signal, and thereby not manipulated internally for a specific task, we argue that the same learning principles and computational architecture can be potentially applicable to other sensory modalities, such as audition and touch. (C) 2015 Elsevier B.V. All rights reserved.	[Ji, Zhengping] Samsung Semicond Inc, Adv Image Res Lab ARIL, Pasadena, CA 91103 USA; [Weng, Juyang] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Ji, ZP (reprint author), Samsung Semicond Inc, Adv Image Res Lab ARIL, Pasadena, CA 91103 USA.	jizhengp@gmail.com; weng@cse.msu.edu					Aguirre GK, 1997, J NEUROSCI, V17, P2512; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259; Backer G, 2001, IEEE T PATTERN ANAL, V23, P1415, DOI 10.1109/34.977565; LABERGE D, 1990, J NEUROSCI, V10, P613; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; Collection T.M., 1968, METHODOLOGIES PATTER, P111; Deco G, 2000, VISION RES, V40, P2845, DOI 10.1016/S0042-6989(00)00140-1; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Emami A, 2005, MACH LEARN, V60, P195, DOI 10.1007/s10994-005-0916-y; Engan K., 1999, IEEE INT C AC SPEECH; Erisir A, 1997, P NATL ACAD SCI USA, V94, P1517; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Ji Z., 2011, NEUROMORPHIC BRAIN B, P156; Ji Z., 2010, INT JOINT C NEUR NET, P1; Ji Z., 2008, P IEEE INT C DEV LEA; Ji ZP, 2011, IEEE T INTELL TRANSP, V12, P402, DOI 10.1109/TITS.2010.2094188; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kandel E.R., 1991, PRINCIPLES NEURAL SC, Vthird; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2007, ADV NEURAL INFORM PR, P1137; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Luciw M., 2010, P INT C DEV LEARN; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700; Pashler H., 1996, ATTENTION; PETERSEN SE, 1985, J NEUROPHYSIOL, V54, P867; Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185; Rao R.P.N., 2004, NEUROBIOLOGY ATTENTI; Rehn M, 2007, J COMPUT NEUROSCI, V22, P135, DOI 10.1007/s10827-006-0003-9; Schill K, 2001, J ELECTRON IMAGING, V10, P152, DOI 10.1117/1.1329627; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sillito AM, 2006, TRENDS NEUROSCI, V29, P307, DOI 10.1016/j.tins.2006.05.001; Treisman A., 1986, SCI AM, V254, P114, DOI [DOI 10.1038/SCIENTIFICAMERICAN1186-114B, 10.1038/scientificamerican1186-114B]; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; Weng J, 1997, INT J COMPUT VISION, V25, P109, DOI 10.1023/A:1007967800668; Weng J., 1992, INTERNATIONAL JOINT, V1, P576; Weng JY, 2009, IEEE T AUTON MENT DE, V1, P68, DOI 10.1109/TAMD.2009.2021698; Weng JY, 2007, NEUROCOMPUTING, V70, P2303, DOI 10.1016/j.neucom.2006.07.017; Weng JY, 2001, SCIENCE, V291, P599, DOI 10.1126/science.291.5504.599; Zhang QA, 2010, IEEE IMAGE PROC, P1665, DOI 10.1109/ICIP.2010.5650188	45	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0921-8890	1872-793X		ROBOT AUTON SYST	Robot. Auton. Syst.	SEP	2015	71				SI		35	48		10.1016/j.robot.2015.03.004		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics	Automation & Control Systems; Computer Science; Robotics	CL7IP	WOS:000357146000005		
J	Lerouge, J; Herault, R; Chatelain, C; Jardin, F; Modzelewski, R				Lerouge, J.; Herault, R.; Chatelain, C.; Jardin, F.; Modzelewski, R.			IODA: An input/output deep architecture for image labeling	PATTERN RECOGNITION			English	Article						Deep learning architectures; Deep neural network; Image labeling; Machine learning; Medical imaging; Sarcopenia	SPEECH RECOGNITION; PROGNOSTIC-FACTOR; SIGN RECOGNITION; SEGMENTATION; REGISTRATION; NETWORK; NETS	In this paper, we propose a deep neural network (DNN) architecture called Input Output Deep Architecture (IODA) for solving the problem of image labeling. IODA directly links a whole image to a whole label map, assigning a label to each pixel using a single neural network forward step. Instead of designing a handcrafted a priori model on labels (such as an atlas in the medical domain), we propose to automatically learn the dependencies between labels. The originality of IODA is to transpose DNN input pre-training trick to the output space, in order to learn a high level representation of labels. It allows a fast image labeling inside a fully neural network framework, without the need of any preprocessing such as feature designing or output coding. In this paper, IODA is applied on both a toy texture problem and a real-world medical image dataset, showing promising results. We provide an open source implementation of IODA.(1,2) (C) 2015 Elsevier Ltd. All rights reserved.	[Lerouge, J.; Herault, R.; Chatelain, C.; Modzelewski, R.] Normandie Univ, INSA Rouen, LITIS, EA 4108,FR CNRS 9638, F-76800 St Etienne, France; [Modzelewski, R.] Henri Becquerel Canc Ctr, Dept Nucl Med, F-76000 Rouen, France; [Modzelewski, R.] Rouen Univ Hosp, F-76000 Rouen, France; [Jardin, F.] Henri Becquerel Canc Ctr, Dept Clin Hematol, F-76000 Rouen, France; [Jardin, F.] Henri Becquerel Canc Ctr, INSERM Unit U918, F-76000 Rouen, France	Lerouge, J (reprint author), Normandie Univ, INSA Rouen, LITIS, EA 4108,FR CNRS 9638, F-76800 St Etienne, France.	julien.lerouge@insa-rouen.fr; romain.herault@insa-rouen.fr; clement.chatelain@insa-rouen.fr; romain.modzelewski@chb.unicancer.fr			project LeMon [ANR-11-JS02-010]	This work has been partly supported by the ANR-11-JS02-010 project LeMon.	Barlas P., 2014, DOCUMENT ANAL SYSTEM, P46; Bascon SM, 2010, COMPUT VIS IMAGE UND, V114, P373, DOI 10.1016/j.cviu.2009.12.002; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bergstra J, 2010, P PYTH SCI COMP C SC, V4, P3; BESAG J, 1986, J ROY STAT SOC B MET, V48, P259; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; Chum O., 2007, P IEEE INT C COMP VI, P1; Chung H., 2009, P SOC PHOTO-OPT INS, V7261; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8; Deng L, 2013, INT CONF ACOUST SPEE, P8599; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Glorot X., 2010, P INT C ART INT STAT; GOSHTASBY A, 1986, PATTERN RECOGN, V19, P459, DOI 10.1016/0031-3203(86)90044-0; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ion A, 2014, INT J COMPUT VISION, V107, P40, DOI 10.1007/s11263-013-0663-7; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Krahenbuhl P., 2011, NIPS, V24, P109; Labbe B., 2009, ICMLA MIAM US, P6; Lafferty J.D., 2001, P INT C MACH LEARN, V18, P282; Lanic H, 2014, LEUKEMIA LYMPHOMA, V55, P817, DOI 10.3109/10428194.2013.816421; Li SZ, 2009, MARKOV RANDOM FIELD; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; Martin L, 2013, J CLIN ONCOL, V31, P1539, DOI 10.1200/JCO.2012.45.2722; Nicolas S, 2006, INT C PATT RECOG, P292; Papavassiliou V, 2010, PATTERN RECOGN, V43, P369, DOI 10.1016/j.patcog.2009.05.007; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Ruta A, 2010, PATTERN RECOGN, V43, P416, DOI 10.1016/j.patcog.2009.05.018; Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296; Srivastava N., 2013, THESIS U TORONTO TOR; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143; Weston J., 2002, ADV NEURAL INFORM PR, V15, P873; Weston J., 2008, ICML 08, P1168; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	40	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	SEP	2015	48	9					2847	2858		10.1016/j.patcog.2015.03.017		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CK3JM	WOS:000356112400008		
J	Tang, JH; Li, ZC; Wang, M; Zhao, RZ				Tang, Jinhui; Li, Zechao; Wang, Meng; Zhao, Ruizhen			Neighborhood Discriminant Hashing for Large-Scale Image Retrieval	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						Hashing; nearest neighbor search; image retrieval; binary codes; neighborhood discriminant information; maximum entropy principle	SEARCH; QUANTIZATION	With the proliferation of large-scale community-contributed images, hashing-based approximate nearest neighbor search in huge databases has aroused considerable interest from the fields of computer vision and multimedia in recent years because of its computational and memory efficiency. In this paper, we propose a novel hashing method named neighborhood discriminant hashing (NDH) (for short) to implement approximate similarity search. Different from the previous work, we propose to learn a discriminant hashing function by exploiting local discriminative information, i. e., the labels of a sample can be inherited from the neighbor samples it selects. The hashing function is expected to be orthogonal to avoid redundancy in the learned hashing bits as much as possible, while an information theoretic regularization is jointly exploited using maximum entropy principle. As a consequence, the learned hashing function is compact and nonredundant among bits, while each bit is highly informative. Extensive experiments are carried out on four publicly available data sets and the comparison results demonstrate the outperforming performance of the proposed NDH method over state-of-the-art hashing techniques.	[Tang, Jinhui; Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Wang, Meng] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China; [Zhao, Ruizhen] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China	Li, ZC (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.	jinhuitang@njust.edu.cn; zechao.li@njust.edu.cn; eric.mengwang@gmail.com; rzhzhao@bjtu.edu.cn			973 Program [2014CB347600]; National Natural Science Foundation of China [61402228]; Natural Science Foundation of Jiangsu Province [BK2012033, BK20140058]; Program for New Century Excellent Talents in University [NCET-12-0632]; Open Projects Program of National Laboratory of Pattern Recognition	This work was supported in part by the 973 Program under Project 2014CB347600, in part by the National Natural Science Foundation of China under Grant 61402228, in part by the Natural Science Foundation of Jiangsu Province under Grant BK2012033 and Grant BK20140058, in part by the Program for New Century Excellent Talents in University under Grant NCET-12-0632, and in part by the Open Projects Program of National Laboratory of Pattern Recognition. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Nilanjan Ray.	Andoni A., 2009, THESIS MIT CAMBRIDGE; Baluja S, 2008, DATA MIN KNOWL DISC, V17, P402, DOI 10.1007/s10618-008-0096-z; Bondugula S., 2012, SURVEY HASHING TECHN; Chua T.-S., 2009, P ACM INT C IM VID R, DOI DOI 10.1145/1646396.1646452; Dick A., 2013, P INT C MACH LEARN, P142; Goldberger J., 2005, P NIPS, V17, P513; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Heo JP, 2012, PROC CVPR IEEE, P2957; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huiskes M. J., 2008, P 1 ACM INT C MULT I, P39, DOI DOI 10.1145/1460096.1460104; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jeffries A., 2013, MAN FLICKR MAKING SE; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Ji J., 2012, P NIPS, P108; Kan MN, 2014, IEEE T CIRC SYST VID, V24, P704, DOI 10.1109/TCSVT.2013.2276713; Kong W., 2012, P ADV NEUR INF PROC, P1646; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kulis B., 2009, P ADV NEUR INF PROC, V22, P1042; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; Li Z., 2015, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2015.2400461, DOI 10.1109/TPAMI.2015.2400461]; Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65; Liu D, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422958; Liu Wei, 2011, Reports in Parasitology, V1, P1; Liu W, 2012, PROC CVPR IEEE, P2074; Liu XL, 2014, PATTERN RECOGN, V47, P748, DOI 10.1016/j.patcog.2013.08.022; Liu Y, 2012, IEEE T IMAGE PROCESS, V21, P4480, DOI 10.1109/TIP.2012.2207394; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; Parfeni L., 2011, FLICKR BOASTS 6 BILL; Raginsky M., 2009, P ADV NEUR INF PROC, V22, P1509; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shakhnarovich G., 2005, THESIS MIT CAMBRIDGE; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Torralba A, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2008.4587633; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wang J., 2014, HASHING SIMILARITY S; Wang J., 2013, P IEEE INT C COMP VI, P3032; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang J., 2013, P ACM INT C MULT, P133; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25; Weiss Y., 2008, NIPS, V21, P1753; Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76; Xu B., 2013, P 23 INT JOINT C ART, P1820; Zhang D., 2012, P 11 IEEE INT C COGN, P18	47	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149	1941-0042		IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	SEP	2015	24	9					2827	2840		10.1109/TIP.2015.2421443		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CJ8NR	WOS:000355760300006	25872214	
J	Liu, J; Liu, BY; Lu, HG				Liu, Jing; Liu, Bingyuan; Lu, Hanging			Detection guided deconvolutional network for hierarchical feature learning	PATTERN RECOGNITION			English	Article						Image representation; Deep leaning; Object recognition	OBJECT RECOGNITION; RECEPTIVE-FIELDS; CORTEX; CLASSIFICATION; ALGORITHM; MODELS	Deep learning models have gained significant interest as a way of building hierarchical image representation. However, current models still perform far behind human vision system because of the lack of selective property, the lack of high-level guidance for learning and the weakness to learn from few examples. To address these problems, we propose a detection-guided hierarchical learning algorithm for image representation. First, we train a multi-layer deconvolutional network in an unsupervised bottom-up scheme. During the training process, we use each raw image as an input, and decompose an image using multiple alternating layers of non-negative convolutional sparse coding and max-pooling. Inspired from the observation that the filters in top layer can be selectively activated by different high-level structures of images, i.e., one or partial filters should correspond to a particular object class, we update the filters in network by minimizing the reconstruction errors of the corresponding feature maps with respect to certain object detection maps obtained by a set of pre-trained detectors. With the fine-tuned network, we can extract the features of given images in a purely unsupervised way with no need of detectors. We evaluate the proposed feature representation on the task of object recognition, for which an SVM classifier with spatial pyramid matching kernel is used. Experiments on the datasets of PASCAL VOC 2007, Caltech-101 and Caltech-256 demonstrate that our approach outperforms some recent hierarchical feature descriptors as well as classical hand-crafted features. (C) 2015 Elsevier Ltd. All rights reserved.	[Liu, Jing; Liu, Bingyuan; Lu, Hanging] CASIA, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Liu, J (reprint author), CASIA, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	jliu@nlpr.ia.ac.cn			973 Program [2012CB316304]; National Natural Science Foundation of China [61272329, 61472422, 61332016]	This work was supported by 973 Program (2012CB316304) and National Natural Science Foundation of China (61272329, 61472422, 61332016).	Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Chatfield K., 2011, BMVC, V76, P1; Dalai N., 2005, INT C COMP VIS PATT, V1, P886, DOI DOI 10.1109/CVPR.2005.177; Desimone Robert, 1984, THE JOURNAL OF NEURO, V8, P2051; Everingham M., 2007, PASCAL VISUAL OBJECT, P4; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Girshick R., 2014, IEEE C COMP VIS PATT, P580; Griffin G., 2007, 7694 CALTECH; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; He K., 2014, EUR C COMP VIS ECCV, P346; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, CORRABS12070580; Hoyer PO, 2003, NEUROCOMPUTING, V52-4, P547, DOI 10.1016/S0925-2312(02)00782-8; Huang F, 2007, B ENTOMOL RES, V97, P1; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23, P1090; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Li L.J., 2010, ADV NEURAL INFORM PR, P1378; Quiroga RQ, 2005, NATURE, V435, P1102, DOI 10.1038/nature03687; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Song Z, 2011, PROC CVPR IEEE, P1585; Taigman Y., 2014, IEEE C COMP VIS PATT, P1701; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van Gemert JC, 2008, LECT NOTES COMPUT SC, V5304, P696, DOI 10.1007/978-3-540-88690-7_52; Wan L., 2013, JMLR WORKSHOP C P, V28, P1058; Yang JC, 2009, PROC CVPR IEEE, P1794; Yu K, 2011, PROC CVPR IEEE, P1713; Zeiler M., 2013, INT C LEARN REPR ICL; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeiler MD, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2018, DOI 10.1109/ICCV.2011.6126474; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957	38	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	AUG	2015	48	8					2645	2655		10.1016/j.patcog.2015.02.002		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CI2MW	WOS:000354582700024		
J	Liu, QH; Hu, XN; Ye, M; Cheng, XQ; Li, F				Liu, Qihe; Hu, Xiaonan; Ye, Mao; Cheng, Xianqiong; Li, Fan			Gas Recognition under Sensor Drift by Using Deep Learning	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							TEMPERATURE MODULATION; ELECTRONIC NOSE; COMPENSATION	Machine olfaction is an intelligent system that combines a cross-sensitivity chemical sensor array and an effective pattern recognition algorithm for the detection, identification, or quantification of various odors. Data collected by the sensor array are the multivariate time series signals with a complex structure, and these signals become more difficult to analyze due to sensor drift. In this work, we focus on improving the classification performance under sensor drift by using the deep learning method, which is popular nowadays. Compared with other methods, our method can effectively tackle sensor drift by automatically extracting features, thus not only removing the complexity of designing the hand-made features but also making it pervasive for a variety of application in machine olfaction. Our experimental results show that the deep learning method can learn the features that are more robust to drift than the original input and achieves high classification accuracy. (C) 2015 Wiley Periodicals, Inc.	[Liu, Qihe; Hu, Xiaonan; Ye, Mao; Li, Fan] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Robot, Key Lab NeuroInformat,Minist Educ, Chengdu 610054, Peoples R China; [Cheng, Xianqiong] Chengdu Univ Technol, Coll Geophys, Chengdu, Peoples R China	Liu, QH (reprint author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Robot, Key Lab NeuroInformat,Minist Educ, Chengdu 610054, Peoples R China.	qiheliu@uestc.edu.cn			Fundamental Research Funds for the Central Universities [ZYGX2012J086, ZYGX2012J079]; National Natural Science Foundation of China [61375038]	We would like to thank Alexander Vergara, San Diego, and Ramon Huerta for their providing public gas sensor drift data. This work is supported in part by the Fundamental Research Funds for the Central Universities (numbers ZYGX2012J086 and ZYGX2012J079) and in part by the National Natural Science Foundation of China (number 61375038).	AIGNER R, 1994, SENSOR ACTUAT B-CHEM, V18, P143, DOI 10.1016/0925-4005(94)87073-X; Artursson T, 2000, J CHEMOMETR, V14, P711, DOI 10.1002/1099-128X(200009/12)14:5/6<711::AID-CEM607>3.0.CO;2-4; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bruins M, 2009, EUR J CLIN MICROBIOL, V28, P775, DOI 10.1007/s10096-009-0700-1; Chang C. C., LIBSVM LIB SUPPORT V; Coates A, 2011, 2011 INT C DOC AN RE, P440; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Gardner J, 1999, ELECT NOSES PRINCIPL; GOPEL W, 1994, SENSOR ACTUAT B-CHEM, V18, P1, DOI 10.1016/0925-4005(94)87049-7; Gutierrez-Osuna R, 2000, P 7 INT S OLF EL NOS; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; Haugen JE, 2000, ANAL CHIM ACTA, V407, P23, DOI 10.1016/S0003-2670(99)00784-9; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2010, MOMENTUM, V9, P3; Jaitly N, 2011, INT CONF ACOUST SPEE, P5884; Klinkenberg R, 2000, P 17 INT C MACH LEAR, P487; Langkvist M, 2011, P NIPS 2011 WORKSH D; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2011.5995496; Le QV, 2011, P 28 INT C MACH LEAR, P265; Lee H., 2009, ADV NEURAL INF PROCE, V9, P1096; Liu QH, 2014, IEEE SENS J, V14, P657, DOI 10.1109/JSEN.2013.2285919; Llobet E, 1997, SENSOR ACTUAT B-CHEM, V41, P13, DOI 10.1016/S0925-4005(97)80272-9; Muezzinoglu MK, 2009, SENSOR ACTUAT B-CHEM, V137, P507, DOI 10.1016/j.snb.2008.10.065; Nair V, 2006, ADV NEURAL INFORM PR, V19, P1339; Pearce TC, 2003, HDB MACHINE OLFACTIO, P134; Romain AC, 2010, SENSOR ACTUAT B-CHEM, V146, P502, DOI 10.1016/j.snb.2009.12.027; Roth M, 1996, SENSOR ACTUAT B-CHEM, V36, P358, DOI 10.1016/S0925-4005(97)80096-2; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Taylor G. W., 2006, ADV NEURAL INF PROCE, V19, P1345; Trincavelli M, 2010, IEEE T BIO-MED ENG, V57, P2884, DOI 10.1109/TBME.2010.2049492; Vergara A, 2012, SENSOR ACTUAT B-CHEM, V166, P320, DOI 10.1016/j.snb.2012.01.074; Vito SD, 2012, IEEE SENS J, V12, P3215; Wulsin D, 2011, J NEURAL ENG, V8, P1741; YAMAZOE N, 1991, SENSOR ACTUAT B-CHEM, V5, P7, DOI 10.1016/0925-4005(91)80213-4	35	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0884-8173	1098-111X		INT J INTELL SYST	Int. J. Intell. Syst.	AUG	2015	30	8			SI		907	922		10.1002/int.21731		16	Computer Science, Artificial Intelligence	Computer Science	CK2AV	WOS:000356012600005		
J	Mahani, AS; Sharabiani, MTA				Mahani, Alireza S.; Sharabiani, Mansour T. A.			SIMD parallel MCMC sampling with applications for big-data Bayesian analytics	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						GPU; Hierarchical Bayesian; Intel Xeon Phi; Logistic regression; OpenMP; Vectorization	HAMILTONIAN MONTE-CARLO; LEARNING ALGORITHM; TOPIC MODELS; SYSTEMS; DISTRIBUTIONS	Computational intensity and sequential nature of estimation techniques for Bayesian methods in statistics and machine learning, combined with their increasing applications for big data analytics, necessitate both the identification of potential opportunities to parallelize techniques such as Monte Carlo Markov Chain (MCMC) sampling, and the development of general strategies for mapping such parallel algorithms to modern CPUs in order to elicit the performance up the compute-based and/or memory-based hardware limits. Two opportunities for Single-Instruction Multiple-Data (SIMD) parallelization of MCMC sampling for probabilistic graphical models are presented. In exchangeable models with many observations such as Bayesian Generalized Linear Models (GLMs), child-node contributions to the conditional posterior of each node can be calculated concurrently. In undirected graphs with discrete-value nodes, concurrent sampling of conditionally-independent nodes can be transformed into a SIMD form. High-performance libraries with multi-threading and vectorization capabilities can be readily applied to such SIMD opportunities to gain decent speedup, while a series of high-level source-code and runtime modifications provide further performance boost by reducing parallelization overhead and increasing data locality for Non-Uniform Memory Access architectures. For big-data Bayesian GLM graphs, the end-result is a routine for evaluating the conditional posterior and its gradient vector that is 5 times faster than a naive implementation using (built-in) multi-threaded Intel MKL BLAS, and reaches within the striking distance of the memory-bandwidth-induced hardware limit. Using multi-threading for cache-friendly, fine-grained parallelization can outperform coarse-grained alternatives which are often less cache-friendly, a likely scenario in modern predictive analytics workflow such as Hierarchical Bayesian GLM, variable selection, and ensemble regression and classification. The proposed optimization strategies improve the scaling of performance with number of cores and width of vector units (applicable to many-core SIMD processors such as Intel Xeon Phi and Graphic Processing Units), resulting in cost-effectiveness, energy efficiency ('green computing'), and higher speed on multi-core x86 processors. (C) 2015 Elsevier B.V. All rights reserved.	[Mahani, Alireza S.] Sentrana Inc, Sci Comp Grp, Washington, DC 20006 USA; [Sharabiani, Mansour T. A.] Univ London Imperial Coll Sci Technol & Med, Natl Heart & Lung Inst, London SW7 2AZ, England	Mahani, AS (reprint author), Sentrana Inc, 1725 I St NW Suite 900, Washington, DC 20006 USA.	alireza.s.mahani@gmail.com					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Ahmed A., 2012, P 5 ACM INT C WEB SE, P123; Antonio K, 2007, INSUR MATH ECON, V40, P58, DOI 10.1016/j.insmatheco.2006.02.013; Babapulle MN, 2004, LANCET, V364, P583, DOI 10.1016/S0140-6736(04)16850-5; Bache K., 2013, UCI MACHINE LEARNING; Bernardo J., 1996, FAR E J MATH SCI, V4, P111; Bishop CM, 2006, PATTERN RECOGNITION; Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826; Bovet D., 2005, UNDERSTANDING LINUX; Brockwell AE, 2006, J COMPUT GRAPH STAT, V15, P246, DOI 10.1198/106186006X100579; Broquedis F, 2009, LECT NOTES COMPUT SC, V5568, P79, DOI 10.1007/978-3-642-02303-3_7; BRUSH SG, 1967, REV MOD PHYS, V39, P883, DOI 10.1103/RevModPhys.39.883; Bryant R., 2011, COMPUTER SYSTEMS PRO, Vsecond; CARLIN BP, 1992, J R STAT SOC C-APPL, V41, P389; Chandra Rohit, 2001, PARALLEL PROGRAMMING; Clint M., 1994, Parallel Processing: CONPAR 94 - VAPP VI. Third Joint International Conference on Vector and Parallel Processing Proceedings; da Silva ARF, 2011, J STAT SOFTW, V44, P1; Descombes X, 1998, IEEE T MED IMAGING, V17, P1028, DOI 10.1109/42.746636; Diaconescu RE, 2007, INT J HIGH PERFORM C, V21, P313, DOI 10.1177/1094342007078451; DUANE S, 1987, PHYS LETT B, V195, P216, DOI 10.1016/0370-2693(87)91197-X; Dumont M.D., 2011, THESIS ROCHESTER I T; Fenton N., 2004, COMBINING EVIDENCE R; Foster I., 1995, DESIGNING BUILDING P; Gelman A., 2007, DATA ANAL USING REGR; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; Girolami M, 2011, J R STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x; Gonzalez J., 2011, INT C ART INT STAT F, P324; Gonzalez J.E., 2012, 10 USENIX S OP SYST, V12, P17; Gonzalez J.E., 2009, P 25 C UNC ART INT, P203; Hastie T., 1987, J R STAT SOC C-APPL, V36, P260; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffman MD, 2014, J MACH LEARN RES, V15, P1593; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Jeffers J., 2013, INTEL XEON PHI COPRO; Kirk D., 2012, PROGRAMMING MASSIVEL; Kontoghiorghes E, 2000, ADV COMPUTATIONAL EC, V15; Kontoghiorghes E.J, 2005, HDB PARALLEL COMPUTI; Kontoghiorghes EJ, 1999, CONCURRENCY-PRACT EX, V11, P323; Kontoghiorghes E.J., 1993, PARALLEL ALGORITHMS, V1, P243; Kontoghiorghes EJ, 1999, PARALLEL COMPUT, V25, P1147, DOI 10.1016/S0167-8191(99)00043-5; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V1, P4; Kumar S, 2008, CONF PROC INT SYMP C, P441, DOI 10.1109/ISCA.2008.38; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2011.5995496; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Low Y., 2012, P VLDB ENDOWMENT, V5, P716; Mahani A.S., 2015, SNS STOCHASTIC NEWTO; Majo Z, 2011, ACM SIGPLAN NOTICES, V46, P11, DOI 10.1145/2076022.1993481; Marsaglia G, 2000, ACM T MATH SOFTWARE, V26, P363, DOI 10.1145/358407.358414; McCool M, 2012, STRUCTURED PARALLEL PROGRAMMING: PATTERNS FOR EFFICIENT COMPUTATION, P1; McCulloch C. E., 2006, GEN LINEAR MIXED MOD; METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Molina da Cruz E.H., 2011, 2011 IEEE INT S PAR, P551; Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461; Neal R.M., 1995, THESIS U TORONTO; Nelder J. A., 1972, GEN LINEAR MODELS; Newman D, 2009, J MACH LEARN RES, V10, P1801; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; PARKINSON D, 1987, PARALLEL COMPUT, V5, P75, DOI 10.1016/0167-8191(87)90008-1; Perez P., 1998, QUARTERLY, V11, P413; Plummer M., 2013, JAGS JUST ANOTHER GI; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Press W. H., 2007, NUMERICAL RECIPES, V3rd; Ren RC, 2007, J CHEM PHYS, V126, DOI 10.1063/1.2743003; Ribeiro C.P., 2010, 2010 IEEE INT S PAR, P1, DOI 10.1109/IPDPSW.2010.5470796; Ripley BD, 2009, STOCHASTIC SIMULATIO, V316; Robert C. P., 2004, MONTE CARLO STAT MET, V319; Rossi P.E., 2005, BAYESIAN STAT MARKET; Sharabiani MTA, 2011, BIOMARKERS, V16, P243, DOI 10.3109/1354750X.2010.547948; Smolensky P., 1986, INFORM PROCESSING DY; Sobehart J.R., 2000, MOODYS PUBLIC FIRM R; Stan Development Team, 2014, STAN A C LIBR PROB S; Strid I, 2010, COMPUT STAT DATA AN, V54, P2814, DOI 10.1016/j.csda.2009.11.019; SUTTER JM, 1993, MICROCHEM J, V47, P60, DOI 10.1006/mchj.1993.1012; Thomas A., 2006, R NEWS, V6, P12; Tibbits MM, 2011, STAT COMPUT, V21, P415, DOI 10.1007/s11222-010-9178-z; Wilkinson D.J., 2010, HDB PARALLEL COMPUTI; Xu T., 2011, INT C ART INT STAT, P798; Yu LB, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, PROCEEDINGS, P555, DOI 10.1109/ISPA.2009.88	82	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473	1872-7352		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	AUG	2015	88						75	99		10.1016/j.csda.2015.02.010		25	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	CH0TC	WOS:000353734300006		
J	Weng, DW; Wang, YH; Gong, MM; Tao, DC; Wei, H; Huang, D				Weng, Dawei; Wang, Yunhong; Gong, Mingming; Tao, Dacheng; Wei, Hui; Huang, Di			DERF: Distinctive Efficient Robust Features From the Biological Modeling of the P Ganglion Cells	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						Computer vision; image matching; local descriptors; wavelets; ganglion cells	LOCAL IMAGE DESCRIPTORS; OBJECT RECOGNITION; RECEPTIVE-FIELDS; HUMAN RETINA; MACAQUE MONKEYS; VISUAL-SYSTEM; CLASSIFICATION; REPRESENTATION; NETWORKS; DEEP	Studies in neuroscience and biological vision have shown that the human retina has strong computational power, and its information representation supports vision tasks on both ventral and dorsal pathways. In this paper, a new local image descriptor, termed distinctive efficient robust features (DERF), is derived by modeling the response and distribution properties of the parvocellular-projecting ganglion cells in the primate retina. DERF features exponential scale distribution, exponential grid structure, and circularly symmetric function difference of Gaussian (DoG) used as a convolution kernel, all of which are consistent with the characteristics of the ganglion cell array found in neurophysiology, anatomy, and biophysics. In addition, a new explanation for local descriptor design is presented from the perspective of wavelet tight frames. DoG is naturally a wavelet, and the structure of the grid points array in our descriptor is closely related to the spatial sampling of wavelets. The DoG wavelet itself forms a frame, and when we modulate the parameters of our descriptor to make the frame tighter, the performance of the DERF descriptor improves accordingly. This is verified by designing a tight frame DoG, which leads to much better performance. Extensive experiments conducted in the image matching task on the multiview stereo correspondence data set demonstrate that DERF outperforms state of the art methods for both hand-crafted and learned descriptors, while remaining robust and being much faster to compute.	[Weng, Dawei; Wang, Yunhong] Beihang Univ, Sch Comp Sci & Technol, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China; [Gong, Mingming; Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Gong, Mingming; Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia; [Wei, Hui] Fudan Univ, Sch Comp Sci, Lab Cognit Model & Algorithm, Shanghai 200438, Peoples R China; [Huang, Di] Beihang Univ, Sch Comp Sci & Engn, Lab Intelligent Recognit & Image Proc, Beijing 100191, Peoples R China	Weng, DW (reprint author), Beihang Univ, Sch Comp Sci & Technol, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.	daweiweng0204@gmail.com; yhwang@buaa.edu.cn; dacheng.tao@uts.edu.au; weihui@fudan.edu.cn; dhuang@buaa.edu.cn			National Basic Research Program of China [2010CB327902]; National Natural Science Foundation of China [61273263, 61202237]; Beijing Municipal Natural Science Foundation [4142032]; Specialized Research Fund for the Doctoral Program of Higher Education [20121102120016]; Group of Ecoles Centrales; Beihang University; Fundamental Research Funds for the Central Universities; Australian Research Council [DP-140102164, FT-130101457]	This work was supported in part by the National Basic Research Program of China under Grant 2010CB327902, in part by the National Natural Science Foundation of China under Grant 61273263 and Grant 61202237, in part by the Beijing Municipal Natural Science Foundation under Grant 4142032, in part by the Specialized Research Fund for the Doctoral Program of Higher Education under Grant 20121102120016, in part by the Joint Project through the LIA 2MCSI Laboratory between the Group of Ecoles Centrales and Beihang University, in part by the Fundamental Research Funds for the Central Universities, and in part by the Australian Research Council under Project DP-140102164 and Project FT-130101457. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Ling Shao.	Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Amiri M, 2011, IEEE T IMAGE PROCESS, V20, P3580, DOI 10.1109/TIP.2011.2156800; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2001, PROC CVPR IEEE, P607; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Chan T.-H., 2014, PCANET SIMPLE DEEP L; Chao-Yi Li, 1992, Vision Research, V32, DOI 10.1016/0042-6989(92)90131-2; CRONER LJ, 1995, VISION RES, V35, P7, DOI 10.1016/0042-6989(94)E0066-T; CURCIO CA, 1990, J COMP NEUROL, V300, P5, DOI 10.1002/cne.903000103; DACEY DM, 1993, J NEUROSCI, V13, P5334; DACEY DM, 1992, P NATL ACAD SCI USA, V89, P9666, DOI 10.1073/pnas.89.20.9666; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; Daubechies I., 1992, 10 LECT WAVELETS, V61; Ding C., 2014, MULTIDIRECTIONAL MUL; Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959; DUFFIN RJ, 1952, T AM MATH SOC, V72, P341, DOI 10.2307/1990760; Edelman S., 1997, COMPLEX CELLS OBJECT; Freeman W. T., 1991, P IEEE PATTERN ANAL, V13, P891, DOI DOI 10.1109/34.93808; Ghosh K, 2005, LECT NOTES COMPUT SC, V3776, P453; Grossmann A., 1989, WAVELETS TIME FREQUE, V1st, P2; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang D, 2014, IEEE T IMAGE PROCESS, V23, P4680, DOI 10.1109/TIP.2014.2353814; Jayachandra D, 2014, IEEE T IMAGE PROCESS, V23, P240, DOI 10.1109/TIP.2013.2288912; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kamermans M, 1996, VISION RES, V36, P4105, DOI 10.1016/S0042-6989(96)00143-5; KAPLAN E, 1982, J PHYSIOL-LONDON, V330, P125; Ke Y, 2004, PROC CVPR IEEE, P506; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Li X., IEEE T CYBE IN PRESS; [李瑶 Li Yao], 2011, [生物物理学报, Acta Biophysica Sinica], V27, P211; Linde O, 2004, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2004.1333965; Liu L, 2014, PATTERN RECOGN, V47, P3819, DOI 10.1016/j.patcog.2014.07.006; LIVINGSTONE M, 1988, SCIENCE, V240, P740, DOI 10.1126/science.3283936; Lowe D. G., 1999, P 7 IEEE INT C COMP, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu X., IEEE T CYBE IN PRESS; Lu XQ, 2014, IEEE T CYBERNETICS, V44, P149, DOI 10.1109/TCYB.2013.2286496; Maani Rouzbeh, 2014, IEEE Trans Image Process, V23, P4625, DOI 10.1109/TIP.2014.2351620; MERIGAN WH, 1991, J NEUROSCI, V11, P994; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Monasterio F. M. D., 1975, J PHYSIOL-LONDON, V251, P167; Moons T., 1996, P 4 EUR C COMP VIS C, P642; Osterberg G., 1935, TOPOGRAPHY LAYER ROD; Ouyang WL, 2012, PROC CVPR IEEE, P3258; Peter G., 1968, J PHYSL, V199, P533; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; RODIECK R. W., 1965, VISION RES, V5, P583, DOI 10.1016/0042-6989(65)90033-7; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519; Shapley R, 1997, CURR BIOL, V7, pR421, DOI 10.1016/S0960-9822(06)00207-7; Shotton J., 2008, P IEEE C COMP VIS PA, P1; Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163; SILVERMAN MS, 1989, P NATL ACAD SCI USA, V86, P711, DOI 10.1073/pnas.86.2.711; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Tao DP, 2015, IEEE T CYBERNETICS, V45, P242, DOI 10.1109/TCYB.2014.2323992; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088; Tao DP, 2014, IEEE T IND INFORM, V10, P813, DOI 10.1109/TII.2013.2255061; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Trzcinski T., 2012, P ADV NIPS, P278; Wang M, 2012, PROC CVPR IEEE, P3274; Xiao L., 2010, P ADV NEUR INF PROC, P2116; Yuan Y., IEEE T NEUR IN PRESS; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894	70	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149	1941-0042		IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	AUG	2015	24	8								10.1109/TIP.2015.2409739		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CG2YS	WOS:000353142800001		
J	Jia, K; Sun, L; Gao, SH; Song, Z; Shi, BE				Jia, Kui; Sun, Lin; Gao, Shenghua; Song, Zhan; Shi, Bertram E.			Laplacian Auto-Encoders: An explicit learning of nonlinear data manifold	NEUROCOMPUTING			English	Article						Auto-encoders; Deep learning; Manifold learning; Image classification	DIMENSIONALITY REDUCTION; IMAGE ANNOTATION; REPRESENTATION	A key factor contributing to the success of many auto-encoders based deep learning techniques is the implicit consideration of the underlying data manifold in their training criteria. In this paper, we aim to make this consideration more explicit by training auto-encoders completely from the manifold learning perspective. We propose a novel unsupervised manifold learning method termed Laplacian Auto-Encoders (LAEs). Starting from a general regularized function learning framework, LAE regularizes training of auto-encoders so that the learned encoding function has the locality-preserving property for data points on the manifold. By exploiting the analog relation between the graph Laplacian and the Laplace-Beltrami operator on the continuous manifold, we derive discrete approximations of the first- and higher-order auto-encoder regularizers that can be applied in practical scenarios, where only data points sampled from the distribution on the manifold are available. Our proposed LAE has potentially better generalization capability, due to its explicit respect of the underlying data manifold. Extensive experiments on benchmark visual classification datasets show that LAE consistently outperforms alternative auto-encoders recently proposed in deep learning literature, especially when training samples are relatively scarce: (C) 2015 Elsevier B.V. All rights reserved.	[Jia, Kui] Univ Macau, Fac Sci & Technol, Dept Elect & Comp Engn, Macau, Peoples R China; [Jia, Kui] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Sun, Lin; Shi, Bertram E.] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China; [Gao, Shenghua] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China; [Song, Zhan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China	Jia, K (reprint author), Adv Digital Sci Ctr, 08-10 Connexis North Tower,1 Fusionopolis Way, Singapore 138632, Singapore.	kuijia@umac.mo; lsunece@ust.hk; gaoshh@shanghaitech.edu.cn; zhan.song@siat.ac.cn; eebert@ee.ust.hk			National Natural Science Foundation of China [61202158]; Singapore's Agency for Science, Technology and Research (A*STAR)	This work is partially supported by the National Natural Science Foundation of China (Grant no. 61202158) and the research grant for the Human Sixth Sense Programme at the Advanced Digital Sciences Center from Singapore's Agency for Science, Technology and Research (A*STAR).	Belkin M, 2005, LECT NOTES COMPUT SC, V3559, P486, DOI 10.1007/11503415_33; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y., 2003, ADV NEURAL INFORM PR; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2013, ADV NEURAL INFORM PR; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bottou L., 2010, P 19 INT C COMP STAT, V19, P177; Cayton L., 2005, TECHNICAL REPORT; Donoho D., 2003, NATL ACAD SCI, V100, P5591; Goodfellow I., 2013, INT C MACH LEARN; Hein M, 2005, LECT NOTES COMPUT SC, V3559, P470, DOI 10.1007/11503415_32; Hinton G. E., 2012, CORR; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky A., 2009, TECHNICAL REPORT; Lafon S.S., 2004, THESIS YALE U; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liao Y., ARXIV13120786; Liu W, 2010, P INT C MACH LEARN, P679; Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302; Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007; Narayanan H., 2010, ADV NEURAL INFORM PR, V23, P1786; Ranzato M., 2007, INT C ART INT STAT, V2, P371; Rifai S., 2012, INT C MACH LEARN; Rifai S., 2011, ICML, P833; Rifai S, 2011, LECT NOTES ARTIF INT, V6912, P645, DOI 10.1007/978-3-642-23783-6_41; Rifai S., 2011, ADV NEURAL INFORM PR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Russakovsky, 2014, ARXIVARXIV14090575; Schaul T., 2013, INT C MACH LEARN ICM; Shaw B., 2009, ICML 09, P937, DOI DOI 10.1145/1553374.1553494; Talwalkar A., 2008, COMPUTER VISION PATT; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tikhonov A.N., 1977, SOLUTIONS ILL POSED; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vladymyrov M., 2013, ECML PKDD, V3, P256; Wan L, 2013, INT C MACH LEARN; WEINBERGER KQ, 2004, INT C COMP VIS PATT, P988; Weston J., 2008, P 25 INT C MACH LEAR, P1168, DOI DOI 10.1145/1390156.1390303; Williams CKI, 2001, ADV NEUR IN, V13, P682; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083; Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377; Yu K., 2011, IEEE C COMP VIS PATT	45	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	JUL 21	2015	160						250	260		10.1016/j.neucom.2015.02.023		11	Computer Science, Artificial Intelligence	Computer Science	CH6IA	WOS:000354139100022		
J	Zhang, CJ; Cheng, J; Zhang, YF; Liu, J; Liang, C; Pang, JB; Huang, QM; Tian, Q				Zhang, Chunjie; Cheng, Jian; Zhang, Yifan; Liu, Jing; Liang, Chao; Pang, Junbiao; Huang, Qingming; Tian, Qi			Image classification using boosted local features with random orientation and location selection	INFORMATION SCIENCES			English	Article						Sparse coding; Image classification; Random orientation; Boosting; Local feature selection	SPARSE REPRESENTATION; LOW-RANK; ANNOTATION; DECOMPOSITION; RECOGNITION	The combination of local features with sparse technique has improved image classification performance dramatically in recent years. Although very effective, this strategy still has two shortcomings. First, local features are often extracted in a pre-defined way (e.g. SIFT with dense sampling) without considering the classification task. Second, the codebook is generated by sparse coding or its variants by minimizing the reconstruction error which has no direct relationships with the classification process. To alleviate the two problems, we propose a novel boosted local features method with random orientation and location selection. We first extract local features with random orientation and location using a weighting strategy. This randomization process makes us to extract more types of information for image representation than pre-defined methods. These extracted local features are then encoded by sparse representation. Instead of generating the codebook in a single process, we construct a series of codebooks and the corresponding encoding parameters of local features using a boosting strategy. The weights of local features are determined by the classification performances of learned classifiers. In this way, we are able to combine the local feature extraction and encoding with classifier training into a unified framework and gradually improve the image classification performance. Experiments on several public image datasets prove the effectiveness and efficiency of the proposed method. (C) 2015 Elsevier Inc. All rights reserved.	[Zhang, Chunjie; Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China; [Zhang, Chunjie; Huang, Qingming] Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management, Beijing 100049, Peoples R China; [Cheng, Jian; Zhang, Yifan; Liu, Jing] Inst Automat Chinese Acad Sci, Natl Lab Pattern Recognit, Beijing, Peoples R China; [Liang, Chao] Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China; [Pang, Junbiao] Beijing Univ Technol, Coll Metropolitan Transportat, Beijing ICey Lab Multimedia & Intelligent Softwar, Beijing, Peoples R China; [Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intell Info Proc, Beijing 100190, Peoples R China; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA	Cheng, J (reprint author), Inst Automat Chinese Acad Sci, Natl Lab Pattern Recognit, POB 2728, Beijing, Peoples R China.	cjzhang@jdl.ac.cn; jcheng@nlpr.ia.ac.cn; yfzhang@nlpr.ia.ac.cn; jliu@nlpr.ia.ac.cn; cliang@whu.edu.cn; junbiao_pang@bjut.edu.cn; qmhuang@jdl.ac.cn; qitian@cs.utsa.edu			National Basic Research Program of China (973 Program) [2012CB316400, 2015CB351802]; National Natural Science Foundation of China [61303154, 61170127, 61272329, 61202234, 61303114, 61025011, 61332016]; Beijing Municipal Natural Science Foundation of China [4132010]; Specialized Research Fund for the Doctoral Program of Higher Education [20130141120024]	This work is supported by National Basic Research Program of China (973 Program): 2012CB316400 and 2015CB351802, National Natural Science Foundation of China: 61303154, 61170127, 61272329, 61202234, 61303114, 61025011 and 61332016. The President Fund of UCAS. Beijing Municipal Natural Science Foundation of China No. 4132010. Specialized Research Fund for the Doctoral Program of Higher Education (No. 20130141120024).	Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Boiman O., 2008, CVPR; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chatfield K., 2011, BMVC, V76, P1; Dalai N., 2005, P CVPR; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Everingham M., 2007, TECHNICAL REPORT; Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Freund Y., 2003, J MACHINE LEARNING R, V4, P933, DOI 10.1162/jmlr.2003.4.6.933; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Gao SH, 2014, IEEE T MULTIMEDIA, V16, P762, DOI 10.1109/TMM.2014.2299516; Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63; Gemert J. C. V., 2010, IEEE T PATTERN ANAL, V32, P1271, DOI DOI 10.1109/TPAMI.2009.132; Griffin G., 2007, TECHNICAL REPORT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Lazebnik S., 2006, P CVPR; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253; Lee H., 2006, P NIPS; Li L.J., 2007, IEEE 11 INT C COMP V, P1; Li Z., IEEE T PATTERN ANAL; Li Z., 2010, ACM MULTIMEDIA, P1187; Li Z.C., 2012, AAAI; Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65; Li ZC, 2013, COMPUT VIS IMAGE UND, V117, P1175, DOI 10.1016/j.cviu.2013.04.003; Liu XZ, 2005, PATTERN RECOGN, V38, P887, DOI 10.1016/j.patcog.2004.11.008; Lowe D., 2012, P CVPR, P3650; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Paisitkriangkrai S, 2014, IEEE T NEUR NET LEAR, V25, P764, DOI 10.1109/TNNLS.2013.2281214; Sande K., 2010, IEEE T PATTERN ANAL, V32, P1582; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418; Sivic J., 2003, ICCV, P1470; Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418; Tang JH, 2012, IEEE T IMAGE PROCESS, V21, P2354, DOI 10.1109/TIP.2011.2180916; Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373; Wang J., 2010, P CVPR; Wang M, 2012, IEEE T MULTIMEDIA, V14, P858, DOI 10.1109/TMM.2012.2187181; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JC, 2009, PROC CVPR IEEE, P1794; Yang L., 2008, CVPR; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zhang CJ, 2014, COMPUT VIS IMAGE UND, V123, P14, DOI 10.1016/j.cviu.2014.02.013; Zhang CJ, 2012, IEEE MULTIMEDIA, V19, P58; Zhang CJ, 2011, PROC CVPR IEEE, P1673; Zhang CJ, 2014, NEUROCOMPUTING, V142, P248, DOI 10.1016/j.neucom.2014.03.059; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang T, 2004, ANN STAT, V32, P56; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141	54	0	0	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255	1872-6291		INFORM SCIENCES	Inf. Sci.	JUL 20	2015	310						118	129		10.1016/j.ins.2015.03.011		12	Computer Science, Information Systems	Computer Science	CH9FJ	WOS:000354341100008		
J	de Franca, FO; Coelho, ALV				de Franca, Fabricio O.; Coelho, Andre L. V.			A biclustering approach for classification with mislabeled data	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Classification; Noisy labels; Biclustering; Feature learning	GENE-EXPRESSION DATA; CLASS NOISE; LABEL NOISE; IMPRECISE PROBABILITIES; ALGORITHM; VALUES	Labeling samples on large data sets is a demanding task prone to different sources of errors. Those errors, denoted as noise, can significantly impact the performance of a classification algorithm due to overfitting of wrongly labeled data. So far, this problem has been treated by avoiding the overfitting and correcting mislabeled data through similarity analysis. The former approach can be affected by the curse of dimensionality and some mislabeled data will not be corrected. In this paper, we investigate the use of a biclustering approach to capture local models of coherence across subsets of instances and attributes. Those models are used to replace and augment the attributes of the original dataset. Through a systematic series of experiments, we have assessed the performance of the proposed approach, referred to as BicNoise, by considering different rates and types of label noise, and also different types of classifiers, binary datasets, and evaluation metrics. The good results achieved suggest that the transformed data can alleviate the dimensionality problem, reduce the redundancy of correlated features and improve the separability of the data, thus improving the classifier performance (most noticeably, in the highest noise settings). (C) 2015 Elsevier Ltd. All rights reserved.	[de Franca, Fabricio O.] Fed Univ ABC UFABC, Ctr Math Comp & Cognit CMCC, Santo Andre, SP, Brazil; [Coelho, Andre L. V.] Univ Fortaleza UNIFOR, Ctr Technol Sci, Grad Program Appl Informat, Fortaleza, Ceara, Brazil	Coelho, ALV (reprint author), Univ Fortaleza UNIFOR, Ctr Technol Sci, Grad Program Appl Informat, Fortaleza, Ceara, Brazil.	folivetti@ufabc.edu.br; acoelho@unifor.br			National Council for Scientific and Technological Development (CNPq/Brazil) [304603/2012-0]	This work has been financially supported by the National Council for Scientific and Technological Development (CNPq/Brazil), under Grant No. 304603/2012-0.	Abellan J, 2003, INT J INTELL SYST, V18, P1215, DOI 10.1002/int.10143; Abellan J, 2012, EXPERT SYST APPL, V39, P6827, DOI 10.1016/j.eswa.2012.01.013; Agrawal R., 1998, SIGMOD Record, V27; Allison P.D., 2002, BRIT J MATH STAT PSY, V55, P193; Atla Abhinav, 2011, J COMPUTING SCI COLL, V26, P96; Bootkrajang J, 2014, PATTERN RECOGN, V47, P3641, DOI 10.1016/j.patcog.2014.05.007; Bootkrajang J., 2012, LNCS, V7523, P143; Bouveyron C, 2009, PATTERN RECOGN, V42, P2649, DOI 10.1016/j.patcog.2009.03.027; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; Cantador I, 2005, LECT NOTES COMPUT SC, V3562, P586; Cao JJ, 2012, PATTERN RECOGN, V45, P4451, DOI 10.1016/j.patcog.2012.05.002; Cheng Y, 2000, P C INT SYST MOL BIO, V2, P93; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Coelho G. P., 2009, J MATH MODELLING ALG, V8, P175; Cover T. M., 2006, ELEMENTS INFORM THEO; de Franca F., 2010, P 12 IEEE C EV COMP, P1; de Franca F. O., 2012, P 2012 11 INT C MACH, P464; de Souto MCP, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-497; de Castro PAD, 2007, LECT NOTES COMPUT SC, V4628, P83; de Franca FO, 2011, IEEE C EVOL COMPUTAT, P632; de Franca FO, 2013, PATTERN RECOGN, V46, P1255, DOI 10.1016/j.patcog.2012.10.022; Dem ar J., 2006, J MACH LEARN RES, V7, P1; Dhillon I. S., 2001, P 7 ACM SIGKDD INT C, P269, DOI DOI 10.1145/502512.502550; Dhillon I.S., 2003, P 9 ACM SIGKDD INT C, P89; Dorigo M, 2000, FUTURE GENER COMP SY, V16, P851, DOI 10.1016/S0167-739X(00)00042-X; Duch W., 2012, P INT JOINT C NEUR N, P1; Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894; Frenay B, 2014, COMPUT STAT DATA AN, V71, P832, DOI 10.1016/j.csda.2013.05.001; Guan DH, 2011, APPL INTELL, V35, P345, DOI 10.1007/s10489-010-0225-4; Guan DH, 2014, KNOWL-BASED SYST, V66, P28, DOI 10.1016/j.knosys.2014.04.013; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; LANGVILLE A. N., 2012, WHOS 1 SCI RATING RA; Little RJA, 2002, STAT ANAL MISSING DA; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mantas CJ, 2014, EXPERT SYST APPL, V41, P4625, DOI 10.1016/j.eswa.2014.01.017; Mantas CJ, 2014, EXPERT SYST APPL, V41, P2514, DOI 10.1016/j.eswa.2013.09.050; Nettleton DF, 2010, ARTIF INTELL REV, V33, P275, DOI 10.1007/s10462-010-9156-z; PRATI RC, 2013, P 2013 IEEE C EV COM, P2964; Prelic A, 2006, BIOINFORMATICS, V22, P1122, DOI 10.1093/bioinformatics/btl060; Rebbapragada U, 2007, LECT NOTES ARTIF INT, V4701, P708; Rider AK, 2013, LECT NOTES COMPUT SC, V8207, P380, DOI 10.1007/978-3-642-41398-8_33; Symeonidis P, 2008, INFORM RETRIEVAL, V11, P51, DOI 10.1007/s10791-007-9038-4; Tabassian M, 2012, EXPERT SYST APPL, V39, P1698, DOI 10.1016/j.eswa.2011.06.061; Tabassian M, 2012, KNOWL-BASED SYST, V27, P92, DOI 10.1016/j.knosys.2011.10.010; Wang XD, 2012, PATTERN RECOGN, V45, P4117, DOI 10.1016/j.patcog.2012.06.005; Witten I. H., 2005, DATA MINING PRACTICA; Wu XD, 2008, IEEE T SYST MAN CY A, V38, P917, DOI 10.1109/TSMCA.2008.923034; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8; Zhu XQ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1168; Zhu XQ, 2006, DATA MIN KNOWL DISC, V12, P275, DOI 10.1007/s10618-005-0012-8	50	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	JUL 15	2015	42	12					5065	5075		10.1016/j.eswa.2015.02.045		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	CH0XY	WOS:000353746900005		
J	Chen, DP; Mak, BKW				Chen, Dongpeng; Mak, Brian Kan-Wing			Multitask Learning of Deep Neural Networks for Low-Resource Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep neural network (DNN); low-resource speech recognition; multitask learning; universal grapheme set; universal phone set	HIDDEN MARKOV-MODELS; LANGUAGE	We propose a multitask learning (MTL) approach to improve low-resource automatic speech recognition using deep neural networks (DNNs) without requiring additional language resources. We first demonstrate that the performance of the phone models of a single low-resource language can be improved by training its grapheme models in parallel under the MTL framework. If multiple low-resource languages are trained together, we investigate learning a set of universal phones (UPS) as an additional task again in the MTL framework to improve the performance of the phone models of all the involved languages. In both cases, the heuristic guideline is to select a task that may exploit extra information from the training data of the primary task(s). In the first method, the extra information is the phone-to-grapheme mappings, whereas in the second method, the UPS helps to implicitly map the phones of the multiple languages among each other. In a series of experiments using three low-resource South African languages in the Lwazi corpus, the proposed MTL methods obtain significant word recognition gains when compared with single-task learning (STL) of the corresponding DNNs or ROVER that combines results from several STL-trained DNNs.	[Chen, Dongpeng; Mak, Brian Kan-Wing] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China	Chen, DP (reprint author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.	dpchen@cse.ust.hk; mak@cse.ust.hk			Research Grants Council of Hong Kong SAR, China [616513, 16206714]	This work was supported by the Research Grants Council of Hong Kong SAR, China, under Grants 616513 and 16206714. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Vincent Vanhoucke.	Baxter J, 2000, J ARTIF INTELL RES, V12, P149; BELLEGARDA JR, 1990, IEEE T ACOUST SPEECH, V38, P2033, DOI 10.1109/29.61531; Ben-David S, 2003, LECT NOTES ARTIF INT, V2777, P567, DOI 10.1007/978-3-540-45167-9_41; Bocchieri E, 2001, IEEE T SPEECH AUDI P, V9, P264, DOI 10.1109/89.906000; Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646; Byrne W, 2000, INT CONF ACOUST SPEE, P1029; Caruana R., 1997, THESIS CARNEGIE MELL, P2; Charoenpornsawat P., 2006, P HUM LANG TECHN C N, P17, DOI 10.3115/1614049.1614054; Chen D., 2014, P ICASSP, P5992; Cohen P., 1997, P AUT SPEECH REC UND, P591; Collobert R., 2008, P 25 INT C MACH LEAR, V307, P160; Cui X., 2014, P ICASSP, P5582; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI 10.1145/1014052.1014067; Fiscus J. G., 1997, P IEEE WORKSH AUT SP, P347; Gales MJF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P58; Ghoshal A, 2013, INT CONF ACOUST SPEE, P7319, DOI 10.1109/ICASSP.2013.6639084; Grezl F., 2014, P ICASSP, P7654; Heigold G, 2013, INT CONF ACOUST SPEE, P8619, DOI 10.1109/ICASSP.2013.6639348; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang JT, 2013, INT CONF ACOUST SPEE, P7304; Huang X. D., 1989, Computer Speech and Language, V3, DOI 10.1016/0885-2308(89)90020-X; Huang Y, 2013, IEEE IMAGE PROC, P2897; Hunnicutt S., 1993, P EUROSPEECH BERLIN, P763; Hwang MY, 1993, IEEE T SPEECH AUDI P, V1, P414; I. P. Association, 1999, HDB INT PHON ASS GUI; Imseng D, 2013, IEEE T AUDIO SPEECH, V21, P1713, DOI 10.1109/TASL.2013.2260150; KANTHAK S, 2002, ACOUST SPEECH SIG PR, P845; Ko T, 2014, SPEECH COMMUN, V56, P132, DOI 10.1016/j.specom.2013.01.010; Kohler J., 1996, P ICSLP; KOHLER J, 1998, ACOUST SPEECH SIG PR, P417; Le VB, 2009, IEEE T AUDIO SPEECH, V17, P1471, DOI 10.1109/TASL.2009.2021723; LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P599, DOI 10.1109/29.52701; Lin H, 2009, INT CONF ACOUST SPEE, P4333, DOI 10.1109/ICASSP.2009.4960588; Miao Y., 2013, P ICASSP, P7304; Min RQ, 2009, IEEE DATA MINING, P357, DOI 10.1109/ICDM.2009.27; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Parveen S., 2003, P EUROSPEECH, P1813; Povey D, 2010, INT CONF ACOUST SPEE, P4330, DOI 10.1109/ICASSP.2010.5495662; Saon G, 2012, IEEE T AUDIO SPEECH, V20, P43, DOI 10.1109/TASL.2011.2129911; Schukat-Talamazzini E. G., 1993, P EUR; Seltzer ML, 2013, INT CONF ACOUST SPEE, P6965, DOI 10.1109/ICASSP.2013.6639012; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stuker S., 2009, THESIS U KARLSRUHE K; Takahashi S., 1995, P IEEE INT C AC SPEE, V1, P520; Tang Y., 2013, ARXIV13060239V3CSLG; Tempest M. M., 2009, DICTIONARYMAKER 2 16; Thrun S., 1997, LEARNING LEARN; Tur G, 2006, INT CONF ACOUST SPEE, P585; Vu N. T., 2014, P ICASSP, P7639; Young S. J., 1993, P EUR C SPEECH COMM, V3, P2203; Yu D, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4409; Zhang Y., 2010, P 26 C UAI JUL; Zhong W., 2012, P ICML; ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7	56	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	JUL	2015	23	7					1172	1183		10.1109/TASLP.2015.2422573		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CK1YE	WOS:000356004800006		
J	Leng, B; Guo, S; Zhang, XY; Xiong, Z				Leng, Biao; Guo, Shuang; Zhang, Xiangyang; Xiong, Zhang			3D object retrieval with stacked local convolutional autoencoder	SIGNAL PROCESSING			English	Article						Object representation; Stacked local convolutional autoencoder; 3D object retrieval	MODEL RETRIEVAL; SHAPE DESCRIPTOR; RECOGNITION; SIMILARITY; GRAPH; REPRESENTATION; FRAMEWORK; MACHINE; SEARCH; SYSTEM	The success of object recognition and retrieval is largely determined by data representation. A good feature descriptor can detect the high-level abstraction of objects, which contains much discriminative information. In this paper, a novel 3D object retrieval method is proposed based on stacked local convolutional autoencoder (SLCAE). In this approach, the greedy layerwise strategy is applied to train SLCAE, and gradient descent method is used for training each layer. After the processing of training, the representations of input data can be obtained, regarded as the features of 3D objects. The experiments are conducted on three publicly available 3D object datasets, and the results demonstrate that the proposed method can greatly improve 3D object retrieval performance, compared with several state-of-the-art methods. (C) 2014 Elsevier B.V. All rights reserved.	[Leng, Biao; Guo, Shuang; Zhang, Xiangyang; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China	Leng, B (reprint author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.	lengbiao@buaa.edu.cn			National Natural Science Foundation of China [61103093, 61472023]; New Teachers' Fund for Doctor Stations from Ministry of Education [20111102120017]; National High-Tech Research and Development Plan of China (863) [2013AA01A601]	This work is supported by the National Natural Science Foundation of China (No. 61103093), (No. 61472023), the New Teachers' Fund for Doctor Stations from Ministry of Education (No. 20111102120017) and the National High-Tech Research and Development Plan of China (863) (No. 2013AA01A601).	Akgul CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25; Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bordes A., 2012, P INT C ART INT STAT, P127; Boulanger-Lewandowski N., 2012, P 29 INT C MACH LEAR, P1159; Bronstein AM, 2009, INT J COMPUT VISION, V81, P281, DOI 10.1007/s11263-008-0172-2; Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470; Collobert R., 2008, ICML, V307, P160, DOI DOI 10.1145/1390156.1390177; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gao Y, 2012, INFORM SCIENCES, V194, P224, DOI 10.1016/j.ins.2012.01.003; Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619; Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081; Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012; Gao Y, 2010, P ACM INT C MULT FIR, P955, DOI 10.1145/1873951.1874122; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Gao Y, 2014, IEEE MULTIMEDIA, V21, P52; Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006; Godil A., 2009, P EUR WORKSH 3D OBJ, P61; Goodfellow I., ARXIV12122686; Gupta R., 2011, P ACM INT C WEB SEAR, P217, DOI 10.1145/1935826.1935868; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Ji RR, 2010, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2010.5540118; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kim HJ, 2010, MULTIMED TOOLS APPL, V47, P7, DOI 10.1007/s11042-009-0404-7; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Larochelle H, 2012, J MACH LEARN RES, V13, P643; LeCun Y., 1989, GEN NETWORK DESIGN S; Leng B., 2014, P 20 ANN INT C MULT, P128; Leng B, 2007, J ZHEJIANG UNIV-SC A, V8, P1953, DOI 10.1631/jzus.2007.A1953; Leng B., 2014, NEUROCOMPUT IN PRESS; Leng B, 2007, LECT NOTES COMPUT SC, V4418, P93; Leng B, 2008, MULTIMED TOOLS APPL, V40, P135, DOI 10.1007/s11042-007-0188-6; Leng BA, 2009, CHINESE J ELECTRON, V18, P291; Leng BA, 2010, FRONT COMPUT SCI CHI, V4, P394, DOI 10.1007/s11704-010-0366-y; Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3; Li F, 2010, SIGNAL PROCESS-IMAGE, V25, P18, DOI 10.1016/j.image.2009.11.001; Li WJ, 2008, IEEE T IMAGE PROCESS, V17, P2236, DOI 10.1109/TIP.2008.2003404; Liu Y., 2006, P IEEE INT C SHAP MO, P16; Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x; Liu ZB, 2010, MULTIMEDIA SYST, V16, P319, DOI 10.1007/s00530-010-0193-x; Mademlis A, 2009, PATTERN RECOGN, V42, P2447, DOI 10.1016/j.patcog.2009.04.024; Martens J., 2013, ADV NEURAL INFORM PR, V26, P2877; Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6; Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026; Patane G, 2009, IEEE T VIS COMPUT GR, V15, P583, DOI 10.1109/TVCG.2009.22; Roux N. L., 2008, NEURAL COMPUT, V20, P1631; Rustamov RM, 2010, VISUAL COMPUT, V26, P1245, DOI 10.1007/s00371-010-0518-y; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034; Shilane P., 2004, P SHAPE MODEL APPL 2, V08540, P167; SOCHER R, 2011, ADV NEURAL INFORM PR, V24, P801; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Vranic D.V., 2005, P IEEE INT C MULT EX, P962; Xiao QK, 2008, ELECTRON LETT, V44, P847, DOI 10.1049/el:20080314; Zarpalas D., 2007, EURASIP J ADV SIGNAL; Zeng J., 2014, MULTIMED TO IN PRESS; Zhu KP, 2009, COMPUT AIDED DESIGN, V41, P28, DOI 10.1016/j.cad.2008.11.007	72	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684	1879-2677		SIGNAL PROCESS	Signal Process.	JUL	2015	112				SI		119	128		10.1016/j.sigpro.2014.09.005		10	Engineering, Electrical & Electronic	Engineering	CE6VN	WOS:000351976400013		
J	Liu, BY; Liu, J; Lu, HG				Liu, Bingyuan; Liu, Jing; Lu, Hanging			Learning representative and discriminative image representation by deep appearance and spatial coding	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article						Image classification; Deep learning; Structured sparsity	CLASSIFICATION; RECOGNITION; FEATURES	How to build a suitable image representation remains a critical problem in computer vision. Traditional Bag-of-Feature (BoF) based models build image representation by the pipeline of local feature extraction, feature coding and spatial pooling. However, three major shortcomings hinder the performance, i.e., the limitation of hand-designed features, the discrimination loss in local appearance coding and the lack of spatial information. To overcome the above limitations, in this paper, we propose a generalized BoF-based framework, which is hierarchically learned by exploring recently developed deep learning methods. First, with raw images as input, we densely extract local patches and learn local features by stacked Independent Subspace Analysis network. The learned features are then transformed to appearance codes by sparse Restricted Boltzmann Machines. Second, we perform spatial max-pooling on a set of over-complete spatial regions, which is generated by covering various spatial distributions, to incorporate more flexible spatial information. Third, a structured sparse Auto-encoder is proposed to explore the region representations into the image-level signature. To learn the proposed hierarchy, we layerwise pre-train the network in unsupervised manner, followed by supervised fine-tuning with image labels. Extensive experiments on different benchmarks, i.e., UIUC-Sports, Caltech-101, Caltech-256, Scene-15 and MIT Indoor-67, demonstrate the effectiveness of our proposed model. (C) 2015 Elsevier Inc. All rights reserved.	[Liu, Bingyuan; Liu, Jing; Lu, Hanging] CASIA, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Liu, J (reprint author), CASIA, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	jliu@nlpr.ia.ac.cn			973 Program [2012CB316304]; National Natural Science Foundation of China [61272329, 61472422, 61332016, 61273034]	This work was supported by 973 Program (2012CB316304) and National Natural Science Foundation of China (61272329, 61472422, 61332016 and 61273034).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bengio S., 2009, NIPS, P676; Boiman O., 2008, CVPR, P1; Boureau YL, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2651, DOI 10.1109/ICCV.2011.6126555; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Chatfield K., 2011, BMVC; Chen XY, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P834; Csurka G., 2004, ECCV, P1; Dalai N., 2005, INT C COMP VIS PATT, V1, P886, DOI DOI 10.1109/CVPR.2005.177; Dixit M, 2011, PROC CVPR IEEE, P937, DOI 10.1109/CVPR.2011.5995674; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Fei-Fei L., 2011, CVPR, P524; Feng J., 2011, CVPR, P2697; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Goh H., 2012, ECCV, P298; Griffin G., 2007, 7694 CAL I TECHN; Harada T, 2011, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR.2011.5995691; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang F, 2007, B ENTOMOL RES, V97, P1; Hyvrinen A., 2009, NATURAL IMAGE STAT; Jenatton R., 2010, ICML, P2297; Jia YQ, 2012, PROC CVPR IEEE, P3370; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Jurie F, 2005, IEEE I CONF COMP VIS, P604; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23, P1090; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q.V., 2011, CVPR, P3361; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Li L.-J., 2010, ECCV 2010 WORKSH PAR, V6553, P57; Li L.J., 2007, IEEE 11 INT C COMP V, P1; Li L.-J., 2010, P ADV NEUR INF PROC, V24, P1378; Lin D., 2014, CVPR, P3726; Liu D., 2008, CVPR; Liu LQ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2486; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J, 2010, ADV NEURAL INFORM PR, V23, P1558; Morioka N, 2010, LECT NOTES COMPUT SC, V6311, P692, DOI 10.1007/978-3-642-15549-9_50; Morioka N., 2010, BMVC; Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464; Perronnin F., 2007, CVPR; Quattoni A., 2006, CVPR, P413; Razavian A.S., 2014, CVPR 2014 WORKSH; Savarese S., 2006, CVPR, V2, P2033; Schmidt M.W., 2008, CVPR, V1, P1; Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093; Sharma G., 2011, BMVC; Todorovic S., 2008, CVPR; van Gemert J.C., 2010, ECCV, V32, P1271; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Xie L., 2014, CVPR, P3734; Yang JC, 2009, PROC CVPR IEEE, P1794; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958; Yu K, 2011, PROC CVPR IEEE, P1713; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeiler MD, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2018, DOI 10.1109/ICCV.2011.6126474; Zheng Y., 2012, ECCV, P172; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141; Zhou X., 2008, IEEE POW EN SOC GEN, P1, DOI 10.1109/GLOCOM.2008.ECP.573; Zhou X, 2009, IEEE I CONF COMP VIS, P1971	61	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142	1090-235X		COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	JUL	2015	136				SI		23	31		10.1016/j.cviu.2015.03.006		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CK3LE	WOS:000356116800004		
J	Lu, JW; Liong, VE; Wang, G; Moulin, P				Lu, Jiwen; Liong, Venice Erin; Wang, Gang; Moulin, Pierre			Joint Feature Learning for Face Recognition	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Face recognition; feature learning; joint learning; deep learning	PATTERNS; REPRESENTATION; IMAGE; CLASSIFICATION; VERIFICATION; SAMPLE; MODEL; SCALE; MAGNITUDES; EIGENFACES	This paper presents a new joint feature learning (JFL) approach to automatically learn feature representation from raw pixels for face recognition. Unlike many existing face recognition systems, where conventional feature descriptors, such as local binary patterns and Gabor features, are used for face representation, we propose an unsupervised feature learning method to learn hierarchical feature representation. Since different face regions have different physical characteristics, we propose to use different feature dictionaries to represent them, and to learn multiple yet related feature projection matrices for these regions simultaneously. Hence position-specific discriminative information can be exploited for face representation. Having learned these feature projections for different face regions, we perform spatial pooling for face patches within each region to enhance the representative power of the learned features. Moreover, we stack our JFL model into a deep architecture to exploit hierarchical information for feature representation and further improve the recognition performance. Experimental results on five widely used face data sets show the effectiveness of our proposed approach.	[Lu, Jiwen; Liong, Venice Erin; Wang, Gang; Moulin, Pierre] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Moulin, Pierre] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA	Lu, JW (reprint author), Adv Digital Sci Ctr, Singapore 138632, Singapore.	jiwen.lu@adsc.com.sg; venice.l@adsc.com.sg; wanggang@ntu.edu.sg; moulin@ifp.uiuc.edu			Human Cyber Security Systems Program within the Advanced Digital Sciences Center, Singapore, through the Agency for Science, Technology and Research, Singapore	This work was supported by the Human Cyber Security Systems Program within the Advanced Digital Sciences Center, Singapore, through the Agency for Science, Technology and Research, Singapore. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Zhenan Sun.	Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469; Arashloo S. R., 2013, P IEEE 6 INT C BIOM, P1; Barkan O., 2013, P IEEE INT C COMP VI, P1960; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Beveridge J. R., 2013, P IEEE 6 INT C BIOM, P1; Cao Q., 2013, P IEEE INT C COMP VI, P2408; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Chai ZH, 2014, IEEE T INF FOREN SEC, V9, P14, DOI 10.1109/TIFS.2013.2290064; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; Deng WH, 2014, PATTERN RECOGN, V47, P3738, DOI 10.1016/j.patcog.2014.06.020; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Deng WH, 2012, PATTERN RECOGN, V45, P4438, DOI 10.1016/j.patcog.2012.06.010; Deniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004; Evgeniou A, 2007, P ADV NEUR INF PROC, V19, P41; Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005; Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017; Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001; Gui J, 2014, IEEE T CIRC SYST VID, V24, P211, DOI 10.1109/TCSVT.2013.2273652; Gui J, 2010, ARTIF INTELL MED, V50, P181, DOI 10.1016/j.artmed.2010.05.004; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu J., 2014, P IEEE CVPR, P1875; Huang G. B., 2007, 0749 U MASS DEP COMP; Huang G. B., 2014, UMCS2014003; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Hussain S. U., 2012, P IEEE VEH TECHN C V, P1; Hyvarinen A., 2009, NATURAL IMAGE STAT, V39, P151, DOI 10.1007/978-1-84882-491-1_7; Kumar A., 2012, P 5 INT C BIOM NEW D, P1; Le Q.V., 2011, P ADV NEUR INF PROC, P1017; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; Lee H., 2006, ADV NEURAL INFORM PR, V19, P801; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JQ, 2014, EARTHQ ENG ENG VIB, V13, P13, DOI 10.1007/s11803-014-0208-2; Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70; Maturana D, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), DOI 10.1109/FG.2011.5771444; Maturana D., 2010, P 10 AS C COMP VIS A, P618; Mendez-Vazquez H., 2013, P ICB JUN, P1; Meng X, 2006, INT C PATT RECOG, P536; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Nguyen H.V., 2011, LNCS, V6493, P709; Ouyang WL, 2012, PROC CVPR IEEE, P3258; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rifai S., 2011, P 28 INT C MACH LEAR, P833; Schwartz WR, 2012, IEEE T IMAGE PROCESS, V21, P2245, DOI 10.1109/TIP.2011.2176951; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Sun Y., 2014, P NIPS, P1988; Sun Y., 2014, P IEEE C CVPR JUN, P1891; Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Verschae R., 2008, P WORKSH FAC REAL LI, P1; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866; Vu N.-S., 2011, P 2011 INT JOINT C B, P1; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wolf L, 2013, PROC CVPR IEEE, P3523, DOI 10.1109/CVPR.2013.452; Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang WC, 2005, IEEE I CONF COMP VIS, P786	70	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	JUL	2015	10	7					1371	1383		10.1109/TIFS.2015.2408431		13	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	CI7PK	WOS:000354956100005		
J	Luo, M; Yan, HC; Hu, B; Zhou, JH; Pang, CK				Luo, Ming; Yan, Heng-Chao; Hu, Bin; Zhou, Jun-Hong; Pang, Chee Khiang			A data-driven two-stage maintenance framework for degradation prediction in semiconductor manufacturing industries	COMPUTERS & INDUSTRIAL ENGINEERING			English	Article						Condition-based maintenance; Deterministic training; Equipment degradation prediction; Probabilistic training; Two-stage maintenance framework	NEURAL-NETWORK; GENETIC ALGORITHMS; LEARNING ALGORITHM; MODEL; PROGNOSTICS	To reduce the production costs and breakdown risks in industrial manufacturing systems, condition-based maintenance has been actively pursued for prediction of equipment degradation and optimization of maintenance schedules. In this paper, a two-stage maintenance framework using data-driven techniques under two training types will be developed to predict the degradation status in industrial applications. The proposed framework consists of three main blocks, namely, Primary Maintenance Block (PMB), Secondary Maintenance Block (SMB), and degradation status determination block. As the popular methods with deterministic training, back-propagation Neural Network (NN) and evolvable NN are employed in PMB for the degradation prediction. Another two data-driven methods with probabilistic training, namely, restricted Boltzmann machine and deep belief network are applied in SMB as the backup of PMB to model non-stationary processes with the complicated underlying characteristics. Finally, the multiple regression forecasting is adopted in both blocks to check prediction accuracies. The effectiveness of our proposed two-stage maintenance framework is testified with extensive computation and experimental studies on an industrial case of the wafer fabrication plant in semiconductor manufactories, achieving up to 74.1% in testing accuracies for equipment degradation prediction. (C) 2015 Elsevier Ltd. All rights reserved.	[Luo, Ming; Yan, Heng-Chao; Zhou, Jun-Hong] A STAR Singapore Inst Mfg Technol, Mfg Execut & Control Grp, Singapore, Singapore; [Yan, Heng-Chao; Hu, Bin; Pang, Chee Khiang] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore	Pang, CK (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore.	justinpang@nus.edu.sg			Singapore MOE AcRF Tier 1 [R-263-000-A52-112]	This work was supported in part by Singapore MOE AcRF Tier 1 Grant R-263-000-A52-112. The authors would like to thank Mr. G. Ramadoss from Department of Electrical and Computer Engineering, National University of Singapore, for his help in conducting some parts of simulation studies.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Ahmad R, 2012, COMPUT IND ENG, V63, P135, DOI 10.1016/j.cie.2012.02.002; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bose BK, 2007, IEEE T IND ELECTRON, V54, P14, DOI 10.1109/TIE.2006.888683; Chen CC, 2011, IEEE T IND ELECTRON, V58, P4353, DOI 10.1109/TIE.2010.2098369; Ghiassi M, 2009, COMPUT IND ENG, V57, P287, DOI 10.1016/j.cie.2008.11.027; Haykin S., 2007, NEURAL NETWORKS COMP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jardine AKS, 2006, MECH SYST SIGNAL PR, V20, P1483, DOI 10.1016/j.ymssp.2005.09.012; Lee J, 2006, COMPUT IND, V57, P476, DOI 10.1016/j.compind.2006.02.014; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Li RY, 2012, J INTELL MANUF, V23, P313, DOI 10.1007/s10845-009-0353-z; Liao WZ, 2012, INT J ADV MANUF TECH, V63, P51, DOI 10.1007/s00170-011-3884-3; Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609; Medjaher K, 2012, IEEE T RELIAB, V61, P292, DOI 10.1109/TR.2012.2194175; Montana DJ, 1989, P 11 INT JOINT C ART, V1, P762; Pacella M, 2011, COMPUT IND ENG, V60, P677, DOI 10.1016/j.cie.2010.12.024; Pang CK, 2011, AUTOM CONTROL ENG SE, P1; Salakhutdinov R., 2009, INT C ART INT STAT, P448; SHEU C, 1994, INT J PROD RES, V32, P1365, DOI 10.1080/00207549408957005; Tan C. M., 2011, 2011 INT C EL DEV SO, P1; Tian ZG, 2012, J INTELL MANUF, V23, P227, DOI 10.1007/s10845-009-0356-9; Tran VT, 2009, EXPERT SYST APPL, V36, P9378, DOI 10.1016/j.eswa.2009.01.007; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Wang GF, 2013, INT J ADV MANUF TECH, V66, P1921, DOI 10.1007/s00170-012-4470-z; Wang HQ, 2011, COMPUT IND ENG, V60, P511, DOI 10.1016/j.cie.2010.12.004; WHITLEY D, 1990, PARALLEL COMPUT, V14, P347, DOI 10.1016/0167-8191(90)90086-O; Zeidi JR, 2013, COMPUT IND ENG, V66, P1004, DOI 10.1016/j.cie.2013.08.015; Zou W., 2012, ADV NEURAL INFORM PR, V25, P3212	29	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0360-8352	1879-0550		COMPUT IND ENG	Comput. Ind. Eng.	JUL	2015	85						414	422		10.1016/j.cie.2015.04.008		9	Computer Science, Interdisciplinary Applications; Engineering, Industrial	Computer Science; Engineering	CK3JE	WOS:000356111600038		
J	Wu, BY; Lyu, SW; Hu, BG; Ji, Q				Wu, Baoyuan; Lyu, Siwei; Hu, Bao-Gang; Ji, Qiang			Multi-label learning with missing labels for image annotation and facial action unit recognition	PATTERN RECOGNITION			English	Article						Multi-label learning; Missing labels; Image annotation; Facial action unit recognition	SUPPORT VECTOR MACHINES; CLASSIFICATION	Many problems in computer vision, such as image annotation, can be formulated as multi-label learning problems. It is typically assumed that the complete label assignment for each training image is available. However, this is often not the case in practice, as many training images may only be annotated with a partial set of labels, either due to the intensive effort to obtain the fully labeled training set or the intrinsic ambiguities among the classes. In this work, we propose a method for multi-label learning that explicitly handles missing labels. We train classifiers with the multi-label with missing labels (MLML) learning framework by enforcing the consistency between the predicted labels and the provided labels as well as the local smoothness among the label assignments. Experiments on three benchmark data sets in image annotation and one benchmark data set in facial action unit recognition demonstrate the improved performance of our method in comparison of several state-of-the-art methods. (C) 2015 Elsevier Ltd. All rights reserved.	[Wu, Baoyuan; Hu, Bao-Gang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Lyu, Siwei] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA; [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Ji, Q (reprint author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	wubaoyuan1987@gmail.com; lsw@cs.albany.edu; bghu@nlpr.ia.ac.cn; qji@ecse.rpi.edu			China Scholarship Council (CSC); US National Science Foundation (NSF) [1145152]; US National Science Foundation Research Grant [CCF-1319800]; National Science Foundation Early Faculty Career Development (CAREER) Award [IIS-0953373]; National Natural Science Foundation of China (NSFC) [61273196]	The work was mostly completed when the first author was a visiting student at Rensselaer Polytechnic Institute (RPI), supported by a scholarship from China Scholarship Council (CSC). We thank CSC and RPI for their support. Qiang Ji is supported in part by a grant from the US National Science Foundation (NSF, No. 1145152). Siwei Lyu is supported in part by the US National Science Foundation Research Grant (CCF-1319800) and the National Science Foundation Early Faculty Career Development (CAREER) Award (IIS-0953373). Bao-Gang Hu and Baoyuan Wu are supported in part by the National Natural Science Foundation of China (NSFC, No. 61273196).	ARMIJO L, 1966, PAC J MATH, V16, P1; Bucak Serhat Selcuk, 2011, CVPR, P2801; Cabral Ricardo Silveira, 2011, NIPS, P190; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Chen Gang, 2008, SIAM INT C DAT MIN S, P410; Chen X., 2010, P ACM INT C MULT, P35, DOI DOI 10.1145/1873951.1873959; Chen XY, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P834; Cusano Claudio, 2003, EL IM 2004, P330; Gehrig Tobias, 2011, ICCV WORKSH, P2092; Goldberg A., 2010, ADV NEURAL INFORM PR, V23, P757; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Huiskes M. J., 2008, P 1 ACM INT C MULT I, P39, DOI DOI 10.1145/1460096.1460104; Jeon Jiwoon, 2003, SIGIR, P119; Jiang Bihan, 2011, FG WORKSH, P314; Kapoor Ashish, 2012, NIPS, P2654; Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477; Lucey P., 2010, COMP VIS PATT REC WO, P94; Maree R, 2005, PROC CVPR IEEE, P34; Mori Y., 1999, 1 INT WORKSH MULT IN; Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042; Rui S, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P322; Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008; Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022; Sun Yu-Yin, 2010, AAAI; Yan Tong, 2007, IEEE Transactions on Pattern Analysis and Machine Intelligence, V29, DOI 10.1109/TPAMI.2007.1094; Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Valstar MF, 2007, LECT NOTES COMPUT SC, V4796, P118; Valstar Michel Francois, 2011, FG, P921; von Ahn Luis, 2004, P SIGCHI C HUM FACT, V6, P319, DOI DOI 10.1145/985692.985733.ISBN; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wallace V., 1978, FACIAL ACTION CODING; Wang CH, 2009, PROC CVPR IEEE, P1643; Wu Fei, 2010, P 2010 ACM INT C MUL, P15; Xu Miao, 2013, NIPS, P2301; Xue XY, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P651; Yakhnenko Oksana, 2011, BMVC, P1; Yang Changbo, 2005, ICIP, V1, P1; Yang Yi, 2011, IJCAI, V2, P1589; Zelnik-Manor L., 2005, ADV NEURAL INFORM PR, V17, P1601; Zha Zheng-Jun, 2008, CVPR, P1; Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013; Zhang M. L, 2010, EUR C MACH LEARN PRI, V16, P999; Zhang ML, 2008, IEEE DATA MINING, P688, DOI 10.1109/ICDM.2008.27; Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495; Zhou Zhi-Hua, 2006, NIPS, P1609; Zhu Y., 2009, 3 INT C AFF COMP INT, P1	52	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	JUL	2015	48	7					2279	2289		10.1016/j.patcog.2015.01.022		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CF1UL	WOS:000352333300013		
J	Motlicek, P; Imseng, D; Potard, B; Garner, PN; Himawan, I				Motlicek, Petr; Imseng, David; Potard, Blaise; Garner, Philip N.; Himawan, Ivan			Exploiting foreign resources for DNN-based ASR	EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING			English	Article						Automatic speech recognition; Deep learning for speech; Acoustic model adaptation; Semi-supervised training	SPEECH RECOGNITION; ALGORITHM	Manual transcription of audio databases for the development of automatic speech recognition (ASR) systems is a costly and time-consuming process. In the context of deriving acoustic models adapted to a specific application, or in low-resource scenarios, it is therefore essential to explore alternatives capable of improving speech recognition results. In this paper, we investigate the relevance of foreign data characteristics, in particular domain and language, when using this data as an auxiliary data source for training ASR acoustic models based on deep neural networks (DNNs). The acoustic models are evaluated on a challenging bilingual database within the scope of the MediaParl project. Experimental results suggest that in-language (but out-of-domain) data is more beneficial than in-domain (but out-of-language) data when employed in either supervised or semi-supervised training of DNNs. The best performing ASR system, an HMM/GMM acoustic model that exploits DNN as a discriminatively trained feature extractor outperforms the best performing HMM/DNN hybrid by about 5 % relative (in terms of WER). An accumulated relative gain with respect to the MFCC-HMM/GMM baseline is about 30 % WER.	[Motlicek, Petr; Imseng, David; Potard, Blaise; Garner, Philip N.; Himawan, Ivan] Idiap Res Inst, Martigny, Switzerland	Motlicek, P (reprint author), Idiap Res Inst, Rue Marconi 19, Martigny, Switzerland.	motlicek@idiap.ch; dimseng@idiap.ch; bpotard@idiap.ch; garner@idiap.ch; ihimawan@idiap.ch			Samsung Electronics Co. Ltd., South Korea; Eurostars Programme by Eureka; European Community; EC FP7 "Speaker Identification integrated project" [607784]	The work was supported by Samsung Electronics Co. Ltd., South Korea, under the project "Multi-Lingual and Cross-Lingual Adaptation for Automatic Speech Recognition". The work was also partially supported by Eurostars Programme powered by Eureka and the European Community under the project "D-Box: A generic dialog box for multi-lingual conversational applications", and by EC FP7 "Speaker Identification integrated project" under grant agreement no. 607784. The authors would like to express their gratitude to the MediaParl project, funded by the Parliament Service of the State of Valais, Switzerland for their financial support and for providing access to the audio-video recordings.	Athineos M, 2003, P ASRU, P261; Bourlard H, 1994, CONTINUOUS SPEECH RE; Cohen J, 2007, ASRU IEEE WORKSH AUT, P237, DOI 10.1109/ASRU.2007.4430115; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Dau-Cheng L, 2010, P INT, P1986; Erhan D, 2010, J MACH LEARN RES, V11, P625; Erhan D., 2009, P 12 INT C ART INT S, V5, P153; Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043; Gales MJF, 1997, CUEDFINFENGTR291; Galliano S, 2006, P INT C LANG RES EV; Ganapathy S, 2009, IEEE WORKSH APPL SIG, P341; Ganapathy S, 2009, J ACOUST SOC AM, V125, pEL8, DOI 10.1121/1.3040022; Gauvain J-L, 1993, P ICASSP, V2, P558; Ghoshal A, 2013, INT CONF ACOUST SPEE, P7319, DOI 10.1109/ICASSP.2013.6639084; Grezl F., 2009, P INT, V9, P2947; Grezl F, 2011, P ASRU, P359; Hermansky H, 2003, P ASRU, P255; HERMANSKY H, 2000, P ICASSP, P1635; Hinton G, 2010, 2010003 UTML TR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HOCHBERG MM, 1995, P IEEE INT C AC SPEE, P69; Huang JT, 2013, INT CONF ACOUST SPEE, P7304; Huang Y, 2013, P INT, P2360; Imseng D, 2014, SPEECH COMMUN, V56, P142, DOI 10.1016/j.specom.2013.01.007; IMSENG D, 2012, P IEEE WORKSH SPOK L, P263; Imseng D, 2014, P IEEE INT C AC SPEE, P2322; IMSENG D, 2013, P IEEE WORKSH AUT SP, P332; Kingsbury B, 1997, P INT C AC SPEECH SI, V2, P1259; Koehn Philipp, 2005, P MT SUMM 10 PHUK TH, P79; Kusumoto A, 2005, SPEECH COMMUN, V45, P101, DOI 10.1016/j.specom.2004.06.003; Lamel LF, 1991, P EUR C SPEECH COMM, P505; Matsoukas S, 1997, DARPA SPEECH REC WOR; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Novak J, 2012, P INT, P2526; Ochiai T, 2014, IEEE INT C AC SPEECH, P6349; Perennou G, 1986, P ICASSP, V11, P325; POVEY D, 2002, P ICASSP, P105; Povey D, 2005, P INT, P2977; Povey D, 2008, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2008.4518545; POVEY D, 2005, P ICASSP 05, V1, P961, DOI 10.1109/ICASSP.2005.1415275; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rabiner LR, 1986, IEEE ASSP MAGAZINE, P5; Schiel F, 2013, AUSSPRACHE LEXIKON P; Swietojanski P, 2014, P IEEE WORKSH SPOK L; Swietojanski P, 2013, P IEEE WORKSH AUT SP, DOI [10.1109/ASRU.2013.6707744, DOI 10.1109/ASRU.2013.6707744]; SWIETOJANSKI P, 2012, P SLT, P246; THOMAS S, 2013, P ICASSP, P6704; THOMAS S, 2010, P INTERSPEECH, P877; Thomas S, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4269; VESELY K, 2013, P ASRU, P267; Vesely K, 2013, INTERSPEECH, P2345; VESELY K, 2012, IEEE SPOK LANG TECHN, P336; Vu NT, 2010, P IEEE WORKSH SPOK L, P183; Wells JC, 2013, SAMPA COMPUTER READA; Young SJ, 1994, P ARPA HUM LANG TECH, P307, DOI DOI 10.3115/1075812.1075885; Yu D, 2010, NIPS 2010 WORKSH DEE	56	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	1687-4722			EURASIP J AUDIO SPEE	EURASIP J. Audio Speech Music Process.	JUN 26	2015									17	10.1186/s13636-015-0058-5		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CL9TR	WOS:000357321500001		
J	Dieleman, S; Willett, KW; Dambre, J				Dieleman, Sander; Willett, Kyle W.; Dambre, Joni			Rotation-invariant convolutional neural networks for galaxy morphology prediction	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods: data analysis; techniques: image processing; catalogues; galaxies: general	DIGITAL-SKY-SURVEY; ESTIMATING PHOTOMETRIC REDSHIFTS; ZOO; CLASSIFICATION; STAR; RECOGNITION; EXTRACTION; DEPENDENCE; FRACTION; SAMPLE	Measuring the morphological parameters of galaxies is a key requirement for studying their formation and evolution. Surveys such as the Sloan Digital Sky Survey have resulted in the availability of very large collections of images, which have permitted population-wide analyses of galaxy morphology. Morphological analysis has traditionally been carried out mostly via visual inspection by trained experts, which is time consuming and does not scale to large (greater than or similar to 10(4)) numbers of images. Although attempts have been made to build automated classification systems, these have not been able to achieve the desired level of accuracy. The Galaxy Zoo project successfully applied a crowdsourcing strategy, inviting online users to classify images by answering a series of questions. Unfortunately, even this approach does not scale well enough to keep up with the increasing availability of galaxy images. We present a deep neural network model for galaxy morphology classification which exploits translational and rotational symmetry. It was developed in the context of the Galaxy Challenge, an international competition to build the best model for morphology classification based on annotated images from the Galaxy Zoo project. For images with high agreement among the Galaxy Zoo participants, our model is able to reproduce their consensus with near-perfect accuracy (> 99 per cent) for most questions. Confident model predictions are highly accurate, which makes the model suitable for filtering large collections of images and forwarding challenging images to experts for manual annotation. This approach greatly reduces the experts' workload without affecting accuracy. The application of these algorithms to larger sets of training data will be critical for analysing results from future surveys such as the Large Synoptic Survey Telescope.	[Dieleman, Sander; Dambre, Joni] Univ Ghent, Elect & Informat Syst Dept, B-9000 Ghent, Belgium; [Willett, Kyle W.] Univ Minnesota, Sch Phys & Astron, Minneapolis, MN 55455 USA	Dieleman, S (reprint author), Univ Ghent, Elect & Informat Syst Dept, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.	sander.dieleman@ugent.be; willett@physics.umn.edu			Winton Capital; UMN; Alfred P. Sloan Foundation; National Science Foundation; U.S. Department of Energy; National Aeronautics and Space Administration; Japanese Monbukagakusho; Max Planck Society; Higher Education Funding Council for England; American Museum of Natural History; Astrophysical Institute Potsdam; University of Basel; University of Cambridge; Case Western Reserve University; University of Chicago; Drexel University; Fermilab; Institute for Advanced Study; Japan Participation Group; Johns Hopkins University; Joint Institute for Nuclear Astrophysics; Kavli Institute for Particle Astrophysics and Cosmology; Korean Scientist Group; Chinese Academy of Sciences (LAMOST); Los Alamos National Laboratory; Max-Planck-Institute for Astronomy (MPIA); Max-Planck-Institute for Astrophysics (MPA); New Mexico State University; Ohio State University; University of Pittsburgh; University of Portsmouth; Princeton University; United States Naval Observatory; University of Washington	We would like to thank Pieter-Jan Kindermans, Francis wyffels, Aaron van den Oord, Pieter Buteneers, Chris Lintott, Philip Marshall and the anonymous reviewer for their valuable feedback. We would like to acknowledge Joyce Noah-Vanhoucke, Chris Lintott, David Harvey, Thomas Kitching and Philip Marshall for their help in designing the Kaggle Galaxy Challenge. We thank Winton Capital for their financial support of the competition, and the Galaxy Zoo volunteers for providing the original morphology classifications. Their efforts are individually acknowledged at http://authors.galaxyzoo.org. KWW is supported in part by a UMN Grant-in-Aid. Funding for the SDSS and SDSS-II has been provided by the Alfred P. Sloan Foundation, the Participating Institutions, the National Science Foundation, the U.S. Department of Energy, the National Aeronautics and Space Administration, the Japanese Monbukagakusho, the Max Planck Society, and the Higher Education Funding Council for England. The SDSS Web Site is http://www.sdss.org/.The SDSS is managed by the Astrophysical Research Consortium for the Participating Institutions. The Participating Institutions are the American Museum of Natural History, Astrophysical Institute Potsdam, University of Basel, University of Cambridge, Case Western Reserve University, University of Chicago, Drexel University, Fermilab, the Institute for Advanced Study, the Japan Participation Group, Johns Hopkins University, the Joint Institute for Nuclear Astrophysics, the Kavli Institute for Particle Astrophysics and Cosmology, the Korean Scientist Group, the Chinese Academy of Sciences (LAMOST), Los Alamos National Laboratory, the Max-Planck-Institute for Astronomy (MPIA), the Max-Planck-Institute for Astrophysics (MPA), New Mexico State University, Ohio State University, University of Pittsburgh, University of Portsmouth, Princeton University, the United States Naval Observatory, and the University of Washington.	Ball NM, 2004, MON NOT R ASTRON SOC, V348, P1038, DOI 10.1111/j.1365-2966.2004.07429.x; Bamford SP, 2009, MON NOT R ASTRON SOC, V393, P1324, DOI 10.1111/j.1365-2966.2008.14252.x; Banerji M, 2010, MON NOT R ASTRON SOC, V406, P342, DOI 10.1111/j.1365-2966.2010.16713.x; Bastien F, 2012, DEEP LEARN UNS FEAT; Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_26; Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349; Bengio Y, 2007, TECHNICAL REPORT; Bergstra J, 2010, P PYTH SCI COMP C SC, V4, P3; Bertin E., 1994, SCI ASTRONOMICAL NEA, P49; Bertin E, 1996, ASTRON ASTROPHYS SUP, V117, P393, DOI 10.1051/aas:1996164; Bishop Christopher M., 2006, PATTERN RECOGNITION, V1; Boureau Y.-L., 2010, P 27 INT C MACH LEAR, P111; Bruna J., 2014, INT C LEARN REPR BAN; Clery D, 2011, SCIENCE, V333, P173, DOI 10.1126/science.333.6039.173; Collister AA, 2004, PUBL ASTRON SOC PAC, V116, P345, DOI 10.1086/383254; Darg DW, 2010, MON NOT R ASTRON SOC, V401, P1043, DOI 10.1111/j.1365-2966.2009.15686.x; de la Calleja J, 2004, MON NOT R ASTRON SOC, V349, P87, DOI 10.1111/j.1365-2966.2004.07442.x; Firth AE, 2003, MON NOT R ASTRON SOC, V339, P1195, DOI 10.1046/j.1365-8711.2003.06271.x; Folkes SR, 1996, MON NOT R ASTRON SOC, V283, P651; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gens R., 2014, ADV NEUR INF PROC SY, P2537; Glorot X., 2011, P 14 INT C ART INT S, V15, P315; Goodfellow I. J., 2013, P 30 INT C MACH LEAR, P1319; Gori S, 2006, VISION RES, V46, P3267, DOI 10.1016/j.visres.2006.03.009; Haussler B, 2013, MON NOT R ASTRON SOC, V430, P330, DOI 10.1093/mnras/sts633; Hinton G. E., 2012, TECHNICAL REPORT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S., 2001, GRADIENT FLOW RECURR; Huertas-Company M, 2011, ASTRON ASTROPHYS, V525, DOI 10.1051/0004-6361/201015735; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Kuminski E, 2014, PUBL ASTRON SOC PAC, V126, P959; Lahav O, 1996, MON NOT R ASTRON SOC, V283, P207; LAHAV O, 1995, SCIENCE, V267, P859, DOI 10.1126/science.267.5199.859; Land K, 2008, MON NOT R ASTRON SOC, V388, P1686, DOI 10.1111/j.1365-2966.2008.13490.x; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lintott C, 2011, MON NOT R ASTRON SOC, V410, P166, DOI 10.1111/j.1365-2966.2010.17432.x; Lintott CJ, 2009, MON NOT R ASTRON SOC, V399, P129, DOI 10.1111/j.1365-2966.2009.15299.x; Lintott CJ, 2008, MON NOT R ASTRON SOC, V389, P1179, DOI 10.1111/j.1365-2966.2008.13689.x; Mairal J., 2014, ADV NEUR INF PROC SY, P2627; Masters KL, 2010, MON NOT R ASTRON SOC, V405, P783, DOI 10.1111/j.1365-2966.2010.16503.x; Masters KL, 2011, MON NOT R ASTRON SOC, V411, P2026, DOI 10.1111/j.1365-2966.2010.17834.x; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Melvin T, 2014, MON NOT R ASTRON SOC, V438, P2882, DOI 10.1093/mnras/stt2397; NAIM A, 1995, MON NOT R ASTRON SOC, V275, P567; Nair V., 2010, P 27 INT C MACH LEAR, P807; Odewahn S., 1992, DIGITISED OPTICAL SK, P215; Orlov N, 2008, PATTERN RECOGN LETT, V29, P1684, DOI 10.1016/j.patrec.2008.04.013; Polsterer KL, 2012, ASTR SOC P, V461, P561; Razavian A. S., 2014, COMP VIS PATT REC WO, P512; Schawinski K, 2009, MON NOT R ASTRON SOC, V396, P818, DOI 10.1111/j.1365-2966.2009.14793.x; Shamir L, 2009, MON NOT R ASTRON SOC, V399, P1367, DOI 10.1111/j.1365-2966.2009.15366.x; Shamir L, 2013, ASTRON COMPUT, V2, P67, DOI 10.1016/j.ascom.2013.09.002; Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163; Simmons BD, 2013, MON NOT R ASTRON SOC, V429, P2199, DOI 10.1093/mnras/sts491; Simonyan K., 2015, INT C LEARN REPR SAN; Skibba RA, 2009, MON NOT R ASTRON SOC, V399, P966, DOI 10.1111/j.1365-2966.2009.15334.x; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Storrie-Lombardi M. C., 1992, MNRAS, V259, P8; Sutskever I., 2013, J MACHINE LEARNING R, P1139; Szegedy C., 2014, ARXIV14094842; van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453; Willett KW, 2013, MON NOT R ASTRON SOC, V435, P2835, DOI 10.1093/mnras/stt1458; Willett KW, 2015, MON NOT R ASTRON SOC, V449, P820, DOI 10.1093/mnras/stv307; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53	65	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0035-8711	1365-2966		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	JUN 21	2015	450	2					1441	1459		10.1093/mnras/stv632		19	Astronomy & Astrophysics	Astronomy & Astrophysics	CK6LB	WOS:000356338500023		
J	Zhu, SH; Li, XX; Shen, SH				Zhu, Songhao; Li, Xiangxiang; Shen, Shuhan			Multimodal deep network learning-based image annotation	ELECTRONICS LETTERS			English	Article								Multilabel image annotation is one of the most important open problems in the computer vision field. Unlike existing works that usually use conventional visual features to annotate images, features based on deep learning have shown potential to achieve outstanding performance. A multimodal deep learning framework is proposed, which aims to optimally integrate multiple deep neural networks pre-trained with convolutional neural networks. In particular, the proposed framework explores a unified two-stage learning scheme that consists of (i) learning to fune-tune the parameters of the deep neural network with respect to each individual modality and (ii) learning to find the optimal combination of diverse modalities simultaneously in a coherent process. Experiments conducted on a variety of public datasets.	[Zhu, Songhao; Li, Xiangxiang; Shen, Shuhan] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Jiangsu, Peoples R China	Zhu, SH (reprint author), Nanjing Univ Posts & Telecommun, Sch Automat, Xianlin Campus, Nanjing 210046, Jiangsu, Peoples R China.	zhush@njupt.edu.cn			Postdoctoral Foundation of China [2014M550297]; Postdoctoral Foundation of Jiangsu Province [1302087B]	This work was supported by the Postdoctoral Foundation of China (No. 2014M550297), and the Postdoctoral Foundation of Jiangsu Province (No. 1302087B).	Bianchi N., 2006, PREDICTION LEARNING; Dong C., 2014, EUR C COMP VIS ZUR G, V8692, P184; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kiros R., 2012, IEEE C NEUR INF PROC, V25, P917; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019	5	0	0	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194	1350-911X		ELECTRON LETT	Electron. Lett.	JUN 11	2015	51	12					905	906		10.1049/el.2015.0258		2	Engineering, Electrical & Electronic	Engineering	CJ7KT	WOS:000355674600013		
J	Floren, A; Naylor, B; Miikkulainen, R; Ress, D				Floren, Andrew; Naylor, Bruce; Miikkulainen, Risto; Ress, David			Accurately decoding visual information from fMRI data obtained in a realistic virtual environment	FRONTIERS IN HUMAN NEUROSCIENCE			English	Article						fMRI BOLD; machine learning; human vision; virtual environments; natural stimuli	SUPPORT VECTOR MACHINES; TOPOGRAPHIC REPRESENTATION; FEEDFORWARD NETWORKS; COGNITIVE STATES; PARIETAL CORTEX; BRAIN; CLASSIFICATION; ALGORITHM; NUMEROSITY; REGRESSION	Three-dimensional interactive virtual environments (VEs) are a powerful tool for brain-imaging based cognitive neuroscience that are presently under-utilized. This paper presents machine-learning based methods for identifying brain states induced by realistic VEs with improved accuracy as well as the capability for mapping their spatial topography on the neocortex. VEs provide the ability to study the brain under conditions closer to the environment in which humans evolved, and thus to probe deeper into the complexities of human cognition. As a test case, we designed a stimulus to reflect a military combat situation in the Middle East, motivated by the potential of using real-time functional magnetic resonance imaging (fMRI) in the treatment of post-traumatic stress disorder. Each subject experienced moving through the virtual town where they encountered 1-6 animated combatants at different locations, while fMRI data was collected. To analyze the data from what is, compared to most studies, more complex and less controlled stimuli, we employed statistical machine learning in the form of Multi-Voxel Pattern Analysis (MVPA) with special attention given to artificial Neural Networks (NN). Extensions to NN that exploit the block structure of the stimulus were developed to improve the accuracy of the classification, achieving performances from 58 to 93% (chance was 16.7%) with six subjects. This demonstrates that MVPA can decode a complex cognitive state, viewing a number of characters, in a dynamic virtual environment. To better understand the source of this information in the brain, a novel form of sensitivity analysis was developed to use NN to quantify the degree to which each voxel contributed to classification. Compared with maps produced by general linear models and the searchlight approach, these sensitivity maps revealed a more diverse pattern of information relevant to the classification of cognitive state.	[Floren, Andrew] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Naylor, Bruce] Univ Texas Austin, Dept Neurosci, Austin, TX 78712 USA; [Miikkulainen, Risto] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA; [Ress, David] Baylor Coll Med, Human Neuroimaging Lab, Houston, TX 77030 USA	Floren, A (reprint author), Univ Texas Austin, Ctr Learning & Memory, Dept Elect & Comp Engn, 100 E 24th St,Stop C7000, Austin, TX 78712 USA.	afloren@utexas.edu			Army Research Office [W911NF-12-1-0160]	The work reported in this paper was financially supported by the Army Research Office (W911NF-12-1-0160).	Baeck A, 2013, NEUROIMAGE, V70, P37, DOI 10.1016/j.neuroimage.2012.12.023; Bishop CM, 2006, PATTERN RECOGNITION; Cabral C, 2012, PATTERN RECOGN, V45, P2064, DOI 10.1016/j.patcog.2011.04.015; Cirsan D., 2012, NEURAL NETWORKS, V32, P333, DOI [10.1016/j.neunet.2012.02.023, DOI 10.1016/J.NEUNET.2012.02.023]; Cortes C, 1995, LEARNING, V20, P273; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Martino F, 2008, NEUROIMAGE, V43, P44, DOI 10.1016/j.neuroimage.2008.06.037; Duda R.O., 1973, PATTERN CLASSIFICATI, V3; Efron B., 1979, ANN STAT, V1, P1, DOI 10.1214/aos/1176344552; Fan Y., 2006, C COMP VIS PATT REC, DOI [10.1109/CVPRW.2006.64, DOI 10.1109/CVPRW.2006.64]; Formisano E, 2008, MAGN RESON IMAGING, V26, P921, DOI 10.1016/j.mri.2008.01.052; Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318; Friston K. J., 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Gebuis T, 2014, TRENDS COGN SCI, V18, P1, DOI 10.1016/j.tics.2013.10.002; Gerardi M, 2008, J TRAUMA STRESS, V21, P209, DOI 10.1002/jts.20331; Glover GH, 1999, NEUROIMAGE, V9, P416, DOI 10.1006/nimg.1998.0419; Goncalves R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048469; Griswold MA, 2002, MAGNET RESON MED, V47, P1202, DOI 10.1002/mrm.10171; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hanke M, 2009, NEUROINFORMATICS, V7, P37, DOI 10.1007/s12021-008-9041-y; Hanson SJ, 2004, NEUROIMAGE, V23, P156, DOI 10.1016/j.neuroimage.2004.05.020; Harvey BM, 2013, SCIENCE, V341, P1123, DOI 10.1126/science.1239052; Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hsu C.W., 2010, TECHNICAL REPORT, V1, P1; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103; KUKKONEN H, 1993, VISION RES, V33, P1431, DOI 10.1016/0042-6989(93)90049-3; Marsh R, 2010, NEUROPSYCHOLOGIA, V48, P2912, DOI 10.1016/j.neuropsychologia.2010.05.033; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Mueller C, 2012, J NEUROSCI METH, V209, P290, DOI 10.1016/j.jneumeth.2012.06.025; Nestares O, 2000, MAGNET RESON MED, V43, P705, DOI 10.1002/(SICI)1522-2594(200005)43:5<705::AID-MRM13>3.0.CO;2-R; Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005; Ojala M, 2010, J MACH LEARN RES, V11, P1833; Op de Beeck HP, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00078; Pereira F, 2009, NEUROIMAGE, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007; POOR HV, 1980, IEEE T AUTOMAT CONTR, V25, P531, DOI 10.1109/TAC.1980.1102349; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Rickard TC, 2000, NEUROPSYCHOLOGIA, V38, P325, DOI 10.1016/S0028-3932(99)00068-8; Sayres R, 2008, J NEUROPHYSIOL, V100, P249, DOI 10.1152/jn.01383.2007; Scheffe H., 1959, ANAL VARIANCE, V72; Schindler A, 2013, CURR BIOL, V23, P177, DOI 10.1016/j.cub.2012.11.060; Shinkareva SV, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001394; Spiers HJ, 2007, TRENDS COGN SCI, V11, P356, DOI 10.1016/j.tics.2007.06.002; Spiers HJ, 2007, NEUROIMAGE, V36, P245, DOI 10.1016/j.neuroimage.2007.02.032; Valente G, 2011, NEUROIMAGE, V56, P651, DOI 10.1016/j.neuroimage.2010.09.062; Weston J., 1999, ESANN, V99, P61; Worsley K. J., 2001, FUNCTIONAL MRI INTRO, P445; Zurada J.M., 1994, CIRCUITS SYSTEMS, V6, P447, DOI DOI 10.1109/ISCAS.1994.409622	53	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5161			FRONT HUM NEUROSCI	Front. Hum. Neurosci.	JUN 9	2015	9								UNSP 327	10.3389/fnhum.2015.00327		13	Neurosciences; Psychology	Neurosciences & Neurology; Psychology	CK4EG	WOS:000356173300001	26106315	
J	Arevalo, J; Cruz-Roa, A; Arias, V; Romero, E; Gonzalez, FA				Arevalo, John; Cruz-Roa, Angel; Arias, Viviana; Romero, Eduardo; Gonzalez, Fabio A.			An unsupervised feature learning framework for basal cell carcinoma image analysis	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						Digital pathology; Representation learning; Unsupervised feature learning; Basal cell carcinoma	INDEPENDENT COMPONENT ANALYSIS; PROSTATE-CANCER; CLASSIFICATION; HISTOLOGY; MODEL; BAG	Objective: The paper addresses the problem of automatic detection of basal cell carcinoma (BCC) in histopathology images. In particular, it proposes a framework to both, learn the image representation in an unsupervised way and visualize discriminative features supported by the learned model. Materials and methods: This paper presents an integrated unsupervised feature learning (UFL) framework for histopathology image analysis that comprises three main stages: (1) local (patch) representation learning using different strategies (sparse autoencoders, reconstruct independent component analysis and topographic independent component analysis (TICA), (2) global (image) representation learning using a bag-of-features representation or a convolutional neural network, and (3) a visual interpretation layer to highlight the most discriminant regions detected by the model. The integrated unsupervised feature learning framework was exhaustively evaluated in a histopathology image dataset for BCC diagnosis. Results: The experimental evaluation produced a classification performance of 98.1%, in terms of the area under receiver-operating-characteristic curve, for the proposed framework outperforming by 7% the state-of-the-art discrete cosine transform patch-based representation. Conclusions: The proposed UFL-representation-based approach outperforms state-of-the-art methods for BCC detection. Thanks to its visual interpretation layer, the method is able to highlight discriminative tissue regions providing a better diagnosis support. Among the different UFL strategies tested, TICA-learned features exhibited the best performance thanks to its ability to capture low-level invariances, which are inherent to the nature of the problem. (C) 2015 Elsevier B.V. All rights reserved.	[Arevalo, John; Cruz-Roa, Angel; Gonzalez, Fabio A.] Univ Nacl Colombia, Fac Engn, Syst & Comp Engn Dept, Machine Learning Percept & Discovery Lab, Bogota, Colombia; [Arias, Viviana] Univ Nacl Colombia, Fac Med, Dept Pathol, Bogota, Colombia; [Romero, Eduardo] Univ Nacl Colombia, Fac Med, Comp Imaging & Med Applicat Lab, Bogota, Colombia	Gonzalez, FA (reprint author), Univ Nacl Colombia, Fac Engn, Syst & Comp Engn Dept, Machine Learning Percept & Discovery Lab, Cra 30 45 03 Ciudad Univ,Bldg 453 Off 114, Bogota, Colombia.	jearevaloo@unal.edu.co; aacruzr@unal.edu.co; vlariasp@unal.edu.co; edromero@unal.edu.co; fagonzalezo@unal.edu.co			Microsoft Research LACCIR [R1212LAC006]; Colciencias [1225-569-34920, 0213-2013, 528/2011, 617/2013]	This work was partially funded by projects "Multimodal Image Retrieval to Support Medical Case-Based Scientific Literature Search", ID R1212LAC006 by Microsoft Research LACCIR, "Diseno implementacion de un sistema de computo sobre recursos heterogeneos para la identificacion de estructuras atmosfericas en prediccion climatologica" number 1225-569-34920 through Colciencias contract number 0213-2013 and "Convocatorial del programa nacional de proyectos para el fortalecimiento de la investigacion, la creacion y la innovacion en posgrados de la Universidad Nacional de Colombia 2013-2015" with proposal number 18722. Cruz-Roa also thanks Colciencias for its support through a doctoral grant in call 528/2011. Arevalo also thanks Colciencias for its support through a doctoral grant in call 617/2013. The authors also thank for K40 Tesla GPU donated by NVIDIA and which was used for some feature learning experiments.	ALBERT R, 1992, CYTOMETRY, V13, P759, DOI 10.1002/cyto.990130712; Chin L, 2008, NATURE, V455, P1061, DOI 10.1038/nature07385; Arevalo J, 2013, 9 INT SEM MED INF PR; Basavanhally A, 2013, IEEE T BIO-MED ENG, V60, P2089, DOI 10.1109/TBME.2013.2245129; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bilgin C, 2007, P ANN INT IEEE EMBS, P5311, DOI 10.1109/IEMBS.2007.4353540; Boucheron L, 2008, THESIS U CALIFORNIA; Caicedo JC, 2008, LECT NOTES COMPUT SC, V4993, P51, DOI 10.1007/978-3-540-68636-1_6; Caicedo JC, 2009, LECT NOTES ARTIF INT, V5651, P126, DOI 10.1007/978-3-642-02976-9_17; Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51; Coates A, 2010, P 14 INT C ART INT S, P215; Coates A, 2013, P 30 INT C MACH LEAR; Collobert R, 2011, BIGLEARN; Cristianini N., 2000, INTRO SUPPORT VECTOR; Cruz-Roa A, 2011, 6 COL COMP C CCC, P1; Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872; Cruz-Roa A., 2012, LECT NOTES COMPUT SC, V7510, P157; Cruz-Roa A, 2011, J PATHOL INFORM, V2; Cruz-Roa A, 2011, ARTIF INTELL MED, V52, P91, DOI 10.1016/j.artmed.2011.04.010; Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50; Dean J, 2012, ADV NEURAL INFORM PR, V25, P1223; Diaz G, 2010, LECT NOTES COMPUT SC, V6419, P55; Diaz G, 2011, MICROSC RES TECHNIQ, V75, P343; Doyle S, 2006, LECT NOTES COMPUT SC, V4191, P504; Doyle S, 2007, I S BIOMED IMAGING, P1284, DOI 10.1109/ISBI.2007.357094; Duan KB, 2003, LECT NOTES COMPUT SC, V2709, P125; Erhan D, 2009, VISUALIZING HIGHER L; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Field DJ, 1989, HUMAN VISION VISUAL, P269; Fletcher C, 2007, DIAGNOSTIC HISTOPATH, V3rd; Fuchs TJ, 2011, COMPUT MED IMAG GRAP, V35, P515, DOI 10.1016/j.compmedimag.2011.02.006; Goodfellow IJ, 2013, ARXIV13084214; Gurcan M. N., 2009, BIOMED ENG IEEE REV, V2, P147; Gutierrez R, 2011, DIAGN PATHOL, V6, DOI 10.1186/1746-1596-6-26; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; He L, 2012, COMPUT METH PROG BIO, V107, P538, DOI 10.1016/j.cmpb.2011.12.007; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2001, NEURAL COMPUT, V13, P1527, DOI 10.1162/089976601750264992; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Jia V, 2014, P ACM INT C MULT, P675; Jolliffe I.T., 2002, PRINCIPAL COMPONENT; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Le Q, 2012, 9 IEEE INT S BIOM IM; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI 10.1109/CVPR.2011.5995496; Le Q, 2011, ADV NEURAL INFORM PR, V24, P1017; Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2012, LECT NOTES COMPUTER, V7583, P496; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Madabhushi A., 2009, IMAGING MED, V1, P7, DOI 10.2217/iim.09.9; Malon C, 2008, Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology 2008. In Memory of Professor Yasuhiko Dote, DOI 10.1145/1456223.1456316; Malon Christopher D, 2013, J Pathol Inform, V4, P9, DOI 10.4103/2153-3539.112694; Marinelli RJ, 2008, NUCLEIC ACIDS RES, V36, pD871, DOI 10.1093/nar/gkm861; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Miller SJ, 2010, J NATL COMPR CANC NE, V8, P836; Montavon G, 2009, THESIS EPFL SWITZERL; Pang B, 2010, CCPR, P1; Raina R., 2007, LEARNING, P759; Rajpoot N, 2007, P BRIT MACH VIS C 20; Rennie JDM, 2005, REGULARIZED LOGISTIC; Roux Ludovic, 2013, J Pathol Inform, V4, P8, DOI 10.4103/2153-3539.112693; Seide F, 2011, INTERSPEECH 2011; Sertel O, 2009, PATTERN RECOGN, V42, P1093, DOI 10.1016/j.patcog.2008.08.027; Wang H, 2014, J MED IMAGING, V1; Wang HB, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043902; WEINSTEI.GD, 1970, CANCER RES, V30, P724; Wong CSM, 2003, BRIT MED J, V327, P794, DOI 10.1136/bmj.327.7418.794; Wu R, 2015, ARXIV150102876	72	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657	1873-2860		ARTIF INTELL MED	Artif. Intell. Med.	JUN	2015	64	2					131	145		10.1016/j.artmed.2015.04.004		15	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	CL5HZ	WOS:000356991700005	25976208	
J	Feng, ZY; Jin, LW; Tao, DP; Huang, SP				Feng, Ziyong Z; Jin, Lianwen; Tao, Dapeng; Huang, Shuangping			DLANet: A manifold-learning-based discriminative feature learning network for scene classification	NEUROCOMPUTING			English	Article						Convolution neural network; Manifold learning; DLA Network; Scene classification	NONLINEAR DIMENSIONALITY REDUCTION; IMAGE CLASSIFICATION; LOCALITY ALIGNMENT; RECOGNITION; FRAMEWORK	This paper presents Discriminative Locality Alignment Network (DLANet), a novel manifold-learning-based discriminative learnable feature, for wild scene classification. Based on a convolutional structure, DLANet learns the filters of multiple layers by applying DLA and exploits the block-wise histograms of the binary codes of feature maps to generate the local descriptors. A DLA layer maximizes the margin between the inter-class patches and minimizes the distance of the intra-class patches in the local region. In particular, we construct a two-layer DLANet by stacking two DLA layers and a feature layer. It is followed by a popular framework of scene classification, which combines Locality-constrained Linear Coding-Spatial Pyramid Matching (LLC-SPM) and linear Support Vector Machine (SVM). We evaluate DLANet on NYU Depth V1, Scene-15 and MIT Indoor-67. Experiments show that DLANet performs well on depth image. It outperforms the carefully tuned features, including SIFT and is also competitive to the other reported methods. (C) 2015 Elsevier B.V. All rights reserved.	[Feng, Ziyong Z; Jin, Lianwen] S China Univ Technol, Sch Elect & Informat Engn, Coll Engn, Guangzhou 510641, Guangdong, Peoples R China; [Tao, Dapeng] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 100864, Peoples R China; [Tao, Dapeng] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China; [Huang, Shuangping] South China Agr Univ, Coll Engn, Guangzhou, Guangdong, Peoples R China	Jin, LW (reprint author), S China Univ Technol, Sch Elect & Informat Engn, Coll Engn, Guangzhou 510641, Guangdong, Peoples R China.	lianwen.jin@gmail.com			NSFC, China [61075021, 61201348, 61472144]; National Science and Technology Support plan [2013BAH65F01-2013BAH65F04]; GDNSF [S2011020000541, S2012040008016, S2013010014240]; GDSTP [2012A010701001]; Research Fund for the Doctoral Program of Higher Education of China [20120172110023]; State Key Laboratory of Digital Publishing Technology, Shenzhen Technology Project [JCYJ20140901003939001]	This research is supported in part by NSFC, China (Grant no.: 61075021, 61201348, 61472144), National Science and Technology Support plan (Grant no.: 2013BAH65F01-2013BAH65F04), GDNSF (Grant no.: S2011020000541, S2012040008016, S2013010014240), GDSTP (Grant no.: 2012A010701001), Research Fund for the Doctoral Program of Higher Education of China (Grant no.: 20120172110023), Opening Project of State Key Laboratory of Digital Publishing Technology, Shenzhen Technology Project (JCYJ20140901003939001).	Bergamo A, 2014, IEEE T PATTERN ANAL, V36, P1988, DOI 10.1109/TPAMI.2014.2313111; Bo L F, 2010, P ADV NEUR INF PROC, P244; Bo LF, 2011, IEEE INT C INT ROBOT, P821; Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015; Bosch A., IEEE T PATTERN ANAL, V30; Boureau Y.-L., 2010, P 27 INT C MACH LEAR; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Chan T. H., 2014, ARXIV14043606; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chatfield K., 2011, P BMVC; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Coates A., 2011, P INT C MACH LEARN; Dalal N, 2005, PROC CVPR IEEE, P886; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Fei-Fei L., 2005, P IEEE C COMP VIS PA; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Feng J., 2011, P IEEE C COMP VIS PA; Fergus R., 2011, P IEEE INT C COMP VI, P601; Guan NY, 2011, IEEE T NEURAL NETWOR, V22, P1218, DOI 10.1109/TNN.2011.2157359; Henaff M., 2011, P INT C MUS INF RETR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 1993, P NEUR INF PROC SYST; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Jia YQ, 2012, PROC CVPR IEEE, P3370; Jiang ZL, 2011, PROC CVPR IEEE, P1697; Julia Vogel, 2007, INT J COMPUT VISION, V72, P133; Ke Y., 2004, P IEEE C COMP VIS PA; Krizhevsky A., 2012, P NEUR INF PROC SYSY; Lazebnik S., 2006, P IEEE INT C COMP VI, P2167; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee HJ, 2009, GEOL SOC AM SPEC PAP, V454, P1, DOI 10.1130/2009.2454(00); Li L J, 2010, P ADV NEUR INF PROC, P1378; Lin D., 2014, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011; Mu Y, 2009, COGN COMPUT, V1, P327, DOI 10.1007/s12559-009-9028-5; Nguyen HV, 2009, LECT NOTES COMPUT SC, V5558, P269, DOI 10.1007/978-3-642-01793-3_28; Norouzi M., 2009, P IEEE C COMP VIS PA, P2735; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pandey M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1307, DOI 10.1109/ICCV.2011.6126383; Pass G., 1996, Proceedings ACM Multimedia 96, DOI 10.1145/244130.244148; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266]; Perronnin F., 2010, IEEE C COMP VIS PATT; Pronobis A, 2010, ROBOT AUTON SYST, V58, P81, DOI 10.1016/j.robot.2009.07.025; Quattoni A, 2009, PROC CVPR IEEE, P413; Rifai S., 2011, P INT C MACH LEARN; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Silberman N., 2012, P EUR C COMP VIS; Sun Y., 2014, ARXIV14064773; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tang S., 2013, COMP VIS ACCV 2012, P525; Tao DP, 2013, IEEE T CYBERNETICS, V43, P1406, DOI 10.1109/TCYB.2013.2264285; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; UDE A, 1994, ADVANCES IN ROBOT KINEMATICS AND COMPUTATIONAL GEOMETRY, P505; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; van Gemert J.C., 2008, P EUR C COMP VIS; Vincent P., 2008, P INT C MACH LEARN; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xiao J., 2013, ICCV; Xiao J., 2014, INT J COMPUT VISION, P1; Xie L., 2014, P IEEE C COMP VIS PA; Xie LX, 2014, IEEE T IMAGE PROCESS, V23, P1994, DOI 10.1109/TIP.2014.2310117; Xu C., 2014, P IEEE C COMP VIS PA; Yang JC, 2009, PROC CVPR IEEE, P1794; Yu K., 2009, P INF PROC SYST; Zeiler M., 2010, P IEEE C COMP VIS PA; Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894; Zhang LP, 2013, IEEE T GEOSCI REMOTE, V51, P242, DOI 10.1109/TGRS.2012.2197860; Zhang TH, 2008, LECT NOTES COMPUT SC, V5302, P725; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212; Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x	73	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	JUN 1	2015	157						11	21		10.1016/j.neucom.2015.01.043		11	Computer Science, Artificial Intelligence	Computer Science	CE4LH	WOS:000351801600002		
J	Han, K; Wang, YX; Wang, DL; Woods, WS; Merks, I; Zhang, T				Han, Kun; Wang, Yuxuan; Wang, DeLiang; Woods, William S.; Merks, Ivo; Zhang, Tao			Learning Spectral Mapping for Speech Dereverberation and Denoising	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep neural networks (DNNs); denoising; dereverberation; spectral mapping; supervised learning	IDEAL BINARY MASKING; REVERBERANT SPEECH; MONAURAL SEGREGATION; COCHLEAR IMPLANTS; NOISY; INTELLIGIBILITY; ALGORITHM; ENVIRONMENTS; OPTIMIZATION; ENHANCEMENT	In real-world environments, human speech is usually distorted by both reverberation and background noise, which have negative effects on speech intelligibility and speech quality. They also cause performance degradation in many speech technology applications, such as automatic speech recognition. Therefore, the dereverberation and denoising problems must be dealt with in daily listening environments. In this paper, we propose to perform speech dereverberation using supervised learning, and the supervised approach is then extended to address both dereverberation and denoising. Deep neural networks are trained to directly learn a spectral mapping from the magnitude spectrogram of corrupted speech to that of clean speech. The proposed approach substantially attenuates the distortion caused by reverberation, as well as background noise, and is conceptually simple. Systematic experiments show that the proposed approach leads to significant improvements of predicted speech intelligibility and quality, as well as automatic speech recognition in reverberant noisy conditions. Comparisons show that our approach substantially outperforms related methods.	[Han, Kun; Wang, Yuxuan; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA; [Woods, William S.; Merks, Ivo; Zhang, Tao] Starkey Hearing Technol, Eden Prairie, MN 55344 USA	Han, K (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	hank@cse.ohio-state.edu; wangyuxu@cse.ohio-state.edu; dwang@cse.ohio-state.edu; bill_woods@starkey.com; ivo_merks@starkey.com; tao_zhang@starkey.com			Air Force Office of Scientific Research (AFOSR) [FA9550-12-1-0130]; Starkey; Ohio Supercomputer Center	This work was supported in part by the Air Force Office of Scientific Research (AFOSR) under Grant FA9550-12-1-0130, a contract from Starkey, and the Ohio Supercomputer Center. A preliminary version of this work was presented at ICASSP 2014 [6]. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Rongshan Yu.	A. N. S. Institute, 1997, AM NAT STAND METH CA; Anastasakos T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1137; Avendano C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P889; Duchi J, 2011, J MACH LEARN RES, V12, P2121; GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317; Habets E., 2010, ROOM IMPULSE RESPONS; Han K., 2014, P ICASSP, P4661; Hazrati O, 2013, J ACOUST SOC AM, V133, P1607, DOI 10.1121/1.4789891; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hu G., 2006, THESIS OHIO STATE U; Hummersone C, 2010, IEEE T AUDIO SPEECH, V18, P1867, DOI 10.1109/TASL.2010.2051354; IEEE, 1969, IEEE T AUDIO ELECTRO, VAE-17, P227; Jin ZZ, 2011, IEEE T AUDIO SPEECH, V19, P1091, DOI 10.1109/TASL.2010.2077280; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Kingsbury BED, 1997, INT CONF ACOUST SPEE, P1259, DOI 10.1109/ICASSP.1997.596174; Kokkinakis K, 2011, J ACOUST SOC AM, V129, P3221, DOI 10.1121/1.3559683; Le Roux J., 2010, P INT C DIG AUD EFF; Lebart K, 2001, ACUSTICA, V87, P359; Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493; MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509; Nabelek A. K., 1992, ACOUSTICAL FACTORS A; Narayanan A., 2014, P ICASSP, P2523; Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4; NEELY ST, 1979, J ACOUST SOC AM, V66, P165, DOI 10.1121/1.383069; Povey D., 2011, P ASRU IEEE, P1; RIX AW, 2001, ACOUST SPEECH SIG PR, P749; Roman N, 2006, J ACOUST SOC AM, V120, P458, DOI 10.1121/1.2204590; Roman N, 2011, J ACOUST SOC AM, V130, P2153, DOI 10.1121/1.3631668; Roman N, 2013, J ACOUST SOC AM, V133, P1707, DOI 10.1121/1.4789895; Sadjadi SO, 2011, INT CONF ACOUST SPEE, P5448; Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881; Tachioka Y., 2013, P 2 INT WORKSH MACH, P19; Vincent E, 2013, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2013.6637622; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang D., 2006, COMPUTATIONAL AUDITO; Wang YX, 2013, INT CONF ACOUST SPEE, P7472; Wu MY, 2006, IEEE T AUDIO SPEECH, V14, P774, DOI 10.1109/TSA.2005.858066; Wu M., 2003, P ICASSP, P844; Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240; Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398; ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7	44	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	JUN	2015	23	6					982	992		10.1109/TASLP.2015.2416653		11	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CI1WQ	WOS:000354536200003		
J	Hou, WL; Gao, XB; Tao, DC; Li, XL				Hou, Weilong; Gao, Xinbo; Tao, Dacheng; Li, Xuelong			Blind Image Quality Assessment via Deep Learning	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Deep learning; image quality assessment (IQA); natural scene statistics (NSS); no reference	NATURAL SCENE STATISTICS; NEURAL-NETWORK; DOMAIN; REPRESENTATION; INFORMATION; FRAMEWORK	This paper investigates how to blindly evaluate the visual quality of an image by learning rules from linguistic descriptions. Extensive psychological evidence shows that humans prefer to conduct evaluations qualitatively rather than numerically. The qualitative evaluations are then converted into the numerical scores to fairly benchmark objective image quality assessment (IQA) metrics. Recently, lots of learning-based IQA models are proposed by analyzing the mapping from the images to numerical ratings. However, the learnt mapping can hardly be accurate enough because some information has been lost in such an irreversible conversion from the linguistic descriptions to numerical scores. In this paper, we propose a blind IQA model, which learns qualitative evaluations directly and outputs numerical scores for general utilization and fair comparison. Images are represented by natural scene statistics features. A discriminative deep model is trained to classify the features into five grades, corresponding to five explicit mental concepts, i.e., excellent, good, fair, poor, and bad. A newly designed quality pooling is then applied to convert the qualitative labels into scores. The classification framework is not only much more natural than the regression-based models, but also robust to the small sample size problem. Thorough experiments are conducted on popular databases to verify the model's effectiveness, efficiency, and robustness.	[Hou, Weilong; Gao, Xinbo] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China; [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, State Key Lab Transient Opt & Photon, Ctr Opt IMagery Anal & Learning OPTIMAL, Xian 710119, Shaanxi, Peoples R China	Hou, WL (reprint author), Xidian Univ, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.	weilonghou@gmail.com; xbgao@ieee.org; dacheng.tao@uts.edu.au; xuelong_li@opt.ac.cn			National Natural Science Foundation of China [61125204, 61125106, 61172146, 61101250, 61372130]; Fundamental Research Funds for the Central Universities [K5051202048, BDZ021403, JB149901]; Program for Changjiang Scholars and Innovative Research Team; University of China [IRT13088]; Shaanxi Innovative Research Team for Key Science and Technology [2012KCT-02]; Key Research Program, Chinese Academy of Sciences, Beijing, China [KGZD-EW-T03]; Australian Research Council [FT-130101457, DP-120103730, LP-140100569]	This work was supported in part by the National Natural Science Foundation of China under Grant 61125204, Grant 61125106, Grant 61172146, Grant 61101250, and Grant 61372130, in part by the Fundamental Research Funds for the Central Universities under Grant K5051202048, Grant BDZ021403, Grant JB149901, in part by the Program for Changjiang Scholars and Innovative Research Team with the University of China under Grant IRT13088, in part by the Shaanxi Innovative Research Team for Key Science and Technology under Grant 2012KCT-02, in part by the Key Research Program, Chinese Academy of Sciences, Beijing, China, under Grant KGZD-EW-T03, and in part by the Australian Research Council under Project FT-130101457, Project DP-120103730, and Project LP-140100569.	Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637; BT. 500, 2002, BT500110602; Callet P. L., 2006, SUBJECTIVE QUALITY A; Collobert R., 2008, P 25 INT C MACH LEAR, V307, P160; Gao XB, 2013, IEEE T NEUR NET LEAR, V24, P2013, DOI 10.1109/TNNLS.2013.2271356; Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014; He LH, 2012, PROC CVPR IEEE, P1146; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Horita Y., 2000, MICT IMAGE QUALITY E; Hutchins E, 1995, COGNITION WILD; Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105; Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620; Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050; Mittal A, 2012, IEEE SIGNAL PROC LET, V19, P75, DOI 10.1109/LSP.2011.2179293; MOHAMED AR, 2011, P IEEE INT C AC SPEE, P5060; Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888; Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325; Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30; Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100; Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550; Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519; Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492; Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Tang HX, 2011, PROC CVPR IEEE, P305; VARADARAJAN S, 2008, IEEE IMAGE PROC, P401; VQEG, 2009, VAL RED REF NO REF O; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang Z, 2002, IEEE IMAGE PROC, P477; Weiss Y., 2007, P IEEE C COMP VIS PA, P1; Xia YS, 2012, IEEE T NEUR NET LEAR, V23, P812, DOI 10.1109/TNNLS.2012.2184800; Ye P, 2012, PROC CVPR IEEE, P1098; Yu JF, 2014, IEEE T NEUR NET LEAR, V25, P780, DOI 10.1109/TNNLS.2013.2281313; Zhang KB, 2013, IEEE T NEUR NET LEAR, V24, P1648, DOI 10.1109/TNNLS.2013.2262001; Zhong S.- H., 2011, P ACM C MULT, P343; Zhong SH, 2010, IEEE IMAGE PROC, P1553, DOI 10.1109/ICIP.2010.5653807	42	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	JUN	2015	26	6					1275	1286		10.1109/TNNLS.2014.2336852		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	CI7PS	WOS:000354957000013	25122842	
J	Xiao, YH; Zhu, ZF; Zhao, Y; Wei, YC; Wei, SK				Xiao, Yanhui; Zhu, Zhenfeng; Zhao, Yao; Wei, Yunchao; Wei, Shikui			Kernel Reconstruction ICA for Sparse Representation	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Image classification; independent component analysis (ICA); nonlinear mapping; pattern recognition	FACE RECOGNITION; IMAGE CLASSIFICATION; MATRIX	Independent component analysis with soft reconstruction cost (RICA) has been recently proposed to linearly learn sparse representation with an overcomplete basis, and this technique exhibits promising performance even on unwhitened data. However, linear RICA may not be effective for the majority of real-world data because nonlinearly separable data structure pervasively exists in original data space. Meanwhile, RICA is essentially an unsupervised method and does not employ class information. Motivated by the success of the kernel trick that maps a nonlinearly separable data structure into a linearly separable case in a high-dimensional feature space, we propose a kernel RICA (kRICA) model to nonlinearly capture sparse representation in feature space. Furthermore, we extend the unsupervised kRICA to a supervised one by introducing a class-driven discrimination constraint, such that the data samples from the same class are well represented on the basis of the corresponding subset of basis vectors. This discrimination constraint minimizes inhomogeneous representation energy and maximizes homogeneous representation energy simultaneously, which is essentially equivalent to maximizing between-class scatter and minimizing within-class scatter at the same time in an implicit manner. Experimental results demonstrate that the proposed algorithm is more effective than other state-of-the-art methods on several datasets.	[Xiao, Yanhui; Zhu, Zhenfeng; Zhao, Yao; Wei, Yunchao; Wei, Shikui] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100055, Peoples R China; [Xiao, Yanhui; Zhu, Zhenfeng; Wei, Yunchao; Wei, Shikui] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China; [Zhao, Yao] State Key Lab Rail Traff Control & Safety, Beijing 100044, Peoples R China	Xiao, YH (reprint author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100055, Peoples R China.	xiaoyanhui@gmail.com; zhfzhu@bjtu.edu.cn; yzhao@bjtu.edu.cn; 11112065@bjtu.edu.cn; shkwei@bjtu.edu.cn			National Basic Research Program of China [2012CB316400]; National Natural Science Foundation of China [61025013, 61172129, 61202241, 61210006]; Program for Changjiang Scholars and Innovative Research Team in University [IRT201206]; Program for New Century Excellent Talents in University [13-0661]; Fundamental Research Funds for the Central Universities [2012JBZ012]	This work was supported in part by the National Basic Research Program of China under Grant 2012CB316400, in part by the National Natural Science Foundation of China under Grant 61025013, Grant 61172129, Grant 61202241, and Grant 61210006, in part by the Program for Changjiang Scholars and Innovative Research Team in University under Grant IRT201206, in part by the Program for New Century Excellent Talents in University under Grant 13-0661, and in part by the Fundamental Research Funds for the Central Universities under Grant 2012JBZ012.	Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085; Bengio Y., 2006, P C NEUR INF PROC SY, V19, P153; Boureau Y.-L., 2010, P 27 INT C MACH LEAR, P111; Boyd S., 2006, IEEE T AUTOMAT CONTR, V51, P1859; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Coates A, 2010, P 14 INT C ART INT S, P215; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; Fei-Fei L., 2007, COMPUTER VISION IMAG, V106, P59, DOI DOI 10.1016/J.CVIU.2005.09.012; Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620; Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1; Golub G. H., 1996, MATRIX COMPUTATIONS; Griffin G., 2007, CALTECH 256 OBJECT C; Grimes DB, 2005, NEURAL COMPUT, V17, P47, DOI 10.1162/0899766052530893; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Jiang ZL, 2011, PROC CVPR IEEE, P1697; Krizhevsky A., CONVOLUTIONAL DEEP B; Le Q., 2012, P 29 INT C MACH LEAR, P81; Le Q.V., 2011, P ADV NEUR INF PROC, P1017; LeCun Y., 2012, P EUR C COMP VIS WOR, V7583, P496; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Plummer D., 1986, MATCHING THEORY; Shawe-Taylor John, 2004, KERNEL METHODS PATTE; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiao Y., 2012, P 20 ACM INT C MULT, P929; Yang J, 2005, PATTERN RECOGN, V38, P1784, DOI 10.1016/j.patcog.2005.01.023; Yang JC, 2009, PROC CVPR IEEE, P1794; Yu K, 2010, P INT C MACH LEARN, P1215; Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989	36	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	JUN	2015	26	6					1222	1232		10.1109/TNNLS.2014.2334711		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	CI7PS	WOS:000354957000009	25069125	
J	Xie, BJ; Liu, Y; Zhang, H; Yu, J				Xie, Bojun; Liu, Yi; Zhang, Hui; Yu, Jian			Efficient image representation for object recognition via pivots selection	FRONTIERS OF COMPUTER SCIENCE			English	Article						efficient kernel descriptor; efficient hierarchical kernel descriptor; incomplete Cholesky decomposition; patch-level features; image-level features	KERNEL DESCRIPTORS; FEATURES; SCENES	Patch-level features are essential for achieving good performance in computer vision tasks. Besides wellknown pre-defined patch-level descriptors such as scaleinvariant feature transform (SIFT) and histogram of oriented gradient (HOG), the kernel descriptor (KD) method [1] offers a new way to "grow-up" features from a match-kernel defined over image patch pairs using kernel principal component analysis (KPCA) and yields impressive results. In this paper, we present efficient kernel descriptor (EKD) and efficient hierarchical kernel descriptor (EHKD), which are built upon incomplete Cholesky decomposition. EKD automatically selects a small number of pivot features for generating patch-level features to achieve better computational efficiency. EHKD recursively applies EKD to form image-level features layer-by-layer. Perhaps due to parsimony, we find surprisingly that the EKD and EHKD approaches achieved competitive results on several public datasets compared with other state-of-the-art methods, at an improved efficiency over KD.	[Xie, Bojun; Liu, Yi; Zhang, Hui; Yu, Jian] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China; [Xie, Bojun; Zhang, Hui] Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding 071000, Peoples R China	Liu, Y (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.	yiliu@bjtu.edu.cn			National Natural Science Foundation of China [61300072, 61033013]; Fundamental Research Funds for the Central Universities [2014JBZ005]; Beijing Committee of Science and Technology, China [Z131110002813118]; Beijing Jiaotong University [K12RC00090]; Research Foundation of Education Bureau of Hebei Province [Z2013124]	The authors acknowledge support from the National Natural Science Foundation of China (Grant No. 61300072, 61033013), the Fundamental Research Funds for the Central Universities (2014JBZ005), the Beijing Committee of Science and Technology, China (Z131110002813118), Beijing Jiaotong University (K12RC00090) and Research Foundation of Education Bureau of Hebei Province (Z2013124).	Bach FR, 2002, J MACHINE LEARNING R, V3, P1; Bo L., 2009, P ADV NEUR INF PROC, P135; Bo L F, 2010, P ADV NEUR INF PROC, P244; Bo LF, 2011, PROC CVPR IEEE, P1729; Boiman O., 2008, P IEEE C COMP VIS PA, P1; Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Dalal N, 2005, PROC CVPR IEEE, P886; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Fine S, 2001, J MACHINE LEARNING R, V2, P243; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jia YQ, 2012, PROC CVPR IEEE, P3370; Krizhevsky A, 2012, P ADV NEUR INF PROC, P1106; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q, 2010, P ANN C NEUR INF PRO, P1279; LeCun Y, 2004, PROC CVPR IEEE, P97; Li F F, 2005, P 2005 IEEE COMP SOC, P524; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li L, 2007, P IEEE INT C COMP VI, P1; Li L J, 2010, P ADV NEUR INF PROC, P1378; Liu LQ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2486; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pandey M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1307, DOI 10.1109/ICCV.2011.6126383; Quattoni A, 2009, PROC CVPR IEEE, P413; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Schlkopf B., 1998, NEURAL COMPUT, V10, P1299; Shabou A, 2012, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2012.6248107; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wang P, 2013, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2013.368; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xie B J, 2013, P IEEE INT C IM PROC, P3479; Yu K, 2010, P INT C MACH LEARN, P1215; Zhu J, 2010, P ADV NEUR INF PROC, P2586	38	0	0	HIGHER EDUCATION PRESS	BEIJING	SHATANHOU ST 55, BEIJING 100009, PEOPLES R CHINA	2095-2228	2095-2236		FRONT COMPUT SCI-CHI	Front.. Comput. Sci.	JUN	2015	9	3					383	391		10.1007/s11704-015-4182-7		9	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	CH7CX	WOS:000354194300005		
J	Yuan, ZQ; Xu, CS; Sang, JT; Yan, SC; Hossain, MS				Yuan, Zhaoquan; Xu, Changsheng; Sang, Jitao; Yan, Shuicheng; Hossain, M. Shamim			Learning Feature Hierarchies: A Layer-Wise Tag-Embedded Approach	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Auto-encoder; deep learning; hierarchical feature learning; social tags	CLASSIFICATION; MULTIMEDIA; MODELS; REPRESENTATION; RECOGNITION; DICTIONARY; MULTIPLE; DATABASE	Feature representation learning is an important and fundamental task in multimedia and pattern recognition research. In this paper, we propose a novel framework to explore the hierarchical structure inside the images from the perspective of feature representation learning, which is applied to hierarchical image annotation. Different from the current trend in multimedia analysis of using pre-defined features or focusing on the end-task "flat" representation, we propose a novel layer-wise tag-embedded deep learning (LTDL) model to learn hierarchical features which correspond to hierarchical semantic structures in the tag hierarchy. Unlike most existing deep learning models, LTDL utilizes both the visual content of the image and the hierarchical information of associated social tags. In the training stage, the two kinds of information are fused in a bottom-up way. Supervised training and multi-modal fusion alternate in a layer-wise way to learn feature hierarchies. To validate the effectiveness of LTDL, we conduct extensive experiments for hierarchical image annotation on a large-scale public dataset. Experimental results show that the proposed LTDL can learn representative features with improved performances.	[Yuan, Zhaoquan; Xu, Changsheng; Sang, Jitao] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Hossain, M. Shamim] King Saud Univ, SWE Dept, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia	Yuan, ZQ (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	zqyuan@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn; jtsang@nlpr.ia.ac.cn; eleyans@nus.edu.sg; mshossain@ksu.edu.sa			National Basic Research Program of China [2012CB316304]; National Natural Science Foundation of China [61225009, 61373122, 61303176, 61402479, 61328205, 61432019]; Beijing Natural Science Foundation [4131004]; Singapore National Research Foundation under its International Research Centre@Singapore Funding Initiative; Deanship of Scientific Research at King Saud University [IRG 14-18]	This work was supported in part by the National Basic Research Program of China under Grant 2012CB316304, by the National Natural Science Foundation of China under Grant 61225009, Grant 61373122, Grant 61303176, Grant 61402479, Grant 61328205, and Grant 61432019, by the Beijing Natural Science Foundation under Grant 4131004, by the Singapore National Research Foundation under its International Research Centre@Singapore Funding Initiative and administered by the IDM Programme Office, and by the Deanship of Scientific Research at King Saud University through the international research group Program IRG 14-18. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Cees Snoek.	Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blei DM, 2004, ADV NEUR IN, V16, P17; Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009; Cesa-Bianchi N, 2006, J MACH LEARN RES, V7, P31; Cesa-Bianchi N., 2006, ACM INT C P SERIES, V148, P177; Chen YQ, 2001, IEEE IMAGE PROC, P385; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Collet C, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P979; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Dalal N, 2005, PROC CVPR IEEE, P886; Deng J, 2009, PROC CVPR IEEE, P248; Deng J., 2011, P IEEE C COMP VIS PA, P785; Deselaers T, 2011, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR.2011.5995474; Donahue Jeff, 2013, ARXIV13101531; Evgeniou T, 2003, IEEE T KNOWL DATA EN, V15, P911, DOI 10.1109/TKDE.2003.1209008; Fawcett T., 2004, MACH LEARN, V31, P1; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Gelman A., 2007, DATA ANAL USING REGR; Griffin G., 2008, P IEEE C COMP VIS PA, P1; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; He Q, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P491, DOI 10.1137/1.9781611972771.50; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Horster E., 2008, P 16 ACM INT C MULT, P643, DOI 10.1145/1459359.1459449; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hotho A., 2002, KUNSTLICHE INTELLIGE, V04, P48; Huang Q., 2011, P IEEE C COMP VIS PA, P1953; Irie G, 2013, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2013.49; Katsurai M, 2014, IEEE T MULTIMEDIA, V16, P1059, DOI 10.1109/TMM.2014.2306655; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23, P1090; Koskela M, 2007, IEEE T MULTIMEDIA, V9, P912, DOI 10.1109/TMM.2007.900137; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2006, ADV NEURAL INFORM PR, V19, P801; LEVITT JB, 1994, J NEUROPHYSIOL, V71, P2517; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marszalek M., 2007, P IEEE C COMP VIS PA, P1; Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Osindero S, 2006, NEURAL COMPUT, V18, P381, DOI 10.1162/089976606775093936; Poli R., 2010, THEORY APPL ONTOLOGY; Ranzato M., 2007, COMP VIS PATT REC IE, V5, P1; Roig Gemma, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), DOI 10.1109/FG.2011.5771328; Sang J., 2011, ACM T MULTIMEDIA C S, V7S, P1; Sang J., 2012, J MULTIMEDIA, V7, P9; Schulz Hannes, 2012, KI-Kunstliche Intelligenz, V26, DOI 10.1007/s13218-012-0198-z; Shen L, 2013, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2013.56; Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Wang K., 2013, P INT C COMP VIS, P2088; Zhang H., 2007, P ACM MULT, P273, DOI DOI 10.1145/1291233.1291290; Zhou N., 2013, IEEE T PATTERN ANAL, V36, P715; Zhou N, 2012, PROC CVPR IEEE, P3490	60	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210	1941-0077		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	JUN	2015	17	6					816	827		10.1109/TMM.2015.2417777		12	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	CI1TM	WOS:000354527500005		
J	LeCun, Y; Bengio, Y; Hinton, G				LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey			Deep learning	NATURE			English	Review							NEURAL-NETWORKS; RECOGNITION; ALGORITHM; MODELS; IMAGES; CORTEX; NETS	Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.	[LeCun, Yann] Facebook Al Res, New York, NY 10003 USA; [LeCun, Yann] New York Univ, New York, NY 10003 USA; [Bengio, Yoshua] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada; [Hinton, Geoffrey] Google, Mountain View, CA 94043 USA; [Hinton, Geoffrey] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	LeCun, Y (reprint author), Facebook Al Res, 770 Broadway, New York, NY 10003 USA.	yann@cs.nyu.edu			Natural Sciences and Engineering Research Council of Canada; Canadian Institute For Advanced Research (CIFAR); National Science Foundation; Office of Naval Research	The authors would like to thank the Natural Sciences and Engineering Research Council of Canada, the Canadian Institute For Advanced Research (CIFAR), the National Science Foundation and Office of Naval Research for support. Y.L. and Y.B. are CIFAR fellows.	Ba J., 2014, P INT C LEARN REPR; Bengio Y., 2005, P ADV NEUR INF PROC, V18, P107; Bengio Y., 2015, P INT C LEARN REPR; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bengio Y., 2014, P 31 INT C MACH LEAR, P226; Bengio Y., 2009, LEARNING DEEP ARCHIT; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bordes A, 2014, MEMORY NETWORKS; BOSER BE, 1991, IEEE J SOLID-ST CIRC, V26, P2017, DOI 10.1109/4.104196; Bottou L, 2014, MACH LEARN, V94, P133, DOI 10.1007/s10994-013-5335-x; Bottou L., 2007, ADV NEURAL INFORM PR, V20, P161; Bottou L., 1989, P EUR, V89, P537; Cadieu CF, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003963; Cho K., 2014, P C EMP METH NAT LAN, P1724; Choromanska A., 2014, P C AI STAT; Ciodaro T, 2012, J PHYS CONF SER, V368, DOI 10.1088/1742-6596/368/1/012030; Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Dahl George E., 2012, IEEE T AUDIO SPEECH, V20, P33; Dauphin Y., 2014, P ADV NEUR INF PROC, V27, P2933; Duda R.O., 1973, PATTERN CLASSIFICATI; ElHihi S., 1995, P ADV NEUR INF PROC, P8; Farabet C., 2011, SCALING MACHINE LEAR, P399; Farabet C., 2012, P INT C MACH LEARN; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97; Girshick R., 2014, P IEEE C COMP VIS PA, P580; Glorot X., 2011, P 14 INT C ART INT S, V15, P315; Graves A., 2014, NEURAL TURING MACHIN; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Gregor K., 2010, P INT C MACH LEARN, P399; Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276; Helmstaedter M, 2013, NATURE, V500, P168, DOI 10.1038/nature12346; Hinton G., 2012, P ADV NEUR INF PROC, V25, P1090; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G. E., 2005, P 19 INT JOINT C ART, P1765; Hinton G. E., 1995, SCIENCE, V268, P1558; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hochreiter S, 1991, THESIS TU MUNICH; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Jean S., 2015, P ACL IJCNLP; Kaggle, 2014, HIGGS BOS MACH LEARN; Kavukcuoglu K., 2010, ADV NEURAL INFORM PR, V23, P1090; Kingma D., 2014, P ADV NEUR INF PROC, V27, P3581; Lakoff G., 2008, METAPHORS WE LIVE BY; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Le Cun Y., 1990, ADV NEURAL INFORM PR, P396; Le Q. V., 2014, P ADV NEUR INF PROC, V27, P3104; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1985, P COGNITIVA, V85, P599; Leung MKK, 2014, BIOINFORMATICS, V30, P121, DOI 10.1093/bioinformatics/btu277; Ma JS, 2015, J CHEM INF MODEL, V55, P263, DOI [10.1021/ci500747n, 10.1021/ci5000747n]; Mikolov T., 2011, P ASRU, P196; Mikolov T., 2013, ADV NEURAL INF PROCE, V26, P3111; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Montufar G., 2014, J DISCRETE MATH, V29, P321; Montufar G. F., 2014, P ADV NEUR INF PROC, V27, P2924; Ning F, 2005, IEEE T IMAGE PROCESS, V14, P1360, DOI 10.1109/TIP.2005.852470; Nowlan S., 1995, NEURAL INFORM PROCES; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Parker D. B., 1985, TR47; Pascanu R., 2013, P 30 INT C MACH LEAR, P1310; Platt J. C., 2003, P INT C DOC AN REC I, P958; Raina R, 2009, 26 ANN INT C MACH LE, V382, P873; Ranzato M, 2013, IEEE T PATTERN ANAL, V35, P2206, DOI 10.1109/TPAMI.2013.29; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; Rogers T. T., 2004, SEMANTIC COGNITION P; Rosenblatt F., 1957, 854601 CORN AER LAB; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Scholkopf B., 2002, LEARNING KERNELS; Schwenk H, 2007, COMPUT SPEECH LANG, V21, P492, DOI 10.1016/j.csl.2006.09.003; Selfridge O., 1958, P S HELD NAT PHYS LA, P513; Sermanet P., 2014, P INT C LEARN REPR; Sermanet P., 2013, P INT C COMP VIS PAT; Simonyan K., 2014, P INT C LEARN REPR; Socher R., 2011, P 28 INT C MACH LEAR, P129; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sutskever I., 2011, P 28 INT C MACH LEAR, P1017; Sutskever I, 2012, THESIS U TORONTO; Szegedy C., 2014, PREPRINT; Taigman Y., 2014, P IEEE C COMP VIS PA, P1701; Tompson J., 2014, P C COMP VIS PATT RE; Tompson J., 2014, P ADV NEUR INF PROC, V27, P1799; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881; VAILLANT R, 1994, IEE P-VIS IMAGE SIGN, V141, P245, DOI 10.1049/ip-vis:19941301; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Vinyals O., 2014, P INT C MACH LEARN; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Werbos P., 1974, THESIS HARVARD U; Weston J., 2015, AI COMPLETE QUESTION; Weston J., 2014, P EMP METH NAT LANG; Xiong H. Y., 2015, SCIENCE, V347, P6218; Xu K., 2015, P INT C LEARN REPR	103	0	0	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	0028-0836	1476-4687		NATURE	Nature	MAY 28	2015	521	7553					436	444		10.1038/nature14539		9	Multidisciplinary Sciences	Science & Technology - Other Topics	CJ2AN	WOS:000355286600030	26017442	
J	Huang, HP; Toyoizumi, T				Huang, Haiping; Toyoizumi, Taro			Advanced mean-field theory of the restricted Boltzmann machine	PHYSICAL REVIEW E			English	Article							BELIEF PROPAGATION; ALGORITHM	Learning in restricted Boltzmann machine is typically hard due to the computation of gradients of log-likelihood function. To describe the network state statistics of the restricted Boltzmann machine, we develop an advanced mean-field theory based on the Bethe approximation. Our theory provides an efficient message-passing-based method that evaluates not only the partition function (free energy) but also its gradients without requiring statistical sampling. The results are compared with those obtained by the computationally expensive sampling-based method.	[Huang, Haiping; Toyoizumi, Taro] RIKEN, Brain Sci Inst, Wako, Saitama 3510198, Japan	Huang, HP (reprint author), RIKEN, Brain Sci Inst, Wako, Saitama 3510198, Japan.	physhuang@gmail.com	Toyoizumi, Taro/G-5632-2015	Toyoizumi, Taro/0000-0001-5444-8829	RIKEN Brain Science Institute; Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) by the Ministry of Education, Culture, Sports, Science and Technology of Japan (MEXT)	This work was supported by RIKEN Brain Science Institute and the Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) by the Ministry of Education, Culture, Sports, Science and Technology of Japan (MEXT).	Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Freund Y., 1994, TECHNICAL REPORT; Heskes T, 2004, NEURAL COMPUT, V16, P2379, DOI 10.1162/0899766041941943; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang HP, 2014, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2014/05/P05020; Huang HP, 2013, J PHYS A-MATH THEOR, V46, DOI 10.1088/1751-8113/46/37/375002; Kabashima Y, 2003, J PHYS A-MATH GEN, V36, P11111, DOI 10.1088/0305-4470/36/43/030; Kappen HJ, 1998, NEURAL COMPUT, V10, P1137, DOI 10.1162/089976698300017386; Koster U, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003684; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Mehta P., ARXIV14103831; Mezard M., 2009, INFORM PHYS COMPUTAT; Mezard M, 2001, EUR PHYS J B, V20, P217, DOI 10.1007/PL00011099; Montanari A, 2004, PHYS REV B, V70, DOI 10.1103/PhysRevB.70.134406; Rivoire O, 2004, EUR PHYS J B, V37, P55, DOI 10.1140/epjb/e2004-00030-4; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194	18	0	0	AMER PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	1539-3755	1550-2376		PHYS REV E	Phys. Rev. E	MAY 18	2015	91	5							050101	10.1103/PhysRevE.91.050101		5	Physics, Fluids & Plasmas; Physics, Mathematical	Physics	CI7VX	WOS:000354974100001		
J	Ohzeki, M				Ohzeki, Masayuki			L-1-Regularized Boltzmann Machine Learning Using Majorizer Minimization	JOURNAL OF THE PHYSICAL SOCIETY OF JAPAN			English	Article							ALGORITHM	We propose an inference method to estimate sparse interactions and biases according to Boltzmann machine learning. The basis of this method is L-1 regularization, which is often used in compressed sensing, a technique for reconstructing sparse input signals from undersampled outputs. L-1 regularization impedes the simple application of the gradient method, which optimizes the cost function that leads to accurate estimations, owing to the cost function's lack of smoothness. In this study, we utilize the majorizer minimization method, which is a well-known technique implemented in optimization problems, to avoid the non-smoothness of the cost function. By using the majorizer minimization method, we elucidate essentially relevant biases and interactions from given data with seemingly strongly-correlated components.	Kyoto Univ, Grad Sch Informat, Dept Syst Sci, Kyoto 6068501, Japan	Ohzeki, M (reprint author), Kyoto Univ, Grad Sch Informat, Dept Syst Sci, Kyoto 6068501, Japan.	mohzeki@i.kyoto-u.ac.jp			JST-CREST; MEXT [251200008, 24740263]; Kayamori Foundation of Informational Science Advancement	The present work is performed by the financial support from the JST-CREST, MEXT KAKENHI Grants No. 251200008 and 24740263, and the Kayamori Foundation of Informational Science Advancement.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Beck A., 2009, GRADIENT BASED ALGOR, P42; Besag J., 1975, J R STAT SOC D-STAT, V24, P179; Bishop CM, 2006, PATTERN RECOGNITION; Cocco S, 2011, PHYS REV LETT, V106, DOI 10.1103/PhysRevLett.106.090601; Cocco S, 2012, J STAT PHYS, V147, P252, DOI 10.1007/s10955-012-0463-4; Decelle A, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.070603; Ekeberg M, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.012707; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ohzeki M, 2015, J PHYS SOC JPN, V84, DOI 10.7566/JPSJ.84.034003; Pankaj M., ARXIV14103831; Raymond J, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.052111; Ricci-Tersenghi F, 2012, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2012/08/P08015; Sessak V, 2009, J PHYS A-MATH THEOR, V42, DOI 10.1088/1751-8113/42/5/055001; Sohl-Dickstein J, 2011, PHYS REV LETT, V107, DOI 10.1103/PhysRevLett.107.220601; Welling M, 2002, LECT NOTES COMPUT SC, V2415, P351; Yamanaka S, 2015, J PHYS SOC JPN, V84, DOI 10.7566/JPSJ.84.024801; Yasuda M, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.012134; Yasuda M, 2012, INT C PATT RECOG, P2234; Yasuda M, 2015, J PHYS SOC JPN, V84, DOI 10.7566/JPSJ.84.034001	22	0	0	PHYSICAL SOC JAPAN	TOKYO	YUSHIMA URBAN BUILDING 5F, 2-31-22 YUSHIMA, BUNKYO-KU, TOKYO, 113-0034, JAPAN	0031-9015			J PHYS SOC JPN	J. Phys. Soc. Jpn.	MAY 15	2015	84	5							054801	10.7566/JPSJ.84.054801		8	Physics, Multidisciplinary	Physics	CG9OS	WOS:000353646600023		
J	Zhang, ZF; Wang, LB; Kai, A; Yamada, T; Li, WF; Iwahashi, M				Zhang, Zhaofeng; Wang, Longbiao; Kai, Atsuhiko; Yamada, Takanori; Li, Weifeng; Iwahashi, Masahiro			Deep neural network-based bottleneck feature and denoising autoencoder-based dereverberation for distant-talking speaker identification	EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING			English	Article						Speaker recognition; Bottleneck features; Denoising autoencoder; Deep neural network; Reverberant speech	MULTICHANNEL LMS ALGORITHM; SPEECH RECOGNITION; SPECTRAL SUBTRACTION; LINEAR PREDICTION; REVERBERATION; VERIFICATION; SUPPRESSION; MODELS; NOISE; HMM	Deep neural network (DNN)-based approaches have been shown to be effective in many automatic speech recognition systems. However, few works have focused on DNNs for distant-talking speaker recognition. In this study, a bottleneck feature derived from a DNN and a cepstral domain denoising autoencoder (DAE)-based dereverberation are presented for distant-talking speaker identification, and a combination of these two approaches is proposed. For the DNN-based bottleneck feature, we noted that DNNs can transform the reverberant speech feature to a new feature space with greater discriminative classification ability for distant-talking speaker recognition. Conversely, cepstral domain DAE-based dereverberation tries to suppress the reverberation by mapping the cepstrum of reverberant speech to that of clean speech with the expectation of improving the performance of distant-talking speaker recognition. Since the DNN-based discriminant bottleneck feature and DAE-based dereverberation have a strong complementary nature, the combination of these two methods is expected to be very effective for distant-talking speaker identification. A speaker identification experiment was performed on a distant-talking speech set, with reverberant environments differing from the training environments. In suppressing late reverberation, our method outperformed some state-of-the-art dereverberation approaches such as the multichannel least mean squares (MCLMS). Compared with the MCLMS, we obtained a reduction in relative error rates of 21.4% for the bottleneck feature and 47.0% for the autoencoder feature. Moreover, the combination of likelihoods of the DNN-based bottleneck feature and DAE-based dereverberation further improved the performance.	[Zhang, Zhaofeng; Wang, Longbiao; Iwahashi, Masahiro] Nagaoka Univ Technol, Nagaoka, Niigata 9402188, Japan; [Kai, Atsuhiko; Yamada, Takanori] Shizuoka Univ, Naka Ku, Hamamatsu, Shizuoka 4328561, Japan; [Li, Weifeng] Tsinghua Univ, Beijing 100084, Peoples R China	Wang, LB (reprint author), Nagaoka Univ Technol, 1603-1 Kamitomioka Cho, Nagaoka, Niigata 9402188, Japan.	wang@vos.nagaokaut.ac.jp			Kayamori Foundation of Informational Science Advancement	This work was partially supported by a research grant from the Kayamori Foundation of Informational Science Advancement.	BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209; Delcroix M, 2007, IEEE T AUDIO SPEECH, V15, P430, DOI 10.1109/TASL.2006.881698; FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530; Gannot S, 2003, EURASIP J APPL SIG P, V2003, P1074, DOI 10.1155/S1110865703305049; Gelbart D, 2002, INTERSPEECH 2002 DEN, P968; Gelbart D, 2001, EVALUATING LONG TERM; Habets EA, 2011, JOINT DEREVERBERATIO, P191; HABETS EAP, 2005, MULTICHANNEL SPEECH, P173; Hinton G, 2010, PRACTICAL GUIDE TRAI; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton R., 2006, SCIENCE, V313, P504; Hirsch HG, 2008, SPEECH COMMUN, V50, P244, DOI 10.1016/j.specom.2007.09.004; Huang YT, 2005, IEEE SIGNAL PROC LET, V12, P173, DOI 10.1109/LSP.2004.842286; Hughes TB, 1999, IEEE T SPEECH AUDI P, V7, P346, DOI 10.1109/89.759045; Hughes TB, 1997, IEEE T SPEECH AUDIO, V7, P490; Ishii T, 2013, P INTERSPEECH LYON F, P3512; Itou K., 1999, Journal of the Acoustical Society of Japan (E), V20; Jin Q, 2006, P ICASSP 2006, V1, P937; Jin Q, 2007, IEEE T AUDIO SPEECH, V15, P2023, DOI 10.1109/TASL.2007.902876; Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015; KINOSHITA K, 2006, SPECTRAL SUBTRACTION, P817; Konig Y, 1998, NONLINEAR DISCRIMINA, P72; Liu F, 1993, EFFICIENT CEPSTRAL N, P69; Lu X, 2013, P INT 13 AUG, P436; MAGANTI H, 2010, AUDITORY BASED MODUL, P570; Mohamed A, 2012, IEEE T AUDIO SPEECH, V20, P12; Nakamura S, 2000, ACOUSTICAL SOUND DAT, P965; Nishiura T, 2008, EVALUATION FRAMEWORK, P968; Nugraha A., 2014, EURASIP J ADV SIG PR, V2014, p[13, 1]; Pelecanos J, 2011, FEATURE WARPING ROBU; REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SADJADI SO, 2011, P IEEE ICASSP, P5448; Sehr A, 2010, IEEE T AUDIO SPEECH, V18, P1676, DOI 10.1109/TASL.2010.2050511; Seltzer ML, 2004, IEEE T SPEECH AUDI P, V12, P489, DOI 10.1109/TSA.2004.832988; Sim BL, 1998, IEEE T SPEECH AUDI P, V6, P328; Subramaniam S, 1996, IEEE T SPEECH AUDI P, V4, P392, DOI 10.1109/89.536934; Van Veen B. D., 1988, IEEE ASSP Magazine, V5, DOI 10.1109/53.665; Vincent P, 2010, J MACHINE LEARNING R, V11, P3371; Vincent P., 2008, EXTRACTING COMPOSING, V307, P1096; Wang L., 2006, EURASIP J APPL SIG P, V2006, P1; Wang L., 2013, P ICASSP, V2013, P7224; Wang LB, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-12; Wang L, 2005, P INTERSPEECH, V2005, P1977; WANG LB, 2007, ROBUST DISTANT SPEEC, P817; Wang LB, 2007, SPEECH COMMUN, V49, P501, DOI 10.1016/j.specom.2007.04.004; Wang LB, 2011, IEICE T INF SYST, VE94D, P659, DOI 10.1587/transinf.E94.D.659; Weninger F, 2014, DEEP RECURRENT DENOI, P4623; Wu MY, 2006, IEEE T AUDIO SPEECH, V14, P774, DOI 10.1109/TSA.2005.858066; Yamada T., 2013, P INT 2013, V2013, P3661; Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029; Yu D, 2011, INTERSPEECH, P237; Zhang Z, 2014, EURASIP J AUDIO SPEE, V2014, P1; Zhu D, 2007, GEN FEATURE TRANSFOR	56	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	1687-4722			EURASIP J AUDIO SPEE	EURASIP J. Audio Speech Music Process.	MAY 12	2015									12	10.1186/s13636-015-0056-7		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CI6QL	WOS:000354885500001		
J	Abdelaziz, AH; Zeiler, S; Kolossa, D				Abdelaziz, Ahmed Hussen; Zeiler, Steffen; Kolossa, Dorothea			Learning Dynamic Stream Weights For Coupled-HMM-Based Audio-Visual Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Audio-visual speech recognition; coupled hidden Markov model; logistic regression; multilayer perceptron; reliability measure; stream weight	BAYESIAN NETWORKS; NOISE; ENHANCEMENT; ALGORITHM; ENTROPY; MODELS; ASR	With the increasing use of multimedia data in communication technologies, the idea of employing visual information in automatic speech recognition (ASR) has recently gathered momentum. In conjunction with the acoustical information, the visual data enhances the recognition performance and improves the robustness of ASR systems in noisy and reverberant environments. In audio-visual systems, dynamic weighting of audio and video streams according to their instantaneous confidence is essential for reliably and systematically achieving high performance. In this paper, we present a complete framework that allows blind estimation of dynamic stream weights for audio-visual speech recognition based on coupled hidden Markov models (CHMMs). As a stream weight estimator, we consider using multilayer perceptrons and logistic functions to map multidimensional reliability measure features to audiovisual stream weights. Training the parameters of the stream weight estimator requires numerous input-output tuples of reliability measure features and their corresponding stream weights. We estimate these stream weights based on oracle knowledge using an expectation maximization algorithm. We define 31-dimensional feature vectors that combine model-based and signal-based reliability measures as inputs to the stream weight estimator. During decoding, the trained stream weight estimator is used to blindly estimate stream weights. The entire framework is evaluated using the Grid audio-visual corpus and compared to state-of-the-art stream weight estimation strategies. The proposed framework significantly enhances the performance of the audio-visual ASR system in all examined test conditions.	[Abdelaziz, Ahmed Hussen; Zeiler, Steffen; Kolossa, Dorothea] Ruhr Univ Bochum, Cognit Signal Proc Grp, Inst Commun Acoust, D-44780 Bochum, Germany	Abdelaziz, AH (reprint author), Ruhr Univ Bochum, Cognit Signal Proc Grp, Inst Commun Acoust, D-44780 Bochum, Germany.	ahmed.hussenabdelaziz@rub.de; steffen.zeiler@rub.de; dorothea.kolossa@rub.de			Ministry of Economic Affairs and Energy of the State of North Rhine-Westphalia [IV.5-43-02/2-005-WFBO-009]; German Research Foundation DFG [KO3434/4-1]	This work was supported by the Ministry of Economic Affairs and Energy of the State of North Rhine-Westphalia under Grant IV.5-43-02/2-005-WFBO-009 and by the German Research Foundation DFG under Grant KO3434/4-1. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Dong Yu.	Abdelaziz A. H., 2014, P ICASSP, P1527; Abdelaziz A. H., 2014, P INTERSPEECH; Adjoudani A., 1996, P NATO ASI C SPEECH; Agresti A, 1992, STAT SCI, V7, P131, DOI DOI 10.1214/SS/1177011454; [Anonymous], 2003, ES202050 ETSI; Astudillo R. F., 2009, P INTERSPEECH; Bourlard H., 1996, P ICSLP; Boyd S., 2009, CONVEX OPTIMIZATION; Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544; Cohen I, 2002, IEEE SIGNAL PROC LET, V9, P12, DOI 10.1109/97.988717; Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479; Estellers V, 2012, IEEE T AUDIO SPEECH, V20, P1145, DOI 10.1109/TASL.2011.2172427; Garg A., 2003, P INT C MULT EXP, P605; Gravier G, 2002, INT CONF ACOUST SPEE, P853; Gurban M., 2008, P EUR SIGN PROC C LA; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hagan MT, 1996, NEURAL NETWORK DESIG; Heckmann M, 2002, EURASIP J APPL SIG P, V2002, P1260, DOI 10.1155/S1110865702206150; Hernando J, 1997, INT CONF ACOUST SPEE, P1267, DOI 10.1109/ICASSP.1997.596176; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Johnson R. A., 2007, APPL MULTIVARIATE ST, V6th; Jourlin P., 1997, P EUR TUT WORKSH AUD; Kantor A, 2008, INT CONF ACOUST SPEE, P4525, DOI 10.1109/ICASSP.2008.4518662; Kolossa D., 2011, P CHIME WORKSH MACH; Kolossa D, 2011, ROBUST SPEECH RECOGNITION OF UNCERTAIN OR MISSING DATA: THEORY AND APPLICATIONS, P1, DOI 10.1007/978-3-642-21317-5; Kolossa D, 2013, IEEE SIGNAL PROC LET, V20, P1018, DOI 10.1109/LSP.2013.2278556; Kolossa D., 2010, P INTERSPEECH; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Liu Peng, 2005, Tsinghua Science and Technology, V10, DOI 10.1016/S1007-0214(05)70045-6; Luettin J, 2001, INT CONF ACOUST SPEE, P169, DOI 10.1109/ICASSP.2001.940794; Marcheret E, 2007, INT CONF ACOUST SPEE, P945; Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915; MCAULAY RJ, 1980, IEEE T ACOUST SPEECH, V28, P137, DOI 10.1109/TASSP.1980.1163394; Meutzner H., 2013, P CHIME WORKSH MACH; MISRA H, 2003, ACOUST SPEECH SIG PR, P741; Nakamura S., 2001, P ASRU2001, P409; Nefian AV, 2002, EURASIP J APPL SIG P, V2002, P1274, DOI 10.1155/S1110865702206083; Neti C., 2001, P IEEE WORKSH MULT S, P619; OpenCV L., 2008, COMPUTER VISION OPEN; Polak E., 1969, REV FRANCAISE INFORM, V16, P35; Potamianos G., 1998, P ICASSP, P3373; Potamianos G., 2000, P ICSLP; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Teissier P, 1999, IEEE T SPEECH AUDI P, V7, P629, DOI 10.1109/89.799688; Tomlinson MJ, 1996, INT CONF ACOUST SPEE, P821, DOI 10.1109/ICASSP.1996.543247; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Vincent E, 2013, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2013.6637622; Virtanen T., 2012, TECHNIQUES NOISE ROB; Vorwerk A, 2011, ROBUST SPEECH RECOGNITION OF UNCERTAIN OR MISSING DATA: THEORY AND APPLICATIONS, P345, DOI 10.1007/978-3-642-21317-5_13; Watanabe T., 1990, P ICSLP	53	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	MAY	2015	23	5					863	876		10.1109/TASLP.2015.2409785		14	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CF1CP	WOS:000352281500005		
J	Baxter, RH; Leach, MJV; Mukherjee, SS; Robertson, NM				Baxter, Rolf H.; Leach, Michael J. V.; Mukherjee, Sankha S.; Robertson, Neil M.			An Adaptive Motion Model for Person Tracking with Instantaneous Head-Pose Features	IEEE SIGNAL PROCESSING LETTERS			English	Article						Computer vision; context awareness; deep belief networks; head pose estimation; tracking; video signal processing; video surveillance	SURVEILLANCE; PATTERNS	This letter presents novel behaviour-based tracking of people in low-resolution using instantaneous priors mediated by head-pose. We extend the Kalman Filter to adaptively combine motion information with an instantaneous prior belief about where the person will go based on where they are currently looking. We apply this new method to pedestrian surveillance, using automatically-derived head pose estimates, although the theory is not limited to head-pose priors. We perform a statistical analysis of pedestrian gazing behaviour and demonstrate tracking performance on a set of simulated and real pedestrian observations. We show that by using instantaneous 'intentional' priors our algorithm significantly outperforms a standard Kalman Filter on comprehensive test data.	[Baxter, Rolf H.; Mukherjee, Sankha S.; Robertson, Neil M.] Heriot Watt Univ, Inst Sensors Signals & Syst, Edinburgh EH14 4AS, Midlothian, Scotland; [Leach, Michael J. V.] Chemring Technol Solut, Romsey SO51 0ZN, Hants, England	Baxter, RH (reprint author), Heriot Watt Univ, Inst Sensors Signals & Syst, Edinburgh EH14 4AS, Midlothian, Scotland.	r.h.baxter@hw.ac.uk; michael.leach@chemringts.com; sm794@hw.ac.uk; n.m.robertson@hw.ac.uk			Engineering and Physical Sciences Research Council (EPSRC) [EP/K014277/1]; MOD University Defence Research Collaboration in Signal Processing	This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) under Grant EP/K014277/1 and the MOD University Defence Research Collaboration in Signal Processing. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Ba-Tuong Vo.	Ba SO, 2004, INT C PATT RECOG, P264, DOI 10.1109/ICPR.2004.1333754; Baxter R. H., 2014, SENSOR SIGNAL PROCES; Bazzani L, 2013, EXPERT SYST, V30, P115, DOI 10.1111/j.1468-0394.2012.00622.x; Benfold B, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2344, DOI 10.1109/ICCV.2011.6126516; Chen C., 2011, IEEE INT C COMP VIS, P860; Chen C, 2012, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2012.6247845; Dee H. M., 2005, IEEE C ADV VID SIGN, P34; Dee HM, 2009, ARTIF INTELL, V173, P329, DOI 10.1016/j.artint.2008.10.011; Ferryman J., 2007, P 10 IEEE INT WORKSH; Hartley R., 2004, MULTIPLE VIEW GEOMET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450; Jacques JCS, 2007, PATTERN ANAL APPL, V10, P321, DOI 10.1007/s10044-007-0070-1; Johnson N., 1996, IMAGE VISION COMPUT, V14, P583; Kalman R., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805; Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Pellegrini S, 2013, COMPUT VIS IMAGE UND, V117, P1215, DOI 10.1016/j.cviu.2012.09.005; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004; Robertson N. M., 2011, EURASIP J IMAGE VIDE; Sankaranarayanan K., 2011, IEEE WORKSH APPL COM, P519; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003; Welch G., 2006, INTRO KALMAN FILTER	26	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9908	1558-2361		IEEE SIGNAL PROC LET	IEEE Signal Process. Lett.	MAY	2015	22	5					578	582		10.1109/LSP.2014.2364458		5	Engineering, Electrical & Electronic	Engineering	AT5QA	WOS:000344995900002		
J	Cao, YQ; Chen, Y; Khosla, D				Cao, Yongqiang; Chen, Yang; Khosla, Deepak			Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Deep learning; Machine learning; Convolutional neural networks; Spiking neural networks; Neuromorphic circuits; Object recognition	INFEROTEMPORAL CORTEX; PATTERN-RECOGNITION; RECEPTIVE FIELDS; VIEW-INVARIANT; REPRESENTATIONS; NEOCOGNITRON; CIRCUITS; POSITION; MODELS	Deep-learning neural networks such as convolutional neural network (CNN) have shown great potential as a solution for difficult vision problems, such as object recognition. Spiking neural networks (SNN)-based architectures have shown great potential as a solution for realizing ultra-low power consumption using spike-based neuromorphic hardware. This work describes a novel approach for converting a deep CNN into a SNN that enables mapping CNN to spike-based hardware architectures. Our approach first tailors the CNN architecture to fit the requirements of SNN, then trains the tailored CNN in the same way as one would with CNN, and finally applies the learned network weights to an SNN architecture derived from the tailored CNN. We evaluate the resulting SNN on publicly available Defense Advanced Research Projects Agency (DARPA) Neovision2 Tower and CIFAR-10 datasets and show similar object recognition accuracy as the original CNN. Our SNN implementation is amenable to direct mapping to spike-based neuromorphic hardware, such as the ones being developed under the DARPA SyNAPSE program. Our hardware mapping analysis suggests that SNN implementation on such spike-based hardware is two orders of magnitude more energy-efficient than the original CNN implementation on off-the-shelf FPGA-based hardware.	[Cao, Yongqiang; Chen, Yang; Khosla, Deepak] HRL Labs LLC, Malibu, CA 90265 USA	Chen, Y (reprint author), HRL Labs LLC, 3011 Malibu Canyon Rd, Malibu, CA 90265 USA.	ychen@hrl.com			Defense Advanced Research Projects Agency Cognitive Technology Threat Warning System (CT2WS) program [W31P4Q-08-C-0264, HR0011-09-C-0001]; SyNAPSE program [W31P4Q-08-C-0264, HR0011-09-C-0001]	This work was partially supported by the Defense Advanced Research Projects Agency Cognitive Technology Threat Warning System (CT2WS) and SyNAPSE programs (contracts W31P4Q-08-C-0264 and HR0011-09-C-0001). The views expressed in this document are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. We would like to thank Dr. Clement Farabet of New York University for providing the initial CNN structure on which the CNN model outlined in Fig. 1 is based; and the anonymous reviewers for their invaluable comments and recommendations that led to this revised manuscript.	Arthur J. V., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252637; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Cao YQ, 2011, NEURAL NETWORKS, V24, P1050, DOI 10.1016/j.neunet.2011.04.004; Cao YQ, 2012, NEURAL NETWORKS, V26, P75, DOI 10.1016/j.neunet.2011.10.010; Cassidy A.S., 2013, 2013 INT JOINT C NEU, P1; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Collobert R, 2011, BIGLEARN; Cruz-Albrecht JM, 2012, IEEE T BIOMED CIRC S, V6, P246, DOI 10.1109/TBCAS.2011.2174152; Farabet C., 2010, IEEE INT S CIRC SYST; Farabet C, 2013, THESIS U PARIS EST; Fazl A, 2009, COGNITIVE PSYCHOL, V58, P1, DOI 10.1016/j.cogpsych.2008.05.001; Folowosele F, 2011, IEEE J EM SEL TOP C, V1, P516, DOI 10.1109/JETCAS.2012.2183409; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Grossberg S, 2009, J VISION, V9, DOI 10.1167/9.4.6; Grossberg S, 2011, NEURAL NETWORKS, V24, P1036, DOI 10.1016/j.neunet.2011.04.001; Hinton G, 2006, COGNITIVE SCI, V30, P725, DOI 10.1207/s15516709cog0000_76; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ho N, 2013, CONVOLUTIONAL NEUR 3; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Itti L, 2013, NEOVISION2 ANNOTATED; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Khosla D., 2013, P SPIE, V8745; Khosla D., 2013, P SPIE, V8713; Krizhevsky A., 2009, THESIS U TORONTO; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin M., 2014, INT C LEARN REPR ICL; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; Merolla P., 2011, CUST INT CIRC C CICC, DOI [10.1109/CICC.2011.6055294, DOI 10.1109/CICC.2011.6055294]; Perez-Carrasco J.A., 2010, 2010 INT C PATT REC, P3085, DOI 10.1109/ICPR.2010.756; Ranzato M., 2007, COMP VIS PATT REC IE, V5, P1; Razavian A.S., 2014, DEEPVISION CVPR 2014; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sermanet P., 2014, INT C LEARN REPR ICL; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56	40	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2015	113	1			SI		54	66		10.1007/s11263-014-0788-3		13	Computer Science, Artificial Intelligence	Computer Science	CH6GX	WOS:000354135700005		
J	Chaturvedi, I; Ong, YS; Arumugam, RV				Chaturvedi, Iti; Ong, Yew-Soon; Arumugam, Rajesh Vellore			Deep transfer learning for classification of time-delayed Gaussian networks	SIGNAL PROCESSING			English	Article						Transfer learning; Manifold; Time-delays; Variable-order; Gaussian networks; Deep neural networks	BAYESIAN NETWORKS; SELECTION; FEEDBACK; GRAPHS	In this paper, we propose deep transfer learning for classification of Gaussian networks with time-delayed regulations. To ensure robust signaling, most real world problems from related domains have inherent alternate pathways that can be learned incrementally from a stable form of the baseline. In this paper, we leverage on this characteristic to address the challenges of complexity and scalability. The key idea is to learn high dimensional network motifs from low dimensional forms through a process of transfer learning. In contrast to previous work, we facilitate positive transfer by introducing a triangular inequality constraint, which provides a measure for the feasibility of mapping between different motif manifolds. Network motifs from different classes of Gaussian networks are used collectively to pre-train a deep neural network governed by a Lyapunov stability condition. The proposed framework is validated on time series data sampled from synthetic Gaussian networks and applied to a real world dataset for the classification of basketball games based on skill level. We observe an improvement in the range of [15-25]% in accuracy and a saving in the range of [25-600]% in computational cost on synthetic as well as realistic networks with time-delays when compared to existing state-of-the-art approaches. In addition, new insights into meaningful offensive formations in the Basketball games can be derived from the deep network. (C) 2014 Elsevier B.V. All rights reserved.	[Chaturvedi, Iti; Ong, Yew-Soon] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Arumugam, Rajesh Vellore] Data Storage Inst, Singapore, Singapore	Ong, YS (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	iti@ntu.edu.sg; asysong@ntu.edu.sg; Rajesh_VA@dsi.a-star.edu.sg			ASTAR Thematic Strategic Research Programme (TSRP) Grant [1121720013]; Center for Computational Intelligence (C2I) at NTU	This work is partially supported by the ASTAR Thematic Strategic Research Programme (TSRP) Grant no. 1121720013 and the Center for Computational Intelligence (C2I) at NTU.	Akutsu T, 2000, J COMPUT BIOL, V7, P331, DOI 10.1089/106652700750050817; Bocsi B., 2013, 2013 INT JOINT C NEU, P1; Bonilla E. V., 2008, ADV NEURAL INFORM PR, V20, P153; Castillo E, 2003, RELIAB ENG SYST SAFE, V79, P139, DOI 10.1016/S0951-8320(02)00225-9; Castillo E., 1996, EXPERT SYSTEMS PROBA; Chen HT, 2012, J VIS COMMUN IMAGE R, V23, P932, DOI 10.1016/j.jvcir.2012.06.003; Chen M., 2012, P 29 INT C MACH LEAR, P767; Chickering D.M., 1997, MACH LEARN, P29; Chow Jia Yi K.Y.H., 2013, ECSS; Fink G. A., 2008, MARKOV MODELS PATTER; Friedman N., 2000, P 16 C UNC ART INT U, P211; Friedman N., 1998, P 14 C UNC ART INT, P139; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; Hamilton J. D., 1994, TIME SERIES ANAL; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Imoto Seiya, 2003, J Bioinform Comput Biol, V1, P231, DOI 10.1142/S0219720003000071; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Li P, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S7-S13; Liu H, 2009, J MACH LEARN RES, V10, P2295; MACHIGASHIRA Y, 1993, P AM MATH SOC, V118, P979, DOI 10.2307/2160150; Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281; Nariai N., 2004, PAC S BIOCOMPUT, V9, P336; Ota K., 2003, GENOME INFORM, V14, P302; Pearl J., 1988, MORGAN KAUFMANN SERI; Prinzie A, 2009, LECT NOTES ARTIF INT, V5433, P123; Raina R., 2006, ICML 2006, P713; Rencher A.C., 2002, METHODS MULTIVARIATE; Schwaighofer A., 2007, STRUCTURE LEARNING D; Seah CW, 2012, IEEE T NEUR NET LEAR, V23, P1074, DOI 10.1109/TNNLS.2012.2198240; Seth AK, 2010, J NEUROSCI METH, V186, P262, DOI 10.1016/j.jneumeth.2009.11.020; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Wagner J, 2005, IEE P SYST BIOL, V152, P109, DOI 10.1049/ip-syb:20050025; Wagner J, 2008, P IEEE, V96, P1398, DOI 10.1109/JPROC.2008.925427; Wu ZG, 2011, ASIAN J CONTROL, V13, P914, DOI 10.1002/asjc.219; Xing Z., 2006, 6 IEEE INT C DAT MIN, P190, DOI 10.1109/ICDMW.2006.120; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083; Yu J, 2012, SIGNAL PROCESS, V92, P2147, DOI 10.1016/j.sigpro.2012.01.028; Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377	43	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684	1879-2677		SIGNAL PROCESS	Signal Process.	MAY	2015	110				SI		250	262		10.1016/j.sigpro.2014.09.009		13	Engineering, Electrical & Electronic	Engineering	CC2OE	WOS:000350183700025		
J	Chen, G; Clarke, D; Giuliani, M; Gaschler, A; Knoll, A				Chen, Guang; Clarke, Daniel; Giuliani, Manuel; Gaschler, Andre; Knoll, Alois			Combining unsupervised learning and discrimination for 3D action recognition	SIGNAL PROCESSING			English	Article						Human action recognition; Depth camera; Unsupervised learning; Multi-kernel learning; Ensemble learning	SUBSPACE; ENSEMBLE; FEATURES	Previous work on 3D action recognition has focused on using hand-designed features, either from depth videos or 2D videos. In this work, we present an effective way to combine unsupervised feature learning with discriminative feature mining. Unsupervised feature learning allows us to extract spatio-temporal features from unlabeled video data. With this, we can avoid the cumbersome process of designing feature extraction by hand. We propose an ensemble approach using a discriminative learning algorithm, where each base learner is a discriminative multi-kernel-learning classifier, trained to learn an optimal combination of joint-based features. Our evaluation includes a comparison to state-of-the-art methods on the MSRAction 3D dataset, where our method, abbreviated EnMkl, outperforms earlier methods. Furthermore, we analyze the efficiency of our approach in a 3D action recognition system. (C) 2014 Elsevier B.V. All rights reserved.	[Chen, Guang; Knoll, Alois] Tech Univ Munich, Inst Informat 6, D-85748 Garching, Germany; [Chen, Guang; Clarke, Daniel; Giuliani, Manuel; Gaschler, Andre] Tech Univ Munich, Fortiss GmbH, D-80805 Munich, Germany	Chen, G (reprint author), Tech Univ Munich, Fortiss GmbH, Guerickestr 25, D-80805 Munich, Germany.	guang@in.tum.de; clarke@fortiss.org; giuliani@fortiss.org; gaschler@fortiss.org; knoll@in.tum.de					Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bloom V., 2012, IEEE C COMP VIS PATT, P7; Chen G., 2014, INT C COMP VIS THEOR; Chen G., 2014, CHALEARN LOOK PEOPL; Chen G., 2014, IEEE INT C ROB AUT; Chen G., 2013, INT C SOC ROB; Chen G., 2013, 12 INT C MACH LEARN, V1, P197; Cheng Z., LECT NOTES COMPUTER, V7584, P52; Dalai N, 2005, IEEE COMP SOC C COMP, V1, P886, DOI DOI 10.1109/CVPR.2005.177; Dong G., 1999, ACM SIGKDD INT C KNO, P43; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gaschler A., 2012, ACM IEEE HCI C GAZ H; Gaschler A., 2012, IEEE RSJ INT C INT R; Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57; Gowayyed M.A., 2013, INT JOINT C ART INT, P1351; Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436; Hernandez-Vela A, 2012, INT C PATT RECOG, P449; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2009, NATURAL IMAGE STAT P; Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174; Kurakin A, 2012, EUR SIGNAL PR CONF, P1975; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587756; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q. V., 2011, IEEE C COMP VIS PATT, P3361; Li W., 2010, CVPR WORKSH, V1, P9; Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597; Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853; Ni B., 2011, ICCV WORKSH, P1147; Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999; Oreifej O., 2013, IEEE C COMP VIS PATT; Oshin O., 2011, IEEE INT C AUT FAC G, P111; Platt J., 1999, ADV LARGE MARGIN CLA, V1, P61; Read J., 2010, PLOS ONE, V5; Rehmani H., 2014, IEEE WINT APPL COMP; Reyes M., 2011, IEEE INT C COMP VIS, P1182, DOI DOI 10.1109/ICCVW.2011.6130384; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Vieira A.W., 2012, PROGR PATTERN RECOGN, V7441, P252; Vishwanathan S.V.N., 2010, ADV NEURAL INFORM PR, V23; Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123; Wang H., 2009, BRIT MACH VIS C; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872; Wang J., 2013, IEEE INT C COMP VIS; Xia L., 2012, IEEE COMP SOC C COMP, P20; Xia L., 2013, IEEE C COMP VIS PATT; Xu X.-S., 2012, P 20 ACM INT C MULT, P737; Yang X., 2012, ICCV WORKSH, P14; Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395; Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377; Yu J, 2012, IEEE T SYST MAN CY B, V42, P1413, DOI 10.1109/TSMCB.2012.2192108; Zhao Y., 2012, SIGN INF PROC ASS AN, P1; Zhou Z.-H., 2009, ENCY BIOMETRICS, P270; Zhu L, 2008, IEEE VEH POW PROP C, P1	59	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684	1879-2677		SIGNAL PROCESS	Signal Process.	MAY	2015	110				SI		67	81		10.1016/j.sigpro.2014.08.024		15	Engineering, Electrical & Electronic	Engineering	CC2OE	WOS:000350183700008		
J	Joanisse, MF; McClelland, JL				Joanisse, Marc F.; McClelland, James L.			Connectionist perspectives on language learning, representation and processing	WILEY INTERDISCIPLINARY REVIEWS-COGNITIVE SCIENCE			English	Review							SPOKEN-WORD-RECOGNITION; SPEECH-PERCEPTION; TIME-COURSE; PAST TENSE; LEXICAL ACCESS; EYE-MOVEMENTS; TRACE MODEL; ACQUISITION; RULES; COMPREHENSION	The field of formal linguistics was founded on the premise that language is mentally represented as a deterministic symbolic grammar. While this approach has captured many important characteristics of the world's languages, it has also led to a tendency to focus theoretical questions on the correct formalization of grammatical rules while also de-emphasizing the role of learning and statistics in language development and processing. In this review we present a different approach to language research that has emerged from the parallel distributed processing or 'connectionist' enterprise. In the connectionist framework, mental operations are studied by simulating learning and processing within networks of artificial neurons. With that in mind, we discuss recent progress in connectionist models of auditory word recognition, reading, morphology, and syntactic processing. We argue that connectionist models can capture many important characteristics of how language is learned, represented, and processed, as well as providing new insights about the source of these behavioral patterns. Just as importantly, the networks naturally capture irregular (non-rule-like) patterns that are common within languages, something that has been difficult to reconcile with rule-based accounts of language without positing separate mechanisms for rules and exceptions. WIREs Cogn Sci 2015, 6:235-247. doi: 10.1002/wcs.1340 For further resources related to this article, please visit the . Conflict of interest: The authors have declared no conflicts of interest for this article.	[Joanisse, Marc F.] Univ Western Ontario, Psychol Brain & Mind Inst, London, ON, Canada; [McClelland, James L.] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA	Joanisse, MF (reprint author), Univ Western Ontario, Psychol Brain & Mind Inst, London, ON, Canada.	marcj@uwo.ca			Canadian Institutes of Health Research; Natural Sciences and Engineering Research Council (Canada)	MFJ is supported by operating grants from the Canadian Institutes of Health Research and the Natural Sciences and Engineering Research Council (Canada).	Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558; BEAUVILLAIN C, 1987, J MEM LANG, V26, P658, DOI 10.1016/0749-596X(87)90108-2; BEAUVOIS MF, 1979, J NEUROL NEUROSUR PS, V42, P1115, DOI 10.1136/jnnp.42.12.1115; Bowers JS, 2014, PSYCHOL REV, V121, P248, DOI 10.1037/a0035943; BYBEE JL, 1982, LANGUAGE, V58, P265, DOI 10.2307/414099; Chater N, 2006, TRENDS COGN SCI, V10, P335, DOI 10.1016/j.tics.2006.05.006; Chemla E, 2009, DEVELOPMENTAL SCI, V12, P396, DOI 10.1111/j.1467-7687.2009.00825.x; Chomsky N., 1959, INFORM CONTR, V2, P137, DOI DOI 10.1016/S0019-9958(59)90362-6; Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750; DAUGHERTY K, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P259; Dell GS, 1997, PSYCHOL REV, V104, P801, DOI 10.1037/0033-295X.104.4.801; Dijkstra A, 1998, LOCALIST CONNECTIONI, P189; Dilkina K, 2008, COGN NEUROPSYCHOL, V25, P136, DOI 10.1080/02643290701723948; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Forster KI, 1976, NEW APPROACHES LANGU, P257; GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110; Gotts Stephen J., 2004, Seminars in Speech and Language, V25, P323, DOI 10.1055/s-2004-837245; Grosjean F. M. J., 1988, LANG COGNITIVE PROC, V3, P233, DOI DOI 10.1080/01690968808402089; Hahn U, 2000, COGNITIVE PSYCHOL, V41, P313, DOI 10.1006/cogp.2000.0737; Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563; Harm MW, 2004, PSYCHOL REV, V111, P662, DOI 10.1037/0033-295X.111.3.662; Harm MW, 1999, PSYCHOL REV, V106, P491, DOI 10.1037//0033-295X.106.3.491; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Joanisse MF, 1999, P NATL ACAD SCI USA, V96, P7592, DOI 10.1073/pnas.96.13.7592; Jones M, 2011, BEHAV BRAIN SCI, V34, P215, DOI [10.1017/S0140525X10003134, 10.1017/S0140525X11001439]; KUCZAJ SA, 1977, J VERB LEARN VERB BE, V16, P589, DOI 10.1016/S0022-5371(77)80021-2; Le QV, 2012, P INT C MACH LEARN E; Leonard L. B., 1998, CHILDREN SPECIFIC LA; MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037//0033-295X.101.4.676; Magnuson JS, 2003, J EXP PSYCHOL GEN, V132, P202, DOI 10.1037/0096-3445.132.2.202; Manis FR, 1996, COGNITION, V58, P157, DOI 10.1016/0010-0277(95)00679-6; Marcus G F, 1992, Monogr Soc Res Child Dev, V57, P1; MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9; Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3; McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002; MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0; McClelland JL, 1986, PARALLEL DISTRIBUTED, VII; McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007; Mirkovic J, 2011, COGNITIVE SCI, V35, P638, DOI 10.1111/j.1551-6709.2011.01174.x; Mohamed A., 2009, SCIENCE, V4, P1, DOI [10.4249/scholarpedia.5947, DOI 10.4249/SCHOLARPEDIA.5947]; Newmeyer Frederick J, 1998, LANGUAGE FORM LANGUA; Patterson KE, 1985, SURFACE DYSLEXIA NEU; Pereira JMS, 2009, NEUROLOGY, V72, P1653, DOI 10.1212/WNL.0b013e3181a55fa2; Piatelli-Palmarini M., 1980, LANGUAGE LEARNING DE; PINKER S, 1991, SCIENCE, V253, P530, DOI 10.1126/science.1857983; Pinker S, 2005, COGNITION, V95, P201, DOI 10.1016/j.cognition.2004.08.004; Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56; Rogers TT, 2004, PSYCHOL REV, V111, P205, DOI 10.1037/0033-295X.111.1.205; Rogers TT, 2003, LANG COGNITIVE PROC, V18, P625, DOI 10.1080/01690960344000053; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V2, P216; Saffran JR, 1996, SCIENCE, V274, P1296; Saxe AM, 2013, P 35 ANN M COGN SCI, P1271; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Smolensky P, 1999, COGNITIVE SCI, V23, P589, DOI 10.1016/S0364-0213(99)00017-8; Socher R., 2013, P 51 ANN M ASS COMP, V1, P455; Socher R., 2013, P 2013 C EMP METH NA, P1631; Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840; TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x; TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863; Tanenhaus MK, 2000, J PSYCHOLINGUIST RES, V29, P557, DOI 10.1023/A:1026464108329; Thomas MSC, 2003, PSYCHOL REV, V110, P647, DOI 10.1037/0033-295X.110.4.647; Ullman M., 1997, J COGNITIVE NEUROSCI, V9, P289; WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392; Westermann G, 2012, PSYCHOL REV, V119, P649, DOI 10.1037/a0028258; Yang JF, 2009, J MEM LANG, V61, P238, DOI 10.1016/j.jml.2009.05.001; Zhou XL, 1999, J EXP PSYCHOL LEARN, V25, P819, DOI 10.1037//0278-7393.25.4.819	67	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1939-5078	1939-5086		WIRES COGN SCI	Wiley Interdiscip. Rev.-Cogn. Sci.	MAY-JUN	2015	6	3					235	247		10.1002/wcs.1340		13	Psychology, Experimental	Psychology	CH2WP	WOS:000353886000004		
J	Ling, ZH; Kang, SY; Zen, H; Senior, A; Schuster, M; Qian, XJ; Meng, H; Deng, L				Ling, Zhen-Hua; Kang, Shi-Yin; Zen, Heiga; Senior, Andrew; Schuster, Mike; Qian, Xiao-Jun; Meng, Helen; Deng, Li			Deep Learning for Acoustic Modeling in Parametric Speech Generation	IEEE SIGNAL PROCESSING MAGAZINE			English	Review							VOICE CONVERSION; NEURAL-NETWORKS; SYNTHESIS SYSTEM; BELIEF NETWORKS; HMM; REPRESENTATIONS; ENHANCEMENT; RECOGNITION; ALGORITHM; EXPERTS		[Ling, Zhen-Hua] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland; [Ling, Zhen-Hua] Univ Sci & Technol China & iFLY TEK Co Ltd, Hefei, Peoples R China; [Ling, Zhen-Hua] Univ Sci & Technol China, Hefei, Peoples R China; [Ling, Zhen-Hua] Univ Washington, Seattle, WA 98195 USA; [Kang, Shi-Yin; Qian, Xiao-Jun; Meng, Helen] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China; [Zen, Heiga; Senior, Andrew] Google, Mountain View, CA USA; [Zen, Heiga; Senior, Andrew] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA; [Zen, Heiga] Toshiba Res Europe Ltd, Cambridge Res Lab, Cambridge, England; [Schuster, Mike] Adv Telecommun Res Labs, Kyoto, Japan; [Qian, Xiao-Jun] Microsoft Res Asia, Speech Grp, Beijing, Peoples R China; [Meng, Helen] Chinese Univ Hong Kong, Fac Engn, Hong Kong, Hong Kong, Peoples R China; [Deng, Li] Univ Waterloo, Waterloo, ON N2L 3G1, Canada; [Deng, Li] Microsoft Res, Deep Learning Technol Ctr, Redmond, WA USA; [Deng, Li] Univ Washington, Seattle, WA 98195 USA	Ling, ZH (reprint author), Univ Sci & Technol China, Hefei, Peoples R China.	zhling@ustc.edu.cn; sykang@se.cuhk.edu.hk; heigazen@google.com; andrewsenior@google.com; schuster@google.com; xjqian@se.cuhk.edu.hk; hmmeng@se.cuhk.edu.hk; deng@microsoft.com	Magazine, Signal Processing/E-9947-2015				Abe M., 1990, Journal of the Acoustical Society of Japan (E), V11; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Chen L.-H., 2013, P INTERSPEECH, P3052; Chen LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1859, DOI 10.1109/TASLP.2014.2353991; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Deng L, 1997, SPEECH COMMUN, V22, P93, DOI 10.1016/S0167-6393(97)00018-6; Deng L., 2003, MATH FDN SPEECH LANG, P115; Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692; Deng L, 2003, SPEECH PROCESSING DY; Desai S, 2010, IEEE T AUDIO SPEECH, V18, P954, DOI 10.1109/TASL.2010.2047683; Erro D, 2010, IEEE T AUDIO SPEECH, V18, P922, DOI 10.1109/TASL.2009.2038663; Fernandez R, 2013, INT CONF ACOUST SPEE, P6885, DOI 10.1109/ICASSP.2013.6638996; Fukada T., 1992, P ICASSP 92, V1, P137; Helander E, 2012, IEEE T AUDIO SPEECH, V20, P806, DOI 10.1109/TASL.2011.2165944; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI DOI 10.1109/9780470544037.CH14; KANG SY, 2013, P ICASSP, P8012; Kang S.-Y., 2014, P INTERSPEECH; Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5; Koriyama T, 2014, IEEE J-STSP, V8, P173, DOI 10.1109/JSTSP.2013.2283461; Ling ZH, 2012, IEEE T AUDIO SPEECH, V20, P1492, DOI 10.1109/TASL.2011.2182511; Ling ZH, 2013, INT CONF ACOUST SPEE, P7825; Ling Z.-H., 2013, IEEE T AUDIO SPEECH, V21, P207; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; Ling Z.-H., 2006, P BLIZZ CHALL WORKSH; Lu H., 2013, P ISCA SSW8, P261; Lu X, 2013, P INT 13 AUG, P436; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mouchtaris A, 2007, IEEE T AUDIO SPEECH, V15, P1180, DOI 10.1109/TASL.2007.894511; Nakashika T., 2014, P IEEE INT C AC SPEE, P7939; Nakashika T., 2013, P INTERSPEECH, P369; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Nose T, 2007, IEICE T INF SYST, VE90D, P1406, DOI 10.1093/ietisy/e90-d.9.1406; Odell JJ, 1995, THESIS CAMBRIDGE U; Park KY, 2000, INT CONF ACOUST SPEE, P1843; Qian Y., 2014, P IEEE INT C AC SPEE, P3857; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Saheer L, 2012, IEEE T AUDIO SPEECH, V20, P2134, DOI 10.1109/TASL.2012.2198058; Sainath TN, 2013, IEEE T AUDIO SPEECH, V21, P2267, DOI 10.1109/TASL.2013.2284378; Saito D, 2012, IEEE T AUDIO SPEECH, V20, P1784, DOI 10.1109/TASL.2012.2188628; Salakhutdinov R., 2009, THESIS U TORONTO; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; Sun JP, 2002, J ACOUST SOC AM, V111, P1086, DOI 10.1121/1.1420380; Tachibana M, 2005, IEICE T INF SYST, VE88D, P2484, DOI 10.1093/ietisy/e88-d.11.2484; Taylor G., 2007, P C ADV NEUR INF PRO, P1345; Tiomkin T., 2010, IEEE T AUDIO SPEECH, V18, P1077; Toda T, 2012, IEEE T AUDIO SPEECH, V20, P2505, DOI 10.1109/TASL.2012.2205241; Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Toda T, 2007, IEICE T INF SYST, VE90D, P816, DOI 10.1093/ietisy/e90-d.5.816; Tokuda K., 2002, P IEEE SPEECH SYNTH; TOKUDA K, 1995, INT CONF ACOUST SPEE, P660, DOI 10.1109/ICASSP.1995.479684; Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Uria B., 2011, P NIPS 2011 WORKSH D; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wu YJ, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P577; Wu YJ, 2006, INT CONF ACOUST SPEE, P89; Wu Z.-Z, 2013, P IEEE CHIN SUMM INT, P104; Xia B.-Y., 2013, P INTERSPEECH, P3444; Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240; Xu Y., P INT IN PRESS; Yamagishi J., 2005, IEICE T INF SYST, VE88-D, P503; Yamagishi J, 2007, IEICE T INF SYST, VE90D, P533, DOI 10.1093/ietisy/e90-d.2.533; Yamagishi J, 2009, IEEE T AUDIO SPEECH, V17, P1208, DOI 10.1109/TASL.2009.2016394; Yoshimura T., 2002, THESIS NAGOYA I TECH; Yoshimura T, 1998, P ICSLP, P29; Yoshimura T., 1999, P EUR, P2347; Yu D., 2010, P NIPS WORKSH DEEP L; Yu K, 2011, SPEECH COMMUN, V53, P914, DOI 10.1016/j.specom.2011.03.003; Zen H, 2012, IEEE T AUDIO SPEECH, V20, P1713, DOI 10.1109/TASL.2012.2187195; Zen H., 2014, P IEEE INT C AC SPEE, P3872; Zen H., 2013, COMMUNICATION; Zen H, 2012, IEEE T AUDIO SPEECH, V20, P794, DOI 10.1109/TASL.2011.2165280; Zen H, 2007, COMPUT SPEECH LANG, V21, P153, DOI 10.1016/j.csl.2006.01.002; Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825; Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004; Zen HG, 2013, INT CONF ACOUST SPEE, P7962; Zen HG, 2007, IEICE T INF SYST, VE90D, P325, DOI 10.1093/ietisy/e90-d.1.325; Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986	86	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-5888	1558-0792		IEEE SIGNAL PROC MAG	IEEE Signal Process. Mag.	MAY	2015	32	3					35	52		10.1109/MSP.2014.2359987		18	Engineering, Electrical & Electronic	Engineering	CF4DL	WOS:000352498800006		
J	Raja, KB; Raghavendra, R; Vemuri, VK; Busch, C				Raja, Kiran B.; Raghavendra, R.; Vemuri, Vinay Krishna; Busch, Christoph			Smartphone based visible iris recognition using deep sparse filtering	PATTERN RECOGNITION LETTERS			English	Article						Visible iris recognition; Deep sparse filtering; Sinartphone iris; Noisy iris; Biometrics	ALGORITHM; IMAGES	Good biometric performance of iris recognition motivates it to be used for many large scale security and access control applications. Recent works have identified visible spectrum iris recognition as a viable option with considerable performance. Key advantages of visible spectrum iris recognition include the possibility of iris imaging in on-the-move and at-a-distance scenarios as compared to fixed range imaging in near-infrared light. The unconstrained iris imaging captures the images with largely varying radius of iris and pupil. In this work, we propose a new segmentation scheme and adapt it to smartphone based visible iris images for approximating the radius of the iris to achieve robust segmentation. The proposed technique has shown the improved segmentation accuracy up to 85% with standard OSIRIS v4.1. This work also proposes a new feature extraction method based on deep sparse filtering to obtain robust features for unconstrained iris images. To evaluate the proposed segmentation scheme and feature extraction scheme, we employ a publicly available database and also compose a new iris image database. The newly composed iris image database (VSSIRIS) is acquired using two different srnartphones - iPhone 5S and Nokia Lumia 1020 under mixed illumination with unconstrained conditions in visible spectrum. The biornetric performance is benchmarked based on the equal error rate ([ER) obtained from various state-of-art schemes and proposed feature extraction scheme. An impressive EER of 1.62% is obtained on our VSSIRIS database and an average gain of around 2% in EER is obtained on the public database as compared to the well-known state-of-art schemes. (C) 2014 Elsevier B.V. All rights reserved.	[Raja, Kiran B.; Raghavendra, R.; Vemuri, Vinay Krishna] Giovik Univ Coll, Norwegian Biometr Lab, N-2802 Gjovik, Norway; [Busch, Christoph] Hsch Darmstadt CASED, D-64295 Darmstadt, Germany	Raja, KB (reprint author), Giovik Univ Coll, Norwegian Biometr Lab, N-2802 Gjovik, Norway.	kiran.raja@hig.no			Morpho (Safran Group)	The authors also wish to express thanks to Morpho (Safran Group) for supporting this work, and in particular to Morpho Research & Technology team for the fruitful technical and scientific exchanges related to this particular work.	Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bowyer KW, 2012, PATTERN RECOGN LETT, V33, P965, DOI 10.1016/j.patrec.2011.11.024; Cheng K. Y., 2012, P IEEE INT MICR S MO, P1; Cheng M.M., 2011, TECHNICAL REPORT; Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; ISO/IEC TC JTC1 SC37 Biometrics, 1979512006 ISOIEC; Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519; Masek L., 2003, MATLAB SOURCE CODE B, V2; Matlab MATLAB, 2013, MATL MATLAB VERS 8 2; Ngiam J., 2011, NIPS, V11, P1125; Proenca H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66; Raghavendra R., 2013, TECHN HOM SEC HST IE, P552; Raghavendra R., 2013, BIOM ICB 2013 6 IAPR, P1; Raghavendra R., 2013, 2 IAPR AS C PATT REC; Raja K.B., 2013, IEEE C COL VIS COMP; Rathgeb C., 2013, ADV INFORM SECURITY, V59; RATHGEB C, 2010, IMAGE ANAL RECOGNITI, V6112, P266, DOI 10.1007/978-3-642-13775-4_27; Rathgeb C, 2011, IET COMPUT VIS, V5, P389, DOI 10.1049/iet-cvi.2010.0176; Stein C., 2012, BIOM SPEC INT GROUP, P1; Sutra G., 2012, BIOMETRIC REFERENCE; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359; Venkataramani K, 2005, IEEE T SYST MAN CY C, V35, P411, DOI 10.1109/TSMCC.2005.848183; Weickert J, 2002, J VIS COMMUN IMAGE R, V13, P103, DOI 10.1006/jvci.2001.0495	27	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY 1	2015	57				SI		33	42		10.1016/j.patrec.2014.09.006		10	Computer Science, Artificial Intelligence	Computer Science	CG5QZ	WOS:000353350200005		
J	Shim, HM; Lee, S				Shim, Hyeon-min; Lee, Sangmin			Multi-channel electromyography pattern classification using deep belief networks for enhanced user experience	JOURNAL OF CENTRAL SOUTH UNIVERSITY			English	Article						electromyography (EMG); pattern classification; feature extraction; deep learning; deep belief network (DBN)	RECOGNITION; PROSTHESES; ALGORITHM	An enhanced algorithm is proposed to recognize multi-channel electromyography (EMG) patterns using deep belief networks (DBNs). It is difficult to classify the EMG features because an EMG signal has nonlinear and time-varying characteristics. Therefore, in several previous studies, various machine-learning methods have been applied. A DBN is a fast, greedy learning algorithm that can find a fairly good set of weights rapidly, even in deep networks with a large number of parameters and many hidden layers. To evaluate this model, we acquired EMG signals, extracted their features, and then compared the model with the DBN and other conventional classifiers. The accuracy of the DBN is higher than that of the other algorithms. The classification performance of the DBN model designed is approximately 88.60%. It is 7.55% (p=9.82x10(-12)) higher than linear discriminant analysis (LDA) and 2.89% (p=1.94x10(-5)) higher than support vector machine (SVM). Further, the DBN is better than shallow learning algorithms or back propagation (BP), and this model is effective for an EMG-based user-interfaced system.	[Shim, Hyeon-min; Lee, Sangmin] Inha Univ, Inst Informat & Elect Res, Inchon 402751, South Korea; [Lee, Sangmin] Inha Univ, Dept Elect Engn, Inchon 402751, South Korea	Lee, S (reprint author), Inha Univ, Inst Informat & Elect Res, 100 Inharo, Inchon 402751, South Korea.	sanglee@inha.ac.kr			Inha University Research Grant, Korea	Foundation item: Project supported by Inha University Research Grant, Korea	Ahsan M.R., 2009, EUROPEAN J SCI RES, V33, P480; Ajiboye AB, 2005, IEEE T NEUR SYS REH, V13, P280, DOI 10.1109/TNSRE.2005.847357; Chen L., 2011, 4 INT C IM SIGN PROC, V1, P139; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUDGINS B, 1993, IEEE T BIO-MED ENG, V40, P82, DOI 10.1109/10.204774; Jaime G. G., 2011, SENSORS, V11, P7110; Jeong EC, 2013, J CENT SOUTH UNIV, V20, P960, DOI 10.1007/s11771-013-1571-2; Khokhar ZO, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-41; Kim KS, 2011, CURR APPL PHYS, V11, P740, DOI 10.1016/j.cap.2010.11.051; Lee JW, 2005, INT J CONTROL AUTOM, V3, P152; Lee S P, 1996, IEEE Trans Rehabil Eng, V4, P439; Lorrain T, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-25; Mandryk RL, 2006, BEHAV INFORM TECHNOL, V25, P141, DOI 10.1080/01449290500331156; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Ning Jiang, 2014, IEEE Transactions on Neural Systems and Rehabilitation Engineering, V22, DOI 10.1109/TNSRE.2013.2278411; Park S H, 1998, IEEE Trans Rehabil Eng, V6, P400; Scheme E, 2011, J REHABIL RES DEV, V48, P643, DOI 10.1682/JRRD.2010.09.0177; Subasi A, 2013, COMPUT BIOL MED, V43, P576, DOI 10.1016/j.compbiomed.2013.01.020; Young AJ, 2013, IEEE T BIO-MED ENG, V60, P1250, DOI 10.1109/TBME.2012.2232293; Zhang DH, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P960	22	0	0	JOURNAL OF CENTRAL SOUTH UNIV TECHNOLOGY	HUNAN	EDITORIAL OFFICE, CHANGSHA, HUNAN 410083, PEOPLES R CHINA	2095-2899	1993-0666		J CENT SOUTH UNIV	J. Cent. South Univ.	MAY	2015	22	5					1801	1808		10.1007/s11771-015-2698-0		8	Metallurgy & Metallurgical Engineering	Metallurgy & Metallurgical Engineering	CI8AF	WOS:000354988900024		
J	Tang, A; Lu, K; Wang, YF; Huang, J; Li, HQ				Tang, Ao; Lu, Ke; Wang, Yufei; Huang, Jie; Li, Houqiang			A Real-Time Hand Posture Recognition System Using Deep Neural Networks	ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY			English	Article						Algorithms; Experimentation; Performance; Kinect; hand tracking; posture recognition; deep neural networks	TRACKING	Hand posture recognition (HPR) is quite a challenging task, due to both the difficulty in detecting and tracking hands with normal cameras and the limitations of traditional manually selected features. In this article, we propose a two-stage HPR system for Sign Language Recognition using a Kinect sensor. In the first stage, we propose an effective algorithm to implement hand detection and tracking. The algorithm incorporates both color and depth information, without specific requirements on uniform-colored or stable background. It can handle the situations in which hands are very close to other parts of the body or hands are not the nearest objects to the camera and allows for occlusion of hands caused by faces or other hands. In the second stage, we apply deep neural networks (DNNs) to automatically learn features from hand posture images that are insensitive to movement, scaling, and rotation. Experiments verify that the proposed system works quickly and accurately and achieves a recognition accuracy as high as 98.12%.	[Tang, Ao; Wang, Yufei; Huang, Jie; Li, Houqiang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China; [Lu, Ke] Univ Chinese Acad Sci, Beijing, Peoples R China	Li, HQ (reprint author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.	tangao@mail.ustc.edu.cn; luk@ucas.ac.cn; feiyuw@mail.ustc.edu.cn; jiehag@mail.ustc.edu.cn; lihq@ustc.edu.cn			Natural Science Foundation of China (NSFC) [61325009, 61390514, 61272316]	This work was supported by the Natural Science Foundation of China (NSFC) under contract No. 61325009, No. 61390514, and No. 61272316.	Aksac Alper, 2011, P 2011 7 INT C EL EL, pII; Argyros Antonis A., 2004, P EUR C COMP VIS ECC, P368; Cao Chuqing, 2010, Proceedings of the 2010 International Conference on Machine Vision and Human-Machine Interface (MVHI 2010), DOI 10.1109/MVHI.2010.39; Caputo Manuel, 2012, MENSCH COMPUTER 2012; Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122; Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Fagiani M., 2013, NEURAL NETS SURROUND, V19, P69; Foresti GL, 1999, IEEE T CIRC SYST VID, V9, P1045, DOI 10.1109/76.795058; Gao W, 2004, PATTERN RECOGN, V37, P2389, DOI 10.1016/j.patcog.2004.04.008; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hsu C. W., 2003, TECHNICAL REPORT; Ji Shuiwang, 2013, 3D CONVOLUTIONAL NEU; Krizhevsky Alex, 2011, P EUR S ART NEUR NET; Kurakin A, 2012, EUR SIGNAL PR CONF, P1975; LECUN Y, 1989, CONNECTIONISM IN PERSPECTIVE, P143; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Yann, 1995, HDB BRAIN THEORY NEU, V3361, P310; Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017; Li Y, 2012, P 3 IEEE INT C SOFTW, P196; Li Zhi, 2009, PROC INT CONF COMPUT, P21; Liu Li, 2013, P INT JOINT C ART IN; Malassiotis S, 2008, IMAGE VISION COMPUT, V26, P1027, DOI 10.1016/j.imavis.2007.11.007; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nebauer C, 1998, IEEE Trans Neural Netw, V9, P685, DOI 10.1109/72.701181; Radha V, 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), DOI 10.1109/NABIC.2009.5393717; Ren Z., 2011, P 19 ACM INT C MULT, P1093, DOI DOI 10.1145/2072298.2071946; Salakhutdinov R., 2008, P ADV NEUR INF PROC, V20, P1249; Seide F., 2011, P INTERSPEECH, P437; Suryanarayan Poonam, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), DOI 10.1109/ICPR.2010.760; SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7; Tusor Balazs, 2010, P IEEE I2 MTC AUST T, P815; Van den Bergh Michael, 2011, P 2011 IEEE WORKSH A, P66; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872; Wang M, 2009, COMPUT VIS IMAGE UND, V113, P384, DOI 10.1016/j.cviu.2008.08.003; Xia L., 2012, P IEEE COMP SOC C CO, P20; Zabulis X., 2009, UNIVERSAL ACCESS HDB	40	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	2157-6904	2157-6912		ACM T INTEL SYST TEC	ACM Trans. Intell. Syst. Technol.	MAY	2015	6	2							21	10.1145/2735952		23	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	CH5BR	WOS:000354049800011		
J	Wright, DE; Smartt, SJ; Smith, KW; Miller, P; Kotak, R; Rest, A; Burgett, WS; Chambers, KC; Flewelling, H; Hodapp, KW; Huber, M; Jedicke, R; Kaiser, N; Metcalfe, N; Price, PA; Tonry, JL; Wainscoat, RJ; Waters, C				Wright, D. E.; Smartt, S. J.; Smith, K. W.; Miller, P.; Kotak, R.; Rest, A.; Burgett, W. S.; Chambers, K. C.; Flewelling, H.; Hodapp, K. W.; Huber, M.; Jedicke, R.; Kaiser, N.; Metcalfe, N.; Price, P. A.; Tonry, J. L.; Wainscoat, R. J.; Waters, C.			Machine learning for transient discovery in Pan-STARRS1 difference imaging	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods: data analysis; methods: statistical; techniques: image processing; surveys; supernovae: general	ULTRALUMINOUS SUPERNOVAE; SUPERLUMINOUS SUPERNOVA; OBJECT CLASSIFICATION; SKY SURVEY; 1ST; PROGENITOR; REDSHIFT	Efficient identification and follow-up of astronomical transients is hindered by the need for humans to manually select promising candidates from data streams that contain many false positives. These artefacts arise in the difference images that are produced by most major ground-based time-domain surveys with large format CCD cameras. This dependence on humans to reject bogus detections is unsustainable for next generation all-sky surveys and significant effort is now being invested to solve the problem computationally. In this paper, we explore a simple machine learning approach to real-bogus classification by constructing a training set from the image data of similar to 32 000 real astrophysical transients and bogus detections from the Pan-STARRS1 Medium Deep Survey. We derive our feature representation from the pixel intensity values of a 20 x 20 pixel stamp around the centre of the candidates. This differs from previous work in that it works directly on the pixels rather than catalogued domain knowledge for feature design or selection. Three machine learning algorithms are trained (artificial neural networks, support vector machines and random forests) and their performances are tested on a held-out subset of 25 per cent of the training data. We find the best results from the random forest classifier and demonstrate that by accepting a false positive rate of 1 per cent, the classifier initially suggests a missed detection rate of around 10 per cent. However, we also find that a combination of bright star variability, nuclear transients and uncertainty in human labelling means that our best estimate of the missed detection rate is approximately 6 per cent.	[Wright, D. E.; Smartt, S. J.; Smith, K. W.; Kotak, R.] Queens Univ Belfast, Sch Math & Phys, Astrophys Res Ctr, Belfast BT7 1NN, Antrim, North Ireland; [Miller, P.] Queens Univ Belfast, Inst Elect Commun & Informat Technol, Belfast BT3 9DT, Antrim, North Ireland; [Rest, A.] Space Telescope Sci Inst, Baltimore, MD 21218 USA; [Burgett, W. S.] GMTO Corp, Pasadena, CA 91101 USA; [Chambers, K. C.; Flewelling, H.; Hodapp, K. W.; Huber, M.; Jedicke, R.; Kaiser, N.; Tonry, J. L.; Wainscoat, R. J.; Waters, C.] Univ Hawaii, Inst Astron, Honolulu, HI 96822 USA; [Metcalfe, N.] Univ Durham, Dept Phys, Durham DH1 3LE, England; [Price, P. A.] Princeton Univ, Dept Astrophys Sci, Princeton, NJ 08544 USA	Wright, DE (reprint author), Queens Univ Belfast, Sch Math & Phys, Astrophys Res Ctr, Belfast BT7 1NN, Antrim, North Ireland.	dwright04@qub.ac.uk			National Aeronautics and Space Administration [NNX08AR22G]; European Research Council under the European Union [291222]; RCUK STFC [ST/I001123/1, ST/L000709/1]; DEL	The Pan-STARRS1 Survey has been made possible through contributions of the Institute for Astronomy, the University of Hawaii, the Pan-STARRS Project Office, the Max-Planck Society and its participating institutes, the Max Planck Institute for Astronomy, Heidelberg and the Max Planck Institute for Extraterrestrial Physics, Garching, The Johns Hopkins University, Durham University, the University of Edinburgh, Queen's University Belfast, the Harvard-Smithsonian Center for Astrophysics and the Las Cumbres Observatory Global Telescope Network, Incorporated, the National Central University of Taiwan, and the National Aeronautics and Space Administration under grant no. NNX08AR22G issued through the Planetary Science Division of the NASA Science Mission Directorate. The research leading to these results has received funding from the European Research Council under the European Union's Seventh Framework Programme (FP7/2007-2013)/ERC Grant agreement no. [291222] (PI : S. J. Smartt) and the RCUK STFC grants ST/I001123/1 and ST/L000709/1. DEW acknowledges support from DEL in the form of a postgraduate studentship.	Bailey S, 2007, ASTROPHYS J, V665, P1246, DOI 10.1086/519832; Baltay C, 2013, PUBL ASTRON SOC PAC, V125, P683, DOI 10.1086/671198; Berger E, 2012, ASTROPHYS J LETT, V755, DOI 10.1088/2041-8205/755/2/L29; Bertin E, 2001, ESO ASTROPHY SYMP, P353, DOI 10.1007/10849171_44; Biau G., 2010, ARXIV10050208; Bloom JS, 2012, PUBL ASTRON SOC PAC, V124, P1175, DOI 10.1086/668468; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brink H, 2013, MON NOT R ASTRON SOC, V435, P1047, DOI 10.1093/mnras/stt1306; Cao Y, 2013, ASTROPHYS J LETT, V775, DOI 10.1088/2041-8205/775/1/L7; Chomiuk L, 2011, ASTROPHYS J, V743, DOI 10.1088/0004-637X/743/2/114; Chornock R, 2013, ASTROPHYS J, V767, DOI 10.1088/0004-637X/767/2/162; Coates A., 2011, P 14 INT C ART INT S; Coates A., 2013, P 30 INT C MACH LEAR, P1337; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Djorgovski S. G., 2012, ARXIV12091681; Donalek C, 2008, AIP CONF PROC, V1082, P252, DOI 10.1063/1.3059057; Drake AJ, 2009, ASTROPHYS J, V696, P870, DOI 10.1088/0004-637X/696/1/870; du Buisson L., 2014, ARXIV14074118; Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109; Gal-Yam A, 2014, NATURE, V509, P471, DOI 10.1038/nature13304; GEVA S, 1992, IEEE T NEURAL NETWOR, V3, P621, DOI 10.1109/72.143376; Gezari S, 2010, ASTROPHYS J LETT, V720, pL77, DOI 10.1088/2041-8205/720/1/L77; Gezari S, 2012, NATURE, V485, P217, DOI 10.1038/nature10990; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hodapp KW, 2004, P SOC PHOTO-OPT INS, V5489, P667, DOI 10.1117/12.550179; Kaiser N, 2010, PROC SPIE, V7733, DOI 10.1117/12.859188; Keller SC, 2007, PUBL ASTRON SOC AUST, V24, P1, DOI 10.1071/AS07001; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lunnan R, 2013, ASTROPHYS J, V771, DOI 10.1088/0004-637X/771/2/97; Magnier E., 2006, ADV MAUI OPT SPAC SU, P455; Magnier EA, 2013, ASTROPHYS J SUPPL S, V205, DOI 10.1088/0067-0049/205/2/20; McCrum M, 2014, MON NOT R ASTRON SOC, V437, P656, DOI 10.1093/mnras/stt1923; Murtagh F., 1991, NEUROCOMPUTING, V2, P183, DOI 10.1016/0925-2312(91)90023-5; Raina R., 2007, LEARNING, P759; Rau A, 2009, PUBL ASTRON SOC PAC, V121, P1334; Rest A, 2005, ASTROPHYS J, V634, P1103, DOI 10.1086/497060; Rest A, 2014, ASTROPHYS J, V795, DOI 10.1088/0004-637X/795/1/44; Romano R. A., 2006, P 5 INT C MACH LEARN, P77; Saffari A., 2009, P IEEE INT C COMP VI, P1393; Schlafly EF, 2012, ASTROPHYS J, V756, DOI 10.1088/0004-637X/756/2/158; Shalev-Shwartz Shai, 2011, Foundations and Trends in Machine Learning, V4, DOI 10.1561/2200000018; Smartt S. J., 2014, ATEL, V6156, P1; Smartt S. J., 2013, MESSENGER, V154, P50; Tonry JL, 2012, ASTROPHYS J, V745, DOI 10.1088/0004-637X/745/1/42; Tonry JL, 2012, ASTROPHYS J, V750, DOI 10.1088/0004-637X/750/2/99; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513	46	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0035-8711	1365-2966		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	MAY 1	2015	449	1					451	466		10.1093/mnras/stv292		16	Astronomy & Astrophysics	Astronomy & Astrophysics	CJ2WO	WOS:000355345600034		
J	Yin, HP; Jiao, XG; Chai, Y; Fang, B				Yin, Hongpeng; Jiao, Xuguo; Chai, Yi; Fang, Bin			Scene classification based on single-layer SAE and SVM	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Scene classification; Feature learning; Single-layer SAE; SVM; PSO	SUPPORT VECTOR MACHINES; IMAGE CLASSIFICATION; FEATURES; REPRESENTATION; RECOGNITION; OPTIMIZATION; MODEL	Scene classification aims to group images into semantic categories. It is a challenging problem in computer vision due to the difficulties of intra-class variability and inter-class similarity. In this paper, a scene classification approach based on single-layer sparse autoencoder (SAE) and support vector machine (SVM) is proposed. This approach consists of two steps: SAE-based feature learning step and SVM-based classification step. In the first step, a single-layer SAE network is constructed and trained by the patches which are sampled randomly from the source images. The feature representation of images is learned by the trained single-layer SAE network. Meanwhile, a pooling operation is used to reduce the dimension of the learned feature vectors. In the second step, in order to improve the classification accuracy, the parameters of SVM are optimized by a particle swarm optimization (PSO) based algorithm. The one-versus-one strategy is employed for the multiple scene classification problem. To show the efficiency of the proposed approach, several public data sets are employed. The results reveal that the proposed approach achieves better classification accuracy than the existing state-of-the-art methods. (C) 2014 Elsevier Ltd. All rights reserved.	[Yin, Hongpeng; Jiao, Xuguo; Chai, Yi] Chongqing Univ, Coll Automat, Chongqing 400030, Peoples R China; [Fang, Bin] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China	Yin, HP (reprint author), Chongqing Univ, Coll Automat, Chongqing 400030, Peoples R China.	yinhongpeng@gmail.com; jiaoxuguo@163.com; chaiyi@cqu.edu.cn; fangbin@cqu.edu.cn			National Natural Science Foundation of China [61203321, 61374135, 61472053, 61173129]; China Postdoctoral Science Foundation [2012M521676]; China Central Universities Foundation [106112013CDJZR170005]; Chongqing Special Funding in Postdoctoral Scientific Research Project [XM2013007]; Specialized Research Fund for the Doctoral Program of Higher Education of China [20120191110026]	We would like to thank the supports by National Natural Science Foundation of China (61203321, 61374135, 61472053, 61173129), China Postdoctoral Science Foundation (2012M521676), China Central Universities Foundation (106112013CDJZR170005), and Chongqing Special Funding in Postdoctoral Scientific Research Project (XM2013007), Specialized Research Fund for the Doctoral Program of Higher Education of China (20120191110026).	Agarwal V., 2006, J PATTERN RECOGN RES, V1, P42; Ali MM, 2013, PATTERN RECOGN LETT, V34, P1525, DOI 10.1016/j.patrec.2013.06.012; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1; Hinton GE, 2011, COMMUN ACM, V54, P94, DOI 10.1145/2001269.2001294; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Krizhevsky A., 2010, INT C ART INT STAT, P621; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Li L.J., 2007, IEEE 11 INT C COMP V, P1; Li L.-J., 2012, LNCS, V6553, P57; Li LY, 2014, PATTERN RECOGN, V47, P2940, DOI 10.1016/j.patcog.2014.03.012; Lin SW, 2008, EXPERT SYST APPL, V35, P1817, DOI 10.1016/j.eswa.2007.08.088; Mesnil G, 2014, MACH LEARN, V94, P281, DOI 10.1007/s10994-013-5336-9; Nakayama H, 2010, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2010.5539921; Nedic V, 2014, EXPERT SYST APPL, V41, P3993, DOI 10.1016/j.eswa.2013.12.025; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003; Serrano-Talamantes JF, 2013, EXPERT SYST APPL, V40, P2398, DOI 10.1016/j.eswa.2012.10.064; Tao W., 2014, INFORM SCI; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Yang JC, 2009, PROC CVPR IEEE, P1794; Zeiler Matthew D., 2013, VISUALIZING UNDERSTA; Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894; Zhou L, 2013, NEUROCOMPUTING, V122, P284, DOI 10.1016/j.neucom.2013.06.023; Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017	38	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	MAY 1	2015	42	7					3368	3380		10.1016/j.eswa.2014.11.069		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	CC2NT	WOS:000350182600007		
J	Feng, FX; Li, RF; Wang, XJ				Feng, Fangxiang; Li, Ruifan; Wang, Xiaojie			Deep correspondence restricted Boltzmann machine for cross-modal retrieval	NEUROCOMPUTING			English	Article						Cross-modal; RBM; Retrieval; Deep Learning; Multi-modal		The task of cross-modal retrieval, i.e., using a text query to search for images or vice versa, has received considerable attention with the rapid growth of multi-modal web data. Modeling the correlations between different modalities is the key to tackle this problem. In this paper, we propose a correspondence restricted Boltzmann machine (Corr-RBM) to map the original features of bimodal data, such as image and text in our setting, into a low-dimensional common space, in which the heterogeneous data are comparable. In our Corr-RBM, two RBMs built for image and text, respectively are connected at their individual hidden representation layers by a correlation loss function. A single objective function is constructed to trade off the correlation loss and likelihoods of both modalities. Through the optimization of this objective function, our Corr-RBM is able to capture the correlations between two modalities and learn the representation of each modality simultaneously. Furthermore, we construct two deep neural structures using Corr-RBM as the main building block for the task of cross-modal retrieval. A number of comparison experiments are performed on three public real-world data sets. All of our models show significantly better results than state-of-the-art models in both searching images via text query and vice versa. (C) 2014 Elsevier B.V. All rights reserved.	[Feng, Fangxiang; Li, Ruifan; Wang, Xiaojie] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100088, Peoples R China	Li, RF (reprint author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100088, Peoples R China.	f.fangxiang@gmail.com; rfli@bupt.edu.cn; xjwang@bupt.edu.cn			National Natural Science Foundation of China [61273365]; National High Technology Research and Development Program of China [2012AA011103]; Discipline Building Plan in 111 Base [B08004]; Fundamental Research Funds for the Central Universities [2013RC0304]; Engineering Research Center of Information Networks, Ministry of Education	This work was partially supported by National Natural Science Foundation of China (no. 61273365), National High Technology Research and Development Program of China (no. 2012AA011103), Discipline Building Plan in 111 Base (no. B08004), the Fundamental Research Funds for the Central Universities (no. 2013RC0304) and Engineering Research Center of Information Networks, Ministry of Education.	Bird S, 2006, P COLING ACL INT PRE, P69, DOI DOI 10.3115/1225403.1225421; Bosch A., 2007, P IEEE INT C COMP VI, V23, P1; Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; Chua T. S., 2009, P ACM INT C IM VID R, DOI [10.1145/1646396.1646452, DOI 10.1145/1646396.1646452]; Desjardins G., 2010, P 13 INT C ART INT S, P145; Feng F., 2014, P INT C MULT MM 14, P7; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.2307/2333955; Huiskes M. J., 2010, P INT C MULT INF RET, P527, DOI 10.1145/1743384.1743475; Kim JW, 2012, INT J STEEL STRUCT, V12, P579, DOI 10.1007/s13296-012-4012-4; Kumar S., 2011, P INT JOINT C ART IN, P1360; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Manning C.D., 2008, INTRO INFORM RETRIEV; Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225; McFee B., 2009, P 26 ANN INT C MACH, P721; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rasiwasia Nikhil, 2010, P INT C MULT, P251, DOI 10.1145/1873951.1873987; Salakhutdinov R., 2009, NIPS, V22, P1607; Salakhutdinov R., 2007, P 24 INT C MACH LEAR, V227, P791, DOI DOI 10.1145/1273496.1273596; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N., 2012, INT C MACH LEARN REP; Srivastava N., 2012, NEUR INF PROC SYST N, V25, P2231; Srivastava N., 2013, P 29 C UNC ART INT U, P616; Taylor G., 2009, P 26 ANN INT C MACH, P1025; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Wang W., 2014, P INT C VER LARG DAT, V7, P649; Welling M., 2004, NEUR INF PROC SYST N, P501; Xu JG, 2014, NEUROCOMPUTING, V139, P328, DOI 10.1016/j.neucom.2014.02.024; Zhu X., 2013, P 21 ACM INT C MULT, P143	32	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	APR 22	2015	154						50	60		10.1016/j.neucom.2014.12.020		11	Computer Science, Artificial Intelligence	Computer Science	CC1DR	WOS:000350081900006		
J	Wang, Y; Hu, SQ				Wang, Yong; Hu, Shiqiang			Exploiting high level feature for dynamic textures recognition	NEUROCOMPUTING			English	Article						Chaotic features; Deep neural network; Bag of features; Dynamic textures recognition	SCENES	In this paper, a novel framework is proposed for dynamic textures (DTs) recognition by learning a high level feature using deep neural network (DNN). The insight behind the method is that a DT appearing in different videos should share similar features, which can be learned for better recognition performance. Unlike many prior works only focus on low level or middle level features, we propose a novel high level feature learning method using DNN. Our goal is to construct a compact and discriminative semantic feature. The conventional bag of features approach using k-means is not semantically meaningful since the clustering criterion is based on appearance similarity. The proposed framework can effectively overcome the problem by capturing the semantic relations of the middle level by DNN. Extensive experiments with qualitative and quantitative results demonstrate the efficacy of our approach. (C) 2014 Elsevier B.V. All rights reserved.	[Wang, Yong; Hu, Shiqiang] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China	Hu, SQ (reprint author), Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China.				National Natural Science Foundation of China [61374161, 61074106]	This work was partly supported by the National Natural Science Foundation of China 61374161 and 61074106.	Ali S., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/ICCV.2007.4409046; Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chan A., 2007, IEEE C COMP VIS PATT; CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149; Dollar P., 2005, VISUAL SURVEILLANCE, V2, P65, DOI DOI 10.1109/VSPETS.2005.1570899; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Fazekas S., 2005, TEXT 2005 4 INT WORK, P37; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Fournier A., 1986, P SIGGRAPH 86, V20, P75; Fraser A.M., 1986, PHYS REV; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Kantz H., 1997, NONLINEAR TIME SERIE; Kennel M.B., 1992, PHYS REV A, V45; Klaser A., 2008, P BRIT MACH VIS C, P995; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Pantel P., 2002, P SPEC INT GROUP KNO; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661; PETERI R, 2005, P IB C PATT REC IM A, V3523, P223, DOI 10.1007/11492542_28; Ranzato M., 2011, IEEE C COMP VIS PATT, P2857; Ravichandran A., 2012, IEEE T PATTERN ANAL; Saisan P., 2001, IEEE C COMP VIS PATT, V2, P58; Siniscalchi M., 2013, NEUROCOMPUTING; Szummer M., 1996, P INT C IM PROC, V3; Taken F., 1981, LECT NOTES MATH; Turney P., 2001, P 12 EUR C MACH LEAR; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882; Xu Y, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1219	33	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	APR 22	2015	154						217	224		10.1016/j.neucom.2014.12.001		8	Computer Science, Artificial Intelligence	Computer Science	CC1DR	WOS:000350081900022		
J	Li, ZH; Fan, YY; Liu, WH				Li, Zuhe; Fan, Yangyu; Liu, Weihua			The effect of whitening transformation on pooling operations in convolutional autoencoders	EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING			English	Article						Convolutional neural network; Sparse autoencoder; Image classification; Computer vision; Unsupervised learning; Deep learning		Convolutional autoencoders (CAEs) are unsupervised feature extractors for high-resolution images. In the pre-processing step, whitening transformation has widely been adopted to remove redundancy by making adjacent pixels less correlated. Pooling is a biologically inspired operation to reduce the resolution of feature maps and achieve spatial invariance in convolutional neural networks. Conventionally, pooling methods are mainly determined empirically in most previous work. Therefore, our main purpose is to study the relationship between whitening processing and pooling operations in convolutional autoencoders for image classification. We propose an adaptive pooling approach based on the concepts of information entropy to test the effect of whitening on pooling in different conditions. Experimental results on benchmark datasets indicate that the performance of pooling strategies is associated with the distribution of feature activations, which can be affected by whitening processing. This provides guidance for the selection of pooling methods in convolutional autoencoders and other convolutional neural networks.	[Li, Zuhe; Fan, Yangyu; Liu, Weihua] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China; [Li, Zuhe] Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450002, Peoples R China	Li, ZH (reprint author), Northwestern Polytech Univ, Sch Elect & Informat, 127 West Youyi Rd, Xian 710072, Peoples R China.	zuheli@126.com			National Natural Science Foundation of China [61202314]; China Postdoctoral Science Foundation [2012 M521801, 2014 T70937]; Science and Technology Innovation Engineering Program for Shaanxi Provincial Key Laboratories [2013SZS15-K02]	This work was supported by the National Natural Science Foundation of China under Grant 61202314, China Postdoctoral Science Foundation under Grant 2012 M521801, China Postdoctoral Science Foundation Special Project under Grant 2014 T70937, and the Science and Technology Innovation Engineering Program for Shaanxi Provincial Key Laboratories under Grant 2013SZS15-K02.	Bell AJ, 1997, ADV NEUR IN, V9, P831; Bengio Y., 2009, MACH LEARN, V2, P1; BOUREAU YL, 2010, COMP VIS PATT REC CV, P2559; Boureau Y.-L., 2010, P 27 INT C MACH LEAR, P111; Ciresan DC, 2011, INT JOINT C ART INT, P1237; Coates A, 2011, INT C ART INT STAT, P215; Goodfellow I, 2009, ADV NEURAL INFORM PR, P646; Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; KOREKADO K, 2003, KNOWLEDGE BASED INTE, V2774, P169, DOI 10.1007/978-3-540-45226-3_24; Krizhevsky, 2009, THESIS U TORONTO; Le QV, 2011, ADV NEURAL INFORM PR, P1017; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Makhzani A, 2014, ARXIV14092752; MASCI J, 2011, ARTIDICIAL NEURAL NE, V6791, P52; Ng AY, DEEP LEARNING; Poultney C., 2006, ADV NEURAL INFORM PR, P1137; Ranzato M, 2007, COMPUTER VISION PATT, P1; SCHERER D, 2010, ARTIFICIAL NEURAL NE, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; SERMANET P, 2013, COMPUTER VISION PATT, P3626; Shannon CE, 2001, ACM SIGMOBILE MOBILE, V5, P3, DOI DOI 10.1145/584091.584093; Sohn K, 2012, ARXIV12066418; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Zeiler MD, 2013, ARXIV13013557	26	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	1687-6180			EURASIP J ADV SIG PR	EURASIP J. Adv. Signal Process.	APR 14	2015									37	10.1186/s13634-015-0222-1		11	Engineering, Electrical & Electronic	Engineering	CG3VM	WOS:000353207700001		
J	Helmstaedter, M				Helmstaedter, Moritz			The Mutual Inspirations of Machine Learning and Neuroscience	NEURON			English	Editorial Material							RECONSTRUCTION; CONNECTOMICS; CORTEX; LAYER	Neuroscientists are generating data sets of enormous size, which are matching the complexity of real-world classification tasks. Machine learning has helped data analysis enormously but is often not as accurate as human data analysis. Here, Helmstaedter discusses the challenges and promises of neuroscience-inspired machine learning that lie ahead.	Max Planck Inst Brain Res, Dept Connect, D-60438 Frankfurt, Germany	Helmstaedter, M (reprint author), Max Planck Inst Brain Res, Dept Connect, Max von Laue Str 4, D-60438 Frankfurt, Germany.	mh@brain.mpg.de					Amat F, 2014, NAT METHODS, V11, P951, DOI [10.1038/nmeth.3036, 10.1038/NMETH.3036]; Clack NG, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002591; Coates A., 2011, P 14 INT C ART INT S; Feldmeyer D, 1999, J PHYSIOL-LONDON, V521, P169, DOI 10.1111/j.1469-7793.1999.00169.x; Greenberg David S, 2014, Cold Spring Harb Protoc, V2014, P912, DOI 10.1101/pdb.top083535; Helmstaedter M, 2011, NAT NEUROSCI, V14, P1081, DOI 10.1038/nn.2868; Helmstaedter M, 2013, NAT METHODS, V10, P501, DOI [10.1038/nmeth.2476, 10.1038/NMETH.2476]; Helmstaedter M, 2013, NATURE, V500, P168, DOI 10.1038/nature12346; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Kabra M, 2013, NAT METHODS, V10, P64, DOI [10.1038/nmeth.2281, 10.1038/NMETH.2281]; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lien AD, 2013, NAT NEUROSCI, V16, P1315, DOI 10.1038/nn.3488; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Meyer HS, 2010, CEREB CORTEX, V20, P2287, DOI 10.1093/cercor/bhq069; Ranzato M.A., 2007, ADV NEUR INF PROC SY, V19; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003; Takemura S, 2013, NATURE, V500, P175, DOI 10.1038/nature12450; Vogelstein R.J., 2004, P 26 ANN INT C IEEE	20	0	0	CELL PRESS	CAMBRIDGE	600 TECHNOLOGY SQUARE, 5TH FLOOR, CAMBRIDGE, MA 02139 USA	0896-6273	1097-4199		NEURON	Neuron	APR 8	2015	86	1					25	28		10.1016/j.neuron.2015.03.031		4	Neurosciences	Neurosciences & Neurology	CF4WE	WOS:000352552900009	25856482	
J	Bengio, Y; Lee, H				Bengio, Yoshua; Lee, Honglak			Editorial introduction to the Neural Networks special issue on Deep Learning of Representations	NEURAL NETWORKS			English	Editorial Material											honglak@eecs.umich.edu					Bahdanau D., 2014, TECHNICAL REPORT; Bengio Y., 2009, LEARNING DEEP ARCHIT; Bengio Y., 2007, NIPS; Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023; Dahl G.E., 2010, NIPS; Deng L., 2010, INTERSPEECH; Devlin J., 2014, ACL; Erhan D, 2010, J MACH LEARN RES, V11, P625; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Glorot X., 2011, DEEP SPARSE RECTIFIE; Glorot X., 2011, ICML; Goodfellow I, 2011, NIPS WORKSH CHALL LE; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Krizhevsky A., 2012, NIPS; Le Q.V., 2012, ICML; LeCun Y., 1998, P IEEE; LeCun Y., 1989, NEURAL COMPUTATION; Lee H., 2009, ICML; Lee H., 2008, NIPS; Lee H, 2009, NIPS; Mesnil G., 2011, JIVILR W CP P UNSUPE, V7; MIKOLOV T, 2013, NIPS; Nair V., 2010, ICML; Raina R., 2007, ICML; Ranzato M., 2007, NIPS; Salakhutdinov R., 2007, ICML; Schmidhuber J., 2014, ARXIV14047828; Seide F., 2011, INTERSPEECH, P437; Sermanet P., 2013, INT C COMP VIS PATT; Sutskever I., 2014, TECHNICAL REPORT; Weston J., 2008, ICML	33	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	APR	2015	64				SI		1	3		10.1016/j.neunet.2014.12.006		3	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	CD2RL	WOS:000350926600001	25595998	
J	Berglund, M; Raiko, T; Cho, K				Berglund, Mathias; Raiko, Tapani; Cho, Kyunghyun			Measuring the usefulness of hidden units in Boltzmann machines with mutual information	NEURAL NETWORKS			English	Article						Deep learning; Restricted Boltzmann machine; Deep Boltzmann machine; Pruning; Structural learning; Mutual information	GRADIENT	Restricted Boltzmann machines (RBMs) and deep Boltzmann machines (DBMs) are important models in deep learning, but it is often difficult to measure their performance in general, or measure the importance of individual hidden units in specific. We propose to use mutual information to measure the usefulness of individual hidden units in Boltzmann machines. The measure is fast to compute, and serves as an upper bound for the information the neuron can pass on, enabling detection of a particular kind of poor training results. We confirm experimentally that the proposed measure indicates how much the performance of the model drops when some of the units of an RBM are pruned away. We demonstrate the usefulness of the measure for early detection of poor training in DBMs. (C) 2014 Elsevier Ltd. All rights reserved.	[Berglund, Mathias; Raiko, Tapani; Cho, Kyunghyun] Aalto Univ, Sch Sci, Dept Informat & Comp Sci, Espoo, Finland	Berglund, M (reprint author), Aalto Univ, Sch Sci, Dept Informat & Comp Sci, Espoo, Finland.	mathias.berglund@aalto.fi			Academy of Finland (Finnish Centre of Excellence in Computational Inference Research COIN) [251170]	This work was supported by the Academy of Finland (Finnish Centre of Excellence in Computational Inference Research COIN, 251170).	Adams R. P., 2010, JMLR WORKSH C P, V9; Berglund M., 2013, P 20 INT C NEUR INF; Cho K, 2013, NEURAL COMPUT, V25, P805, DOI 10.1162/NECO_a_00397; Cho K., 2011, P INT C MACH LEARN, P105; Cho K., 2013, P 23 INT C ART NEUR; Desjardins G., 2011, ADV NEURAL INFORM PR, V24, P2501; Engelbrecht AP, 2001, IEEE T NEURAL NETWOR, V12, P1386, DOI 10.1109/72.963775; Glorot X., 2010, J MACH LEARN RES P T, V9, P249; Goodfellow I., 2013, ADV NEURAL INFORM PR, P548; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Reed R., 1993, T NEURAL NETWORKS, V4, P740; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2009, JMLR WORKSH C P, P448; Salakhutdinov RR., 2008, 2008002 UTML TR DEP; Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI 10.1145/1273496.1273596; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Zhou G., 2012, J MACHINE LEARNING R, P1453	23	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	APR	2015	64				SI		12	18		10.1016/j.neunet.2014.09.004		7	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	CD2RL	WOS:000350926600003	25318376	
J	Elfwing, S; Uchibe, E; Doya, K				Elfwing, S.; Uchibe, E.; Doya, K.			Expected energy-based restricted Boltzmann machine for classification	NEURAL NETWORKS			English	Article						Classification; Restricted Boltzmann machine; Expected energy; Free energy	RECOGNITION; NETS; DEEP	In classification tasks, restricted Boltzmann machines (RBMs) have predominantly been used in the first stage, either as feature extractors or to provide initialization of neural networks. In this study, we propose a discriminative learning approach to provide a self-contained RBM method for classification, inspired by free-energy based function approximation (FE-RBM), originally proposed for reinforcement learning. For classification, the FE-RBM method computes the output for an input vector and a class vector by the negative free energy of an RBM. Learning is achieved by stochastic gradient-descent using a mean-squared error training objective. In an earlier study, we demonstrated that the performance and the robustness of FE-RBM function approximation can be improved by scaling the free energy by a constant that is related to the size of network. In this study, we propose that the learning performance of RBM function approximation can be further improved by computing the output by the negative expected energy (EE-RBM), instead of the negative free energy. To create a deep learning architecture, we stack several RBMs on top of each other. We also connect the class nodes to all hidden layers to try to improve the performance even further. We validate the classification performance of EE-RBM using the MNIST data set and the NORB data set, achieving competitive performance compared with other classifiers such as standard neural networks, deep belief networks, classification RBMs, and support vector machines. The purpose of using the NORB data set is to demonstrate that EE-RBM with binary input nodes can achieve high performance in the continuous input domain. (C) 2014 The Authors. Published by Elsevier Ltd.	[Elfwing, S.; Uchibe, E.; Doya, K.] Grad Univ, Okinawa Inst Sci & Technol, Okinawa 9040495, Japan	Elfwing, S (reprint author), Grad Univ, Okinawa Inst Sci & Technol, 1919-1 Tancha, Okinawa 9040495, Japan.	elfwing@oist.jp; uchibe@oist.jp; doya@oist.jp	Elfwing, Stefan/G-2940-2015; Doya, Kenji/B-5841-2015	Elfwing, Stefan/0000-0001-6689-1000; Doya, Kenji/0000-0002-2446-6820	 [23120007];  [26120727]	This work was supported by Grant-in-Aid for Scientific Research on Innovative Areas: Prediction and Decision Making 23120007 and 26120727.	Bengio Y., 2007, LARGE SCALE KERNEL M; Bengio Y., 2006, P ADV NEUR INF PROC, V19; Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Elfwing S., 2013, FRONTIERS NEUROROBOT, V7; Freund Y., 1992, ADV NEURAL INFORM PR, V4; Goodfellow I. J., 2013, P ADV NEUR INF PROC, V26; Goodfellow I. J., 2013, P INT C MACH LEARN I; Hinton G. E., 2012, ARXIV12070580CENE; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton G.E., 2010, 2010003 UTML TR DEP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Larochelle H, 2012, J MACH LEARN RES, V13, P643; Larochelle H., 2008, P INT C MACH LEARN I; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2004, P CVPR2004; Nair V., 2008, P ADV NEUR INF PROC, V21; Ngiam J., 2011, P 28 INT C MACH LEAR, P1105; Raiko T., 2012, P INT C ART INT STAT, P924; Salakhutdinov R., 2009, JMLR W CP AISTATS 20, V5, P448; Sallans B, 2004, J MACH LEARN RES, V5, P1063; Schmah T., 2008, P ADV NEUR INF PROC, V21; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1; Sutton RS, 1998, REINFORCEMENT LEARNI	26	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	APR	2015	64				SI		29	38		10.1016/j.neunet.2014.09.006		10	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	CD2RL	WOS:000350926600005	25318375	
J	Hayat, M; Bennamoun, M; An, SJ				Hayat, Munawar; Bennamoun, Mohammed; An, Senjian			Deep Reconstruction Models for Image Set Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image set classification; deep learning; auto-encoders; video based face recognition; object recognition	FACE RECOGNITION; REPRESENTATION; APPEARANCE	Image set classification finds its applications in a number of real-life scenarios such as classification from surveillance videos, multi-view camera networks and personal albums. Compared with single image based classification, it offers more promises and has therefore attracted significant research attention in recent years. Unlike many existing methods which assume images of a set to lie on a certain geometric surface, this paper introduces a deep learning framework which makes no such prior assumptions and can automatically discover the underlying geometric structure. Specifically, a Template Deep Reconstruction Model (TDRM) is defined whose parameters are initialized by performing unsupervised pre-training in a layer-wise fashion using Gaussian Restricted Boltzmann Machines (GRBMs). The initialized TDRM is then separately trained for images of each class and class-specific DRMs are learnt. Based on the minimum reconstruction errors from the learnt class-specific models, three different voting strategies are devised for classification. Extensive experiments are performed to demonstrate the efficacy of the proposed framework for the tasks of face and object recognition from image sets. Experimental results show that the proposed method consistently outperforms the existing state of the art methods.	[Hayat, Munawar; Bennamoun, Mohammed; An, Senjian] Univ Western Australia, Sch Comp Sci & Software Engn, Perth, WA 6009, Australia	Hayat, M (reprint author), Univ Western Australia, Sch Comp Sci & Software Engn, Perth, WA 6009, Australia.	munawar.hayat@research.uwa.edu.au; mohammed.bennamoun@uwa.edu.au; senjian.an@uwa.edu.au			SIRF scholarship from the University of Western Australia (UWA); ARC [DPI10102166]	This work is supported by SIRF scholarship from the University of Western Australia (UWA) and ARC grant DPI10102166.	Arandjelovic O, 2005, PROC CVPR IEEE, P581; Bengio Y., 2012, P NEUR NETW TRICKS T, P437; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Carreira-Perpinan M. A., 2005, P INT C ART INT STAT, P17; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Gross R., 2001, CMURITR0118; Hamm J., 2008, P 25 INT C MACH LEAR, P376, DOI 10.1145/1390156.1390204; Harandi M. T., 2012, P IEEE WORKSH APPL C, P433; Harandi M. T., 2010, P IEEE C COMP VIS PA, P2705; Hayat M., 2014, P IEEE C COMP VIS PA, P1915; Hinton G, 2006, COGNITIVE SCI, V30, P725, DOI 10.1207/s15516709cog0000_76; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283; Huang Z., 2013, P 11 AS C COMP VIS, P589; Kim M., 2008, P IEEE C COMP VIS PA, P1; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Lee KC, 2003, PROC CVPR IEEE, P313; Leibe B, 2003, PROC CVPR IEEE, P409; Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nishiyama M., 2007, P IEEE C COMP VIS PA, P1; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ortiz EG, 2013, PROC CVPR IEEE, P3531, DOI 10.1109/CVPR.2013.453; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang R., 2008, P IEEE C COMP VIS PA, P1; Wang RP, 2009, PROC CVPR IEEE, P429; Wang RP, 2012, PROC CVPR IEEE, P2496; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yamaguchi O., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670968; Yang M.-C., 2013, P 10 IEEE INT C WORK, P1; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhu P., 2013, P INT C COMP VIS, P2664	45	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					713	727		10.1109/TPAMI.2014.2353635		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CD6QF	WOS:000351213400002		
J	Hou, WL; Gao, XB				Hou, Weilong; Gao, Xinbo			Saliency-Guided Deep Framework for Image Quality Assessment	IEEE MULTIMEDIA			English	Article							NATURAL SCENE STATISTICS		[Hou, Weilong] Xidian Univ, Intelligent Informat Proc, Xian, Peoples R China; [Hou, Weilong] Univ Technol Sydney, Sydney, NSW 2007, Australia; [Gao, Xinbo] Minist Educ, Beijing, Peoples R China; [Gao, Xinbo] Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China	Hou, WL (reprint author), Xidian Univ, Intelligent Informat Proc, Xian, Peoples R China.	weilonghou@gmail.com; xbgao@mail.xidian.edu.cn					Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Callet P. L., 2006, SUBJECTIVE QUALITY A; Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014; He LH, 2012, PROC CVPR IEEE, P1146; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Horita Y., 2000, MICT IMAGE QUALITY E; Hou WL, 2013, PATTERN RECOGN, V46, P2658, DOI 10.1016/j.patcog.2013.03.008; Hou W.L., 2014, P INT C MULT EXP, P1; Larson E. C., 2009, CATEGORICAL IMAGE QU; Liu Z.B., 2014, PEDIAT NEONATOL, P1; Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888; Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325; Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30; Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563; Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492; Sheikh H.R., 2003, LIVE IMAGE QUALITY A; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Ye P, 2012, PROC CVPR IEEE, P1098	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1070-986X	1941-0166		IEEE MULTIMEDIA	IEEE Multimedia	APR-JUN	2015	22	2					46	55				10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	CL1HW	WOS:000356694400006		
J	Kim, S; Yu, Z; Kil, RM; Lee, M				Kim, Sangwook; Yu, Zhibin; Kil, Rhee Man; Lee, Minho			Deep learning of support vector machines with class probability output networks	NEURAL NETWORKS			English	Article						Deep learning; Support vector machine; Class probability output network; Uncertainty measure	STACKED GENERALIZATION; RECOGNITION; ALGORITHM	Deep learning methods endeavor to learn features automatically at multiple levels and allow systems to learn complex functions mapping from the input space to the output space for the given data. The ability to learn powerful features automatically is increasingly important as the volume of data and range of applications of machine learning methods continues to grow. This paper proposes a new deep architecture that uses support vector machines (SVMs) with class probability output networks (CPONs) to provide better generalization power for pattern classification problems. As a result, deep features are extracted without additional feature engineering steps, using multiple layers of the SVM classifiers with CPONs. The proposed structure closely approaches the ideal Bayes classifier as the number of layers increases. Using a simulation of classification problems, the effectiveness of the proposed method is demonstrated. (C) 2014 Elsevier Ltd. All rights reserved.	[Kim, Sangwook; Yu, Zhibin; Lee, Minho] Kyungpook Natl Univ, Sch Elect Engn, Taegu 702701, South Korea; [Kil, Rhee Man] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, Gyeonggi Do, South Korea	Kil, RM (reprint author), Kyungpook Natl Univ, Sch Elect Engn, 1370 Sankyuk Dong, Taegu 702701, South Korea.	rmkil@skku.edu; mholee@knu.ac.kr			ICT R&D program of MSIP/IITP [10041826]; Industrial Strategic Technology Development Program - Ministry of Knowledge Economy (MIKE, Korea) [10044009]	This work was partly supported by the ICT R&D program of MSIP/IITP. [10041826, Development of emotional features sensing, diagnostics and distribution s/w platform for measurement of multiple intelligence from young children] and by the Industrial Strategic Technology Development Program [10044009] funded by the Ministry of Knowledge Economy (MIKE, Korea) (50%).	Anthony M., 1997, COMPUTATIONAL LEARNI; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bache K., 2013, UCI MACHINE LEARNING; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Ben-Tal A., 1982, OPTIMALITY STABILITY, P39; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; GUIGNARD M, 1969, SIAM J CONTROL, V7, P232, DOI 10.1137/0307016; Hastie T., 1998, ADV NEURAL INFORM PR; Hinton G, 2010, MOMENTUM, V9, P926; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kim HG, 2011, LECT NOTES COMPUT SC, V7064, P774; Kim S., 2013, NEURAL INFORM PROCES, P458; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Luenberger D. G., 1968, OPTIMIZATION VECTOR; Metsis V., 2006, CEAS, P27; Park WJ, 2009, IEEE T NEURAL NETWOR, V20, P1659, DOI 10.1109/TNN.2009.2029103; Platt J., 1999, ADV LARGE MARGIN CLA, V10, P61; Rohatgi V. K., 2001, INTRO PROBABILITY ST, P598; Rosas H, 2010, IEEE T CONSUM ELECTR, V56, P2296, DOI 10.1109/TCE.2010.5681103; Schapire RE, 2003, LECT NOTES STAT, V171, P149; Schapire RE, 1998, ANN STAT, V26, P1651; Smolensky P., 1986, INFORM PROCESSING DY; Tang Yichuan, 2013, WORKSH CHALL REPR LE; Tesauro G., 1992, REINFORCEMENT LEARNI, P33; Ting KM, 1999, J ARTIF INTELL RES, V10, P271; Utgoff PE, 2002, NEURAL COMPUT, V14, P2497, DOI 10.1162/08997660260293319; Vapnik V. N., 1998, STAT LEARNING THEORY; Weston J., 1999, ESANN, V99, P61; Wiering M., 2013, DEEP SUPPORT VECTOR; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	36	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	APR	2015	64				SI		19	28		10.1016/j.neunet.2014.09.007		10	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	CD2RL	WOS:000350926600004	25304363	
J	Liu, F; Liu, BQ; Sun, CJ; Liu, M; Wang, XL				Liu, Feng; Liu, Bingquan; Sun, Chengjie; Liu, Ming; Wang, Xiaolong			Deep Belief Network-Based Approaches for Link Prediction in Signed Social Networks	ENTROPY			English	Article								In some online social network services (SNSs), the members are allowed to label their relationships with others, and such relationships can be represented as the links with signed values (positive or negative). The networks containing such relations are named signed social networks (SSNs), and some real-world complex systems can be also modeled with SSNs. Given the information of the observed structure of an SSN, the link prediction aims to estimate the values of the unobserved links. Noticing that most of the previous approaches for link prediction are based on the members' similarity and the supervised learning method, however, research work on the investigation of the hidden principles that drive the behaviors of social members are rarely conducted. In this paper, the deep belief network (DBN)-based approaches for link prediction are proposed. Including an unsupervised link prediction model, a feature representation method and a DBN-based link prediction method are introduced. The experiments are done on the datasets from three SNSs (social networking services) in different domains, and the results show that our methods can predict the values of the links with high performance and have a good generalization ability across these datasets.	[Liu, Feng; Liu, Bingquan; Sun, Chengjie; Liu, Ming; Wang, Xiaolong] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China; [Wang, Xiaolong] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China	Liu, BQ (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Da Zhi St, Harbin 150001, Peoples R China.	fengliu@insun.hit.edu.cn; liubq@insun.hit.edu.cn; cjsun@insun.hit.edu.cn; mliu@insun.hit.edu.cn; wangxl@insun.hit.edu.cn			National Natural Science Foundation of China [61100094, 61272383, 61300114]; China Postdoctoral Science Foundation [2013M530156]	This work is supported by the National Natural Science Foundation of China (61100094, 61272383 and 61300114) and the China Postdoctoral Science Foundation (No. 2013M530156). We appreciate Baoxun Wang for his constructive suggestions on this paper.	Al Hasan M., 2006, P WORKSH LINK AN COU; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Y., 2013, HDB NEURAL INFORM PR, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Brzozowski MJ, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P817; Burke M, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P27; Carreira-Perpinan M., 2005, ARTIF INTELL, V2005, P17; Davis J.A., 1967, HUM RELAT; Doreian P, 2009, SOC NETWORKS, V31, P1, DOI 10.1016/j.socnet.2008.08.001; Facchetti G, 2011, P NATL ACAD SCI USA, V108, P20953, DOI 10.1073/pnas.1109521108; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Getoor L., 2005, ACM SIGKDD EXPLORATI, V7, P3, DOI DOI 10.1145/1117454.1117456; Guha R, 2004, P 13 INT C WORLD WID, P403, DOI DOI 10.1145/988672.988727; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton G.E., PRACTICAL GUIDE TRAI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang E.H., 2012, ANN M ASS COMP LING, V1, P873; Krizhevsky A., USING VERY DEEP AUTO; Kunegis J., 2009, P 18 INT C WORLD WID, P741, DOI DOI 10.1145/1526709.1526809; Leskovec J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1361; Leskovec Jure, 2010, P 19 INT C WORLD WID, P641, DOI 10.1145/1772690.1772756; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Liu F, 2012, IEEE SYS MAN CYBERN, P1706; Liu F., 2013, NEURAL INFORM PROCES, P425; Lu LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027; Massa P., 2005, 20 NAT C ART INT, V1, P121; Nowak S., 2010, P INT C MULT INF RET, P35, DOI 10.1145/1743384.1743398; Popescul A., 2003, P IJCAI 2003 WORKSH, P109; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Schaul T, 2010, J MACH LEARN RES, V11, P743; Symeonidis P, 2014, WORLD WIDE WEB, V17, P743, DOI 10.1007/s11280-013-0228-2; Taskar B., 2003, LINK PREDICTION RELA; Teh Y. W., 2003, J MACHINE LEARNING R, V4, P1235, DOI 10.1162/jmlr.2003.4.7-8.1235; Wang B., 2010, P 48 ANN M ASS COMP, P1230; Wang B., 2011, TALIP, V10, P21; Yang B, 2007, IEEE T KNOWL DATA EN, V19, P1333, DOI 10.1109/TKDE.2007.1061	40	0	0	MDPI AG	BASEL	POSTFACH, CH-4005 BASEL, SWITZERLAND	1099-4300			ENTROPY-SWITZ	Entropy	APR	2015	17	4					2140	2169		10.3390/e17042140		30	Physics, Multidisciplinary	Physics	CH6DH	WOS:000354125700030		
J	Liu, SQ; Liu, SD; Cai, WD; Che, HY; Pujol, S; Kikinis, R; Feng, DG; Fulham, MJ				Liu, Siqi; Liu, Sidong; Cai, Weidong; Che, Hangyu; Pujol, Sonia; Kikinis, Ron; Feng, Dagan; Fulham, Michael J.		ADNI	Multimodal Neuroimaging Feature Learning for Multiclass Diagnosis of Alzheimer's Disease	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						Alzheimer's disease (AD); classification; deep Learning; MRI; neuroimaging; positron emission tomography (PET)	MILD COGNITIVE IMPAIRMENT; FRONTOTEMPORAL DEMENTIA; FEATURE-EXTRACTION; ELASTIC NET; RETRIEVAL; CLASSIFICATION; BIOMARKERS; OPTIMIZATION; NETWORK; PREDICT	The accurate diagnosis of Alzheimer's disease (AD) is essential for patient care and will be increasingly important as disease modifying agents become available, early in the course of the disease. Although studies have applied machine learning methods for the computer-aided diagnosis of AD, a bottleneck in the diagnostic performance was shown in previous methods, due to the lacking of efficient strategies for representing neuroimaging biomarkers. In this study, we designed a novel diagnostic framework with deep learning architecture to aid the diagnosis of AD. This framework uses a zero-masking strategy for data fusion to extract complementary information from multiple data modalities. Compared to the previous state-of-the-art workflows, our method is capable of fusing multimodal neuroimaging features in one setting and has the potential to require less labeled data. A performance gain was achieved in both binary classification and multiclass classification of AD. The advantages and limitations of the proposed framework are discussed.	[Liu, Siqi; Liu, Sidong; Cai, Weidong; Che, Hangyu; Feng, Dagan] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol Res Grp, Sydney, NSW 2006, Australia; [Liu, Sidong; Cai, Weidong; Pujol, Sonia; Kikinis, Ron] Harvard Univ, Sch Med, Brigham & Womens Hosp, Surg Planning Lab,Dept Radiol, Cambridge, MA 02138 USA; [Feng, Dagan] Shanghai Jiao Tong Univ, Med X Res Inst, Shanghai 200030, Peoples R China; [Fulham, Michael J.] Univ Sydney, Royal Prince Alfred Hosp, Dept PET & Nucl Med, Sydney, NSW 2006, Australia; [Fulham, Michael J.] Univ Sydney, Sydney Med Sch, Sydney, NSW 2006, Australia	Liu, SQ (reprint author), Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol Res Grp, Sydney, NSW 2006, Australia.	sliu4512@uni.sydney.edu.au			ARC; AADRF; NA-MIC [NIH U54EB005149]; NAC [NIH P41EB015902]	This work was supported in part by the ARC, AADRF, NA-MIC (NIH U54EB005149), and NAC (NIH P41EB015902).	Bengio Y., 2005, P ADV NEUR INF PROC, P107; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Bengio Y., 2012, P NEUR NETW TRICKS T, P437; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bouwman FH, 2007, NEUROBIOL AGING, V28, P1070, DOI 10.1016/j.neurobiolaging.2006.05.006; Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381; Brosch T., 2013, P INT C MED IM COMP, V8150, P633; Cai W., 2014, P IEEE INT S BIOM IM, P677; Cai WD, 2010, IEEE IMAGE PROC, P3201, DOI 10.1109/ICIP.2010.5651869; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Che H., 2014, P IEEE INT S BIOM IM, P911; Chetelat G, 2003, NEUROLOGY, V60, P1374; Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013; Davatzikos C, 2011, NEUROBIOL AGING, V32, DOI DOI 10.1016/J.NEUROBIOLAGING.2010.05.023; DeCarli C, 2003, LANCET NEUROL, V2, P15, DOI 10.1016/S1474-4422(03)00262-X; Dubois B, 2007, LANCET NEUROL, V6, P734, DOI 10.1016/S1474-4422(07)70178-3; Fan Y, 2008, NEUROIMAGE, V41, P277, DOI 10.1016/j.neuroimage.2008.02.043; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; Foster NL, 2007, BRAIN, V130, P2616, DOI 10.1093/brain/awm177; Gallant S. I., 1993, NEURAL NETWORK LEARN; Gauthier S, 2006, LANCET, V367, P1262, DOI 10.1016/S0140-6736(06)68542-5; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Heckemann RA, 2011, NEUROIMAGE, V56, P2024, DOI 10.1016/j.neuroimage.2011.03.014; Higdon R, 2004, STAT MED, V23, P315, DOI 10.1002/sim.1719; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132; Kloppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319; Liu J., 2014, ANN INT C IEEE ENG M, P934; Liu S., 2012, J NUCL MED S1, V53, P2309; Liu S., 2013, P INT C MED IM COMP, P303; Liu S., 2013, P 20 IEEE INT C IM P, P601; Liu S., 2013, P IEEE INT S BIOM IM, P206; Liu S., 2013, J NUCL MED S2, V54, P1807; Liu S. Q., 2015, P AUSTR C ART LIF CO, P350; Liu S. Q., 2014, P IEEE INT S BIOM IM, P1015; Liu S. Q., 2014, J NUCL MED S1, V55, P2018; Liu SD, 2010, IEEE ENG MED BIO, P5657; Liu SD, 2012, IEEE IMAGE PROC, P1249; Liu SD, 2011, IEEE ENG MED BIO, P7009; Liu SD, 2011, I S BIOMED IMAGING, P1877; Liu SD, 2014, COMPUT MED IMAG GRAP, V38, P436, DOI 10.1016/j.compmedimag.2014.05.003; Mazziotta J, 2001, PHILOS T R SOC B, V356, P1293; MCKHANN G, 1984, NEUROLOGY, V34, P939; Ngiam J., 2011, P 28 INT C MACH LEAR, P265; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Poultney C., 2006, ADV NEURAL INFORM PR, P1137; Risacher SL, 2009, CURR ALZHEIMER RES, V6, P347; Schnabel J.A., 2001, P MED IM COMP COMP A, V2208, P573; Shen L, 2011, LECT NOTES COMPUT SC, V7012, P27; Singh N., 2012, P INT C MED IM COMP, V7510, P132; Suk H-I, 2013, BRAIN STRUCTURE FUNC, P1; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Weston J., 2012, DEEP LEARNING VIA SE, P639; Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008; Zhang F., 2014, J NUCL MED S1, V55, P2029; Zou H, 2005, J ROY STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou W. Y., 2011, P NIPS WORKSH DEEP L	64	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9294	1558-2531		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	APR	2015	62	4					1132	1140		10.1109/TBME.2014.2372011		9	Engineering, Biomedical	Engineering	CE3ZR	WOS:000351769700013	25423647	
J	Lv, YS; Duan, YJ; Kang, WW; Li, ZX; Wang, FY				Lv, Yisheng; Duan, Yanjie; Kang, Wenwen; Li, Zhengxi; Wang, Fei-Yue			Traffic Flow Prediction With Big Data: A Deep Learning Approach	IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS			English	Article						Deep learning; stacked autoencoders (SAEs); traffic flow prediction	NEURAL-NETWORK APPROACH; MODELS; MULTIVARIATE; VOLUME; REGRESSION; ALGORITHM	Accurate and timely traffic flow information is important for the successful deployment of intelligent transportation systems. Over the last few years, traffic data have been exploding, and we have truly entered the era of big data for transportation. Existing traffic flow prediction methods mainly use shallow traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, a novel deep-learning-based traffic flow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic traffic flow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the first time that a deep architecture model is applied using autoencoders as building blocks to represent traffic flow features for prediction. Moreover, experiments demonstrate that the proposed method for traffic flow prediction has superior performance.	[Lv, Yisheng; Duan, Yanjie; Kang, Wenwen; Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China; [Li, Zhengxi] North China Univ Technol, Beijing 100144, Peoples R China	Lv, YS (reprint author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.	yisheng.lv@ia.ac.cn; duanyanjie2012@ia.ac.cn; kangwenwen2012@ia.ac.cn; lzx@ncut.edu.cn; feiyue@ieee.org	吕, 宜生/	吕, 宜生/0000-0002-0508-1298	National Natural Science Foundation of China [61233001, 61203166, 71232006, 61104054, 61273326]	This work was supported in part by the National Natural Science Foundation of China under Grants 61233001, 61203166, 71232006, 61104054, and 61273326. The Associate Editor for this paper was J. Zhang.	Ahmed M. S., 1979, TRANSPORT RES REC, P1; Ben-Akiva M., 1995, URBAN TRAFFIC NETWOR, P83; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Caltrans, 2014, PERF MEAS SYST PEMS; Cetin M, 2006, TRANSPORT RES REC, P23; Chan KY, 2012, IEEE T INTELL TRANSP, V13, P644, DOI 10.1109/TITS.2011.2174051; Chang H, 2012, IET INTELL TRANSP SY, V6, P292, DOI 10.1049/iet-its.2011.0123; Chen CY, 2012, TRANSPORT RES C-EMER, V22, P103, DOI 10.1016/j.trc.2011.12.006; Chung E., 2001, 24 AUSTR TRANSP RES; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Comert G, 2013, IEEE T INTELL TRANSP, V14, P1360, DOI 10.1109/TITS.2013.2260540; DAVIS GA, 1991, J TRANSP ENG-ASCE, V117, P178, DOI 10.1061/(ASCE)0733-947X(1991)117:2(178); Dia H, 2001, EUR J OPER RES, V131, P253, DOI 10.1016/S0377-2217(00)00125-9; Dimitriou L, 2008, TRANSPORT RES C-EMER, V16, P554, DOI 10.1016/j.trc.2007.11.003; DOUGHERTY M, 1995, TRANSPORT RES C-EMER, V3, P247, DOI 10.1016/0968-090X(95)00009-8; Duncan G., 1997, P IEE C STRAT CONTR; ElFaouzi NE, 1996, TRANSPORTATION AND TRAFFIC THEORY, P41; Feng J., 1901, P IEEE IJCNN IEEE WO, P1897; Ghosh B, 2009, IEEE T INTELL TRANSP, V10, P246, DOI 10.1109/TITS.2009.2021448; Goodfellow I. J., 2013, ARXIV13126082; HAMED MM, 1995, J TRANSP ENG-ASCE, V121, P249, DOI 10.1061/(ASCE)0733-947X(1995)121:3(249); Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huval B., 2013, ARXIV13126885; Jeong YS, 2013, IEEE T INTELL TRANSP, V14, P1700, DOI 10.1109/TITS.2013.2267735; Kamarianakis Y, 2003, TRANSPORT RES REC, P74; Kirby HR, 1997, INT J FORECASTING, V13, P43, DOI 10.1016/S0169-2070(96)00699-1; Kumar K, 2013, PROCD SOC BEHV, V104, P755, DOI 10.1016/j.sbspro.2013.11.170; Lee S., 1999, TRANSPORT RES REC, V1678, P179, DOI 10.3141/1678-22; Levin M., 1980, TRANSPORT RES REC, P47; Li L., 2006, P I EL ENG INT TRANS, V153, P33, DOI DOI 10.1049/IP-ITS:20055009; Lippi M, 2013, IEEE T INTELL TRANSP, V14, P871, DOI 10.1109/TITS.2013.2247040; OKUTANI I, 1984, TRANSPORT RES B-METH, V18, P1, DOI 10.1016/0191-2615(84)90002-X; Palm R. B., 2012, PREDICTION CANDIDATE; Park B, 1998, TRANSPORT RES REC, P39; Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015; Ran B, 2000, INT J TECHNOL MANAGE, V20, P326, DOI 10.1504/IJTM.2000.002870; Shiliang Sun, 2011, IEEE Transactions on Intelligent Transportation Systems, V12, DOI 10.1109/TITS.2010.2093575; Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277; Smith BL, 2002, TRANSPORT RES C-EMER, V10, P303, DOI 10.1016/S0968-090X(02)00009-8; Smith BL, 1997, J TRANSP ENG-ASCE, V123, P261, DOI 10.1061/(ASCE)0733-947X(1997)123:4(261); Stathopoulos A, 2003, TRANSPORT RES C-EMER, V11, P121, DOI 10.1016/S0968-090X(03)00004-4; Sun HY, 2003, TRANSPORT RES REC, P143; Sun SL, 2006, IEEE T INTELL TRANSP, V7, P124, DOI 10.1109/TITS.2006.869623; Tahmasbi R, 2014, IEEE T INTELL TRANSP, V15, P250, DOI 10.1109/TITS.2013.2278614; Tan MC, 2009, IEEE T INTELL TRANSP, V10, P60, DOI 10.1109/TITS.2008.2011693; Van Hinsbergen C. P., 2007, ITS WORLD C BEIJ CHI; vanderVoort M, 1996, TRANSPORT RES C-EMER, V4, P307, DOI 10.1016/S0968-090X(97)82903-8; Vlahogianni EI, 2005, TRANSPORT RES C-EMER, V13, P211, DOI 10.1016/j.trc.2005.04.007; Vlahogianni EI, 2004, TRANSPORT REV, V24, P533, DOI 10.1080/0144164042000196000; Williams BM, 2003, J TRANSP ENG-ASCE, V129, P664, DOI 10.1061/(ASCE)0733-947X(2003)129:6(664); Williams BM, 2001, TRANSPORT RES REC, P194; Williams BM, 1998, TRANSPORT RES REC, P132; Yang F, 2004, TRANSPORT RES REC, P1; Yin HB, 2002, TRANSPORT RES C-EMER, V10, P85, DOI 10.1016/S0968-090X(01)00004-3; Zargari SA, 2012, EXPERT SYST, V29, P124, DOI 10.1111/j.1468-0394.2010.00567.x; Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1624, DOI 10.1109/TITS.2011.2158001; Zhang N, 2008, IEEE INTELL SYST, V23, P19; Zheng WZ, 2006, J TRANSP ENG-ASCE, V132, P114, DOI 10.1061/(ASCE)0733-947X(2006)132:2(114); Zhong M, 2005, J COMPUT CIVIL ENG, V19, P94, DOI 10.1061/(ASCE)0887-3801(2005)19:1(94)	61	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1524-9050	1558-0016		IEEE T INTELL TRANSP	IEEE Trans. Intell. Transp. Syst.	APR	2015	16	2					865	873		10.1109/TITS.2014.2345663		9	Engineering, Civil; Engineering, Electrical & Electronic; Transportation Science & Technology	Engineering; Transportation	CF1CZ	WOS:000352282500029		
J	Raghavendra, R; Busch, C				Raghavendra, R.; Busch, Christoph			Robust Scheme for Iris Presentation Attack Detection Using Multiscale Binarized Statistical Image Features	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Biometrics; iris recognition; anti-spoofing; presentation attacks	RECOGNITION; ALGORITHM; FILTERS	Vulnerability of iris recognition systems remains a challenge due to diverse presentation attacks that fail to assure the reliability when adopting these systems in real-life scenarios. In this paper, we present an in-depth analysis of presentation attacks on iris recognition systems especially focusing on the photo print attacks and the electronic display (or screen) attack. To this extent, we introduce a new relatively large scale visible spectrum iris artefact database comprised of 3300 iris normal and artefact samples that are captured by simulating five different attacks on iris recognition system. We also propose a novel presentation attack detection (PAD) scheme based on multiscale binarized statistical image features and linear support vector machines. Extensive experiments are carried out on four different publicly available iris artefact databases that have revealed the outstanding performance of the proposed PAD scheme when benchmarked with various well-established state-of-the-art schemes.	[Raghavendra, R.; Busch, Christoph] Gjovik Univ Coll, Norwegian Biometr Lab, N-2815 Gjovik, Norway	Raghavendra, R (reprint author), Gjovik Univ Coll, Norwegian Biometr Lab, N-2815 Gjovik, Norway.	raghu07.mys@gmail.com; christoph.bush@hig.no			European Union [284862]	This work was supported by the European Union Seventh Framework Programme FP7/2007-2013 under Grant 284862 for the large-scale integrated Project FIDELITY. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Stan Z. Li. (Corresponding author: R. Raghavendra.)	[Anonymous], 2014, 3010732014 ISOIEC WD; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Czajka A, 2013, 2013 18TH INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P28; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Daugman J., 2004, P 7 INT BIOM C, P1; Erdogmus N., 2013, P IEEE 6 INT C BIOM, P1; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332; Galbally J., 2012, P 5 IAPR ICB MAR APR, P271; He X., 2008, P IEEE GLOBECOM, P1; He XF, 2009, LECT NOTES COMPUT SC, V5558, P1132; He XF, 2007, LECT NOTES COMPUT SC, V4642, P540; He ZF, 2009, LECT NOTES COMPUT SC, V5558, P1080; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hughes Ken, 2013, Proceedings of the 2013 46th Hawaii International Conference on System Sciences (HICSS 2013), DOI 10.1109/HICSS.2013.172; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P1; Kanematsu M., 2007, P ANN C SICE SEP, P361; Kannala J., 2012, P 21 INT C PATT REC, P1363; Lee E., 2005, LECT NOTES COMPUTER, V3832, P397; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; Lee S. S., 2006, POW EL SPEC C 2006 P, P1; Maatta J., 2011, P IEEE INT JOINT C B, P1; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34; Raghavendra R, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P155, DOI 10.1109/ACPR.2013.22; Raghavendra R., 2014, P 2 ACM WORKSH INF H, P181; Raghavendra R, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P193, DOI 10.1109/ICAPR.2009.23; Sequeira A. F., 2013, P 9 INT C COMP VIS T, P1; Sun ZN, 2014, IEEE T PATTERN ANAL, V36, P1120, DOI 10.1109/TPAMI.2013.234; Sutra G., 2012, BIOMETRIC REFERENCE; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025	33	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	APR	2015	10	4					703	715		10.1109/TIFS.2015.2400393		13	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	CE9CR	WOS:000352141700002		
J	Rong, WG; Peng, BL; Ouyang, YX; Li, C; Xiong, Z				Rong, Wenge; Peng, Baolin; Ouyang, Yuanxin; Li, Chao; Xiong, Zhang			Structural information aware deep semi-supervised recurrent neural network for sentiment analysis	FRONTIERS OF COMPUTER SCIENCE			English	Article						sentiment analysis; recurrent neural network; deep learning; machine learning	LANGUAGE; CLASSIFICATION; ALGORITHM; TIME	With the development of Internet, people are more likely to post and propagate opinions online. Sentiment analysis is then becoming an important challenge to understand the polarity beneath these comments. Currently a lot of approaches from natural language processing's perspective have been employed to conduct this task. The widely used ones include bag-of-words and semantic oriented analysis methods. In this research, we further investigate the structural information among words, phrases and sentences within the comments to conduct the sentiment analysis. The idea is inspired by the fact that the structural information is playing important role in identifying the overall statement's polarity. As a result a novel sentiment analysis model is proposed based on recurrent neural network, which takes the partial document as input and then the next parts to predict the sentiment label distribution rather than the next word. The proposed method learns words representation simultaneously the sentiment distribution. Experimental studies have been conducted on commonly used datasets and the results have shown its promising potential.	[Rong, Wenge; Peng, Baolin; Ouyang, Yuanxin; Li, Chao; Xiong, Zhang] Beihang Univ, Sch Engn & Comp Sci, Beijing 100191, Peoples R China; [Rong, Wenge; Ouyang, Yuanxin; Li, Chao; Xiong, Zhang] Beihang Univ, Res Inst, Shenzhen 518057, Peoples R China	Ouyang, YX (reprint author), Beihang Univ, Sch Engn & Comp Sci, Beijing 100191, Peoples R China.	oyyx@buaa.edu.cn			National High Technology Research and Development Program of China [2011AA010502]; National Natural Science Foundation of China [61103095]; Fundamental Research Funds for the Central Universities; Shenzhen Key Laboratory of Data Vitalization (Smart City)	This work was partially supported by the National High Technology Research and Development Program of China (2011AA010502), the National Natural Science Foundation of China (Grant No. 61103095), and the Fundamental Research Funds for the Central Universities. We are grateful to Shenzhen Key Laboratory of Data Vitalization (Smart City) for supporting this research.	Andreevskaia A, 2006, P 11 C EUR CHAPT ASS; Beineke P, 2004, P AAAI SPRING S EXPL; Bengio Y., 2006, P NIPS, P153; Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950; Cardie C, 2003, P 2003 AAAI SPRING S, P20; Chapelle O., 2006, SEMISUPERVISED LEARN; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Cowan J D, 1994, ADV NEURAL INFORM PR, V6; Dave K., 2003, P 12 INT C WORLD WID, P519, DOI DOI 10.1145/775152.775226; Davidov Dmitry, 2010, P 23 INT C COMP LING, P241; De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Erhan D, 2010, J MACH LEARN RES, V11, P625; Erhan D, 2009, P 12 INT C ART INT S, P153; Frinken V, 2010, LECT NOTES ARTIF INT, V5998, P185, DOI 10.1007/978-3-642-12159-3_17; Higashinaka R, 2006, P 21 INT C COMP LING; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hopfield J. J., 1982, NATL ACAD SCI, V79, P2554, DOI DOI 10.1073/PNAS.79.8.2554; Hu M, 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073; Hu X, 2013, P 22 INT C WORLD WID, P607; Joachims T., 1999, P 16 INT C MACH LEAR, V99, P200; Kim S M, 2006, P 21 INT C COMP LING; Kingsbury B, 2009, INT CONF ACOUST SPEE, P3761, DOI 10.1109/ICASSP.2009.4960445; Kombrink S., 2011, P INTERSPEECH, P2877; Lafferty J. D., 2001, ICML, P282; Lee D H, 2013, P 2013 ICML WORKSH C; Li JX, 2006, COMMUN ACM, V49, P76, DOI 10.1145/1121949.1121951; Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755; Liu KL, 2012, P 26 AAAI C ART INT; Liu XH, 2011, COMM COM INF SC, V226, P337; Maas A L, 2011, P 49 ANN M ASS COMP, P142; Maas A.L., 2012, P 13 ANN C INT SPEEC; Manning C.D., 2008, INTRO INFORM RETRIEV; Martens James, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_27; McClosky D, 2006, P 2006 HUM LANG TECH; Mikolov T., 2013, CORR; Mikolov T, 2012, THESIS BRNO U TECHNO; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mikolov T, 2011, INT CONF ACOUST SPEE, P5528; Minsky M, 1987, PERCEPTRONS INTRO CO; Mnih A., 2008, P 22 ANN C NEUR INF, P1081; Morinaga S., 2002, P 8 ACM SIGKDD INT C, P341, DOI DOI 10.1145/775047.775098; Nakagawa T., 2010, P HUM LANG TECHN 11, P786; Pang B, 2005, P 43 ANN M ASS COMP; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79; Pang B., 2007, FOUND TRENDS INF RET, V2, P1; Pascanu R., 2013, P 30 INT C MACH LEAR, P1310; Pennebaker J. W., 2001, LINGUISTIC INQUIRY W; Ranzato M, 2007, P 21 ANN C NEUR INF; Rosenfeld B, 2007, P 45 ANN M ASS COMP; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Rumelhart D E, 2002, COGNITIVE MODELING, P213; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; SCHWENK H, 2002, ACOUST SPEECH SIG PR, P765; Smith N A, 2005, P 43 ANN M ASS COMP, P354, DOI 10.3115/1219840.1219884; Socher R., 2011, P C EMP METH NAT LAN, P151; Stone P. J., 1966, GEN INQUIRER COMPUTE; Subramanya A., 2010, P 2010 C EMP METH NA, P167; Tan C, 2011, P 17 ACM SIGKDD INT, P1397, DOI DOI 10.1145/2020408.2020614; Teh Y W, 2000, P 2000 ADV NEUR INF, V13, P908; Turney P., 2002, P 40 ANN M ASS COMP, P417, DOI DOI 10.3115/1073083.1073153; Ueffing N, 2007, P 45 ANN M ASS COMP; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; van der Maaten L, 2012, MACH LEARN, V87, P33, DOI 10.1007/s10994-011-5273-4; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Volkova S, 2013, P 51 ANN M ASS COMP, V2, P505; Waibel A., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.39; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Whitelaw C., 2005, P 14 ACM INT C INF K, P625, DOI DOI 10.1145/1099554.1099714; Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9; Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90; Yao K, 2013, P 14 ANN C INT SPEEC, P2524; Zhou ZH, 2006, LECT NOTES ARTIF INT, V4099, P5; Zhu X., 2009, SYNTHESIS LECT ARTIF, V3, P1, DOI DOI 10.2200/S00196ED1V01Y200906AIM006	78	0	0	HIGHER EDUCATION PRESS	BEIJING	SHATANHOU ST 55, BEIJING 100009, PEOPLES R CHINA	2095-2228	2095-2236		FRONT COMPUT SCI-CHI	Front.. Comput. Sci.	APR	2015	9	2					171	184		10.1007/s11704-014-4085-7		14	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	CE0TN	WOS:000351519500001		
J	Wang, L; Liu, T; Wang, G; Chan, KL; Yang, QX				Wang, Li; Liu, Ting; Wang, Gang; Chan, Kap Luk; Yang, Qingxiong			Video Tracking Using Learned Hierarchical Features	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article						Object tracking; deep feature learning; domain adaptation	SPARSE APPEARANCE MODEL; ROBUST VISUAL TRACKING; OBJECT TRACKING; NEURAL-NETWORKS; REPRESENTATION; RECOGNITION; HISTOGRAMS; SELECTION	In this paper, we propose an approach to learn hierarchical features for visual object tracking. First, we offline learn features robust to diverse motion patterns from auxiliary video sequences. The hierarchical features are learned via a two-layer convolutional neural network. Embedding the temporal slowness constraint in the stacked architecture makes the learned features robust to complicated motion transformations, which is important for visual object tracking. Then, given a target video sequence, we propose a domain adaptation module to online adapt the pre-learned features according to the specific target object. The adaptation is conducted in both layers of the deep feature learning module so as to include appearance information of the specific target object. As a result, the learned hierarchical features can be robust to both complicated motion transformations and appearance changes of target objects. We integrate our feature learning algorithm into three tracking methods. Experimental results demonstrate that significant improvement can be achieved using our learned hierarchical features, especially on video sequences with complicated motion transformations.	[Wang, Li; Liu, Ting; Wang, Gang; Chan, Kap Luk] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Wang, Gang] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Yang, Qingxiong] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Wang, L (reprint author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	wa0002li@e.ntu.edu.sg; liut0016@e.ntu.edu.sg; gangwang6@gmail.com; eklchan@ntu.edu.sg; qiyang@cityu.edu.hk			Ministry of Education (MOE) [RG84/12, ARC28/14]; Agency for Science, Technology and Research [PSF1321202099]	This work was supported in part by the Ministry of Education (MOE) Tier 1 under Grant RG84/12, in part by the MOE Tier 2 under Grant ARC28/14, and in part by the Agency for Science, Technology and Research under Grant PSF1321202099. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Joseph P. Havlicek.	Adam A., 2006, P IEEE C COMP VIS PA, P798; Avidan S., 2005, P IEEE C COMP VIS PA, P494; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Babenko B, 2009, PROC CVPR IEEE, P983; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bao CL, 2012, PROC CVPR IEEE, P1830; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Cadieu C. F., 2008, P C NEUR INF PROC SY, P209; Coates A., 2012, P NIPS, P2681; Coates A., 2011, P ANN C NEUR INF PRO, P2528; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N, 2005, PROC CVPR IEEE, P886; Doucet A., 2001, SEQUENTIAL MONTE CAR; Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870; Eslami SMA, 2012, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2012.6247702; Glorot X., 2011, P 28 INT C MACH LEAR, P513; GRABNER H, 2008, P EUR C COMP VIS MAR, V5302, P234; Grabner H., 2006, P BMVC, V1, P47; Grabner M., 2007, P IEEE C COMP VIS PA, P1; He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HO J, 2004, P IEEE C COMP VIS PA, V1, P782, DOI 10.1109/CVPR.2004.1315111; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jia X, 2012, PROC CVPR IEEE, P1822; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Krizhevsky A., 2012, P 26 ANN C NEUR INF, P1097; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Le Q. V., 2012, P INT C MACH LEARN, P1; Le Q.V., 2011, P ADV NEUR INF PROC, P1017; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; Li HX, 2011, PROC CVPR IEEE, P1305; Li N, 2008, SCIENCE, V321, P1502, DOI 10.1126/science.1160028; Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313; Liu BY, 2011, PROC CVPR IEEE, P1313; LIU BY, 2010, P 11 EUR C COMP VIS, V6314, P624; Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969; Mei X., 2009, P IEEE INT C COMP VI, P1436; Mei X, 2011, PROC CVPR IEEE, P1257; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pang Y., 2013, P ICCV, P2784; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Wang B, 2014, P IEEE C CVPR JUN, P1234; Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307; Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677; Wang G, 2012, IEEE T PATTERN ANAL, V34, P2177, DOI 10.1109/TPAMI.2012.29; Wang G, 2013, IEEE T PATTERN ANAL, V35, P2442, DOI 10.1109/TPAMI.2013.58; Wang N., 2013, P C NEUR INF PROC SY, P809; Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P3296, DOI 10.1109/TIP.2012.2190085; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yang J., 2007, P 15 INT C MULT, P188, DOI 10.1145/1291233.1291276; Yang JC, 2009, PROC CVPR IEEE, P1794; Zhang K., 2012, P 12 EUR C COMP VIS, P864; Zhang TZ, 2012, PROC CVPR IEEE, P2042; Zhong W, 2012, PROC CVPR IEEE, P1838; Zou W. Y., 2012, P ADV NEUR INF PROC, P3212	63	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1057-7149	1941-0042		IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	APR	2015	24	4					1424	1435		10.1109/TIP.2015.2403231		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CD4XH	WOS:000351088600008		
J	Zhou, P; Jiang, H; Dai, LR; Hu, Y; Liu, QF				Zhou, Pan; Jiang, Hui; Dai, Li-Rong; Hu, Yu; Liu, Qing-Feng			State-Clustering Based Multiple Deep Neural Networks Modeling Approach for Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Cross entropy training; data partition; deep neural networks (DNN); model parallelism; multiple DNNs (mDNN); parallel training; sequence training; speech recognition; state clustering	SYSTEMS	The hybrid deep neural network (DNN) and hidden Markov model (HMM) has recently achieved dramatic performance gains in automatic speech recognition (ASR). The DNN-based acoustic model is very powerful but its learning process is extremely time-consuming. In this paper, we propose a novel DNN-based acoustic modeling framework for speech recognition, where the posterior probabilities of HMM states are computed from multiple DNNs (mDNN), instead of a single large DNN, for the purpose of parallel training towards faster turnaround. In the proposed mDNN method all tied HMM states are first grouped into several disjoint clusters based on data-driven methods. Next, several hierarchically structured DNNs are trained separately in parallel for these clusters using multiple computing units (e.g. GPUs). In decoding, the posterior probabilities of HMM states can be calculated by combining outputs from multiple DNNs. In this work, we have shown that the training procedure of the mDNN under popular criteria, including both frame-level cross-entropy and sequence-level discriminative training, can be parallelized efficiently to yield significant speedup. The training speedup is mainly attributed to the fact that multiple DNNs are parallelized over multiple GPUs and each DNN is smaller in size and trained by only a subset of training data. We have evaluated the proposed mDNN method on a 64-hour Mandarin transcription task and the 320-hour Switchboard task. Compared to the conventional DNN, a 4-cluster mDNN model with similar size can yield comparable recognition performance in Switchboard (only about 2% performance degradation) with a greater than 7 times speed improvement in CE training and a 2.9 times improvement in sequence training, when 4 GPUs are used.	[Zhou, Pan; Dai, Li-Rong; Hu, Yu; Liu, Qing-Feng] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China; [Jiang, Hui] York Univ, Lassonde Sch Engn, Dept Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada	Zhou, P (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230026, Peoples R China.	pan2005@mail.ustc.edu.cn; hj@cse.yorku.ca; lrdai@ustc.edu.cn; yuhu@iflytek.com; qfliu@iflytek.com			National Nature Science Foundation of China [61273264]; National 973 program of China [2012CB326405]	This work was supported in part by the National Nature Science Foundation of China under Grant 61273264 and in part by the National 973 program of China under Grant 2012CB326405. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Mei-Yuh Hwang.	Abdel-Hamid O., 2012, P IEEE INT C AC SPEE; Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736; Bourlard H., 1992, P IEEE INT C AC SPEE; Bourlard H.A., 1993, CONNECTIONIST SPEECH; Chen X., 2012, P INTERSPEECH; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; FRANCO H, 1994, COMPUT SPEECH LANG, V8, P211, DOI 10.1006/csla.1994.1010; Gibson M., 2006, P INTERSPEECH; Grezl F., 2007, P IEEE INT C AC SPEE, P4729; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jaitly N., 2012, P INTERSPEECH; Jiang H, 2010, COMPUT SPEECH LANG, V24, P589, DOI 10.1016/j.csl.2009.08.002; Kingsbury B., 2012, P INTERSPEECH; Kontar S., 2006, P 12 INT C SOFT COMP; Le H.-S., 2013, IEEE T AUDIO SPEECH, V21, P197; Le Q., 2012, P ICML; Li X., 2006, P INT C SPOK LANG PR; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed A.-R., 2012, P IEEE INT C AC SPEE; Mohamed A.-R., 2009, P NIPS WORKSH DEEP L; Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301; Park J., 2009, P INTERSPEECH; Povey D., 2004, DISCRIMINATIVE TRAIN, V79; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath T. N., 2013, P IEEE INT C AC SPEE; Seide F., 2011, P IEEE WORKSH AUT SP; Seide F., 2014, P INTERSPEECH; Seide F., 2011, P INTERSPEECH, P437; Su H., 2013, P IEEE INT C AC SPEE; Valtchev V, 1997, SPEECH COMMUN, V22, P303, DOI 10.1016/S0167-6393(97)00029-0; Vesely K., 2010, P INTERSPEECH; Xue J., 2013, P INTERSPEECH; Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313; Yu D., 2010, P NIPS WORKSH DEEP L; Yu D., 2012, P IEEE INT C AC SPEE; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zhang S., 2014, P IEEE INT C AC SPEE; Zhang S., 2013, P IEEE INT C AC SPEE; Zhou P., 2014, P IEEE INT C AC SPEE; Zhou P., 2013, P IEEE INT C AC SPEE	43	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	APR	2015	23	4					631	642		10.1109/TASLP.2015.2392944		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CE4ZY	WOS:000351840600003		
J	Geman, D; Geman, S; Hallonquist, N; Younes, L				Geman, Donald; Geman, Stuart; Hallonquist, Neil; Younes, Laurent			Visual Turing test for computer vision systems	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						scene interpretation; computer vision; Turing test; binary questions; unpredictable answers	OBJECT RECOGNITION; DATABASE; PERFORMANCE; ANNOTATION; MODELS; TOOL	Today, computer vision systems are tested by their accuracy in detecting and localizing instances of objects. As an alternative, and motivated by the ability of humans to provide far richer descriptions and even tell a story about an image, we construct a "visual Turing test": an operator-assisted device that produces a stochastic sequence of binary questions from a given test image. The query engine proposes a question; the operator either provides the correct answer or rejects the question as ambiguous; the engine proposes the next question ("just-in-time truthing"). The test is then administered to the computer-vision system, one question at a time. After the system's answer is recorded, the system is provided the correct answer and the next question. Parsing is trivial and deterministic; the system being tested requires no natural language processing. The query engine employs statistical constraints, learned from a training set, to produce questions with essentially unpredictable answers-the answer to a question, given the history of questions and their correct answers, is nearly equally likely to be positive or negative. In this sense, the test is only about vision. The system is designed to produce streams of questions that follow natural story lines, from the instantiation of a unique object, through an exploration of its properties, and on to its relationships with other uniquely instantiated objects.	[Geman, Donald; Hallonquist, Neil; Younes, Laurent] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21287 USA; [Geman, Stuart] Brown Univ, Div Appl Math, Providence, RI 02912 USA	Geman, S (reprint author), Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21287 USA.	stuart_geman@brown.edu			Office of Naval Research [ONR N000141010933]; Defense Advanced Research Projects Agency [FA8650-11-1-7151]; National Science Foundation [0964416]	We received helpful input from Mark Johnson of Macquarie University and Vincent Velten of the Air Force Research Laboratory. This work was partially supported by the Office of Naval Research under Contract ONR N000141010933, the Defense Advanced Research Projects Agency under Contract FA8650-11-1-7151, and the National Science Foundation under Grant 0964416.	Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Chang LB, 2011, INT J COMPUT VISION, V93, P117, DOI 10.1007/s11263-010-0391-1; Deng J, 2009, PROC CVPR IEEE, P248; Endres I, 2010, P IEEE 2010 CVPR, P1; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Girshick R., 2013, ARXIV13112524; Hariharan B, 2014, ECCV 2014, P297; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krizhevsky A, 2012, NIPS, P1097; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu W, 2014, ARXIV14062375; Oh S., 2011, P IEEE C COMP VIS PA, P3153; Ommer B, 2006, P IEEE INT C COMP VI, P194; Oquab M., 2014, P IEEE 2014 CVPR, P1717; Ozdemir B, 2010, PATTERN RECOGN LETT, V31, P1128, DOI 10.1016/j.patrec.2009.10.016; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Russell S, 2003, ARTIFICIAL INTELLIGE; Saygin AP, 2003, TURNING TEST, P23; Turing A., 1950, MIND, V49, p[433, 2099], DOI DOI 10.1093/MIND/LIX.236.433; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169; Yu GS, 2009, INT CONF ACOUST SPEE, P1597, DOI 10.1109/ICASSP.2009.4959904; Zhang N, 2013, ARXIV13115591; Zhu Qiang, 2006, CVPR, V2, P1491; Zhu S.-C., 2006, FDN TRENDS COMPUTER, V2, P259, DOI 10.1561/0600000018	28	0	0	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	MAR 24	2015	112	12					3618	3623		10.1073/pnas.1422953112		6	Multidisciplinary Sciences	Science & Technology - Other Topics	CE0EJ	WOS:000351477000029	25755262	
J	Schuld, M; Sinayskiy, I; Petruccione, F				Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco			Simulating a perceptron on a quantum computer	PHYSICS LETTERS A			English	Article						Quantum neural network; Quantum machine learning; Quantum computing; Linear classification	NEURAL-NETWORKS; MODEL	Perceptrons are the basic computational unit of artificial neural networks, as they model the activation mechanism of an output neuron due to incoming signals from its neighbours. As linear classifiers, they play an important role in the foundations of machine learning. In the context of the emerging field of quantum machine learning, several attempts have been made to develop a corresponding unit using quantum information theory. Based on the quantum phase estimation algorithm, this paper introduces a quantum perceptron model imitating the step-activation function of a classical perceptron. This scheme requires resources in O(n) (where n is the size of the input) and promises efficient applications for more complex structures such as trainable quantum neural networks. (C) 2014 Elsevier B.V. All rights reserved.	[Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco] Univ KwaZulu Natal Durban, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Kwa Zulu, South Africa; [Sinayskiy, Ilya; Petruccione, Francesco] Natl Inst Theoret Phys NITheP, ZA-4001 Kwa Zulu, South Africa	Schuld, M (reprint author), Univ KwaZulu Natal Durban, Sch Chem & Phys, Quantum Res Grp, ZA-4001 Kwa Zulu, South Africa.	schuld@ukzn.ac.za			South African Research Chair Initiative of the Department of Science and Technology, Republic of South Africa; National Research Foundation	This work is based upon research supported by the South African Research Chair Initiative of the Department of Science and Technology, Republic of South Africa, and National Research Foundation.	Altaisky M., ARXIVQUANTPH0107012; BARENCO A, 1995, PHYS REV A, V52, P3457, DOI 10.1103/PhysRevA.52.3457; Behrman EC, 2000, INFORM SCIENCES, V128, P257, DOI 10.1016/S0020-0255(00)00056-6; Dorit Aharonov J.K., 2001, P 33 STOC, P50; Fei L., 2003, P IEEE INT C NEUR NE, V1, P539; Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237866; Gupta S, 2001, J COMPUT SYST SCI, V63, P355, DOI 10.1006/jcss.2001.1769; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kouda N, 2005, NEURAL COMPUT APPL, V14, P114, DOI 10.1007/S00521-004-0446-8; LEWENSTEIN M, 1994, J MOD OPTIC, V41, P2491, DOI 10.1080/09500349414552331; Minsky M., 1969, PERCEPTRONS INTRO CO; Nielsen M. A., 2010, QUANTUM COMPUTATION; Plenio MB, 2001, CONTEMP PHYS, V42, P25, DOI 10.1080/00107510010018916; Purushothaman G, 1997, IEEE T NEURAL NETWOR, V8, P679, DOI 10.1109/72.572106; Quoc Le V., 2013, 2013 IEEE INT C AC S, P8595; Ricks B., 2003, ADV NEURAL INFORM PR, V16, P1; Rojas R., 1996, NEURAL NETS SYSTEMAT; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sagheer A., ARXIV13124149; Schuld M, 2014, QUANTUM INF PROCESS, V13, P2567, DOI 10.1007/s11128-014-0809-8; Siomau M, 2014, QUANTUM INF PROCESS, V13, P1211, DOI 10.1007/s11128-013-0723-5; Watrous J., 2014, LECT NOT WINT 2006; Zhou RG, 2007, INT J THEOR PHYS, V46, P3209, DOI 10.1007/s10773-007-9437-8	24	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0375-9601	1873-2429		PHYS LETT A	Phys. Lett. A	MAR 20	2015	379	7					660	663		10.1016/j.physleta.2014.11.061		4	Physics, Multidisciplinary	Physics	CB8KD	WOS:000349877600009		
J	Berniker, M; Kording, KP				Berniker, Max; Kording, Konrad P.			Deep networks for motor control functions	FRONTIERS IN COMPUTATIONAL NEUROSCIENCE			English	Article						optimal control; deep learning; neural networks; arm reaches; motor control; motor learning	CEREBELLAR VENTRAL PARAFLOCCULUS; OCULAR FOLLOWING RESPONSES; TEMPORAL FIRING PATTERNS; PURKINJE-CELLS; REACHING MOVEMENTS; NEURAL-NETWORKS; ARM MOVEMENTS; CORTEX; DYNAMICS; MODEL	The motor system generates time-varying commands to move our limbs and body. Conventional descriptions of motor control and learning rely on dynamical representations of our body's state (forward and inverse models), and control policies that must be integrated forward to generate feedforward time-varying commands; thus these are representations across space, but not time. Here we examine a new approach that directly represents both time-varying commands and the resulting state trajectories with a function; a representation across space and time. Since the output of this function includes time, it necessarily requires more parameters than atypical dynamical model. To avoid the problems of local minima these extra parameters introduce, we exploit recent advances in machine learning to build our function using a stacked autoencoder, or deep network. With initial and target states as inputs, this deep network can be trained to output an accurate temporal profile of the optimal command and state trajectory for a point-to-point reach of a non-linear limb model, even when influenced by varying force fields. In a manner that mirrors motor babble, the network can also teach itself to learn through trial and error. Lastly, we demonstrate how this network can learn to optimize a cost objective. This functional approach to motor control is a sharp departure from the standard dynamical approach, and may offer new insights into the neural implementation of motor control.	[Berniker, Max] Univ Illinois, Dept Mech & Ind Engn, Chicago, IL 60607 USA; [Berniker, Max; Kording, Konrad P.] Northwestern Univ, Dept Phys Med & Rehabil, Chicago, IL 60611 USA	Berniker, M (reprint author), Univ Illinois, Dept Mech & Ind Engn, 842 West Taylor St,2023 ERE, Chicago, IL 60607 USA.	mbernike@uic.edu			National Science Foundation [CMMI 1200830]; National Institute of Neurological Disorders and Stroke [1R01-NS-063399]	MB is supported in part by the National Science Foundation Grant CMMI 1200830. KPK is supported by National Institute of Neurological Disorders and Stroke Grant 1R01-NS-063399.	ABELES M, 1993, J NEUROPHYSIOL, V70, P1629; Averbeck BB, 2002, P NATL ACAD SCI USA, V99, P13172, DOI 10.1073/pnas.162485599; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Berniker M, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002210; Berniker M, 2008, NAT NEUROSCI, V11, P1454, DOI 10.1038/nn.2229; Bertsekas DP, 1995, DYNAMIC PROGRAMMING, V1; Bryson A., 1975, APPL OPTIMAL CONTROL; Churchland MM, 2012, NATURE, V487, P51, DOI 10.1038/nature11129; Cohen YE, 2002, NAT REV NEUROSCI, V3, P553, DOI 10.1038/nrn873; Coltz JD, 1999, J NEUROSCI, V19, P1782; d'Avella A, 2003, NAT NEUROSCI, V6, P300, DOI 10.1038/nn1010; Dearden A., 2005, P INT JOINT C ART IN; Doeringer JA, 1998, J NEUROPHYSIOL, V80, P1787; Fishbach A, 2007, EXP BRAIN RES, V177, P45, DOI 10.1007/s00221-006-0652-y; Georgopoulos AP, 2007, P NATL ACAD SCI USA, V104, P11068, DOI 10.1073/pnas.0611597104; Gomi H, 1998, J NEUROPHYSIOL, V80, P818; Goodfellow I., 2009, P ADV NEURAL INFORM; Hayon G, 2005, J COMPUT NEUROSCI, V18, P41, DOI 10.1007/s10827-005-5479-1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOGAN N, 1984, J NEUROSCI, V4, P2745; HOGAN N, 1987, EXERCISE SPORT SCI R, V15, P153; Kobayashi Y, 1998, J NEUROPHYSIOL, V80, P832; Krebs HI, 1999, P NATL ACAD SCI USA, V96, P4645, DOI 10.1073/pnas.96.8.4645; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Meltzoff AN, 1997, EARLY DEV PARENTING, V6, P179, DOI 10.1002/(SICI)1099-0917(199709/12)6:3/4<179::AID-EDP157>3.0.CO;2-R; MIALL RC, 1993, J MOTOR BEHAV, V25, P53; Paz R, 2003, NAT NEUROSCI, V6, P882, DOI 10.1038/nn1097; Saegusa R., 2009, ROB BIOM 2008 ROBIO, DOI [10.1109/ROBIO.2009.4913101, DOI 10.1109/ROBIO.2009.4913101]; Salakhutdinov R., 2009, P INT C ART INT STAT; Schweighofer N, 1998, EUR J NEUROSCI, V10, P86, DOI 10.1046/j.1460-9568.1998.00006.x; Schweighofer N, 1998, EUR J NEUROSCI, V10, P95, DOI 10.1046/j.1460-9568.1998.00007.x; Shenoy KV, 2013, ANNU REV NEUROSCI, V36, P337, DOI 10.1146/annurev-neuro-062111-150509; SHIDARA M, 1993, NATURE, V365, P50, DOI 10.1038/365050a0; Stengel R.F., 1994, OPTIMAL CONTROL ESTI; Tanji J, 2001, ANNU REV NEUROSCI, V24, P631, DOI 10.1146/annurev.neuro.24.1.631; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P., 2008, P 25 INT C MACH LEAR	38	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5188			FRONT COMPUT NEUROSC	Front. Comput. Neurosci.	MAR 19	2015	9								32	10.3389/fncom.7015.00032		10	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	CF3VF	WOS:000352476200001	25852530	
J	Leng, B; Zhang, X; Yao, M; Xiong, Z				Leng, Biao; Zhang, Xiangyang; Yao, Ming; Xiong, Zhang			A 3D model recognition mechanism based on deep Boltzmann machines	NEUROCOMPUTING			English	Article						3D model recognition; Deep Boltzmann machines; Semi-supervised learning	3-D OBJECT RETRIEVAL; SHAPE DESCRIPTOR; RELEVANCE FEEDBACK; LEARNING ALGORITHM; SEARCH ENGINE; SYSTEM; SIMILARITY; CLASSIFICATION; FRAMEWORK; NETWORKS	The effectiveness of 3D model recognition generally depends on the feature representations and classification methods. Previous algorithms have not shown good capacities to detect 3D model's feature, thus, they seem not to be competent to recognize 3D model. Meanwhile, recent efforts have illustrated that Deep Boltzmann Machines (DBM) have great power to approximate the distributions of input data, and can archive state-of-the-arts results. In this paper, we propose a novel 3D model recognition mechanism based on DBM, which can be divided into two parts: one is feature detecting based on DBM, and the other is classification based on semi-supervised learning method. During the first part, the high-level abstraction representation can be obtained from a well-trained DBM, and the feature is used in semi-supervised classification method in the second part. The experiments are conducted on publicly available 3D model data sets: Princeton Shape Benchmark (PSB), SHREC'09 and National Taiwan University (NTU). The proposed method is compared with several state-of-the-art methods in terms of several popular evaluation criteria, and the experimental results show better performance of the proposed model. (C) 2014 Elsevier B.V. All rights reserved.	[Leng, Biao; Zhang, Xiangyang; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China; [Yao, Ming] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Leng, B (reprint author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.	lengbiao@buaa.edu.cn			National Natural Science Foundation of China [61103093, 61472023]; New Teachers' Fund for Doctor Stations from Ministry of Education [20111102120017]; National High-Tech Research and Development Plan of China (863) [2013AA01A601]	The 3D model databases PSB and NTU are from the Shape Retrieval and Analysis Group at the University of Princeton and the National Taiwan University. This work is supported by the National Natural Science Foundation of China (no. 61103093), (no. 61472023), the New Teachers' Fund for Doctor Stations from Ministry of Education (no. 20111102120017) and the National High-Tech Research and Development Plan of China (863) (no. 2013AA01A601).	Akgul CB, 2010, INT J COMPUT VISION, V89, P392, DOI 10.1007/s11263-009-0294-1; Akgul CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25; Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359; Atmosukarto I, 2005, P 11 INT MULT MOD C, P334; Bengio Y., 2009, TRENDS MACH LEARN, V2, P1; Biasotti S, 2008, PATTERN RECOGN, V41, P2855, DOI 10.1016/j.patcog.2008.02.003; Blum A., 2001, P 18 INT C MACH LEAR, P19; Bronstein AM, 2009, INT J COMPUT VISION, V81, P281, DOI 10.1007/s11263-008-0172-2; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI 10.1145/1390156.1390177; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2; Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Elad M., 2001, P 6 EUR WORKSH MULT, P97; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; Gao Y, 2012, INFORM SCIENCES, V194, P224, DOI 10.1016/j.ins.2012.01.003; Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619; Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081; Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012; Gao Y, 2010, P ACM INT C MULT FIR, P955, DOI 10.1145/1873951.1874122; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Gao Y, 2014, IEEE MULTIMEDIA, V21, P52; Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006; Giorgi D, 2010, VISUAL COMPUT, V26, P1321, DOI 10.1007/s00371-010-0524-0; Godil A., 2009, P EUR WORKSH 3D OBJ, P61; Goldfeder C., 2008, P 8 ACM IEEE CS JOIN, P355, DOI 10.1145/1378889.1378950; Goldfeder C, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P233, DOI 10.1109/SMI.2008.4547983; Grzegorzek M, 2010, PATTERN ANAL APPL, V13, P333, DOI 10.1007/s10044-009-0163-0; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Kim HJ, 2010, MULTIMED TOOLS APPL, V47, P7, DOI 10.1007/s11042-009-0404-7; Krizhevsky A, 2012, P ADV NEUR INF PROC, P1106; Laga H, 2006, VISUAL COMPUT, V22, P324, DOI 10.1007/s00371-006-0010-x; Lai Kang, 2013, Frontiers of Computer Science, V7, DOI 10.1007/s11704-013-1266-8; Leifman G, 2005, VISUAL COMPUT, V21, P865, DOI 10.1007/s00371-005-0341-z; Leng B., 2014, P 20 ANN INT C MULT, P128; Leng B, 2007, J ZHEJIANG UNIV-SC A, V8, P1953, DOI 10.1631/jzus.2007.A1953; Leng B, 2007, LECT NOTES COMPUT SC, V4418, P93; Leng B, 2008, MULTIMED TOOLS APPL, V40, P135, DOI 10.1007/s11042-007-0188-6; Leng BA, 2009, CHINESE J ELECTRON, V18, P291; Leng BA, 2010, FRONT COMPUT SCI CHI, V4, P394, DOI 10.1007/s11704-010-0366-y; Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Li F, 2010, SIGNAL PROCESS-IMAGE, V25, P18, DOI 10.1016/j.image.2009.11.001; Li JB, 2013, NEURAL COMPUT APPL, V22, P771, DOI 10.1007/s00521-011-0768-2; Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x; Liu ZB, 2010, MULTIMEDIA SYST, V16, P319, DOI 10.1007/s00530-010-0193-x; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; OHBUCHI R, 2008, P IEEE INT C SHAP MO, P93; Ohbuchi R., 2007, P ACM MIR 2007, P31, DOI 10.1145/1290082.1290090; Onasoglou E, 2008, MULTIMED TOOLS APPL, V39, P217, DOI 10.1007/s11042-008-0216-1; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6; Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026; Paquet E, 1999, IMAGE VISION COMPUT, V17, P157, DOI 10.1016/S0262-8856(98)00119-X; Park YS, 2009, IEEE T CONSUM ELECTR, V55, P240; Passalis G, 2007, VISUAL COMPUT, V23, P5, DOI 10.1007/s00371-006-0037-z; Patane G, 2009, IEEE T VIS COMPUT GR, V15, P583, DOI 10.1109/TVCG.2009.22; Qian Q, 2013, FRONT COMPUT SCI-CHI, V7, P359, DOI 10.1007/s11704-013-2110-x; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Rustamov RM, 2010, VISUAL COMPUT, V26, P1245, DOI 10.1007/s00371-010-0518-y; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R., 2012, P ADV NEUR INF PROC, P2456; Salakhutdinov R., 2009, P INT C ART INT STAT, P448; Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/SMI.2004.1314504; Tieleman T., 2009, P 26 INT C MACH LEAR, P1033; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Toldo R, 2010, VISUAL COMPUT, V26, P1257, DOI 10.1007/s00371-010-0519-x; Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Zarpalas D., 2007, EURASIP J APPL SIG P, V39, P441; Zeng J., 2014, MULTIM TOOL IN PRESS; Zhu KP, 2009, COMPUT AIDED DESIGN, V41, P28, DOI 10.1016/j.cad.2008.11.007	80	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAR 5	2015	151		2				593	602		10.1016/j.neucom.2014.06.084		10	Computer Science, Artificial Intelligence	Computer Science	AY7QF	WOS:000347753500008		
J	Li, SZ; Yu, B; Wu, W; Su, SZ; Ji, RR				Li, Shao-Zi; Yu, Bin; Wu, Wei; Su, Song-Zhi; Ji, Rong-Rong			Feature learning based on SAE-PCA network for human gesture recognition in RGBD images	NEUROCOMPUTING			English	Article						Deep learning; Auto-encoder; Convolutional neural networks; American sign language recognition	3-D OBJECT RETRIEVAL	Coming with the emerging of depth sensors link Microsoft Kinect, human hand gesture recognition has received ever increasing research interests recently. A successful gesture recognition system has usually heavily relied on having a good feature representation of data, which is expected to be task-dependent as well as coping with the challenges and opportunities induced by depth sensor. In this paper, a feature learning approach based on sparse auto-encoder (SAE) and principle component analysis is proposed for recognizing human actions, i.e. finger-spelling or sign language, for RGB-D inputs. The proposed model of feature learning is consisted of two components: First, features are learned respectively from the RGB and depth channels, using sparse auto-encoder with convolutional neural networks. Second, the learned features from both channels is concatenated and fed into a multiple layer PCA to get the final feature. Experimental results on American sign language (ASL) dataset demonstrate that the proposed feature learning model is significantly effective, which improves the recognition rate from 75% to 99.05% and outperforms the state-of-the-art. (C) 2014 Elsevier B.V. All rights reserved.	[Li, Shao-Zi; Yu, Bin; Wu, Wei; Su, Song-Zhi; Ji, Rong-Rong] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China; [Li, Shao-Zi; Yu, Bin; Wu, Wei; Su, Song-Zhi; Ji, Rong-Rong] Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China; [Yu, Bin] GuiZhou Normal Univ, Inst Math & Comp Sci, Beijing 550001, Guizhou, Peoples R China	Ji, RR (reprint author), Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China.	rrji@xmu.edu.cn			Nature Science Foundation of China [61422210, 61373076, 61202143]; Fundamental Research Funds for the Central Universities [2013121026, 2011121052]; 985 Project of Xiamen University; Natural Science Foundation of Fujian Province [2013J05100, 2010J01345, 2011J01367]; Key Projects Fund of Science and Technology in Xiamen [3502Z20123017]; Research Fund for the Doctoral Program of Higher Education of China [201101211120024]; Special Fund for Developing Shenzhen's Strategic Emerging Industries [JCYJ20120614164600201]; Hunan Provincial Natural Science Foundation [12JJ2040]; Hunan Province Research Foundation of Education Committee [09A046]	This work is supported by the Nature Science Foundation of China (Nos. 61422210, 61373076, 61202143), the Fundamental Research Funds for the Central Universities (Nos. 2013121026, 2011121052), the 985 Project of Xiamen University, the Natural Science Foundation of Fujian Province (Nos. 2013J05100, 2010J01345 and 2011J01367), the Key Projects Fund of Science and Technology in Xiamen (no. 3502Z20123017), the Research Fund for the Doctoral Program of Higher Education of China (no. 201101211120024), the Special Fund for Developing Shenzhen's Strategic Emerging Industries (no. JCYJ20120614164600201), the Hunan Provincial Natural Science Foundation (12JJ2040), and the Hunan Province Research Foundation of Education Committee (09A046).	Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bo LF, 2011, IEEE INT C INT ROBOT, P821; Dalai N., 2005, IEEE INT C COMP VIS, P886; Estrela B.N., 2013, WVC 9 WORKSH VIS COM; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Isaacs J, 2004, SOUTHEAST SYMP SYSTE, P132; Keskin C., 2012, IEEE COMP SOC C COMP, P31; Keskin Cem, 2013, CONSUMER DEPTH CAMER, P119; Kim Y, 2013, INT CONF ACOUST SPEE, P3687; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Le Q. V., 2011, IEEE C COMP VIS PATT, P3361; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7; Mitchell B., 2012, 11 INT C MACH LEARN, P162; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Otiniano Rodriguez K., 2013, 2013 26 SIBGRAPI C G, P1; Pugeault N., 2011, IEEE INT C COMP VIS, P1114; Rongrong Ji, 2013, IEEE Transactions on Multimedia, V15, DOI 10.1109/TMM.2012.2225035; Rongrong J., 2009, P 17 ACM INT C MULT, P105, DOI 10.1145/1631040.1631057; Rongrong Ji, 2012, IEEE Transactions on Image Processing, V21, DOI 10.1109/TIP.2011.2176950; Rongrong Ji, 2012, International Journal of Computer Vision, V96, DOI 10.1007/s11263-011-0472-9; Rongrong J., 2010, IEEE C COMP VIS PATT, P918; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Sivic J., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Socher R., 2012, ADV NEURAL INF PROCE, V25, P665; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; Van den Bergh M., 2011, IEEE WORKSH APPL COM, P66; Yuan Z., 2013, P 21 ACM INT C MULT, P253; Zhang C., 2013, 10 IEEE INT C WORKSH, P1	37	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAR 5	2015	151		2				565	573		10.1016/j.neucom.2014.06.086		9	Computer Science, Artificial Intelligence	Computer Science	AY7QF	WOS:000347753500005		
J	Zou, FH; Wang, YF; Yang, Y; Zhou, K; Chen, YP; Song, JK				Zou, Fuhao; Wang, Yunfei; Yang, Yang; Zhou, Ke; Chen, Yunpeng; Song, Jingkuan			Supervised feature learning via l(2)-norm regularized logistic regression for 3D object recognition	NEUROCOMPUTING			English	Article						Logistic regression; Stochastic gradient ascent; 3D object recognition; Feature learning	IMAGE FEATURES; RETRIEVAL	With the advance of 3D digitalization techniques, it has produced a large number of digital 3D objects, which are usually present in graph, image or video format. In this paper, we focus on designing a novel feature extraction method towards 2D image of 3D object for recognition task. Motivated by the fact that the responses generated by a classifier for two objects can highly reflect their semantic similarity, we attempt to exploit a set of classifiers to construct feature extraction method. The basic idea is as follows. We first learn a classifier for each class and then combine the outputs of all classifiers as object feature. Due to the label information being considered, the proposed method will be more powerful than the typical methods, such as SIFT based bag-of-feature and sparse coding, in terms of discovering the latent semantic information. This is helpful to improve the accuracy of the object recognition. In addition, to make the proposed method scalable to be trained over the massive data (so as to better its generalization ability), the l(2)-norm logistic regression is selected as the classifier and trained with stochastic gradient ascent. At the aspect of time complexity, the proposed method is linear to the number of image pixels and less expensive than the other two methods. These arguments have been demonstrated by the obtained experimental results, which is performed over four 3D datasets, such as COIL-100, 3Ddata, ETH-80 and RGB-D dataset. (C) 2014 Elsevier B.V. All rights reserved.	[Zou, Fuhao; Wang, Yunfei; Chen, Yunpeng] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China; [Yang, Yang] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China; [Zhou, Ke] Huazhong Univ Sci & Technol, Wuhan Natl Lab Optoelect, Wuhan 430074, Peoples R China; [Song, Jingkuan] Univ Trento, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy	Wang, YF (reprint author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.	yunfeiwang@hust.edu.cn			National Basic Research Program (973 Program) of China [2011CB302305]; National Natural Science Foundation of China [61232004]	This work is supported in part by the National Basic Research Program (973 Program) of China under Grant no. 2011CB302305 and the National Natural Science Foundation of China under Grant no. 61232004.	Brown M, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P56, DOI 10.1109/3DIM.2005.81; Chu C.T., NIPS, V6, P281; Daoudi E.M., 2012, IMAGE SIGNAL PROCESS, P391; Forssen P.E., IEEE 11 INT C COMP V, P1; Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ji R., 2014, IEEE T IMAG IN PRESS, VXX; Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950; Larios N., 2011 IEEE WORKSH APP, P329; Lazebnik S., 2006 IEEE COMP SOC C, V2, P2169; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Leibe B., 2003 IEEE COMP SOC C, V2, P11; Li X., 2007, IEEE 11 INT C COMP V, P1; Liu Q., 2012, TSINGHUA SCI TECHNOL, V17, P128; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060; Nair V., NIPS, P1339; Nayar S.K., 1996, TECHNICAL REPORT; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Savarese S., ICCV, P1; Sheng X., INT C COMM CIRC SYST, P1000; Socher R., NIPS, P665; Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679; Urdiales C, 2010, IEEE MEDITERR ELECT, P206, DOI 10.1109/MELCON.2010.5476302; Wang G, 2012, IEEE T PATTERN ANAL, V34, P2177, DOI 10.1109/TPAMI.2012.29; Yan P., IEEE 11 INT C COMP V, P1; Yang Y., 2013, ACM T MULTIMED COMPU, V9; Yang Y., 2014, IEEE T MULT IN PRESS, VXX; Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118; Yang Y., P IEEE COMP SOC C CO, V4, P881; Yin XX, 2012, COMPUT METH PROG BIO, V108, P629, DOI 10.1016/j.cmpb.2011.10.007; Yoon SM, 2012, ELECTRON LETT, V48, P493, DOI 10.1049/el.2012.0170; Zinkevich M., NIPS, V4, P4	37	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAR 5	2015	151		2				603	611		10.1016/j.neucom.2014.06.089		9	Computer Science, Artificial Intelligence	Computer Science	AY7QF	WOS:000347753500009		
J	Xu, JG; Li, H; Zhou, SL				Xu, Jungang; Li, Hui; Zhou, Shilong			An Overview of Deep Generative Models	IETE TECHNICAL REVIEW			English	Article						Deep belief networks; Restricted boltzmann machine; Deep autoencoder; Deep generative model; Deep boltzmann machine	RESTRICTED BOLTZMANN MACHINES; NEURAL-NETWORKS; CONTRASTIVE DIVERGENCE; BELIEF NETWORKS; VISUAL-CORTEX; RECOGNITION	As an important category of deep models, deep generative model has attracted more and more attention with the proposal of Deep Belief Networks (DBNs) and the fast greedy training algorithm based on restricted Boltzmann machines (RBMs). In the past few years, many different deep generative models are proposed and used in the area of Artificial Intelligence. In this paper, three important deep generative models including DBNs, deep autoencoder, and deep Boltzmann machine are reviewed. In addition, some successful applications of deep generative models in image processing, speech recognition and information retrieval are also introduced and analysed.	[Xu, Jungang; Li, Hui; Zhou, Shilong] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China	Xu, JG (reprint author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China.	xujg@ucas.ac.cn; lihui211@mails.ucas.ac.cn; zhoushilong12@mails.ucas.ac.cn			National Natural Science Foundation of China [61372171]; National Key Technology R&D Program of China [2012BAH23B03]	This work was supported by the National Natural Science Foundation of China [grant number 61372171]; the National Key Technology R&D Program of China [grant number 2012BAH23B03].	Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1; Bengio Y, 2009, NEURAL COMPUT, V21, P1601, DOI 10.1162/neco.2008.11-07-647; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Cho K. H., 2010, P 2010 INT JOINT C N, P1; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; Deng L., 2013, DEEP LEARNING SIGNAL; Earl DJ, 2005, PHYS CHEM CHEM PHYS, V7, P3910, DOI 10.1039/b509983h; Fang W, 2012, IETE TECH REV, V29, P380, DOI 10.4103/0256-4602.103168; Freund Y, 1991, ADV NEURAL INFORM PR, V4, P912; HECHTNIELSEN R, 1995, SCIENCE, V269, P1860, DOI 10.1126/science.269.5232.1860; Hinton G, 2011, TOP COGN SCI, V3, P74, DOI 10.1111/j.1756-8765.2010.01109.x; Hinton G. E., 1995, SCIENCE, V268, P1558; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Iba Y, 2001, INT J MOD PHYS C, V12, P623, DOI 10.1142/S0129183101001912; Jordan M. I., 1998, LEARNING GRAPHICAL M; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Luo J., 2012, INT J APPL MATH STAT, V28, P59; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Neal RM, 1996, STAT COMPUT, V6, P353, DOI 10.1007/BF00143556; Plaut D. C., 1987, Computer Speech and Language, V2, DOI 10.1016/0885-2308(87)90026-X; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R., 2012, ADV NEURAL INFORM PR, V25, P1; Salakhutdinov R., 2009, THESIS U TORONTO TOR; Saul LK, 1996, J ARTIF INTELL RES, V4, P61; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2222; Tanveer A., 2013, IETE TECHNICAL REV, V30, P47; TESAURO G, 1992, MACH LEARN, V8, P257, DOI 10.1007/BF00992697; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; Werbos P., 1974, REGRESSION NEW TOOLS; Xu JG, 2014, NEUROCOMPUTING, V139, P328, DOI 10.1016/j.neucom.2014.02.024	46	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0256-4602	0974-5971		IETE TECH REV	IETE Tech. Rev.	MAR 4	2015	32	2					131	139		10.1080/02564602.2014.987328		9	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	CE5AS	WOS:000351842700007		
J	Hu, WP; Qian, Y; Soong, FK; Wang, Y				Hu, Wenping; Qian, Yao; Soong, Frank K.; Wang, Yong			Improved mispronunciation detection with deep neural network trained acoustic models and transfer learning based logistic regression classifiers	SPEECH COMMUNICATION			English	Article						Computer-aided language learning; Mispronunciation detection; Deep neural network; Logistic regression; Transfer learning	SPEECH RECOGNITION; KNOWLEDGE; ERROR	Mispronunciation detection is an important part in a Computer-Aided Language Learning (CALL) system. By automatically pointing out where mispronunciations occur in an utterance, a language learner can receive informative and to-the-point feedbacks. In this paper, we improve mispronunciation detection performance with a Deep Neural Network (DNN) trained acoustic model and transfer learning based Logistic Regression (LR) classifiers. The acoustic model trained by the conventional GMM-HMM based approach is refined by the DNN training with enhanced discrimination. The corresponding Goodness Of Pronunciation (GOP) scores are revised to evaluate pronunciation quality of non-native language learners robustly. A Neural Network (NN) based, Logistic Regression (LR) classifier, where a general neural network with shared hidden layers for extracting useful speech features is pre-trained firstly with pooled, training data in the sense of transfer learning, and then phone-dependent, 2-class logistic regression classifiers are trained as phone specific output layer nodes, is proposed to mispronunciation detection. The new LR classifier streamlines training multiple individual classifiers separately by learning the common feature representation via the shared hidden layer. Experimental results on an isolated English word corpus recorded by non-native (L2) English learners show that the proposed GOP measure can improve the performance of GOP based mispronunciation detection approach, i.e., 7.4% of the precision and recall rate are both improved, compared with the conventional GOP estimated from GMM-HMM. The NN-based LR classifier improves the equal precision recall rate by 25% over the best GOP based approach. It also outperforms the state-of-art Support Vector Machine (SVM) based classifier by 2.2% of equal precision recall rate improvement. Our approaches also achieve similar results on a continuous read, L2 Mandarin language learning corpus. (C) 2014 Elsevier B.V. All rights reserved.	[Hu, Wenping; Wang, Yong] Univ Sci & Technol China, Hefei 230026, Peoples R China; [Hu, Wenping; Qian, Yao; Soong, Frank K.] Microsoft Res Asia, Beijing 100080, Peoples R China	Qian, Y (reprint author), Microsoft Res Asia, Beijing 100080, Peoples R China.	hwping@mail.ustc.edu.cn; yaoqian@microsoft.com; frankkps@microsoft.com; yongwang@ustc.edu.cn					Bahl L., 1986, P INT C AC SPEECH SI, V11, P49, DOI DOI 10.1109/ICASSP.1986.1169179>; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bishop CM, 2006, PATTERN RECOGNITION; Chen N.F., 2013, P INTERSPEECH 2013 I, P2370; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Franco H., 1999, P EUR, V2, P851; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hirabayashi K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P598; Hu W., 2014, P ICASSP 2014 IEEE, P3230; Hu W., 2013, P INTERSPEECH 2013 I, P1886; Hu W., 2014, P ISCSLP 2014 IEEE, P245; Huang JT, 2013, INT CONF ACOUST SPEE, P7304; Ito A., 2005, P EUROSPEECH, P173; Jiang H, 2005, SPEECH COMMUN, V45, P455, DOI 10.1016/j.specrom.2004.12.004; Jie J., 2009, P ICASSP 2009 IEEE, P4833; Joachims T., 1998, 24 LS8 U DORTM; Juang B.H., 1997, IEEE T SPEECH AUDIO, V5, P266; Kim Y, 1997, P EUR, V97, P645; Pitrelli J.F., 1995, PHONEBOOK NYNEX ISOL; POVEY D, 2002, ACOUST SPEECH SIG PR, P105; Qian X., 2012, P INTERSPEECH 2012 I; Qian XJ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P757; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Seide F., 2011, P ASRU, P24; Soong F.K., 2004, P SWIM 2004; Strik H, 2009, SPEECH COMMUN, V51, P845, DOI 10.1016/j.specom.2009.05.007; Tokuda K, 2002, IEICE T INF SYST, VE85D, P455; Truong K, 2004, THESIS UTRECHT U NET; van Doremalen J, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P580, DOI 10.1109/ASRU.2009.5373335; Vanhoucke V, 2013, INT CONF ACOUST SPEE, P7582, DOI 10.1109/ICASSP.2013.6639137; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang YB, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5049; Wei S, 2009, SPEECH COMMUN, V51, P896, DOI 10.1016/j.specom.2009.03.004; Witt SM, 2000, SPEECH COMMUN, V30, P95, DOI 10.1016/S0167-6393(99)00044-8; Witt S.M., 2012, P INT S AUT DET ERR, P1; Xu S, 2009, INT CONF ACOUST SPEE, P4841; Xue J., 2013, P INTERSPEECH, P2365; Yan K., 2011, IJITCS, V3, P17; Yoon SY, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P614; Zhang F, 2008, INT CONF ACOUST SPEE, P5077	42	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	MAR	2015	67						154	166		10.1016/j.specom.2014.12.008		13	Acoustics; Computer Science, Interdisciplinary Applications	Acoustics; Computer Science	CC1HD	WOS:000350090900013		
J	McLoughlin, I; Zhang, HM; Xie, ZP; Song, Y; Xiao, W				McLoughlin, Ian; Zhang, Haomin; Xie, Zhipeng; Song, Yan; Xiao, Wei			Robust Sound Event Classification Using Deep Neural Networks	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Auditory event detection; machine hearing	AUDIO CLASSIFICATION; IMAGE FEATURE; RECOGNITION; FEATURES; MODEL; RETRIEVAL	The automatic recognition of sound events by computers is an important aspect of emerging applications such as automated surveillance, machine hearing and auditory scene understanding. Recent advances in machine learning, as well as in computational models of the human auditory system, have contributed to advances in this increasingly popular research field. Robust sound event classification, the ability to recognise sounds under real-world noisy conditions, is an especially challenging task. Classification methods translated from the speech recognition domain, using features such as mel-frequency cepstral coefficients, have been shown to perform reasonably well for the sound event classification task, although spectrogram-based or auditory image analysis techniques reportedly achieve superior performance in noise. This paper outlines a sound event classification framework that compares auditory image front end features with spectrogram image-based front end features, using support vector machine and deep neural network classifiers. Performance is evaluated on a standard robust classification task in different levels of corrupting noise, and with several system enhancements, and shown to compare very well with current state-of-the-art classification techniques.	[McLoughlin, Ian; Zhang, Haomin; Xie, Zhipeng; Song, Yan] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China; [Xiao, Wei] Huawei Technol Duesseldorf GmbH, European Res Ctr, D-80992 Munich, Germany	McLoughlin, I (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China.	ivm@ustc.edu.cn			Huawei Innovation Research Program under Machine Hearing and Perception Project [YB2012120147]; Fundamental Research Funds for the Central Universities, China [WK2100000002]; Natural Science Foundation of China (NSFC) [61172158]	This work was supported in part by the Huawei Innovation Research Program under Machine Hearing and Perception Project Contract YB2012120147, and in part by the Fundamental Research Funds for the Central Universities, China, under Grant WK2100000002. The work of Y. Song was supported by the Natural Science Foundation of China (NSFC) under Grant 61172158. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. DeLiang Wang.	Atrey PK, 2006, INT CONF ACOUST SPEE, P813; BERGEAUD F, 1995, PROC SPIE, V2569, P2, DOI 10.1117/12.217583; Bleeck S, 2004, ACTA ACUST UNITED AC, V90, P781; Cai R, 2006, IEEE T AUDIO SPEECH, V14, P1026, DOI 10.1109/TSA.2005.857575; Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Chechik G., 2008, P ACM INT C MULT INF; Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438; Dennis J, 2013, PATTERN RECOGN LETT, V34, P1085, DOI 10.1016/j.patrec.2013.02.015; Dennis J, 2013, IEEE T AUDIO SPEECH, V21, P367, DOI 10.1109/TASL.2012.2226160; Dennis J, 2011, IEEE SIGNAL PROC LET, V18, P130, DOI 10.1109/LSP.2010.2100380; Dennis J. W., 2014, THESIS NANYANG TECHN; Glasberg BR, 2002, J AUDIO ENG SOC, V50, P331; Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791; Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626; Gupta R., 2013, P INT LYON FRANC, P173; Heittola T., 2011, WORKSH MACH LIST MUL, P36; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang Z., 2014, P IEEE INT C AC SPEE, P1364; Lin CC, 2005, IEEE T SPEECH AUDI P, V13, P644, DOI 10.1109/TSA.2005.851880; Lyon R. F., 2011, P IEEE WORKSH APPL S, pviii; Lyon R. F., 2010, IEEE SIGNAL PROCESS, V42, P1414; Lyon R. F., 2010, U.S. patent appl., Patent No. [12/722,437, 12722437]; Lyon RF, 2010, NEURAL COMPUT, V22, P2390, DOI 10.1162/NECO_a_00011; Lyon RF, 2011, INT CONF ACOUST SPEE, P5876; McLoughlin I., 2009, APPL SPEECH AUDIO PR; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Moore B. C., 1986, AUDITORY FREQUENCY S; Moore B. C. J., 1992, INTRO PSYCHOL HEARIN; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Nakamura S., 1999, P EUR SEP, P2255; Palm R. B., 2012, THESIS TU DENMARK LY; PATTERSON RD, 1995, J ACOUST SOC AM, V98, P1890, DOI 10.1121/1.414456; Phan H., 2014, P 15 ANN C INT SPEEC; Plinge A., 2014, P IEEE INT C AC SPEE, P3732; Portelo J, 2009, INT CONF ACOUST SPEE, P1973, DOI 10.1109/ICASSP.2009.4959998; Schneider R, 2014, ENCYCLOP MATH APPL, V151, P1; Sidiropoulos P., 2013, LECT NOTES ELECT ENG, V158, P3; Sorin A., 2003, EXTENDED ADV FRONT A, V202, P212; Walters T. C., 2014, AIM C C IMPLEMENTATI; Walters T. C., 2011, THESIS U CAMBRIDGE C; Zhang WQ, 2011, IEEE T AUDIO SPEECH, V19, P266, DOI 10.1109/TASL.2010.2047680	43	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	MAR	2015	23	3					540	552		10.1109/TASLP.2015.2389618		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CD2AO	WOS:000350876100012		
J	Mesnil, G; Dauphin, Y; Yao, KS; Bengio, Y; Deng, L; Hakkani-Tur, D; He, XD; Heck, L; Tur, G; Yu, D; Zweig, G				Mesnil, Gregoire; Dauphin, Yann; Yao, Kaisheng; Bengio, Yoshua; Deng, Li; Hakkani-Tur, Dilek; He, Xiaodong; Heck, Larry; Tur, Gokhan; Yu, Dong; Zweig, Geoffrey			Using Recurrent Neural Networks for Slot Filling in Spoken Language Understanding	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Recurrent neural network (RNN); slot filling; spoken language understanding (SLU); word embedding	SPEECH RECOGNITION; CLASSIFICATION; ALGORITHM	Semantic slot filling is one of the most challenging problems in spoken language understanding (SLU). In this paper, we propose to use recurrent neural networks (RNNs) for this task, and present several novel architectures designed to efficiently model past and future temporal dependencies. Specifically, we implemented and compared several important RNN architectures, including Elman, Jordan, and hybrid variants. To facilitate reproducibility, we implemented these networks with the publicly available Theano neural network toolkit and completed experiments on the well-known airline travel information system (ATIS) benchmark. In addition, we compared the approaches on two custom SLU data sets from the entertainment and movies domains. Our results show that the RNN-based models outperform the conditional random field (CRF) baseline by 2% in absolute error reduction on the ATIS benchmark. We improve the state-of-the-art by 0.5% in the Entertainment domain, and 6.7% for the movies domain.	[Mesnil, Gregoire] Univ Rouen, Dept Comp Sci, F-76821 Mont St Aignan, France; [Mesnil, Gregoire] Univ Montreal, Dept Comp Sci, Montreal, PQ H3T 1J4, Canada; [Dauphin, Yann; Bengio, Yoshua] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3T 1J4, Canada; [Yao, Kaisheng; Deng, Li; He, Xiaodong; Yu, Dong; Zweig, Geoffrey] Microsoft Res, Redmond, WA 98052 USA; [Hakkani-Tur, Dilek] Microsoft Res, Mountain View, CA 94043 USA; [Tur, Gokhan] Apple, Cupertino, CA 95014 USA; [Heck, Larry] Google, Mountain View, CA 94043 USA	Mesnil, G (reprint author), Univ Rouen, Dept Comp Sci, F-76821 Mont St Aignan, France.	gregoire.mesnil@umontreal.ca			Compute Canada; Calcul Quebec	This work was supported in part by Compute Canada and Calcul Quebec. Part of this work was done while Y. Dauphin and G. Mesnil were interns at Microsoft Research. The guest editor coordinating the review of this manuscript and approving it for publication was Dr. James Glass.	Bengio Y., 2009, LEARNING DEEP ARCHIT; Bengio Y., 2000, P NIPS; Bergstra J., 2012, J MACH LEARN RES; Bergstra J., 2010, P PYTH SCI COMP C SC; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Dahl George E., 2012, IEEE T AUDIO SPEECH, V20, P33; Dauphin Y., 2013, P INT C LEARN REPR I; Deng L, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P210; Deng L., 2014, DEEP LEARNING METHOD; Deoras A., 2013, P INTERSPEECH; Elman J., 1990, COGNITIVE SCI, V14; Gao J., 2014, P EMNLP, P2; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Haffner P., 2003, P IEEE INT C AC SPEE, P632; Hakkani-Tur D, 2011, INT CONF ACOUST SPEE, P5636; He XD, 2011, IEEE SIGNAL PROC MAG, V28, P126, DOI 10.1109/MSP.2011.941852; He XD, 2013, P IEEE, V101, P1116, DOI 10.1109/JPROC.2012.2236631; He Y., 2003, P IEEE AUT SPEECH RE, P583; Heck L, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P228, DOI 10.1109/SLT.2012.6424227; Heck L., 2014, P IEEE GLOB C SIGN I; Henderson M., 2012, P IEEE SLT; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang P.-S., 2013, P ACM INT C INF KNOW; Jeong MW, 2007, INT CONF ACOUST SPEE, P141; Jordan M., 1997, 8604 U CAL I COMP SC; Kingsbury B., 2012, P INTERSPEECH; Krizhevsky A., 2012, ADV NEURAL INF PROCE, V25; Kudo T., 2001, P ACL; KUHN R, 1995, IEEE T PATTERN ANAL, V17, P449, DOI 10.1109/34.391397; Lafferty J, 2001, P ICML; Liu J., 2012, P INTERSPEECH; Macherey M., 2001, P EUR C SPEECH COMM, P2205; McCallum A., 2000, P 17 INT C MACH LEAR, P591; Mesnil G., 2011, P JMLR W CP P UNS TR, V7; Mesnil G., 2013, P INTERSPEECH; Mikolov T., 2013, P NAACL HLT; Mikolov T, 2011, INT CONF ACOUST SPEE, P5528; Mikolov T, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P234, DOI 10.1109/SLT.2012.6424228; Miller S., 1994, P ACL; Peng J., 2009, P NIPS; Pieraccini R., 1992, IEEE INT C AC SPEECH, V1, P193; Raymond C., 2007, P INTERSPEECH; Sarikaya R, 2011, INT CONF ACOUST SPEE, P5680; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Schwenk H., 2005, P HLT EMNLP; Shen Y., 2014, P CIKM; Socher R., 2012, P 2012 JOINT C EMP M, P1201; Su H, 2013, INT CONF ACOUST SPEE, P6664; Tur G., 2010, P IEEE SLT; Tur G, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5045; Tur G, 2011, INT CONF ACOUST SPEE, P5628; Tur G., 2011, SPOKEN LANGUAGE UNDE; Vesely K., 2013, P INTERSPEECH; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Wang YY, 2011, ADV MATER RES-SWITZ, V298, P35, DOI 10.4028/www.scientific.net/AMR.298.35; Wang YY, 2005, IEEE SIGNAL PROC MAG, V22, P16; Wang Y.-Y., 2006, P ICSLP; Xu P., 2013, P ASRU; Yaman S, 2008, IEEE T AUDIO SPEECH, V16, P1207, DOI 10.1109/TASL.2008.2001106; Yao K., 2014, P IEEE SLT; Yao K., 2013, P INTERSPEECH; Yao K., 2013, P NIPS DEEP LEARN WO; Yao K., 2014, P ICASSP, P4105; Yih W., 2014, P ACL; Yu D., 2014, AUTOMATIC SPEECH REC; Yu D, 2010, IEEE J-STSP, V4, P965, DOI 10.1109/JSTSP.2010.2075990; Yu M., 2013, P NAACL HLT, P563; Zue VW, 2000, P IEEE, V88, P1166, DOI 10.1109/5.880078	70	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	MAR	2015	23	3					530	539		10.1109/TASLP.2014.2383614		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CD2AO	WOS:000350876100011		
J	Nakashika, T; Takiguchi, T; Ariki, Y				Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo			Voice Conversion Using RNN Pre-Trained by Recurrent Temporal Restricted Boltzmann Machines	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep Learning; recurrent neural network; recurrent temporal restricted Boltzmann machine (RTRBM); speaker specific features; voice conversion	SPEECH RECOGNITION	This paper presents a voice conversion (VC) method that utilizes the recently proposed probabilistic models called recurrent temporal restricted Boltzmann machines (RTRBMs). One RTRBM is used for each speaker, with the goal of capturing high-order temporal dependencies in an acoustic sequence. Our algorithm starts from the separate training of one RTRBM for a source speaker and another for a target speaker using speaker-dependent training data. Because each RTRBM attempts to discover abstractions to maximally express the training data at each time step, as well as the temporal dependencies in the training data, we expect that the models represent the linguistic-related latent features in high-order spaces. In our approach, we convert (match) features of emphasis for the source speaker to those of the target speaker using a neural network (NN), so that the entire network (consisting of the two RTRBMs and the NN) acts as a deep recurrent NN and can be fine-tuned. Using VC experiments, we confirm the high performance of our method, especially in terms of objective criteria, relative to conventional VC methods such as approaches based on Gaussian mixture models and on NNs.	[Nakashika, Toru] Kobe Univ, Grad Sch Syst Informat, Kobe, Hyogo 6578501, Japan; [Takiguchi, Tetsuya; Ariki, Yasuo] Kobe Univ, Org Adv Sci & Technol, Kobe, Hyogo 6578501, Japan	Nakashika, T (reprint author), Kobe Univ, Grad Sch Syst Informat, Kobe, Hyogo 6578501, Japan.	nakashika@me.cs.scitec.kobe-u.ac.jp					Abe M., 1988, P ICASSP, P655; Boulanger-Lewandowski N., 2012, P INT C MACH LEARN; Chen L.-H., 2013, P INTERSPEECH, P3052; Cho K, 2011, LECT NOTES COMPUT SC, V6791, P10; DENG L, 2001, ACOUST SPEECH SIG PR, P301; Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Freund Y., 1994, UNSUPERVISED LEARNIN; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jian ZH, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P210; KAIN A, 1998, ACOUST SPEECH SIG PR, P285; Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Kunikoshi A., 2009, P INTERSPEECH, P308; KUREMATSU A, 1990, SPEECH COMMUN, V9, P357, DOI 10.1016/0167-6393(90)90011-W; Lee CH, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2254; Ling ZH, 2012, IEEE T AUDIO SPEECH, V20, P1492, DOI 10.1109/TASL.2011.2182511; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; Ling Z.-H., 2006, P BLIZZ CHALL WORKSH; McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778; Milner B., 2002, P ICSLP DENV CO US, P2421; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007; Nakashika T., 2014, P IEEE INT C AC SPEE, P7939; Nakashika T., 2013, P INTERSPEECH, P369; Pascanu R., 2012, ARXIV12115063; Saito D., 2011, P INTERSPEECH, P653; Saito D, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1728; Smolensky P., 1986, PARALLEL DISTRIB PRO, V1; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; Sutskever I., 2008, NIPS, V21, P2008; Takashima R, 2012, 2012 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY (SLT 2012), P313, DOI 10.1109/SLT.2012.6424242; Taylor G. W., 2006, ADV NEURAL INF PROCE, V19, P1345; Toda T, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2446; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Tomoki T., 2007, IEICE T INF SYST, V90, P816; VALBRET H, 1992, SPEECH COMMUN, V11, P175, DOI 10.1016/0167-6393(92)90012-V; Veaux C., 2011, P INTERSPEECH, P2765; Wu Y.-J., 2004, P IEEE INT C AC SPEE, P629; Wu Z., 2013, P 8 ISCA SPEECH SYNT; Wu Z.-Z, 2013, P IEEE CHIN SUMM INT, P104	42	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	MAR	2015	23	3					580	587		10.1109/TASLP.2014.2379589		8	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CD2AO	WOS:000350876100015		
J	Pao, HK; Lee, YJ; Huang, CY				Pao, Hsing-Kuo; Lee, Yuh-Jye; Huang, Chun-Ying			Rejoinder to 'Statistical learning methods for information security: fundamentals and case studies'	APPLIED STOCHASTIC MODELS IN BUSINESS AND INDUSTRY			English	Article							BIG DATA		[Pao, Hsing-Kuo; Lee, Yuh-Jye] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan; [Huang, Chun-Ying] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung, Taiwan	Pao, HK (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.	pao@mail.ntust.edu.tw; yuh-jye@mail.ntust.edu.tw; chuang@ntou.edu.tw					Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878; Bradskis G, 2008, LEARNING OPENCV COMP; Chari S, 2015, APPL STOCH MODEL BUS, V31, P116, DOI 10.1002/asmb.2103; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang CY, 2013, COMPUT NETW, V57, P514, DOI 10.1016/j.comnet.2012.07.018; Jacobs A, 2009, COMMUN ACM, V52, P36, DOI 10.1145/1536616.1536632; Lynch C, 2008, NATURE, V455, P28, DOI 10.1038/455028a; Manyikas J, 2011, BIG DATA NEXT FRONTI; Paos H-K, 2010, IEEE T COMPUTATIONAL, V2, P162; Paos H-K, 2015, APPL STOCH MODEL BUS, V31, P97, DOI [10.1002/asmb.2052, DOI 10.1002/ASMB.2052]; Ravishanker G, 2015, APPL STOCH MODEL BUS, V31, P114, DOI 10.1002/asmb.2033	11	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1524-1904	1526-4025		APPL STOCH MODEL BUS	Appl. Stoch. Models. Bus. Ind.	MAR-APR	2015	31	2			SI		119	121		10.1002/asmb.2118		3	Operations Research & Management Science; Mathematics, Interdisciplinary Applications; Statistics & Probability	Operations Research & Management Science; Mathematics	CF9DG	WOS:000352861400004		
J	Rashwan, MAA; Al Sallab, AA; Raafat, HM; Rafea, A				Rashwan, Mohsen A. A.; Al Sallab, Ahmad A.; Raafat, Hazem M.; Rafea, Ahmed			Deep Learning Framework with Confused Sub-Set Resolution Architecture for Automatic Arabic Diacritization	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Arabic diacritization; classifier design; deep networks; part-of-speech (PoS) tagging		The Arabic language belongs to a group of languages that require diacritization over their characters. Modern Standard Arabic (MSA) transcripts omit the diacritics, which are essential for many machine learning tasks like Text-To-Speech (TTS) systems. In this work Arabic diacritics restoration is tackled under a deep learning framework that includes the Confused Sub-set Resolution (CSR) method to improve the classification accuracy, in addition to an Arabic Part-of-Speech (PoS) tagging framework using deep neural nets. Special focus is given to syntactic diacritization, which still suffers low accuracy as indicated in prior works. Evaluation is done versus state-of-the-art systems reported in literature, with quite challenging datasets collected from different domains. Standard datasets like the LDC Arabic Tree Bank are used in addition to custom ones we have made available online to allow other researchers to replicate these results. Results show significant improvement of the proposed techniques over other approaches, reducing the syntactic classification error to 9.9% and morphological classification error to 3% compared to 12.7% and 3.8% of the best reported results in literature, improving the error by 22% over the best reported systems.	[Rashwan, Mohsen A. A.] Engn Co Dev Comp Syst RDI, Giza 12613, Egypt; [Rashwan, Mohsen A. A.] Cairo Univ, Fac Engn, Dept Elect & Elect Commun, Giza 00202, Egypt; [Al Sallab, Ahmad A.] Valeo Interbranch Automot Software, Giza, Egypt; [Al Sallab, Ahmad A.] Cairo Univ, Fac Engn, Dept Elect & Elect Commun, Giza 12613, Egypt; [Raafat, Hazem M.] Kuwait Univ, Dept Comp Sci, Safat 13060, Kuwait; [Rafea, Ahmed] Amer Univ Cairo, Dept Comp Sci, Cairo 11835, Egypt	Rashwan, MAA (reprint author), Engn Co Dev Comp Syst RDI, Giza 12613, Egypt.	mohsen_rashwan@rdi-eg.com; ahmad.el-sallab@valeo.com; hazem@cs.ku.edu.kw; rafea@aucegypt.edu					Habash N., 2007, P 8 M N AM CHAP ASS; Hai-Son L., 2011, P IEEE INT C AC SPEE, P5524; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Minh-Thang L., 2013, P C COMP NAT LANG LE; Raafat H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), DOI 10.1109/ICDAR.1993.395582; Rashwan M. A. A., 2009, P INT C NAT LANG PRO, P1; Rashwan MAA, 2011, IEEE T AUDIO SPEECH, V19, P166, DOI 10.1109/TASL.2010.2045240; Salakhutdinov R., 2009, THESIS U TORONTO TOR; Zitouni I., 2006, P 21 INT C COMP LING	9	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	MAR	2015	23	3					505	516		10.1109/TASLP.2015.2395255		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CD2AO	WOS:000350876100009		
J	Zhao, L; Gao, XB; Tao, DC; Li, XL				Zhao, Lin; Gao, Xinbo; Tao, Dacheng; Li, Xuelong			A deep structure for human pose estimation	SIGNAL PROCESSING			English	Article						Pose estimation; Human detection; Articulated shapes; Deformable part models	PICTORIAL STRUCTURES; FLEXIBLE MIXTURES; FEATURE-SELECTION; TREE MODELS; PARTS; RECOGNITION; CONSTRAINTS; RETRIEVAL	Articulated human pose estimation in unconstrained conditions is a great challenge. We propose a deep structure that represents a human body in different granularity from coarse-to-fine for better detecting parts and describing spatial constrains between different parts. Typical approaches for this problem just utilize a single level structure, which is difficult to capture various body appearances and hard to model high-order part dependencies. In this paper, we build a three layer Markov network to model the body structure that separates the whole body to poselets (combined parts) then to parts representing joints. Parts at different levels are connected through a parent-child relationship to represent high-order spatial relationships. Unlike other multi-layer models, our approach explores more reasonable granularity for part detection and sophisticatedly designs part connections to model body configurations more effectively. Moreover, each part in our model contains different types so as to capture a wide range of pose modes. And our model is a tree structure, which can be trained jointly and favors exact inference. Extensive experimental results on two challenging datasets show the performance of our model improving or being on-par with state-of-the-art approaches. (C) 2014 Elsevier B.V. All rights reserved.	[Zhao, Lin; Gao, Xinbo] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China; [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China	Gao, XB (reprint author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.	xbgao@mail.xidian.edu.cn			National Natural Science Foundation of China [61125204, 61432014, 61172146]; Fundamental Research Funds for the Central Universities [K5051202048, BDZ021403, JB149901]; Program for Changjiang Scholars and Innovative Research Team in University of China [IRT13088]; Shaanxi Innovative Research Team for Key Science and Technology [2012KCT-02]	We want to thank the helpful comments and suggestions from the anonymous reviewers. This research was supported partially by the National Natural Science Foundation of China (Grant Nos. 61125204, 61432014, and 61172146), the Fundamental Research Funds for the Central Universities (Grant Nos. K5051202048, BDZ021403 and JB149901), the Program for Changjiang Scholars and Innovative Research Team in University of China (No. IRT13088) and the Shaanxi Innovative Research Team for Key Science and Technology (No. 2012KCT-02).	Andriluka M, 2009, PROC CVPR IEEE, P1014; Andriluka M, 2012, INT J COMPUT VISION, V99, P259, DOI 10.1007/s11263-011-0498-z; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Duan K., 2012, BR MACH VIS C; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; Eichner M., 2013, LNCS, V7724, P138; Elguebaly T, 2013, SIGNAL PROCESS, V93, P1531, DOI 10.1016/j.sigpro.2012.07.037; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V., 2008, IEEE C COMP VIS PATT, P1; Ferrari V., BUFFY STICKMEN V3 0; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hogg D, 1983, COMPUT VIS GRAPH IMA, V1, P5; Hong CQ, 2013, IEEE SYS MAN CYBERN, P2103, DOI 10.1109/SMC.2013.360; Jiang H., 2008, IEEE C COMP VIS PATT, P1, DOI 10.1109/GLOCOM.2008.ECP.929; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Ju S. X., 1996, INT C AUT FAC GEST R, P38; Liu L, 2013, SIGNAL PROCESS, V93, P1521, DOI 10.1016/j.sigpro.2012.07.017; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522; Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82; Pishchulin L., 2013, INT C COMP VIS, P3487; Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052; Ramanan D., 2006, P 20 ANN C NEUR INF, V19, P1129; Ren XF, 2005, IEEE I CONF COMP VIS, P824; Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30; Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607; Sapp B, 2010, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2010.5540182; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Sigal L., 2011, HUMAN POSE ESTIMATIO; Sun M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P723; Tian TP, 2010, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2010.5540227; Tian YD, 2012, LECT NOTES COMPUT SC, V7576, P256; Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17; Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83; Wang Y, 2008, LECT NOTES COMPUT SC, V5304, P710; Wang Y, 2011, PROC CVPR IEEE, P1705; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2011, PROC CVPR IEEE, P1385; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395	42	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684	1879-2677		SIGNAL PROCESS	Signal Process.	MAR	2015	108						36	45		10.1016/j.sigpro.2014.07.031		10	Engineering, Electrical & Electronic	Engineering	AW8XI	WOS:000346542300005		
J	Nakashika, T; Takiguchi, T; Ariki, Y				Nakashika, Toru; Takiguchi, Tetsuya; Ariki, Yasuo			Voice conversion using speaker-dependent conditional restricted Boltzmann machine	EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING			English	Article						Voice conversion; Conditional restricted Boltzmann machine; Deep learning; Recurrent neural network; Speaker-specific features	SPEECH RECOGNITION; LEARNING ALGORITHM; NEURAL-NETWORKS; TRANSFORMATION	This paper presents a voice conversion (VC) method that utilizes conditional restricted Boltzmann machines (CRBMs) for each speaker to obtain high-order speaker-independent spaces where voice features are converted more easily than those in an original acoustic feature space. The CRBM is expected to automatically discover common features lurking in time-series data. When we train two CRBMs for a source and target speaker independently using only speaker-dependent training data, it can be considered that each CRBM tries to construct subspaces where there are fewer phonemes and relatively more speaker individuality than the original acoustic space because the training data include various phonemes while keeping the speaker individuality unchanged. Each obtained high-order feature is then concatenated using a neural network (NN) from the source to the target. The entire network (the two CRBMs and the NN) can be also fine-tuned as a recurrent neural network (RNN) using the acoustic parallel data since both the CRBMs and the concatenating NN have network-based representation with time dependencies. Through voice-conversion experiments, we confirmed the high performance of our method especially in terms of objective evaluation, comparing it with conventional GMM, NN, RNN, and our previous work, speaker-dependent DBN approaches.	[Nakashika, Toru] Kobe Univ, Grad Sch Syst Informat, Nada Ku, Kobe, Hyogo 6578501, Japan; [Takiguchi, Tetsuya; Ariki, Yasuo] Kobe Univ, Org Adv Sci & Technol, Nada Ku, Kobe, Hyogo 6578501, Japan	Nakashika, T (reprint author), Kobe Univ, Grad Sch Syst Informat, Nada Ku, 1-1 Rokkodai, Kobe, Hyogo 6578501, Japan.	nakashika@me.cs.scitec.kobe-u.ac.jp					ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; CHO K, 2011, RTIFICIAL NEURAL NET, V6791, P10; DENG L, 2001, P ICASSP, P301; DESAI S, 2009, P ICASSP, P3893; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Freund Y, 1991, ADV NEURAL INFORM PR, V4, P912; Gray R., 1984, ASSP MAG, V1, P4; Helander E, 2010, IEEE T AUDIO SPEECH, V18, P912, DOI 10.1109/TASL.2010.2041699; Hinton G, 2010, TECH REP DEP COMPUTE; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jian ZH, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P210; Kain A, 1998, INT CONF ACOUST SPEE, P285, DOI 10.1109/ICASSP.1998.674423; KAWAHARA H, 2008, P ICASSP, P3933; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Kunikoshi A., 2009, P INTERSPEECH, P308; KUREMATSU A, 1990, SPEECH COMMUN, V9, P357, DOI 10.1016/0167-6393(90)90011-W; LEE CH, 2006, P INT 2006 ICSLP SEP, P2254; Ling ZH, 2012, IEEE T AUDIO SPEECH, V20, P1492, DOI 10.1109/TASL.2011.2182511; Ling Z-H, 2006, BLIZZ CHALL WORKSH U; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; Ling-Hui C, 2013, P INTERSPEECH, P3052; McDermott E, 2007, IEEE T AUDIO SPEECH, V15, P203, DOI 10.1109/TASL.2006.876778; Milner B., 2002, P ICSLP DENV CO US, P2421; Mohamed A-R, 2012, AUDIO SPEECH LANGUAG, V20, P14; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007; Nakashika T., 2013, P INTERSPEECH, P369; NARENDRANATH M, 1995, SPEECH COMMUN, V16, P207, DOI 10.1016/0167-6393(94)00058-I; Pascanu R, 2012, DIFFICULTY TRAINING; Saito D., 2011, P INTERSPEECH, P653; SAITO D, 2010, P INTERSPEECH, P1728; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; TAKASHIMA R, 2012, IEEE SPOK LANG TECHN, P313; Taylor GW, 2006, ADV NEURAL INFORM PR, P1345; TODA T, 2006, P ICSLP SEPT, P2446; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Tomoki T., 2007, IEICE T INF SYST, V90, P816; VALBRET H, 1992, SPEECH COMMUN, V11, P175, DOI 10.1016/0167-6393(92)90012-V; Veaux C., 2011, P INTERSPEECH, P2765; Wu Y.-J., 2004, P IEEE INT C AC SPEE, P629; Wu Z, 2013, P 8 ISCA SPEECH SYNT, P221; Wu Z, 2013, P IEEE CHIN SUMM INT	44	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	1687-4722			EURASIP J AUDIO SPEE	EURASIP J. Audio Speech Music Process.	FEB 25	2015									8	10.1186/s13636-014-0044-3		12	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	CC9GR	WOS:000350676900001		
J	Maniak, T; Jayne, C; Iqbal, R; Doctor, F				Maniak, Tomasz; Jayne, Chrisina; Iqbal, Rahat; Doctor, Faiyaz			Automated intelligent system for sound signalling device quality assurance	INFORMATION SCIENCES			English	Article						Non-speech sound recognition; Audio signal processing; Artificial neural networks; Auto-encoder; Manufacturing; Automation	DEEP NEURAL-NETWORKS	This paper presents a novel approach to the detection and recognition of faulty audio signalling devices as part of an automated industrial manufacturing quality assurance process. The proposed system outperforms other well-established automated systems based on mel-frequency cepstrum coefficients (MFCC) and multi-layer perceptron (MLP). It uses both unlabelled sound data and labelled historical data acquired from human experts in detecting faulty signalling devices. The unlabelled data is used to train a deep neural network generative model to create multiple levels of hierarchical feature extractors which are used to train an MLP classifier, with the intent to model the human reasoning and judging processes in respect to sound classification. This paper presents the results of real world experiments based on data pertaining to the audio signalling quality assurance process for car instrument cluster manufacturing. These results show that the proposed system is able to successfully classify speakers into two groups: "Good" and "No good" depending on the part quality. The proposed system proves to be capable enough to eliminate the need for a manual inspection within the manufacturing process and is shown to be able to diagnose a fault with a high degree of accuracy. This work can be extended to other areas of automotive inspection where there is a need for a robust solution to sound detection and where an output signal is represented by a complex and changing frequency spectrum even with significant environmental noise. (C) 2014 Elsevier Inc. All rights reserved.	[Maniak, Tomasz] UK NSI Co Ltd, Nippon Seiki, Engn & Qual Dept, Redditch B98 9HL, Worcs, England; [Jayne, Chrisina; Iqbal, Rahat; Doctor, Faiyaz] Coventry Univ, Fac Engn & Comp, Coventry CV1 5FB, W Midlands, England	Maniak, T (reprint author), UK NSI, Res, Merse Rd,North Moons Moat, Redditch B98 9HL, England.	maniakt@uni.coventry.ac.uk; chrisinajayne@coventry.ac.uk; r.iqbal@coventry.ac.uk; fayaz.doctor@coventry.ac.uk					Atrey P.K., 2006, AC SPEECH SIGN PROC, V5, pV; AYRES RU, 1994, J ECON BEHAV ORGAN, V24, P35, DOI 10.1016/0167-2681(94)90053-1; Bengio Y., 2006, NIPS, P153; Chor B., 1985, P 26 IEEE S FDN COMP, P396; Ciresan D.C., 2013, IDSIA0513; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Gandhi S., 2013, ENG NUICONE 2013 NIR, P1; Glorot X., 2010, P AISTATS, P249; Goodfellow I., 2013, ADV NEURAL INFORM PR, V26, P548; Hamming R. W., 1989, DIGITAL FILTERS; Hawkins J., 2008, SOL STAT CIRC C 2008, P38; Hermansky H., 2000, ACOUST SPEECH SIG PR, P1635; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G.E., 2012, LECT NOTES COMPUTER, V7700, P599; Houghton Mifflin, 1992, AM HERITAGE DICT ENG; Jesorsky P., 1978, AC SPEECH SIGN PROC, V3, P279; Karbasi M., 2011, INF COMM SIGN PROC I, P1; Karjalainen M., 1984, AC SPEECH SIGN PROC, V9, P132; Kinderman R., 1980, MARKOV RANDOM FIELDS; Landis RJ, 1977, BIOMETRICS, V33, P159, DOI DOI 10.2307/2529310; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Maniak T, 2013, IEEE SYS MAN CYBERN, P4812, DOI 10.1109/SMC.2013.819; Masci J., 2013, ICIP, P2713; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; Neal R., 1993, CRGTR931 U TOR DEP C; Niebles J.C., 2007, COMP VIS PATT REC 20, P17; Nishimura K., 2013, SIGN INF PROC ASS AN, P1; Rabiner L.R., 1996, AUTOMATIC SPEECH SPE, P1; Sainath TN, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4153; Sampan S., 1997, THESIS VIRGINIA POLY; Sheikhzadeh H, 1999, COMPUT SPEECH LANG, V13, P39, DOI 10.1006/csla.1998.0049; Sullivan T.M., 1996, THESIS CARNEGIE MELL; VINYALS O, 2011, AC SPEECH SIGNAL PRO, P4596; Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946; Zeiler M.D., 2013, CORR	40	0	0	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255	1872-6291		INFORM SCIENCES	Inf. Sci.	FEB 10	2015	294						600	611		10.1016/j.ins.2014.09.042		12	Computer Science, Information Systems	Computer Science	AW8XN	WOS:000346542800043		
J	Montalto, A; Tessitore, G; Prevete, R				Montalto, Alessandro; Tessitore, Giovanni; Prevete, Roberto			A linear approach for sparse coding by a two-layer neural network	NEUROCOMPUTING			English	Article						Neural networks; Sparse coding; Linear approach; Encoder-decoder	ALGORITHM	Many approaches to transform classification problems from non-linear to linear by feature transformation have been recently presented in the literature. These notably include sparse coding methods and deep neural networks. However, many of these approaches require the repeated application of a learning process upon the presentation of unseen data input vectors, or else involve the use of large numbers of parameters and hyper-parameters, which must be chosen through cross-validation, thus increasing running time dramatically. In this paper, we propose and experimentally investigate a new approach for the purpose of overcoming limitations of both kinds. The proposed approach makes use of a linear auto-associative network (called SCNN) with just one hidden layer. The combination of this architecture with a specific error function to be minimized enables one to learn a linear encoder computing a sparse code which turns out to be as similar as possible to the sparse coding that one obtains by re-training the neural network. Importantly, the linearity of SCNN and the choice of the error function allow one to achieve reduced running time in the learning phase. The proposed architecture is evaluated on the basis of two standard machine learning tasks. Its performances are compared with those of recently proposed non-linear auto-associative neural networks. The overall results suggest that linear encoders can be profitably used to obtain sparse data representations in the context of machine learning problems, provided that an appropriate error function is used during the learning phase. (c) 2014 Elsevier B.V. All rights reserved.	[Montalto, Alessandro] Univ Ghent, Data Anal Dept, Ghent, Belgium; [Tessitore, Giovanni] Univ Naples Federico II, Dept Phys Sci, Naples, Italy; [Prevete, Roberto] Univ Naples Federico II, DIETI, Naples, Italy	Prevete, R (reprint author), Univ Naples Federico II, DIETI, Naples, Italy.	rprevete@unina.it					Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Basso C, 2011, LECT NOTES COMPUT SC, V6791, P379, DOI 10.1007/978-3-642-21735-7_47; Basso C., PADDLE PROXIMAL ALGO; Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bishop C.M., 1995, NEURAL NETWORKS PATT; Cardoso A, 2013, NEUROCOMPUTING, V99, P575, DOI 10.1016/j.neucom.2012.07.027; Coates A., 2011, J MACHINE LEARNING R, V15, P215; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Dauphin Y., BIG NEURAL NETWORKS; Hastie T., 2003, ELEMENTS STAT LEARNI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kavukcuoglu K., FAST INFERENCE SPARS; Larochelle H, 2009, J MACH LEARN RES, V10, P1; LeCon Y., 1998, P IEEE, V86, P2278; LeCun Y., 1995, NEURAL NETW STAT MEC, V261, P276; Mairal J, 2010, J MACH LEARN RES, V11, P19; Martin D., 2001, P 8 INT C COMP VIS, V2, P416, DOI 10.1109/ICCV.2001.937655; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2007, COMP VIS PATT REC IE, V5, P1; Reim M., 2007, J COMPUT NEUROSCI, V22, P135; Sivaram GSVS, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2270; Wong Y., ABS13031624 CORR; Yu Kai, 2009, NIPS, V9, P1; Zeng XH, 2010, NEUROCOMPUTING, V73, P684, DOI 10.1016/j.neucom.2008.11.033	29	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	FEB 3	2015	149		C				1315	1323		10.1016/j.neucom.2014.08.066		9	Computer Science, Artificial Intelligence	Computer Science	CK3GR	WOS:000356105100019		
J	Bu, SH; Han, PC; Liu, ZB; Han, JW; Lin, HW				Bu, Shuhui; Han, Pengcheng; Liu, Zhenbao; Han, Junwei; Lin, Hongwei			Local deep feature learning framework for 3D shape	COMPUTERS & GRAPHICS-UK			English	Article						Bag-of-words; Deep learning; Shape correspondence; Shape symmetry detection; Shape recognition; Local deep feature	OBJECT RETRIEVAL; MODELS; DESCRIPTORS; RECOGNITION	For 3D shape analysis, an effective and efficient feature is the key to popularize its applications in 3D domain. In this paper, we present a novel framework to learn and extract local deep feature (LDF), which encodes multiple low-level descriptors and provides high-discriminative representation of local region on 3D shape. The framework consists of four main steps. First, several basic descriptors are calculated and encapsulated to generate geometric bag-of-words in order to make full use of the various basic descriptors' properties. Then 3D mesh is down-sampled to hundreds of feature points for accelerating the model learning. Next, in order to preserve the local geometric information and establish the relationships among points in a local area, the geometric bag-of-words are encoded into local geodesic-aware bag-of-features (LGA-BoF). However, the resulting feature is redundant, which leads to low discriminative and efficiency. Therefore, in the final step, we use deep belief networks (DBNs) to learn a model, and use it to generate the LDF, which is high-discriminative and effective for 3D shape applications. 3D shape correspondence and symmetry detection experiments compared with related feature descriptors are carried out on several datasets and shape recognition is also conducted, validating the proposed local deep feature learning framework. (C) 2014 Elsevier Ltd. All rights reserved.	[Bu, Shuhui; Han, Pengcheng; Liu, Zhenbao; Han, Junwei] Northwestern Polytech Univ, Xian, Peoples R China; [Lin, Hongwei] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China	Liu, ZB (reprint author), Northwestern Polytech Univ, Xian, Peoples R China.	liuzhenbao@nwpu.edu.cn			National Natural Science Foundation of China [61202185, 61003137, 91120005, 61473231]; Fundamental Research Funds for the Central Universities [310201401-(JCQ01009), 310201401-(JCQ01012)]; Shaanxi Natural Science Fund [2012JQ8037]; Open Project Program of the State Key Lab of CAD&CG Zhejiang University [A1306]	This work is partly supported by grants from National Natural Science Foundation of China (Nos. 61202185, 61003137, 91120005, 61473231), the Fundamental Research Funds for the Central Universities (No. 310201401-(JCQ01009,JCQ01012)), Shaanxi Natural Science Fund (No. 2012JQ8037), Open Project Program of the State Key Lab of CAD&CG (A1306) Zhejiang University.	Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Barra V, 2013, EUR WORKSH 3D OBJ RE, P25; Ben-Chen M., 2008, EUR WORKSH 3D OBJ RE, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bimbo A. D., 2006, ACM T MULTIM COMPUT, V2, P20, DOI 10.1145/1126004.1126006; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; BRONSTEIN A.M., 2011, TOG, V30, P1; Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838; Bu SH, 2014, VISUAL COMPUT, V30, P867, DOI 10.1007/s00371-014-0970-1; Castellani U, 2011, IEEE T PATTERN ANAL, V33, P2555, DOI 10.1109/TPAMI.2011.85; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; de Amorim RC, 2012, PATTERN RECOGN, V45, P1061, DOI 10.1016/j.patcog.2011.08.012; Dubrovina A, 2010, P S 3D DAT PROC, V2; Freund Y., 1994, UNSUPERVISED LEARNIN; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Giorgi D, 2007, TECHNICAL REPORT; Heider P, 2011, P 4 EUR C 3D OBJ RET, P49; Hilaga M, 2001, COMP GRAPH, P203; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hu JX, 2009, VISUAL COMPUT, V25, P667, DOI 10.1007/s00371-009-0340-6; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839; Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142; Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974; Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43; Kokkinos I, 2012, PROC CVPR IEEE, P159, DOI 10.1109/CVPR.2012.6247671; Kovnatsky A., 2012, P EUR C 3D OBJ RETR, P39; Laga H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516975; Laga H, 2010, P 3 EUR C 3D OBJ RET, P15; Lavoue G, 2011, EUR WORKSH 3D OBJ RE; Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lian Z., 2012, PATTERN RECOGN, V46, P449; Litman R, 2014, IEEE T PATTERN ANAL, V36, P171, DOI 10.1109/TPAMI.2013.148; Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9; Lopez-Sastre RJ, 2013, COMPUT GRAPH-UK, V37, P473, DOI 10.1016/j.cag.2013.04.003; Mykhalchuk V, 2013, COMPUT GRAPH-UK, V37, P539, DOI 10.1016/j.cag.2013.04.005; Osada R., 2001, SHAPE MODELING INT, P154; Ovsjanikov M., 2009, IEEE 12 INT C COMP V, P320; Peyre G, 2006, INT J COMPUT VISION, V69, P145, DOI 10.1007/s11263-006-6859-3; Sfikas K, 2012, VISUAL COMPUT, V28, P943, DOI 10.1007/s00371-012-0714-z; Shapira L, 2010, INT J COMPUT VISION, V89, P309, DOI 10.1007/s11263-009-0279-0; Shen Y-T, 2003, EUROGRAPHICS, P1; Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8; Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628; Sipiran I, 2013, COMPUT GRAPH-UK, V37, P460, DOI 10.1016/j.cag.2013.04.002; Smolensky P, INFORM PROCESSING DY; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383; Tabia H, 2013, EUR WORKSH 3D OBJ RE; Tang S, ABS12022368 CORR; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Tevs A, 2011, COMPUT GRAPH FORUM, V30, P543, DOI 10.1111/j.1467-8659.2011.01879.x; Wu HY, 2010, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2010.5540180	55	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0097-8493	1873-7684		COMPUT GRAPH-UK	Comput. Graph.-UK	FEB	2015	46				SI		117	129		10.1016/j.cag.2014.09.007		13	Computer Science, Software Engineering	Computer Science	CA2OZ	WOS:000348748700014		
J	Deng, CW; Huang, GB; Xu, J; Tang, JX				Deng ChenWei; Huang GuangBin; Xu Jia; Tang JieXiong			Extreme learning machines: new trends and applications	SCIENCE CHINA-INFORMATION SCIENCES			English	Review						extreme learning machine; fast learning; high-speed and real-time signal processing; large-scale computing; big-data; feature representation	IMAGE QUALITY ASSESSMENT; NONNEGATIVE MATRIX FACTORIZATION; FEEDFORWARD NETWORKS; NEURAL-NETWORKS; ALGORITHM; APPROXIMATION; CLASSIFICATION; REGRESSION; FEATURES	Extreme learning machine (ELM), as a new learning framework, draws increasing attractions in the areas of large-scale computing, high-speed signal processing, artificial intelligence, and so on. ELM aims to break the barriers between the conventional artificial learning techniques and biological learning mechanism and represents a suite of machine learning techniques in which hidden neurons need not to be tuned. ELM theories and algorithms argue that "random hidden neurons" capture the essence of some brain learning mechanisms as well as the intuitive sense that the efficiency of brain learning need not rely on computing power of neurons. Thus, compared with traditional neural networks and support vector machine, ELM offers significant advantages such as fast learning speed, ease of implementation, and minimal human intervention. Due to its remarkable generalization performance and implementation efficiency, ELM has been applied in various applications. In this paper, we first provide an overview of newly derived ELM theories and approaches. On the other hand, with the ongoing development of multilayer feature representation, some new trends on ELM-based hierarchical learning are discussed. Moreover, we also present several interesting ELM applications to showcase the practical advances on this subject.	[Deng ChenWei; Xu Jia; Tang JieXiong] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China; [Huang GuangBin] Nanyang Technol Univ, Sch Elect Engn, Singapore 639798, Singapore	Huang, GB (reprint author), Nanyang Technol Univ, Sch Elect Engn, Singapore 639798, Singapore.	egbhuang@ntu.edu.sg			National Natural Science Foundation of China [61301090]	This work was supported by National Natural Science Foundation of China (Grant No. 61301090).	An L, 2012, IEEE IMAGE PROC, P2209; ANDERSON W. N., 1985, LINEAR MULTILINEAR A, V18, P141, DOI 10.1080/03081088508817681; Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bi F, 2010, ADV NEURAL NETWORK R, P729; Bouzerdoum A, 2004, Proceedings of the Fourth IEEE International Symposium on Signal Processing and Information Technology, P330, DOI 10.1109/ISSPIT.2004.1433751; Buffalo EA, 2010, P NATL ACAD SCI USA, V107, P361, DOI 10.1073/pnas.0907658106; Carrai P, 2002, P IEEE INT S CIRC SY; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Decherchi S, 2013, NEUROCOMPUTING, V102, P78, DOI 10.1016/j.neucom.2011.12.050; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hassoun M H, 1995, FUNDAMENTALS ARTIFIC, P35; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOERL AE, 1970, TECHNOMETRICS, V12, P55; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Huang G, 2014, IEEE T SY B IN PRESS; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2004, IEEE IJCNN, P985; Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009; Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2; Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604; Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008; Kasun LLC, 2013, IEEE INTELL SYST, V28, P31; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; Li K, 2005, IEEE T AUTOMAT CONTR, V50, P1211, DOI 10.1109/TAC.2005.852557; Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382; Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583; Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935; Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343; Minhas R, 2010, NEUROCOMPUTING, V73, P1906, DOI 10.1016/j.neucom.2010.01.020; MOTTER BC, 1993, J NEUROPHYSIOL, V70, P909; Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391; Narwaria M, 2012, PATTERN RECOGN, V45, P299, DOI 10.1016/j.patcog.2011.06.023; Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Suresh S, 2009, APPL SOFT COMPUT, V9, P541, DOI 10.1016/j.asoc.2008.07.005; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; TANABE K, 1971, NUMER MATH, V17, P203, DOI 10.1007/BF01436376; Tang J, 2014, P IEEE INT IN PRESS; Tang J, 2014, IEEE T NEUR IN PRESS; Tang J, 2014, IEEE T GEOS IN PRESS; van Gestel T, 2002, LEAST SQUARES SUPPOR; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Wang S, 2013, P IEEE CHIN SUMM INT, P255; Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; White H, 1992, ARTIFICIAL NEURAL NE, P30; Wilamowski BM, 2010, IEEE T NEURAL NETWOR, V21, P1793, DOI 10.1109/TNN.2010.2073482; Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhu CR, 2010, IEEE T GEOSCI REMOTE, V48, P3446, DOI 10.1109/TGRS.2010.2046330; Zhu JY, 2012, IEEE T IMAGE PROCESS, V21, P919, DOI 10.1109/TIP.2011.2169971	60	0	0	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1674-733X	1869-1919		SCI CHINA INFORM SCI	Sci. China-Inf. Sci.	FEB	2015	58	2							020301	10.1007/s11432-014-5269-3		16	Computer Science, Information Systems	Computer Science	CC7FV	WOS:000350534000001		
J	Kang, TG; Kwon, K; Shin, JW; Kim, NS				Kang, Tae Gyoon; Kwon, Kisoo; Shin, Jong Won; Kim, Nam Soo			NMF-based Target Source Separation Using Deep Neural Network	IEEE SIGNAL PROCESSING LETTERS			English	Article						Deep neural network; dictionary learning; non-negative matrix factorization; speech enhancement; target source separation		Non-negative matrix factorization (NMF) is one of the most well-known techniques that are applied to separate a desired source from mixture data. In the NMF framework, a collection of data is factorized into a basis matrix and an encoding matrix. The basis matrix for mixture data is usually constructed by augmenting the basis matrices for independent sources. However, target source separation with the concatenated basis matrix turns out to be problematic if there exists some overlap between the subspaces that the bases for the individual sources span. In this letter, we propose a novel approach to improve encoding vector estimation for target signal extraction. Estimating encoding vectors from the mixture data is viewed as a regression problem and a deep neural network (DNN) is used to learn the mapping between the mixture data and the corresponding encoding vectors. To demonstrate the performance of the proposed algorithm, experiments were conducted in the speech enhancement task. The experimental results show that the proposed algorithm outperforms the conventional encoding vector estimation scheme.	[Kang, Tae Gyoon; Kwon, Kisoo; Kim, Nam Soo] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea; [Kang, Tae Gyoon; Kwon, Kisoo; Kim, Nam Soo] Seoul Natl Univ, Inst New Media & Commun, Seoul, South Korea; [Shin, Jong Won] Gwangju Inst Sci & Technol, Sch Informat & Commun, Kwangju, South Korea	Kang, TG (reprint author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.	tgkang@hi.snu.ac.kr; kskwon@hi.snu.ac.kr; jwshin@gist.ac.kr; nkim@snu.ac.kr			National Research Foundation of Korea (NRF) - Korea government (MEST) [2012R1A2A2A01045874]; MSIP (Ministry of Science, ICT and Future Planning), Korea, under the ITRC (Information Technology Research Center) support program [NIPA-2014-H0301-14-1019]	This work was supported by the National Research Foundation of Korea (NRF) funded by the Korea government (MEST) under Grant 2012R1A2A2A01045874, and by the MSIP (Ministry of Science, ICT and Future Planning), Korea, under the ITRC (Information Technology Research Center) support program (NIPA-2014-H0301-14-1019) supervised by the NIPA (National IT Industry Promotion Agency). (NIPA-2014-H0301-14-1019) supervised by the NIPA (National IT Industry Promotion Agency). The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Emanuel A. P. Habets.	Cabras G., 2010, P SOUND MUS COMP C B, P314; Choi S., 2008, P IEEE INT JOINT C N; DU J, 2008, P INTERSPEECH, P569; Grais E. M., 2014, P IEEE INT C AC SPEE, P3762; Grais E. M., 2011, INT C DIG SIGN PROC, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoyer PO, 2000, NETWORK-COMP NEURAL, V11, P191, DOI 10.1088/0954-898X/11/3/302; Huang P.-S., 2014, P IEEE INT C AC SPEE, P1581; ITU, 2000, PERC EV SPEECH QUAL; ITU, 2012, TEST SIGN US TEL; Jin Y. G., 2010, IEICE T INF SYST, VE93-D, P922; Mairal J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Palm R. B., 2012, PREDICTION CANDIDATE; Qian Y., 2014, P IEEE INT C AC SPEE, P3857; Ramanath R, 2003, P 32 APPL IM PATT RE, P33; Salakhutdinov R., 2007, P ADV NEUR INF PROC, V20, P1; Schnass K, 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, DOI 10.1109/ICASSP.2010.5495208; Seung H. S., 2000, P NEURAL INFORMATION, V13, P556; Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005; Wang C., 2011, P INF THEOR APPL WOR, P1; Wang Z., 2014, P IEEE INT C AC SPEE, P3777; Weninger F., 2011, P CHIME WORKSH FLOR, P24; Wilson KW, 2008, INT CONF ACOUST SPEE, P4029, DOI 10.1109/ICASSP.2008.4518538	26	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9908	1558-2361		IEEE SIGNAL PROC LET	IEEE Signal Process. Lett.	FEB	2015	22	2					229	233		10.1109/LSP.2014.2354456		5	Engineering, Electrical & Electronic	Engineering	CB0EE	WOS:000349297400005		
J	Langkvist, M; Loutfi, A				Langkvist, Martin; Loutfi, Amy			Learning Feature Representations with a Cost-Relevant Sparse Autoencoder	INTERNATIONAL JOURNAL OF NEURAL SYSTEMS			English	Article						Sparse autoencoder; unsupervised feature learning; weighted cost function	NEURAL-NETWORKS; ALGORITHM; NOISE	There is an increasing interest in the machine learning community to automatically learn feature representations directly from the (unlabeled) data instead of using hand-designed features. The autoencoder is one method that can be used for this purpose. However, for data sets with a high degree of noise, a large amount of the representational capacity in the autoencoder is used to minimize the reconstruction error for these noisy inputs. This paper proposes a method that improves the feature learning process by focusing on the task relevant information in the data. This selective attention is achieved by weighting the reconstruction error and reducing the influence of noisy inputs during the learning process. The proposed model is trained on a number of publicly available image data sets and the test error rate is compared to a standard sparse autoencoder and other methods, such as the denoising autoencoder and contractive autoencoder.	[Langkvist, Martin; Loutfi, Amy] Univ Orebro, Sch Sci & Technol Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden	Loutfi, A (reprint author), Univ Orebro, Sch Sci & Technol Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden.	martin.langkvist@oru.se; amy.loutfi@oru.se					Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, DOI 10.1007/978-3-642-35289-8_26; Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bergstra J, 2013, P 30 INT C MACH LEAR, V28, P115; Elkan C, 2001, P 17 INT JOINT C ART, V17, P973; Erhan D, 2010, J MACH LEARN RES, V11, P625; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HOLMSTROM L, 1992, IEEE T NEURAL NETWOR, V3, P24, DOI 10.1109/72.105415; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kukar M, 1998, ECAI 1998: 13TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P445; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; LeCun Y., 2004, P CVPR 04, P907; Lee H., 2008, ADV NEURAL INFORM PR, V20, P873; MATSUOKA K, 1992, IEEE T SYST MAN CYB, V22, P436, DOI 10.1109/21.155944; Nair V., 2010, P 27 INT C MACH LEAR, P807; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Plaut D. C., 1986, TECHNICAL REPORT; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137; Rifai S., P 29 INT C MACH LEAR, P833; Sohn K., 2013, P 30 INT C MACH LEAR, P217; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tarr G. L., 1991, TECHNICAL REPORT; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang XG, 2004, NEUROCOMPUTING, V57, P477, DOI 10.1016/j.neucom.2003.12.006	31	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657	1793-6462		INT J NEURAL SYST	Int. J. Neural Syst.	FEB	2015	25	1							1450034	10.1142/S0129065714500348		11	Computer Science, Artificial Intelligence	Computer Science	AZ0XO	WOS:000347965500005	25515941	
J	Wang, Y; Yang, JA; Lu, J; Liu, H; Wang, LW				Wang, Yi; Yang, Jun-an; Lu, Jun; Liu, Hui; Wang, Lun-wu			Hierarchical deep belief networks based point process model for keywords spotting in continuous speech	INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS			English	Article						keyword spotting; point process model; deep belief network; hierarchical deep belief network	HIDDEN MARKOV-MODELS; TEMPORAL PATTERNS; RECOGNITION	Point process model keyword spotting (KWS) system has attracted considerable attentions in the areas of keyword spotting by its capacity that can generalize from a relatively small numbers of training examples. But unfortunately, the accuracy level of the point process model is not comparable with the state-of-the-art KWS systems because of the poor modeling capacity of the phoneme detector, which are based on Gaussian Mixture Models. In this paper, focus on improving the performance of detector in point process model, we propose an enhanced version of point process model, which is based on hierarchical deep belief networks (DBNs). Hierarchical DBNs are used as the phoneme detector in this system, and they combine the advantages of both the DBN and the hierarchical architecture for capturing complex statistical patterns in speech while overcoming the inherent flaws of conventional hidden Markov models and multilayer layer perceptron. Experiments results on TIMIT database show that the proposed method can yield 2% improvement. Furthermore, in the case when training examples are extremely limited, it can achieve better results over state-of-the-art KWS systems. Copyright (c) 2013 John Wiley & Sons, Ltd.	[Wang, Yi; Yang, Jun-an; Lu, Jun; Liu, Hui; Wang, Lun-wu] Hefei Elect Engn Inst, Lab 404, Hefei 230037, Peoples R China; [Wang, Yi; Yang, Jun-an; Lu, Jun; Liu, Hui] Key Lab Elect Restrict Anhui Prov, Hefei 230037, Peoples R China	Wang, Y (reprint author), Hefei Elect Engn Inst, Lab 404, 460 Huangshan Rd, Hefei 230037, Peoples R China.	wygggg@126.com			National Natural Science Foundation of China [61272333]; Anhui Provincial Natural Science Foundation [1208085MF94, 1308085QF99]	The authors would like to thank Dr. Guo-ping Hu, Dr. Si Wei, Mr. Lin Liu, and Mr. Jia Pan at Anhui USTC iFlytek Corporation for preparing the dataset and engaging in valuable discussions for DBN. This paper is also supported by National Natural Science Foundation of China under Grant No. 61272333 and Anhui Provincial Natural Science Foundation under Grant Nos. 1208085MF94 and 1308085QF99.	Bergstra J., 2010, P PYTH SCI COMP C SC; Bridle JS., 1973, BRIT AC SOC M, P1; Chen B, 2003, P EUR, P429; Deng L., 2011, P AS PAC SIGN INF PR; Garofolo JS, 1993, TIMIT ACOUSTIC PHONE; HERMANSKY H, 1999, ACOUST SPEECH SIG PR, P289; Hinton G., 2010, 2010003 U TOR MACH L; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; JAMES DA, 1994, INT CONF ACOUST SPEE, P377; Jansen A, 2009, IEEE T AUDIO SPEECH, V17, P1457, DOI 10.1109/TASL.2009.2021307; Jansen A, 2009, SPEECH COMMUN, V51, P1155, DOI 10.1016/j.specom.2009.05.008; Keshet J, 2009, SPEECH COMMUN, V51, P317, DOI 10.1016/j.specom.2008.10.002; Kim Y, 2012, INT J COMMUN SYST, V25, P691, DOI 10.1002/dac.1211; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mohamed AR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4273; Pinto J, 2011, IEEE T AUDIO SPEECH, V19, P225, DOI 10.1109/TASL.2010.2045943; Rose RC, 1996, WORD SPOTTING CONTIN, P303; Shekofteh Y, 2012, P INT C E BUS E GOV, P1168; Silaghi MC, 1999, P IEEE AUT SPEECH RE, P213; Siniscalchi SM, 2013, IEEE SIGNAL PROC LET, V20, P201, DOI 10.1109/LSP.2013.2237901; Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510; Stevens KN, 1998, ACOUSTIC PHOENETICS; Su GM, 2011, INT J COMMUN SYST, V24, P1261, DOI 10.1002/dac.1190; Suga N, 2006, LISTENING SPEECH AUD, P159; TEJEDOR J, 2010, P INTERSPEECH 2010 C, P701; Thambiratnam K, 2005, INT CONF ACOUST SPEE, P465; WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088	30	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1074-5351	1099-1131		INT J COMMUN SYST	Int. J. Commun. Syst.	FEB	2015	28	3					483	496		10.1002/dac.2681		14	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	CA2CE	WOS:000348715800007		
J	Yu, YT; Li, J; Guan, HY; Jia, F; Wang, C				Yu, Yongtao; Li, Jonathan; Guan, Haiyan; Jia, Fukai; Wang, Cheng			Learning Hierarchical Features for Automated Extraction of Road Markings From 3-D Mobile LiDAR Point Clouds	IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING			English	Article						Deep learning; mobile light detection and ranging (LiDAR); point cloud; road marking; three dimensional (3-D) extraction	TRACKING	This paper presents a novel method for automated extraction of road markings directly from three dimensional (3-D) point clouds acquired by a mobile light detection and ranging (LiDAR) system. First, road surface points are segmented from a raw point cloud using a curb-based approach. Then, road markings are directly extracted from road surface points through multisegment thresholding and spatial density filtering. Finally, seven specific types of road markings are further accurately delineated through a combination of Euclidean distance clustering, voxel-based normalized cut segmentation, large-size marking classification based on trajectory and curb-lines, and small-size marking classification based on deep learning, and principal component analysis (PCA). Quantitative evaluations indicate that the proposed method achieves an average completeness, correctness, and F-measure of 0.93, 0.92, and 0.93, respectively. Comparative studies also demonstrate that the proposed method achieves better performance and accuracy than those of the two existing methods.	[Yu, Yongtao; Jia, Fukai; Wang, Cheng] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart Cities SCSC, Xiamen 361005, Peoples R China; [Li, Jonathan] Xiamen Univ, Key Lab Underwater Acoust Commun & Marin Informat, Xiamen 361005, Peoples R China; [Li, Jonathan; Guan, Haiyan] Univ Waterloo, Dept Geog & Environm Management, Waterloo, ON N2L 3G1, Canada	Li, J (reprint author), Xiamen Univ, Key Lab Underwater Acoust Commun & Marin Informat, Xiamen 361005, Peoples R China.	junli@xmu.edu.cn	WANG, Cheng/A-9472-2012	WANG, Cheng/0000-0001-6075-796X	Natural Sciences and Engineering Research Council of Canada (NSERC) [111368]; Natural Science Foundation of China (NSFC) [41471379]	This work was supported in part by the discovery grant from the Natural Sciences and Engineering Research Council of Canada (NSERC) under Grant 111368 and in part by the general grant from the Natural Science Foundation of China (NSFC) under Grant 41471379. (Corresponding author: Jonathan Li.)	Chen X., 2009, P 17 ACM SIGSPATIAL, P488, DOI 10.1145/1653771.1653851; Gopalan R, 2012, IEEE T INTELL TRANSP, V13, P1088, DOI 10.1109/TITS.2012.2184756; Guan HY, 2014, ISPRS J PHOTOGRAMM, V87, P93, DOI 10.1016/j.isprsjprs.2013.11.005; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Lindner P., 2009, P IEEE C INT TRANSP, P1; Mancini A., 2012, P IEEE SME MECH EMB, P281; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Salakhutdinov R, 2013, IEEE T PATTERN ANAL, V35, P1958, DOI 10.1109/TPAMI.2012.269; Salakhutdinov R., 2009, P INT C ART INT STAT, V12, P448; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Thuy M, 2010, METROL MEAS SYST, V17, P311, DOI 10.2478/v10178-010-0027-3; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Tournaire O, 2009, ISPRS J PHOTOGRAMM, V64, P621, DOI 10.1016/j.isprsjprs.2009.05.005; Yang BS, 2012, PHOTOGRAMM ENG REM S, V78, P331	18	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1939-1404	2151-1535		IEEE J-STARS	IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.	FEB	2015	8	2					709	726		10.1109/JSTARS.2014.2347276		18	Engineering, Electrical & Electronic; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology	Engineering; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology	CF1AY	WOS:000352277100023		
J	Mettler, B; Kong, ZD; Li, B; Andersh, J				Mettler, Berenice; Kong, Zhaodan; Li, Bin; Andersh, Jonathan			Systems view on spatial planning and perception based on invariants in agent-environment dynamics	FRONTIERS IN NEUROSCIENCE			English	Article						guidance; perception; decision making; visual attention; dynamics	EYE-MOVEMENTS; ARM MOVEMENTS; GUIDANCE; VISION; MECHANISMS; AVOIDANCE; BEHAVIOR	Modeling agile and versatile spatial behavior remains a challenging task, due to the intricate coupling of planning, control, and perceptual processes. Previous results have shown that humans plan and organize their guidance behavior by exploiting patterns in the interactions between agent or organism and the environment. These patterns, described under the concept of Interaction Patterns (IPs), capture invariants arising from equivalences and symmetries in the interaction with the environment, as well as effects arising from intrinsic properties of human control and guidance processes, such as perceptual guidance mechanisms. The paper takes a systems' perspective, considering the IP as a unit of organization, and builds on its properties to present a hierarchical model that delineates the planning, control, and perceptual processes and their integration. The model's planning process is further elaborated by showing that the IP can be abstracted, using spatial time-to-go functions. The perceptual processes are elaborated from the hierarchical model. The paper provides experimental support for the model's ability to predict the spatial organization of behavior and the perceptual processes.	[Mettler, Berenice; Li, Bin; Andersh, Jonathan] Univ Minnesota, Dept Aerosp Engn & Mech, Interact Guidance & Control Lab, Minneapolis, MN 55455 USA; [Kong, Zhaodan] Boston Univ, Dept Mech Engn, Boston, MA 02215 USA; [Andersh, Jonathan] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Mettler, B (reprint author), Univ Minnesota, Dept Aerosp Engn & Mech, Interact Guidance & Control Lab, Minneapolis, MN 55455 USA.	mettler@umn.edu			National Science Foundation [CMMI-1254906]; Office of Naval Research [11361538]	This research work was enabled thanks to financial support from the National Science Foundation (Career Grant CMMI-1254906) and the Office of Naval Research (Grant 11361538).	Abbeel P., 2007, P NEUR INF PROC SYST, P2007; Andersh J., 2014, IEEE RSJ INT C INT R; Badre D, 2008, TRENDS COGN SCI, V12, P193, DOI 10.1016/j.tics.2008.02.004; Barto A., 2003, DISCRETE EVENT DYN S, V13, P341, DOI [DOI 10.1023/A:1025696116075, 10.1023/A:1025696116075)00052-1]; Bellman R. E., 1962, APPL DYNAMIC PROGRAM; Belta C., 2005, ROBOTICS IEEE T, V21, P864, DOI [10.1109/TRO.2005.851359, DOI 10.1109/TRO.2005.851359]; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bernstein N. A., 1967, COORDINATION REGULAT; Bertsekas D. P., 1995, DYNAMIC PROGRAMMING; Betts J.T., 2001, PRACTICAL METHODS OP; BOGHEN D, 1974, INVEST OPHTH VISUAL, V13, P619; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; BROCKETT RW, 1993, PROG SYST C, V14, P29; Brockett R. W., 1990, ROBOTICS, V41, P181; Bryson A., 1975, APPL OPTIMAL CONTROL; Bryson AE, 1996, IEEE CONTR SYST MAG, V16, P26, DOI 10.1109/37.506395; BULLOCK D, 1988, PSYCHOL REV, V95, P49, DOI 10.1037/0033-295X.95.1.49; Cisek P, 2010, ANNU REV NEUROSCI, V33, P269, DOI 10.1146/annurev.neuro.051508.135409; de Berg M., 2008, COMPUTATIONAL GEOMET, DOI [10.1007/978-3-540-77974-2, DOI 10.1007/978-3-540-77974-2]; FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392; FLASH T, 1985, J NEUROSCI, V5, P1688; FRAZZOLI E, 2002, AIAA J GUIDANCE CONT, V25, P116; Gibson J. J., 1979, ECOLOGICAL APPROACH; Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009; Hebb DO, 1949, ORG BEHAV NEUROPSYCH; Heffley R. K., 1979, P 15 ANN C MAN CONTR, P545; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; KALASKA JF, 1992, SCIENCE, V255, P1517, DOI 10.1126/science.1549781; Kong Z., 2011, IEEE RSJ INT C INT R; Kong Z., 2014, TECHNICAL REPORT; Kong ZD, 2013, IEEE T HUM-MACH SYST, V43, P371, DOI 10.1109/TSMC.2013.2262043; Kugler PN, 1987, INFORM NATURAL LAW S; Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935; Land MF, 1999, J COMP PHYSIOL A, V185, P341, DOI 10.1007/s003590050393; Lee DN, 1998, ECOL PSYCHOL, V10, P221, DOI 10.1207/s15326969eco103&4_4; Li B., 2014, 5 ANN WORKSH MOD MON; Li B., 2013, AM CONTR C ACC; MacAdam CC, 2003, VEHICLE SYST DYN, V40, P101, DOI 10.1076/vesd.40.1.101.15875; MCBEATH MK, 1995, SCIENCE, V268, P569, DOI 10.1126/science.7725104; McRuer D., 1974, AGARDAG188; McRuer D., 1967, HUM FACTORS ELECT, V3, P231; MCRUER D, 1980, AUTOMATICA, V16, P237, DOI 10.1016/0005-1098(80)90034-5; Mettler B., 2011, COG CRIT, V3, P1; Mettler B, 2013, IEEE T HUM-MACH SYST, V43, P32, DOI 10.1109/TSMCA.2012.2207110; Mettler B, 2010, CONTROL ENG PRACT, V18, P773, DOI 10.1016/j.conengprac.2010.02.013; Mettler B., 2012, 2 INT C APPL THEOR A; Michon J., 1985, HUMAN BEHAV TRAFFIC, V28, P485; Miller G. A., 1960, PLANS STRUCT BEHAV, DOI [10.1037/10039-000, DOI 10.1037/10039-000]; Mountcastle V., 1978, MINDFUL BRAIN; MUNHALL KG, 1986, BEHAV BRAIN SCI, V9, P615; Navalpakkam V., 2006, 2006 IEEE COMP SOC C, V2, P2049, DOI 10.1109/CVPR.2006.54; Newell A., 1994, UNIFIED THEORIES COG; Padfield GD, 2003, J AM HELICOPTER SOC, V48, P108; Padfield GD, 2012, J GUID CONTROL DYNAM, V35, P80, DOI 10.2514/1.54065; Quigley M., 2009, P OP SOURC SOFTW WOR; SensoMotoric Instruments, 2012, IVIEW ETG US MAN; Shalizi CR, 2001, J STAT PHYS, V104, P817, DOI 10.1023/A:1010388907793; Simon HA., 1962, P AM PHILOS SOC, V106, P467; Srinivasan M, 2006, INVERTEBRATE VISION, P462; Terada R, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), DOI 10.1109/ITSC.2010.5625154; TURVEY MT, 1986, ACTA PSYCHOL, V63, P133, DOI 10.1016/0001-6918(86)90060-0; Tustin A., 1947, Journal of the Institution of Electrical Engineers. IIA. Automatic Regulators and Servo Mechanisms, V94; van Breugel F, 2012, J EXP BIOL, V215, P1783, DOI 10.1242/jeb.066498; Warren WH, 2006, PSYCHOL REV, V113, P358, DOI 10.1037/0033-295X.113.2.358; WARREN WH, 2004, OPTIC FLOW, V324, P307	65	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-453X			FRONT NEUROSCI-SWITZ	Front. Neurosci.	JAN 13	2015	8								439	10.3389/fnins.2014.00439		14	Neurosciences	Neurosciences & Neurology	CG0FK	WOS:000352941800001		
J	Molfese, DL				Molfese, Dennis L.			The Need for Theory to Guide Concussion Research	DEVELOPMENTAL NEUROPSYCHOLOGY			English	Article							BRAIN	Although research into concussion has greatly expanded over the past decade, progress in identifying the mechanisms and consequences of head injury and recovery are largely absent. Instead, data are accumulated without the guidance of a systematic theory to direct research questions or generate testable hypotheses. As part of this special issue on sports concussion, I advance a theory that emphasizes changes in spatial and temporal distributions of the brain's neural networks during normal learning and the disruptions of these networks following injury. Specific predictions are made regarding both the development of the network as well as its breakdown following injury.	Univ Nebraska, Ctr Brain Biol & Behav, Lincoln, NE 68588 USA	Molfese, DL (reprint author), Univ Nebraska, Ctr Brain Biol & Behav, C88,East Stadium,POB 880156, Lincoln, NE 68588 USA.	dmolfese2@unl.edu			National Institute of Child Health and Human Development [R01-HD17860, R01 HD073202]; National Heart, Lung, and Blood Institute [5R01HL070911]; National Institute of Mental Health [HD062072]; U.S. Department of Education [R215K000023, R215R990011]	This work was supported in part by grants from the National Institute of Child Health and Human Development (R01-HD17860, R01 HD073202), National Heart, Lung, and Blood Institute (5R01HL070911), National Institute of Mental Health (HD062072), and the U.S. Department of Education (R215K000023, R215R990011).	Anderson J., 1983, ARCHITECTURE COGNITI; Blakemore SJ, 2006, J CHILD PSYCHOL PSYC, V47, P296, DOI 10.1111/j.1469-7610.2006.01611.x; Casey BJ, 2000, BIOL PSYCHOL, V54, P241, DOI 10.1016/S0301-0511(00)00058-2; FINGER S, 1973, BRAIN RES, V63, P1, DOI 10.1016/0006-8993(73)90072-3; Hebb DO, 1949, ORG BEHAV NEUROPSYCH; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Maccotta L, 2007, CEREB CORTEX, V17, P443, DOI 10.1093/cercor/bhj161; McClelland J.L., 1986, EXPLORATIONS MICROST, V2; Molfese DL, 2008, DEV NEUROPSYCHOL, V33, P682, DOI 10.1080/87565640802418647; Toga AW, 2006, TRENDS NEUROSCI, V29, P148, DOI 10.1016/j.tins.2006.01.007	10	0	0	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND	8756-5641	1532-6942		DEV NEUROPSYCHOL	Dev. Neuropsychol.	JAN 2	2015	40	1			SI		1	6		10.1080/87565641.2015.1006479		6	Psychology, Developmental; Psychology; Psychology, Experimental	Psychology	CA6IR	WOS:000349015800001	25649772	
J	Brocki, L; Marasek, K				Brocki, Lukasz; Marasek, Krzysztof			Deep Belief Neural Networks and Bidirectional Long-Short Term Memory Hybrid for Speech Recognition	ARCHIVES OF ACOUSTICS			English	Article						deep belief neural networks; long-short term memory; bidirectional recurrent neural networks; speech recognition; large vocabulary continuous speech recognition	LEARNING ALGORITHM	This paper describes a Deep Belief Neural Network (DBNN) and Bidirectional Long-Short Term Memory (LSTM) hybrid used as an acoustic model for Speech Recognition. It was demonstrated by many independent researchers that DBNNs exhibit superior performance to other known machine learning frameworks in terms of speech recognition accuracy. Their superiority comes from the fact that these are deep learning networks. However, a trained DBNN is simply a feed-forward network with no internal memory, unlike Recurrent Neural Networks (RNNs) which are Turing complete and do posses internal memory, thus allowing them to make use of longer context. In this paper, an experiment is performed to make a hybrid of a DBNN with an advanced bidirectional RNN used to process its output. Results show that the use of the new DBNN-BLSTM hybrid as the acoustic model for the Large Vocabulary Continuous Speech Recognition (LVCSR) increases word recognition accuracy. However, the new model has many parameters and in some cases it may suffer performance issues in real-time applications.	[Brocki, Lukasz; Marasek, Krzysztof] Polish Japanese Acad Informat Technol, PL-02008 Warsaw, Poland	Brocki, L (reprint author), Polish Japanese Acad Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.	lucas@primespeech.pl			European Community from the European Social Fund within the INTERKADRA project [UDA-POKL-04.01.01-00-014/10-00]; NCN [N516519439]; Eu-Bridge project [287658]	This work was financially supported by the European Community from the European Social Fund within the INTERKADRA project UDA-POKL-04.01.01-00-014/10-00, NCN N516519439 grant and Eu-Bridge project (FP7 grant agreement no. 287658).	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brocki L., 2006, TSD 2006 BRNO CZECH; Dahl GE, 2011, INT CONF ACOUST SPEE, P4688; Federico M., 2008, P INT BRISB AUSTR; Graves A., 2004, BIOADIT 2004 LAUS SW, P175; Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799; Graves A., 2006, INT C MACH LEARN, P369; Graves A., 2013, ICASSP 2013 VANC CAN; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Korzinek D., 2011, INTELLIGENT TOOLS BU, V467, P489; Lee A., 2001, P EUR C SPEECH COMM, P1691; Mohamed A-r, 2009, NIPS WORKSH DEEP LEA; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Stolcke A., 2002, SRILM EXTENSIBLE LAN; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Wollmer M., 2009, NOLISP 2009 VIC SPAI; Young S., 2000, HTK BOOK	20	0	0	POLSKA AKAD NAUK, POLISH ACAD SCIENCES, INST FUNDAMENTAL TECH RES PAS	WARSZAWA	PL DEFILAD 1, WARSZAWA, 00-901, POLAND	0137-5075	2300-262X		ARCH ACOUST	Arch. Acoust.		2015	40	2					191	195		10.1515/aoa-2015-0021		5	Acoustics	Acoustics	CK8XT	WOS:000356524100006		
J	Brosch, T; Tam, R				Brosch, Tom; Tam, Roger			Efficient Training of Convolutional Deep Belief Networks in the Frequency Domain for Application to High-Resolution 2D and 3D Images	NEURAL COMPUTATION			English	Letter								Deep learning has traditionally been computationally expensive, and advances in training methods have been the prerequisite for improving its efficiency in order to expand its application to a variety of image classification problems. In this letter, we address the problem of efficient training of convolutional deep belief networks by learning the weights in the frequency domain, which eliminates the time-consuming calculation of convolutions. An essential consideration in the design of the algorithm is to minimize the number of transformations to and from frequency space. We have evaluated the running time improvements using two standard benchmark data sets, showing a speed-up of up to 8times on 2D images and up to 200times on 3D volumes. Our training algorithm makes training of convolutional deep belief networks on 3D medical images with a resolution of up to 128 x 128 x 128 voxels practical, which opens new directions for using deep learning for medical image analysis.	[Brosch, Tom; Tam, Roger] MS MRI Res Grp, Vancouver, BC V6T 2B5, Canada; [Brosch, Tom] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada; [Tam, Roger] Univ British Columbia, Dept Radiol, Vancouver, BC V5Z 1M9, Canada	Brosch, T (reprint author), MS MRI Res Grp, Vancouver, BC V6T 2B5, Canada.	brosch.tom@gmail.com; roger.tam@ubc.ca					Brosch T, 2013, LECT NOTES COMPUT SC, V8150, P633, DOI 10.1007/978-3-642-40763-5_78; Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P1; Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50; Deng J, 2009, PROC CVPR IEEE, P248; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1; Krizhevsky A., 2012, HIGH PERFORMANCE C C; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Lee N, 2011, I S BIOMED IMAGING, P321, DOI 10.1109/ISBI.2011.5872414; Liao S., 2013, MED IMAGE COMPUTING, V8150, P254; Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498; Mathieu M., 2014, P 2 INT C LEARN REPR, P1; Nair V., 2010, P 27 INT C MACH LEAR, P807; Raina R., 2009, P 26 INT C MACH LEAR; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Wu GR, 2013, LECT NOTES COMPUT SC, V8150, P649; Zeiler M. D., 2013, P 1 INT C LEARN REPR, P1	20	0	0	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	0899-7667	1530-888X		NEURAL COMPUT	Neural Comput.	JAN	2015	27	1					211	227		10.1162/NECO_a_00682		17	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AX2GY	WOS:000346762700009	25380341	
J	Chetty, G; Yamin, M				Chetty, Girija; Yamin, Mohammad			INTELLIGENT HUMAN ACTIVITY RECOGNITION SCHEME FOR EHEALTH APPLICATIONS	MALAYSIAN JOURNAL OF COMPUTER SCIENCE			English	Article						smart phone; body sensor; activity recognition; machine learning; assisted living		Automatic activity recognition systems aim to capture the state of the user and its environment by exploiting heterogeneous sensors, and permit continuous monitoring of numerous physiological signals, where these sensors are attached to the subject's body. This can be immensely useful in healthcare applications, for automatic and intelligent daily activity monitoring for elderly people. In this paper, we present a novel data analytic scheme for intelligent Human Activity Recognition (AR) using wireless body sensors and smartphone inertial sensors which use information theory-based feature ranking algorithms and classifiers based on random forests, ensemble learning and lazy learning. Further, we propose a novel multimodal scheme based on combining multimodal three dimensional (x, y, z) accelerometer and gyro data from smart phone inertial sensors. Extensive experiments using different publicly available database of human activity show that the proposed approach can assist in the development of intelligent and automatic real time human activity monitoring technology for eHealth application scenarios for elderly, disabled and people with special needs.	[Chetty, Girija] Univ Canberra, Canberra, ACT 2601, Australia; [Yamin, Mohammad] King Abdulaziz Univ, Jeddah, Saudi Arabia	Chetty, G (reprint author), Univ Canberra, Canberra, ACT 2601, Australia.	Girija.Chetty@canberra.edu.au; myamin@kau.edu.sa					Andrew Galen, 2013, DEEP CANONICAL CORRE, V28, P1247; Anguita Davide, 2012, INT WORKSH AMB ASS L; Ashraf Mohammad, 2012, INT J INTELLIGENT IN, V3, P110; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chavarriaga Ricardo, 2013, PATTERN RECOGNITION; Chetty Girija, 2005, P 8 IEEE S SIGN PROC, P66; Ekholm J., 2011, GARTNER MOBILE COMMU; Ganapathiraju A., 2004, SIGNAL PROCESSING IE, V52, P2348; Hardoon DR, 2007, NEUROIMAGE, V37, P1250, DOI 10.1016/j.neuroimage.2007.06.017; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kwapisz J. R., 2011, SIGKDD EXPLOR NEWSL, V12, P74, DOI DOI 10.1145/1964897.1964918; Mannini A, 2010, SENSORS-BASEL, V10, P1154, DOI 10.3390/s100201154; Moohebat M, 2015, J ASSOC INF SCI TECH, V66, P501, DOI 10.1002/asi.23194; Powers D. M. W., 2011, J MACHINE LEARNING T, V2, P37; Ravi N., 2005, P 17 C INN APPL ART, P1541; Rodriguez-Molinero A., 2007, WORLD PARK C GLASG; Roggen Daniel, 2010, 7 INT C NETW SENS SY; Shayegan MA, 2014, J APPL MATH, DOI 10.1155/2014/654787; Wawrzynek J., 1993, VLSI NEUR NETW ART I, V103; Yeow WL, 2014, EXPERT SYST APPL, V41, P3497, DOI 10.1016/j.eswa.2013.10.054	20	0	0	UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH	KUALA LUMPUR	UNIV MALAYA, FAC COMPUTER SCIENCE & INFORMATION TECH, KUALA LUMPUR, 50603, MALAYSIA	0127-9084			MALAYS J COMPUT SCI	Malayas. J. Comput. Sci.		2015	28	1					59	69				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	CE7BW	WOS:000351993000005		
J	Fan, XN; Zhang, SW				Fan, Xiao-Nan; Zhang, Shao-Wu			lncRNA-MFDL: identification of human long non-coding RNAs by fusing multiple features and using deep learning	MOLECULAR BIOSYSTEMS			English	Article							AMINO-ACID-COMPOSITION; ENCODE PROJECT; HUMAN GENOME; DARK-MATTER; TRANSCRIPTS; ALGORITHM; INFORMATION	Long noncoding RNAs (lncRNAs) are emerging as a novel class of noncoding RNAs and potent gene regulators, which play an important and varied role in cellular functions. lncRNAs are closely related with the occurrence and development of some diseases. High-throughput RNA-sequencing techniques combined with de novo assembly have identified a large number of novel transcripts. The discovery of large and 'hidden' transcriptomes urgently requires the development of effective computational methods that can rapidly distinguish between coding and long noncoding RNAs. In this study, we developed a powerful predictor (named as lncRNA-MFDL) to identify lncRNAs by fusing multiple features of the open reading frame, k-mer, the secondary structure and the most-like coding domain sequence and using deep learning classification algorithms. Using the same human training dataset and a 10-fold cross validation test, lncRNA-MFDL can achieve 97.1% prediction accuracy which is 5.7, 3.7, and 3.4% higher than that of CPC, CNCI and lncRNA-FMFSVM predictors, respectively. Compared with CPC and CNCI predictors in other species (e.g., anole lizard, zebrafish, chicken, gorilla, macaque, mouse, lamprey, orangutan, xenopus and C. elegans) testing datasets, the new lncRNA-MFDL predictor is also much more effective and robust. These results show that lncRNA-MFDL is a powerful tool for identifying lncRNAs. The lncRNA-MFDL software package is freely available at http://compgenomics.utsa.edu/lncRNA_MDFL/for academic users.	[Fan, Xiao-Nan; Zhang, Shao-Wu] Northwestern Polytech Univ, Key Lab Informat Fus Technol, Minist Educ, Sch Automat, Xian 710072, Peoples R China	Zhang, SW (reprint author), Northwestern Polytech Univ, Key Lab Informat Fus Technol, Minist Educ, Sch Automat, Xian 710072, Peoples R China.	zhangsw@nwpu.edu.cn			National Natural Science Foundation of China [61170134, 61473232, 91430111]; Graduate Starting Seed Fund of Northwestern Polytechnical University [Z2014145, Z2014152]	This paper was supported by the National Natural Science Foundation of China (61170134, 61473232, 91430111) and the Graduate Starting Seed Fund of Northwestern Polytechnical University (Z2014145, Z2014152).	Aguilo F, 2011, CANCER RES, V71, P5365, DOI 10.1158/0008-5472.CAN-10-4379; Arrial RT, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-239; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Buchan JR, 2006, NUCLEIC ACIDS RES, V34, P1015, DOI 10.1093/nar/gkj488; Cesana M, 2011, CELL, V147, P358, DOI 10.1016/j.cell.2011.09.028; Chen W., 2013, NUCLEIC ACIDS RES; Chen WP, 2011, PROTEOME SCI, V9, DOI 10.1186/1477-5956-9-9; Chou KC, 2011, J THEOR BIOL, V273, P236, DOI 10.1016/j.jtbi.2010.12.024; Clamp M, 2007, P NATL ACAD SCI USA, V104, P19428, DOI 10.1073/pnas.0709013104; Consortium I.H.G.S., 2004, NATURE, V431, P931, DOI DOI 10.1038/NATURE03001; Deng L., 2011, P AS PAC SIGN INF PR; Deng L., 2011, P INT; Deng L., 2013, FDN TRENDS SIGNAL PR, V2-3, P197; Deng L., 2012, AC SPEECH SIGN PROC; Deng L., 2013, AC SPEECH SIGN PROC; Dinger ME, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000176; Frith MC, 2005, EUR J HUM GENET, V13, P894, DOI 10.1038/sj.ejhg.5201459; Guttman M, 2012, NATURE, V482, P339, DOI 10.1038/nature10887; Harrow J, 2012, GENOME RES, V22, P1760, DOI 10.1101/gr.135350.111; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Hofacker I. L., 2009, CURRENT PROTOCOLS BI; Hofacker IL, 2003, NUCLEIC ACIDS RES, V31, P3429, DOI 10.1093/nar/gkg599; Johnson JM, 2005, TRENDS GENET, V21, P93, DOI 10.1016/j.tig.2004.12.008; Kong L, 2007, NUCLEIC ACIDS RES, V35, pW345, DOI 10.1093/nar/gkm391; Lin MF, 2011, BIOINFORMATICS, V27, pI275, DOI 10.1093/bioinformatics/btr209; Lv J, 2013, NUCLEIC ACIDS RES, V41, P10044, DOI 10.1093/nar/gkt818; Mukherjee S, 2009, NUCLEIC ACIDS RES, V37, DOI 10.1093/nar/gkp318; Pennisi E, 2012, SCIENCE, V337, P1159, DOI 10.1126/science.337.6099.1159; Riddihough G, 2005, SCIENCE, V309, P1507, DOI 10.1126/science.309.5740.1507; Sun K, 2013, BMC GENOMICS, V14, DOI 10.1186/1471-2164-14-S2-S7; Sun L, 2013, NUCLEIC ACIDS RES, V41, DOI 10.1093/nar/gkt646; Wang L, 2013, NUCLEIC ACIDS RES, V41, DOI 10.1093/nar/gkt006; Wang YQ, 2014, GENE, V533, P94, DOI 10.1016/j.gene.2013.09.118; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zhang SW, 2014, ANAL BIOCHEM, V449, P164, DOI 10.1016/j.ab.2013.12.013; Zhang SW, 2008, AMINO ACIDS, V35, P591, DOI 10.1007/s00726-008-0086-x; Zhang SW, 2008, AMINO ACIDS, V34, P565, DOI 10.1007/s00726-007-0010-9	38	0	0	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	1742-206X	1742-2051		MOL BIOSYST	Mol. Biosyst.		2015	11	3					892	897		10.1039/c4mb00650j		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	CC0AA	WOS:000349995600022	25588719	
J	Fierst, JL; Phillips, PC				Fierst, Janna L.; Phillips, Patrick C.			Modeling the Evolution of Complex Genetic Systems: The Gene Network Family Tree	JOURNAL OF EXPERIMENTAL ZOOLOGY PART B-MOLECULAR AND DEVELOPMENTAL EVOLUTION			English	Article							RESTRICTED BOLTZMANN MACHINES; WAGNERS CANALIZATION MODEL; DROSOPHILA-MELANOGASTER; EVOLVABILITY; INFORMATION; ROBUSTNESS; DYNAMICS; FERROMAGNETISM; ORGANIZATION; ENVIRONMENT	In 1994 and 1996, Andreas Wagner introduced a novel model in two papers addressing the evolution of genetic regulatory networks. This work, and a suite of papers that followed using similar models, helped integrate network thinking into biology and motivate research focused on the evolution of genetic networks. The Wagner network has its mathematical roots in the Ising model, a statistical physics model describing the activity of atoms on a lattice, and in neural networks. These models have given rise to two branches of applications, one in physics and biology and one in artificial intelligence and machine learning. Here, we review development along these branches, outline similarities and differences between biological models of genetic regulatory circuits and neural circuits models used in machine learning, and identify ways in which these models can provide novel insights into biological systems. J. Exp. Zool. (Mol. Dev. Evol.) 324B: 1-12, 2015. (c) 2014 Wiley Periodicals, Inc.	[Fierst, Janna L.; Phillips, Patrick C.] Univ Oregon, Inst Ecol & Evolut, Eugene, OR 97403 USA	Fierst, JL (reprint author), Univ Oregon, Inst Ecol & Evolut, Eugene, OR 97403 USA.	jfierst@uoregon.edu			National Institutes of Health [GM096008]	Grant sponsor: National Institutes of Health; grant number: GM096008.	Amores A, 1998, SCIENCE, V282, P1711, DOI 10.1126/science.282.5394.1711; Arabidopsis Genome Initiative, 2000, Nature (London), V408, P796; Azevedo RBR, 2006, NATURE, V440, P87, DOI 10.1038/nature04488; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bergman A, 2003, NATURE, V424, P549, DOI 10.1038/nature01834; Borenstein E, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000202; BRUSH SG, 1967, REV MOD PHYS, V39, P883, DOI 10.1103/RevModPhys.39.883; Ciliberti S, 2007, P NATL ACAD SCI USA, V104, P13591, DOI 10.1073/pnas.0705396104; Draghi J, 2009, J EVOLUTION BIOL, V22, P599, DOI 10.1111/j.1420-9101.2008.01663.x; Draghi JA, 2012, EVOLUTION, V66, P2891, DOI 10.1111/j.1558-5646.2012.01649.x; Espinosa-Soto C., 2011, BMC EVOL BIOL, V11, P1; Espinosa-Soto C, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000719; Fierst JL, 2011, EVOL BIOL, V38, P52, DOI 10.1007/s11692-010-9103-6; Fierst JL, 2011, J EVOLUTION BIOL, V24, P1992, DOI 10.1111/j.1420-9101.2011.02333.x; Hardy GH, 1908, SCIENCE, V28, P49, DOI 10.1126/science.28.706.49; Hill AV, 1910, J PHYSIOL-LONDON, V40, piv; Hinton GE, 1983, P 5 ANN C COGN SCI S; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition; Hof RD, 2013, MIT TECHNOLOGY REV; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Huerta-Sanchez E, 2007, THEOR POPUL BIOL, V71, P121, DOI 10.1016/j.tpb.2006.10.006; Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; Jaeger J, 2004, NATURE, V430, P368, DOI 10.1038/nature02678; Jaeger J, 2004, GENETICS, V167, P1721, DOI 10.1534/genetics.104.027334; KAUFFMAN S, 1974, J THEOR BIOL, V44, P167, DOI 10.1016/S0022-5193(74)80037-8; Kauffman S. A., 1993, ORIGINS ORDER; KAUFFMAN SA, 1969, J THEOR BIOL, V22, P437, DOI 10.1016/0022-5193(69)90015-0; Le Cunff Y, 2012, J THEOR BIOL, V314, P69, DOI 10.1016/j.jtbi.2012.08.020; Lenz W., 1920, Physikalische Zeitschrift, V21; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; LEVINS R, 1966, AM SCI, V54, P421; MacCarthy T, 2007, P NATL ACAD SCI USA, V104, P12801, DOI 10.1073/pnas.0705455104; Makin JG, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003035; Masel J, 2009, TRENDS GENET, V25, P395, DOI 10.1016/j.tig.2009.07.005; Masel J, 2004, J EVOLUTION BIOL, V17, P1106, DOI 10.1111/j.1420-9101.2004.00739.x; MAY RM, 1972, NATURE, V238, P413, DOI 10.1038/238413a0; McCulloch W, 1943, B MATH BIOPHYS, V7, P115; Moreno-Risueno MA, 2010, SCIENCE, V329, P1306, DOI 10.1126/science.1191937; Onsager L, 1944, PHYS REV, V65, P117, DOI 10.1103/PhysRev.65.117; Palmer ME, 2009, EVOLUTION, V63, P418, DOI 10.1111/j.1558-5646.2008.00577.x; Peierls R, 1936, P CAMB PHILOS SOC, V32, P477; Perkins TJ, 2006, PLOS COMPUT BIOL, V2, P417, DOI 10.1371/journal.pcbi.0020051; Pinho R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034285; Proulx SR, 2005, TRENDS ECOL EVOL, V20, P345, DOI 10.1016/j.tree.2005.04.004; Provine W.-B., 1971, ORIGINS THEORETICAL; Rockman MV, 2006, NAT REV GENET, V7, P862, DOI 10.1038/nrg1964; Rodrigues JFM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000613; Rojas R, 1996, NEURAL NETWORKS SYST; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rosenblatt F, 1957, CORNELL AERONAUTICAL, V85, P460; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rosenblatt F., 1961, TECHNICAL REPORT; Sevim V, 2008, J THEOR BIOL, V253, P323, DOI 10.1016/j.jtbi.2008.03.003; SHERRINGTON D, 1975, PHYS REV LETT, V35, P1792, DOI 10.1103/PhysRevLett.35.1792; Siegal ML, 2007, GENETICA, V129, P83, DOI 10.1007/s10709-006-0035-0; Siegal ML, 2002, P NATL ACAD SCI USA, V99, P10528, DOI 10.1073/pnas.102303999; Smolensky P., 1986, INFORM PROCESSING DY; Stein DL, 2012, COMPLEX SYST, V20, P115; Stutz C, 1999, PHYS TODAY, V52, P106, DOI 10.1063/1.882538; Tarca AL, 2007, PLOS COMPUT BIOL, V3, P953, DOI 10.1371/journal.pcbi.0030116; Turing AM, 1937, P LOND MATH SOC, V43, P544; Turing A., 1936, P LOND MATH SOC, V42, P230, DOI DOI 10.1112/PLMS/S2-42.1.230; von Dassow G, 2000, NATURE, V406, P188, DOI 10.1038/35018085; Waddington CH, 1942, NATURE, V150, P563, DOI 10.1038/150563a0; Waddington CH, 1957, STRATEGY GENES DISCU; Wagner A, 1996, EVOLUTION, V50, P1008, DOI 10.2307/2410642; WAGNER A, 1994, P NATL ACAD SCI USA, V91, P4387, DOI 10.1073/pnas.91.10.4387; Wagner A., 2005, ROBUSTNESS EVOLVABIL; Wagner GP, 1996, EVOLUTION, V50, P967, DOI 10.2307/2410639; Wang YH, 2013, BIOINFORMATICS, V29, P126, DOI 10.1093/bioinformatics/btt234; Weinberg W., 1908, JAHRESH VEREIN VATER, V64, P368; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038	74	0	0	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1552-5007	1552-5015		J EXP ZOOL PART B	J. Exp. Zool. Part B	JAN	2015	324	1					1	12		10.1002/jez.b.22597		12	Evolutionary Biology; Developmental Biology; Zoology	Evolutionary Biology; Developmental Biology; Zoology	AW4RC	WOS:000346267300001	25504926	
J	Li, H; Li, XY; Ramanathan, M; Zhang, AD				Li, Hui; Li, Xiaoyi; Ramanathan, Murali; Zhang, Aidong			Prediction and Informative Risk Factor Selection of Bone Diseases	IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS			English	Article						Electronic health records (EHRs); risk factor analysis; integrated feature extraction; risk factor selection; disease memory; osteoporosis; bone fracture	OSTEOPOROTIC FRACTURES; BOLTZMANN MACHINES; NETWORKS; EPIDEMIOLOGY; MODELS; WOMEN; HIP; BMD	With the booming of healthcare industry and the overwhelming amount of electronic health records (EHRs) shared by healthcare institutions and practitioners, we take advantage of EHR data to develop an effective disease risk management model that not only models the progression of the disease, but also predicts the risk of the disease for early disease control or prevention. Existing models for answering these questions usually fall into two categories: the expert knowledge based model or the handcrafted feature set based model. To fully utilize the whole EHR data, we will build a framework to construct an integrated representation of features from all available risk factors in the EHR data and use these integrated features to effectively predict osteoporosis and bone fractures. We will also develop a framework for informative risk factor selection of bone diseases. A pair of models for two contrast cohorts (e.g., diseased patients versus non-diseased patients) will be established to discriminate their characteristics and find the most informative risk factors. Several empirical results on a real bone disease data set show that the proposed framework can successfully predict bone diseases and select informative risk factors that are beneficial and useful to guide clinical decisions.	[Li, Hui; Li, Xiaoyi; Zhang, Aidong] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA; [Ramanathan, Murali] SUNY Buffalo, Dept Pharmaceut Sci, Buffalo, NY 14260 USA	Li, H (reprint author), SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.	hli24@buffalo.edu; xiaoyili@buffalo.edu; murali@buffalo.edu; azhang@buffalo.edu					Ackley H., 1985, COGNITIVE SCI, V9, P147; Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; [Anonymous], 2012, WHAT BREAST CANC SUR; [Anonymous], 2012, PREVENTING FALLS REL; Bender Ralf, 2009, V471, P179, DOI 10.1007/978-1-59745-416-2_9; Bensen R, 2005, BMC MUSCULOSKEL DIS, V6, DOI 10.1186/1471-2474-6-47; Black DM, 2001, OSTEOPOROSIS INT, V12, P519, DOI 10.1007/s001980170072; Carreira-Perpinan M., 2005, P 10 INT WORKSH ART; Chawla N. V., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI DOI 10.1145/1007730.1007733; Cummings S.R., 1995, STUDY OSTEOPOROTIC F, V332, P767; Drummond C., 2003, P WORKSH LEARN IMB D, V11, P1; Erhan D., 2010, 1355 DIRO U MONTR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Faulkner KA, 2009, OSTEOPOROSIS INT, V20, P2025, DOI 10.1007/s00198-009-0909-y; Getoor L, 2004, ARTIF INTELL MED, V30, P233, DOI 10.1016/j.artmed.2003.11.003; Ha S. H., 2011, INT J KNOWL DISCOV B, V2, P60; Hafstein S. F., 2007, ALGORITHM CONSTRUCTI; Hinton G. E., 2009, SCHOLARPEDIA, V4, P5947; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Kanis J., 2012, OSTEOPOROSIS INT, V23, P1; Kanis JA, 2007, OSTEOPOROSIS INT, V18, P1033, DOI 10.1007/s00198-007-0343-y; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lemineur G., 2007, P IEEE 33 ANN C IND, P3039; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Li H., 2012, P ACM C BIOINF COMP, P361; Li J, 2008, QUAL RELIAB ENG INT, V24, P291, DOI 10.1002/qre.893; Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853; Moudani W., 2012, INT J INTELL INF TEC, V8, P26; Ordonez C, 2011, INTELL DATA ANAL, V15, P173, DOI 10.3233/IDA-2010-0462; RIIS BJ, 1995, AM J MED, V98, pS29, DOI 10.1016/S0002-9343(05)80042-7; Robbins JA, 2005, OSTEOPOROSIS INT, V16, P149, DOI 10.1007/s00198-004-1661-y; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Sirola J., 2010, J OSTEOPOROS, V2010; Storkey A. J., 1999, Neural Networks, V12, DOI 10.1016/S0893-6080(99)00038-6; Tang Y., 2010, P 27 ANN INT C MACH, P1055; Tang YC, 2012, PROC CVPR IEEE, P2264; Tranah GJ, 2010, J AM GERIATR SOC, V58, P282, DOI 10.1111/j.1532-5415.2009.02674.x; Wang W., 2006, P IEEE 27 ANN INT C, P886; WHO Scientific Group, 2003, WHO TECH REP SER; World Health Organization, 2004, WHO SCI GROUP ASS OS	41	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1545-5963	1557-9964		IEEE ACM T COMPUT BI	IEEE-ACM Trans. Comput. Biol. Bioinform.	JAN-FEB	2015	12	1					79	91		10.1109/TCBB.2014.2330579		13	Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability	Biochemistry & Molecular Biology; Computer Science; Mathematics	CB5MN	WOS:000349671700009		
J	Li, RF; Feng, FX; Wang, XJ; Lu, P; Li, BH				Li, Ruifan; Feng, Fangxiang; Wang, Xiaojie; Lu, Peng; Li, Bohan			Obtaining Cross Modal Similarity Metric with Deep Neural Architecture	MATHEMATICAL PROBLEMS IN ENGINEERING			English	Article							MULTIMODAL SIMILARITY; REPRESENTATIONS; NETWORKS	Analyzing complex system with multimodal data, such as image and text, has recently received tremendous attention. Modeling the relationship between different modalities is the key to address this problem. Motivated by recent successful applications of deep neural learning in unimodal data, in this paper, we propose a computational deep neural architecture, bimodal deep architecture (BDA) for measuring the similarity between different modalities. Our proposed BDA architecture has three closely related consecutive components. For image and text modalities, the first component can be constructed using some popular feature extraction methods in their individual modalities. The second component has two types of stacked restricted Boltzmann machines (RBMs). Specifically, for image modality a binary-binary RBM is stacked over a Gaussian-binary RBM; for text modality a binary-binary RBM is stacked over a replicated softmax RBM. In the third component, we come up with a variant autoencoder with a predefined loss function for discriminatively learning the regularity between different modalities. We show experimentally the effectiveness of our approach to the task of classifying image tags on public available datasets.	[Li, Ruifan; Feng, Fangxiang; Wang, Xiaojie; Lu, Peng; Li, Bohan] Beijing Univ Posts & Telecommun, Sch Comp, Beijing 100876, Peoples R China; [Li, Ruifan; Wang, Xiaojie] Minist Educ, Engn Res Ctr Informat Networks, Beijing 100876, Peoples R China	Li, RF (reprint author), Beijing Univ Posts & Telecommun, Sch Comp, Beijing 100876, Peoples R China.	rfli@bupt.edu.cn			National Natural Science Foundation of China [61273365, 61100120, 61202247, 61202248]; National High Technology Research and Development Program of China [2012AA011103]; Discipline Building Plan in 111 Base [B08004]; Fundamental Research Funds for the Central Universities [2013RC0304]	This work was partially supported by National Natural Science Foundation of China (nos. 61273365, 61100120, 61202247, and 61202248), National High Technology Research and Development Program of China (no. 2012AA011103), Discipline Building Plan in 111 Base (no. B08004), and Fundamental Research Funds for the Central Universities (no. 2013RC0304). The authors would also like to thank the editor and the anonymous reviewers for their useful comments and suggestions that allowed them to improve the final version of this paper.	Anderson T. W., 2003, INTRO MULTIVARIATE S, V3rd; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Blei D., 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460; Chen K, 2011, IEEE T NEURAL NETWOR, V22, P1744, DOI 10.1109/TNN.2011.2167240; Chopra S, 2005, PROC CVPR IEEE, P539; Coates A., 2011, P 28 INT C MACH LEAR, P921; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Feng F., 2014, P INT C MULT MM 14, P7; Goodfellow I. J., 2013, P 20 INT C NEUR INF, P117; Ham F. M., 2000, PRINCIPLES NEUROCOMP; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; HEIGOLD G, 2013, P 38 IEEE INT C AC S, P8619; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; JIA YQ, 2011, P ACM INT C MULT INF, P2407; Kim J., 2012, P COLING, P579; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; LeCun Y., 2006, PREDICTING STRUCTURE, P1; Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295; Li LX, 2014, P NATL ACAD SCI USA, V111, P8392, DOI 10.1073/pnas.1407083111; Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225; McFee B, 2011, J MACH LEARN RES, V12, P491; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Rasiwasia Nikhil, 2010, P INT C MULT, P251, DOI 10.1145/1873951.1873987; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R., 2009, P 23 ANN C NEUR INF, V22, P1607; Shinkareva SV, 2011, NEUROIMAGE, V54, P2418, DOI 10.1016/j.neuroimage.2010.10.042; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; von Ahn Luis, 2004, P SIGCHI C HUM FACT, V6, P319, DOI DOI 10.1145/985692.985733.ISBN; Welling M., 2004, ADV NEURAL INFORM PR, V17, P501; Xing E. P., 2005, P 21 C UNC ART INT U, P633; Yu D, 2013, IEEE T AUDIO SPEECH, V21, P388, DOI 10.1109/TASL.2012.2227738	38	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1024-123X	1563-5147		MATH PROBL ENG	Math. Probl. Eng.		2015									293176	10.1155/2015/293176		9	Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications	Engineering; Mathematics	CJ3YX	WOS:000355421800001		
S	Mobahi, H; Fisher, JW	Tai, XC	Bae, E; Chan, TF; Lysaker, M		Mobahi, Hossein; Fisher, John W., III	Tai, XC		Coarse-to-Fine Minimization of Some Common Nonconvexities	ENERGY MINIMIZATION METHODS IN COMPUTER VISION AND PATTERN RECOGNITION, EMMCVPR 2015	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR)	JAN 13-16, 2015	Hong Kong, PEOPLES R CHINA	Hong Kong Univ Sci & Technol, Hong Kong Univ Sci & Technol, Jockey Club Inst Adv Study		Continuation Method; Diffusion Equation; Nonconvex Optimization; Graduated Nonconvexity		The continuation method is a popular heuristic in computer vision for nonconvex optimization. The idea is to start from a simplified problem and gradually deform it to the actual problem while tracking the solution. There are many choices for how to map the nonconvex objective to some convex task. One popular principle for such construction is Gaussian smoothing of the objective function. This involves an integration which may be expensive to compute numerically. We argue that often simple tricks at the problem formulation plus some mild approximations can make the resulted task amenable to closed form integral.	[Mobahi, Hossein] Comp Sci & Artificial Intelligence Lab CSAIL, Cambridge, MA 02139 USA; MIT, Cambridge, MA 02139 USA	Mobahi, H (reprint author), Comp Sci & Artificial Intelligence Lab CSAIL, Cambridge, MA 02139 USA.	hmobahi@csail.mit.edu; fisher@csail.mit.edu					Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Bengio Y., 2009, INT C MACH LEARN ICM; Bengio Y., 2009, LEARNING DEEP ARCHIT; Besl P.J., 1992, IEEE T PATTERN ANAL, V14; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Blake A, 1987, VISUAL RECONSTRUCTIO; Brox T., 2005, THESIS SAARLAND U GE; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Curless B., 1996, ACM T GRAPHIC, V30, P303; Dabov F., 2007, IEEE T IMAGE PROCESS, V16, P2080; Dhillon P.S., 2012, AISTATS 2012, V15; Erhan D., 2009, J MACHINE LEARNING R, V5, P153; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gehler P., 2007, AISTATS 2007 MICR BR, P123; Goldluecke B, 2013, SIAM J IMAGING SCI, V6, P1626, DOI 10.1137/120862351; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kim M., 2010, GAUSSIAN PROCESSES M, P535; Krishnamurthy V., 1996, P SIGGRAPH, V96, P313; MacQueen J, 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Mairal J., 2009, ACM INT C P SERIES, V382, P87; Mobahi H., 2009, PICT COD S; Mobahi H, 2015, LECT NOTES COMPUT SC, V8932, P43, DOI 10.1007/978-3-319-14612-6_4; Mobahi H., 2012, P CVPR 2012; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nielsen M., 1993, P BRIT MACH VIS C, P60; Sindhwani V., 2006, INT C MACH LEARN 200, P841, DOI DOI 10.1145/1143844.1143950; Strekalovskiy E, 2014, SIAM J IMAGING SCI, V7, P294, DOI 10.1137/130908348; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Turk G., 1994, P SIGGRAPH, P311, DOI 10.1145/192161.192241; Vural E, 2013, SIAM J IMAGING SCI, V6, P2310, DOI 10.1137/130909858; Watson LT, 2001, SIAM J OPTIMIZ, V11, P761, DOI 10.1137/S105262349936121X	33	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-319-14612-6; 978-3-319-14611-9	LECT NOTES COMPUT SC			2015	8932						71	84				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BD0ON	WOS:000357502000006		
J	Morgan, DAE		Zelnio, E; Garber, FD		Morgan, David A. E.			Deep convolutional neural networks for ATR from SAR imagery	ALGORITHMS FOR SYNTHETIC APERTURE RADAR IMAGERY XXII	Proceedings of SPIE		English	Proceedings Paper	Conference on Algorithms for Synthetic Aperture Radar Imagery XXII	APR 23, 2015	Baltimore, MD	SPIE		Deep Learning; Convolutional Neural Networks; ATR; SAR; Machine Learning; Image Processing	CLASSIFICATION; RECOGNITION	Deep architectures for classification and representation learning have recently attracted significant attention within academia and industry, with many impressive results across a diverse collection of problem sets. In this work we consider the specific application of Automatic Target Recognition (ATR) using Synthetic Aperture Radar (SAR) data from the MSTAR public release data set. The classification performance achieved using a Deep Convolutional Neural Network (CNN) on this data set was found to be competitive with existing methods considered to be state-of-the-art. Unlike most existing algorithms, this approach can learn discriminative feature sets directly from training data instead of requiring pre-specification or pre-selection by a human designer. We show how this property can be exploited to efficiently adapt an existing classifier to recognise a previously unseen target and discuss potential practical applications.	BAE Syst, London, England	Morgan, DAE (reprint author), BAE Syst, London, England.	david.morgan15@baesystems.com					Arel I., 2010, COMPUTATIONAL INTELL, V5, P13; Bengio Y., 2013, PATTERN ANAL MACHINE, V35, P1798; Bishop C.M., 1995, NEURAL NETWORKS PATT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; J Cui, 2005, P SPIE, V5; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7; O'Sullivan J., 2001, AEROSPACE ELECT SYST, V37, P91; Patnaik R., 2007, P SOC PHOTO-OPT INS, V6574; Pham QH, 1999, P SOC PHOTO-OPT INS, V3721, P292, DOI 10.1117/12.357647; Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859; Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10; Schumacher R, 2005, RADAR CONF, P167; Singh R, 2002, P SOC PHOTO-OPT INS, V4727, P265, DOI 10.1117/12.478684; Srinivas U., 2014, AEROSPACE ELECT SYST, V50, P591; Sun Y., 2007, AEROSPACE ELECT SYST, V43, P112; Zhao Q, 2000, OPT ENG, V39, P1230, DOI 10.1117/1.602495; Zhao Q., 2001, AEROSPACE ELECT SYST, V37, P643	19	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-1-62841-591-9	PROC SPIE			2015	9475								94750E	10.1117/12.2176558		13	Engineering, Electrical & Electronic; Optics; Telecommunications	Engineering; Optics; Telecommunications	BC9TD	WOS:000356858900010		
J	Park, S; Bong, K; Shin, D; Lee, J; Choi, S; Yoo, HJ			IEEE	Park, Seongwook; Bong, Kyeongryeol; Shin, Dongjoo; Lee, Jinmook; Choi, Sungpill; Yoo, Hoi-Jun			A 1.93TOPS/W Scalable Deep Learning/Inference Processor with Tetra-Parallel MIMD Architecture for Big-Data Applications	2015 IEEE INTERNATIONAL SOLID-STATE CIRCUITS CONFERENCE DIGEST OF TECHNICAL PAPERS (ISSCC)	IEEE International Solid State Circuits Conference		English	Proceedings Paper	62nd IEEE International Solid-State Circuits Conference (ISSCC)	FEB 22-26, 2015	San Francisco, CA	Inst Elect & Elect Engineers					[Park, Seongwook; Bong, Kyeongryeol; Shin, Dongjoo; Lee, Jinmook; Choi, Sungpill; Yoo, Hoi-Jun] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea	Park, S (reprint author), Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.						Hamburg M., 2012, ANAL INTELS IVY BRID, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kim J. B., 2014, IEEE S VLSI CIRC, V57, P1, DOI 10.3345/kjp.2014.57.1.1; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Liao JG, 1998, J COMPUT GRAPH STAT, V7, P253, DOI 10.2307/1390703; Lu JJ, 2014, ISSCC DIG TECH PAP I, V57, P504; Pham PH, 2012, MIDWEST SYMP CIRCUIT, P1044	7	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0193-6530		978-1-4799-6224-2	ISSCC DIG TECH PAP I			2015	58						80	U105				3	Engineering, Electrical & Electronic	Engineering	BC7WN	WOS:000355252700027		
J	Qian, YL; Dong, J; Wang, W; Tan, TI		Alattar, AM; Memon, ND; Heitzenrater, CD		Qian, Yinlong; Dong, Jing; Wang, Wei; Tan, Tieniu			Deep learning for steganalysis via convolutional neural networks	MEDIA WATERMARKING, SECURITY, AND FORENSICS 2015	Proceedings of SPIE		English	Proceedings Paper	Conference on Media Watermarking, Security, and Forensics	FEB 09-11, 2015	San Francisco, CA	Soc Imaging Sci & Technol, SPIE		Steganalysis; Deep Learning; Feature Learning; Convolutional Neural Networks; Gaussian Nonlinearity		Current work on steganalysis for digital images is focused on the construction of complex handcrafted features. This paper proposes a new paradigm for steganalysis to learn features automatically via deep learning models. We novelly propose a customized Convolutional Neural Network for steganalysis. The proposed model can capture the complex dependencies that are useful for steganalysis. Compared with existing schemes, this model can automatically learn feature representations with several convolutional layers. The feature extraction and classification steps are unified under a single architecture, which means the guidance of classification can be used during the feature extraction step. We demonstrate the effectiveness of the proposed model on three state-of-the-art spatial domain steganographic algorithms - HUGO, WOW, and S-UNIWARD. Compared to the Spatial Rich Model (SRM), our model achieves comparable performance on BOSSbase and the realistic and large Image Net database.	[Qian, Yinlong] Univ Sci & Technol China, Dept Automat, Hefei, Anhui, Peoples R China; [Qian, Yinlong; Dong, Jing; Wang, Wei; Tan, Tieniu] Chinese Acad Sci, Inst Automat, Ctr Res Intelligent Percept & Comp, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China	Dong, J (reprint author), Chinese Acad Sci, Inst Automat, Ctr Res Intelligent Percept & Comp, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.	ylqian@mail.ustc.edu.cn; jdong@nlpr.ia.ac.cn; wwang@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn					Bas P., 2011, LECT NOTES COMPUTER, V6958, P59; Bishop Christopher M., 2006, PATTERN RECOGNITION, V1; Boureau Y.-L., 2010, P 27 INT C MACH LEAR, P111; Browne M, 2003, LECT NOTES ARTIF INT, V2903, P641; Ciresan D., 2011, P 22 INT JOINT C ART, V2, P1237; Collobert R., 2008, ICML, V307, P160, DOI DOI 10.1145/1390156.1390177; Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Holub V, 2012, 2012 IEEE INTERNATIONAL WORKSHOP ON INFORMATION FORENSICS AND SECURITY (WIFS), P234, DOI 10.1109/WIFS.2012.6412655; Holub V., 2013, IS T SPIE ELECT IMAG; Holub V., 2013, P 1 ACM WORKSH INF H, P59; Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1097; Larochelle H, 2009, J MACH LEARN RES, V10, P1; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Nair V., 2010, P 27 INT C MACH LEAR, P807; Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842; PEVNY T, 2010, INF HID 12 INT WORKS, V6387, P161, DOI 10.1007/978-3-642-16435-4_13; Ranzato M., 2007, COMP VIS PATT REC IE, V5, P1; Salakhutdinov R., 2009, ARTIF INTELL, V5, P448; Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, DOI 10.1007/978-3-642-36373-3_5	24	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-1-62841-499-8	PROC SPIE			2015	9409								94090J	10.1117/12.2083479		10	Computer Science, Theory & Methods; Optics; Imaging Science & Photographic Technology	Computer Science; Optics; Imaging Science & Photographic Technology	BC6OR	WOS:000354264600016		
J	Recchia, G; Sahlgren, M; Kanerva, P; Jones, MN				Recchia, Gabriel; Sahlgren, Magnus; Kanerva, Pentti; Jones, Michael N.			Encoding Sequential Information in Semantic Space Models: Comparing Holographic Reduced Representation and Random Permutation	COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE			English	Article							SIMPLE RECURRENT NETWORKS; LEXICAL COOCCURRENCE; ASSOCIATIVE INFORMATION; DISTRIBUTIONAL MODELS; GRAMMATICAL STRUCTURE; TEMPORAL CONTEXT; NEURAL-NETWORKS; WORD; LANGUAGE; MEMORY	Circular convolution and random permutation have each been proposed as neurally plausible binding operators capable of encoding sequential information in semantic memory. We perform several controlled comparisons of circular convolution and random permutation as means of encoding paired associates as well as encoding sequential information. Random permutations outperformed convolution with respect to the number of paired associates that can be reliably stored in a single memory trace. Performance was equal on semantic tasks when using a small corpus, but random permutations were ultimately capable of achieving superior performance due to their higher scalability to large corpora. Finally, "noisy" permutations in which units are mapped to other units arbitrarily (no one-to-one mapping) perform nearly as well as true permutations. These findings increase the neurological plausibility of random permutations and highlight their utility in vector space models of semantics.	[Recchia, Gabriel] Univ Cambridge, Cambridge CB2 1TN, England; [Sahlgren, Magnus] Swedish Inst Comp Sci, S-16429 Kista, Sweden; [Kanerva, Pentti] Univ Calif Berkeley, Redwood Ctr Theoret Neurosci, Berkeley, CA 94720 USA; [Jones, Michael N.] Indiana Univ, Bloomington, IN 47405 USA	Jones, MN (reprint author), Indiana Univ, Bloomington, IN 47405 USA.	jonesmn@indiana.edu					Andrews M, 2009, PSYCHOL REV, V116, P463, DOI 10.1037/a0016261; Andrews M, 2010, TOP COGN SCI, V2, P101, DOI 10.1111/j.1756-8765.2009.01074.x; Baroni M., 2008, ITALIAN J LINGUISTIC, V20, P53; Bengio Y., 2013, LECT NOTES COMPUTER, V7978, P1; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BORSELLI.A, 1973, KYBERNETIK, V13, P113, DOI 10.1007/BF00288790; Brand M, 2006, LINEAR ALGEBRA APPL, V415, P20, DOI 10.1016/j.laa.2005.07.021; Buchanan L, 1996, BRAIN COGNITION, V32, P111; Buchanan L, 2001, PSYCHON B REV, V8, P531, DOI 10.3758/BF03196189; Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020; Burgess C, 1998, BEHAV RES METH INS C, V30, P188, DOI 10.3758/BF03200643; Burgess C., 2000, COGNITIVE DYNAMICS C, P117; Choo F., 2010, P 32 ANN C COGN SCI, P2188; Collobert R., 2008, P 25 INT C MACH LEAR, V307, P160; Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009; Cox GE, 2011, BEHAV RES METHODS, V43, P602, DOI 10.3758/s13428-011-0125-5; Cuppini C, 2009, BIOSYSTEMS, V96, P195, DOI 10.1016/j.biosystems.2009.01.006; de Vega M., 2008, SYMBOLS EMBODIMENT D; Dennis S, 2005, COGNITIVE SCI, V29, P145, DOI 10.1207/s15516709cog0000_9; DEVALOIS KK, 1979, J PHYSIOL-LONDON, V291, P483; Durda K, 2009, BEHAV RES METHODS, V41, P1210, DOI 10.3758/BRM.41.4.1210; Durda K, 2008, BEHAV RES METHODS, V40, P705, DOI 10.3758/BRM.40.3.705; EICH JM, 1982, PSYCHOL REV, V89, P627, DOI 10.1037//0033-295X.89.6.627; EICH JM, 1985, PSYCHOL REV, V92, P1; Eliasmith C., 2003, NEURAL ENG COMPUTATI; Eliasmith C, 2012, SCIENCE, V338, P1202, DOI 10.1126/science.1225266; Eliasmith C., 2005, P 27 ANN C COGN SCI, P624; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844; Elman JL, 2009, COGNITIVE SCI, V33, P547, DOI 10.1111/j.1551-6709.2009.01023.x; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110; Firth J. R., 1957, STUDIES LINGUISTIC A, P1; Foldiak P, 2008, SCHOLARPEDIA, V3, P2984; FOSS DJ, 1982, COGNITIVE PSYCHOL, V14, P590, DOI 10.1016/0010-0285(82)90020-2; Gardenfors P, 2014, GEOMETRY OF MEANING: SEMANTICS BASED ON CONCEPTUAL SPACES, P1; Garson J., 2012, STANDFORD ENCY PHILO; Gazzaniga MS, 2002, COGNITIVE NEUROSCIEN, V2nd; Glenberg AM, 2000, J MEM LANG, V43, P379, DOI 10.1006/jmla.2000.2714; Gomez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4; Gorrell G., 2006, P 11 C EUR CHAPT ASS, P97; Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211; Griffiths TL, 2005, ADV NEURAL INFORM PR, V17, P537; Hare M, 2003, J MEM LANG, V48, P281, DOI 10.1016/S0749-596X(02)00516-8; Hare M, 2009, COGNITION, V111, P151, DOI 10.1016/j.cognition.2009.01.009; Hare M, 2004, LANG COGNITIVE PROC, V19, P181, DOI 10.1080/0169090344000152; Harris Z., 1970, DISTRIBUTIONAL STRUC; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Howard M. W., 2004, P 37 ANN M SOC MATH; Howard MW, 2002, J MATH PSYCHOL, V46, P269, DOI 10.1006/jmps.2001.1388; Howard MW, 2011, TOP COGN SCI, V3, P48, DOI 10.1111/j.1756-8765.2010.01112.x; Jackendoff R., 2002, FDN LANGUAGE BRAIN M; Johns B. T., 2009, P 31 ANN M COGN SCI, P2795; Johns B. T., 2008, P 30 COGN SCI SOC M, P279; Jones LL, 2010, J EXP PSYCHOL LEARN, V36, P135, DOI 10.1037/a0017517; Jones M. N., 2005, THESIS QUENNS U; Jones M. N., 2010, P 32 ANN M COGN SCI, P877; Jones M. N., 2015, OXFORD HDB MATH COMP; Jones MN, 2007, PSYCHOL REV, V114, P1, DOI 10.1037/0033-295X.114.1.1; Jones MN, 2006, J MEM LANG, V55, P534, DOI 10.1016/j.jml.2006.07.003; Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8; Kanerva P., 1996, LECT NOTES COMPUTER, V1112, P869; Kanerva P, 1988, SPARSE DISTRIBUTED M; Kanerva P., 2000, P 22 ANN C COGN SCI, P103; Karlgren J., 2001, FDN REAL WORLD INTEL; Kintsch W, 2005, DISCOURSE PROCESS, V39, P125; Kintsch W, 2011, TOP COGN SCI, V3, P346, DOI 10.1111/j.1756-8765.2010.01107.x; Kwantes PJ, 2005, PSYCHON B REV, V12, P703, DOI 10.3758/BF03196761; Landauer T., 2006, HDB LATENT SEMANTIC; Landauer T. K., 2013, SCHOLARPEDIA, V3, P4356; Landauer TK, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P412; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Legate J. A., 2013, RICH LANGUAGES POOR, P68; Licklider J. C. R., 1959, PSYCHOL STUDY SCI, V1, P41; Liepa P., 1977, MODELS CONTENT ADDRE; Louwerse M, 2011, COGNITIVE SCI, V35, P381, DOI 10.1111/j.1551-6709.2010.01157.x; Louwerse MM, 2011, TOP COGN SCI, V3, P273, DOI 10.1111/j.1756-8765.2010.01106.x; Lowe W., 2001, P 23 ANN C COGN SCI, P576; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766; MACDONALD MC, 1993, J MEM LANG, V32, P692, DOI 10.1006/jmla.1993.1035; MacDonald MC, 1997, LANG COGNITIVE PROC, V12, P121, DOI 10.1080/016909697386826; Martens J., 2011, P 28 INT C MACH LEAR, P1033; McKoon G, 2003, PSYCHOL REV, V110, P490, DOI 10.1037/0033-295X.110.3.490; McRae K, 2005, MEM COGNITION, V33, P1174, DOI 10.3758/BF03193221; McRae K, 1997, J EXP PSYCHOL GEN, V126, P99, DOI 10.1037/0096-3445.126.2.99; Mikolov T., ADVANCES; MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936; Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x; Mnih A., 2009, P NIPS, P1081; Murakoshi K, 2007, BIOSYSTEMS, V90, P903, DOI 10.1016/j.biosystems.2007.06.001; MURDOCK BB, 1992, J MATH PSYCHOL, V36, P68, DOI 10.1016/0022-2496(92)90053-A; MURDOCK BB, 1982, PSYCHOL REV, V89, P609, DOI 10.1037/0033-295X.89.6.609; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Onnis L, 2008, COGNITIVE SCI, V32, P184, DOI 10.1080/03640210701703691; OSEAGHDHA PG, 1989, J EXP PSYCHOL LEARN, V15, P73; Perfetti CA, 1998, DISCOURSE PROCESS, V25, P363; Plate T.A., 2003, HOLOGRAPHIC REDUCED; Plate TA, 2000, NETWORK-COMP NEURAL, V11, P321, DOI 10.1088/0954-898X/11/4/305; PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968; Pribram K. H., 1986, J NEUROLINGUIST, V2, P349, DOI 10.1016/S0911-6044(86)80021-5; PRIBRAM K H, 1973, P293; Rao V. A., 2008, ADV NEURAL INFORM PR, V20, P1193; Rasmussen D, 2011, TOP COGN SCI, V3, P140, DOI 10.1111/j.1756-8765.2010.01127.x; Recchia G, 2009, BEHAV RES METHODS, V41, P647, DOI 10.3758/BRM.41.3.647; Recchia G., 2010, P 32 ANN COGN SCI SO, P865; Reichardt W. E., 1978, CEREBRAL CORRELATES; Resnik P., 1995, P 14 INT JOINT C ART, P448; Riordan B, 2011, TOP COGN SCI, V3, P303, DOI 10.1111/j.1756-8765.2010.01111.x; Riordan B., 2007, P 29 C COGN SCI SOC, P599; Risley T. R., 2006, EARLY INTERVENTION P, V4, P83; Rogers T. T., 2004, SEMANTIC COGNITION P; Rohde D., 2006, P ANN M COGN SCI SOC; RUBENSTE.H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657; Rubin T. N., 2014, P 35 ANN C COGN SCI; Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243; Sahlgren M., 2006, THESIS STOCKHOLM U; Sahlgren M., 2008, P 30 ANN C COGN SCI, P1300; Sahlgren M., 2005, 7 INT C TERM KNOWL E; Schutze H., 1992, DIMENTIONS MEANING; SERVANSCHREIBER D, 1991, MACH LEARN, V7, P161, DOI 10.1007/BF00114843; Shaoul C, 2010, BEHAV RES METHODS, V42, P393, DOI 10.3758/BRM.42.2.393; SHEPARD RN, 1990, PSYCHOL REV, V97, P579, DOI 10.1037//0033-295X.97.4.579; Siakaluk P. D., 2003, P 13 ANN M CAN SOC B; Simon H. A., 1996, SCI ARTIFICIAL, V2nd, P183; Song D., 2001, P 24 ANN INT C RES D, P327, DOI 10.1145/383952.384017; Stewart T. C., 2010, P 10 INT C COGN MOD, P235; Steyvers M, 2010, ACTA PSYCHOL, V133, P234, DOI 10.1016/j.actpsy.2009.10.010; STJOHN MF, 1990, ARTIF INTELL, V46, P217, DOI 10.1016/0004-3702(90)90008-N; Sutherland J. G., 1990, International Journal of Neural Systems, V1, DOI 10.1142/S0129065790000163; Sutskever I., 2011, P 28 INT C MACH LEAR, P1017; Sutskever I, 2013, P 30 INT C MACH LEAR, P1139; TARABAN R, 1988, J MEM LANG, V27, P597, DOI 10.1016/0749-596X(88)90011-3; Tong MH, 2007, NEURAL NETWORKS, V20, P424, DOI 10.1016/j.neunet.2007.04.013; Utsumi A., 2010, P 32 ANN M COGN SCI, P1034; van Leijenhorst DC, 2005, INFORM SCIENCES, V170, P263, DOI 10.1016/j.ins.2004.03.006; Veale R., 2012, P 34 ANN C COGN SCI, P1072; Vigliocco G, 2004, COGNITIVE PSYCHOL, V48, P422, DOI 10.1016/j.cogpsych.2003.09.001; Warren T, 2008, J EXP PSYCHOL LEARN, V34, P1001, DOI 10.1037/0278-7393.34.4.1001; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Weston J., 2012, LECT NOTES COMPUTER, V7700, P639; Willits J. A., 2007, P 29 ANN C COGN SCI, P707; Yamazaki T, 2007, NEURAL NETWORKS, V20, P290, DOI 10.1016/j.neunet.2007.04.004	146	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1687-5265	1687-5273		COMPUT INTEL NEUROSC	Comput. Intell. Neurosci.		2015									986574	10.1155/2015/986574		18	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	CG2ZB	WOS:000353143900001		
J	Salakhutdinov, R		Fienberg, SE		Salakhutdinov, Ruslan			Learning Deep Generative Models	ANNUAL REVIEW OF STATISTICS AND ITS APPLICATION, VOL 2	Annual Review of Statistics and Its Application		English	Article; Book Chapter						deep learning; deep belief networks; deep Boltzmann machines; graphical models	NEURAL-NETWORKS; BOLTZMANN MACHINES; RECOGNITION	Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many artificial intelligence-related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. In this article, we review several popular deep learning models, including deep belief networks and deep Boltzmann machines. We show that (a) these deep generative models, which contain many layers of latent variables and millions of parameters, can be learned efficiently, and (b) the learned high-level feature representations can be successfully applied in many application domains, including visual object recognition, information retrieval, classification, and regression tasks.	[Salakhutdinov, Ruslan] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Salakhutdinov, Ruslan] Univ Toronto, Dept Stat Sci, Toronto, ON M5S 3G4, Canada	Salakhutdinov, R (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.	rsalakhu@cs.toronto.edu			CIFAR; Google; Samsung; ONR [N00014-14-1-0232]	This research was supported by CIFAR, Google, Samsung, and ONR Grant N00014-14-1-0232.	Bengio Y., 2009, TRENDS MACH LEARN, V2, P1; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Y., 2007, LARGE SCALE KERNEL M, V34; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blei DM, 2014, ANNU REV STAT APPL, V1, P203, DOI 10.1146/annurev-statistics-022513-115657; Collobert R., 2008, P 25 INT C MACH LEAR, V307, P160; Dahl GE, 2014, ARXIV14061231STATML; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2002, NEURAL COMPUT, V14, P1711; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Huiskes MJ, 2008, P 16 INT C MULT INF; Krizhevsky A., 2012, ADV NEURAL INFORM PR, V25, P1106; Larochelle H, 2009, J MACH LEARN RES, V10, P1; LeCun Y, 2004, PROC CVPR IEEE, P97; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Lenz I, 2013, P ROB SCI SYST 9 BER; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nair V, 2009, ADV NEURAL INFORM PR, V21, P1145; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Ranzato M., 2008, ADV NEURAL INFORM PR, V20, P1185; Ranzato M., 2007, P IEEE C COMP VIS PA, V5, P1, DOI DOI 10.1109/CVPR.2007.383157; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov R., 2009, ADV NEURAL INFORM PR, V22, P1607; Salakhutdinov R, 2007, P ART INT STAT, V2, P412; Salakhutdinov R., 2009, P INT C ART INT STAT, V5, P448; Salakhutdinov RR., 2008, 2008002 UTML TR DEP; Salakhutdinov RR, 2013, P 29 C UNC ART INT B, P616; Salakhutdinov RR, 2008, P 25 INT C MACH LEAR, P872, DOI 10.1145/1390156.1390266; Salakhutdinov RR, 2008, ADV NEURAL INFORM PR, V20, P1249; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; SOCHER R, 2011, ADV NEURAL INFORM PR, V24, P801; Srivastava N, 2014, J MACH LEARN RES, V15, P2949; Sutskever I, 2013, P 30 INT C MACH LEAR, P1139; Taylor G. W., 2006, ADV NEURAL INF PROCE, V19, P1345; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Torralba A, 2008, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2008.4587633; Uria B, 2014, P 31 INT C MACH LEAR, P467; Vincent P., 2008, P 25 INT C MACH LEAR, V307, P1096; Wang T, 2012, INT C PATT RECOG, P3304; Welling M., 2005, ADV NEURAL INFORM PR, V17, P1481; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI 10.1080/17442509908834179; Yuille AL, 2004, ADV NEURAL INFORM PR, V17, P1593	54	0	0	ANNUAL REVIEWS	PALO ALTO	4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA	2326-8298			ANNU REV STAT APPL			2015	2						361	385		10.1146/annurev-statistics-010814-020120		25	Mathematics, Interdisciplinary Applications; Statistics & Probability	Mathematics	BC9NA	WOS:000356627500016		
J	Sun, X; Zhang, TD; Chai, YT; Liu, Y				Sun, Xiao; Zhang, Tongda; Chai, Yueting; Liu, Yi			Localized Ambient Solidity Separation Algorithm Based Computer User Segmentation	COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE			English	Article							CONSUMER SEGMENTATION; LINK	Most of popular clustering methods typically have some strong assumptions of the dataset. For example, the k-means implicitly assumes that all clusters come from spherical Gaussian distributions which have different means but the same covariance. However, when dealing with datasets that have diverse distribution shapes or high dimensionality, these assumptions might not be valid anymore. In order to overcome this weakness, we proposed a new clustering algorithm named localized ambient solidity separation (LASS) algorithm, using a new isolation criterion called centroid distance. Compared with other density based isolation criteria, our proposed centroid distance isolation criterion addresses the problem caused by high dimensionality and varying density. The experiment on a designed two-dimensional benchmark dataset shows that our proposed LASS algorithm not only inherits the advantage of the original dissimilarity increments clustering method to separate naturally isolated clusters but also can identify the clusters which are adjacent, overlapping, and under background noise. Finally, we compared our LASS algorithm with the dissimilarity increments clustering method on a massive computer user dataset with over two million records that contains demographic and behaviors information. The results show that LASS algorithm works extremely well on this computer user dataset and can gain more knowledge from it.	[Sun, Xiao; Chai, Yueting; Liu, Yi] Tsinghua Univ, Natl Engn Lab E Commerce Technol, Beijing 100084, Peoples R China; [Sun, Xiao] DNSLAB, China Internet Network Informat Ctr, Beijing 100190, Peoples R China; [Zhang, Tongda] Stanford Univ, Elect Engn Dept, Stanford, CA 94305 USA	Sun, X (reprint author), Tsinghua Univ, Natl Engn Lab E Commerce Technol, Beijing 100084, Peoples R China.	sunx11@mails.tsinghua.edu.cn					Bhatnagar A, 2004, J BUS RES, V57, P758, DOI 10.1016/S0148-2963(02)00357-0; Bichis-Lupas M., 2001, Journal of Park and Recreation Administration, V19, P78; Bosnjak Z., 2011, P 6 IEEE INT S APPL, P379; Chapelle O., 2006, SEMISUPERVISED LEARN; de Souto MCP, 2008, IEEE IJCNN, P2792, DOI 10.1109/IJCNN.2008.4634191; Diday E., 1980, COMMUNICATION CYBERN, V10, P47; Fred ALN, 2003, IEEE T PATTERN ANAL, V25, P944, DOI 10.1109/TPAMI.2003.1217600; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsieh TC, 2011, COMM COM INF SC, V171, P197; HUBERT L, 1974, J AM STAT ASSOC, V69, P698, DOI 10.2307/2286004; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jakkula V, 2008, METHOD INFORM MED, V47, P70, DOI 10.3414/ME9103; Lorenzo-Romero C, 2012, SOC BEHAV PERSONAL, V40, P401, DOI 10.2224/sbp.2012.40.3.401; Macharia J, 2013, BRIT FOOD J, V115, P1313, DOI 10.1108/BFJ-09-2011-0215; Martinez-Garcia E, 2010, J AIR TRANSP MANAG, V16, P234, DOI 10.1016/j.jairtraman.2010.01.003; Miller E., 2008, NATURE, V455, P1; Musen M. A., 2014, BIOMEDICAL INFORM, P643; Nassar S., 2004, P 2004 ACM SIGMOD IN, P467, DOI 10.1145/1007568.1007621; Onwezen MC, 2012, FOOD QUAL PREFER, V24, P276, DOI 10.1016/j.foodqual.2011.11.002; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; Tang QY, 2013, INSECT SCI, V20, P254, DOI 10.1111/j.1744-7917.2012.01519.x; Tasdemir Kadim, 2012, Pattern Recognition, V45, DOI 10.1016/j.patcog.2012.02.012; Wedel M., 2000, MARKET SEGMENTATION; Westad F, 2004, FOOD QUAL PREFER, V15, P681, DOI 10.1016/j.foodqual.2004.04.004; Witten I. H., 2005, DATA MINING PRACTICA; Wu RS, 2011, ELECTRON COMMER R A, V10, P331, DOI 10.1016/j.elerap.2010.11.002	27	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1687-5265	1687-5273		COMPUT INTEL NEUROSC	Comput. Intell. Neurosci.		2015									829201	10.1155/2015/829201		16	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	CM6IP	WOS:000357792100001		
J	Tamilselvan, P; Wang, PF				Tamilselvan, Prasanna; Wang, Pingfeng			A tri-fold hybrid classification approach for diagnostics with unexampled faulty states	MECHANICAL SYSTEMS AND SIGNAL PROCESSING			English	Article						Fault diagnostics; Health monitoring; Unexampled faulty	ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; SELF-ORGANIZING MAP; OUTLIER DETECTION; POWER TRANSFORMERS; NOVELTY DETECTION; IN-SERVICE; PROPAGATION; MULTICLASS; ALGORITHMS	System health diagnostics provides diversified benefits such as improved safety, improved reliability and reduced costs for the operation and maintenance of engineered systems. Successful health diagnostics requires the knowledge of system failures. However, with an increasing system complexity, it is extraordinarily difficult to have a well-tested system so that all potential faulty states can be realized and studied at product testing stage. Thus, real time health diagnostics requires automatic detection of unexampled system faulty states based upon sensory data to avoid sudden catastrophic system failures. This paper presents a trifold hybrid classification (THC) approach for structural health diagnosis with unexampled health states (UHS), which comprises of preliminary VHS identification using a new thresholded Mahalanobis distance (TMD) classifier, VHS diagnostics using a two-class support vector machine (SVM) classifier, and exampled health states diagnostics using a multi-class SVM classifier. The proposed THC approach, which takes the advantages of both TMD and SVM-based classification techniques, is able to identify and isolate the unexampled faulty states through interactively detecting the deviation of sensory data from the exampled health states and forming new ones autonomously. The proposed THC approach is further extended to a generic framework for health diagnostics problems with unexampled faulty states and demonstrated with health diagnostics case studies for power transformers and rolling bearings. (C) 2014 Elsevier Ltd. All rights reserved.	[Tamilselvan, Prasanna; Wang, Pingfeng] Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA	Wang, PF (reprint author), Wichita State Univ, Dept Ind & Mfg Engn, Wichita, KS 67208 USA.	pxtamilselvan@wichita.edu; pingfeng.wang@wichita.edu	Wang, Pingfeng/D-3764-2011	Wang, Pingfeng/0000-0002-2160-4917	National Science Foundation [CMMI-1200597]; Wichita State University through the University Research Creative Project Awards (UCRA)	This research is partially supported by the National Science Foundation (CMMI-1200597) and Wichita State University through the University Research Creative Project Awards (UCRA).	Agarwal D., 2006, KNOWL INF SYST, V11, P29, DOI 10.1007/s10115-006-0036-4; ALGUINDIGUE IE, 1993, IEEE T IND ELECTRON, V40, P209, DOI 10.1109/41.222642; ALLAN D, 1992, IEEE T ELECTR INSUL, V27, P578, DOI 10.1109/14.142722; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Augusteijn MF, 2002, INT J REMOTE SENS, V23, P2891, DOI 10.1080/01431160110055804; Barnett V., 1994, OUTLIERS STAT DATA, V3rd; Bianco AM, 2001, J FORECASTING, V20, P565, DOI 10.1002/for.768; Booth C, 1998, NEUROCOMPUTING, V23, P97, DOI 10.1016/S0925-2312(98)00064-2; Breikin T., 2005, P 16 IFAC WORLD C; Chandola Varun, 2009, ACM COMPUT SURVEYS, V41; Dasgupta D, 2000, IEEE SYS MAN CYBERN, P125, DOI 10.1109/ICSMC.2000.884976; Dekker R, 1996, RELIAB ENG SYST SAFE, V51, P229, DOI 10.1016/0951-8320(95)00076-3; Ebeling C. E., 1997, INTRO RELIABILITY MA; Ge M, 2004, MECH SYST SIGNAL PR, V18, P143, DOI 10.1016/S0888-3270(03)00071-2; Geramifard O., 2010, P IEEE INT C CONTR A, P1618; Gonzalez F. A., 2003, Genetic Programming and Evolvable Machines, V4, DOI 10.1023/A:1026195112518; Hautamaki V, 2004, INT C PATT RECOG, P430, DOI 10.1109/ICPR.2004.1334558; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1007/s10462-004-4304-y; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang RQ, 2007, MECH SYST SIGNAL PR, V21, P193, DOI 10.1016/j.ymssp.2005.11.008; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Leibfried T, 1998, IEEE COMPUT APPL POW, V11, P36, DOI 10.1109/67.694934; Li Y, 1999, TRIBOL T, V42, P385, DOI 10.1080/10402009908982232; Licht T., 2003, AM SOC MECH ENG DYN, V71, P1059; Lu W., 2010, P PROGN HLTH MAN C P; MARTIN KF, 1994, INT J MACH TOOL MANU, V34, P527, DOI 10.1016/0890-6955(94)90083-3; Mathur A, 2008, IEEE GEOSCI REMOTE S, V5, P241, DOI 10.1109/LGRS.2008.915597; Pawar PM, 2007, MECH SYST SIGNAL PR, V21, P2212, DOI 10.1016/j.ymssp.2006.09.006; Pecht M., 2008, PROGNOSTICS HLTH MAN; Qiu H, 2003, ADV ENG INFORM, V17, P127, DOI 10.1016/j.aei.2004.08.001; Rivera HL, 2000, IEEE J SEL TOP QUANT, V6, P788, DOI 10.1109/2944.892619; Saimurugan M., 2010, EXPERT SYST APPL, P3819; Samanta B, 2004, MECH SYST SIGNAL PR, V18, P625, DOI 10.1016/S0888-3270(03)00020-7; Saxena A, 2007, APPL SOFT COMPUT, V7, P441, DOI 10.1016/j.asoc.2005.10.001; Sotiris VA, 2010, IEEE T RELIAB, V59, P277, DOI 10.1109/TR.2010.2048740; Srinivasan S., 2007, J ELECT COMPUT ENG, V6, P62; Tamilselvan P., 2011, P ASME 2011 INT DES; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Wang P., 2010, ANN C PROGN HLTH MAN; Wong MLD, 2006, MECH SYST SIGNAL PR, V20, P593, DOI 10.1016/j.ymssp.2005.01.008; Yang BS, 2005, MECH SYST SIGNAL PR, V19, P371, DOI 10.1016/j.myssp.2004.06.002; Yang WX, 2008, IEEE ASME INT C ADV, P1296; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhang KJ, 2007, LECT NOTES ARTIF INT, V4632, P158	45	0	0	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0888-3270			MECH SYST SIGNAL PR	Mech. Syst. Signal Proc.	JAN	2015	50-51						437	455		10.1016/j.ymssp.2014.05.016		19	Engineering, Mechanical	Engineering	AR6IK	WOS:000343687200029		
J	Wu, HJ; Zhang, XW; Zhang, LL; Zou, X		Yang, L; Zhao, M		Wu Haijia; Zhang Xiongwei; Zhang Liangliang; Zou Xia			Speech Separation based on Deep Belief Network	PROCEEDINGS OF THE 2015 INTERNATIONAL INDUSTRIAL INFORMATICS AND COMPUTER ENGINEERING CONFERENCE	ACSR-Advances in Comptuer Science Research		English	Proceedings Paper	International Industrial Informatics and Computer Engineering Conference (IIICEC)	JAN 10-11, 2015	Xian, PEOPLES R CHINA			speech separation; deep learning; deep belief network; restricted Boltzmann machine; autoencoder	SIGNAL; SEGREGATION; ENHANCEMENT	Thanks to its hierarchical and generative nature, Deep Belief Network (DBN) is effective to feature representation and extraction in signal processing. In this paper, DBN is investigated and implemented to monaural speech separation. Firstly, two separate DBNs are trained to extract features from mixed noisy signals and target clean speech respectively. Subsequently, the two types of extracted features are associated together by training a BP neural network to obtain a mapping from the features of mixed signals to the features of target speech. Finally, by performing DBN and the above mapping neural network, target speech can be estimated from the input mixed signals. Experiments are conducted on different kinds of mixed signals including female/male speech mixtures, human-speech/Gaussian-noise audio mixtures, and human-speech/music audio mixtures. The PESQ scores of the extracted speech are 3.32, 2.59, and 3.42 respectively, which illustrates that the model performs well on speech separation tasks, especially on the mixed signals where the inference signals have obvious spectral structures.	[Wu Haijia; Zhang Xiongwei; Zhang Liangliang; Zou Xia] PLA Univ Sci & Technol, Coll Command Informat & Syst, Nanjing 210007, Jiangsu, Peoples R China	Wu, HJ (reprint author), PLA Univ Sci & Technol, Coll Command Informat & Syst, Nanjing 210007, Jiangsu, Peoples R China.	wu_haijia@163.com; xwzhang9898@163.com; vermouthlove@hotmail.com; zlc1997@163.com					Bengio Y, 2011, LECT NOTES ARTIF INT, V6926, P1, DOI 10.1007/978-3-642-24477-3_1; BROWN GJ, 1994, COMPUT SPEECH LANG, V8, P297, DOI 10.1006/csla.1994.1016; Deng L., 2010, ISCA CHIB JAP, P9; EPHRAIM Y, 1995, IEEE T SPEECH AUDI P, V3, P251, DOI 10.1109/89.397090; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu GN, 2008, J ACOUST SOC AM, V124, P1306, DOI 10.1121/1.2939132; Hu Y., 2006, P INTERSPEECH PHIL P; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Keyvanrad M. A., 2014, INT C LEARN REPR ICL, P4; Nesta F, 2011, IEEE T AUDIO SPEECH, V19, P624, DOI 10.1109/TASL.2010.2053027; Virtanen Tuomas, 2007, IEEE T AUDIO SPEECH, V15, P1; Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240; Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038; Zhu XL, 2007, IEEE T AUDIO SPEECH, V15, P1645, DOI 10.1109/TASL.2007.899236	14	0	0	ATLANTIS PRESS	PARIS	29 AVENUE LAVMIERE, PARIS, 75019, FRANCE	2352-538X		978-94-62520-54-7	ACSR ADV COMPUT			2015							1486	1493				8	Automation & Control Systems; Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Automation & Control Systems; Computer Science	BC4TW	WOS:000352968400330		
J	Xu, Y; Du, J; Dai, LR; Lee, CH				Xu, Yong; Du, Jun; Dai, Li-Rong; Lee, Chin-Hui			A Regression Approach to Speech Enhancement Based on Deep Neural Networks	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep neural networks (DNNs); dropout; global variance equalization; noise aware training; noise reduction; nonstationary noise; speech enhancement	SPECTRAL AMPLITUDE ESTIMATOR; NOISE-ESTIMATION; RECOGNITION; ALGORITHM; ENVIRONMENTS; SUPPRESSION; SEPARATION	In contrast to the conventional minimum mean square error (MMSE)-based noise reduction techniques, we propose a supervised method to enhance speech by means of finding a mapping function between noisy and clean speech signals based on deep neural networks (DNNs). In order to be able to handle a wide range of additive noises in real-world situations, a large training set that encompasses many possible combinations of speech and noise types, is first designed. A DNN architecture is then employed as a nonlinear regression function to ensure a powerful modeling capability. Several techniques have also been proposed to improve the DNN-based speech enhancement system, including global variance equalization to alleviate the over-smoothing problem of the regression model, and the dropout and noise-aware training strategies to further improve the generalization capability of DNNs to unseen noise conditions. Experimental results demonstrate that the proposed framework can achieve significant improvements in both objective and subjective measures over the conventional MMSE based technique. It is also interesting to observe that the proposed DNN approach can well suppress highly nonstationary noise, which is tough to handle in general. Furthermore, the resulting DNN model, trained with artificial synthesized data, is also effective in dealing with noisy speech data recorded in real-world scenarios without the generation of the annoying musical artifact commonly observed in conventional enhancement methods.	[Xu, Yong; Du, Jun; Dai, Li-Rong] Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China; [Lee, Chin-Hui] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA USA	Xu, Y (reprint author), Univ Sci & Technol China, Natl Engn Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China.	jundu@ustc.edu.cn			National Nature Science Foundation of China [61273264, 61305002]; National 973 program of China [2012CB326405]	This work was supported in part by the National Nature Science Foundation of China under Grants 61273264 and 61305002 and the National 973 program of China under Grant 2012CB326405. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. DeLiang Wang.	Abdel-Hamid O, 2013, INT CONF ACOUST SPEE, P7942, DOI 10.1109/ICASSP.2013.6639211; Anderson M. J., 1974, DESIGN EXPT; [Anonymous], 2001, P862 ITUT; Benesty J., 2005, SPEECH ENHANCEMENT; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209; Cappe O, 1994, IEEE T SPEECH AUDI P, V2, P345, DOI 10.1109/89.279283; Chen LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1859, DOI 10.1109/TASLP.2014.2353991; Christensen H, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1918; Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1; Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544; Deng L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1692; DU J, 2008, P INTERSPEECH, P569; EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550; EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453; Erhan D, 2010, J MACH LEARN RES, V11, P625; Garofolo J. S., 1988, GETTING STARTED DARP; Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893; Hinton G., 2012, IMPROVING NEURAL NET; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hirsch H.G., 2000, P ISCA ITRW ASR2000, P181; Hu G., 2004, 100 NONSPEECH ENV SO; Hussain A, 2007, LECT NOTES COMPUT SC, V4391, P217; Larochelle H, 2009, J MACH LEARN RES, V10, P1; LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540; Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291; Loizou P., 2013, SPEECH ENHANCEMENT T; Lu X, 2013, P INT 13 AUG, P436; Maas AL, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P22; Narayanan A., 2014, P ICASSP, P2523; Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038; Narayanan A, 2014, IEEE-ACM T AUDIO SPE, V22, P826, DOI 10.1109/TASLP.2014.2305833; Plackett RL, 1946, BIOMETRIKA, V33, P305, DOI 10.2307/2332195; Rabiner L. R., 2010, THEORY APPL DIGITAL; Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005; Rangachari Sundarrajan, 2004, IEEE INT C AC SPEECH, V1, pI ; Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199; Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100; Shi GJ, 2006, IEEE T AUDIO SPEECH, V14, P1867, DOI 10.1109/TSA.2005.858512; Srinivasan S., 2005, THESIS KTH ROYAL I T; Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881; Tamura S. I., 1989, P INT C AC SPEECH SI, P2001; Tchorz J, 2003, IEEE T SPEECH AUDI P, V11, P184, DOI 10.1109/TSA.2003.811542; Toda T, 2005, INT CONF ACOUST SPEE, P9; Torre A., 2005, IEEE T SPEECH AUDIO, V13, P355; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Wan E. A., 1998, HDB NEURAL NETWORKS; Wang D., 2006, COMPUTATIONAL AUDITO; Wang Y, 2014, J MED ULTRASOUND, V22, P22; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; Wollmer M, 2013, INT CONF ACOUST SPEE, P6822, DOI 10.1109/ICASSP.2013.6638983; Xia B.-Y., 2013, P INTERSPEECH, P3444; XIE F, 1994, INT CONF ACOUST SPEE, P53; Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240; Zhang X.-L., 2014, P INTERSPEECH, P1534	56	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	JAN	2015	23	1					7	19		10.1109/TASLP.2014.2364452		13	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AZ2NR	WOS:000348070700002		
J	Yan, Y; Yin, XC; Li, SJ; Yang, MY; Hao, HW				Yan, Yan; Yin, Xu-Cheng; Li, Sujian; Yang, Mingyuan; Hao, Hong-Wei			Learning Document Semantic Representation with Hybrid Deep Belief Network	COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE			English	Article								High-level abstraction, for example, semantic representation, is vital for document classification and retrieval. However, how to learn document semantic representation is still a topic open for discussion in information retrieval and natural language processing. In this paper, we propose a new Hybrid Deep Belief Network (HDBN) which uses Deep Boltzmann Machine (DBM) on the lower layers together with Deep Belief Network (DBN) on the upper layers. The advantage of DBM is that it employs undirected connection when training weight parameters which can be used to sample the states of nodes on each layer more successfully and it is also an effective way to remove noise from the different document representation type; the DBN can enhance extract abstract of the document in depth, making the model learn sufficient semantic representation. At the same time, we explore different input strategies for semantic distributed representation. Experimental results show that our model using the word embedding instead of single word has better performance.	[Yan, Yan; Yin, Xu-Cheng; Yang, Mingyuan] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Dept Comp Sci & Technol, Beijing 100083, Peoples R China; [Li, Sujian] Peking Univ, Minist Educ, Key Lab Computat Linguist, Beijing 100871, Peoples R China; [Hao, Hong-Wei] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China	Yin, XC (reprint author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Dept Comp Sci & Technol, Beijing 100083, Peoples R China.	xuchengyin@ustb.edu.cn			National Natural Science Foundation of China [61175020, 61473036]	This work was partly supported by the National Natural Science Foundation of China (61175020 and 61473036).	Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Carreira- Perpinan M. A., 2005, P 10 INT WORKSH ART, P33; Collobert R., 2007, P 45 ANN M ASS COMP, V45, P560; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Hinton G. E., 2009, ADV NEURAL INFORM PR, P1607; Hinton G. E., 2012, ADV NEURAL INFORM PR, V25, P2447; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50; Huang E. H., 2012, P ACL, P873; Joachims T., 1996, PROBABILISTIC ANAL R; Kim J., 2012, P COLING, P579; Larochelle H., 2011, J MACHINE LEARNING R, V15, P29; Larochelle H., 2012, P ADV NEUR INF PROC, P2708; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Rinaldi AM, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P106; Salakhutdinov R., 2009, P INT C ART INT STAT, P448; Salakhutdinov R., 2010, P 13 INT C ART INT S, P693; Shaban Khaled B, 2009, Journal of Software, V4, DOI 10.4304/jsw.4.5.391-404; Srivastava N., MODELING DOCUMENTS D; Turian J., 2010, P 48 ANN M ASS COMP, P384; van der Maaten L., BARNES HUT SNE; Williams R., 2007, P IN IEEE IES DIG EC, P410	26	0	0	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1687-5265	1687-5273		COMPUT INTEL NEUROSC	Comput. Intell. Neurosci.		2015									650527	10.1155/2015/650527		9	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	CF2EP	WOS:000352360600001		
J	Yang, XS; Zhang, TZ; Xu, CS				Yang, Xiaoshan; Zhang, Tianzhu; Xu, Changsheng			Cross-Domain Feature Learning in Multimedia	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Cross-domain; deep learning; feature learning; multi-modal	CLASSIFICATION	In the Web 2.0 era, a huge number of media data, such as text, image/video, and social interaction information, have been generated on the social media sites (e.g., Facebook, Google, Flickr, and YouTube). These media data can be effectively adopted for many applications (e.g., image/video annotation, image/video retrieval, and event classification) in multimedia. However, it is difficult to design an effective feature representation to describe these data because they have multi-modal property (e.g., text, image, video, and audio) and multi-domain property (e.g., Flickr, Google, and YouTube). To deal with these issues, we propose a novel cross-domain feature learning (CDFL) algorithm based on stacked denoising auto-encoders. By introducing the modal correlation constraint and the cross-domain constraint in conventional auto-encoder, our CDFL can maximize the correlations among different modalities and extract domain invariant semantic features simultaneously. To evaluate our CDFL algorithm, we apply it to three important applications: sentiment classification, spam filtering, and event classification. Comprehensive evaluations demonstrate the encouraging performance of the proposed approach.	[Yang, Xiaoshan; Zhang, Tianzhu; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Yang, Xiaoshan; Zhang, Tianzhu; Xu, Changsheng] China Singapore Inst Digital Media, Singapore 119613, Singapore	Yang, XS (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	xiaoshang.yang@nlpr.ia.ac.cn; tzzhang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn			National Program on Key Basic Research Project under the 973 Program [2012CB316304]; National Natural Science Foundation of China [61225009, 61303173, 61373122, 61432019]; Beijing Natural Science Foundation [4131004]	This work was supported in part by the National Program on Key Basic Research Project under the 973 Program, Project No. 2012CB316304, the National Natural Science Foundation of China under Grants 61225009, 61303173, 61373122, and 61432019, and the Beijing Natural Science Foundation under Grant 4131004. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. K. Selcuk Candan.	Baktashmotlagh M., 2013, P IEEE INT C COMP VI, P769; Bao Bing-Kun, 2013, P 3 ACM C INT C MULT, P135; Bengio Y., 2006, P NIPS, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2013, P SLSP, P1; Blitzer J., 2007, P 45 ANN M ASS COMP, V7, P440; Blitzer J., 2006, P C EMP METH NAT LAN, P120, DOI 10.3115/1610075.1610094; Borgwardt K. M., 2006, P 14 INT C INT SYST, V22, P49; Boumal N, 2014, J MACH LEARN RES, V15, P1455; Brenner M., 2012, P 2 ACM INT C MULT R, P21; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Chen M., 2012, P 29 INT C MACH LEAR, P767; Glorot X., 2011, P 28 INT C MACH LEAR, P513; Gong B., 2013, P INT C MACH LEARN, P222; Gong B., 2013, P NIPS, P1286; Gong BQ, 2012, PROC CVPR IEEE, P2066; Gretton A., 2009, DATASET SHIFT MACHIN, V3, P5; Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120; Habrard Amaury, 2013, P ECML PKDD, P433; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffman J., 2012, P ECCV, V7573, P702; Huang J., 2007, P ADV NEUR INF SYST, V19, P601; Jin X., 2010, P ACM MULT, P1235, DOI 10.1145/1873951.1874196; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; Liu LQ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2486; Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151; Long M., 2013, P IEEE INT C COMP VI, P2200; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu WT, 2013, IEEE T MULTIMEDIA, V15, P1920, DOI 10.1109/TMM.2013.2280895; Ma Ge, 2013, P IEEE INT C MULT EX, P1; Ma Z., 2012, P 20 ACM INT C MULT, P469; Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7; Ngiam J., 2011, P 28 INT C MACH LEAR, P689; Orlando S., 2013, P 22 INT C WORLD WID, P1285; Over P., 2013, P TRECVID, P1; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; PETKOS G, 2012, P 2 ACM INT C MULT R, V23, P1; Qi GJ, 2011, P 20 INT C WORLD WID, P297; Ranzato M., 2006, P NIPS, V19, P1137; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Rasiwasia Nikhil, 2010, P INT C MULT, P251, DOI 10.1145/1873951.1873987; Reuter T., 2012, P 2 ACM INT C MULT R, p[22, 1, 8]; Roy S. D., 2012, P ACM MULT, P649; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Sang J., 2011, TOMCCAP, V7, P30; Sang Jitao, 2012, P 20 ACM INT C MULT, P19; Schapire R., 1996, MACH LEARN P 13 INT, V13, P148; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; Tan C, 2011, P 17 ACM SIGKDD INT, P1397, DOI DOI 10.1145/2020408.2020614; THEIL H, 1988, STAT PROBABIL LETT, V6, P137, DOI 10.1016/0167-7152(88)90107-1; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang Y., 2012, P 20 ACM MM 2012 ACM, P865; Yang JC, 2009, PROC CVPR IEEE, P1794; Zaharieva M., 2013, P 3 ACM C INT C MULT, P167	59	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210	1941-0077		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	JAN	2015	17	1					64	78		10.1109/TMM.2014.2375793		15	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	AX6QW	WOS:000347047400007		
J	Rinkus, GJ				Rinkus, Gerard J.			Sparsey (TM): event recognition via deep hierarchical sparse distributed codes	FRONTIERS IN COMPUTATIONAL NEUROSCIENCE			English	Article						sparse distributed codes; cortical hierarchy; sequence recognition; event recognition; deep learning; critical periods; time warp invariance	INFERIOR TEMPORAL CORTEX; PRIMARY VISUAL-CORTEX; RECEPTIVE-FIELDS; OBJECT RECOGNITION; QUANTITATIVE THEORY; ASSOCIATIVE MEMORY; TERM-MEMORY; AREA V4; ORGANIZATION; MACAQUE	The visual cortex's hierarchical, multi-level organization is captured in many biologically inspired computational vision models, the general idea being that progressively larger scale (spatially/temporally) and more complex visual features are represented in progressively higher areas. However, most earlier models use localist representations (codes) in each representational field (which we equate with the cortical macrocolumn, "mac"), at each level. In localism, each represented feature/concept/event (hereinafter "item") is coded by a single unit. The model we describe, Sparsey, is hierarchical as well but crucially, it uses sparse distributed coding (SDC) in every mac in all levels. In SDC, each represented item is coded by a small subset of the mac's units. The SDCs of different items can overlap and the size of overlap between items can be used to represent their similarity. The difference between localism and SDC is crucial because SDC allows the two essential operations of associative memory, storing a new item and retrieving the best-matching stored item, to be done in fixed time for the life of the model. Since the model's core algorithm, which does both storage and retrieval (inference), makes a single pass over all macs on each time step, the overall model's storage/retrieval operation is also fixed-time, a criterion we consider essential for scalability to the huge ("Big Data") problems. A 2010 paper described a nonhierarchical version of this model in the context of purely spatial pattern processing. Here, we elaborate a fully hierarchical model (arbitrary numbers of levels and macs per level), describing novel model principles like progressive critical periods, dynamic modulation of principal cells' activation functions based on a mac-level familiarity measure, representation of multiple simultaneously active hypotheses, a novel method of time warp invariant recognition, and we report results showing learning/recognition of spatiotemporal patterns.	Neurithm Syst LLC, Newton, MA 02466 USA	Rinkus, GJ (reprint author), Neurithm Syst LLC, 275 Grove St,Suite 2-4069, Newton, MA 02466 USA.	grinkus@brandeis.edu			U.S. Office of Naval Research's Computational Neuroscience Program; DARPA's UPSIDE Program	This work was supported by research contracts under the U.S. Office of Naval Research's Computational Neuroscience Program and DARPA's UPSIDE Program.	Barkat TR, 2011, NAT NEUROSCI, V14, P1189, DOI 10.1038/nn.2882; Barrett AB, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000259; Bart E, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00056; Bengio Y., 2012, TECHNICAL REPORT; Bengio Y, 2007, PROG BRAIN RES, V165, P521, DOI 10.1016/S0079-6123(06)65033-4; Constantinople CM, 2013, SCIENCE, V340, P1591, DOI 10.1126/science.1236425; DAMASIO AR, 1989, COGNITION, V33, P25, DOI 10.1016/0010-0277(89)90005-X; Dean T., 2006, P 9 INT S ART INT MA; DeAngelis GC, 1999, J NEUROSCI, V19, P4046; DEANGELIS GC, 1993, J NEUROPHYSIOL, V69, P1118; DESIMONE R, 1984, J NEUROSCI, V4, P2051; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Douglas R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.480; Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152; Edelman S, 1991, Curr Opin Neurobiol, V1, P270, DOI 10.1016/0959-4388(91)90089-P; Feldman V, 2009, NEURAL COMPUT, V21, P2715, DOI 10.1162/neco.2009.08-08-851; Frey U, 1997, NATURE, V385, P533, DOI 10.1038/385533a0; FUKUSHIMA K, 1984, BIOL CYBERN, V50, P105, DOI 10.1007/BF00337157; Gauthier B, 2012, J NEUROSCI, V32, P14433, DOI 10.1523/JNEUROSCI.2467-12.2012; Gavornik JP, 2014, NAT NEUROSCI, V17, P732, DOI 10.1038/nn.3683; George D, 2005, P INT JOINT C NEUR N; GROSSBER.S, 1973, STUD APPL MATH, V52, P213; GROSSBERG S, 1980, PSYCHOL REV, V87, P1; Hecht-Nielsen R, 2005, NEURAL NETWORKS, V18, P111, DOI 10.1016/j.neunet.2004.11.003; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Jitsev E., 2010, SELF ORG HIERARCHICA; Jockel S., 2009, CROSSMODAL LEARNING; Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8; Kanerva P., 1994, P INT C ART NEUR NET; Kanerva P, 1988, SPARSE DISTRIBUTED M; Kiani R, 2007, J NEUROPHYSIOL, V97, P4296, DOI 10.1152/jn.00024.2007; Knoblich U., 2007, CBCL TECHNICAL REPOR; Kouh M, 2008, NEURAL COMPUT, V20, P1427, DOI 10.1162/neco.2008.02-07-466; Kreiman G, 2006, NEURON, V49, P433, DOI 10.1016/j.neuron.2005.12.019; Le Q.V., 2011, P IEEE C COMP VIS PA, P3361; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Litvak S, 2009, NEURAL COMPUT, V21, P3010, DOI 10.1162/neco.2009.05-08-783; Lucke J, 2004, NEURAL NETWORKS, V17, P1377, DOI 10.1016/j.neunet.2004.07.008; Moll M, 1997, NEURAL NETWORKS, V10, P1017, DOI 10.1016/S0893-6080(97)00016-6; Moncada D, 2007, J NEUROSCI, V27, P7476, DOI 10.1523/JNEUROSCI.1083-07.2007; Morris RGM, 1999, TRENDS NEUROSCI, V22, P256, DOI 10.1016/S0166-2236(99)01413-7; Murray JF, 2007, NEURAL COMPUT, V19, P2301, DOI 10.1162/neco.2007.19.9.2301; Nandy AS, 2013, NEURON, V78, P1102, DOI 10.1016/j.neuron.2013.04.016; Ohki K, 2005, NATURE, V433, P597, DOI 10.1038/nature03274; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Oster M, 2009, NEURAL COMPUT, V21, P2437, DOI 10.1162/neco.2009.07-08-829; Pandipati S, 2012, J NEUROPHYSIOL, V108, P1999, DOI 10.1152/jn.00322.2012; Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495; Rachkovskij DA, 2001, NEURAL COMPUT, V13, P411, DOI 10.1162/089976601300014592; Rachkovskij DA, 2001, IEEE T KNOWL DATA EN, V13, P261, DOI 10.1109/69.917565; Ramirez A, 2014, NAT NEUROSCI, V17, P866, DOI 10.1038/nn.3720; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rinkus G., 1996, COMBINATORIAL NEURAL; Rinkus GJ, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00017; Rolls ET, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00035; ROLLS ET, 1994, P ROY SOC B-BIOL SCI, V257, P9, DOI 10.1098/rspb.1994.0087; ROLLS ET, 1992, PHILOS T ROY SOC B, V335, P11, DOI 10.1098/rstb.1992.0002; Rubio-Garrido P, 2009, CEREB CORTEX, V19, P2380, DOI 10.1093/cercor/bhn259; Rust NC, 2005, NEURON, V46, P945, DOI 10.1016/j.neuron.2005.05.021; Rust NC, 2010, J NEUROSCI, V30, P12978, DOI 10.1523/JNEUROSCI.0179-10.2010; Sadovsky AJ, 2014, J NEUROSCI, V34, P7769, DOI 10.1523/JNEUROSCI.0169-14.2014; Sajikumar S, 2004, NEUROSCIENCE, V129, P503, DOI 10.1016/j.neuroscience.2004.08.014; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Saul L. K., 2002, THINK GLOBALLY FIT L; Schuldt C., 2004, RECOGNIZING HUMAN AC; Serre T, 2007, PROG BRAIN RES, V165, P33, DOI 10.1016/S0079-6123(06)65004-8; Serre T., 2005, 2005036 AI MIT; St-Pierre F, 2014, NAT NEUROSCI, V17, P884, DOI 10.1038/nn.3709; Taylor G. W., 2010, EUR C COMP VIS ECCV; Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731; Uusitalo MA, 1997, NEUROSCI LETT, V224, P45, DOI 10.1016/S0304-3940(97)13445-0; Valiant LG, 2006, BIOL CYBERN, V95, P205, DOI 10.1007/s00422-006-0079-3; WIESEL TN, 1963, J NEUROPHYSIOL, V26, P978; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0; Yu AJ, 2002, NEURAL COMPUT, V14, P2857, DOI 10.1162/089976602760805313	78	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5188			FRONT COMPUT NEUROSC	Front. Comput. Neurosci.	DEC 15	2014	8								160	10.3389/fncom.2014.00160		44	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	AY1WS	WOS:000347380700002	25566046	
J	Qi, J; Yang, ZY				Qi, Jin; Yang, Zhiyong			Learning Dictionaries of Sparse Codes of 3D Movements of Body Joints for Real-Time Human Activity Understanding	PLOS ONE			English	Article							MILD COGNITIVE IMPAIRMENT; ACTION RECOGNITION; DEFICITS; VISION; HMM	Real-time human activity recognition is essential for human-robot interactions for assisted healthy independent living. Most previous work in this area is performed on traditional two-dimensional (2D) videos and both global and local methods have been used. Since 2D videos are sensitive to changes of lighting condition, view angle, and scale, researchers begun to explore applications of 3D information in human activity understanding in recently years. Unfortunately, features that work well on 2D videos usually don't perform well on 3D videos and there is no consensus on what 3D features should be used. Here we propose a model of human activity recognition based on 3D movements of body joints. Our method has three steps, learning dictionaries of sparse codes of 3D movements of joints, sparse coding, and classification. In the first step, space-time volumes of 3D movements of body joints are obtained via dense sampling and independent component analysis is then performed to construct a dictionary of sparse codes for each activity. In the second step, the space-time volumes are projected to the dictionaries and a set of sparse histograms of the projection coefficients are constructed as feature representations of the activities. Finally, the sparse histograms are used as inputs to a support vector machine to recognize human activities. We tested this model on three databases of human activities and found that it outperforms the state-of-the-art algorithms. Thus, this model can be used for real-time human activity recognition in many applications.	[Qi, Jin; Yang, Zhiyong] Georgia Regents Univ, Brain & Behav Discovery Inst, James & Jean Culver Vis Discovery Inst, Dept Ophthalmol, Augusta, GA 30912 USA	Yang, ZY (reprint author), Georgia Regents Univ, Brain & Behav Discovery Inst, James & Jean Culver Vis Discovery Inst, Dept Ophthalmol, Augusta, GA 30912 USA.	zhyang@gru.edu					Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Campbell L. W., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466880; Camplani M., 2012, P SPIE 3 DIMENSIONAL, V8290; Cook DJ, 2005, SMART ENV TECHNOLOGI, P1; Das B, 2012, PERS UBIQUIT COMPUT, V16, P859, DOI 10.1007/s00779-011-0445-6; Dollar P., 2005, IEEE INT WORKSH VIS, V2, P65; Farias ST, 2006, ALZ DIS ASSOC DIS, V20, P217, DOI 10.1097/01.wad.0000213849.51495.d9; Gupta R, 2013, P 21 ACM INT C MULT, P283; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2009, NATURAL IMAGE STAT P; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Jalal A, 2011, LECT NOTES COMPUT SC, V6719, P25, DOI 10.1007/978-3-642-21535-3_4; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; JOHANSSON G, 1975, SCI AM, V232, P76; Kaushik P, 2008, METHOD INFORM MED, V47, P203, DOI 10.3414/ME9111; Klaser A., 2008, BRIT MACH VIS C, P995; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le QV, 2011, ADV NEURAL INFORM PR, V24, P1017; Lei J., 2012, P 2012 ACM C UB COMP, P208; Li W., 2010, CVPR WORKSH, V1, P9; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Muller M., 2006, P EUR ACM SIGGRAPH S, V2, P137; Ngiam J, ICML, P265; Ni BB, 2012, LECT NOTES COMPUT SC, V7573, P173; Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Piyathilaka L, 2013, C IND ELECT APPL, P567; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Reisberg B, 2001, INT PSYCHOGERIATR, V13, P163, DOI 10.1017/S1041610201007566; Schmitter-Edgecombe M, 2009, NEUROPSYCHOLOGY, V23, P168, DOI 10.1037/a0014186; Shotton J, 2013, STUDIES COMPUTATIONA, V411, P119; Sung J, 2011, AAAI WORKSHOPS, VWS-11-16, P47; Sung JY, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), P842; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Vieira A.W., 2012, LECT NOTES COMPUTER, V7441, P252; Wadley VG, 2008, AM J GERIAT PSYCHIAT, V16, P416, DOI 10.1097/JGP.0b013e31816b7303; Wang J, 2013, PATTERN ANAL MACHINE, V36, P914; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Xia L., 2012, COMP VIS PATT REC WO, P20; Yang X., 2012, COMP VIS PATT REC WO, P14; Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001; Yao A, 2012, INT J COMPUT VISION, V100, P16, DOI 10.1007/s11263-012-0532-9; Ye M, 2013, LECT NOTES COMPUTER, V8200, P149; Zhang C, 2012, J COMPUTER VISION IM, V2; Zhang H., 2011, INTELLIGENT ROBOTS S, V2011, P2044; Zhu XY, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046686	52	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	DEC 4	2014	9	12							e114147	10.1371/journal.pone.0114147		24	Multidisciplinary Sciences	Science & Technology - Other Topics	AW6MB	WOS:000346382500117	25473850	
J	Bu, SH; Liu, ZB; Han, JW; Wu, J; Ji, RR				Bu, Shuhui; Liu, Zhenbao; Han, Junwei; Wu, Jun; Ji, Rongrong			Learning High-Level Feature by Deep Belief Networks for 3-D Model Retrieval and Recognition	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						3-D model recognition; 3-D model retrieval; bag-of-words; deep belief networks; deep learning	3D SHAPE RETRIEVAL; OBJECT RETRIEVAL; DESCRIPTORS; WORDS	3-D shape analysis has attracted extensive research efforts in recent years, where the major challenge lies in designing an effective high-level 3-D shape feature. In this paper, we propose a multi-level 3-D shape feature extraction framework by using deep learning. The low-level 3-D shape descriptors are first encoded into geometric bag-of-words, from which middle-level patterns are discovered to explore geometric relationships among words. After that, high-level shape features are learned via deep belief networks, which are more discriminative for the tasks of shape classification and retrieval. Experiments on 3-D shape recognition and retrieval demonstrate the superior performance of the proposed method in comparison to the state-of-the-art methods.	[Bu, Shuhui; Liu, Zhenbao; Han, Junwei; Wu, Jun] Northwestern Polytech Univ, Xian 710072, Peoples R China; [Ji, Rongrong] Xiamen Univ, Sch Informat Sci & Engn, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China	Han, JW (reprint author), Northwestern Polytech Univ, Xian 710072, Peoples R China.	bushuhui@nwpu.edu.cn; liuzhenbao@nwpu.edu.cn; jhan@nwpu.edu.cn; junwu@nwpu.edu.cn; rrji@xmu.edu.cn			National Natural Science Foundation of China [61202185, 61003137, 91120005, 61473231, 61373076, 61422210, 61103062]; Fundamental Research Funds for the Central Universities [310201401-(JCQ01009, JCQ01012), 2013121026]; Shaanxi Natural Science Fund [2012JQ8037]; Open Project Program of the State Key Lab of CAD& CG of Zhejiang University [A1306]; Xiamen University [985]	This work was supported in part by the National Natural Science Foundation of China under Grant 61202185, Grant 61003137, Grant 91120005, Grant 61473231, Grant 61373076, Grant 61422210, and Grant 61103062, the Fundamental Research Funds for the Central Universities under Grant 310201401-(JCQ01009, JCQ01012) and Grant 2013121026, the Shaanxi Natural Science Fund under Grant 2012JQ8037, the Open Project Program of the State Key Lab of CAD& CG of Zhejiang University under Grant A1306, and Xiamen University under the 985 Project. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. K. Selcuk Candan. (Corresponding author: Junwei Han.)	Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019; Barra V., 2013, P EUR WORKSH 3D OBJ, P25; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bimbo A. D., 2006, ACM T MULTIM COMPUT, V2, P20, DOI 10.1145/1126004.1126006; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405; Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838; Bu SH, 2014, VISUAL COMPUT, V30, P867, DOI 10.1007/s00371-014-0970-1; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Cordeiro de Amorim Renato, 2012, Pattern Recognition, V45, DOI 10.1016/j.patcog.2011.08.012; Cornea N. D., 2005, Proceedings. International Conference on Shape Modeling and Applications; Dubrovina A., 2010, P S 3D DAT P, V2; Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081; Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502; Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760; Giorgi D., 2007, 9 CNR IMATI; Hilaga M, 2001, COMP GRAPH, P203; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kazhdan M, 2003, P EUR ACM SIGGRAPH S, P156; Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43; Kovnatsky A., 2012, P EUR C 3D OBJ RETR, P39; Laga H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516975; Laga H, 2010, P 3 EUR C 3D OBJ RET, P15; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Lavoue G., 2011, P EUR WORKSH 3D OBJ, P41; Lavoue G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3; Lian Z., 2011, 3DOR, V11, P79; Lian ZH, 2010, IEEE IMAGE PROC, P3181, DOI 10.1109/ICIP.2010.5654226; Litman R, 2014, IEEE T PATTERN ANAL, V36, P171, DOI 10.1109/TPAMI.2013.148; Liu Y., 2006, P IEEE INT C SHAP MO, P16; Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9; Mademlis A, 2008, IEEE T MULTIMEDIA, V10, P819, DOI 10.1109/TMM.2008.922790; Maes C., 2010, P 4 IEEE INT C BTAS, P1; Osada R., 2001, Proceedings International Conference on Shape Modeling and Applications, DOI 10.1109/SMA.2001.923386; Ovsjanikov M., 2009, P NORDIA 09, P320; Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6; Reuter M., 2005, P ACM S SOL PHYS MOD, P101, DOI DOI 10.1145/1060244.1060256; Sfikas K, 2012, VISUAL COMPUT, V28, P943, DOI 10.1007/s00371-012-0714-z; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/SMI.2004.1314504; Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8; Sipiran I, 2013, COMPUT GRAPH-UK, V37, P460, DOI 10.1016/j.cag.2013.04.002; SMEETS D, 2009, COMPUTER ANAL IMAGES, V5702, P757, DOI 10.1007/978-3-642-03767-2_92; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383; Tabia H., 2013, P 6 EUR WORKSH 3D OB, P17; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x; Toldo R., 2009, P EUR WORKSH 3 D OBJ, P21; Wu HY, 2010, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2010.5540180	57	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210	1941-0077		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	DEC	2014	16	8					2154	2167		10.1109/TMM.2014.2351788		14	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	AU4HL	WOS:000345571300007		
J	Chiachia, G; Falcao, AX; Pinto, N; Rocha, A; Cox, D				Chiachia, Giovani; Falcao, Alexandre X.; Pinto, Nicolas; Rocha, Anderson; Cox, David			Learning Person-Specific Representations From Faces in the Wild	IEEE Transactions on Information Forensics and Security			English	Article						Face recognition; face information modeling; representation learning; deep learning; biologically-inspired computer vision; partial least squares; support vector machines	PARTIAL LEAST-SQUARES; RECOGNITION; HUMANS; MODELS; VIDEO	Humans are natural face recognition experts, far out-performing current automated face recognition algorithms, especially in naturalistic, "in the wild" settings. However, a striking feature of human face recognition is that we are dramatically better at recognizing highly familiar faces, presumably because we can leverage large amounts of past experience with the appearance of an individual to aid future recognition. Meanwhile, the analogous situation in automated face recognition, where a large number of training examples of an individual are available, has been largely underexplored, in spite of the increasing relevance of this setting in the age of social media. Inspired by these observations, we propose to explicitly learn enhanced face representations on a per-individual basis, and we present two methods enabling this approach. By learning and operating within person-specific representations, we are able to significantly outperform the previous state-of-the-art on PubFig83, a challenging benchmark for familiar face recognition in the wild, using a novel method for learning representations in deep visual hierarchies. We suggest that such person-specific representations aid recognition by introducing an intermediate form of regularization to the problem.	[Chiachia, Giovani; Falcao, Alexandre X.; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, BR-13083970 Campinas, SP, Brazil; [Pinto, Nicolas; Cox, David] Harvard Univ, Cambridge, MA 02138 USA	Chiachia, G (reprint author), Univ Estadual Campinas, Inst Comp, BR-13083970 Campinas, SP, Brazil.	chiachia@ic.unicamp.br; afalcao@ic.unicamp.br; pinto@alum.mit.edu; anderson.rocha@ic.unicamp.br; davidcox@fas.harvard.edu			Fundacao de Amparo a Pesquisa do Estado de Sao Paulo [2010/00994-8, 2010/05647-4, 2013/11359-0]; National Council for Scientific and Technological Development, Brasilia, Brazil [303673/2010-9, 304352/2012-8, 477662/2013-7, 479070/2013-0]; Microsoft Research, Redmond, WA, USA; Rowland Institute at Harvard, Cambridge, MA, USA	This work was supported in part by the Fundacao de Amparo a Pesquisa do Estado de Sao Paulo under Grant 2010/00994-8, Grant 2010/05647-4, and Grant 2013/11359-0, in part by the National Council for Scientific and Technological Development, Brasilia, Brazil, under Grant 303673/2010-9, Grant 304352/2012-8, Grant 477662/2013-7, and Grant 479070/2013-0, in part by Microsoft Research, Redmond, WA, USA, and in part by the Rowland Institute at Harvard, Cambridge, MA, USA. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Aly A. Farag.	Abdi H., 2010, WILEY INTERDISCIPLIN, V2, P97, DOI DOI 10.1002/WICS.51; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bengio Y, 2007, ADV NEURAL INFORM PR; Bergstra J., 2013, P 30 INT C MACH LEAR, P115; Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; BRUCE V, 1986, BRIT J PSYCHOL, V77, P305; Burton AM, 2011, BRIT J PSYCHOL, V102, P943, DOI 10.1111/j.2044-8295.2011.02039.x; Burton AM, 1999, PSYCHOL SCI, V10, P243, DOI 10.1111/1467-9280.00144; Burton AM, 2005, COGNITIVE PSYCHOL, V51, P256, DOI 10.1016/j.cogpsych.2005.06.003; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Chellappa R, 2010, COMPUTER, V43, P46, DOI 10.1109/MC.2010.37; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Chiachia G., 2012, P BMVC, P1; Coates A., 2011, P 28 INT C MACH LEAR, P921; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; de Carlos Paulo G., 2013, P 10 IEEE INT C AUT, P1; de O Costa F., 2014, PATTERN RECOGNIT LET, V39, P91; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Guo HD, 2011, INT J DIGIT EARTH, V4, P1, DOI 10.1080/17538947.2011.544077; Heisele B., 2001, P 8 IEEE INT C COMP, P688, DOI 10.1109/ICCV.2001.937693; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang G. B., 2007, 0749 U MASS DEP COMP; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kamarainen J.-K., 2011, HDB FACE RECOGNITION, P79; Kembhavi A, 2011, IEEE T PATTERN ANAL, V33, P1250, DOI 10.1109/TPAMI.2010.182; Krishna S., 2005, P IAPR INT C BIOM, P182; Krizhevsky A., 2012, ADV NEURAL INFORM PR; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Le Q., 2012, P 29 INT C MACH LEAR, P81; Le Q. V., 2010, ADV NEURAL INFORM PR; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LINDGREN F, 1995, J CHEMOMETR, V9, P331, DOI 10.1002/cem.1180090502; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790410; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pinto N., 2011, P IEEE COMP SOC C CO, P35; Pinto N., 2011, P INT C AUT FAC GEST, P8; Poggio T., 2011, NATURE P; Quiroga RQ, 2005, NATURE, V435, P1102, DOI 10.1038/nature03687; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34; Saxe A., 2011, P 28 INT C MACH LEAR, P1089; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Schwartz WR, 2012, IEEE T IMAGE PROCESS, V21, P2245, DOI 10.1109/TIP.2011.2176951; Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Sivic J, 2009, PROC CVPR IEEE, P1145; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Vasilescu MAO, 2002, INT C PATT RECOG, P511; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; Wolf L, 2009, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2009.5459323; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zafeiriou S, 2007, IEEE T INF FOREN SEC, V2, P55, DOI 10.1109/TIFS.2006.890308	56	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	DEC	2014	9	12					2089	2099		10.1109/TIFS.2014.2359543		11	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	CG4WX	WOS:000353289900007		
J	Ebadi, T; Kukenys, I; Browne, WN; Zhang, MJ				Ebadi, Toktam; Kukenys, Ignas; Browne, Will N.; Zhang, Mengjie			Human-Interpretable Feature Pattern Classification System Using Learning Classifier Systems	EVOLUTIONARY COMPUTATION			English	Article						Learning classifier system; evolutionary computation; pattern recognition; Haar-like features	PROBABILISTIC NEURAL NETWORKS; IMAGE CLASSIFICATION; RECOGNITION; ENSEMBLES; ACCURACY; FORESTS; TREES	Image pattern classification is a challenging task due to the large search space of pixel data. Supervised and subsymbolic approaches have proven accurate in learning a problem's classes. However, in the complex image recognition domain, there is a need for investigation of learning techniques that allow humans to interpret the learned rules in order to gain an insight about the problem. Learning classifier systems (LCSs) are a machine learning technique that have been minimally explored for image classification. This work has developed the feature pattern classification system (FPCS) framework by adopting Haar-like features from the image recognition domain for feature extraction. The FPCS integrates Haar-like features with XCS, which is an accuracy-based LCS. A major contribution of this work is that the developed framework is capable of producing human-interpretable rules. The FPCS system achieved 91 +/- 1% accuracy on the unseen test set of the MNIST dataset. In addition, the FPCS is capable of autonomously adjusting the rotation angle in unaligned images. This rotation adjustment raised the accuracy of FPCS to 95%. Although the performance is competitive with equivalent approaches, this was not as accurate as subsymbolic approaches on this dataset. However, the benefit of the interpretability of rules produced by FPCS enabled us to identify the distribution of the learned angles-a normal distribution around 0 degrees-which would have been very difficult in subsymbolic approaches. The analyzable nature of FPCS is anticipated to be beneficial in domains such as speed sign recognition, where underlying reasoning and confidence of recognition needs to be human interpretable.	[Ebadi, Toktam; Kukenys, Ignas; Browne, Will N.; Zhang, Mengjie] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand	Ebadi, T (reprint author), Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand.	toktam.ebadi@ecs.vuw.ac.nz; ignas.kukenys@ecs.vuw.ac.nz; will.browne@ecs.vuw.ac.nz; mengjie.zhang@ecs.vuw.ac.nz					Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Bernado-Mansilla E, 2003, EVOL COMPUT, V11, P209, DOI 10.1162/106365603322365289; Bernard S, 2009, LECT NOTES ARTIF INT, V5755, P536; Bosch A., 2007, P IEEE INT C COMP VI, P1; Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI DOI 10.1145/1282280.1282340; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bull L, 2007, IEEE T EVOLUT COMPUT, V11, P496, DOI 10.1109/TEVC.2006.885163; Butz MV, 2006, RULE BASED EVOLUTION; Butz MV, 2004, IEEE T EVOLUT COMPUT, V8, P28, DOI 10.1109/TEVC.2003.818194; Casagrande N., 2005, THESIS U MONTREAL; Ciresan DC, 2011, PROC INT CONF DOC, P1135, DOI 10.1109/ICDAR.2011.229; Deselaers T., 2007, P IEEE C COMP VIS PA, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Drugowitsch J, 2008, DESIGN ANAL LEARNING; Fleuret F., 2003, P INT WORKSH STAT CO; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; Grauman K., 2005, P IEEE INT C COMP VI, V2, P1458; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huy NQ, 2009, EVOL COMPUT, V17, P231, DOI 10.1162/evco.2009.17.2.231; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kukenys I, 2011, LECT NOTES COMPUT SC, V6624, P183, DOI 10.1007/978-3-642-20525-5_19; Lanzi P. L., 1999, P GEN EV COMP C, V1, P345; Lanzi PL, 2007, EVOL COMPUT, V15, P133, DOI 10.1162/evco.2007.15.2.133; Larochelle H., 2007, P 24 INT C MACH LEAR, P473, DOI 10.1145/1273496.1273556; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LeCun Y., 1990, P 10 INT C PATT REC, V2, P35; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P 26 ANN INT C MACH, P609, DOI DOI 10.1145/1553374.1553453; Li XC, 2008, ENG APPL ARTIF INTEL, V21, P785, DOI 10.1016/j.engappai.2007.07.001; Maji S., 2008, P IEEE C COMP VIS PA, P1; Mao KZ, 2000, IEEE T NEURAL NETWOR, V11, P1009, DOI 10.1109/72.857781; Maree R, 2005, PROC CVPR IEEE, P34; Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822; MUSAVI MT, 1994, IEEE T PATTERN ANAL, V16, P659, DOI 10.1109/34.295911; Nigrin A., 1993, NEURAL NETWORKS PATT; Orriols-Puig A, 2009, IEEE T EVOLUT COMPUT, V13, P1093, DOI 10.1109/TEVC.2009.2019829; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Romero RD, 1997, PATTERN RECOGN, V30, P1279, DOI 10.1016/S0031-3203(96)00166-5; Scholkopf B., 2002, LEARNING KERNELS SUP; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Sutton R., 1998, REINFORCEMENT LEARNI, V28; Varma M., 2007, P IEEE INT C COMP VI, P1; Viola P, 2001, PROC CVPR IEEE, P511; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Zhang J., 2006, P INT C BIOM IMP MAD, P93; Zhao K, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 1, PROCEEDINGS, P228, DOI 10.1109/IITA.2009.200	48	0	0	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	1063-6560	1530-9304		EVOL COMPUT	Evol. Comput.	WIN	2014	22	4					629	650		10.1162/EVCO_a_00127		22	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	AW0ET	WOS:000345964200004	24697596	
J	Goh, H; Thome, N; Cord, M; Lim, JH				Goh, Hanlin; Thome, Nicolas; Cord, Matthieu; Lim, Joo-Hwee			Learning Deep Hierarchical Visual Feature Coding	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Bag-of-words (BoW) framework; computer vision; deep learning; dictionary learning; hierarchical visual architecture; image categorization; restricted Boltzmann machine (RBM); sparse feature coding; transfer learning	IMAGE CLASSIFICATION; OBJECT RECOGNITION; RECEPTIVE-FIELDS; NATURAL IMAGES; SPARSE; NETWORKS; REPRESENTATIONS; CORTEX; MODEL	In this paper, we propose a hybrid architecture that combines the image modeling strengths of the bag of words framework with the representational power and adaptability of learning deep architectures. Local gradient-based descriptors, such as SIFT, are encoded via a hierarchical coding scheme composed of spatial aggregating restricted Boltzmann machines (RBM). For each coding layer, we regularize the RBM by encouraging representations to fit both sparse and selective distributions. Supervised fine-tuning is used to enhance the quality of the visual representation for the categorization task. We performed a thorough experimental evaluation using three image categorization data sets. The hierarchical coding scheme achieved competitive categorization accuracies of 79.7% and 86.4% on the Caltech-101 and 15-Scenes data sets, respectively. The visual representations learned are compact and the model's inference is fast, as compared with sparse coding methods. The low-level representations of descriptors that were learned using this method result in generic features that we empirically found to be transferrable between different image data sets. Further analysis reveal the significance of supervised fine-tuning when the architecture has two layers of representations as opposed to a single layer.	[Goh, Hanlin; Lim, Joo-Hwee] Agcy Sci Technol & Res, Inst Infocomm Res, Singapore 119613, Singapore; [Goh, Hanlin; Lim, Joo-Hwee] Image & Pervas Access Lab, Singapore 138632, Singapore; [Thome, Nicolas; Cord, Matthieu] Univ Paris 04, Univ Paris 06, Lab Informat Paris 6, F-75005 Paris, France	Goh, H (reprint author), Agcy Sci Technol & Res, Inst Infocomm Res, Singapore 119613, Singapore.	hlgoh@i2r.a-star.edu.sg; nicolas.thome@lip6.fr; matthieu.cord@lip6.fr; joohwee@i2r.a-star.edu.sg			French Embassy in Singapore	This work was supported in part by the French Embassy in Singapore through the Merlion Project and Ph.D. Program from 2010 to 2012.	Avila S., 2012, COMPUT VIS IMAGE UND, V117, P453; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Bengio Y., 2006, P NIPS, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; BLACKWELL D, 1947, ANN MATH STAT, V18, P105, DOI 10.1214/aoms/1177730497; Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91; Boiman O., 2008, P IEEE C COMP VIS PA, P1; Boureau Y., 2011, P ICCV, P1; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Boureau Y.-L., 2010, P 27 INT C MACH LEAR, P111; Dalal N, 2005, PROC CVPR IEEE, P886; Deng J, 2009, PROC CVPR IEEE, P248; Duchenne O, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1792, DOI 10.1109/ICCV.2011.6126445; Fei-Fei L., 2004, P CVPR WORKSH; Feng J., 2011, P IEEE C COMP VIS PA, P2609; Foldiak P, 2009, CURR BIOL, V19, pR904, DOI 10.1016/j.cub.2009.08.020; Goh H., 2012, P 12 ECCV, P298; Goh H., 2013, P NIPS; Goh H, 2011, IEEE IMAGE PROC, P1241; Goh H.G., 2010, P 7 CONS COMM NETW C, P1, DOI 10.1109/NLPKE.2010.5587801; Griffin G., 2007, 7694 CALTECH; Hinton G. E., 2010, TR2010003 UTML DEP C; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Hyvarinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jiang ZL, 2011, PROC CVPR IEEE, P1697; Kavukcuoglu K., 2010, P NIPS, V1-9; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605; Krizhevsky A., 2012, P NIPS, P1; Larochelle H, 2008, P 25 INT C MACH LEAR, P536, DOI 10.1145/1390156.1390224; Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1985, P COGNITIVA, V85, P599; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Lee H.Y., 2008, P IEEE INT EL DEV M, P1, DOI 10.1145/1389586.1389590; Liu LQ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2486; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, ADV NEURAL INFORM PR, V21, P1033; McCann S., 2012, P ACCV, P204; Mitchell T. M., 1980, CBMTR117 RUTG U DEP; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339; Ngiam J., 2011, P NIPS, P17; Oliveira GL, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA), P2592, DOI 10.1109/ICRA.2012.6224785; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266]; Raina R., 2007, LEARNING, P759; Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rolls ET, 1990, NETWORK-COMP NEURAL, V1, P407, DOI 10.1088/0954-898X/1/4/002; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sivic J., 2003, P 9 IEEE C COMP VIS, V2, P1470, DOI DOI 10.1109/ICCV.2003.1238663; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Sohn K, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P2643; Swersky K., 2010, P INF THEOR APPL WOR, P1; Theriault C., 2012, IEEE T IMAGE PROCESS, V22, P764; Tuytelaars T, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), P1824, DOI 10.1109/ICCV.2011.6126449; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vapnik V. N., 1995, NATURE STAT LEARNING; Vincent P, 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Welling M., 2003, P NIPS, P1; Willmore B, 2001, NETWORK-COMP NEURAL, V12, P255, DOI 10.1088/0954-898X/12/3/302; Yang JC, 2009, PROC CVPR IEEE, P1794; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958; Yang JC, 2010, LECT NOTES COMPUT SC, V6315, P113; Yang L., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/DYSPAN.2008.47; Yu K, 2011, PROC CVPR IEEE, P1713; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141	77	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	DEC	2014	25	12					2212	2225		10.1109/TNNLS.2014.2307532		14	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	AU3MZ	WOS:000345518900008	25420244	
J	Han, K; Wang, DL				Han, Kun; Wang, DeLiang			Neural Network Based Pitch Tracking in Very Noisy Speech	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Deep neural networks (DNNs); pitch estimation; recurrent neural networks (RNNs); supervised learning; viterbi decoding	MULTIPITCH TRACKING; REVERBERANT SPEECH; ALGORITHM; SEGREGATION; RECOGNITION; DATABASE	Pitch determination is a fundamental problem in speech processing, which has been studied for decades. However, it is challenging to determinate pitch in strong noise because the harmonic structure is corrupted. In this paper, we estimate pitch using supervised learning, where the probabilistic pitch states are directly learned from noisy speech data. We investigate two alternative neural networks modeling pitch state distribution given observations. The first one is a feedforward deep neural network (DNN), which is trained on static frame-level acoustic features. The second one is a recurrent deep neural network (RNN) which is trained on sequential frame-level features and capable of learning temporal dynamics. Both DNNs and RNNs produce accurate probabilistic outputs of pitch states, which are then connected into pitch contours by Viterbi decoding. Our systematic evaluation shows that the proposed pitch tracking algorithms are robust to different noise conditions and can even be applied to reverberant speech. The proposed approach also significantly outperforms other state-of-the-art pitch tracking algorithms.	[Han, Kun; Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA	Han, K (reprint author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	hank@cse.ohio-state.edu			Air Force Office of Scientific Research (AFOSR) [FA9550-12-1-0130]; Ohio Supercomputer Center	This work was supported in part by the Air Force Office of Scientific Research (AFOSR) under Grant FA9550-12-1-0130 and the Ohio Supercomputer Center. A preliminary version of this work was presented at ICASSP 2014 [15]. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Zhen-Hua Ling.	ATAL BS, 1972, J ACOUST SOC AM, V52, P1687, DOI 10.1121/1.1913303; Bagshaw P. C., 1993, P EUR C SPEECH COMM, V2, P1003; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Boersma P., 2007, PRAAT DOING PHONETIC; Chu W, 2012, IEEE T AUDIO SPEECH, V20, P933, DOI 10.1109/TASL.2011.2168518; de Cheveigne A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024; Deng L, 2013, INT CONF ACOUST SPEE, P8604; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Fosler-Lussier E, 2013, P IEEE, V101, P1054, DOI 10.1109/JPROC.2013.2248112; Gonzalez S, 2014, IEEE-ACM T AUDIO SPE, V22, P518, DOI 10.1109/TASLP.2013.2295918; Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI 10.1007/978-3-642-24797-2; Habets E., 2010, ROOM IMPULSE RESPONS; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; Han K., 2014, P ICASSP, P1488; HERMES DJ, 1988, J ACOUST SOC AM, V83, P257, DOI 10.1121/1.396427; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hu G., 2006, THESIS OHIO STATE U; Hu G., 2006, 100 NONSPEECH SOUNDS; Hu GN, 2010, IEEE T AUDIO SPEECH, V18, P2067, DOI 10.1109/TASL.2010.2041110; Huang F., 2013, IEEE T AUDIO SPEECH, V21, P99; Jin Z., 2011, REVERBERANT PITCH EV; Jin ZZ, 2011, IEEE T AUDIO SPEECH, V19, P1091, DOI 10.1109/TASL.2010.2077280; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Kalatzis V, 1998, HUM MOL GENET, V7, P1589, DOI 10.1093/hmg/7.10.1589; Lafferty J. D., 2001, ICML, P282; Lee B.S., 2012, P INTERSPEECH; Li J., 2012, P SLT; Maas A., 2012, P INTERSPEECH; MCGONEGAL CA, 1975, IEEE T ACOUST SPEECH, V23, P570, DOI 10.1109/TASSP.1975.1162750; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Nakatani T, 2008, SPEECH COMMUN, V50, P203, DOI 10.1016/j.specom.2007.09.003; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SCHROEDE.MR, 1968, J ACOUST SOC AM, V43, P829, DOI 10.1121/1.1910902; Sutskever I., 2013, THESIS U TORONTO TOR; Talkin D., 1995, SPEECH CODING SYNTHE, V495, P495; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Vinyals O, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4085; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; Williams R. J., 1990, NEURAL COMPUT, V2, P490, DOI 10.1162/neco.1990.2.4.490; Wu MY, 2003, IEEE T SPEECH AUDI P, V11, P229, DOI 10.1109/TSA.2003.811539; ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7	43	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	DEC	2014	22	12					2158	2168		10.1109/TASLP.2014.2363410		11	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AS7UI	WOS:000344459700020		
J	Hausknecht, M; Lehman, J; Miikkulainen, R; Stone, P				Hausknecht, Matthew; Lehman, Joel; Miikkulainen, Risto; Stone, Peter			A Neuroevolution Approach to General Atari Game Playing	IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES			English	Article						Algorithms; artificial neural networks; genetic algorithms; evolutionary computation; neural networks	NEURAL-NETWORKS; EVOLUTION	This paper addresses the challenge of learning to play many different video games with little domain-specific knowledge. Specifically, it introduces a neuroevolution approach to general Atari 2600 game playing. Four neuroevolution algorithms were paired with three different state representations and evaluated on a set of 61 Atari games. The neuroevolution agents represent different points along the spectrum of algorithmic sophistication-including weight evolution on topologically fixed neural networks (conventional neuroevolution), covariance matrix adaptation evolution strategy (CMA-ES), neuroevolution of augmenting topologies (NEAT), and indirect network encoding (HyperNEAT). State representations include an object representation of the game screen, the raw pixels of the game screen, and seeded noise (a comparative baseline). Results indicate that direct-encoding methods work best on compact state representations while indirect-encoding methods (i.e., HyperNEAT) allow scaling to higher dimensional representations (i.e., the raw game screen). Previous approaches based on temporal-difference (TD) learning had trouble dealing with the large state spaces and sparse reward gradients often found in Atari games. Neuroevolution ameliorates these problems and evolved policies achieve state-of-the-art results, even surpassing human high scores on three games. These results suggest that neuroevolution is a promising approach to general video game playing (GVGP).	[Hausknecht, Matthew; Lehman, Joel; Miikkulainen, Risto; Stone, Peter] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	Hausknecht, M (reprint author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	mhauskn@cs.utexas.edu			National Science Foundation (NSF) [IIS-0917122, IIS-0915038, DBI-0939454]; U.S. Office of Naval Research (ONR) [N00014-09-1-0658]; U.S. Federal Highway Administration [DTFH61-07-H-00030]	This work has taken place in the Learning Agents Research Group (LARG), Artificial Intelligence Laboratory, The University of Texas at Austin. LARG research is supported in part by the National Science Foundation (NSF) under Grants IIS-0917122, IIS-0915038, and DBI-0939454; by the U.S. Office of Naval Research (ONR) under Grant N00014-09-1-0658; and by the U.S. Federal Highway Administration under Grant DTFH61-07-H-00030.	Barbu A., 2010, P IEEE INT C ROB AUT, P1879; Bellemare M., 2012, ADV NEURAL INF PROCE, V25, P2222; Bellemare M. G., 2012, P 26 AAAI C ART INT, P864; Bellemare M. G., 2012, CORR; Bohm N., 2004, P LERN WISS AD LWA 2, P118; Bongard J, 2011, P NATL ACAD SCI USA, V108, P1234, DOI 10.1073/pnas.1015390108; Clune J, 2009, IEEE C EVOL COMPUTAT, P2764, DOI 10.1109/CEC.2009.4983289; Clune J, 2011, IEEE T EVOLUT COMPUT, V15, P346, DOI 10.1109/TEVC.2010.2104157; Cobo L. C., 2011, P INT JOINT C ART IN, P1243; D'Ambrosio D. B., 2008, P 10 ANN C GEN EV CO, P819, DOI 10.1145/1389095.1389256; Diuk C., 2008, P 25 INT C MACH LEAR, P240, DOI 10.1145/1390156.1390187; Edgers G., ATARI DEEP HIST VIDE; Floreano Dario, 2008, Evolutionary Intelligence, V1, DOI 10.1007/s12065-007-0002-4; Fogel D. B., 2001, BLONDIE24 PLAYING ED; Gauci J, 2008, P 23 NAT C ART INT A, P628; Genesereth M, 2005, AI MAG, V26, P62; Hansen N, 2006, STUD FUZZ SOFT COMP, V192, P75; Hausknecht M., 2012, P GEN EV COMP C JUL; Hester T, 2013, MACH LEARN, V90, P385, DOI 10.1007/s10994-012-5322-7; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hutter M., 2005, UNIVERSAL ARTIFICIAL; Kaiser L., 2012, P 26 AAAI C ART INT, P963; Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282; Le Q. V., 2011, CORR; Legg S., 2011, CORR; Lehman J., 2011, GENETIC PROGRAMMING, P37; Levine J., 2013, GEN VIDEO GAME PLAYI; Levine J., 2013, DAGSTUHL FOLLOWUPS, P77; Lipson H, 2000, NATURE, V406, P974; Lucas S. M., 2007, ACM SIGEVOLUTION NEW, V2, P37, DOI 10.1145/1399962.1399969; MacAlpine P., 2011, P 26 AAAI C ART INT, P1047; Miikkulainen R., 2010, ENCY MACHINE LEARNIN; Murphy VII T., 2013, ASS COMP HER SIGBOVI; Naddaf Y., 2010, THESIS U ALBERTA EDM; Parker M., 2009, P IEEE S COMP INT GA, P287; Parker M, 2008, 2008 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P151, DOI 10.1109/CIG.2008.5035634; Schaul T., 2013, P IEEE C COMP INT GA, DOI [10.1109/CIG.2013.6633610, DOI 10.1109/CIG.2013.6633610]; Schaul T., 2011, CORR; Schrum ., 2012, HUMAN LIKE COMBAT BE, P119; Stanley K. O., 2005, P IEEE S COMP INT GA; Stanley K. O., 2001, AI01290 U TEX AUST D; Stanley KO, 2009, ARTIF LIFE, V15, P185, DOI 10.1162/artl.2009.15.2.15202; Stanley KO, 2004, LECT NOTES COMPUT SC, V3103, P1226; Stanley KO, 2007, GENET PROGRAM EVOL M, V8, P131, DOI 10.1007/s10710-007-9028-8; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Stone P., 2001, P 18 INT C MACH LEAR, P537; Sutskever I., 2011, P 28 INT C MACH LEAR, P1017; Szita I, 2006, NEURAL COMPUT, V18, P2936, DOI 10.1162/neco.2006.18.12.2936; Togelius J., 2009, P IEEE S COMP INT GA, P156; Valsalam V. K., 2012, EVOL INTELL, V5, P1; Verbancsics P, 2010, J MACH LEARN RES, V11, P1737; Wintermute S., 2010, P 24 AAAI C ART INT	52	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1943-068X	1943-0698		IEEE T COMP INTEL AI	IEEE Trans. Comput. Intell. AI Games	DEC	2014	6	4					355	366		10.1109/TCIAIG.2013.2294713		12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	AX1UF	WOS:000346730700006		
J	Jiang, Y; Wang, DL; Liu, RS; Feng, ZM				Jiang, Yi; Wang, DeLiang; Liu, RunSheng; Feng, ZhenMing			Binaural Classification for Reverberant Speech Segregation Using Deep Neural Networks	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Binary classification; computational auditory scene analysis (CASA); deep neural networks (DNNs); room reverberation; speech segregation	SOURCE SEPARATION; MASK ESTIMATION; NOISE; RECOGNITION; TIME; INTELLIGIBILITY; LOCALIZATION; ALGORITHM; FREQUENCY; ENVIRONMENTS	Speech signal degradation in real environments mainly results from room reverberation and concurrent noise. While human listening is robust in complex auditory scenes, current speech segregation algorithms do not perform well in noisy and reverberant environments. We treat the binaural segregation problem as binary classification, and employ deep neural networks (DNNs) for the classification task. The binaural features of the interaural time difference and interaural level difference are used as the main auditory features for classification. The monaural feature of gammatone frequency cepstral coefficients is also used to improve classification performance, especially when interference and target speech are collocated or very close to one another. We systematically examine DNN generalization to untrained spatial configurations. Evaluations and comparisons show that DNN-based binaural classification produces superior segregation performance in a variety of multisource and reverberant conditions.	[Jiang, Yi; Liu, RunSheng; Feng, ZhenMing] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA; [Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA	Jiang, Y (reprint author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.	jiangyi09@mails.tsinghua.edu.cn; dwang@cse.ohio-state.edu; lrs-dee@tsinghua.edu.cn; fzm@mail.tsinghua.edu.cn			Air Force Office of Scientific Research [FA9550-12-1-0130]	The work of D. L. Wang was supported in part by the Air Force Office of Scientific Research under Grant FA9550-12-1-0130. This work was performed while the first author was a visiting scholar at the Ohio State University. A preliminary version of this paper was published by Interspeech 2014 [18]. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Mads Graesboll Christensen.	ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599; Anzalone MC, 2006, EAR HEARING, V27, P480, DOI 10.1097/01.aud.0000233891.86809.df; Blauert J., 1997, SPATIAL HEARING PSYC; Bregman AS, 1990, AUDITORY SCENE ANAL; Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929; Campbell D. R., 2005, Computing and Information Systems, V9; Cherry E. C., 1957, ON HUMAN COMMUN; Darwin CJ, 2008, PHILOS T R SOC B, V363, P1011, DOI 10.1098/rstb.2007.2156; Dillon H, 2012, HEARING AIDS; Garofolo JS, 1993, TIMIT ACOUSTIC PHONE; Han K, 2012, J ACOUST SOC AM, V132, P3475, DOI 10.1121/1.4754541; Harding S, 2006, IEEE T AUDIO SPEECH, V14, P58, DOI 10.1109/TSA.2005.860354; Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893; Heller LM, 2010, J ACOUST SOC AM, V128, P310, DOI 10.1121/1.3436524; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu GN, 2004, IEEE T NEURAL NETWOR, V15, P1135, DOI 10.1109/TNN.2004.832812; Hummersone C, 2010, IEEE T AUDIO SPEECH, V18, P1867, DOI 10.1109/TASL.2010.2051354; Jiang Y., 2014, P INTERSPEECH, P2400; Jin ZZ, 2009, IEEE T AUDIO SPEECH, V17, P625, DOI 10.1109/TASL.2008.2010633; Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603; Kokkinakis K, 2011, J ACOUST SOC AM, V129, P3221, DOI 10.1121/1.3559683; Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617; Mandel MI, 2010, IEEE T AUDIO SPEECH, V18, P382, DOI 10.1109/TASL.2009.2029711; May T, 2012, IEEE T AUDIO SPEECH, V20, P2016, DOI 10.1109/TASL.2012.2193391; Nakatani T, 1996, INT CONF ACOUST SPEE, P653, DOI 10.1109/ICASSP.1996.543205; Patterson R. D., 1988, 2341 MRC APPL PSYCH; Rickard S, 2007, SIGNALS COMMUN TECHN, P217, DOI 10.1007/978-1-4020-6479-1_8; Roman N, 2006, J ACOUST SOC AM, V120, P4040, DOI 10.1121/1.2355480; Roman N, 2011, J ACOUST SOC AM, V130, P2153, DOI 10.1121/1.3631668; Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463; Roman N., 2003, P ADV NEUR INF PROC, P1425; Seltzer ML, 2004, SPEECH COMMUN, V43, P379, DOI 10.1016/j.specom.2004.03.006; Shamsoddini A, 2001, SPEECH COMMUN, V33, P179, DOI 10.1016/S0167-6393(00)00015-7; Sinex DG, 2013, J ACOUST SOC AM, V133, P2390, DOI 10.1121/1.4792143; VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3; Wang D., 2006, COMPUTATIONAL AUDITO; Wang D.L., 2005, SPEECH SEPARATION HU; Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459; Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961; Woodruff J, 2013, IEEE T AUDIO SPEECH, V21, DOI 10.1109/TASL.2012.2236316; Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803	42	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	DEC	2014	22	12					2112	2121		10.1109/TASLP.2014.2361023		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AS7UI	WOS:000344459700016		
J	Buessler, JL; Smagghe, P; Urban, JP				Buessler, Jean-Luc; Smagghe, Philippe; Urban, Jean-Philippe			Image receptive fields for artificial neural networks	NEUROCOMPUTING			English	Article						Computer vision; Visual object recognition; Artificial neural networks model; Supervised learning algorithm; Visual receptive fields; Extreme Learning Machine	HANDWRITTEN DIGIT RECOGNITION; OBJECT RECOGNITION; NEOCOGNITRON; MODEL	This paper describes the structure of the Image Receptive Fields Neural Network (IRF-NN) introduced recently by our team. This structure extends simplified learning introduced by Extreme Learning Machine and Reservoir Computing techniques to the field of images. Neurons are organized in a single hidden layer feedforward network architecture with an original organization of the network's input weights. To represent color images efficiently, without prior feature extraction, the weight values linked to a neuron are determined by a 2-D Gaussian function. The activation of a neuron by an image presents the properties of a nonlinear localized receptive field, parameterized with a small number of degrees of freedom. A network composed of a large number of neurons, each associated with a randomly initialized and constant receptive field, induces a remarkable representation of the images. Supervised training determines only the output weights of the network. It is therefore extremely fast, without retro-propagation or iterations, adapted to large sets of images. The network is easy to implement, presents excellent generalization performances for classification applications, and allows the detection of unknown inputs. The efficiency of this technique is illustrated with several benchmarks, photo and video datasets. (C) 2014 Elsevier B.V. All rights reserved.	[Buessler, Jean-Luc; Smagghe, Philippe; Urban, Jean-Philippe] Univ Haute Alsace, Fac Sci & Tech, F-68093 Mulhouse, France	Urban, JP (reprint author), Univ Haute Alsace, Fac Sci & Tech, 4 Rue Freres Lumiere, F-68093 Mulhouse, France.	jp.urban@uha.fr					Aginsky V, 2000, VIS COGN, V7, P147; Anderson E., 1995, LAPACK USERS GUIDE R; Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005; Bishop C.M., 1995, NEURAL NETWORKS PATT; Cardoso A, 2013, NEUROCOMPUTING, V99, P575, DOI 10.1016/j.neucom.2012.07.027; Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Coates A., 2011, 14 INT C ART INT STA, V15; Cox D., 2011 IEEE INT C AUT, P8; Cristianini N., 2000, INTRO SUPPORT VECTOR; Daum P, 2011, LECT NOTES COMPUT SC, V6792, P95, DOI 10.1007/978-3-642-21738-8_13; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; Fukushima K, 2013, NEURAL NETWORKS, V40, P18, DOI 10.1016/j.neunet.2013.01.001; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Golub G. H., 1996, J HOPKINS STUDIES MA, V3rd; Hansen M., 1987, BIT, V27, P534; Haykin S., 1994, NEURAL NETWORKS COMP; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Jaeger H., 2001, 148 GERM NAT RES CTR; Krizhevsky A., ADV NEURAL INFORM PR, V25, P1106; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lindeberg T., 1993, Journal of Mathematical Imaging and Vision, V3, DOI 10.1007/BF01664794; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Matas J., 2004, 12 EUR SIGN PROC C E; Mikolajczyk K, 2005, IEEE I CONF COMP VIS, P1792; Nene S.A., 1996, TECHNICAL REPORT; Nilsback M.-E., 2006, IEEE C COMP VIS PATT, V2, P1447; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; Russ J. C., 1995, IMAGE PROCESSING HDB; Saxe A., 2011, P 28 INT C MACH LEAR, P1089; Smagghe P., 2013, EUR S ART NEUR NETW; Smagghe P., 2013, IJCNN; Tuytelaars Tinne, 2007, Foundations and Trends in Computer Graphics and Vision, V3, DOI 10.1561/0600000017; Verstraeten D, 2007, NEURAL NETWORKS, V20, P391, DOI 10.1016/j.neunet.2007.04.003; Viola P., 2001, P 2001 IEEE COMP SOC, V1, P1, DOI DOI 10.1109/CVPR.2001.990517; Zhang C., 2010, TECHNICAL REPORT, P1	42	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	NOV 20	2014	144						258	270		10.1016/j.neucom.2014.04.045		13	Computer Science, Artificial Intelligence	Computer Science	AO9LS	WOS:000341677800024		
J	Gan, JY; Li, LC; Zhai, YK; Liu, YH				Gan, Junying; Li, Lichen; Zhai, Yikui; Liu, Yinhua			Deep self-taught learning for facial beauty prediction	NEUROCOMPUTING			English	Article						Deep self-taught learning; Regression methods; Local binary pattern; Facial beauty prediction	MACHINE; ATTRACTIVENESS; ALGORITHM; MODELS	Most modern research of facial beauty prediction focuses on geometric features by traditional machine learning methods. Geometric features may easily lose much feature information characterizing facial beauty, rely heavily on accurate manual landmark localization of facial features and impose strict restrictions on training samples. Deep architectures have been recently demonstrated to be a promising area of research in statistical machine learning. In this paper, deep self-taught learning is utilized to obtain hierarchical representations, learn the concept of facial beauty and produce human-like predictor. Deep learning is helpful to recognize a broad range of visual concept effectively characterizing facial beauty. Through deep learning, reasonable apparent features of face images are extracted without depending completely on artificial feature selection. Self-taught learning, which has the ability of automatically improving network systems to understand the characteristics of data distribution and making recognition significantly easier and cheaper, is used to relax strict restrictions of training samples. Moreover, in order to choose a more appropriate method for mapping high-level representations into beauty ratings efficiently, we compare the performance of five regression methods and prove that support vector machine (SVM) regression is better. In addition, novel applications of deep self-taught learning on local binary pattern (LBP) and Gabor filters are presented, and the improvements on facial beauty prediction are shown by deep self-taught learning combined with LBP. Finally, human-like performance is obtained with learning features in full-sized and high-resolution images. (C) 2014 Elsevier B.V. All rights reserved.	[Gan, Junying; Li, Lichen; Zhai, Yikui; Liu, Yinhua] Wuyi Univ, Sch Informat Engn, Jiangmen 529020, Guangdong, Peoples R China	Zhai, YK (reprint author), Wuyi Univ, Sch Informat Engn, Jiangmen 529020, Guangdong, Peoples R China.	junyinggan@163.com; lilichen0906@163.com; yikuizhai@163.com; yinhualiu2109@163.com			National Natural Science Foundation of China [61072127, 61372193, 61070167]; NSF of Guangdong Province, PRC [S2013010013311, 10152902001000002, S2011010001085, S2011040004211]; High Level Personal Project of Guandong Colleges [[2010] 79]; Foundation for Distinguished Young Talents in Higher Education of Guangdong, China [2012LYM_0127]; Science Foundation of Young Teachers of Wuyi University [2013zk07]; Zhejiang Key Laboratory for Signal Processing [ZJKL_4_SP-OP2014-05]	This work is supported by the National Natural Science Foundation of China (No. 61072127, 61372193, and 61070167), the NSF of Guangdong Province, PRC (No. S2013010013311, 10152902001000002, S2011010001085, and S2011040004211), the High Level Personal Project of Guandong Colleges (No. [2010] 79), the Foundation for Distinguished Young Talents in Higher Education of Guangdong, China under Grant No. 2012LYM_0127, and Science Foundation of Young Teachers of Wuyi University(No. 2013zk07), and the Opening Project of Zhejiang Key Laboratory for Signal Processing (No. ZJKL_4_SP-OP2014-05).	Altwaijry H, 2013, IEEE WORK APP COMP, P117, DOI 10.1109/WACV.2013.6475008; Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364; Bastien F., 2010, 1353 DEP IRO U MONTR; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Brereton RG, 2010, ANALYST, V135, P230, DOI 10.1039/b918972f; Chen F., LECT NOTES COMPUTER, V6165; Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Doi E, 2003, NEURAL COMPUT, V15, P397, DOI 10.1162/089976603762552960; Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602; Fuller W.A., STATISTICS C, V37; Gray D, 2010, LECT NOTES COMPUT SC, V6316, P434, DOI 10.1007/978-3-642-15567-3_32; Hastie T., 2001, ELEMENTS STAT LEARNI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang G.B., 2012, P INT C COMP VIS PAT, P223; Kagian A, 2008, VISION RES, V48, P235, DOI 10.1016/j.visres.2007.11.007; Kagian A., 2007, ADV NEURAL INFORM PR; Kay S., 1993, FUNDAMENTALS STAT SI, P1; Lee H., 2010, THESIS STANFORD U; Lee H., 2009, P INT C MACH LEARN I, P21; Lee H., 2007, ADV NEURAL INFO PROC, P873; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Lee H., COMMUN ACM, V54; Mohammad N., 2009, P IEEE C COMP VIS PA, P2735; Mu Y., 2012, NEUROCOMPUTING, V99, P59; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Raina R, 2007, P 24 INT C MACH LEAR, P759, DOI DOI 10.1145/1273496.1273592; Rhodes G, 2006, ANNU REV PSYCHOL, V57, P199, DOI 10.1146/annurev.psych.57.102904.190208; Whitehill J., 2008, P FG 08, P1; Zahang D., 2011, PATTERN RECOGN, V44, P940	31	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	NOV 20	2014	144						295	303		10.1016/j.neucom.2014.05.028		9	Computer Science, Artificial Intelligence	Computer Science	AO9LS	WOS:000341677800027		
J	Rubinstein, R; Elad, M				Rubinstein, Ron; Elad, Michael			Dictionary Learning for Analysis-Synthesis Thresholding	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						Analysis dictionary learning; signal deblurring; sparse representation; thresholding	WAVELET SHRINKAGE; K-SVD; ALGORITHM; REPRESENTATIONS; REGRESSION; SPARSITY; MODEL	Thresholding is a classical technique for signal denoising. In this process, a noisy signal is decomposed over an orthogonal or overcomplete dictionary, the smallest coefficients are nullified, and the transform pseudo-inverse is applied to produce an estimate of the noiseless signal. The dictionaries used is this process are typically fixed dictionaries such as the DCT or Wavelet dictionaries. In this work, we propose a method for incorporating adaptive, trained dictionaries in the thresholding process. We present a generalization of the basic process which utilizes a pair of overcomplete dictionaries, and can be applied to a wider range of recovery tasks. The two dictionaries are associated with the analysis and synthesis stages of the algorithm, and we thus name the process analysis-synthesis thresholding. The proposed training method trains both the dictionaries and threshold values simultaneously given examples of original and degraded signals, and does not require an explicit model of the degradation. Experiments with small-kernel image deblurring demonstrate the ability of our method to favorably compete with dedicated deconvolution processes, using a simple, fast, and parameterless recovery process.	[Rubinstein, Ron; Elad, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Rubinstein, R (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.				European Community FP7-ERC program [320649]	The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Zhi-Quan (Tom) Luo. This work was supported by the European Community FP7-ERC program, Grant agreement no. 320649.	Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Adler A., 2010, EUR C COMP VIS ECCV; Adler A., 2010, INT C AC SPEECH SIGN; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Candes EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633; Chen Y., 2012, WORKSH AN OP LEARN V; Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954; DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Elad M, 2007, INVERSE PROBL, V23, P947, DOI 10.1088/0266-5611/23/3/007; Elad M, 2006, IEEE T INFORM THEORY, V52, P5559, DOI 10.1109/TIT.2006.885522; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; Hawe S., 2013, IEEE T IMAGE PROCESS, V22; Hel-Or Y, 2008, IEEE T IMAGE PROCESS, V17, P443, DOI 10.1109/TIP.2008.917204; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Katkovnik V, 2005, IEEE T IMAGE PROCESS, V14, P1469, DOI 10.1109/TIP.2005.851705; Kavukcuoglu K., 2010, ARXIV10103467; Kavukcuoglu K., 2010, C NEUR INF PROC SYST; Nam S, 2013, APPL COMPUT HARMON A, V34, P30, DOI 10.1016/j.acha.2012.03.006; Neelamani R, 2004, IEEE T SIGNAL PROCES, V52, P418, DOI 10.1109/TSP.2003.821103; Ophir B., 2011, EUR SIGN SPROC C EUS; Peyre G., 2011, SAMPL THEOR APPL SAM; Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551; Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477; Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445; Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI 10.1109/TIP.2002.1014998; Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Yaghoobi M., 2011, EUR SIGN PROC C EUSI; Yaghoobi M., 2012, INT C AC SPEECH SIGN	35	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1053-587X	1941-0476		IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	NOV 15	2014	62	22					5962	5972		10.1109/TSP.2014.2360157		11	Engineering, Electrical & Electronic	Engineering	AS7XX	WOS:000344466200014		
J	Ueda, M; Nishitani, Y; Kaneko, Y; Omote, A				Ueda, Michihito; Nishitani, Yu; Kaneko, Yukihiro; Omote, Atsushi			Back-Propagation Operation for Analog Neural Network Hardware with Synapse Components Having Hysteresis Characteristics	PLOS ONE			English	Article							DEVICE	To realize an analog artificial neural network hardware, the circuit element for synapse function is important because the number of synapse elements is much larger than that of neuron elements. One of the candidates for this synapse element is a ferroelectric memristor. This device functions as a voltage controllable variable resistor, which can be applied to a synapse weight. However, its conductance shows hysteresis characteristics and dispersion to the input voltage. Therefore, the conductance values vary according to the history of the height and the width of the applied pulse voltage. Due to the difficulty of controlling the accurate conductance, it is not easy to apply the back-propagation learning algorithm to the neural network hardware having memristor synapses. To solve this problem, we proposed and simulated a learning operation procedure as follows. Employing a weight perturbation technique, we derived the error change. When the error reduced, the next pulse voltage was updated according to the back-propagation learning algorithm. If the error increased the amplitude of the next voltage pulse was set in such way as to cause similar memristor conductance but in the opposite voltage scanning direction. By this operation, we could eliminate the hysteresis and confirmed that the simulation of the learning operation converged. We also adopted conductance dispersion numerically in the simulation. We examined the probability that the error decreased to a designated value within a predetermined loop number. The ferroelectric has the characteristics that the magnitude of polarization does not become smaller when voltages having the same polarity are applied. These characteristics greatly improved the probability even if the learning rate was small, if the magnitude of the dispersion is adequate. Because the dispersion of analog circuit elements is inevitable, this learning operation procedure is useful for analog neural network hardware.	[Ueda, Michihito; Nishitani, Yu; Kaneko, Yukihiro; Omote, Atsushi] Panasonic Corp, Adv Res Div, Sora Ku, Kyoto, Japan	Ueda, M (reprint author), Panasonic Corp, Adv Res Div, Sora Ku, Kyoto, Japan.	ueda.michihito@jp.panasonic.com					Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072; Bryson AE, 1969, APPL OPTIMAL CONTROL, P481; Coates A., 2013, P 30 INT C MACH LEAR, P1337; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HO Y., 2009, INT C COMP AID DES, P485; Hu M, 2014, IEEE T NEURAL NETWOR; Ishii H., 1992, International Electron Devices Meeting 1992. Technical Digest (Cat. No.92CH3211-0), DOI 10.1109/IEDM.1992.307395; JABRI M, 1992, IEEE T NEURAL NETWOR, V3, P154, DOI 10.1109/72.105429; Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h; Kaneko Y, 2013, S VLSI TECH, pT238; Kaneko Y, 2011, J APPL PHYS, V110, DOI 10.1063/1.3651098; Kaneko Y, 2014, IEEE T ELECTRON DEV, V61, P2827, DOI 10.1109/TED.2014.2331707; Kaneko Y, 2011, APPL PHYS LETT, P99; Kato Y, 2008, JPN J APPL PHYS, V47, P2719, DOI 10.1143/JJAP.47.2719; Kuzum D, 2012, NANO LETT, V12, P2179, DOI 10.1021/nl201040y; Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343; MILLER SL, 1990, J APPL PHYS, V68, P6463, DOI 10.1063/1.346845; Nishitani Y, 2013, JPN J APPL PHYS, V52, DOI 10.7567/JJAP.52.04CE06; Nishitani Y, 2012, J APPL PHYS, V111; Partzsch J, 2011, IEEE T NEURAL NETWOR, V22, P919, DOI 10.1109/TNN.2011.2134109; Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932; Ueda M, 2011, J APPL PHYS, V110, DOI 10.1063/1.3653830; Wang CA, 1999, IEEE T NEURAL NETWOR, V10, P1511, DOI 10.1109/72.809097; Xia QF, 2009, NANO LETT, V9, P3640, DOI 10.1021/nl901874j	24	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	NOV 13	2014	9	11							e112659	10.1371/journal.pone.0112659		10	Multidisciplinary Sciences	Science & Technology - Other Topics	AY6YT	WOS:000347709300081	25393715	
J	Mao, ZJ; Ma, CF; Huang, THM; Chen, YD; Huang, YF				Mao, Zijing; Ma, Chifeng; Huang, Tim H-M; Chen, Yidong; Huang, Yufei			BIMMER: a novel algorithm for detecting differential DNA methylation regions from MBDCap-seq data	BMC BIOINFORMATICS			English	Article							GENOME-WIDE IDENTIFICATION; BREAST-CANCER; GENE; CDC5L; PROGRESSION; INHIBITION; DENSITY	DNA methylation is a common epigenetic marker that regulates gene expression. A robust and cost-effective way for measuring whole genome methylation is Methyl-CpG binding domain-based capture followed by sequencing (MBDCap-seq). In this study, we proposed BIMMER, a Hidden Markov Model (HMM) for differential Methylation Regions (DMRs) identification, where HMMs were proposed to model the methylation status in normal and cancer samples in the first layer and another HMM was introduced to model the relationship between differential methylation and methylation statuses in normal and cancer samples. To carry out the prediction for BIMMER, an Expectation-Maximization algorithm was derived. BIMMER was validated on the simulated data and applied to real MBDCap-seq data of normal and cancer samples. BIMMER revealed that 8.83% of the breast cancer genome are differentially methylated and the majority are hypo-methylated in breast cancer.	[Mao, Zijing; Ma, Chifeng] Univ Texas San Antonio, Dept Elect & Comp Engn, San Antonio, TX 78229 USA; [Huang, Tim H-M] Univ Texas Hlth Sci Ctr San Antonio, Dept Mol Med, San Antonio, TX 78229 USA; [Chen, Yidong; Huang, Yufei] Univ Texas Hlth Sci Ctr San Antonio, Dept Epidemiol & Biostat, San Antonio, TX 78229 USA; [Chen, Yidong] Univ Texas Hlth Sci Ctr San Antonio, Greehey Childrens Canc Res Inst, San Antonio, TX 78229 USA; [Huang, Tim H-M; Chen, Yidong] Univ Texas Hlth Sci Ctr San Antonio, Canc Therapy & Res Ctr, San Antonio, TX 78229 USA	Chen, YD (reprint author), Univ Texas Hlth Sci Ctr San Antonio, Dept Epidemiol & Biostat, San Antonio, TX 78229 USA.	cheny8@uthscsa.edu; yufei.huang@utsa.edu			NSF [CCF-1246073]; Qatar National Research Fund [09-897-3-235]; UTSA Computational System Biology Core - National Institute on Minority Health and Health Disparities from the National Institutes of Health [G12MD007591]	Publication of this article has been funded by NSF Grant (CCF-1246073) to YH and a Qatar National Research Fund (09-897-3-235) to YH and YC to support this project. This work also has been supported by the help of UTSA Computational System Biology Core, funded by the National Institute on Minority Health and Health Disparities (G12MD007591) from the National Institutes of Health.	Ajuh P, 2000, EMBO J, V19, P6569, DOI 10.1093/emboj/19.23.6569; Bock C, 2010, NAT BIOTECHNOL, V28, P1106, DOI 10.1038/nbt.1681; Cheung AKL, 2011, P NATL ACAD SCI USA, V108, P8390, DOI 10.1073/pnas.1101747108; Choi HJ, 2010, BIOCHEM BIOPH RES CO, V400, P396, DOI 10.1016/j.bbrc.2010.08.084; Ganesh K, 2011, J BIOL CHEM, V286, P17091, DOI 10.1074/jbc.M110.208769; Groenen PMA, 1998, GENOMICS, V49, P218, DOI 10.1006/geno.1998.5254; Gu F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060980; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hon GC, 2012, GENOME RES, V22, P246, DOI 10.1101/gr.125872.111; Huang Z, 2012, ONCOGENE, V31, P3709, DOI 10.1038/onc.2011.529; Kharchenko PV, 2008, NAT BIOTECHNOL, V26, P1351, DOI 10.1038/nbt.1508; Kulis M, 2010, ADV GENET, V70, P27, DOI [10.1016/B978-0-12-380866-0.60002-2, 10.1016/S0065-2660(10)70002-X]; Lewin J, 2007, INT J BIOCHEM CELL B, V39, P1539, DOI 10.1016/j.biocel.2007.03.006; Li H, 2009, BIOINFORMATICS, V25, P1754, DOI 10.1093/bioinformatics/btp324; Lu XY, 2008, MOL CANCER RES, V6, P937, DOI 10.1158/1541-7786.MCR-07-2115; Luo RZ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085592; Malentacchi F, 2009, NUCLEIC ACIDS RES, V37, DOI 10.1093/nar/gkp383; Mitsui T, 2011, MOL CELL ENDOCRINOL, V345, P68, DOI 10.1016/j.mce.2011.07.021; Nair NU, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039573; Obazee O, 2013, BREAST CANCER RES TR, V138, P543, DOI 10.1007/s10549-013-2448-7; Qin ZHS, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-369; Robinson MD, 2010, GENOME RES, V20, P1719, DOI 10.1101/gr.110601.110; Seifert M, 2012, BIOINFORMATICS, V28, P2930, DOI 10.1093/bioinformatics/bts562; Sun TT, 2011, CELL, V144, P703, DOI 10.1016/j.cell.2011.02.003; Taslim C, 2009, BIOINFORMATICS, V25, P2334, DOI 10.1093/bioinformatics/btp384; Villa-Moruzzi E, 2013, MOL CELL BIOCHEM, V375, P151, DOI 10.1007/s11010-012-1537-y; Wakefield A, 2013, CANCER RES, V73, P745, DOI 10.1158/0008-5472.CAN-12-1321; Xu H, 2008, BIOINFORMATICS, V24, P2344, DOI 10.1093/bioinformatics/btn402; Yang A. S., 2004, NUCL ACIDS RES, V32; Yudkin HL, 1965, CHANNEL STATE TESTIN, V126; Zhang LS, 2014, PATHOL ONCOL RES; Zhang Y, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-9-r137	32	0	0	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	NOV 6	2014	15			12					S6	10.1186/1471-2105-15-S12-S6		12	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	AU6AR	WOS:000345685000006	25474268	
J	Alain, G; Bengio, Y				Alain, Guillaume; Bengio, Yoshua			What Regularized Auto-Encoders Learn from the Data-Generating Distribution	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						auto-encoders; denoising auto-encoders; score matching; unsupervised representation learning; manifold learning; Markov chains; generative models		What do auto-encoders learn about the underlying data-generating distribution? Recent work suggests that some auto-encoder variants do a good job of capturing the local manifold structure of data. This paper clarifies some of these previous observations by showing that minimizing a particular form of regularized reconstruction error yields a reconstruction function that locally characterizes the shape of the data-generating density. We show that the auto-encoder captures the score (derivative of the log-density with respect to the input). It contradicts previous interpretations of reconstruction error as an energy function. Unlike previous results, the theorems provided here are completely generic and do not depend on the parameterization of the auto-encoder: they show what the auto-encoder would tend to if given enough capacity and examples. These results are for a contractive training criterion we show to be similar to the denoising auto-encoder training criterion with small corruption noise, but with contraction applied on the whole reconstruction function rather than just encoder. Similarly to score matching, one can consider the proposed training criterion as a convenient alternative to maximum likelihood because it does not involve a partition function. Finally, we show how an approximate Metropolis-Hastings MCMC can be setup to recover samples from the estimated distribution, and this is confirmed in sampling experiments.	[Alain, Guillaume; Bengio, Yoshua] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada	Alain, G (reprint author), Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ H3C 3J7, Canada.	GUILLAUME.ALAIN@UMONTREAL.CA; YOSHUA.BENCIO@UMONTREAL.CA			NSERC; Canada Research Chairs; CIFAR	The authors thank Salah Rifai Max Welling, Yutian Chen and Pascal Vincent for fruitful discussions, and acknowledge the funding support from NSERC, Canada Research Chairs and CIFAR.	Bengio Y, 2011, LECT NOTES ARTIF INT, V6926, P1, DOI 10.1007/978-3-642-24477-3_1; Bengio Y., 2012, TECHNICAL REPORT; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Bengio Y., 2007, NIPS 2006; Bengio Yoshua, 2013, ICML 13; Bengio Yoshua, 2013, ARXIV13056663 U MONT; Cayton Lawrence, 2005, CS20080923 UCSD; Dacorogna B., 2004, INTRO CALCULUS VARIA; Gregor Karol, 2011, NIPS 2011; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Honglak Lee, 2009, ICML 2009; Hyvarinen A, 2007, COMPUT STAT DATA AN, V51, P2499, DOI 10.1016/j.csda.2006.09.003; Hyvarinen Aapo, 2005, J MACHINE LEARNING R, V6; Jain Viren, 2008, NIPS 2008; Kavukcuoglu K., 2009, CVPR 2009; Kingma Diederik, 2010, NIPS 2010; Narayanan Hariharan, 2010, NIPS 2010; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Ranzato M., 2007, NIPS 2006; Ranzato M., 2008, NIPS 2007; Rifai Salah, 2011, ICML 2011; Rifai Salah, 2012, ICML 2012; Rifai Salah, 2011, NIPS 2011; Salakhutdinov R., 2009, AISTATS 2009; Swersky Kevin, 2011, ICML 2011; Vincent Pascal, 2011, NEURAL COMPUTATION, V23; Vincent Pascal, 2008, ICML 2008	27	0	0	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	NOV	2014	15						3563	3593				31	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	CG2SV	WOS:000353126200008		
J	Charalampous, K; Gasteratos, A				Charalampous, Konstantinos; Gasteratos, Antonios			A tensor-based deep learning framework	IMAGE AND VISION COMPUTING			English	Article						Deep learning; Hierarchical Temporal Memory (HTM); Tensor algebra; L-1-norm; Support Vector Clustering; Spatio-temporal features	FACE RECOGNITION; SUPPORT; PROJECTIONS; ALGORITHM; NETWORKS; CORTEX; ROBUST	This paper presents an unsupervised deep leaming framework that derives spatio-temporal features for human-robot interaction. The respective models extract high-level features from low-level ones through a hierarchical network, viz. the Hierarchical Temporal Memory (HTM), providing at the same time a solution to the curse of dimensionality in shallow techniques. The presented work incorporates the tensor-based framework within the operation of the nodes and, thus, enhances the feature derivation procedure. This is due to the fact that tensors allow the preservation of the initial data format and their respective correlation and, moreover, attain more compact representations. The computational nodes form spatial and temporal groups by exploiting the multilinear algebra and subsequently express the samples according to those groups in terms of proximity. This generic framework may be applied in a diverse of visual data, while it has been examined on sequences of color and depth images, exhibiting remarkable performance. (C) 2014 Elsevier B.V. All rights reserved.	[Charalampous, Konstantinos; Gasteratos, Antonios] Democritus Univ Thrace, Dept Prod & Management Engn, GR-67100 Xanthi, Greece	Charalampous, K (reprint author), Democritus Univ Thrace, Dept Prod & Management Engn, Vas Sofias 12,Bldg 1,Off 205, GR-67100 Xanthi, Greece.	kchara@pme.duth.gr; agaster@pme.duth.gr					Bazzani L., 2011, INT C MACH LEARN, P937; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Ben-Hur A, 2002, J MACH LEARN RES, V2, P125, DOI 10.1162/15324430260185565; Ben-Hur A, 2001, ADV NEUR IN, V13, P367; Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125; Charalampous K, 2012, ELECTRON LETT, V48, P1259, DOI 10.1049/el.2012.1033; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S003614450037906X; Chiang JH, 2003, IEEE T FUZZY SYST, V11, P518, DOI 10.1109/TFUZZ.2003.814839; Dean Jeffrey, 2012, ADV NEURAL INFORM PR; Dollar P., 2005, IEEE INT WORKSH VIS, P65; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Efros A.A., 2003, ICCV, V2, P726; Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286; Fletcher R., 1987, PRACTICAL METHODS OP; George D., 2009, PLOS COMPUT BIOL, V5; George D., 2008, THESIS; Guo WW, 2012, IEEE T IMAGE PROCESS, V21, P816, DOI 10.1109/TIP.2011.2165291; He X., 2005, INT C MULT ACM, P132; He X., 2005, ADV NEURAL INFORM PR; Hinton G. E., 2012, CORR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang F.J., 2006, C COMP VIS PATT REC, V1, P284, DOI DOI 10.1109/CVPR.2006.164; Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002; Jhuang H, 2007, ICCV, P1, DOI [DOI 10.1109/ICCV.2007.4408988, 10.1109/ICCV.2007.4408988]; JI SW, 2013, T PATTERN ANAL MACH, V35, P221; Klaser A., 2008, BRIT MACH VIS C, p[275, 1]; Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001; Kostavelis I, 2012, PATTERN RECOGN LETT, V33, P670, DOI 10.1016/j.patrec.2011.11.017; Kotsia I, 2012, PATTERN RECOGN, V45, P4192, DOI 10.1016/j.patcog.2012.04.033; Kotsia I, 2011, PROC CVPR IEEE, P633, DOI 10.1109/CVPR.2011.5995663; Kurakin A, 2012, EUR SIGNAL PR CONF, P1975; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev Ivan, 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587756; Le Q., 2011, CVPR, P3361; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Lee J, 2005, IEEE T PATTERN ANAL, V27, P461; Lee J, 2006, IEEE T PATTERN ANAL, V28, P1869; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Mountcastle V.B., 1979, ORG PRINCIPLE CEREBR; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Norouzi M., 2009, COMP VIS PATT REC 20, P2735; Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005; Ranzato M, 2007, COMPUTER VISION PATT, P1; Ranzato M., 2011, COMP VIS PATT REC CV, P2857; Rodriguez M. D., 2008, CVPR, P1; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Tang Y., 2010, ICML, P1055; Tao D., 2006, COMP VIS PATT REC IE, V2, P1670; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881; VASILESCU MAO, 2003, PROC CVPR IEEE, P93, DOI DOI 10.1109/CVPR2003.1211457; von Melchner L, 2000, NATURE, V404, P871, DOI 10.1038/35009102; Wang H., 2009, BMVC; Wang J., 2012, ECCV, P872; Welling Max, 2004, ADV NEURAL INFORM PR, P1481; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; Yang JH, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P898; Zafeiriou S, 2009, IEEE T NEURAL NETWOR, V20, P217, DOI 10.1109/TNN.2008.2005293; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957	63	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856	1872-8138		IMAGE VISION COMPUT	Image Vis. Comput.	NOV	2014	32	11					916	929		10.1016/j.imavis.2014.08.003		14	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	AS7FP	WOS:000344422900009		
J	Gao, WX; Cao, QY; Qian, Y				Gao, Weixun; Cao, Qiying; Qian, Yao			Cross-Dialectal Voice Conversion with Neural Networks	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						voice conversion; neural network; cross-dialectal; frequency warping; pre-training; sequence training	SPEECH SYNTHESIS; REPRESENTATIONS; SELECTION	In this paper, we use neural networks (NNs) for cross-dialectal (Mandarin-Shanghainese) voice conversion using a bi-dialectal speakers' recordings. This system employs a nonlinear mapping function, which is trained by parallel mandarin features of source and target speakers, to convert source speaker's Shanghainese features to those of target speaker. This study investigates three training aspects: a) Frequency warping, which is supposed to be language independent; b) Pre-training, which drives weights to a better starting point than random initialization or be regarded as unsupervised feature learning; and c) Sequence training, which minimizes sequence-level errors and matches objectives used in training and converting. Experimental results show that the performance of cross-dialectal voice conversion is close to that of intra-dialectal. This benefit is likely from the strong learning capabilities of NNs, e.g., exploiting feature correlations between fundamental frequency (F0) and spectrum. The objective measures: log spectral distortion (LSD) and root mean squared error (RMSE) of F0, both show that pre-training and sequence training outperform the frame-level mean square error (MSE) training. The naturalness of the converted Shanghainese speech and the similarity between converted Shanghainese speech and target Mandarin speech are significantly improved.	[Gao, Weixun] Donghua Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China; [Cao, Qiying] Donghua Univ, Coll Comp Sci & Technol, Shanghai, Peoples R China; [Qian, Yao] Microsoft Res Asia, Speech Grp, Beijing, Peoples R China	Gao, WX (reprint author), Donghua Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.	gwx@shnu.edu.cn					Chen C.J., 1997, P EUROSPEECH, P1543; Chen L., 2013, P INTERSPEECH, P3053; Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; Desai S, 2010, IEEE T AUDIO SPEECH, V18, P954, DOI 10.1109/TASL.2010.2047683; Erhan D, 2010, J MACH LEARN RES, V11, P625; Gao WX, 2014, J INF SCI ENG, V30, P1149; Greisbach R., 1995, STUDIES FORENSIC PHO, V64, P49; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110; Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5; Kingsbury B, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P10; Krogh A., 1992, NEURAL INFORM PROCES, P950; Laroia R., 1991, P IEEE INT C AC SPEE, P641, DOI 10.1109/ICASSP.1991.150421; Lei M, 2010, INT CONF ACOUST SPEE, P4230, DOI 10.1109/ICASSP.2010.5495688; Ling Z.- H., 2006, P BLIZZ CHALL 2006 W; Mohamed A.-R., 2010, P INTERSPEECH, P2846; Nakashika T., 2013, P INTERSPEECH, P369; Rath S. P., 2009, P INT BRIGHT UK, P556; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sainath T.N., 2011, P ASRU, P30; Seide F., 2011, P ASRU, P24; Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472; Sundermann D, 2006, INT CONF ACOUST SPEE, P81; Talkin D., 1995, SPEECH CODING SYNTHE, V495, P495; Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344; Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820; Wu YJ, 2006, INT CONF ACOUST SPEE, P89; Wu Z.-Z, 2013, P IEEE CHIN SUMM INT, P104; Yu D., 2010, P NIPS WORKSH	30	0	0	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011, JAPAN	1745-1361			IEICE T INF SYST	IEICE Trans. Inf. Syst.	NOV	2014	E97D	11					2872	2880		10.1587/transinf.2014EDP7116		9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	AZ3QH	WOS:000348141300006		
J	Ko, C; Sohn, G; Remmel, TK; Miller, J				Ko, Connie; Sohn, Gunho; Remmel, Tarmo K.; Miller, John			Hybrid Ensemble Classification of Tree Genera Using Airborne LiDAR Data	REMOTE SENSING			English	Article						LiDAR; ensemble classification; tree genera; Random Forests	ALPHA SHAPE METRICS; LASER-SCANNING DATA; REMOTE-SENSING DATA; INDIVIDUAL TREES; MULTIPLE CLASSIFIERS; HYPERSPECTRAL DATA; RANDOM FORESTS; PULSE DENSITY; INTENSITY; HEIGHT	This paper presents a hybrid ensemble method that is comprised of a sequential and a parallel architecture for the classification of tree genus using LiDAR (Light Detection and Ranging) data. The two classifiers use different sets of features: (1) features derived from geometric information, and (2) features derived from vertical profiles using Random Forests as the base classifier. This classification result is also compared with that obtained by replacing the base classifier by LDA (Linear Discriminant Analysis), kNN (k Nearest Neighbor) and SVM (Support Vector Machine). The uniqueness of this research is in the development, implementation and application of three main ideas: (1) the hybrid ensemble method, which aims to improve classification accuracy, (2) a pseudo-margin criterion for assessing the quality of predictions and (3) an automatic feature reduction method using results drawn from Random Forests. An additional point-density analysis is performed to study the influence of decreased point density on classification accuracy results. By using Random Forests as the base classifier, the average classification accuracies for the geometric classifier and vertical profile classifier are 88.0% and 88.8%, respectively, with improvement to 91.2% using the ensemble method. The training genera include pine, poplar, and maple within a study area located north of Thessalon, Ontario, Canada.	[Ko, Connie; Sohn, Gunho; Miller, John] York Univ, Dept Earth & Space Sci & Engn, Toronto, ON M3J 1P3, Canada; [Remmel, Tarmo K.] York Univ, Dept Geog, Toronto, ON M3J 1P3, Canada	Ko, C (reprint author), York Univ, Dept Earth & Space Sci & Engn, 4700 Keele St,Ross North 430, Toronto, ON M3J 1P3, Canada.	cko@yorku.ca; gsohn@yorku.ca; remmelt@yorku.ca; jrmiller@yorku.ca			GeoDigital International Inc.; Ontario Centres for Excellence; Natural Sciences and Engineering Research Council of Canada	This research was funded by GeoDigital International Inc., Ontario Centres for Excellence, and a Discovery Grant from the Natural Sciences and Engineering Research Council of Canada. We thanks Richard Pollock, Konstantin Lisitsyn, Doug Parent, and Yulia Lazukova at GeoDigital International Inc. for their assistance in preparing the data; Junji Zhang, Jili Li, Yoonseok Jwa at York University, Canada, and Nakhyn Song at Inha University, South Korea for acquiring field surveying data for this study.	Alexander C, 2014, REMOTE SENS ENVIRON, V147, P156, DOI 10.1016/j.rse.2014.02.013; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Barilotti A., CURVATURE ANAL LIDAR; Brandtberg T, 2007, ISPRS J PHOTOGRAMM, V61, P325, DOI 10.1016/j.isprsjprs.2006.10.006; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Briem GJ, 2002, IEEE T GEOSCI REMOTE, V40, P2291, DOI 10.1109/TGRS.2002.802476; Clark ML, 2005, REMOTE SENS ENVIRON, V96, P375, DOI 10.1016/j.rse.2005.03.009; Cochrane MA, 2000, INT J REMOTE SENS, V21, P2075, DOI 10.1080/01431160050021303; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dettling M, 2004, BIOINFORMATICS, V20, P3583, DOI 10.1093/bioinformatics/bth447; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Engler R, 2013, FOREST ECOL MANAG, V310, P64, DOI 10.1016/j.foreco.2013.07.059; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Ghimire B, 2012, GISCI REMOTE SENS, V49, P623, DOI 10.2747/1548-1603.49.5.623; Ghosh A, 2014, INT J APPL EARTH OBS, V26, P49, DOI 10.1016/j.jag.2013.05.017; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Holmgren J, 2004, REMOTE SENS ENVIRON, V90, P415, DOI 10.1016/S0034-4257(03)00140-8; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kato A, 2009, REMOTE SENS ENVIRON, V113, P1148, DOI 10.1016/j.rse.2009.02.010; Kavzoglu T, 2013, INT J REMOTE SENS, V34, P4224, DOI 10.1080/01431161.2013.774099; Kim S, 2011, REMOTE SENS ENVIRON, V115, P3329, DOI 10.1016/j.rse.2011.07.016; Ko C., COMP STUDY USING GEO; Ko C, 2013, CAN J REMOTE SENS, V39, pS73, DOI 10.5589/m13-024; Korpela I, 2010, SILVA FENN, V44, P319, DOI 10.14214/sf.156; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Li M, 2013, GISCI REMOTE SENS, V50, P361, DOI 10.1080/15481603.2013.819161; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Long JA, 2013, GISCI REMOTE SENS, V50, P418, DOI 10.1080/15481603.2013.817150; Magnusson M, 2007, FOREST SCI, V53, P619; Mellor A, 2013, REMOTE SENS-BASEL, V5, P2838, DOI 10.3390/rs5062838; Orka H.O., UTILIZING AIRBORNE L; Orka HO, 2009, REMOTE SENS ENVIRON, V113, P1163, DOI 10.1016/j.rse.2009.02.002; Palmason J.A., FUSION MORPHOLOGICAL; R Development Core Team, R LANG ENV STAT COMP; Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7; Ruta D., 2000, Computing and Information Systems, V7; Samadzadegan F, 2010, LECT NOTES COMPUT SC, V5997, P254; Schwing A., ADAPTIVE RANDOM FORE; Serpico S.B., COMP FEATURE REDUCTI; Tong S, 2002, J MACH LEARN RES, V2, P45; Vauhkonen J, 2008, CAN J REMOTE SENS, V34, pS441; Vauhkonen J, 2009, FOREST SCI, V55, P37; Vauhkonen J, 2010, REMOTE SENS ENVIRON, V114, P1263, DOI 10.1016/j.rse.2010.01.016; Zhang CY, 2013, GISCI REMOTE SENS, V50, P562, DOI 10.1080/15481603.2013.836807; Zhou Z.H., 2012, CHAPMAN HALL CRC MAC	47	0	0	MDPI AG	BASEL	POSTFACH, CH-4005 BASEL, SWITZERLAND	2072-4292			REMOTE SENS-BASEL	Remote Sens.	NOV	2014	6	11					11225	11243		10.3390/rs61111225		19	Remote Sensing	Remote Sensing	AU3RG	WOS:000345530700044		
J	Lei, J; Li, GH; Tu, D; Guo, Q				Lei, Jun; Li, GuoHui; Tu, Dan; Guo, Qiang			Convolutional restricted Boltzmann machines learning for robust visual tracking	NEURAL COMPUTING & APPLICATIONS			English	Article						CRBM; Object tracking; Feature selection; Naive Bayes classifier		It is a critical step to choose visual features in object tracking. Most existing tracking approaches adopt handcrafted features, which greatly depend on people's prior knowledge and easily become invalid in other conditions where the scene structures are different. On the contrary, we learn informative and discriminative features from image data of tracking scenes itself. Local receptive filters and weight sharing make the convolutional restricted Boltzmann machines (CRBM) suit for natural images. The CRBM is applied to model the distribution of image patches sampled from the first frame which shares same properties with other frames. Each hidden variable corresponding to one local filter can be viewed as a feature detector. Local connections to hidden variables and max-pooling strategy make the extracted features invariant to shifts and distortions. A simple naive Bayes classifier is used to separate object from background in feature space. We demonstrate the effectiveness and robustness of our tracking method in several challenging video sequences. Experimental results show that features automatically learned by CRBM are effective for object tracking.	[Lei, Jun; Li, GuoHui; Tu, Dan; Guo, Qiang] Natl Univ Def Technol, Dept Syst Engn, Coll Informat Syst & Management, Changsha 410073, Hunan, Peoples R China	Lei, J (reprint author), Natl Univ Def Technol, Dept Syst Engn, Coll Informat Syst & Management, Changsha 410073, Hunan, Peoples R China.	leijun1987@gmail.com			State Key Laboratory of Mathematical Engineering and Advanced Computing [2013A08]	This work was partially supported by the Open Project Program of the State Key Laboratory of Mathematical Engineering and Advanced Computing Grant 2013A08.	Alper Yilmaz, 2006, ACM COMPUT SURV, V38, P1; Anastasios Doulamis, 2011, MULTIMED TOOLS APPL, V50, P49; Bashir Faisal, 2006, P 9 IEEE INT WORKSH; Boris Babenko, 2011, IEEE T PATTERN ANAL, V33, P2259; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Feng Tang, 2009, IEEE COMP SOC C COMP, P1; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Grabner M., 2007, IEEE C COMP VIS PATT, P1; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Jepson Allan D, 2013, IEEE T PATTERN ANAL, V25, P1296; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Li HX, 2011, PROC CVPR IEEE, P1305; Norouzi M, 2007, THESIS SHARIF U TECH; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96; Yoshua Bengio, 2009, LEARNING DEEP ARCHIT; Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678; Zhang K., 2012, EUR C COMP VIS FLOR, P866	19	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0941-0643	1433-3058		NEURAL COMPUT APPL	Neural Comput. Appl.	NOV	2014	25	6					1383	1391		10.1007/s00521-014-1625-x		9	Computer Science, Artificial Intelligence	Computer Science	AR8KM	WOS:000343824000015		
J	Wang, GS; Sim, KC				Wang, Guangsen; Sim, Khe Chai			Regression-Based Context-Dependent Modeling of Deep Neural Networks for Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Articulatory features; context dependent modeling; deep neural network; logistic regression	HIDDEN MARKOV-MODELS	The data sparsity problem is addressed by using the decision tree state clusters as the training targets for the state-of-the-art context-dependent (CD) deep neural network (DNN) systems. The CD states within a cluster cannot be distinguished at the frame level. We surmise that the state clustering may cause an issue for the standard CD-DNNs, which has so far not been addressed in the literature. In this paper, a logistic regression framework is proposed for the CD-DNNs based on a set of broad phone classes to address both the data sparsity and the clustering problems. To address the data sparsity issue, the triphones are clustered into shorter biphones with broad phone contexts under multiple articulatory categories. A DNN is trained to discriminate the disjoint biphone clusters within each articulatory category. The regression bases are formed by the concatenated log posterior probabilities of all the broad phone DNNs. Logistic regression is used to transform the regression bases into the triphone state posteriors. Clustering of the regression parameters is used to reduce the regression model complexity while still achieving unique acoustic scores for all possible triphones. Based on some approximations, the regression model can be trained as a sparse softmax layer and its parameters can be learned by optimizing the cross-entropy criterion. The experimental results on a broadcast news transcription task reveal that the proposed regression-based CD-DNN significantly outperforms the standard CD-DNN. The best system provides a 1.3% absolute word error rate reduction compared to the best standard CD-DNN system.	[Wang, Guangsen; Sim, Khe Chai] Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117417, Singapore	Wang, GS (reprint author), Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117417, Singapore.	guangsen.soc.nus@gmail.com; simkc@comp.nus.edu.sg			Singapore National Research Foundation under its International Research Centre @ Singapore	This work was supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Vincent Vanhoucke.	Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090; DENG L, 1994, J ACOUST SOC AM, V95, P2702, DOI 10.1121/1.409839; Gales M. J. F., 1996, GENERATION USE REGRE; Graff David, 1999, P DARPA BROADC NEWS, P57; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang X., 1989, V89136 CARN MELL U C; Hwang MY, 1993, IEEE T SPEECH AUDI P, V1, P414; Lee C.-H., 2007, P INTERSPEECH; LEE KF, 1990, IEEE T ACOUST SPEECH, V38, P599, DOI 10.1109/29.52701; Metze F., 2005, ARTICULATORY FEATURE; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010; Povey D., 2011, P IEEE WORKSH AUT SP; Povey D., 2004, THESIS CAMBRIDGE U; Reichl W, 2000, IEEE T SPEECH AUDI P, V8, P555, DOI 10.1109/89.861375; Sainath T.N., 2011, P ASRU, P30; Schwarz P., 2008, PHONEME RECOGNITION; Seide F., 2011, P ASRU, P24; Sim KC, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P546, DOI 10.1109/ASRU.2009.5372910; Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008; Siohan O., 2005, P INT C AC SPEECH SI; S.J.Y, 2009, HTK BOOK VERSION 3 4; Valtchev V, 1997, SPEECH COMMUN, V22, P303, DOI 10.1016/S0167-6393(97)00029-0; Wang G., 2012, P ICASSP, P4717; Wang GS, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P338; Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824; Young SJ, 1994, P ARPA HUM LANG TECH, P307, DOI DOI 10.3115/1075812.1075885; Yu K, 2011, SPEECH COMMUN, V53, P914, DOI 10.1016/j.specom.2011.03.003	31	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290			IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.	NOV	2014	22	11					1660	1669		10.1109/TASLP.2014.2344855		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	AO8HW	WOS:000341596200008		
J	Zou, Q; Cao, Y; Li, QQ; Huang, CH; Wang, S				Zou, Qin; Cao, Yu; Li, Qingquan; Huang, Chuanhe; Wang, Song			Chronological classification of ancient paintings using appearance and shape features	PATTERN RECOGNITION LETTERS			English	Article						Painting classification; Painting style analysis; Deep learning; Image classification	SYSTEM; ART	Ancient paintings are valuable for historians and archeologists to study the humanities, customs and economy of the corresponding eras. For this purpose, it is important to first determine the era in which a painting was drawn. This problem can be very challenging when the paintings from different eras present a same topic and only show subtle difference in terms of the painting styles. In this paper, we propose a novel computational approach to address this problem by using the appearance and shape features extracted from the paintings. In this approach, we first extract the appearance and shape features using the SIFT and kAS descriptors, respectively. We then encode these features with deep learning in an unsupervised way. Finally, we combine all the features in the form of bag-of-visual-words and train a classifier in a supervised fashion. In the experiments, we collect 660 Flying-Apsaras paintings from Mogao Grottoes in Dunhuang, China and classify them into three different eras, with very promising results. (C) 2014 Elsevier B.V. All rights reserved.	[Zou, Qin; Huang, Chuanhe] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China; [Cao, Yu; Wang, Song] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA; [Li, Qingquan] Shenzhen Univ, Shenzhen Key Lab Spatial Informat Smart Sensing &, Shenzhen 518060, Shandong, Peoples R China	Zou, Q (reprint author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.	qinnzou@gmail.com; cao@cec.sc.edu; qqIi@whu.edu.cn; huangch@whu.edu.cn; songwang@sc.edu	Cao, Yu/G-9532-2015		National Basic Research Program of China [2012CB725303]; China Postdoctoral Science Foundation [2012M521472]; National Natural Science Foundation of China [61301277, 41371431]; Hubei Provincial Natural Science Foundation [2013CFB299]; AFOSR [FA9550-1-1-0327]; NSF [IIS-1017199]	This research was supported by the National Basic Research Program of China under Grant No. 2012CB725303, the China Postdoctoral Science Foundation funded project (2012M521472), National Natural Science Foundation of China (61301277 and 41371431), Hubei Provincial Natural Science Foundation (2013CFB299), the fund of AFOSR FA9550-1-1-0327, and NSF IIS-1017199.	Arora R.S., 2012, ICPR, P3541; Bengio Y., 2006, NIPS, P153; BRESSAN M, 2008, IEEE IMAGE PROC, P113; Chang C.C., 2011, ACM T INTEL SYST TEC, V2, P2, DOI DOI 10.1145/1961189.1961199; Condorovici RG, 2013, LECT NOTES COMPUT SC, V7944, P687; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Graham D.J., 2012, WILEY INTERDISCIPLIN, V4, P115; Gunsel B., 2005, ICIP, P558; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Icoglu O., 2004, EUS, P749; Ivanoya K., 2008, SERDICA J COMPUTING, V2, P111; Jacobsen CR, 2013, SIGNAL PROCESS, V93, P579, DOI 10.1016/j.sigpro.2012.09.019; Khan F.S., 2010, 2010 CREATE C, P329; Lewis PH, 2004, IEEE T IMAGE PROCESS, V13, P302, DOI 10.1109/TIP.2003.821346; Li Jia, 2004, IEEE Trans Image Process, V13, P340, DOI 10.1109/TIP.2003.821349; Lombardi T., 2004, ACM SIGMM MIR, P107; Lombardi T., 2005, THESIS PACE U; Lowe D., 1999, INT C COMP VIS CORF, P1150; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1; Mitov I., 2012, LNCS, V6411, P146; Perronnin F., 2007, CVPR, P1; Ranzato M. A., 2006, NIPS, P1137; Sablatnig R, 1998, INT C PATT RECOG, P172; Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672; Stork DG, 2009, LECT NOTES COMPUT SC, V5702, P9; Temel B., 2009, J ELECT ELECT ENG, V9, P791; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Weijer J. V. D., 2007, CVPR, P1; Yu X., 2007, BRIT MACH VIS C, P1; Zhong S., 2011, ACM MULTIMEDIA, P343; Zujovic J., 2009, IEEE INT WORKSH MULT, P1	34	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV 1	2014	49						146	154		10.1016/j.patrec.2014.07.002		9	Computer Science, Artificial Intelligence	Computer Science	AR8WO	WOS:000343852400020		
J	Aly, S				Aly, Saleh			Learning invariant local image descriptor using convolutional Mahalanobis self-organising map	NEUROCOMPUTING			English	Article						Local feature descriptor; Mahalanobis self-organising map; Handwritten digit recognition; Face recognition	FACE RECOGNITION; NEURAL-NETWORKS; FEATURES; SOM; EIGENFACES; ALGORITHM; PCA	The image descriptor is a critical issue for most image recognition problems. Local image descriptors based on Gabor filters, SIFT, HOG and LBP have exhibited good image representation for many applications. However, these descriptors are designed in a hand-crafted way and the extracted features may not be appropriate from one application to another. In this paper, a new learning based mechanism is proposed to learn invariant image features that are optimal for image representation in a data-driven way. Particularly, a new stochastic mini-batch learning algorithm is proposed to train a Mahalanobis self-organising map (MSOM) model. The MSOM model consists of a group of connected neurons where each neuron is attached with a set of sub-neurons. In this model, neurons learn local features from training images while sub-neurons learn local variations. In the proposed MSOM model, invariance is achieved by learning both neuron means and covariance matrix for each neuron. The principal eigenvectors of the learned covariance matrices are then used to represent local variations of the learned features. Two new models based on SOM and MSOM, namely convolutional SOM (CSOM) and convolutional Mahalanobis SOM (CMSOM), are also proposed as local image descriptors using local feature histograms. The CSOM and CMSOM have a similar structure as other convolutional neural networks (CNNs). However, the CSOM and CMSOM employ an index of the best learned feature instead of the feature response used in CNNs. Experimental results on the ORL and Yale face databases and the MNIST handwritten digit database show the robustness of the proposed methods. (C) 2014 Elsevier B.V. All rights reserved.	Aswan Univ, Fac Engn, Dept Elect Engn, Aswan 81542, Egypt	Aly, S (reprint author), Aswan Univ, Fac Engn, Dept Elect Engn, Aswan 81542, Egypt.	saleh@aswu.edu.eg					Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Aly S, 2008, IEEE IJCNN, P845, DOI 10.1109/IJCNN.2008.4633896; Aly Saleh, 2008, Artificial Life and Robotics, V13, DOI 10.1007/s10015-008-0555-z; Aly S., 2010, 2010 20 INT C PATT R, P2909, DOI 10.1109/ICPR.2010.713; Aly S, 2009, LECT NOTES COMPUT SC, V5863, P733, DOI 10.1007/978-3-642-10677-4_84; Aly S.K., 2009, MVA, P475; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Dalai N, 2005, IEEE COMP SOC C COMP, V1, P886, DOI DOI 10.1109/CVPR.2005.177; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Duda R, 2001, PATTERN CLASSIFICATI; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang D, 2008, NEUROCOMPUTING, V71, P3544, DOI 10.1016/j.neucom.2007.10.004; Kohonen T, 2001, SELF ORGANIZING MAPS; Kohonen T, 1997, NEURAL COMPUT, V9, P1321, DOI 10.1162/neco.1997.9.6.1321; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Larochelle H, 2009, J MACH LEARN RES, V10, P1; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 2004, P 2004 IEEE COMP SOC, V2, P11; Lee H., 2009, P 26 ANN INT C MACH, V11, P609, DOI DOI 10.1145/1553374.1553453; Lopez-Rubio E, 2004, NEURAL NETWORKS, V17, P261, DOI 10.1016/j.neunet.2003.04.001; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Moller R, 2004, NEUROCOMPUTING, V62, P305, DOI 10.1016/j.neucom.2003.09.014; Ruiz-del-Solar J, 1998, NEUROCOMPUTING, V21, P7, DOI 10.1016/S0925-2312(98)00041-1; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341300; Serre T, 2005, PROC CVPR IEEE, P994; Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V., 1999, NATURE STAT LEARNING; Yang XD, 2013, PATTERN RECOGN LETT, V34, P1130, DOI 10.1016/j.patrec.2013.03.009; Yu K., 2009, ADV NEURAL INFORM PR, V22, P2223	34	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	OCT 22	2014	142				SI		239	247		10.1016/j.neucom.2014.03.060		9	Computer Science, Artificial Intelligence	Computer Science	AN1KO	WOS:000340341400025		
J	Wang, ZY; Cui, P; Li, FT; Chang, E; Yang, SQ				Wang, Zhiyu; Cui, Peng; Li, Fangtao; Chang, Edward; Yang, Shiqiang			A data-driven study of image feature extraction and fusion	INFORMATION SCIENCES			English	Article						Image annotation; Image feature; Web-scale; Fusion	OBJECT RECOGNITION; CORTEX; CLASSIFICATION; RETRIEVAL; STIMULI; SCALE	Feature analysis is the extraction and comparison of signals from multimedia data, which can subsequently be semantically analyzed. Feature analysis is the foundation of many multimedia computing tasks such as object recognition, image annotation, and multimedia information retrieval. In recent decades, considerable work has been devoted to the research of feature analysis. In this work, we use large-scale datasets to conduct a comparative study of four state-of-the-art, representative feature extraction algorithms: color-texture codebook (CT), SIFT codebook, HMAX, and convolutional networks (ConvNet). Our comparative evaluation demonstrates that different feature extraction algorithms enjoy their own advantages, and excel in different image categories. We provide key observations to explain where these algorithms excel and why. Based on these observations, we recommend feature extraction principles and identify several pitfalls for researchers and practitioners to avoid. Furthermore, we determine that in a large training dataset with more than 10,000 instances per image category, the four evaluated algorithms can converge to the same high level of category-prediction accuracy. This result supports the effectiveness of the data-driven approach. Finally, based on learned clues from each algorithm's confusion matrix, we devise a fusion algorithm to harvest synergies between these four algorithms and further improve class-prediction accuracy. (C) 2014 Elsevier Inc. All rights reserved.	[Wang, Zhiyu; Cui, Peng; Yang, Shiqiang] Tsinghua Univ, Dept Comp Sci, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China; [Wang, Zhiyu; Cui, Peng; Yang, Shiqiang] Tsinghua Univ, Beijing Key Lab Networked Multimedia, Beijing 100084, Peoples R China; [Li, Fangtao; Chang, Edward] Google Beijing, Beijing, Peoples R China	Cui, P (reprint author), Tsinghua Univ, Dept Comp Sci, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	cuip@mail.tsinghua.edu.cn			National Natural Science Foundation of China [61370022, 61003097, 60933013, 61210008]; International Science and Technology Cooperation Program of China [2013DFG12870]; National Program on Key Basic Research Project [2011CB302206]	This work is supported by the National Natural Science Foundation of China (Nos. 61370022, 61003097, 60933013, and 61210008), International Science and Technology Cooperation Program of China (No. 2013DFG12870), and the National Program on Key Basic Research Project (No. 2011CB302206).	Alajlan Naif, 2012, INF SCI; Bengio Y., 2009, LEARNING DEEP ARCHIT; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Cao Y., 2010, IEEE C COMP VIS PATT; Chang E., 2011, FDN LARGE SCALE MULT; Chang E. Y., 2000, Proceedings IEEE Workshop on Content-Based Access of Image and Video Libraries, DOI 10.1109/IVL.2000.853848; Chang E.Y., 2007, ADV NEURAL INFORM PR, V20, P16; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; Cui P, 2012, IEEE T MULTIMEDIA, V14, P102, DOI 10.1109/TMM.2011.2176110; Cui P, 2011, DATA MIN KNOWL DISC, V22, P467, DOI 10.1007/s10618-010-0195-5; Cui Peng, 2007, CVPR, P1; Deng Jia, 2009, IEEE C COMP VIS PATT; Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3; Dor O, 2012, INFORM SCIENCES, V189, P176, DOI 10.1016/j.ins.2011.11.039; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gawne TJ, 2002, J NEUROPHYSIOL, V88, P1128, DOI 10.1152/jn.00131.2002; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083; Goodrum A. A., 2000, Informing Science, V3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; Iyengar G., 2003, P 11 ACM INT C MULT, P255; Jegou H., 2009, IEEE INT C COMP VIS; Jiang Y.-G., 2007, ACM INT C IM VID RET; Kohavi R., 1998, MACH LEARN, V30, P271, DOI DOI 10.1023/A:1017181826899; Lampl I, 2004, J NEUROPHYSIOL, V92, P2704, DOI 10.1152/jn.00060.2004; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LEU JG, 1991, PATTERN RECOGN, V24, P949, DOI 10.1016/0031-3203(91)90092-J; Liu Shaowei, 2013, COMPUT VIS IMAGE UND; Lowe D.G., 1999, IEEE INT C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Miller EK, 2000, NAT REV NEUROSCI, V1, P59, DOI 10.1038/35036228; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 1997, COGNITIVE PSYCHOL, V34, P72, DOI 10.1006/cogp.1997.0667; Pedronette Daniel Carlos Guimardes, 2012, INF SCI, V207, P19; Pichler O, 1996, PATTERN RECOGN, V29, P733, DOI 10.1016/0031-3203(95)00127-1; Prasad S, 2008, IEEE T GEOSCI REMOTE, V46, P1448, DOI 10.1109/TGRS.2008.916207; Ranzato M.A., 2007, IEEE C COMP VIS PATT; Riesenhuber M, 1999, NEURON, V24, P87, DOI 10.1016/S0896-6273(00)80824-7; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; Roubos JA, 2003, INFORM SCIENCES, V150, P77, DOI 10.1016/S0020-0255(02)00369-9; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Serre T., 2006, THESIS MIT; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith J., 1996, IEEE T PATTERN ANAL; Snoek C. G. M., 2005, P 13 ANN ACM INT C M, P399, DOI 10.1145/1101149.1101236; Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013; Tong S., 2001, ACM MULTIMEDIA, V9, P107; van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400; Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397; Xu C., 2012, PRACT APPL INTELL SY, P129; Yager RR, 2004, INFORM SCIENCES, V163, P175, DOI 10.1016/j.ins.2003.03.018; Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5; Yasuda M., 2009, CEREBRAL CORTEX; Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782; Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009; Zha Z.J., 2009, P 17 ACM INT C MULT, P15, DOI 10.1145/1631272.1631278; Zha Z.-J., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587384; Zhang Xiao Ming, 2011, IEEE INT C COMM ICC, P1	62	0	0	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255	1872-6291		INFORM SCIENCES	Inf. Sci.	OCT 10	2014	281						536	558		10.1016/j.ins.2014.02.030		23	Computer Science, Information Systems	Computer Science	AN1AR	WOS:000340315600037		
J	Bu, SH; Cheng, SG; Liu, ZB; Han, JW				Bu, Shuhui; Cheng, Shaoguang; Liu, Zhenbao; Han, Junwei			Multimodal Feature Fusion for 3D Shape Recognition and Retrieval	IEEE MULTIMEDIA			English	Article							DESCRIPTORS	A 3D feature-learning framework combines the different modality data that characterizes a 3D shape to promote the discriminability of unimodal features.	[Bu, Shuhui; Cheng, Shaoguang; Liu, Zhenbao; Han, Junwei] Northwestern Polytech Univ, Xian, Peoples R China; [Bu, Shuhui; Cheng, Shaoguang; Liu, Zhenbao; Han, Junwei] Northwestern Polytech Univ, Sch Aeronaut, Xian, Peoples R China	Liu, ZB (reprint author), Northwestern Polytech Univ, Xian, Peoples R China.	bushuhui@nwpu.edu.cn; chengshaoguang@mail.nwpu.edu.cn; liuzhenbao@nwpu.edu.cn; jhan@nwpu.edu.cn			National Natural Science Foundation of China [61202185, 61003137, 91120005, 61473231]; Fundamental Research Funds for the Central Universities [310201401-(JCQ01009), 310201401-(JCQ01012)]; Shaanxi Natural Science Fund [2012JQ8037]; Open Project Program of the State Key Lab of CAD&CG at Zhejiang University [A1306]	This work is partly supported by grants from the National Natural Science Foundation of China (61202185, 61003137, 91120005, and 61473231), the Fundamental Research Funds for the Central Universities (310201401-(JCQ01009, JCQ01012)), Shaanxi Natural Science Fund (2012JQ8037), and the Open Project Program of the State Key Lab of CAD&CG (A1306) at Zhejiang University.	Barra V., 2013, P EUR WORKSH 3D OBJ, P25; Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405; Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838; Bu SH, 2014, VISUAL COMPUT, V30, P867, DOI 10.1007/s00371-014-0970-1; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Laga H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516975; Laga H, 2010, P 3 EUR C 3D OBJ RET, P15; Lian Z., 2010, SHAPE MODELING INT, P25; Litman R, 2014, IEEE T PATTERN ANAL, V36, P171, DOI 10.1109/TPAMI.2013.148; Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9; Shen Y.-T., 2003, PRINCIPLES NONLINEAR, P1; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1070-986X	1941-0166		IEEE MULTIMEDIA	IEEE Multimedia	OCT-DEC	2014	21	4					38	46				9	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	AT5PQ	WOS:000344995000006		
J	Szymanski, L; McCane, B				Szymanski, Lech; McCane, Brendan			Deep Networks are Effective Encoders of Periodicity	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS			English	Article						Deep architectures; universal approximation	UNIVERSAL APPROXIMATORS; BELIEF NETWORKS; BOLTZMANN MACHINES; RECOGNITION; DIMENSION	We present a comparative theoretical analysis of representation in artificial neural networks with two extreme architectures, a shallow wide network and a deep narrow network, devised to maximally decouple their representative power due to layer width and network depth. We show that, given a specific activation function, models with comparable VC-dimension are required to guarantee zero error modeling of real functions over a binary input. However, functions that exhibit repeating patterns can be encoded much more efficiently in the deep representation, resulting in significant reduction in complexity. This paper provides some initial theoretical evidence of when and how depth can be extremely effective.	[Szymanski, Lech; McCane, Brendan] Univ Otago, Dept Comp Sci, Dunedin 9016, New Zealand	Szymanski, L (reprint author), Univ Otago, Dept Comp Sci, Dunedin 9016, New Zealand.	lechszym@cs.otago.ac.nz; mccane@cs.otago.ac.nz					Anthony M., 1999, NEURAL NETWORK LEARN; Bengio Y., 2007, LARGE SCALE KERNEL M, P321; Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Delalleau O., 2011, ADV NEURAL INFORM PR, P666; GOLDBERG PW, 1995, MACH LEARN, V18, P131, DOI 10.1007/BF00993408; Hastad J., 1986, P 18 ANN ACM S THEOR, P6, DOI 10.1145/12130.12132; Hastad J., 1991, Computational Complexity, V1, DOI 10.1007/BF01272517; Hecht-Nielsen R., 1987, P IEEE 1 ANN INT C N, V3; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Koiran P, 1997, J COMPUT SYST SCI, V54, P190, DOI 10.1006/jcss.1997.1479; Larochelle H., 2007, P 24 INT C MACH LEAR, V227, P473; Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Montufar G, 2011, NEURAL COMPUT, V23, P1306, DOI 10.1162/NECO_a_00113; Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311; Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661; Szymanski L., 2013, P INT JOINT C NEUR N, P1; Szymanski L., 2012, P INT JOINT C NEUR N, P1076; Vapnik V. N., 1995, NATURE STAT LEARNING	22	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2162-237X	2162-2388		IEEE T NEUR NET LEAR	IEEE Trans. Neural Netw. Learn. Syst.	OCT	2014	25	10					1816	1827		10.1109/TNNLS.2013.2296046		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	AR6PH	WOS:000343704900007	25291735	
J	Yuan, ZQ; Sang, JT; Xu, CS; Liu, Y				Yuan, Zhaoquan; Sang, Jitao; Xu, Changsheng; Liu, Yan			A Unified Framework of Latent Feature Learning in Social Media	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						Deep learning; feature learning; india buffet process; social media	LINK-PREDICTION; IMAGE RETRIEVAL; NEURAL-NETWORKS; ALGORITHM; RELEVANCE; MODEL	The current trend in social media analysis and application is to use the pre-defined features and devoted to the later model development modules to meet the end tasks. Representation learning has been a fundamental problem in machine learning, and widely recognized as critical to the performance of end tasks. In this paper, we provide evidence that specially learned features will addresses the diverse, heterogeneous, and collective characteristics of social media data. Therefore, we propose to transfer the focus from the model development to latent feature learning, and present a unified framework of latent feature learning on social media. To address the noisy, diverse, heterogeneous, and interconnected characteristics of social media data, the popular deep learning is employed due to its excellent abstract abilities. In particular, we instantiate the proposed framework by (1) designing a novel relational generative deep learning model to solve the social media link analysis task, and (2) developing a multimodal deep learning to lambda rank model towards the social image retrieval task. We show that the derived latent features lead to improvement in both of the social media tasks.	[Yuan, Zhaoquan; Sang, Jitao; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Liu, Yan] Hong Kong Polytech Univ, Dept Comp, Kowloon 999077, Hong Kong, Peoples R China	Yuan, ZQ (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	zqyuan@nlpr.ia.ac.cn; jtsang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn; csyliu@comp.polyu.edu.hk			National Basic Research Program of China [2012CB316304]; National Natural Science Foundation of China [61225009, 61373122, 61303176]; Beijing Natural Science Foundation [4131004]; Singapore National Research Foundation under International Research Centre at the Singapore Funding Initiative	This work was supported in part by the National Basic Research Program of China under Grant 2012CB316304, the National Natural Science Foundation of China under Grants 61225009, 61373122, and 61303176, the Beijing Natural Science Foundation under Grant 4131004, and the Singapore National Research Foundation under its International Research Centre at the Singapore Funding Initiative and administered by the IDM Programme Office. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Cees Snoek.	Ahlqvist T., 2008, VTT; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Bengio Y, 2007, ADV NEURAL INFORM PR, V19, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Biel JI, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037690; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Burges C. J., 2006, NIPS, V6, P193; Caicedo JC, 2012, P 2 ACM INT C MULT R, P56; Cao L., 2009, P 17 ACM INT C MULT, P125, DOI 10.1145/1631272.1631292; Coates A., 2011, P 14 INT C ART INT S, V15, P215; Collobert R., 2008, P 25 INT C MACH LEAR, V307, P160; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Dong YX, 2012, IEEE DATA MINING, P181, DOI 10.1109/ICDM.2012.140; Friedland G., 2010, P ACM MULT, P1245, DOI 10.1145/1873951.1874197; Gao H., 2013, P ASONAM; Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676; Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791; Griffiths T., 2005, SCI NEW YORK, V18, P475; Hasan Mohammad Al, 2006, P SDM 06 WORKSH LINK; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; Huiskes M. J., 2008, P 1 ACM INT C MULT I, P39, DOI DOI 10.1145/1460096.1460104; Kang Y, 2011, LECT NOTES ARTIF INT, V6912, P130; Kashima H, 2006, IEEE DATA MINING, P340; Kemp C., P 21 NAT C AI, V1, P381; Lee H., 2007, ADV NEURAL INFORM PR, V19, P801; Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Lin YR, 2011, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1993077.1993081; Liu D., 2012, P 20 ACM INT C MULT, P659; Liu L., 2008, P INT WORLD WID WEB, P1009, DOI 10.1145/1367497.1367633; Lucchi A, 2012, LECT NOTES COMPUT SC, V7572, P130, DOI 10.1007/978-3-642-33718-5_10; Menon AK, 2011, LECT NOTES ARTIF INT, V6912, P437, DOI 10.1007/978-3-642-23783-6_28; Mesnil G., 2011, P UNS TRANSF LEARN W; Miller K. T., 2009, ADV NEURAL INF PROCE, V22; Naphade MR, 2004, J VIS COMMUN IMAGE R, V15, P348, DOI 10.1016/j.jvcir.2004.04.010; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Rasiwasia Nikhil, 2010, P INT C MULT, P251, DOI 10.1145/1873951.1873987; Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771; Robert C. P., 2004, MONTE CARLO STAT MET; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Sang Jitao, 2012, P 20 ACM INT C MULT, P19; Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Srivastava N., 2012, ADV NEURAL INFORM PR, V25, P2231; Sundaram H, 2012, P IEEE, V100, P2737, DOI 10.1109/JPROC.2012.2191529; Vogel J, 2004, LECT NOTES COMPUT SC, V3115, P207; Wu X, 2007, P ACM INT C MULT, P218, DOI 10.1145/1291233.1291280; Yuan Z., 2013, P 21 ACM INT C MULT, P253; Zhu G., 2010, P INT C MULT, P461, DOI 10.1145/1873951.1874028	55	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210	1941-0077		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	OCT	2014	16	6					1624	1635		10.1109/TMM.2014.2322338		12	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	AT1UW	WOS:000344720200011		
J	Zhou, SS; Chen, QC; Wang, XL				Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong			Active Semi-Supervised Learning Method with Hybrid Deep Belief Networks	PLOS ONE			English	Article								In this paper, we develop a novel semi-supervised learning algorithm called active hybrid deep belief networks (AHD), to address the semi-supervised sentiment classification problem with deep learning. First, we construct the previous several hidden layers using restricted Boltzmann machines (RBM), which can reduce the dimension and abstract the information of the reviews quickly. Second, we construct the following hidden layers using convolutional restricted Boltzmann machines (CRBM), which can abstract the information of reviews effectively. Third, the constructed deep architecture is fine-tuned by gradient-descent based supervised learning with an exponential loss function. Finally, active learning method is combined based on the proposed deep architecture. We did several experiments on five sentiment classification datasets, and show that AHD is competitive with previous semi-supervised learning algorithm. Experiments are also conducted to verify the effectiveness of our proposed method with different number of labeled reviews and unlabeled reviews respectively.	[Zhou, Shusen] Ludong Univ, Sch Informat & Elect Engn, Yantai, Shandong, Peoples R China; [Chen, Qingcai; Wang, Xiaolong] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Guangdong, Peoples R China	Zhou, SS (reprint author), Ludong Univ, Sch Informat & Elect Engn, Yantai, Shandong, Peoples R China.	zhoushusen@gmail.com			National Natural Science Foundation of China [61300155]; Scientific Research Fund of Ludong University [LY2013004]; Scientific Research Fund of Ludong University	This work is supported in part by National Natural Science Foundation of China (No. 61300155), and Scientific Research Fund of Ludong University (LY2013004). Shusen Zhou received the funding from Scientific Research Fund of Ludong University. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Blitzer J, 2007, ACL, P440; Chapelle O., 2006, SEMISUPERVISED LEARN; Collobert R, 2006, J MACH LEARN RES, V7, P1687; Dasgupta S, 2009, JOINT C 47 ANN M ASS, P701; Desjardins G., 2008, TECHNICAL REPORT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kamvar S., 2003, IJCAI, P561; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, ADV NEURAL INFORM PR, P1096; Lee H., 2009, INT C MACH LEARN, P609, DOI DOI 10.1145/1553374.1553453; Li S, 2010, ANN M ASS COMP LING, P414; LIU Y, 2010, INT ACM SIGIR C RES, P873; Pang B, 2002, C EMP METH NAT LANG, P79; Pang B.L., 2008, FDN TRENDS INFORM RE, V2; Ranzato M, 2008, INT C MACH LEARN, P792; Salakhutdinov R, 2007, J MACH LEARN RES, V2, P412; Sindhwani V, 2008, IEEE DATA MINING, P1025, DOI 10.1109/ICDM.2008.113; Socher R., 2013, P 2013 C EMP METH NA, P1631; Socher R., 2011, P C EMP METH NAT LAN, P151; Tong S, 2002, J MACH LEARN RES, V2, P45; Wei W, 2010, ANN M ASS COMP LING, P404; Zhen Y, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P299; Zhou S, 2010, INT C COMP LING, P1515; Zhu X., 2007, TECHNICAL REPORT	24	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	SEP 10	2014	9	9							e107122	10.1371/journal.pone.0107122		8	Multidisciplinary Sciences	Science & Technology - Other Topics	AP4EP	WOS:000342030300060	25208128	
J	Han, S; Vasconcelos, N				Han, Sunhyoung; Vasconcelos, Nuno			Object recognition with hierarchical discriminant saliency networks	FRONTIERS IN COMPUTATIONAL NEUROSCIENCE			English	Article						object recognition; object detection; top-down saliency; discriminant saliency; hierarchical network	VISUAL-CORTEX; INFEROTEMPORAL CORTEX; RECEPTIVE-FIELDS; IMAGE RETRIEVAL; MODEL; ATTENTION; MECHANISMS; FEATURES; SEARCH; SHAPE	The benefits of integrating attention and object recognition are investigated. While attention is frequently modeled as a pre-processor for recognition, we investigate the hypothesis that attention is an intrinsic component of recognition and vice-versa. This hypothesis is tested with a recognition model, the hierarchical discriminant saliency network (HDSN), whose layers are top-down saliency detectors, tuned for a visual class according to the principles of discriminant saliency. As a model of neural computation, the HDSN has two possible implementations. In a biologically plausible implementation, all layers comply with the standard neurophysiological model of visual cortex, with sub-layers of simple and complex units that implement a combination of filtering, divisive normalization, pooling, and non-linearities. In a convolutional neural network implementation, all layers are convolutional and implement a combination of filtering, rectification, and pooling. The rectification is performed with a parametric extension of the now popular rectified linear units (ReLUs), whose parameters can be tuned for the detection of target object classes. This enables a number of functional enhancements over neural network models that lack a connection to saliency, including optimal feature denoising mechanisms for recognition, modulation of saliency responses by the discriminant power of the underlying features, and the ability to detect both feature presence and absence. In either implementation, each layer has a precise statistical interpretation, and all parameters are tuned by statistical learning. Each saliency detection layer learns more discriminant saliency templates than its predecessors and higher layers have larger pooling fields. This enables the HDSN to simultaneously achieve high selectivity to target object classes and invariance. The performance of the network in saliency and object recognition tasks is compared to those of models from the biological and computer vision literatures. This demonstrates benefits for all the functional enhancements of the HDSN, the class tuning inherent to discriminant saliency, and saliency layers based on templates of increasing target selectivity and invariance. Altogether, these experiments suggest that there are non-trivial benefits in integrating	[Han, Sunhyoung] ID Analyt, Analyt Dept, San Diego, CA 92128 USA; [Vasconcelos, Nuno] Univ Calif San Diego, Stat & Visual Comp Lab, La Jolla, CA 92093 USA	Han, S (reprint author), ID Analyt, Analyt Dept, 15253 Ave Sci, San Diego, CA 92128 USA.	shan@idanalytics.com					Boiman O., 2008, IEEE C COMP VIS PATT; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Brincat SL, 2004, NAT NEUROSCI, V7, P880, DOI 10.1038/nn1278; Bruce N., 2006, NEURAL INFORM PROCES; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; Carandini M., 2011, NAT REV NEUROSCI, V13, P51, DOI [10.1038/nrn3136, DOI 10.1038/NRN3136]; Carandini M, 1997, J NEUROSCI, V17, P8621; Carandini M, 2005, J NEUROSCI, V25, P10577, DOI 10.1523/JNEUROSCI.3726-05.2005; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633; Chatfield K., 2011, BRIT MACH VIS C DUND; Coates A, 2011, INT C ART INT STAT, P215; Csurka G., 2004, ECCV WORKSH STAT LEA; Dalal N., 2005, IEEE C COMP VIS PATT; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Dixit M., 2011, IEEE C COMP VIS PATT; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Dorko G., 2005, RR5497 INRIA RHON AL; Duda R, 2001, PATTERN CLASSIFICATI; Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002; Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597; Fei-Fei L, 2005, IEEE C COMP VIS PATT; Fei-Fei L., 2005, CVPR WORKSH GEN MOD; Felzenszwalb P, 2009, IEEE T PATTERN ANAL, V32, P1627, DOI DOI 10.1109/TPAMI.2009.167; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gao D., 2005, IEEE C COMP VIS PATT; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Gao DS, 2009, NEURAL COMPUT, V21, P239, DOI 10.1162/neco.2009.11-06-391; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; GEMAN S, 1984, PATTERN ANAL MACHINE, V6, P721, DOI DOI 10.1109/TPAMI.1984.4767596; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Graham NV, 2011, VISION RES, V51, P1397, DOI 10.1016/j.visres.2011.02.007; Guo C.L., 2008, IEEE C COMP VIS PATT; Han S., 2011, 2011 IEEE COMP SOC C; Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034; He X., 2004, IEEE C COMP VIS PATT; HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hou X., 2007, IEEE C COMP VIS PATT; Huang J., 1999, IEEE C COMP VIS PATT; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jarrett K., 2009, IEEE C COMP VIS PATT; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kanan C., 2010, IEEE C COMP VIS PATT; Kavukcuoglu K., 2010, NEURAL INFORM PROCES; Krizhevsky A., 2012, NEURAL INFORM PROCES; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Lazebnik S., 2006, IEEE C COMP VIS PATT; LeCun Y., 1990, NEURAL INFORM PROCES; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Lowe D. G., 1999, INT C COMP VIS CORF; Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98; Mairal J., 2008, IEEE C COMP VIS PATT; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Maunsell JHR, 2006, TRENDS NEUROSCI, V29, P317, DOI 10.1016/j.tins.2006.04.001; Miau K., 2001, P SPIE 46 ANN INT S; Moosmann F., 2007, NEURAL INFORM PROCES; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Nair Vinod, 2010, ICML, P807; Navalpakkam V, 2007, NEURON, V53, P605, DOI 10.1016/j.neuron.2007.01.018; PERRETT DI, 1993, IMAGE VISION COMPUT, V11, P317, DOI 10.1016/0262-8856(93)90011-5; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rosenholtz R, 1999, VISION RES, V39, P3157, DOI 10.1016/S0042-6989(99)00077-2; Saenko K., 2010, ECCV HER GREEC SEP, P213; Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sivic J., 2003, INT C COMP VIS NIC; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9; TSOTSOS JK, 1991, BEHAV BRAIN SCI, V14, P506; Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125; Vasconcelos N., 1997, DAT COMPR C SNOWB UT; Vasconcelos N., 2000, IEEE C COMP VIS PATT; Vasconcelos N, 2004, IEEE T INFORM THEORY, V50, P1482, DOI 10.1109/TIT.2004.830760; Vidal-Naquet M., 2003, IEEE C COMP VIS PATT; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wang J., 2010, IEEE C COMP VIS PATT, P3360; Winn J., 2005, INT C COMP VIS BEIJ; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Wolfe JM, 1998, CURR BIOL, V8, pR303, DOI 10.1016/S0960-9822(98)70192-7; Yamane Y, 2008, NAT NEUROSCI, V11, P1352, DOI 10.1038/nn.2202; Yang J., 2009, IEEE C COMP VIS PATT; Yarbus A. L, 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]; Zhang H., 2006, IEEE C COMP VIS PATT; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhou X., 2009, IEEE C COMP VIS PATT	94	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-5188			FRONT COMPUT NEUROSC	Front. Comput. Neurosci.	SEP 9	2014	8								109	10.3389/fncom.2014.00109		20	Mathematical & Computational Biology; Neurosciences	Mathematical & Computational Biology; Neurosciences & Neurology	AP3GW	WOS:000341964600001	25249971	
J	Fan, K; Zhang, HY; Yan, SB; Wang, LW; Zhang, WS; Feng, JF				Fan, Kai; Zhang, Hongyi; Yan, Songbai; Wang, Liwei; Zhang, Wensheng; Feng, Jufu			Learning a generative classifier from label proportions	NEUROCOMPUTING			English	Article						Proportion learning; Bayesian model; Restricted Boltzmann machine		Learning a classifier when only knowing the features and marginal distribution of class labels in each of the data groups is both theoretically interesting and practically useful. Specifically, we consider the case in which the ratio of the number of data instances to the number of classes is large. We prove sample complexity upper bound in this setting, which is inspired by an analysis of existing algorithms. We further formulate the problem in a density estimation framework to learn a generative classifier. We also develop a practical RBM-based algorithm which shows promising performance on benchmark datasets. (C) 2014 Elsevier B.V. All rights reserved.	[Fan, Kai; Zhang, Hongyi; Yan, Songbai; Wang, Liwei; Feng, Jufu] Peking Univ, Sch Elect Engn & Comp Sci, MOE, Key Lab Machine Percept, Beijing, Peoples R China; [Zhang, Wensheng] Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China	Wang, LW (reprint author), Peking Univ, Sch Elect Engn & Comp Sci, MOE, Key Lab Machine Percept, Beijing, Peoples R China.	wanglw@cis.pku.edu.cn			NSFC [61222307, 61075003, 61333015]; NBRPC [2011CB302400]	This work was supported by NSFC (61222307, 61075003, 61333015) and NBRPC (2011CB302400).	Altun Y, 2006, LECT NOTES ARTIF INT, V4005, P139, DOI 10.1007/11776420_13; Bengio Y., 2007, GREDDY LAYER WISE TR, V19, P153; Carreira-Perpinan M., 2005, 10 INT WORKSH ART IN; Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1; Hinton G., 2003, PRACTICAL GUIDE TRAI; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Kifer D., 2009, ACM SIGMOD 09 PROV R; Kueck H., 2005, LEARNING INDIVIDUALS, P332; Marco S., 2011, ECML PKDD 2011 3, V6931, P349; Quadrianto N, 2009, J MACH LEARN RES, V10, P2349; Rueping Stefan, 2010, P 27 ANN INT C MACH; Salakhutdinov R., 2008, QUANTITATIVE ANAL DE; Smola A, 2007, BUNDLE METHODS MACHI; Vapnik V. N., 1998, STAT LEARNING THEORY; Wedin P.-A., 1973, BIT (Nordisk Tidskrift for Informationsbehandling), V13, DOI 10.1007/BF01933494; Zhang F., 2011, MATRIX THEORY BASIC, V2nd	16	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	SEP 2	2014	139				SI		47	55		10.1016/j.neucom.2013.09.057		9	Computer Science, Artificial Intelligence	Computer Science	AJ4QV	WOS:000337661800006		
J	Courville, A; Desjardins, G; Bergstra, J; Bengio, Y				Courville, Aaron; Desjardins, Guillaume; Bergstra, James; Bengio, Yoshua			The Spike-and-Slab RBM and Extensions to Discrete and Sparse Data Distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature learning; unsupervised learning; restricted boltzmann machines; natural image modeling	NATURAL IMAGES; EMERGENCE; PRODUCTS; EXPERTS	The spike-and-slab restricted Boltzmann machine (ssRBM) is defined to have both a real-valued "slab" variable and a binary "spike" variable associated with each unit in the hidden layer. The model uses its slab variables to model the conditional covariance of the observation-thought to be important in capturing the statistical properties of natural images. In this paper, we present the canonical ssRBM framework together with some extensions. These extensions highlight the flexibility of the spike-and-slab RBM as a platform for exploring more sophisticated probabilistic models of high dimensional data in general and natural image data in particular. Here, we introduce the subspace-ssRBM focused on the task of learning invariant features. We highlight the behaviour of the ssRBM and its extensions through experiments with the MNIST digit recognition task and the CIFAR-10 object classification task.	[Courville, Aaron] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada; [Desjardins, Guillaume; Bengio, Yoshua] Univ Montreal, DIRO, Montreal, PQ H3T 1J4, Canada; [Bergstra, James] Univ Waterloo, Ctr Theoret Neurosci, Waterloo, ON N2L 3G1, Canada; [Bergstra, James] Harvard Univ, Cambridge, MA 02138 USA; [Bengio, Yoshua] Univ Montreal, Machine Learning Lab LISA, Montreal, PQ, Canada	Courville, A (reprint author), Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada.	aaron.courville@umontreal.ca; desjagui@iro.umontreal.ca; james.bergstra@gmail.com; Yoshua.Bengio@umontreal.ca			NSERC; FQRNT; CIFAR; RQCHP; Compute Canada	The authors acknowledge NSERC, FQRNT, CIFAR, RQCHP and Compute Canada for their financial and computational support; and Chris Williams for pointing out the connection to the PoPPCA model. They also thank the anonymous reviewers for their valuable suggestions for improving the paper.	Bergstra J, 2011, NEURAL COMPUT, V23, P774, DOI 10.1162/NECO_a_00084; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Cho K., 2010, P INT JOINT C NEUR N; Coates, 2011, P 28 INT C MACH LEAR; Coates A., 2011, P ADV NEUR INF PROC; Coates A., 2011, P INT C ART INT STAT; Courville A., 2011, P INT C MACH LEARN I; Desjardins G., 2010, P 13 INT C ART INT S, V9, P145; Garrigues P., 2008, P ADV NEUR INF PROC; Goodfellow I., 2012, P 29 INT C MACH LEAR; Goodfellow I. J., 2013, P INT C MACH LEARN I; Hinton G., 2010, 2010003 U TOR; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 1998, NATO ADV SCI I D-BEH, V89, P479; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A, 2001, INDEPENDENT COMPONEN; Kavukcuoglu K., 2009, P IEEE C COMP VIS PA; Kivinen J.J., 2012, P 15 INT C ART INT S; Kohonen T, 1996, BIOL CYBERN, V75, P281, DOI 10.1007/s004220050295; Krizhevsky A., 2009, TECHNICAL REPORT; Krizhevsky A., 2010, TECHNICAL REPORT; Le Q., 2010, P ADV NEUR INF PROC; Le Q.V., 2011, P IEEE C COMP VIS PA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe D., 1999, P IEEE 7 INT C COMP; Lucke J., 2011, ARXIV11052493; Luo H., 2013, P INT C ART INT STAT; Martens J., 2010, P INT C ART INT STAT; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; Mohamed S., 2011, ARXIV11061157; Nair V., 2010, P 27 INT C MACH LEAR; Neal R., 1993, CRGTR931 U TOR DEP C; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ranzato M., 2010, P INT C ART INT STAT; Ranzato M., 2010, P ADV NEUR INF PROC; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Ranzato M.A., 2011, P IEEE C COMP VIS PA; Rifai S., 2011, P 28 INT C MACH LEAR; Salakhutdinov R., 2010, P ADV NEUR INF PROC; Socher R., 2011, P INT C MACH LEARN I; Tieleman T., 2008, P 25 INT C MACH LEAR, P1064, DOI 10.1145/1390156.1390290; Titsias M.K., 2011, P ADV NEUR INF PROC; Vincent P., 2008, P 25 INT C MACH LEAR; Welling M., 2003, P ADV NEUR INF PROC; Williams CKI, 2002, NEURAL COMPUT, V14, P1169, DOI 10.1162/089976602753633439; Younes L., 1998, STOCHASTICS STOCHAST, P177; Yu K., 2010, P INT C MACH LEARN I; Zhou M., 2009, P ADV NEUR INF PROC, P2295	49	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1874	1887		10.1109/TPAMI.2013.238		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	AM9OE	WOS:000340210100013		
J	Demetgul, M; Yildiz, K; Taskin, S; Tansel, IN; Yazicioglu, O				Demetgul, M.; Yildiz, K.; Taskin, S.; Tansel, I. N.; Yazicioglu, O.			Fault diagnosis on material handling system using feature selection and data mining techniques	MEASUREMENT			English	Article						Servo-pneumatic; Material handling system; Fault diagnosis; Feature selection; Data mining; Dimension reduction; Gustafson-Kessel; k-Medoids	DIFFUSION MAPS; DIMENSIONALITY REDUCTION; NEURAL-NETWORK; ALGORITHM; ACTUATOR; MODELS; PLANT	The material handling systems are one of the key components of the most modern manufacturing systems. The sensory signals of material handling systems are nonlinear and have unique characteristics. It is very difficult to encode and classify these signals by using multipurpose methods. In this study, performances of multiple generic methods were studied for the diagnostic of the pneumatic systems of the material handling systems. Diffusion Map (DM), Local Linear Embedding (LLE) and AutoEncoder (AE) algorithms were used for future extraction. Encoded signals were classified by using the Gustafson-Kessel (GK) and k-medoids algorithms. The accuracy of the estimations was better than 90% when the LLE was used with GK algorithm. (C) 2014 Elsevier Ltd. All rights reserved.	[Demetgul, M.] Marmara Univ, Fac Technol, Dept Mechatron Engn, Istanbul, Turkey; [Yildiz, K.] Marmara Univ, Tech Educ Fac, Dept Comp & Control Educ, Istanbul, Turkey; [Taskin, S.] Celal Bayar Univ, Fac Engn, Dept Elect & Elect Engn, Manisa, Turkey; [Tansel, I. N.] Florida Int Univ, Fac Engn, Dept Mat & Mech Engn, Miami, FL 33199 USA; [Yazicioglu, O.] Istanbul Commerce Univ, Fac Engn & Design, Dept Ind Engn, Istanbul, Turkey	Demetgul, M (reprint author), Marmara Univ, Fac Technol, Dept Mechatron Engn, Istanbul, Turkey.	mdemetgul@marmara.edu.tr			Celal Bayar University Scientific Research Projects Commission [2012-52]; Marmara University Scientific Research Projects Commission [FEN-A-080410-0081]	The authors present their special thanks to the Celal Bayar University Scientific Research Projects Commission for the supports of the study under project number 2012-52.The authors also thanks to the Marmara University Scientific Research Projects Commission for the supports of the study under project number FEN-A-080410-0081.	Balasko B., 2005, FUZZY CLUSTERING DAT; Bezdek J.C., 1999, FUZZY MODELS ALGORIT, V4; Bouamama BO, 2005, CONTROL ENG PRACT, V13, P159, DOI 10.1016/j.congenprac.2004.03.003; Choi SW, 2003, IND ENG CHEM RES, V42, P108, DOI 10.1021/ie000722x; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P53, DOI 10.1016/j.acha.2006.04.004; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; DeMers D., 1992, ADV NEURAL INFORMATI, V5, P580; Demetgul M, 2011, ADV ENG SOFTW, V42, P1051, DOI 10.1016/j.advengsoft.2011.07.004; Demetgul M., 2011, CONDITIONING MONITOR; Demetgul M, 2009, EXPERT SYST APPL, V36, P10512, DOI 10.1016/j.eswa.2009.01.028; Duda R.O., 2003, PATTERN CLASSIFICATI, V2; Gustafson D.E., 1979, CDC 1979, P761; He QP, 2005, AICHE J, V51, P555, DOI 10.1002/aic.10325; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Karpenko M, 2003, CONTROL ENG PRACT, V11, P1289, DOI 10.1016/S0967-0661(02)00245-9; Kohonen T., 1988, ALSO SPRINGER SERIES, V8; KUNG SY, 1994, IEEE T SIGNAL PROCES, V42, P1202, DOI 10.1109/78.295198; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223; Mendonca LF, 2009, EXPERT SYST APPL, V36, P1092, DOI 10.1016/j.eswa.2007.11.009; Nakutis Z., 2007, INSTR MEAS TECHN C P, P1; Nakutis Z., 2008, APPROACH PNEUMATIC C, P72; Nakutis Z., 2005, MATAVIMAI, V36, P16; Nogami T., 1993, IEEE INT C NEURAL NE, V1993, P1876; Rousseeuw P. J., 1990, FINDING GROUPS DATA; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sarbu C, 2007, CHEMOMETR INTELL LAB, V86, P121, DOI 10.1016/j.chemolab.2006.08.015; Sepasi M, 2010, INT J CONTROL AUTOM, V8, P149, DOI 10.1007/s12555-010-0119-6; Shi L, 2004, P AMER CONTR CONF, P3753; Song S.O., 2003, P INT S ADV CONTR CH; Teppola P, 1999, J CHEMOMETR, V13, P445, DOI 10.1002/(SICI)1099-128X(199905/08)13:3/4<445::AID-CEM557>3.3.CO;2-N; Uppal F.J., 2002, P 15 IFAC WORLD C, P21; Uppal F.J., 2002, P EUR S ART NEUR NET, P501; Van der Maaten L. J. P., 2007, INTRO DIMENSIONALITY; Wang J, 2004, IEEE-ASME T MECH, V9, P100, DOI 10.1109/TMECH.2004.823883; Xu R, 2010, ARTIF INTELL MED, V48, P91, DOI 10.1016/j.artmed.2009.06.001; Yang WX, 2006, J SOUND VIB, V293, P213, DOI 10.1016/j.jsv.2005.09.004; Yuan SF, 2007, MECH SYST SIGNAL PR, V21, P1787, DOI 10.1016/j.ymssp.2006.07.008; Zhang Q., 2005, COMPUTATIONAL SCI IT, V2005, P207	40	0	0	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0263-2241	1873-412X		MEASUREMENT	Measurement	SEP	2014	55						15	24		10.1016/j.measurement.2014.04.037		10	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	AM4HM	WOS:000339814500002		
J	Ji, NN; Zhang, JS; Zhang, CX				Ji, Nan-Nan; Zhang, Jiang-She; Zhang, Chun-Xia			A sparse-response deep belief network based on rate distortion theory	PATTERN RECOGNITION			English	Article						Deep belief network; Kullback-Leibler divergence; Information entropy; Rate distortion theory; Unsupervised feature learning	NEURAL-NETWORKS; VISUAL-CORTEX; RECOGNITION; STIMULI; VISION; LEARN; V2	Deep belief networks (DBNs) are currently the dominant technique for modeling the architectural depth of brain, and can be trained efficiently in a greedy layer-wise unsupervised learning manner. However, DBNs without a narrow hidden bottleneck typically produce redundant, continuous-valued codes and unstructured weight patterns. Taking inspiration from rate distortion (RD) theory, which encodes original data using as few bits as possible, we introduce in this paper a variant of DBN, referred to as sparse-response DBN (SR-DBN). In this approach, Kullback-Leibler divergence between the distribution of data and the equilibrium distribution defined by the building block of DBN is considered as a distortion function, and the sparse response regularization induced by L-1-norm of codes is used to achieve a small code rate. Several experiments by extracting features from different scale image datasets show that our approach SR-DBN learns codes with small rate, extracts features at multiple levels of abstraction mimicking computations in the cortical hierarchy, and obtains more discriminative representation than PCA and several basic algorithms of DBNs. (C) 2014 Elsevier Ltd. All rights reserved.	[Ji, Nan-Nan; Zhang, Jiang-She; Zhang, Chun-Xia] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China	Zhang, JS (reprint author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.	jszhang@mail.xjtu.edu.cn			National Basic Research Program of China (973 Program) [2013CB329404]; National Natural Science Foundation of China [91230101, 61075006, 11131006, 11201367]; Research Fund for the Doctoral Program of Higher Education of China [20100201120048]	This work was supported by the National Basic Research Program of China (973 Program) under Grant no. 2013CB329404, the National Natural Science Foundation of China under Grant nos. 91230101, 61075006, 11131006, 11201367, the Research Fund for the Doctoral Program of Higher Education of China under Grant nos. 20100201120048.	Barlow H B, 1972, Perception, V1, P371, DOI 10.1068/p010371; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y., 2007, P ADV NEUR INF PROC, P153; Bengio Yoshua, 2009, Foundations and Trends in Machine Learning, V2, DOI 10.1561/2200000006; Buesing L., 2007, ADV NEURAL INFORM PR, V20, P193; Chen EK, 2008, INT CONF ACOUST SPEE, P829, DOI 10.1109/ICASSP.2008.4517738; Cover T. M., 2006, ELEMENTS INFORM THEO; Dahl G., 2012, IEEE T AUDIO SPEECH, V20, P14; Deselaers T., 2009, P EACL 2009 WORKSH S, P233, DOI 10.3115/1626431.1626476; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fischer A., 2012, LNCS, V7441, P14; Freund Y., 1992, P ADV NEUR INF PROC, P912; Halkias X., SPARSE PENALTY DEEP; Hino H, 2009, LECT NOTES COMPUT SC, V5551, P84, DOI 10.1007/978-3-642-01507-6_11; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton G.E., 2005, INT C ART INT STAT; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2010, 2010003 U TORONTO; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6; Hochreiter S., 1997, THEORETICAL ASPECTS, P297; Horster E., 2008, P 16 ACM INT C MULT, P643, DOI 10.1145/1459359.1459449; Hyvarinen A, 2005, BMC NEUROSCI, V6, DOI 10.1186/1471-2202-6-12; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Jehee JFM, 2006, J PHYSIOLOGY-PARIS, V100, P125, DOI 10.1016/j.jphysparis.2006.09.011; Jolliffe IT, 1986, PRINCIPAL COMPONENT, V487; Krizhevsky A., 2009, TECHNICAL REPORT; Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272; LeCun Y, 2004, PROC CVPR IEEE, P97; Lee H., 2007, P ADV NEUR INF PROC, P1416; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Liu Y, 2011, PATTERN RECOGN, V44, P2287, DOI 10.1016/j.patcog.2010.12.012; Luo H., 2011, P 25 AAAI C ART INT; Mohamed A., 2009, P ADV NEUR INF PROC; Morris G, 2003, J PHYSIOLOGY-PARIS, V97, P581, DOI 10.1016/j.jphysparis.2004.01.015; Olshausen B., 1996, NATURE          0613, P607; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osindero S, 2006, NEURAL COMPUT, V18, P381, DOI 10.1162/089976606775093936; Plahl C., 2012, P INT C AC SPEECH SI, P4156; Raina R., 2009, P 26 ANN INT C MACH, P873; Ranzato M., 2008, P ADV NEUR INF PROC, P1185; Ranzato M., 2006, P NEUR INF PROC SYST, P1137; Sainath TN, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4153; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Salakhutdinov RR, 2008, P 25 INT C MACH LEAR, P872, DOI 10.1145/1390156.1390266; Shamir O, 2010, THEOR COMPUT SCI, V411, P2696, DOI 10.1016/j.tcs.2010.04.006; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Taylor G., 2009, P 26 ANN INT C MACH, P1025; Taylor G. W., 2007, ADV NEURAL INFORM PR, V19, P1345; Vincent P., 2008, ICML, P1096	52	0	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	SEP	2014	47	9					3179	3191		10.1016/j.patcog.2014.03.025		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	AI4YG	WOS:000336872000031		
J	Qiao, H; Li, YL; Tang, T; Wang, P				Qiao, Hong; Li, Yinlin; Tang, Tang; Wang, Peng			Introducing Memory and Association Mechanism Into a Biologically Inspired Visual Model	IEEE TRANSACTIONS ON CYBERNETICS			English	Article						Association; biologically inspired visual model; memory; object recognition	MONKEY INFEROTEMPORAL CORTEX; OBJECT RECOGNITION; DECLARATIVE MEMORY; ATTENTION MODEL; FACIAL FEATURES; SEMANTIC MEMORY; TEMPORAL-LOBE; FAMILIARITY; MOTION; DISCRIMINATION	A famous biologically inspired hierarchical model (HMAX model), which was proposed recently and corresponds to V1 to V4 of the ventral pathway in primate visual cortex, has been successfully applied to multiple visual recognition tasks. The model is able to achieve a set of position- and scale-tolerant recognition, which is a central problem in pattern recognition. In this paper, based on some other biological experimental evidence, we introduce the memory and association mechanism into the HMAX model. The main contributions of the work are: 1) mimicking the active memory and association mechanism and adding the top down adjustment to the HMAX model, which is the first try to add the active adjustment to this famous model and 2) from the perspective of information, algorithms based on the new model can reduce the computation storage and have a good recognition performance. The new model is also applied to object recognition processes. The primary experimental results show that our method is efficient with a much lower memory requirement.	[Qiao, Hong; Li, Yinlin; Tang, Tang; Wang, Peng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China	Qiao, H (reprint author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.	hong.qiao@ia.ac.cn; yinlin.li@ia.ac.cn; tang.tang@ia.ac.cn; peng_wang@ia.ac.cn			National Natural Science Foundation of China [61033011, 61210009, 61379093]; National Key Technology Research and Development Program [2012BAI34B02]	This work was supported in part by the National Natural Science Foundation of China under Grant 61033011, Grant 61210009, and Grant 61379093, and in part by the National Key Technology Research and Development Program 2012BAI34B02. This paper was recommended by Associate Editor X. Li.	Begum M, 2010, IEEE T SYST MAN CY B, V40, P1305, DOI 10.1109/TSMCB.2009.2037511; Bogacz R, 1999, IEE CONF PUBL, P773, DOI 10.1049/cp:19991205; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Brown MW, 2001, NAT REV NEUROSCI, V2, P51, DOI 10.1038/35049064; Casile A, 2005, J VISION, V5, P348, DOI 10.1167/5.4.6; Chertkow H., 2002, NEUROLOGY NEUROSCIEN, V2, P516, DOI [10.1007/s11910-002-0039-9, DOI 10.1007/S11910-002-0039-9]; Chinellato E, 2012, IEEE T SYST MAN CY B, V42, P530, DOI 10.1109/TSMCB.2011.2168952; Conway MA, 2009, NEUROPSYCHOLOGIA, V47, P2305, DOI 10.1016/j.neuropsychologia.2009.02.003; Donaldson W, 1996, MEM COGNITION, V24, P523, DOI 10.3758/BF03200940; Eichenbaum H, 2000, NAT REV NEUROSCI, V1, P41, DOI 10.1038/35036213; Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355; FUJITA I, 1992, NATURE, V360, P343, DOI 10.1038/360343a0; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057; HAIST F, 1992, J EXP PSYCHOL LEARN, V18, P691, DOI 10.1037//0278-7393.18.4.691; Hamidi M, 2010, MACH VISION APPL, V21, P969, DOI 10.1007/s00138-009-0216-9; Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034; HART J, 1990, ANN NEUROL, V27, P226, DOI 10.1002/ana.410270303; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hintzman DL, 1998, MEM COGNITION, V26, P449, DOI 10.3758/BF03201155; Hirshman E, 1997, MEM COGNITION, V25, P345, DOI 10.3758/BF03211290; HODGES JR, 1992, BRAIN, V115, P1783, DOI 10.1093/brain/115.6.1783; Huang KQ, 2011, IEEE T SYST MAN CY B, V41, P307, DOI 10.1109/TSMCB.2009.2037923; Huang YZ, 2011, IEEE T SYST MAN CY B, V41, P1668, DOI 10.1109/TSMCB.2011.2158418; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Lang S., 2003, P INT C MULT INT VAN, P28; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Li H, 2013, IEEE T CYBERNETICS, V43, P412, DOI 10.1109/TSMCB.2012.2208743; Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410; Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98; Martin A, 2001, CURR OPIN NEUROBIOL, V11, P194, DOI 10.1016/S0959-4388(00)00196-3; MARTIN A, 1995, SCIENCE, V270, P102, DOI 10.1126/science.270.5233.102; McElree B, 1999, J EXP PSYCHOL LEARN, V25, P563, DOI 10.1037//0278-7393.25.3.563; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Mutch J., 2006, IEEE COMP SOC C COMP, V1, P11, DOI DOI 10.1109/CVPR.2006.200; Peters RJ, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279920.1279923; Renzi C., 2013, NEUROIMAGE; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rust NC, 2006, NAT NEUROSCI, V9, P1421, DOI 10.1038/nn1786; Seeck M, 1997, NEUROREPORT, V8, P2749, DOI 10.1097/00001756-199708180-00021; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sigala R, 2005, LECT NOTES COMPUT SC, V3696, P241; Squire LR, 2007, NAT REV NEUROSCI, V8, P872, DOI 10.1038/nrn2154; Squire LR, 1998, HIPPOCAMPUS, V8, P205, DOI 10.1002/(SICI)1098-1063(1998)8:3<205::AID-HIPO3>3.0.CO;2-I; STRYKER MP, 1992, NATURE, V360, P301, DOI 10.1038/360301a0; Tani J, 2008, IEEE T SYST MAN CY B, V38, P43, DOI 10.1109/TSMCB.2007.907738; Tovee MJ, 1998, NEURON, V21, P1239, DOI 10.1016/S0896-6273(00)80644-3; Tulving E, 1998, HIPPOCAMPUS, V8, P198, DOI 10.1002/(SICI)1098-1063(1998)8:3<198::AID-HIPO2>3.0.CO;2-G; Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472; Wang G, 1996, SCIENCE, V272, P1665, DOI 10.1126/science.272.5268.1665; YAMANE S, 1988, EXP BRAIN RES, V73, P209, DOI 10.1007/BF00279674; Yu YL, 2010, IEEE T SYST MAN CY B, V40, P1398, DOI 10.1109/TSMCB.2009.2038895	56	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2168-2267	2168-2275		IEEE T CYBERNETICS	IEEE T. Cybern.	SEP	2014	44	9					1485	1496		10.1109/TCYB.2013.2287014		12	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	AP6ZP	WOS:000342227500001	24184793	
J	Snaider, J; Franklin, S				Snaider, Javier; Franklin, Stan			Modular Composite Representation	COGNITIVE COMPUTATION			English	Article						Reduced description; Holistic record; High-dimensional representation	DISTRIBUTED REPRESENTATIONS; RECOGNITION; SEMANTICS; MEMORY	High-dimensional vector spaces have noteworthy properties that make them attractive for representation models. A reduced description model is a mechanism for encoding complex structures as single high-dimensional vectors. Moreover, these vectors can be used to directly process complex operations such as analogies, inferences, and structural comparisons. Also, it is possible to reconstruct the whole structure from the reduced description vector. Here, we introduce the modular composite representation (MCR), a new reduced description model that employs long integer vectors. We also describe several experiments with them, and give a theoretical analysis of the distance distribution in this vector space, and of properties of this representation. Finally, we compare MCR with other two reduced description models: Spatter Code and holographic reduced representation.	[Snaider, Javier; Franklin, Stan] Univ Memphis, Dept Comp Sci, Inst Intelligent Syst, Memphis, TN 38152 USA; [Snaider, Javier; Franklin, Stan] FedEx Inst Technol, Memphis, TN 38152 USA	Snaider, J (reprint author), FedEx Inst Technol, 403h,365 Innovat Dr, Memphis, TN 38152 USA.	jsnaider@memphis.edu					Arel I., 2009, P AAAI 2009 FALL S B; Cambria E, 2012, SENTIC COMPUTING; Cambria E, 2012, COGN COMPUT, V4, P477, DOI 10.1007/s12559-012-9145-4; Cohen T, 2009, J BIOMED INFORM, V42, P390, DOI 10.1016/j.jbi.2009.02.002; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Foundalis HE, 2006, THESIS INDIANA U IND; Franklin S, 2006, IDPT 2006 P INT DES; Franklin S., 1995, ARTIFICIAL MINDS; George D., 2008, THESIS STANFORD U; Grassi M, 2011, COGN COMPUT, V3, P480, DOI 10.1007/s12559-011-9101-8; HINTON GE, 1990, ARTIF INTELL, V46, P47, DOI 10.1016/0004-3702(90)90004-J; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Jockel S, 2009, THESIS U HAMBURG HAM; Jones MN, 2007, PSYCHOL REV, V114, P1, DOI 10.1037/0033-295X.114.1.1; Kanerva P., 1994, ICANN '94. Proceedings of the International Conference on Artificial Neural Networks; Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8; Kanerva P, 1988, SPARSE DISTRIBUTED M; Laird J. E., 2008, ARTIFICIAL GEN INTEL; McClelland J. L., 1986, PARALLEL DISTRIBUTED, P77; Plate T.A., 2003, HOLOGRAPHIC REDUCED; PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968; POLLACK JB, 1990, ARTIF INTELL, V46, P77, DOI 10.1016/0004-3702(90)90005-K; Rachkovskij DA, 2001, NEURAL COMPUT, V13, P411, DOI 10.1162/089976601300014592; Robertson P, 2011, BIOL INSPIRED COGNIT; Sahlgren M., 2005, METH APPL SEM IND WO; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Snaider J, 2013, NEURAL NETWORKS, V46, P144, DOI 10.1016/j.neunet.2013.05.005; Snaider J., 2012, THESIS U MEMPHIS MEM; Snaider J, 2011, 4 C ART GEN INT MOUN; Snaider J, 2012, COGN COMPUT, V4, P172, DOI 10.1007/s12559-012-9125-8; Snaider J, 2012, 25 FLOR ART INT RES; Starzyk JA, 2007, IEEE T NEURAL NETWOR, V18, P344, DOI 10.1109/TNN.2006.884681; Stewart TC, 2011, BIOL INSPIRED COGNIT; Sun R, 2001, IEEE INTELL SYST, V16, P67, DOI 10.1109/MIS.2001.1463065; Turney PD, 2010, J ARTIF INTELL RES, V37, P141; Wang QF, 2013, COGN COMPUT, V5, P234, DOI 10.1007/s12559-012-9183-y; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0; Winston P.H., 1992, ARTIFICIAL INTELLIGE	39	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1866-9956	1866-9964		COGN COMPUT	Cogn. Comput.	SEP	2014	6	3			SI		510	527		10.1007/s12559-013-9243-y		18	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AO8HB	WOS:000341593600019		
J	Zhu, DQ; Li, DC; Carterette, B; Liu, HF				Zhu, Dongqing; Li, Dingcheng; Carterette, Ben; Liu, Hongfang			Integrating information retrieval with distant supervision for Gene Ontology annotation	DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION			English	Article								This article describes our participation of the Gene Ontology Curation task (GO task) in BioCreative IV where we participated in both subtasks: A) identification of GO evidence sentences (GOESs) for relevant genes in full-text articles and B) prediction of GO terms for relevant genes in full-text articles. For subtask A, we trained a logistic regression model to detect GOES based on annotations in the training data supplemented with more noisy negatives from an external resource. Then, a greedy approach was applied to associate genes with sentences. For subtask B, we designed two types of systems: (i) search-based systems, which predict GO terms based on existing annotations for GOESs that are of different textual granularities (i.e., full-text articles, abstracts, and sentences) using state-of-theart information retrieval techniques (i.e., a novel application of the idea of distant supervision) and (ii) a similarity-based system, which assigns GO terms based on the distance between words in sentences and GO terms/synonyms. Our best performing system for subtask A achieves an F1 score of 0.27 based on exact match and 0.387 allowing relaxed overlap match. Our best performing system for subtask B, a search-based system, achieves an F1 score of 0.075 based on exact match and 0.301 considering hierarchical matches. Our search-based systems for subtask B significantly outperformed the similarity-based system.	[Zhu, Dongqing; Li, Dingcheng; Liu, Hongfang] Mayo Clin, Dept Hlth Sci Res, Rochester, MN 55905 USA; [Zhu, Dongqing; Carterette, Ben] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA	Liu, HF (reprint author), Mayo Clin, Dept Hlth Sci Res, 200 First St SW, Rochester, MN 55905 USA.	liu.hongfang@mayo.edu			US National Science Foundation [ABI: 0845523]; US National Institute of Health [R01LM009959]; US NSF [ABI:0845523]; US NIH [R01LM009959]	The work was supported by US National Science Foundation (ABI: 0845523) and US National Institute of Health (R01LM009959). Funding for open access charge: US NSF (ABI:0845523) and US NIH (R01LM009959).	Auken K.V., 2013, BIOCREATIVE 4 WORKSH; Blaschke C, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S16; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blei D.M., NIPS; Chen Y., BIOINF BIOM WORKSH B; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jonnalagadda S.R., 2013, BIOINF BIOM BIBM 201, P5; Komarek P., 2005, LR TRIRLS LOGISTIC R; Lee H., 2009, P 26 ANN INT C MACH; Lee H., 2009, NIPS NEW YORK NY US; Leong K., 1998, P INET 98, V98, P21; Li D., 2012, ENTITY RELATION DETE; Li D., 2011, P TEXTGRAPHS 6 GRAPH; Li W., 2006, ICML 06 P 23 INT C M; Liu H, 2013, J NUTR BIOCHEM, V24, P1817, DOI 10.1016/j.jnutbio.2013.04.002; Liu HF, 2010, LECT N BIOINFORMAT, V6004, P62, DOI 10.1007/978-3-642-13131-8_8; Liu Mei, 2012, AMIA Annu Symp Proc, V2012, P577; Lu Z., 2012, DATABASE; Mao Y., 2013, BIOCREAT 4 WORKSH BE; NIH, 2013, GENERIF GEN REF FUNC; Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185; Real R, 1996, SYST BIOL, V45, P380, DOI 10.2307/2413572; Strohman T., 2005, P INT C INT AN AMH M; Teh Y. W., 2004, NIPS; Van Auken K, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-228; Zhang Y., 2013, BIOINF BIOM BIBM 201, P72	26	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1758-0463			DATABASE-OXFORD	Database	SEP 1	2014									bau087	10.1093/database/bau087		7	Mathematical & Computational Biology	Mathematical & Computational Biology	AO4LA	WOS:000341308200001		
J	Banerjee, B; Dutta, JK				Banerjee, Bonny; Dutta, Jayanta K.			SELP: A general-purpose framework for learning the norms from saliencies in spatiotemporal data	NEUROCOMPUTING			English	Article						Lateral connections; Surprise; Invariance; Predict; Explain; Hierarchical feature learning	PRIMARY AUDITORY-CORTEX; RECEPTIVE-FIELDS; VISUAL-CORTEX; FUNCTIONAL ARCHITECTURE; PATTERN-RECOGNITION; STRIATE CORTEX; DIVISIVE NORMALIZATION; BINOCULAR INTERACTION; SENSORY SUBSTITUTION; RETINAL PROJECTIONS	Sensors that monitor around the clock are everywhere. Due to the sheer amount of data these sensors can generate, the resources required to store, protect personal information, and analyze them are enormous. Since noteworthy events happen only occasionally, it is not necessary to store or analyze the data generated at every instant of time. Rather, it is imperative for a smart memory to learn the norms in such data so that only the abnormal (or salient) events may be stored. We present a general-purpose biologically plausible computational framework, called SELP, for learning the norms (or invariances) as a hierarchy of features from space- and time-varying data in an unsupervised and online manner from saliencies or surprises in the data. Given streaming data, this framework runs a relentless cycle - detect unexpected or Salient event, Explain the salient event, Learn from its explanation, Predict the future events - involving the real external world and its internal model, and hence the name. Experimental results from different functions of this framework are presented with a particular emphasis on the role of lateral connections in each layer. (C) 2014 Elsevier B.V. All rights reserved.	[Banerjee, Bonny] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA; Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA	Banerjee, B (reprint author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.	bonnybanerjee@yahoo.com; jkdutta@memphis.edu			U.S. National Science Foundation under CISE [1231620]	Research reported in this paper was partially supported by the U.S. National Science Foundation under CISE Grant no. 1231620.	Abbott LF, 1999, BRAIN RES BULL, V50, P303, DOI 10.1016/S0361-9230(99)00161-6; Agrawal D., 2011, CYBER CTR TECHNICAL; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bach-y-Rita P, 2003, TRENDS COGN SCI, V7, P541, DOI 10.1016/j.tics.2003.10.013; Bach-Y-Rita P, 2004, ANN NY ACAD SCI, V1013, P83, DOI 10.1196/annals.1305.006; Baldi P, 2010, NEURAL NETWORKS, V23, P649, DOI 10.1016/j.neunet.2009.12.007; Banerjee B, 2013, IEEE DATA MINING, P497, DOI 10.1109/ICDMW.2013.134; Banerjee B., 2013, SHOULD INTELLIGENCE, P2; Banerjee B., 2012, 28 S COMP FOUND PERC; Banerjee B., 2013, IEEE INT C BIG DAT, P14; Banerjee B., 2013, IEEE INT C BIG DAT, P7; Banerjee B, 2013, IEEE DATA MINING, P505, DOI 10.1109/ICDMW.2013.135; BARLOW HB, 1953, J PHYSIOL-LONDON, V119, P69; Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577; Bengio Y., 2009, TRENDS MACH LEARN, V2, P1; Bertsekas D. P., 1999, NONLINEAR PROGRAMMIN; Betsch BY, 2004, BIOL CYBERN, V90, P41, DOI 10.1007/s00422-003-0434-6; Bi GQ, 2001, ANNU REV NEUROSCI, V24, P139, DOI 10.1146/annurev.neuro.24.1.139; Bottou L, 2008, ADV NEURAL INFORM PR, V20, P161; Bouvrie J, 2008, INT CONF ACOUST SPEE, P4733, DOI 10.1109/ICASSP.2008.4518714; Brooks R. A., 1990, Robotics and Autonomous Systems, V6, DOI 10.1016/S0921-8890(05)80025-9; BYLANDER T, 1991, ARTIF INTELL, V49, P25, DOI 10.1016/0004-3702(91)90005-5; Cadieu C, 2007, J NEUROPHYSIOL, V98, P1733, DOI 10.1152/jn.01265.2006; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; Chalasani R., 2013, COMPUT RES REPOS; CONSTANTINEPATON M, 1978, SCIENCE, V202, P639, DOI 10.1126/science.309179; David SV, 2009, J NEUROSCI, V29, P3374, DOI 10.1523/JNEUROSCI.5249-08.2009; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Douglas RJ, 2010, HDB BRAIN MICROCIRCU, P15; Dutta J.K., 2013, COMPUT RES REPOS; Dutta J.K., 2012, 28 S COMP FOUND PERC; Egner T, 2010, J NEUROSCI, V30, P16601, DOI 10.1523/JNEUROSCI.2770-10.2010; Einhauser W., 2001, THESIS I NEUROINFORM; Einhauser W, 2002, EUR J NEUROSCI, V15, P475, DOI 10.1046/j.0953-816x.2001.01885.x; Farabet C., 2011, SCALING MACHINE LEAR, P11; Fiorillo C. D., 2008, PLOS ONE, V3; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000211; Fukushima K, 2003, NEUROCOMPUTING, V51, P161, DOI 10.1016/S0925-2312(02)00614-8; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; George D, 2005, IEEE IJCNN, P1812; George D., 2008, THESIS STANFORD U CA; Gill P, 2008, J NEUROPHYSIOL, V99, P2809, DOI 10.1152/jn.01270.2007; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; HARTLINE H. K., 1940, AMER JOUR PHYSIOL, V130, P700; Hawkins J., 2011, HIERARCHICAL TEMPORA; HEEGER DJ, 1992, VISUAL NEUROSCI, V9, P181; Hegde J, 2000, J NEUROSCI, V20, part. no.; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ho YC, 2002, J OPTIMIZ THEORY APP, V115, P549, DOI 10.1023/A:1021251113462; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215; Hubel D, 1995, EYE BRAIN VISION; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P1041; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hyvarinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6; Ito M, 2004, J NEUROSCI, V24, P3313, DOI 10.1523/JNEUROSCI.4364-03.2004; Jehee JFM, 2006, J PHYSIOLOGY-PARIS, V100, P125, DOI 10.1016/j.jphysparis.2006.09.011; Kavukcuoglu K., 2009, IEEE C COMP VIS PATT; Kong Shu, 2012, CORR; Kouh M, 2008, NEURAL COMPUT, V20, P1427, DOI 10.1162/neco.2008.02-07-466; KUFFLER SW, 1953, J NEUROPHYSIOL, V16, P37; Larochelle H, 2009, J MACH LEARN RES, V10, P1; LeCun Y., 1995, HDB BRAIN THEORY NEU, P255; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2008, ADV NEURAL INFORM PR; Lee H., 2010, ADV NEURAL INFORM PR, V22; Lee H., 2009, INT C MACH LEARN, V11, P609, DOI DOI 10.1145/1553374.1553453; Long PM, 2007, INFORM PROCESS LETT, V103, P131, DOI 10.1016/j.ipl.2007.03.004; Mairal J, 2010, J MACH LEARN RES, V11, P19; Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213; Martinez LM, 2003, NEUROSCIENTIST, V9, P317, DOI 10.1177/1073858403252732; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; Masquelier T., 2007, 60 MIT; METIN C, 1989, P NATL ACAD SCI USA, V86, P357, DOI 10.1073/pnas.86.1.357; Meyer T, 2011, P NATL ACAD SCI USA, V108, P19401, DOI 10.1073/pnas.1112895108; Mountcastle V., 1978, MINDFUL BRAIN; Ng A., 2001, ADV NEURAL INFORM PR, V14; Nucleus Research, 2012, NUCL RES FRA NEW MOD; Olsen SR, 2010, NEURON, V66, P287, DOI 10.1016/j.neuron.2010.04.009; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pati Y. C., 1993, C REC 27 AS C SIGN S, V1, P40; Ranzato M., 2007, J MACHINE LEARNING R, V2, P371; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rao RPN, 1999, VISION RES, V39, P1963, DOI 10.1016/S0042-6989(98)00279-X; Rehn M, 2007, J COMPUT NEUROSCI, V22, P135, DOI 10.1007/s10827-006-0003-9; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; ROE AW, 1992, J NEUROSCI, V12, P3651; Rust N., 2008, SOC NEUR ANN M; Rust NC, 2005, NEURON, V46, P945, DOI 10.1016/j.neuron.2005.05.021; Schmah T., 2009, ADV NEURAL INFORM PR, V21, P1409; Serre T., 2006, 28 MIT CSAIL; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Simoncelli E.P., 2000, ADV NEURAL INFORM PR, V13, P166; Sjostrom PJ, 2001, NEURON, V32, P1149, DOI 10.1016/S0896-6273(01)00542-6; Spratling MW, 2010, J NEUROSCI, V30, P3531, DOI 10.1523/JNEUROSCI.4911-09.2010; Vapnik V. N., 1998, STAT LEARNING THEORY; Vincent P., 2008, INT C MACH LEARN, P1096; von Melchner L, 2000, NATURE, V404, P871, DOI 10.1038/35009102; Wainwright MJ, 2002, NEURAL INF PROCESS S, P203; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Zylberberg J., 2011, PLOS COMPUT BIOL, V7	106	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	AUG 22	2014	138						41	60		10.1016/j.neucom.2013.02.044		20	Computer Science, Artificial Intelligence	Computer Science	AI9OK	WOS:000337261700005		
J	Plis, SM; Hjelm, DR; Salakhutdinov, R; Allen, EA; Bockholt, HJ; Long, JD; Johnson, HJ; Paulsen, JS; Turner, JA; Calhoun, VD				Plis, Sergey M.; Hjelm, Devon R.; Salakhutdinov, Ruslan; Allen, Elena A.; Bockholt, Henry J.; Long, Jeffrey D.; Johnson, Hans J.; Paulsen, Jane S.; Turner, Jessica A.; Calhoun, Vince D.			Deep learning for neuroimaging: a validation study	FRONTIERS IN NEUROSCIENCE			English	Article						MRI; fMRI; intrinsic networks; classification; unsupervised learning	NONLINEAR DIMENSIONALITY REDUCTION; COMPONENT ANALYSIS; BLIND SEPARATION; BRAIN NETWORKS; FMRI DATA; SIMULATION	Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methodsis, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) napplication of deep learning methods to structuraland functional brain imaging data. These methods include deep belief networks and their building block the restricted Boltzmann machine. We also describe a novel constraint-based approachto visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.	[Plis, Sergey M.; Allen, Elena A.; Calhoun, Vince D.] Mind Res Network, Albuquerque, NM 87106 USA; [Hjelm, Devon R.; Calhoun, Vince D.] Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; [Salakhutdinov, Ruslan] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Allen, Elena A.] Univ Bergen, Dept Biol & Med Psychol, Bergen, Norway; [Bockholt, Henry J.] Univ Iowa, Adv Biomed Informat Grp LLC, Iowa City, IA USA; [Long, Jeffrey D.; Johnson, Hans J.; Paulsen, Jane S.] Univ Iowa, Carver Coll Med, Dept Psychiat, Iowa City, IA USA; [Long, Jeffrey D.] Univ Iowa, Coll Publ Hlth, Dept Biostat, Iowa City, IA USA; [Johnson, Hans J.] Univ Iowa, Coll Engn, Dept Biomed Engn, Iowa City, IA 52242 USA; [Paulsen, Jane S.] Univ Iowa, Inst Neurosci, Dept Psychol, Iowa City, IA USA; [Paulsen, Jane S.] Univ Iowa, Carver Coll Med, Dept Neurol, Iowa City, IA USA; [Turner, Jessica A.] Georgia State Univ, Inst Neurosci, Dept Psychol, Atlanta, GA 30303 USA; [Calhoun, Vince D.] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA	Plis, SM (reprint author), Mind Res Network, 1101 Yale Blvd NE, Albuquerque, NM 87106 USA.	s.m.plis@gmail.com	Turner, Jessica/H-7282-2015	Turner, Jessica/0000-0003-0076-8434	 [P20GM103472];  [NS0040068];  [COBRE: 2R01EB005846]	This work was supported in part by grants 2R01EB005846, COBRE: P20GM103472 and NS0040068. We thank Dr. vander Maaten for insightful comments on the initial drafts of this paper.	Allen EA, 2014, CEREB CORTEX, V24, P663, DOI 10.1093/cercor/bhs352; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; BISWAL B, 1995, MAGNET RESON MED, V34, P537, DOI 10.1002/mrm.1910340409; Brookes MJ, 2011, P NATL ACAD SCI USA, V108, P16783, DOI 10.1073/pnas.1112685108; Calhoun VD, 2008, HUM BRAIN MAPP, V29, P828, DOI 10.1002/hbm.20581; Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014; de Vries T, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.151; Derbinsky N., 2013, ARXIV13051961; Elser V, 2007, P NATL ACAD SCI USA, V104, P418, DOI 10.1073/pnas.0606359104; Erhardt EB, 2012, NEUROIMAGE, V59, P4160, DOI 10.1016/j.neuroimage.2011.11.088; Fischer Asja, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, DOI 10.1007/978-3-642-33275-3_2; Freire L, 2002, IEEE T MED IMAGING, V21, P470, DOI 10.1109/TMI.2002.1009383; Friston K. J., 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Gravel S, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.036706; Hastie T., 2009, ELEMENTS STAT LEARNI; Hinton G., 2000, NEURAL COMPUT, V14, P2002, DOI DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hinton G.E., 2012, ARXIV12070580; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hjelm RD, 2014, NEUROIMAGE, V96, P245, DOI 10.1016/j.neuroimage.2014.03.048; Hoyer P.O., 2002, NEURAL NETWORKS SIGN, P557; Krizhevsky A., 2012, NEURAL INFORM PROCES; Le Q. V., 2011, NIPS, P1017; Le Q. V., 2012, INT C MACH LEARN ED, P103; Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081; LIU J, 2007, BIOMEDICAL IMAGING N, P1028, DOI DOI 10.1109/ISBI.2007.357030; McKeown MJ, 1998, HUM BRAIN MAPP, V6, P160, DOI 10.1002/(SICI)1097-0193(1998)6:3<160::AID-HBM5>3.0.CO;2-1; Meda SA, 2008, SCHIZOPHR RES, V101, P95, DOI 10.1016/j.schres.2008.02.007; Moosmann M, 2008, INT J PSYCHOPHYSIOL, V67, P212, DOI 10.1016/j.ijpsycho.2007.05.016; Nair V., 2010, P 27 INT C MACH LEAR, P807; POTLURU VK, 2008, CIRC SYST 2008 ISCAS, P1336; Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rubinov M, 2011, NEUROIMAGE, V56, P2068, DOI 10.1016/j.neuroimage.2011.03.069; Sammon Jr J., 1969, COMPUT IEEE T, V100, P401, DOI [DOI 10.1109/T-C.1969.222678, 10.1109/T-C.1969.222678]; Sui J, 2012, J NEUROSCI METH, V204, P68, DOI 10.1016/j.jneumeth.2011.10.031; Swanson N, 2011, HUM BRAIN MAPP, V32, P654, DOI 10.1002/hbm.21055; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; van den Heuvel M., 2010, EUR NEUROPSYCHOPHARM; Van der Maaten L., 2008, J MACH LEARN RES, V9, P85; West D.B., 2001, INTRO GRAPH THEORY, Vsecond; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430; Zuo XN, 2010, NEUROIMAGE, V49, P2163, DOI 10.1016/j.neuroimage.2009.10.080	43	0	0	FRONTIERS RESEARCH FOUNDATION	LAUSANNE	PO BOX 110, LAUSANNE, 1015, SWITZERLAND	1662-453X			FRONT NEUROSCI-SWITZ	Front. Neurosci.	AUG 20	2014	8								229	10.3389/fnins.2014.00229		11	Neurosciences	Neurosciences & Neurology	AW8KN	WOS:000346510900001	25191215	
J	Galtier, MN; Marini, C; Wainrib, G; Jaeger, H				Galtier, Mathieu N.; Marini, Camille; Wainrib, Gilles; Jaeger, Herbert			Relative entropy minimizing noisy non-linear neural network to approximate stochastic processes	NEURAL NETWORKS			English	Article						Echo state networks; Linear inverse modeling; Relative entropy; Stochastic processes; El Nino southern oscillation	SURFACE TEMPERATURE ANOMALIES; LEARNING ALGORITHM; EL-NINO; PREDICTION; SYSTEMS; MODELS; SKILL	A method is provided for designing and training noise-driven recurrent neural networks as models of stochastic processes. The method unifies and generalizes two known separate modeling approaches, Echo State Networks (ESN) and Linear Inverse Modeling (LIM), under the common principle of relative entropy minimization. The power of the new method is demonstrated on a stochastic approximation of the El Mino phenomenon studied in climate research. (C) 2014 Elsevier Ltd. All rights reserved.	[Galtier, Mathieu N.; Jaeger, Herbert] Jacobs Univ Bremen gGmbH, Sch Sci & Engn, D-28759 Bremen, Germany; [Marini, Camille] Univ Hamburg, Inst Meereskunde, Zentrum Meeres & Klimaforsch, Hamburg, Germany; [Marini, Camille] MINES ParisTech, F-06904 Sophia Antipolis, France; [Wainrib, Gilles] Univ Paris 13, Lab Anal Geometrie & Applicat, F-93430 Villetaneuse, France	Galtier, MN (reprint author), EPI NeuroMathComp, CR INRIA, Sophia Antipolis Mditerranee 2004,Route Lucioles, F-06902 Sophia Antipolis, France.	mathieu.galtier@inria.fr			Amarsi European Project	The authors would like to thank Mantas Lukosevicius for helpful discussions. MNG was funded by the Amarsi European Project.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Avellaneda M., 1997, APPL MATH FINANCE, V4, P37; Barnston AG, 2012, B AM METEOROL SOC, V93, P631, DOI 10.1175/BAMS-D-11-00111.1; Bishop CM, 2006, PATTERN RECOGNITION; Box GE, 2013, TIME SERIES ANAL FOR; Buesing L, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002211; Chatzis SP, 2011, IEEE T NEURAL NETWOR, V22, P1435, DOI 10.1109/TNN.2011.2162109; Cover T. M., 2012, ELEMENTS INFORM THEO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deser C, 2010, ANNU REV MAR SCI, V2, P115, DOI 10.1146/annurev-marine-120408-151453; Ellis R., 2005, ENTROPY LARGE DEVIAT, V1431; FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X; Galtier MN, 2013, NEURAL COMPUT, V25, P2815, DOI 10.1162/NECO_a_00512; Girsanov I. V., 1960, THEOR PROBAB APPL, V5, P285, DOI 10.1137/1105027; Hawkins E, 2011, CLIM DYNAM, V37, P2495, DOI 10.1007/s00382-011-1023-3; Haykin S., 2005, ADAPTIVE FILTER THEO; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Husmeier D, 1997, NEURAL NETWORKS, V10, P479, DOI 10.1016/S0893-6080(96)00062-7; Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016; Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277; Krogh A, 1999, NEURAL COMPUT, V11, P541, DOI 10.1162/089976699300016764; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Liu DY, 2011, NUMER ALGORITHMS, V58, P53, DOI 10.1007/s11075-011-9447-8; Lukosevicius M., 2009, COMPUTER SCI REV, V3, P127, DOI DOI 10.1016/J.COSREV.2009.03.005; Maass W, 2002, NEURAL COMPUT, V14, P2531, DOI 10.1162/089976602760407955; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; Murphy K. P., 2002, THESIS U CALIFORNIA; Newman M., 2013, J CLIMATE; PEARLMUTTER BA, 1995, IEEE T NEURAL NETWOR, V6, P1212, DOI 10.1109/72.410363; PENLAND C, 1995, J CLIMATE, V8, P1999, DOI 10.1175/1520-0442(1995)008<1999:TOGOTS>2.0.CO;2; PENLAND C, 1993, J CLIMATE, V6, P1067, DOI 10.1175/1520-0442(1993)006<1067:PONSST>2.0.CO;2; PENLAND C, 1994, J CLIMATE, V7, P1352, DOI 10.1175/1520-0442(1994)007<1352:ABCFSN>2.0.CO;2; Penland C, 1996, PHYSICA D, V98, P534, DOI 10.1016/0167-2789(96)00124-8; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rayner N., 2003, J GEOPHYS RES ATMOSP, V108; Risken H., 1996, FOKKER PLANCK EQUATI, V18; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Shreve S.E., 1991, BROWNIAN MOTION STOC, V113; Sontag E., 1997, DEALING COMPLEXITY N, P1; Sutskever I., 2006, 2006003 UTML TR U TR; Trenberth KE, 1997, B AM METEOROL SOC, V78, P2771, DOI 10.1175/1520-0477(1997)078<2771:TDOENO>2.0.CO;2; Wainrib G, 2013, LECT NOTES MATH, V2058, P73, DOI 10.1007/978-3-642-32157-3_4; Williams R. J., 1995, BACK PROPAGATION THE, P433; Zanna L, 2012, J CLIMATE, V25, P5047, DOI 10.1175/JCLI-D-11-00539.1	46	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	AUG	2014	56						10	21		10.1016/j.neunet.2014.04.002		12	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	AK7MJ	WOS:000338612100002	24815743	
