PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
B	Gupta, MR; Gray, RM			IEEE	Gupta, MR; Gray, RM			Reducing bias in supervised learning	PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING			English	Proceedings Paper	12th IEEE Workshop on Statistical Signal Processing	SEP 28-OCT 01, 2003	St Louis, MO	IEEE Signal Proc Soc, DARPA, USAF Res Lab, Off Naval Res, Natl Sci Fdn				Nonparametric statistical supervised learning methods often suffer from bias caused by non-uniformity of the probability distribution of training samples. We discuss this problem and propose a new nonparametric neighborhood method for classification and estimation that significantly reduces the bias. Simulations exemplify the advantages, and theoretical results are noted.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.						Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GRAY RM, 1997, P COMPR COMPL SEQ C, P172; Gupta M. R., 2003, THESIS STANFORD U ST; Hastie T, 2001, ELEMENTS STAT LEARNI; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Kang H. R., 1997, COLOR TECHNOLOGY ELE; KOHONEN T, 1988, 2ND P IEEE INT C NEU, V1, P61; OBRIEN D, 2003, P INT C IM P; Rovatti R, 1998, IEEE T COMPUT, V47, P894, DOI 10.1109/12.707591; Wu N., 1997, MAXIMUM ENTROPY METH	12	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7997-7				2003							482	485				4	Computer Science, Information Systems; Mathematics, Interdisciplinary Applications; Imaging Science & Photographic Technology; Telecommunications	Computer Science; Mathematics; Imaging Science & Photographic Technology; Telecommunications	BY73T	WOS:000189451000134	
S	Jankowski, N			IEEE; IEEE	Jankowski, N			Discrete feature weighting & selection algorithm	PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003, VOLS 1-4	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUL 20-24, 2003	PORTLAND, OR	Int Neural Network Soc, IEEE Neural Networks Soc				A new method of feature weighting, useful also for feature selection has been described. It is quite efficient and gives quite accurate results. In general weighting algorithm may be used with any kind of learning algorithm. The weighting algorithm with k-nearest neighbors model was used to estimate the optimal feature base for a given distance measure. Results obtained with this algorithm clearly show its superior performance in several benchmark tests.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Ul Grudziadzka 5, PL-87100 Torun, Poland.						ADAMCZAK R, 1997, 3 C NEUR NETW THEIR, P65; Almuallim H., 1992, Proceedings of the Ninth Biennial Conference of the Canadian Society for Computational Studies of Intelligence; Bennett K.P., 1997, SUPPORT VECTOR MACHI; Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASH M, 1997, INTELLIGENT DATA ANA, V1; Duch W., 1999, INT JOINT C NEUR NET, P742; DUCH W, 1998, NEURAL PROCESS LETT, V7, P1; DUDA RO, 1997, PATTER CLASSIFICATIO; FERNANDEZ M, 1999, 5 INT WORK C ART NAT, P477; Grabczewski K., 2000, NEURAL NETWORKS SOFT, P202; JANKOWSKI N, 1999, THESIS N COPERNICUS; Merz C.J., 1998, UCI REPOSITORY MACHI; Michie D, 1994, MACHINE LEARNING NEU; Schiffmann W., 1993, P EUR S ART NEUR NET, P97; SHANG N, 1996, P ICONIP 96; Ster B., 1996, P INT C ENG APPL NEU, P427; Weiss S., 1990, READINGS MACHINE LEA; WILSON DR, 1997, THESIS B YOUNG U; WILSON DR, 1996, INT C ART INT EXP SY, P11; ZARNDT F, 1995, THESIS B YOUNG U	21	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	0-7803-7898-9	IEEE IJCNN			2003							636	641				6	Computer Science, Artificial Intelligence	Computer Science	BX30P	WOS:000184903300116	
S	Timar, G; Balya, D; Szatmari, I; Rekeczky, C			IEEE; IEEE	Timar, G; Balya, D; Szatmari, I; Rekeczky, C			Feature guided visual attention with topographic array processing and neural network-based classification	PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003, VOLS 1-4	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUL 20-24, 2003	PORTLAND, OR	Int Neural Network Soc, IEEE Neural Networks Soc			CNN; PARALLEL; MACHINE	Biological systems are constantly engulfed in sensory input that must be processed. Attention has evolved to cut down on the magnitude of the input and enable the agent to analyze the most important parts of the information. This is especially true for the visual system where the appropriate field of view and scale must be determined. Our system receives a video flow with considerably higher resolution than the resolution of the cellular neural net based visual microprocessor that computes the topographic features of the input. This process requires a dynamic positioning of the processing window in the video flow. We have developed a fast attention and selection algorithm that allows the system to choose the field of view and scale (zoom) level for the next frame based on the features computed from the current frame and the output of the ART or NNC-based classifiers. The algorithmic framework and the hardware architecture of the system are presented along with experimental chip results for several video flows recorded in flying vehicles.	Hungarian Acad Sci, Inst Comp & Automat, Anal & Neural Comp Lab, H-1111 Budapest, Hungary	Timar, G (reprint author), Hungarian Acad Sci, Inst Comp & Automat, Anal & Neural Comp Lab, Kende U 13-17, H-1111 Budapest, Hungary.						CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; Chua LO, 1997, INT J BIFURCAT CHAOS, V7, P2219, DOI 10.1142/S0218127497001618; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ESPEJO S, 1998, P 5 INT C EL CIRC SY, P203; Kaufman L., 1990, FINDING GROUPS DATA; LINAN G, 2001, EUR C CIRC THEOR DES, P345; Niebur E, 1998, ATTENTIVE BRAIN, P163; Rekeczky C, 1999, J VLSI SIG PROCESS S, V23, P373, DOI 10.1023/A:1008153320440; Roska B, 2001, NATURE, V410, P583, DOI 10.1038/35069068; ROSKA T, 1993, IEEE T CIRCUITS-II, V40, P163, DOI 10.1109/82.222815; THAKOOR S, 2002, ARTIFICIAL LIFE, V8; WERBLIN F, 1995, INT J CIRC THEOR APP, V23, P541, DOI 10.1002/cta.4490230602; ZARANDY A, 2003, IN PRESS IEEE J CIRC; *AN COMP LTD, 2002, AL PRO R2 3	15	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	0-7803-7898-9	IEEE IJCNN			2003							1492	1496				5	Computer Science, Artificial Intelligence	Computer Science	BX30P	WOS:000184903300272	
B	Zeng, XC; Martinez, T			IEEE; IEEE	Zeng, XC; Martinez, T			A noise filtering method using neural networks	SCIMA 2003: IEEE INTERNATIONAL WORKSHOP ON SOFT COMPUTING TECHNIQUES IN INSTRUMENTATION, MEASUREMENT AND RELATED APPLICATIONS			English	Proceedings Paper	IEEE International Workshop on Soft Computing Techniques in Instrumentation, Measurement and Related Applications	MAY   17, 2003	PROVO, UT	IEEE Instrumentat & Measurement Soc	BRIGHAM YOUNG UNIV		NEAREST NEIGHBOR RULE; LEARNING ALGORITHMS; CLASSIFICATION	During the data collecting and labeling process it is possible for noise to. be introduced into a data set. As a result, the quality of the data set degrades and experiments and inferences derived from the data set become less reliable. In this paper we present an algorithm, called ANR (automatic noise reduction), as a filtering mechanism to identify and remove noisy data items whose classes have been mislabeled The underlying mechanism behind ANR is based on a framework of multi-layer artificial neural networks. ANR assigns each data item a soft class label in the form of a class probability vector, which is initialized to the original class label and can be modified during training. When the noise level is reasonably small (< 30%), the non-noisy data is dominant in determining the network architecture and its output, and thus a mechanism for correcting mislabeled data can be provided by aligning class probability vector with the network output. With a learning procedure for class probability vector based on its difference from the network output, the probability of a mislabeled class gradually becomes smaller while that of the correct class becomes larger, which eventually causes a correction of mislabeled data after sufficient training. After training, those data items whose classes have been relabeled are then treated as noisy data and removed from the data set. We evaluate the performance of the ANR based on 12 data sets drawn from the UCI data repository. The results show that ANR is capable of identifying a significant portion of noisy data. An average increase in accuracy of 24.5% can be achieved at a noise level of 25% by using ANR as a training data filter for a nearest neighbor classifier, as compared to the one without using ANR.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Zeng, XC (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.						Aha D.W., 1989, P 11 INT JOINT C ART, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; Gamberger D., 1996, P 7 INT WORKSH ALG L, P199; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; John G. H., 1995, P 1 INT C KNOWL DISC, P174; Merz C. J., 1996, UCI REPOSITORY MACHI; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Teng C. M., 1999, P 16 INT C MACH LEAR, P239; TENG CM, 2000, LECT NOTES AI; WILSON D, 1972, IEEE T SYST MAN CYB, V6, P448; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WILSON DR, 1997, MACH LEARN, P403; Winston P. H., 1975, PSYCHOL COMPUTER VIS; Zeng X., 2001, INTELL DATA ANAL, V5, P491	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7711-7				2003							26	31				6	Computer Science, Artificial Intelligence	Computer Science	BX02K	WOS:000183992100005	
B	Shibata, T; Kato, T; Wada, T		Wu, XD; Tuzhilin, A; Shavlik, J		Shibata, T; Kato, T; Wada, T			K-D decision tree: An accelerated and memory efficient nearest neighbor classifier	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI			RULE; ALGORITHM	Most nearest neighbor (NN) classifiers employ NN search algorithms for the acceleration. However, NN classification does not always require the NN search. Based on this idea, we propose a novel algorithm named k-d decision tree (KDDT). Since KDDT uses Voronoi condensed prototypes, it is less memory consuming than naive NN classifiers. We have confirmed that KDDT is much faster than NN search based classifiers through the comparative, experiment (from 9 to 369 times faster).	Wakayama Univ, Fac Syst Engn, Wakayama, Japan	Shibata, T (reprint author), Wakayama Univ, Fac Syst Engn, Wakayama, Japan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AHA W, 1989, P 11 IJCAI, P794; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BENTLEY L, 1975, COMMUNICATIONS ACM, V18; BHATTACHARYA RS, 1981, INT S INF THEOR SANT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Vapnik V.N., 1995, NATURE STAT LEARNING	14	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1978-4				2003							641	644				4	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400102	
B	Zhu, HW; Basir, O		Wu, XD; Tuzhilin, A; Shavlik, J		Zhu, HW; Basir, O			A K-NN associated fuzzy evidential reasoning classifier with adaptive neighbor selection	THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS			English	Proceedings Paper	3rd IEEE International Conference on Data Mining	NOV 19-22, 2003	MELBOURNE, FL	IEEE Comp Soc TCCI, IEEE Comp Soc TCPAMI				The paper presents a fuzzy evidential reasoning algorithm in light of the Dempster-Shafer evidence theory and the K-nearest neighbor algorithm for pattern classification. Given an input pattern to be classified, each of its K nearest neighbors is viewed as an evidence source, in terms of a fuzzy evidence structure. The distance between the input pattern and each of its K nearest neighbors is used for mass determination while the contextual information of the nearest neighbor in the training sample space is formulated by a fuzzy set in determining a fuzzy focal element. Therefore, pooling evidence provided by neighbors is realized by a fuzzy evidential reasoning, where feature selection is further considered through ranking and adaptive combination of neighbors. A fast implementation scheme of the fuzzy evidential reasoning is also developed. Experimental results of classifying multi-channel remote sensing images have shown that the proposed approach outperforms the K-nearest neighbor (K-NN) algorithm [1], the fuzzy K-nearest neighbor (F-KNN) algorithm [2], the evidence-theoretic Knearest neighbor (E-KNN) algorithm [3], and the fuzzy extended version of E-KNN (FE-KNN) [4], in terms of the classification accuracy and insensitivity to the number K of nearest neighbors.	Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	Zhu, HW (reprint author), Univ Waterloo, Dept Syst Design Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Giacinto G, 2000, PATTERN RECOGN LETT, V21, P385, DOI 10.1016/S0167-8655(00)00006-4; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Shafer G., 1976, MATH THEORY EVIDENCE; ZHU H, 2003, P 5 IEEE INT S COMP; ZOUHAL LM, 1997, P 2 INT ICSC S FUZZ, P294	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1978-4				2003							709	712				4	Computer Science, Artificial Intelligence	Computer Science	BY34Z	WOS:000188999400119	
S	Sanz, PJ; Marin, R; Sanchez, JS			IEEE; IEEE	Sanz, PJ; Marin, R; Sanchez, JS			Fast object recognition methods for the UJI online robot	2003 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, CONFERENCE PROCEEDINGS	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics (SMC 03)	OCT 05-08, 2003	WASHINGTON, D.C.	IEEE, Syst, Man & Cybernet Soc		object recognition; online robots; neural networks		Within the context of online robots, a considerable amount of research has traditionally focused on the global system functionality, including the way of interaction between the user and the robot. Recent results in different robotics areas have demonstrated the potential of a number of techniques from the Pattern Recognition and Machine Learning domains, although very few work has been specifically addressed to online robots, where the object recognition is directly performed by the user. In this paper, we investigate the feasibility of using a neural network approach to object recognition in the context of online robots, and discuss the main advantages over the application of statistical learning methods. Some experiments with the UJI (Universitat Jaume I) online robot evaluate the performance of different neural network implementations, comparing it to that of some distance-based object recognition algorithms.	Jaume I Univ, Dept Comp Sci, Castellon de La Plana, Spain	Sanz, PJ (reprint author), Jaume I Univ, Dept Comp Sci, Castellon de La Plana, Spain.	sanzp@ieee.org; rmarin@icc.uji.es; sanchez@uji.es					CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox M.J., 1994, P 2 INT C WORLD WID; DASARATHY BV, 1990, NEAREST NEIGHBOUR NN; Duda R., 1973, PATTERN CLASSIFICATI; FERWORN A, 1999, P IASTED C ROB APPL, P158; GOLDBERG K, 1995, P ACM SIGGRAPH, P135; GOLDBERG K, 1995, IEEE INT CONF ROBOT, P654, DOI 10.1109/ROBOT.1995.525358; GOLDBERG S, 1998, IROS 98 WORKSH WEB R, P55; Holmstrom L, 1997, IEEE T NEURAL NETWOR, V8, P5, DOI 10.1109/72.554187; HU M, 1962, IRE T INFORM THEOR, V8, P179; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013643; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013644; MCKEE GT, 1996, ROBOTICS MACHINE PER, V5; PAULO E, 1996, P IEEE INT C ROB AUT, P1250; Preece J. J., 1994, HUMAN COMPUTER INTER; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Saucy P, 2000, IEEE ROBOT AUTOM MAG, V7, P41, DOI 10.1109/100.833574; Schalkoff R, 1992, PATTERN RECOGNITION; Schulz D, 2000, IEEE ROBOT AUTOM MAG, V7, P48, DOI 10.1109/100.833575; SIMMONS R, 1998, P IROS 98 WORKSH WEB, P43	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	0-7803-7952-7	IEEE SYS MAN CYBERN			2003							2791	2796				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Robotics	Automation & Control Systems; Computer Science; Robotics	BX83D	WOS:000186578600456	
B	Chang, F; Lin, CC; Lin, WH			IEEE	Chang, F; Lin, CC; Lin, WH			A two-stage classification method for vector pattern matching problems	2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	NOV 02-05, 2003	Xian, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Tech Comm Cybernet, Hebei Univ, NW Polytech Univ		disambiguation; learning mechanism; nearest neighbor; support vector machines; template; vector; pattern matching		In this paper, we propose a new method to classify unknown objects into a large number of possible patterns (classes) and thereby solve vector-matching problems. The core of this method is a learning mechanism that reduces a huge amount of training samples into a highly condensed set of templates. When used in a testing process, these templates hold target patterns within the nearest K templates for almost all unknown objects, where K is a small number (2 or 3, for example). This learning mechanism also produces an extremely small set of confusing pairs, in opposition to all N(N-1)/2 possible pairs, where N is the total number of patterns. These pairs are further processed by a disambiguation procedure that improves the overall performance of the pattern classifier. This learning method thus suggests a two-stage online process for classifying unknown objects. The first stage reduces the number of possible candidates to a few candidates and the second stage identifies the target patterns out of these candidates.	Acad Sinica, Inst Informat Sci, Taipei, Taiwan	Chang, F (reprint author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.						Burges C J C, 1998, KNOWLEDGE DISCOVERY, V2; Chang C. C., LIBSVM LIB SUPPORT V; CHANG F, UNPUB IEEE T PATTERN; Cherkassky V, 1998, LEARNING DATA; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; HSU CW, 2000, IEEE T NEURAL NETWOR, V13, P415; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Reilly D. L., 1990, INTRO NEURAL ELECT N; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Vapnik V.N., 1995, NATURE STAT LEARNING	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7865-2				2003							3022	3027				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BY61C	WOS:000189420700605	
B	Wang, Z; Hu, WD; Yu, WX			IEEE	Wang, Z; Hu, WD; Yu, WX			A quick evidential classification algorithm based on K-nearest neighbor rule	2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	NOV 02-05, 2003	Xian, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Tech Comm Cybernet, Hebei Univ, NW Polytech Univ		theory of evidence; testing of evidence consistency; conflict among evidences; k-nearest neighbor rule; quick evidential classification algorithm; superball searching		Under the frame of Dempster-Shafer theory of evidence, a distance function to depict comparability between evidences is constructed according to the conflict among evidences, which is for the case that the origin of few evidences is uncertain. In order to conquer these disadvantages of traditional quick k-nearest neighbor(k-NN) classification algorithm, this paper proposes a quick k-NN evidence classification algorithm-super-ball search evidence classification(ab. S-BSEC) algorithm based on near neighbor searching. Simulation results show that this method is superior to the traditional k-NN algorithm in terms of the recognition speed under the same recognition rate and k, and super-ball algorithm is not sensitive to searching order of training sample.	Natl Univ Def Technol, ATR State Key Lab, Changsha 410073, Peoples R China	Wang, Z (reprint author), Natl Univ Def Technol, ATR State Key Lab, Changsha 410073, Peoples R China.						BIAN Z, 1988, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1991, NEAREST NEIGHBOR NOR; HE You, 2000, MULTISENSOR INFORMAT; Llinas J., 1990, MULTISENSOR DATA FUS; LOWRANCE JD, 1983, 307 SRI INT ART INT; THIERRY D, 1995, IEEE T SYST MAN CYB, V25, P804; WANG FL, 1983, FDN PATTERN RECOGNIT; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7865-2				2003							3248	3252				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BY61C	WOS:000189420700650	
B	Droettboom, M		Marshall, CC; Henry, G; Delcambre, L		Droettboom, M			Correcting broken characters in the recognition of historical printed documents	2003 JOINT CONFERENCE ON DIGITAL LIBRARIES, PROCEEDINGS			English	Proceedings Paper	Joint Conference on Digital Libraries	MAY 27-31, 2003	HOUSTON, TX	IEEE TC Digital Lib, ACM SIGIR, ACM SIGWEB, Coalit Networked Informat, DELOS, Amer Soc Informat Sci & Technol	RICE UNIV			This paper presents a new technique for dealing with broken characters, one of the major challenges in the optical character recognition (OCR) of degraded historical printed documents. A technique based on graph combinatorics is used to rejoin the appropriate connected components. It has been applied to real data with successful results.	Johns Hopkins Univ, Digital Knowledge Ctr, Baltimore, MD 21218 USA	Droettboom, M (reprint author), Johns Hopkins Univ, Digital Knowledge Ctr, 3400 N Charles St, Baltimore, MD 21218 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Droettboom M., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries; FUJINAGA I, 1991, INT COMP MUSIC C, P66; HARDING SM, 1997, EUR C DIG LIB, P345; Kass M., 1987, INT C COMP VIS, P259; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; 1799, STAT ACCOUNTS SCOTLA	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1939-3				2003							364	366		10.1109/JCDL.2003.1204889		3	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	BW95C	WOS:000183728000051	
B	Marsi, E; Reynaert, M; van den Bosch, A; Daelemans, W; Hoste, V			ACL	Marsi, E; Reynaert, M; van den Bosch, A; Daelemans, W; Hoste, V			Learning to predict pitch accents and prosodic boundaries in Dutch	41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	41st Annual Meeting of the Association-for-Computational-Linguistics	JUL 07-12, 2003	Sapporo, JAPAN	Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR			LANGUAGE	We train a decision tree inducer (CART) and a memory-based classifier (MBL) on predicting prosodic pitch accents and breaks in Dutch text, on the basis of shallow, easy-to-compute features. We train the algorithms on both tasks individually and on the two tasks simultaneously. The parameters of both algorithms and the selection of features are optimized per task with iterative deepening, an efficient wrapper procedure that uses progressive sampling of training data. Results show a consistent significant advantage of MBL over CART, and also indicate that task combination can be done at the cost of little generalization score loss. Tests on cross-validated data and on held-out data yield F-scores of MBL on accent placement of 84 and 87, respectively, and on breaks of 88 and 91, respectively. Accent placement is shown to outperform an informed baseline rule; reliably predicting breaks other than those already indicated by intra-sentential punctuation, however, appears to be more challenging.	Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands			van den Bosch, Antal/G-5072-2011	van den Bosch, Antal/0000-0003-2493-656X			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BLACK AW, 1995, P SPRING M ACOUSTIC; Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cutler A, 1997, LANG SPEECH, V40, P141; Daelemans W, 2002, P 3 INT C LANG RES E, P755; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; DAELEMANS W, 2002, ILK02010 ILK TILB U; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; FIX, 1981, 4 USAF SCH AV MED; HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C; Koehn P, 2000, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2000.861813; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Ladd D. R., 1996, INTONATIONAL PHONOLO; MARSI GJ, 2002, P INT C SPOK LANG PR, P1273; PAN, 2000, P 35 ANN M ASS COMP; PAN S, 1999, P EMNLP VLC 99; Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188; RIJSBERGEN CJV, 1979, INFORMATION RETRIEVA; Salton G., 1989, AUTOMATIC TEXT PROCE; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Taylor P., 1999, EDINBURGH SPEECH TOO; Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041; VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V1, P529; WANG MQ, 1997, COMPUTER SPEECH LANG, V6, P175	25	0	0	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA		1-932432-09-4				2003							489	496				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAP08	WOS:000223097500062	
B	Park, SB; Zhang, BT			ACL	Park, SB; Zhang, BT			Text chunking by combining hand-crafted rules and memory-based learning	41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	41st Annual Meeting of the Association-for-Computational-Linguistics	JUL 07-12, 2003	Sapporo, JAPAN	Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR				This paper proposes a hybrid of hand-crafted rules and a machine learning method for chunking Korean. In the partially free word-order languages such as Korean and Japanese, a small number of rules dominate the performance due to their well-developed postpositions and endings. Thus, the proposed method is primarily based on the rules, and then the residual errors are corrected by adopting a memory-based machine learning method. Since the memory-based learning is an efficient method to handle exceptions in natural language processing, it is good at checking whether the estimates are exceptional cases of the rules and revising them. An evaluation of the method yields the improvement in F-score over the rules or various machine learning methods alone.	Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea							Cherkassky V, 1998, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2001, TIMBL TILBURG MEMORY; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Golding AR, 1996, ARTIF INTELL, V87, P215, DOI 10.1016/0004-3702(95)00120-4; Joachims T., 1998, MAKING LARGE SCALE S; KIM KC, 1995, J KISS, V22, P1384; Kudoh Taku, 2000, P CONLL 2000 LLL 200, p142~144; PARK SB, 2001, P 19 INT C COMPUTER, P225; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; RAMSHAW L, 1995, P 3 ACL WORKSH VER L, P80; SHIN HP, 1999, P C HANG KOR LANG IN, P240; YOON JT, 1999, CSTR99139 KAIST CORP; Zhang T., 2001, P 39 ANN M ASS COMP, P539, DOI 10.3115/1073012.1073081; *CONLL, 2000, SHAR TASK COMP NAT L	15	0	0	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA		1-932432-09-4				2003							497	504				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAP08	WOS:000223097500063	
J	Chien, JT; Wu, CC				Chien, JT; Wu, CC			Discriminant waveletfaces and nearest feature classifiers for face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						discriminant waveletface; nearest feature classifier; face recognition	CLASSIFICATION	Feature extraction, discriminant analysis, and classification rule are three crucial issues for face recognition. This paper presents hybrid approaches to handle three issues together. For feature extraction, we apply the multiresolution wavelet transform to extract waveletface. We also perform the linear discriminant analysis on waveletfaces to reinforce discriminant power. During classification, the nearest feature plane (NFP) and nearest feature space (NFS) classifiers are explored for robust decision in presence of wide facial variations. Their relationships to conventional nearest neighbor and nearest feature line classifiers are demonstrated. In the experiments, the discriminant waveletface incorporated with the NFS classifier achieves the best face recognition performance.	Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan	Chien, JT (reprint author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.	jtchien@mail.ncku.edu.tw					AVERBUCH A, 1996, IEEE T IMAGE PROCESS, V5; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; CHENG Y, 1991, SPIE P INTELLIGENT R, V10, P85; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ETEMAD K., 1996, P INT C AC SPEECH SI, P2148; Fisher RA, 1938, ANN EUGENIC, V8, P376; Foltyniewicz R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546715; Fukunaga K., 1990, INTRO STAT PATTERN R; GOLDSTEI.AJ, 1971, PR INST ELECTR ELECT, V59, P748, DOI 10.1109/PROC.1971.8254; KOUZANI AZ, 1997, P IEEE C SYST MAN CY, P1614; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lin SH, 1997, IEEE T NEURAL NETWOR, V8, P114; LIU C, 2000, P INT C PATTERN RECO, V1, P249; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Nefian AV, 1998, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.1998.678085; Rao Raghuveer M., 1998, WAVELET TRANSFORMS I; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Zhang J, 1997, P IEEE, V85, P1423	22	179	206	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1644	1649				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	618YA	WOS:000179444600008	
J	Achiron, A; Gicquel, S; Miron, S; Faibel, M				Achiron, A; Gicquel, S; Miron, S; Faibel, M			Brain MRI lesion load quantification in multiple sclerosis: A comparison between automated multispectral and semi-automated thresholding computer-assisted techniques	MAGNETIC RESONANCE IMAGING			English	Article						MRI; multiple sclerosis; lesions; quantification	VOLUME MEASUREMENTS; SEGMENTATION; IMAGES; INTRAOBSERVER; INTEROBSERVER	Brain magnetic resonance imaging (MRI) lesion volume measurement is an advantageous tool for assessing disease burden in multiple sclerosis (MS). We have evaluated two computer-assisted techniques: MSA multispectral automatic technique that is based on bayesian classification of brain tissue and NIH image analysis technique that is based on local (lesion by lesion) thresholding, to establish reliability and repeatability values for each technique. Brain MRIs were obtained for 30 clinically definite relapsing-remitting MS patients using a 2.0 Tesla MR scanner with contiguous, 3 mm thick axial, T1, T2 and PD weighted modalities. Digital (Dicom 3) images were analyzed independently by three observers; each analyzed the images twice, using the two different techniques (Total 360 analyses). Accuracy of lesion load measurements using phantom images of known volumes showed significantly better results for the MSA multispectral technique (p < 0.001). The mean intra-and inter-observer variances were, respectively, 0.04 +/- 0.4 (range 0.04-0.13), and 0.09 +/- 0.6 (range 0.01-0.26) for the multispectral MSA analysis technique, 0.24 +/- 2.27 (range 0.23-0.72) and 0.33 +/- 3.8 (range 0.47-1.36) for the NIH threshold technique. These data show that the MSA multispectral technique is significantly more accurate in lesion volume measurements, with better results of within and between observers' assessments, and the lesion load measurements are not influenced by increased disease burden. Measurements by the MSA multispectral technique were also faster and decreased analysis time by 43%. The MSA multispectral technique is a promising tool for evaluating MS patients. Non-biased recognition and delineation algorithms enable high accuracy, low intra-and inter-observer variances and fast assessment of MS related lesion load. (C) 2002 Elsevier Science Inc. All rights reserved.	Chaim Sheba Med Ctr, Multiple Sclerosis Ctr, IL-52621 Tel Hashomer, Israel; Chaim Sheba Med Ctr, Neuroradiol Unit, IL-52621 Tel Hashomer, Israel	Achiron, A (reprint author), Chaim Sheba Med Ctr, Multiple Sclerosis Ctr, IL-52621 Tel Hashomer, Israel.						ARDEKANI BA, 1994, J COMPUT ASSIST TOMO, V18, P963, DOI 10.1097/00004728-199411000-00022; Atkins MS, 1998, IEEE T MED IMAGING, V17, P98, DOI 10.1109/42.668699; Bobroff S, 1999, MAGN RESON IMAGING, V17, P783, DOI 10.1016/S0730-725X(99)00010-7; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; COLLINS DL, 1994, J COMPUT ASSIST TOMO, V18, P192; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ege BM, 2000, COMPUT METH PROG BIO, V62, P165, DOI 10.1016/S0169-2607(00)00065-1; Filippi M, 1995, BRAIN, V118, P1593, DOI 10.1093/brain/118.6.1593; Filippi M, 1995, BRAIN, V118, P1601, DOI 10.1093/brain/118.6.1601; Gasperini C, 2001, MULT SCLER, V7, P27, DOI 10.1191/135245801672817145; GONZALEZ CF, 1994, J NEUROIMAGING, V4, P188; Grimaud J, 1996, MAGN RESON IMAGING, V14, P495, DOI 10.1016/0730-725X(96)00018-5; Johnston B, 1996, IEEE T MED IMAGING, V15, P154, DOI 10.1109/42.491417; KAMBER M, 1995, IEEE T MED IMAGING, V14, P442, DOI 10.1109/42.414608; Lampinen J, 2001, NEURAL NETWORKS, V14, P257, DOI 10.1016/S0893-6080(00)00098-8; LI SZ, 1994, MAGN RESON IMAGING, V12, P1079, DOI 10.1016/0730-725X(94)91240-W; Miller DH, 1998, BRAIN, V121, P3, DOI 10.1093/brain/121.1.3; MITCHELL JR, 1994, JMRI-J MAGN RESON IM, V4, P197, DOI 10.1002/jmri.1880040218; Molyneux PD, 1998, J NEUROL NEUROSUR PS, V65, P42, DOI 10.1136/jnnp.65.1.42; PANNIZZO F, 1992, MAGNET RESON MED, V24, P90, DOI 10.1002/mrm.1910240110; PATY DW, 1993, NEUROLOGY, V43, P662; POSER CM, 1983, ANN NEUROL, V13, P227, DOI 10.1002/ana.410130302; Press W.H., 1994, NUMERICAL RECIPES C; Francis G, 2001, NEUROLOGY, V56, P1628; SANDOR T, 1991, INT J BIOMED COMPUT, V29, P133, DOI 10.1016/0020-7101(91)90004-X; Simon JH, 1997, AM J NEURORADIOL, V18, P580; SUZUKI H, 1991, COMPUT MED IMAG GRAP, V15, P233, DOI 10.1016/0895-6111(91)90081-6; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Van Leemput K, 2001, IEEE T MED IMAGING, V20, P677, DOI 10.1109/42.938237; Vinitski S, 1997, MAGNET RESON MED, V37, P457, DOI 10.1002/mrm.1910370325; WICKS DAG, 1992, NEURORADIOLOGY, V34, P475; Zijdenbos Alex P., 1994, Critical Reviews in Biomedical Engineering, V22, P401	32	15	15	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0730-725X		MAGN RESON IMAGING	Magn. Reson. Imaging	DEC	2002	20	10					713	720		10.1016/S0730-725X(02)00606-9		8	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	648NK	WOS:000181157300003	
J	Hofmann, WK; de Vos, S; Komor, M; Hoelzer, D; Wachsman, W; Koeffler, HP				Hofmann, WK; de Vos, S; Komor, M; Hoelzer, D; Wachsman, W; Koeffler, HP			Characterization of gene expression of CD34(+) cells from normal and myelodysplastic bone marrow	BLOOD			English	Article							MICROARRAY ANALYSIS; APOPTOSIS; IDENTIFICATION; DIFFERENTIATION; CLASSIFICATION; PROLIFERATION; HEMATOPOIESIS; ACTIVATION; RESISTANCE; ONCOGENE	Gene patterns of expression in purified CD34(+) bone marrow cells from 7 patients with low-risk myelodysplastic syndrome (MDS) and 4 patients with high-risk MDS were compared with expression data from CD34+ bone marrow cells from 4 healthy control subjects. CD34 cells were isolated by magnetic cell separation, and high-density oligonucleotide microarray analysis was performed. For confirmation, the expression of selected genes was analyzed by real-time polymerase chain reaction. Class membership prediction analysis selected 11 genes. Using the expression profile of these genes, we were able to discriminate patients with low-risk from patients with high-risk MDS and both patient groups from the control group by hierarchical clustering (Spearman confidence). The power of these 11 genes was verified by applying the algorithm to an unknown test set containing expression data from 8 additional patients with MDS (3 at low risk, 5 at high risk). Patients at low risk could be distinguished from those at high risk by clustering analysis. In low-risk MDS, we found that the retinoic-acid-induced gene (RAI3), the radiation-inducible, immediate-early response gene (IEX1), and the stress-induced phosphoprotein 1 (STIP1) were down-regulated. These data suggest that CD34(+) cells from patients with low-risk MDS lack defensive proteins, resulting in their susceptibility to cell damage. In summary, we propose that gene expression profiling may have clinical relevance for risk evaluation in MDS at the time of initial diagnosis. Furthermore, this study provides evidence that in MDS, hematopoietic stem cells accumulate defects that prevent normal hematopoiesis.	Univ Hosp, Dept Hematol Oncol, D-60596 Frankfurt, Germany; Cedars Sinai Res Inst, Div Hematol Oncol, Los Angeles, CA USA; Univ Calif Los Angeles, Sch Med, Dept Pathol, Los Angeles, CA 90024 USA; VASDHS, Res Serv, San Diego, CA USA; Univ Calif San Diego, Sch Med, Div Hematol Oncol, La Jolla, CA 92093 USA; Univ Calif San Diego, Sch Med, Ctr Canc, La Jolla, CA 92093 USA	Hofmann, WK (reprint author), Univ Hosp, Dept Hematol, Theodor Stern Kai 7, D-60596 Frankfurt, Germany.						Bennett JM, 2000, INT J HEMATOL, V72, P131; Bulyk ML, 2001, P NATL ACAD SCI USA, V98, P7158, DOI 10.1073/pnas.111163698; Bustin SA, 2000, J MOL ENDOCRINOL, V25, P169, DOI 10.1677/jme.0.0250169; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeRisi J, 2000, FEBS LETT, V470, P156, DOI 10.1016/S0014-5793(00)01294-1; De Vos J, 2001, BLOOD, V98, P771, DOI 10.1182/blood.V98.3.771; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Greenberg P, 1997, BLOOD, V89, P2079; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hofmann WK, 1999, EXP HEMATOL, V27, P395, DOI 10.1016/S0301-472X(98)00077-0; Hofmann WK, 2001, BLOOD, V98, P787, DOI 10.1182/blood.V98.3.787; Kalina U, 2000, EXP HEMATOL, V28, P1158, DOI 10.1016/S0301-472X(00)00527-0; Kaminski N, 2000, P NATL ACAD SCI USA, V97, P1778, DOI 10.1073/pnas.97.4.1778; Khan J, 1999, P NATL ACAD SCI USA, V96, P13264, DOI 10.1073/pnas.96.23.13264; Kitagawa M, 1997, LEUKEMIA, V11, P2049, DOI 10.1038/sj.leu.2400844; Kondratyev AD, 1996, CANCER RES, V56, P1498; Lee YT, 2001, BLOOD, V98, P1914, DOI 10.1182/blood.V98.6.1914; Miyazato A, 2001, BLOOD, V98, P422, DOI 10.1182/blood.V98.2.422; Neiman PE, 2001, P NATL ACAD SCI USA, V98, P6378, DOI 10.1073/pnas.111144898; Novitzky N, 2000, EXP HEMATOL, V28, P941, DOI 10.1016/S0301-472X(00)00489-6; Parker JE, 1998, BRIT J HAEMATOL, V101, P220; Parker JE, 2000, BLOOD, V96, P3932; Peters UR, 1999, CANCER RES, V59, P4233; Preisler HD, 2001, LEUKEMIA, V15, P1589, DOI 10.1038/sj.leu.2402211; Schmidt JV, 2000, GENE DEV, V14, P1997; Shetty V, 2000, BLOOD, V96, P1388; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; Wu MX, 1998, SCIENCE, V281, P998, DOI 10.1126/science.281.5379.998; Zhao RB, 2000, GENE DEV, V14, P981	31	130	137	AMER SOC HEMATOLOGY	WASHINGTON	1900 M STREET. NW SUITE 200, WASHINGTON, DC 20036 USA	0006-4971		BLOOD	Blood	NOV 15	2002	100	10					3553	3560		10.1182/blood.V100.10.3553		8	Hematology	Hematology	613YE	WOS:000179158500017	
J	Bartnikas, R				Bartnikas, R			Partial discharges - Their mechanism, detection and measurement	IEEE TRANSACTIONS ON DIELECTRICS AND ELECTRICAL INSULATION			English	Review							GAS-INSULATED SUBSTATIONS; MULTILAYER PERCEPTRON TECHNIQUE; FREQUENCY SPECTRUM ANALYSIS; COMPUTER-AIDED MEASUREMENT; GENERATOR STATOR WINDINGS; PD PATTERN-RECOGNITION; SHORT AIR GAPS; NEURAL-NETWORK; POWER TRANSFORMERS; DIELECTRIC LIQUIDS	Different partial discharge (PD) detection and measurement procedures suitable for use on cables, capacitors, transformers and rotating machines are examined and compared. Both narrow and wide bandwidth PD detectors are considered; particular attention is given in regard to their suitability to different types of electrical apparatus and cable specimens under test as well as their applicability to discharge site location and their capability to detect different forms of PD. A rather substantial portion of the discussion is devoted to the use of intelligent machines as applied to PD pattern recognition in terms of either PD pulse-height/discharge epoch (phase) distributions or discharge pulse shape attributes.	Inst Rech Hydro Quebec, Varennes, PQ J3X 1S1, Canada	Bartnikas, R (reprint author), Inst Rech Hydro Quebec, 1800 Montee Ste Julie, Varennes, PQ J3X 1S1, Canada.						Ahmed NH, 1998, IEEE T DIELECT EL IN, V5, P181, DOI 10.1109/94.671927; ALLEN DJ, 1973, PUBL 1, V94, P65; ANDERSON JG, 1956, AIEE T POWER APPARAT, V75, P1193; ASHWANDEN T, 1998, P CIGR PAR; AUDOLI A, 1991, 3 IEEE INT C PROP AP; AUDOLI A, 1992, 1992 IEEE INT S EL I, P359; AUDOLI A, 1990, 1990 IEEE INT S EL I, P379; AUSTIN J, 1976, IEEE T ELECTR INSUL, V11, P129, DOI 10.1109/TEI.1976.297920; BAGHURST AH, 1985, C EL INS DIEL PHEN O, P471; BAPT JC, 1975, 1975 S INT TECHN HAU, P276; BAPT JC, 1974, C EL INS DIEL PHEN N, P282; BARTNIKAS R, UNPUB MULTISTRESS AG; BARTNIKA.R, 1973, IEEE T ELECTR INSUL, VEI 8, P2, DOI 10.1109/TEI.1973.299235; BARTNIKA.R, 1968, IEEE T ELECTR INSUL, VEI 3, P91, DOI 10.1109/TEI.1968.299037; BARTNIKA.R, 1966, REV SCI INSTRUM, V37, P1245, DOI 10.1063/1.1720468; BARTNIKAS R, 1992, IEEE T PLASMA SCI, V20, P487, DOI 10.1109/27.163585; BARTNIKAS R, 1966, P CIGR PAR; BARTNIKA.R, 1965, IEEE T POWER AP SYST, VPA84, P770; BARTNIKAS R, 1999, POWER COMMUNICATION; BARTNIKAS R, 1994, MONOGRAPH, V2; Bartnikas R., 1969, IEEE Transactions on Instrumentation and Measurement, VIM-18, DOI 10.1109/TIM.1969.4313834; Bartnikas R., 1968, British Journal of Applied Physics (Journal of Physics D), V1; BARTNIKAS R, 1993, IEEE T ELECTR INSUL, V28, P956, DOI 10.1109/14.249369; BARTNIKAS R, 1963, IEEE T POWER APPAR S, V82, P366; BARTNIKA.R, 1971, IEEE T ELECTR INSUL, VEI 6, P63, DOI 10.1109/TEI.1971.299156; BARTNIKAS R, 1975, IEEE T POWER AP SYST, VPA94, P716, DOI 10.1109/T-PAS.1975.31899; BARTNIKAS R, 1987, STP ASTM, V926; BARTNIKAS R, 1983, IEEE T ELECTR INSUL, V18, P458, DOI 10.1109/TEI.1983.298686; BARTNIKAS R, 1983, STP ASTM, V783; BARTNIKA.R, 1972, IEEE T ELECTR INSUL, VEI 7, P3, DOI 10.1109/TEI.1972.299182; Bartnikas R., 1976, 1976 IEEE International Symposium on Electrical Insulation; BARTNIKAS R, 1987, IEEE T ELECTR INSUL, V22, P629, DOI 10.1109/TEI.1987.299011; BARTNIKAS R, 1979, STP ASTM, V669; BARTNIKAS R, 1962, THESIS MCGILL U MONT; BARTNIKAS R, 1995, IEEE T DIELECT EL IN, V2, P557, DOI 10.1109/94.407021; BARTNIKA.R, 1969, J APPL PHYS, V40, P1974, DOI 10.1063/1.1657880; BARTNIKAS R, 1992, IEEE T ELECTR INSUL, V27, P3, DOI 10.1109/14.123436; BARTNIKA.R, 1973, IEEE T INSTRUM MEAS, VIM22, P403, DOI 10.1109/TIM.1973.4314196; BARTNIKA.R, 1969, ARCH ELEKTROTECH, V52, P348, DOI 10.1007/BF01573780; BARTNIKAS R, 1990, IEEE T ELECTR INSUL, V25, P111, DOI 10.1109/14.45238; BEALE R, 1985, NEURAL COMPUTING INT; BENGSTSSON T, 1997, 10 INT S HV ENG MONT, V4, P115; BEYER M, 1982, IEEE T POWER APPARAT, V101, P3451; BHIMANI BV, 1961, AIEE T POWER APPARAT, V80, P148; BIDHENDI HN, 1997, P 10 INT S HIGH VOLT, P87; Blokhintsev I, 1999, IEEE T ENERGY CONVER, V14, P930, DOI 10.1109/60.815010; BOGGS SA, 1982, IEEE T POWER AP SYST, V101, P1935, DOI 10.1109/TPAS.1982.317482; BOGGS SA, 1981, IEEE T POWER AP SYST, V100, P3969, DOI 10.1109/TPAS.1981.316992; Borsi H, 2000, IEEE T DIELECT EL IN, V7, P21, DOI 10.1109/94.839337; BORSI H, 1992, IEEE T ELECTR INSUL, V27, P1118, DOI 10.1109/14.204862; BORSI H, 1993, IEEE T ELECTR INSUL, V28, P1007, DOI 10.1109/14.249374; BOYERS DG, 1982, APPL PHYS LETT, V41, P28, DOI 10.1063/1.93310; BOZZO R, 1996, 1996 IEEE INT S EL I, P389; BOZZO R, 1993, IEEE T ELECTR INSUL, V28, P1050, DOI 10.1109/14.249378; Brauer I, 2000, PHYS REV LETT, V84, P4104, DOI 10.1103/PhysRevLett.84.4104; BREAZEAL W, 1995, PHYS REV E, V52, P1503, DOI 10.1103/PhysRevE.52.1503; BROMLEY JC, 1982, DOBL C APR 20 BOST; BROWN RD, 1965, IEEE T POWER AP SYST, VPA84, P667; Buchalla H, 1995, PROCEEDINGS: ELECTRICAL ELECTRONICS INSULATION CONFERENCE AND ELECTRICAL MANUFACTURING & COIL WINDING CONFERENCE, P613, DOI 10.1109/EEIC.1995.482503; CACCIARI M, 1995, IEE P-SCI MEAS TECH, V142, P102, DOI 10.1049/ip-smt:19951634; Cacciari M, 1995, IEEE T DIELECT EL IN, V2, P1166, DOI 10.1109/94.484322; CACHIN C, 1995, IEEE T DIELECT EL IN, V2, P578, DOI 10.1109/94.407023; CAMPBELL SR, 1994, IEEE T ENERGY CONVER, V9, P281, DOI 10.1109/60.300147; Candela R, 2000, IEEE T DIELECT EL IN, V7, P87, DOI 10.1109/94.839345; Carminati E, 2001, IEEE T INSTRUM MEAS, V50, P1413, DOI 10.1109/19.963218; Carminati E, 2000, IEEE T DIELECT EL IN, V7, P440, DOI 10.1109/94.848934; CHURCH HF, 1972, ELECTRA, V21, P30; COLE HA, 1976, NUCL INSTRUMENTA NOV, P551; Contin A, 2000, IEEE T DIELECT EL IN, V7, P48, DOI 10.1109/94.839341; Contin A, 1998, IEEE T DIELECT EL IN, V5, P110, DOI 10.1109/94.660784; CONTIN A, 1993, IEEE T ELECTR INSUL, V28, P1032; CONTIN A, 1995, MATER ENG, V6, P345; COSTELLO DA, 1969, IEEE C REC 69 CNPWR, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox E., 1994, FUZZY SYSTEMS HDB; DAKIN TW, 1969, IEEE T POWER AP SYST, VPA88, P251, DOI 10.1109/TPAS.1969.292314; DAKIN TW, 1979, STP ASTM, V669; DAKIN TW, 1960, AIEE T, V79, P648; DAWES CL, 1926, AIEE T, V45, P141; DENSLEY RJ, 1994, IEEE T POWER DELIVER, V9, P559, DOI 10.1109/61.277729; DEVINS JC, 1984, IEEE T ELECTR INSUL, V19, P475, DOI 10.1109/TEI.1984.298770; DEVINS JC, 1962, C EL INS DIEL PHEN N, P97; Dubois D., 1980, FUZZY SETS SYSTEMS T; Duda R., 1973, PATTERN CLASSIFICATI; EAGER GS, 1967, IEEE T POWER AP SYST, VPA86, P10, DOI 10.1109/TPAS.1967.291773; EAGER GS, 1969, IEEE T POWER AP SYST, VPA88, P342, DOI 10.1109/TPAS.1969.292455; EICHHORN RM, 1983, STP ASTM, V783; EIGEN D, 1966, Patent No. 3466537; EMERY FT, 1981, IEEE T POWER AP SYST, V100, P4974, DOI 10.1109/TPAS.1981.316465; EMERY FT, 1980, IEEE T POWER AP SYST, V99, P2232, DOI 10.1109/TPAS.1980.319853; Ficker T, 2001, IEEE T DIELECT EL IN, V8, P220, DOI 10.1109/94.919935; Field F. H., 1957, ELECT IMPACT PHENOME; Forster E.O., 1994, MONOGRAPH ASTM, VIII; FORSTER EO, 1993, IEEE T ELECTR INSUL, V28, P941, DOI 10.1109/14.249367; FORSTER EO, 1990, J PHYS D, V23, P1606; FRUTH B, 1989, 6 INT S H V ENG NEW; FRUTH B, 1994, IEEE INT C PROP APPL, P578; FRUTH B, 1997, 4 VOLT C NOV 12 14 C; FRUTH B, 1990, P CIGR PAR; FRUTH B, 1992, IEEE T ELECTR INSUL, V27, P60, DOI 10.1109/14.123441; FRUTH BA, 1994, 1994 IEEE INT S EL I, P296; FRUTH BA, 1996, 1996 IEEE INT S EL I, P397; FUHR J, 1993, IEEE T ELECTR INSUL, V28, P1057, DOI 10.1109/14.249379; GAILHOFER C, 1974, ELECTRA PARIS; GALAND L, 1971, REV G N RALE LECTRIC, V80, P399; Gallant S. I., 1993, NEURAL NETWORK LEARN; GANGER B, 1967, BROWN BOVERI REV, P355; GARCIACOLON VR, 2002, 2002 IEEE INT S EL I, P57; GISH H, 1990, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.1990.115636; GOMEZGARCIA M, 1990, IEEE T ELECTR INSUL, V25, P688; GOMEZGARCIA M, 1987, IEEE T ELECTR INSUL, V22, P199; GOODING FH, 1957, AIEE T POWER APPARAT, V16, P999; FRUTH BA, 1995, IEE P-SCI MEAS TECH, V142, P22, DOI 10.1049/ip-smt:19951643; GROSS DW, 2002, 2002 IEEE INT S EL I, P570; GRUNEWALD P, 1994, P CIGR PAR; Gulski E, 2000, IEEE T DIELECT EL IN, V7, P95, DOI 10.1109/94.839346; GULSKI E, 1993, IEEE T ELECTR INSUL, V28, P969, DOI 10.1109/14.249370; GULSKI E, 1995, IEEE T DIELECT EL IN, V4, P630; GULSKI E, 1993, IEEE T ELECTR INSUL, V28, P984, DOI 10.1109/14.249372; GULSKI E, 1992, IEEE T ELECTR INSUL, V27, P82, DOI 10.1109/14.123443; GUPTA MM, 1988, FUZZY LOGIC KNOWLEDG; HAESSIG M, 2000, IEEE INT S EL INS AN; HAMPTON BF, 1992, CIGR GEN SESS PAR; HANTOUCHE C, 1993, IEEE T ELECTR INSUL, V28, P1025, DOI 10.1109/14.249376; HANTOUCHE C, 1992, IEEE INT S EL INS JU, P401; HAROLDSEN S, 1968, P CIGR PAR; HARROLD RT, 1979, IEEE T POWER AP SYST, V98, P444, DOI 10.1109/TPAS.1979.319380; HARROLD RT, 1973, IEEE T POWER AP SYST, VPA92, P187, DOI 10.1109/TPAS.1973.293612; HARROLD RT, 1971, IEEE T POWER AP SYST, VPA90, P2339, DOI 10.1109/TPAS.1971.293082; HARROLD RT, 1970, IEEE T POWER AP SYST, VPA89, P1584, DOI 10.1109/TPAS.1970.292805; HARROLD RT, 1970, IEEE T POWER AP SYST, VPA89, P1591, DOI 10.1109/TPAS.1970.292806; HARROLD RT, 1979, STP ASTM, V669; HENNINGSEN CG, 1996, IEEE TRANSM DISTR C; HENRIKSEN M, 1986, IEEE T ENERGY CONVER, V1, P161; HERBST I, 1993, CIGR S BERL; HIKITA M, 1990, IEEE T ELECTR INSUL, V25, P453, DOI 10.1109/14.55716; HOLBOLL JT, 1992, IEEE T S ELECTR INSU, P354; HOUGEN LR, 1960, NATURE, V188, P577, DOI 10.1038/188577a0; HOWELLS E, 1978, IEEE T POWER AP SYST, V97, P1538, DOI 10.1109/TPAS.1978.354646; HOZUMI N, 1992, IEEE T ELECTR INSUL, V27, P550, DOI 10.1109/14.142718; HUCKER T, 1995, IEEE T DIELECT EL IN, V2, P544, DOI 10.1109/94.407020; HUDON C, 1990, 1990 IEEE INT S EL I, P153; Hudon C, 1995, IEEE T DIELECT EL IN, V2, P1083, DOI 10.1109/94.484310; Hudon C., 2001, Proceedings: Electrical Insulation Conference and Electrical Manufacturing and Coil Winding Conference (Cat. No.01CH37264), DOI 10.1109/EEIC.2001.965753; HUDON C, 1991, CEIDP IEEE C REC 91, P237; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; BOGGS SA, 1992, IEEE T POWER DELIVER, V7, P499; JAMES RE, 1989, IEEE T ELECTR INSUL, V24, P657, DOI 10.1109/14.34201; JAMES RE, 1986, IEEE T ELECTR INSUL, V21, P629, DOI 10.1109/TEI.1986.348968; Johnson J.S., 1951, AIEE T POWER APPARAT, V70, P1998; Johnson J.S., 1951, AIEE T, V70, P1993; JOHNSON JS, 1951, AIEE T POWER APPARAT, V70, P749; JONES SL, 1990, IEEE INT S EL INS TO, P106, DOI 10.1109/ELINSL.1990.109719; JUDD MD, 1995, IEE P-SCI MEAS TECH, V142, P237, DOI 10.1049/ip-smt:19951699; KATSUTA G, 1992, IEEE T POWER DELIVER, V7, P1068, DOI 10.1109/61.141815; KELEN A, 1995, IEEE T DIELECT EL IN, V2, P529, DOI 10.1109/94.407018; KELEN A, 1995, IEEE T DIELECT EL IN, V2, P780, DOI 10.1109/94.469975; KELEN A, 1976, P CIGR PAR; KELLEY EF, 1989, IEEE T ELECTR INSUL, V24, P1109, DOI 10.1109/14.46345; KIM YJ, 2002, 2002 IEEE INT S EL I, P5; KIM YJ, 1992, IEEE T ELECTR INSUL, V27, P1026, DOI 10.1109/14.256478; KITAMURA Y, 1985, IEEE C ELECTR INSUL, P485; KNAPP CH, 1990, IEEE T POWER DELIVER, V5, P859, DOI 10.1109/61.53094; Kohonen T., 1988, SELF ORG ASS MEMORY; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KONIG D, 1972, P CIGR, V1, P74; Kranz HG, 2000, IEEE T DIELECT EL IN, V7, P12, DOI 10.1109/94.839336; KRANZ HG, 1992, IEEE T ELECTR INSUL, V27, P93, DOI 10.1109/14.123444; KRANZ HG, 1993, IEEE T ELECTR INSUL, V28, P1016, DOI 10.1109/14.249375; KRIVDA A, 1995, IEEE T DIELECT EL IN, V2, P796, DOI 10.1109/94.469976; KRIVDA A, 1995, IEEE T DIELECT EL IN, V2, P889, DOI 10.1109/94.469983; Kung S. Y., 1993, DIGITAL NEURAL NETWO; KURRER R, 1994, GASEOUS DIELECTRICS, V7, P557; Kurtz M., 1973, ONTARIO HYDRO RES Q, V25, P1; KURTZ M, 1979, IEEE T POWER AP SYST, V98, P1596, DOI 10.1109/TPAS.1979.319475; KURTZ M, 1978, 1978 IEEE INT S EL I, P73; KURTZ M, 1980, P CIGR PAR; Lalitha EM, 2000, IEEE T DIELECT EL IN, V7, P40, DOI 10.1109/94.839339; Lemke E., 1976, Elektrie, V30; LESAINT O, 1991, IEEE T ELECTR INSUL, V26, P941; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; Lloyd BA, 1999, IEEE T ENERGY CONVER, V14, P1131, DOI 10.1109/60.815038; LUNDGAARD LE, 1990, IEEE T POWER DELIVER, V5, P1751, DOI 10.1109/61.103670; LYLES JF, 1988, IEEE T ENERGY CONVER, V3, P824, DOI 10.1109/60.9358; Mandelbrot B. B., 1983, FRACTAL GEOMETRY NAT; MASHIKIAN MS, 1992, IEEE T ELECTR INSUL, V27, P37, DOI 10.1109/14.123439; MASHIKIAN MS, 1994, IEEE T POWER DELIVER, V9, P620, DOI 10.1109/61.296237; MASON JH, 1951, P I ELECTR ENG, V98, P44; MAYOUX C, 1977, IEEE T ELECTR INSUL, V12, P153, DOI 10.1109/TEI.1977.297969; MAYOUX C, 1973, J APPL PHYS, V44, P3940, DOI 10.1063/1.1662876; MAYOUX C, 1995, IEEE T DIELECT EL IN, V2, P641; MAYOUX CJ, 1976, IEEE T ELECTR INSUL, V11, P139, DOI 10.1109/TEI.1976.297921; MAZROUA AA, 1993, IEEE T ELECTR INSUL, V28, P1082, DOI 10.1109/14.249382; MAZROUA AA, 1995, IEEE T POWER DELIVER, V10, P92, DOI 10.1109/61.368411; MAZROUA AA, 1994, IEEE T DIELECT EL IN, V1, P1119, DOI 10.1109/94.368651; MAZZETTI C, 1992, IEEE T ELECTR INSUL, V27, P445, DOI 10.1109/14.142705; MCMAHON EJ, 1959, AIEE T COMMUNICATI 1, V78, P654; Meek J.M., 1953, ELECT BREAKDOWN GASE; MEGAHED IY, 1975, IEEE T ELECTR INSUL, VEI10, P69, DOI 10.1109/TEI.1975.297865; Meijer S, 1998, IEEE T DIELECT EL IN, V5, P830, DOI 10.1109/94.740764; MENDEL JM, 1995, P IEEE, V83, P245; MILLER R, 1979, IEEE T ELECTR INSUL, V12, P127; MING Y, 2002, 2002 IEEE INT S EL I, P9; MIRALAI SF, 2000, LOW TEMPERATURE PLAS, V1, P33; Miralai S.F, 2000, PLASMAS POLYM, V5, P63, DOI 10.1023/A:1009531831404; MONNETTE E, 1999, P 14 INT S PLASM CHE, V1, P991; Montanari GC, 2000, IEEE T DIELECT EL IN, V7, P30, DOI 10.1109/94.839338; MORHUIS PHF, 1995, P IEE SCI MEASUREMEN, V142, P62; Morin R, 2000, IEEE T ENERGY CONVER, V15, P149, DOI 10.1109/60.866992; MORIN R, 1991, IEEE TRANSM DISTR C; MORIN R, 1999, P IEEE TRANSM DISTR; MORSHUIS P, 1995, IEEE T DIELECT EL IN, V2, P744, DOI 10.1109/94.469971; MORSHUIS PHF, 1990, J PHYS D APPL PHYS, V23, P1562, DOI 10.1088/0022-3727/23/12/012; Nakanishi Y., 1993, Electrical Engineering in Japan, V113, DOI 10.1002/eej.4391130806; Narbut P., 1965, IEEE Transactions on Power Apparatus and Systems, VPAS-84; GUTFLEISCH F, 1995, IEEE T DIELECT EL IN, V2, P729, DOI 10.1109/94.469970; NIEMEYER L, 1995, IEEE T DIELECT EL IN, V2, P510, DOI 10.1109/94.407017; Nikonov V, 2001, IEEE T PLASMA SCI, V29, P866, DOI 10.1109/27.974972; Nikonov V, 2001, J PHYS D APPL PHYS, V34, P2979, DOI 10.1088/0022-3727/34/19/308; NOVAK JP, 1991, IEEE T PLASMA SCI, V19, P95, DOI 10.1109/27.106802; NOVAK JP, 1990, IEEE T PLASMA SCI, V18, P775, DOI 10.1109/27.62342; Novak JP, 2000, IEEE T DIELECT EL IN, V7, P146, DOI 10.1109/94.839353; NOVAK JP, 1987, J APPL PHYS, V62, P3605, DOI 10.1063/1.339263; NOVAK JP, 1988, J PHYS D APPL PHYS, V21, P896, DOI 10.1088/0022-3727/21/6/006; NOVAK JP, 1988, J APPL PHYS, V64, P1767, DOI 10.1063/1.341773; NOVAK JP, 1995, IEEE T DIELECT EL IN, V2, P724, DOI 10.1109/94.469969; OKAMOTO T, 1986, IEEE T ELECTR INSUL, V21, P1015, DOI 10.1109/TEI.1986.349017; OLIVER BM, 1954, P IRE I RADIO EN MTT, V2, P1686; ORCHARD RA, 1995, NRCERB1015; OSVATH P, 1995, IEEE T DIELECT EL IN, V2, P685, DOI 10.1109/94.407033; PALMER AJ, 1974, APPL PHYS LETT, V25, P138, DOI 10.1063/1.1655412; PEARSON JS, 1991, IEEE T ELECTR INSUL, V26, P469, DOI 10.1109/14.85119; Pompili M, 2002, IEEE T DIELECT EL IN, V9, P104, DOI 10.1109/94.983893; Pompili M, 2000, IEEE T DIELECT EL IN, V7, P113, DOI 10.1109/94.839348; POMPILI M, 1995, IEEE T DIELECT EL IN, V2, P602, DOI 10.1109/94.407025; Pompili M, 1998, IEEE T DIELECT EL IN, V5, P402, DOI 10.1109/94.689430; POVEY EH, 1979, STP ASTM, V669; PULTRUM E, 1995, P JICABLE, P662; QUINN GE, 1940, AIEE T, V59, P709; RADU I, 2002, P INT C HIGH PRESS L; Raether H., 1964, ELECT AVALANCHES BRE; Rayner E.H., 1912, Journal of the Institution of Electrical Engineers, V49; REYNOLDS EH, 1958, C EL INS DIEL PHEN N; ROBINSON DM, 1936, DIELECTRIC PHENOMENA; Robinson D.M., 1935, Journal of the Institution of Electrical Engineers, V77; ROTH A, 1927, HOCHSPANGSTECHNIK; ROWNTREE P, 1991, J PHYS CHEM-US, V95, P4902, DOI 10.1021/j100165a054; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salama MMA, 2002, IEEE T NEURAL NETWOR, V13, P446, DOI 10.1109/72.991430; Salama MMA, 2000, IEEE T DIELECT EL IN, V7, P118, DOI 10.1109/94.839349; SANCHE L, 1993, IEEE T ELECTR INSUL, V28, P789, DOI 10.1109/14.237742; SATISH L, 1995, IEEE T DIELECT EL IN, V2, P352, DOI 10.1109/94.395421; SCHERING H, 1924, ISOLIERSTOFFE ELEKTR; SEDDING HG, 1991, IEEE T ENERGY CONVER, V6, P700, DOI 10.1109/60.103644; Simpson PK, 1990, ARTIFICIAL NEURAL SY; SMITH LE, 1970, 37 ANN INT C DOBL CL; STARR WT, 1956, Patent No. 2750562; Steel Z, 1996, J GAMBL STUD, V12, P3, DOI DOI 10.1007/BF01533186; STEINER JP, 1992, IEEE T ELECTR INSUL, V27, P44, DOI 10.1109/14.123440; Stone G. C., 1995, IEEE Transactions on Dielectrics and Electrical Insulation, V2, DOI 10.1109/94.407027; Stone G, 2000, IEEE T DIELECT EL IN, V7, P6, DOI 10.1109/94.839335; STONE GC, 1992, IEEE T ELECTR INSUL, V27, P70, DOI 10.1109/14.123442; STONE GC, 1995, IEEE T DIELECT EL IN, V2, P567, DOI 10.1109/94.407022; STONGE H, 1978, EL938 EPRI; SUZUKI H, 1992, IEEE T ELECTR INSUL, V27, P543, DOI 10.1109/14.142717; Tangen K.O., 1964, Elektrotechnische Zeitschrift. Ausgabe A: Zentralblatt fur Elektrotechnik, V85; THEONG AT, 1968, P CIGR PAR; THOENG AT, 1973, C PUBL 1, V94; TIMPERLEY JE, 1989, PROCEEDINGS OF THE 19TH ELECTRICAL ELECTRONICS INSULATION CONFERENCE, P300, DOI 10.1109/EEIC.1989.208246; TIMPERLEY JE, 1983, IEEE T POWER AP SYST, V102, P693, DOI 10.1109/TPAS.1983.318030; TRAIN D, 1974, IEEE T POWER AP SYST, VPA93, P1909, DOI 10.1109/TPAS.1974.293843; TYKOCINER JT, 1933, U ILLINOIS B, V50; TYKOCINER JT, 1933, U ILLINOIS B, V49; VAILLANCOURT GH, 1985, IEEE T POWER AP SYST, V104, P900, DOI 10.1109/TPAS.1985.319091; van Breen HJ, 2002, IEEE T DIELECT EL IN, V9, P140, DOI 10.1109/94.983898; VANBRUNT RJ, 1993, IEEE T ELECTR INSUL, V28, P905, DOI 10.1109/14.249364; VANBRUNT RJ, 1991, IEEE T ELECTR INSUL, V26, P902, DOI 10.1109/14.99099; VONGLAHN P, 1995, IEEE T DIELECT EL IN, V2, P590, DOI 10.1109/94.407024; VORA JP, 1965, IEEE T POWER AP SYST, VPA84, P707; VOSS RE, 1985, SEALING PHENOMENA DI; WAGNER H, 1977, IEEE T ELECTR INSUL, V12, P395, DOI 10.1109/TEI.1977.297990; WARD BH, 1992, IEEE T POWER DELIVER, V7, P469; Watson PK, 1998, IEEE T DIELECT EL IN, V5, P344, DOI 10.1109/94.689423; WEEKS WL, 1982, IEEE T POWER AP SYST, V101, P2328, DOI 10.1109/TPAS.1982.317461; WERLE P, 2002, 2002 IEEE INT S EL I, P166; WERTHEIMER MR, NATO APPL SCI SERIES; Whitehead S., 1953, DIELECTRIC BREAKDOWN; WICHMANN A, 1987, CIGR S 05 87 VIENN; WILSON A, 1991, P IEE A, V138, P153; WOLTER KD, 1987, STP ASTM, V926; Zondervan JP, 2000, IEEE T DIELECT EL IN, V7, P59, DOI 10.1109/94.839342; *AEIC, 1993, AEIC CS795 SPEC CROS; *AEIC, 1996, AEIC CS695 SPEC ETHY; *AEIC, 1994, AEIC CS595 SPEC CROS; [Anonymous], 2000, 14342000 IEEE; [Anonymous], 2862000 IEEE; *ANSI, C6831976 ANSI; *ANSI, C6321987 ANSI; *ASTM, 2001, ASTM BOOK STAND, V10; *CIGR, 1971, ELECTRA PARIS, P13; *ICEA, 1980, ICEA PUBL; *IEC, 1996, IEC SPEC 60270; *IEC, 1987, IEC PUBL 1, V871; *IEC, 1967, IEC SPEC 70; *IEC, 1987, IEC PUBL 2, V871; *IEEE, C571241991 IEEE; *IEEE, 1992, C571131991 IEEE; *NEMA, 1071964R1971 NEMA	308	92	105	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1070-9878		IEEE T DIELECT EL IN	IEEE Trns. Dielectr. Electr. Insul.	OCT	2002	9	5					763	808		10.1109/TDEI.2002.1038663		46	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	609KB	WOS:000178901200023	
J	Wu, YQ; Ianakiev, K; Govindaraju, V				Wu, YQ; Ianakiev, K; Govindaraju, V			Improved k-nearest neighbor classification	PATTERN RECOGNITION			English	Article						k-nearest neighbor classification; pattern classification; classifier; template condensing; preprocessing		k-nearest neighbor (k-NN) classification is a well-known decision rule that is widely used in pattern classification. However, the traditional implementation of this method is computationally expensive. In this paper we develop two effective techniques, namely, template condensing and preprocessing, to significantly speed up k-NN classification while maintaining the level of accuracy. Our template condensing technique aims at "sparsifying" dense homogeneous clusters of prototypes of any single class. This is implemented by iteratively eliminating patterns which exhibit high attractive capacities. Our preprocessing technique filters a large portion of prototypes which are unlikely to match against the unknown pattern. This again accelerates the classification procedure considerably, especially in cases where the dimensionality of the feature space is high. One of our case studies shows that the incorporation of these two techniques to k-NN rule achieves a seven-fold speed-up without sacrificing accuracy. CD 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	SUNY Buffalo, Ctr Excellence Pattern Anal & Recognit, Buffalo, NY 14228 USA	Wu, YQ (reprint author), Univ Illinois, Comp & Syst Res Lab 139, 1308 W Main St, Urbana, IL 61801 USA.						BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DUDANI SA, 1991, DISTANCE WEIGHTED K, P92; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SRIKANTAN G, 1994, THESIS STATE U NEW Y; Srikantan G, 1996, PATTERN RECOGN, V29, P1147, DOI 10.1016/0031-3203(95)00146-8	14	25	27	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	OCT	2002	35	10					2311	2318		10.1016/S0031-3203(01)00132-7		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	583FR	WOS:000177396500024	
J	Gora, G; Wojna, A				Gora, G; Wojna, A			RIONA: A new classification system combining rule induction and instance-based learning	FUNDAMENTA INFORMATICAE			English	Article						machine learning; instance-based learning; rule induction; nearest neighbour method		The article describes a method combining two widely-used empirical approaches to learning from examples: rule induction and instance-based learning. In our algorithm (RIONA) decision is predicted not on the basis of the whole support set of all rules matching a test case. but the support set restricted to a neighbourhood of a test case. The size of the optimal neighbourhood is automatically induced during the learning phase. The empirical study shows the interesting fact that it is enough to consider a small neighbourhood to achieve classification accuracy comparable to an algorithm considering the whole learning set. The combination of k-NN and a rule-based algorithm results in a significant acceleration of the algorithm using all minimal rules. Moreover, the presented classifier has high accuracy for both kinds of domains: more suitable for k-NN classifiers and more suitable for rule based classifiers.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Gora, G (reprint author), Warsaw Univ, Inst Informat, Banacha 2, PL-02097 Warsaw, Poland.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAZAN JG, 2000, P 2 INT C ROUGH SETS, P106; Bazan JG, 1998, P 1 INT C ROUGH SETS, P521; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Bishop CM, 1996, NEURAL NETWORKS PATT; Blake CL, 1998, UCI REPOSITORY MACHI; Burr Ridge I, 1997, MACHINE LEARNING; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1996, MACH LEARN, V24, P141; Duda R., 1973, PATTERN CLASSIFICATI; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; GOLDING AR, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P22; GORA G, 2002, P 3 INT C ROUGH SETS; GORA G, 2002, P 13 EUR C MACH LEAR; Grzymala-Busse J. W., 1992, INTELLIGENT DECISION, P3; GRZYMALABUSSE JW, 1998, ROUGH SETS KNOWLEDGE, V1, P366; GRZYMALABUSSE JW, 1997, P 6 INT S INT INF SY, P149; LI J, 2001, 5 PAC AS C KNOWL DIS, P455; Li J, 2000, P 4 EUR C PRINC PRAC, P191; LI J, 2001, DEEPS NEW INSTANCE B; Maneewongvatana S., 2001, P INT C COMP SCI ICC, P842; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Nguyen H. S., 1995, P 2 JOINT ANN C INF, P34; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Skowron A., 1992, INTELLIGENT DECISION, P331; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; WETTSCHERECK D, 1994, THESIS OREGON STATE	31	27	28	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	AUG	2002	51	4					369	390				22	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	630EM	WOS:000180094600003	
J	Gyorfi, L; Schafer, D; Walk, H				Gyorfi, L; Schafer, D; Walk, H			Relative stability of global errors of nonparametric function estimators	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						nonparametric density estimation; nonparametric regression estimation; relative stability	NEIGHBOR PATTERN-CLASSIFICATION; HISTOGRAM DENSITY-ESTIMATION; ASYMPTOTIC NORMALITY; L1 CONVERGENCE; REGRESSION; EQUIVALENCE; CONSISTENCY; THEOREM; RATES	This paper presents relative stability properties of various nonparametric density estimators (histogram, kernel estimates) and of regression estimators (partitioning, kernel, and nearest neighbor estimates). In density estimation, let E(n) denote the L(1) error of an estimate calculated from n data, whereas in regression estimation, the L(2) error of the estimate is used. Sufficient conditions for E(n)/E{E(n)} --> 1 in probability are provided. If this limit holds, the asymptotic behavior of the random error E(n) can be characterized by its expectation E{E(n)}, and one may apply, for example, the established rate-of-convergence results for E{E(n)}.	Tech Univ Budapest, Dept Comp Sci & Informat Theory, H-1521 Budapest, Hungary; Univ Stuttgart, Fachbereich Math, D-70511 Stuttgart, Germany	Gyorfi, L (reprint author), Tech Univ Budapest, Dept Comp Sci & Informat Theory, H-1521 Budapest, Hungary.	gyorfi@szit.bme.hu; schaefdk@mathematik.uni-stuttgart.de; walk@mathematik.uni-stuttgart.de					ABOUJAOUDE S, 1977, THESIS U PARIS 6 PAR; ABOUJAOUDE S, 1976, ANN I H POINCARE B, V12, P213; Beirlant J, 1998, J STAT PLAN INFER, V71, P93, DOI 10.1016/S0378-3758(98)00008-1; BEIRLANT J, 1994, CAN J STAT, V22, P309, DOI 10.2307/3315594; Beirlant J, 1998, J NONPARAMETR STAT, V9, P197, DOI 10.1080/10485259808832742; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; DEVROYE L, 1989, J STAT PLAN INFER, V23, P71, DOI 10.1016/0378-3758(89)90040-2; DEVROYE L, 1983, P 4 PANN S MATH STAT, P67; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1988, PROBAB THEORY REL, V77, P521, DOI 10.1007/BF00959615; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; Devroye L.P., 1985, NONPARAMETRIC DENSIT; DEVROYE L, 1991, NATO ADV SCI I C-MAT, V335, P31; EFRON B, 1981, ANN STAT, V9, P586, DOI 10.1214/aos/1176345462; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, 2002, IN PRESS DISTRIBUTIO; GYORFI L, 1991, NATO ADV SCI I C-MAT, V335, P329; HALL P, 1984, J MULTIVARIATE ANAL, V14, P1, DOI 10.1016/0047-259X(84)90044-7; HOLSTROM L, 1992, J MULTIVARIATE ANAL, V40, P245; KRZYZAK A, 1986, IEEE T INFORM THEORY, V32, P668, DOI 10.1109/TIT.1986.1057226; LUGOSI G, 2002, PRINCIPLES NONPARAME, P5; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; NADARAYA EA, 1970, THEOR PROBAB APPL+, V15, P134, DOI 10.1137/1115015; Reiss R.-D., 1989, APPROXIMATE DISTRIBU; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STEELE JM, 1986, ANN STAT, V14, P753, DOI 10.1214/aos/1176349952; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; TUKEY JW, 1947, ANN MATH STAT, V18, P529, DOI 10.1214/aoms/1177730343; TUKEY JW, 1961, P 4 BERK S, P681; Watson G.S., 1964, SANKHYA A, V26, P359	34	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	AUG	2002	48	8					2230	2242		10.1109/TIT.2002.800491		13	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	576JJ	WOS:000177000400008	
J	Yager, RR				Yager, RR			Using fuzzy methods to model nearest neighbor rules	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						fuzzy methods; IOWA; nearest neighbor models	OPERATOR; FUSION	The basic principle used in the construction of nearest neighbor models is discussed. The induced OWA (IOWA) operators are shown to provide a useful formal structure for building nearest neighbor models. A methodology for learning IOWA operator nearest neighbor models is described. Various types of nearest neighbor rules are investigated including those based on a linguistic specification. The situation in which the value of interest lies in an ordinal set is also considered. It is shown that the weighted median provides a useful tool for constructing nearest neighbor rules in this case.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				Bezdek J.C, 1999, FUZZY MODELS ALGORIT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Duda R., 1973, PATTERN CLASSIFICATI; Filev D, 1998, FUZZY SET SYST, V94, P157, DOI 10.1016/S0165-0114(96)00254-0; FILEV D, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P468, DOI 10.1109/FUZZY.1994.343740; FUKUNAGA K, 1991, STAT PATTERN RECOGNI; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; MITCHELL H, 1997, P INT C FUZZ LOG APP, P39; Mitchell HB, 2000, INT J INTELL SYST, V15, P317, DOI 10.1002/(SICI)1098-111X(200004)15:4<317::AID-INT4>3.0.CO;2-J; Torra V., 1999, MATHWARE SOFT COMPUT, V6, P249; Yager R., 1987, FUZZY SETS APPL SELE; Yager R. R., 1997, ORDERED WEIGHTED AVE; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager RR, 1997, INT J GEN SYST, V26, P239, DOI 10.1080/03081079708945181; Yager R.R., 1999, COMPUTING WORDS INFO, P50; Yager RR, 1997, ORDERED WEIGHTED AVERAGING OPERATORS, P41; Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789; Yager RR, 1998, INT J APPROX REASON, V18, P35, DOI 10.1016/S0888-613X(97)10003-2; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; Zadeh L. A., 1999, COMPUTING WORDS INFO, V1; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904	22	12	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	AUG	2002	32	4					512	525		10.1109/TSMCB.2002.1018770		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	574VA	WOS:000176909200011	
J	Lazzerini, B; Marcelloni, F				Lazzerini, B; Marcelloni, F			Classification based on neural similarity	ELECTRONICS LETTERS			English	Article								Following the approach of extracting similarity metrics directly from labelled data, a standard back-propagation neural network is adopted to determine a degree of similarity between pairs of input points. The similarity computed by the network is then used to guide a k-NN classifier, which associates a label with an unknown pattern based on the k most similar points. Experimental results on both synthetic and real-world data sets show that the similarity-based k-NN rule outperforms the Euclidean distance-based k-NN rule.	Univ Pisa, Dipartimento Ingn Informaz, I-56122 Pisa, Italy	Lazzerini, B (reprint author), Univ Pisa, Dipartimento Ingn Informaz, Via Diotisalvi 2, I-56122 Pisa, Italy.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Jain A., 1999, ACM COMPUT SURV, V31, P265; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; PEDRYCZ W, 2001, P 2 INT WORKSH SOFT, P60	6	2	2	IEE-INST ELEC ENG	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194		ELECTRON LETT	Electron. Lett.	JUL 18	2002	38	15					810	812		10.1049/el:20020549		3	Engineering, Electrical & Electronic	Engineering	582FM	WOS:000177339100031	
J	Nugroho, AS; Kuroyanagi, S; Iwata, A				Nugroho, AS; Kuroyanagi, S; Iwata, A			A solution for imbalanced training sets problem by CombNET-II and its application on fog forecasting	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						neural network; CombNET-II; self-growing algorithm; imbalanced training sets problem; fog forecasting		Studies on artificial neural network have been conducted for a long time, and its contribution has been shown in many fields. However, the application of neural networks in the real world domain is still a challenge, since nature does not always provide the required satisfactory conditions. One example is the class size unbalanced condition in which one class is heavily under-represented compared to another class. This condition is often found in the real world domain and presents several difficulties for algorithms that assume the balanced condition of the classes. In this paper, we propose a method for solving problems posed by imbalanced training sets by applying the modified large-scale neural network "CombNET-II." CombNET-II consists of two types of neural networks. The first type is a one-layer vector quantization neural network to turn the problem into a more balanced condition. The second type consists of several modules of three-layered multilayer perceptron trained by backpropagation for finer classification. CombNET-II combines the two types of neural networks to solve the problem effectively within a reasonable time. The performance is then evaluated by turning the model into a practical application for a fog forecasting problem. Fog forecasting is an imbalanced training sets problem, since the probability of fog appearance in the observation location is very low. Fog events should be predicted every 30 minutes based on the observation of meteorological conditions. Our experiments showed that CombNET-II could achieve a high prediction rate compared to the k-nearest neighbor classifier and the three-layered multilayer perceptron trained with BP. Part of this research was presented in the 1999 Fog Forecasting Contest sponsored by Neurocomputing Technical Croup of IEICE, Japan; and CombNET-II achieved the highest accuracy among the participants.	Nagoya Inst Technol, Dept Elect & Comp Engn, Nagoya, Aichi 4668555, Japan	Nugroho, AS (reprint author), Nagoya Inst Technol, Dept Elect & Comp Engn, Nagoya, Aichi 4668555, Japan.						ANTO SN, 1999, P 1999 IEICE GEN C Y, P323; Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANTAS AS, 2000, P IJCNN2000, V4, P435, DOI 308154337,12,1; Duda R., 1973, PATTERN CLASSIFICATI; Funkunaga K., 1990, INTRO STAT PATTERN R; HOTTA K, 1992, IEICE T D, V75, P545; Japkowicz N., 2000, P 2000 INT C ART INT, V1, P111; JAPKOWICZ N, 2000, INT WORKSH LEARN IMB; KAWAJIRI H, 1998, P 4 EANN GIBR JUN, P40; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Kubat M., 1997, P 14 INT C MACH LEAR, P179; 1999 FOG FORECASTING	13	7	9	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	JUL	2002	E85D	7					1165	1174				10	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	581YU	WOS:000177323400011	
J	Bloch, DA; Olshen, RA; Walker, MG				Bloch, DA; Olshen, RA; Walker, MG			Risk estimation for classification trees	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						.632 bootstrap; empirical Bayes; Breiman's method	CONSISTENT NONPARAMETRIC REGRESSION; LEARNING-TESTING METHODS; FOLD CROSS-VALIDATION; ALGORITHM; CART	This article is a study of techniques for bias reuction of estimates of risk both globally and within terminal nodes of CART R classification trees. In Section 5.4 of Classification and Regression Trees, Leo Breiman presented an estimator that has two free parameters. An empirical Bayes method was put forth for estimating them. Here we explain why the estimator should be successful in the many examples for which it is. We give numerical evidence from simulations in the two-class case with attention to ordinary resubstitution and seven other methods of estimation. There are 14 sampling distributions, all but one simulated and the remaining concerning E. coli promoter regions. We report on varying minimum node sizes of the trees prior probabilities and misclassification costs; and, when relevant, the numbers of bootstraps or cross-validations. A variation of Breiman's method in which repeated cross-validation is employed to estimate global rates of misclassification was the most accurate from among the eight methods. Exceptions are cases for which the Bayes risk of the Bayes rule is small, For them, either a local bootstrap.632 estimate or Breiman's method modified to use a bootstrap estimate of the global misclassification rate is most accurate.	Stanford Univ, Sch Med, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Walker Biosci, Sunnyvale, CA 94087 USA	Bloch, DA (reprint author), Stanford Univ, Sch Med, Dept Hlth Res & Policy, Stanford, CA 94305 USA.						Anderson T. W., 1966, MULTIVARIATE ANAL, P5; Bishop Y., 1975, DISCRETE MULTIVARIAT; BLOCH DA, 1989, J AM STAT ASSOC, V84, P897, DOI 10.2307/2290064; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRENT RP, 1971, COMPUT J, V14, P422, DOI 10.1093/comjnl/14.4.422; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; BURMAN P, 1990, SANKHYA SER A, V52, P314; Clark L. A., 1992, STAT MODELS S, P377; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; Dannegger F, 2000, STAT MED, V19, P475, DOI 10.1002/(SICI)1097-0258(20000229)19:4<475::AID-SIM351>3.0.CO;2-V; Donoho DL, 1997, ANN STAT, V25, P1870, DOI 10.1214/aos/1069362377; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; EFRON B, 1982, SIAM NSF CBMS MONOGR, V38; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GOLDMAN L, 1988, NEW ENGL J MED, V318, P798; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P147, DOI 10.1016/0047-259X(84)90022-8; HARLEY CB, 1987, NUCLEIC ACIDS RES, V15, P2343, DOI 10.1093/nar/15.5.2343; Hastie T., 1990, SHRINKING TREES; KARLIN S, 1958, ANN MATH STAT, V29, P406, DOI 10.1214/aoms/1177706620; KUELBS J, 1980, ANN PROBAB, V8, P405, DOI 10.1214/aop/1176994716; Lehmann E.L., 1983, THEORY POINT ESTIMAT; Lugosi G, 1996, ANN STAT, V24, P687; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WALKER MG, 1992, THESIS STANFORD U ST; ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027	30	6	6	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600		J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2002	11	2					263	288		10.1198/106186002760180509		26	Statistics & Probability	Mathematics	561RX	WOS:000176157400001	
J	Barkol, O; Rabani, Y				Barkol, O; Rabani, Y			Tighter lower bounds for nearest neighbor search and related problems in the cell probe model	JOURNAL OF COMPUTER AND SYSTEM SCIENCES			English	Article; Proceedings Paper	32nd Annual ACM Symposium on Theory of Computing	JUN 21-23, 2000	PORTLAND, OREGON				ALGORITHM	We prove new lower bounds for nearest neighbor search in the Hamming cube. Our lower bounds are for randomized, two-sided error, algorithms in Yao's cell probe model. Our bounds are in the form of a tradeoff among the number of cells, the size of a cell, and the search time. For example, suppose we are searching among n points in the d dimensional cube, we use poly(n, d) cells, each containing poly(d, log n) bits. We get a lower bound of Omega(d/log n) on the search time, a significant improvement over the recent bound of Omega(log d) of Borodin et al. This should be contrasted with the upper bound of D(log log d) for approximate search (and O(1) for a decision version of the problem; our lower bounds hold in that case). By previous results, the bounds for the cube imply similar bounds for nearest neighbor search in high dimensional Euclidean space, and for other geometric problems. (C) 2002 Elsevier Science (USA).	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Barkol, O (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; Ajtai M., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301424; AJTAI M, 1999, NONLINEAR TIME LOWER; Alon N., 1992, PROBABILISTIC METHOD; ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Beame P., 1998, Proceedings 39th Annual Symposium on Foundations of Computer Science (Cat. No.98CB36280), DOI 10.1109/SFCS.1998.743453; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Chakrabarti A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301325; CLARKSON A, 1994, P 10 SCG, P160; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Berg M., 1997, COMPUTATIONAL GEOMET; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Duda R., 1973, PATTERN CLASSIFICATI; FAGIN R, 1998, P PODS; Flickner M., 1995, IEEE COMPUT, V28, P23; Gersho A, 1991, VECTOR QUANTIZATION; HASTIE T, 1995, 1 INT C KNOWL DISC D; INDYK P, IN PRESS SODA 2000; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; MATOUSEK J, 1991, PROCEEDINGS - 32ND ANNUAL SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, P207, DOI 10.1109/SFCS.1991.185370; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Miltersen P. B., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225093; PENTLAND A, 1994, P SPIE C STOR RETR I, V2; Salton G., 1989, AUTOMATIC TEXT PROCE; SMEULDERS AWM, 1996, P 1 WORKSH IM DAT MU; Yao A.C., 1985, P 17 ANN ACM S THEOR, P163, DOI 10.1145/22145.22163; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274	36	7	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0022-0000		J COMPUT SYST SCI	J. Comput. Syst. Sci.	JUN	2002	64	4					873	896		10.1006/jcss.2002.1831		24	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	571ME	WOS:000176720500007	
J	Pekalska, E; Duin, RPW				Pekalska, E; Duin, RPW			Dissimilarity representations allow for building good classifiers	PATTERN RECOGNITION LETTERS			English	Article						similarity representations; normal density-based classifiers		In this paper, a classification task on dissimilarity representations is considered. A traditional way to discriminate between objects represented by dissimilarities is the nearest neighbor method. It suffers, however, from a number of limitations, i.e., high computational complexity, a potential loss of accuracy when a small set of prototypes is used and sensitivity to noise. To overcome these shortcomings, we propose to use a normal density-based classifier constructed on the same representation. We show that such a classifier, based on a weighted combination of dissimilarities, can significantly improve the nearest neighbor rule with respect to the recognition accuracy and computational effort. (C) 2002 Elsevier Science B.V. All rights reserved.	Delft Univ Technol, Appl Phys Lab, Pattern Recognit Grp, NL-2628 CJ Delft, Netherlands	Pekalska, E (reprint author), Delft Univ Technol, Appl Phys Lab, Pattern Recognit Grp, Lorentzweg 1, NL-2628 CJ Delft, Netherlands.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Dubuisson M. P., 1994, P 12 INT C PATT REC, V1, P566, DOI DOI 10.1109/ICPR.1994.576361; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R. P. W., 2000, P 15 INT C PATT REC, V2, P1, DOI 10.1109/ICPR.2000.906006; Duin RPW, 1999, PATTERN RECOGN LETT, V20, P1175, DOI 10.1016/S0167-8655(99)00085-9; EDELMAN Shimon, 1999, REPRESENTATION RECOG; Fukunaga K., 1990, INTRO STAT PATTERN R; Goldstone R., 1999, MIT ENCY COGNITIVE S, P763; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOUTEPEN J, 1994, THESIS DELFT U TECHN, P1; HOUTEPEN J, 1994, 2 AALB S CHROM AN SE; HOUTEPEN J, 1994, 2 PLEN WORKSH ECA AM; PEKALSKA E, 2000, P 15 INT C PATT REC, V2, P12, DOI 10.1109/ICPR.2000.906008; Pekalska E, 2001, ELECTRON LETT, V37, P159, DOI 10.1049/el:20010121; Ripley B. D., 1996, PATTERN RECOGNITION; Vapnik V.N., 1998, STAT LEARNING THEORY; WHARTON CM, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P588; Wilson C., 1992, HANDPRINTED CHARACTE	20	78	80	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2002	23	8					943	956		10.1016/S0167-8655(02)00024-7		14	Computer Science, Artificial Intelligence	Computer Science	540AU	WOS:000174906500005	
J	Billsus, D; Clifford, AB; Evans, G; Gladish, B; Pazzani, M				Billsus, D; Clifford, AB; Evans, G; Gladish, B; Pazzani, M			Adaptive interfaces for ubiquitous web access	COMMUNICATIONS OF THE ACM			English	Article							USER	The invention of the movable type printing press launched the information age by making the mass distribution of information both feasible and economical. Newspapers, magazines, shopping catalogs, restaurant guides, and classified advertisements can trace their origins to the printing process. Five and a half centuries of technological progress in communications networks, protocols, computers, and user interface design led to the Web, online publishing, and e-commerce. Consumers and businesses have access to-vast stores of information. All this information, however, used to be accessible only while users were tethered to a computer at home or in an office. Wireless data and voice access to-this vast store allows unprecedented access to information from any location at any time.	AdaptiveInfo, Irvine, CA USA	Billsus, D (reprint author), AdaptiveInfo, Irvine, CA USA.						Billsus D, 1998, P 15 INT C MACH LEAR, P46; Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781; Buchanan G., 2001, P 10 INT C WORLD WID, P673, DOI 10.1145/371920.372181; CHEVERST K, 2002, COMMUN ACM, V45; CLAYPOOL M, 2000, P INT C INT US INT S, P33; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; KOBSA A, 2002, COMMUN ACM, V45; MAES P, 1994, COMMUN ACM, V37; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Yang Y., 1999, J INFORMATION RETRIE, V1, P67	12	66	67	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036 USA	0001-0782		COMMUN ACM	Commun. ACM	MAY	2002	45	5					34	38				5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	544NC	WOS:000175165600014	
J	Stewart, B				Stewart, B			Predicting project delivery rates using the Naive-Bayes classifier	JOURNAL OF SOFTWARE MAINTENANCE AND EVOLUTION-RESEARCH AND PRACTICE			English	Article						software effort estimation; Bayesian networks; machine learning; model trees; neural networks	SOFTWARE	The importance of accurate estimation of software development effort is well recognized in software engineering. In recent years, machine learning approaches have been studied as possible alternatives to more traditional software cost estimation methods. The objective of this paper is to investigate the utility of the machine learning algorithm known as the Naive-Bayes classifier for estimating software project effort. We present empirical experiments with the Benchmark 6 data set from the International Software Benchmarking Standards Group to estimate project delivery rates and compare the performance of the Naive-Bayes approach to two other machine learning methods model trees and neural networks. A project delivery rate is defined as the number of effort hours per function point. The approach described is general and can be used to analyse not only software development data but also data on software maintenance and other types of software engineering. The paper demonstrates that the Naive-Bayes classifier has a potential to be used as an alternative machine learning tool for software development effort estimation. Copyright (C) 2002 John Wiley Sons, Ltd.	Univ Western Sydney, Sch Comp & Informat Technol, Penrith S DC, NSW 1797, Australia	Stewart, B (reprint author), Univ Western Sydney, Sch Comp & Informat Technol, Campbelltown Campus,Locked Bag 1797, Penrith S DC, NSW 1797, Australia.						ALBRECHT AJ, 1983, IEEE T SOFTWARE ENG, V9, P639, DOI 10.1109/TSE.1983.235271; Bishop C. M., 1995, NEURAL NETWORKS PATT; Boehm B.W., 1981, SOFTWARE ENG EC; Breiman L, 1984, CLASSIFICATION REGRE; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; Briand L. C., 1999, Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002), DOI 10.1109/ICSE.1999.841022; Castillo E., 1997, EXPERT SYSTEMS PROBA; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowell RG, 1999, PROBABILISTIC NETWOR; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Goldberg D. E, 1989, GENETIC ALGORITHMS S; JENSEN FV, INTRO BAYESIAN NETWO; JORGENSEN M, 1995, IEEE T SOFTWARE ENG, V21, P674, DOI 10.1109/32.403791; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MOTODA H, 1998, FEATURE EXTRACTION C; Neapolitan R. E., 1990, PROBABILISTIC REASON; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Pfleeger S. L, 1998, SOFTWARE ENG THEORY; PUTNAM LH, 1978, IEEE T SOFTWARE ENG, V4, P345, DOI 10.1109/TSE.1978.231521; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shepperd M, 1997, IEEE T SOFTWARE ENG, V23, P736, DOI 10.1109/32.637387; Shin M, 2000, IEEE T SOFTWARE ENG, V26, P567; SRINIVASAN K, 1995, IEEE T SOFTWARE ENG, V21, P126, DOI 10.1109/32.345828; Witten I. H., 2000, DATA MINING PRACTICA	26	9	10	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX PO19 1UD, ENGLAND	1532-060X		J SOFTW MAINT EVOL-R	J. Softw. Maint. Evol.-Res. Pract.	MAY-JUN	2002	14	3					161	179		10.1002/smr.250		19	Computer Science, Software Engineering	Computer Science	568UM	WOS:000176563100002	
J	Liu, H; Motoda, H				Liu, H; Motoda, H			On issues of instance selection	DATA MINING AND KNOWLEDGE DISCOVERY			English	Editorial Material							ALGORITHMS		Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA; Osaka Univ, Inst Sci & Ind Res, Osaka, Japan	Liu, H (reprint author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.						Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAEZAYATES R, 1999, MORDEN INFORMATION R; BLOEDORN E, 1998, FEATURE EXTRACTION C, P51; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; BREIMAN L, 1984, STAT SIGNAL PROCESSI, P191; Breiman L, 1984, CLASSIFICATION REGRE; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Burr Ridge I, 1997, MACHINE LEARNING; CHANG C, 1974, IEEE T COMPUTERS, V23; Chaudhuri S., 1998, P ACM SIGMOD INT C M, P436, DOI 10.1145/276304.276343; Cochran W. G, 1977, SAMPLING TECHNIQUES; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devlin B., 1997, DATA WAREHOUSE ARCHI; Domingo C, 2002, DATA MIN KNOWL DISC, V6, P131, DOI 10.1023/A:1014091514039; DUMOUCHEL W, 1999, P 5 ACM C KNOWL DISC; Everitt B., 1974, CLUSTER ANAL; Fayyad U, 1996, ADV KNOWLEDGE DISCOV, P495; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; FREUND Y, 1994, AAAI FALL S SERIES, P85; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; HARRISJONES C, 1997, AMSCATWP97118; Hussain F., 1999, TRC699 NAT U SING SC; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; KIVINEN J, 1994, SIGMOD PODS 94, P77; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Langley P., 1996, ELEMENTS MACHINE LEA; Lewis DD, 1994, P 17 ANN INT ACM SIG, P3; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Liu H., 1998, FEATURE SELECTION KN; Liu H., 1998, FEATURE EXTRACTION C; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; McCallum A., 1998, P 15 INT C MACH LEAR, P350; PIATETSKYSHAPIR.G, 1984, ACM SIGMOD C, P256; Provost F, 1999, DATA MIN KNOWL DISC, V3, P131, DOI 10.1023/A:1009876119989; PROVOST F, 1999, P 5 ACM C KNOWL DISC; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; REINARTZ T, 1999, LNAI, V1623; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Scholkopf B., 1995, P 1 INT C KNOWL DISC, P252; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; SMITH P, 1998, INTO STAT; Syed N. A., 1999, P 5 ACM SIGKDD INT C, P317, DOI 10.1145/312129.312267; SZALAY A, 1999, SCI AM; Utogoff P, 1989, MACH LEARN, V4, P161; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N., 1995, NATURE STAT LEARNING; Weiss S. M., 1998, PREDICTIVE DATA MINI	57	55	58	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					115	130		10.1023/A:1014056429969		16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600001	
J	Brighton, H; Mellish, C				Brighton, H; Mellish, C			Advances in instance selection for instance-based learning algorithms	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article						instance-based learning; instance selection; forgetting; pruning	NEAREST-NEIGHBOR RULE; CLASSIFICATION	The basic nearest neighbour classifier suffers from the indiscriminate storage of all presented training instances. With a large database of instances classification response time can be slow. When noisy instances are present classification accuracy can suffer. Drawing on the large body of relevant work carried out in the past 30 years, we review the principle approaches to solving these problems. By deleting instances, both problems can be alleviated, but the criterion used is typically assumed to be all encompassing and effective over many domains. We argue against this position and introduce an algorithm that rivals the most successful existing algorithm. When evaluated on 30 different problems, neither algorithm consistently outperforms the other: consistency is very hard. To achieve the best results, we need to develop mechanisms that provide insights into the structure of class definitions. We discuss the possibility of these mechanisms and propose some initial measures that could be useful for the data miner.	Univ Edinburgh, Dept Theoret & Appl Linguist, Language Evolut & Computat Res Unit, Edinburgh EH8 9LL, Midlothian, Scotland; Univ Edinburgh, Dept Artificial Intelligence, Edinburgh EH1 1HN, Midlothian, Scotland	Brighton, H (reprint author), Univ Edinburgh, Dept Theoret & Appl Linguist, Language Evolut & Computat Res Unit, Edinburgh EH8 9LL, Midlothian, Scotland.	henryb@ling.ed.ac.uk; chrism@dai.ed.ac.uk	Brighton, Henry/A-3504-2011				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; BRIGHTON H, 1996, THESIS U EDINBURGH S; BRIGHTON H, 1997, THESIS U EDINBURGH S; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; BRIGHTON H, 1997, UNPUB GEOMETRIC CRIT; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; Cameron-Jones R. M., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; DAELEMANS W, 1997, P 9 EUR C MACH LEARN, P29; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Holte RC, 1989, P 11 INT JOINT C ART, P813; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; Kolodner J., 1993, CASE BASED REASONING; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Salganicoff M., 1993, P 10 INT C MACH LEAR, P276; SALZBERG S, 1991, MACH LEARN, V6, P227; Scott P. D., 1988, P 5 INT C MACH LEARN, P459; Sebban M, 1999, LECT NOTES ARTIF INT, V1704, P184; SMYTH B, 1995, INT JOINT C ART INT, V1, P377; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VANDENBOSCH A, 1998, P NEMLAP3 CONLL98, P195, DOI 10.3115/1603899.1603933; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 1997, MACH LEARN P 14 INT; Zhang J., 1992, P 9 INT MACH LEARN C, P470	32	144	150	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	APR	2002	6	2					153	172		10.1023/A:1014043630878		20	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	518TU	WOS:000173684600003	
J	Ranilla, J; Bahamonde, A				Ranilla, J; Bahamonde, A			FAN: Finding Accurate iNductions	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES			English	Article						machine learning; classification rules; minimum distance; induction from examples	LEARNING ALGORITHMS; NEAREST-NEIGHBOR	In this paper we present a machine-learning algorithm that computes a small set of accurate and interpretable rules. The decisions of these rules can be straight-forwardly explained as the conclusions drawn by a case-based reasoner. Our system is named FAN, an acronym for finding accurate inductions. It starts from a collection of training examples and produces propositional rules able to classify unseen cases following a minimum-distance criterion in their evaluation procedure. In this way, we combine the advantages of instance-based algorithms and the conciseness of rule (or decision-tree) inducers, The algorithm followed by FAN can be seen as the result of successive steps of pruning heuristics. The main tool employed is that of the impurity level, a measure of the classification quality of a rule, inspired by a similar measure used in IB3. Finally, a number of experiments were conducted with standard benchmark datasets of the UCI repository to test the performance of our system, successfully comparing FAN with a wide collection of machine-learning algorithms. (C) 2002 Elsevier Science Ltd. All rights reserved.	Univ Oviedo, Ctr Artificial Intelligence, Gijon 33271, Spain	Ranilla, J (reprint author), Univ Oviedo, Ctr Artificial Intelligence, Campus Viesques, Gijon 33271, Spain.		Ranilla, Jose/E-8012-2013	Ranilla, Jose/0000-0003-2941-3741			Aha D.W., 1990, THESIS U CALIFORNIA; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAHAMONDE A, 1994, INT J COMPUT MATH, V54, P127, DOI 10.1080/00207169408804346; Blake CL, 1998, UCI REPOSITORY MACHI; BOTANA F, 1995, INT J HUM-COMPUT ST, V42, P137, DOI 10.1006/ijhc.1995.1006; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; del Coz JJ, 1999, LECT NOTES COMPUT SC, V1606, P527; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P, 1996, MACH LEARN, V24, P141; Furnkranz J, 1997, MACH LEARN, V27, P139, DOI 10.1023/A:1007329424533; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohonen T, 1995, SELF ORGANIZING MAPS; Luaces O, 1999, LECT NOTES COMPUT SC, V1606, P497; LUACES O, 1998, LECT NOTES ARTIF INT, V1416, P448; MCCARTHY J, 1980, ARTIF INTELL, V13, P27, DOI 10.1016/0004-3702(80)90011-9; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Pratt WK, 1991, DIGITAL IMAGE PROCES; Quinlan J., 1983, MACHINE LEARNING ART, V1, P463; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RANILLA J, 1995, P 6 C AS ESP INT ART, P225; RANILLA J, 1998, REV IBEROAMERICANA I, V4, P4; Rendell L., 1986, Machine Learning, V1, DOI 10.1007/BF00114117; Salzberg S.L., 1990, LEARNING NESTED GEN; SPIEGEL MR, 1970, ESTADISTICA; Thrun S.B., 1991, CSCMU91197; Ventura D., 1995, P 10 INT S COMP INF, P443; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	37	12	12	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1071-5819		INT J HUM-COMPUT ST	Int. J. Hum.-Comput. Stud.	APR	2002	56	4					445	474		10.1006/ijhc.1002		30	Computer Science, Cybernetics; Ergonomics; Psychology, Multidisciplinary	Computer Science; Engineering; Psychology	564VR	WOS:000176334700004	
J	Cha, GH; Zhu, XM; Petkovic, D; Chung, CW				Cha, GH; Zhu, XM; Petkovic, D; Chung, CW			An efficient indexing method for nearest neighbor searches in high-dimensional image databases	IEEE TRANSACTIONS ON MULTIMEDIA			English	Article						dimensionality curse; image database; indexing method; nearest neighbor (NN) search	ALGORITHM	Nearest neighbor (NN) search is emerging as an important search paradigm in a variety of applications in which objects are represented as vectors of d numeric features. However, despite decades of efforts, except for the filtering approach such as the VA-file [31], the current solutions to find exact kNNs are far from satisfactory for large d. The filtering approach represents vectors as compact approximations and by first scanning these smaller approximations, only a small fraction of the real vectors are visited. In this paper, we introduce the local polar coordinate file (LPC-file) using the filtering approach for nearest-neighbor searches in high-dimensional image databases. The basic idea is to partition the vector space into rectangular cells and then to approximate vectors by polar coordinates on the partitioned local cells. The LPC information significantly enhances the discriminatory power of the approximation. To demonstrate the effectiveness of the LPC-file, we conducted extensive experiments and compared the performance with the VA-file and the sequential scan by using synthetic and real data sets. The experimental results demonstrate that the LPC-file outperforms both of the VA-file and the sequential scan in total elapsed time and in the number of disk accesses and that the LPC-file is robust in both "good" distributions (such as random) and "bad" distributions (such as skewed and clustered).	Tonymyong Univ Informat Technol, Dept Multimedia Engn, Pusan 608711, South Korea; eLance com, Sunnyvale, CA 94086 USA; Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea; IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	Cha, GH (reprint author), Tonymyong Univ Informat Technol, Dept Multimedia Engn, Pusan 608711, South Korea.	ghcha@tmic.tit.ac.kr; xzhu@elance.com; dragutin@vmware.com; chungcw@islab.kaist.ac.kr	Chung, Chin-Wan/C-2029-2011				Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; ATKINSON MD, 1986, COMMUN ACM, V29, P996, DOI 10.1145/6617.6621; BECHTOLD S, 1998, P ACM SIGMOD INT C M, P142; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Cha GH, 1998, MULTIMED TOOLS APPL, V6, P263, DOI 10.1023/A:1009608331551; Comer D., 1979, ACM COMPUT SURV, V11, P121, DOI 10.1145/356770.356776; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Flickner M., 1995, IEEE COMPUT, V28, P23; HASTIE T, 1995, P 1 INT C KNOWL DISC, P142; Henrich A, 1998, PROC INT CONF DATA, P362, DOI 10.1109/ICDE.1998.655799; Horowitz E., 1995, FUNDAMENTALS DATA ST; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kanth K. V., 1998, P ACM SIGMOD INT C M, P166; Kataymaand N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Knuth D. E., 1973, ART COMPUTER PROGRAM, V3; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; MEGIDDO N, 1997, 10093 IBM RJ ALM RES; MIYAHARA M, 1992, P SPIE VIS COMMUN IM, V1001, P650; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Ponceleon D., 1998, Proceedings ACM Multimedia 98, DOI 10.1145/290747.290760; Roussopoulos N, 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; SALTON G, 1983, INTRO MODERN INFORMA; SHEPHERD J, 1999, P IS T SPIE C STOR R, V7, P350; STRANG G, 1980, LINEAR ALGEBRA ITS A; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; ZEZULA P, 1998, VLDB J, V7, P294	32	33	38	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1520-9210		IEEE T MULTIMEDIA	IEEE Trans. Multimedia	MAR	2002	4	1					76	87				12	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	524CY	WOS:000173995500008	
J	Hofmann, WK; de Vos, S; Elashoff, D; Gschaidmeier, H; Hoelzer, D; Koeffler, HP; Ottmann, OG				Hofmann, WK; de Vos, S; Elashoff, D; Gschaidmeier, H; Hoelzer, D; Koeffler, HP; Ottmann, OG			Relation between resistance of Philadelphia-chromosome-positive acute lymphoblastic leukaemia to the tyrosine kinase inhibitor ST1571 and gene-expression profiles: a gene-expression study	LANCET			English	Article							CELL-LINES; MICROARRAY; STI571; SENSITIVITY; ACTIVATION; MECHANISM; LEUKEMIA; CANCER	Background The ABL tyrosine kinase inhibitor STI571 is a promising agent for treatment of advanced Philadelphia-chromosome-positive (Ph+) acute lymphoblastic leukaemia. However, resistance to this drug develops within a few months in most patients. We aimed to predict resistance to STI571. Methods Total RNA was extracted from 25 bone-marrow samples from 19 patients with Ph+ acute lymphoblastic leukaemia who were enrolled into a phase 11 study. 17 samples were obtained before STI571 treatment was started: ten from individuals who were classified as good responders to STI571 (sensitive), and seven from individuals who did not to respond to STI571 (primary resistance). Eight samples were obtained from patients during treatment with STI571. We analysed six matched samples, which were obtained before and during treatment with STI571. Oligonucleotide microarray analysis of samples was done with high-density microarrays. Findings We identified 95 genes whose expression could be used to predict sensitivity of leukaemic cells to STI571. On this basis, all the STI571-sensitive samples could clearly be distinguished from the resistant cases. 56 highly differentially expressed genes were identified in leukaemic cells that were secondarily resistant to STI571. Resistant leukaemic cells expressed high levels of Bruton's tyrosine kinase and two ATP synthetases (ATP5A1 and ATP5C1), and showed significantly reduced expression of the proapoptotic gene BAK1 and the cell-cycle control gene p15 INK4b, Interpretation We have shown the clinical relevance of gene expression data for the pretreatment assessment of acute lymphoblastic leukaemia. Our results have implications for future clinical studies of tyrosine kinase inhibitors.	Univ Hosp, Dept Haematol & Oncol, D-60596 Frankfurt, Germany; Univ Calif Los Angeles, Sch Med, Cedars Sinai Res Inst, Div Haematol & Oncol, Los Angeles, CA USA; Univ Calif Los Angeles, Sch Med, Dept Pathol, Los Angeles, CA 90024 USA; Univ Calif Los Angeles, Sch Publ Hlth, Dept Biostat, Los Angeles, CA 90024 USA; Novartis Pharma AG, Nurnberg, Germany	Hofmann, WK (reprint author), Univ Hosp, Dept Haematol & Oncol, Theodor Stern Kai 7, D-60596 Frankfurt, Germany.						Barthe C, 2001, Science, V293, P2163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeRisi J, 2000, FEBS LETT, V470, P156, DOI 10.1016/S0014-5793(00)01294-1; Desiderio S, 1997, CURR OPIN IMMUNOL, V9, P534, DOI 10.1016/S0952-7915(97)80107-0; Druker BJ, 2001, NEW ENGL J MED, V344, P1038, DOI 10.1056/NEJM200104053441402; Druker BJ, 1996, NAT MED, V2, P561, DOI 10.1038/nm0596-561; Druker BJ, 2001, NEW ENGL J MED, V344, P1031, DOI 10.1056/NEJM200104053441401; Goldman JM, 2001, NEW ENGL J MED, V344, P1084, DOI 10.1056/NEJM200104053441409; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gorre ME, 2001, SCIENCE, V293, P876, DOI 10.1126/science.1062538; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hochhaus A, 2001, SCIENCE, V293, P2163; Hofmann WK, 2001, BLOOD, V98, P787, DOI 10.1182/blood.V98.3.787; Honda H, 1998, BLOOD, V91, P2067; Huettner CS, 2000, NAT GENET, V24, P57; Kaminski N, 2000, P NATL ACAD SCI USA, V97, P1778, DOI 10.1073/pnas.97.4.1778; Knight ZA, 2000, BLOOD, V96, P4003; Komatani H, 2001, CANCER RES, V61, P2827; Kudoh K, 2000, CANCER RES, V60, P4161; le Coutre P, 2000, BLOOD, V95, P1758; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Mahon FX, 2000, BLOOD, V96, P1070; Ottmann OG, 2000, BLOOD, V96, p828A; PUISSANT C, 1990, BIOTECHNIQUES, V8, P148; Satterthwaite AB, 2000, P NATL ACAD SCI USA, V97, P6687, DOI 10.1073/pnas.110146697; Takata M, 1996, J EXP MED, V184, P31, DOI 10.1084/jem.184.1.31; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; Weisberg E, 2000, BLOOD, V95, P3498; Wilson Michael, 1999, Proceedings of the National Academy of Sciences of the United States of America, V96, P12833, DOI 10.1073/pnas.96.22.12833	29	149	157	LANCET LTD	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0140-6736		LANCET	Lancet	FEB 9	2002	359	9305					481	486		10.1016/S0140-6736(02)07678-X		6	Medicine, General & Internal	General & Internal Medicine	520ML	WOS:000173785600011	
J	Devi, VS; Murty, MN				Devi, VS; Murty, MN			An incremental prototype set building technique	PATTERN RECOGNITION			English	Article						pattern classification; prototype selection; supervised learning; k-nearest neighbour	NEAREST	This paper deals with the task of finding a set of prototypes from the training set. A reduced set is obtained which is used instead of the training set when nearest neighbour classification is used. Prototypes are added in an incremental fashion, where at each step of the algorithm, the number of prototypes selected keeps on increasing. The number of patterns in the training data classified correctly also keeps on increasing till all patterns are classified properly. After this, a deletion operator is used where some prototypes which are not so useful are removed. This method has been used to obtain the prototypes for a variety of benchmark data sets and results have been presented. (C) 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Murty, MN (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Murphy P., 1994, UCI REPOSITORY MACHI; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SUSHEELA V, 2000, SOFT COMPUTING IMAGE; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511	10	18	18	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	FEB	2002	35	2					505	513				9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	507AV	WOS:000173005000017	
J	Holz, HJ; Loew, MH				Holz, HJ; Loew, MH			Validation of relative feature importance using natural data	PATTERN RECOGNITION LETTERS			English	Article						feature analysis; classifier-independent; discriminatory power; feature selection; non-parametric		Feature analysis for classification is based on the discriminatory power of features. In previous research, we have presented a metric called relative feature importance (RFI) for measuring the non-parametric discriminatory power (NPDP) of features, RFI has been shown to correctly rank features for a variety of artificial data sets. In this work, we validate RFI on natural data, using several natural data sets. (C) 2002 Elsevier Science B.V. All rights reserved.	Calif State Univ Hayward, Dept Math & Comp Sci, Hayward, CA 94542 USA; George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA	Holz, HJ (reprint author), Calif State Univ Hayward, Dept Math & Comp Sci, Hayward, CA 94542 USA.						BLACKARD JA, 1998, THESIS COLORADO STAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Gelsema ES, 1996, PATTERN RECOGN LETT, V17, P1047, DOI 10.1016/0167-8655(96)00068-2; GELSEMA ES, 1994, PATTERN RECOGNITION, V4; Holz HJ, 1997, PATTERN RECOGN LETT, V18, P1219, DOI 10.1016/S0167-8655(97)00118-9; Holz H. J., 1996, Applied Parallel Computing. Computation in Physics, Chemistry and Engineering Science. Second International Workshop, PARA '95. Proceedings; HOLZ HJ, 1994, PATTERN RECOGN, V4, P473; HOLZ HJ, 1999, THESIS G WASHINGTON; Kohavi R, 1996, P 2 INT C KNOWL DISC, p202~207	10	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB	2002	23	4					367	380		10.1016/S0167-8655(01)00170-2		14	Computer Science, Artificial Intelligence	Computer Science	524BM	WOS:000173992100004	
S	Meir, R; Ratsch, G		Mendelson, S; Smola, AJ		Meir, R; Ratsch, G			An introduction to boosting and leveraging	ADVANCED LECTURES ON MACHINE LEARNING	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	Summer School on Advanced Lectures on Machine Learning	FEB 11-22, 2002	CANBERRA, AUSTRALIA	Res Sch Informat Sci & Engn, Natl Inst Engn & Informat Sci	AUSTRALIAN NATL UNIV		INFORMATION CRITERION; LOGISTIC-REGRESSION; MODEL SELECTION; VECTOR MACHINES; DECISION TREES; ALGORITHMS; NETWORKS; GRADIENT; DESCENT; BOUNDS	We provide an introduction to theoretical and practical aspects of Boosting and Ensemble learning, providing a useful reference for researchers in the field of Boosting as well as for those seeking to enter this fascinating area of research. We begin with a short background concerning the necessary learning theoretical foundations of weak learners and their linear combinations. We then point out the useful connection between Boosting and the Theory of Optimization, which facilitates the understanding of Boosting and later on enables us to move on to new Boosting algorithms, applicable to a broad spectrum of problems. In order to increase the relevance of the paper to practitioners, we have added remarks, pseudo code, "tricks of the trade", and algorithmic considerations where appropriate. Finally, we illustrate the usefulness of Boosting algorithms by giving an overview of some existing applications. The main ideas are illustrated on the problem of binary classification, although several extensions are discussed.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT 0200, Australia	Meir, R (reprint author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	rmeir@ee.technion.ac.il; Gunnar.Raetsch@anu.edu.au					ABNEY S, 1999, P JOINT SIGDAT C EMP; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Anthony M., 1999, NEURAL NETWORK LEARN; ANTOS A, 2002, J MACHINE LEARNING R, V3, P73; ASLAM JA, 2000, P COLT SAN FRANC; AUDRINO F, 2002, IN PRESS J COMPUTATI; BARNES JP, 1999, THESIS AUSTR NATL U; BARTLETT P, 2002, LECT NOTES COMPUT SC, V2375, P44; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; BARTLETT PL, 2002, IN PRESS J MACHI OCT; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bauschke H. H., 1997, J CONVEX ANAL, V4, P27; BENDAVID S, 2001, P 14 ANN C COMP LEAR, P507; Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BENNETT KP, 2002, P ICML; BENNETT KP, 1993, OPTIMIZATION METHODS, V3, P27; BERTONI A, 1997, LNCS, V5, P343; Bertsekas DP, 1995, NONLINEAR PROGRAMMIN; Bishop C. M., 1995, NEURAL NETWORKS PATT; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Boser B., 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Bradley P. S., 1998, P 15 INT C MACH LEAR, P82; Bregman LM, 1967, USSR COMP MATH MATH, V7, P200, DOI 10.1016/0041-5553(67)90040-7; Breiman L., 2000, SOME INFINITY THEORY; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L., 1997, 460 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BREIMAN L, 504 U CAL BERK STAT; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; BSHOUTY N, 2002, IN PRESS JMLR, P107; BUHLMANN P, 2001, 605 UC BERK STAT DEP; BUHLMANN P, 2002, J AM STAT ASS; Campbell C, 2001, ADV NEUR IN, V13, P395; CARMICHAEL J, 1990, EPRI J ELECT POWER R; Censor Y., 1997, NUMERICAL MATH SCI C; CESABIANCHI N, 1994, IEEE T INFORM THEORY, V40, P1215, DOI 10.1109/18.335953; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chen S., 1995, 479 STANF U DEP STAT; COHEN WW, 1998, ADV NEURAL INFORMATI, V10; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; COMINETTI R, 1994, JOTA, V83; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Crammer K, 2000, P 13 ANN C COMP LEAR, P35; Cristianini N, 2000, INTRO SUPPORT VECTOR; DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021; DEMIRIZ A, 2002, J MACHINE LEARNING R, V46, P225; DETTLING M, 2002, USE BOOSTING TUMOR C; Devroye L., 1996, APPL MATH; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DOMINGO C, 2000, P COLT SAN FRANC; DRUCKER H, 1994, NEURAL COMPUTATION, V6; Drucker H., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000352; Duffy N, 2000, ADV NEUR IN, V12, P258; Duffy N., 2000, P 13 ANN C COMP LEAR, P208; Duffy N, 1999, LECT NOTES ARTIF INT, V1572, P18; DUFFY N, 2000, BOOSTING METHODS REG; ELYANIV R, 2002, P 13 EUR C MACH LEAR; Escudero G, 2000, LECT NOTES ARTIF INT, V1810, P129; Feller W., 1968, INTRO PROBABILITY TH; FISHER DH, 1997, IMPROVING REGRESSORS; Frean Marcus, 1998, SIMPLE COST FUNCTION; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FREUND Y, 1998, P ICML; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Freund Y, 1999, GAME ECON BEHAV, V29, P79, DOI 10.1006/game.1999.0738; FREUND Y, 1994, LNCS; Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; FRIEDMAN J, 2000, ANN STAT, V2, P375; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J, TECHNICAL REPORT DEP; Friedman J, 1999, GREEDY FUNCTION APPR; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman J.H., 1999, STOCHASTIC GRADIENT; FRISCH KR, 1955, COMMUNICATION   0513; GRAEPEL T, 1999, P ICANN 99, V1, P304; GRANDVALET Y, 2001, P ICANN VIENN AUSTR; GRANDVALET Y, 2001, LECT NOTES COMPUTER; GROVE AJ, 1998, P 15 NAT C ART INT; Guruswami V., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307429; HART W, 1992, P IEEE, V80; Haruno M, 1999, MACH LEARN, V34, P131, DOI 10.1023/A:1007597902467; Hastie T. J., 2001, SPRINGER SERIES STAT; Hastie T J, 1990, MONOGRAPHS STAT APPL, V43; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; Haykin S, 1998, NEURAL NETWORKS COMP; Helmbold DP, 1999, IEEE T NEURAL NETWOR, V10, P1291, DOI 10.1109/72.809075; HERBRICH R, 2002, ADAPTIVE COMPUTATION, V7; HERBRICH R, 2000, P ANN C COMP LEARN T, P304; HERBRICH R, 2002, JMLR, V3, P175; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; Huang F, 2000, P 4 IEEE INT C AUT F, P245; Iyer R. D., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, DOI 10.1145/354756.354794; James W., 1961, 4TH P BERK S MATH ST, V1, P361; JIANG W, 2001, P 18 INT C MACH LEAR; Johnson D. S., 1978, Theoretical Computer Science, V6, DOI 10.1016/0304-3975(78)90006-3; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kearns M. J., 1994, INTRO COMPUTATIONAL; Kearns M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237994; KEARNS M, 1994, J ACM, V41, P67, DOI 10.1145/174644.174647; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; Kivinen J, 1997, INFORM COMPUT, V132, P1, DOI 10.1006/inco.1996.2612; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307424; Kiwiel KC, 1998, APPL MATH OPT, V38, P239, DOI 10.1007/s002459900090; KOLTCHINSKII V, 2002, ANN STAT, V30; KRIEGER A, 2001, P 18 ICML; Lafferty J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307422; LEBANON G, 2002, IN PRESS ADV NEURAL, V14; LEBANON G, NCTR2001098 NEUROCOL; LeCun Y.A., 1995, P INT C ART NEUR NET, V2, P53; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; LITTLESTONE N, 1995, COMPUT COMPLEX, V5, P1, DOI 10.1007/BF01277953; Luenberger D., 1984, LINEAR NONLINEAR PRO; LUGOSI G, 2002, LECT NOTES ARTIF INT, V2375, P303; LUO ZQ, 1992, J OPTIMIZ THEORY APP, V72, P7, DOI 10.1007/BF00939948; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; MANNOR S, 2001, P 14 ANN C COMP LEAR, P461; Mannor S, 2002, MACH LEARN, V48, P219, DOI 10.1023/A:1013959922467; MANNOR S, 2002, LECT NOTES COMPUT SC, V2375, P319; Mason L, 2000, ADV NEUR IN, P221; MASON L, 1998, IMPROVED GEN EXPLICI; MASON L, 1999, THESIS AUSTR NATL U; Mason L., 1999, ADV LARGE MARGIN CLA; Matousek J., 1999, GEOMETRIC DISCREPANC; Meir R., 2000, P 13 ANN C COMP LEAR, P190; MEIR R, 2002, UNPUB DATA DEPENDENT; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; MERLER S, 2001, LNCS, V2096, P32; MOODY JE, 1992, ADV NEUR IN, V4, P847; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MURATA N, 1994, IEEE T NEURAL NETWOR, V5, P865, DOI 10.1109/72.329683; Nash S. G., 1996, LINEAR NONLINEAR PRO; NOCK R, 2002, LNAI, V2430; Onoda T., 1998, P INT C ART NEUR NET, P195; ONODA T, 2000, P NC 2000 BERL; OSULLIVAN J, 2000, P 17 ICML; OZA N, 2001, P KDD 01; Pietra Stephen Della, 2001, CMUCS01109 SCH COMP; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1996, LECT NOTES COMPUTER, V1160, P143; RATSCH G, 2002, GI EDITION LECT NOTE, V2, P125; Ratsch G, 2000, ADV NEUR IN, P207; RATSCH G, 2002, IN PRESS ADV NEURAL, V14; RATSCH G, 2003, IN PRESS NIPS, V15; RATSCH G, 2002, NIPS, V14; RATSCH G, 2001, 98 ROYAL HOLL COLL; Ratsch G., 2000, P 13 ANN C COMP LEAR; RATSCH G, NCTR2000085 NEUROCOL; RATSCH G, 2000, 119 GMD; RATSCH G, 2002, LECT NOTES ARTIF INT, V2375, P319; RATSCH G, NCTR2001098 NEUROCOL; Ratsch G., 2001, THESIS U POTSDAM POT; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RATSCH G, NCTR1998021 NEUROCOL; RATSCH G, 2002, MACH LEARN, V48, P193; RATSCH G, 1998, THESIS U POTSDAM; RATSCH G, 2002, IN PRESS IEEE PAMI, V24; Ridgeway G., 1999, P ART INT STAT, P152; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Robert C. P., 1994, BAYESIAN CHOICE DECI; ROCHERY M, 2002, INT C ACC SPEECH SIG; Rockafellar R.T, 1970, PRINCETON LANDMARKS; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHAPIRE R, 1998, P 21 ANN INT C RES D; Schapire R. E., 1999, P 16 INT JOINT C ART; Schapire R.E., 2002, WORKSH NONL EST CLAS; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHAPIRE RE, 2002, P P 19 INT CLASS MAC; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schapire Robert E., 1997, MACH LEARN P 14 INT, P313; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Scholkopf B., 2002, LEARNING KERNELS; SCHOLKOPF B, 1999, 87 TR MICR RES; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; SERVEDIO R, 2001, P 14 ANN C COMP LEAR, P473; SERVEDIO RA, 2000, P COLT SAN FRANC, P148; SHAWETAYLOR J, 2001, NCTR2000082 NEUROCOL; Shawe-Taylor J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307470; SHAWETAYLOR J, 2000, ADV LARGE MARGIN CLA, P247; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Singer Y, 2000, ADV NEUR IN, V12, P610; Tax D, 1999, P EUR S ART NEUR NET, P251; Thollard F, 2002, LECT NOTES ARTIF INT, V2430, P431; Tikhonov A. N., 1977, SOLUTIONS ILL POSED; Tsuda K, 2002, IEEE T NEURAL NETWOR, V13, P70, DOI 10.1109/72.977272; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; von Neumann J, 1928, MATH ANN, V100, P295; WALKER MA, 2001, P 2 ANN M N AM CHAPT; Wellner J. A., 1996, WEAK CONVERGENCE EMP; Zemel RS, 2001, ADV NEUR IN, V13, P696; ZHANG T, 2002, ADV NEURAL INFORMATI, V14; Zhang T, 2002, MACH LEARN, V46, P91, DOI 10.1023/A:1012498226479; ZHANG T, 2002, SEQUENTIAL GREEDY AP; ZHANG T, 2001, RC22155 IBM RES; Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X	211	114	114	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-00529-3	LECT NOTES ARTIF INT			2002	2600						118	183				66	Computer Science, Artificial Intelligence; Statistics & Probability	Computer Science; Mathematics	BW57Z	WOS:000182487800004	
S	Bernado, E; Llora, X; Garrell, JM		Lanzi, P; Stolzmann, W; Wilson, SW		Bernado, E; Llora, X; Garrell, JM			XCS and GALE: A comparative study of two learning classifier systems on data mining	ADVANCES IN LEARNING CLASSIFIER SYSTEMS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Workshop on Learning Classifier Systems	JUL 07-08, 2001	SAN FRANCISCO, CALIFORNIA				ALGORITHMS	This paper compares the learning performance, in terms of prediction accuracy, of two genetic-based learning systems, XCS and GALE, with six well-known learning algorithms, coming from instance based learning, decision tree induction, rule-learning, statistical modeling and support vector machines. The experiments, performed on several datasets, show the suitability of the genetic-based learning classifier systems for classification tasks. Both XCS and GALE significantly achieved better results than IB1 and Naive Bayes. Besides, any method could not outperform XCS and GALE significantly.	Engn & Arquitectura La Salle, Barcelona 08022, Spain	Bernado, E (reprint author), Engn & Arquitectura La Salle, Psg Bonanova 8, Barcelona 08022, Spain.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Altenberg L., 1995, FDN GENETIC ALGORITH, VIII, P23; Blake CL, 1998, UCI REPOSITORY MACHI; BONELLI P, 1991, 4 INT C GEN ALG ICGA, P288; BUTZ MV, 2000, 2000017 ILLIGAL U IL; CANTUPAZ E, 2000, GENETIC EVOLUTIONARY, P1053; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DIEFERSON LA, 2000, WORKSH DAT MIN EV CO, P89; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; FLOCKHART IW, 1995, 10 EPCC AIKMS GA MIN; Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98); FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; Giordana A, 1995, EVOL COMPUT, V3, P375, DOI 10.1162/evco.1995.3.4.375; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Han J., 2001, DATA MINING CONCEPTS; HARTLEY A, 1999, P GEN EV COMP C 1999, P266; Hayes-Roth F., 1978, PATTERN DIRECTED INF, P313; Holland J. H., 1986, MACHINE LEARNING ART, V2, P593; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLMES JH, 1997, P 7 INT C GEN ALG IC, P426; HOLMES JH, 2000, 3 INT WORKSH LEARN C; Janikow C. Z., 1993, MACH LEARN, V13, P198; John G. H., 1995, 11 C UNC ART INT, P338; Kovacs T., 1999, P GEN EV COMP C GECC, P329; Kovacs T., 1997, SOFT COMPUTING ENG D, P59; Koza J. R., 1992, GENETIC PROGRAMMING; LANZI PL, 1999, P GEN EV COMP C GECC, P353; Lanzi P-L., 2000, LEARNING CLASSIFIER, P223; LLORA X, 2000, P GEN EV COMP C GECC, P868; LLORA X, 2001, IN PRESS P 18 INT C; LLORA X, 2001, IN PRESS P GEN EV CO; LLORA X, 2000, P LEARN 00 WORKSH; Marti J, 1998, P SOC PHOTO-OPT INS, V3338, P1215, DOI 10.1117/12.310849; MARTIN JK, 1996, 9621 U CAL DEP INF C; MARTINEZ E, 1996, 8 MED EL C IND APPL, P1067; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Platt J, 1998, ADV KERNEL METHODS S; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Smith S. F., 1983, P 8 INT JOINT C ART, P422; WILSON SW, 1999, FESTSCHRIFT HONOR JH; WILSON SW, 1999, 9911 PRED DYN; WILSON SW, 1998, GEN PROGR P 3 ANN C; WILSON SW, 2000, 3 INT WORKSH LEARN C; Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149; Witten I. H., 2000, DATA MINING PRACTICA	49	38	38	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-43793-2	LECT NOTES ARTIF INT			2002	2321						115	132				18	Computer Science, Artificial Intelligence	Computer Science	BW13N	WOS:000180978300008	
S	Domeniconi, C; Gunopulos, D		Dietterich, TG; Becker, S; Ghahramani, Z		Domeniconi, C; Gunopulos, D			Adaptive nearest neighbor classification using support vector machines	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA				REGRESSION	The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence of classification performance improvement over the SVM algorithm alone and over a variety of adaptive learning schemes, by using both simulated and real data sets.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Domeniconi, C (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.						Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; BELLMAN BE, 1961, ADAPTIVE CONTROL PRO; Brown M., 1999, KNOWLEDGE BASED ANAL; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2000, ADV NEURAL INFORMATI; DOMENICONI C, 2001, UCRCSE0104 DEP COMP; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P EUR C MACH LEARN; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Osuna E., 1997, P COMP VIS PATT REC; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	16	2	2	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258	0-262-04208-8	ADV NEUR IN			2002	14						665	672				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100083	
S	Vincent, P; Bengio, Y		Dietterich, TG; Becker, S; Ghahramani, Z		Vincent, P; Bengio, Y			K-Local hyperplane and convex distance nearest neighbor algorithms	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 14, VOLS 1 AND 2	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	15th Annual Conference on Neural Information Processing Systems (NIPS)	DEC 03-08, 2001	VANCOUVER, CANADA					Guided by an initial idea of building a complex (non linear) decision surface with maximal local margin in input space, we give a possible geometrical intuition as to why K-Nearest Neighbor (KNN) algorithms often perform more poorly than SVMs on classification tasks. We then propose modified K-Nearest Neighbor algorithms to overcome the perceived problem. The approach is similar in spirit to Tangent Distance, but with invariances inferred from the local neighborhood rather than prior knowledge. Experimental results on real world classification tasks suggest that the modified KNN algorithms often give a dramatic improvement over standard KNN and perform as well or better than SVMs.	Univ Montreal, Dept IRO, Montreal, PQ H3C 3J7, Canada	Vincent, P (reprint author), Univ Montreal, Dept IRO, CP 6128, Montreal, PQ H3C 3J7, Canada.						ATKESON CG, 1996, ARTIFICIAL INTELLIGE; Boser B. E, 1992, 5 ANN ACM WORKSH COL, P144; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Chapelle O, 2001, ADV NEUR IN, V13, P416; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman J ., 1994, 113 STANF U STAT DEP; Hastie T, 1996, ADV NEUR IN, V8, P409; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; ORMONEIT D, 2000, ADV NEURAL INFORMATI, V12; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SIMARD P, 1998, LECT NOTES COMPUTER, V1524; Tong S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Vapnik V.N., 1995, NATURE STAT LEARNING; ZHANG B, 2001, HPL200189	16	47	48	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258	0-262-04208-8	ADV NEUR IN			2002	14						985	992				8	Computer Science, Artificial Intelligence	Computer Science	BV95T	WOS:000180520100123	
J	Chung, TP; Laramie, JM; Province, M; Cobb, JP				Chung, TP; Laramie, JM; Province, M; Cobb, JP			Functional genomics of critical illness and injury	CRITICAL CARE MEDICINE			English	Review						genomics; profiling; sepsis; networks; bioinformatics; microarray	MICROARRAY GENE-EXPRESSION; DNA ARRAYS; SEPSIS; DISCOVERY; PATTERNS		Washington Univ, Sch Med, Dept Surg,Cellular Injury & Adaptat Lab, Burn Trauma & Surg Crit Care Sect, St Louis, MO 63110 USA; Washington Univ, Sch Med, Div Biostat, St Louis, MO 63110 USA	Cobb, JP (reprint author), Washington Univ, Sch Med, Dept Surg,Cellular Injury & Adaptat Lab, Burn Trauma & Surg Crit Care Sect, Campus Box 8109,660 S Euclid Ave, St Louis, MO 63110 USA.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; BAKER CC, 1983, SURGERY, V94, P331; Bezdek J., 1981, PATTERN RECOGNITION; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; BROWN PO, 1999, OBSERVING LIVING GEN; Buchman TG, 2001, SHOCK, V16, P248, DOI 10.1097/00024382-200116040-00002; Cheung VG, 1999, NAT GENET, V21, P15, DOI 10.1038/4439; CHUNG TP, 2001, ABSTR SHOCK S1, V15, P26; COBB JP, 2002, IN PRESS CRIT CARE M; COBB JP, 2001, BROAD SCALE SPLENIC; Cobb JP, 2001, SHOCK, V15, P165; COBB JP, 2000, SHOCK S2, V13, P32; Cobb JP, 2001, SHOCK, V16, P264; Collins FS, 2001, JAMA-J AM MED ASSOC, V285, P540, DOI 10.1001/jama.285.5.540; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deitch EA, 1998, SHOCK, V9, P1, DOI 10.1097/00024382-199801000-00001; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; EVERITT B, 1974, CLUSTER ANAL, V122; Fields S, 1999, P NATL ACAD SCI USA, V96, P8825, DOI 10.1073/pnas.96.16.8825; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gaasterland T, 2000, NAT GENET, V24, P204, DOI 10.1038/73392; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hieter P, 1997, SCIENCE, V278, P601, DOI 10.1126/science.278.5338.601; Hotchkiss RS, 1997, CRIT CARE MED, V25, P1298, DOI 10.1097/00003246-199708000-00015; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Jeong H, 2001, NATURE, V411, P41, DOI 10.1038/35075138; Jeong H, 2000, NATURE, V407, P651; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohonen T, 1995, SELF ORGANIZING MAPS; KOUSTOVA E, 2001, SHOCK S1, V15, P26; LANDER ES, 2001, NATURE GENETICS S, V21, P3; Lee MLT, 2000, P NATL ACAD SCI USA, V97, P9834, DOI 10.1073/pnas.97.18.9834; Lockhart DJ, 2000, NATURE, V405, P827, DOI 10.1038/35015701; Mir KU, 2000, TRENDS GENET, V16, P63, DOI 10.1016/S0168-9525(99)01947-2; Risch NJ, 2000, NATURE, V405, P847, DOI 10.1038/35015718; Rizzo WB, 1999, AM J HUM GENET, V65, P1547, DOI 10.1086/302681; Sander C, 2000, SCIENCE, V287, P1977, DOI 10.1126/science.287.5460.1977; Schadt EE, 2000, J CELL BIOCHEM, V80, P192; Sherlock G, 2000, CURR OPIN IMMUNOL, V12, P201, DOI 10.1016/S0952-7915(99)00074-6; Spengler SJ, 2000, SCIENCE, V287, P1221, DOI 10.1126/science.287.5456.1221; Staudt LM, 2000, ANNU REV IMMUNOL, V18, P829, DOI 10.1146/annurev.immunol.18.1.829; Sun L, 1999, J CLIN ONCOL, V17, P3753; WEINSTEIN JN, 1998, SCIENCE, V282, P627; Young RA, 2000, CELL, V102, P9, DOI 10.1016/S0092-8674(00)00005-2; Zien A., 2001, BIOINFORMATICS, V17, pS323; 2001, NATURE MED, V7, P751	48	21	24	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA	0090-3493		CRIT CARE MED	Crit. Care Med.	JAN	2002	30	1		1			S51	S57		10.1097/00003246-200201001-00007		7	Critical Care Medicine	General & Internal Medicine	516VG	WOS:000173577000007	
S	Toussaint, G		Akiyama, J; Kano, M		Toussaint, G			Open problems in geometric methods for instance-based learning	DISCRETE AND COMPUTATIONAL GEOMETRY	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th Japanese Conference on Discrete and Computational Geometry (JCDCG 2002)	DEC 06-09, 2002	TOKYO, JAPAN	Tokai Univ			RELATIVE NEIGHBORHOOD GRAPH; PATTERN CLASSIFICATION; ALGORITHMS; RULE	In the typical approach to instance-based learning, random data (the training set of patterns) are collected and used to design a decision rule (classifier). One of the most well known such rules is the k-nearest-neighbor decision rule in which an unknown pattern is classified into the majority class among its k nearest neighbors in the training set. In the past fifty years many approaches have been proposed to improve the performance of this rule. More recently geometric methods have been found to be the best. Here we mention a variety of open problems of a computational geometric nature that arize in these methods. To provide some context and motivation for these open problems we briefly describe the methods and list some key references.	McGill Univ, Sch Comp Sci, Montreal, PQ, Canada	Toussaint, G (reprint author), McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.	godfried@cs.mcgill.ca					Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANDRADE DV, 2001, P 13 CAN C COMP GEOM; BRIGHTON H, 1999, PRINCIPLES DATA MINI; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L, 1996, PROBABILISTIC THEORY; Duda R. O., 2001, PATTERN CLASSIFICATI; Ekin O, 1999, INFOR, V37, P337; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GODFRIED T, 1980, P 5 S OP RES U KOLN, P425; GOODMAN LA, 1954, J AM STAT ASSOC, P723; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; ICHINO M, 1985, PATTERN RECOGN, V18, P161, DOI 10.1016/0031-3203(85)90040-8; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Liotta G, 1998, COMP GEOM-THEOR APPL, V10, P1, DOI 10.1016/S0925-7721(97)00018-7; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; OROURKE J, 1997, HDB DISCRETE COMPUTA, P797; PATERSON MS, 1992, LECT NOTES COMPUT SC, V623, P416; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; SEBBAN M, 2001, P 18 INT C MACH LEAR; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; SU TH, 1991, COMPUTING, V46, P121, DOI 10.1007/BF02239166; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; TOUSSAINT GT, 1974, P 2 INT JOINT C PATT, P27; TOUSSAINT GT, 2002, INTERFACE 2002; Toussaint G. T., 1979, Proceedings of COMPSAC the IEEE Computer Society's Third International Computer Software and Applications Conference; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Toussaint G. T., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; TOUSSAINT GT, 1980, ELECTRON LETT, V16, P860, DOI 10.1049/el:19800611; Vapnik V.N., 1998, STAT LEARNING THEORY; WILFONG G, 1991, P 7 ANN ACM S COMP G, P224, DOI 10.1145/109648.109673; Wilson D. R., 1997, MACH LEARN, P404; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	43	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-20776-7	LECT NOTES COMPUT SC			2002	2866						273	283				11	Computer Science, Theory & Methods; Mathematics	Computer Science; Mathematics	BY30M	WOS:000188862800029	
B	Zhang, B; Srihari, SN			IEEE; IEEE	Zhang, B; Srihari, SN			A fast algorithm for finding k-nearest neighbors with non-metric dissimilarity	EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS			English	Proceedings Paper	8th International Workshop on Frontiers in Handwriting Recognition	AUG 06-08, 2002	ONTARIO, CANADA	Univ Buffalo, CEDAR, Microsoft, Siemens, Hitachi, Motorola, US Postal Serv, A2iA, Int Assoc Pattern Recognit				Fast nearest neighbor (NN)finding has been extensively studied. While some fast NN algorithms using metrics rely on the essential properties of metric spaces, the others using non-metric measures fail for large-size templates. However in some applications with very large size templates, the best performance is achieved by NN methods based on the dissimilarity measures resulting in a special space where computations cannot be pruned by the algorithms based-on the triangular inequality. For such NN methods, the existing fast algorithms except condensing algorithms are not applicable. In this paper, a fast hierarchical search algorithm is proposed to find k-NNs using a non-metric measure in a binary feature space, Experiments with handwritten digit recognition show that the new algorithm reduces on average dissimilarity computations by more than 90% while losing the accuracy by less than 0.1%, with a 10% increase in memory.	SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Buffalo, NY 14228 USA	Zhang, B (reprint author), SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Buffalo, NY 14228 USA.						BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; Cha SH, 2002, PATTERN RECOGN, V35, P515, DOI 10.1016/S0031-3203(01)00032-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUNKUNAGA K, 1975, IEEE T COMPUT, V24, P750; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1692-0				2002							13	18				4	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BV03S	WOS:000177665000002	
S	Pimentel, CF; da Fonseca, MJ; Jorge, JA		Blostein, D; Kwon, YB		Pimentel, CF; da Fonseca, MJ; Jorge, JA			Experimental evaluation of a trainable scribble recognizer for calligraphic interfaces	GRAPHICS RECOGNITION: ALGORITHMS AND APPLICATIONS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	4th International Workshop on Graphics Recognition	SEP 07-08, 2001	KINGSTON, CANADA	Int Assoc Pattern Recognit, TC 10, Queens Univ, Comp Sci & Engn Res Informat Ctr, Xero Fdn, Commun & Informat Technol Ontario				This paper describes a trainable recognizer for hand-drawn sketches using geometric features. We compare three different learning algorithms and select the best approach in terms of cost-performance ratio. The algorithms employ classic machine-learning techniques using a clustering approach. Experimental results show competing performance (95.1%) with the non-trainable recognizer (95.8%) previously developed, with obvious gains in flexibility and expandability. In addition, we study both their classification and learning performance with increasing number of examples per class.	Univ Tecn Lisboa, IST, Dept Engn Informat, P-1049001 Lisbon, Portugal	Pimentel, CF (reprint author), Univ Tecn Lisboa, IST, Dept Engn Informat, Av Rovisco Pais, P-1049001 Lisbon, Portugal.	pimentelcesar@hotmail.com; mjf@inesc.pt; jaj@inesc.pt	Jorge, Joaquim/C-5596-2008	Jorge, Joaquim/0000-0001-5441-4637			APTE A, 1993, P UIST 93 ATL GA; Bishop C. M., 1995, NEURAL NETWORKS PATT; BOYCE JE, 1985, SIAM J COMPUT, V14, P134, DOI 10.1137/0214011; Cestnik B., 1990, P EUR C ART INT, P147; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FAYYAD UM, 1991, THESIS U MICHIGAN; Fonseca MJ, 2001, PATTERN RECOGN LETT, V22, P1311, DOI 10.1016/S0167-8655(01)00076-9; FREEMAN H, 1975, COMMUN ACM, V18, P409, DOI 10.1145/360881.360919; LITTLESTONE N, 1991, UCSCCRL9128 COMP ENG; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; MALERBA D, 1995, LEARNING DATA AI STA; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; O'Rourke J, 1998, COMPUTATIONAL GEOMET; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, J OPER RES SOC, V38, P347; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1983, MACHINE LEARNING ART; RUBINE DH, 1991, SIGGRAPH 91 C P ACM; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669	24	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-44066-6	LECT NOTES COMPUT SC			2002	2390						81	91				11	Computer Science, Theory & Methods	Computer Science	BW27B	WOS:000181394100007	
B	Wang, PF; Mosley, C		Wang, L; Rajapakse, JC; Fukushima, K; Lee, SY; Yao, X		Wang, PF; Mosley, C			Associative memory neural networks for information retrieval of text word pairs	ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING: COMPUTATIONAL INTELLIGENCE FOR THE E-AGE			English	Proceedings Paper	9th International Conference on Neural Information Processing	NOV 18-22, 2002	SINGAPORE, SINGAPORE	Asia Pacific Neural Network Assembly, Singapore Neurosci Assoc, SEAL & FSKD Conf Steering Comm, Nanyang Technol Univ, Sch Elect & Electr Engn			ALGORITHM	Natural language information processing remains a challenge in Linguistics. Existing methods for retrieval of text often use stemming to retain common roots and base recall on these root words [1,4,5,9]. This requires the removal of stop words, e.g., numbers, symbols, high frequency bid low semantic weight words, thereby precluding phrases using these words [2]. In addition stemming is a morphologic approach that cannot readily process homonyms, synonyms and certain inflectional and derived forms [4.5]. Machine learning approaches assign words to categories [5,6,7,81, but application to a large corpus remains in debate [4]. For this study, we describe the application of the Cortronic theory and methods developed by Robert Hecht-Nielsen [2.3] to information retrieval of text word pairs. Hecht-Nielsen's theories build on associative memory artificial neural networks (AMNNs) introduced by Steinbuch [10] and extended by Willshaw et al. [ 11] especially in regards sparseness [2,3]. The AADNs are used to process a large corpus without excluding stop words, and retain the joint probability of mutual occurrences that allows rapid retrieval of word pairs. This AMNN approach includes three key components: representation of arbitrary objects (words), learning and knowledge accumulation based on measurement of co-occurrence and use of all the learned knowledge to produce (predict) the missing word in a phrase.	SSC SD, Marine Environm Qual Branch, San Diego, CA 92152 USA	Wang, PF (reprint author), SSC SD, Marine Environm Qual Branch, Code 2362, San Diego, CA 92152 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HECHTNIELSEN R, 2002, NEURALSCIENCE AI END; HECHTNIELSEN R, 2002, NEUROCOMPUTING; Hull DA, 1996, J AM SOC INFORM SCI, V47, P70, DOI 10.1002/(SICI)1097-4571(199601)47:1<70::AID-ASI7>3.0.CO;2-#; Jurafsky Daniel, 2000, SPEECH LANGUAGE PROC; KIM JY, 1994, SOFTWARE PRACT EXPER, V24, P79, DOI 10.1002/spe.4380240105; KROVETZ R, 1993, P 16 ANN INT ACM SIG, P191, DOI 10.1145/160688.160718; MOONEY RJ, 1995, MACH LEARN, V19, P79, DOI 10.1007/BF00994661; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; STEINBUCH K, 1961, KYBERNETIK, V1, P36, DOI 10.1007/BF00293853; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0	11	0	0	NANYANG TECHNOLOGICAL UNIV	SINGAPORE	NANYANG AVENUE, SINGAPORE 639815, SINGAPORE		981-04-7524-1				2002							2200	2203				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BW69E	WOS:000182832400450	
B	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			IEEE; IEEE	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			Comparison of wavelet-based methods for the prognosis of failures in electric motors	IEEE POWER ELECTRONICS IN TRANSPORATION			English	Proceedings Paper	7th Workshop on Power Electronics in Transportation	OCT 24-25, 2002	AUBURN HILL, MI	IEEE Power Electr Soc, IEEE SE Michigan Sect, Soc Automot Engineers, IEEE Vehicular Technol Soc		fault prognosis; wavelets; DC motors		The ability to give a prognosis for failure of a system is an invaluable tool and can be applied to electric motors. In this paper, three wavelet based methods have been developed that achieve this goal. Wavelet and filter bank theory, the nearest neighbor rule, and linear discriminant functions are reviewed. A framework for the development of a fault detection and classification algorithm based on the coefficients calculated from the discrete wavelet transform and using clustering is described. An experimental setup based on RT-Linux is described and results from testing are presented, verifying the analysis.	Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48823 USA	Zanardelli, WG (reprint author), Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48823 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Guo H, 1998, INTRO WAVELETS WAVEL; MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727; Young T. Y., 1974, CLASSIFICATION ESTIM; ZANARDELLI WG, 2001, IEEE INT S DIAGN EL, P591; ZANARDELLI WG, 2000, THESIS MICHIGAN STAT	7	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7492-4				2002							61	67				7	Engineering, Electrical & Electronic; Transportation Science & Technology	Engineering; Transportation	BW20N	WOS:000181178100009	
S	Bao, YG; Du, XY; Ishii, N		Yin, H; Allinson, N; Freeman, R; Keane, J; Hubbard, S		Bao, YG; Du, XY; Ishii, N			Combining feature selection with feature weighting for k-NN classifier	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2002	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Conference on Intelligent Data Engineering and Automated Learning	AUG 12-14, 2002	MANCHESTER, ENGLAND	Univ Manchester Inst Sci & Technol			LEARNING ALGORITHMS	The k-nearest neighbor (k-NN) classification is a simple and effective classification approach. However, it suffers from over-sensitivity problem due to irrelevant and noisy features. In this paper, we propose an algorithm to improve the effectiveness of k-NN by combining these two approaches. Specifically, we select all relevant features firstly, and then assign a weight to each one. Experimental results show that our algorithm achieves the highest accuracy or near to the highest accuracy on all test datasets. It also achieves higher generalization accuracy compared with the well-known algorithms IB1-4 and C4.5.	Nagoya Inst Technol, Dept Intelligence & Comp Sci, Nagoya, Aichi 4668555, Japan; Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China	Bao, YG (reprint author), Nagoya Inst Technol, Dept Intelligence & Comp Sci, Nagoya, Aichi 4668555, Japan.		ruc, comp_xinxi/E-4212-2012				Aha D., 1998, FEATURE EXTRACTION C; AHA DW, 1994 WORKSH TR WS 94; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AYAN NF, 1999, 8 TURK S ART INT NEU; BAO YG, 6 INT C SOFT COMP II, P452; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Cardie C, 2000, MACH LEARN, V41, P85, DOI 10.1023/A:1007665204628; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KOHAVI R, ECML 97; LEE KC, 1999, LECT NOTES ARTIF INT, V1574, P138; Merz C.J., 1998, UCI REPOSITORY MACHI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-44025-9	LECT NOTES COMPUT SC			2002	2412						461	468				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BY01R	WOS:000187252500069	
J	Santinelli, A; Mazzucchelli, R; Colanzi, P; Tinca, A; Montironi, R				Santinelli, A; Mazzucchelli, R; Colanzi, P; Tinca, A; Montironi, R			Image processing, diagnostic information extraction and quantitative assessment in pathology	JOURNAL OF CELLULAR AND MOLECULAR MEDICINE			English	Article						image analysis; pathology; quantitation	PROSTATIC INTRAEPITHELIAL NEOPLASIA; NUCLEAR CHROMATIN TEXTURE; LESIONS; CANCER; ADENOCARCINOMA; PREDICTION; CARCINOMA; NETWORKS; SURVIVAL; SYSTEM	As we enter the information age we hold strong beliefs in the benefits of digital technology applied to pathology: numerical representation offers objectivity. Digital knowledge may indeed lead to significant information discovery, and, processing systems might be designed to allow a true evolution of capabilities. Questions arise whether the methodology underlying quantitative analysis provides the information that we need and whether it is appropriate for some of the problems encountered in diagnostic and prognostic histopathology. While one certainly would not dispute the value of statistical procedures, the clinical needs call for individual patient targeted prognosis.	Univ Ancona, Sch Med, Dept Pathol & Lab, Ancona, Italy	Montironi, R (reprint author), Univ Ancona, Sch Med, Osped Reg, Inst Pathol Anat & Histopathol, I-60020 Ancona, Italy.						Bartels PH, 1998, ANAL QUANT CYTOL, V20, P389; BARTELS PH, 1992, ANAL QUANT CYTOL, V14, P459; Bartels PH, 1996, EUR UROL, V30, P222; Bartels PH, 2001, PROSTATE, V48, P144, DOI 10.1002/pros.1093; BARTELS PH, 1995, PATHOL RES PRACT, V191, P945; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P397; BARTELS PH, 1995, PATHOLOGICA, V87, P115; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P407; Becker R. L. Jr., 1995, Pathologica (Genoa), V87, P246; Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; da Silva VD, 1999, ANAL QUANT CYTOL, V21, P113; Dukes CE, 1932, J PATHOL BACTERIOL, V35, P323, DOI 10.1002/path.1700350303; Hamilton PW, 1999, ANAL QUANT CYTOL, V21, P283; IRINOPOULOU T, 1993, ANAL QUANT CYTOL, V15, P341; JASS J, 1987, LANCET, V1, P1333; Jorgensen T, 1996, CYTOMETRY, V24, P277, DOI 10.1002/(SICI)1097-0320(19960701)24:3<277::AID-CYTO11>3.0.CO;2-N; Mairinger T, 1999, PROSTATE, V41, P12; Mazzucchelli R, 2001, ANTICANCER RES, V21, P1157; MONTIRONI R, 2000, J UROL PATH, V12, P133, DOI 10.1385/JUP:12:3:133; MONTIRONI R, 1995, PATHOL RES PRACT, V191, P917; Montironi R, 1997, J CLIN PATHOL, V50, P775, DOI 10.1136/jcp.50.9.775; POMANTE R, 1998, ACTA UROL ITAL, V12, P331	23	5	5	CAROL DAVILA UNIV PRESS	BUCHARESST	8 EROILOR SANITARI BLVD, BUCHARESST 76241, ROMANIA	1582-1838		J CELL MOL MED	J. Cell. Mol. Med.	JAN-MAR	2002	6	1					93	106		10.1111/j.1582-4934.2002.tb00314.x		14	Cell Biology; Medicine, Research & Experimental	Cell Biology; Research & Experimental Medicine	544JW	WOS:000175155300008	
B	Oliveira, PM; Lobo, V; Barroso, V; Moura-Pires, F			IEEE; IEEE; IEEE	Oliveira, PM; Lobo, V; Barroso, V; Moura-Pires, F			Detection and classification of underwater transients with data driven methods based on time-frequency distributions and non-parametric classifiers	OCEANS 2002 MTS/IEEE CONFERENCE & EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS			English	Proceedings Paper	MTS/IEEE Oceans 2002 Conference	OCT 29-31, 2002	BILOXI, MS	Marine Technol Soc, IEEE, OES			NEAREST	Due to the complexity of underwater transients and background interference, model based approaches to transient detection/classification are often not practical. This has motivated an interest for data-driven, model-free methods. One such method was presented in [2] and modified in [1], where it was applied to the detection of underwater transients. In this article, we will extend that approach, to allow its use in the more demanding environment of a brown water environment, where background noise is constituted by a multitude of different interferences, non-white, and highly non-stationary. Also, the assumption of linear separability amongst the transients and the background noise in the time-frequency or related domains will be discarded, leading to the use of an additional classifier stage. A technique to minimize the number of prototypes on this classifier will be presented. The developed methods are used to detect and classify real underwater transients, recorded off the Portuguese coast. Estimation of the overall error rate of the method is obtained using cross-validation with the available data set, showing that these methods can effectively be used in real environment situations.	Escola Naval, Alfeite, P-2800 Almada, Portugal	Oliveira, PM (reprint author), Escola Naval, Alfeite, P-2800 Almada, Portugal.						AHA DW, 1997, ARTIFICIAL INTELLIGE, V11; Bax E, 2000, IEEE T INFORM THEORY, V46, P2746, DOI 10.1109/18.887892; Bishop C. M., 1995, NEURAL NETWORKS PATT; Breiman L, 1984, CLASSIFICATION REGRE; Cohen L., 1995, TIME FREQUENCY ANAL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNNINGHAM GS, 1994, IEEE T SIGNAL PROCES, V42, P1496, DOI 10.1109/78.286965; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; Duda R. O., 2001, PATTERN CLASSIFICATI; Fix E., 1951, DISCRIMINATORY ANAL, P261; FLANDRIN P, 1988, IEEE T ACOUST SPEECH, V36, P1377, DOI 10.1109/29.90365; JONES DL, P 1995 IEEE INT C AC, P1033; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; LOBO V, 1998, WCCI WORLD C COMP IN; Nock R, 2001, PATTERN RECOGN LETT, V22, P407, DOI 10.1016/S0167-8655(00)00133-1; OLIVEIRA PM, 2000, P MTS IEEE OC 2000 A; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7534-3				2002							12	16				5	Acoustics; Engineering, Ocean; Engineering, Electrical & Electronic; Instruments & Instrumentation; Imaging Science & Photographic Technology	Acoustics; Engineering; Instruments & Instrumentation; Imaging Science & Photographic Technology	BW53J	WOS:000182293200003	
B	Yager, RR			IEEE; IEEE	Yager, RR			Prototype reasoning and knowledge creation using granular objects	PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2			English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 12-17, 2002	HONOLULU, HI	IEEE, IEEE Neural Network Soc				We introduce a general framework which we call prototype based reasoning. We explain its role as a technology for knowledge discovery We look at some types of prototype based reasoning systems. First we consider nearest neighbor based systems. We then look at fuzzy rule based models and view these as prototype based reasoning. This unified perspective allows us to extend the capabilities of fuzzy modeling technology in a number of directions.	Iona Coll, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 2001, PTTERN CLASSIFICATIO; Yager R. R., 2001, International Journal of Fuzzy Systems, V3; YAGER RR, 2001, MII2111 ION COLL MAC	4	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7280-8				2002							680	684				5	Computer Science, Artificial Intelligence	Computer Science	BU95M	WOS:000177476600121	
B	Hullermeier, E			IEEE; IEEE	Hullermeier, E			Exploiting similarity and experience in decision making	PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2			English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 12-17, 2002	HONOLULU, HI	IEEE, IEEE Neural Network Soc				The idea of case-based decision making has recently been proposed as an alternative to expected utility theory. A case-based decision maker learns by storing already experienced decision problems, along with a rating of the results. Whenever a new problem needs to be solved, possible actions are assessed on the basis of experience from similar situations in which these actions have already been applied. In this paper, we consider case-based decision making within the context of instance-based learning, which is a special type of machine learning method. This consideration makes us suggest alternative case-based decision principles. These principles are motivated from a computational point of view and characterized axiomatically. Moreover, the possibility of applying case-based decision making in approximate reasoning is briefly touched on.	Univ Dortmund, Dept Comp Sci, D-4600 Dortmund, Germany	Hullermeier, E (reprint author), Univ Dortmund, Dept Comp Sci, D-4600 Dortmund, Germany.						Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; ELLSBERG D, 1961, Q J ECON, V75, P643, DOI 10.2307/1884324; Gilboa I, 1996, GAME ECON BEHAV, V15, P1, DOI 10.1006/game.1996.0056; Gilboa I, 1998, ECAI 1998: 13TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P706; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Morgenstern O., 1953, THEORY GAMES EC BEHA; Savage L., 1954, FDN STAT; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Simon H, 1957, MODELS MAN; Simon H., 1958, ORGANIZATIONS; Tversky A., 1986, J BUS, V59, P251	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7280-8				2002							729	734				6	Computer Science, Artificial Intelligence	Computer Science	BU95M	WOS:000177476600130	
B	Domeniconi, C; Gunopulos, D		Grossman, R; Han, J; Motwani, R; Kumar, V; Mannila, H		Domeniconi, C; Gunopulos, D			Efficient local flexible nearest neighbor classification	PROCEEDINGS OF THE SECOND SIAM INTERNATIONAL CONFERENCE ON DATA MINING	SIAM PROCEEDINGS SERIES		English	Proceedings Paper	2nd SIAM International Conference on Data Mining (SDM 02)	APR 11-13, 2002	ARLINGTON, VA	SIAM			REGRESSION	The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. The employment of a local adaptive metric becomes crucial in order to keep class conditional probabilities close to uniform, and therefore to minimize the bias of estimates. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence, together with a formal justification, of classification performance improvement over the SVM algorithm alone and over a variety of adaptive learning schemes, by using both simulated and real data sets. Moreover, the proposed method has the important advantage of superior efficiency over the most competitive technique used in our experiments.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Domeniconi, C (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.						Aha D. W., 1997, ARTIF INTELL, V11, P1; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; Brown M., 1999, KNOWLEDGE BASED ANAL; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2001, ADV NEURAL INFORMATI, V14; DOMENICONI C, 2000, ADV NEURAL INFORMATI, V13; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Ho T.K., 1998, LECT NOTES COMPUTER, P640; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P EUR C MACH LEARN; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Osuna E., 1997, P COMP VIS PATT REC; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING	23	0	0	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA		0-89871-517-2	SIAM PROC S			2002							353	369				17	Computer Science, Artificial Intelligence	Computer Science	BU81X	WOS:000177123500021	
S	Sanchez, JS; Barandela, R; Ferri, FJ		Escrig, MT; Toledo, F; Golobardes, E		Sanchez, JS; Barandela, R; Ferri, FJ			On filtering the training prototypes in nearest neighbour classification	TOPICS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th Catalonian Conference on Artificial Intelligence	OCT 24-25, 2002	CASTELLON, SPAIN	Asociacio Catalana Intelligencia Artificial, British Petr Oil Castellon, Univ Jaume I, Dept Ingn Ciencia Computadores, Fdn Caixa Castello Bancaixa, Generalitat Valenciana, Minist Educ & Ciencia			LEARNING ALGORITHMS; SELECTION; CLASSIFIERS; DESIGN; GRAPHS; RULE	Filtering (or editing) is mainly effective in improving the classification accuracy of the Nearest Neighbour (NN) rule, and also in reducing its storage and computational requirements. This work reviews some well-known editing algorithms for NN classification and presents alternative approaches based on combining the NN and the, Nearest Centroid Neighbourhood of a sample. Finally, an empirical analysis over real data sets is provided.	U Jaume I, Dept Llenguatges & Sistemes Informat, Castello 12071, Spain; Inst Tecnol Toluca, Metepec 52140, Mexico; Univ Valencia, Dept Informat, E-46100 Burjassot, Valencia, Spain	Sanchez, JS (reprint author), U Jaume I, Dept Llenguatges & Sistemes Informat, Castello 12071, Spain.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Barandela R, 2000, LECT NOTES COMPUT SC, V1876, P621; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P11, DOI 10.1016/0167-8655(95)00093-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; FERRI FJ, 1998, LECT NOTES COMPUTER, V1451, P620; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Hand DJ, 1997, CONSTRUCTION ASSESSM; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Liu H., 1998, FEATURE SELECTION KN; Merz C.J., 1998, UCI REPOSITORY MACHI; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	33	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-00011-9	LECT NOTES ARTIF INT			2002	2504						239	248				10	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	BW66V	WOS:000182749300021	
S	Wada, Y; Kasuga, H; Sumita, K		Kasturi, R; Laurendeau, D; Suen, C		Wada, Y; Kasuga, H; Sumita, K			An evolutionary approach for the generation of diversiform characters using a handwriting model	16TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL III, PROCEEDINGS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	16th International Conference on Pattern Recognition (ICPR)	AUG 11-15, 2002	QUEBEC CITY, CANADA	Int Assoc Pattern Recognit, Canadian Image Processing & Pattern Recognit Soc, Ctr Rech Informat Montreal, Matrox Imaging, Ind & Commerce Quebec, Rech, Sci & Technol Quebec, Microsoft Res, Bell, Lab Vis & Syst Numer, Comp Vis & Syst Lab, Ctr Pattern Recognit & Machine Intelligence, Ctr Etudes Reconnaissance Formes & Intelligence Artificielle, Scribers, Coreco Imaging, Precarn			ARM	In pattern recognition, a large number of diversiform characters is necessary to train / test a handwritten character recognition system. However it is not easy to collect a large number of natural samples. The artificial diversification of characters has been suggested as one means of collecting a variety of characters[1]. In this paper, we show that a handwriting model can be applied to the diversification of characters. The characters diversified by the model can be used as a database of character images for training / testing purposes. Wada & Kawato's handwriting model [2] is based on an optimal principle and the feature space of the characters includes sets of via-points extracted from actual handwritten characters. The handwriting model can be used to generate a variety of characters by changing via point information. In this paper we propose a method for generating a large variety of characters by changing via-point information based on a genetic algorithm and we show that the accuracy of a handwritten character recognition system that uses the characters generated by the proposed method as the training data, is equivalent to that of a system composed by using natural data.	Nagaoka Univ Technol, Nagaoka, Niigata 94021, Japan	Wada, Y (reprint author), Nagaoka Univ Technol, 1603-1, Nagaoka, Niigata 94021, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELMAN S, 1987, BIOL CYBERN, V57, P25, DOI 10.1007/BF00318713; FLASH T, 1985, J NEUROSCI, V5, P1688; Ghosh D, 1999, PATTERN RECOGN, V32, P907, DOI 10.1016/S0031-3203(98)00114-9; GLUCKSMAN H, 1967, IEEE COMP C, P138; HASE H, 1988, IEICE T D, V71, P1048; ISHII K, 1983, IEICE D, V66, P1270; Mori K., 1973, P 1 INT JOINT C PATT, P50; Nakano E, 1999, J NEUROPHYSIOL, V81, P2140; Nilsson Nils J., 1965, LEARNING MACHINES; Plamondon R, 1998, BIOL CYBERN, V78, P119, DOI 10.1007/s004220050419; WADA Y, 1995, BIOL CYBERN, V73, P3, DOI 10.1007/BF00199051	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-1695-X	INT C PATT RECOG			2002							131	134				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BV12Q	WOS:000177887100032	
S	Paredes, R; Vidal, E; Keysers, D		Kasturi, R; Laurendeau, D; Suen, C		Paredes, R; Vidal, E; Keysers, D			An evaluation of the WPE algorithm using tangent distance.	16TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITON, VOL IV, PROCEEDINGS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	16th International Conference on Pattern Recognition (ICPR)	AUG 11-15, 2002	QUEBEC CITY, CANADA	Int Assoc Pattern Recognit, Canadian Image Processing & Pattern Recognit Soc, Ctr Rech Informat Montreal, Matrox Imaging, Ind & Commerce Quebec, Rech, Sci & Technol Quebec, Microsoft Res, Bell, Lab Vis & Syst Numer, Comp Vis & Syst Lab, Ctr Pattern Recognit & Machine Intelligence, Ctr Etudes Reconnaissance Formes & Intelligence Artificielle, Scribers, Coreco Imaging, Precarn		editing; condensing; Nearest Neighbour; weighted prototypes; tangent distance		Weighting Prototype Editing (WPE) is a novel approach to edit a given set of prototypes so that the resulting set can outperform the original one in terms of the Nearest Neighbor (NN) classification accuracy This technique is applied in this work along with tin interesting dissimilarity measure between pixel maps, known as Tangent Distance (TD). Experiments on the USPS handwriting digits benchmark corpus are presented, with results showing the capability of the WPE to improve the already good results based on TD NN classification.	Univ Politecn Valencia, Inst Tecnol Informat, E-46071 Valencia, Spain	Paredes, R (reprint author), Univ Politecn Valencia, Inst Tecnol Informat, E-46071 Valencia, Spain.	rparedes@iti.upv.es; evidal@iti.upv.es; keysers@I6.Informatik.RWTH-Aachen.DE					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE G, 1995, PROBABILISTIC THEORY; KEYSERS D, 2001, LNCS, V2167, P263; Keysers D., 2000, P 15 INT C PATT REC, V2, P38, DOI 10.1109/ICPR.2000.906014; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; PAREDES R, 2000, 15 INT C PATT REC 15; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	11	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-1695-X	INT C PATT RECOG			2002							48	51				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BV12R	WOS:000177887500011	
S	Demiros, I; Antonopoulos, V; Georgantopoulos, B; Triantafyllou, Y; Piperidis, S			IEEE; IEEE; IEEE; IEEE	Demiros, I; Antonopoulos, V; Georgantopoulos, B; Triantafyllou, Y; Piperidis, S			Connectionist models for sentence-based text extracts	2001 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-5: E-SYSTEMS AND E-MAN FOR CYBERNETICS IN CYBERSPACE	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics (SMC)	OCT 07-10, 2001	TUCSON, AZ	IEEE, Raytheon		summarization; term extraction; statistical filtering; self-organizing maps; neural networks		This paper addresses the problem of creating a summary by extracting a set of sentences that are likely to represent the content of a document. A small scale experiment is conducted leading to the compilation of an evaluation corpus for the Greek language. Two models of sentence extraction are then described, along the lines of shallow linguistic analysis, feature combination and machine learning. Both models are based on term extraction and statistical filtering. After extracting the individual features of the text, we apply them to two neural networks that classify each sentence depending on its feature vector, the term weight being the feature with the best discriminant capacity. A three-layer feedforward network trained with the highly popular backpropagation algorithm and a competitive learning self-organizing reap characterized by the formation of a topographic map, both trained on a small manually annotated corpus of summaries, perform the sentence extraction task. Both methods could be used for rapid light information retrieval-oriented summarization.	Inst Language & Speech Proc, Athens 15125, Greece	Demiros, I (reprint author), Inst Language & Speech Proc, Artemidos 6 & Epidavrou, Athens 15125, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AONE C, 1998, P 36 ANN M ASS COMP, P62; Barzilay R., 1997, P ACL WORKSH INT SCA, P10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2000, TIMBL; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; FIRMIN T, 1998, ADV AUTOMATIC TEXT S, P325; FUM D, 1985, P 9 INT JOINT C ART, P840; GAVRILIDOU M, 1999, LREI62048; HAYKIN S, 1999, NEURAL NETWORKS COMP; Jones K.S., 1998, ADV AUTOMATIC TEXT S, P1; Kohonen T., 2000, IEEE T NEURAL NETWOR, V11; KOHONEN T, 1989, SELF ORGANIZATION AS; KUPIEC J, 1995, P 18 ACM SIGIR C, P88; LEHNERT W, 1981, 7 INT JOINT C ART IN; LIN X, 1991, P ANN INT CM SIGIR C; LUHN HP, 1958, IBM J RES DEV, V2, P159; MARCU D, 1997, ACL EACL 97 SUMM WOR, P82; MITCHELL T, 1997, MACHINGE LEARNING; Mittal V., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); MORRIS A, 1998, ADV AUTOMATIC TEXT S, P305; MYAENG SH, 1998, ADV AUATOMATIC TEXT, P61; Nguyen D., 1990, P INT JOINT C NEUR N; PIPERIDIS S, 1999, ASLIB TRANSLATING CO; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SKOUSEN R, 1989, ANAL MODELING LANGUA; STANFILL C, 1986, COMMUN ACM, V29, P1212; TEUFEL S, 1998, ADV AUTOMATIC TEXT S, P155; Zechner K., 1996, P 16 INT C COMP LING, P986	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	0-7803-7087-2	IEEE SYS MAN CYBERN			2002							2648	2653				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BU92K	WOS:000177404200464	
B	Tsiriga, V; Virvou, M			IEEE; IEEE	Tsiriga, V; Virvou, M			Dynamically initializing the student model in a web-based language tutor	2002 FIRST INTERNATIONAL IEEE SYMPOSIUM INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS			English	Proceedings Paper	1st International IEEE Symposium on Intelligent Systems	SEP 10-12, 2002	VARNA, BULGARIA	IEEE Control Syst Soc, IEEE Instrumentat & Measurement Soc, IEEE Reg 8, Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, IEE IM CS SMC Joint Chapter Bulgaria, IEEE Sect Bulgaria, ICT Dev Agcy, EUNITE		intelligent tutoring systems; student model initialization; distance weighted k-nearest neighbor; stereotypes	MULTISTRATEGY	In this paper we describe the method for initializing the student model in a Web-based language tutor. This tutor is an Intelligent Tutoring System (ITS) that operates on the WWW and aims at teaching non-native speakers the domain of the passive voice of the English language. It uses an innovative combination of stereotypes and the distance weighted k-nearest neighbor algorithm to initialize the model of a new student. In particular, the student is first assigned to a stereotype category concerning her/his knowledge level based on her/his performance on a preliminary test. The system then initializes all aspects of the student model using the distance weighted k-nearest neighbor algorithm among the students that belong to the same stereotype category with the new student. The basic idea of the algorithm is to weigh the contribution of each of the neighbor students according to their distance from the new student; the distance between students is calculated based on a similarity measure. In our case the similarity measure is estimated taking into account the students' mother tongue, how careful they are when solving exercises, as well as their knowledge of other languages. This information is acquired directly by the student at her/his first interaction with the system.	Univ Piraeus, Dept Informat, Piraeus 18534, Greece	Tsiriga, V (reprint author), Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Baffes P., 1996, Journal of Artificial Intelligence in Education, V7; Ballim A., 1991, User Modeling and User-Adapted Interaction, V1, DOI 10.1007/BF00158951; Burr Ridge I, 1997, MACHINE LEARNING; Burton R. B., 1982, INTELLIGENT TUTORING, P157; CHIN DN, 1989, USER MODELS DIALOG S, P74; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Emde W., 1996, P 13 INT C MACH LEAR, P122; Hoppe H. U., 1994, Journal of Artificial Intelligence in Education, V5; HUANG X, 1991, USER MODEL USER-ADAP, V1, P87, DOI 10.1007/BF00158953; Kay J, 2000, LECT NOTES COMPUT SC, V1839, P19; Kono Y., 1994, Journal of Artificial Intelligence in Education, V5; Langley P., 1984, P NATIONAL C ARTIFIC, P193; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MICHAUD LN, 2001, P 8 INT C US MOD SON, P14; MURPHY M, 1997, P 6 INT C US MOD, P301; RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8; Rich E., 1979, COGNITIVE SCI, V3, P329, DOI DOI 10.1207/515516709C0G0304_3; Sison R, 1998, INT J ARTIFICIAL INT, V9, P128; Sison R, 1998, USER MODEL USER-ADAP, V8, P103, DOI 10.1023/A:1008225015395; Sison RC, 2000, MACH LEARN, V38, P157, DOI 10.1023/A:1007690108308; SLEEMAN D, 1987, ARTIFICIAL INTELIGEN; Virvou M, 2001, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P131; Weber G., 1997, P 6 INT C US MOD, P289; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	27	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7601-3				2002							138	143				6	Computer Science, Artificial Intelligence	Computer Science	BW08J	WOS:000180818600024	
B	Lazzerini, B; Marcelloni, F		Zakharevich, VG; Kureichik, VM		Lazzerini, B; Marcelloni, F			K-NN algorithm based on neural similarity	2002 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE SYSTEMS, PROCEEDINGS			English	Proceedings Paper	IEEE International Conference on Artificial Intelligence Systems (ICAIS 2002)	SEP 05-10, 2002	DIVNOMORSKOE, RUSSIA	IEEE Comp Soc, Minist Educ Russian Federat, Taganrog State Univ Radio Engn, World Federat Sof Comp, Russian Assoc Artificial Intelligence, Russian Fdn Basic Res, Russian Acad Nat Sci				The aim of this paper is to present a k-nearest neighbour (k-NN) classifier based on a neural model of the similarity measure between data. After a preliminary phase of supervised learning for similarity determination, we use the neural similarity measure to guide the k-NN rule. Experiments on both synthetic and real-world data show that the similarity-based k-NN rule outperforms the Euclidean distance-based k-NN rule.	Univ Pisa, Dipartimento Ingn Informaz, I-56122 Pisa, Italy	Lazzerini, B (reprint author), Univ Pisa, Dipartimento Ingn Informaz, Via Diotisalvi 2, I-56122 Pisa, Italy.						Aha D., 1998, FEATURE EXTRACTION C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Jain A., 1999, ACM COMPUT SURV, V31, P265; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Kohonen T., 1989, SELF ORG ASS MEMORY; MICHALSKI RS, 1983, IEEE T PATTERN ANAL, V5, P396; PEDYCZ W, 2001, P 2 INT WORKSH SOFT; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1733-1				2002							67	70				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BV23P	WOS:000178285500014	
B	Vasilic, S; Kezunovic, M			IEEE; IEEE	Vasilic, S; Kezunovic, M			An improved neural network algorithm for classifying the transmission line faults	2002 IEEE POWER ENGINEERING SOCIETY WINTER MEETING, VOLS 1 AND 2, CONFERENCE PROCEEDINGS			English	Proceedings Paper	Winter Meeting of the IEEE-Power-Engineering-Society	JAN 27-31, 2002	NEW YORK, NY	IEEE Power Engn Soc		clustering methods; electromagnetic transients; neural networks; pattern classification; power system faults; protective relaying; testing; training.	NETS	This study introduces a new concept of artificial intelligence based algorithm for classifying the faults in power system networks. This classification identifies the exact type and zone of the fault. The algorithm is based on unique type of neural network specially developed to deal with large set of highly dimensional input data. An improvement of the algorithm is proposed by implementing various steps of input signal preprocessing, through the selection of parameters for analog filtering, and values for the data window and sampling frequency. In addition, an advanced technique for classification of the test patterns is discussed and the main advantages comparing to previously used nearest neighbor classifier are shown.	Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA	Vasilic, S (reprint author), Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA.						BALL GH, 1967, BEHAV SCI, V12, P345; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kezunovic M, 1997, ENG INTELL SYST ELEC, V5, P185; Kezunovic M, 1996, IEEE COMPUT APPL POW, V9, P42, DOI 10.1109/67.539846; KEZUNOVIC M, 2001, CIGRE SC 34 C SIB RO; KEZUNOVIC M, 1995, ELECTR POW SYST RES, V34, P109, DOI 10.1016/0378-7796(95)00962-X; KEZUNOVIC M, 2001, IEEE PORT POW TECH C; KOHONEN T, 1997, SELF ORG MAPS, P426; PAO YH, 1989, ADAPTIVE PATTERN REC, P309; PAO YH, 1992, IEEE T POWER SYST, V7, P878, DOI 10.1109/59.141799; Udren EA, 1997, IEEE T POWER DELIVER, V12, P134, DOI 10.1109/61.568233; *CAN EMTP US GROUP, 1992, ALT TRANS PROGR ATP; *MATHW INC, 1999, US MATLAB	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7322-7				2002							918	923				6	Energy & Fuels; Engineering, Multidisciplinary	Energy & Fuels; Engineering	BV37Q	WOS:000178748500179	
B	van den Bosch, A; Buchholz, S			ACL	van den Bosch, A; Buchholz, S			Shallow parsing on the basis of words only: A case study	40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	40th Annual Meeting of the Association-for-Computational-Linguistics	JUL 07-12, 2002	Philadelphia, PA	Assoc Computat Linguist, Assoc Computat Linguist, N Amer Chapter, Linguist Data Consortium, Microsoft Res, Sun, 240 Teragram, AT&T, BASIS Technol, BBN Technologies, LexisNexis, Cornell	Univ Penn			We describe a case study in which a memory-based learning algorithm is trained to simultaneously chunk sentences and assign grammatical function tags to these chunks. We compare the algorithm's performance on this parsing task with varying training set sizes (yielding learning curves) and different input representations. In particular we compare input consisting of words only, a variant that includes word form information for low-frequency words, gold-standard POS only, and combinations of these. The word-based shallow parser displays an apparently log-linear increase in performance, and surpasses the flatter POS-based curve at about 50,000 sentences of training data. The low-frequency variant performs even better, and the combinations is best. Comparative experiments with a real POS tagger produce lower results. We argue that we might not need an explicit intermediate POS-tagging step for parsing when a sufficient amount of training material is available and word form information is used for low-frequency words.	Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands			van den Bosch, Antal/G-5072-2011	van den Bosch, Antal/0000-0003-2493-656X			Abney S., 1991, PRINCIPLE BASED PARS, P257; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AITMOKHTAR S, 1997, P ACL 97 WORKSH INF; ARGAMON S, 1998, P COLING ACL MONTR C, P67; BANKO M, 2001, P 39 ANN M 10 C EUR; Brill E., 1993, THESIS U PENNSYLVANI; BUCHHOLZ S, 1999, P JOINT SIGDAT C EMP, P239; CHARNIAK E., 2000, P 1 C N AM CHAPT ASS, P132; CHRUCH KW, 1988, P 2 APPL NLP ACL; Collins M, 1996, P 34 ANN M ASS COMP; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1997, 9 EUR C MACH LEARN P, P29; DAELEMANS W, 2001, TIMBL TILBURG MEMORY; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; DAELEMANS W, 1999, P CONLL BERG NORW; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; EISNER J, 1997, P 16 INT C COMP LING; FERRO L, 1999, P 3 COMP NAT LANG LE, P43; Kim Tjong, 2000, P CONLL 2000 LLL 200, P127; LI X, 2001, P 5 COMP NAT LANG LE; Marcus M, 1994, COMPUTATIONAL LINGUI, V19, P313; MUNOZ M, 1999, P 1999 JOINT SIGDAT, P168; Pollard C., 1987, CSLI LECT NOTES, V13; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ramshaw L. A., 1995, P 3 WORKSH VER LARG, P82; Ratnaparkhi A, 1997, P 2 C EMP METH NAT L, P1; RATNAPARKHI A, 1996, P C EMP METH NAT LAN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; VEENSTRA J, 2000, P CONLL 2000 LLL 200, P157; WEISS SM, 1991, COMPUTER SYSTEMS THA; ZAVREL J, 1997, P 7 BELG DUTCH C MAC, pR20	34	0	0	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA		1-55860-883-4				2002							433	440				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Statistics & Probability	Computer Science; Linguistics; Mathematics	BAP07	WOS:000223096700055	
B	Yoshioka, H; Shirato, Y; Toyoda, I; Umehira, M			IEEE; IEEE; IEEE	Yoshioka, H; Shirato, Y; Toyoda, I; Umehira, M			A fast modulation recognition technique using nearest neighbor rules with optimized threshold for modulation classification in Rayleigh fading channels	5TH INTERNATIONAL SYMPOSIUM ON WIRELESS PERSONAL MULTIMEDIA COMMUNICATIONS, VOLS 1-3, PROCEEDINGS			English	Proceedings Paper	5th International Symposium on Wireless Personal Multimedia Communications	OCT 27-30, 2002	HONOLULU, HI	Yokosuka Res Pk, CRL, IEEE, Lucent Technologies		automatic modulation recognition; threshold for symbol selection; Rayleigh fading channels; Nearest Neighbor (NN) rules		This paper describes a fast modulation recognition technique for use in Rayleigh fading channels. To achieve fast and accurate modulation recognition, we propose the optimum threshold for symbol selection in fading channels. The result is a 20% reduction in recognition time with high recognition accuracy.								COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Higashida Y., 1988, Transactions of the Institute of Electronics, Information and Communication Engineers B, VJ71B; ISHII H, 1998, RCS9871 IEICE; ROLAND C, 2001, IST MOBILE COMMUNICA; TAIRA S, 2000, P VTC2000 SPR, V3, P1717; Umebayashi K., 2000, P PIMRC 2000, V1, P43; YOSHIOKA H, 2001, P ISSSE 01 TOK JAP, P212	7	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7442-8				2002							1049	1052				4	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BV58Q	WOS:000179449100210	
B	Inakoshi, H; Ando, T; Sato, A; Okamoto, S			IEEE	Inakoshi, H; Ando, T; Sato, A; Okamoto, S			Discovery of emerging patterns from nearest neighbors	2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	NOV 04-05, 2002	BEIJING, PEOPLES R CHINA	IEEE, SMC, Hebei Univ, Machine Learning Ctr				In this paper, we propose a scalable classifier that uses jumping emerging patterns (JEPs), which are combinations of values that occur in one class. The original classifier, DeEPs, is an instance-based classifier that operates on all instances in real-time. It discovers maximal patterns that occur throughout the entire database and identifies JEPs by using these patterns. The necessary computational effort, though, is likely to increase when DeEPs is applied to a large database. Our proposed classifier operates on the nearest neighbors of a test instance. This reduction of instances improves scalability as the database volume increases. Moreover, our classifier imposes a restriction regarding JEPs discovery, so that it excludes patterns that cannot be identified as either correct JEPs or JEPs caused by the maximal patterns missing from nearest neighbors. These probably incorrect JEPs are specialized with additional items and participate in class determination. Our classifier performs significantly faster with these two enhancements, while it remains as accurate as the original classifier.	Fujitsu Labs Ltd, Mihama Ku, Chiba 2618588, Japan	Inakoshi, H (reprint author), Fujitsu Labs Ltd, Mihama Ku, 9-3 Nakase 1 Chome, Chiba 2618588, Japan.						Agrawal R., 1994, P 20 INT C VER LARG; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Iba W., 1992, P 10 NAT C ART INT, P223; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; LI J, 2000, DEEPS NEW INSTANCE B; OKAMOTO S, 1997, P 2 INT C CAS BAS RE, P349; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7508-4				2002							1920	1925				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BW27J	WOS:000181396300419	
J	Holst, M; Irle, A				Holst, M; Irle, A			Nearest neighbor classification with dependent training sequences	ANNALS OF STATISTICS			English	Article						nearest neighbor classification; asymptotic risk; dependent training samples	DENSITY-ESTIMATION; CONSISTENCY; REGRESSION	The asymptotic classification risk for nearest neighbor procedures is well understood in the case of i.i.d. training sequences. In this article, we generalize these results to a class of dependent models including hidden Markov models. In the case where the observed patterns have Lebesgue densities, the asymptotic risk takes the same expression as in the i.i.d. case. For discrete distributions, we show that the asymptotic risk depends on the rule used for breaking ties of equal distances.	Univ Kiel, Math Seminar, D-24908 Kiel, Germany	Holst, M (reprint author), Univ Kiel, Math Seminar, Ludewig Meyn Str 4, D-24908 Kiel, Germany.						Adams TM, 1998, ANN PROBAB, V26, P794; Bickel PJ, 1998, ANN STAT, V26, P1614; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR CLA; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Fix E, 1951, DISCRIMINATORY ANAL; Fix E., 1952, DISCRIMINATORY ANAL; GYORFI L, 1992, COMPUT STAT DATA AN, V14, P437, DOI 10.1016/0167-9473(92)90059-O; Huang X., 1990, HIDDEN MARKOV MODELS; Irle A, 1997, J MULTIVARIATE ANAL, V60, P123, DOI 10.1006/jmva.1996.1647; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Leadbetter M.R., 1983, EXTREMES RELATED PRO; MacDonald I. L., 1997, HIDDEN MARKOV OTHER; Morvai G, 1996, ANN STAT, V24, P370; Nobel AB, 1998, IEEE T INFORM THEORY, V44, P537, DOI 10.1109/18.661503; SHANNON CE, 1951, AT&T TECH J, V30, P50; Smith D K, 1994, Qual Health Care, V3, P75, DOI 10.1136/qshc.3.2.75; Snapp RR, 1998, ANN STAT, V26, P850; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Vieu P., 1989, LECT NOTES STAT, V60; Wheeden R. L., 1977, MEASURE INTEGRAL	26	2	2	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0090-5364		ANN STAT	Ann. Stat.	OCT	2001	29	5					1424	1442				19	Statistics & Probability	Mathematics	513DB	WOS:000173361700010	
J	Picard, RW; Vyzas, E; Healey, J				Picard, RW; Vyzas, E; Healey, J			Toward machine emotional intelligence: Analysis of affective physiological state	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						emotion recognition; physiological patterns; feature selection; Fisher Projection; affective computing; emotional intelligence	FACIAL EXPRESSIONS; FEATURE-SELECTION; IMAGE-ANALYSIS; FACE	The ability to recognize emotion is one of the hallmarks of emotional intelligence, an aspect of human intelligence that has been argued to be even more important than mathematical and verbal intelligences. This paper proposes that machine intelligence needs to include emotional intelligence and demonstrates results toward this goal: developing a machine's ability to recognize human affective state given four physiological signals. We describe difficult Issues unique to obtaining reliable affective data and collect a large set of data from a subject trying to elicit and experience each of eight emotional states, daily, over multiple weeks. This paper presents and compares multiple algorithms for feature-based recognition of emotional state from this data. We analyze four physiological signals that exhibit problematic day-to-day variations: The features of different emotions on the same day tend to cluster more tightly than do the features of the same emotion on different days. To handle the daily variations, we propose new features and algorithms and compare their performance, We find that the technique of seeding a Fisher Projection with the results of Sequential Floating Forward Search improves the performance of the Fisher Projection and provides the highest recognition rates reported to date for classification of affect from physiology: 81 percent recognition accuracy on eight classes of emotion, including neutral.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; MIT, Media Lab, Cambridge, MA 02139 USA	Picard, RW (reprint author), MIT, Media Lab, 20 Ames St, Cambridge, MA 02139 USA.						Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614; Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037//0022-3514.37.11.2049; Cacioppo J., 2000, HDB EMOTIONS, P173; CACIOPPO JT, 1990, AM PSYCHOL, V45, P16, DOI 10.1037/0003-066X.45.1.16; Cannon WB, 1927, AM J PSYCHOL, V39, P106, DOI 10.2307/1415404; Chen L. S., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670976; CLYNES DM, 1977, SENTICS TOUCH EMOTIO; Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damasio A. R., 1994, DESCARTES ERROR EMOT; Dawson M, 1990, PRINCIPLES PSYCHOPHY, P295; De Silva L. C., 1997, Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat. No.97TH8237), DOI 10.1109/ICICS.1997.647126; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Duda R., 1973, PATTERN CLASSIFICATI; EKMAN P, 1983, SCIENCE, V221, P1208, DOI 10.1126/science.6612338; ESSA I, 1997, P WORKSH PERC US INT, P45; ESSA IA, 1995, THESIS MIT MED LAB; Fridlund A. J., 1983, SOCIAL PSYCHOPHYSIOL, P243; Goleman D., 1995, EMOTIONAL INTELLIGEN; HAMA H, 1990, PERCEPT MOTOR SKILL, V70, P371; HANSEN J, 1999, P INT C AC SPEECH SI; HEALEY J, 1998, P IEEE INT C AC SPEE; HEALEY J, 1998, P WORKSH PERC US INT; HEALEY JA, 2000, 526 MIT; HUANG TS, 1998, P ATR WORKSH VIRT CO; IZARD CE, 1993, PSYCHOL REV, V100, P68, DOI 10.1037//0033-295X.100.1.68; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; James W., 1992, W JAMES WRITINGS 187, P350; Keltner D., 2000, HDB EMOTIONS, P236; LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037//0003-066X.50.5.372; LeDoux J., 1996, EMOTIONAL BRAIN; LYYKEN DT, 1966, PSYCHOPHYSIOLOGICAL, V66, P481; LYYKEN DT, 1971, PSYCHOPHYSIOLOGY, V8, P656; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; Picard R., 1997, AFFECTIVE COMPUTING; Picard R. W., 1997, PERSONAL TECHNOLOGIE, V1, P231, DOI 10.1007/BF01682026; POLZIN T, 2000, THESIS SCH COMP SCI; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PUDIL P, 1994, IMAGE VISION COMPUT, V12, P193, DOI 10.1016/0262-8856(94)90072-8; Reeves B., 1996, MEDIA EQUATION; Salovey P., 1990, IMAGINATION COGNITIO, V9, P185, DOI DOI 10.2190/DUGG-P24E-52WK-6CDG; SCHACHTER S, 1964, ADV EXP SOC PSYCHOL, V1, P49, DOI 10.1016/S0065-2601(08)60048-9; SCHEIRER J, 2001, IN PRESS INTERACTION; Scherer KR, 1981, SPEECH EVALUATION PS, P189; SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570; Sigman M. D., 1997, CHILDREN AUTISM DEV; VYZAS E, 1998, P AAAI 1998 FALL S E; VYZAS E, 1999, P EM BAS AG ARCH 3 I, P135; WINTON WM, 1984, J EXP SOC PSYCHOL, V20, P195, DOI 10.1016/0022-1031(84)90047-7; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414	51	366	390	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1175	1191		10.1109/34.954607		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	482QK	WOS:000171586600011	
J	Divakaran, A; Radhakrishnan, R; Peker, KA				Divakaran, A; Radhakrishnan, R; Peker, KA			Video summarization using descriptors of motion activity: A motion activity based approach to key-frame extraction from video shots	JOURNAL OF ELECTRONIC IMAGING			English	Article							CLUSTERING METHODS; REPRESENTATION; VALIDITY	We describe a video summarization technique that uses motion descriptors computed in the compressed domain, It can either speed up conventional color-based video summarization techniques, or rapidly generate a key-frame based summary by itself. The basic hypothesis of the work is that the intensity of motion activity of a video segment is a direct indication of its "summarizability," which we experimentally verify using the MPEG-7 [MPEG-7 Visual Committee Draft URL: http.,//www.cselt.it/mpeg/working documents.htm official MPEG site] motion activity descriptor and the fidelity measure proposed in H. S. Chang, S. Sull, and S. U. Lee, "Efficient video indexing scheme for content-based retrieval, " IEEE Trans, Circuits Syst. Video Technol. 9(8), (1999). Note that the compressed domain extraction of motion activity intensity is much simpler than the color-based calculations. We are thus able to quickly identify easy to summarize segments of a video sequence since they have a low intensity of motion activity. We are able to easily summarize these segments by simply choosing their first frames. We can then apply conventional color-based summarization techniques to the remaining segments. We thus speed up color-based summarization by reducing the number of segments processed. Our results also motivate a simple and novel key-frame extraction technique that relies on a motion activity based nonuniform sampling of the frames. Our results indicate that it can either be used by itself or to speed up color-based techniques as explained earlier. (C) 2001 SPIE and IS&T.	Mitsubishi Elect Res Labs, Murray Hill, NJ 07834 USA; Polytech Univ, Brooklyn, NY 11201 USA	Divakaran, A (reprint author), Mitsubishi Elect Res Labs, 571 Cent Ave, Murray Hill, NJ 07834 USA.						AIGRAIN P, 1995, P SOC PHOTO-OPT INS, V2417, P35, DOI 10.1117/12.206061; AOKI H, 1996, P ACM MULT 96 BOST M; BEDNAR JB, 1984, IEEE T ACOUST SPEECH, V32, P145, DOI 10.1109/TASSP.1984.1164279; Bezdek J., 1981, PATTERN RECOGNITION; BORECZKY JS, 1998, P INT C AC SPEECH SI, V6, P3741, DOI 10.1109/ICASSP.1998.679697; Butler S, 1996, SIGNAL PROCESS-IMAGE, V8, P269, DOI 10.1016/0923-5965(95)00052-6; Cios K., 1998, DATA MINING METHODS; COLL DC, 1976, IEEE T COMMUN, V27, P1201; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EICKELER S, 1999, P ICASSP PHOEN MAR, V6, P2999; FERMAN AM, 1999, P IEEE ICIP KOB JAP; FERMAN AM, UNPUB IEEE T IMAGE P; FERMAN AM, 1998, P SOC PHOTO-OPT INS, V3312, P71; Ferman AM, 1998, J VIS COMMUN IMAGE R, V9, P336, DOI 10.1006/jvci.1998.0402; Fischer S., 1995, P ACM MULT 95 SAN FR, P295, DOI 10.1145/217279.215283; Han J. H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.784711; Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162; ISENHOUR JP, 1975, AV COMMUN REV, V23, P69; Jensen FV, 1996, INTRO BAYESIAN NETWO; Kasturi R, 1991, COMPUTER VISION PRIN, P469; KAWIN BF, 1987, MOVIES WORK; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kuncheva LI, 1998, INT J UNCERTAIN FUZZ, V6, P437, DOI 10.1142/S0218488598000355; MARTIENZ JM, 2001, JTC1SC29WG11N4031 IS; MILLERSON G, 1990, TECHNIQUE TELEVISION; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; Salt B, 1992, FILM STYLE TECHNOLOG; Tou J.T., 1974, PATTERN RECOGNITION; VASCONCELOS N, 1998, P IEEE INT C IM PROC, V3, P153, DOI 10.1109/ICIP.1998.999006; W3C, 2001, XML SCHEM; WOLF W, 1997, P ICASSP, V4, P2609; WORTH S, 1968, AV COMMUN REV, V16, P121; Xie X.L., 1991, IEEE T PAMI, V3, P841; Yeung M. M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.546973; YEUNG MM, 1995, INT C IM PROC, V1, P338; YEUNG MM, 1995, P SOC PHOTO-OPT INS, V2417, P399, DOI 10.1117/12.206067; Zhang H. J., 1993, ACM MULTIMEDIA SYSTE, V1, P10; Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800; *ISO IEC, 2001, JTC1SC29WG11N4002 IS; *ISO IEC, 2001, JTC1SC29WG11N3966 IS; *ISO IEC, 2001, JTC1SC29WG11N4062 IS; *MPEG7 VID GROUP, 1999, JTC1SC29WG11N2466 IS	42	17	18	I S & T - SOC IMAGING SCIENCE TECHNOLOGY	SPRINGFIELD	7003 KILWORTH LANE, SPRINGFIELD, VA 22151 USA	1017-9909		J ELECTRON IMAGING	J. Electron. Imaging	OCT	2001	10	4					909	929		10.1117/1.1406507		21	Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Engineering; Optics; Imaging Science & Photographic Technology	495RY	WOS:000172355200008	
J	Sbai, EH				Sbai, EH			Cluster analysis by adaptive rank-order filters	PATTERN RECOGNITION			English	Article						cluster analysis; mode; probability density function (pdf); rank-order; entropy	MORPHOLOGY	An adaptive filter is proposed for detecting the modes of underlying probability density function of the data. The adaptive procedure is based on the selection of an appropriate rank order according to the local measurements of the entropy of the density function. The approach requires no a priori information about the structure of the data set but it is governed by the sampling parameter. Experiments demonstrate the usefulness of the filter. (C) 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Univ Moulay Ismail, Ecole Super Technol, Meknes 50006, Morocco	Sbai, EH (reprint author), Univ Moulay Ismail, Ecole Super Technol, Route Agouray,BP 3103, Meknes 50006, Morocco.						BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247; Brink AD, 1996, PATTERN RECOGN LETT, V17, P29, DOI 10.1016/0167-8655(95)00096-8; CACOULLOS T, 1966, ANN I STAT MATH, V18, P178; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society; David H., 1980, ORDER STAT; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L.P., 1985, NONPARAMETRIC DENSIT; DUDA RO, 1965, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; GOIN JE, 1982, PATTERN RECOGN, V15, P263, DOI 10.1016/0031-3203(82)90077-2; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532; JUSTUSSON BI, 1981, 2 DIMENSIONAL DIGITA, V2, P161; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663; POSTAIRE JG, 1993, IEEE T PATTERN ANAL, V15, P170, DOI 10.1109/34.192490; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Serra J., 1982, IMAGE ANAL MATH MORP; SHANNON CE, 1904, MATH THEORY COMMUNUC; VASSEUR CPA, 1980, IEEE T SYST MAN CYB, V10, P145; ZHANG RD, 1994, PATTERN RECOGN, V27, P135, DOI 10.1016/0031-3203(94)90023-X	26	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	OCT	2001	34	10					2015	2027		10.1016/S0031-3203(00)00130-8		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	462JP	WOS:000170417200012	
J	Li, WB; Friedland, W; Pomplun, E; Jacob, P; Paretzke, HG; Lassmann, M; Reiners, C				Li, WB; Friedland, W; Pomplun, E; Jacob, P; Paretzke, HG; Lassmann, M; Reiners, C			Track structures and dose distributions from decays of I-131 and I-125 in and around water spheres simulating micrometastases of differentiated thyroid cancer	RADIATION RESEARCH			English	Article							MONTE-CARLO SIMULATION; INTERNALIZING ANTIBODIES; RADIOACTIVE IODINE; I125 SEED; RADIATION; CARCINOMA; DOSIMETRY; RADIONUCLIDES; RADIOIODINE; THERAPY	The disintegration of the radionuclides I-131 and I-125 and the subsequent charged-particle tracks left behind in water (as a model substance for a biological cell) are simulated by the Monte Carlo track structure simulation code PARTRAC, using new inelastic electron scattering cross sections for condensed water. Every photon and electron emitted was followed in detail, event by event, down to 10 eV. From the spatial information on the track structures, absorbed dose distributions per I-131 and I-121 decay were calculated in and around water spheres simulating micrometastases as well as in the tissue surrounding such metastases. These radionuclides were assumed to be distributed uniformly inside spheres of different diameters (0.01, 0.03, 0.1, 0.3, 1.0 and 3.0 nun). The respective electron degradation spectra, the nearest-neighbor distance distributions between inelastic events, and the distance distributions for all activations for both iodine radionuclides were calculated. The absorbed fractions of the initial electron energies, absorbed doses and energy depositions, and single-event distributions, F-1(epsilon), inside the six water spheres described above and in the surrounding tissue were also calculated. The absorbed doses per decay inside the six water spheres, i.e., the calculated S values (listed from 0.01 to 3.0 nun), were 6.8 x 10(-4), 7.2 x 10(-5), 5.5 x 10(-6), 4.9 x 10(-7), 3.1 x 10(-8) and 1.8 x 10(-9) Gy Bq(-1) s(-1) for I-131, and 3.4 x 10(-3), 1.7 x 10(-4), 5.1 x 10(-6), 2.0 x 10(-1), 5.6 x 10(-9) and 2.2 x 10(-11) Gy Bq(-1) s(-1) for I-125. It is concluded that in the treatment of thyroid cancer, the geometrical track structure properties of I-125 might be superior to those of I-131 in micrometastases with diameters less than 0.1 nun; however, in this medical context, many other factors also have to be considered. (C) 2001 by Radiation Research Society.	Inst Radiat Protect, Natl Res Ctr Environm & Hlth, GSF, D-85764 Neuherberg, Germany	Li, WB (reprint author), Inst Radiat Protect, Natl Res Ctr Environm & Hlth, GSF, D-85764 Neuherberg, Germany.		Lassmann, Michael/B-2284-2013				AKABANI G, 1991, J NUCL MED, V32, P835; BEARDEN JA, 1967, REV MOD PHYS, V39, P125, DOI 10.1103/RevModPhys.39.125; Behr TM, 1998, INT J CANCER, V76, P738, DOI 10.1002/(SICI)1097-0215(19980529)76:5<738::AID-IJC20>3.0.CO;2-Z; Behr TM, 2000, EUR J NUCL MED, V27, P753, DOI 10.1007/s002590000272; BEHRENS H, 1969, LANDOLTBORNSTEIN NUM, V4; BEIERWALTES WH, 1979, SEMIN NUCL MED, V9, P151, DOI 10.1016/S0001-2998(79)80023-9; BEIERWALTES WH, 1978, SEMIN NUCL MED, V8, P95, DOI 10.1016/S0001-2998(78)80010-5; BEIERWALTES WH, 1978, SEMIN NUCL MED, V8, P79, DOI 10.1016/S0001-2998(78)80009-9; BENUA RS, 1962, AMER J ROENTGENOL RA, V87, P171; BERGER MJ, 1971, DISTRIBUTION ABSORBE; BOOZ J, 1987, RADIAT ENVIRON BIOPH, V26, P151, DOI 10.1007/BF01211409; BURNS GS, 1988, MED PHYS, V15, P56, DOI 10.1118/1.596151; CHARLTON DE, 1981, RADIAT RES, V87, P10, DOI 10.2307/3575537; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS WG, 1983, PHYS MED BIOL, V28, P1251, DOI 10.1088/0031-9155/28/11/005; DALE RG, 1983, MED PHYS, V10, P176, DOI 10.1118/1.595297; DILLMAN MJ, 1980, TM6689 ORNL; Dingfelder M, 1998, RADIAT PHYS CHEM, V53, P1; Dottorini ME, 1997, J NUCL MED, V38, P669; Evans R. D, 1956, ATOMIC NUCL; Friedland W, 1998, RADIAT RES, V150, P170, DOI 10.2307/3579852; Goddu S M, 1997, MIRD CELLULAR S VALU; GODDU SM, 1994, J NUCL MED, V35, P521; Govindan SV, 2000, J NUCL MED, V41, P2089; Hartman T, 2000, INT J RADIAT ONCOL, V46, P1025, DOI 10.1016/S0360-3016(99)00476-9; HENSS S, 1992, BIOPHYSICAL MODELLIN, P67; JUNGERMAN JA, 1984, INT J APPL RADIAT IS, V35, P883, DOI 10.1016/0020-708X(84)90025-5; KONOPINSKY EJ, 1965, ALPHA BETA GAMMA RAY, V2, P1327; KRISHNASWAMY V, 1978, RADIOLOGY, V126, P489; LING CC, 1985, MED PHYS, V12, P652, DOI 10.1118/1.595689; LOEVINGE.R, 1968, PHYS MED BIOL, V13, P205, DOI 10.1088/0031-9155/13/2/306; Loevinger R, 1988, MIRD PRIMER ABSORBED; Maxon HR, 1997, THYROID, V7, P183, DOI 10.1089/thy.1997.7.183; MAXON HR, 1992, J NUCL MED, V33, P1132; Paretzke H G, 1987, KINETICS NONHOMOGENE, P89; POMPLUN E, 1987, RADIAT RES, V111, P533, DOI 10.2307/3576938; REINERS C, 1996, THYR ID MERCK EUR TH, P89; REINERS CHR, 1999, RAD THYROID CANC, P407; ROSSI HH, 1996, MICRODOSIMETRY ITS A; SAENGER EL, 1979, SEMIN NUCL MED, V9, P72, DOI 10.1016/S0001-2998(79)80038-0; SCHLESINGER T, 1989, RADIOTHER ONCOL, V14, P35, DOI 10.1016/0167-8140(89)90006-6; SCHLUMBERGER M, 1987, J CLIN ENDOCR METAB, V65, P1088; SINCLAIR WK, 1956, BRIT J RADIOL, V29, P36; SISSON J, 1997, THYROID, V7, P312; Stabin MG, 1996, J NUCL MED, V37, P538; SYNDER WS, 1975, ABSORBED DOSE PER UN; VASSILOPOULOUSELLIN R, 1993, CANCER, V71, P1348, DOI 10.1002/1097-0142(19930215)71:4<1348::AID-CNCR2820710429>3.0.CO;2-3; WU CS, 1965, ALPHA BETA GAMMA RAY, V2, P1365; *ICRP, 1983, PUBLICATION ICRP, V38; *ICRU, 1983, 36 ICRU INT COMM RAD; *ICRU, 1998, 60 ICRU INT COMM RAD; *ICRU, 1997, 56 INT COMM RAD UN M; *NAT NUCL DAT CTR, 1998, NUCL STRUCT DEC DAT	53	16	18	RADIATION RESEARCH SOC	OAK BROOK	820 JORIE BOULEVARD, OAK BROOK, IL 60523 USA	0033-7587		RADIAT RES	Radiat. Res.	OCT	2001	156	4					419	429		10.1667/0033-7587(2001)156[0419:TSADDF]2.0.CO;2		11	Biology; Biophysics; Radiology, Nuclear Medicine & Medical Imaging	Life Sciences & Biomedicine - Other Topics; Biophysics; Radiology, Nuclear Medicine & Medical Imaging	478DE	WOS:000171327000010	
J	Sadek, AW; Smith, BL; Demetsky, MJ				Sadek, AW; Smith, BL; Demetsky, MJ			A prototype case-based reasoning system for real-time freeway traffic routing	TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES			English	Article						case-based reasoning; real-time traffic routing; intelligent transportation systems; artificial intelligence; decision support systems	ASSIGNMENT; MODEL	With the recent advances in communications and information technology, real-time traffic routing has emerged as a promising approach to alleviating congestion. Existing approaches to developing real-time routing strategies, however, have limitations. This study examines the potential for using case-based reasoning (CBR). an emerging artificial intelligence paradigm, to overcome such limitations. CBR solves new problems by reusing solutions of similar past problems. To illustrate the feasibility of the approach, the study develops and evaluates a prototype CBR routing system for the interstate network in Hampton Roads, Virginia. Cases for building the system's case-base are generated using a heuristic dynamic traffic assignment (DTA) model designed for the region. Using a second set of cases, the study evaluates the performance of the prototype system by comparing its solutions to those of the DTA model. The evaluation results demonstrate that the prototype system is capable of running in real-time, and of producing high quality solutions using case-bases of reasonable size. (C) 2001 Elsevier Science Ltd. All rights reserved.	Univ Vermont, Dept Civil & Environm Engn, Burlington, VT 05405 USA; Univ Virginia, Dept Civil Engn, Charlottesville, VA 22903 USA	Sadek, AW (reprint author), Univ Vermont, Dept Civil & Environm Engn, 213-B Votey, Burlington, VT 05405 USA.						AAMODT A, 1994, AI COMMUN, V7, P39; Aerde M. V., 1988, TRANSPORT RES A-POL, V22A, P435; Blumentritt C. W., 1981, 232 NCHRP TRB NAT RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIESZ TL, 1989, OPER RES, V37, P893, DOI 10.1287/opre.37.6.893; GUPTA A, 1992, TRANSPORT RES REC, V1358, P60; JAYAKRISHNAN R, 1995, TRANSPORT RES C-EMER, V3, P51, DOI 10.1016/0968-090X(94)00015-W; KHATTAK A, 1996, TRANSPORTATION RES C, V3, P267; KIRKPATRICK S, 1983, SCIENCE, P220; LAFORTUNE S, 1993, TRANSPORT RES B-METH, V27, P451, DOI 10.1016/0191-2615(93)90017-5; MADANAT SM, 1996, TRANSPORT RES REC, V1537, P98, DOI 10.3141/1537-14; Mahmassani H, 1993, LARGE URBAN SYSTEMS, P91; Merchant D. K., 1978, Transportation Science, V12, DOI 10.1287/trsc.12.3.183; PAPAGEORGIOU M, 1990, TRANSPORT RES B-METH, V24, P471, DOI 10.1016/0191-2615(90)90041-V; PEETA S, 1995, TRANSPORT RES C-EMER, V3, P83, DOI 10.1016/0968-090X(94)00016-X; RAN B, 1993, OPER RES, V41, P192, DOI 10.1287/opre.41.1.192; RITCHIE SG, 1991, TRANSPORT RES REC, V1320, P7; SADEK AW, 1998, TRANSPORTATION RES R, V1651; SADEK AW, 1999, IN PRESS TRANSPORTAT; Smith B., 1996, TRANSPORT RES REC, V1554, P136, DOI 10.3141/1554-17; Smith BL, 1994, TRANSPORT RES REC, V1453, P98; WATSON I, 1995, P 1 UK WORKSH SALF U, P1; WETTSCHERECK D, 1995, P 1 INT C CAS BAS RE, P359	23	10	11	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0968-090X		TRANSPORT RES C-EMER	Transp. Res. Pt. C-Emerg. Technol.	OCT	2001	9	5					353	380		10.1016/S0968-090X(00)00046-2		28	Transportation Science & Technology	Transportation	462XK	WOS:000170444900004	
J	Pal, SK; Bandyopadhyay, S; Murthy, CA				Pal, SK; Bandyopadhyay, S; Murthy, CA			Genetic classifiers for remotely sensed images: comparison with standard methods	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							CLASSIFICATION ACCURACY; ALGORITHMS	In this article the effectiveness of some recently developed genetic algorithm-based pattern classifiers was investigated in the domain of satellite imagery which usually have complex and overlapping class boundaries. Landsat data, SPOT image and IRS image are considered as input. The superiority of these classifiers over k-NN rule, Bayes' maximum likelihood classifier and multilayer perceptron (MLP) for partitioning different landcover types is established. Results based on producer's accuracy (percentage recognition score), user's accuracy and kappa values are provided. Incorporation of the concept of variable length chromosomes and chromosome discrimination led to superior performance in terms of automatic evolution of the number of hyperplanes for modelling the class boundaries, and the convergence time. This non-parametric classifier requires very little a priori information, unlike k-NN rule and MLP (where the performance depends heavily on the value of k and the architecture, respectively), and Bayes' maximum likelihood classifier (where assumptions regarding the class distribution functions need to be made).	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India	Pal, SK (reprint author), Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Calcutta 700035, W Bengal, India.						Bandyopadhyay S, 1998, INFORM SCIENCES, V104, P293, DOI 10.1016/S0020-0255(97)00069-8; Bandyopadhyay S, 1998, PATTERN RECOGN LETT, V19, P1171, DOI 10.1016/S0167-8655(98)00097-X; CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P1671; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L, 1991, HDB GENETIC ALGORITH; Dayhoff J.E., 1990, NEURAL NETWORK ARCHI; Fukunaga K, 1972, INTRO STAT PATTERN R; GELSEMA ES, 1995, SPECIAL ISSUE GENETI, V16; Goldberg D., 1989, COMPLEX SYSTEMS, V3, P493; Goldberg D. E, 1989, GENETIC ALGORITHMS S; PAL A, 1993, INF SCI, V67, P189; PAL A, 1990, THESIS INDIAN STAT I; Pal S K, 1996, GENETIC ALGORITHMS P; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Richards J. A., 1993, REMOTE SENSING DIGIT; ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223; SCHRIEVER JR, 1995, PHOTOGRAMM ENG REM S, V61, P321; Tou J.T., 1974, PATTERN RECOGNITION; *NRSA, 1986, IRS DATA USERS HDB	19	27	32	TAYLOR & FRANCIS LTD	LONDON	11 NEW FETTER LANE, LONDON EC4P 4EE, ENGLAND	0143-1161		INT J REMOTE SENS	Int. J. Remote Sens.	SEP 10	2001	22	13					2545	2569		10.1080/01431160120325		25	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	464WU	WOS:000170557000008	
J	Sansone, C; Tortorella, F; Vento, M				Sansone, C; Tortorella, F; Vento, M			A classification reliability driven reject rule for multi-expert systems	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						classification; multi-expert systems; reliability; reject option; classification cost	HANDWRITTEN NUMERALS; CLASSIFIERS; RECOGNITION; COMBINATION	In this paper we propose a reject rule applicable to a Multi-Expert System (MES). The rule is adaptive to the given domain and allows the achievement of the best trade-off between reject and error rates as a function of the costs attributed to errors and rejects in the considered application. The results of the method axe particularly effective since the method does not rely on particular statistical assumptions, as other reject rules. An experimental analysis carried out on publicly available databases is reported together with a comparison with other methods present in the literature.	Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy; Univ Cassino, Dipartimento Automazione Elettromagnetismo Ingn I, I-03043 Cassino, FR, Italy	Sansone, C (reprint author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.		Tortorella, Francesco/F-5964-2010				ACKERMANN B, 1996, IAM96002 U BERN I IN; BATTITI R, 1994, NEURAL NETWORKS, V7, P691, DOI 10.1016/0893-6080(94)90046-9; Blake CL, 1998, UCI REPOSITORY MACHI; Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Stefano C, 2000, IEEE T SYST MAN CY C, V30, P84, DOI 10.1109/5326.827457; DESTEFANO C, 1995, P 9 SCAND C IM AN, P1123; Foggia P, 1999, PATTERN RECOGN, V32, P1435, DOI 10.1016/S0031-3203(98)00169-1; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P608, DOI 10.1109/34.601248; HECTHNIELSEN R, 1990, NEUROCOMPUTING; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KANG H, 1997, P 4 INT C DOC AN REC, V2, P870; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LAM L, 1995, PATTERN RECOGN LETT, V16, P945, DOI 10.1016/0167-8655(95)00050-Q; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; LEE DS, 1995, P 3 INT C DOC AN REC, P42; Pudill P., 1992, P 11 IAPR INT C PATT, V2, P92; Rahman AFR, 1998, PATTERN RECOGN, V31, P1255, DOI 10.1016/S0031-3203(97)00161-1; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	27	5	5	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	SEP	2001	15	6					885	904		10.1142/S0218001401001210		20	Computer Science, Artificial Intelligence	Computer Science	484GJ	WOS:000171681600001	
J	Roy, K; Sengupta, C; De, AU				Roy, K; Sengupta, C; De, AU			Theoretical aspects of rational drug design - An overview	JOURNAL OF SCIENTIFIC & INDUSTRIAL RESEARCH			English	Review							MATRIX-METALLOPROTEINASE INHIBITORS; MOLECULAR CONNECTIVITY; ANTIOXIDANT VITAMINS; BIOLOGICAL-ACTIVITY; LIPID-PEROXIDATION; ELECTROTOPOLOGICAL STATE; PARTITION-COEFFICIENT; PROTEASE INHIBITORS; HANSCH ANALYSIS; TAU INDEXES	The major techniques of drug discovery processes for the past thirty years have been summarized. However, because of rapid advances in information technology and emergence of plethora of newer techniques, e.g., PCMM, UPGMA, MMG, FALS, MMFF, etc., this short review obviously does not give an exhaustive coverage. The paper summarizes different approaches of rational drug design methods with a primary focus on quantitative structure-activity relationship QSAR) and molecular modelling studies. Apart from an overview of classical QSAR tools (Hansch approach, Fujita-Ban modification of Free Wilson model and topological schemes) and different mathematical methods of QSAR, different components of molecular modelling including techniques of computational chemistry (quantum and molecular mechanical approaches) are briefly discussed. Various receptor-dependent and receptor-independent 3-D QSAR methods and techniques like protein modelling, de novo ligand design and receptor mapping are also summarized. Some other trends in recent drug development process like mass ligand screening, recombinant DNA technology, peptidomimetics, oligonucleotide therapeutics, cabohydrate based drug design, and prodrug design are also mentioned.	Jadavpur Univ, Dept Pharmaceut Technol, Div Med & Pharmaceut Chem, Drug Theoret Lab, Calcutta 700032, W Bengal, India	De, AU (reprint author), Jadavpur Univ, Dept Pharmaceut Technol, Div Med & Pharmaceut Chem, Drug Theoret Lab, Calcutta 700032, W Bengal, India.		Roy, Kunal/B-1673-2009	Roy, Kunal/0000-0003-4486-8074			AOYAMA T, 1990, J MED CHEM, V33, P2583, DOI 10.1021/jm00171a037; APPELT K, 1997, STRUCTURE BASED DRUG, P1; ARANDA A, 1973, CR ACAD SCI C CHIM, V276, P1301; BABALAN AT, 1980, STERIC FIT QUANTITAT; Balant L. P., 1995, BURGERS MED CHEM, V1, P949; BALDWIN JJ, 1989, J MED CHEM, V32, P2510, DOI 10.1021/jm00132a003; BEASLEY JG, 1969, BIOCHIM BIOPHYS ACTA, V178, P175, DOI 10.1016/0005-2744(69)90144-2; BENCT LZ, 1996, GOODMAN GILMANS PHAR, P3; Benet LZ, 1996, GOODMAN GILMANS PHAR, P1707; BROUGHTON BJ, 1975, J MED CHEM, V18, P1117, DOI 10.1021/jm00245a014; Christen WG, 1999, P ASSOC AM PHYSICIAN, V111, P16, DOI 10.1046/j.1525-1381.1999.09231.x; CHRISTOFFERSEN RE, 1995, BURGERS MED CHEM DRU, V1, P9; COLLOUS T, 1973, DISCRIMINANT ANAL AP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMER RD, 1978, QUANTITATIVE STRUCTU; CRIPPEN GM, 1982, MOL PHARMACOL, V22, P11; Crooke ST, 1995, BURGERS MED CHEM DRU, V1, P863; CURRIN RT, 1990, TRANSPLANTATION, V50, P1076; DANIELS TD, 1982, WILSON GISVOLDS TXB, P5; DAVIS AM, 1995, ADV COMPUTER ASSISTE, P39; De A. K., 1997, Biomedicine, V17, P99; DE AU, 1981, INDIAN J CHEM B, V20, P58; DE AU, 1979, INDIAN J CHEM B, V16, P57; DE AU, 1977, J INDIAN CHEM SOC, V54, P1071; DE AU, 1979, INDIAN J CHEM B, V18, P172; DE AU, 2001, INDIAN J PHARM ED, V35, P71; DE AU, 1978, INDIAN J CHEM B, V16, P716; DE AU, 1980, INDIAN J CHEM B, V19, P787; DE AU, 1978, INDIAN J CHEM B, V16, P1104; DE AU, 1982, INDIAN J CHEM B, V21, P430; DE AU, 1979, INDIAN J CHEM B, V17, P261; DE K, 2000, INDIAN J PHARM SCI, V62, P343; DIRMLA JP, 1979, J MED CHEM, V22, P1118; DOWEYKO AM, 1988, J MED CHEM, V31, P1396, DOI 10.1021/jm00402a025; Duran B.C., 1974, CLUSTER ANAL SURVEY; DUTTA H, 1993, INDIAN J BIOCHEM BIO, V30, P128; DUTTA H, 1991, INDIAN J BIOCHEM BIO, V28, P210; DUTTA H, 1909, INDIAN J BIOCH BIOPH, V33, P76; ESTERBAUER H, 1988, ISI ATLAS-BIOCHEM, V1, P311; FRANKE R, 1995, CHEMOMETRIC METHODS, P113, DOI 10.1002/9783527615452.ch4; FREE SM, 1964, J MED CHEM, V7, P395, DOI 10.1021/jm00334a001; FUJITA T, 1971, J MED CHEM, V14, P148, DOI 10.1021/jm00284a016; Gaziano JM, 1999, P ASSOC AM PHYSICIAN, V111, P2, DOI 10.1046/j.1525-1381.1999.09229.x; GOLDENDER VE, 1980, DRUG DESIGN, V9, P300; GOOD AC, 1993, J MED CHEM, V36, P433, DOI 10.1021/jm00056a002; Goodman M., 1995, BURGERS MED CHEM DRU, V1, P803; GREER J, 1994, J MED CHEM, V37, P1035, DOI 10.1021/jm00034a001; Gund P., 1997, PROGR MOL SUBCELLULA, V5, P117; Gupta P, 1998, J APPL TOXICOL, V18, P317, DOI 10.1002/(SICI)1099-1263(1998090)18:5<317::AID-JAT514>3.0.CO;2-U; Gutteridge J. M. C., 1994, ANTIOXIDANTS NUTR HL; HALL LH, 1975, J PHARM SCI, V64, P1974, DOI 10.1002/jps.2600641215; HALL LH, 1991, QUANT STRUCT-ACT REL, V10, P43, DOI 10.1002/qsar.19910100108; HALL LH, 1977, TETRAHEDRON, V33, P1953, DOI 10.1016/0040-4020(77)80383-9; HALLIWELL B, 1991, DRUGS, V42, P569, DOI 10.2165/00003495-199142040-00003; Halliwell B., 1989, FREE RADICALS BIOL M; Hammett L.B., 1940, PHYSICAL ORGANIC CHE, P184; HANSCH C, 1964, J AM CHEM SOC, V86, P1616, DOI 10.1021/ja01062a035; HANSCH C, 1995, EXPORING QSAR STRUCT; HARPER NJ, 1971, ADV DRUG RES, V6, P53; HENKEL JG, 1995, PRINCIPLES MED CHEM, P58; HILPERT K, 1994, J MED CHEM, V37, P3889, DOI 10.1021/jm00049a008; HIRSCHMANN R, 1995, NEW PERSPECTIVES IN DRUG DESIGN, P1; HODES L, 1979, ACS SYM SER, V112, P583; HODGKIN EE, 1993, J COMPUT AID MOL DES, V7, P515, DOI 10.1007/BF00124360; HOLLAND JH, 1992, SCI AM, V267, P66; HOLLOWAY MK, 1995, J MED CHEM, V38, P305, DOI 10.1021/jm00002a012; Hopfinger A.J., 1997, PRACTICAL APPL COMPU, P105; HOPFINGER AJ, 1981, INTERMOLECULAR FORCE, P431; HOPFINGER AJ, 1980, J AM CHEM SOC, V102, P7196, DOI 10.1021/ja00544a005; HUBEL S, 1980, PHARMAZIE, V35, P424; Ip SP, 1996, BIOCHEM PHARMACOL, V52, P1687, DOI 10.1016/S0006-2952(96)00517-5; JAIN AN, 1994, J MED CHEM, V37, P2315, DOI 10.1021/jm00041a010; JAMBHEKAR SS, 1995, PRINCIPLES MED CHEM, P12; JOLIFFE IJ, 1986, PRINCIAL COMPONENT A; JORGENSE.EC, 1965, J MED CHEM, V8, P533, DOI 10.1021/jm00328a029; KAKEYA N, 1969, CHEM PHARM BULL, V17, P1010; KAKEYA N, 1969, CHEM PHARM BULL, V17, P2558; KALE RK, 1990, RADIAT PHYS CHEM, V36, P361; KATAKURA S, 1993, BIOCHEM BIOPH RES CO, V197, P965, DOI 10.1006/bbrc.1993.2573; KAUFMAN JJ, 1975, INT J QUANTUM CHEM, V2, P35; Kearsley S., 1990, TETRAHEDRON COMPUT M, V3, P615, DOI 10.1016/0898-5529(90)90162-2; KEMPF DJ, 1995, P NATL ACAD SCI USA, V92, P2484, DOI 10.1073/pnas.92.7.2484; KIER LB, 1975, J PHARM SCI, V64, P1971, DOI 10.1002/jps.2600641214; KIER LB, 1980, J PHARM SCI, V69, P807, DOI 10.1002/jps.2600690717; KIER LB, 1995, CHEMOMETRIC METHODS, P39; Kier LB, 1997, MED CHEM RES, V7, P394; Kier L.B., 1986, MOL CONNECTIVITY STR; KIER LB, 1970, MOL ORBITAL STUDIES; Kier LB, 1976, MOL CONNECTIVITY CHE; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; KIER LB, 1976, J PHARM SCI, V65, P1226, DOI 10.1002/jps.2600650824; KIRSCHNER GL, 1979, DRUG DESIGN, V8, P73; Kitiyakara C, 1998, CURR OPIN NEPHROL HY, V7, P531, DOI 10.1097/00041552-199809000-00008; Kubinyi H., 1993, QSAR HANSCH ANAL REL; Kubiyini H, 1995, BURGERS MED CHEM DRU, V1, P497; Kumar KV, 1999, TRANSPLANTATION, V67, P1065, DOI 10.1097/00007890-199904150-00022; Lai YL, 1998, J CARDIOVASC PHARM, V32, P714, DOI 10.1097/00005344-199811000-00006; Lebedev A. A., 1996, Eksperimental'naya i Klinicheskaya Farmakologiya, V59, P28; Lee IM, 1999, P ASSOC AM PHYSICIAN, V111, P10, DOI 10.1046/j.1525-1381.1999.09230.x; LEHNINGER AL, 1993, PRINCIPLES BIOCH, P268; LINDQUIST RN, 1975, DRUG DESIGN, V5, P24; Luo XP, 1997, BBA-MOL BASIS DIS, V1360, P45; MAGEE PS, 1990, QUANT STRUCT-ACT REL, V9, P202, DOI 10.1002/qsar.19900090304; Malinowski E., 1980, FACTOR ANAL CHEM; MANALLACK DT, 1995, ADV COMPUTER ASSISTE, P293; MARDEROSIAN AHD, 1995, REMINGTON SCI PRACTI, V1, P809; MARSHALL GR, 1995, BURGERS MED CHEM DRU, P573; MARTIN A, 1999, PHYSICAL PHARM, P512; MARTIN YC, 1974, NEUROPSYCHOPHARMACOL, P37; MARTIN YC, 1982, STRATEGY DRUG RES, V4, P269; MARTIN YC, 1978, QUANTITATIVE DRUG DE; Mathison I.W., 1989, PRINCIPLES MED CHEM, P49; Mc Farland J.W., 1995, CHEMOMETRIC METHODS, P295; MICHEL HJ, 1978, QUANTITATIVE STRUCTU, P89; MONTERO JL, 1974, CR ACAD SCI C CHIM, V279, P809; Montgomery J. A., 1993, Drugs of the Future, V18, P887; Montgomery John A., 1994, Perspectives in Drug Discovery and Design, V2, P205, DOI 10.1007/BF02171744; MORIGUCHI I, 1977, CHEM PHARM BULL, V25, P2800; MURCKO MA, 1997, PRACTICAL APPL COMPU, P305; MURRAY WJ, 1975, J PHARM SCI, V64, P1978, DOI 10.1002/jps.2600641216; MUSSER JH, 1995, BURGERS MED CHEM DRU, V1, P901; Nagy A, 1996, FREE RADICAL BIO MED, V20, P567, DOI 10.1016/0891-5849(95)02046-2; Naviaa MA, 1992, CURR OPIN STRUC BIOL, V2, P202, DOI 10.1016/0959-440X(92)90147-Y; O'Brien PM, 2000, J MED CHEM, V43, P156, DOI 10.1021/jm9903141; ORTIZ AR, 1995, J MED CHEM, V38, P2681, DOI 10.1021/jm00014a020; PAL DK, 1988, INDIAN J CHEM B, V27, P734; PAL DK, 1989, INDIAN J CHEM B, V28, P261; PAL DK, 1990, INDIAN J CHEM B, V29, P451; PAL DK, 1992, INDIAN J CHEM B, V31, P109; PANDEYA SN, 1998, INTRO DRUG DESIGN, P39; PARKHOMENKO AE, 1996, TERAPEVT ARKH, V65, P47; PEITSCH MC, 1997, PRACTICAL APPL COMPU, P227; Purcell W.P., 1973, STRATEGY DRUG DESIGN; PURCELL WP, 1965, BIOCHIM BIOPHYS ACTA, V105, P201; RAINER F, 1984, THEORETICAL DRUG DES, V7; RANDIC M, 1975, J AM CHEM SOC, V97, P6609, DOI 10.1021/ja00856a001; REMERS WA, 1974, J MED CHEM, V17, P729, DOI 10.1021/jm00253a014; RIPKA WC, 1997, STRUCTURE BASED DRUG, P265; Ross EM, 1996, GOODMAN GILMANS PHAR, P29; ROUOT B, 1977, J PHARMACOL-PARIS, V8, P95; Roy K, 2001, Drug Des Discov, V17, P199; Roy Kunal, 2000, Indian Journal of Experimental Biology, V38, P580; Roy K, 2000, Acta Pol Pharm, V57, P385; Roy K, 1999, INDIAN J CHEM B, V38, P1194; Roy K, 2001, INDIAN J CHEM B, V40, P129; ROY K, 2000, DRUG DESIGN DISCOVER, V17, P483; Roy K, 2001, Drug Des Discov, V17, P207; Roy K., 1998, Indian Journal of Pharmaceutical Sciences, V60, P153; Roy K., 2000, Indian Journal of Pharmaceutical Sciences, V62, P46; Roy K, 2001, INDIAN J CHEM B, V40, P209; Roy K, 1999, INDIAN J CHEM B, V38, P664; Roy K, 1999, INDIAN J CHEM B, V38, P942; Roy K., 1999, Indian Journal of Pharmaceutical Sciences, V61, P76; Roy K, 2000, J INDIAN CHEM SOC, V77, P428; ROY K, 2001, IN PRESS INDIAN J B, V40; Roy K., 1999, Indian Journal of Pharmaceutical Sciences, V61, P44; SAHA A, 2000, J INDIAN CHEM SOC, V78, P92; Saha A, 2000, Acta Pol Pharm, V57, P441; Saha A., 2000, Indian Journal of Pharmaceutical Sciences, V62, P115; SCHONFELD JV, 1997, CELL MOL LIFE SCI, V53, P917; Scozzafava A, 2000, J MED CHEM, V43, P1858, DOI 10.1021/jm990594k; SENGUPTA M, 1995, INDIAN J BIOCHEM BIO, V32, P302; Sengupta Mita, 1993, Indian Journal of Experimental Biology, V31, P21; SESTANJ K, 1984, J MED CHEM, V27, P255, DOI 10.1021/jm00369a003; SEYDEL JK, 1971, ARZNEI-FORSCHUNG, V21, P187; SEYDEL JK, 1979, CHEM STRUKTUR BIOL A; Shannon C. E., 1949, MATH THEORY COMMUNIC; SINGAL PK, 1995, J MOL CELL CARDIOL, V27, P1055, DOI 10.1016/0022-2828(95)90074-8; SPELLMEYER DC, 1997, PRACTICAL APPL COMPU, P165; STACEY NH, 1980, TOXICOL APPL PHARM, V53, P470, DOI 10.1016/0041-008X(80)90359-2; SURESH C, 1999, EVERYMANS SCI, V33, P149; SWEETMAN PM, 1995, BURGERS MED CHEM DRU, V1, P697; Tarin J, 1998, REPROD NUTR DEV, V38, P499, DOI 10.1051/rnd:19980502; THIBAUT U, 1993, 3D QSAR DRUG DESIGN, P661; TOLLENAERE JP, 1976, EUR J MED CHEM, V11, P298; TOPLISS JG, 1972, J MED CHEM, V15, P394, DOI 10.1021/jm00274a017; Touroutoglou N, 1996, CLIN CANCER RES, V2, P227; TRIPATHY KD, 1988, ESSENTIALS MED PHARM, P180; TRIPATHY KD, 1999, ESSENTIALS MED PHARM, P36; TUTE MS, 1995, PRINCIPLES MED CHEM, P50; VANDEWATERBEEMD H, 1995, CHEMOMETRIC METHODS, P283; Venuti M.C., 1995, BURGERS MED CHEM DRU, P661; WALTERS DE, 1994, J MED CHEM, V37, P2527, DOI 10.1021/jm00042a006; WANG CH, 1995, NEW PERSPECTIVES DRU, P35; WEINSTEIN H, 1974, CHEM BIOCH REACTIVIT, P493; WILLIAMS M, 1995, BURGERS MED CHEM DRU, V1, P349; WILLIAMS M, 1990, DRUG DISCOVERY TECHN, P129; Wilson R.J., 1972, INTRO GRAPH THEORY; WISE M, 1986, MOL GRAPHICS DRUG DE, P183; WOHL JA, 1970, MOL ORBITAL STUDIES, P262; Wold S., 1984, CHEMOMETRICS MATH ST, P17; WOLD S, 1995, CHEMOMETRIC METHODS, P196; ZANGER M, 1985, REMINGTONS PHARM SCI, P435; ZIMMERMAN JJ, 1989, PRINCIPLES MED CHEM, P49	194	6	6	NATL INST SCIENCE COMMUNICATION	NEW DELHI	DR K S KRISHNAN MARG, NEW DELHI 110 012, INDIA	0022-4456		J SCI IND RES INDIA	J. Sci. Ind. Res.	SEP	2001	60	9					699	716				18	Engineering, Multidisciplinary	Engineering	470WM	WOS:000170894300001	
J	Goyache, F; del Coz, JJ; Quevedo, JR; Lopez, S; Alonso, J; Ranilla, J; Luaces, O; Alvarez, I; Bahamonde, A				Goyache, F; del Coz, JJ; Quevedo, JR; Lopez, S; Alonso, J; Ranilla, J; Luaces, O; Alvarez, I; Bahamonde, A			Using artificial intelligence to design and implement a morphological assessment system in beef cattle	ANIMAL SCIENCE			English	Article						artificial intelligence; beef cattle; linear type; machine learning	LINEAR TYPE TRAITS; UDDER TRAITS; DAIRY EWES; HERD LIFE	In this paper a methodology is developed to improve the design and implementation of a linear morphological system in beef cattle using artificial intelligence. The proposed process involves an iterative mechanism where type traits are successively defined and computationally represented using knowledge engineering methodologies, scored by a set of trained human experts and finally, analysed by means of four reputed machine learning algorithms. The results thus achieved serve as feed back to the next iteration in order to improve the accuracy and efficacy of the proposed assessment system. A sample of 260 conformation records of the Asturiana de los Valles beef cattle breed is shown to illustrate the methodology. Three sources of inconsistency were detected: (a) the existence of different interpretations of the trait's definition, increasing the subjectivity of the assessment; (b) the narrow range of variation of some of the anatomical traits assessed; (c) the inclusion of some complex traits in the assessment system. In this sense, the reopening of the evaluated Asturiana de los Valles assessment system is recommended. In spite of the difficulty of collecting data from live animals, further implications of the artificial intelligence systems on morphological assessment are pointed out.	SERIDA CENSYRA Somio, E-33203 Gijon, Asturias, Spain; Univ Oviedo, Ctr Inteligencia Artificia, E-33271 Gijon, Asturias, Spain	Goyache, F (reprint author), SERIDA CENSYRA Somio, C Camino de los Claveles 604, E-33203 Gijon, Asturias, Spain.		Goyache, Felix/B-7764-2009; Alvarez, Isabel/B-7814-2011				Bahamonde A, 1997, LECT NOTES COMPUT SC, V1240, P536; BERG RT, 1979, NUEVOS CONCEPTOS SOB; BROTHERSTONE S, 1994, ANIM PROD, V59, P183; BROTHERSTONE S, 1991, ANIM PROD, V53, P279; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; delaFuente LF, 1996, LIVEST PROD SCI, V45, P171, DOI 10.1016/0301-6226(96)00003-6; DELCOZ JJ, 1999, P 8 C AS ESP INT ART, V1, P117; del Coz JJ, 1999, LECT NOTES COMPUT SC, V1606, P527; FERNANDEZ G, 1995, J DAIRY SCI, V78, P842; GOYACHE F, 1999, FEDERACION ESPANOLA, V16, P8; Linko S, 1998, TRENDS FOOD SCI TECH, V9, P3, DOI 10.1016/S0924-2244(97)00002-2; LOPEZ S, 2000, REV IBEROAMERICANA I, V10, P5; Luaces O, 1999, LECT NOTES COMPUT SC, V1606, P497; Michalski R. S., 1998, MACHINE LEARNING DAT; Nilsson N. J., 1998, ARTIFICIAL INTELLIGE; PIETERSMA D, 1999, P 2 EUR C EUR FED IN, P669; QUEVEDO JR, 1999, P 8 C AS ESP INT ART, V1, P64; QUINLAN JR, 1993, P 10 INT MACH LEARN; QUINLAN JR, 2000, CUBIST RELEASE 1 08; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rich E., 1991, ARTIFICIAL INTELLIGE; SHI MJ, 1993, GENET SEL EVOL, V25, P177, DOI 10.1051/gse:19930205; SHORT TH, 1992, J DAIRY SCI, V75, P1987; Vallejo M., 1993, Archivos de Zootecnia, V42, P29; Vukasinovic N, 1997, LIVEST PROD SCI, V49, P227, DOI 10.1016/S0301-6226(97)00014-6; Wang Y., 1997, P EUR C MACH LEARN U; Yang XZ, 1999, T ASAE, V42, P1063; *ASS NAZ ALL BOV I, 1997, RAZZ CHIAN; *INT COMM AN REC, 1995, REC GUID APP INT AGR	29	12	12	BRITISH SOC ANIMAL SCIENCE	PENICUIK	PUBLICATIONS DEPT, PO BOX 3, PENICUIK EH26 ORZ, MIDLOTHIAN, SCOTLAND	1357-7298		ANIM SCI	Anim. Sci.	AUG	2001	73		1				49	60				12	Agriculture, Dairy & Animal Science	Agriculture	460PG	WOS:000170317200006	
J	Liu, HF; Lussier, YA; Friedman, C				Liu, HF; Lussier, YA; Friedman, C			Disambiguating ambiguous biomedical terms in biomedical narrative text: An unsupervised method	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						natural language processing; word sense disambiguation; corpus-based machine learning; MedLEE; UMLS; MEDLINE	SPECIAL ISSUE; LANGUAGE	With the growing use of Natural Language Processing (NLP) techniques for information extraction and concept indexing in the biomedical domain, a method that quickly and efficiently assigns the correct sense of an ambiguous biomedical term in a given context is needed concurrently. The current status of word sense disambiguation (WSD) in the biomedical domain is that handcrafted rules are used based on contextual material. The disadvantages of this approach are (i) generating WSD rules manually is a time-consuming and tedious task, (ii) maintenance of rule sets becomes increasingly difficult over time, and (iii) handcrafted rules are often incomplete and perform poorly in new domains comprised of specialized vocabularies and different genres of text. This paper presents a two-phase unsupervised method to build a WSD classifier for an ambiguous biomedical term W The first phase automatically creates a sense-tagged corpus for W, and the second phase derives a classifier for W using the derived sense-tagged corpus as a training set. A formative experiment was performed, which demonstrated that classifiers trained on the derived sense-tagged corpora achieved an overall accuracy of about 97%, with greater than 90% accuracy for each individual ambiguous term. (C) 2001 Elsevier Science (USA).	CUNY Grad Sch & Univ Ctr, Div Comp Sci, New York, NY 10016 USA; CUNY Queens Coll, Dept Comp Sci, New York, NY USA; Columbia Univ Coll Phys & Surg, Dept Med Informat, New York, NY 10032 USA	Liu, HF (reprint author), CUNY Grad Sch & Univ Ctr, Div Comp Sci, New York, NY 10016 USA.						Aronson A. R., 1994, P RIAO 94, P197; BLOOM D, 2000, BJU INT, P1; BRUCE R, P ACL, V32, P139; BRUCE R, 1994, P ACL, V32, P139; Campbell D A, 2001, Proc AMIA Symp, P90; CARDIE C, P NAT C AI, V11, P798; CHEUNG T, 1999, AM HEART J, V134, P726; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; Duda R., 1973, PATTERN CLASSIFICATI; ESCUDERO G, 2000, P 14 EUR C ART INT E, P421; Fellbaum C., 1998, WORDNET ELECT LEXICA; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161; Friedman C, 2000, Proc AMIA Symp, P270; Friedman C, 2001, Proc AMIA Symp, P189; Friedman C, 1998, METHOD INFORM MED, V37, P334; Gale W.A., 1992, P 4 INT C THEOR METH, P101; HRIPCSAK G, 1995, ANN INTERN MED, V122, P681; Ide N, 1998, COMPUT LINGUIST, V24, P1; Johnson SB, 1999, J AM MED INFORM ASSN, V6, P205; Kilgarriff A, 2000, COMPUT HUMANITIES, V34, P1, DOI 10.1023/A:1002619001915; Knirsch CA, 1998, INFECT CONT HOSP EP, V19, P94; LEACOCK C, 1993, P ARPA WORKSH HUM LU; Leacock C, 1998, COMPUT LINGUIST, V24, P147; LI M, T NEURAL NETW, V11, P647; Liu H, 2001, Proc AMIA Symp, P393; MOONEY RJ, 1996, P EMNLP, V1, P82; NADKAMI P, 2001, J AM MED INFORM ASSN, V80, P80; NG HT, 1996, P ACL, V34, P40; NG HT, 1997, P EMNLP2; NG HT, 1997, AI MAGAZINE      WIN, P45; Reis BY, 2001, J BIOMED INFORM, V34, P15, DOI 10.1006/jbin.2001.1005; Rindflesch T C, 1994, Proc Annu Symp Comput Appl Med Care, P240; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; ROTH L, 2000, P AMIA ANN FALL S 20, P1124; STEVENSON M, 1999, P INT JOINT C AI; YAROWSKY D, 1994, P ACL, V32, P88; YAROWSKY D, P ACL, V32, P88; *US DHHS NIH NAT L, UMLS KNOWL SOURC	39	28	28	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	AUG	2001	34	4					249	261		10.1006/jbin.2001.1023		13	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	541RX	WOS:000174998900002	
J	Skubalska-Rafajlowicz, E				Skubalska-Rafajlowicz, E			Data compression for pattern recognition based on space-filling curve pseudo-inverse mapping	NONLINEAR ANALYSIS-THEORY METHODS & APPLICATIONS			English	Article; Proceedings Paper	3rd World Congress of Nonlinear Analysts Catania	JUL 19-26, 2000	SICILY, ITALY			space-filling curves; pattern recognition; data compression	VECTOR QUANTIZATION	A new class of methods of data compression for pattern recognition in multidimensional space is discussed. These methods combine the space-filling curve based transformation of multidimensional data into the unit interval and pattern recognition algorithms in one dimension. This transformation yield the powerful reduced complexity pattern recognition method.	Wroclaw Tech Univ, Inst Engn Cybernet, PL-50370 Wroclaw, Poland	Skubalska-Rafajlowicz, E (reprint author), Wroclaw Tech Univ, Inst Engn Cybernet, Wyspianskiego 27, PL-50370 Wroclaw, Poland.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diamantini C, 1998, IEEE T NEURAL NETWOR, V9, P174, DOI 10.1109/72.655039; Fukunaga K, 1972, INTRO STAT PATTERN R; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Hilbert D, 1891, MATH ANN, V38, P459, DOI DOI 10.1007/BF01199431; Kohonen T., 1995, SELF ORG MAPS; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; PATRICK EA, 1968, IEEE T COMPUT, VC 17, P949, DOI 10.1109/TC.1968.226443; Peano G, 1890, MATH ANN, V36, P157, DOI 10.1007/BF01199438; PLATZMAN LK, 1989, J ACM, V36, P719, DOI 10.1145/76359.76361; QUWEIDER MK, 1995, IEEE SIGNAL PROCESSI, V2, P170; RITTER H, 1991, IEEE T NEURAL NETWOR, V2, P173, DOI 10.1109/72.80310; Sagan H, 1994, SPACE FILLING CURVES; Sierpinski W, 1912, B ACAD SCI CRACOW A, V1912, P463; SKUBALSKARAFAJL.E, 1996, P 13 ICPR VIENN AUST, P221; SKUBALSKARAFAJL.E, P 4 C NEUR NETW THEI, P226; SKUBALSKARAFAJL.E, P 3 C NEUR NETW THEI, P161; SKUBALSKARAFAJL.E, 1999, UNPUB PATTERN RECOGN; STEELE JM, 1989, OPER RES LETT, V8, P237; YAIR E, 1992, IEEE T SIGNAL PROCES, V40, P294, DOI 10.1109/78.124940; ZADOR PL, 1982, IEEE T INFORM THEORY, V28, P139, DOI 10.1109/TIT.1982.1056490; Zheng Y, 1996, IEEE T NEURAL NETWOR, V7, P87	23	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0362-546X		NONLINEAR ANAL-THEOR	Nonlinear Anal.-Theory Methods Appl.	AUG	2001	47	1	1				315	326		10.1016/S0362-546X(01)00179-1		12	Mathematics, Applied; Mathematics	Mathematics	466BX	WOS:000170625400030	
J	Bainbridge, D; Bell, T				Bainbridge, D; Bell, T			The challenge of optical music recognition	COMPUTERS AND THE HUMANITIES			English	Article						optical music recognition; musical data acquisition; document image analysis; pattern recognition		This article describes the challenges posed by optical music recognition - a topic in computer science that aims to convert scanned pages of music into an on-line format. First, the problem is described: then a generalised framework for software is presented that emphasises key stages that must be solved: staff line identification, musical object location, musical feature classification, and musical semantics. Next, significant research projects in the area are reviewed, showing how each fits the generalised framework. The article concludes by discussing perhaps the most open question in the field: how to compare the accuracy and success of rival systems, highlighting certain steps that help ease the task.	Univ Waikato, Dept Comp Sci, Hamilton, New Zealand; Univ Canterbury, Dept Comp Sci, Christchurch, New Zealand	Bainbridge, D (reprint author), Univ Waikato, Dept Comp Sci, Hamilton, New Zealand.						Alphonce B., 1988, P SMALL COMP ARTS, P8; ANSTINCE J, 1996, THESIS U CANTERBURY; BAINBRIDGE D, 1994, 2 U CANT; BAINBRIDGE D, 1994, NZ SCI MONTHLY, V5, P10; BAINBRIDGE D, 1997, THESIS U CANTERBURY; BAINBRIDGE D, 1994, 0594 TRCOSC U CANT D; BAINBRIDGE D, P IEEE DAT COMPR C, P208; BAINBRIDGE D, 1996, P 19 AUSTR COMP SCI, P308; BAINBRIDGE D, 1997, HDB CHARACTER RECOGN, P583; BAINBRIDGE D, 1994, 0694 TRCOSC U CANT D; BAINBRIDGE D, 1997, P IM PROC ITS APPL T, P756; BAINOV D, 1995, PROCEEDINGS OF THE FIFTH INTERNATIONAL COLLOQUIUM ON DIFFERENTIAL EQUATIONS, P23; BAIRD HS, 1992, STRUCTURED DOCUMENT; BAUMANN S, 1992, SERIES MACHINE PERCE, V5, P363; Blostein D., 1992, STRUCTURED DOCUMENT, P405; Boyle RD, 1988, COMPUTER VISION 1 CO; BULIS A, 1992, P INT COMP MUS C, P110; BUNKE H, 1982, IEEE T PATTERN ANAL, V4, P574; Bunke H., 1997, HDB CHARACTER RECOGN; Carter N., 1992, STRUCTURED DOCUMENT, P456; CARTER NP, 1994, COMPUTING MUSICOLOGY, V9, P152; CARTER NP, 1992, SERIES MACHINE PERCE, V5, P352; CARTER NP, 1994, P SOC PHOTO-OPT INS, V2181, P279, DOI 10.1117/12.171115; CARTER NP, 1989, THESIS U SURREY GUIL; Carter N. P., 1992, Machine Vision and Applications, V5, DOI 10.1007/BF02627000; CARTER NP, 1990, P INT ASS PATT REC W, P482; CARTER NP, 1993, STANM87 DEP MUS; Clarke A.T., 1988, P COMP MUS RES C LAN, P84; COUASNON B, 1994, INT ASS PATT REC WOR, P15; COUASNON B, 1997, THESIS IRISA FRANCE; COUASNON B, 1995, 3 INT C PRACT APPL P, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAHMY H, 1991, P 1 INT C DOC AN REC, V1, P70; FAHMY H, 1992, SERIES MACHINE PERCE, V5, P373; Foley J.D., 1990, COMPUTER GRAPHICS PR; FUJINAGA I, 1988, THESIS MCGILL U MONT; FUJINAGA I, 1989, PROCEEDINGS : 1989 INTERNATIONAL COMPUTER MUSIC CONFERENCE, NOVEMBER 2-5, P113; FUJINAGA I, 1989, P 1 INT C MUS PERC C, P87; FUJINAGA I, 1992, SPIE, V1785, P210; FUJINAGA I, 1991, P INT COMP MUS C MON, P66; FUJINAGA I, 1997, THESIS MCGILL U MONT; FUJINAGA I, 1992, P INT COMP MUS C SAN, P117; FUJINAGA I, 1991, COMPUTERS MUSIC RES, V3, P139; FUJINAGA I, 1989, COMPUTERS MUSIC RES, V1, P161; GLASS S, 1989, THESIS U CANTERBURY; HAKEN L, 1993, COMPUT MUSIC J, V17, P43, DOI 10.2307/3680942; HEUSSENSTAMM G, 1987, NORTON MANUAL MUSCI; KASSLER M, 1972, PERSPECT NEW MUSIC, V11, P250, DOI 10.2307/832471; KATO H, 1990, P IAPR WORKSH SYNT S, P231; MATSUSHIM AT, 1985, B SCI ENG RES LAB, V112, P25; MCGEE W, 1991, COMPUT HUMANITIES, V25, P47; MODAYUR BR, 1995, MUSER PROTOYPE MUSIC; Ng KC, 1996, IMAGE VISION COMPUT, V14, P39, DOI 10.1016/0262-8856(95)01038-6; NG KC, 1995, P 11 C MUS INF BOL I, P167; NG KC, 1995, THESIS U LEEDS LEEDS; Pavlidis T, 1982, ALGORITHMS GRAPHICS; PRERAU DS, 1971, THESIS MIT CAMBRIDGE; PRERAU DS, 1975, COMPUT HUMANITIES, V9, P25, DOI 10.1007/BF02404318; PRERAU DS, 1970, THESIS MIT CAMBRIDGE; PRERAU DS, 1971, P FALL JOINT COMP C; PRUSLIN D, 1966, THESIS MIT CAMBRIDGE; READ G, 1974, MUSIC NOTATION MANUA; REED T, 1995, THESIS U CALGARY CAN; ROACH JW, 1988, PATTERN RECOGN, V21, P33, DOI 10.1016/0031-3203(88)90069-6; ROADS C, 1986, COMPUT MUSIC J, V10, P39, DOI 10.2307/3679483; ROSS T, 1970, ART MUSIC ENGRAVING; Russ J C, 1992, IMAGE PROCESSING HDB; SELFRIDGEFIELD E, 1994, COMPUTING MUSICOLOGY, V9, P109; Witten Ian H., 1994, MANAGING GIGABYTES C; WOLMAN J, 1992, P INT COMP MUS C SAN, P125; YADID O, 1992, P INT COMP MUS C SAN, P128	71	18	20	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0010-4817		COMPUT HUMANITIES	Comput. Humanit.	MAY	2001	35	2					95	121		10.1023/A:1002485918032		27	Computer Science, Interdisciplinary Applications	Computer Science	415QF	WOS:000167733600002	
J	Priebe, CE				Priebe, CE			Olfactory classification via interpoint distance analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ensemble classifiers; combining classifiers; nonparametric; nearest-neighbor; interpoint distance; rank statistic; subsample statistic; functional data; artificial nose; electronic nose; analytical chemistry; chemometrics	SYSTEM	Detection of the presence of a single prespecified chemical analyte at low concentration in complex backgrounds is a difficult application for chemical sensors. This article considers a database of artificial nose observations designed specifically to allow for the investigation of chemical sensor data analysis performance on the problem of trichloroethylene (TCE) detection. We consider an approach to this application which uses an ensemble of subsample classifiers based on interpoint distances. Experimental results are presented indicating that our nonparametric methodology is a useful tool in olfactory classification.	Johns Hopkins Univ, Whiting Sch Engn, Dept Math Sci, Baltimore, MD 21218 USA	Priebe, CE (reprint author), Johns Hopkins Univ, Whiting Sch Engn, Dept Math Sci, Baltimore, MD 21218 USA.		Priebe, Carey E./A-3305-2010				Bickel P. J., 1977, MATH STAT BASIC IDEA; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; David H. A., 1970, ORDER STAT; Devroye L, 1996, PROBABILISTIC THEORY; Dickinson TA, 1996, NATURE, V382, P697, DOI 10.1038/382697a0; Dietterich TG, 1997, AI MAG, V18, P97; FRIEDMAN JH, 1996, UNPUB ANOTHER APPROA; GUITIERREZOSUNA R, 1998, IEEE SPECTRUM, V35; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 1998, ANN STAT, V26, P451; Hastie T.J., 1990, GEN ADDITIVE MODELS; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kaplan G, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.669973; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Maa JF, 1996, ANN STAT, V24, P1069; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Nagle HT, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.715180; PRIEBE CE, 2000, P STAT COMP SECT AM; Priebe CE, 1999, COMMUN STAT-THEOR M, V28, P2871, DOI 10.1080/03610929908832454; RAMSAY J. O., 1997, FUNCTIONAL DATA ANAL; Ripley B. D., 1996, PATTERN RECOGNITION; Skalak D. B., 1997, THESIS U MASSACHUSET; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Stern P, 1999, SCIENCE, V286, P703, DOI 10.1126/science.286.5440.703; Vapnik V.N., 1995, NATURE STAT LEARNING; Wand M. P., 1995, KERNEL SMOOTHING; White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; Xie JD, 2000, J NONPARAMETR STAT, V12, P661, DOI 10.1080/10485250008832827; 1998, IEEE SPECTRUM, V35, P22	35	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					404	413		10.1109/34.917575		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	421MJ	WOS:000168067900006	
J	Mitchell, HB; Schaefer, PA				Mitchell, HB; Schaefer, PA			A "soft" K-Nearest Neighbor voting scheme	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							SIMILARITY MEASURES; FUZZY VALUES; ALGORITHM; OPERATOR	The K-Nearest Neighbor (K-NN) voting scheme is widely used in problems requiring pattern recognition or classification. In this voting scheme an unknown pattern is classified according to the classifications of its K nearest neighbors. If a majority of the K nearest neighbors have a given classification C*, then the unknown pattern is also given the classification C*. Although the scheme works well it is sensitive to the number of nearest neighbors, K, which is used. In this paper we describe a fuzzy K-NN voting scheme in which effectively the value of K varies automatically according to the local density of known patterns. We find that the new scheme consistently outperforms the traditional K-NN algorithm. (C) 2001 John Wiley & Sons, Inc.	Elta Elect Ind Ltd, Intelligence Ctr Dept, Ashdod, Israel	Mitchell, HB (reprint author), Elta Elect Ind Ltd, Intelligence Ctr Dept, Ashdod, Israel.						BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; CHEN SM, 1995, FUZZY SET SYST, V72, P79; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR NN, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R. O., 2001, PATTERN CLASSIFICATI; Fukunaga K., 1993, HDB PATTERN RECOGNIT, P33; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM YK, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P1673, DOI 10.1109/FUZZY.1995.409901; KISSIOV VT, 1992, FUZZY SET SYST, V49, P323, DOI 10.1016/0165-0114(92)90284-B; KITTLER J, 1981, PATTERN RECOGN, V13, P245, DOI 10.1016/0031-3203(81)90101-1; Liao TW, 1997, FUZZY SET SYST, V92, P289, DOI 10.1016/S0165-0114(96)00176-5; Mitchell HB, 2000, INT J INTELL SYST, V15, P317, DOI 10.1002/(SICI)1098-111X(200004)15:4<317::AID-INT4>3.0.CO;2-J; PAPPIS CP, 1995, FUZZY SET SYST, V75, P135, DOI 10.1016/0165-0114(95)00023-E; PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4; Schaefer PA, 1999, INT J INTELL SYST, V14, P123, DOI 10.1002/(SICI)1098-111X(199902)14:2<123::AID-INT1>3.3.CO;2-5; Schalkoff R, 1992, PATTERN RECOGNITION; WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T; Webb A.R., 1999, STAT PATTERN RECOGNI; Yang MS, 1998, IEEE T SYST MAN CY B, V28, P461, DOI 10.1109/3477.678652; 1967, IEEE T CIRCUITS SY 1, V44, P622	23	9	10	JOHN WILEY & SONS INC	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158-0012 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	APR	2001	16	4					459	468		10.1002/int.1018		10	Computer Science, Artificial Intelligence	Computer Science	419PJ	WOS:000167957300002	
J	Granger, E; Rubin, MA; Grossberg, S; Lavoie, P				Granger, E; Rubin, MA; Grossberg, S; Lavoie, P			A What-and-Where fusion neural network for recognition and tracking of multiple radar emitters	NEURAL NETWORKS			English	Article						radar; electronic support measures; pattern recognition; data fusion; neural network; ARTMAP; Kalman filter	ARTMAP; CATEGORIZATION; CLASSIFICATION; ARCHITECTURE; SEQUENCES; MAPS	A neural network recognition and tracking system is proposed for classification of radar pulses in autonomous Electronic Support Measure systems. Radar type information is considered with position-specific information from active emitters in a scene. Type-specific parameters of the input pulse stream are fed to a neural network classifier trained on samples of data collected in the field. Meanwhile, a clustering algorithm is used to separate pulses from different emitters according to position-specific parameters of the input pulse stream. Classifier responses corresponding to different emitters are separated into tracks, or trajectories, one per active emitter, allowing for more accurate identification of radar types based on multiple views of emitter data along each emitter trajectory. Such a What-and-Where fusion strategy is motivated by a similar subdivision of labor in the brain. The fuzzy ARTMAP neural network is used to classify streams of pulses according to radar type using their functional parameters. Simulation results obtained with a radar pulse data set indicate that fuzzy ARTMAP compares favorably to several other approaches when performance is measured in terms of accuracy and computational complexity. Incorporation into fuzzy ARTMAP of negative match tracking (from ARTMAP-IC) facilitated convergence during training with this data set. Other modifications improved classification of data that include missing input pattern components and missing training classes. Fuzzy ARTMAP was combined with a bank of Kalman filters to group pulses transmitted from different emitters based on their position-specific parameters, and with a module to accumulate evidence from fuzzy ARTMAP responses corresponding to the track defined for each emitter. Simulation results demonstrate that the system provides a high level of performance on complex, incomplete and overlapping radar data. (C) 2001 Elsevier Science Ltd. All rights reserved.	Boston Univ, Dept Cognit & Neural Syst, Boston, MA 02215 USA; Def Res Estab, Dept Natl Def, Ottawa, ON K1A 0Z4, Canada; Ecole Polytech, Dept Elect & Comp Engn, Montreal, PQ H3C 3A7, Canada; Boston Univ, Ctr Adapt Syst, Boston, MA 02215 USA	Grossberg, S (reprint author), Boston Univ, Dept Cognit & Neural Syst, 677 Beacon St, Boston, MA 02215 USA.						Anderberg M. R., 1973, CLUSTER ANAL APPL; ANDERSON JA, 1990, P IEEE, V78, P1646, DOI 10.1109/5.58358; BALOCH AA, 1991, NEURAL NETWORKS, V4, P271, DOI 10.1016/0893-6080(91)90067-F; Bar-Shalom Y., 1993, ESTIMATION TRACKING; Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4; Bishop C. M., 1995, NEURAL NETWORKS PATT; Blackman S. S., 1986, MULTIPLE TARGET TRAC; BRADSKI G, 1994, BIOL CYBERN, V71, P469, DOI 10.1007/BF00198465; Bradski G, 1995, NEURAL NETWORKS, V8, P1053, DOI 10.1016/0893-6080(95)00053-4; BROWNE JPR, 1998, ELECT WARFARE; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P805, DOI 10.1109/72.392245; CARPENTER GA, 1997, INTELLIGENT ENG SYST, V7, P23; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; CARPENTER GA, 1997, P INT C NEUR NETW, V3, P1459, DOI 10.1109/ICNN.1997.614010; Carpenter GA, 1998, NEURAL NETWORKS, V11, P323, DOI 10.1016/S0893-6080(97)00067-1; CARPENTER KE, 1992, HARVARD LIBR BULL, V3, P5; Chandra V., 1988, Proceedings of the Twentieth Southeastern Symposium on System Theory (Cat. No.88CH2553-6), DOI 10.1109/SSST.1988.17025; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davies G J, 1982, J Orthop Sports Phys Ther, V3, P164; DERMIRIZ A, 1999, INTELLIGENT ENG SYST, V9, P809; Dubes R.C., 1988, ALGORITHMS CLUSTERIN; Duda R., 1973, PATTERN CLASSIFICATI; FILHO ADM, 1994, P INT RAD C, P470; Fukunaga K., 1990, INTRO STAT PATTERN R; GHAHRAMANI Z, 1994, 1509 MIT A I LAB; Granger E, 1999, ADV NEUR IN, V11, P875; GRANGER E, 1999, INTELLIGENT ENG SYST, V9, P3; GRANGER E, 2000, P INT JOINT C NEUR N, V4, P35; GRANT PM, 1982, P I ELECTR ENG, V129, P621; Gray R. M., 1984, IEEE ASSP Magazine, V1, DOI 10.1109/MASSP.1984.1162229; Grossberg S, 2000, TRENDS COGN SCI, V4, P233, DOI 10.1016/S1364-6613(00)01464-9; Helstrom C. W., 1995, ELEMENTS SIGNAL DETE; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; KAMGARPARSI B, 1996, NRLFR5720NRL969803; Little R. J. A., 1987, STAT ANAL MISSING DA; MALONEY PS, 1989, P IEEE INT C NEUR NE, V1, P289; MARDIA HK, 1989, IEE PROC-F, V136, P149; MEILER PP, 1990, FEL90B023 TNO PHYS E; Pape D. R., 1997, Proceedings of the SPIE - The International Society for Optical Engineering, V3160, DOI 10.1117/12.283939; Parra L, 1996, NEURAL COMPUT, V8, P260, DOI 10.1162/neco.1996.8.2.260; PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6; ROE AL, 1994, P 7 INT C IND ENG AP, P565; ROGERS JAV, 1985, P I ELECTR ENG, V132, P621; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHLEHER DC, 1986, INTRO ELECT WARFACE; Schleher D.C., 1999, ELECT WARFARE INFORM; SCIORTINO JC, 1997, NAV ENG J, P73; SELF A, 1991, AGARD 91, V9, P1; Specht D. F., 1989, Wescon/89. Conference Record; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Tsui J.B-Y., 1986, MICROWAVE RECEIVERS; WANG EK, 1991, ELECTROANAL, V3, P1, DOI 10.1002/elan.1140030102; WILEY RG, 1993, ELECT INTELLIGENCE A; WILKINSON MA, 1985, P I ELECTR ENG, V132, P229; Williamson JR, 1997, NEURAL COMPUT, V9, P1517, DOI 10.1162/neco.1997.9.7.1517; Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8	59	26	32	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	APR	2001	14	3					325	344		10.1016/S0893-6080(01)00019-3		20	Computer Science, Artificial Intelligence	Computer Science	426DN	WOS:000168334700006	
J	Katila, M; Tomppo, E				Katila, M; Tomppo, E			Selecting estimation parameters for the Finnish multisource National Forest Inventory	REMOTE SENSING OF ENVIRONMENT			English	Article						nonparametric estimation; satellite images; multisource forest inventory; stratification Cross-validation; training data selection	NEIGHBOR; AREA	The paper examines the selection of parameters for the nonparametric k-NN estimation method that is used in the Finnish multisource National Forest Inventory (MS-NFI). The MS-NFI utilises NFI field plot data, optical area satellite images and digital maps and produces forest variable estimates from the single pixel level up to the national level. The most important parameters to be selected are: the distance metric, the number of the nearest neighbours, ii, parameters related to the digital elevation model, stratification of the image data, as well as the width of the moving geographical horizontal and vertical reference areas (HRAs and VRAs). The root mean square errors (RMSEs) and significance of biases at pixel level were evaluated in order to find optimal parameters. A leave-one-out cross-validation method was applied. The emphasis is placed on the search for moving geographical HRAs and VRAs, as well as in the stratification of the field plots and the satellite images on the basis of auxiliary data. Stratification reduces the bias of the estimates significantly within each strata. With the current sampling intensity of the Finnish national forest inventory, a geographical HRA with a radius of 40-50 km was found optimal for the total volume estimates and for volumes by tree species in the mineral land map stratum. On the average, there was a sufficient number of field plots to cover the variation of forest variables within the image area to be analysed. The inclusion of field plot data beyond this area introduced bias to the estimates. For the peatland strata, a wider reference area, 60-90 km, was needed. A VRA together with topographic correction of the digital values of images, reduced the standard error of the volume estimates in Northern Finland. (C) 2001 Elsevier Science Inc. All rights reserved.	Finnish Forest Res Inst, FIN-00170 Helsinki, Finland	Katila, M (reprint author), Finnish Forest Res Inst, Unioninkatu 40 A, FIN-00170 Helsinki, Finland.						ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURRAN PJ, 1986, PHOTOGRAMM ENG REM S, V52, P229; EISELE FA, 1997, 1997 M WALL PRIZ S 1, P71; FRANCOLOPEZ H, 2000, IN PRESS REMOTE SENS; Gjertsen A.K., 2000, REMOTE SENSING FORES, P167; HAGNER O, 1997, 29 SWED U AGR SCI DE; Katila M, 2000, CAN J FOREST RES, V30, P1329, DOI 10.1139/cjfr-30-8-1329; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KILKKI P, 1987, REMOTE SENSING AIDED, P2089; LINTON O, 1998, ENCY STAT SCI UPDATE, V2, P470; MOEUR M, 1995, FOREST SCI, V41, P337; Nilsson M., 1997, THESIS SWEDISH U AGR; Poso S, 1999, SILVA FENN, V33, P41; RAO JNK, 1998, ENCY STAT SCI UPDATE, V2, P621; Seppala M., 1980, FENNIA, V158, P41; TOKOLA T, 1998, THESIS U JOENS; Tokola T, 1996, INT J REMOTE SENS, V17, P2333; Tokola Timo, 1997, Silva Fennica, V31, P67; Tokola T, 1999, CAN J FOREST RES, V29, P303, DOI 10.1139/cjfr-29-3-303; Tomppo E., 1991, INT ARCH PHOTOGRAMME, V28, P419; TOMPPO E, 1992, INT ARCH PHOTOGRA 7B, V29, P671; Tomppo E., 1987, Proceedings of the 5th Scandinavian Conference on Image Analysis; TOMPPO E, 1999, FOLIA FOR HELSINKI, V2, P389; Tomppo E., 1998, FOLIA FORESTALIA B, V4B, P619; TOMPPO E, 1996, NEW THRUSTS FOREST I, V1, P27; TOMPPO E, 1997, STUDY EUROPEAN FORES, V2, P145; TOMPPO E, 1998, FOLIA FORESTALIA B, V2, P293; Tomppo E, 1992, ACTA FOR FENN, V229, P1; Tomppo E, 1999, SCAND J FOREST RES, V14, P182; *FINN FOR RES I, 1999, FINN STAT YB FOR	31	96	99	ELSEVIER SCIENCE INC	NEW YORK	655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010 USA	0034-4257		REMOTE SENS ENVIRON	Remote Sens. Environ.	APR	2001	76	1					16	32		10.1016/S0034-4257(00)00188-7		17	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	421JN	WOS:000168061400002	
J	Wong, KD; Cox, DC				Wong, KD; Cox, DC			Two-state pattern-recognition handoffs for corner-turning situations	IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY			English	Article						handoffs; handovers; land mobile radio cellular systems; land mobile radio propagation factors; pattern recognition	ALGORITHMS	Handoff algorithms are used in wireless cellular systems to decide when and to which base station to handoff. Traditional handoff algorithms generally cannot keep both the average number of unnecessary handoffs and the handoff decision delay low. They do not exploit the relative constancy of path loss and shadow fading effects at any given location around a base station. However, handoff algorithms with both a negligible number of unnecessary handoffs and a negligible decision delay can be realized by exploiting this information. One example is the set of handoff algorithms using pattern recognition introduced in previous work. In this paper, we describe how pattern-recognition handoff algorithms can be applied to the problem of turning a corner. This can be used as part of an integrated pattern-recognition handoff algorithm or together with a traditional handoff algorithm, in which case the pattern recognition handles only the special cases like turning a corner.	Telecordia Technol, Red Bank, NJ 07701 USA; Stanford Univ, Ctr Telecommun, Stanford, CA 94305 USA	Wong, KD (reprint author), Telecordia Technol, Red Bank, NJ 07701 USA.						AMITAY N, 1992, IEEE T VEH TECHNOL, V41, P337, DOI 10.1109/25.182582; AUSTIN MD, 1994, IEEE T VEH TECHNOL, V43, P549, DOI 10.1109/25.312791; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GREENSTEIN LJ, 1992, IEEE COMMUN MAG, V30, P76, DOI 10.1109/35.210359; Jakes Jr W. C., 1974, MICROWAVE MOBILE COM; Kennemann O., 1994, P 6 NORD SEM DIG MOB, P195; LOTSE F, 1990, P IEEE VEH TECHN C O, P539; MATURINOLOZOYA H, 1994, P VEH TECH C 94 STOC, P96, DOI 10.1109/VETEC.1994.345157; MURASE A, 1991, P VTC 91, P524; Nadler M, 1993, PATTERN RECOGNITION; NARASIMHAN R, 1998, P IEEE INT S PERS IN; PRAKASH R, 1998, P IEEE INT S PERS IN; Ramo S., 1965, FIELDS WAVES COMMUNI; Santucci F, 2000, IEEE T COMMUN, V48, P231, DOI 10.1109/26.823556; STEELE R, 1995, IEEE COMMUN MAG  JAN, V33; Verdone R, 1998, ELECTRON LETT, V34, P950, DOI 10.1049/el:19980718; VIJAYAN R, 1993, IEEE T VEH TECHNOL, V42, P351, DOI 10.1109/25.231888; WHITTEKER JH, 1988, IEEE T VEH TECHNOL, V37; Wong D, 1999, IEEE T VEH TECHNOL, V48, P956, DOI 10.1109/25.765026; WONG D, 2000, IEEE J SEL AREA COMM, V18, P1301; *RES DEV CTR RAD S, 1993, PERS HAND PHON SYST	21	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0018-9545		IEEE T VEH TECHNOL	IEEE Trans. Veh. Technol.	MAR	2001	50	2					354	363		10.1109/25.923048		10	Engineering, Electrical & Electronic; Telecommunications; Transportation Science & Technology	Engineering; Telecommunications; Transportation	433ZQ	WOS:000168791000002	
J	Vaid, TP; Burl, MC; Lewis, NS				Vaid, TP; Burl, MC; Lewis, NS			Comparison of the performance of different discriminant algorithms in analyte discrimination tasks using an array of carbon black-polymer composite vapor detectors	ANALYTICAL CHEMISTRY			English	Article							PATTERN-RECOGNITION; CLASSIFICATION	An array of 20 compositionally different carbon black-polymer composite chemiresistor vapor detectors was challenged under laboratory conditions to discriminate between a pair of extremely similar pure analytes (H2O and D2O), compositionally similar mixtures of pairs of compounds, and low concentrations of vapors of similar chemicals. Several discriminant algorithms were utilized, including it nearest neighbors (kNN, with K = 1), linear discriminant analysis (LDA, or Fisher's linear discriminant), quadratic discriminant analysis (QDA), regularized discriminant analysis (RDA, a hybrid of LDA and QDA), partial least squares, and soft independent modeling of class analogy (SIMCA). H2O and D2O were perfectly classified by most of the discriminants when a separate training and test set was used. As expected, discrimination performance decreased as the analyte concentration decreased, and performance decreased as the composition of the analyte mixtures became more similar. RDA was the overall best-performing discriminant, and LDA was the best-performing discriminant that did not require several cross-validations for optimization.	CALTECH, Div Chem & Chem Engn, Pasadena, CA 91125 USA	Lewis, NS (reprint author), CALTECH, Div Chem & Chem Engn, Pasadena, CA 91125 USA.		Vaid, Thomas/G-9523-2012				AEBERHARD S, 1993, J CHEMOMETR, V7, P99, DOI 10.1002/cem.1180070204; Albert KJ, 2000, CHEM REV, V100, P2595, DOI 10.1021/cr980102w; BURNS JA, 1993, CHEM REV, V93, P2583, DOI 10.1021/cr00024a001; CAREY WP, 1986, ANAL CHEM, V58, P3077, DOI 10.1021/ac00127a037; CAREY WP, 1987, ANAL CHEM, V59, P1529, DOI 10.1021/ac00138a010; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Doleman BJ, 1998, P NATL ACAD SCI USA, V95, P5442, DOI 10.1073/pnas.95.10.5442; Doleman BJ, 1998, ANAL CHEM, V70, P4177, DOI 10.1021/ac971204+; Duda R., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRANK I E, 1989, Journal of Chemometrics, V3, P463, DOI 10.1002/cem.1180030304; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Livingstone D., 1995, DATA ANAL CHEM APPL; Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j; LORBER A, 1986, ANAL CHEM, V58, P1167, DOI 10.1021/ac00297a042; Severin EJ, 2000, ANAL CHEM, V72, P658, DOI 10.1021/ac9910278; VAID T, UNPUB; WEAST RC, 1986, CRC HDB CHEM PHYSICS; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0	23	35	35	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700		ANAL CHEM	Anal. Chem.	JAN 15	2001	73	2					321	331		10.1021/ac000792f		11	Chemistry, Analytical	Chemistry	391QE	WOS:000166366000028	
S	Domeniconi, C; Peng, J; Gunopulos, D		Leen, TK; Dietterich, TG; Tresp, V		Domeniconi, C; Peng, J; Gunopulos, D			An adaptive metric machine for pattern classification	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 13	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS		English	Proceedings Paper	14th Annual Neural Information Processing Systems Conference (NIPS)	NOV 27-DEC 02, 2000	DENVER, CO				NEAREST-NEIGHBOR CLASSIFICATION	Nearest neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a locally adaptive nearest neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for producing neighborhoods that axe elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the modified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using a variety of real world data.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Domeniconi, C (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.						Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2000, PROC CVPR IEEE, P517, DOI 10.1109/CVPR.2000.855863; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Merz C. J., 1996, UCI REPOSITORY MACHI; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Quinlin J. R., 1993, C4 5 PROGRAMS MACHIN	12	3	3	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1049-5258	0-262-12241-3	ADV NEUR IN			2001	13						458	464				7	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	BT08J	WOS:000171891800065	
J	Comas, J; Dzeroski, S; Gibert, K; Roda, IR; Sanchez-Marre, M				Comas, J; Dzeroski, S; Gibert, K; Roda, IR; Sanchez-Marre, M			Knowledge discovery by means of inductive methods in wastewater treatment plant data	AI COMMUNICATIONS			English	Article; Proceedings Paper	2nd Workshop on Binding Environmental Science and Artificial Intelligence (BESAI '2000)	2000	BERLIN, GERMANY			knowledge discovery; machine learning; decision trees; rule induction; statistical clustering and rule induction; case-based learning; instance-based learning; wastewater treatment	SYSTEM	Artificial intelligence techniques, including machine learning methods, and statistical techniques have shown promising results as decision support tools, because of their capabilities of knowledge discovery, heuristic reasoning and working with uncertain and qualitative information. Wastewater treatment plants are complex environmental processes that are difficult to manage and control. This paper discusses the qualitative and quantitative performance of several machine learning and statistical methods to discover knowledge patterns in data. The methods are tested and compared on a wastewater treatment data set. The methods used are: induction of decision trees, two different techniques of rule induction and two memory-based learning methods: instance-based learning and case-based learning. All the knowledge patterns discovered by the different methods are compared in terms of predictive accuracy, the number of attributes and examples used, and the meaningful-ness to domain experts.	Tech Univ Catalonia, Dept Software, Artificial Intelligence Sect, E-08034 Barcelona, Catalonia, Spain; Univ Girona, Chem & Environm Engn Lab, E-17071 Girona, Catlonia, Spain; Jozef Stefan Inst, Dept Intelligent Syst, SI-1000 Ljubljana, Slovenia; Tech Univ Catalonia, Dept Stat & Operat Res, E-08028 Barcelona, Spain	Sanchez-Marre, M (reprint author), Tech Univ Catalonia, Dept Software, Artificial Intelligence Sect, Campus Nord Edifici C5, E-08034 Barcelona, Catalonia, Spain.		Sanchez-Marre, Miquel/A-8569-2011				AAMODT A, 1994, AI COMMUN, V7, P39; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BEJAR J, 1995, THESIS U POLITECNICA; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COMAS J, 1999, P 8 SPAN C ART INT C, P17; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NEAREST NEIGHBOUR NN; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1957, 4 US AIR FORC SCH AV; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GIBERT K, 2000, WORKSH BIND ENV SCI; GIBERT K, 1994, THESIS TU CATALONIA; Gibert K, 1998, LECT NOTES ARTIF INT, V1510, P83; Gibert K, 1998, COMPUTACION SISTEMAS, V1, P213; GIBERT K, 2000, P 10 C ESP TECN LOG, P497; Guariso G., 1989, ENV DECISION SUPPORT; HOLTE R, 1989, P 10 INT JOINT C ART; JENKINS D, 1993, MANUAL CAUSES CONTRO; Kolodner J., 1993, CASE BASED LEARNING; Kolodner J., 1993, CASE BASED REASONING; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RODA IR, 1999, P CHEM IND ENV, V3, P653; RODA IR, 2000, IN PRESS ENV TEC SEP; Roda IR, 1999, CHEM ENG PROG, V95, P39; RODA LR, 1999, AAAI 99 WORKSH ENV D, P68; Sanchez M, 1996, ARTIF INTELL ENG, V10, P275, DOI 10.1016/0954-1810(96)00004-0; Sanchez-Marre M., 1997, Microcomputers in Civil Engineering, V12; Sanchez M, 1997, APPL INTELL, V7, P147, DOI 10.1023/A:1008202113300; Sanchez-Marre M, 1999, ENVIRON MODELL SOFTW, V14, P349, DOI 10.1016/S1364-8152(98)00097-8; SANCHEZMARRE M, 1998, ACIA B, V14, P246; SHANNON CE, 1948, AT&T TECH J, V27, P379; Tukey J. W, 1977, EXPLORATORY DATA ANA; WATSO I, 1996, LECT NOTES ARTIF INT, V1020, P3; WETTSCHERECK D, 1994, THESIS OREGON STATE; Witten I. H., 2000, DATA MINING; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445	42	17	17	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2001	14	1					45	62				18	Computer Science, Artificial Intelligence	Computer Science	425CC	WOS:000168269900006	
B	Roncaglia, A; Brasini, F; Elmi, I; Dori, L; Rudan, M		Stetter, JR; Penrose, WR		Roncaglia, A; Brasini, F; Elmi, I; Dori, L; Rudan, M			Improving concentration estimation of pollutant gases by means of K-nn classification with adaptive vote	ARTIFICIAL CHEMICAL SENSING: OLFACTION AND THE ELECTRONIC NOSE (ISOEN 2001)	ELECTROCHEMICAL SOCIETY SERIES		English	Proceedings Paper	8th International Symposium on Olfaction and the Electronic Nose (ISOEN 2001)	MAR 25-30, 2001	WASHINGTON, D.C.	Electrochem Soc, Sensor Div				Principal Component Analysis with K-nn classification is often used in the field of electronic nose. The classification is usually based on consensual vote of the nearest neighbors. In this paper, a different decision policy is implemented, based on an adaptive vote which takes into account the structure of the-knowledge set. The method is tested on an experimental data set acquired with an array of tin oxide sensors for environmental applications.	Univ Bologna, DEIS, I-40136 Bologna, Italy	Roncaglia, A (reprint author), Univ Bologna, DEIS, Viale Risorgimento 2, I-40136 Bologna, Italy.						BRASINI F, 1989, SENSOR ACTUAT B-CHEM, V69, P219; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DORI L, 1997, EUROSENSORS, V11; GARDNER JW, 1991, SENSOR ACTUAT B-CHEM, V4, P109, DOI 10.1016/0925-4005(91)80185-M; ROVATTI R, 1995, NEURAL COMPUT, V7, P594, DOI 10.1162/neco.1995.7.3.594; SHURMER HV, 1989, SENSOR ACTUATOR, V18, P361, DOI 10.1016/0250-6874(89)87042-8; STETTER JR, 1992, ANAL CHEM, V58, P109	7	0	0	ELECTROCHEMICAL SOCIETY INC	PENNINGTON	65 S MAIN ST, PENNINGTON, NJ 08534-2839 USA		1-56677-321-0	ELEC SOC S			2001	2001	15					170	175				6	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	BX29M	WOS:000184844800026	
J	Attaf, MT				Attaf, MT			Determination of states of operation by input feed signal analysis	CANADIAN JOURNAL OF PHYSICS			French	Article							PATTERN	We want to solve a problem one faces in the automobile industry. We aim to develop a method capable of precision measurements on systems made up of four coupled electric machines hermetically enclosed, each having three possible states of operation. The main problem comes from the impossibility of making direct measurements inside the enclosure, the only measurable quantity being the global input signal. The method introduces a technique to separate the states of operation from that of failure, using an analysis in Fourier space of the small variations of the input signal.	Ecole Polytech, Dept Genie Phys, Montreal, PQ H3C 3A7, Canada; Univ Quebec, Dept Phys, Montreal, PQ H3C 3P8, Canada	Attaf, MT (reprint author), Ecole Polytech, Dept Genie Phys, CP 6079,Succ Ctr Ville, Montreal, PQ H3C 3A7, Canada.						ABARBANEL HDI, 1992, P IEEE INT C AC SPEE, V4, P113, DOI 409238438,12,1; Bousseljot R, 1998, COMPUT CARDIOL, V25, P349; CHEN CH, 1983, DIGITAL WAVEFORM REC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1979, IEEE T INFORM THEORY, V25, P749, DOI 10.1109/TIT.1979.1056099; Ferguson T. S., 1967, MATH STAT DECISION T; Fukunaga K., 1990, INTRO STAT PATTERN R; GLEICK J, 1987, THEORIE CHAOS; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; ISABELLE SH, 1998, DIGITAL SIGNAL PROCE, pCH72; JUFER M, 1989, CIRCUITS MAGNETIQUES; KUFNER A, 1971, FOURIER SERIES; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Marill T., 1960, Institute of Radio Engineers Transactions on Electronic Computers, VEC-9; Moon F.C., 1987, CHAOTIC VIBRATIONS I; OPPENHEIM AV, 1998, DIGITAL SIGNAL PROCE, pCH71; SCHWARTZ M, 1975, SIGNAL PROCESSING DI; SEBESTYEN GS, 1961, IRE T INFORM THEOR, V7, P44, DOI 10.1109/TIT.1961.1057617; Semnani RJ, 1998, COMPUT CARDIOL, V25, P57; Shanmugan K. S., 1988, RANDOM SIGNALS DETEC; TOU J, 1981, PATTERN RECOGNITION; Van Trees H. L., 1968, DETECTION ESTIMATI 1; WEAVERHJ, 1983, APPL DISCRETE CONTIN; WILMSHURT TH, 1985, SIGNAL RECOVERY NOIS	24	0	0	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA, ONTARIO K1A 0R6, CANADA	0008-4204		CAN J PHYS	Can. J. Phys.	JAN	2001	79	1					59	74		10.1139/cjp-79-1-59		16	Physics, Multidisciplinary	Physics	423JF	WOS:000168172000006	
B	Dahbur, K; Muscarello, T		Chung, A		Dahbur, K; Muscarello, T			Cascaded system for criminal pattern classification	COMPUTER APPLICATIONS IN INDUSTRY AND ENGINEERING			English	Proceedings Paper	14th International Conference on Computer Applications in Industry and Engineering	NOV 27-29, 2001	LAS VEGAS, NV	Int Soc Comp & Their Applicat		neural network; Kohonen network; data mining	MACHINE	Data mining is a field in computer science that specializes in extracting implicit information that is distributed across the stored data records and/or exists as associations among groups of records. Discovering serial criminal patterns in crime databases is, in general, a clustering activity in the area of data mining that is concerned with detecting trends in the data by classifying and grouping similar records. In this paper, we report on the different statistical and neural network approaches to the clustering problem in data mining in general, and as it applies to our crime domain in particular. We discuss our approach of using a cascaded network of Kohonen neural networks followed by heuristic processing of the networks outputs. We address the issues in this project and the reasoning behind this approach, including: the choice of neural networks, in general, over statistical algorithms as the main tool, and the use of Kohonen networks in particular, the choice for the cascaded approach instead of the direct approach, and the choice of a heuristics subsystem as a back-end subsystem to the neural networks.	Depaul Univ, Chicago, IL 60604 USA	Dahbur, K (reprint author), Depaul Univ, Chicago, IL 60604 USA.						Adriaans P., 1996, DATA MINING; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BATCHELO.BG, 1969, ELECTRON LETT, V5, P481, DOI 10.1049/el:19690366; Bigus J. P., 1996, DATA MINING NEURAL N; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V2; CARPENTER GA, 1988, COMPUTER, V21, P77, DOI 10.1109/2.33; CARPENTER GA, 1990, NEURAL NETWORKS, V3, P129, DOI 10.1016/0893-6080(90)90085-Y; CHUNG FL, 1994, NEURAL NETWORKS, V7, P539; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diday E., 1973, International Journal of Computer & Information Sciences, V2, DOI 10.1007/BF00987153; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; KOHONEN T, 1988, P IEEE INT C NEUR NE; Kohonen T., 1990, P IEEE, V78; LEE DH, 1996, P INT C ANN, P299; MACQUEEN J, P K BERK S PROB STAT; MCKINZIE P, 1994, IEEE INT C NEUR NETW, V2, P616; Moustakis V, 1996, INT J HUM-COMPUT INT, V8, P221; NAYLER J, 1998, 1 ANN INNS M, P311; OSHEA T, 1995, APPL ARTIFICIAL INTE; PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1; PARK DC, 1994, P IEEE C NEUR NETW, P1626; XIA X, 1996, THESIS U TEXAS AUSTI	23	0	0	INTERNATIONAL SOCIETY COMPUTER S & THEIR APPLICATIONS (ISCA)	RALEIGH	8820 SIX FORKS ROAD, RALEIGH, NC 27615 USA		1-880843-40-4				2001							13	18				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BV53R	WOS:000179289400004	
J	Pal, NR; Ghosh, S				Pal, NR; Ghosh, S			Some classification algorithms integrating Dempster-Shafer theory of evidence with the rank nearest neighbor rules	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article						nearest neighbor classifier; rank nearest neighbor; theory of evidence	MODEL	We propose five different ways of integrating Dempster-Shafer theory of evidence and the rank nearest neighbor classification rules with a view to exploiting the benefits of both. These algorithms have been tested on both real and synthetic data sets and compared with the k-NN, m-MRNN, and k-NNDST, which is an algorithm that also combines Dempster-Shafer theory with the le-NN rule. If different features have widely different variances then the distance-based classifier, algorithms like Ic-NN and k-NNDST may not perform weil, but in this case the proposed algorithms are expected to perform better. Our simulation results indeed reveal this. Moreover, the proposed algorithms are found to exhibit significant improvement over the m-MRNN rule.	Indian Stat Inst, Elect & Commun Sci Unit, Calcutta 700035, W Bengal, India; ITT Ind Inc, Adv Engn Sci, Washington, DC 20024 USA	Pal, NR (reprint author), Indian Stat Inst, Elect & Commun Sci Unit, Calcutta 700035, W Bengal, India.						ANDERSON T, 1966, P 1 INT S AN NEW YOR; BAGUI SC, 1993, PATTERN RECOGN LETT, V14, P537, DOI 10.1016/0167-8655(93)90102-J; BAGUI SC, 1995, PATTERN RECOGN LETT, V16, P601, DOI 10.1016/0167-8655(95)80006-F; BAGUI SC, 1989, THESIS U ALBERTA EDM; BHATTACHARJEE A, 1986, THESIS U CALCUTTA CA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; ELOUEDI Z, 2000, P INT C INF PROC MAN, V1, P141; Fix E., 1951, 4 USAF SCH AV MED; Johnson R A, 1988, APPL MULTIVARIATE ST; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; SHAFER G, 1994, MATH EVIDENCE DEMPST; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1998, HDB DEFEASIBLE REASO, V1, P267; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	16	2	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4427		IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	JAN	2001	31	1					59	66		10.1109/3468.903867		8	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	403VK	WOS:000167063000006	
B	Yager, RR		Smith, MH; Gruver, WA; Hall, LO		Yager, RR			Nearest neighbor rules using ordinal information	JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5			English	Proceedings Paper	9th International-Fuzzy-Systems-Association World Congress/20th North-American-Fuzzy-Information-Processing-Society, International Conference	JUL 25-28, 2001	VANCOUVER, CANADA	Int Fuzzy Syst Assoc, N Amer Fuzzy Informat Proc Soc, IEEE Syst, Man & Cybernet Soc, IEEE, Neural Networks Council				We focus on the task of obtaining missing information about some object using nearest neighbor type methods. These approaches mediate this problem with the aid of a collection of data objects about which we have fun knowledge. These methods require the calculation of the similarity between the target and the data objects and then the fusion of the known values guided by the similarities. Here we concentrate on a mixed scale situation, the similarities are numeric values but the missing information is drawn from an ordinal scale. We shown that the weighted median provides a fusion operation that can be used in this mixed scale environment. We look at some classes of nearest neighbor rules that can be expressed using this framework. Finally we turn to the problem of learning weighted median type rules and provide a learning algorithm.	Iona Coll, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				Bezdek J.C, 1999, FUZZY MODELS ALGORIT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Yager RR, 1998, INT J APPROX REASON, V18, P35, DOI 10.1016/S0888-613X(97)10003-2	3	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7078-3				2001							968	972				5	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BT52S	WOS:000173245100171	
B	Ishibuchi, H; Nakashima, T; Nii, M		Smith, MH; Gruver, WA; Hall, LO		Ishibuchi, H; Nakashima, T; Nii, M			Learning of neural networks with GA-based instance selection	JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5			English	Proceedings Paper	9th International-Fuzzy-Systems-Association World Congress/20th North-American-Fuzzy-Information-Processing-Society, International Conference	JUL 25-28, 2001	VANCOUVER, CANADA	Int Fuzzy Syst Assoc, N Amer Fuzzy Informat Proc Soc, IEEE Syst, Man & Cybernet Soc, IEEE, Neural Networks Council			GENETIC ALGORITHMS; SET	We examine the effect of instance and feature selection on the generalization ability of trained neural networks for pattern classification problems. Before the learning of neural networks, a genetic-algorithm-based instance and feature selection method is applied for reducing the size of training data. Nearest neighbor classification is used for evaluating the classification ability of subsets of training data in instance and feature selection. Neural networks are trained by the selected subset (i.e., reduced training data). In this paper, we first explain our GA-based instance and feature selection method. Then we examine the effect of instance and feature selection on the generalization ability of trained neural networks through computer simulations on various artificial and real-world pattern classification problems.	Univ Osaka Prefecture, Dept Ind Engn, Sakai, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Univ Osaka Prefecture, Dept Ind Engn, Gakuen Cho 1-1, Sakai, Osaka 5998531, Japan.						CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ishibuchi H., 2001, INSTANCE SELECTION C, P95; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7078-3				2001							2102	2107				6	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BT52S	WOS:000173245100371	
J	Al-Ammar, AS; Barnes, RM				Al-Ammar, AS; Barnes, RM			Supervised cluster classification using the original n-dimensional space without transformation into lower dimension	JOURNAL OF CHEMOMETRICS			English	Article						supervised cluster analysis; direct clustering in original space	MILK	A novel supervised classification algorithm, direct clustering in n-dimensional space (DCNS), was developed for difficult data sets where conventional methods of supervised clustering are expected to fail. The method is based, when applied on >3-dimensional spaces, on an algorithm that performs special treatment on the measurement space, so that the treated space can allow a computer-aided clustering methodology similar to that used by human vision, However, unlike other techniques that reduce the dimensionality of the space, the proposed method preserves the original dimensions while performing a computer-simulated human vision clustering in the original n-dimensional space. Thus the overlap between clusters that results from the dimensionality reduction is eliminated. The proposed method was applied to two real data sets. The results are compared with those obtained using principal component analysis (PCA), an artificial neural network (ANN), and the k-nearest-neighbor (KNN) technique. On one data set containing only two clusters, the DCNS algorithm gives better cluster separation than the other three methods. However, when all four methods were applied on the second data set, containing eight different clusters, PCA, ANN and KNN were unable to give useful cluster separation, while the DCNS method was able to separate all clusters and classify the unknown points successfully with their corresponding clusters. The DCNS technique is able to perform other important cluster analysis tasks, such as testing the discriminatory power of a variable, selecting one variable from many, and conducting preliminary unsupervised clustering. Copyright (C) 2000 John Wiley & Sons, Ltd.	Univ Massachusetts, Lederle Grad Res Ctr Towers, Dept Chem, Amherst, MA 01003 USA	Barnes, RM (reprint author), Univ Massachusetts, Lederle Grad Res Ctr Towers, Dept Chem, Box 34510, Amherst, MA 01003 USA.						Amarasiriwardena D, 1997, CAN J ANAL SCI SPECT, V42, P69; BEEBE KR, 1998, CHEMOMETRICS PRACTIC, P180; BEEBE KR, 1998, CHEMOMETRICS PRACTIC, P56; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMINE D, 1993, J CHEMOMETR, V7, P227, DOI 10.1002/cem.1180070402; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; HOFFMAN K, 1975, ANAL EUCLIDEAN SPACE, P153; KOHNEN T, 1982, BIOL CYBERN, V43, P59; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; Lutter C, 1998, CHEMOSPHERE, V37, P1761, DOI 10.1016/S0045-6535(98)00241-0; MARESDEN JE, 1974, ELEMENTARY CLASSICAL, P61; MEGLEN RR, 1991, J CHEMOMETR, V5, P163, DOI 10.1002/cem.1180050305; Watanabe S., 1985, PATTERN RECOGNITION; Werbos P. J., 1982, System Modeling and Optimization. Proceedings of the 10th IFIP Conference; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; ZHU EY, 1993, CHEM J CHINESE U, V14, P621; ZUPAN J, 1993, NEURAL NETWORKS CHEM, P171	17	1	2	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX PO19 1UD, ENGLAND	0886-9383		J CHEMOMETR	J. Chemometr.	JAN	2001	15	1					49	67		10.1002/1099-128X(200101)15:1<49::AID-CEM631>3.0.CO;2-2		19	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	397VR	WOS:000166718900005	
S	Romero, E; Raymackers, JM; Macq, B; Cuisenaire, O			IEEE; IEEE; IEEE	Romero, E; Raymackers, JM; Macq, B; Cuisenaire, O			Automatic fibrosis quantification by using a k-NN classificator	PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-4: BUILDING NEW BRIDGES AT THE FRONTIERS OF ENGINEERING AND MEDICINE	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	23rd Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society	OCT 25-28, 2001	ISTANBUL, TURKEY	Natl Sci Fdn, TUBITAK, Sci & Tech Res Ctr Turkey, ISIK Univ, COMNET, EREL Techno Grp, GUZEL SANATLAR Printinghouse, JOHNSON&JOHNSON Med, PFIZER, SIEMENS Med, TURKCELL Iletism Hizmetler A S, ALSTOM Elect Ltd Co, GANTEK Technol & SUN Microsyst, TURCOM Co Grp		automatic morphometry; fibrosis morphometry; muscle measurements; k-NN	MUSCULAR-DYSTROPHY; EFFICIENT	This work presents an automatic algorithm to measure fibrosis in muscle sections of mdx mice, a mutant species used as a model of the Duchenne dystrophy. The algorithm described herein automatically segments three different tissues: Muscle cell tissue (MT), Pure collagen fiber deposit (CD) and cellular infiltrates surrounded by loose collagen deposit (CI), by using a statistical classifier based on the k-Nearest Neighbour (k-NN) decision rule in the RGB color space. The algorithm is trained by selecting a number of correctly classified pixels from each class. The k-NN rule classifies other pixels in the class that is most represented among the k nearest training samples in the RGB space, which is efficiently implemented with a fast k-distance transform algorithm. All extracted areas are quantified in absolute (mum(2)) and relative (%) values. For validation of this method, the different tissues were manually segmented and their quantifications statistically compared with those obtained automatically. Statistical analysis showed inter-operator variability in manual segmentation. Automatic quantifications of the same areas did not differ significantly from their mean manual evaluations. In conclusion, this method produce fast, reliable and reproducible results.	Univ Catholique Louvain, Commun & Remote Sensing Lab, Louvain, Belgium	Romero, E (reprint author), Univ Catholique Louvain, Commun & Remote Sensing Lab, Louvain, Belgium.						BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; CORNELIO F, 1984, ANN NEUROL, V16, P694, DOI 10.1002/ana.410160612; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUISENAIRE O, 2000, P 10 EUR SIGN PROC C, P1365; CULLEN MJ, 1975, J NEUROL SCI, V24, P179, DOI 10.1016/0022-510X(75)90232-4; Emery A.E.H., 1993, DUCHENNE MUSCULAR DY; FIEDMAN J, 1975, IEEE T COMPUT, V24, P1000; FIX E, 1951, AF41128131 USAF SCH; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GUNDERSEN HJG, 1988, APMIS, V96, P379; HAGEMAN ATM, 1993, J NEUROL SCI, V115, P95, DOI 10.1016/0022-510X(93)90072-7; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JIANG QY, 1993, PATTERN RECOGN LETT, V14, P531, DOI 10.1016/0167-8655(93)90101-I; MARKESBERY WR, 1977, NEUROLOGY, V27, P727; Nyengaard JR, 1999, J AM SOC NEPHROL, V10, P1100; REMUZZI A, 1995, KIDNEY INT, V48, P155, DOI 10.1038/ki.1995.279; Romano LA, 1996, J HISTOTECHNOL, V19, P121; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; Weibel ER, 1989, STEREOLOGICAL METHOD	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X	0-7803-7211-5	P ANN INT IEEE EMBS			2001	23		1-4				2609	2612				4	Cardiac & Cardiovascular Systems; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Neurosciences	Cardiovascular System & Cardiology; Computer Science; Engineering; Neurosciences & Neurology	BV41G	WOS:000178871900710	
B	Marsh, R		Arabnia, HR		Marsh, R			Improved correlation target rejection using neural net post-processing	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II			English	Proceedings Paper	International Conference on Imaging Science, Systems, and Technology (CISST 2001)	JUN 25-28, 2001	LAS VEGAS, NV	Comp Sci Res, Educ & Applicat Press, Int Technol Inst, Korea Informat Processing Soc, World Acad Sci Informat Technol, PACT Corp		optical correlation; matched filters; pattern recognition; neural networks	INVARIANT PATTERN-RECOGNITION; CIRCULAR HARMONIC EXPANSION; FOURIER-MELLIN DESCRIPTORS; TRANSFORMS; ALGORITHM; ROTATION; NETWORKS	An improvement on the scale and rotation tolerant correlation inethodfirst proposed by Casesent and Psaltis[1] is presented. In computer simulations, using a target set of 26 scaled and rotated objects (1820 images total), a non-target set of 10 scaled and rotated objects (700 images total), the system accurately identified targets with 88.4% accuracy and rejected non-targets with 95.6% accuracy, We preprocess the target and reference images with a centering algorithm, a log-polar transform, and a modified median filter. The resulting image data is correlated using a typical 4-f correlator and post-processed by a neural network.	Univ N Dakota, Dept Comp Sci, Grand Forks, ND 58201 USA	Marsh, R (reprint author), Univ N Dakota, Dept Comp Sci, Grand Forks, ND 58201 USA.						AGUI T, 1991, SPIE, V1606, P188; Altmann J., 1987, Journal of Information Processing and Cybernetics, V23; APICELLA A, 1989, P SOC PHOTO-OPT INS, V1092, P252; BOOTH JJ, 1995, P SOC PHOTO-OPT INS, V2490, P108; BROUSIL JK, 1967, IEEE TRANS ELECTRON, VEC16, P818, DOI 10.1109/PGEC.1967.264726; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; COTTRELL DM, 1987, APPL OPTICS, V26, P3755, DOI 10.1364/AO.26.003755; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta B, 1996, J I EL TELECOM ENG, V42, P3; Goodman J. W., 1968, INTRO FOURIER OPTICS; GRACE AE, 1991, PATTERN RECOGN LETT, V12, P635, DOI 10.1016/0167-8655(91)90018-H; HORNER JL, 1984, APPL OPTICS, V23, P812; HSU YN, 1982, APPL OPTICS, V21, P4016, DOI 10.1364/AO.21.004016; HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012; JUELL P, 2000, P INT C IM SCI SYST; KUMAR BVKV, 1992, APPL OPTICS, V31, P4773, DOI 10.1364/AO.31.004773; MARSH R, 1990, Patent No. 07545013; MEHANIAN C, 1991, SPIE, V1471, P200; MINNIX JI, 1991, VISUAL COMMUNICATION, V1606, P241; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Pratt WK, 1978, DIGITAL IMAGE PROCES, P526; Schalkoff RJ, 1989, DIGITAL IMAGE PROCES, P279; SCHILS GF, 1988, J OPT SOC AM A, V5, P1309, DOI 10.1364/JOSAA.5.001309; SHENG Y, 1986, J OPT SOC AM A, V3, P771, DOI 10.1364/JOSAA.3.000771; SHENG YL, 1991, J OPT, V22, P223, DOI 10.1088/0150-536X/22/5/003; THORNTON AL, 1997, 6 INT C IM PROC ITS; TITCHMARSH EC, 1959, INTRO THEORY FOURIER; VANDERLUGT A, 1964, IEEE T INFORMATION T, V10, P130; WALSH TR, 1990, OPT ENG, V29, P1052; WHALEN AD, 1971, DETECTION SIGNALS NO, P167; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0; ZELL A, 1995, SNNS STUTTGART NEURA	33	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA		1-892512-74-2				2001							419	425				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BT32W	WOS:000172651200068	
J	Tomppo, E; Korhonen, KT; Heikkinen, J; Yli-Kojola, H				Tomppo, E; Korhonen, KT; Heikkinen, J; Yli-Kojola, H			Multi-source inventory of the forests of the Hebei Forestry Bureau, Heilongjiang, China.	SILVA FENNICA			English	Article						forest inventory; satellite images; k-nearest neighbour method; models; China		A multi-source forest inventory method is applied to the estimation of forest resources in the area of the Hebei Forest Bureau in Heilongjiang province in North-East China. A stratified systematic cluster sampling design was utilised in field measurements. The design was constructed on the basis of information from earlier stand-level inventories, aerial orthophotographs, experiences from other sampling inventories and the available budget. Sample tree volumes were estimated by means of existing models. New models were constructed and their parameters estimated for tallied tree volumes and volume increments. The estimates for the area of the Bureau were computed from field measurements. and for the areas of the forest farms estimated from field measurements and satellite images. A k-nearest neighbour method was utilised. This method employing satellite image data makes it possible to estimate all variables, particularly for smaller areas than that possible using field measurements only. The methods presented, or their modifications, could also be applied to the planning and realisation of forest inventories elsewhere in Temperate or Boreal zones. The inventory in question gave an estimate of 114 m(3)/ha (the multi-source inventory 119 m(3)/ha) instead of 72 m(3)/ha as previously estimated from available information. Totally nineteen tree species, genera of species or tree species groups were identified (Appendix 1). The forests were relatively young, 60% of them younger than 40 years and 85% younger than 60 years.	Finnish Forest Res Inst, FIN-00170 Helsinki, Finland	Tomppo, E (reprint author), Finnish Forest Res Inst, Uninioninkatu 40 A, FIN-00170 Helsinki, Finland.						Cochran W. G, 1977, SAMPLING TECHNIQUES; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNIA T, 1987, ESTIMATION TRESS BIO, P37; DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P121; KILKKI P, 1987, REMOTE SENSING AIDED, P209; KORHONEN KT, 1990, SILVA FENNICA, V25, P77; KORHONEN KT, 1993, UNPUB FIELD INSTRUCT; KUJALA M, 1980, FOLIA FORESTALIA, V441; LAPPI J, 1991, SAMPLE PLOT SIZE STA; Loetsch F., 1973, FOREST INVENTORY, VII; MATEM B, 1947, MEDDELANDEN FRAN STA, V36; MATEM B, 1986, LECT NOTES STAT, V36; PAIVINEN R, 1987, PUBLICATIONS SCI, V11; Poso S., 1972, COMMUNICATIONES I FO, P76; Poso S., 1978, COMMUNICATIONES I FO, V93; Ranneby B, 1987, STUDIA FORESTALIA SU, V177; RANNEBY B, 1981, 21 SWED U AGR SCI SE; SALMINEN S, 1985, SILVA FENNICA, V19, P226; SCHREUDER H.T., 1993, SAMPLING METHODS MUL; SVENSSON SA, 1988, 46 SWED U AGR SCI DE; Tomppo E., 1991, INT ARCH PHOTOGRAMME, V28, P419; TOMPPO E, 1994, INVENTORY RESULTS HE; TOMPPO E, 1996, IUFRO 20 WORLD C 6 1; TOMPPO E, 1997, STUDY EUROPEAN FORES, P145; TOMPPO E, 1998, FOLIA FORESTALIA B, V2, P293; *EUR COMM, 1997, STUD EUR FOR INF COM	27	16	18	EXCHANGE CENTRE SCIENTIFIC LITERATURE	HELSINKI	MARIANKATU 5, FIN-00170 HELSINKI, FINLAND	0037-5330		SILVA FENN	Silva. Fenn.		2001	35	3					309	328				20	Forestry	Forestry	482NH	WOS:000171581900005	
B	Vuori V; Laaksonen, J; Oja, E; Kangas, J			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Vuori, V; Laaksonen, J; Oja, E; Kangas, J			Speeding up on-line recognition of handwritten characters by pruning the prototype set	SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, PROCEEDINGS			English	Proceedings Paper	6th International Conference on Document Analysis and Recognition (ICDAR)	SEP 10-13, 2001	SEATTLE, WA	Int Assoc Pattern Recognit				This work describes a prototype-based online handwritten character recognition system and a two-phase recognition scheme aimed to speed up the recognition. In the first phase, the prototype set is pruned and ordered on the basis of preclassification performed with heavily down-sampled characters and prototypes. In the second phase, the final classification is perforated without down-sampling by using the reduced set of prototypes. Two down-sampling methods, a linear and nonlinear one, have been analyzed to see their properties regarding the recognition time and accuracy.	Helsinki Univ Technol, Lab Comp & Informat Sci, FIN-02015 Helsinki, Finland	Vuori V (reprint author), Helsinki Univ Technol, Lab Comp & Informat Sci, POB 5400, FIN-02015 Helsinki, Finland.	vuokko.vuori@hut.fi; jorma.laaksonen@hut.fi; erkki.oja@hut.fi; jari.a.kangas@nokia.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANKISH C, 1995, P ACM CHI 95 C HUM F; Kohonen T., 1997, SPRINGER SERIES INFO, V30; LAAKSONEN J, 1998, P INT C ART NEUR NET, P245; LaLomia M.J., 1994, P ACM CHI 94 HUM FAC, P107; MACKENZIE IS, 1994, INT J HUM-COMPUT ST, V41, P775, DOI 10.1006/ijhc.1994.1081; Sankoff D., 1983, TIME WARPS STRING ED; Vuori V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791907; VUORI V, 1999, THESIS HELSINKI U TE; Vuori V., 2000, P 7 INT WORKSH FRONT, P13; Webster RG, 1998, PATTERN RECOGN, V31, P193, DOI 10.1016/S0031-3203(97)00036-8	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1263-1				2001							501	505				3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BT06N	WOS:000171845000096	
B	Lisboa, FOSS; Nicoletti, MD; Ramer, A			IEEE; IEEE; IEEE	Lisboa, FOSS; Nicoletti, MD; Ramer, A			A fuzzy classifier system based on generalized exemplars	10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3: MEETING THE GRAND CHALLENGE: MACHINES THAT SERVE PEOPLE			English	Proceedings Paper	10th IEEE International Conference on Fuzzy Systems	DEC 02-05, 2001	MELBOURNE, AUSTRALIA	IEEE	UNIV MELBOURNE			This paper describes the main ideas used in the development of a fuzzy classifier system which induces fuzzy hypotheses from a set of examples described by fuzzy real numbers and an associated crisp class. It presents and discusses some results obtained using a prototype system.	USP, IFSC, BR-13560970 Sao Carlos, SP, Brazil	Lisboa, FOSS (reprint author), USP, IFSC, BR-13560970 Sao Carlos, SP, Brazil.		Lisboa, Flavia/I-6767-2012				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MERZ C. J., 1998, THESIS U CALIFORNIA; NICOLETTI MC, 1996, P EUR WORKSH FUZZ DE, P140; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALZBERG S, 1991, MACH LEARN, V6, P252	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7293-X				2001							73	76				4	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Automation & Control Systems; Computer Science; Engineering; Imaging Science & Photographic Technology	BV21J	WOS:000178178300018	
S	Bissacco, A; Chiuso, A; Ma, Y; Soatto, S		Jacobs, A; Baldwin, T		Bissacco, A; Chiuso, A; Ma, Y; Soatto, S			Recognition of human gaits	2001 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOL 2, PROCEEDINGS	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	Conference on Computer Vision and Pattern Recognition	DEC 08-14, 2001	KAUAI, HI	IEEE Comp Soc			SUBSPACE ALGORITHMS; IDENTIFICATION; CLASSIFICATION; DYNAMICS	We pose the problem of recognizing different types of human gait in the space of dynamical systems where each gait is represented Established techniques are employed to track a kinematic model of a human body in motion, and the trajectories of the parameters are used to learn a representation of a dynamical system, which defines a gait.. Various types of distance between models are then computed These computations are non trivial due to the fact that, even for the case of linear systems, the space of canonical realizations is not linear.	Univ Calif Los Angeles, Los Angeles, CA 90095 USA	Bissacco, A (reprint author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.						Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; BLACK M, 1996, EIGENTRACKING ROBUST; Black M., 1998, P 5 EUR C COMP VIS, V1, P909; BOBICK A, 1996, APPEARANCE BASED REP; Brand M., 1997, P C COMP VIS PATT RE, P213; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; Campbell L. W., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466880; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DECOCK K, 2000, P INT S MATH THEORY; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GAVRILA DM, 1996, TRACKING HUMANS ACTI; GIESE MA, 2000, INT J COMPUT VISION, V38, P1264; GOLUB G, 1992, IMA VOLUMES MATH ITS, V69, P27; Hoey J., 2000, P C COMP VIS PATT RE, V1, P752, DOI 10.1109/CVPR.2000.855896; LITTLE JJ, 1996, RECOGNIZING PEOPLE T; Ljung L., 1987, SYSTEM IDENTIFICATIO; Madabhushi A., 1999, Proceedings Second IEEE Workshop on Visual Surveillance (VS'99) (Cat. No.98-89223), DOI 10.1109/VS.1999.780265; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; NIYOGI AA, 1994, P IEEE C COMP VIS PA, P469; North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523; PAVLOVIC V, 2000, P INT C COMP VIS PAT; STARNER T, 1997, P ISCV 95, V29, P213; VANOVERSCHEE P, 1994, AUTOMATICA, V30, P75, DOI 10.1016/0005-1098(94)90230-5; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; WEINSTEIN A, 1999, BERKELEY CPAM PREPRI, V768; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; WREN C, 1998, DYNAMIC MODELS HUMAN; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726	28	6	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919	0-7695-1272-0	PROC CVPR IEEE			2001							52	57				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX22K	WOS:000184694400008	
B	Solanas, E; Duay, V; Cuisenaire, O; Thiran, JP			IEEE; IEEE	Solanas, E; Duay, V; Cuisenaire, O; Thiran, JP			Relative anatomical location for statistical non-parametric brain tissue classification in MR images	2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS			English	Proceedings Paper	International Conference on Image Processing (ICIP 2001)	OCT 07-10, 2001	THESSALONIKI, GREECE	IEEE Signal Processing Soc, IEEE				We propose a statistical non-parametric classification of brain tissues from an MR image based on the voxel intensities and on die relative anatomical location of the different tissues. Classically, the overlap of the tissue probability distribution functions for voxel intensities can be reduced by using multi-component (T1w,T2w,Pd....) MR images, but at a much higher cost for image acquisition. Instead, we generate an artificial image component as the distance from the edges of the segmented brain. The non-parametric k-Nearest Neighbors rule (k-NN) is used since it requires no a priori on the probability distribution of this distance component. The k-NN rule is also tested using different metrics (Euclidean, weighted Euclidean, Mahalanobis) in the classification space to define what "nearest neighbors" are. The results are twofold: firstly we show that all metrics perform well in ideal conditions, but that the Mahalanobis (and to some extent the weighted Euclidean) metric is more robust in case of under-training of the classifier. Secondly we show that using the relative anatomical location in combination with the intensity information improves the classification of the tissues.	Swiss Fed Inst Technol, EPFL, Signal Proc Lab, LTS, CH-1015 Lausanne, Switzerland	Solanas, E (reprint author), Swiss Fed Inst Technol, EPFL, Signal Proc Lab, LTS, CH-1015 Lausanne, Switzerland.						BRUMMER ME, 1993, IEEE T MED IMAGING, V12, P153, DOI 10.1109/42.232244; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUISENAIRE O, 2000, P 10 EUR SIGN PROC C, P1365; CUISENAIRE O, 1999, THESIS CATHOLIC U LO; Devroye L, 1996, PROBABILISTIC THEORY; Duda R., 1973, PATTERN CLASSIFICATI; FIX E, 1952, 2149004 USAF; FIX E, 1951, 2149004 USAF; SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3; SCHROETER P, 1996, THESIS SWISS FEDERAL	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-6725-1				2001							885	888				4	Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BV16U	WOS:000178044600225	
B	Raymer, ML; Kuhn, LA; Punch, WF			IEEE COMPUTER SOCIETY; IEEE COMPUTER SOCIETY	Raymer, ML; Kuhn, LA; Punch, WF			Knowledge discovery in biological datasets using a hybrid Bayes classifier/evolutionary algorithm	2ND ANNUAL IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS			English	Proceedings Paper	2nd IEEE International Symposium on Bioinformatics and Bioengineering (BIBE 2001)	NOV 04-06, 2001	BETHESDA, MD	IEEE Comp Soc, IEEE CS Virtual Intelligence Task Force, Wright State Univ, Informat Technol Res Inst, AIIS Inc			GENETIC ALGORITHMS; FEATURE-SELECTION	A key element of bioinformatics research is the extraction of meaningful information fi-om large experimental data sets. Various approaches, including statistical and graph theoretical methods, data mining, and computational pattern recognition, have been applied to this task with varying degrees of success. We have previously shown that a genetic algorithm coupled with a k-nearest-neighbors classifier performs well in extracting information about protein-water binding from X-ray crystallographic protein structure data. Using a novel classifier based on the Bayes discriminant function, we present a hybrid algorithm that employs feature selection and extraction to isolate salient features from large biological data sets. The effectiveness of this algorithm is demonstrated on various biological and medical data sets.	Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA	Raymer, ML (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.		Raymer, Michael/G-3398-2013	Raymer, Michael/0000-0003-2649-0792			BAYES T, PHIL T ROY SOC, V53, P1763; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JAYNES ET, 1968, IEEE T SYST SCI CYB, VSSC4, P227, DOI 10.1109/TSSC.1968.300117; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; MAO J, 1994, P 12 INT C PATT REC, P622; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; Pudil P., 1994, PATTERN RECOGN, V15, P1119; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1986, MACHINE LEARNING ART, P149; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1986, P 2 AUSTR C APPL EXP; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; RAYMER ML, 1997, P 7 INT C GEN ALG IC, P561; RAYMER ML, 2001, UNPUB PROTEIN ENG; Raymer ML, 1997, J MOL BIOL, V265, P445, DOI 10.1006/jmbi.1996.0746; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; VAFAIE H, 1998, FEATURE EXTRACTION C, P307; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; YANG J, 1998, P INT JOINT C NEUR N; YANG J, 1998, FEATURE EXTRACTION C, P117	31	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1423-5				2001							236	245				10	Computer Science, Interdisciplinary Applications; Engineering, Biomedical	Computer Science; Engineering	BT33T	WOS:000172674600031	
B	Henry, JL		Verma, B; Namatame, A; Yao, X; Selvaraj, H; DeCarvalho, A; Ohuchi, A		Henry, JL			A k-nearest neighbour method for managing the evolution of a learning base	ICCIMA 2001: FOURTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Computational Intelligence and Multimedia Applications (ICCIMA 2001)	OCT 30-NOV 01, 2001	YOKUSIKA, JAPAN	CS, Natl Defense Acad, CIRL, Griffith Univ, SCS, Univ Birmingham, EE, Univ Las Vegas, CS, Univ Sao Paulo				A character recognition system with continuous learning seeks to constantly enhance its base representation models in order to provide the best recognition rate. The method we are presenting enables the system to enhance its base with models, which are performant in recognition. This method also enables to get rid of models regularly doubtable it? efficiency when it comes to interpretation of the characters studied. This ride is similar to the one used in the "Death by, suffocation" game of life of Conway. We based ourselves oil the theory of k-nearest neighbours to develop a new approach we named, epsilon -adaptive neighbourhood. It makes an adjustment of classes possible, according to confidence rate in each model of the learning base. These rates which are practically, represented as weights are taken into account by the stage of the recognition system during the character recognition phase. The use of weight as a model selection factor, useful for recognition, enables the system to Manage the evolution of the learning base.	TRIVIA, Fac Sci Exactes & Nat, Pointe A Pitre 97159, Guadeloupe	Henry, JL (reprint author), TRIVIA, Fac Sci Exactes & Nat, Pointe A Pitre 97159, Guadeloupe.						Cech E, 1966, TOPOLOGICAL SPACES; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; HART PE, 1968, IEEE T INFORMATION T, V14; HENRY JL, 1996, P IAPR WORKSH MACH V, P377; Kittler J., 1982, PATTERN RECOGNITION; KITTLER J, 1978, KYBERNETES, V7, P313, DOI 10.1108/eb005497; SBLIEN S, 1988, INT J PATTERN RECOGN, V2, P608; SINHA RMK, 1988, PATTERN RECOGN, V21, P463, DOI 10.1016/0031-3203(88)90006-4; TAKAHASHI H, 1990, PATTERN RECOGN, V23, P363, DOI 10.1016/0031-3203(90)90023-E; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1312-3				2001							357	361				5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Computer Science; Engineering	BT43T	WOS:000173022300070	
J	Azuaje, F; Dubitzky, W; Black, N; Adamson, K				Azuaje, F; Dubitzky, W; Black, N; Adamson, K			Retrieval strategies for case-based reasoning: a categorised bibliography	KNOWLEDGE ENGINEERING REVIEW			English	Review							ENGINEERING DESIGN RETRIEVAL; NEAREST-NEIGHBOR RULE; INFORMATION-RETRIEVAL; PATTERN-CLASSIFICATION; SIMILARITY MEASURES; NEURAL-NETWORK; FUZZY VALUES; ALGORITHM; SYSTEM; KNOWLEDGE	The retrieval of relevant cases plays a crucial role in case-based reasoning. There are three major methods for the retrieval of relevant cases: computational approaches (based upon measures of similarity), representational approaches (based upon indexing structures) and hybrid approaches. This paper looks at recent successful implementations of case retrieval with regard to this classification framework. Similarly it emphasises computational and representational models applied to feature-vector case representations.	Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland; German Canc Res Ctr, Bioinformat Syst, D-6900 Heidelberg, Germany; Univ Ulster, Sch Informat & Software Engn, Coleraine BT52 1SA, Londonderry, North Ireland	Azuaje, F (reprint author), Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland.						AAMODT A, 1994, AI COMMUN, V7, P39; AAMODT A, 1989, P 3 EUR KNOW ACQ KNO, P311; Aamodt A., 1991, THESIS U TRONDHEIM; AGRE G, 1995, P 1 INT C ICCBR 95 O, P109; AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1993, P 14 ANN C COGN SCI, P534; ANAND S, 1998, LECT NOTES ARTIFICIA, V1394; Anand SS, 1999, ARTIF INTELL MED, V15, P193, DOI 10.1016/S0933-3657(98)00052-9; ARYA S, 1995, THESIS U MAR COMP VI; ATKESON CG, 1997, LAZY LEARNING; Azuaje F, 2000, IEEE T SYST MAN CY B, V30, P448, DOI 10.1109/3477.846233; Azuaje FJ, 1998, PROCEEDING OF THE THIRD INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND EXPERT SYSTEMS IN MEDICINE AND HEALTHCARE, P286; AZUAJE F, 1998, P 8 MED C MED BIOL E; Azuaje F, 1999, IEEE T BIO-MED ENG, V46, P1181, DOI 10.1109/10.790493; BATH PA, 1994, J CHEM INF COMP SCI, V34, P141, DOI 10.1021/ci00017a017; BECKER L, 1989, P CAS BAS REAS WORKS; BIBERMAN Y, 1994, LECT NOTES COMPUTER, V784; Bloch G, 1997, IEEE T NEURAL NETWOR, V8, P910, DOI 10.1109/72.595889; BONZANO A, 1997, P CAS BAS REAS RES D; BONZANO A, 1997, CASE BASED REASONING; BRIDGE D, 1998, LECT NOTES ARTIFICIA, V1488; CAIN T, 1991, P CAS BAS REAS WORKS, P23; CAUDELL TP, 1994, NEURAL NETWORKS, V7, P1339, DOI 10.1016/0893-6080(94)90084-1; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen S., 1992, FUZZY MULTIPLE ATTRI; CHEN SM, 1995, FUZZY SET SYST, V72, P79; Cleary J. G., 1979, ACM Transactions on Mathematical Software, V5, DOI 10.1145/355826.355832; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Coupey P, 1998, APPL ARTIF INTELL, V12, P71, DOI 10.1080/088395198117910; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox E, 1994, FUZZY SYSTEMS HDB PR; DAS G, 1997, LECT NOTES ARTIFICIA, V1263; DASARATHY V, 1991, NEAREST NEIGHBOUR NN; Davey B. A., 1990, INTRO LATTICES ORDER; deAngulo VR, 1997, IEEE T NEURAL NETWOR, V8, P951, DOI 10.1109/72.595895; Dickhaus H, 1996, IEEE ENG MED BIOL, V15, P103, DOI 10.1109/51.537066; DIDAY E, 1974, P 2 INT JOINT C PATT, P534; Di Gesu V, 1999, PATTERN RECOGN LETT, V20, P207, DOI 10.1016/S0167-8655(98)00115-9; Dorronsoro JR, 1997, IEEE T NEURAL NETWOR, V8, P827, DOI 10.1109/72.595879; DOWNS GM, 1995, REV COMP CH, V7, P1; DOWNS GM, 1985, REV COMPUTATIONAL CH, V7, P1; Downs J, 1996, ARTIF INTELL MED, V8, P403, DOI 10.1016/0933-3657(95)00044-5; DUBITZKY W, 1996, P 2 INT C NEUR NETW, P97; DUBITZKY W, 1997, P 15 INT JOINT C ART, P226; DUBITZKY W, 1999, P ISCA 14 INT C COMP, P107; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Figliola A, 1997, IEEE ENG MED BIOL, V16, P74, DOI 10.1109/51.585521; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gebhardt F., 1997, REASONING COMPLEX CA; GESU VD, 1994, FUZZY SETS SYST, V68, P293; Gudivada V. N., 1997, IEEE Internet Computing, V1, DOI 10.1109/4236.623969; HAN U, 1998, ARTIF INTELL, V12, P393; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HUNT JE, 1995, P 1 INT C ICCBR 95 O, P205; HYUNG LK, 1994, FUZZY SET SYST, V62, P291; JAGADISH HV, 1996, MULTIMEDIA DATABASE; Jurisica I, 1998, ARTIF INTELL MED, V12, P1, DOI 10.1016/S0933-3657(97)00037-7; KAMP G, 1994, P 2 EUR WORKSH CAS B, P175; KOEHLER J, 1994, MOR KAUF R, P351; KOHLE M, 1996, P INT C ART NEUR NET, P581; KOKAR MM, 1993, INT J INTELL SYST, V8, P857; KOLODNER J, 1995, COMPUTATION INTELLIG; Kolodner J., 1993, CASE BASED REASONING; Kolodner J. L., 1996, CASE BASED REASONING; KONTKANEN P, 1998, LECT NOTES ARTIFICIA, V1488; KORN F, 1996, CSTR3613 U MAR I ADV; KRANTZ DH, 1975, J MATH PSYCHOL, V12, P4, DOI 10.1016/0022-2496(75)90047-4; LEE RW, 1995, P 1 INT C CBR ICCBR, P23; LIAO TW, 1996, P 5 IEEE INT C FUZZ, P100; Liao TW, 1998, APPL ARTIF INTELL, V12, P267, DOI 10.1080/088395198117730; LING CX, 1997, LAZY LEARNING; MALEK M, 1995, LECT NOTES ARTIFICIA, V1010; MATUSCHEK D, 1997, P FLOR AI RES S FLOR, P432; MERKL D, 1997, LECT NOTES ARTIFICIA, V1263; MIYAMOTO S, 1990, FUZZY SET SYST, V38, P191, DOI 10.1016/0165-0114(90)90149-Z; MOHRI T, 1994, CASE BASED REASONING; MORGAN JN, 1973, THAID; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; OSBORNE H, 1997, P INT WORKSH SIM CAT, P173; OSBORNE H, 1997, CASED BASED REASONIN; Pal K., 1995, Progress in Case-Based Reasoning. First United Kingdom Workshop. Proceedings; PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4; PAZZANI M, 1991, J LEARN SCI, V1, P153, DOI 10.1207/s15327809jls0102_2; PERNER P, 1993, P EWCBR 93, V2, P403; PERNER P, 1998, LECT NOTES ARTIFICIA, V1488; RAGHAVAN VV, 1986, J AM SOC INFORM SCI, V37, P279, DOI 10.1002/asi.4630370502; RANDALL D, 1997, J ARTIFICIAL INT RES, V6, P1; Reategui EB, 1997, ARTIF INTELL MED, V9, P5, DOI 10.1016/S0933-3657(96)00359-4; REATEGUI EB, 1995, LECT NOTES ARTIFICIA, V1010; REISER C, 1994, CASE BASED REASONING; RICCI F, 1995, P 1 INT C CAS BAS RE, P301; RICCI F, 1998, LECT NOTES ARTIFICIA, V1488; Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217; Rissland E. L., 1996, Artificial Intelligence and Law, V4, DOI 10.1007/BF00123994; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Salzberg S., 1991, MACH LEARN, V6, P277; SANTINI S, 1995, SIMILARITY MATCHING; SCOTT T, 1997, EARTH ISL J, V12, P2; Sebestyen G. S., 1962, DECISION MAKING PROC; Sellers P. H., 1974, Journal of Combinatorial Theory, Series A, V16, DOI 10.1016/0097-3165(74)90050-8; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; SIMON JC, 1974, P 2 INT JOINT C PATT, P660; Smith SDG, 1997, IEEE T NEURAL NETWOR, V8, P847, DOI 10.1109/72.595882; SNEATH PHA, 1974, NUMERICAL TAXONOMY P; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STRUZIK Z, 1998, LECT NOTES ARTIFICIA, V1394; Surma J., 1995, P 1 INT C CAS BAS RE, P325; TANAKA E, 1996, IEICE T INF SYST E79, P1358; TING KM, 1995, LECT NOTES ARTIFICIA, V1010; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; TVERSKY A, 1978, COGNITION CATEGORISA; ULTSCH A, 1995, P KI 95, P258; Vosniadou S., 1989, SIMILARITY ANALOGICA; MARIR F, 1994, KNOWL ENG REV, V9, P355; WESS S, 1994, P 2 EUR WORKSH CAS B, P165; Wess S., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; WESS S, 1993, P 1 EUR WORKSH EWCBR, P77; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1995, AIC95012 NAV RES LAB; WHITE DW, 1996, P SPIE C STOR RETR I, V4, P62; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WOLVERTON M, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P56; WU S, 1990, INFORM PROCESS LETT, V35, P317, DOI 10.1016/0020-0190(90)90035-V; YUANHUI Z, 1997, LECT NOTES ARTIFICIA, V1263; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zavrel J, 1996, ARTIF INTELL REV, V10, P477, DOI 10.1007/BF00130695; Zwick R., 1987, International Journal of Approximate Reasoning, V1, DOI 10.1016/0888-613X(87)90015-6	131	3	3	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	0269-8889		KNOWL ENG REV	Knowl. Eng. Rev.	DEC	2000	15	4					371	379				9	Computer Science, Artificial Intelligence	Computer Science	446CF	WOS:000169494800003	
J	Ferrari, A; Borgatti, M; Guerrieri, R				Ferrari, A; Borgatti, M; Guerrieri, R			A complete system for NN classification based on a VLSI array processor	PATTERN RECOGNITION			English	Article						pattern classification; k-nearest neighbors; array processor; configurable architecture; VLSI	RECOGNITION	This paper describes a VLSI array processor system designed and built for classification problems based on the k-nearest-neighbors approach. This architecture is suitable for different pattern recognition applications and is very efficient for high-dimensional databases. The architecture is scalable with the size of the recognition problem making the system effectively applicable to computational intensive application like on-line pattern recognition. A system prototype composed of a board with two processors, the software driver and a test application have been built and evaluated. For handwritten character recognition task the complete system shows a speed up of 260 times over a sequential algorithm running on a Sun SPARC20 workstation. (C) 2000 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	PARADES GEIE, I-00186 Rome, Italy; STMicroelect, Cent Res & Dev, Innovat Syst Design Grp, Agrate Brianza, Italy; Univ Bologna, DEIS, I-40136 Bologna, Italy	Ferrari, A (reprint author), PARADES GEIE, Via San Pantaleo 66, I-00186 Rome, Italy.						CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DODDINGTON GR, 1981, IEEE SPECTRUM, V18; Duda R., 1973, PATTERN CLASSIFICATI; FISHER FP, P 1970 NEC, P481; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Fukunaga K., 1990, STAT PATTERN RECOGNI; GARRIS MD, 1992, NIST SPECIAL DATABAS, V3; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HENNESSY JL, 1990, COMPUTER ARCHITECTUR, pCH8; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KOVACS ZM, 1992, P 11 ICPR 1992 THE H, V2, P96; KOVACSV ZM, 1995, PATTERN RECOGN, V28, P293, DOI 10.1016/0031-3203(94)00099-8; Kramer A, 1997, ISSCC DIG TECH PAP I, V40, P44, DOI 10.1109/ISSCC.1997.585253; LIN YC, 1992, IEE ELECT LETT, V28, P1073; Lipman A, 1997, IEEE T VLSI SYST, V5, P320, DOI 10.1109/92.609875; Omohundro S. M., 1987, Complex Systems, V1; OMOHUNDRO SM, 1987, TR89063 INT COMP SCI; PARHAMI B, 1987, IEEE T COMPUT, V36, P1233; PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532; RABINER LR, 1979, IEEE T ACOUST SPEECH, V27, P336, DOI 10.1109/TASSP.1979.1163259; Tzionas P. G., 1994, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V2, DOI 10.1109/92.311634; ULUG B, 1995, ICASSP 95 MAY, V5, P3479; *APT CORP, 1993, PROGR INT SYST DAT B	25	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	DEC	2000	33	12					2083	2093		10.1016/S0031-3203(99)00192-2		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	356ZH	WOS:000089473700013	
J	Wu, CH; Yu, CJ; Lee, SJ				Wu, CH; Yu, CJ; Lee, SJ			An extended system for conceptual clustering	APPLIED ARTIFICIAL INTELLIGENCE			English	Article							ALGORITHM; KNOWLEDGE; CLASSIFICATION	CLUSTER/2 (Michalski, 1980a, Stepp & Michalski, 1986) in a conceptual clustering system, having the great advantage that obtained clusters are represented in the form of symbolic expressions. However, it has some disadvantages. In this article, a modified version of CLUSTER/2 is proposed. Background knowledge can be conveyed to the system through semantic networks; differentiation among objects is calculating using semantic distance. A different quality evaluation is used to measure the quality of clustering in a more sensible way. The order dependence problem of overlap resolution is eliminated with a fuzzy k-nearest neighborhood technique. Finally, a hill-climbing algorithm is applied to determine the number of clusters automatically. These improvements provide a more stable and user-friendly clustering environment for the user, without changing the system architecture of CLUSTER/2.	Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan; Shu Te Inst TEchnol, Dept Informat Management, Kaohsiung, Taiwan	Lee, SJ (reprint author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.						BECK HW, 1994, IEEE T KNOWL DATA EN, V6, P396, DOI 10.1109/69.334862; BEREAU M, 1991, FUZZY SETS SYSTEMS, V44, P16; Bhatia SK, 1998, IEEE T SYST MAN CY B, V28, P427, DOI 10.1109/3477.678640; Biswas G, 1998, IEEE T SYST MAN CY C, V28, P219, DOI 10.1109/5326.669556; CHATURVEDI AR, 1993, EXPERT SYST APPL, V6, P23, DOI 10.1016/0957-4174(93)90016-Y; Cheeseman P., 1988, P 5 INT C MACH LEARN, P54; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; EVERITT B, 1927, CLUSTER ANAL; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; FISHER DH, 1986, ARTIFICIAL INTELLIGE; HADZIKADIC M, 1989, P 11 INT JOINT C ART, P831; Hanson S. J., 1989, Machine Learning, V3, DOI 10.1007/BF00116838; HENDLER JA, 1992, COMPUT MATH APPL, V23, P277, DOI 10.1016/0898-1221(92)90144-7; Lebowitz M., 1987, Machine Learning, V2, DOI 10.1007/BF00114264; LIANG T, 1990, EXPERT SYSTEMS APPL, V1, P391, DOI 10.1016/0957-4174(90)90048-Y; LUGER GF, 1993, ARTIFICIAL INHERITAN; McClelland J. L., 1986, PARALLEL DISTRIBUTED; MICHALSKI RS, 1978, 867 U ILL COMP SCI D; MICHALSKI RS, 1986, MACHINE LEARNING ART; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4; MILLIGAN GW, 1983, IEEE T PATTERN ANAL, V5, P40; MINEAU GW, 1995, IEEE T KNOWL DATA EN, V7, P824, DOI 10.1109/69.469834; Murphy P., 1994, UCI REPOSITORY MACHI; NEVINS AJ, 1995, MACH LEARN, V18, P5, DOI 10.1007/BF00993819; Nordhausen B., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; QUILLIAN MR, 1985, READINGS KNOWLEDGE R; Rich E., 1991, ARTIFICIAL INTELLIGE; Russell SJ, 1995, ARTIFICIAL INTELLIGE; STEFAN W, 1994, MACH LEARN, V14, P169; STEPP R, 1986, MACHINE LEARNING ART, V2; STEPP RE, 1984, UIUCDCS841189; STEPP RE, 1986, ARTIF INTELL, V28, P43, DOI 10.1016/0004-3702(86)90030-5; ZADEH LA, 1983, FUZZY SET SYST, V11, P199	38	0	0	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	NOV	2000	14	10					943	965		10.1080/08839510050179455		23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	372CR	WOS:000165217200001	
J	Bax, E				Bax, E			Validation of nearest neighbor classifiers	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						error bounds; machine learning; nearest neighbor classifier; statistics; validation		This correspondence presents a method to bound the out-of-sample error rate of a nearest neighbor classifier.(1) The bound is based only on the examples that comprise the classifier. Thus all available examples can be used in the classifier; no examples need to be withheld to compute error bounds. The estimate used in the bound is an extension of the holdout estimate. The difference in error rates between the holdout classifier and the classifier consisting of all available examples is estimated using truncated inclusion and exclusion.	Univ Richmond, Dept Math & Comp Sci, Richmond, VA 23173 USA	Bax, E (reprint author), Univ Richmond, Dept Math & Comp Sci, Richmond, VA 23173 USA.						BAX E, IN PRESS IEEE T NEUR; Bax E, 1998, NEURAL COMPUT, V10, P975, DOI 10.1162/089976698300017584; Bax E, 1998, PATTERN RECOGN LETT, V19, P127, DOI 10.1016/S0167-8655(97)00160-8; CATALTEPE Z, 1998, ADV NEURAL INFORMATI, V10; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1969, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P202, DOI 10.1109/TIT.1979.1056032; FRANKLIN J, 1979, METHODS MATH EC, P190; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; Hoeffding W., 1963, AM STAT ASS J, V58, P13; Kuhn H. W., 1950, P 2 BERK S MATH STAT, P481; LINIAL N, 1990, COMBINATORICA, V10, P349, DOI 10.1007/BF02128670; MOTWANI R, 1995, RANDOMIZED ALGORITHM, P46; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; Vapnik V., STAT LEARNING THEORY; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	20	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	NOV	2000	46	7					2746	2752		10.1109/18.887892		7	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	378VY	WOS:000165606900049	
J	Paredes, R; Vidal, E				Paredes, R; Vidal, E			A class-dependent weighted dissimilarity measure for nearest neighbor classification problems	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbour classification; weighted dissimilarity measures; iterative optimization; fractional programming		A class-dependent weighted (CDW) dissimilarity measure in vector spaces is proposed to improve the performance of the nearest neighbor (NN) classifier. In order to optimize the required weights, an approach based on Fractional Programming is presented. Experiments with several standard benchmark data sets show the effectiveness of the proposed technique. (C) 2000 Published by Elsevier Science B.V.	Univ Politecn Valencia, Inst Tecnol Informat, E-46071 Valencia, Spain	Paredes, R (reprint author), Univ Politecn Valencia, Inst Tecnol Informat, Camino Vera S-N, E-46071 Valencia, Spain.						BLAKE CL, UCI RESPOSITORY MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Duda R. O., 1973, PATTERN RECOGNITION; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; Fukunaga K., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90043-5; FUKUNAGA K, 1985, IEEE T PATTERN ANAL, V7, P107; LUK A, 1986, PATTERN RECOGN LETT, V4, P375, DOI 10.1016/0167-8655(86)90059-0; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; PAREDES R, 2000, P 15 INT C PATT REC; PAREDES R, 1998, P 8 S NAC REC FORM A; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SHORT RD, 1980, P 5 IEEE INT C PATT; SHULTZ TR, 1994, MACH LEARN, V16, P57, DOI 10.1023/A:1022630902151; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Sniedovich M, 1992, DYNAMIC PROGRAMMING; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; URAHAMA K, 1995, PATTERN RECOGN, V28, P761, DOI 10.1016/0031-3203(94)00142-9; VIDAL E, 1995, IEEE T PATTERN ANAL, V17, P899, DOI 10.1109/34.406656	20	31	31	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV	2000	21	12					1027	1036		10.1016/S0167-8655(00)00064-7		10	Computer Science, Artificial Intelligence	Computer Science	377YV	WOS:000165554700002	
J	Kim, S; Schatzki, TF				Kim, S; Schatzki, TF			Apple watercore sorting system using X-ray imagery: I. Algorithm development	TRANSACTIONS OF THE ASAE			English	Article						apples; red delicious; watercore damage; X-ray imaging; neural nets; feature extraction; two-dimensional imaging	DETECTING WATERCORE	Watercore is an internal disorder that leads to breakdown of tissue and possibly loss or downgrade of the product. It is very difficult to determine whether an apple contains watercore or not, especially in the early stages, based solely on external information, since watercore does not alter external texture until after severe internal breakdown. In this study, we explored the possibility of using two-dimensional (2-D) X-ray imaging to detect internal watercore damage in apples. The algorithm to detect Red 'Delicious' watercore apples consists of two stages, the first stage extracts features from the apple x-ray. image and the second stage categorizes apples into different watercore levels using the features identified. A total of eight features were extracted from an x-ray scanned apple image and these features were fed into neural network classifier to categorize them into three different classes, clean, mild, and severe. The results showed that the system was able to correctly recognize apples into clean and severe categories within 5-8% false positive and negative ratios. The result also showed that the algorithm was able to recognize apples independent of apple orientation, but only if the stem-calyx axis made a fixed angle with the x-ray beam. Sorting at random apple orientation was not tested. The estimated speed of the system, if implemented on a DSP board, will be fast enough to keep up with the current apple processing line.	USDA ARS, Western Reg Res Ctr, Albany, CA 94710 USA	Schatzki, TF (reprint author), USDA ARS, Western Reg Res Ctr, 800 Buchanan St, Albany, CA 94710 USA.						BIRTH GERALD S., 1964, PROC AMER SOC HORT SCI, V85, P74; CASASENT D, 1999, IN PRESS T ASAE; Cavalieri RP, 1998, ACTA HORTIC, V464, P103; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIDLER JC, 1973, RES REV; GARRETT RE, 1976, QUALITY DETECTION FO, P107; Goodman P. H., 1996, NEVPROP SOFTWARE VER; KEMP H. K., 1939, Journal of the Australian Institute of Agricultural Science, V5, P227; LEFEBVRE M, 1994, SPIE P OPTICS AGR FO, V2345, P2; Marlow G. C., 1984, Horticultural Reviews, V6, P189; PORRITT S. W., 1963, CANADIAN JOUR PLANT SCI, V43, P600; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAS Institute Inc, 1989, SAS STAT US GUID VER, V1; Schatzki TF, 1997, T ASAE, V40, P1407; SCHATZKI TF, 1983, IEEE T PATTERN ANAL, V5, P645; Shahin MA, 1999, T ASAE, V42, P1889; SHAHIN MA, 1997, 973077 ASAE; SMAGULA JM, 1968, P AM SOC HORTIC SCI, V93, P753; SMITH AJM, 1937, RPT FOOD INVEST BD, P127; THROOP JA, 1989, T ASAE, V32, P2087; THROOP JA, 1995, 956176 ASAE; THROOP JA, 1994, T ASAE, V37, P873; TOLLNER EW, 1992, T ASAE, V35, P1921; *USDA AMS, 1976, US STAND GRAD APPL E	24	21	25	AMER SOC AGRICULTURAL ENGINEERS	ST JOSEPH	2950 NILES RD, ST JOSEPH, MI 49085-9659 USA	0001-2351		T ASAE	Trans. ASAE	NOV-DEC	2000	43	6					1695	1702				8	Agricultural Engineering	Agriculture	402EJ	WOS:000166972800045	
J	Brasini, F; Rovatti, R; Hermle, T; Rudan, M				Brasini, F; Rovatti, R; Hermle, T; Rudan, M			Cluster translation for concentration estimation	SENSORS AND ACTUATORS B-CHEMICAL			English	Article; Proceedings Paper	6th International Symposium on Electronic Noses (ISOEN 99)	SEP 20-22, 1999	TUBINGEN, GERMANY			MOSES system; nearest-neighbour estimation; cluster translation		A method to estimate the concentration of samples acquired by means of nonlinear sensors is proposed. It is tested using data provided by the MOSES system and shows improvement upon pure nearest-neighbour (N-N) estimation when data are not available for all concentrations. (C) 2000 Elsevier Science S.A. All rights reserved.	Univ Bologna, DEIS, I-40136 Bologna, Italy; Univ Tubingen, WSI, D-72076 Tubingen, Germany	Brasini, F (reprint author), Univ Bologna, DEIS, Viale Risorgimento 2, I-40136 Bologna, Italy.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Mitrovics J, 1998, ACCOUNTS CHEM RES, V31, P307, DOI 10.1021/ar970064n; Yea B, 1999, SENSOR ACTUAT B-CHEM, V56, P181, DOI 10.1016/S0925-4005(99)00188-4	3	1	1	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0925-4005		SENSOR ACTUAT B-CHEM	Sens. Actuator B-Chem.	OCT 25	2000	69	3					219	222		10.1016/S0925-4005(00)00492-5		4	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	367CE	WOS:000090043400003	
J	Zheng, ZJ; Webb, GI				Zheng, ZJ; Webb, GI			Lazy learning of Bayesian rules	MACHINE LEARNING			English	Article						Bayesian classification; semi-naive Bayesian classification; decision trees; decision rules; lazy learning		The naive Bayesian classifier provides a simple and effective approach to classifier learning, but its attribute independence assumption is often violated in the real world. A number of approaches have sought to alleviate this problem. A Bayesian tree learning algorithm builds a decision tree, and generates a local naive Bayesian classifier at each leaf. The tests leading to a leaf can alleviate attribute inter-dependencies for the local naive Bayesian classifier. However, Bayesian tree learning still suffers from the small disjunct problem of tree learning. While inferred Bayesian trees demonstrate low average prediction error rates, there is reason to believe that error rates will be higher for those leaves with few training examples. This paper proposes the application of lazy learning techniques to Bayesian tree induction and presents the resulting lazy Bayesian rule learning algorithm, called LBR. This algorithm can be justified by a variant of Bayes theorem which supports a weaker conditional attribute independence assumption than is required by naive Bayes. For each test example, it builds a most appropriate rule with a local naive Bayesian classifier as its consequent. It is demonstrated that the computational requirements of LBR are reasonable in a wide cross-section of natural domains. Experiments with these domains show that, on average, this new algorithm obtains lower error rates significantly more often than the reverse in comparison to a naive Bayesian classifier, C4.5, a Bayesian tree learning algorithm, a constructive Bayesian classifier that eliminates attributes and constructs new attributes using Cartesian products of existing nominal attributes, and a lazy decision tree learning algorithm. It also outperforms, although the result is not statistically significant, a selective naive Bayesian classifier.	Deakin Univ, Sch Comp & Math, Geelong, Vic 3217, Australia	Zheng, ZJ (reprint author), Deakin Univ, Sch Comp & Math, Geelong, Vic 3217, Australia.	zijian@deakin.edu.au; webb@deakin.edu.au	Webb, Geoffrey/A-1347-2008				Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C. L., 1998, UCI RESPOSITORY MACH; Breiman L, 1984, CLASSIFICATION REGRE; BRIAND LC, 1992, IEEE T SOFTWARE ENG, V18, P931, DOI 10.1109/32.177363; Cestnik B., 1990, P EUR C ART INT, P147; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; CHATFIELD C, 1978, STAT TECHNOLOGY COUR; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; FULTON T, 1996, P 2 INT C KNOWL DISC, P14; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Geiger D., 1992, P 8 C UNC AI, P92; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Holte RC, 1989, P 11 INT JOINT C ART, P813; Iba W., 1992, P 10 NAT C ART INT, P223; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kittler J., 1986, HDB PATTERN RECOGNIT, P59; Kohavi R, 1996, P 2 INT C KNOWL DISC, p202~207; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; Kononenko I., 1990, CURRENT TRENDS KNOWL; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; KUBAT M, 1993, P 8 EUR C MACH LEARN, P366; Langley P., 1993, P 1993 EUR C MACH LE, P153; Langley P., 1994, P 10 C UNC ART INT, P339; Pazzani M. J., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; Sahami M, 1996, P 2 INT C KNOWL DISC, P334; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Singh M, 1995, P 12 INT C MACH LEAR, P497; Singh M., 1996, P 13 INT C MACH LEAR, P453; Ting K., 1994, P 10 CAN C ART INT, P91; TING KM, 1994, 491 U SYDN BASS DEP; VISWANATHAN M, 1998, P 10 EUR C MACH LEAR, P149; Webb G I, 1998, P 11 AUSTR JOINT C A, P285; Webb G. I., 1996, Proceedings ofthe Conference, ISIS '96. Information, Statistics and Induction in Science; Wolpert D. H., 1994, MATH GEN	47	82	94	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	OCT	2000	41	1					53	84		10.1023/A:1007613203719		32	Computer Science, Artificial Intelligence	Computer Science	342PL	WOS:000088654300003	
J	Cardie, C				Cardie, C			A cognitive bias approach to feature selection and weighting for case-based learners	MACHINE LEARNING			English	Article						case-based learning; instance-based learning; feature set selection; feature weighting; natural language learning	INDIVIDUAL-DIFFERENCES; LEARNING ALGORITHMS; WORKING MEMORY; LAZY LEARNERS; LANGUAGE; MACHINE; INFORMATION; ADVANTAGE; MENTION; SPANISH	Research in psychology, psycholinguistics, and cognitive science has discovered and examined numerous psychological constraints on human information processing. Short term memory limitations, a focus of attention bias, and a preference for the use of temporally recent information are three examples. This paper shows that psychological constraints such as these can be used effectively as domain-independent sources of bias to guide feature set selection and weighting for case-based learning algorithms. We first show that cognitive biases can be automatically and explicitly encoded into the baseline instance representation: each bias modifies the representation by changing features, deleting features, or modifying feature weights. Next, we investigate the related problems of cognitive bias selection and cognitive bias interaction for the feature weighting approach. In particular, we compare two cross-validation algorithms for bias selection that make different assumptions about the independence of individual component biases. In evaluations on four natural language learning tasks, we show that the bias selection algorithms can determine which cognitive bias or biases are relevant for each learning task and that the accuracy of the case-based learning algorithm improves significantly when the selected bias(es) are incorporated into the baseline instance representation.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Cardie, C (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Broadbent D., 1958, PERCEPTION COMMUNICA; CAIN T, 1991, P CAS BAS REAS WORKS, P191; Cardie C, 1997, AI MAG, V18, P65; Cardie C., 1997, P 14 INT C MACH LEAR, P57; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Cardie C, 1999, J EXP THEOR ARTIF IN, V11, P297, DOI 10.1080/095281399146445; CARREIRAS M, 1995, PSYCHON B REV, V2, P124, DOI 10.3758/BF03214418; Caruana R., 1994, P 11 INT C MACH LEAR, P28; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; CUETOS F, 1988, COGNITION, V30, P73, DOI 10.1016/0010-0277(88)90004-2; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; DAELEMANS W, 1999, J EXPT THEORETICAL A, V11; DANEMAN M, 1983, J EXP PSYCHOL LEARN, V9, P561, DOI 10.1037/0278-7393.9.4.561; DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6; Domingos P, 1997, ARTIF INTELL REV, V11, P227; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; FRAZIER L, 1978, COGNITION, V6, P291, DOI 10.1016/0010-0277(78)90002-1; FRIEDMAN JH, 1994, UNPUB FLEXIBLE METRI; GERNSBACHER MA, 1989, J MEM LANG, V28, P735, DOI 10.1016/0749-596X(89)90006-5; GIBSON E, 1990, P 12 ANN C COGN SCI, P72; GIBSON E, 1993, 6 ANN CUNY SENT PROC; GORDON DF, 1995, MACH LEARN, V20, P5, DOI 10.1023/A:1022630017346; HASTIE TJ, 1995, UNPUB DISCRIMINANT A; HOWE N, 1997, P 2 INT C CAS BAS RE, P455; John G. H., 1994, P 11 INT C MACH LEAR, P121; KIMBALL J, 1973, COGNITION, V2, P15, DOI 10.1016/0010-0277(72)90028-5; KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H; LANGLEY P, 1996, ELEMENTS MACH LEARNI; LEHNERT W, 1991, P 3 MESS UND C MUC 3, P223, DOI 10.3115/1071958.1071994; LEHNERT W, 1990, ADV CONNECTIONIST NE; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; Maron O, 1997, ARTIF INTELL REV, V11, P193, DOI 10.1023/A:1006556606079; MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037//0033-295X.101.2.343; Mitchell Tom M., 1997, MACH LEARNING; NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1207/s15516709cog1401_2; Nicol J. L., 1988, THESIS MIT CAMBRIDGE; PROVOST FJ, 1995, MACH LEARN, V20, P35, DOI 10.1007/BF00993474; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SKALAK DB, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P325; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wilson R. A., 1999, MIT ENCY COGNITIVE S; XU L, 1989, 9 INT C PATT REC, P706; *MUC3, 1991, P 3 MESS UND C MUC 3; *MUC5, 1995, P 5 MESS UND C MUC 5	54	4	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	OCT	2000	41	1					85	116		10.1023/A:1007665204628		32	Computer Science, Artificial Intelligence	Computer Science	342PL	WOS:000088654300004	
J	Benitez, MC; Rubio, A; Garcia, P; de la Torre, A				Benitez, MC; Rubio, A; Garcia, P; de la Torre, A			Different confidence measures for word verification in speech recognition	SPEECH COMMUNICATION			English	Article						key-word spotting; key-word verification; non-parametric classifiers; confidence measures	DISCRIMINATIVE UTTERANCE VERIFICATION; INFORMATION; SYSTEM	Recent research in Automatic Speech Recognition (ASR) technologies has shown the key-word spotting (KWS) systems as one of the most interesting options for accessing information using speech. KWS systems can accept spontaneous speech, which allows potential users to ask for information without learning complex protocols for the human-machine communication. One of the most relevant aspects in KWS systems is the verification of key-word candidates. Utterances detected as key-words could be either 'false alarms' (non-key-words or incorrectly recognized key-words) or 'correct key-words'. The use of confidence measurements allows (by additional processing of the spoken sentence) the verification of the candidates and the decision as to whether each utterance must be accepted as a correctly recognized key-word or rejected as a false alarm. In this work we propose a novel method for verification in those KWS systems based on phone models. Under our new approach, a phonematic speech recognizer decodes the spoken sentence in parallel with the KWS recognizer. The first one produces a phone string as output while the second one generates a key-word/filler-model string. By aligning both strings, a set of characteristics is extracted which are used to verify the putatives key-word. For that we have built two classifiers; in the first one the euclidean metric is modified and adapted in a local and iterative way in order to give greater importance to the most discriminate directions between the classes. The second is a vector quantizer which was trained using adaptative technique learning. We have applied the proposed method to several KWS tasks. Experimental results presented in this paper show that the proposed verification method improves the performance of the KWS systems by reducing the false alarm rate without a significant increase in the rejection of correctly detected keywords. (C) 2000 Elsevier Science B.V. All rights reserved.	Univ Granada, Fac Ciencias, Dept Elect & Tecnol Comp, E-18071 Granada, Spain	Benitez, MC (reprint author), Univ Granada, Fac Ciencias, Dept Elect & Tecnol Comp, E-18071 Granada, Spain.	carmen@hal.ugr.es	de la Torre, Angel/C-6618-2012; Benitez Ortuzar, M Del Carmen/C-2424-2012; Prieto, Ignacio/B-5361-2013				BENITEZ MC, 1998, THESIS U GRANADA; BLOOTHOOFT, 1997, ELSNET; BOURLARD H, 1994, P IEEE INT C AC SPEE, P373; Caminero J, 1997, INT CONF ACOUST SPEE, P891, DOI 10.1109/ICASSP.1997.596079; Casacuberta F., 1991, P WORKSH INT COOP ST; Chigier B., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), DOI 10.1109/ICASSP.1992.226112; Cole RA, 1997, SPEECH COMMUN, V23, P243, DOI 10.1016/S0167-6393(97)00049-6; COLEMAN EA, 1995, J VINYL ADDIT TECHN, V1, P1, DOI 10.1002/vnl.730010102; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX S, 1996, P INT C AC SPEECH SI, P511; DIAZ J, 1995, THESIS U GRANADA; FOOTE JT, 1995, EUR C SPEECH COMM TE, P2145; Fukunaga K., 1990, STAT PATTERN RECOGNI; GARCIA P, 1996, THESIS U GRANADA; GARCIA P, 1998, 1 INT C LANG RES EV, P1263; Gillick L, 1997, INT CONF ACOUST SPEE, P879, DOI 10.1109/ICASSP.1997.596076; GRAY RM, 1990, ENTROPY INFORMATION; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; JAMES DA, 1995, THESIS U CAMBRIDGE; Kellner A, 1997, SPEECH COMMUN, V23, P95, DOI 10.1016/S0167-6393(97)00036-8; KOHONEN T, 1990, NEURAL NETWORK THEOR, P74; KOO MW, 1999, EUROSPEECH, P287; Lamel LF, 1997, SPEECH COMMUN, V23, P67, DOI 10.1016/S0167-6393(97)00037-X; Lleida E, 1996, INT CONF ACOUST SPEE, P507, DOI 10.1109/ICASSP.1996.541144; MATHAN L, 1991, INT CONF ACOUST SPEE, P93, DOI 10.1109/ICASSP.1991.150286; NETI CV, 1997, P INT C AC SPEECH SI, P883; RICARDI G, 1997, INT C AC SPEECH SIGN, P1143; ROHLICEK J, 1993, P INT C AC SPEECH SI, V2, P459; ROSE RC, 1995, COMPUT SPEECH LANG, V9, P309, DOI 10.1006/csla.1995.0015; Rubio AJ, 1997, INT CONF ACOUST SPEE, P895, DOI 10.1109/ICASSP.1997.596080; RUBIO AJ, 1997, EURO SPEECH, P1779; Schaaf T, 1997, INT CONF ACOUST SPEE, P875, DOI 10.1109/ICASSP.1997.596075; Sukkar RA, 1996, IEEE T SPEECH AUDI P, V4, P420, DOI 10.1109/89.544527; Sukkar RA, 1997, SPEECH COMMUN, V22, P333, DOI 10.1016/S0167-6393(97)00031-9; Weintraub M, 1997, INT CONF ACOUST SPEE, P887, DOI 10.1109/ICASSP.1997.596078; WILCOX LD, 1991, EURO SPEECH; WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088; ZUE V, 1997, EURO SPEECH; ZUE V, 1997, EURO SPEECH, P2227; *UCL, 1991, SAMSCL018 U COLL LON; *UPC, 1993, SANA002 UPC U AUT BA	41	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393		SPEECH COMMUN	Speech Commun.	SEP	2000	32	1-2					79	94		10.1016/S0167-6393(00)00025-X		16	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	350HM	WOS:000089095100007	
J	Jurs, PC; Bakken, GA; McClelland, HE				Jurs, PC; Bakken, GA; McClelland, HE			Computational methods for the analysis of chemical sensor array data from volatile analytes	CHEMICAL REVIEWS			English	Review							ARTIFICIAL NEURAL-NETWORK; PATTERN-RECOGNITION ANALYSIS; ELECTRONIC NOSE TECHNOLOGY; FILM-COATED SENSORS; GAS SENSOR; ORGANIC-COMPOUNDS; VAPOR RECOGNITION; ODOR CLASSIFICATION; POLYMER COMPOSITE; HUMID AIR		Penn State Univ, Dept Chem, Davey Lab 152, University Pk, PA 16802 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, Davey Lab 152, University Pk, PA 16802 USA.						ALBERT K, UNPUB; Ali Z, 1999, J THERM ANAL CALORIM, V55, P371, DOI 10.1023/A:1010186728654; Anklam E, 1998, FOOD CHEM, V61, P243, DOI 10.1016/S0308-8146(97)00104-0; Annor-Frempong IE, 1998, MEAT SCI, V50, P139, DOI 10.1016/S0309-1740(98)00001-1; AUGE J, 1995, SENSOR ACTUAT B-CHEM, V26, P181, DOI 10.1016/0925-4005(94)01582-3; Ballantine D.S., 1997, ACOUSTIC WAVE SENSOR; Baltes H, 1996, SENSORS UPDATE, V2; BARKER PS, 1994, SENSOR ACTUAT B-CHEM, V17, P143, DOI 10.1016/0925-4005(94)87042-X; Barko G, 1997, TALANTA, V44, P2237, DOI 10.1016/S0039-9140(97)00168-9; BARKO G, 1995, TALANTA, V42, P475, DOI 10.1016/0039-9140(95)01435-E; Barko G, 1998, ANAL CHIM ACTA, V367, P135, DOI 10.1016/S0003-2670(98)00132-9; Barshick SA, 1998, J FORENSIC SCI, V43, P284; Blixt Y, 1999, INT J FOOD MICROBIOL, V46, P123, DOI 10.1016/S0168-1605(98)00192-5; Bodenhofer K, 1997, ANAL CHEM, V69, P3058, DOI 10.1021/ac9612990; Borjesson T, 1996, CEREAL CHEM, V73, P457; BOURROUNET B, 1995, SENSOR ACTUAT B-CHEM, V26, P250; BRERETON RG, 1992, MULTIVATIATE PATTERN, V9; Broyden C. G., 1970, J I MATH ITS APPL, V6, P76, DOI DOI 10.1093/IMAMAT/6.1.76; Brudzewski K, 1999, SENSOR ACTUAT B-CHEM, V55, P38, DOI 10.1016/S0925-4005(99)00040-4; Buhlmann K, 1998, SENSOR ACTUAT B-CHEM, V49, P156, DOI 10.1016/S0925-4005(98)00108-7; BURNS JA, 1993, CHEM REV, V93, P2583, DOI 10.1021/cr00024a001; Byfield MP, 1996, GEC-J RES, V13, P17; Carrasco A, 1998, FLAVOUR FRAG J, V13, P335, DOI 10.1002/(SICI)1099-1026(1998090)13:5<335::AID-FFJ753>3.3.CO;2-6; Corcoran P, 1998, SENSOR ACTUAT B-CHEM, V48, P448, DOI 10.1016/S0925-4005(98)00083-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craven MA, 1996, TRAC-TREND ANAL CHEM, V15, P486, DOI 10.1016/S0165-9936(96)00061-1; D'Amico A, 1998, BIOSENS BIOELECTRON, V13, P711, DOI 10.1016/S0956-5663(98)00026-8; DAVIDE FAM, 1994, SENSOR ACTUAT B-CHEM, V18, P244, DOI 10.1016/0925-4005(94)87090-X; Di Natale C., 1995, SENSOR ACTUAT B-CHEM, V26-27, P237; Di Natale C, 1997, SENSOR ACTUAT B-CHEM, V44, P521, DOI 10.1016/S0925-4005(97)00175-5; Diamond D., 1998, PRINCIPLES CHEM BIOL; Dickert FL, 1999, ANAL CHEM, V71, P1338, DOI 10.1021/ac981014e; Dickinson TA, 1996, NATURE, V382, P697, DOI 10.1038/382697a0; Dickinson TA, 1997, ANAL CHEM, V69, P3413, DOI 10.1021/ac970501b; Dickinson TA, 1998, TRENDS BIOTECHNOL, V16, P250, DOI 10.1016/S0167-7799(98)01185-8; DINATALE C, 1995, SENSOR ACTUAT B-CHEM, V25, P808, DOI 10.1016/0925-4005(95)85180-1; Di Natale C, 1998, SENSOR ACTUAT B-CHEM, V50, P246, DOI 10.1016/S0925-4005(98)00242-1; DiNatale C, 1996, SENSOR ACTUAT B-CHEM, V33, P83, DOI 10.1016/0925-4005(96)01918-1; DINATALE C, 1995, SENSOR ACTUAT B-CHEM, V24, P801; Doleman BJ, 1998, ANAL CHEM, V70, P2560, DOI 10.1021/ac971238h; Doleman BJ, 1998, ANAL CHEM, V70, P4177, DOI 10.1021/ac971204+; Domansky K, 1998, ANAL CHEM, V70, P473, DOI 10.1021/ac970427x; Duda R., 1973, PATTERN CLASSIFICATI; Eklov T, 1999, ANAL CHIM ACTA, V381, P221, DOI 10.1016/S0003-2670(98)00739-9; Eklov T, 1998, J SCI FOOD AGR, V76, P525, DOI 10.1002/(SICI)1097-0010(199804)76:4<525::AID-JSFA983>3.0.CO;2-A; Fenner RA, 1999, WATER ENVIRON RES, V71, P282, DOI 10.2175/106143098X121888; FLETCHER R, 1970, COMPUT J, V13, P317, DOI 10.1093/comjnl/13.3.317; FREUND MS, 1995, P NATL ACAD SCI USA, V92, P2652, DOI 10.1073/pnas.92.7.2652; Gardner J. W., 1999, ELECT NOSES PRINCIPL; Gardner JW, 1996, SENSOR ACTUAT B-CHEM, V33, P60, DOI 10.1016/0925-4005(96)01819-9; GARDNER JW, 1997, HDB BIOSENSORS ELECT; Gardner JW, 1998, MEAS SCI TECHNOL, V9, P120, DOI 10.1088/0957-0233/9/1/016; GARDNER JW, 1994, SENSOR ACTUAT B-CHEM, V18, P240, DOI 10.1016/0925-4005(94)87089-6; Gibson TD, 1997, SENSOR ACTUAT B-CHEM, V44, P413, DOI 10.1016/S0925-4005(97)00235-9; Gnani D, 1998, SENSOR ACTUAT B-CHEM, V47, P77, DOI 10.1016/S0925-4005(98)00010-0; GOLDFARB D, 1970, MATH COMPUT, V24, P23, DOI 10.2307/2004873; Grate JW, 1999, ANAL CHEM, V71, P1033, DOI 10.1021/ac9810011; Grate JW, 1999, ANAL CHEM, V71, P4544, DOI 10.1021/ac990336v; GRATE JW, 1997, HDB BIOSENSORS ELECT; HANSON SJ, 1995, BACKPROPAGATION THEO; He XW, 1997, TALANTA, V44, P2033, DOI 10.1016/S0039-9140(97)00020-9; Hertz J., 1991, INTRO THEORY NEURAL; HIBBERT DB, 1993, CHEMOM INTELL LAB SY, V19, P227; HIERLEMANN A, 1996, SENSORS UPDATE; Holmberg M., 1996, SENSOR ACTUAT B-CHEM, V35-36, P528; Holmberg M, 1998, BIOTECHNOL TECH, V12, P319, DOI 10.1023/A:1008862617082; HOLMBERG M, 1995, SENSOR ACTUAT B-CHEM, V26, P246; Hong HK, 1996, SENSOR ACTUAT B-CHEM, V33, P68, DOI 10.1016/0925-4005(96)01892-8; HONG HK, 1996, SENSOR ACTUAT B-CHEM, V35, P338; Hoyt AE, 1998, ANAL CHEM, V70, P2137, DOI 10.1021/ac971095z; Huyberechts G, 1997, SENSOR ACTUAT B-CHEM, V45, P123, DOI 10.1016/S0925-4005(97)00283-9; Ide J, 1998, IEICE T ELECTRON, VE81C, P1057; Inoue H, 1998, J SOL-GEL SCI TECHN, V11, P67, DOI 10.1023/A:1008688917552; Janata J, 1998, ANAL CHEM, V70, p179R; Johnson R.A., 1982, APPL MULTIVARIATE ST; JOHNSON S, 1999, THESIS PENNSYLVANIA; Johnson SR, 1997, ANAL CHEM, V69, P4641, DOI 10.1021/ac970298k; KALIVAS JH, 1993, MATH ANAL SPECTRA OR; Kasuba T., 1993, AI Expert, V8; KAY SM, 1981, P IEEE, V69, P1380, DOI 10.1109/PROC.1981.12184; Kermani BG, 1999, IEEE T BIO-MED ENG, V46, P429, DOI 10.1109/10.752940; Keshri G, 1998, LETT APPL MICROBIOL, V27, P261, DOI 10.1046/j.1472-765X.1998.00438.x; Kohonen T., 1997, SELF ORG MAPS; KOWALSKI BR, 1973, J AM CHEM SOC, V95, P686, DOI 10.1021/ja00784a007; Kraus G, 1995, CHEMOMETR INTELL LAB, V30, P211, DOI 10.1016/0169-7439(95)00027-5; Kress-Rogers E., 1997, HDB BIOSENSORS ELECT; Lane AJP, 1998, J DAIRY SCI, V81, P2145; Lang PM, 1998, J MULTIVARIATE ANAL, V65, P58, DOI 10.1006/jmva.1997.1727; Lau KT, 1998, SENSOR ACTUAT B-CHEM, V50, P69, DOI 10.1016/S0925-4005(98)00158-0; Lazzerini B, 1998, ELECTRON LETT, V34, P2229, DOI 10.1049/el:19981552; Liden H, 1998, ANAL CHIM ACTA, V361, P223, DOI 10.1016/S0003-2670(98)00035-X; LIVINGSTONE DJ, 1993, J MED CHEM, V36, P1295, DOI 10.1021/jm00061a023; Llobet E, 1999, MEAS SCI TECHNOL, V10, P538, DOI 10.1088/0957-0233/10/6/320; Llobet E, 1997, SENSOR ACTUAT B-CHEM, V41, P13, DOI 10.1016/S0925-4005(97)80272-9; Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j; LUCASIUS CB, 1993, CHEMOMETR INTELL LAB, V19, P1, DOI 10.1016/0169-7439(93)80079-W; LUKE BT, 1994, J CHEM INF COMP SCI, V34, P1279, DOI 10.1021/ci00022a009; Malinowski ER, 1991, FACTOR ANAL CHEM; Mandenius CF, 1997, BIOTECHNOL BIOENG, V55, P427, DOI 10.1002/(SICI)1097-0290(19970720)55:2<427::AID-BIT20>3.0.CO;2-C; Marco S, 1998, IEEE T INSTRUM MEAS, V47, P316, DOI 10.1109/19.728841; Maricou H, 1998, WATER AIR SOIL POLL, V107, P423, DOI 10.1023/A:1019882724915; Marth M, 1998, J CHEMOMETR, V12, P249, DOI 10.1002/(SICI)1099-128X(199807/08)12:4<249::AID-CEM512>3.0.CO;2-G; Masila M, 1998, ELECTROANAL, V10, P312, DOI 10.1002/(SICI)1521-4109(199804)10:5<312::AID-ELAN312>3.3.CO;2-1; Massart DL, 1983, INTERPRETATION ANAL; Maul F, 1998, J AM SOC HORTIC SCI, V123, P1094; McCarrick CW, 1996, ANAL CHEM, V68, P4264, DOI 10.1021/ac9603892; Mitrovics J, 1998, ACCOUNTS CHEM RES, V31, P307, DOI 10.1021/ar970064n; MOORE SW, 1993, SENSOR ACTUAT B-CHEM, V16, P344, DOI 10.1016/0925-4005(93)85207-Q; Nagle HT, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.715180; Nakamoto T, 1997, SENSOR ACTUAT B-CHEM, V41, P183, DOI 10.1016/S0925-4005(97)80293-6; Nakamura M, 1996, SENSOR ACTUAT B-CHEM, V33, P122, DOI 10.1016/0925-4005(96)01820-5; NAKAMURA M, 1994, SENSOR ACTUAT B-CHEM, V20, P231, DOI 10.1016/0925-4005(94)01197-4; Nakata S, 1996, ANAL CHEM, V68, P2067, DOI 10.1021/ac9510954; Namdev PK, 1998, BIOTECHNOL PROGR, V14, P75, DOI 10.1021/bp970141d; Nanto H, 1996, SENSOR ACTUAT B-CHEM, V35, P183, DOI 10.1016/S0925-4005(97)80051-2; NIEBLING G, 1995, SENSOR ACTUAT B-CHEM, V24, P805; Osbourn GC, 1998, ACCOUNTS CHEM RES, V31, P297, DOI 10.1021/ar970070j; OSBOURN GC, 1995, PATTERN RECOGN, V28, P1793, DOI 10.1016/0031-3203(95)00032-U; Park J, 1999, ANAL CHEM, V71, P3877, DOI 10.1021/ac9902401; Pearce TC, 1998, ANALYST, V123, P2057, DOI 10.1039/a804019b; Ping W, 1996, SENSOR ACTUAT B-CHEM, V37, P169, DOI 10.1016/S0925-4005(97)80134-7; Ping W, 1996, MEAS SCI TECHNOL, V7, P1707, DOI 10.1088/0957-0233/7/12/003; Ratton L, 1997, SENSOR ACTUAT B-CHEM, V41, P105, DOI 10.1016/S0925-4005(97)80283-3; Ricco AJ, 1998, ACCOUNTS CHEM RES, V31, P289, DOI 10.1021/ar9600749; ROSEPEHRSSON SL, 1988, ANAL CHEM, V60, P2801, DOI 10.1021/ac00175a032; Roussel S, 1998, J FOOD ENG, V37, P207, DOI 10.1016/S0260-8774(98)00081-8; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCHWEIZERBERBERICH PM, 1994, SENSOR ACTUAT B-CHEM, V18, P282, DOI 10.1016/0925-4005(94)87095-0; Schweizer-Berberid M., 1995, SENSOR ACTUAT B-CHEM, V26/27, P232; Seemann J, 1997, FRESEN J ANAL CHEM, V359, P100, DOI 10.1007/s002160050543; Severin EJ, 1998, ANAL CHEM, V70, P1440, DOI 10.1021/ac970757h; Shaffer RE, 1998, FIELD ANAL CHEM TECH, V2, P179, DOI 10.1002/(SICI)1520-6521(1998)2:3<179::AID-FACT7>3.0.CO;2-Q; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; SHANNO DF, 1970, MATH COMPUT, V24, P647, DOI 10.2307/2004840; Sharaf MA, 1986, CHEMOMETRICS; Shukla KK, 1998, SENSOR ACTUAT B-CHEM, V50, P194, DOI 10.1016/S0925-4005(98)00236-6; Singh S, 1996, SENSOR ACTUAT B-CHEM, V30, P185, DOI 10.1016/0925-4005(96)80047-5; SOMMER V, 1995, SENSOR ACTUAT B-CHEM, V28, P217, DOI 10.1016/0925-4005(95)01721-6; Srivastava AK, 1998, MICROELECTR J, V29, P921, DOI 10.1016/S0026-2692(98)00056-1; Stuetz RM, 1998, WATER SCI TECHNOL, V38, P331, DOI 10.1016/S0273-1223(98)00559-9; Stuetz RM, 1999, WATER RES, V33, P442, DOI 10.1016/S0043-1354(98)00245-0; Stuetz RM, 1999, WATER RES, V33, P453, DOI 10.1016/S0043-1354(98)00246-2; SUTTER JM, 1995, J CHEM INF COMP SCI, V35, P77, DOI 10.1021/ci00023a011; SUTTER JM, 1995, DATA HANDLING SCI TE, V15; Sutter JM, 1997, ANAL CHEM, V69, P856, DOI 10.1021/ac960982j; Ulmer H, 1997, SENSOR ACTUAT B-CHEM, V43, P24, DOI 10.1016/S0925-4005(97)00161-5; VAIHINGER S, 1991, SENSORS COMPREHENSIV, V2; Vandeginste B. G. M., 1998, HDB CHEMOMETRICS Q B; Vlachos D, 1996, SENSOR ACTUAT B-CHEM, V33, P77, DOI 10.1016/0925-4005(96)01917-X; WANG ZY, 1995, ANAL CHEM, V67, P1497, DOI 10.1021/ac00105a003; White J, 1998, BIOL CYBERN, V78, P245, DOI 10.1007/s004220050430; Wijesundera C, 1998, AUST J DAIRY TECHNOL, V53, P141; Zellers ET, 1998, ANAL CHEM, V70, P4191, DOI 10.1021/ac980344w; ZELLERS ET, 1995, ANAL CHEM, V67, P1092, DOI 10.1021/ac00102a012; Zellers ET, 1996, ANAL CHEM, V68, P2409, DOI 10.1021/ac9603643; Ziegler C, 1998, BIOSENS BIOELECTRON, V13, P539, DOI 10.1016/S0956-5663(97)00093-6	157	260	262	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0009-2665		CHEM REV	Chem. Rev.	JUL	2000	100	7					2649	2678		10.1021/cr9800964		30	Chemistry, Multidisciplinary	Chemistry	337MY	WOS:000088366500009	
J	Wong, KD; Cox, DC				Wong, KD; Cox, DC			A pattern recognition system for handoff algorithms	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS			English	Article						cellular; handoff; handover; pattern recognition; wireless	SIGNAL	In wireless cellular systems, handoff algorithms decide when and to which base station to handoff, Traditional handoff algorithms generally cannot keep both the average number of unnecessary handoffs and the handoff decision delay low, They do not exploit the relative constancy of path loss and shadow fading effects at any given location around a base station. This information can in fact be used to improve the efficiency of handoff algorithms, as we do in our new handoff algorithms using statistical pattern recognition. Handoff algorithms with both a negligible number of unnecessary handoffs and a negligible decision delay can therefore be realized.	Telcordia Technol, Red Bank, NJ 07701 USA; Stanford Univ, Stanford, CA 94305 USA	Wong, KD (reprint author), Telcordia Technol, Red Bank, NJ 07701 USA.						AUSTIN MD, 1994, ELECTRON LETT, V30, P1914, DOI 10.1049/el:19941322; AUSTIN MD, 1994, IEEE T VEH TECHNOL, V43, P549, DOI 10.1109/25.312791; Berg J. E., 1992, P IEEE VEH TECHN C, P666; Chia S.T.S., 1991, P IEEE VEHICULAR TEC, P531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HOLTZMANN JM, 1995, IEEE T VEH TECHN FEB, P59; Jakes Jr W. C., 1974, MICROWAVE MOBILE COM; KAPOOR V, 1994, P ICC 94 NEW ORL, P1297, DOI 10.1109/ICC.1994.368895; KELLY OE, 1995, P IEEE PIMRC 95 TOR, P809; Kennemann O., 1994, P 6 NORD SEM DIG MOB, P195; MATURINOLOZOYA H, 1994, P VEH TECH C 94 STOC, P96, DOI 10.1109/VETEC.1994.345157; Nadler M, 1993, PATTERN RECOGNITION; NARASIMHAN R, 1998, P IEEE INT S PERS IN; REZAIIFAR R, 1995, P VEH TECH C 95 CHIC, P887; SAMPATH A, 1993, P IEEE VEH TECH C, P859; SENADJI B, 1994, P IEEE VEH TECHN C S, P77, DOI 10.1109/VETEC.1994.345161; TRIPATHI N, 1998, P IEEE INT C COMM AT, P1733; VIJAYAN R, 1993, IEEE T VEH TECHNOL, V42, P351, DOI 10.1109/25.231888; WONG D, 1998, THESIS STANFORD U; Wong D, 1999, IEEE T VEH TECHNOL, V48, P956, DOI 10.1109/25.765026; *MOT INC, 1995, FIN TEXT PACS LIC AI	21	22	23	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0733-8716		IEEE J SEL AREA COMM	IEEE J. Sel. Areas Commun.	JUL	2000	18	7					1301	1312		10.1109/49.857930		12	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	343UA	WOS:000088719300017	
J	Egmont-Petersen, M; Schreiner, U; Tromp, SC; Lehmann, TM; Slaaf, DW; Arts, T				Egmont-Petersen, M; Schreiner, U; Tromp, SC; Lehmann, TM; Slaaf, DW; Arts, T			Detection of leukocytes in contact with the vessel wall from in vivo microscope recordings using a neural network	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						leukocyte detection; microcirculation; model-based image processing; nonlinear filtering; object recognition; shape characterization; stochastic model	IMAGE-ANALYSIS; RECOGNITION; MOTION	Leukocytes play an important role in the host defense as they may travel from the blood stream into the tissue in reacting to inflammatory stimuli. The leukocyte-vessel wall interactions are studied in post capillary vessels by intraviral video microscopy during in vivo animal experiments. Sequences of video images are obtained and digitized with a frame grabber. A method for automatic detection and characterization of leukocytes in the video images is developed. Individual leukocytes are detected using a neural network that is trained with synthetic leukocyte images generated using a novel stochastic model. This model makes it feasible to generate images of leukocytes with different shapes and sizes under various lighting conditions. Experiments indicate that neural networks trained with the synthetic leukocyte images perform better than networks trained with images of manually detected leukocytes. The best performing neural network trained with synthetic leukocyte images resulted in an 18% larger area under the ROC curve than the best performing neural network trained with manually detected leukocytes.	Maastricht Univ, Dept Biophys, Maastricht, Netherlands; Aachen Univ Technol, Inst Med Informat, Aachen, Germany; Maastricht Univ, Dept Physiol, Maastricht, Netherlands	Egmont-Petersen, M (reprint author), Maastricht Univ, Dept Biophys, Maastricht, Netherlands.						CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEKRUGER D, 1994, PATTERN RECOGN, V27, P461, DOI 10.1016/0031-3203(94)90030-2; EGBRINK MGAO, 1992, CIRC RES, V70, P355; EGMONTPETERSEN M, 1996, AACH WORKSH BILDV ME, P209; Egmont-Petersen M, 1999, PATTERN RECOGN LETT, V20, P521, DOI 10.1016/S0167-8655(99)00024-0; EGMONTPETERSEN M, 1999, PATTERN ANAL APPL, V2, P521; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; GONSALEZ RC, 1992, DIGITAL IMAGE PROCES; Hektor J., 1997, Journal of Computer-Assisted Microscopy, V9; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; JAHNE B., 1995, DIGITAL IMAGE PROCES; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LINDEBERG T, 1994, GEOMETRY DRIVEN DIFF, pCH2; LOBREGT S, 1995, IEEE T MED IMAGING, V14, P12, DOI 10.1109/42.370398; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sato Y, 1997, IEEE T BIO-MED ENG, V44, P225, DOI 10.1109/10.563292; SLAAF DW, 1982, INT J MICROCIRC, V1, P121; SPRINGER TA, 1994, CELL, V76, P301, DOI 10.1016/0092-8674(94)90337-9; VIEREN C, 1995, PATTERN RECOGN LETT, V16, P679, DOI 10.1016/0167-8655(95)00019-D; VILLIERS JD, 1992, IEEE T NEURAL NETWOR, P136; WATANABE M, 1991, MICROVASC RES, V41, P41, DOI 10.1016/0026-2862(91)90006-W; WEINSTEIN MC, 1978, CLIN DECISION ANAL; WOLPERT DH, 1995, SFI9502010; YIP CYJ, 1991, MICROVASC RES, V41, P73, DOI 10.1016/0026-2862(91)90009-Z	27	14	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	JUL	2000	47	7					941	951		10.1109/10.846689		11	Engineering, Biomedical	Engineering	327KV	WOS:000087793800014	
J	Raymer, ML; Punch, WE; Goodman, ED; Kuhn, LA; Jain, AK				Raymer, ML; Punch, WE; Goodman, ED; Kuhn, LA; Jain, AK			Dimensionality reduction using genetic algorithms	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION			English	Article						curse of dimensionality; feature extraction; feature selection; genetic algorithms; pattern classification	FEATURE-EXTRACTION; FEATURE-SELECTION; NEURAL NETWORKS; PROTEINS	Pattern recognition generally requires that objects be described in terms of a set of measurable features. The selection and quality of the features representing each pattern have a considerable bearing on the success of subsequent pattern classification. Feature extraction is the process of deriving new features from the original features in order to reduce the cost of feature measurement, increase classifier efficiency, and allow higher classification accuracy, Many current feature extraction techniques involve linear transformations of the original pattern vectors to new vectors of lower dimensionality. While this is useful for data visualization and increasing classification efficiency, it does not necessarily reduce the number of features that must be measured since each new feature may be a linear combination of all of the features in the original pattern vector, Here, we present a new approach to feature extraction in which feature selection, feature extraction, and classifier training are performed simultaneously using a genetic algorithm, The genetic algorithm optimizes a vector of feature weights, which are used to scale the individual features in the original pattern vectors in either a linear or a nonlinear fashion. A masking vector is also employed to perform simultaneous selection of a subset of the features, We employ this technique in combination with the k nearest neighbor classification rule, and compare the results with classical feature selection and extraction techniques including sequential floating forward feature selection, and linear discriminant analysis. We also present results for the identification of favorable water-binding sites on protein surfaces, an important problem in biochemistry and drug design.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; Michigan State Univ, Case Ctr Comp Aided Engn & Mfg, E Lansing, MI 48824 USA; Michigan State Univ, Dept Biochem, E Lansing, MI 48824 USA	Raymer, ML (reprint author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.		Raymer, Michael/G-3398-2013	Raymer, Michael/0000-0003-2649-0792			ABOLA EE, 1987, PROTEIN DATA BANK CR, P107; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Biem A, 1997, IEEE T SIGNAL PROCES, V45, P500, DOI 10.1109/78.554319; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craig L, 1998, J MOL BIOL, V281, P183, DOI 10.1006/jmbi.1998.1907; CROSBY JL, 1967, SCI PROG, V55, P279; Duda R., 1973, PATTERN CLASSIFICATI; Efron B., 1982, CBMS NSF REGIONAL C, V38; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Ferri F., 1994, PATTERN RECOGN, P403; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRASER A. S., 1957, AUSTRALIAN JOUR BIOL SCI, V10, P484; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HOLLAND JH, 1975, ADAPTATOIN NATURAL A; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kuhn LA, 1995, PROTEINS, V23, P536, DOI 10.1002/prot.340230408; Lee C, 1997, IEEE T NEURAL NETWOR, V8, P75; MAO J, 1994, P 12 INT C PATT REC, P622; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; MARCHAND A, 1983, AM J CLIN PATHOL, V80, P369; Merz C.J., 1998, UCI REPOSITORY MACHI; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1986, P 2 AUSTR C APPL EXP; RAYMER ML, 1997, P 7 INT C GEN ALG IC, P561; RAYMER ML, UNPUB PROTEIN ENG; Raymer ML, 1997, J MOL BIOL, V265, P445, DOI 10.1006/jmbi.1996.0746; REED J, 1967, J THEOR BIOL, V17, P319, DOI 10.1016/0022-5193(67)90097-5; Rogson J., 1966, NATURAL AUTOMATA USE, P3; SCHRAUDOLPH NN, 1992, CS92249 U CAL DEP CO; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Sridharan NS, 1989, P 11 INT JOINT C ART, P781; WEISS S, 1990, EMPIRICAL COMP PATTE	41	268	275	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1089-778X		IEEE T EVOLUT COMPUT	IEEE Trans. Evol. Comput.	JUL	2000	4	2					164	171		10.1109/4235.850656		8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	334WL	WOS:000088208600006	
J	Kushilevitz, E; Ostrovsky, R; Rabani, Y				Kushilevitz, E; Ostrovsky, R; Rabani, Y			Efficient search for approximate nearest neighbor in high dimensional spaces	SIAM JOURNAL ON COMPUTING			English	Article						nearest neighbor search; data structures; random projections	ALGORITHM	We address the problem of designing data structures that allow efficient search for approximate nearest neighbors. More specifically given a database consisting of a set of vectors in some high dimensional Euclidean space, we want to construct a space-efficient data structure that would allow us to search, given a query vector, for the closest or nearly closest vector in the database. We also address this problem when distances are measured by the L-1 norm and in the Hamming cube. Significantly improving and extending recent results of Kleinberg, we construct data structures whose size is polynomial in the size of the database and search algorithms that run in time nearly linear or nearly quadratic in the dimension. (Depending on the case, the extra factors are polylogarithmic in the size of the database.).	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; Bell Commun Res Inc, Morristown, NJ 07960 USA	Kushilevitz, E (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; Alon N., 1992, PROBABILISTIC METHOD; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Clarkson K. L., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.177609; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Dolev D., 1993, Proceedings of the 2nd Israel Symposium on Theory and Computing Systems (Cat. No.93TH0520-7), DOI 10.1109/ISTCS.1993.253486; DOLEV D, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P251; Duda R., 1973, PATTERN CLASSIFICATI; FEIGE U, 1990, PROCEEDINGS OF THE TWENTY SECOND ANNUAL ACM SYMPOSIUM ON THEORY OF COMPUTING, P128, DOI 10.1145/100216.100230; FIGIEL T, 1977, ACTA MATH-DJURSHOLM, V139, P53, DOI 10.1007/BF02392234; Flickner M., 1995, IEEE COMPUT, V28, P23; Gersho A, 1991, VECTOR QUANTIZATION; Goldreich O., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73010; HASTIE T, 1995, 1 INT ACM C KNOWL DI; INDK P, 1998, P 30 ANN ACM S THEOR, P604; INDYK P., 1997, P 29 ANN ACM S THEOR, P618, DOI 10.1145/258533.258656; Johnson W. B., 1984, CONT MATH, V26, P189; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E., 1997, COMMUNICATION COMPLE; Linial N., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237999; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; MATOUSEK J, 1991, PROCEEDINGS - 32ND ANNUAL SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, P207, DOI 10.1109/SFCS.1991.185370; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; Mulmuley K., 1993, COMPUTATIONAL GEOMET; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; Salton G., 1989, AUTOMATIC TEXT PROCE; SMEULDERS AWM, 1996, WORLD SCI SER SOFTWA, V8; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Yao A.C., 1985, P 17 ANN ACM S THEOR, P163, DOI 10.1145/22145.22163	35	60	60	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0097-5397		SIAM J COMPUT	SIAM J. Comput.	JUN 28	2000	30	2					457	474		10.1137/S0097539798347177		18	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	334BV	WOS:000088166000006	
J	de Bruijn, LM; Hasman, A; Arends, JW				de Bruijn, LM; Hasman, A; Arends, JW			Supporting the classification of pathology reports: comparing two information retrieval methods	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE			English	Article						N-gram; information theory; SNOMED; coding		In this contribution two methods from the domain of information retrieval are compared. The goal of the retrieval is to select from a library of pathology reports those ones that are most similar to a given report. The SNOMED codes that accompany these reports are presented to the pathologist who has to code the given report with the aim to improve the quality of coding. The reports were represented either as a vector of words or as a vector of N-grams. Both 4-, 5- and 6-grams were used. The similarity of the reports was determined by comparing the SNOMED terms that were added to the reports. It could be concluded that the word-based method was consistently better than the N-gram method. (C) 2000 Elsevier Science Ireland Ltd. All rights reserved.	Univ Maastricht, Dept Med Informat, Maastricht, Netherlands; Univ Limburg, Acad Hosp Maastricht, Dept Pathol, Maastricht, Netherlands	de Bruijn, LM (reprint author), Univ Maastricht, Dept Med Informat, Maastricht, Netherlands.		Hasman, Arie/F-1816-2013				Chudacek J., 1984, Informatie, V26; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAMASHEK M, 1995, SCIENCE, V267, P843, DOI 10.1126/science.267.5199.843; de Bruijn LM, 1998, METHOD INFORM MED, V37, P260; deBruijn LM, 1996, ST HEAL T, V34, P198; deBruijn LM, 1997, COMPUT METH PROG BIO, V54, P115, DOI 10.1016/S0169-2607(97)00040-0; FINDLER NV, 1979, IEEE T PATTERN ANAL, V1, P116; GANTNER GE, 1979, SYSTEMATIZED NOMENCL; HALL PA, 1986, J CLIN PATHOL, V39, P622, DOI 10.1136/jcp.39.6.622; ROTHWELL DJ, 1993, SYSTEMATIZED NOMENCL; SALTON G, 1983, INTRO MODERN INFORMA	11	6	6	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0169-2607		COMPUT METH PROG BIO	Comput. Meth. Programs Biomed.	JUN	2000	62	2					109	113		10.1016/S0169-2607(00)00056-0		5	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	307BG	WOS:000086633100005	
J	De, RK; Pal, SK				De, RK; Pal, SK			Pattern classification using fuzzy sets and neural nets: a case-based approach	ENGINEERING INTELLIGENT SYSTEMS FOR ELECTRICAL ENGINEERING AND COMMUNICATIONS			English	Article						pattern classification; fuzzy sets; neural nets	SYSTEM	The present article describes a case-based pattern classification method in connectionist framework using fuzzy set theory. Some labeled samples from each class are selected automatically as cases based on the concept of fuzzy similarity, and are represented as hidden nodes. The number of nodes is determined by the extent of fuzzy regions around cases. These are determined adaptively through growing and pruning under supervised training of the network. The effectiveness of the system, along with comparisons, has been demonstrated on various synthetic and real life pattern recognition problems for different extent of fuzzy regions.	Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India	De, RK (reprint author), Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India.						AAMODT A, 1994, AI COMMUN, V7, P39; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMESHEK E, 1993, ADV CONNECTIONIST NE, V2; Dubois D, 1998, INT J INTELL SYST, V13, P345, DOI 10.1002/(SICI)1098-111X(199804)13:4<345::AID-INT3>3.3.CO;2-I; Fukunaga K, 1972, INTRO STAT PATTERN R; HAYASHI Y, 1991, ADV NEURAL INFORMATI, P578; Kolodner J., 1993, CASE BASED REASONING; Liu ZQ, 1997, IEEE T FUZZY SYST, V5, P209; MAIN J, 1996, P NAFIPS 1996 BIENN, P438, DOI 10.1109/NAFIPS.1996.534774; MALEK M, 1995, CONNECTIONIST INDEXI; Pal S. K, 1986, FUZZY MATH APPROACH; Watson I., 1997, APPL CASE BASED REAS; Petersen J, 1997, FUZZY SET SYST, V85, P247, DOI 10.1016/0165-0114(95)00354-1	13	0	0	C R L PUBLISHING LTD	MARKET HARBOROUGH	PO BOX 31, MARKET HARBOROUGH LE16 9RQ, LEICS, ENGLAND	0969-1170		ENG INTELL SYST ELEC	Eng. Intell. Syst. Elect. Eng. Commun.	JUN	2000	8	2					103	108				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	327JH	WOS:000087790400005	
J	Bermejo, S; Cabestany, J				Bermejo, S; Cabestany, J			A batch learning vector quantization algorithm for nearest neighbour classification	NEURAL PROCESSING LETTERS			English	Article						Learning Vector Quantization; Newton's optimization; nearest neighbour classification; batch learning algorithms		We introduce a batch learning algorithm to design the set of prototypes of 1 nearest-neighbour classifiers. Like Kohonen's LVQ algorithms, this procedure tends to perform vector quantization over a probability density function that has zero points at Bayes borders. Although it differs significantly from their online counterparts since: (1) its statistical goal is clearer and better defined; and (2) it converges superlinearly due to its use of the very fast Newton's optimization method. Experiments results using artificial data confirm faster training time and better classification performance than Kohonen's LVQ algorithms.	Univ Politecn Catalunya, Dept Elect Engn, ES-08034 Barcelona, Spain							Bottou L., 1998, ONLINE LEARNING NEUR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gersho A., 1992, VECTOR QUANTIZATION; Hestenes M., 1980, CONJUGATE DIRECTION; Kohonen T., 1996, SELF ORG MAPS; Kohonen T, 1995, LVQ PAK LEARNING VEC; LAVIGNA A, 1990, THESIS U MARYLAND; Vapnik V., 1982, SPRINGER SERIES STAT	8	6	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1370-4621		NEURAL PROCESS LETT	Neural Process. Lett.	JUN	2000	11	3					173	184		10.1023/A:1009634824627		12	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	331VT	WOS:000088039900001	
J	Komosinski, M; Krawiec, K				Komosinski, M; Krawiec, K			Evolutionary weighting of image features for diagnosing of CNS tumors	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						evolutionary weighting; image features; diagnosis of CNS tumors	FEATURE SUBSET-SELECTION; SEGMENTATION	This paper concerns an application of evolutionary feature weighting for diagnosis support in neuropathology. The original data in the classification task are the microscopic images of ten classes of central nervous system (CNS) neuroepithelial tumors. These images are segmented and described by the features characterizing regions resulting from the segmentation process. The final features are in part irrelevant. Thus, we employ an evolutionary algorithm to reduce the number of irrelevant attributes, using the predictive accuracy of a classifier ('wrapper' approach) as an individual's fitness measure. The novelty of our approach consists in the application of evolutionary algorithm for feature weighting, not only for feature selection. The weights obtained give quantitative information about the relative importance of the features. The results of computational experiments show a significant improvement of predictive accuracy of the evolutionarily found feature sets with respect to the original feature set. (C) 2000 Elsevier Science B.V. All rights reserved.	Poznan Univ Technol, Inst Comp Sci, PL-60965 Poznan, Poland	Komosinski, M (reprint author), Poznan Univ Technol, Inst Comp Sci, Piotrowo 3A, PL-60965 Poznan, Poland.						Aha D. W., 1991, P DARPA CAS BAS REAS, P147; AHA DW, 1994, CASE BASED REASONING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BOUCKAERT A, 1988, NEW ENGL J MED, V350, P2800; BRILL FZ, 1992, IEEE T NEURAL NETWOR, V3, P324, DOI 10.1109/72.125874; Chan SWK, 1996, ARTIF INTELL MED, V8, P67, DOI 10.1016/0933-3657(95)00021-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASH M, 1997, INTELL DATA ANAL, P1; Davis L, 1991, HDB GENETIC ALGORITH; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Gonzalez R., 1992, DIGITAL IMAGE PROCES; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hayes-Roth F., 1983, BUILDING EXPERT SYST; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; JELONEK J, 1998, J DECIS SYST, V7, P39; JELONEK J, 1998, P 7 INT S INT INF SY, P146; Jelonek J, 1997, ARTIF INTELL MED, V9, P227, DOI 10.1016/S0933-3657(96)00375-2; JELONEK J, 1999, POLISH J PATHOL, P2; JELONEK J, 1995, SOFT COMPUTING; JELONEK J, 1999, LECT NOTES ARTIF INT, V1609, P665; John G. H., 1994, P 11 INT C MACH LEAR, P121; KLEIHUES P, 1993, NEW WHO CLASSIFICATI, P3; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MANGO LJ, 1994, CANCER LETT, V77, P155, DOI 10.1016/0304-3835(94)90098-1; Matheus C.J., 1989, P 11 INT JOINT C ART, P645; MATHEUS CJ, P 8 INT WORKSH MACH; Michalewicz Z, 1996, GENETIC ALGORITHMS D; Michalski R. S., 1994, MACHINE LEARNING MUL, V4; Michalski R.S., 1978, 927 U ILL DEP COMP S; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/cviu.1993.1024; RICHELDI M, 1996, P 2 INT C KNOWL DISC, P379; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; WNEK J, 1991, P IJCAI 91 WORKSH EV; Yang J., 1998, FEATURE EXTRACTION C	40	10	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAY	2000	19	1					25	38		10.1016/S0933-3657(99)00048-2		14	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	308KQ	WOS:000086710600002	
J	Friedman, J; Hastie, T; Tibshirani, R				Friedman, J; Hastie, T; Tibshirani, R			Additive logistic regression: A statistical view of boosting	ANNALS OF STATISTICS			English	Article						classification; tree; nonparametric estimation; stagewise fitting; machine learning	CLASSIFICATION	Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted Versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications.	Stanford Univ, Dept Stat, Stanford, CA 94305 USA; Stanford Linear Accelerator Ctr, Stanford, CA 94305 USA; Stanford Univ, Dept Hlth Res & Policy, Div Biostat, Stanford, CA 94305 USA	Friedman, J (reprint author), Stanford Univ, Dept Stat, Sequoia Hall, Stanford, CA 94305 USA.						BREIMAN L, 1998, COMBINING PREDICTORS; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; BREIMAN L, 1997, 504 U CAL DEPT STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BUJA A, 1989, ANN STAT, V17, P453, DOI 10.1214/aos/1176347115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIETTERICH T, 1998, MACH LEARN, P1; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FREUND Y, 1997, J COMPUT SYSTEM SCI, V55; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238163; Friedman J, 1996, ANOTHER APPROACH POL; Friedman J, 1999, GREEDY FUNCTION APPR; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Hastie T, 1998, ANN STAT, V26, P451; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE TJ, 1990, GENERALIZED ADDITIVE; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Huber P., 1964, ANN MATH STAT, V53, P73; Kearns M. J., 1994, INTRO COMPUTATIONAL; Kobel C, 2011, GEN LINEAR MODELS; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Schapire R., 1997, P 14 INT C MACH LEAR, P313; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHAPIRE RE, 1998, P 11 ANN C COMP LEAR; Schapire RE, 1998, ANN STAT, V26, P1651; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972	29	1269	1330	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 7, 3401 INVESTMENT BLVD, HAYWARD, CA 94545 USA	0090-5364		ANN STAT	Ann. Stat.	APR	2000	28	2					337	374		10.1214/aos/1016218223		38	Statistics & Probability	Mathematics	360LT	WOS:000089669700001	
J	Levy, AY; Weld, DS				Levy, AY; Weld, DS			Intelligent Internet systems	ARTIFICIAL INTELLIGENCE			English	Editorial Material							WEB		Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Levy, AY (reprint author), Univ Washington, Dept Comp Sci & Engn, Box 352350, Seattle, WA 98195 USA.	alon@cs.washington.edu					ABITEBOUL S, 1997, P INT C DAT THEOR IC; ABITEBOUL S, 1998, P ACM SIGACT SIGMOD; ADALI S, 1996, P ACM SIGMOD C MAN D; AMBITE J, 1998, P ACM SIGMOD C MAN D; Ambite JL, 2000, ARTIF INTELL, V118, P115, DOI 10.1016/S0004-3702(00)00003-5; ANDERSON CR, 1999, P INT WORKSH WEB DAT; Arens Y., 1996, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V6, DOI 10.1007/BF00122124; Arocena Gustavo, 1998, P INT C DAT ENG ICDE; ASHISH N, 1997, P COOP INF SYST; ATZENI P, 1998, P C EXT DAT TECHN ED; BALABANOVIC M, 1997, FAB CONTENT BASED CO; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; BAUER M, 2000, P 2000 C INT US INT; BEERI C, 1998, P INT WORKSH WEB DAT; Bergamaschi S., 1999, SIGMOD Record, V28; BILLSUS D, 1999, P 7 INT C US MOD, P99; BLAKELEY JA, 1996, P ACM SIGMOD C MAN D, P161, DOI 10.1145/233269.233329; Brin S., 1998, P 7 WORLD WID WEB C; Buneman P., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263675; CALIFF M, 1997, WORKSH NAT LANG LEAR; Carberry S., 1988, Computational Linguistics, V14; CATARCI T, 1993, J INTELLIGENT COOPER; CHAUDHURI S, 1995, P INT C DAT ENG ICDE; CLUET S, 1998, P ACM SIGMOD C MAN D; COHEN W, 1998, P ACM SIGMOD C MAN D; Cohen WW, 2000, ARTIF INTELL, V118, P163, DOI 10.1016/S0004-3702(99)00102-2; COLLINS A, 1982, P 4 ANN C COGN SCI S; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craven M, 2000, ARTIF INTELL, V118, P69, DOI 10.1016/S0004-3702(00)00004-7; CRAVEN M, 1998, P AAAI 98 MAD WI; DENT L, 1992, P 10 NAT C ART INT S, P96; DEUTSCH A, 1999, P WORLD WID WEB 8 C; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Doorenbos R. B., 1997, Proceedings of the First International Conference on Autonomous Agents, DOI 10.1145/267658.267666; DUSCHKA O, 1997, P ACM S APPL COMP SA; DUSCHKA O, 1999, J LOGIC PROGRAMMING; DUSCHKA O, 1997, P AAAI 97 PROV RI; DUSCHKA OM, 1997, P ACM SIGACT SIGMOD; Etzioni O, 1997, ARTIF INTELL, V89, P113, DOI 10.1016/S0004-3702(96)00026-4; ETZIONI O, 1994, COMMUN ACM, V37, P72, DOI 10.1145/176789.176797; ETZIONI O, 1994, MOR KAUF R, P178; FENSEL D, 1999, P IJCAI WORKSH INT I; FERNANDEZ M, 1998, P ACM SIGMOD C MAN D; FERNANDEZ M, 1999, P IJCAI 99 STOCKH SW; FLORESCU D, 1999, P ACM SIGMOD C MAN D; FLORESCU D, 1996, INT J INTELLIGENT CO, V5; Florescu D., 1998, SIGMOD Record, V27; Florescu D, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P216; Freitag D., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; FRIEDMAN M, 1997, P IJCAI 97 NAG JAP; Garcia-Molina H., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008683107812; GOLDEN K, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1048; GOOD N, 1999, P AAAI 99 ORL FL; HAAS L, 1997, P INT C VER LARG DAT; HSU C, 1998, J INFORMATION SYSTEM, V23; HUFFMAN S, 1996, CONNECTIONIST STAT S; Hull R., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263668; Hull R., 1996, P ACM SIGMOD INT C M, P481, DOI 10.1145/233269.233365; IVES Z, 1999, P ACM SIGMOD C MAN D; JAKOBOVITS R, 1997, AMIA FALL S, P454; Joachims T., 1997, P 15 INT JOINT C ART, P770; KAUTZ H, 1994, P AAAI 94 SEATTL WA; Kleinberg J., 1998, P 9 ACM SIAM S DISCR; KNOBLOCK C, 1998, P AAAI WORKSH INT DA; KNOBLOCK CA, 1995, AAAI SPRING S INF GA; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; KUSHMERICK N, 1997, P IJCAI 97 NAG JAP; Kushmerick N., 1999, Proceedings of the Third International Conference on Autonomous Agents, DOI 10.1145/301136.301186; KWOK CT, 1996, P AAAI 96 PORTL OR; LAMBRECHT E, 1999, P 16 INT JOINT C ART, P1204; Lane T., 1997, P 20 NAT INF SYST SE, V1, P366; LAU T, 1999, P 7 INT C US MOD, P119; LAU T, 1999, COMM ACM; Lesser V, 2000, ARTIF INTELL, V118, P197, DOI 10.1016/S0004-3702(00)00005-9; Levy A, 1999, LECT NOTES COMPUT SC, V1600, P249; Levy A., 1996, P INT C VER LARG DAT; LEVY AY, 1995, P ACM SIGACT SIGMOD; LEVY AY, 1995, AAAI FALL S AI APPL; LEVY AY, 1996, P ACM SIGACT SIGMOD; LI WS, 1995, AAAI SPRING S INF GA; Lieberman H., 1995, P 14 INT JOINT C ART, P924; MAES P, 1994, COMMUN ACM, V37, P31; MAES P, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P459; MAES P, 1994, COMMUN ACM, V37, P146; McCallum A., 1999, P 16 INT JOINT C ART, P662; MITCHELL T, 1994, COMMUN ACM, V37, P81; MOTRO A, 1989, ACM T DATABASE SYST, V14, P480, DOI 10.1145/76902.76904; MOTRO A, 1996, P 1996 C INF QUAL, P94; MUSLEA I, 1999, P 3 INT C AUT AG; Noy Natalya Freidman, 1999, P KNOWL ACQ WORKSH B; Palopoli Luigi, 1999, P COOPIS; PAOLINI P, 1998, P C EXT DAT TECHN ED; PAPAKONSTANTINO.Y, 1996, P INT C VER LARG DAT; Pazzani M, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P54; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; PERKOWITZ M, 1995, P IJCAI 95 MONTR QUE, P930; PERKOWITZ M, 1999, P 8 INT WWW C TOR ON; PERKOWITZ M, 1997, P IJCAI 97 NAG JAP; Perkowitz M, 2000, ARTIF INTELL, V118, P245, DOI 10.1016/S0004-3702(99)00098-3; Perkowitz M., 1997, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V8, DOI 10.1023/A:1008672508721; PERKOWITZ M, 1998, P AAAI 98 MAD WI; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAJARAMAN A, 1995, P ACM SIGACT SIGMOD; Riedl J., 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; Shardanand U., 1995, C HUM FACT COMP SYST; SLEEMAN D. H., 1982, INTELLIGENT TUTORING; Soderland S, 1999, MACH LEARN, V34, P233, DOI 10.1023/A:1007562322031; Soderland S., 1997, P 3 INT C KNOWL DISC; Steven A. L., 1983, MENTAL MODELS; TOMASIC A, 1998, IEEE T KNOWLEDGE DAT; TOYAMA M, 1998, P C EXT DAT TECHN ED; Tsatalos O. G., 1996, VLDB Journal, V5, DOI 10.1007/s007780050018; ULMAN JD, 1997, P INT C DAT THEOR IC; Urhan T., 1998, P 1998 ACM SIGMOD IN, P130, DOI 10.1145/276304.276317; VASSALOS V, 1997, P INT C VER LARG DAT; WOELK D, 1995, P ACM SIGMOD C MAN D, P443, DOI 10.1145/223784.223867; WOELK D, 1993, P ACM SIGMOD INT C M, P491, DOI 10.1145/170035.170150; Yang H. Z., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; YERNENI R, 1998, P C EXT DAT TECHN ED, P57; Zilberstein S., 1997, P AAAI WORKSH BUILD; Zukerman I., 1999, P 7 INT C US MOD UM, P275	123	24	25	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	APR	2000	118	1-2					1	14		10.1016/S0004-3702(00)00013-8		14	Computer Science, Artificial Intelligence	Computer Science	308WW	WOS:000086736700001	
J	Kim, SH; Shin, SW				Kim, SH; Shin, SW			Identifying the impact of decision variables for nonlinear classification tasks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						feature weighting; similarity assessment; k-nearest neighbor; lazy learning; artificial neural network; genetic algorithms	LEARNING ALGORITHMS; GENETIC ALGORITHMS; NEURAL NETWORKS; SELECTION; FEATURES	This paper presents a novel procedure to improve a class of learning systems known as lazy learning algorithms by optimizing the selection of variables and their attendant weights through an artificial neural network and a genetic algorithm. The procedure utilizes its previous knowledge base-also called a case base-to select an effective subset for adaptation. In particular, the procedure explores a space of N variables and generates a reduced space of M dimensions. This is achieved through clustering and compaction. The clustering stage involves the minimization of distances among individuals within the same class while maximizing the distances among different classes. The compaction stage involves the elimination of the irrelevant or redundant feature dimensions. To achieve these two goals concurrently through the evolutionary process, new measures of fitness have been developed. The metrics lead to procedures which exhibit superior characteristics in terms of both accuracy and efficiency. The efficiency springs from a reduction in the number of features required for analysis, thereby saving on computational cost as well as data collection requirements. The utility of the new techniques is validated against a variety of data sets from natural and commercial sources. (C) 2000 Published by Elsevier Science Ltd. All rights reserved.	Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul, South Korea; Samsung SDS Co Ltd, Seoul, South Korea	Kim, SH (reprint author), Korea Adv Inst Sci & Technol, Grad Sch Management, Seoul, South Korea.						AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BELUE LM, 1995, NEUROCOMPUTING, V7, P111, DOI 10.1016/0925-2312(94)E0053-T; BRILL FZ, 1992, IEEE T NEURAL NETWOR, V3, P324, DOI 10.1109/72.125874; Burr Ridge I, 1997, MACHINE LEARNING; Chambers L., 1995, PRACTICAL HDB GENETI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DASH M, 1997, FEATURE SELECTION CL; Duda R.O., 1973, PATTER CLASSIFICATIO; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HOLLAND JH, 1975, ADAPTATION NATURAL A; Howes P, 1999, NEUROCOMPUTING, V24, P191, DOI 10.1016/S0925-2312(98)00102-7; Ishii N, 1998, IEEE INTERNATIONAL JOINT SYMPOSIA ON INTELLIGENCE AND SYSTEMS - PROCEEDINGS, P27; John G.H., 1994, INT C MACH LEARN, P121; KELLY JD, 1991, INT JOINT C ART INT, P645; KIM SH, 1998, KOR EXP SYST SOC 98, P123; Kolodner J., 1993, CASE BASED REASONING; LANGLEY P, 1993, IJCAI-93, VOLS 1 AND 2, P889; LEAKE D, 1995, INT C CAS BAS REAS S; Looney C.G., 1997, PATTERN RECOGNITION; MURPHY PM, 1993, UCI REPOSITORY MACHI; PUNCH WF, 1993, INT C GEN ALG, P557; Schank R. C., 1977, SCRIPTS PLANS GOALS; SCHANK RC, 1990, INSIDE CASE BASED RE; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; Shin KS, 1999, EXPERT SYST APPL, V16, P85, DOI 10.1016/S0957-4174(98)00063-3; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; STANFILL C, 1986, COMMUN ACM, P1213; TARR G, 1991, THESIS SCH ENG OH; VAFAIE H, 1993, INT C TOOLS ART INT, P57; Watson I., 1997, APPL CASE BASED REAS; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YOON Y, 1994, DECIS SUPPORT SYST, V11, P497, DOI 10.1016/0167-9236(94)90021-3	35	13	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	APR	2000	18	3					201	214		10.1016/S0957-4174(99)00062-7		14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	310BU	WOS:000086807300003	
J	Prevost, L; Milgram, M				Prevost, L; Milgram, M			Modelizing character allographs in omni-scriptor frame: a new non-supervised clustering algorithm	PATTERN RECOGNITION LETTERS			English	Article						dynamic character recognition; allographs; heterogeneous classes; clustering; classification by modelization	RECOGNITION	The "problem of the allographs" specific of the dynamic handwriting in omni-scriptor context renders the implementation of "classical" clustering algorithms particularly delicate because it introduces the notion of heterogeneous classes characterized by strongly variable example densities. We propose here a hybrid clustering algorithm combining both a prototype placement stage and an adaptation stage. The process reduces drastically the number of references to be examined during a k-nn classification while preserving to the classifier a high level of performance. The experience has been driven on an extensive alphabet including 80 classes. Recognition rates, evaluated on nearly 35 000 examples from the UNIPEN basis show the reliability of the modelization. (C) 2000 Published by Elsevier Science B.V. All rights reserved.	Univ Paris 06, LIS Grp P&C, F-75252 Paris 05, France	Prevost, L (reprint author), Univ Paris 06, LIS Grp P&C, Boite 164,4 Pl Jussieu, F-75252 Paris 05, France.						ANQUETIL E, 1996, IWFHR 96, P47; BENGIO Y, 1995, NEURAL COMPUT, V7, P1289, DOI 10.1162/neco.1995.7.6.1289; BONTEMPI B, 1994, INT C PATT RECOG, P83, DOI 10.1109/ICPR.1994.576880; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duneau L, 1996, PATTERN RECOGN, V29, P1981, DOI 10.1016/S0031-3203(96)00042-8; GARCIASALICETTI S, 1996, ICPR 96 D, P515; GENTRIC P, 1993, ICOHD 93, P13; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; Ho T. K., 1994, IEEE T PATTERN ANAL, V16; Kohonen T., 1989, SELF ORG ASS MEMORY; MANKE S, 1994, INT C PATT RECOG, P596, DOI 10.1109/ICPR.1994.577051; MORASSO P, 1993, PATTERN RECOGN, V26, P451, DOI 10.1016/0031-3203(93)90172-S; Nathan K. S., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), DOI 10.1109/ICASSP.1993.319762; Prevost L, 1998, INT C PATT RECOG, P381; PREVOST L, 1997, ICDAR 97, P499; Ridella S., 1995, WCNN '95. World Congress on Neural Networks. 1995 International Neural Network Society Annual Meeting; SCHWENK H, 1996, ICPR 96 D, P520	17	9	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	APR	2000	21	4					295	302		10.1016/S0167-8655(99)00159-2		8	Computer Science, Artificial Intelligence	Computer Science	298QA	WOS:000086149600002	
J	Wilson, DR; Martinez, TR				Wilson, DR; Martinez, TR			Reduction techniques for instance-based learning algorithms	MACHINE LEARNING			English	Article						instance-based learning; nearest neighbor; instance reduction; pruning; classification	NEAREST-NEIGHBOR; SIMILARITY	Instance-based learning algorithms are often faced with the problem of deciding which instances to store for use during generalization. Storing too many instances can result in large memory requirements and slow execution speed, and can cause an oversensitivity to noise. This paper has two main purposes. First, it provides a survey of existing algorithms used to reduce storage requirements in instance-based learning algorithms and other exemplar-based algorithms. Second, it proposes six additional reduction algorithms called DROP1-DROP5 and DEL (three of which were first described in Wilson & Martinez, 1997c, as RT1-RT3) that can be used to remove instances from the concept description. These algorithms and 10 algorithms from the survey are compared on 31 classification tasks. Of those algorithms that provide substantial storage reduction, the DROP algorithms have the highest average generalization accuracy in these experiments, especially in the presence of uniform class noise.	Brigham Young Univ, Dept Comp Sci, Neural Network & Machine Learning Lab, Provo, UT 84602 USA	Wilson, DR (reprint author), Brigham Young Univ, Dept Comp Sci, Neural Network & Machine Learning Lab, Provo, UT 84602 USA.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BATCHELOR BG, 1978, PATTERN RECOGNITION; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; Broomhead D. S., 1988, Complex Systems, V2; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DeGroot MH, 1986, PROBABILITY STAT; DIDAY E, 1974, 2 INT JOINT C PATT R, P534; DIETTERICH TG, 1989, P 6 INT WORKSH MACH, P124; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; Domingos P, 1996, MACH LEARN, V24, P141; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; Kubat M., 1997, MACH LEARN INT WORKS, P179; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Merz C. J., 1996, UCI REPOSITORY MACHI; MICHALSKI RS, 1981, PROGR PATTERN RECOGN, V1, P33; MITCHELL TM, 1980, READINGS MACHINE LEA, P184; Nadler M, 1993, PATTERN RECOGNITION; Papadimitriou C., 1982, COMBINATORIAL OPTIMI; PAPADIMITRIOU CH, 1980, LECT NOTES COMPUTER, V85, P470; RENALS S, 1989, P INT JOINT C NEURAL, V1, P461; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salzberg S., 1991, MACH LEARN, V6, P277; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Specht D., 1992, P INT JOINT C NEUR N, V1, P761, DOI 10.1109/IJCNN.1992.287095; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; Wasserman PD, 1993, ADV METHODS NEURAL N, P147; Watson I., 1994, KNOWLEDGE ENG REV, V9; WESS S, 1993, TOPICS CASE BASED RE, P67; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, V784, P323; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson D. R., 1997, P INT C ART NEUR NET, P514; WILSON DR, 1997, MACH LEARN, P403; WILSON DR, 1996, P INT C NEUR NETW IC, V2, P1263, DOI 10.1109/ICNN.1996.549079; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOLPERT DH, 1993, 92035001 SFI TR; Zhang J., 1992, P 9 INT MACH LEARN C, P470	54	373	386	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAR	2000	38	3					257	286		10.1023/A:1007626913721		30	Computer Science, Artificial Intelligence	Computer Science	283CZ	WOS:000085259700002	
J	Warfield, SK; Kaus, M; Jolesz, FA; Kikinis, R				Warfield, SK; Kaus, M; Jolesz, FA; Kikinis, R			Adaptive, template moderated, spatially varying statistical classification	MEDICAL IMAGE ANALYSIS			English	Article; Proceedings Paper	1st International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 98)	OCT 11-13, 1998	CAMBRIDGE, MASSACHUSETTS	Harvard Med Sch, Boston, Massachusetts Inst Technol, MA		segmentation; elastic matching; nonlinear registration; nearest neighbor classification; multiple sclerosis; knee cartilage; neonate; brain; tumor	DIGITAL BRAIN ATLAS; MR-IMAGES; SEGMENTATION; EVOLUTION	A novel image segmentation algorithm was developed to allow the automatic segmentation of both normal and abnormal anatomy from medical images. The new algorithm is a form of spatially varying statistical classification, in which an explicit anatomical template is used to moderate the segmentation obtained by statistical classification. The algorithm consists of an iterated sequence of spatially varying classification and nonlinear registration, which forms an adaptive, template moderated (ATM). spatially varying statistical classification (SVC), Classification methods and nonlinear registration methods are often complementary, both in the tasks where they succeed and in the tasks where they fail. By integrating these approaches the new algorithm avoids many of the disadvantages of each approach alone while exploiting the combination. The ATM SVC algorithm was applied to several segmentation problems, involving different image contrast mechanisms and different locations in the body. Segmentation and validation experiments were carried out for problems involving the quantification of normal anatomy (MRI of brains of neonates) and pathology of various types (MRI of patients with multiple sclerosis, MRI of patients with brain tumors, MRI of patients with damaged knee cartilage). In each case, the ATM SVC algorithm provided a better segmentation than statistical classification or elastic matching alone. (C) 2000 Elsevier Science B.V. All rights reserved.	Brigham & Womens Hosp, Surg Planning Lab, Boston, MA 02115 USA; Harvard Univ, Sch Med, Dept Radiol, Boston, MA 02115 USA	Warfield, SK (reprint author), Brigham & Womens Hosp, Surg Planning Lab, 75 Francis St, Boston, MA 02115 USA.		Warfield, Simon/B-3352-2009				BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; CHRISTENSEN GE, 1994, PHYS MED BIOL, V39, P609, DOI 10.1088/0031-9155/39/3/022; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; CLINE HE, 1990, J COMPUT ASSIST TOMO, V14, P1037, DOI 10.1097/00004728-199011000-00041; COLLINS DL, 1994, THESIS MCGILL U; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dengler J., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000170; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646; GUTTMANN CRG, 1995, AM J NEURORADIOL, V16, P1481; HUPPI P, 1997, SOC PEDI RES 1997 AN, V41, P1733; Huppi PS, 1998, ANN NEUROL, V43, P224, DOI 10.1002/ana.410430213; KAMBER M, 1992, SPIE VIS BIOMED COMP, V1808, P590; Kikinis R, 1996, IEEE T VIS COMPUT GR, V2, P232, DOI 10.1109/2945.537306; KIKINIS R, 1992, JMRI-J MAGN RESON IM, V2, P619, DOI 10.1002/jmri.1880020603; Kumar A, 1996, IEEE T IMAGE PROCESS, V5, P598, DOI 10.1109/83.491336; Solloway S, 1997, MAGNET RESON MED, V37, P943, DOI 10.1002/mrm.1910370620; Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4; Van Leemput K, 1998, LECT NOTES COMPUT SC, V1496, P1222; VANNIER MW, 1985, RADIOLOGY, V154, P221; WARFIELD S, 1995, IMAGE GUIDED SURG, V1, P326; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; Warfield SK, 1999, BRAIN WARPING, P67, DOI 10.1016/B978-012692535-7/50080-X; Warfield SK, 1998, PARALLEL COMPUT, V24, P1345, DOI 10.1016/S0167-8191(98)00061-1; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747	27	200	202	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1361-8415		MED IMAGE ANAL	Med. Image Anal.	MAR	2000	4	1					43	55		10.1016/S1361-8415(00)00003-7		13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	404LR	WOS:000167100200005	
J	Wilson, DR; Martinez, TR				Wilson, DR; Martinez, TR			An integrated instance-based learning algorithm	COMPUTATIONAL INTELLIGENCE			English	Article						inductive learning; instance-based learning; classification; pruning; distance function; distance-weighting; voting; parameter estimation	NEAREST NEIGHBOR ALGORITHM; SIMILARITY; FEATURES	The basic nearest-neighbor rule generalizes well in many domains but has several shortcomings, including inappropriate distance functions, large storage requirements, slow execution time, sensitivity to noise, and an inability to adjust its decision boundaries after storing the training data. This paper proposes methods for overcoming each of these weaknesses and combines the methods into a comprehensive learning system called the Integrated Decremental Instance-Based Learning Algorithm (IDIBL) that seeks to reduce storage, improve execution speed, and increase generalization accuracy, when compared to the basic nearest neighbor algorithm and other learning models. IDIBL tunes its own parameters using a new measure of fitness that combines confidence and cross-validation accuracy in order to avoid discretization problems with more traditional leave-one-out cross-validation. Tn our experiments IDIBL achieves higher generalization accuracy than other less comprehensive instance-based learning algorithms, while requiring less than one-fourth the storage of the nearest neighbor algorithm and improving execution speed by a corresponding factor. In experiments on twenty-one data sets, IDIBL also achieves higher generalization accuracy than that reported for sixteen major machine learning and neural network models.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Wilson, DR (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.						AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BATCHELOR BG, 1978, PATTERN RECOGNITION; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; Broomhead D. S., 1988, Complex Systems, V2; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Conover WJ., 1971, PRACTICAL NONPARAMET, P206; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1979, P IEEE, V67, P708, DOI 10.1109/PROC.1979.11321; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DeGroot MH, 1986, PROBABILITY STAT; DENG K, 1995, P INT JOINT C ART IN; DIDAY E, 1974, 2 INT JOINT C PATT R, P534; DIETTERICH TG, 1989, P 6 INT WORKSH MACH, P124; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fisher RA, 1936, ANN EUGENIC, V7, P179; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GIRAUDCARRIER C, 1995, INTELLIGENT SYSTEMS, V1, P341; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Iba W., 1992, P 10 NAT C ART INT, P223; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KOHAVI R, 1995, P INT JOINT C ART IN; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LEBOWITZ M, 1985, COGNITIVE SCI, V9, P285, DOI 10.1016/S0364-0213(85)80001-X; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; MERZ CJ, 1996, UCI REPOSITORY MACH; MICHALSKI RS, 1969, P 5 INT S INF PROC B, P12; Michels R G, 1981, Retina, V1, P1; Michie D, 1994, MACHINE LEARNING NEU; MITCHELL TM, 1980, READINGS MACHINE LEA, P184; Mohri T., 1994, CASE BASED REASONING, P123; MOORE AW, 1993, MACHINE LEARNING; NADLER M, 1993, PATTERN REC ENG; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Papadimitriou C., 1982, COMBINATORIAL OPTIMI; PAPADIMITRIOU CH, 1980, LECT NOTES COMPUTER, V85, P470; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RENALS S, 1989, P INT JOINT C NEURAL, V1, P461; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rosenblatt Frank, 1959, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; Salzberg S., 1991, MACH LEARN, V6, P277; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; SCHAFFER C, 1993, MACHINE LEARNING, V13; Schapire R. E., 1997, MACH LEARN, p322{330; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; Wasserman P.D., 1993, ADV METHODS NEURAL C; WATSON I, 1994, KNOWL ENG REV, V9, P327; Wess S., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1995, AIC95012 NAV CTR APP; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 2000, IN PRESS MACHINE LEA, V38; WILSON DR, 1997, MACH LEARN, P403; Wilson D. R., 1997, Proceedings. Intelligent Information Systems. IIS'97 (Cat. No.97TB100201), DOI 10.1109/IIS.1997.645199; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WILSON DR, 1996, INT C ART INT EXP SY, P11; WOLPERT DH, 1993, 92035001 SFI SANT FE; ZARNDT F, 1995, THESIS B YOUNG U; ZHANG J, 1992, P 9 INT C MACH LEARN	80	38	39	BLACKWELL PUBLISHERS	MALDEN	350 MAIN STREET, STE 6, MALDEN, MA 02148 USA	0824-7935		COMPUT INTELL	Comput. Intell.	FEB	2000	16	1					1	28		10.1111/0824-7935.00103		28	Computer Science, Artificial Intelligence	Computer Science	290XN	WOS:000085703300001	
J	Liu, BD; Chen, CY; Tsao, JY				Liu, BD; Chen, CY; Tsao, JY			A modular current-mode classifier circuit for template matching application	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-ANALOG AND DIGITAL SIGNAL PROCESSING			English	Article						classifier circuit; current-mode circuit; Euclidean distance	VECTOR SUMMATION; CMOS	ln this brief, a current-mode Euclidean distance calculator circuit is proposed to play the role of a classifier. This classifier circuit is designed based on a subtracter circuit, an absoluter circuit, a squarer/divider:circuit. and a square-rooter/multiplier circuit. The modular design of this classifier allows it to be easily extended for classification application with more input dimensions by doing some proper signal-scaling work due to the dynamic range limited by the square-rooter/multiplier circuit. This classifier circuit has been fabricated with a 0.6-mu m single-polysilicon double-metal CMOS process. Both simulation results and measurements of the implemented chip are presented to confirm the function of this classifier.	Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan	Liu, BD (reprint author), Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 70101, Taiwan.						BATCHELOR BG, 1978, PATTERN RECOGNITION; Bezdek J., 1981, PATTERN RECOGNITION; BULT K, 1987, IEEE J SOLID-ST CIRC, V22, P357, DOI 10.1109/JSSC.1987.1052733; CHEN CY, 1996, P IEEE INT S CIRC SY, P511; CHEN CY, 1997, P INT S VLSI TECHN S, P83; CHEN CY, 1996, P 5 IEEE INT C FUZZ, P1080; Chen CY, 1997, IEE P-CIRC DEV SYST, V144, P265, DOI 10.1049/ip-cds:19971378; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FRANCO S, 1988, DESIGN OPERATIONAL A, P58; GNANADESIKAN R, 1977, METHODS STAT DATA AN; HUANG CY, 1995, ELECTRON LETT, V31, P1517, DOI 10.1049/el:19950976; Huang CY, 1999, ANALOG INTEGR CIRC S, V19, P255, DOI 10.1023/A:1008327929519; HUANG CY, 1994, ELECTRON LETT, V30, P1924, DOI 10.1049/el:19941342; HUNT E, 1975, ARTIFICIAL ITELLIGEN; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LANDOLT O, 1992, ELECTRON LETT, V28, P352, DOI 10.1049/el:19920220; Liu SI, 1996, IEEE T CIRCUITS-II, V43, P520; SEEVINCK E, 1991, IEEE J SOLID-ST CIRC, V26, P1098, DOI 10.1109/4.90062; SEEVINCK E, 1984, IEEE J SOLID-ST CIRC, V19, P311, DOI 10.1109/JSSC.1984.1052143; WIEGERIK RJ, 1993, ANAL SYNTHESIS MOS T; Winston P. H., 1977, ARTIFICIAL INTELLIGE	22	21	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1057-7130		IEEE T CIRCUITS-II	IEEE Trans. Circuits Syst. II-Analog Digit. Signal Process.	FEB	2000	47	2					145	151				7	Engineering, Electrical & Electronic	Engineering	287RY	WOS:000085521000009	
J	Baram, Y				Baram, Y			A geometric approach to consistent classification	PATTERN RECOGNITION			English	Article						classification; local separation; consistent reduction; nearest neighbor; condensed nearest neighbor; reduced nearest neighbor		A classifier is called consistent with respect to a given set of class-labeled points if it correctly classifies the set. We consider classifiers defined by unions of local separators (e.g., polytopes) and propose algorithms for consistent classifier reduction. The proposed approach yields a consistent reduction of the nearest-neighbor classifier, relating the expected classifier size to a local clustering property of the data and resolving unanswered questions raised by Hart (IEEE Trans. Inform. Theory IT-14(3) (1968)) with respect to the complexity of the condensed nearest neighbor method. (C) 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Baram, Y (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						AKIMOVA IY, 1984, ENG CYBERN, V22, P6; AKIMOVA IY, 1984, TKH KIBERN, V22, P102; Anderberg M. R., 1973, CLUSTER ANAL APPL; BARAM Y, 1996, NEUROCOMPUTING, V10, P347; Baum E. B., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90020-9; BONNER RE, 1964, IBM J RES DEV, V8, P22; Conway J. H., 1988, SPHERE PACKINGS LATT; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Everitt B. S., 1993, CLUSTER ANAL; Fukunaga K., 1990, INTRO STAT PATTERN R; GORDON AD, 1980, CLASSIFICATION; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jain A., 1988, ALGORITHMS CLUSTERIN; LEE DT, 1984, IEEE T COMPUT, V33, P1072; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; *U CAL IRV, MACH LEARN DAT BAS	20	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	FEB	2000	33	2					177	184		10.1016/S0031-3203(99)00050-3		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	265TX	WOS:000084262800001	
S	Sebban, M; Nock, R		Hamilton, HJ		Sebban, M; Nock, R			Identifying and eliminating irrelevant instances using information theory	ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	13th Biennial Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence (AI 2000)	MAY 14-17, 2000	MONTREAL, CANADA	Univ Regina, Simon Fraser Univ, Canadian Soc Computat Studies Intelligence			NEAREST-NEIGHBOR	While classical approaches deal with prototype selection (PS) using accuracy maximization, we investigate PS in this paper as an information preserving problem. We use information theory to build a statistical criterion from the nearest-neighbor topology. This statistical framework is used in a backward prototype selection algorithm (PSRCG). It consists in identifying and eliminating uninformative instances, and then reducing the global uncertainty of the learning set. We draw from experimental results and rigorous comparisons two main conclusions: (i) our approach provides a good compromise solution based on the requirement to keep a small number of prototypes, while not compromising the classification accuracy; (ii) our PSRCG algorithm seems to be robust in the presence of noise. Performances on several benchmarks tend to show the relevance and the effectiveness of our method in comparison with the classic PS algorithms based on the accuracy.	French W Indies & Guiana Univ, Dept Juridical Sci, TRIVIA Comp Sci, F-97190 Pointe A Pitre, France	Sebban, M (reprint author), French W Indies & Guiana Univ, Dept Juridical Sci, TRIVIA Comp Sci, F-97190 Pointe A Pitre, France.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BRIGHTON H, 1999, 3 EUR C PRINC PRACT, P283; BRODLEY C, 1996, 13 NAT C ART INT; BRODLEY C, 1993, 10 INT MACH LEARN C, P17; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMINGOS P, 1995, INT JOINT C ART INT; Freund Y, 1996, P 13 INT C MACH LEAR; GATES GW, 1972, IEEE T INFORM THEORY, P431; HART PE, 1968, IEEE T INFORMATI MAY, P515; Kearns M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237994; Keogh E., 1997, P 14 INT C MACH LEAR, P406; KOLLER D, 1996, 13 INT C MACH LEARN; LIGHT RJ, 1971, J AM STAT ASSOC, V66, P534, DOI 10.2307/2283520; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; SEBBAN M, 1999, 12 INT FLOR AI RES S, P230; SEBBAN M, 1999, 3 EUR C PRINC PRACT, P214; SKALAK D, 1996, UMCS1196089; SKALAK D, 1994, 11 INT MACH LEARN C, P293; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; WETTSCHERECK, 1994, 7 EUR MACH LEARN C A; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WILSON D, 1998, MACHINE LEARNING; Zhang J., 1992, P 9 INT MACH LEARN C, P470	23	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67557-4	LECT NOTES ARTIF INT			2000	1822						90	101				12	Computer Science, Artificial Intelligence	Computer Science	BR57V	WOS:000166853200008	
S	Li, JY; Ramamohanarao, K; Dong, GZ		He, J; Sato, M		Li, JY; Ramamohanarao, K; Dong, GZ			Emerging patterns and classification	ADVANCES IN COMPUTING SCIENCE-ASIAN 2000, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	6th Asian Computing Science Conference	NOV 25-27, 2000	GEORGE TOWN, MALAYSIA	Asian Int Technol, Univ Sains Malaysia, Penang State Govt, INRIA, Natl Univ Singapore, UNU, IIST				In this work, we review an important kind of knowledge pattern, emerging patterns (EPs). Emerging patterns are associated with two data sets, and can be used to describe significant changes between the two data sets. To discover all EPs embedded in high-dimension and large-volume databases is a challenging problem due to the number of candidates. We describe a special type of EP, called jumping emerging patterns (JEPs) and review some properties of JEP spaces (the spaces of jumping emerging patterns). We describe efficient border-based algorithms to derive the boundary elements of JEP spaces. Moreover, we describe a new classifier, called DeEPs, which makes use of the discriminating power of emerging patterns. The experimental results show that the accuracy of DeEPs is much better than that of k-nearest neighbor and that of C5.0.	Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia; Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA	Li, JY (reprint author), Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia.	jyli@cs.mu.oz.au; rao@cs.mu.oz.au; gdong@cs.wright.edu					Agarwal R., 1994, P 20 INT C VER LARG, P487; Bayardo Jr R.J, 1998, P ACM SIGMOD INT C M, P85, DOI 10.1145/276304.276313; Blake C.L., 1998, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dong G., 1999, P 2 INT C DISC SCI, P30; FAYYAD U., 1996, ADV KNOWLEDGE DISCOV, P1; Gunter CA, 1997, ARTIF INTELL, V95, P357, DOI 10.1016/S0004-3702(97)00033-7; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li J, 2000, P 4 PAC AS C KNOWL D, P220; Li JY, 1999, LECT NOTES ARTIF INT, V1704, P406; LI JY, 2000, P 4 EUR C PRINC PRAC; Mitchell T. M., 1977, P 5 INT JOINT C ART, P305; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Srikant R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-41428-2	LECT NOTES COMPUT SC			2000	1961						15	32				18	Computer Science, Theory & Methods	Computer Science	BS86G	WOS:000171236800003	
S	Sanchez, JS; Pla, F; Herrero, MC		Ferri, FJ; Inesta, JM; Amin, A; Pudil, P		Sanchez, JS; Pla, F; Herrero, MC			Using the dual of proximity graphs for binary decision tree design	ADVANCES IN PATTERN RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Joint International-Association-of-Pattern-Recognition International Workshops - SSPR 2000 and SPR 2000	AUG 30-SEP 01, 2000	ALICANTE, SPAIN	Int Assoc Pattern Recognit, Univ Valencia, Dept Informat	UNIV ALICANTE	Nearest Neighbour; decision tree; classification; gabriel graph; relative neighbourhood graph	NEAREST-NEIGHBOR CLASSIFIERS; NEURAL-NETWORK; ALGORITHM	This paper describes an algorithm to design a tree-structured classifier with the hyperplanes associated with a set of prototypes. The main purpose of this technique consists of defining a classification scheme whose result is close to that produced by the Nearest Neighbour decision rule, but getting important computation savings during classification.	Univ Jaume 1, Dept Informat, E-12071 Castellon de La Plana, Spain	Sanchez, JS (reprint author), Univ Jaume 1, Dept Informat, E-12071 Castellon de La Plana, Spain.	sanchez@uji.es; pla@uji.es; cherrero@uji.es					BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; Breiman L, 1984, CLASSIFICATION REGRE; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HEATH D, 1993, P 13 INT JOINT C ART, P1202; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; SANCHEZ JS, 1998, P 14 INT C PATT REC, V1, P542, DOI 10.1109/ICPR.1998.711200; TOUSSAINT GT, 1984, COMP SCI STAT 16 S I, P97; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4	24	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67946-4	LECT NOTES COMPUT SC			2000	1876						482	490				9	Computer Science, Theory & Methods	Computer Science	BS80F	WOS:000171155700050	
S	Omachi, S; Sun, F; Aso, H		Ferri, FJ; Inesta, JM; Amin, A; Pudil, P		Omachi, S; Sun, F; Aso, H			A new approximation method of the quadratic discriminant function	ADVANCES IN PATTERN RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Joint International-Association-of-Pattern-Recognition International Workshops - SSPR 2000 and SPR 2000	AUG 30-SEP 01, 2000	ALICANTE, SPAIN	Int Assoc Pattern Recognit, Univ Valencia, Dept Informat	UNIV ALICANTE		HANDWRITTEN	For many statistical pattern recognition methods, distributions of sample vectors are assumed to be normal, and the quadratic discriminant function derived from the probability density function of multivariate normal distribution is used for classification. However, the computational cost is O(n(2)) for n-dimensional vectors. Moreover, if there are not enough training sample patterns, covariance matrix can not be estimated accurately. In the case that the dimensionality is large, these disadvantages markedly reduce classification performance. In order to avoid these problems, in this paper, a new approximation method of the quadratic discriminant function is proposed. This approximation is done by replacing the values of small eigenvalues by a constant which is estimated by the maximum likelihood estimation. This approximation not only reduces the computational cost but also improves the classification accuracy.	Tohoku Univ, Grad Sch Engn, Aoba Ku, Sendai, Miyagi 9808579, Japan; Tohoku Bunka Gakuen Univ, Fac Sci & Technol, Aoba Ku, Sendai, Miyagi 9818551, Japan	Omachi, S (reprint author), Tohoku Univ, Grad Sch Engn, Aoba Ku, Aoba 05, Sendai, Miyagi 9808579, Japan.						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BUTUROVIC LJ, 1994, IEEE T PATTERN ANAL, V16, P420, DOI 10.1109/34.277596; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fix E., 1951, 4 SCH AV MED; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Fukunaga K., 1990, INTRO STAT PATTERN R; Grother P. J., 1995, NIST SPECIAL DATABAS; Kato N., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ79D-II; Kato N, 1999, IEEE T PATTERN ANAL, V21, P258, DOI 10.1109/34.754617; KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L; KURITA M, 1983, PRL8279 IEICE, P105; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Takeshita T., 1987, Transactions of the Institute of Electronics, Information and Communication Engineers D, VJ70D	16	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67946-4	LECT NOTES COMPUT SC			2000	1876						601	610				10	Computer Science, Theory & Methods	Computer Science	BS80F	WOS:000171155700062	
S	Holz, HJ; Loew, MH		Ferri, FJ; Inesta, JM; Amin, A; Pudil, P		Holz, HJ; Loew, MH			Design choices and theoretical issues for relative feature importance, a metric for nonparametric discriminatory power	ADVANCES IN PATTERN RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Joint International-Association-of-Pattern-Recognition International Workshops - SSPR 2000 and SPR 2000	AUG 30-SEP 01, 2000	ALICANTE, SPAIN	Int Assoc Pattern Recognit, Univ Valencia, Dept Informat	UNIV ALICANTE	discriminatory power; feature selection; feature extraction; feature analysis; non-parametric; classifier-independent; relative feature importance; multi-class		We have developed relative feature importance (RFI), a metric for the classifier-independent ranking of features. Previously, we have shown the metric to rank accurately features for a wide variety of artificial and natural problems, for both two-class and multi-class problems. In this paper, we present the design of the metric, including both theoretical considerations and statistical analysis of the possible components.	George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20002 USA	Holz, HJ (reprint author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20002 USA.						BENBASSAT M, 1978, INFORM CONTROL, V39, P227, DOI 10.1016/S0019-9958(78)90587-9; Chang I., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139730; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Fukunaga K., 1990, INTRO STAT PATTERN R; Holz HJ, 1997, PATTERN RECOGN LETT, V18, P1219, DOI 10.1016/S0167-8655(97)00118-9; HOLZ HJ, 1994, PATTERN RECOGN, V4, P473; Holz H. J., 1994, Proceedings 1994 IEEE-IMS Workshop on Information Theory and Statistics (Cat. No.94TH8100), DOI 10.1109/WITS.1994.513894; HOLZ HJ, 2000, 15 INT C PATT REC BA; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; JOHNSON NL, 1977, STAT EXPT DESIGN ENG, P614; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; VANCAMPENHOUT JM, 1980, J AM STAT ASSOC, V75, P104	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67946-4	LECT NOTES COMPUT SC			2000	1876						696	705				10	Computer Science, Theory & Methods	Computer Science	BS80F	WOS:000171155700072	
S	Pierson, WE; Ross, T		Zelnio, EG		Pierson, WE; Ross, T			Automatic target recognition (ATR) evaluation theory: a survey	ALGORITHMS FOR SYNTHETIC APERTURE RADAR IMAGERY VII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Algorithms for Synthetic Aperture Radar Imagery VII	APR 24-28, 2000	ORLANDO, FL	SPIE		automatic target recognition; performance estimation; statistical pattern recognition		Proper evaluation of a pattern recognition system in the lab is paramount to its success in the field. In most commercial pattern recognition applications, such as breast cancer detection, optical character recognition, and industrial quality assurance, the boundaries and expectation of the system are well defined. This is due, at least in part, to an excellent understanding of the problem and data space for these applications. For these functions, a method for rigorous evaluation is well understood. However, the size and complexity of the data and problem spaces for automatic target recognition (ATR) systems is enormous. The consequences are that a complete understanding of how an ATR system will perform in practice is extraordinarily difficult to estimate. Thus the act of evaluating an ATR system becomes as important as its design. This paper compiles and reports the techniques used to evaluate ATR system performance. It surveys the specific difficulties associated with ATR performance estimation as well as approaches used to mitigate these obstacles.	USAF, Res Lab, Wright Patterson AFB, OH 45433 USA	Pierson, WE (reprint author), USAF, Res Lab, 2241 Avion Circle, Wright Patterson AFB, OH 45433 USA.						BAYES T, 1764, PHIL T, P370; BHATTACH.CG, 1967, BIOMETRICS, V23, P115, DOI 10.2307/2528285; CHERNOFF H, 1966, ANN I STAT MATH, V18, P179; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CHOW CK, 1957, IRE T ELECT COMP DEC, P41; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DALE AI, 1981, ARCH HIST EXACT SCI, P23; David F.N., 1962, GAMES GODS GAMBLING; Devroye L, 1996, PROBABILISTIC THEORY; Devroye L.A, 1987, COURSE DENSITY ESTIM; Efron B., 1993, INTRO BOOTSTRAP; FIX E, 1949, 2149004 USAF SCH AV; Fu K, 1986, HDB PATTERN RECOGNIT; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1972, IEEE T INFORMATI NOV, P814; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P608, DOI 10.1109/34.601248; Hacking Ian, 1975, EMERGENCE PROBABILIT; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; KHALFA J, 1994, WHAT IS INTELLIGENCE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pierson W., 1998, THESIS OHIO STATE U; RISSANEN J, 1978, AUTOMATICA, V14, P456; TODHHUNTER I, 1965, HIST MATH THEORY PRO; Vapnik V.N., 1995, NATURE STAT LEARNING	25	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-3679-8	P SOC PHOTO-OPT INS			2000	4053						666	676				3	Mathematics, Applied; Optics; Telecommunications	Mathematics; Optics; Telecommunications	BQ82J	WOS:000089706700064	
B	Juell, P; Marsh, R		Arabnia, HR		Juell, P; Marsh, R			Improved scale and rotation invariant correlation using block-median filtering	CISST'2000: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, VOLS I AND II			English	Proceedings Paper	International Conference on Imaging Science, Systems, and Technology (CISST 2000)	JUN 26-29, 2000	LAS VEGAS, NV	Comp Sci, Res, Educ & Applicat Press, Int Technol Inst, Korea Informat Processing Soc, PDPTA, World Sci & Engn Soc		optical correlation; matched filters; pattern recognition	CIRCULAR HARMONIC EXPANSION; FOURIER-MELLIN DESCRIPTORS; PATTERN-RECOGNITION; NEURAL NETWORKS; TRANSFORMS	An involvement on the scale and rotation tolerant correlation method first proposed by Casesent and Psaltis[1] is presented. In computer simulations, using a target set of 26 scaled and rotated objects (1820 images total), the system accurately identified the targets with 93.6% accuracy. We preprocess the target and reference images with a centering algorithm, a log-polar transform, a modified median filter and a Laplace edge-extracting filter. The resulting image data, when correlated using a typical 4-f correlator, exhibits good scale and rotation tolerance.	N Dakota State Univ, Dept Comp Sci & Operat Res, Fargo, ND 58105 USA	Juell, P (reprint author), N Dakota State Univ, Dept Comp Sci & Operat Res, Fargo, ND 58105 USA.						AGUI T, 1991, SPIE, V1606, P188; Altmann J., 1987, Journal of Information Processing and Cybernetics, V23; APICELLA A, 1989, P SOC PHOTO-OPT INS, V1092, P252; BROUSIL JK, 1967, IEEE TRANS ELECTRON, VEC16, P818, DOI 10.1109/PGEC.1967.264726; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CASASENT D, 1976, OPT COMMUN, V19, P217, DOI 10.1016/0030-4018(76)90346-1; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; COTTRELL DM, 1987, APPL OPTICS, V26, P3755, DOI 10.1364/AO.26.003755; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta B, 1996, J I EL TELECOM ENG, V42, P3; Goodman J. W., 1968, INTRO FOURIER OPTICS; GRACE AE, 1991, PATTERN RECOGN LETT, V12, P635, DOI 10.1016/0167-8655(91)90018-H; HORNER JL, 1984, APPL OPTICS, V23, P812; HSU YN, 1982, APPL OPTICS, V21, P4016, DOI 10.1364/AO.21.004016; HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012; KUMAR BVKV, 1992, APPL OPTICS, V31, P4773, DOI 10.1364/AO.31.004773; MEHANIAN C, 1991, SPIE, V1471, P200; MINNIX JI, 1991, IMAGE PROCESSING, V1606, P241; Pratt WK, 1978, DIGITAL IMAGE PROCES, P526; Schalkoff RJ, 1989, DIGITAL IMAGE PROCES, P279; SHENG Y, 1986, J OPT SOC AM A, V3, P771, DOI 10.1364/JOSAA.3.000771; SHENG YL, 1991, J OPT, V22, P223, DOI 10.1088/0150-536X/22/5/003; THORNTON AL, 1997, 6 INT C IM PROC ITS; TITCHMARSH EC, 1959, INTRO THEORY FOURIER; VANDERLUGT AB, 1964, IEEE T INFORM THEORY, V10, P2; WHALEN AD, 1971, DETECTION SIGNALS NO, P167; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0	27	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA		1-892512-55-6				2000							207	213				7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BR81Y	WOS:000167666100031	
S	Sbihi, A; Moussa, A; Benmiloud, B; Postaire, JG		Kiers, HAL; Rasson, JP; Gronen, PJF; Schader, M		Sbihi, A; Moussa, A; Benmiloud, B; Postaire, JG			A Markovian approach to unsupervised multidimensional pattern classification	DATA ANALYSIS, CLASSIFICATION, AND RELATED METHODS	STUDIES IN CLASSIFICATION, DATA ANALYSIS, AND KNOWLEDGE ORGANIZATION		English	Proceedings Paper	7th Conference of the International-Federation-of-Classification-Societies	JUL 11-14, 2000	NAMUR, BELGIUM	Int Federat Classificat Soc	UNIV NAMUR			This paper proposes a new method for core cluster detection prior to unsupervised automatic classification. Based upon a Markov random field model, this approach transforms the set of multidimensional observations into a normalised discret binary set, which represents the observable field. The field of classes is then represented by connex components corresponding to the cores, or prototypes, inside the samples. Classification results of artificially generated data are compared with results obtained by a classical clustering method.	Univ Ibn Tofail, FSK, Lab Image & Reconnaissance Formes, Kenitra, Morocco							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGN, P448; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; POSTAIRE JG, 1983, IEEE T PATTERN ANAL, V4, P663; SBIHI A, 1995, DATA KNOWLEDGE THEOR, P212; VASSEUR CPA, 1980, IEEE T SYST MAN CYB, V10, P145	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1431-8814	3-540-67521-3	ST CLASS DAT ANAL			2000							247	252				6	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	BR45N	WOS:000166471700040	
S	Domeniconi, C; Peng, J; Gunopulos, D			IEEE; IEEE; IEEE	Domeniconi, C; Peng, J; Gunopulos, D			Adaptive metric nearest neighbor classification	IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, VOL I	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2000)	JUN 13-15, 2000	HILTON HEAD ISL, SC	IEEE Comp Soc, IEEE Comp Soc, Tech Comm Pattern Anal & Machine Intelligence				Nearest neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a local adaptive nearest neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for producing neighborhoods that are highly adaptive to query locations. Neighborhoods are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the modified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using a variety of simulated and real world data.	Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA	Domeniconi, C (reprint author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.						Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Ho T.K., 1998, LECT NOTES COMPUTER, P640; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; MCLACHLAN GJ, 1992, DISCRIMIANT ANAL STA; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN	12	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919	0-7695-0662-3	PROC CVPR IEEE			2000							517	522				6	Computer Science, Artificial Intelligence	Computer Science	BQ57F	WOS:000088804500073	
S	Trappenberg, TP; Back, AD		Amari, SI; Giles, CL; Gori, M; Piuri, V		Trappenberg, TP; Back, AD			A classification scheme for applications with ambiguous data	IJCNN 2000: PROCEEDINGS OF THE IEEE-INNS-ENNS INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOL VI	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE/INNS/ENNS International Joint Conference on Neural Networks (IJCNN 2000)	JUL 24-27, 2000	COMO, ITALY	IEEE Neural Network Council, Int Neural Network Soc, European Neural Network Soc		data classification; ambiguous data; probabilistic ANN; k-NN algorithm		We propose a scheme for pattern classifications in applications which include ambiguous data, that is, where pattern occupy overlapping areas in the feature space. Such situations frequently occur with noisy data and/or where some features are unknown. We demonstrate that it is advantageous to first detect those ambiguous areas with the help of training data and then to re-classify those data in these areas as ambiguous before making class predictions on rest sets. This scheme is demonstrated with a simple example and benchmarked on two real world applications.	Univ Oxford, Dept Psychol, Ctr Cognit Neurosci, Oxford OX1 3UD, England	Trappenberg, TP (reprint author), Univ Oxford, Dept Psychol, Ctr Cognit Neurosci, Oxford OX1 3UD, England.						AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUCH W, 1999, IN PRESS INT J ADV C; Duda R., 1973, PATTERN CLASSIFICATI; Fischer RA, 1936, ANN EUGEN, V7, P179; Friedman J.H., 1984, CLASSIFICATION REGRE; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; HANSON R, 1991, P 12 INT JOINT C ART, P692; Mangasarian O. L., 1990, SIAM NEWS, V23; MERTZ CJ, UCI REPOSITORY MACHI; Michie D, 1994, MACHINE LEARNING NEU; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Tsoi A. C., 1991, ADV NEURAL INFORMATI, V3, P963; VAPNIK V, 1997, ADV NEURAL INFORMATI, V9; Vapnik V.N., 1995, NATURE STAT LEARNING	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1098-7576		IEEE IJCNN			2000							296	301				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BQ71L	WOS:000089240600049	
J	Sarkar, M; Leong, TY				Sarkar, M; Leong, TY			Application of K-nearest neighbors algorithm on breast cancer diagnosis problem	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Proceedings Paper	Annual Symposium of the American-Medical-Informatics-Association	NOV 04-08, 2000	LOS ANGELES, CALIFORNIA	Amer Med Informat Assoc				This paper addresses the Breast Cancer diagnosis problem as a pattern classification problem. Specifically, this problem is studied using the Wisconsin-Madison Breast Cancer data set. The Knearest neighbors algorithm is employed as the classifier. Conceptually and implementation-wise, the Knearest neighbors algorithm is simpler than the other techniques that have been applied to this problem. In addition, the Knearest neighbors algorithm produces the overall classification result 1.17% better than the best result known for this problem.	Natl Univ Singapore, Sch Comp, Dept Comp Sci, Med Comp Lab, Singapore 119260, Singapore	Sarkar, M (reprint author), Natl Univ Singapore, Sch Comp, Dept Comp Sci, Med Comp Lab, Lower Kent Ridge Rd, Singapore 119260, Singapore.						BLAKE CL, 1998, UCI RESP MACHINE LEA; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1979, PATTERN CLASSIFICATI; FIX E, 1953, DISCRIMINATORY ANAL; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; KELLER JM, 1985, IEEE T PATTERN ANAL, V7, P693; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Mico L, 1998, PATTERN RECOGN LETT, V19, P351, DOI 10.1016/S0167-8655(98)00007-5; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Pena Reyes C. A., 1999, ARTIF INTELL, V17, P131, DOI 0.1.1.21.7030; SETANIO R, 1996, ARTIF INTELL, V8, P37; SETANIO R, 2000, ARTIF INTELL, V18, P205; TAHA I, 1997, P IEEE INT C NEUR NE, P221; TAHA I, 1996, TR9701106 U TEX COMP; TAHA I, 1996, UTCVISSTR97007 COMP	16	0	0	HANLEY & BELFUS INC	PHILADELPHIA	210 S 13TH ST, PHILADELPHIA, PA 19107 USA	1067-5027		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.		2000				S			759	763				5	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science; Medical Informatics	Computer Science; Information Science & Library Science; Medical Informatics	458RC	WOS:000170207500155	
B	Mitani, Y; Hirayama, H; Yasuda, H; Kido, S; Hamamoto, Y; Ueda, K; Matsunaga, N		Howlett, RJ; Jain, LC		Mitani, Y; Hirayama, H; Yasuda, H; Kido, S; Hamamoto, Y; Ueda, K; Matsunaga, N			A Gabor filter-based classification for diffuse lung opacities in thin-section computed tomography images	KES'2000: FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ENGINEERING SYSTEMS & ALLIED TECHNOLOGIES, VOLS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Knowledge-Based Intelligent Engineering Systems and Allied Technologies	AUG 30-31, 2000	BRIGHTON, ENGLAND	IEE, IEEE	UNIV BRIGHTON			The classification of diffuse lung opacities in thin-section computed tomography(HRCT) images is an important step of developing a computer-aided diagnosis(CAD) system. In this paper, we have evaluated the performance of a Gabor filter-based classification of typical diffuse lung opacities in HRCT images. The experimental results show that the Gabor filter-based approach is one of effective means for classifying diffuse lung diseases.	Yamaguchi Jr Coll, Hofu 7471232, Japan	Mitani, Y (reprint author), Yamaguchi Jr Coll, Hofu 7471232, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Fukunaga K., 1990, INTRO STAT PATTERN R; Gabor D., 1946, Journal of the Institution of Electrical Engineers. III. Radio and Communication Engineering, V93; Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314	7	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-6400-7				2000							780	783				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BR39B	WOS:000166277600178	
J	Li, JY; Dong, GZ; Ramamohanarao, K				Li, Jinyan; Dong, Guozhu; Ramamohanarao, Kotagiri			Instance-Based Classification by Emerging Patterns	LECTURE NOTES IN COMPUTER SCIENCE <D>			English	Article								Emerging patterns (EPs), namely itemsets whose supports change significantly from one class to another, capture discriminating features that sharply contrast instances between the classes. Recently, EP-based classifiers have been proposed, which first mine as many EPs as possible (called eager-learning) from the training data and then aggregate the discriminating power of the mined EPs for classifying new instances. We propose here a new, instance-based classifier using EPs, called DeEPs, to achieve much better accuracy and efficiency than the previously proposed EP-based classifiers. High accuracy is achieved because the instance-based approach enables DeEPs to pinpoint all EPs relevant to a test instance, some of which are missed by the eager-learning approaches. High efficiency is obtained using a series of data reduction and concise data-representation techniques. Experiments show that DeEPs' decision time is linearly scalable over the number of training instances and nearly linearly over the number of attributes. Experiments on 40 datasets also show that DeEPs is superior to other classifiers on accuracy.	[Li, Jinyan; Ramamohanarao, Kotagiri] Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia; [Dong, Guozhu] Wright State Univ, Dept CSE, Dayton, OH 45435 USA	Li, JY (reprint author), Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia.	jyli@cs.mu.oz.au; gdong@cs.wright.edu; rao@cs.mu.oz.au					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEITEL HM, 1998, C PROGRAM; Dong G., 1999, P 2 INT C DISC SCI, P30; Duda R., 1973, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; LI J, 2000, DEEPS INSTANCE BASED; LI J, 2000, P 17 INT C MACH LEAR; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li J, 2000, P 4 PAC AS C KNOWL D, P220; Liu B., 1998, P 4 INT C KNOWL DISC; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN	15	4	4	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0302-9743		LECT NOTES COMPUT<D>	Lect. Notes Comput. Sci.		2000	1910						191	200				10	Computer Science, Theory & Methods	Computer Science	V12XW	WOS:000207632900020	
J	Grosser, D; Diatta, J; Conruyt, N				Grosser, David; Diatta, Jean; Conruyt, Noel			Improving Dissimilarity Functions with Domain Knowledge, applications with IKBS system	LECTURE NOTES IN COMPUTER SCIENCE <D>			English	Article						KDD; Domain Knowledge; Dissimilarity Functions; Generalization Accuracy		Some of the fundamental and theoretical issues in Knowledge Discovery in Database (KDD) rely on knowledge representation and the use of prior and domain knowledge to extract useful information from data. In many data exploration algorithms, dissimilarity functions do not use domain knowledge for the cases comparison. The Iterative Knowledge Base System (IKBS) has been designed to improve generalization accuracy of exploration algorithms through the use of structural properties of domain models. A general mathematical framework for utilizing structural properties of the domain model encompassing the definition of a Dissimilarity Function for Structured Descriptions is proposed. Applications are conducted with the help of IKBS on a set of databases from the UCI machine learning repository and on structured domain definition data.	[Grosser, David; Diatta, Jean; Conruyt, Noel] Univ Reunion, IREMIA, F-97715 St Denis Messag 9, France	Grosser, D (reprint author), Univ Reunion, IREMIA, 15 Ave Rene Cassin,BP 7151, F-97715 St Denis Messag 9, France.	grosser@univ-reunion.fr; jdiatta@univ-reunion.fr; conruyt@univ-reunion.fr					Conruyt N, 1999, LECT NOTES ARTIF INT, V1650, P401; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIATTA J, 1999, INF 01 IREMIA U REUN; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Klosgen W., 1996, ADV KNOWLEDGE DISCOV; MERZ, 1996, UCI REPOSITORY MACHI; RANDALL WD, 1997, J ARTIFICIAL INTELLI, V6, P1; SCHAFFER, 1994, P ML 94	8	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0302-9743		LECT NOTES COMPUT<D>	Lect. Notes Comput. Sci.		2000	1910						409	415				7	Computer Science, Theory & Methods	Computer Science	V12XW	WOS:000207632900045	
S	Latourrette, M		LaopezDeMantaras, R; Plaza, E		Latourrette, M			Toward an explanatory similarity measure for nearest-neighbor classification	MACHINE LEARNING: ECML 2000	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	11th European Conference on Machine Learning	MAY 31-JUN 02, 2000	BARCELONA, SPAIN	European Network Excellence Machine Learn, CSIC, Spanish Sci & Technol Council, Catalan Assoc Artifical Intell, Inst Invest Intell Artif				In this paper, a new similarity measure for nearest-neighbor classification is introduced. This measure is an approximation of a theoretical similarity that has some interesting properties. In particular, this latter is a step toward a theory of concepts formation. It renders identical some examples that have distinct representations. Moreover, these examples share some properties relevant for the concept undertaken. Hence, a rule-based representation of the concept can be inferred from the theoretical similarity. Moreover, in this paper, the approximation is validated by some preliminary experiments on non-noisy datasets.	Univ Montpellier 2, CNRS, UMR 5506, Lab Informat Robot & Microelect Montpellier, F-34392 Montpellier, France	Latourrette, M (reprint author), Univ Montpellier 2, CNRS, UMR 5506, Lab Informat Robot & Microelect Montpellier, 161 Rue Ada, F-34392 Montpellier, France.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BIDERMAN Y, 1994, LECT NOTE AI ECML 94; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LACHICHE N, 1998, LNAI, V1398, P268; Salzberg S.L., 1990, LEARNING NESTED GEN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-67602-3	LECT NOTES ARTIF INT			2000	1810						238	245				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BR57W	WOS:000166853300025	
J	Lienhart, R; Effelsberg, W				Lienhart, R; Effelsberg, W			Automatic text segmentation and text recognition for video indexing	MULTIMEDIA SYSTEMS			English	Article						video processing; character segmentation; text recognition; OCR; video indexing; video content analysis	IMAGES	Efficient indexing and retrieval of digital video is an important function of video databases. One powerful index for retrieval is the text appearing in them. It enables content-based browsing. We present our new methods for automatic segmentation of text in digital videos. The algorithms we propose make use of typical characteristics of text in videos in order to enable and enhance segmentation performance. The unique features of our approach are the tracking of characters and words over their complete duration of occurrence in a video and the integration of the multiple bitmaps of a character over time into a single bitmap. The output of the text segmentation step is then directly passed to a standard OCR software package in order to translate the segmented text into ASCII. Also, a straightforward indexing and retrieval scheme is introduced. It is used in the experiments to demonstrate that the proposed text segmentation algorithms together with existing text recognition algorithms are suitable for indexing and retrieval of relevant video sequences in and from a video database. Our experimental results are very encouraging and suggest that these algorithms can be used in video retrieval applications as well as to recognize higher level semantics in videos.	Intel Corp, Microprocessor Res Labs, Santa Clara, CA 95052 USA; Univ Mannheim, D-68131 Mannheim, Germany	Lienhart, R (reprint author), Intel Corp, Microprocessor Res Labs, Santa Clara, CA 95052 USA.						Canny J., 1986, PAMI, V8, P679; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS M, 1994, P ACM MULT 15 20 OCT, P478, DOI 10.1145/192593.197412; Flichner M, 1995, IEEE COMPUT, V9, P23; Gong Y., 1995, P INT C MULT COMP SY, P167; HJELSVOLD R, 1995, P ACM MULTIMIDEA, P283, DOI 10.1145/217279.215282; HOROWITZ SL, 1972, COMPUT GRAPHICS IMAG, V1, P360; JAHNE B., 1995, DIGITAL IMAGE PROCES; Jahne B., 1997, PRACTICAL HDB IMAGE; Jain A. K., 1992, Machine Vision and Applications, V5, DOI 10.1007/BF02626996; Lienhart R, 1996, P SOC PHOTO-OPT INS, V2666, P180, DOI 10.1117/12.234741; Lienhart R., 1997, COMMUN ACM, V40, P55; LIENHART R, 1998, THESIS U MANNHEIM MA; Lienhart R., 1996, Proceedings ACM Multimedia 96, DOI 10.1145/244130.244137; LINDBLAD CJ, 1995, IEEE J SEL AREA COMM, V13, P768; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; OHYA J, 1994, IEEE T PATTERN ANAL, V16, P214, DOI 10.1109/34.273729; POYNTON CA, 1995, TECHNICAL INTRO DIGI; SALTON G, 1983, INTRO MODERN INFORMA; Sato T, 1998, IEEE INT WORKSH CONT, P52; SMITH JR, 1987, VISUAL SEEK FULLY AU; Smith M. A., 1995, CMUCS95186; Stephen G.A., 1994, STRING SEARCHING ALG; Takatoo M., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9); Wu V., 1997, P 2 ACM INT C DIG LI, P23; YEO BL, 1996, P SOC PHOTO-OPT INS, P38; Zhang H. J., 1995, P ACM MULT 95 SAN FR, P15, DOI 10.1145/217279.215068; ZHANG HJ, 1994, P INT C MULT COMP SY, P45; ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, DOI 10.1016/S0146-664X(76)80014-7	30	46	58	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	0942-4962		MULTIMEDIA SYST	Multimedia Syst.	JAN	2000	8	1					69	81		10.1007/s005300050006		13	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	279XD	WOS:000085069600006	
J	Dasarathy, BV; Sanchez, JS; Townsend, S				Dasarathy, BV; Sanchez, JS; Townsend, S			Nearest neighbour editing and condensing tools-synergy exploitation	PATTERN ANALYSIS AND APPLICATIONS			English	Article						editing and condensing tools; nearest neighbour; synergy exploitation	GRAPHS; RULE	The objective of this study has been to explore and exploit the synergy among the Nearest Neighbour (NN) editing and condensing tools previously reported in the literature in order to facilitate the use of NN techniques in near real-time applications. The extraordinary progress in the computer field has made NN techniques, once considered impractical from a computational viewpoint, feasible for consideration in rime-constrained, real-world applications. This study accordingly addresses the issue of minimising the computational resource requirements of NN techniques, memory as well as time, through the: use of prototype reduction techniques such as Minimal Consistent Sec (;MCS) selection while preserving the performance quality through suitable editing techniques, such as Proximity Graphs (PG). The tools employed in this investigation are first described briefly. Results of experiments conducted on well known data sets in the literature with various combinations of editing and condensing tools are then presented and discussed to assess the benefits of synergy among these tools. These results demonstrate the: potential benefits of such synergy, and highlight the desirability of a more thorough exploration of combinations of other alternative editing and condensing tools that have been reported in the literature over the past few decades.	Dynet Inc, Huntsville, AL 35814 USA; Univ Jaume 1, Dept Informat, Castello, Spain	Dasarathy, BV (reprint author), Dynet Inc, POB 5500, Huntsville, AL 35814 USA.						ALINAT P, 1993, 4 ROARS ESPRIT; BRODER AZ, 1985, IEEE T SYST MAN CYB, V15, P136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Toussaint G. T., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	18	31	31	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.		2000	3	1					19	30		10.1007/s100440050003		12	Computer Science, Artificial Intelligence	Computer Science	300FH	WOS:000086242100002	
B	Frosini, G; Lazzerini, B; Marcelloni, F		Whalen, T		Frosini, G; Lazzerini, B; Marcelloni, F			A modified fuzzy C-means algorithm for feature selection	PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS			English	Proceedings Paper	19th International Conference of the North-American-Fuzzy-Information-Processing-Society	JUL 13-15, 2000	ATLANTA, GA	N Amer Fuzzy Informat Proc Soc				In this paper we propose a novel method for feature selection based on a modified fuzzy C-means algorithm with supervision (MFCMS). MFCMS adopts an appropriately modified version of the objective function used by the classic fuzzy C-means. We applied MFCMS to some real-world pattern classification benchmarks. To test the effectiveness of MFCMS as feature selector, we used the well-known k-nearest neighbor as learning algorithm. In our experiments we found that the classification performance using the set of features selected by MFCMS is better than that using all the original features. Furthermore, our approach proved to be less time-consuming than other feature selection methods.	Univ Pisa, Dipartimento Ingn Informaz, I-56126 Pisa, Italy	Frosini, G (reprint author), Univ Pisa, Dipartimento Ingn Informaz, Via Diotisalvi 2, I-56126 Pisa, Italy.						Ball G. H., 1965, ISODATA NOVEL METHOD; Bezdek J., 1981, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GUSTAFSON DE, 1979, ADV FUZZY SET THEORY, P605; PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6; Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232; RICHELDI M, 1996, P 2 INT C KNOWL DISC, P379; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YANG V, 1998, FEATURE EXTRACTION C	12	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-6274-8				2000							148	152		10.1109/NAFIPS.2000.877409		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BQ89L	WOS:000089942800028	
B	Bao, YG; Du, XY; Ishii, N		Lu, H; Spaccapietra, S; Kambayashi, Y; Wang, S		Bao, YG; Du, XY; Ishii, N			Improving performance of the k-nearest neighbor classifier by tolerant rough sets	PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM ON COOPERATIVE DATABASE SYSTEMS FOR ADVANCED APPLICATIONS			English	Proceedings Paper	3rd International Symposium on Cooperative Database Systems for Advanced Applications (CODAS 2001)	APR 23-24, 2001	BEIJING, PEOPLES R CHINA	Natl Nat Sci Fdn China, China CompWorld, Kyoto Univ, K C Wong Educ Fdn, Renim Univ China, Database Soc China Comp Federat				In this paper, we report our efforts in improving the performance of the k-nearest neighbor classification by introducing the tolerant rough set. We relate the tolerant rough relation with object similarity. Two objects are called similar if and only if these two objects satisfy the requirements of the tolerant rough relation. Hence, the tolerant rough set is used to select objects from the training data and constructing the similarity function. The GA algorithm is used for seeking the optimal similarity metrics. Experiments have been conducted on some artificial and real world data, the results show that our algorithm can improve the performance of the k-nearest neighbor classification, and get the higher accuracy compared with the C4.5 system.	Nagoya Inst Technol, Dept Intelligence & Comp Sci, Showa Ku, Nagoya, Aichi 4668555, Japan	Bao, YG (reprint author), Nagoya Inst Technol, Dept Intelligence & Comp Sci, Showa Ku, Nagoya, Aichi 4668555, Japan.						BAO YG, 6 INT C SOFT COMP II, P452; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Guvenir H.A, 1997, P 12 INT S COMP INF, P44; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; KRETOWSKI M, 1995, 54 ICS WARS U TECHN; LIN TY, 1996, IMASACS MULT C LILL, P1095; Liu H., 1998, FEATURE SELECTION KN; Mitchell M, 1996, INTRO GENETIC ALGORI; NEJMAN D, 1994, 18 ICS WARS U TECHN; OHAVI K, 1996, DATA MINING USING ML, P234; Pawlak Z, 1991, ROUGH SETS; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; WANG Y, 1998, INT J ART INT TOOLS, V7, P31, DOI 10.1142/S0218213098000032; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yao YY, 2000, P SOC PHOTO-OPT INS, V4057, P108, DOI 10.1117/12.381723	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-1128-7				2000							167	171				5	Computer Science, Information Systems	Computer Science	BS91N	WOS:000171369700020	
B	Ting, KM; Zheng, ZJ; Webb, G		Bramer, M; Macintosh, A; Coenen, F		Ting, KM; Zheng, ZJ; Webb, G			Learning Lazy Rules to improve the performance of classifiers	RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XVI	B C S CONFERENCE SERIES		English	Proceedings Paper	19th SGES International Conference on Knowledge-Based Systems and Applied Artificial Intelligence (ES99)	DEC 13-15, 1999	CAMBRIDGE, ENGLAND	SGES, Appl AI				Based on an earlier study on lazy Bayesian rule learning, this paper introduces a general lazy learning framework, called LAZYRULE, that begins to learn a rule only when classifying a test case. The objective of the framework is to improve the performance of a base learning algorithm. It has the potential to be used for different types of base learning algorithms. LAZYRULE performs attribute elimination and training case selection using cross-validation to generate the most appropriate rule for each test case. At the consequent of the rule, it applies the base learning algorithm on the selected training subset and the remaining attributes to construct a classifier to make a prediction. This combined action seeks to build a better performing classifier for each test case than the classifier trained using all attributes and all training cases. We show empirically that LAZYRULE improves the performances of naive Bayesian classifiers and majority vote.	Deakin Univ, Sch COmp & Math, Geelong, Vic 3217, Australia	Ting, KM (reprint author), Deakin Univ, Sch COmp & Math, Geelong, Vic 3217, Australia.						Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Cestnik B., 1990, P EUR C ART INT, P147; CHATFIELD C, 1978, STAT TECHNOLOGY COUR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; FULTON T, 1996, P 2 INT C KNOWL DISC, P14; Iba W., 1992, P 10 NAT C ART INT, P223; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kononenko I., 1990, CURRENT TRENDS KNOWL; Langley P., 1994, P 10 C UNC ART INT, P339; THOMPSON MD, 1992, PLANT MOL BIOL, V18, P931, DOI 10.1007/BF00019207; VISWANATHAN M, 1998, P 10 EUR C MACH LEAR, P149; ZHENG Z, IN PRESS MACHINE LEA; ZHENG Z, 1999, P 16 INT C MACH LEAR, P493	21	0	0	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND		1-85233-231-X	BCS CONF SERIES			2000							122	131				10	Computer Science, Artificial Intelligence	Computer Science	BP82R	WOS:000086321700008	
S	Paredes, R; Vidal, E		Sanfeliu, A; Villanueva, JJ; Vanrell, M; Alquezar, R; Jain, AK; Kittler, J		Paredes, R; Vidal, E			Weighting prototypes. A new editing approach.	15TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2, PROCEEDINGS: PATTERN RECOGNITION AND NEURAL NETWORKS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	15th International Conference on Pattern Recognition (ICPR-2000)	SEP 03-07, 2000	BARCELONA, SPAIN	Int Assoc Pattern Recognit, Assoc Pattern Recognit & Image Anal, Ctr Visio Comp, Univ Autonoma Barcelona, Univ Politecn Catalunya, Comissionat Universitats Recerca, Generalitat Catalunya Dept Presidencia, Minist Ciencia Tecnol, Fdn Catalana Recerca, HP Invent		editing; condensing; nearest neighbour; classification; weighted prototypes; gradient descent		It is well known that editing techniques can be applied to (large) sets of prototypes in order to bring the error rate of the Nearest Neighbour classifier close to the optimal Bayes risk. However, in practice, the behaviour of these techniques uses to be much worse than expected from the asymptotic predictions. A novel editing technique is introduced here which explicitly aims at obtaining a good editing rule for each given prototype set. This is achieved by first learning an adequate assignment of a weight to each prototype and then pruning out those prototypes having large weights. Experiments are presented which clearly show the superiority of this new method, specially for small data sets and/or large dimensions.	Univ Politecn Valencia, Inst Informat Technol, E-46071 Valencia, Spain	Paredes, R (reprint author), Univ Politecn Valencia, Inst Informat Technol, E-46071 Valencia, Spain.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE G, 1995, PROBABILISTIC THEORY; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; PAREDES R, 1999, 8 S NAC REC FORM AN, V1, P437; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-0751-4	INT C PATT RECOG			2000							25	28				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BR56P	WOS:000166814800006	
S	Mitani, Y; Hamamoto, Y		Sanfeliu, A; Villanueva, JJ; Vanrell, M; Alquezar, R; Jain, AK; Kittler, J		Mitani, Y; Hamamoto, Y			Classifier design based on the use of nearest neighbor samples	15TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2, PROCEEDINGS: PATTERN RECOGNITION AND NEURAL NETWORKS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	15th International Conference on Pattern Recognition (ICPR-2000)	SEP 03-07, 2000	BARCELONA, SPAIN	Int Assoc Pattern Recognit, Assoc Pattern Recognit & Image Anal, Ctr Visio Comp, Univ Autonoma Barcelona, Univ Politecn Catalunya, Comissionat Universitats Recerca, Generalitat Catalunya Dept Presidencia, Minist Ciencia Tecnol, Fdn Catalana Recerca, HP Invent				A considerable amount of effort has been devoted to design a classifier in small training sample size situations. In this paper, we propose to design a nonparametric classifier based on the use of nearest neighbor samples. In the experiments, both the artificial and real data sets were used. The proposed classifier is compared with the 1-NN, k-NN, and Euclidcan distance classifiers in terms of the error rate, in small training sample size situations. Experimental results show that the proposed classifier is very effective, even in practical situations.	Yamaguchi Jr Coll, Hofu 7471232, Japan	Mitani, Y (reprint author), Yamaguchi Jr Coll, Hofu 7471232, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBOUR NO; Devijver P. A., 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5; Jain A., 1988, ALGORITHMS CLUSTERIN; MARILL T, 1963, IEEE T INFORM THEORY, V9, P11, DOI 10.1109/TIT.1963.1057810; OKAMOTO S, 1998, THESIS U KYUSHU; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Yamamoto K, 1996, IEICE T INF SYST, VE79D, P417	13	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-0751-4	INT C PATT RECOG			2000							769	772				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BR56P	WOS:000166814800181	
S	Kangas, J		Sanfeliu, A; Villanueva, JJ; Vanrell, M; Alquezar, R; Jain, AK; Kittler, J		Kangas, J			Comparison between two prototype representation schemes for a nearest neighbor classifier	15TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2, PROCEEDINGS: PATTERN RECOGNITION AND NEURAL NETWORKS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	15th International Conference on Pattern Recognition (ICPR-2000)	SEP 03-07, 2000	BARCELONA, SPAIN	Int Assoc Pattern Recognit, Assoc Pattern Recognit & Image Anal, Ctr Visio Comp, Univ Autonoma Barcelona, Univ Politecn Catalunya, Comissionat Universitats Recerca, Generalitat Catalunya Dept Presidencia, Minist Ciencia Tecnol, Fdn Catalana Recerca, HP Invent				The paper is about the problem of finding good prototypes for a condensed nearest neighbor classifier in a recognition system. A comparison study is done between two prototype representation schemes. The prototype search is done by a genetic algorithm which is able to generate novel prototypes (i.e. prototypes which are not among the training samples). It is shown that the generalized representation scheme is more powerful, giving significantly larger normalized interclass distances. It is also shown that both representation schemes with genetic algorithm give significantly better prototypes than a direct prototype selection algorithm, which can select only among the training samples.	Nokia China R&D Ctr, Beijing 100013, Peoples R China	Kangas, J (reprint author), Nokia China R&D Ctr, 11 He Ping Li Dong Jie, Beijing 100013, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBOUR NN; FIX E, 1951, 4 USAF SCH AVI; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kangas J., 1999, Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300), DOI 10.1109/ICCIMA.1999.798513; MICHALEWICZ Z, 1996, GENETIC ALGORITHMS P; Mitchell M, 1996, INTRO GENETIC ALGORI; Ripley B. D., 1996, PATTERN RECOGNITION; Sankoff D., 1983, TIME WARPS STRING ED; YUEN H, 1996, P INT C AC SPEECH SI, V6, P3426	11	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-0751-4	INT C PATT RECOG			2000							773	776				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BR56P	WOS:000166814800182	
S	Riba, JR; Carnicer, A; Vallmitjana, S; Juvells, I		Sanfeliu, A; Villanueva, JJ; Vanrell, M; Alquezar, R; Jain, AK; Kittler, J		Riba, JR; Carnicer, A; Vallmitjana, S; Juvells, I			Methods for invariant signature classification	15TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2, PROCEEDINGS: PATTERN RECOGNITION AND NEURAL NETWORKS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	15th International Conference on Pattern Recognition (ICPR-2000)	SEP 03-07, 2000	BARCELONA, SPAIN	Int Assoc Pattern Recognit, Assoc Pattern Recognit & Image Anal, Ctr Visio Comp, Univ Autonoma Barcelona, Univ Politecn Catalunya, Comissionat Universitats Recerca, Generalitat Catalunya Dept Presidencia, Minist Ciencia Tecnol, Fdn Catalana Recerca, HP Invent				In this communication we present a comparison of several statistical methods to carry out an automatic recognition of signatures. To perform the method we have used 6 subjects and the calibration set is composed of 50 signatures for each class. The recognition process consists on the computation of 48 features for each image of the calibration set. Second, a feature extraction process, based in canonical variables analysis, is carried out in order to reduce the number of variables to be used. Finally, the classification process is performed by using different statistical methods: PCR, PLS, LDA, SIMCA, DASCO, and others. Results obtained show that incorrect signature detection errors are less than 3 % in all the techniques considered. However, by using LDA (linear discriminant analysis) the total error is less than 0.2 %. Moreover, the use of LDA is suggested due to the speed of the algorithm. These results prove the utility of this technique for signature automatic recognition.	Univ Politecn Catalunya, EUETI Ingualada, E-08700 Igualada, Barcelona, Spain	Riba, JR (reprint author), Univ Politecn Catalunya, EUETI Ingualada, Placa Rei 15, E-08700 Igualada, Barcelona, Spain.		Carnicer, Artur/B-1442-2013				Bajaj R, 1997, PATTERN RECOGN, V30, P1, DOI 10.1016/S0031-3203(96)00059-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN RECOGNITION; FRANK I E, 1989, Journal of Chemometrics, V3, P463, DOI 10.1002/cem.1180030304; GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X; HU M, 1962, IRE T INFORM THEOR, V8, P179; KOWALSKI BR, 1991, J CHEMOMETR, V5, P129, DOI 10.1002/cem.1180050303; KRZANOWSKI WJ, 1995, J CHEMOMETR, V9, P509, DOI 10.1002/cem.1180090608; PARKER JR, 1993, PRACTICAL VISION USI; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; RIBA JR, 1997, S NAC AERFAI CTR VIS; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SHERALI HD, 1995, J GLOBAL OPTIM, V7, P1, DOI 10.1007/BF01100203; Wichern D. W., 1992, APPL MULTIVARIATE ST; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; YENDLE PW, 1989, J CHEMOMETR, V3, P589, DOI 10.1002/cem.1180030407; Zadeh LA, 1965, INFORM CONTR, V8, P353	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-0751-4	INT C PATT RECOG			2000							953	956				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BR56P	WOS:000166814800224	
B	Chadwick, SP		Valafar, F		Chadwick, SP			Knowing when to exclude data	METMBS'00: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MATHEMATICS AND ENGINEERING TECHNIQUES IN MEDICINE AND BIOLOGICAL SCIENCES, VOLS I AND II			English	Proceedings Paper	International Conference on Mathematics and Engineering Techniques in Medicine and Biological Sciences (METMBS 00)	JUN 26-29, 2000	LAS VEGAS, NV	Comp Sci, Res, Educ & Applicat Press, Int Technol Inst, Korea Informat Processing Soc, PDPTA		machine learning; diagnostic algorithms		Any data set contains elements that are of questionable quality. The ability to exclude data that is marginal or counterproductive can have a large impact on the accuracy of a diagnostic tool. This paper presents ways to measure and visualize the quality of the data and shows their application to improving the accuracy obtained.	Univ Texas, Greenville, TX 75401 USA	Chadwick, SP (reprint author), Univ Texas, 1227 Pk St, Greenville, TX 75401 USA.						AHA D, UC IRVINE ML DATA RE; Breiman L., 1984, WADSWORTH STAT PROBA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Duda R., 1973, PATTERN CLASSIFICATI; Hastie T, 1996, CLASSIFICATION PAIRW; KAI MT, 1996, MACHING LEARNING, P498; SCHWEITZER H, 1997, P 14 NAT C ART INT 9, P88	8	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA		1-892512-62-9				2000							587	592				6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematics, Interdisciplinary Applications	Computer Science; Engineering; Mathematics	BR81W	WOS:000167662700088	
S	Dasarathy, BV; Sanchez, JS		Sanfeliu, A; Villanueva, JJ; Vanrell, M; Alquezar, R; Jain, AK; Kittler, J		Dasarathy, BV; Sanchez, JS			Tandem fusion of nearest neighbor editing and condensing algorithms - Data dimensionality effects	15TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2, PROCEEDINGS: PATTERN RECOGNITION AND NEURAL NETWORKS	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	15th International Conference on Pattern Recognition (ICPR-2000)	SEP 03-07, 2000	BARCELONA, SPAIN	Int Assoc Pattern Recognit, Assoc Pattern Recognit & Image Anal, Ctr Visio Comp, Univ Autonoma Barcelona, Univ Politecn Catalunya, Comissionat Universitats Recerca, Generalitat Catalunya Dept Presidencia, Minist Ciencia Tecnol, Fdn Catalana Recerca, HP Invent			GRAPHS; RULE	In this paper, the effect of the dimensionality of date sets on the exploitation of synergy among known nearest neighbour (NN) editing and condensing tools is analyzed using a synthetic data set. The synergy is exploited through a tandem mode of fusion approach that combines the proximity graph (PG) based editing scheme and the minimal consistent set (MCS) condensing technique. These two methods were selected on the basis of prior experience to representatively evaluate the effect of the data dimensionality. The algorithm level fusion of PG editing and MCS condensing is experimentally shown to be a powerful implement across the range of data dimensionality.	Dynet Inc, Huntsville, AL 35814 USA	Dasarathy, BV (reprint author), Dynet Inc, POB 5500, Huntsville, AL 35814 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DASARATHY BV, 1990, NEAREST NEIGHBOUR NN; Devijver P. A., 1982, PATTERN RECOGNITION; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; MURPHY PM, 1991, UCI REPOSITORY MACHI; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-0751-4	INT C PATT RECOG			2000							692	695				2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BR56P	WOS:000166814800163	
B	Mitani, T; Hamamoto, Y		Baozong, Y; Xiaofang, T		Mitani, T; Hamamoto, Y			Classifier design using nearest neighbor samples	2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III			English	Proceedings Paper	5th International Conference on Signal Processing	AUG 21-25, 2000	BEIJING, PEOPLES R CHINA	Chinese Inst Electr, Signal Proc Soc, IEEE, Signal Proc Soc, Union Radio Sci Int, CIE Comm URSI, IEEE, Beijing Sect, Natl Nat Sci Fdn China, IEEE, Comp Soc Beijing Chapter, IEEE, SP Soc Beijing Chapter		classifier design; nearest neighbor samples; dimensionality; small sample size		A considerable amount of effort has been devoted to design a classifier in practical situations. In this paper. a simple nonparametric classifier is proposed. The proposed classifier uses nearest neighbor training samples from a pattern to be classified and its performance is compared with that of the k-NN classifier in terms of the error rate, particularly in small training sample size situations. Experimental results show that the proposed classifier is promising in practical situations.	Yamaguchi Jr Coll, Hofu 7471232, Japan	Mitani, T (reprint author), Yamaguchi Jr Coll, Hofu 7471232, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; OKAMOTO S, 1998, THESIS U KYUSHU; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6	10	0	0	PUBLISHING HOUSE ELECTRONICS INDUSTRY	BEIJING	PO BOX 173 WANSHOU ROAD, BEIJING 100036, PEOPLES R CHINA		0-7803-5747-7				2000							1448	1452				5	Engineering, Electrical & Electronic	Engineering	BR32Z	WOS:000166107600312	
J	Yakowitz, S; Gyorfi, L; Kieffer, J; Morvai, G				Yakowitz, S; Gyorfi, L; Kieffer, J; Morvai, G			Strongly consistent nonparametric forecasting and regression for stationary ergodic sequences	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article						time-series regression; nonparametric estimation; forecasting; universal prediction	TIME-SERIES; CONVERGENCE; RATES	Let {(X(i), Y(i))} be a stationary ergodic time series with (X, Y) values in the product space R(d) x R. This study offers what is believed to be the first strongly consistent (with respect to pointwise, least-squares, and uniform distance) algorithm for inferring m(x) = E[Y(0)\X(0) = x] under the presumption that m(x) is uniformly Lipschitz continuous. Auto-regression, or forecasting, is an important special case, and as such our work extends the literature of nonparametric. nonlinear forecasting by circumventing customary mixing assumptions. The work is motivated by a time series model in stochastic finance and by perspectives of its contribution to the issues of universal time series estimation. (C) 1999 Academic Press.	Univ Arizona, Tucson, AZ 85721 USA; Tech Univ Budapest, Budapest, Hungary; Univ Minnesota, Minneapolis, MN 55455 USA	Yakowitz, S (reprint author), Univ Arizona, Tucson, AZ 85721 USA.	yak@sie.arizona.edu; gyorfi@inf.bme.hu; kieffer@ee.umn.edu; morvai@inf.bme.hu	Morvai, Gusztav/H-8854-2012				ALGOET P, 1992, ANN PROBAB, V20, P901, DOI 10.1214/aop/1176989811; ALGOET PH, 1994, IEEE T INFORM THEORY, V40, P609, DOI 10.1109/18.335876; ALGOET PH, 1995, ANN PROBAB, V23, P474, DOI 10.1214/aop/1176988396; Ash RB, 1972, REAL ANAL PROBABILIT; Bailey D. H., 1976, THESIS STANFORD U; Bodie Z., 1996, INVESTMENTS; BOLLERSLEV T, 1992, J ECONOMETRICS, V52, P5, DOI 10.1016/0304-4076(92)90064-X; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS R, 1999, ANN STAT, V26, P2049; DEVROYE L, 1989, J STAT PLAN INFER, V23, P71, DOI 10.1016/0378-3758(89)90040-2; DEVROYE L, 1983, P 4 PANN S MATH STAT, P67; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; GREBLICKI W, 1984, ANN STAT, V12, P1570, DOI 10.1214/aos/1176346815; Gyorfi L, 1998, IEEE T INFORM THEORY, V44, P886, DOI 10.1109/18.661540; GYORFI L, 1991, NATO ADV SCI I C-MAT, V335, P329; Gyorfi L., 1989, NONPARAMETRIC CURVE; KIEFFER JC, 1979, ANN PROBAB, V7, P882, DOI 10.1214/aop/1176994948; KRZYZAK A, 1984, IEEE T INFORM THEORY, V30, P78, DOI 10.1109/TIT.1984.1056842; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Mandelbrot BB, 1999, SCI AM, V280, P70; MASRY E, 1995, ECONOMET THEOR, V11, P258; MORVAI G, 1996, THESIS TU BUDAPEST; MORVAI G, 1999, IN PRESS STAISTICS; Morvai G, 1997, IEEE T INFORM THEORY, V43, P483, DOI 10.1109/18.556107; Morvai G, 1996, ANN STAT, V24, P370; Nobel AB, 1998, IEEE T INFORM THEORY, V44, P537, DOI 10.1109/18.661503; ORNSTEIN DS, 1978, ISRAEL J MATH, V30, P292, DOI 10.1007/BF02761077; Resnick SI, 1997, ANN STAT, V25, P1805, DOI 10.1214/aos/1069362376; Robinson P. M., 1994, ADV ECONOMETRICS, VI, P47; Rosenblatt M, 1970, NONPARAMETRIC TECHNI, P199; ROUSSAS GG, 1969, ANN I STAT MATH, V21, P73, DOI 10.1007/BF02532233; Ryabko B. Ya., 1988, Problems of Information Transmission, V24; SHIELDS PC, 1993, IEEE T INFORM THEORY, V39, P520, DOI 10.1109/18.212281; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Watson G.S., 1964, SANKHYA A, V26, P359; WILLINGER W, 1995, STAT SCI, V10, P67, DOI 10.1214/ss/1177010131; YAKOWITZ S, 1993, STOCH PROC APPL, V48, P311, DOI 10.1016/0304-4149(93)90050-E; ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934	40	3	3	ELSEVIER INC	SAN DIEGO	525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA	0047-259X		J MULTIVARIATE ANAL	J. Multivar. Anal.	OCT	1999	71	1					24	41		10.1006/jmva.1999.1825		18	Statistics & Probability	Mathematics	246VP	WOS:000083185800002	
J	Duvdevani-Bar, S; Edelman, S				Duvdevani-Bar, S; Edelman, S			Visual recognition and categorization on the basis of similarities to multiple class prototypes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						representation; similarity; visual shape recognition; categorization; view space; shape space	OBJECT RECOGNITION; FACE RECOGNITION; 3-D OBJECTS; REPRESENTATION; SHAPE; IMAGE; APPEARANCE; EXAMPLES; SURFACE; SPACES	One of the difficulties of object recognition stems from the need to overcome the variability in object appearance caused by pose and other factors, such as illumination. The influence of these factors can be countered by learning to interpolate between stored views of the target object, taken under representative combinations of viewing conditions. Difficulties of another kind arise in daily life situations that require categorization, rather than recognition, of objects. Although categorization cannot rely on interpolation between stored examples, we show that knowledge of several representative members, or prototypes, of each of the categories of interest can provide the necessary computational substrate for the categorization of new instances. We describe a system that represents input shapes by their similarities to several prototypical objects, and show that it can recognize new views of the familiar objects, discriminate among views of previously unseen shapes, and attribute the latter to familiar categories.	Weizmann Inst Sci, Dept Appl Math, IL-76100 Rehovot, Israel; Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA	Duvdevani-Bar, S (reprint author), Weizmann Inst Sci, Dept Appl Math, IL-76100 Rehovot, Israel.						Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Basri R, 1996, INT J COMPUT VISION, V19, P147, DOI 10.1007/BF00055802; BAXTER J, 1997, P 14 INT C MACH LEAR, P39; BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Breuel T, 1992, THESIS MIT; Broomhead D. S., 1988, Complex Systems, V2; BURGE M, 1997, J COMPUTING INFORMAT, V4, P39; BURL M, 1998, RECOGNITION VISUAL O; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVERDIERE VC, 1998, LNCS SERIES, V1406, P640; Duda R., 1973, PATTERN CLASSIFICATI; Duvdevani-Bar S., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670935; DUVDEVANIBAR S, 1997, THESIS WEIZMANN I SC; EDELMAN S, 1992, LECT NOTES COMPUT SC, V588, P787; Edelman S., 1997, P SIM CAT WORKSH DEP, P75; EDELMAN S, 1993, IEEE T PATTERN ANAL, V15, P833, DOI 10.1109/34.236244; EDELMAN S, 1995, MIND MACH, V5, P45, DOI 10.1007/BF00974189; Edelman S, 1998, BEHAV BRAIN SCI, V21, P449; Edelman S, 1997, NEURAL COMPUT, V9, P701, DOI 10.1162/neco.1997.9.4.701; EDELMAN S, 1997, MECH PERCEPTUAL LEAR, P353; FILLENBAUM S, 1979, STRUCTURES SUBJECTIV; Gersho A., 1992, VECTOR QUANTIZATION; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P330, DOI 10.1109/34.485561; JOLICOEUR P, 1984, COGNITIVE PSYCHOL, V16, P243, DOI 10.1016/0010-0285(84)90009-4; Kanatani K., 1990, GROUP THEORETICAL ME; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; LANDO M, 1995, NETWORK-COMP NEURAL, V6, P551, DOI 10.1088/0954-898X/6/4/003; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LOWE DG, 1986, PERCEPTUAL ORG VISUA; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nelson RC, 1998, VISION RES, V38, P2469, DOI 10.1016/S0042-6989(98)00030-3; Palmer S., 1981, ATTENTION PERFORM, VIX, P135; POGGIO T, 1992, 1347 MIT ART INT LAB; POGGIO T., 1989, 1140 MIT ART INT LAB; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; PRICE CJ, 1989, Q J EXP PSYCHOL-A, V41, P797; RIESENHUBER M, 1998, IN PRESS ADV NEURAL, V10; Rosch E., 1978, COGNITION CATEGORIZA, P27; SCHIELE B, 1996, LECT NOTES COMPUTER, V1, P610; SHAPIRA Y, 1991, P IJCAI, P1257; SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390; SMITH I, 1990, SOLID STATE TECHNOL, V33, P53; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Ullman S, 1996, HIGH LEVEL VISION; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Vetter T., 1995, CEREB CORTEX, V3, P261; WEISS Y, 1995, NETWORK-COMP NEURAL, V6, P19, DOI 10.1088/0954-898X/6/1/002; *SAS I INC, 1989, US GUID VERS 6	58	17	17	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1999	33	3					201	228		10.1023/A:1008102413960		28	Computer Science, Artificial Intelligence	Computer Science	248WM	WOS:000083299800003	
J	Brusic, V; Zeleznikow, J				Brusic, V; Zeleznikow, J			Knowledge discovery and data mining in biological databases	KNOWLEDGE ENGINEERING REVIEW			English	Review							PROTEIN-STRUCTURE; RETRIEVAL-SYSTEM; NEURAL-NETWORK; PREDICTION; IMPLEMENTATION; SEQUENCES; ALGORITHM; PROTOTYPE; DISTANCE; SEARCHES	The new technologies for Knowledge Discovery from Databases (KDD) and data mining promise to bring new insights into a voluminous growing amount of biological data. KDD technology is complementary to laboratory experimentation and helps speed up biological research. This article contains an introduction to KDD, a review of data mining tools, and their biological applications. We discuss the domain concepts related to biological data and databases, as well as current KDD and data mining developments in biology.	Kent Ridge Digital Labs, Singapore 119613, Singapore; La Trobe Univ, Sch Comp Sci & Comp Engn, Bundoora, Vic, Australia	Brusic, V (reprint author), Kent Ridge Digital Labs, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.						Agarwal P, 1996, J COMPUT BIOL, V3, P1, DOI 10.1089/cmb.1996.3.1; Altschul SF, 1996, METHOD ENZYMOL, V266, P460; ALTSCHUL SF, 1994, NAT GENET, V6, P119, DOI 10.1038/ng0294-119; ASHLEY KD, 1992, ARTIF INTELL, V1, P113, DOI 10.1007/BF00114920; Baldi P., 1998, BIOINFORMATICS MACHI; Bates D. M., 1988, NONLINEAR REGRESSION; Benton D, 1996, TRENDS BIOTECHNOL, V14, P261, DOI 10.1016/0167-7799(96)10037-8; Brachman R., 1996, ADV KNOWLEDGE DISCOV, P37; Braren R, 1997, ADV EXP MED BIOL, V419, P163; BRAZMA A, 1997, 5 INT C INT SYST MOL, P65; Brazma A, 1998, J COMPUT BIOL, V5, P279, DOI 10.1089/cmb.1998.5.279; Brenner SE, 1996, METHOD ENZYMOL, V266, P635; Brusic V, 1998, BIOINFORMATICS, V14, P121, DOI 10.1093/bioinformatics/14.2.121; BRUSIC V, 1998, SILICO BIOL, V1; BRUSIC V, 1994, COMPLEX SYSTEMS MECH, P253; BRUSIC V, 1998, KNOWLEDGE SHARING BI; Cattell K, 1996, BIOTECHNIQUES, V21, P1118; Cheesman P, 1996, ADV KNOWLEDGE DISCOV, P153; CHEN IA, 1995, LBNL38181; CHEN RO, 1997, 5 INT C INT SYST MOL, P84; CODD E, 1993, PROVIDING OLAP ON LI; Coggon D., 1997, EPIDEMIOLOGY UNINITI; COOK JA, 1995, P S FAT FRACT ORD IN, V2, P155; COPPIETERS J, 1997, PROTOTYPING INTERNET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crowley EM, 1997, J MOL BIOL, V268, P8, DOI 10.1006/jmbi.1997.0965; DAVIDSON SB, 1997, J DIGITAL LIB, V1, P36; DECKER KM, 1995, 9502 CSCSETH; DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703; Discala C, 1999, NUCLEIC ACIDS RES, V27, P10, DOI 10.1093/nar/27.1.10; Dodge C, 1998, NUCLEIC ACIDS RES, V26, P313, DOI 10.1093/nar/26.1.313; Durbin R., 1991, C ELEGANS DATABASE D; DZEROSKI S, 1996, ADV KNOWLEDGE DISCOV, P117; Eckman BA, 1998, BIOINFORMATICS, V14, P2, DOI 10.1093/bioinformatics/14.1.2; Etzold T, 1996, METHOD ENZYMOL, V266, P114; Fayyad U, 1996, AI MAG, V17, P37; FIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817; FIREBAUGH MW, 1989, ARTIFICIAL INTELLIGE; Friedman J H, 1995, Stat Methods Med Res, V4, P197, DOI 10.1177/096228029500400303; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Hieter P, 1997, SCIENCE, V278, P601, DOI 10.1126/science.278.5338.601; Honeyman MC, 1998, NAT BIOTECHNOL, V16, P966, DOI 10.1038/nbt1098-966; Hu J, 1998, BIOINFORMATICS, V14, P112, DOI 10.1093/bioinformatics/14.2.112; IV Elder J.F., 1996, ADV KNOWLEDGE DISCOV, P83; KAUVAR LM, 1995, CHEM BIOL, V2, P107, DOI 10.1016/1074-5521(95)90283-X; King RD, 1996, P NATL ACAD SCI USA, V93, P438, DOI 10.1073/pnas.93.1.438; KLEIN P, 1988, J THEOR BIOL, V130, P461, DOI 10.1016/S0022-5193(88)80210-8; Kolodner J., 1993, CASE BASED REASONING; Kosko B, 1993, FUZZY THINKING NEW S; KOSKY AS, 1996, LBNL38975; KROGH A, 1994, NUCLEIC ACIDS RES, V22, P4768, DOI 10.1093/nar/22.22.4768; Kubinyi H, 1998, J MED CHEM, V41, P2553, DOI 10.1021/jm970732a; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Leng B, 1994, J Comput Biol, V1, P25; Levin JM, 1997, PROTEIN ENG, V10, P771, DOI 10.1093/protein/10.7.771; Li M, 1996, J THEOR BIOL, V182, P463, DOI 10.1006/jtbi.1996.0188; Markowitz V M, 1995, J Comput Biol, V2, P537, DOI 10.1089/cmb.1995.2.537; McCullagh P., 1989, GEN LINEAR MODELS; MIGIMATSU H, 1996, USE DBGET LINKDB; OVERTON CG, 1998, COMPUTATIONAL METHOD, P65; Pearson WR, 1998, J MOL BIOL, V276, P71, DOI 10.1006/jmbi.1997.1525; QU K, 1998, ISMB, V6, P131; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rawlings CJ, 1997, CURR OPIN GENET DEV, V7, P416, DOI 10.1016/S0959-437X(97)80158-X; RITTER O, 1994, COMPUT BIOMED RES, V27, P97, DOI 10.1006/cbmr.1994.1011; Salzberg S, 1995, J Comput Biol, V2, P473, DOI 10.1089/cmb.1995.2.473; STORMO GD, 1982, NUCLEIC ACIDS RES, V10, P2997, DOI 10.1093/nar/10.9.2997; Schuler GD, 1996, METHOD ENZYMOL, V266, P141; SHOUDAI T, 1995, ISMB, V3, P359; SIEBURG HB, 1993, ISMB, V1, P354; Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Tatusov RL, 1997, SCIENCE, V278, P631, DOI 10.1126/science.278.5338.631; Thorne JL, 1998, MOL BIOL EVOL, V15, P1647; Uberbacher EC, 1996, METHOD ENZYMOL, V266, P259; Whittaker J., 1990, GRAPHICAL MODELS APP, P507; YU CH, 1994, ANN M AM ED RES ASS; ZELEZNIKOW J, 1994, COMPUTER LAW SERIES, V13; Zhang CT, 1998, PROTEIN ENG, V11, P971, DOI 10.1093/protein/11.11.971	80	9	10	CAMBRIDGE UNIV PRESS	NEW YORK	40 WEST 20TH STREET, NEW YORK, NY 10011-4211 USA	0269-8889		KNOWL ENG REV	Knowl. Eng. Rev.	SEP	1999	14	3					257	277		10.1017/S0269888999003069		21	Computer Science, Artificial Intelligence	Computer Science	275DL	WOS:000084804100003	
J	Ma, S; Ji, CY				Ma, S; Ji, CY			Performance and efficiency: Recent advances in supervised learning	PROCEEDINGS OF THE IEEE			English	Review						evolutionary computation; hybrid models; neural networks; supervised learning	FEEDFORWARD NEURAL NETWORKS; EM ALGORITHM; CLASSIFICATION; CAPACITY; EVOLUTION; FRAMEWORK; SYSTEMS	This paper reviews recent advances in supervised learning with a focus on two most important issues: performance and efficiency. Performance addresses the generalization capability of a learning machine on randomly chosen samples that are not included in a training set. Efficiency deals with the complexity of a learning machine in both space and time. As these two issues are general to various learning machines nod learning approaches, we focus on a special type of adaptive learning systems with a neural architecture. We discuss four types of learning approaches. training all individual model; combinations of several well-trained models; combinations of many weak models; and evolutionary computation of models. We explore advantages and weaknesses of each approach and their inter relations, and we pose open questions for possible future research.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA; Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Ma, S (reprint author), IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA.						ABUMOSTAFA YS, 1989, IEEE COMMUN MAG, V27, P25, DOI 10.1109/35.41397; ATARI S, 1992, NEURAL NETWORKS, V3, P260; ATLAS L, 1990, P IEEE, V78, P1614, DOI 10.1109/5.58347; ATMAR W, 1994, IEEE T NEURAL NETWOR, V5, P130, DOI 10.1109/72.265967; Back T., 1997, IEEE T EVOLUTIONARY, V1; Back T., 1996, EVOLUTIONARY ALGORIT; Baldi P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.589; BARRON A, 1997, COMMUNICATION; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; BARRON AR, 1984, SELF ORGANIZING METH; Barron A.R., 1994, MACH LEARN, V14, P113; BAUM EB, 1991, IEEE T NEURAL NETWOR, V2, P5, DOI 10.1109/72.80287; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BENDAVID S, 1994, ALGORITHMICA, V1, P2; BENEDIKTSSON JA, 1992, IEEE T SYST MAN CYB, V22, P688, DOI 10.1109/21.156582; BENGIO Y, 1994, ADV NEURAL INFORMATI, V6, P75; Bertsekas D. P., 1996, NEURODYNAMIC PROGRAM; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; BREIMAN L, 1996, MACH LEARN, V24, P132; BREIMAN LE, 1993, P NEUR NETW COMP SNO; BROWN TX, IN PRESS OPTIMIZING; BYNE W, 1992, IEEE T NEURAL NETWOR, V3, P612; Cesa-Bianchi N., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167198; COVER TM, 1968, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagum P., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492471; DEMIRAL HT, 1995, P WORLD C NEUR NETW, P591; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Dietterich TG, 1997, AI MAG, V18, P97; Dietterich TG, 1998, ANN STAT, V26, P838; Duda R., 1973, PATTERN CLASSIFICATI; Fahlman SE, 1991, ADV NEURAL INFORMATI, P190; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Fine T.L., 1999, FEEDFORWARD NEURAL N; FINE TL, 1999, P 1998 IEEE INT S IN, P161; Fogel D. B., 1995, EVOLUTIONARY COMPUTA; FOGEL DB, 1990, BIOL CYBERN, V63, P487, DOI 10.1007/BF00199581; Fogel DB, 1997, P SOC PHOTO-OPT INS, V3165, P14, DOI 10.1117/12.279591; FOREST S, 1990, EMERGENT COMPUTATION; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J, 1998, ADDITIVE LOGISTIC RE; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GROSSMAN R, 1992, THESIS WIZMANN I SCI; HAUSSLER D, 1991, P 4 WORKSH COMP LEAR; HOLLAND JH, 1986, PHYSICA D, V22, P307; HOLLAND JH, 1992, SCI AM, V267, P66; JI C, 1996, NIPS             MAY, P494; JI C, 1993, P NEUR INF PROC SYST; JI C, 1998, NEURAL NETWORKS  AUG; JI C, 1991, P 4 WORKSH COMP LEAR; Ji CY, 1997, IEEE T NEURAL NETWOR, V8, P32; Ji CY, 1998, IEEE T INFORM THEORY, V44, P256; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Judd S., 1990, NEURAL NETWORK DESIG; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73049; Kleinberg EM, 1990, ANN MATH ARTIFICIAL, V1, P207, DOI 10.1007/BF01531079; KLEINBERG EM, 1993, P 3 INT WORKSH FRONT, P175; KROGH A, 1990, ADV NEURAL INFORMATI, V2, P733; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Lawrence S, 1999, IEEE COMMUN MAG, V37, P116, DOI 10.1109/35.739314; Littlefield TR, 1998, J CRANIOFAC SURG, V9, P11, DOI 10.1097/00001665-199801000-00004; Ma S, 1998, IEEE T SIGNAL PROCES, V46, P2270; Ma S, 1997, NEURAL NETWORKS, V10, P243, DOI 10.1016/S0893-6080(96)00049-4; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MANIEZZO V, 1994, IEEE T NEURAL NETWOR, V5, P39, DOI 10.1109/72.265959; MCELIECE RJ, 1987, IEEE T INFORM THEORY, V33, P461, DOI 10.1109/TIT.1987.1057328; MEIR R, 1995, NIPS, V7, P295; MERZ C, 1996, P NAT C ART INT; MERZ C, 1997, NIPS, V9; MICHALEWICZ Z, 1996, GENETIC ALGORITHMS P; MITRA U, 1994, IEEE J SEL AREA COMM, V12, P1460, DOI 10.1109/49.339913; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; MOODY J, 1991, NEURAL INFORM PROCES; NEAL RM, 1993, NEURAL INFORM PROCES; NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473; PERRONE MP, 1993, ARTIFICIAL NEURAL NE, pCH10; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RANGARAJAN S, 1993, IEEE T SOFTWARE ENG, V19, P698, DOI 10.1109/32.238570; ROHWER R, 1990, ADV NEURAL INFORMATI, V2, P558; RUMELHART D E, 1986, LEARNING INT REPRESE; Saad D., 1990, Complex Systems, V4; Salomon R., 1998, IEEE Transactions on Evolutionary Computation, V2, DOI 10.1109/4235.728207; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schwefel H.-P., 1995, EVOLUTION OPTIMUM SE; LEVIN E, 1990, P IEEE, V78, P1568, DOI 10.1109/5.58339; THOTTAN M, 1998, IEEE NETWORK MAG SEP; TISHBY N, 1989, P INT JOINT C NEUR N; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1995, NATURE STAT LEARNING; Weigend A., 1991, P INT JOINT C NEUR N, P2374, DOI 10.1109/IJCNN.1991.170743; WEIGEND AS, 1991, P IEEE INT J C NEURA, P2069, DOI 10.1109/IJCNN.1991.170692; WERBOS PJ, 1993, P INT C NEUR NETW; WHITE H, 1992, PARAMETRIC STAT ESTI; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	102	16	17	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0018-9219		P IEEE	Proc. IEEE	SEP	1999	87	9					1519	1535				17	Engineering, Electrical & Electronic	Engineering	229CV	WOS:000082176700006	
J	Hamilton, PW; Bartels, PH; Anderson, N; Thompson, D; Montironi, R; Sloan, JM				Hamilton, PW; Bartels, PH; Anderson, N; Thompson, D; Montironi, R; Sloan, JM			Case-based prediction of survival in colorectal cancer patients	ANALYTICAL AND QUANTITATIVE CYTOLOGY AND HISTOLOGY			English	Article						colorectal neoplasms; prognosis; expert systems; case-based reasoning; nearest neighbor analysis		OBJECTIVE: To develop an approach to the prediction of survival in patients with colorectal cancer using nearest neighbor analysis and case-based reasoning. STUDY DESIGN: A total of 216 patients with full clinicopathologic records and five-year follow-up were the subjects of this study. They were divided into It cove database of 162 cases and a test group of 54 cases, with follow up on all patients. When the patient was still alive at the end of the follow-up period, censored survival time was used. For each of the test cases, the four closest neighbors from the database were retrieved and their median survival time recorded and used as the predicted estimate of survival. Case matching was based on a Euclidean multivariate distance measure for the three best predictor variables: patient age, Dukes stage and tubule configuration . Cases with the smallest distance from the test case were considered to be the most similar. The predicted survival times for the test cases were compared with the actual, observed survival in the test cases to determine the success of this approach. RESULTS: The results showed reasonable concordance between observed and predicted survival figures, although there was a large degree of spread. Classification of cases into less than or equal to 60 and > 60 months' survival showed a correct classification rate of 63%. For the prediction of survival time, the distribution Of differences between observed and predicted survival times for the uncensored test cases had a median value of-5 months but also showed a wide dispersion of values. Correlation of observed and predicted survival times, while not reaching statistical significance at P < .05, did show a strong positive association. CONCLUSION: Case-based approaches to the prediction of survival times in cancer patients are important. The results of the current study illustrate the difficulties in applying this approach to survival data and highlight the complexity of patient information and the inability to accurately predict patient outcome on 17 small subset of clinicopathologic features. While extensive work needs to be carried out to improve prediction power, this study illustrates the potential for case-based analyses. The ability to retrieve feature-matched cases from hospital patient databases has clear, independent advantages in patient management, but the ability to provide reliable, targeted prognostic estimates on individual cases should be a common goal in medical research.	Queens Univ Belfast, Dept Pathol, Quantitat Pathol Lab, Belfast BT12 6BL, Antrim, North Ireland; Royal Grp Hosp, Dept Pathol, Belfast, Antrim, North Ireland; Univ Arizona, Ctr Opt Sci, Tucson, AZ USA; Univ Ancona, Osped Regionale, Sch Med, Inst Pathol Anat & Histopathol, Ancona, Italy	Hamilton, PW (reprint author), Queens Univ Belfast, Dept Pathol, Quantitat Pathol Lab, Grosvenor Rd, Belfast BT12 6BL, Antrim, North Ireland.						Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEANS GT, 1992, BRIT J SURG, V79, P608, DOI 10.1002/bjs.1800790706; Dukes CE, 1932, J PATHOL BACTERIOL, V35, P323, DOI 10.1002/path.1700350303; JASS J, 1987, LANCET, V1, P1333; Kolodner J., 1993, CASE BASED REASONING; OBRIEN MJ, 1988, BR J MED SCI, V157, P5	7	6	6	SCI PRINTERS & PUBL INC	ST LOUIS	P.O. DRAWER 12425 8342 OLIVE BLVD, ST LOUIS, MO 63132 USA	0884-6812		ANAL QUANT CYTOL	Anal. Quant. Cytol. Histol.	AUG	1999	21	4					283	291				9	Cell Biology	Cell Biology	226EX	WOS:000082008300002	
J	Cheng, CB; Lee, ES				Cheng, CB; Lee, ES			Nonparametric fuzzy regression - k-NN and kernel smoothing techniques	COMPUTERS & MATHEMATICS WITH APPLICATIONS			English	Article						nonparametric fuzzy regression; k-NN smoothing; kernel smoothing	LINEAR-REGRESSION; NEURAL NETWORKS	Fuzzy regression without predefined functional form, or nonparametric fuzzy regression, is investigated. The two most basic nonparametric regression techniques in statistics, namely, k-nearest neighbor smoothing and kernel smoothing, are fuzzified and analyzed. Algorithms are proposed to obtain the best smoothing parameters based on the minimization of cross-validation criteria. (C) 1999 Elsevier Science Ltd. All rights reserved.	Kansas State Univ, Dept Ind & Mfg Syst Engn, Manhattan, KS 66506 USA	Cheng, CB (reprint author), Kansas State Univ, Dept Ind & Mfg Syst Engn, Manhattan, KS 66506 USA.						CELMINS A, 1987, FUZZY SET SYST, V22, P245, DOI 10.1016/0165-0114(87)90070-4; CHANG PT, 1994, COMPUT MATH APPL, V27, P11; Chang P.T., 1994, THESIS KANSAS STATE; CHANG PT, 1994, COMPUT MATH APPL, V28, P61, DOI 10.1016/0898-1221(94)00127-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1980, FUZZY SETS SYSTEMS T; Fedrizzi M., 1995, Proceedings. 1995. Second New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems, DOI 10.1109/ANNES.1995.499483; Hardle W, 1990, APPL NONPARAMETRIC R; Ishibuchi H., 1993, P ICNN 93, P1650; ISHIBUCHI H, 1993, FUZZY SET SYST, V57, P27, DOI 10.1016/0165-0114(93)90118-2; ISHIBUCHI H, 1992, FUZZY SET SYST, V50, P257, DOI 10.1016/0165-0114(92)90224-R; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MIYAZAKI A, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P52, DOI 10.1109/FUZZY.1994.343690; POKORNY M, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P2051, DOI 10.1109/FUZZY.1995.409960; STONE M, 1974, J R STAT SOC B, V36, P111; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; TANAKA H, 1987, FUZZY SET SYST, V24, P363, DOI 10.1016/0165-0114(87)90033-9; TANAKA H, 1989, EUR J OPER RES, V40, P389, DOI 10.1016/0377-2217(89)90431-1	18	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0898-1221		COMPUT MATH APPL	Comput. Math. Appl.	AUG	1999	38	3-4					239	251		10.1016/S0898-1221(99)00198-4		13	Computer Science, Interdisciplinary Applications; Mathematics, Applied	Computer Science; Mathematics	223TA	WOS:000081855800019	
J	Lee, CH; Shin, DG				Lee, CH; Shin, DG			A multistrategy approach to classification learning in databases	DATA & KNOWLEDGE ENGINEERING			English	Article						rule induction; lazy learning; database; data mining; hellinger divergence	RULES; ALGORITHM; DISCOVERY	This paper proposes a hybrid classification learning system for databases that integrates rule induction and lazy learning. For rule induction learning, we use an entropy function based on Hellinger divergence to measure the amount of information each inductive rule contains. For lazy learning, we also use the Hellinger measure to automatically generate attribute weights and to compute similarities between data values of non-numeric data types. Our system has been implemented and tested extensively on a number of well-known machine learning data sets. The performance of our system was favorable compared to those of other well-known classification learning techniques based on monostrategic learning methods. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA; DongGuk Univ, Informat & Commun Dept, Chung Gu, Seoul 100715, South Korea	Lee, CH (reprint author), Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT 06269 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BERAN R, 1977, ANN STAT, V5, P445, DOI 10.1214/aos/1176343842; Breiman L, 1984, CLASSIFICATION REGRE; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; Chan K. C. C., 1991, Knowledge discovery in databases; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dejong G., 1986, Machine Learning, V1, DOI 10.1023/A:1022898111663; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; Holland J. H., 1986, INDUCTION PROCESSES; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KAN G, 1986, BRIT HEART J, V56, P422; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; LEE CH, 1994, P 11 EUR C ART INT A; LEE CH, 1994, THESIS U CONNECTICUT; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MINTON S, 1987, P 4 INT MACH LEARN W; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; OURSTON D, 1994, ARTIF INTELL, V66, P273, DOI 10.1016/0004-3702(94)90028-0; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; PAZZANI MJ, 1988, P EWSL; Piatetsky-Shapiro G., 1991, Knowledge discovery in databases; Quinlan J. R., 1987, P 10 INT JOINT C ART, P304; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RUMELHART DE, 1987, PDP RES GROUP PARALL, V1; SALZBERG S, 1988, TR1088 HARV U CTR RE; Smith E. E., 1981, CATEGORIES CONCEPTS; SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TAN M, 1988, P 5 INT C MACH LEARN, P121; WEISS SM, 1993, IEEE EXPERT, V8, P61, DOI 10.1109/64.248354; Wettschereck D., 1995, P 1 INT C CAS BAS RE; WHITEHALL BL, 1990, THESIS U ILLINOIS; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; Zhang J., 1992, P 9 INT MACH LEARN C, P470	37	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X		DATA KNOWL ENG	Data Knowl. Eng.	AUG	1999	31	1					67	93		10.1016/S0169-023X(99)00018-X		27	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	229VF	WOS:000082215900003	
J	Ekin, O; Hammer, PL; Kogan, A; Winter, P				Ekin, O; Hammer, PL; Kogan, A; Winter, P			Distance-based classification methods	INFOR			English	Article							NEAREST-NEIGHBOR; RULES; INDUCTION	Given a set of points in a Euclidean space, and a partitioning of this "training set" into two or more subsets ("classes"), we consider the problem of identifying a "reasonable" assignment of another point in the Euclidean space ("query point") to one of these classes. The various classifications proposed in this paper are determined by the distances between the query point and the points in the training set. We report results of extensive computational experiments comparing the new methods with two well-known distance-based classification methods (k-nearest neighbors and Parzen windows) on data sets commonly used in the literature. The results show that the performance of both new and old distance-based methods is on par with and often better than that of the other best classification methods known. Moreover, the new classification procedures proposed in this paper are: (i) easy to implement, (ii) extremely fast, and (iii) very robust (i.e. their performance is insignificantly affected by the choice of parameter values).	Bilkent Univ, Dept Ind Engn, TR-06533 Bilkent, Turkey; Rutgers State Univ, RUTCOR, Piscataway, NJ 08854 USA; Rutgers State Univ, Fac Management, Newark, NJ 07102 USA; Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark	Ekin, O (reprint author), Bilkent Univ, Dept Ind Engn, TR-06533 Bilkent, Turkey.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AISERMAN MA, 1970, METHOD POTENTIAL FUN; BASHKIROV OA, 1964, AVTOMAT TELEMEKH, V25, P5692; BELFAYS P, 1985, COMPUTATIONAL STAT Q, V2, P15; BERGADANO F, 1992, MACH LEARN, V8, P5, DOI 10.1023/A:1022682318197; BRAZDIL P, EVALUATION CHARACTER; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; CARTER C, 1987, IEEE EXPERT      FAL, P71; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; DUDANI S, IEEE T SYSTEMS MAN C, V4, P325; FISHER FP, 1970, P NATL EL C DEC, V26, P481; Fisher R. A., 1950, CONTRIBUTIONS MATH S; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED, P261; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Merz C. J., 1996, UCI REPOSITORY MACHI; MICHALSKI RS, 1980, INT J MAN MACH STUD, V12, P63, DOI 10.1016/S0020-7373(80)80054-X; MOONEY RJ, 1995, MACH LEARN, V19, P79, DOI 10.1007/BF00994661; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; NOORDEWIER MO, 1990, ADV NEURAL INFORMATI, V3; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rayward-Smith V. J., 1983, INT J MATH ED SCI TE, V14, P15, DOI 10.1080/0020739830140103; RAYWARDSMITH VJ, 1986, NETWORKS, V16, P283, DOI 10.1002/net.3230160305; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SCHLIMMER JC, 1984, CONCEPT ACQUISITION; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); Sridharan NS, 1989, P 11 INT JOINT C ART, P781; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; WAXMAN BM, 1988, INFORM PROCESS LETT, V29, P2283; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WINTER P, 1992, ALGORITHMICA, V7, P309, DOI 10.1007/BF01758765	39	4	4	INFOR	DOWNSVIEW ONTARIO	UNIV TORONTO PRESS, JOURNALS DEPT,5201 DUFFERIN ST, DOWNSVIEW ONTARIO, TORONTO M3H 5T8, CANADA	0315-5986		INFOR	Infor	AUG	1999	37	3					337	352				16	Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	228ZF	WOS:000082166900009	
J	Foggia, P; Sansone, C; Tortorella, F; Vento, M				Foggia, P; Sansone, C; Tortorella, F; Vento, M			Multiclassification: reject criteria for the Bayesian combiner	PATTERN RECOGNITION			English	Article						multi-expert systems; Bayesian combination; classification; reliability; error reject trade-off; Chow's rule	UNCONSTRAINED HANDWRITTEN NUMERALS; RECOGNITION; CLASSIFICATION; COMBINATION	In the present paper we propose a method for determining the best trade-off between error rate and reject rate for a multi-expert system (MES) using the Bayesian combining rule. The method is based on the estimation of the reliability of each classification act and on the evaluation of the convenience of rejecting the input sample when the reliability is under a threshold, evaluated on the basis of the requirements of the application domain. The adaptability to the given domain represents an original feature since, till now, the problem of defining a reject rule for an MES has not been systematically introduced, and the few existing proposals seldom take into account the requirements of the domain. The met:hod has been widely tested with reference to the recognition of handwritten characters coming from a standard database. The results are also compared with those provided by employing the well-known Chow's rule. (C) 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy; Univ Cassino, Dipartimento Automaz Elettromagnetismo Ingn Infor, I-03043 Cassino, Italy	Vento, M (reprint author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.		Tortorella, Francesco/F-5964-2010				ACKERMANN B, 1996, IAM96002 U BERN I IN; Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358; CORDELLA LP, 1997, NEURAL NETWORK SYSTE, V5, P161; CORDELLA LP, 1995, MACH VISION APPL, V8, P336, DOI 10.1007/s001380050014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESTEFANO C, 1996, P 13 INT C PATT REC, V2, P290, DOI 10.1109/ICPR.1996.546835; DESTEFANO C, 1995, P 9 SCAND C IM AN, P1123; Foggia P, 1997, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, P6, DOI 10.1109/ICDAR.1997.619804; Grother P. J., 1995, NIST SPECIAL DATABAS; HECTHNIELSEN R, 1990, NEUROCOMPUTING; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KANG H, 1997, P 4 INT C DOC AN REC, V2, P870; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LAM L, 1994, P 4 INT WORKSH FRONT, P245; Pratt WK, 1991, DIGITAL IMAGE PROCES; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	23	17	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	AUG	1999	32	8					1435	1447		10.1016/S0031-3203(98)00169-1		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	212TQ	WOS:000081233000010	
J	Daelemans, W				Daelemans, W			Introduction to the special issue on memory-based language processing	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Editorial Material							LAZY LEARNING ALGORITHMS; CLASSIFICATION		Tilburg Univ, ILK, NL-5000 LE Tilburg, Netherlands							AAMODT A, 1994, AI COMMUN, V7, P39; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALLEN J, 1995, NATURAL LANGUAGE UND; ARGAMON S, 1998, P COLING ACL MONTR C, P67; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BOD R, 1998, GRAMMAR; BOD R, 1995, ILLC DISSERTATION SE; Bod R, 1997, TEXT SPEECH LANG TEC, V2, P137; BONNEMA R, 1997, P 35 ANN M ASS COMP, P159; Booij G., 1989, YB MORPHOLOGY, V2, P55; Brill E, 1995, COMPUT LINGUIST, V21, P543; BRILL E, 1997, AI MAGAZINE, V18; Brill E, 1997, AI MAG, V18, P13; BUCHHOLZ S, 1999, P JOINT SIGDAT C EMP, P239; Bybee Joan L., 1988, THEORETICAL MORPHOLO, P119; CARDIE C, 1996, P C EMP METH NAT LAN, P113; CARDIE C, 1994, THESIS U MASSACHUSET; Cardie C., 1993, P 10 INT C MACH LEAR, P25; CARDIE C, 1999, MACH LEARN, V11, P1; CARDIE C, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P798; CHANDLER S, 1993, J PSYCHOLINGUIST RES, V22, P593; Charniak E., 1993, STAT LANGUAGE LEARNI; Church K. W., 1993, COMPUTATIONAL LINGUI, V19.1, P1; Cohen W. W., 1995, P 12 INT C MACH LEAR; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1995, LECT NOTES ARTIF INT, V898, P85; DAELEMANS W, 1992, TWLT3 CONNECTIONISM, P27; DAELEMANS W, 1997, METHODS LANGUAGE PRO, P3; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; DAELEMANS W, PROGR SPEECH SYNTHES, P77; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; Daelemans W., 1994, Computational Linguistics, V20; Dagan I, 1999, MACH LEARN, V34, P43, DOI 10.1023/A:1007537716579; DASARATHY BV, 1991, NEAREST NEIGHBOUR NN; EDDINGTON D, 1998, IN PRESS FESTSCHRIFT; FIX E, 1952, 11 USAF SCH AV MED, P280; Fix E., 1951, 4 USAF SCH AV MED, P261; Fujii A, 1998, COMPUT LINGUIST, V24, P573; Gazdar G., 1989, NATURAL LANGUAGE PRO; HERMJAKOB U, 1997, THESIS U TEXAS AUSTI; HERMJAKOB U, 1997, P 35 ANN M ASS COMP, P482; JONES D, 1996, ANALOGICAL NATURAL L, P430; KASIF S, 1997, UNPUB FRAMEWORK MEMO; Kolodner J., 1993, CASE BASED REASONING; Langacker R. W., 1991, CONCEPT IMAGE SYMBOL; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LEHNERT W, 1987, P 6 NAT C ART INT AA, P301; LEPAGE Y, 1998, P 36 ANN M ACL MONTR, P718; Manning C, 1999, FDN STAT NATURAL LAN; Masand B., 1992, P 15 ANN INT ACM SIG, P59, DOI 10.1145/133160.133177; Nagao M., 1984, ARTIFICIAL HUMAN INT, P173; Ng HT, 1996, P 34 ANN M ASS COMP, P40, DOI 10.3115/981863.981869; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; PIRELLI V, 1993, ACTA LINGUISTICA HUN, V41, P235; PIRRELLI V, 1994, P 16 INT C COMP LING, P234; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Riesbeck C., 1989, INSIDE CASE BASED RE; RILOFF E, 1994, ACM T INFORM SYST, V12, P296, DOI 10.1145/183422.183428; SCHA R, 1992, GRAMMA TTT, V1, P57; SIMMONS R, 1993, COMPUTATIONAL LINGUI, V18, P391; Skousen Royal, 1992, ANALOGY STRUCTURE; Skousen Royal, 1989, ANALOGICAL MODELLING; Smith E. E., 1981, CATEGORIES CONCEPTS; STANFILL C, 1986, COMMUN ACM, V29, P1212; van den Bosch A., 1999, P 37 ANN M ASS COMP, P285, DOI 10.3115/1034678.1034726; VAPNIK V, 1995, ESTIMATION DEPENDENC; VEENSTRA J, UNPUB MEMORY BASED W; WEIJTERS A, 1991, P INT C ART NEUR NET; WERMTER S, 1996, SPRINGER LECT NOTES, V1040; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; YVON F, 1997, P 35 ANN M ASS COMP, P428; ZAVREL J, 1997, P WORKSH COMP NAT LA, P136; Zavrel J, 1997, P 35 ANN M ASS COMP, P436	77	12	12	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0952-813X		J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.	JUL-SEP	1999	11	3					287	296		10.1080/095281399146436		10	Computer Science, Artificial Intelligence	Computer Science	241AA	WOS:000082858000001	
J	Van den Bosch, A				Van den Bosch, A			Careful abstraction from instance families in memory-based language learning	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Article						careful abstraction; memory-based learning; generalized exemplars; natural language processing	ALGORITHMS	Empirical studies in inductive language learning point at pure memory-based learning as a successful approach to many language learning tasks, often performing better than learning methods that abstract from the learning material. The possibility is left open, however, that limited, careful abstraction in memory-based learning may be harmless to generalization, as long as the disjunctivity of language data is preserved. We test this hypothesis, by comparing empirically a range of careful abstraction methods, focusing particularly on methods that (i) generalize instances and (ii) perform oblivious (partial) decision-tree abstraction. These methods are applied to a selection of language learning tasks, and their generalization performance as well as memory item compression rates are collected. On the basis of the results we conclude that when combined with feature weighting or value distance metrics, careful abstraction equals or outperforms pure memory-based learning, yet mainly on small data sets. In the concluding case study involving large data sets, we find that the FAMBL algorithm, a new careful abstractor which merges families of instances, performs close to pure memory-based learning, though it equals it only on three of the six tasks. On the basis of the gathered empirical results, we discuss the incorporation of the notion of instance families, i.e. carefully generalized instances, in memory-based language learning.	Tilburg Univ, ILK Res Grp, NL-5000 LE Tilburg, Netherlands			van den Bosch, Antal/G-5072-2011	van den Bosch, Antal/0000-0003-2493-656X			Abney S., 1991, PRINCIPLE BASED PARS; AHA D. W., 1992, P 9 INT C MACH LEARN, P1; Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Baayen R. H., 1993, CELEX LEXICAL DATA B; Blake CL, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; CARDIE C, 1996, P C EMP METH NLP U P; CARDIE C, 1994, THESIS U MASSACHUSET; CHURCH KW, 1988, P 2 APPL NLP C; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COLLINS M, 1995, P 3 WORKSH VER LARG; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1992, ARTIFICIAL NEURAL NE, V2, P1647; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; Daelemans W., 1992, P TWLT3 CONN NAT LAN, P27; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; DAELEMANS W, 1997, FOLIA LINGUISTICA, V31; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1980, P 5 INT C PATT REC I; Dietterich T. G., 1998, NEURAL COMPUTATION, V10; DOMINGOS P, 1995, 952 U CAL IRV DEP IN; Domingos P, 1996, MACH LEARN, V24, P141; Fix E., 1951, 4 USAF SCH AV MED; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Golding AR, 1999, MACH LEARN, V34, P107, DOI 10.1023/A:1007545901558; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Iba W., 1992, P 10 NAT C ART INT, P223; Kolodner J., 1993, CASE BASED REASONING; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LEHNERT W, 1987, P 6 NAT C ART INT AA, P301; Marcus M, 1994, COMPUTATIONAL LINGUI, V19, P313; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Niblett T, 1987, PROGR MACHINE LEARNI, P67; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ramshaw L. A., 1995, P 3 WORKSH VER LARG, P82; Ratnaparkhi A., 1998, THESIS U PENNSYLVANI; RATNAPARKHI A, 1994, WORKSH HUM LANG TECH; Salzberg S., 1991, MACH LEARN, V6, P277; SALZBERG SL, 1997, DATA MINING KNOWLEDG, V1; Sejnowski T. J., 1987, Complex Systems, V1; Shavlik J. W., 1990, READINGS MACHINE LEA; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STANFILL C, 1987, P 6 NAT C ART INT AA, P577; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VANDENBOSCH A, 1996, P 2 INT C NEW METH N, P79; VANDENBOSCH A, 1997, THESIS U MAASTRICHT; VAPNIK V, 1993, NEURAL COMPUT, V5, P893, DOI 10.1162/neco.1993.5.6.893; VEENSTRA J, 1998, P BENELEARN 98 8 BEL, P71; WETTSCHERECK D, 1995, MACH LEARN, V19, P1; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1994, ADV NEURAL INFORMATI, V6, P184; WETTSCHERECK D, 1994, THESIS OREGON STATE; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; ZAVREL J, 1997, P WORKSH COMP LANG L	64	0	0	TAYLOR & FRANCIS LTD	LONDON	ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND	0952-813X		J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.	JUL-SEP	1999	11	3					339	368				30	Computer Science, Artificial Intelligence	Computer Science	241AA	WOS:000082858000003	
J	Vinitski, S; Gonzalez, CF; Knobler, R; Andrews, D; Iwanaga, T; Curtis, M				Vinitski, S; Gonzalez, CF; Knobler, R; Andrews, D; Iwanaga, T; Curtis, M			Fast tissue segmentation based on a 4D feature map in characterization of intracranial lesions	JMRI-JOURNAL OF MAGNETIC RESONANCE IMAGING			English	Article						MRI; tissue segmentation; 4D feature map; brain tumor; multiple sclerosis	RECONSTRUCTION; CONNECTIVITY; IMAGES	The aim of this work was to develop a fast and accurate method for tissue segmentation in magnetic resonance imaging (MRI) based on a four-dimensional (4D) feature map and compare it with that derived from a 3D feature map. High-resolution MRI was performed in 5 normal individuals, in 12 patients with brain multiple sclerosis (MS), and 9 patients with malignant brain tumors. Three inputs (proton-density, TB-weighted fast spin-echo, and T1-weighted spin-echo MR images) were routinely utilized. As a fourth input, either magnetization transfer MRT was used or T1-weighted post-contrast MRI tin patients only). A modified k-nearest neighbor segmentation algorithm was optimized for maximum computation speed and highquality segmentation. In that regard, we a) discarded the redundant seed points; b) discarded the points within 0.5 standard deviation from the cluster center that were nonoverlapping with other tissue; and c) removed outlying seed points outside 5 times the standard deviation from the cluster center of each tissue class. After segmentation, a stack of color-coded segmented images was created. Our new technique utilizing all four MRI Inputs provided better segmentation than that based on three inputs (P < 0.001 for FAS and P < 0.001 for tumors). The tissues were smoother due to the reduction of statistical noise, and the delineation of the tissues became sharper. Details that were previously blurred or invisible now became apparent. In normal persons a detailed depiction of deep gray matter nuclei was obtained, In malignant tumors, up to five abnormal tissue types were identified: 1) solid tumor core, 2) cyst, 3) edema In white matter 4) edema in gray matter, and 5) necrosis. Delineation of MS plaque in different stages of demyelination became much sharper. In conclusion, the proposed methodology warrants further development and clinical evaluation, (C) 1999 Wiley-Liss, Inc.	Thomas Jefferson Univ Hosp, Dept Radiol, Philadelphia, PA 19107 USA	Vinitski, S (reprint author), Thomas Jefferson Univ Hosp, Dept Radiol, 132 S 10th St, Philadelphia, PA 19107 USA.						BRASCH R, 1993, MRI CONTRAST ENHANCE; CLINE HE, 1987, MAGN RESON IMAGING, V5, P345, DOI 10.1016/0730-725X(87)90124-X; CLINE HE, 1990, J COMPUT ASSIST TOMO, V14, P1037, DOI 10.1097/00004728-199011000-00041; CLINE HE, 1988, MED PHYS, V15, P320, DOI 10.1118/1.596225; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAWSONSAUNDERS RG, 1990, BASIC CLIN BIOSTATIS; GERIG G, 1992, IEEE T MED IMAGING, V2; GONZALEZ CF, 1991, NEURORADIOLOGY S, P123; HU BS, 1992, MAGNET RESON MED, V26, P231, DOI 10.1002/mrm.1910260205; MOHAMED FB, 1998, IN PRESS MAGN RES ME; Mohamed FB, 1995, P IEEE ENG MED BIOL, V17, P36; Nissanov J, 1997, RADIOLOGY, V205, P51; VINITSKI S, 1993, IMAGE PROCESSING THE, P325; Vinitski S., 1995, Image Analysis and Processing. 8th International Conference, ICIAP '95. Proceedings; Vinitski S, 1997, MAGNET RESON MED, V37, P457, DOI 10.1002/mrm.1910370325; VINITSKI S, 1994, P IEEE ENG MED BIOL, V16, P577; VINITSKI S, 1988, MAGN RESON IMAGING, V6, P707, DOI 10.1016/0730-725X(88)90095-1; Vinitski S, 1998, JMRI-J MAGN RESON IM, V8, P814, DOI 10.1002/jmri.1880080410; *MONTR NEUR I, 1995, P NIH WORSH MONTR NE	19	15	15	JOHN WILEY & SONS INC	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158-0012 USA	1053-1807		JMRI-J MAGN RESON IM	JMRI-J. Magn. Reson. Imaging	JUN	1999	9	6					768	776		10.1002/(SICI)1522-2586(199906)9:6<768::AID-JMRI3>3.0.CO;2-2		9	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	206FQ	WOS:000080867000003	
J	Lavrac, N				Lavrac, N			Selected techniques for data mining in medicine	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						data mining; machine learning; medical applications	DIAGNOSIS; KNOWLEDGE; DISCOVERY; INDUCTION	Widespread use of medical information systems and explosive growth of medical databases require traditional manual data analysis to be coupled with methods for efficient computer-assisted analysis. This paper presents selected data mining techniques that can be applied in medicine, and in particular some machine learning techniques including the mechanisms that make them better suited for the analysis of medical databases (derivation of symbolic rules, use of background knowledge, sensitivity and specificity of induced descriptions). The importance of the interpretability of results of data analysis is discussed and illustrated on selected medical applications. (C) 1999 Elsevier Science B.V. All rights reserved.	Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia	Lavrac, N (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia.	nada.lavrac@ijs.si					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BRATKO I, 1986, CISM COURSES LECT, V382, P163; BRATKO I, 1987, AI METHODS STAT; CESTNIK B, 1987, PROGR MACHINE LEARNI; Cestnik B., 1990, P EUR C ART INT, P147; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Dzeroski S, 1996, Technol Health Care, V4, P203; Fayyad U, 1996, COMMUN ACM, V39, P24, DOI 10.1145/240455.240463; Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464; FIX E, 1957, 4 US AIR FORC SCH AV; Frawley WJ, 1991, KNOWLEDGE DISCOVERY; French S., 1986, DECISION THEORY; GROSELJ C, 1997, P WORKSH COMP AID DA, P68; HOLTE R, 1989, P 10 INT JOINT C ART; Kira K., 1992, P 9 INT C MACH LEARN, P249; KIRA K, 1992, P AAAI 1992 SAN JOS; KONENKO I, 1994, P EUR C MACH LEARN B, P171; KONONENKO I, 1995, P ISSEK WORKSH MATH, P199; KONONENKO I, 1995, P WORKSH COMP AID DA; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Kukar M, 1996, ARTIF INTELL MED, V8, P431, DOI 10.1016/S0933-3657(96)00351-X; KUKAR M, 1998, ARTIF INTELL MED; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Lavrac N, 1997, INTELLIGENT DATA ANA; LAVRAC N, 1991, P 5 EUR WORK SESS LE, P265; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; LESMO L, 1982, APPROXIMATE REASONIN; LUCAS PJF, 1995, KNOWL ENG REV, V10, P153; Michie D, 1994, MACHINE LEARNING NEU; Mizoguchi F, 1997, KLUWER INT SER ENG C, V414, P227; MOZETIC I, UIUCDCSF85949 U ILL; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; Muggleton S., 1991, New Generation Computing, V8; NIBLETT T, 1986, RES DEV EXPERT SYSTE, V3, P24; NUNEZ M, 1990, CURRENT TRENDS KNOWL; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Pilih IA, 1997, KLUWER INT SER ENG C, V414, P131; PIRNAT V, 1989, P 2 EUR C ART INT ME, P24; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Richeldi M., 1995, P 8 EUR C MACH LEARN, P335; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SHANKLE WR, 1997, NTELLIGENT DATA ANAL, P149; SHANNON CE, 1948, AT&T TECH J, V27, P379; WETTSCHERECK D, 1994, THESIS OREGON STATE; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; Zelic I, 1997, J Med Syst, V21, P429, DOI 10.1023/A:1022880431298; ZUPAN B, 1997, P 6 C ART INT MED BE, P86	57	93	94	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAY	1999	16	1					3	23		10.1016/S0933-3657(98)00062-1		21	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	184DR	WOS:000079595400002	
J	Malhotra, MK; Sharma, S; Nair, SS				Malhotra, MK; Sharma, S; Nair, SS			Decision making using multiple models	EUROPEAN JOURNAL OF OPERATIONAL RESEARCH			English	Article						classification decisions; neural nets; multivariate techniques	NEURAL NETWORKS; IDENTIFICATION; SAVINGS; FAILURE	Many real world business situations require classification decisions that must often be made on the basis of judgment and past performance. In this paper, we propose a decision framework that combines multiple models or techniques in a complementary fashion to provide input to managers who make such decisions on a routine basis. We illustrate the framework by specifically using five different classification techniques-neural networks, discriminant analysis, quadratic discriminant analysis (QDA), k-nearest neighbor (KNN), and multinomial logistic regression analysis (MNL). Application of the decision framework to an actual retail department store data shows that it is most useful in those cases where uncertainty is high and a priori classification cannot be made with a high degree of reliability. The proposed framework thus enhances the value of exception reporting, and provides managers additional insights into the phenomenon being studied. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ S Carolina, Coll Business Adm, Dept Management Sci, Columbia, SC 29208 USA; Univ S Carolina, Coll Business Adm, Dept Mkt, Columbia, SC 29208 USA; Univ Missouri, Dept Mech & Aerosp Engn, Columbia, MO 65211 USA	Malhotra, MK (reprint author), Univ S Carolina, Coll Business Adm, Dept Management Sci, Columbia, SC 29208 USA.	malhotra@darla.badm.sc.edu					AFFIF AA, 1984, COMPUTER AIDED MULTI; Agresti A., 1990, CATEGORICAL DATA ANA; AGRESTI A, 1984, ANAL ORDINARY CATEGO; ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933; Altman E. I., 1977, J BANK FINANC, V1, P29, DOI 10.1016/0378-4266(77)90017-6; ARCHER NP, 1993, DECISION SCI, V24, P60, DOI 10.1111/j.1540-5915.1993.tb00462.x; BARTH JR, 1989, RES FINANCIAL SERVIC; BOOTH DE, 1989, DECISION SCI, V20, P320, DOI 10.1111/j.1540-5915.1989.tb01881.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dillon WR, 1984, MULTIVARIATE ANAL; Fishman MB, 1991, TECHNICAL ANAL S APR, P18; Freeman D. H., 1987, APPL CATEGORICAL DAT; Hand D. J., 1981, DISCRIMINATION CLASS; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; JOHNSON RA, 1988, APPL MULTIVARIATE AN; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MISTRY SI, 1994, IEEE CONTR SYST MAG, V14, P48, DOI 10.1109/37.291457; Nelson MM, 1991, PRACTICAL GUIDE NEUR; PANTALONE CC, 1987, AREUEA J, V15, P46; PATUWO E, 1993, DECISION SCI, V24, P825, DOI 10.1111/j.1540-5915.1993.tb00491.x; RAO VS, 1995, GROUP DECIS NEGOT, V4, P251, DOI 10.1007/BF01384691; Rumelhart D.E., 1987, PARALLEL DISTRIBUTED; SALCHENBERGER LM, 1992, DECISION SCI, V23, P899, DOI 10.1111/j.1540-5915.1992.tb00425.x; Sharma S., 1996, APPL MULTIVARIATE TE; SHARMA S, 1982, J MARKETING, V46, P104, DOI 10.2307/3203345; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; URBAN GL, 1992, DESIGNING MARKETING	28	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0377-2217		EUR J OPER RES	Eur. J. Oper. Res.	APR 1	1999	114	1					1	14		10.1016/S0377-2217(98)00037-X		14	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	167WU	WOS:000078657800001	
J	Krishna, V; Chandramouli, R; Ranganathan, N				Krishna, V; Chandramouli, R; Ranganathan, N			Computation of lower bounds for switching activity using decision theory	IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS			English	Article						CMOS circuits; decision theory; register transfer level; switching activity		Accurate switching-activity estimation is crucial for power budgeting. It is impractical to obtain an accurate estimate by simulating the circuit for all possible inputs. An alternate approach would be to compute tight bounds for the switching activity. In this paper, we propose a nonsimulative decision theoretic method to compute the tower bound for switching activity. First, we show that the switching activity can be modeled as the decision error of an abstract two-class problem. It is shown that the Bayes error L* is a lower bound for the switching activity. Further, we improve L* to obtain a tighter bound L-1, which is based on the one-nearest neighbor classification error, The proposed lower bounds are used for switching-activity characterization at the register transfer (RT) level. Experimental results for the RT-level switching-activity estimates for ISCAS'85 circuits are presented. This technique is simple and fast and produces accurate estimates.	Univ S Florida, Dept Comp Sci & Engn, Ctr Microelect Res, Tampa, FL 33620 USA	Krishna, V (reprint author), Univ S Florida, Dept Comp Sci & Engn, Ctr Microelect Res, Tampa, FL 33620 USA.	ranganat@csee.usf.edu					Berger J. O., 1985, STAT DECISION THEORY; CHEN Z, 1997, P IEEE INT C COMP AI, P40; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Marculescu D, 1996, IEEE T COMPUT AID D, V15, P599, DOI 10.1109/43.503930; Marculescu R, 1994, P INT C COMP AID DES, P294; Najm F., 1995, P DES AUT C, P623, DOI 10.1145/217474.217600; Nemani M, 1996, IEEE T COMPUT AID D, V15, P588, DOI 10.1109/43.503929; RAMPRASAD S, 1997, P INT C COMP AID DES, P126; Sentovich E., 1992, P INT C COMP DES OCT, P328, DOI 10.1109/ICCD.1992.276282; SHANBHAG N, 1996, P INT S LOW POW DES, P43, DOI 10.1109/LPE.1996.542728; YUAN LP, 1996, P ISLPED 96 ACM IEEE, P73	11	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1063-8210		IEEE T VLSI SYST	IEEE Trans. Very Large Scale Integr. (VLSI) Syst.	MAR	1999	7	1					125	129		10.1109/92.748209		5	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	172JZ	WOS:000078920900015	
J	Zheng, GL; Billings, SA				Zheng, GL; Billings, SA			An enhanced sequential fuzzy clustering algorithm	INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE			English	Article							VECTOR QUANTIZATION	A sequential fuzzy clustering algorithm is proposed based on a modification to the objective function used in the fuzzy competitive learning algorithm. The new learning algorithm can be used to enhance the excitation on the non-winning centroids and to reduce the excitation on the winning centroid when the fuzziness parameter is close to unit. The excitation on the winning centroid can be further reduced when the input pattern is far away from the winning centroid. An excitation-inhibition mechanism can also be introduced into the learning such that the non-winning centroids move towards the input pattern while the winning centroid moves away from the input pattern when the winning centroid is far away from the input pattern. The new algorithm overcomes the problem of underutilization of centroids found in the k-means or related clustering algorithms and in the fuzzy competitive learning algorithm when the fuzziness parameter is close to unity. The performance of the new algorithm is demonstrated on the IRIS data set.	Univ Sheffield, Dept Automat Control & syst Engn, Sheffield S1 3JD, S Yorkshire, England	Zheng, GL (reprint author), Univ Sheffield, Dept Automat Control & syst Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.						ANDERBERG MR, 1973, CLUSTERING ANAL APPL; Bezdek J., 1981, PATTERN RECOGNITION; CHINRUNGRUENG C, 1995, IEEE T NEURAL NETWOR, V6, P157, DOI 10.1109/72.363440; CHUNG FL, 1994, NEURAL NETWORKS, V7, P539; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EVERITT B, 1993, CLUSTERING ANAL; Fisher RA, 1936, ANN EUGENIC, V7, P179; Karayiannis NB, 1996, IEEE T NEURAL NETWOR, V7, P1062, DOI 10.1109/72.536304; AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R; Kohonen T., 1989, SELF ORG ASS MEMORY; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; PAL NR, 1993, IEEE T NEURAL NETWOR, V4, P549, DOI 10.1109/72.238310; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945	13	2	2	TAYLOR & FRANCIS LTD	LONDON	ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND	0020-7721		INT J SYST SCI	Int. J. Syst. Sci.	MAR	1999	30	3					295	307		10.1080/002077299292443		13	Automation & Control Systems; Computer Science, Theory & Methods; Operations Research & Management Science	Automation & Control Systems; Computer Science; Operations Research & Management Science	174NL	WOS:000079041200006	
J	Hattori, K; Takahashi, M				Hattori, K; Takahashi, M			A new nearest-neighbor rule in the pattern classification problem	PATTERN RECOGNITION			English	Article						nearest-neighbor rule; distance-weighted k-nearest neighbor rule; fuzzy k-nearest neighbor rule; leave one out technique; number of samples misclassified; pattern classification problems	ALGORITHM; SET	A new nearest-neighbor (NN) rule is proposed. In this rule, the ii-nearest neighbors of an input sample are obtained in each class. Two classification examples are presented to lest the NN rule proposed. The number of samples misclassified N-m is evaluated. The minimum of N-m in the the NN rule proposed is found to be nearly equal to or less than those in the k-NN, distance-weighted k-NN and fuzzy k-NN rules. The NN rule proposed is shown to be very flexible. It will yield good classification results, if the parameters introduced in it are optimized. (C) 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Toyohashi Univ Technol, Dept Elect & Elect Engn, Toyohashi, Aichi 441, Japan	Hattori, K (reprint author), Toyohashi Univ Technol, Dept Elect & Elect Engn, Tempaku Cho, Toyohashi, Aichi 441, Japan.						Anderson E., 1935, B AM IRIS SOC, V59, P2; BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; BOX GEP, 1964, J ROY STAT SOC B, V26, P211; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Duda R., 1973, PATTERN CLASSIFICATI; DUDANI SA, 1991, IEEE COMP SOC, P92; Fix E, 1951, DISCRIMINATORY ANAL; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; SAKIA RM, 1992, STATISTICIAN, V41, P169, DOI 10.2307/2348250; Shafer G., 1976, MATH THEORY EVIDENCE; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; VanderHeiden R, 1997, PATTERN RECOGN, V30, P273, DOI 10.1016/S0031-3203(96)00077-5; WHITNEY AW, 1966, P 4 ALL C CIRC SYST; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4	27	16	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	1999	32	3					425	432		10.1016/S0031-3203(98)00097-1		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	170NY	WOS:000078813500007	
J	Bagui, SC; Mehra, KL				Bagui, SC; Mehra, KL			Classification of multiple observations using multi-stage rank nearest neighbor rule	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						multiple measurement classification; rank nearest neighbor classification; multiple measurement discrimination		In this article, a multi-stage (M-stage) rank nearest-neighbor (MRNN)-type rule is proposed and studied for the classification of a sample of multiple (m) independent univariate observations between two populations. The asymptotic total probability of misclassification (TPMC) - viz., the asymptotic risk R-(M)(m) - for the proposed MRNN rule is derived. It is shown firstly that (i) the asymptotic risk R-(1)(2) of the 1st stage RNN rule for m = 2 is lower than the corresponding risk R-(1)(1) for m = 1, by a factor less than one, and secondly that (ii) for m = 2, the M-stage rule asymptotic risk R(M)(2) decreases as the number M of the stages employed increases. The former result leads to an improved upper bound on R-(1)(2) in terms of Bayes risk R*(1) (cf Cover and Hart (1967) IEEE Trans. Inform. Theory, Das Gupta and Lin (1980) Sankhya A). Also, a cross-validation-type estimator for the asymptotic risk R-(1)(m) is shown to be asymptotically unbiased and L-2-consistent. Finally, some comparative Monte-Carlo results are reported to illuminate the performance characteristics of the proposed rule in small sample situations. (C) 1999 Elsevier Science B.V. All rights reserved.	Univ W Florida, Dept Math & Stat, Pensacola, FL 32514 USA; Univ Alberta, Dept Math Sci, Edmonton, AB T6G 2G1, Canada							ANDERSON T, 1966, P 1 INT S AN NEW YOR; BAGUI SC, 1993, CALCUTTA STAT ASS B, V43, P45; BAGUI SC, 1995, SANKHYA A 2, V57, P316; BAGUI SC, 1998, STATIST, V16, P181; Bagui SC, 1997, J STAT PLAN INFER, V65, P323, DOI 10.1016/S0378-3758(97)00055-4; CHOI SC, 1972, BIOMETR Z, V14, P8, DOI 10.1002/bimj.19720140103; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1980, SANKHYA A, V42, P219; DASGUPTA S, 1964, SANKHYA A, V26, P25; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; FIX E, 1952, 4 US AIR FORC SCH AV; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GOVINDARAJULU Z, 1977, CAN J STAT, V5, P167, DOI 10.2307/3314775; GUPTA AK, 1986, COMPUT MATH APPL-A, V12, P301, DOI 10.1016/0898-1221(86)90082-9; GUPTA AK, 1990, J STAT COMPUT SIM, V34, P119, DOI 10.1080/00949659008811211; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; HUDIMOTO H, 1964, ANN I STAT MATH, V9, P31; LIN HE, 1979, SANKHYA B 2, V41, P41; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Serfling R. J, 1980, APPROXIMATION THEORE; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; XIRU C, 1985, SCENTIA SINICA A, V28, P673	23	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758		J STAT PLAN INFER	J. Stat. Plan. Infer.	FEB 1	1999	76	1-2					163	183		10.1016/S0378-3758(98)00137-2		21	Statistics & Probability	Mathematics	163UG	WOS:000078424300011	
J	Daelemans, W; Van den Bosch, A; Zavrel, J				Daelemans, W; Van den Bosch, A; Zavrel, J			Forgetting exceptions is harmful in language learning	MACHINE LEARNING			English	Article						memory-based learning; natural language learning; edited nearest neighbor classifier; decision-tree learning	ALGORITHMS; INDUCTION	We show that in language learning, contrary to received wisdom, keeping exceptional training instances in memory can be beneficial for generalization accuracy. We investigate this phenomenon empirically on a selection of benchmark natural language processing tasks: grapheme-to-phoneme conversion, part-of-speech tagging, prepositional-phrase attachment, and base noun phrase chunking. In a first series of experiments we combine memory-based learning with training set editing techniques, in which instances are edited based on their typicality and class prediction strength. Results show that editing exceptional instances (with low typicality or low class prediction strength) tends to harm generalization accuracy. In a second series of experiments we compare memory-based learning and decision-tree learning methods on the same selection of tasks, and find that decision-tree learning often performs worse than memory-based learning. Moreover, the decrease in performance can be linked to the degree of abstraction from exceptions (i.e., pruning or eagerness). We provide explanations for both results in terms of the properties of the natural language processing tasks and the learning algorithms.	Tilburg Univ, ILK Computat Linguist, NL-5000 LE Tilburg, Netherlands	Daelemans, W (reprint author), Tilburg Univ, ILK Computat Linguist, POB 90153, NL-5000 LE Tilburg, Netherlands.						Abney S., 1991, PRINCIPLE BASED PARS; AHA D. W., 1992, P 9 INT C MACH LEARN, P1; Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Baayen R. H., 1993, CELEX LEXICAL DATA B; Bod R, 1995, THESIS U AMSTERDAM; CARDIE C, 1996, P C EMP METH NLP U P; CARDIE C, 1993, AAAI 93, P798; CARDIE C, 1994, THESIS U MASSACHUSET; CHURCH KW, 1988, P 2 APPL NLP ACL; COLLINS M, 1995, P 3 WORKSH VER LARG; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1997, 9 EUR C MACH LEARN P, P29; DAELEMANS W, 1995, LECT NOTES ARTIF INT, V898, P85; DAELEMANS W, 1998, 9803 ILK; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; Daelemans W., 1992, P TWLT3 CONN NAT LAN, P27; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; DAELEMANS W, 1996, P CLS OP AC YEAR 199, P83; DAELEMANS WMP, 1996, PROGR SPEECH SYNTHES, P77; Dagan Ido, 1997, P 35 ANN M ASS COMP, P56; Danyluk A. P., 1993, P 10 INT C MACH LEAR, P81; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1980, P 5 INT C PATT REC I; DIETTERICH TG, 1998, IN PRESS NEURAL COMP; Domingos P, 1996, MACH LEARN, V24, P141; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Holte RC, 1989, P 11 INT JOINT C ART, P813; JONES D, 1996, ANALOGICAL NATURAL L, P430; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; Kolodner J., 1993, CASE BASED REASONING; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LEHNERT W, 1987, P 6 NAT C ART INT AA, P301; Magerman D., 1994, THESIS STANFORD U; Marcus M, 1994, COMPUTATIONAL LINGUI, V19, P313; Michie D, 1994, MACHINE LEARNING NEU; Mooney R. J., 1996, P C EMP METH NAT LAN, P82; MOONEY RJ, 1995, J ARTIF INTELL RES, V3, P1; NG HT, 1997, P 2 C EMP METH NAT L, P208; NG HT, 1996, P 34 M ASS COMP LING; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1007/BF00153762; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ramshaw L. A., 1995, P 3 WORKSH VER LARG, P82; Ratnaparkhi A, 1997, P 2 C EMP METH NAT L, P1; RATNAPARKHI A, 1994, WORKSH HUM LANG TECH; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; Salganicoff M., 1993, P 10 INT C MACH LEAR, P276; Salzberg S.L., 1990, LEARNING NESTED GEN; Scott P. D., 1988, P 5 INT C MACH LEARN, P459; Sejnowski T. J., 1987, Complex Systems, V1; SHAVLIK JW, 1991, MACH LEARN, V6, P111, DOI 10.1023/A:1022602303196; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STANFILL C, 1987, P 6 NAT C ART INT AA, P577; Ting K., 1994, P 10 CAN C ART INT, P91; TING KM, 1994, P 3 PAC RIM INT C AR, P360; VANDENBOSCH A, 1996, P 2 INT C NEW METH N, P79; VANDENBOSCH A, 1995, P 5 BELG DUTCH C MAC, P118; VOISIN J, 1987, PATTERN RECOGN, V5, P465; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; ZAVREL J, 1997, P WORKSH COMP LANG L; ZAVREL J, 1997, P 35 ANN M ACL MADR; Zhang J., 1992, P 9 INT MACH LEARN C, P470	68	56	56	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB	1999	34	1-3					11	41		10.1023/A:1007585615670		31	Computer Science, Artificial Intelligence	Computer Science	186WF	WOS:000079753100002	
J	Dagan, I; Lee, L; Pereira, FCN				Dagan, I; Lee, L; Pereira, FCN			Similarity-based models of word cooccurrence probabilities	MACHINE LEARNING			English	Article						statistical language modeling; sense disambiguation	SPARSE DATA; TESTS	In many applications of natural language processing (NLP) it is necessary to determine the likelihood of a given word combination. For example, a speech recognizer may need to determine which of the two word combinations "eat a peach" and "eat a peach" is more likely. Statistical NLP methods determine the likelihood of a word combination from its Frequency in a training corpus. However. the nature of language is such that many word combinations are infrequent and do not occur in any given corpus. In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on "most similar" words. We describe probabilistic word association models based on distributional word similarity, and apply them to two tasks, language modeling and pseudo-word disambiguation. In the language modeling task, a similarity-based model is used to improve probability estimates for unseen bigrams in a back-off language model. The similarity-based method yields a 20% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error. We also compare four similarity-based estimation methods against back-off and maximum-likelihood estimation methods on a pseudo-word sense disambiguation task in which we controlled for both unigram and bigram frequency to avoid giving too much weight to easy-to-disambiguate high-frequency configurations. The similarity-based methods perform up to 40% better on this particular task.	Bar Ilan Univ, Dept Math & Comp Sci, IL-52900 Ramat Gan, Israel; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; AT&T Bell Labs, Res, Florham Park, NJ 07932 USA	Dagan, I (reprint author), Bar Ilan Univ, Dept Math & Comp Sci, IL-52900 Ramat Gan, Israel.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atherton JC, 1997, ALIMENT PHARM THERAP, V11, P11, DOI 10.1046/j.1365-2036.11.s1.3.x; Brown P. F., 1992, Computational Linguistics, V18; CARDIE C, 1993, 11 NAT C ART INT MEN, P798; CHEN SF, 1996, 34 ANN M ACL SOM NEW, P310; Church K. W., 1991, Computer Speech and Language, V5, DOI 10.1016/0885-2308(91)90016-J; Church K. W., 1988, Second Conference on Applied Natural Language Processing; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAGAN I, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P164; Dagan I, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P56; DAGAN I, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P272; DAGAN I, 1995, COMPUT SPEECH LANG, V9, P123, DOI 10.1006/csla.1995.0008; Devroye L, 1996, PROBABILISTIC THEORY; Duda R., 1973, PATTERN CLASSIFICATI; Essen U., 1992, P ICASSP, V1, P161; FINCH S, 1993, THESIS U EDINBURGH; GALE W, 1992, FALL S PROB APPR NAT, P54; GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344; GREFENSTETTE G, 1992, INT C RES DEV INF RE, P89; Grefenstette G, 1994, EXPLORATIONS AUTOMAT; Grishman R., 1986, Computational Linguistics, V12; GRISMAN R, 1993, HUMAN LANGUAGE TECHN, P254; HINDLE D, 1990, 28TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P268; Jelinek F., 1980, P WORKSH PATT REC PR; JELINEK F, 1992, ADV SPEECH SIGNAL PR, P651; JIANG JJ, 1997, ROCLING 10 INT C TAI; KAROV Y, 1996, 4 WORKSH VER LARG CO, P42; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KNESER R, 1993, EUR C SPEECH COMM TE, P973; KULLBACK S, 1959, INFORMATION THEORY S; Lee Lillian, 1997, THESIS HARVARD U CAM; Lin DK, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P64; LIN D, 1998, MACH LEARN P 15 INT; LIN DY, 1991, STAT SINICA, V1, P1; LUK AK, 1995, 33 ANN M ACL SOM NEW, P181; Miller George A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; Ng H.T., 1996, 34 ANN M ACL SOM NEW, P40; NG HT, 1997, 2 C EMP METH NAT LAN, P208; PAUL DB, 1991, ARPA SPEECH NAT LANG, P284; PEREIRA F, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P183; Rao C. R., 1982, SANKHYA A, V44, P1; RESNIK P, 1992, WORKSH STAT BAS NAT, P56; Resnik P, 1995, 3 WORKSH VER LARG CO, P54; RUGE G, 1992, INFORM PROCESS MANAG, V28, P317, DOI 10.1016/0306-4573(92)90078-E; Saul L, 1997, 2 C EMP METH NAT LAN, P81; SCHUTZE H, 1992, FALL S PROB APPR NAT, P113; SCHUTZE H, 1992, SUPERCOMPUTING 92 : PROCEEDINGS, P787; Schutze H., 1993, ADV NEURAL INFORMATI, V5, P895; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Sugawara K., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8); UEBERLA JP, 1994, DRACISCSE1RN9413 FOR; Ushioda A., 1996, 4 WORKSH VER LARG CO, P28; WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000; YAROWSKY D, 1992, COLING 92, P454; Zavrel J, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P436	56	73	81	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB	1999	34	1-3					43	69		10.1023/A:1007537716579		27	Computer Science, Artificial Intelligence	Computer Science	186WF	WOS:000079753100003	
J	Andrecut, M				Andrecut, M			A statistical-fuzzy perceptron	MODERN PHYSICS LETTERS B			English	Article								An optimal statistical perceptron algorithm is derived using the Bayes classification theory. The described algorithm is able to construct an optimal classification hyperplane for separable and nonseparable classes. The described algorithm can be easily improved by imposing a simple fuzzyfication scheme of the training sets.	Int Ctr Theoret Phys, I-34100 Trieste, Italy; Univ Babes Bolyai, Fac Phys, R-3400 Cluj Napoca, Romania	Andrecut, M (reprint author), Int Ctr Theoret Phys, POB 586, I-34100 Trieste, Italy.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUMITRESCU D, 1993, FUZZY SET SYST, V56, P155, DOI 10.1016/0165-0114(93)90140-D; Fukunaga K, 1972, INTRO STAT PATTERN R; Gallant S. I., 1993, NEURAL NETWORK LEARN; ROSENBLATT F, 1962, PRINCIPLES NEURODINA; Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266	6	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0217-9849		MOD PHYS LETT B	Mod. Phys. Lett. B	JAN 10	1999	13	1					33	41		10.1142/S0217984999000063		9	Physics, Applied; Physics, Condensed Matter; Physics, Mathematical	Physics	183AB	WOS:000079529500005	
S	Lavrac, N		Horn, W; Shahar, Y; Lindberg, G; Andreassen, S; Wyatt, J		Lavrac, N			Machine learning for data mining in medicine	ARTIFICIAL INTELLIGENCE IN MEDICINE	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	Joint European Conference on Artificial Intelligence in Medicine and Medical Decision Making (AIMDM 99)	JUN 20-24, 1999	AALBORG, DENMARK				NEURAL NETWORKS; EXPERT-SYSTEM; BREAST-CANCER; FUZZY ARTMAP; DIAGNOSIS; RULES; CLASSIFICATION; PATHOLOGY; MODEL; CARE	Large collections of medical data are a valuable resource from which potentially new and useful knowledge can be discovered through data mining. This paper gives an overview of machine learning approaches used in mining of medical data, distinguishing between symbolic and sub-symbolic data mining methods, and giving references to applications of these methods in medicine. In addition, the paper presents selected measures for performance evaluation used in medical prediction and classification problems, proposing also some alternative measures for rule evaluation that can be used in ranking and filtering of induced rule sets.	Jozef Stefan Inst, Ljubljana 1000, Slovenia	Lavrac, N (reprint author), Jozef Stefan Inst, Jamova 39, Ljubljana 1000, Slovenia.	nada.lavrac@ijs.si					AAMODT A, 1994, AI COMMUN, V7, P39; Agrawal R., 1996, ADV KNOWLEDGE DISCOV, P307; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ASTION ML, 1992, ARCH PATHOL LAB MED, V116, P995; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Bradburn C, 1993, Comput Nurs, V11, P20; Breiman L, 1984, CLASSIFICATION REGRE; Brossette SE, 1998, J AM MED INFORM ASSN, V5, P373; CARPENTER GA, 1993, P WORLD C NEURAL NET, V1, P501; CARUANA R, 1995, NEURAL INFORMATION P, P7; Cestnik B., 1990, P EUR C ART INT, P147; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Compton P, 1989, APPL EXPERT SYSTEMS, P366; COMPTON P, 1988, SPRINGER LNAI, V406, P292; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Dehaspe L., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; DeRaedt L, 1997, MACH LEARN, V26, P99, DOI 10.1023/A:1007361123060; Downs J, 1996, ARTIF INTELL MED, V8, P403, DOI 10.1016/0933-3657(95)00044-5; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Dzeroski S, 1996, Technol Health Care, V4, P203; EDWARDS G, 1993, PATHOLOGY, V25, P27; Fausett L., 1994, FUNDAMENTALS NEURAL; FIX E, 1957, 4 US AIR FORC SCH AV; Ham FM, 1996, IEEE T BIO-MED ENG, V43, P425, DOI 10.1109/10.486263; HORN KA, 1985, AUST COMPUT J, V17, P7; KAHN CE, 1994, INVEST RADIOL, V29, P643, DOI 10.1097/00004424-199406000-00009; Kattan MW, 1997, KLUWER INT SER ENG C, V414, P295; Kohonen T., 1988, SELF ORG ASS MEMORY; KOMOROWSKI J, 1998, IN PRESS ARTIFICIAL; Kononenko I, 1998, MACHINE LEARNING DAT, P389; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LAVRAC N, 1999, IN PRESS AI COMMUNIC; Lavrac N, 1997, INTELLIGENT DATA ANA; LAVRAC N, 1999, IN PRESS ARTIFICIAL; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; LAVRAC N, 1999, UNPUB INT WORKSH IND; LIESTOL K, 1994, STAT MED, V13, P1189, DOI 10.1002/sim.4780131202; MACURA RT, 1997, ARTIFICIAL INTELLIGE, V9; Macura RT, 1997, ARTIF INTELL MED, V9, P1, DOI 10.1016/S0933-3657(96)00358-2; Mariuzzi GM, 1997, PATHOL RES PRACT, V193, P535; MCSHERRY D, 1997, P 6 C ART INT MED EU, P223; McSherry D, 1997, ARTIF INTELL MED, V10, P269, DOI 10.1016/S0933-3657(97)00396-5; Michalski R. S., 1983, MACH LEARN, V1, P83; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; Michie D, 1994, MACHINE LEARNING NEU; Modai I, 1996, J Med Syst, V20, P403, DOI 10.1007/BF02257284; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; NIBLETT T, 1986, RES DEV EXPERT SYSTE, V3, P24; PAWLAK Z, 1991, ROUGH SETS THEORET D, V9; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; POLOWSKI L, 1998, STUDIES FUZZINESS SO, V18; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Setiono R, 1996, ARTIF INTELL MED, V8, P37, DOI 10.1016/0933-3657(95)00019-4; Srinivasan A, 1997, KLUWER INT SER ENG C, V414, P243; Tsumoto S, 1998, LECT NOTES ARTIF INT, V1424, P475; WETTSCHERECK D, 1994, THESIS OREGON STATE; Wu CH, 1997, COMPUT CHEM, V21, P237, DOI 10.1016/S0097-8485(96)00038-1; Zhu Y, 1997, IEEE T MED IMAGING, V16, P55	66	15	15	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66162-X	LECT NOTES ARTIF INT			1999	1620						47	62				16	Computer Science, Artificial Intelligence	Computer Science	BP75N	WOS:000086071900004	
S	Blanzieri, E; Ricci, F		Althoff, KD; Bergmann, R; Branting, LK		Blanzieri, E; Ricci, F			Probability based metrics for Nearest Neighbor classification and Case-Based Reasoning	CASE-BASED REASONING RESEARCH AND DEVELOPMENT	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	3rd International Conference on Case-Based Reasoning (ICCBR-99)	JUL 27-30, 1999	SEEON MONASTERY, GERMANY	German Soc Comp Sci, Amer Assoc Artificial Intelligence, AcknoSoft, BSR Consulting, DaimlerChrysler, Fraunhofer Inst Exptl Software Engn, Inference Syst, Fraunhofer Inst Exptl Software Engn, Interact Multimedia Syst, Univ Kaiserslautern, Univ Wyoming				This paper is focused on a class of metrics for the Nearest Neighbor classifier, whose definition is based on statistics computed on the case base. We show that these metrics basically rely on a probability estimation phase. In particular, we reconsider a metric proposed in the 80's by Short and Fukunaga, we extend its definition to an input space that includes categorical features and we evaluate empirically its performance. Moreover, we present a novel probability based metric, called Minimum Risk Metric (MRM), i.e. a metric for classification tasks that exploits estimates of the posterior probabilities. MRM is optimal, in the sense that it optimizes the finite misclassification risk, whereas the Short and Fukunaga Metric minimizes the difference between finite risk and asymptotic risk. An experimental comparison of MRM with the Short and Fukunaga Metric, the Value Difference Metric, and Euclidean-Hamming metrics on benchmark datasets shows that MRM outperforms the other metrics. MRM performs comparably to the Bayes Classifier based on the same probability estimates. The results suggest that MRM can be useful in case-based applications where the retrieval of a nearest neighbor is required.	IRST, ITC, I-38050 Povo, TN, Italy	Blanzieri, E (reprint author), IRST, ITC, I-38050 Povo, TN, Italy.		Ricci, Francesco/H-3367-2012				AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; AHA DW, 1990, PROGRAM OF THE TWELFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P141; AVESANI P, 1999, IN PRESS APPL ARTIFI; BELLAZZI R, 1998, EUR WORKSH CAS BAS R; BLANZIERI E, 1996, 1 EUR WORKSH COGNITI; Burr Ridge I, 1997, MACHINE LEARNING; Cardie C., 1997, P 14 INT C MACH LEAR, P57; CAZZANI M, 1998, THESIS U MILANO; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; HASTIE T, 1995, KDD 95 P 1 INT C KNO; Kontkanen P, 1998, LECT NOTES ARTIF INT, V1488, P13; KONTKANEN P, 1998, LECT NOTES ARTIF INT, V1398, P77; Merz C. J., 1996, UCI REPOSITORY MACHI; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; RICCI F, 1999, IN PRESS IEEE T PATT; RICCI F, 1995, INT C CAS BAS REAS I; Scott D. W., 1992, MULTIVARIATE DENSITY; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WILSON DR, 1997, J ARTIFICIAL INTELLI, V11, P1	27	10	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66237-5	LECT NOTES ARTIF INT			1999	1650						14	28				15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BP13D	WOS:000084209300002	
J	Priebe, CE; Cowen, LJ				Priebe, CE; Cowen, LJ			A generalized Wilcoxon-Mann-Whitney statistic	COMMUNICATIONS IN STATISTICS-THEORY AND METHODS			English	Article						U-statistic; rank statistic; stochastic ordering; permutation test; subsample test; distribution-free test; Pitman's asymptotic relative efficiency; exact distribution; recurrence; generating function; discriminant analysis; classification		We develop a simple but useful generalization of the classical Wilcoxon-Mann-Whitney statistic. A normal approximation and a recurrence for the exact distribution of this generalization are available. The statistic has potential application in nonparametric discriminant analysis.	Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA			Priebe, Carey E./A-3305-2010				Ahmad IA, 1996, AM STAT, V50, P324, DOI 10.2307/2684929; Bartoszynski R, 1997, J AM STAT ASSOC, V92, P577, DOI 10.2307/2965706; BRUS T, 1989, STAT PROBABIL LETT, V7, P161; CHANG DK, 1992, STAT PROBABIL LETT, V13, P343, DOI 10.1016/0167-7152(92)90106-F; Cheung YK, 1997, STAT SINICA, V7, P805; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deshpande J. V., 1980, SANKHYA B, VB42, P236; Devroye L, 1996, PROBABILISTIC THEORY; DIBUCCHIANICO A, 1997, UNPUB COMPUTER ALGEB; Duda R., 1973, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED; KOCHAR SC, 1978, COMMUN STAT A-THEOR, V7, P1243, DOI 10.1080/03610927808827708; Kumar N, 1997, COMMUN STAT-THEOR M, V26, P943, DOI 10.1080/03610929708831960; Lehmann E.L., 1975, NONPARAMETRICS STAT; Maa JF, 1996, ANN STAT, V24, P1069; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Pitman EJG, 1949, LECT NOTES NONPARAME; PRIEBE CE, 1998, 585 J HOPK U DEP MAT; SHETTY ID, 1988, COMMUN STAT THEORY, V17, P2389; STEPHENSON RW, 1985, COMMUN STAT-THEOR M, V14, P1669; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; XIE J, 1999, IN PRESS J NONPAR ST	22	7	7	MARCEL DEKKER INC	NEW YORK	270 MADISON AVE, NEW YORK, NY 10016 USA	0361-0926		COMMUN STAT-THEOR M	Commun. Stat.-Theory Methods		1999	28	12					2871	2878		10.1080/03610929908832454		8	Statistics & Probability	Mathematics	263JU	WOS:000084122200005	
S	Luaces, O; del Coz, JJ; Quevedo, JR; Alonso, J; Ranilla, J; Bahamonde, A		Mira, J; SanchezAndres, JV		Luaces, O; del Coz, JJ; Quevedo, JR; Alonso, J; Ranilla, J; Bahamonde, A			Autonomous clustering for machine learning	FOUNDATIONS AND TOOLS FOR NEURAL MODELING, PROCEEDINGS, VOL I	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Work-Conference on Artificial and Natural Neural Networks (IWANN 99)	JUN 02-04, 1999	ALICANTE, SPAIN	Asociac Espanola Redes Neuronales, Univ Nacl Educ Distancia, Univ Miguel Hernandez, IFIP, Spanish RIG IEEE Neural Networks Council			RULES	In this paper, starting from a collection of training examples, we show how to produce a very compact set of classification rules. The induction idea is a clustering principle based on Kohonen's self-organizing algorithms. The function to optimize in the aggregation of examples to become rules is a classificatory quality measure called impurity level, which was previously employed in our system called FAN. The rule conditions obtained in this way are densely populated areas in the attribute space. The main goal of our system, in addition to its accuracy, is the high quality of explanations that it can provide attached to the classification decisions.	Univ Oviedo, Ctr Inteligencia Artificial, E-33271 Gijon, Spain	Luaces, O (reprint author), Univ Oviedo, Ctr Inteligencia Artificial, Campus Viesques, E-33271 Gijon, Spain.						Aha D.W., 1990, THESIS U CALIFORNIA; Bahamonde A, 1997, LECT NOTES COMPUT SC, V1240, P536; Blake CL, 1998, UCI REPOSITORY MACHI; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELCOZ JJ, 1999, SELF ORG CASES FIND; Fisher RA, 1936, ANN EUGENIC, V7, P179; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohonen T., 1995, SELF ORG MAPS; LUACES O, 1998, LECT NOTES ARTIF INT, V1416, P448; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RANILLA J, 1998, REV IBEROAMERICANA I, V4, P4; RANILLA J, 1998, FAN FINDING ACCURATE; Salzberg S.L., 1990, LEARNING NESTED GEN; SPIEGEL MR, 1970, ESTADISTICA	17	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66069-0	LECT NOTES COMPUT SC			1999	1606						497	506				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BQ95X	WOS:000165140200053	
S	del Coz, JJ; Luaces, O; Quevedo, JR; Alonso, J; Ranilla, J; Bahamonde, A		Mira, J; SanchezAndres, JV		del Coz, JJ; Luaces, O; Quevedo, JR; Alonso, J; Ranilla, J; Bahamonde, A			Self-organizing cases to find paradigms	FOUNDATIONS AND TOOLS FOR NEURAL MODELING, PROCEEDINGS, VOL I	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Work-Conference on Artificial and Natural Neural Networks (IWANN 99)	JUN 02-04, 1999	ALICANTE, SPAIN	Asociac Espanola Redes Neuronales, Univ Nacl Educ Distancia, Univ Miguel Hernandez, IFIP, Spanish RIG IEEE Neural Networks Council			RULES	Case-based information systems can be seen as lazy machine learning algorithms; they select a number of training instances and then classify unseen cases as the most similar stored instance. One of the main disadvantages of these systems is the high number of patterns retained. In this paper, a new method for extracting just a small set of paradigms from a set of training examples is presented. Additionally, we provide the set of attributes describing the representative examples that are relevant for classification purposes. Our algorithm computes the Kohonen self-organizing maps attached to the training set to then compute the coverage of each map node. Finally, a heuristic procedure selects both the paradigms and the dimensions (or attributes) to be considered when measuring similarity in future classification tasks.	Univ Oviedo, Ctr Inteligencia Artificial, E-33271 Gijon, Spain	del Coz, JJ (reprint author), Univ Oviedo, Ctr Inteligencia Artificial, Campus Viesques, E-33271 Gijon, Spain.						Aha D.W., 1990, THESIS U CALIFORNIA; Bahamonde A, 1997, LECT NOTES COMPUT SC, V1240, P536; Blake CL, 1998, UCI REPOSITORY MACHI; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohonen T., 1995, SELF ORG MAPS; LUACES O, 1998, LECT NOTES ARTIF INT, V1416, P448; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RANILLA J, 1998, REV IBEROAMERICANA I, V4, P4; RANILLA J, 1998, FAN FINDING ACCURATE; Salzberg S.L., 1990, LEARNING NESTED GEN; Skalak D.B., 1994, MACH LEARN P 11 INT, P293; SMYTH B, 1998, LECT NOTES ARTIF INT, V1416, P507; SPIEGEL MR, 1970, ESTADISTICA; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	19	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66069-0	LECT NOTES COMPUT SC			1999	1606						527	536				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BQ95X	WOS:000165140200056	
S	El-Maleh, K; Samouelian, A; Kabal, P			IEEE; IEEE	El-Maleh, K; Samouelian, A; Kabal, P			Frame level noise classification in mobile environments	ICASSP '99: 1999 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, PROCEEDINGS VOLS I-VI	International Conference on Acoustics Speech and Signal Processing (ICASSP)		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 99)	MAR 15-19, 1999	PHOENIX, AZ	IEEE, IEEE Signal Proc Soc				Background environmental noises degrade the performance of speech-processing systems (e.g. speech coding, speech recognition). By modifying the processing according to the type of background noise, the performance can be enhanced. This requires noise classification. In this paper, four pattern-recognition frameworks have been used to design noise classification algorithms. Classification is done on a frame-by-frame basis (e.g. once every 20 ms). Five commonly encountered noises in mobile telephony (i.e. car, street, babble, factory, and bus) have been considered in our study. Our experimental results show that the Line Spectral Frequencies (LSF's) are robust features in distinguishing the different classes of noises.	McGill Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada	El-Maleh, K (reprint author), McGill Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.						COUVREUR C, 1995, P EURONOISE 95 LYON, P1007; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; KATES JM, 1995, J ACOUST SOC AM, V97, P461, DOI 10.1121/1.412274; Kobayashi D., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.607143; LIU CS, 1990, P IEEE INT C AC SPEE, P277; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; RAUBER TW, 1994, THESIS U NOVA LISBOA; SAMOUELIAN A, 1997, COMPUTER SPEECH LANG, P161; VARGA AP, 1992, NOISE 92 STUDY EFFEC; WIGREN T, 1995, P IEEE INT C AC SPEE, P25; *ITU T, 1997, DEL 11 E WP 12 BACKG; *ITU T, 1997, C M 12 1 E LIST WORD	13	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149	0-7803-5041-3	INT CONF ACOUST SPEE			1999							237	240				4	Acoustics; Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Acoustics; Computer Science; Engineering	BM75N	WOS:000079690700060	
S	Brown, TX			IEEE'; IEEE'	Brown, TX			Classifying loss rates in broadband networks	IEEE INFOCOM '99 - THE CONFERENCE ON COMPUTER COMMUNICATIONS, VOLS 1-3, PROCEEDINGS: THE FUTURE IS NOW	IEEE INFOCOM SERIES		English	Proceedings Paper	18th Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM 99)	MAR 21-25, 1999	NEW YORK, NY	IEEE Comp Soc, IEEE Commun Soc			ETHERNET	Tasks such as admission control in ATM and predicting overload conditions in telephone networks require a function that specifies what conditions will result in loss rates exceeding a threshold, p*. This paper considers the formal task of deriving such a classification function based on samples at different conditions. When the size of these samples is small relative to 1/p*, previously proposed methods incorrectly classify conditions that surpass the threshold by orders of magnitude. This paper derives general conditions for consistent and robust classifiers and presents specific methods that meet these conditions. The paper analyzes the methods with respect to asymptotic and finite sample behavior and the results are confirmed using simulated data.	Univ Colorado, Dept Elect & Comp Engn, Boulder, CO 80309 USA	Brown, TX (reprint author), Univ Colorado, Dept Elect & Comp Engn, Boulder, CO 80309 USA.						Bishop C.M., 1992, NEURAL NETWORKS PATT; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; BROWN TX, 1997, 5 IFIP WORKSH PERF M; BROWN TX, 1995, P INT W APPL NEURAL, V2, P153; Brown TX, 1997, ADV NEUR IN, V9, P932; CLOPPER CS, 1934, BIOMETRIKA, V26, P21; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DVORETZKY A, 1956, ANN MATH STAT, V27, P642, DOI 10.1214/aoms/1177728174; ESTRELLA AD, 1994, ELECTRON LETT, V30, P577, DOI 10.1049/el:19940371; GAENNSSLER P, 1986, ENCY STAT SCI, V3, P443; Garrett M., 1994, P ACM SIGCOMM 94 LON, P269, DOI 10.1145/190314.190339; HEFFES H, 1986, IEEE J SEL AREA COMM, V4, P856, DOI 10.1109/JSAC.1986.1146393; Heyman DP, 1996, IEEE ACM T NETWORK, V4, P40, DOI 10.1109/90.503760; Hiramatsu A, 1990, IEEE Trans Neural Netw, V1, P122, DOI 10.1109/72.80211; HIRAMATSU A, 1995, IEEE COMM MAG    OCT, P58; HUI T, 1998, GLOBECOM 98 SYDN 8 1; LELAND WE, 1994, IEEE ACM T NETWORK, V2, P1, DOI 10.1109/90.282603; Matsunawa T., 1986, ENCY STAT SCI, V7, P20; Paxson V., 1994, P ACM SIGCOMM 94 LON, P257, DOI 10.1145/190314.190338; Schwartz M., 1987, TELECOMMUNICATION NE; TRANGIA P, P GLOBECOM 92 ORL, V92, P1303; 1982, ENCY STAT SCI, V2, P21	23	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-166X	0-7803-5417-6	IEEE INFOCOM SER			1999							361	370		10.1109/INFCOM.1999.749303		10	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BM70K	WOS:000079541500043	
B	Blanzieri, E; Ricci, F		Bratko, I; Dzeroski, S		Blanzieri, E; Ricci, F			A minimum risk metric for Nearest Neighbor classification	MACHINE LEARNING, PROCEEDINGS			English	Proceedings Paper	16th International Conference on Machine Learning (ICML 99)	JUN 27-30, 1999	BLED, SLOVENIA	HERMES SoftLab, DaimlerChrysler Res & Technol Ctr, JerovsekComp, Jozef Stefan Inst, Micro Res, MLNET-II ESPRIT IV Project 29288, Slovenian Minist Sci & Technol, TEMIDA, TSE TRADE				Nearest Neighbor is a well-known algorithm extensively studied by the Pattern Recognition and Machine Learning communities and widely exploited in Case Based Reasoning applications. The notion of metric is central to Nearest Neighbor's working and different feature weighting metrics have been proposed in order to increase its performance. In this work we present an original Probability Based Metric, i.e. a metric for classification tasks that relies on estimates of the posterior probabilities, called Minimum Risk Metric (MRM). MRM is optimal but it optimizes directly the finite misclassification risk whereas the Short and Fukunaga Metric minimize the difference between finite risk and asymptotic risk. An experimental comparison of MRM with Short and Fukunaga Metric, Value Difference Metric, and Euclidean-Hamming metrics on benchmark datasets shows that MRM outperforms the other metrics and performs comparably to the Bayes Classifier based on the same probability estimates. The results suggests that MRM can be useful in applications were the retrieval of a nearest neighbor is required (e.g. Case Based Reasoning).	ITC IRST, I-38050 Trent, Italy	Blanzieri, E (reprint author), ITC IRST, Via Sommarive, I-38050 Trent, Italy.						AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; AHA DW, 1990, PROGRAM OF THE TWELFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P141; Bellazzi R, 1998, LECT NOTES ARTIF INT, V1488, P64; BLANZIERI E, 1996, 18 COGN SCI C, P501; Burr Ridge I, 1997, MACHINE LEARNING; Cardie C., 1997, P 14 INT C MACH LEAR, P57; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FRIEDMAN JH, 1994, FLEXIBLE METRIC NEIG; HASTIE T, 1995, KDD95 P 1 INT C KNOW; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Randall John E., 1997, National Science Museum Monographs, V11, P1; RICCI F, 1998, IEEE T PATT AN MACH; RICCI F, 1995, INT C CAS BAS REAS I; Scott D. W., 1992, MULTIVARIATE DENSITY; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SHORT RD, 1990, P 5 IEEE INT C PATT, P81; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658	23	0	0	MORGAN KAUFMANN PUB INC	SAN FRANCISCO	340 PINE STR, 6TH FLR, SAN FRANCISCO, CA 94104-3205 USA		1-55860-612-2				1999							22	31				10	Computer Science, Artificial Intelligence	Computer Science	BV38D	WOS:000178755300003	
S	Talukder, A; Casasent, D		Casasent, DP; Chao, TH		Talukder, A; Casasent, D			Nonlinear features for product inspection	OPTICAL PATTERN RECOGNITION X	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Optical Pattern Recognition X	APR 07-08, 1999	ORLANDO, FL	SPIE - Int Soc Opt Engn		classification; discrimination; detection; feature extraction; k nearest neighbor classifier (modified); nonlinear features; product inspection; X-ray sensors	X-RAY IMAGES; MACHINE RECOGNITION; CLASSIFICATION; REPRESENTATION; DAMAGE	Classification of real-time X-ray images of randomly oriented touching pistachio nuts is discussed. The ultimate objective is the development of a system for automated non-invasive detection of defective product items on a conveyor belt. We discuss the extraction of new features that allow better discrimination between damaged and clean items (pistachio nuts). This feature extraction and classification stage is the new aspect of this paper; our new maximum representation and discriminating feature (MRDF) extraction method computes nonlinear features that are used as inputs to a new modified k nearest neighbor classifier. In this work, the MRDF is applied to standard features (rather than iconic data). The MRDF is robust to various probability distributions of the input class and is shown to provide good classification and new ROC (receiver operating characteristic) data.	Carnegie Mellon Univ, Dept Elect & Comp Engn, Lab Opt Data Proc, Pittsburgh, PA 15213 USA	Talukder, A (reprint author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Lab Opt Data Proc, Pittsburgh, PA 15213 USA.						Casasent D, 1997, P SOC PHOTO-OPT INS, V3205, P46, DOI 10.1117/12.285589; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; DUDANI SA, 1991, NEAREST NEIGHBOR NOR, P92; Faux ID, 1979, COMPUTATIONAL GEOMET; Fisher R. A., 1950, CONTRIBUTIONS MATH S; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; HAMAMOTO Y, 1993, PATTERN RECOGN, V26, P1863, DOI 10.1016/0031-3203(93)90183-W; KARHUNEN J, 1994, NEURAL NETWORKS, V7, P113, DOI 10.1016/0893-6080(94)90060-4; Keagy PM, 1996, P SOC PHOTO-OPT INS, V2907, P196, DOI 10.1117/12.262859; KEAGY PM, 1993, CEREAL CHEM, V70, P696; Keagy PM, 1996, FOOD SCI TECHNOL-LEB, V29, P140; Lippmann R.P., 1987, IEEE ASSP MAG, V4, P4; SAS Institute, 1988, SAS STAT US GUID REL; SCHATZKI TF, 1996, P SOC PHOT INSTR ENG, V2907; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TALUKDER A, 1998, P SPIE, V3543; Talukder A, 1998, OPT ENG, V37, P904, DOI 10.1117/1.601925; Talukder A, 1998, P SOC PHOTO-OPT INS, V3390, P12, DOI 10.1117/12.304801; TAYLOR JG, 1993, NEURAL NETWORKS, V6, P423, DOI 10.1016/0893-6080(93)90009-L; TOMEK I, 1991, NEAREST NEIGHBOR NOR, P86; VANHORN KS, 1994, NEURAL NETWORKS, V7, P491, DOI 10.1016/0893-6080(94)90082-5; Wilks S.S., 1962, MATH STAT	23	4	4	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-3189-3	P SOC PHOTO-OPT INS			1999	3715						32	43		10.1117/12.341305		12	Computer Science, Artificial Intelligence; Optics	Computer Science; Optics	BM94Q	WOS:000080212700003	
J	Egmont-Petersen, M; Pelikan, E				Egmont-Petersen, M; Pelikan, E			Detection of bone tumours in radiographic images using neural networks	PATTERN ANALYSIS AND APPLICATIONS			English	Article						bone tumours; feature selection; feed-forward neural network; quality assessment; self-organising feature map; texture	RECOGNITION; CLASSIFIERS; DIAGNOSIS; SYSTEM	We develop an approach for segmenting radiographic images of focal bone lesions possibly caused by bone tumour. A neural network is used to classify individual pixels by a convolution operation based on a feature vector. We design eight features chat characterise the local texture in the neighbourhood of a pixel. Four of the features are based on co occurrence matrices computed from the neighbourhood. The true class label of the pixels in the radiographs are obtained from annotations made by an experienced radiologist. Neural networks and self-organising feature maps are trained to perform the segmentation cask. The experiments confirm che feasibility of using a feature-based neural network for finding pathologic bone changes in radiographic images. An analysis of the eight features indicates that the presence of edges and transitions, the complexity of the texture, as well as the amount of high frequencies in che texture, are che main features discriminating (soft) tissue from pathologic bone, the two classes most likely to be confused.	Leiden Univ, Ctr Med, Div Image Proc, Dept Radiol, NL-2300 RC Leiden, Netherlands; Philips Med Syst, Sci Tech Dept, Hamburg, Germany	Egmont-Petersen, M (reprint author), Leiden Univ, Ctr Med, Div Image Proc, Dept Radiol, C2-S,POB 9600, NL-2300 RC Leiden, Netherlands.						Bajaj R, 1997, PATTERN RECOGN, V30, P1, DOI 10.1016/S0031-3203(96)00059-3; BOHNDORF K, 1993, ZENTRALBLATT RADIOLO, V147, P987; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; EGMONTPETERSEN M, 1996, NETWORKS MED; Egmont-Petersen M, 1998, NEURAL NETWORKS, V11, P623, DOI 10.1016/S0893-6080(98)00031-8; Egmont-Petersen M, 1994, Artif Intell Med, V6, P359, DOI 10.1016/0933-3657(94)90002-7; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; Freyschmidt J, 1988, KNOCHENTUMOREN KLIN; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Hand D. J., 1981, DISCRIMINATION CLASS; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARRISON RF, 1991, P 3 EUR C ART INT ME, P119; HART A, 1989, P AIME 89, P115; Heikkonen J, 1996, PATTERN RECOGN LETT, V17, P413, DOI 10.1016/0167-8655(95)00136-0; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Huang K., 1997, Pattern Recognition, V30, DOI 10.1016/S0031-3203(96)00063-5; IFTEKHARUDDIN KM, 1995, OPT ENG, V34, P3193, DOI 10.1117/12.213654; ITOH K, 1994, COMPUT METH PROG BIO, V43, P15, DOI 10.1016/0169-2607(94)90179-1; JAVIDI B, 1995, APPL OPTICS, V34, P3950, DOI 10.1364/AO.34.003950; Jorgensen TM, 1996, PATTERN RECOGN LETT, V17, P399, DOI 10.1016/0167-8655(95)00135-2; KEPUSKA VZ, 1995, PHOTOGRAMM ENG REM S, V61, P917; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1991, P ART NEUR NETW, P951; LODWICK GS, 1969, RONTGENBLATT, V22, P162; NOBIS T, 1994, BERUCKSICHTIGUNG LOK; PELIKAN E, 1994, P DAGM GERM C PATT R, P589; PELIKAN E, 1995, TEXTURORIENTIERTE SE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REINUS WR, 1994, INVEST RADIOL, V29, P606, DOI 10.1097/00004424-199406000-00002; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Riede UN, 1989, ALLGEMEINE SPEZIELLE; Serpico SB, 1996, PATTERN RECOGN LETT, V17, P1331, DOI 10.1016/S0167-8655(96)00090-6; Sklansky J, 1996, INT J PATTERN RECOGN, V10, P587, DOI 10.1142/S0218001496000360; SORGEL W, 1998, P BILDV MED, P179; Stassopoulou A, 1996, PATTERN RECOGN LETT, V17, P1325, DOI 10.1016/S0167-8655(96)00089-X; TALMON JL, 1986, PATTERN RECOGN LETT, V4, P31, DOI 10.1016/0167-8655(86)90070-X; VOGELSANG F, 1993, P WORKSH NEUR NETW R, P201; VOGELSANG F, 1993, P DAGM GERM C PATT R, P450; WEILER F, 1993, P DAGM, P460	40	13	13	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.		1999	2	2					172	183		10.1007/s100440050026		12	Computer Science, Artificial Intelligence	Computer Science	256CE	WOS:000083707400007	
J	Cordella, LP; Foggia, P; Sansone, C; Tortorella, F; Vento, M				Cordella, LP; Foggia, P; Sansone, C; Tortorella, F; Vento, M			Reliability parameters to improve combination strategies in multi-expert systems	PATTERN ANALYSIS AND APPLICATIONS			English	Article						classification reliability; combining rules; multi-expert systems; neural nets; OCR; statistical classifiers	CLASSIFICATION; CLASSIFIERS; RECOGNITION	Recognition systems based on a combination of different experts have been widely investigated in the recent: past. General criteria for improving the performance of such systems are based on estimating the reliability associated with the decision of each expert, so as to suitably weight its response in the combination phase. According to the methods proposed to-date, when the expert assigns a sample to a class, the reliability of such a decision is estimated on the basis of the recognition rate obtained by the expert on the chosen class during the training phase. As a consequence, the same reliability value is associated with every decision attributing a sample to a same class, even though it seems reasonable ro take into account: its dependence on the quality of the specific sample. We propose a method for estimating the reliability of each single recognition act of an expert on the basis of information directly derived from its output. In this way, the reliability value of a decision is more properly estimated, thus allowing a more precise weighting during the combination phase. The definition of the reliability parameters for widely used classification paradigms is discussed, together with the combining rules employing them for weighting the expert opinions. The results obtained by combining four experts in order to recognise handwritten numerals from a standard character database are presented. Comparison with classical combining rules is also reported, and the advantages of the proposed approach outlined.	Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy; Univ Cassino, Dipartimento Automaz Elettromagnetismo Ingn Infor, I-03043 Cassino, Italy	Cordella, LP (reprint author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.		Tortorella, Francesco/F-5964-2010				ACKERMANN B, 1996, IAM96002 U BERN; Anderson J. A., 1988, NEUROCOMPUTING FDN R; Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860; CHO SB, 1995, IEEE T SYST MAN CYB, V25, P380; CORDELLA LP, 1995, MACH VISION APPL, V8, P336, DOI 10.1007/s001380050014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASRATHY B, 1990, NEAREST NEIGHBOR PAT; Fu K. S., 1974, SYNTACTIC METHODS PA; Fukunaga K., 1990, INTRO STAT PATTERN R; Hall D., 1992, MATH TECHNIQUES MULT; HUANG TS, 1995, ENVIRON GEOCHEM HLTH, V17, P1; Jacobs R. A., 1991, NEURAL COMPUT, V3, P1; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KITTLER J, 1997, PROGR HANDWRITING RE, P231; LAM L, 1994, P 4 INT WORKSH FRONT, P245; LAM L, 1995, PATTERN RECOGN LETT, V16, P945, DOI 10.1016/0167-8655(95)00050-Q; LEE DS, 1995, P 3 INT C DOC AN REC, P42; Lippmann R.P., 1987, IEEE ASSP MAG, V4, P4; Pavlidis T., 1977, STRUCTURAL PATTERN R; Powalka RK, 1996, HANDWRITING AND DRAWING RESEARCH, P329; Rahman AFR, 1997, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, P886, DOI 10.1109/ICDAR.1997.620639; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	24	47	47	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.		1999	2	3					205	214		10.1007/s100440050029		10	Computer Science, Artificial Intelligence	Computer Science	256CF	WOS:000083707500001	
J	Foggia, P; Sansone, C; Tortorella, F; Vento, M				Foggia, P; Sansone, C; Tortorella, F; Vento, M			Definition and validation of a distance measure between structural primitives	PATTERN ANALYSIS AND APPLICATIONS			English	Article						character recognition; circular arcs; graph matching; nearest neighbour classifier; optical character recognition; shape distance; structural descriptions	PATTERN-RECOGNITION; IMAGE; SYSTEM; SEARCH	This paper proposes a structural description scheme using second order primitives, in particular circular arcs. In this framework, a distance measure between pairs of circular arcs and relations among them is introduced, and its main properties are discussed. This measure accomplishes some perceptive criteria for increasing its efficiency: it proved applicable in a wide class of application domains characterised by high variability in the shape of the visual patterns, where a structural approach is particularly useful. The description method together with the distance have been experimentally validated in the context of the recognition of handwritten digits coming from a standard character database.	Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy; Univ Cassino, Dipartimento Automaz Elettromagnetismo Ingn Infor, I-03043 Cassino, Italy	Vento, M (reprint author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.		Tortorella, Francesco/F-5964-2010				ARCELLI C, 1994, HUMAN MACHINE VISION; ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; BUNKE H, 1995, LECT NOTES COMPUTER, V974; CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358; CORDELLA LP, 1994, ASPECTS VISUAL FORM; CORDELLA LP, 1995, MACH VISION APPL, V8, P336, DOI 10.1007/s001380050014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604; HOWELL GW, 1993, CVGIP-GRAPH MODEL IM, V55, P89; KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0; Nilsson N. J., 1982, PRINCIPLES ARTIFICIA; Nishida H, 1996, COMPUT VIS IMAGE UND, V64, P248, DOI 10.1006/cviu.1996.0057; PEI SC, 1995, PATTERN RECOGN, V28, P107, DOI 10.1016/0031-3203(94)00086-2; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; RUSSEL FJ, 1992, P 10 EUR C ART INT V, P1; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P505; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7, P90; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48; Wang YK, 1997, IEEE T SYST MAN CY B, V27, P588; WEST GAW, 1991, PATTERN RECOGN, V24, P643, DOI 10.1016/0031-3203(91)90031-Y; 1993, 2 INT C DOC AN REC	25	3	3	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.		1999	2	3					215	227		10.1007/s100440050030		13	Computer Science, Artificial Intelligence	Computer Science	256CF	WOS:000083707500002	
S	Talukder, A; Casasent, D; Lee, HW; Keagy, PM; Schatzki, TF		Meyer, GE; DeShazer, JA		Talukder, A; Casasent, D; Lee, HW; Keagy, PM; Schatzki, TF			A new feature extraction method for classification of agricultural products from X-ray images	PRECISION AGRICULTURE AND BIOLOGICAL QUALITY	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Precision Agriculture and Biological Quality	NOV 03-04, 1998	BOSTON, MA	SPIE-Int Soc Opt Engn		classification; discrimination; detection; feature extraction; K nearest neighbor classifier (modified); nonlinear features; product inspection; X-ray sensors	MACHINE RECOGNITION; DAMAGE	Classification of real-time X-ray images of randomly oriented touching pistachio nuts is discussed. The ultimate objective is the development of a system for automated non-invasive detection of defective product items on a conveyor belt. We discuss the extraction of new features that allow better discrimination between damaged and clean items (pistachio nuts). This feature extraction and classification stage is the new aspect of this paper; our new maximum representation and discriminating feature (MRDF) extraction method computes nonlinear features that are used as inputs to a new modified k nearest neighbor classifier. In this work, the MRDF is applied to standard features (rather than iconic data). The MRDF is robust to various probability distributions of the input class and is shown to provide good classification and new ROC (receiver operating characteristic) data.	Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Talukder, A (reprint author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.						Casasent D, 1997, P SOC PHOTO-OPT INS, V3205, P46, DOI 10.1117/12.285589; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; DUDANI SA, 1991, NEAREST NEIGHBOR NOR, P92; Faux ID, 1979, COMPUTATIONAL GEOMET; Fisher R. A., 1950, CONTRIBUTIONS MATH S; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; HAMAMOTO Y, 1993, PATTERN RECOGN, V26, P1863, DOI 10.1016/0031-3203(93)90183-W; KARHUNEN J, 1994, NEURAL NETWORKS, V7, P113, DOI 10.1016/0893-6080(94)90060-4; Keagy PM, 1996, P SOC PHOTO-OPT INS, V2907, P196, DOI 10.1117/12.262859; KEAGY PM, 1993, CEREAL CHEM, V70, P696; Keagy PM, 1996, FOOD SCI TECHNOL-LEB, V29, P140; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; SAS Institute, 1988, SAS STAT US GUID REL; SCHATZKI TF, 1996, P SOC PHOTOOPTICAL I, V2905; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TALUKDER A, 1998, P SPIE, V8543; Talukder A, 1998, OPT ENG, V37, P904, DOI 10.1117/1.601925; Talukder A, 1998, P SOC PHOTO-OPT INS, V3390, P12, DOI 10.1117/12.304801; TAYLOR JG, 1993, NEURAL NETWORKS, V6, P423, DOI 10.1016/0893-6080(93)90009-L; TOMEK I, 1991, NEAREST NEIGHBOR NOR, P86; VANHORN KS, 1994, NEURAL NETWORKS, V7, P491, DOI 10.1016/0893-6080(94)90082-5; Wilks S.S., 1962, MATH STAT	23	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-3155-9	P SOC PHOTO-OPT INS			1999	3543						119	130		10.1117/12.336874		12	Agronomy; Biology	Agriculture; Life Sciences & Biomedicine - Other Topics	BM50V	WOS:000078921900014	
S	Brighton, H; Mellish, C		Zytkow, JM; Rauch, J		Brighton, H; Mellish, C			On the consistency of information filters for lazy learning algorithms	PRINCIPLES OF DATA MINING AND KNOWLEDGE DISCOVERY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	3rd European Conference on Principles of Data Mining and Knowledge Discovery in Databases (PKDD 99)	SEP 15-18, 1999	PRAGUE, CZECH REPUBLIC	Komercni Banka	UNIV ECON, LAB INTELLIGENT SYST			A common practice when filtering a case-base is to employ a filtering scheme that decides which cases to delete, as well as how many cases to delete, such that the storage requirements are minimized and the classification competence is preserved or improved. We introduce an algorithm that rivals the most successful existing algorithm in the average case when filtering 30 classification problems. Neither algorithm consistently outperforms the other, with each performing well on different problems. Consistency over many domains, we argue, is very hard to achieve when deploying a filtering algorithm.	SHARP Labs Europe Ltd, Oxford, England; Univ Edinburgh, Dept Artificial Intelligence, Edinburgh EH8 9YL, Midlothian, Scotland	Brighton, H (reprint author), SHARP Labs Europe Ltd, Oxford Sci Pk, Oxford, England.		Brighton, Henry/A-3504-2011				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BRIGHTON H, 1996, THESIS U EDINBURGH S; BRIGHTON H, 1997, THESIS U EDINBURGH S; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Merz C. J., 1996, UCI REPOSITORY MACHI; SMYTH B, 1995, INT JOINT C ART INT, V1, P377; VANDENBOSCH A, 1998, P NEMLAP3 CONLL98, P195, DOI 10.3115/1603899.1603933; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 1997, MACHINE LEARNING	9	12	13	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-66490-4	LECT NOTES ARTIF INT			1999	1704						283	288				6	Computer Science, Artificial Intelligence	Computer Science	BS61Q	WOS:000170570600031	
B	Gionis, A; Indyk, P; Motwani, R		Atkinson, M; Orlowska, ME; Valduriez, P; Zdonik, S; Brodie, M		Gionis, A; Indyk, P; Motwani, R			Similarity search in high dimensions via hashing	PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES			English	Proceedings Paper	25th International Conference on Very Large Data Bases	SEP 07-10, 1999	EDINBURGH, SCOTLAND	ORACLE, Sun Microsyst, IBM, Microsoft SQL Server, Scottish Widows			NEIGHBOR	The nearest- or near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately, all known techniques for solving this problem fall prey to the "curse of dimensionality." That is, the data structures scale poorly with data dimensionality; in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should suffice for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our method gives significant improvement in running time over other methods for searching in high-dimensional spaces based on hierarchical tree decomposition. Experimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50).	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Gionis, A (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.		Gionis, Aristides/G-2225-2013	Gionis, Aristides/0000-0002-5211-112X			ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Arya S, 1996, DISCRETE COMPUT GEOM, V16, P155, DOI 10.1007/BF02716805; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BERCHTOLD S, 1998, P ACM SIGMOD, P501, DOI 10.1145/276304.276353; Chan T. M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, DOI 10.1145/262839.263001; CHAUDHURI S, P SIGMOD 98, P436; CIACCIA P, P PODS 98, P59; COHEN E, FINDING INTERESTING; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Duda R., 1973, PATTERN CLASSIFICATI; Edelsbrunner H., 1987, ALGORITHMS COMBINATO; FALOUTSOS C, 1995, CSTR3514 U MAR DEP C; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, DOI 10.1007/BF00962238; FIGIEL T, 1977, ACTA MATH-DJURSHOLM, V139, P53, DOI 10.1007/BF02392234; Flickner M., 1995, IEEE COMPUT, V28, P23; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gersho A, 1991, VECTOR QUANTIZATION; HASTIE T, 1995, P 1 INT C KNOWL DISC, P142; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; INDYK P, FINDING PIRATED VIDE; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; KANTH KVR, P SIGMOD, P166; KARHUNEN K, 1947, ANN ACAD SCI FENNI A, V137; KATAYAMA N, P SIGMOD 97, P369; KOIVUNE V, 1995, IEEE WORKSH NONL SIG; Linial N., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), DOI 10.1109/SFCS.1994.365733; Love M., 1948, PROCESSUS STOCHASTIQ; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MANKU GS, P SIGMOD 98, P426; MATIAS Y, P SIGMOD 98, P448; Motwani R., 1995, RANDOMIZED ALGORITHM; OTTERMAN M, 1992, APPROXIMATE MATCHING; PENTLAND A, 1994, P SPIE C STOR RETR I, V2; SALTON G, 1983, INTRO MODERN INFORMA; Samet H., 1989, DESIGN ANAL SPATIAL; Sellis T, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P13; SMEULDERS AWM, 1996, P 1 INT WORKSH; Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578; Smith J.R, 1997, THESIS COLUMBIA U; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Wyszecki G., 1982, COLOR SCI CONCEPTS M	44	209	236	MORGAN KAUFMANN PUB INC	SAN FRANCISCO	340 PINE STR, 6TH FLR, SAN FRANCISCO, CA 94104-3205 USA		1-55860-615-7				1999							518	529				4	Computer Science, Information Systems	Computer Science	BQ81V	WOS:000089669900049	
S	Ishibuchi, H; Nakashima, T		McKay, B; Yao, X; Newton, CS; Kim, JH; Furuhashi, T		Ishibuchi, H; Nakashima, T			Evolution of reference sets in nearest neighbor classification	SIMULATED EVOLUTION AND LEARNING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd Asia-Pacific Conference on Simulated Evolution and Learning (SEAL 98)	NOV 24-27, 1998	CANBERRA, AUSTRALIA			genetic algorithms; pattern classification; nearest neighbor classification; combinatorial optimization; multi-objective optimization; knowledge discovery	GENETIC ALGORITHMS	This paper proposes a genetic-algorithm-based approach for finding a compact reference set used in nearest neighbor classification. The reference set is designed by selecting a small number of reference patterns from a large number of training patterns using a genetic algorithm. The genetic algorithm also removes unnecessary features. The reference set in our nearest neighbor classification consists of selected patterns with selected features. A binary string is used for representing the inclusion (or exclusion) of each pattern and feature in the reference set. Our goal is to minimize the number of selected patterns, to minimize the number of selected features, and to maximize the classification performance of the reference set. The effectiveness of our approach is examined by computer simulations on commonly used data sets.	Univ Osaka Prefecture, Dept Ind Engn, Sakai, Osaka 5998531, Japan	Ishibuchi, H (reprint author), Univ Osaka Prefecture, Dept Ind Engn, Gakuen Cho 1-1, Sakai, Osaka 5998531, Japan.		Ishibuchi, Hisao/B-3599-2009	Ishibuchi, Hisao/0000-0001-9186-6472			CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ishibuchi H, 1997, FUZZY SET SYST, V89, P135, DOI 10.1016/S0165-0114(96)00098-X; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Knight L., 1995, P 6 INT C GEN ALG, P429; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; NAKASHIMA T, 1998, P INT C EV COMP, P709; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	13	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-65907-2	LECT NOTES ARTIF INT			1999	1585						82	89				8	Computer Science, Artificial Intelligence	Computer Science	BP96U	WOS:000086778800011	
B	Lindenbaum, M; Markovich, S; Rusakov, D			AAAI; AAAI	Lindenbaum, M; Markovich, S; Rusakov, D			Selective sampling for nearest neighbor classifiers	SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99)			English	Proceedings Paper	16th National Conference on Artificial Intelligence (AAAI-99)/11th Conference on Innovative Applications of Artificial Intelligence (IAAI-99)	JUL 18-22, 1999	ORLANDO, FL	Amer Assoc Artificial Intelligence, ACM,SIGART, US Def, Adv Res Projects Agcy, Microsoft Corp, USN, Res Lab, USN, Off Naval Res, NASA, Ames Res Ctr, NSF, Rent Comp				In the passive, traditional, approach to learning, the information available to the learner is a set of classified examples, which are randomly drawn from the instance space. In many applications, however, the initial classification of the training set is a costly process, and an intelligently selection of training examples from unlabeled data is done by an active learner. This paper proposes a lookahead algorithm for example selection and addresses the problem of active learning in the context of nearest neighbor classifiers. The proposed approach relies on using a random field model for the example labeling, which implies a dynamic change of the label estimates during the sampling process. The proposed selective sampling algorithm was evaluated empirically on artificial and real data sets. The experiments show that the proposed method outperforms other methods in most cases.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Lindenbaum, M (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Blake CL, 1998, UCI REPOSITORY MACHI; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAGAN I, 1995, MACH LEARN INT WORKS; DAVIS DT, 1992, IJCNN, V1, P676; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1007/BF00114162; HASENJAGER M, 1996, ICANN, P501; Hasenjager M, 1998, NEURAL PROCESS LETT, V7, P107, DOI 10.1023/A:1009688513124; KROGH A, 1994, NIPS, V7, P231; Lang K.J., 1988, P 1988 CONN MOD SUMM, P52; Lewis David D., 1994, MACH LEARN P 11 INT, P148; LINDENBAUM M, 1999, CIS9906 TECHN ISR I; MacKay D., 1998, NATO ASI SERIES F, V168, P133; Papoulis A., 1991, PROBABILITY RANDOM V; RAYCHAUDHURI T, 1995, IEEE ICNN, V3, P1338; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; WONG E, 1985, STOHASTIC PROCESSES	22	0	0	AMER ASSOC ARTIFICIAL INTELLIGENCE	MENLO PK	445 BURGESS DR, MENLO PK, CA 94025 USA		0-262-51106-1				1999							366	371				6	Computer Science, Artificial Intelligence	Computer Science	BQ85T	WOS:000089853000052	
B	Kamp, JF; Poirier, F; Doignon, P			ASSOC INT CYBERNET; ASSOC INT CYBERNET	Kamp, JF; Poirier, F; Doignon, P			Interaction with in-vehicle systems. A neural network approach to recognize symbols drawn with the finger on a touchpad	15TH INTERNATIONAL CONGRESS ON CYBERNETICS, PROCEEDINGS			English	Proceedings Paper	15th International Congress on Cybernetics	AUG 24-28, 1998	NAMUR, BELGIUM	Assoc Int Cybernet		neural network; character recognition; handwritten characters; touchpad; in-vehicle; interaction			UBS, Lab VALORIA Tohannic, F-56000 Vannes, France	Kamp, JF (reprint author), UBS, Lab VALORIA Tohannic, Rue Yves Mainguy, F-56000 Vannes, France.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; GARCIASAICETTI S, 1996, SEGMENTATION DYNAMIQ; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; Kohonen T., 1991, ARTIFICIAL NEURAL NE; Paelke G. M., 1993, Proceedings of the Human Factors and Ergonomics Society 37th Annual Meeting. Designing for Diversity; POIRIER F, 1991, DVQ DYNAMIC VECTOR Q	7	0	0	ASSOC INT CYBERNETIQUE	NAMUR	PALAIS EXPOSITIONS PLACE ANDRE RIJKMANS, NAMUR, BELGIUM		2-87215-004-8				1999							249	254				6	Computer Science, Cybernetics	Computer Science	BN15K	WOS:000080876900036	
B	Boudaoud, N; Masson, M		Dave, RN; Sudkamp, T		Boudaoud, N; Masson, M			Detection of incipient fault using fuzzy agglomerative clustering algorithm	18TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS			English	Proceedings Paper	18th International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS 99)	JUN 10-12, 1999	NEW YORK, NY	N Amer Fuzzy Informat Proc Soc, IEEE Neural Networks Council, IEEE Syst Man & Cybernet Soc				This paper depicts an adaptive diagnostic system based on a fuzzy pattern recognition approach. The proposed system is designed to operate on-line and to deal with the following characteristics: on-line adaptation of classes, detection of slow or abrupt changes and stabilization in a new state, on-line creation of new classes. To meet these requirements, classes are constructed sequentially with a fuzzy agglomerative clustering procedure. Such a clustering procedure requires only one pass through the data, the fuzzy prototypes are created or adapted as new observations are gathered. A prototype is labelled as it is created by using a k-Nearest Neighbours rule with a distance reject option. This labelling rule is well adapted for stationnary states and abrupt changes. However, this rule does not operate in case of incipient faults. To deal with this limitation, we define the concept of temporary prototype. To decide if this prototype is representative of a stationary state or a transient one we introduce a progressive hypotheses test based on the activation rate of the prototype. The results of a robustness study are presented. Finally, the diagnosis system operation is demonstrated on a simulated example.	Univ Technol Compiegne, CQP2 Lab, F-60200 Compiegne, France	Boudaoud, N (reprint author), Univ Technol Compiegne, CQP2 Lab, F-60200 Compiegne, France.						Carpenter G, 1991, P INT JOINT C NEUR N, V2, P411; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Hart P., 1988, IEEE T INFORM THEORY, V13, P21; NEWTON SC, 1992, IEEE T NEURAL NETWOR, V3, P794, DOI 10.1109/72.159068; SCOTT AJ, 1971, BIOMETRICS, V27, P387, DOI 10.2307/2529003; Simpson P. K., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/TFUZZ.1993.390282; Wald A., 1973, SEQUENTIAL ANAL	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-5211-4				1999							233	237		10.1109/NAFIPS.1999.781689		5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BN34H	WOS:000081666600050	
B	Nakashima, T; Ishibuchi, H		Dave, RN; Sudkamp, T		Nakashima, T; Ishibuchi, H			Learning of fuzzy reference sets in nearest neighbor classification	18TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS			English	Proceedings Paper	18th International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS 99)	JUN 10-12, 1999	NEW YORK, NY	N Amer Fuzzy Informat Proc Soc, IEEE Neural Networks Council, IEEE Syst Man & Cybernet Soc			GENETIC ALGORITHMS; SYSTEMS; RULES	We have already proposed a GA-based approach to the design of compact fuzzy nearest neighbor classifiers. In this paper, we propose two learning algorithms for the fuzzy nearest neighbor classifiers: one is the learning of the certainty grade of each fuzzy if-then rule, and the other is the learning of the radius of its antecedent fuzzy set (i.e., the radius of the circular-cone type membership function). These two algorithms are based on a reward-punishment scheme. When a pattern is correctly classified the certainty grade of the winner fuzzy if-then rule and/or the radius of its antecedent fuzzy set ale increased. On the other hand, the certainty grade and/or the radius of the winner fuzzy if-then rule are decreased when a pattern is misclassified. We examine the learning algorithms by computer simulations on real-world pattern classification problems. We demonstrate that the performance of the fuzzy nearest neighbor classifiers is improved by the learning.	Univ Osaka Prefecture, Dept Ind Engn, Sakai, Osaka 5998531, Japan	Nakashima, T (reprint author), Univ Osaka Prefecture, Dept Ind Engn, Gakuen Cho 1-1, Sakai, Osaka 5998531, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ishibuchi H, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P673, DOI 10.1109/ICEC.1997.592401; Ishibuchi H., 1998, Proceedings of the 5th International Conference on Soft Computing and Information/Intelligent Systems. Methodologies for the Conception, Design and Application of Soft Computing; ISHIBUCHI H, 1994, FUZZY SET SYST, V65, P237, DOI 10.1016/0165-0114(94)90022-1; Ishibuchi H, 1997, FUZZY SET SYST, V89, P135, DOI 10.1016/S0165-0114(96)00098-X; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Knight L., 1995, P 6 INT C GEN ALG, P429; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; KUNCHEVA LI, 1997, P 7 IFSA WORLD C PRA, V3, P217; NAKASHIMA T, 1998, P INT C EV COMP, P709; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P4089	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-5211-4				1999							357	360		10.1109/NAFIPS.1999.781714		4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BN34H	WOS:000081666600075	
J	Savazzi, P; Favalli, L; Costamagna, E; Mecocci, A				Savazzi, P; Favalli, L; Costamagna, E; Mecocci, A			A suboptimal approach to channel equalization based on the nearest neighbor rule	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS			English	Article						clustering; equalizers; K-nearest neighbor (K-NN); mobile communications	CONTINUOUS PHASE MODULATION; DIGITAL MOBILE RADIO; RECEIVER; GMSK; MLSE	Recent applications of clustering and neural network techniques to channel equalization have revealed the classification nature of this problem. This paper illustrates an implementation of a global system for mobile communications (GSM) receiver in which channel equalization and demodulation are realized by means of the nearest neighbor (NN) classifier algorithm. The most important advantage in using such techniques is the significant reduction in terms of computational complexity compared with the maximum likelihood sequence estimation (MLSE) equalizer. The proposed approach involves symbol-by-symbol interpretation and the knowledge of the channel is embedded in the mapping process of the received symbols over the symbols of the training sequence. This means that no explicit channel estimation need be carried out, either with correlative blocks or using neural networks thus speeding up the entire process. The performance of the proposed receiver, evaluated through a channel simulator for mobile radio communications, is compared with the results obtained by means of a 16-state Viterbi algorithm and other suboptimal receivers. It is shown that the presented algorithm increases the bit error rate (BER) compared with the MLSE demodulator, but the performance degradation, despite the simplicity of the receiver, is kept within the limits imposed by the GSM specifications.	Univ Pavia, Dipartimento Elettron, I-27100 Pavia, Italy; Univ Siena, Dipartimento Elettron, I-53100 Siena, Italy	Savazzi, P (reprint author), Univ Pavia, Dipartimento Elettron, Via Palestro 3, I-27100 Pavia, Italy.		Savazzi, Pietro/B-5531-2008				ABRARDO A, 1993, ELECTRON LETT, V29, P2167, DOI 10.1049/el:19931454; BENELLI G, 1994, IEEE T VEH TECHNOL, V43, P870, DOI 10.1109/25.330149; BENELLI G, 1995, EUR T TELECOMMUN, V6, P455; BENELLI G, 1991, P INT C GLOBECOM 91, P1469; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARIA G, 1991, IEEE T VEH TECHNOL, V40, P392, DOI 10.1109/25.289420; DASARATHY BV, 1991, NN PATTERN CLASSIFIC; DAVELLA R, 1989, IEEE J SEL AREA COMM, V7, P122, DOI 10.1109/49.16853; Duda R., 1973, PATTERN CLASSIFICATI; FAVALLI L, 1997, P INT C DIG SIGN PRO, P287; FORNEY GD, 1972, IEEE T INFORM THEORY, V18, P363, DOI 10.1109/TIT.1972.1054829; GROSSBERG S, 1990, INTRO NEURAL ELECT N; KALEH GK, 1989, IEEE J SEL AREA COMM, V7, P1427, DOI 10.1109/49.44586; KECHRIOTIS G, 1994, IEEE T NEURAL NETWOR, V5, P2670; LAURENT PA, 1986, IEEE T COMMUN, V34, P140; MCLANE PJ, 1983, IEEE T COMMUN, V31, P290, DOI 10.1109/TCOM.1983.1095805; Mulgrew B, 1996, IEEE SIGNAL PROC MAG, V13, P50, DOI 10.1109/79.487041; MUROTA K, 1981, IEEE T COMMUN, V29, P1044, DOI 10.1109/TCOM.1981.1095089; Proakis J.G., 1995, DIGITAL COMMUNICATIO; QURESHI SUH, 1985, P IEEE, V73, P1349, DOI 10.1109/PROC.1985.13298; RAHELI R, 1995, IEEE T COMMUN, V43, P354, DOI 10.1109/26.380054; SIMMONS SJ, 1983, IEEE T COMMUN, V31, P1273, DOI 10.1109/TCOM.1983.1095778; Sklar B, 1997, IEEE COMMUN MAG, V35, P148, DOI 10.1109/MCOM.1997.621038; Sklar B, 1997, IEEE COMMUN MAG, V35, P136, DOI 10.1109/35.620535; SUNDBERG CE, 1986, IEEE COMMUN MAG, V24, P25, DOI 10.1109/MCOM.1986.1093063; THEODORIDIS S, 1995, IEE P-COMMUN, V142, P165, DOI 10.1049/ip-com:19951853; THEODORIS S, 1996, P EUSIPCO 96 C TRIES, V1, P611; VECIANA GD, 1992, IEEE T COMMUN, V40, P1392; *ETSI GSM REC 05 0, 1998, MOD; *ETSI GSM REC 05 0, 1998, RAD TRANSM REC	30	16	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0733-8716		IEEE J SEL AREA COMM	IEEE J. Sel. Areas Commun.	DEC	1998	16	9					1640	1648		10.1109/49.737633		9	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	156MF	WOS:000078004600005	
J	Kulkarni, SR; Lugosi, G; Venkatesh, SS				Kulkarni, SR; Lugosi, G; Venkatesh, SS			Learning pattern classification - A survey	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Review						classification; learning; statistical pattern recognition; survey review	MULTILAYER FEEDFORWARD NETWORKS; VAPNIK-CHERVONENKIS DIMENSION; CONSISTENT NONPARAMETRIC REGRESSION; STRONG UNIVERSAL CONSISTENCY; EMPIRICAL RISK MINIMIZATION; DECISION TREE DESIGN; NEURAL NETWORKS; ASSOCIATIVE MEMORY; EXPONENTIAL BOUNDS; DENSITY-ESTIMATION	Classical and recent results in statistical pattern recognition and learning theory are reviewed in a two-class pattern classification setting, This basic model best illustrates intuition and analysis techniques while still containing the essential features and serving as a prototype for many applications. Topics discussed include nearest neighbor, kernel, and histogram methods, Vapnik-Chervonenkis theory, and neural networks. The presentation and the large (though nonexhaustive) list of references is geared to provide a useful overview of this field for both specialists and nonspecialists.	Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA; Pompeu Fabra Univ, Dept Econ, Barcelona 08005, Spain; Univ Penn, Dept Elect Engn, Philadelphia, PA 19104 USA	Kulkarni, SR (reprint author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.	kulkarni@ee.princeton.edu; lugosi@upf.es; venkatesh@ee.upenn.edu					Aizerman M., 1970, AM MATH SOC TRANSL, V87, P281; Aizerman M.A., 1964, Avtomatika i Telemekhanika, V25; Aizerman M.A., 1964, AUTOMAT REM CONTR, V25, P1546; Aizerman M.A., 1964, Avtomatika i Telemekhanika, V25; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; Aleksander I., 1990, INTRO NEURAL COMPUTI; Alexander K., 1984, ANN PROBAB, V4, P1041; AMARI S, 1990, P IEEE, V78, P1443, DOI 10.1109/5.58324; ANDERSON JA, 1994, INTRO PRACTICAL NEUR; ANDERSON MW, 1970, IEEE T INFORM THEORY, V16, P541, DOI 10.1109/TIT.1970.1054532; Anderson T. W., 1966, MULTIVARIATE ANAL, P5; Anthony M., 1992, COMPUTATIONAL LEARNI; ANTHONY M, 1993, DISCRETE APPL MATH, V47, P207, DOI 10.1016/0166-218X(93)90126-9; ANTOS A, 1997, MACHINE LEARN; Arbib M. A., 1987, BRAINS MACHINES MATH; ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51; ATIYA A, 1993, IEEE T NEURAL NETWOR, V4, P117, DOI 10.1109/72.182701; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; BALDI P, 1988, NEURAL INFORMATION P; BARRON AR, 1991, 58 U ILL URB CHAMP; BARRON AR, 1991, NATO ADV SCI I C-MAT, V335, P561; BARRON AR, 1994, MACH LEARN, V14, P115, DOI 10.1023/A:1022650905902; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; BARRON AR, 1996, IN PRESS PROBAB THEO; Barron A.R., 1988, P 20 S INT COMP SCI, P192; BARRON AR, 1989, PROCEEDINGS OF THE 28TH IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-3, P280, DOI 10.1109/CDC.1989.70117; BARRON RL, 1975, COMP DES, V75, P65; BARTLETT P, IN PRESS NEURAL COMP; BARTLETT PL, 1997, IN PRESS IEEE T INFO; Bashkirov O.A., 1964, Avtomatika i Telemekhanika, V25; Baum E. B., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90020-9; BAUM EB, 1990, NEURAL COMPUT, V2, P248, DOI 10.1162/neco.1990.2.2.248; BAUM EB, 1991, IEEE T NEURAL NETWOR, V2, P5, DOI 10.1109/72.80287; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BEAKLEY GW, 1972, IEEE T COMPUT, VC 21, P1337, DOI 10.1109/T-C.1972.223505; Beck J., 1979, Problems of Control and Information Theory, V8; BENEDEK GM, 1991, THEOR COMPUT SCI, V86, P377, DOI 10.1016/0304-3975(91)90026-X; BHATTACHARYA PK, 1987, ANN STAT, V15, P976, DOI 10.1214/aos/1176350487; BICKEL PJ, 1983, ANN PROBAB, V11, P185, DOI 10.1214/aop/1176993668; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Boser B., 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; BRAVERMA.EM, 1965, AUTOMAT REM CONTR+, V26, P2130; BRAVERMA.EM, 1966, AUTOMAT REM CONTR+, V27, P80; BREIMAN L, 1996, 460 U CAL BERK DEP S; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Broomhead D. S., 1988, Complex Systems, V2; BRUCK J, 1990, SIAM J DISCRETE MATH, V3, P168, DOI 10.1137/0403015; BUESCHER KL, 1996, IEEE T AUTOMAT CONTR, V42, P557; Buescher KL, 1996, IEEE T AUTOMAT CONTR, V41, P545, DOI 10.1109/9.489275; BURSHTEIN D, 1992, ANN STAT, V20, P1637, DOI 10.1214/aos/1176348789; CHEN T, 1990, P 22 S INT COMP SCI, P163; CHEN XR, 1987, J MULTIVARIATE ANAL, V21, P179, DOI 10.1016/0047-259X(87)90106-0; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; CIAMPI A, 1991, COMPUT STAT DATA AN, V12, P57, DOI 10.1016/0167-9473(91)90103-9; COHEN MA, 1983, IEEE T SYST MAN CYB, V13, P815; COLLOMB G, 1981, INT STAT REV, V49, P75, DOI 10.2307/1403039; Collomb G., 1980, LECT NOTES MATH, V821, P159; COLLOMB G, 1979, CR ACAD SCI A MATH, V289, P245; Cortes C, 1995, MACH LEARN, V20, P1; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1975, COMMUN CYBERN, V10, P15; COVER TM, 1968, PATTERN RECOGN, P283; COVER TM, 1969, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Dantzig G. B., 1963, LINEAR PROGRAMMING E; Darken C., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168357; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; DASGUPTA, 1994, THEORETICAL ADV NEUR, P357; DASGUPTA S, 1964, SANKHYA A, V26, P25; DEVIJVER PA, 1979, IEEE T INFORM THEORY, V25, P749, DOI 10.1109/TIT.1979.1056099; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L. P., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing; DEVROYE L, 1995, PATTERN RECOGN, V28, P1011, DOI 10.1016/0031-3203(94)00141-8; DEVROYE L, 1989, J STAT PLAN INFER, V23, P71, DOI 10.1016/0378-3758(89)90040-2; DEVROYE L, 1982, J MULTIVARIATE ANAL, V12, P72, DOI 10.1016/0047-259X(82)90083-5; DEVROYE LP, 1976, IEEE T INFORM THEORY, V22, P586, DOI 10.1109/TIT.1976.1055604; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; DEVROYE L, 1982, Z WAHRSCHEINLICHKEIT, V61, P467, DOI 10.1007/BF00531618; Devroye L, 1997, TEST, V6, P223; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1983, P 4 PANN S MATH STAT, P67; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; DEVROYE LP, 1976, 183 U TEX EL RES CTR; Devroye L.P., 1985, NONPARAMETRIC DENSIT; DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P202, DOI 10.1109/TIT.1979.1056032; DRUCKER H, 1996, ADV NEURAL INFORMATI, V8, P148; Duda R., 1973, PATTERN CLASSIFICATI; Dudley R. M., 1984, LECT NOTES MATH, V1097, P1; DUDLEY RM, 1994, IEEE T INFORM THEORY, V40, P883, DOI 10.1109/18.335898; DUDLEY RM, 1978, ANN PROBAB, V6, P899, DOI 10.1214/aop/1176995384; DUDLEY RM, 1979, ADV MATH, V31, P306, DOI 10.1016/0001-8708(79)90047-1; EECKMAN FH, 1988, NEURAL INFORMATION P, P242; EECKMAN FH, 1986, NEURAL NETWORKS COMP, P135; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; EHRENFEUCHT A, 1989, INFORM COMPUT, V82, P247, DOI 10.1016/0890-5401(89)90002-3; Erdelyi A, 1956, ASYMPTOTIC EXPANSION; FARAGO A, 1993, IEEE T INFORM THEORY, V39, P1146, DOI 10.1109/18.243433; Fisher RA, 1936, ANN EUGENIC, V7, P179; FIX E, 1951, REP USAF SCH AVIATIO, V4, P261; FIX E, 1952, REP USAF SCH AVIATIO, V11, P280; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; Fukunaga K, 1972, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P434, DOI 10.1109/TIT.1973.1055049; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Garey M.R., 1979, COMPUTERS INTRACTABI; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; Gelfand S.B., 1991, ARTIFICIAL NEURAL NE, P71; GELFAND SB, 1989, P 1989 IEEE INT C SY, P818; GESSAMAN MP, 1970, ANN MATH STAT, V41, P1344, DOI 10.1214/aoms/1177696909; GESSAMAN MP, 1972, J AM STAT ASSOC, V67, P468, DOI 10.2307/2284408; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; Goldberg P., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168377; GOODMAN RM, 1988, IEEE T INFORM THEORY, V34, P979, DOI 10.1109/18.21221; GORDON L, 1978, ANN STAT, V6, P515, DOI 10.1214/aos/1176344197; GORDON L, 1980, J MULTIVARIATE ANAL, V10, P611, DOI 10.1016/0047-259X(80)90074-3; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P147, DOI 10.1016/0047-259X(84)90022-8; GREBLICKI W, 1987, IEEE T INFORM THEORY, V33, P408, DOI 10.1109/TIT.1987.1057309; GREBLICKI W, 1984, ANN STAT, V12, P1570, DOI 10.1214/aos/1176346815; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; GYORFI L, 1975, TOPICS INFORMATION T, P299; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HAUSSLER D, 1988, P 29 IEEE S FDN COMP, P100, DOI 10.1109/SFCS.1988.21928; HAUSSLER D, 1992, INFORM COMPUT, V100, P78, DOI 10.1016/0890-5401(92)90010-D; Haykin S., 1994, NEURAL NETWORKS; Hebb D O, 1949, ORG BEHAV; HEGEDUS T, 1993, P 1 EUR C COMP LEARN; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hertz J., 1991, INTRO THEORY NEURAL; HIRSCH MW, 1989, NEURAL NETWORKS, V2, P331, DOI 10.1016/0893-6080(89)90018-X; HO YC, 1966, J SIAM CONTROL, V4, P112; Holden S. B., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238067; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HORNIK K, 1993, NEURAL NETWORKS, V6, P1069; HORVATH M, 1997, IN PRESS DISCR APPL; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; JONES LK, 1990, P IEEE, V78, P1586, DOI 10.1109/5.58342; Judd JS, 1990, NEURAL NETWORK DESIG; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; KARPINSKI M, 1997, J COMP SYST SCI, V54; KEARNS M, 1997, P 10 ANN ACM WORK CO; Kearns M., 1995, Proceedings of the Eighth Annual Conference on Computational Learning Theory, DOI 10.1145/225298.225301; Kearns M. J., 1994, INTRO COMPUTATIONAL; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Kohonen T., 1988, SELF ORG ASS MEMORY; KOIRAN P, 1997, J COMP SYST SCI, V54; Kolmogorov A.N., 1961, AM MATH SOC TRANSL, V17, P277; KOMLOS J, IN PRESS J COMP SYST; KOMLOS J, 1988, CS88131 U CAL; KOMLOS J, 1988, NEURAL NETWORKS, V1, P239, DOI 10.1016/0893-6080(88)90029-9; KRZYZAK A, 1998, IN PRESS IEEE T NEUR; KRZYZAK A, 1984, IEEE T INFORM THEORY, V31, P91; Krzyzak A, 1996, IEEE T NEURAL NETWOR, V7, P475, DOI 10.1109/72.485681; KRZYZAK A, 1991, IEEE T INFORM THEORY, V37, P490, DOI 10.1109/18.79905; Kulkarni SR, 1997, IEEE T INFORM THEORY, V43, P154, DOI 10.1109/18.567668; KULKARNI SR, 1993, MACH LEARN, V11, P23, DOI 10.1023/A:1022627018023; LACHENBR.PA, 1967, BIOMETRICS, V23, P639, DOI 10.2307/2528418; Ledoux M., 1991, PROBABILITY BANACH S; LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5; LI XB, 1986, PATTERN RECOGN, V19, P229, DOI 10.1016/0031-3203(86)90013-0; LIN JH, 1991, MACH LEARN, V6, P211, DOI 10.1007/BF00114777; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Lugosi G, 1996, IEEE T INFORM THEORY, V42, P48, DOI 10.1109/18.481777; LUGOSI G, 1995, STAT PROBABIL LETT, V25, P71, DOI 10.1016/0167-7152(94)00207-O; Lugosi G, 1996, ANN STAT, V24, P687; LUGOSI G, 1995, IEEE T INFORM THEORY, V41, P677, DOI 10.1109/18.382014; Lunts A., 1967, ENG CYBERN, V3, P98; Maass W., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167193; MACINTYRE M, 1993, P 25 ANN ACM S THEOR, P325; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; MASSART P, 1990, ANN PROBAB, V18, P1269, DOI 10.1214/aop/1176990746; MCELIECE RJ, 1987, IEEE T INFORM THEORY, V33, P461, DOI 10.1109/TIT.1987.1057328; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; MEIR R, 1997, P 10 ANN ACM WORK CO; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MICHELBRIAND C, 1994, ASYMPTOTIC BEHAV AID; MIELNICZUK J, 1993, IN PRESS NEURAL NETW; Minsky M., 1988, PERCEPTRONS; MIZOGUCHI R, 1977, SYST COMP CONTR, V8, P114; MODHA DS, 1996, IN PRESS IEEE T INFO; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; MORGAN JN, 1963, J AM STAT ASSOC, V58, P415, DOI 10.2307/2283276; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; NADARAYA EA, 1970, THEOR PROBAB APPL+, V15, P134, DOI 10.1137/1115015; NATARAJAN BK, 1991, MACHINE LEARNING THE; NEWMAN CM, 1988, NEURAL NETWORKS, V1, P223, DOI 10.1016/0893-6080(88)90028-7; NILSSON N. J., 1990, MATH FDN LEARNING MA; Nobel A, 1996, ANN STAT, V24, P1084; Nobel AB, 1997, IEEE T INFORM THEORY, V43, P1122, DOI 10.1109/18.605573; Olshen R., 1977, ANN STAT, V5, P632; PARK Y, 1990, PATTERN RECOGN, V23, P1393, DOI 10.1016/0031-3203(90)90086-Z; PARRONDO JMR, 1993, J PHYS A-MATH GEN, V26, P2211, DOI 10.1088/0305-4470/26/9/016; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATRICK EA, 1967, TREE6712 PURD U; PATRICK EA, 1966, TREE6618 PURD U; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905; PERETTO P, 1986, IEEE T SYST MAN CYB, V16, P73, DOI 10.1109/TSMC.1986.289283; Pineda F. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.161; PITT L, 1988, J ACM, V35, P965, DOI 10.1145/48014.63140; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Pollard D., 1990, NSF CBMS REGIONAL C; Pollard D., 1984, CONVERGENCE STOCHAST; Pollard D., 1989, STAT SCI, V4, P341, DOI 10.1214/ss/1177012394; Powell M., 1987, ALGORITHMS APPROXIMA; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Qing-Yun S., 1983, Pattern Recognition, V16, DOI 10.1016/0031-3203(83)90076-6; QUESENBE.CP, 1968, ANN MATH STAT, V39, P664, DOI 10.1214/aoms/1177698425; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ripley BD, 1993, NETWORKS CHAOS STAT, P40; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Rissanen J., 1989, SERIES COMPUTER SCI, V15; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; Royall R., 1966, THESIS STANFORD U ST; ROYCHOWDHURY V, 1994, THEORETICAL ADV NEUR; Rudin W., 1974, REAL COMPLEX ANAL; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAKURAI A, 1993, P WORLD C NEUR NETW, V3, P540; Sauer N., 1972, Journal of Combinatorial Theory, Series A, V13, DOI 10.1016/0097-3165(72)90019-2; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHAPIRE RE, 1997, UNPUB BOOSTING MARGI; Schlafli L, 1950, GESAMMELTE MATH ABHA, V1, P209; Schuurmans D., 1995, Computational Learning Theory. Second European Conference, EuroCOLT '95. Proceedings; Sebestyen G. S., 1962, DECISION MAKING PROC; SETHI IK, 1991, ARTIFICIAL NEURAL NE, P71; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441; Shawe-Taylor J., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, DOI 10.1145/238061.238070; SHAWETAYLOR J, 1993, DISCRETE APPL MATH, V42, P65, DOI 10.1016/0166-218X(93)90179-R; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Simon HU, 1997, SIAM J COMPUT, V26, P751, DOI 10.1137/S0097539793259185; SIMON HU, 1991, INFORM PROCESS LETT, V39, P137, DOI 10.1016/0020-0190(91)90109-U; Simon H. U., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, DOI 10.1145/168304.168385; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101; SNAPP RR, 1998, IN PRESS ANN STAT; SNAPP RR, 1997, TRUVMCS1997001 DEP C; SONTAG ED, 1992, J COMPUT SYST SCI, V45, P20, DOI 10.1016/0022-0000(92)90039-L; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STENGLE G, 1989, ANN STAT, V17, P1441, DOI 10.1214/aos/1176347373; STOLLER DS, 1954, J AM STAT ASSOC, V49, P770, DOI 10.2307/2281538; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STONE M, 1974, J R STAT SOC B, V36, P111; STUTE W, 1984, ANN STAT, V12, P917, DOI 10.1214/aos/1176346711; TALAGRAND M, 1994, ANN PROBAB, V22, P28, DOI 10.1214/aop/1176988847; TALMON JL, 1986, PATTERN RECOGNITION, V2; TOUSSAIN.GT, 1970, IEEE T COMPUT, VC 19, P541, DOI 10.1109/T-C.1970.222972; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V, 1974, THEORY PATTERN RECOG; Vapnik V., 1982, ESTIMATION DEPENDENC; VAPNIK VN, 1981, THEOR PROBAB APPL+, V26, P532; VAPNIK VN, 1991, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VENKATESH SS, 1994, THEORETICAL ADV NEUR; Venkatesh S. S., 1991, Journal of Complexity, V7, DOI 10.1016/0885-064X(91)90040-5; VENKATESH SS, 1993, J COMPUT SYST SCI, V46, P198, DOI 10.1016/0022-0000(93)90003-F; VENKATESH SS, 1992, IEEE T INFORM THEORY, V38, P1114, DOI 10.1109/18.135650; VENKATESH SS, 1992, NEURAL NETWORKS PERC, V2; Venkatesh S. S., 1991, Journal of Complexity, V7, DOI 10.1016/0885-064X(91)90030-2; Vidyasagar M., 1997, THEORY LEARNING GEN; VU VH, 1997, P C NEUR INF PROC SY; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; WANG C, 1994, WORK APPL DESCRIPTIO; WANG C, 1993, C NEUR INF PROC SYST; WANG CC, IN PRESS IEEE T INFO; WANG CC, 1995, THESIS U PENNSYLVANI; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406; Wasan M., 1969, STOCHASTIC APPROXIMA; Watson G.S., 1964, SANKHYA A, V26, P359; WENOCUR RS, 1981, DISCRETE MATH, V33, P313, DOI 10.1016/0012-365X(81)90274-0; WHITE H, 1990, NEURAL NETWORKS, V3, P535, DOI 10.1016/0893-6080(90)90004-5; Whittaker H., 1991, P 23 S INT COMP SCI, P190; Widrow B., 1960, IRE WESCON CONV RE 4, P96; Wolverton C.T., 1969, IEEE T SYST SCI CYB, V5, P307; YANG Y, 1998, IN PRESS IEEE T INFO; ZHAO LC, 1989, J MULTIVARIATE ANAL, V29, P260, DOI 10.1016/0047-259X(89)90027-4; ZHAO LC, 1990, THEOR PROBAB APPL+, V35, P396, DOI 10.1137/1135057; ZHAO LC, 1987, J MULTIVARIATE ANAL, V21, P168, DOI 10.1016/0047-259X(87)90105-9	303	63	64	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	OCT	1998	44	6					2178	2206		10.1109/18.720536		29	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	128ZC	WOS:000076437400008	
J	Zupan, B; Dzeroski, S				Zupan, B; Dzeroski, S			Acquiring background knowledge for machine learning using function decomposition: a case study in rheumatology	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article; Proceedings Paper	6th Conference on Artificial Intelligence in Medicine Europe (AIME 97)	MAR 23-26, 1997	GRENOBLE, FRANCE	Univ Joseph fourier, Grenoble, CNRS, Grenoble Isere Dev, France, Assoc Francaise Intelligence Artificielle		background knowledge; knowledge acquisition and validation; inductive learning; typical co-occurrences; function decomposition; diagnosis of rheumatic diseases		Domain or background knowledge is often needed in order to solve difficult problems of learning medical diagnostic rules. Earlier experiments have demonstrated the utility of background knowledge when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences of several groups of attributes was provided by a medical expert. This paper explores the possibility of automating the process of acquiring background knowledge of this kind and studies the utility of such methods in the problem domain of rheumatic diseases. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set of attributes. The method is evaluated by comparing the typical co;occurrences it identifies as well as their contribution to the performance of machine learning algorithms, to the ones provided by a medical expert. (C) 1998 Elsevier Science B.V. All rights reserved.	Jozef Stefan Inst, Dept Intelligent Syst, SI-1000 Ljubljana, Slovenia	Zupan, B (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, SI-1000 Ljubljana, Slovenia.	blaz.zupan@ijs.si					ASHENHURST RL, 1952, BL111, P541; BIERMANN AW, 1982, IEEE T SYST MAN CYB, V12, P635, DOI 10.1109/TSMC.1982.4308882; BOHANEC M, 1997, P 4 C INT SOC DEC SU, P503; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Curtis H. A., 1962, NEW APPROACH DESIGN; DIERKES U, 1993, CALC VAR PARTIAL DIF, V1, P37, DOI 10.1007/BF02163263; Dzeroski S, 1996, Technol Health Care, V4, P203; FIX E, 1957, 4 US AIR FORC SCH AV; Harmon P., 1988, EXPERT SYSTEMS TOOLS; KARALIC A, 1990, SISTEMICA, V1, P113; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; LAVRAC N, 1991, P 3 SCAND C ART INT, P138; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; Michie D, 1995, LECT NOTES ARTIF INT, V912, P17; MICHIE D, 1994, MACHINE LEARNING NER; PERKOWSKI MA, 1995, UNIFIED APPROACH FUN; PIRNAT V, 1989, P 2 EUR C ART INT ME, P24; SAATY TL, 1993, MULTICRITERIA DECISI; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHAPIRO A, 1982, ADV COMPUTER CHESS, V3, P73; WETTSCHERECK D, 1994, THESIS OREGON STATE; Zupan B., 1997, P 14 INT C MACH LEAR, P421	24	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	SEP-OCT	1998	14	1-2					101	117		10.1016/S0933-3657(98)00018-9		17	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	124QJ	WOS:000076193000006	
J	Gu, C; Lee, MC				Gu, C; Lee, MC			Semiautomatic segmentation and tracking of semantic video objects	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			English	Article						mathematic morphology; perspective motion model; segmentation; semantic video object; tracking	DYNAMIC SCENE ANALYSIS; IMAGE SEQUENCE; MOTION MODELS; ALGORITHM	This paper introduces a novel semantic video object extraction system using mathematical morphology and a perspective motion model. Inspired by the results from the study of the human visual system, we intend to solve the semantic video object extraction problem in two separate steps: supervised I-frame segmentation, and unsupervised P-frame tracking. First, the precise semantic video object boundary can be found using a combination of human assistance and a morphological segmentation tool. Second, the semantic video objects in the remaining frames are obtained using global perspective motion estimation and compensation of the previous semantic video object plus boundary refinement as used for I frames.	Microsoft Corp, Redmond, WA 98052 USA	Gu, C (reprint author), Microsoft Corp, Redmond, WA 98052 USA.						AGGARWAL JK, 1981, P IEEE, V69, P562, DOI 10.1109/PROC.1981.12025; ANANDAN P, MOTION ANAL IMAGE SE, P1; AVID G, 1985, IEEE T PATTERN ANAL, V7, P384; AYER S, 1994, P 3 EUR C COMP VIS S, P316; BLACK MJ, 1992, ECCV 92, P485; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; BOUTHEMY P, 1993, OPT ENG, V32, P1205, DOI 10.1117/12.134183; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), DOI 10.1109/WVM.1991.212810; DERICHE R, 1990, ECCV 88, P259; EDELMAN S, 1990, 1239 AI MIT; Foley J.D., 1990, COMPUTER GRAPHICS PR; FORD RM, 1994, CVGIP-GRAPH MODEL IM, V56, P75; GOH WB, 1994, CVGIP-IMAG UNDERSTAN, V59, P307, DOI 10.1006/cviu.1994.1025; GORDON GL, 1989, IEEE WORKSH VIS MOT, P13; GU C, 1995, THESIS LTS EPFL; GU C, 1995, P INT S MULT COMM VI, P233; GUO PX, 1994, SEMIN VIROL, V5, P1, DOI 10.1006/smvy.1994.1001; Haralick R., 1992, COMPUTER ROBOT VISIO, V1; Haralick R. M., 1993, COMPUTER ROBOT VISIO, VII; Horn B. K. P., 1986, ROBOT VISION; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; Irani M., 1992, P 2 EUR C COMP VIS S, P282; Kruse SM, 1996, SIGNAL PROCESS-IMAGE, V9, P29, DOI 10.1016/S0923-5965(96)00006-9; KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184; Lee MC, 1997, IEEE T CIRC SYST VID, V7, P130; LETGERS GR, 1982, IEEE T PATTERN ANAL, V4, P583; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431; Marr D., 1982, VISION; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, DOI 10.1016/1047-3203(90)90014-M; MEYER F, 1992, 4TH INT C IM PROC IT, P303; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/cviu.1994.1047; Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220; MUSMANN HG, 1989, IMAGE COMMUN, V1, P117; NAGEL HH, 1994, P 3 EUR C COMP VIS S, P305; NICOLAS H, 1992, P INT C AC SPEECH SI, P2825; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; ROGNONE A, 1992, 2 EUR C COMP VIS ECC, P258; RUI Y, 1998, ICASSP 98 SEATTL WA; SALEMBIER P, 1995, P IEEE, V83, P843, DOI 10.1109/5.387088; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2; SERRA J, 1992, CIRC SYST SIGNAL PR, V11, P47, DOI 10.1007/BF01189221; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56; SZELISKI R, 1996, IEEE COMPUT GRAPH, P22; Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3); THOMPSON WB, 1990, INT J COMPUT VISION, V4, P39, DOI 10.1007/BF00137442; TOKLU C, 1997, ICIP 97, V1, P113; TORR PHS, 1993, IMAGE VISION COMPUT, V11, P180, DOI 10.1016/0262-8856(93)90034-E; UEDA N, 1992, LECT NOTES COMPUT SC, V588, P453; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wu S. F., 1993, Journal of Visual Communication and Image Representation, V4, DOI 10.1006/jvci.1993.1003; YAO YS, 1995, IEEE T IMAGE PROCESS, V4; YUILLE A, 1992, ACTIVE VISION; *ISO IEC, 1997, JTC1SC29WG11	59	153	175	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1051-8215		IEEE T CIRC SYST VID	IEEE Trans. Circuits Syst. Video Technol.	SEP	1998	8	5					572	584				13	Engineering, Electrical & Electronic	Engineering	120QH	WOS:000075967500006	
J	Kubat, M				Kubat, M			Decision trees can initialize radial-basis function networks	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						decision trees; neural networks; pattern recognition; radial-basis functions	NEURAL NETWORKS; NETS	Successful implementations of radial-basis function (RBF) networks for classification tasks must deal with architectural issues, the burden of irrelevant attributes, scaling, and some other problems, This paper addresses these issues by initializing RBF networks with decision trees that define relatively pure regions in the instance space; each of these regions then determines one basis function. The resulting network is compact, easy to induce, and has favorable classification accuracy.	Univ SW Louisiana, Ctr Adv Comp Studies, Lafayette, LA 70504 USA; Southern Univ, Dept Comp Sci, Baton Rouge, LA 70813 USA	Kubat, M (reprint author), Univ SW Louisiana, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.						ANDREW C, 1995, EUR S ART NEUR NETW; BIOCH JC, P IEEE INT C NEUR NE, V4, P1739; Breiman L, 1984, CLASSIFICATION REGRE; BRENT RP, 1991, IEEE T NEURAL NETWOR, V2, P346, DOI 10.1109/72.97911; Broomhead D. S., 1988, Complex Systems, V2; CARTER C, 1987, IEEE EXPERT      FAL, P71; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; CHENG YH, 1994, P IEEE, P797; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR CLA; DIETTERICH TG, STAT TESTS COMP SUPE; Duda R., 1973, PATTERN CLASSIFICATI; FRITZKE B, 1994, NEURAL PROCESS LETT, V1, P2, DOI 10.1007/BF02312392; FRITZKE B, 1994, ADV NEURAL INFORMATI, V6, P255; Fu L, 1994, NEURAL NETWORKS COMP; GOODMAN RM, 1992, NEURAL COMPUT, V4, P781, DOI 10.1162/neco.1992.4.6.781; Haykin S., 1994, NEURAL NETWORKS COMP; Ivanova I, 1995, KNOWL-BASED SYST, V8, P333, DOI 10.1016/0950-7051(96)81917-4; KUBAT M, 1994, BIOL CYBERN, V79, P443; KUBAT M, P 5 BELG DUTCH C MAC, P61; Kubat M., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Lee Y., 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; LOWE D, 1989, IEE CONF PUBL, P171; MOODY J, 1989, NEURAL COMPUT, V1, P282; Murphy P. M., UCI REPOSITORY MACHI; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; OPITZ DW, 1994, P 11 INT C MACH LEAR; OPITZ DW, 1993, P 13 INT JOINT C ART, P1360; PARK Y, 1990, P IEEE INT C NEUR NE, V1, P94; POGGIO T, 1990, SCIENCE, V247, P987; Powell M. J. D., 1988, Numerical Analysis 1987; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Saha A., 1990, ADV NEURAL INFORMATI, P482; SANGER TD, 1991, IEEE T NEURAL NETWOR, V2, P285, DOI 10.1109/72.80339; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; TOWELL GG, P 8 NAT C ART INT AA, P861; WETTSCHERECK D, 1992, ADV NEUR IN, V4, P1133; Widrow B., 1960, IRE WESCON CONV RE 4, P96	38	53	54	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	SEP	1998	9	5					813	821		10.1109/72.712154		9	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	116HX	WOS:000075719800008	
J	Setiono, R; Thong, JYL; Yap, CS				Setiono, R; Thong, JYL; Yap, CS			Symbolic rule extraction from neural networks - An application to identifying organizations adopting IT	INFORMATION & MANAGEMENT			English	Article						backpropagation algorithm; neural networks; symbolic rules; IT adoption	SELECTION	Interest in the application of neural networks as tools for decision support has been growing in recent years. A major drawback often associated with neural networks is the difficulty in understanding the knowledge represented by a trained network. This paper describes an approach that can extract symbolic rules from neural networks. We illustrate how the approach successfully extracted rules from a data set collected from a survey of the service sectors in the United Kingdom. The extracted rules were then used to distinguish between organizations using computers from those that do not. The classification scheme based on these rules was used to identify specific segments of a market for promoting adoption of information technology The extracted rules are not only concise but also outperform discriminant analysis in terms of predictive accuracy. (C) 1998 Elsevier Science B.V. All rights reserved.	Natl Univ Singapore, Sch Comp, Kent Ridge 119260, Singapore; Hong Kong Univ Sci & Technol, Dept Informat & Syst Management, Hong Kong, Peoples R China	Setiono, R (reprint author), Natl Univ Singapore, Sch Comp, Kent Ridge 119260, Singapore.		Thong, James/B-9123-2011	Thong, James/0000-0002-1640-0581			Breiman L, 1984, CLASSIFICATION REGRE; COAKLEY JR, 1993, INTELLIGENT SYSTEMS, V2, P19; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUTTA S, 1994, DECIS SUPPORT SYST, V11, P527, DOI 10.1016/0167-9236(94)90023-X; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Karnin E D, 1990, IEEE Trans Neural Netw, V1, P239, DOI 10.1109/72.80236; Liu H, 1995, PROC INT C TOOLS ART, P388; LODEWYCK RW, 1993, INFORM MANAGE, V24, P1, DOI 10.1016/0378-7206(93)90042-R; MULLER B, 1990, NEURAL NETWORKS INTO; PIRAMUTHU S, 1994, DECIS SUPPORT SYST, V11, P509, DOI 10.1016/0167-9236(94)90022-1; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rojas R., 1996, NEURAL NETWORKS SYST; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SALCHENBERGER LM, 1992, DECISION SCI, V23, P899, DOI 10.1111/j.1540-5915.1992.tb00425.x; Lu HJ, 1996, IEEE T KNOWL DATA EN, V8, P957; SETIONO R, 1996, IEEE COMPUTER    MAR, P71; Setiono R, 1997, NEURAL COMPUT, V9, P185, DOI 10.1162/neco.1997.9.1.185; Smith M, 1993, NEURAL NETWORKS STAT; Sohl JE, 1995, INFORM MANAGE, V29, P297, DOI 10.1016/0378-7206(95)00033-4; TAM KY, 1992, MANAGE SCI, V38, P926, DOI 10.1287/mnsc.38.7.926; Thodberg H. H., 1991, International Journal of Neural Systems, V1, DOI 10.1142/S0129065791000352; VANOOYEN A, 1992, NEURAL NETWORKS, V5, P465, DOI 10.1016/0893-6080(92)90008-7; YAP CS, 1990, INFORM MANAGE, V18, P97, DOI 10.1016/0378-7206(90)90056-N	23	17	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-7206		INFORM MANAGE	Inf. Manage.	SEP	1998	34	2					91	101		10.1016/S0378-7206(98)00048-2		11	Computer Science, Information Systems; Information Science & Library Science; Management	Computer Science; Information Science & Library Science; Business & Economics	115GF	WOS:000075654600003	
J	Gascuel, O; Bouchon-Meunier, B; Caraux, G; Gallinari, P; Guenoche, A; Guermeur, Y; Lechevallier, Y; Marsala, C; Miclet, L; Nicolas, J; Nock, R; Ramdani, M; Sebag, M; Tallur, B; Venturini, G; Vitte, P				Gascuel, O; Bouchon-Meunier, B; Caraux, G; Gallinari, P; Guenoche, A; Guermeur, Y; Lechevallier, Y; Marsala, C; Miclet, L; Nicolas, J; Nock, R; Ramdani, M; Sebag, M; Tallur, B; Venturini, G; Vitte, P			Twelve numerical symbolic and hybrid supervised classification methods	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Supervised Classification; statistical methods; discriminant analysis; Neural Networks; Classification Trees; Machine Learning approaches; hybrid methods; Waveform Recognition Problem	NEURAL NETWORKS; ALGORITHMS	Supervised classification has already been the subject of numerous studies in the fields of Statistics, Pattern Recognition and Artificial Intelligence under various appellations which include discriminant analysis, discrimination and concept learning. Many practical applications relating to this field have been developed. New methods have appeared in recent years, due to developments concerning Neural Networks and Machine Learning. These "hybrid" approaches share one common factor in that they combine symbolic and numerical aspects. The former are characterized by the representation of knowledge, the latter by the introduction of frequencies and probabilistic criteria. In the present study, we shall present a certain number of hybrid methods, conceived (or improved) by members of the SYMENU research group. These methods issue mainly from Machine Learning and from research on Classification Trees done in Statistics, and they may also be qualified as "rule-based". They shall be compared with other more classical approaches. This comparison will be based on a detailed description of each of the twelve methods envisaged, and on the results obtained concerning the "Waveform Recognition Problem" proposed by Breiman et al.,(4) which is difficult for rule based approaches.	LIRMM, Montpellier 5, France; Univ Paris 06, IBP, LAFORIA, F-75252 Paris 5, France; CNRS, LIM, F-13288 Marseille 9, France; Inst Natl Rech Informat & Automat, F-78153 Le Chesnay, France; IRISA, ENSSAT, F-22300 Lannion, France; Inst Rech Informat & Syst Aleatoires, F-35042 Rennes, France; Ecole Polytech, CNRS 317, LMS, F-91128 Palaiseau, France; E3I, F-37913 Tours 9, France	Gascuel, O (reprint author), LIRMM, 161 Rue Ada, Montpellier 5, France.	gascuel@lirmm.fr					AUGIER S, 1995, P 1 INT C KNOWL DISC, P21; BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141; BONGARD N, 1970, PATTERN RECOGNITION; Breiman L, 1984, CLASSIFICATION REGRE; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; CHANG C, 1974, IEEE T COMPUT, V26, P1179; CHUNG SL, 1995, INT J HIGH SPEED COM, V7, P109, DOI 10.1142/S0129053395000075; CLARK P, 1987, PROGR MACHINE LEARNI, P11; Coster M., 1989, PRECIS ANAL IMAGES; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY DV, 1991, NEAREST NEIGHBOR NN; De Jong K., 1988, Machine Learning, V3, DOI 10.1023/A:1022606120092; de Carvalho Gomes F., 1994, Annals of Mathematics and Artificial Intelligence, V10; DIETTERICH TG, 1983, MACHINE LEARNING ART, P41; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U., 1993, P 13 INT JOINT C ART; Fisher RA, 1936, ANN EUGENIC, V7, P179; FISHER WD, 1958, J AM STAT ASSOC, V53, P789, DOI 10.2307/2281952; FLEGG HG, 1967, ALGEBRE BOOL SON UTI; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Fukunaga K., 1990, STAT PATTERN RECOGNI; GASCUEL O, 1986, P 1 EUR WORK SESS MA; GASCUEL O, 1991, INDUCTION SYMBOLIQUE, P327; GEEMAN S, 1992, NEURAL COMPUT, V4, P1; GUENOCHE A, 1995, 126 LAB INF MARS; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P925; Hand D. J., 1981, DISCRIMINATION CLASS; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; Hertz J., 1991, INTRO THEORY NEURAL; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; KUNTZMANN J, 1967, ALGEBRE BOOLE MACHIN; LECHEVALLIER Y, 1990, 1247 INRIA; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; LERMAN IC, 1991, P APPL STOCHASTIC MO, P63; Marsala C., 1996, Proceedings of the Fifth IEEE International Conference on Fuzzy Systems. FUZZ-IEEE '96 (Cat. No.96CH35998), DOI 10.1109/FUZZY.1996.552399; Michalski R. S., 1983, MACHINE LEARNING ART, P83; MICHALSKI RS, 1986, P AAAI 86 5 NAT C AR; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; MUGGLETON SH, 1992, INDUCTIVE LEARNING P; NICOLAS J, 1993, P JOURN FRANC APPR A; NICOLAS J, 1991, P APPL STOCHASTIC MO; NOCK R, 1995, P INT C MACH LEARN J; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Quinlan J.R., 1990, MACHINE LEARNING ART, VIII, P140; QUINLAN R, 1986, MACH LEARN, V1, P86; QUINQUETON J, 1983, P 6 INT JOINT C PATT; RAMDANI M, 1994, THESIS U P M CURIE; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SEBAG M, 1996, P INT C MACH LEARN J; SEBAG M, 1994, P INT C MACH LEARN J; Sejnowski T. J., 1987, Complex Systems, V1; Serra J., 1982, IMAGE ANAL MATH MORP; SHAVLIK W, 1991, MACH LEARN, V6, P11; Shortliffe E. H., 1976, COMPUTER BASED MED C; SONQUIST JA, 1963, DETECTION INTERACTIO; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; VANDERSMAGT PP, 1994, NEURAL NETWORKS, V7, P1; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VENTURINI G, 1994, THESIS U PARIS 11 OR; VERE SA, 1978, PATTERN DIRECTED INF, P281; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; Wegener I., 1987, COMPLEXITY BOOLEAN F; Widrow B., 1960, IRE WESCON CONV RE 4, P96; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Winston P.H., 1975, PSYCHOL COMPUTER VIS, P157; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	76	2	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 9128, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	AUG	1998	12	5					517	571		10.1142/S0218001498000336		55	Computer Science, Artificial Intelligence	Computer Science	118AE	WOS:000075814400001	
J	Lee, HM; Chen, KH; Jiang, IF				Lee, HM; Chen, KH; Jiang, IF			A neural network classifier with disjunctive fuzzy information	NEURAL NETWORKS			English	Article						disjunctive fuzzy information; neural network classifier; prototype; exemplar; trapezoidal fuzzy interval; on-line learning; non-linear separability		This paper presents a neural network classifier that learns disjunctive fuzzy information in the feature space. This neural network consists of two types of nodes in the hidden layer. The prototype nodes and exemplar nodes represent cluster centroids and exceptions in the feature space, respectively. This classifier automatically generates and refines prototypes for distinct clusters in the feature space. The number and sizes of these prototypes are not restricted, so the prototypes will form near-optimal decision regions to meet the distribution of input patterns and classify as many input patterns as possible. Next, exemplars will be created and expanded to learn the patterns that cannot be classified by the prototypes. Such a training strategy can reduce the memory requirement and speed up the process of non-linear classification. In addition, on-line learning is supplied in this classifier and the computational load is lightened. The experimental results manifest that this model can reduce the number of hidden nodes by determining the appropriate number of prototype nodes. (C) 1998 Elsevier Science Ltd. All rights reserved.	Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan	Lee, HM (reprint author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.						ABOUNASR MA, 1995, PATTERN RECOGN, V28, P581, DOI 10.1016/0031-3203(94)00114-2; CAGNONI S, 1994, P IEEE INT C NEUR NE, V2, P762, DOI 10.1109/ICNN.1994.374273; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; Chen KH, 1997, FUZZY SET SYST, V91, P15, DOI 10.1016/S0165-0114(96)00145-5; CHEN KH, 1995, P 3 EUR C INT TECHN, V1, P387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1980, FUZZY SETS SYSTEMS T; Duda R., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Grossberg S., 1982, STUDIES MIND BRAIN N; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; ISHIBUCHI H, 1992, P IEEE INT C FUZZY S, P1293; KELLER R, 1987, EXPERT SYSTEM TECHNO; Kohonen T., 1989, SELF ORG ASS MEMORY; Kosko B, 1992, NEURAL NETWORKS FUZZ; LIPPMANN RP, 1989, IEEE COMMUN MAG, V27, P47, DOI 10.1109/35.41401; McClelland J. L., 1988, EXPLORATIONS PARALLE; Pao Y. H., 1989, ADAPTIVE PATTERN REC; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Zimmermann H.J., 1991, FUZZY SET THEORY ITS	25	17	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.	AUG	1998	11	6					1113	1125		10.1016/S0893-6080(98)00058-6		13	Computer Science, Artificial Intelligence	Computer Science	133JY	WOS:000076684500012	
J	Dzeroski, S; Schulze-Kremer, S; Heidtke, KR; Siems, K; Wettschereck, D; Blockeel, H				Dzeroski, S; Schulze-Kremer, S; Heidtke, KR; Siems, K; Wettschereck, D; Blockeel, H			Diterpene structure elucidation from C-13 NMR spectra with Inductive Logic Programming	APPLIED ARTIFICIAL INTELLIGENCE			English	Article								We present a novel application of Inductive Logic Programming (ILP) to the problem of diterpene structure elucidation from C-13 NMR spectra. Diterpenes ale organic compounds of low molecular weight with a skeleton of 20 caibon atoms. They are of significant chemical and commercial interest because of their use as lead compounds in the search for new pharmaceutical effectors. The interpretation of diterpene C-13 NMR spectra normally requires specialists with detailed spectroscopic knowledge and substantial experience in natural products chemistry, specifically knowledge on peak patterns and chemical structures. Given a database of peak patterns for diterpenes with known structure, we apply several ILP approaches to discover correlations between peak patterns and chemical structure. The approaches used include first-order inductive learning, relational instance based learning, induction of logical decision trees, and inductive constraint logic. Performance close to that of domain experts is achieved, which suffices for practical use.	Jozef Stefan Inst, Dept Intelligent Syst, SI-1000 Ljubljana, Slovenia; Max Planck Inst Mol Genet, Otto Warburg Lsb, Dept Lehrach, Berlin, Germany; AnalytiCon GMBH, Berlin, Germany; GMD, FITKI, St Augustin, Germany; Katholieke Univ Leuven, Dept Comp Sci, B-3001 Heverlee, Belgium	Dzeroski, S (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, SI-1000 Ljubljana, Slovenia.	Saso.Dzeroski@ijs.si					Abraham RJ, 1978, PROTON CARBON 13 NMR; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BLOCKEEL H, 1997, P 7 INT WORKSH IND L; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERAEDT L, 1995, P 6 INT WORKSH ALG L, P80; DERAEDT L, 1994, ARTIF INTELL, V70, P375, DOI 10.1016/0004-3702(94)90112-0; DZEROSKI S, 1996, P ECAI 96 WORKSH INT, P21; Emde W., 1996, P 13 INT C MACH LEAR, P122; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Gallant S. I., 1993, NEURAL NETWORK LEARN; GRAY NAB, 1982, PROG NUCL MAG RES SP, V15, P201, DOI 10.1016/0079-6565(82)80003-4; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Muggleton S., 1990, P 1 C ALG LEARN THEO, P368; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; SCHULZEKREMER S, 1995, MOL BIOINFORMATICS A; VANLAER W, 1997, P 8 INT S METHODOLOG, P277; WETTSCHERECK D, 1994, THESIS OREGON STATE; ZELL A, 1995, 695 U STUTTGART I PA; 1995, NATURAL PRODUCTS CD	23	17	18	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0883-9514		APPL ARTIF INTELL	Appl. Artif. Intell.	JUL-AUG	1998	12	5					363	383		10.1080/088395198117686		21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	ZW786	WOS:000074448200002	
J	Couvreur, C; Bresler, Y				Couvreur, C; Bresler, Y			Automatic classification of environmental noise sources by statistical methods	NOISE CONTROL ENGINEERING JOURNAL			English	Article							PATTERN-RECOGNITION	This paper shows how the tools of statistical pattern recognition can be used to create an "intelligent" noise monitoring system able to distinguish between the acoustic signals of different types of environmental noise sources, e.g., airplanes, cars, or trucks. The basics of statistical pattern recognition theory are reviewed in a tutorial fashion and illustrated on simple acoustical noise recognition examples. Guidelines for the design, training, and utilization of a pattern classification system are provided, The pitfalls of an intuitive, heuristic approach to these tasks are highlighted. Experimental results obtained by an automatic noise recognition system based on a statistical pattern recognition framework are presented. Finally, possible improvements of this system which are currently being investigated further are discussed. (C) 1998 Institute of Noise Control Engineering.	Lernout & Hauspie Speech Prod, B-1780 Wemmel, Belgium	Couvreur, C (reprint author), Lernout & Hauspie Speech Prod, Koning Albert Iaan I 64, B-1780 Wemmel, Belgium.						ADAMS KM, 1995, P INTER NOISE 95; ADAMS KM, 1996, P INTERNOISE 96 LIV, P2805; Anderson T., 1984, INTRO MULTIVARIATE S; BENBASSAT M, 1982, CLASSIFICATION PATTE; CABELL RH, 1989, AIAA 12 AER C SAN AN; CHAPELLE P, 1997, COMMUNICATION; CHAPELLE P, 1993, BRUSSELS S CHARLEROI; CLAIRBOIS JP, 1993, P INTER NOISE 93; COUVREUR C, 1997, ACT 4 C FRANC AC MAR, V2, P1311; COUVREUR C, 1994, STAT PATTERN RECOGNI; COUVREUR C, 1997, ONE 3 OCTAVE FILTERS; COUVREUR C, 1998, P 8 IEEE DIG SIGN PR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROISEZ LM, 1995, THESIS FACULTE POLYT; DARLINGTON P, 1996, P INTERNOISE 96 LIV, P2595; DARLINGTON P, 1995, P I ACOUST, V17, P179; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; Devroye L, 1996, PROBABILISTIC THEORY; Duda R., 1973, PATTERN CLASSIFICATI; FLINDELL IH, 1992, P EURONOISE LOND, P437; Fukunaga K., 1990, INTRO STAT PATTERN R; Couvreur C, 1998, APPL ACOUST, V54, P187, DOI 10.1016/S0003-682X(97)00105-9; GOLIC JD, 1987, IEEE T INFORM THEORY, V33, P681, DOI 10.1109/TIT.1987.1057357; GOLIC JD, 1987, IEEE T INFORM THEORY, V33, P694, DOI 10.1109/TIT.1987.1057349; Haykin S., 1994, NEURAL NETWORKS COMP; KEVELAER B, 1995, THESIS U LIEGE BELGI; Lehmann E., 1991, THEORY POINT ESTIMAT; Lehmann E.L., 1986, TESTING STAT HYPOTHE; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Michie D, 1994, MACHINE LEARNING NEU; MOUKAS P, 1982, IEEE T SYST MAN CYB, V12, P622, DOI 10.1109/TSMC.1982.4308881; MUCHALL RC, 1994, NEDERLANDS AKOESTISC, P19; NEMERLIN J, UNPUB ABAV WORKSH RE; Proakis JG, 1992, ADV DIGITAL SIGNAL P; Randall R.B., 1987, FREQUENCY ANAL; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Schuermann J., 1996, PATTERN CLASSIFICATI; SCOTT EA, 1993, AIAA J, V31, P1583, DOI 10.2514/3.11818; SETHI IK, 1981, IEEE T SYST MAN CYB, V11, P245; TAKINAMI H, 1996, P INTER NOISE 96, P2623; Therrien Charles W., 1989, DECISION ESTIMATION; WALLIS AD, 1995, P EURO NOISE 95, P1031; WALLIS AD, 1996, P INTER NOISE 96, P2571; Yamada I., 1985, Journal of the Acoustical Society of Japan (E), V6; YAMAGUSHI K, 1993, P INTER NOISE 93, P1669; *AM NAT STANT I, 1993, S1111986 ANSI AC SOC; *BRUEL KJAER, 1990, APPL SOFTW TYPE 7618; *BRUEL KJAER, 1990, NOIS LEV AN 4435 INS	49	1	1	INST NOISE CONTROL ENG	POUGHKEEPSIE	PO BOX 3206 ARLINGTON BRANCH, POUGHKEEPSIE, NY 12603 USA	0736-2501		NOISE CONTROL ENG	Noise Control Eng. J.	JUL-AUG	1998	46	4					167	182		10.3397/1.2828469		16	Acoustics; Engineering, Multidisciplinary	Acoustics; Engineering	123HM	WOS:000076119800004	
J	Echanobe, J; de Mendivil, JRG; Garitagoitia, JR; Alastruey, CF				Echanobe, J; de Mendivil, JRG; Garitagoitia, JR; Alastruey, CF			Deformed systems for contextual postprocessing	FUZZY SETS AND SYSTEMS			English	Article						artificial intelligence; image processing; linguistic modelling; pattern recognition	TEXT RECOGNITION; ALGORITHM	In this paper a fuzzy method for contextual postprocessing, able to deal with the measurement level output that an isolated character classifier (ICC) can provide for every input letter, is introduced. The ICC information, is expressed as a fuzzy character which is then post-processed, by a deformed system, together with the rest of the fuzzy characters from a word. This deformed system implicitly contains the contextual knowledge provided by a dictionary and it is defined as an extension, for fuzzy inputs, of a classic automaton. Therefore, in the method, the classification of a character is postponed until the context is taken into account. This means that the classification and contextual processes are computed together. The formulation of the deformed systems makes possible the utilization of different strategies for the evidences composition. The method and also the composition strategies are evaluated in a text recognition experiment and high rates are obtained in correcting the characters miss-recognized by the ICC. Moreover, the results are compared with one of the best postprocessing methods and a clear improvement is achieved. (C) 1998 Elsevier Science B.V. All rights reserved.	Univ Basque Country, Dept Elect & Elect, Bilbao 48080, Spain; Publ Univ Navarra, Dept Computat & Automat Control, Pamplona 31006, Spain; Publ Univ Navarra, Dept Math & Computat, Pamplona 31006, Spain	Echanobe, J (reprint author), Univ Basque Country, Dept Elect & Elect, POB 644, Bilbao 48080, Spain.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; ECHANOVE J, 1994, INT C ART NEUR NETW; ELLIMAN DG, 1990, PATTERN RECOGN, V23, P337, DOI 10.1016/0031-3203(90)90021-C; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826; Hopcroft J.E., 1979, INTRO AUTOMATA THEOR; HULL JJ, 1983, IEEE T PATTERN ANAL, V5, P384; Kucera H, 1967, COMPUTATIONAL ANAL P; LANDAU GM, 1988, J COMPUT SYST SCI, V37, P63, DOI 10.1016/0022-0000(88)90045-1; Negoita C. V., 1975, APPL FUZZY SETS SYST; REINA R, 1992, 2 INT C FUZZ LOG NEU; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184; SHINGHAL R, 1983, PATTERN RECOGN, V16, P261, DOI 10.1016/0031-3203(83)90030-4; VIDAL E, 1985, NATO ASI SERIES F, V16, P427; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Zimmermann H.-J., 1990, FUZZY SET THEORY ITS	16	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JUN 16	1998	96	3					335	341		10.1016/S0165-0114(96)00304-1		7	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	ZJ784	WOS:000073252800004	
J	Snapp, RR; Venkatesh, SS				Snapp, RR; Venkatesh, SS			Asymptotic expansions of the k nearest neighbor risk	ANNALS OF STATISTICS			English	Article						k nearest neighbor classifier; finite-sample risk; asymptotic expansions; Laplace's method	ERROR	The finite-sample risk of the k nearest neighbor classifier that uses a weighted L-p-metric as a measure of class similarity is examined. For a family of classification problems with smooth distributions in R-n, an asymptotic expansion for the risk is obtained in decreasing fractional powers of the reference sample size. An analysis of the leading expansion coefficients reveals that the optimal weighted L-p-metric, that is, the metric that minimizes the finite-sample risk, tends to a weighted Euclidean (i.e., L-2)metric as the sample size is increased. Numerical simulations corroborate this finding for a pattern recognition problem with normal class-conditional densities.	Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA; Univ Penn, Dept Elect Engn, Philadelphia, PA 19104 USA	Snapp, RR (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT 05405 USA.						Breiman L, 1984, CLASSIFICATION REGRE; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; Erdelyi A, 1956, ASYMPTOTIC EXPANSION; FIX E, 1951, 2149004 US AIR FORC, P261; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; FULKS W, 1961, PAC J MATH, V11, P185; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Knuth D. E., 1976, SIGACT News, V8; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; SMITH SJ, 1994, IEEE T PATTERN ANAL, V16, P915, DOI 10.1109/34.310689; SNAPP PR, 1996, ADV NEURAL INFORMATI, V8; SNAPP RR, 1998, UVMCS19980101 U VERM; SNAPP RR, 1994, P 12 INT C PATT REC, V2, P1, DOI 10.1109/ICPR.1994.576865; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Watson GN, 1918, P LOND MATH SOC, V17, P116	19	6	7	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 7, 3401 INVESTMENT BLVD, HAYWARD, CA 94545 USA	0090-5364		ANN STAT	Ann. Stat.	JUN	1998	26	3					850	878				29	Statistics & Probability	Mathematics	176DK	WOS:000079135500006	
J	Yang, MS; Chen, CH				Yang, MS; Chen, CH			On the edited fuzzy kappa-nearest neighbor rule	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article							ALGORITHM	Classification of objects is an important area in a variety of fields and applications. In the presence of full knowledge of the underlying joint distributions, Bayes analysis yields an optimal decision procedure and produces optimal error rates. Many different methods are available to make a decision in those cases where information of the underlying joint distributions is not presented. The k nearest neighbor rule (k-NNR) is a well-known nonparametric decision procedures. Many classification rules based on the k-NNR have already been proposed and applied in diverse substantive areas. The edited k-NNR proposed by Wilson [11] would be an important one. Fuzzy theory, originated by Zadeh [16], is widely used to represent the uncertainty of class membership. The fuzzy k-NNR has been proposed by several investigators. In this paper an edited type-of the fuzzy k-NNR is developed. Next, some asymptotic properties of the proposed edited fuzzy k-NNR are created. Moreover, numerical comparisons are made between the proposed edited fuzzy k-NNR and the other fuzzy k-NNR. Those results confirm that the edited fuzzy k-NNR has a better performance than the fuzzy k-NNR.	Chung Yuan Christian Univ, Dept Math, Chungli 32023, Taiwan	Yang, MS (reprint author), Chung Yuan Christian Univ, Dept Math, Chungli 32023, Taiwan.						BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; FIX E, 1951, 2149004 US AIR FORC; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; URAHAMA K, 1994, PATTERN RECOGN LETT, V15, P723, DOI 10.1016/0167-8655(94)90077-9; WANGER TJ, 1971, IEEE T INFORM THEORY, V17, P566; WANGER TJ, 1973, IEEE T INFORM THEORY, P696; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YAN H, 1993, PATTERN RECOGN, V26, P17; YANG MS, 1994, INT J GEN SYST, V22, P391, DOI 10.1080/03081079408935224; YANG MS, 1993, FUZZY SET SYST, V60, P273, DOI 10.1016/0165-0114(93)90438-N; YANG MS, 1993, MATH COMPUT MODEL, V18, P1, DOI 10.1016/0895-7177(93)90202-A; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	16	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	1998	28	3					461	466				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	ZP219	WOS:000073729800015	
J	Wold, S; Sjostrom, M				Wold, S; Sjostrom, M			Chemometrics and its roots in physical organic chemistry	ACTA CHEMICA SCANDINAVICA			English	Review							FREE-ENERGY RELATIONSHIPS; PATTERN-RECOGNITION; CHEMICAL DATA; BINDING; SEQUENCES; ACID	Linear free energy relationships (LFERs) and extra-thermodynamic relationships (ETRs), i.e., similarity and analogy models of physical organic chemistry, are mathematically and statistically equivalent to the models much used in chemometrics and data analysis, i.e., PCA, PLS, and SIMCA. Examples of early LFERs and ETRs include the Bronsted, Hammett, Taft, and Hansch relationships. Much of the early development of chemometrics derives from this equivalence. Thus, the interpretation and derivation of LFERs and ETRs as the first terms of serial expansions of perturbation theory applied to moderate structural change lead first to the SIMCA method for classification and discriminant analysis (pattern recognition), then to the approach of principal properties for the characterization of structural fragments, compounds, and materials, and finally also strongly influenced the development of PLS and its use in structure-effect relationships such as quantitative structure-activity relationships (QSARs). The interpretation of chemical data by a combination of physical organic chemistry models and chemometric principles often leads to interesting conclusions as illustrated by some examples.	Umea Univ, Dept Organ Chem, Chemometr Res Grp, S-90187 Umea, Sweden	Wold, S (reprint author), Umea Univ, Dept Organ Chem, Chemometr Res Grp, S-90187 Umea, Sweden.						ALBANO C, 1981, THESIS UMEA U UMEA; ALBANO C, 1980, J CHEM SOC PERK T 2, P1447, DOI 10.1039/p29800001447; AUSTEL V, 1994, QSAR CHEMOMETRIC MET, V2, P48; Carlson R., 1992, DESIGN OPTIMIZATION; CHEUNG HS, 1980, J BIOL CHEM, V255, P401; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; DUNN WJ, 1994, QSAR CHEMOMETRIC MET, V2, P179; DUNN WJ, 1978, J MED CHEM, V21, P922, DOI 10.1021/jm00207a015; Eberson L., 1987, ELECT TRANSFER REACT; ERIKSSON L, 1991, THESIS UMEA U UMEA; Exner O., 1972, ADV LINEAR FREE ENER, P1; GOODFORD PJ, 1985, J MED CHEM, V28, P849, DOI 10.1021/jm00145a002; HAMMETT LP, 1972, ADV LINEAR FREE ENER; Hansch C, 1995, EXPLORING QSAR FUNDA; HANSCH C, 1994, QSAR CHEMOMETRIC MET, V2; HANSCH C, 1962, NATURE, V194, P178, DOI 10.1038/194178b0; HELLBERG S, 1991, INT J PEPT PROT RES, V37, P414; HELLBERG S, 1987, J MED CHEM, V30, P1126, DOI 10.1021/jm00390a003; HELLBERG S, 1986, THESIS UMEA U UMEA; HELLBERG S, 1987, ACTA PHARM JUGOSL, V37, P53; Himmelreich R, 1996, NUCLEIC ACIDS RES, V24, P4420, DOI 10.1093/nar/24.22.4420; JOHNSSON J, 1992, THESIS UMEA U UMEA; Jurs P.C., 1975, CHEM APPL PATTERN RE; KOWALSKI BR, 1984, CHEMOMETRICS MATH; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KOWALSKI BR, 1973, J AM CHEM SOC, V95, P686, DOI 10.1021/ja00784a007; KUBINYI H, 1993, QSAR HANSCH ANAL REL, V1; KUBINYI H, 1993, 3 D QSAR DRUG DESIGN; LINDBERG W, 1983, ANAL CHEM, V55, P643, DOI 10.1021/ac00255a014; Malinowski E., 1980, FACTOR ANAL CHEM; Martens H., 1989, MULTIVARIATE CALIBRA; Nilsson Nils J., 1965, LEARNING MACHINES; PALM VA, 1971, OSNOVY KOLICHESTVENN; SANDBERG M, 1997, THESIS UMEA U UMEA; SANDBERG M, IN PRESS J MED CHEM; SJOSTROM M, 1974, CHEM SCRIPTA, V6, P114; SJOSTROM M, 1983, ANAL CHIM ACTA, V150, P61, DOI 10.1016/S0003-2670(00)85460-4; SJOSTROM M, 1994, QSAR CHEMOMETRIC MET, V2, P63; SJOSTROM M, 1977, ACS SYM SER, V52, P243; SJOSTROM M, 1981, ACTA CHEM SCAND B, V35, P537, DOI 10.3891/acta.chem.scand.35b-0537; SJOSTROM M, 1987, EMBO J, V6, P823; SJOSTROM M, 1978, CORRELATION ANAL CHE, P1; SJOSTROM M, 1976, CHEM SCRIPTA, V9, P200; SKAGERBERG B, 1989, THESIS UMEA U UMEA; Wold H., 1982, SYSTEM INDIRECT OBSE, V2; WOLD S, 1974, CHEM SCRIPTA, V5, P97; WOLD S, 1973, EUR FED CHEM ENG C U, V4, P25; WOLD S, UMINF8380; Wold S., 1983, LECT NOTES MATH, P286; WOLD S, 1993, ANAL CHIM ACTA, V277, P239, DOI 10.1016/0003-2670(93)80437-P; WOLD S, 1982, P C MATR PENC PIT SW; WOLD S, 1972, CHEM SCRIPTA, V2, P49; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052	54	15	15	MUNKSGAARD INT PUBL LTD	COPENHAGEN	35 NORRE SOGADE, PO BOX 2148, DK-1016 COPENHAGEN, DENMARK	0904-213X		ACTA CHEM SCAND	Acta Chem. Scand.	MAY	1998	52	5					517	523		10.3891/acta.chem.scand.52-0517		7	Biochemistry & Molecular Biology; Chemistry, Multidisciplinary	Biochemistry & Molecular Biology; Chemistry	ZL284	WOS:000073417200001	
J	Djouadi, A				Djouadi, A			On the reduction of the nearest-neighbor variation for more accurate classification and error estimates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest-neighbor risk; nearest-neighbor classifier; Bayes error; asymptotic risk; risk estimation	RULE	In designing the nearest-neighbor (NN) classifier, a method is presented to produce a finite sample size risk close to the asymptotic one. It is based on an attempt to eliminate the first-order effects of the sample size, as well as all higher odd terms. This method uses the 2-NN rule without the rejection option and utilizes a polarization scheme. Simulation results are included as a means of verifying this analysis.	Lucent Technol, Columbus, OH 43213 USA	Djouadi, A (reprint author), Lucent Technol, Room 3T-335B,6200 E Broad St, Columbus, OH 43213 USA.	adjouadi@lucent.com					BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1979, IEEE T INFORM THEORY, V25, P749, DOI 10.1109/TIT.1979.1056099; Duda R. O., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; FUKUNAGA K, 1985, IEEE T PATTERN ANAL, V7, P107; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition	8	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					567	571		10.1109/34.682188		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	ZR253	WOS:000073955600014	
J	Zouhal, LM; Denoeux, T				Zouhal, LM; Denoeux, T			An evidence-theoretic k-NN rule with parameter optimization	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						evidence theory; learning systems; parameter estimation; pattern classification; uncertainty	TRANSFERABLE BELIEF MODEL	This paper presents a learning procedure for optimizing the parameters in the evidence-theoretic k-nearest neighbor rule, a pattern classification method based on the Dempster-Shafer theory of belief functions. In this approach, each neighbor of a pattern to be classified is considered as an item of evidence supporting certain hypotheses concerning the class membership of that pattern. Based on this evidence, basic belief masses are assigned to each subset of the set of classes. Such masses are obtained for each of the k-nearest neighbors of the pattern under consideration and aggregated using the Dempster's rule of combination. In many situations, this method was found experimentally to yield lower error rates than other methods using the same information. However, the problem of tuning the parameters of the classification rule was so far unresolved. In this paper, we determine optimal or near-optimal parameter values from the data by minimizing an error function. This refinement of the original method is shown experimentally to result in substantial improvement of classification accuracy.	Univ Technol Compiegne, CNRS, UMR 6599, F-60205 Compiegne, France	Zouhal, LM (reprint author), Univ Technol Compiegne, CNRS, UMR 6599, Heudiasyc BP 20529, F-60205 Compiegne, France.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denoeux T, 1997, PATTERN RECOGN, V30, P1095, DOI 10.1016/S0031-3203(96)00137-9; DENOEUX T, IN PRESS TRAITEMENT; DENOEUX T, 1996, CESA 96 IMACS MULT C, V1, P104; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lawson Charles L., 1974, SOLVING LEAST SQUARE; MURPHY PM, 1994, UCI REPOSITION MACHI; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; SMETS P, 1990, IEEE T PATTERN ANAL, V12, P447, DOI 10.1109/34.55104; ZOUHAL LM, 1997, THESIS U TECHNOLOGIE	15	97	103	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	MAY	1998	28	2					263	271		10.1109/5326.669565		9	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	ZR902	WOS:000074026800008	
J	El-Kwae, EA; Fishman, JE; Bianchi, MJ; Pattany, PM; Kabuka, MR				El-Kwae, EA; Fishman, JE; Bianchi, MJ; Pattany, PM; Kabuka, MR			Detection of suspected malignant patterns in three-dimensional magnetic resonance breast images	JOURNAL OF DIGITAL IMAGING			English	Article						breast cancer; magnetic resonance imaging (MRI); neural networks; Boolean neural networks		In this article, a Boolean Neural Network (BNN) is used for the detection of suspected malignant regions in 3D breast magnetic resonance (MR) images. The BNN is characterized by fast learning and classification, guaranteed convergence, and simple, integer weight calculations. The BNN learning algorithm is incremental, which allows the addition and deletion of training patterns without unlearning those already learned. The incremental learning algorithm automatically reduces the training set and trains the network only with those examples estimated to be useful. The architecture is suitable for parallel hardware implementation using available Very Large Scale Integration (VLSI) technology. The BNN was trained by using a set of malignant, benign, and false-positive patterns, extracted by experts, from selected MR studies, by using an incremental teaming algorithm. After training, the network was tested by means of a consistency checking test, cross validation techniques, and patterns from actual MR breast images. During the consistency test, the BNN was tested by using the same patterns used for training. The BNN classification accuracy in this case was 99.75%, proving the ability of the BNN to select useful patterns from the training set. Then, a leave one out cross-validation (LOOCV) test was done by using patterns from the training set and the classification accuracy was 90%. Next, an extended training set was created by shifting the original patterns in different directions. A cross-validation test was then performed by dividing the set of patterns into a training and a test set. Classification accuracy was compared to the nearest neighbor classifier. Results showed that the BNN achieved an average of 77% classification accuracy while requiring only 34% of the original training set. On the other hand, the nearest neighbor classifier achieved an accuracy of 57.9% while retaining the whole training set. Another test using actual MR slices different from the training set was done and results compared favorably to a radiologist's findings. Test results show the BNN's capability to detect suspected malignant regions in 3D MR images of the breast. The proposed BNN architecture can save the radiologist a great deal of time browsing MR slices searching for suspected malignancies. Copyright (C) 1998 by W.B. Saunders Company.	Univ Miami, Dept Radiol, Ctr Med Imaging & Med Informat, Miami, FL 33136 USA	Kabuka, MR (reprint author), Univ Miami, Dept Radiol, Ctr Med Imaging & Med Informat, 1150 NW 14th St,Suite 301, Miami, FL 33136 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBO NN N; ELKWAE E, 1996, P ART NEUR NETW ENG, P437; ELKWAE EA, 1996, S COMPUTER APPL RADI, P304; GIGER ML, 1993, CATEGORICAL COURSE P; GILLES R, 1993, RADIOLOGY, V188, P473; Guerin S, 1997, PRESSE MED, V26, P1149; Heywang-Koebrunner S H, 1994, Magn Reson Imaging Clin N Am, V2, P527; HUSSAIN B, 1993, IEEE T PATTERN ANAL, V16, P355; HUSSAIN B, 1992, SPIE 1992 INT S OPTI; KORN F, 1996, C VERY LARGE DATABAS; Piccoli C W, 1994, Magn Reson Imaging Clin N Am, V2, P557; SHIRISH B, 1993, P 1993 IEEE INT C NE, P1096; SHIRISH B, 1994, THESIS U MIAMI; SHIRRISH B, 1993, IEEE T COMPUT, V42, P1271; SRINIVAS G, 1995, IEEE T PATTERN ANAL, V17, P1239; Tou J.T., 1974, PATTERN RECOGNITION; WEINREB JC, 1994, MAGN RESON QUART, V10, P67; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; XIAHONG L, 1994, P S COMPUTER ASSISTE; *NAT CANC I, 1995, CANC CANC FACTS	21	6	6	W B SAUNDERS CO	PHILADELPHIA	INDEPENDENCE SQUARE WEST CURTIS CENTER, STE 300, PHILADELPHIA, PA 19106-3399 USA	0897-1889		J DIGIT IMAGING	J. Digit. Imaging	MAY	1998	11	2					83	93				11	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	ZN911	WOS:000073695900004	
J	Eklund, PW; Kirkby, SD; Salim, A				Eklund, PW; Kirkby, SD; Salim, A			Data mining and soil salinity analysis	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article								The paper explores connections between decision support systems, remotely sensed and GIS data for environmental planning, and monitoring secondary soil salinization. The paper introduces a decision support knowledge base system called SALT MANAGER used as the starting point for three experiments in data mining which structure the paper. In the first, classified GIS data is passed to an inductive learning programme. The task is to reconstruct the classification rules. The resulting rules are used to improve knowledge base system performance. The second experiment reports on patterns of attribute value combinations occurring for specific classification classes. These patterns can be used to elicit new knowledge in the domain and lead to a form of knowledge discovery. This process is commonly referred to as 'data mining'. The third experiment measures the effect of an additional electromagnetic data layer on the knowledge base system. Again, our efforts yield novel knowledge discovery results from the application of data mining techniques. Finally, a comparison of different machine learning algorithms in the secondary salinization domain is given.	Univ Adelaide, Dept Comp Sci, Adelaide, SA, Australia; Univ Adelaide, Key Ctr Social Applicat GIS, Adelaide, SA, Australia	Eklund, PW (reprint author), Univ Adelaide, Dept Comp Sci, Adelaide, SA, Australia.						Aha D.W., 1989, P 11 INT JOINT C ART, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Breiman L, 1984, CLASSIFICATION REGRE; CARBONELL JG, 1989, ARTIF INTELL, V40, P1, DOI 10.1016/0004-3702(89)90045-3; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEGREEF PA, 1985, IJCAI 85, P390; DIETTERICH TG, 1983, MACHINE LEARNING ART, P41; FAYYAD UM, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P749; HAYWARD SA, 1987, INT J MAN MACH STUD, V26, P487, DOI 10.1016/S0020-7373(87)80083-4; HENSCHKE CJ, 1994, 193 PRIM IND DEP; Ho Y., 1969, APPL OPTIMAL CONTROL; Kibler D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00315.x; Kirkby SD, 1996, APPL GEOGR, V16, P289, DOI 10.1016/0143-6228(96)00016-1; KIRKBY SD, 1994, TR9421 U AD DEP COMP; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; Quinlan J. R., 1983, MACHINE LEARNING ART, P463; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; ROMANIUK SG, 1993, TRH393 NAT U SING DE; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALIM AS, 1994, TR9402 U AD DEP COMP; THOMAS IL, 1984, PHOTOGRAMM ENG REM S, V50, P1491; Winston P. H., 1992, ARTIFICIAL INTELLIGE; ZHANG K, 1992, IGARSS 92, V1, P319	28	18	29	TAYLOR & FRANCIS LTD	LONDON	ONE GUNPOWDER SQUARE, LONDON EC4A 3DE, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	APR-MAY	1998	12	3					247	268		10.1080/136588198241888		22	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	ZK674	WOS:000073349500003	
J	Lin, XF; Ding, XQ; Wu, YS				Lin, XF; Ding, XQ; Wu, YS			Theoretical analysis of the confidence metrics for nearest neighbor classifier	CHINESE SCIENCE BULLETIN			English	Article						nearest neighbor classifier; confidence value; optimal rejection; handwritten numeral recognition		Confidence value plays a vital role in the decision of rejection threshold and the integration of multiple classifiers. Nearest neighbor (NN) classifier is the most traditional and most common nonparameter statistical pattern classifier, However, so far there is no explicate theoretical analysis of the connection between nearest distance and confidence value. An analytical insight into different approximations is presented and one formula is pointed out that it is optimal in the sense of mathematical expectation. Practice in handwritten numeral recognition strongly supports the conclusion.	Tsing Hua Univ, Dept Elect Engn, Beijing 100084, Peoples R China	Lin, XF (reprint author), Tsing Hua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GARRIS MD, 1994, NIST FORM BASED HAND; LIN XF, P ICDAR 97, P471; RICHARD DM, 1991, NEURAL COMPUT, V2, P461	4	0	0	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1001-6538		CHINESE SCI BULL	Chin. Sci. Bull.	MAR	1998	43	6					464	467		10.1007/BF02883809		4	Multidisciplinary Sciences	Science & Technology - Other Topics	ZR011	WOS:000073926600007	
J	Skerl, V				Skerl, V			Human extracellular proteins display a different pattern of local sequence similarity with the four classes of human T-cell receptor V regions than foreign proteins and human intracellular proteins: a preliminary report	IMMUNOLOGY LETTERS			English	Article						immune tolerance; gamma delta T-cells; self/foreign discrimination; sequence analysis; T-cell receptor V gamma and V delta regions; topological compartments	ENVELOPE PROTEIN; IMMUNODEFICIENCY	A pool of 110 randomly selected/generated amino acids sequences was used to perform specific local sequence similarity alignment analysis with the pool of 279 reported sequences of human T-cell receptor (TCR) V-regions. The 110 analyzed sequences were divided, according to their origin and nature, into six protein groups, as: human intracellular (hi), extracellular/transmembrane (he) and extracellular adhesive matrix (ha) proteins, 'average' human proteins (hum), proteins of non-human origin (nhum) and randomly generated quasi-protein sequences (r). These sequences were decomposed into all their overlapping 11-mer segments, generating a total of 56 836 derived peptides (at least 8000 per group). Each derived peptide was aligned with the 279 human TCR V-regions and assigned to the category (alpha-like, beta-like, gamma-like or delta-like) corresponding to the class (V alpha, V beta, V gamma or V delta) of the V-region encompassing the most similar segment, as determined by the performed similarity-search. The six protein groups were found to differ significantly in their distribution of derived peptides among the four categories. According to the binomial tests results, human proteins from the extracellular compartment (he, ha) comprise a higher proportion of delta-like segments (P = 2.3 x 10(-2) and P < 10(-8), respectively) than the 'average' human proteins (hum). In addition, and in accordance with this finding, proteins that are normally not found in that topological compartment comprise a lower proportion of delta-like peptides (P = 1.4 x 10(-5) and P < 10(-8) for groups nhum and hi, respectively) than the 'average' human proteins (hum). In contrast, these proteins comprise a higher proportion of gamma-like segments (P = 8.3 x 10(-3), P = 1.4 x 10(-3) and P = 1.7 x 10(-4), for groups r, nhum and hi, respectively) than the 'average' human proteins (hum). These findings indicate significant differences between proteins encountered in the extracellular compartment-that are normally immunologically tolerated-and those the presence of which is usually non-tolerated. The results suggest that the discrimination and the reaction of the human immune network to proteins found in the extracellular compartment correlate with the proteins' pattern of preferential local sequence similarity with the V gamma and V delta classes of human TCR V-regions, implying a specific and an important role of gamma delta-cells in the maintenance of the immune homeostasis. Whether this implication represents a rule associated with self-tolerance, will be investigated by future analyses. (C) 1998 Elsevier Science B.V. All rights reserved.	Inst Nucl Sci Vinca, Multidisciplinary Res Lab 1802, YU-11001 Belgrade, Yugoslavia	Skerl, V (reprint author), Inst Nucl Sci Vinca, Multidisciplinary Res Lab 1802, POB 522, YU-11001 Belgrade, Yugoslavia.						BAIROCH A, 1992, NUCLEIC ACIDS RES, V20, P2019; BRUTLAG DL, 1990, COMPUT APPL BIOSCI, V6, P237; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; GUSTAFSON TL, 1987, TRUE EPISTAT MANUAL; HAAS W, 1993, ANNU REV IMMUNOL, V11, P637, DOI 10.1146/annurev.immunol.11.1.637; JAVAHERIAN K, 1989, P NATL ACAD SCI USA, V86, P6768, DOI 10.1073/pnas.86.17.6768; KABAT AE, 1992, SEQUENCES PROTEINS I; METLAS R, 1995, IMMUNOL LETT, V47, P25, DOI 10.1016/0165-2478(95)00056-B; MODROW S, 1987, J VIROL, V61, P570; Simon Gyorgy, 1992, Protein Sequences and Data Analysis, V5, P39; SKERL V, 1997, THESIS U BELGRADE; SKERL V, 1994, JUGOSLAV PHYSL PHARM, V30, P127	13	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-2478		IMMUNOL LETT	Immunol. Lett.	FEB	1998	60	2-3					67	72		10.1016/S0165-2478(97)00139-9		6	Immunology	Immunology	ZE690	WOS:000072820500002	
J	Fuchs, M; Fuchs, M				Fuchs, M; Fuchs, M			Feature-based learning of search-guiding heuristics for theorem proving	AI COMMUNICATIONS			English	Article						theorem proving; search heuristics; machine learning		Automated reasoning or theorem proving essentially amounts to solving search problems. Despite significant progress in recent years theorem provers still have many shortcomings. The use of machine-learning techniques is acknowledged as promising, but difficult to apply in the area of theorem proving. We propose here to learn search-guiding heuristics by employing features in a simple, yet effective manner. Features are used to adapt a heuristic to a solved source problem. The adapted heuristic can then be utilized profitably for solving related target problems. Experiments have demonstrated that the approach allows a theorem prover to prove hard problems that were out of reach before.	Tech Univ Munich, Fak Informat, D-80290 Munich, Germany; Australian Natl Univ, RSISE, Automated Reasoning Project, Canberra, ACT 0200, Australia	Fuchs, M (reprint author), Tech Univ Munich, Fak Informat, D-80290 Munich, Germany.	fuchsm@in.tum.de					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AVENHAUS J, 1995, LNCS, V914, P397; BACHMAIR L, 1989, C RES EQ ALG STRUCT; BROCK B, 1988, LECT NOTES COMPUT SC, V310, P454; BRUNDY A, 1988, LNCS, V310, P111; Chang C.-L., 1973, SYMBOLIC LOGIC MECH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENZINGER J, 1996, LECT NOTES ARTIF INT, V1104, P62; Denzinger J., 1997, P 15 INT JOINT C ART, P102; Ellman T., 1989, ACM COMPUT SURV, V21, P163, DOI 10.1145/66443.66445; FUCHS M, 1997, THESIS HAMBURG; FUCHS M, 1997, LECT NOTES ARTIF INT, V1323, P13; Fuchs M, 1997, LECT NOTES ARTIF INT, V1266, P23; Fuchs M., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; FUCHS M, 1996, LECT NOTES ARTIF INT, V1104, P523; Fuchs M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Fuchs M., 1997, Progress in Artificial Intelligence. 8th Portuguese Conference on Artificial Intelligence, EPIA-97. Proceedings; FUCHS M, 1997, LNAI, V1323, P1; Hillenbrand T, 1996, LECT NOTES COMPUT SC, V1103, P432; KAMIN S, 1980, ATTEMPTS GEN RECURSI; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kolbe T, 1995, LECT NOTES ARTIF INT, V912, P303; Kolbe T., 1994, P 11 ECAI 94, P80; McCune W, 1997, J AUTOM REASONING, V19, P263, DOI 10.1023/A:1005843212881; McCune W. W., 1994, ANL946; MELIS E, 1995, P 14 INT JOINT C ART, P182; MOSER M, 1997, J AUTOMATED REASONIN; Sherrah J. R., 1997, P 2 INT C GEN PROGR, P304; SUTCLIFFE G, 1994, LECT NOTES ARTIF INT, V814, P252; SUTTNER C, 1990, LECT NOTES ARTIF INT, V449, P470; Veroff R, 1996, J AUTOM REASONING, V16, P223, DOI 10.1007/BF00252178; WEIDENBACH C, 1996, LECT NOTES ARTIF INT, V1104, P141; Wilson D. R., 1996, Proceedings of the IASTED International Conference. Artificial Intelligence, Expert Systems and Neural Networks; WOS L, 1995, COMPUT MATH APPL, V29, P133, DOI 10.1016/0898-1221(94)00220-F; Yang J., 1997, P GEN PROGR C GP 97, P380	35	3	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		1998	11	3-4					175	189				15	Computer Science, Artificial Intelligence	Computer Science	181HP	WOS:000079436200002	
S	Satoh, K		Richter, MM; Smith, CH; Wiehagen, R; Zeugmann, T		Satoh, K			Analysis of case-based representability of Boolean functions by monotone theory	ALGORITHMIC LEARNING THEORY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th International Conference on Algorithnic Learning Theory	OCT 08-10, 1998	OTZENHAUSEN, GERMANY	Japanese Soc Artificial Intelligence, Univ Kaiserslautern				Classification is one of major tasks in case-based reasoning(CBR) and many studies have been done for analyzing properties of case-based classification [1, 14, 10, 15, 12, 9, 13, 7]. However, these studies only consider numerical similarity measures whereas there are other kinds of similarity measure for different tasks. Among:these measures, HYPO system [2, 3] in a legal domain uses a similarity measure based on set inclusion of differences of attributes in cases. In this paper, we give an analysis of representability of boolean functions in case-based classification using the above set inclusion based similarity. We show that such case-based classification has a strong connection between monotone theory studied in [4, 11]. Monotone theory is originated from computational learning theory and is used to show learnability of boolean function with polynomial DNF size and polynomial CNF size [4] and is used for deductive reasoning as well [11]. In this paper, we analyze a case-based representability of boolean functions by using the above relationship between the case-based classification by set inclusion based similarity and the monotone theory. We show that any boolean function is representable by a casebase whose size is bounded in polynomial of its DNF size and its CNF size and thus, k-term DNF, k-clause CNF can be efficiently representable in a casebase using set inclusion similarity.	Hokkaido Univ, Div Elect & Informat, Kita Ku, Sapporo, Hokkaido 0608628, Japan	Satoh, K (reprint author), Hokkaido Univ, Div Elect & Informat, Kita Ku, N13W8, Sapporo, Hokkaido 0608628, Japan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ashley K., 1990, MODELING LEGAL ARGUM; ASHLEY KD, 1994, LECT NOTES ARTIF INT, V837, P338; BSHOUTY NH, 1995, INFORM COMPUT, V123, P146, DOI 10.1006/inco.1995.1164; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; GLOBIG C, 1996, P ECAI 96, P117; GOODMAN M, 1990, INNOVATIVE APPL ARTI, V2, P86; Griffiths AD, 1995, LECT NOTES ARTIF INT, V912, P161; JANTKE KP, 1995, THEOR COMPUT SCI, V137, P25, DOI 10.1016/0304-3975(95)91134-C; Khardon R, 1996, ARTIF INTELL, V87, P187, DOI 10.1016/S0004-3702(96)00006-9; OKAMOTO S, 1995, LNAI, V984, P101; OKAMOTO S, 1995, LECT NOTES ARTIF INT, V1010, P253; RACHLIN J, 1994, MACHINE LEARNING P 1, P242; SALZBERG S, 1995, IEEE T PATTERN ANAL, V17, P599, DOI 10.1109/34.387506; SATOH K, 1996, P ECAI 9L, P142; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-65013-X	LECT NOTES ARTIF INT			1998	1501						179	190				12	Computer Science, Artificial Intelligence	Computer Science	BN96F	WOS:000083674100014	
J	Hahn, U; Chater, N				Hahn, U; Chater, N			Similarity and rules: distinct? exhaustive? empirically distinguishable?	COGNITION			English	Review						similarity-based process; rule-based process	LANGUAGE-ACQUISITION; CONTEXT THEORY; CATEGORIZATION; CLASSIFICATION; RECOGNITION; KNOWLEDGE; LOGIC; MODEL; REPRESENTATIONS; ACTIVATION	The distinction between rule-based and similarity-based processes in cognition is of fundamental importance for cognitive science, and has been the focus of a large body of empirical research. However, intuitive uses of the distinction are subject to theoretical difficulties and their relation to empirical evidence is not clear. We propose a 'core' distinction between rule-and similarity-based processes, in terms of the way representations of stored information are 'matched' with the representation of a novel item. This explication captures the intuitively clear-cut cases of processes of each type, and resolves apparent problems with the rule/similarity distinction. Moreover, it provides a clear target for assessing the psychological and Al literatures. We show that many lines of psychological evidence are less conclusive than sometimes assumed, but suggest that converging lines of evidence may be persuasive. that the Al literature suggests that approaches which combine rules and similarity are an important new focus for empirical work. (C) 1998 Elsevier Science B.V.	Univ Warwick, Dept Psychol, Coventry CV4 7AL, W Midlands, England	Hahn, U (reprint author), Univ Warwick, Dept Psychol, Coventry CV4 7AL, W Midlands, England.	u.hahn@warwick.ac.uk	Hahn, Ulrike/A-8947-2010				AAMODT A, 1994, AI COMMUN, V7, P39; ADA D, 1994, P AAAI 94 WORKSH CAS; Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALLEN SW, 1991, J EXP PSYCHOL GEN, V120, P3, DOI 10.1037//0096-3445.120.1.3; ALTMANN GTM, 1995, J EXP PSYCHOL LEARN, V21, P899, DOI 10.1037//0278-7393.21.4.899; Anderson J., 1983, ARCHITECTURE COGNITI; Andrews R, 1995, KNOWL-BASED SYST, V8, P373, DOI 10.1016/0950-7051(96)81920-4; Ashley K., 1990, MODELING LEGAL ARGUM; Barsalou L. W., 1990, ADV SOCIAL COGNITION, VIII, P61; BATES E, 1993, BRAIN DEV COGNITION; BERRY D, 1984, Q J EXPT PSYCHOL, V86, P209; BERRY DC, 1988, BRIT J PSYCHOL, V79, P251; BOOLOS G, 1988, COMPUTABILITY LOGIC; BRAINE MDS, 1978, PSYCHOL REV, V85, P1, DOI 10.1037//0033-295X.85.1.1; BRANTING K, 1991, THESIS U TEXAS AUSTI; BRANTING K, 1989, P 11 ANN M COGN SCI, P139; BROOKS LR, 1991, J EXP PSYCHOL GEN, V120, P316, DOI 10.1037/0096-3445.120.3.316; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; BROWN M, 1995, 1 UK CAS BAS REAS WO; BULLINARIA J, 1994, P 16 ANN M COGN SCI; BULLINARIA JA, 1995, LANG COGNITIVE PROC, V10, P227, DOI 10.1080/01690969508407095; CHATER N, 1996, PSYCHOL PHILOS INTER; CHENG P, 1985, COGNITIVE PSYCHOL, V17, P293; Chomsky N., 1986, KNOWLEDGE LANGUAGE I; CHOMSKY N, 1980, BEHAV BRAIN SCI, V3, P1; COLLINS AW, 1992, MIDW STUDIES PHILOS, V17, P74, DOI 10.1111/j.1475-4975.1992.tb00143.x; COSMIDES L, 1989, COGNITION, V31, P187, DOI 10.1016/0010-0277(89)90023-1; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIES M, 1995, PHILOS PERSPECTIVES, V9; DAYAL S, 1993, P 4 INT C ART INT LA; DELOSH E, 1993, INTERPOLATION EXTRAP; Dreyfus Hubert L., 1992, WHAT COMPUTERS STILL; DULANY DE, 1984, J EXP PSYCHOL GEN, V113, P541, DOI 10.1037/0096-3445.113.4.541; Ervin S. M., 1964, NEW DIRECTIONS STUDY; FEIGENBAUM E, 1977, P IJCAI 77; Fodor J. A., 1983, MODULARITY MIND; FORRESTER N, 1994, P 16 ANN M COGN SCI; FUNNELL E, 1983, BRIT J PSYCHOL, V74, P159; GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1016/S0364-0213(83)80009-3; GENTNER D, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P504; GENTNER D, 1994, PSYCHOL SCI, V5, P152, DOI 10.1111/j.1467-9280.1994.tb00652.x; Gentner D., 1989, SIMILARITY ANALOGICA; GINET C, 1992, MIDWEST STUD PHILOS, V17, P53, DOI 10.1111/j.1475-4975.1992.tb00142.x; Ginsberg M., 1987, READINGS NONMONOTONI; GLUSHKO RJ, 1979, J EXP PSYCHOL HUMAN, V5, P674, DOI 10.1037//0096-1523.5.4.674; GOLDSTONE RL, 1994, J EXP PSYCHOL LEARN, V20, P3, DOI 10.1037/0278-7393.20.1.3; GOLDSTONE RL, 1994, COGNITION, V52, P125, DOI 10.1016/0010-0277(94)90065-5; Goodman N., 1972, PROBLEMS PROJECTS; Goswami U., 1990, PHONOLOGICAL SKILLS; HADLEY R, 1993, TR9302 CSSIS S FRAS; HAHN U, 1997, KNOWLEDGE CONCEPTS C; HAHN U, 1996, IN PRESS ARTIFICIAL; HAHN U, 1996, THESIS U OXFORD UK; HAHN U, 1997, P GALA 97 C LANG ACQ; HAUGELAND J, 1985, ARTIFICAL INTELLIGEN; HAYES P, 1979, EXPERT STSTEMS MICRO; HERBIG B, 1992, SWP9208 SEKI U KAIS; HERRNSTEIN RJ, 1990, COGNITION, V37, P133, DOI 10.1016/0010-0277(90)90021-B; INHELDER B, 1958, GROWTH LOGICAL REASO; Johnson-Laird P. N., 1991, DEDUCTION; JORDAN M, 1986, PARALLEL DISTRIBUTED, V1; KOH KH, 1991, J EXP PSYCHOL LEARN, V17, P811, DOI 10.1037/0278-7393.17.5.811; KOLODNER JL, 1992, ARTIF INTELL REV, V6, P3, DOI 10.1007/BF00155578; KOLODNER JL, 1991, AI MAGAZINE      SUM, P52; KOMATSU LK, 1992, PSYCHOL BULL, V112, P500, DOI 10.1037//0033-2909.112.3.500; Kripke S., 1982, WITTGENSTEIN RULES P; KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037//0033-295X.99.1.22; LAMBERTS K, 1995, J EXP PSYCHOL GEN, V124, P161, DOI 10.1037/0096-3445.124.2.161; Langley P., 1996, ELEMENTS MACHINE LEA; LANGLEY P, 1994, AAAI 94 WORKSH CAS B; Marcus GF, 1995, COGNITIVE PSYCHOL, V29, P189, DOI 10.1006/cogp.1995.1015; MCCARTHY R, 1986, CORTEX, V22, P868; McDermott D., 1987, Computational Intelligence, V3, DOI 10.1111/j.1467-8640.1987.tb00183.x; MCDOWELL J, 1984, SYNTHESE, V58, P325, DOI 10.1007/BF00485246; MEDIN DL, 1987, CONCEPTS CONCEPTUAL; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MITCHELL T, 1990, READINGS MACHINE LEA; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; MYLLYMAKI P, 1993, 1 EUR WORKSH CAS BAS; Nakisa RC, 1996, PROCEEDINGS OF THE EIGHTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P177; NAKISA RC, 1998, COGNITIVE MODELS LAN; NEWELL A, 1963, MODELING MIND; Newell A., 1991, UNIFIED THEORIES COG; NEWELL A, 1990, PHILOS ARTIFICAL INT; Newell A., 1972, HUMAN PROBLEM SOLVIN; NISBETT RE, 1977, PSYCHOL REV, V84, P231, DOI 10.1037/0033-295X.84.3.231; NOSOFSKY R, 1992, LEARNING THEORY CONN; NOSOFSKY RM, 1988, J EXP PSYCHOL LEARN, V14, P700, DOI 10.1037/0278-7393.14.4.700; NOSOFSKY RM, 1989, J EXP PSYCHOL LEARN, V15, P282, DOI 10.1037/0278-7393.15.2.282; NOSOFSKY RM, 1984, J EXP PSYCHOL LEARN, V10, P104, DOI 10.1037/0278-7393.10.1.104; OAKSFORD M, 1993, BEHAV BRAIN SCI, V16, P360; Oaksford M., 1991, Mind and Language, V6, DOI 10.1111/j.1468-0017.1991.tb00173.x; Pavlov I.P., 1927, CONDITIONAL REFLEXES; PENNINGTON N, 1993, COGNITION, V49, P123, DOI 10.1016/0010-0277(93)90038-W; PICKERING M, 1995, MIND MACH, V5, P309, DOI 10.1007/BF00974748; PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7; PLUNKETT K, 1991, COGNITION, V38, P43, DOI 10.1016/0010-0277(91)90022-V; PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W; POSNER MI, 1970, J EXP PSYCHOL, V83, P304, DOI 10.1037/h0028558; PUTNAM H, 1974, PHILOS K POPPER, V1; Pylyshyn Z. W., 1984, COMPUTATION COGNITIO; Quine W. V. O., 1960, WORD OBJECT; REBER AS, 1989, J EXP PSYCHOL GEN, V118, P219, DOI 10.1037//0096-3445.118.3.219; REDINGTON M, 1994, P 16 ANN M COGN SCI; Redington M, 1996, J EXP PSYCHOL GEN, V125, P123, DOI 10.1037//0096-3445.125.2.123; REDINGTON M, 1996, THESIS U OXFORD; REED SK, 1972, COGNITIVE PSYCHOL, V3, P382, DOI 10.1016/0010-0285(72)90014-X; REITER R, 1980, ARTIF INTELL, V13, P81, DOI 10.1016/0004-3702(80)90014-4; RIPS I, 1994, PSYCHOL PROOF; RISSLAND E, 1993, P 4 INT C ART INT LA; RISSLAND EL, 1991, INT J MAN MACH STUD, V34, P839, DOI 10.1016/0020-7373(91)90013-W; ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X; ROSS BH, 1987, J EXP PSYCHOL LEARN, V13, P629, DOI 10.1037//0278-7393.13.4.629; ROSS BH, 1984, COGNITIVE PSYCHOL, V16, P371, DOI 10.1016/0010-0285(84)90014-8; ROSS BH, 1990, J EXP PSYCHOL LEARN, V16, P42, DOI 10.1037/0278-7393.16.1.42; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; RUMELHART DE, 1993, ATTENTION PERFORM, V14, P3; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Schank R. C., 1982, DYNAMIC MEMORY THEOR; SEARLE J, 1980, BEHAV BRAIN SCI, V3, P1; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; SEIFERT C, 1989, P CAS BAS REAS WORKS; SELFRIDGE OG, 1959, S MECH THOUGHT PROCE; Shallice T, 1988, NEUROPSYCHOLOGY MENT; Shanks D., 1995, PSYCHOL ASS LEARNING; SHANKS DR, 1994, BEHAV BRAIN SCI, V17, P367; SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390; SHEPARD RN, 1957, PSYCHOMETRIKA, V22, P325, DOI 10.1007/BF02288967; Shieber Stuart M., 1986, INTRO UNIFICATION BA; Shortliffe E. H., 1976, COMPUTER BASED MED C; SIDMAN M, 1982, J EXP ANAL BEHAV, V37, P5, DOI 10.1901/jeab.1982.37-5; Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037//0033-2909.119.1.3; SMITH EE, 1992, COGNITIVE SCI, V16, P1; Smith E. E., 1981, CATEGORIES CONCEPTS; SMOLENOV H, 1987, J NONCLASSICAL LOGIC, V4, P5; Touretzky D. S., 1986, MATH INHERITANCE SYS; TOURETZKY DS, 1988, COGNITIVE SCI, V12, P423, DOI 10.1207/s15516709cog1203_4; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; VAUGHAN W, 1988, J EXP PSYCHOL ANIM B, V14, P36, DOI 10.1037/0097-7403.14.1.36; VOKEY JR, 1992, J EXP PSYCHOL LEARN, V18, P328, DOI 10.1037//0278-7393.18.2.328; VOKEY JR, 1994, J EXPT PSYCHOL LEARN, V18, P1504; WASON PC, 1968, Q J EXP PSYCHOL, V20, P273, DOI 10.1080/14640746808400161; WESTERMANN G, 1994, P 17 ANN M COGN SCI, P236; Wettschereck D., 1995, P 1 INT C CAS BAS RE; WETTSCHERECK D, 1995, AIC95012 NAV CTR APP; YOUNG RM, 1981, COGNITIVE SCI, V5, P153, DOI 10.1207/s15516709cog0502_3	148	60	60	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0010-0277		COGNITION	Cognition	JAN	1998	65	2-3					197	230		10.1016/S0010-0277(97)00044-9		34	Psychology, Experimental	Psychology	ZA983	WOS:000072422500005	
B	Wong, D; Cox, D			IEEE; IEEE	Wong, D; Cox, D			Multi-state pattern recognition handoff algorithms	GLOBECOM 98: IEEE GLOBECOM 1998 - CONFERENCE RECORD, VOLS 1-6: THE BRIDGE TO GLOBAL INTEGRATION			English	Proceedings Paper	IEEE Global Telecommunications Conference (GLOBECOM 98)	NOV 08-12, 1998	SYDNEY, AUSTRALIA	IEEE Network World, IEEE Commun Soc, ICC Globecom, Telstra, Ericsson, Siemens, Lucent Technol, ALC-TEL, Cisco Syst, World Com, Csiro, NORTEL, Fujitsu, Hewlett Packard, IBM, Motorola				In wireless cellular systems, handoff algorithms decide when and to which base station to handoff. Traditional handoff algorithms generally cannot keep both the average number of unnecessary handoffs and the handoff decision delay low. They do not exploit the relative constancy of path loss and shadow fading effects at any given location around a base station. This information can in fact be used to improve the efficiency of handoff algorithms, as we do in our new handoff algorithms using pattern recognition. Handoff algorithms with both a negligible number of unnecessary handoffs and a negligible decision delay can therefore be realized. We illustrate the benefits of using this kind of handoff algorithm by applying a two-state handoff algorithm to the problem of turning around a corner in a microcellular system.	Stanford Univ, Stanford, CA 94305 USA	Wong, D (reprint author), Stanford Univ, Stanford, CA 94305 USA.						AUSTIN MD, 1994, IEEE T VEH TECHNOL, V43, P549, DOI 10.1109/25.312791; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DC, 1987, P IEEE, V75, P436, DOI 10.1109/PROC.1987.13755; Jakes W. C., 1994, MICROWAVE MOBILE COM; Kennemann O., 1994, P 6 NORD SEM DIG MOB, P195; MATURINOLOZOYA H, 1994, IEEE VEH TECHN C STO, P96; REZAIIFAR R, 1996, IEEE VEH TECHN C CHI, P887; VIJAYAN R, 1993, IEEE T VEH TECHNOL, V42, P351, DOI 10.1109/25.231888; WONG D, 1998, IEEE INT C UN PERS C	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-4985-7				1998							1420	1425				6	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BN33U	WOS:000081660200237	
J	Diamantini, C; Spalvieri, A				Diamantini, C; Spalvieri, A			Quantizing for minimum average misclassification risk	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						learning labeled vector quantization; statistical pattern recognition	VECTOR QUANTIZATION; NEURAL NETWORKS; DESIGN; CLASSIFICATION; ALGORITHM; SYSTEMS; PARZEN; ERROR	In pattern classification, a decision rule is a labeled partition of the observation space, where labels represent classes, A way to establish a decision rule is to attach a label to each code vector of a vector quantizer (VQ). When a labeled VQ is adopted as a classifier, we have to design it in such a way that high classification performance is obtained by a given number of code vectors, In this paper we propose a learning algorithm which optimizes the position of labeled code vectors in the observation space under the minimum average misclassification risk criterion.	Univ Ancona, Dipartimento Elettron, Ist Informat, I-60131 Ancona, Italy; Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Diamantini, C (reprint author), Univ Ancona, Dipartimento Elettron, Ist Informat, I-60131 Ancona, Italy.						Bianchi N, 1995, LECT NOTES ARTIF INT, V934, P367; BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P458, DOI 10.1109/72.88165; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESA VR, 1993, ADV NEURAL INFORMATI, V5, P220; DIAMANTINI C, 1995, THESIS U ANCONA; DIAMANTINI C, 1994, INT C ART NEUR NETW, V2, P1091; DIAMANTINI C, 1995, ELECTRON LETT, V31, P1556, DOI 10.1049/el:19951082; DIAMANTINI C, 1996, IEEE T CIRCUITS SYST, V47, P425; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P423, DOI 10.1109/34.19040; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Fukunaga K., 1990, INTRO STAT PATTERN R; Gersho A., 1992, VECTOR QUANTIZATION; Hartigan J., 1975, CLUSTERING ALGORITHM; HWANG JN, 1994, IEEE T SIGNAL PROCES, V42, P2795; KASSAM SA, 1977, IEEE T COMMUN, V25, P479, DOI 10.1109/TCOM.1977.1093858; Kohonen T., 1995, SELF ORG MAPS; KOHONEN T, 1988, 2ND P IEEE INT C NEU, V1, P61; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LONGO M, 1990, IEEE T INFORM THEORY, V36, P241, DOI 10.1109/18.52470; MCLEAN GF, 1993, IEEE T SYST MAN CYB, V23, P637, DOI 10.1109/21.256539; MORGERA SD, 1984, IEEE T PATTERN ANAL, V6, P1398; NEDELJKOVIC V, 1993, IEEE T NEURAL NETWOR, V4, P650, DOI 10.1109/72.238319; OEHLER KL, 1995, IEEE T PATTERN ANAL, V17, P461, DOI 10.1109/34.391396; PADOS DA, 1995, IEEE T NEURAL NETWOR, V6, P596, DOI 10.1109/72.377966; PAL NR, 1993, IEEE T NEURAL NETWOR, V4, P549, DOI 10.1109/72.238310; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; POOR HV, 1977, IEEE T COMMUN, V25, P893, DOI 10.1109/TCOM.1977.1093935; Spalvieri A, 1996, ELECTRON LETT, V32, P628, DOI 10.1049/el:19960450; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Van Trees H. L., 1971, DETECTION ESTIMATI 3; WASSEL GN, 1972, IEEE T SYST MAN CYB, V24, P533; Watanabe S, 1969, KNOWING GUESSING; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326	34	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JAN	1998	9	1					174	182		10.1109/72.655039		9	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	YR386	WOS:000071490200016	
J	Zhao, QF				Zhao, QF			Co-evolutionary learning of neural networks	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			English	Article; Proceedings Paper	4th International Conference on Soft Computing	SEP 30-OCT 05, 1996	IIZUKA, JAPAN					Compared with the conventional approaches, the evolutionary algorithms (EAs) are more efficient for system design in the sense that EAs can provide higher opportunity for obtaining the global optimal solution. However, in most existing EAs, an individual corresponds directly to a possible solution, and a large amount of computations is required for designing large-scaled systems, To solve this problem, this paper proposes a co-evolutionary algorithm (CEA). The basic idea is to divide and conquer: divide the system into many small homogeneous modules, define an individual as a module, find many good individuals using existing EAs, and put them together again to form the whole system. To make the study more concrete, we focus the discussion on the evolutionary learning of neural networks for pattern recognition. Experimental results are provided to show the procedure and the performance of the CEA.	Univ Aizu, Aizu Wakamatsu 96580, Japan	Zhao, QF (reprint author), Univ Aizu, Aizu Wakamatsu 96580, Japan.	qf-zhao@u-aizu.ac.jp					Constantine L. L., 1979, STRUCTURED DESIGN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox B.J., 1986, OBJECT ORIENTED PROG; De Jong K. A., 1995, P 4 ANN C EV PROGR, P307; Fogel D. B., 1995, EVOLUTIONARY COMPUTA; Goldberg D., 1989, GENETIC ALGORITHMS S; Hanson N., 1996, Proceedings of 1996 IEEE International Conference on Evolutionary Computation (ICEC'96) (Cat. No.96TH8114), DOI 10.1109/ICEC.1996.542381; Koza J.R., 1994, GENETIC PROGRAMMING; MINKSY M, 1994, SOC MIND; Moriarty DE, 1996, MACH LEARN, V22, P11, DOI 10.1007/BF00114722; Potter MA, 1994, LECT NOTES COMPUT SC, V866, P249; TANEE R, 1989, THESIS U MICHIGAN; ZHAO QF, 1996, P ICNN 96 PLEN PAN S, P124; ZHAO QF, 1996, P LIZ 96 JAP IIZ, P529; ZHAO QF, 1996, P ICNN 96 WASH DC, P403; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762	16	5	5	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1064-1246		J INTELL FUZZY SYST	J. Intell. Fuzzy Syst.		1998	6	1					83	90				8	Computer Science, Artificial Intelligence	Computer Science	112KW	WOS:000075494700008	
J	Huet, F; Philipp, S				Huet, F; Philipp, S			Fusion of images interpreted by a new fuzzy classifier	PATTERN ANALYSIS AND APPLICATIONS			English	Article						aerial image; evaluation; fusion; fuzzy classification; interpretation; segmentation	EDGE-DETECTION; REGION	This paper presents a global system for the fusion of images segmented by various methods and interpreted by a fuzzy classifier. A set of complementary segmentation operators is applied to the image. Each region of the segmented images is interpreted by the fuzzy classifier, through membership degrees to classes. The fuzzy classifier builds the classes automatically from examples, even in the case of complex data sets. Interpreted images are then merged by a fusion operator from the fuzzy set: theory. Several fusion operators are compared. They trust mure high membership degrees to classes, which are considered as reliability degrees. The fusion of the interpreted images improves the segmentation, and gives solutions to segmentation and interpretation evaluation.	UCP, ENSEA, ETIS, F-95014 Cergy Pontoise, France	Philipp, S (reprint author), UCP, ENSEA, ETIS, 6 Ave Ponceau,BP 44, F-95014 Cergy Pontoise, France.						Anderson T. W., 1958, INTRO MULTIVARIATE S; Bezdek J., 1981, PATTERN RECOGNITION; Bloch I, 1996, IEEE T SYST MAN CY A, V26, P52, DOI 10.1109/3468.477860; BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B; CHARROUX B, 1996, P ICIP 96 LAUS SWITZ, V3, P939, DOI 10.1109/ICIP.1996.560952; CHARROUX B, 1996, THESIS U PARIS 11; CHARROUX B, 1995, P 9 SCAND C IM AN UP, P671; CHASSERY JM, 1984, IEEE T PATTERN ANAL, V6, P794; CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241; Cocquerez J.-P., 1985, Traitement du Signal, V2; COCQUEREZ JP, 1997, COMP SYSTEMS IMAGE I, P86; Cocquerez J.-P., 1992, Traitement du Signal, V9; COQUEREZ JP, 1995, ANAL IMAGES FILTRAGE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; DERICHE R, 1988, P 9 ICPR ROM IT; DUBUISSON B, 1990, DIAGNOSTIC RECONAISS; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fukunaga K, 1972, INTRO STAT PATTERN R; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; GAMBOTTO JP, 1993, PATTERN RECOGN LETT, V14, P869, DOI 10.1016/0167-8655(93)90150-C; GRENIER D, 1984, THESIS UTC FRANCE; HAJJAMI HE, 1991, THESIS UTC FRANCE; KARAFALAH R, 1995, THESIS U SAVOIE FRAN; KARAFALAH R, 1994, P IEEE ICIP 94 AUST, V3, P470, DOI 10.1109/ICIP.1994.413762; Bloch I., 1994, Traitement du Signal, V11; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition	33	2	2	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.		1998	1	4					231	247		10.1007/BF01234770		17	Computer Science, Artificial Intelligence	Computer Science	256CD	WOS:000083707300003	
B	Ramscar, M; Hahn, U		Gernsbacher, MA; Derry, SJ		Ramscar, M; Hahn, U			What family resemblances are not: The continuing relevance of Wittgenstein to the study of concepts and categories	PROCEEDINGS OF THE TWENTIETH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY			English	Proceedings Paper	20th Annual Conference of the Cognitive-Science-Society	AUG 01-04, 1998	MADISON, WI	Cognit Sci Soc	UNIV WISCONSIN			We argue that common interpretations of Wittgenstein's philosophical Investigations within Cognitive Science misrepresent his account, underplaying its radical content. Appropriately interpreted, this account continues to challenge contemporary theories of concepts and categorisation. We illustrate the continued relevance of his position by directly applying its critique to current approaches to categorisation.	Univ Edinburgh, Dept Artificial Intelligence, Edinburgh EH1 1HN, Midlothian, Scotland	Ramscar, M (reprint author), Univ Edinburgh, Dept Artificial Intelligence, 80 S Bridge, Edinburgh EH1 1HN, Midlothian, Scotland.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; ANSCOMBE E, 1953, PHILOS INVESTIGATION; Barsalou L., 1987, CONCEPTS CONCEPTUAL; BECHTEL W, 1991, CONNECTIONISM MIND; BRANTING K, 1989, P 11 ANN M COGN SCI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hahn U., 1997, KNOWLEDGE CONCEPTS C, P43; HAHN U, IN PRESS BEHAV BRAIN; HAHN U, 1997, COGNITION, V65; Johnson-Laird P. N., 1983, MENTAL MODELS; Katz J. J., 1972, SEMANTIC THEORY; KOMATSU LK, 1992, PSYCHOL BULL, V112, P500, DOI 10.1037//0033-2909.112.3.500; Lakoff G., 1987, WOMEN FIRE DANGEROUS; Langley P., 1996, ELEMENTS MACHINE LEA; Medin D., 1989, SIMILARITY ANALOGICA; MURPHY GL, 1985, PSYCHOL REV, V92, P289, DOI 10.1037//0033-295X.92.3.289; NOSOFSKY RM, 1988, J EXP PSYCHOL LEARN, V14, P700, DOI 10.1037/0278-7393.14.4.700; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; RAMSCAR MJA, 1997, DEP ARTIFICIAL INTEL, P205; SCHYNS PG, IN PRESS BEHAV BRAIN; Schyns PG, 1997, J EXP PSYCHOL LEARN, V23, P681, DOI 10.1037//0278-7393.23.3.681; Small SL, 1997, BRAIN LANG, V57, P181, DOI 10.1006/brln.1997.1730; Smith E. E., 1981, CATEGORIES CONCEPTS; Taylor John R., 1995, LINGUISTIC CATEGORIZ	24	4	4	LAWRENCE ERLBAUM ASSOC PUBL	MAHWAH	10 INDUSTRIAL AVE, MAHWAH, NJ 07430 USA		0-8058-3231-9				1998							865	870				6	Language & Linguistics; Psychology; Psychology, Multidisciplinary; Psychology, Experimental	Linguistics; Psychology	BR96W	WOS:000168193500156	
S	Gu, C; Lee, MC		Aizawa, K; Stevenson, RL; Zhang, YQ		Gu, C; Lee, MC			Tracking of multiple semantic video objects for Internet applications	VISUAL COMMUNICATIONS AND IMAGE PROCESSING '99, PARTS 1-2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Meeting on Visual Communications and Image Processing	JAN 25-27, 1999	SAN JOSE, CA	IS&T, SPIE		semantic video object; segmentation; tracking; Internet application	DYNAMIC SCENE ANALYSIS; IMAGE SEQUENCE; MOTION MODELS; SEGMENTATION; ALGORITHM	This paper introduces a novel tracking system for generic semantic video objects using backward region-based classification. It consists of five elementary steps: region pre-processing, region extraction, region-based motion estimation, region classification and region post-processing. Region pre-processing simplifies the input data. Region extraction finds the basic elements for classification. Region-based motion estimation provides the trajectory information about each basic element. Region classification determines the interior/exterior parts of semantic video objects. Finally, region post-processing cleans the results. We will show solid performance of this generic tracking system with pixel-wise accuracy for internet applications.	Microsoft Corp, Redmond, WA 98052 USA	Gu, C (reprint author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.						AGGARWAL JK, 1981, P IEEE, V69, P562, DOI 10.1109/PROC.1981.12025; AVID G, 1985, IEEE T PATTERN ANAL, V7, P384; AYER S, 1994, P 3 EUR C COMP VIS S, P316; BLACK MJ, 1992, ECCV 92, P485; BONNAUD L, 1997, ICIP 97, V2, P426; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Chang SF, 1998, P IEEE, V86, P884; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; CHEN T, 1998, P IEEE, V86; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), DOI 10.1109/WVM.1991.212810; DERICHE R, 1990, ECCV 88, P259; FU Y, 1998, ICIP 98 OCT, V3, P633; GOH WB, 1994, CVGIP-IMAG UNDERSTAN, V59, P307, DOI 10.1006/cviu.1994.1025; GORDON GL, 1989, IEEE WORKSH VIS MOT, P13; GU C, 1995, THESIS LTS EPFL; Gu C, 1998, IEEE T CIRC SYST VID, V8, P572; GU C, 1995, MULTIMEDIA COMMUNICA; GUO PX, 1994, SEMIN VIROL, V5, P1, DOI 10.1006/smvy.1994.1001; Haralick R., 1992, COMPUTER ROBOT VISIO, V1; Haralick R. M., 1993, COMPUTER ROBOT VISIO, VII; Horn B. K. P., 1986, ROBOT VISION; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; Irani M., 1992, P 2 EUR C COMP VIS S, P282; KUNT M, 1985, P IEEE, V73; Lee MC, 1997, IEEE T CIRC SYST VID, V7, P130; LETGERS GR, 1982, IEEE T PATTERN ANAL, V4, P583; MARQUES F, 1998, INT C IM PROC ICIP, V3, P628; Marr D., 1982, VISION; MEIER T, 1998, ICIP 98 OCT CHIC, V2, P652; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/cviu.1994.1047; Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147; MOSCHENI F, 1996, ICASSP 96 ATL GA MAY, V4, P1914; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220; MUSMANN HG, 1989, IMAGE COMMUN, V1, P117; NAGEL HH, 1994, P 3 EUR C COMP VIS S, P305; NICOLAS H, 1992, P INT C AC SPEECH SI, P2825; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; ROGNONE A, 1992, 2 EUR C COMP VIS ECC, P258; RUI Y, 1998, ICASSP 98 MAY SEATTL; SALEMBIER P, 1995, P IEEE, V83, P843, DOI 10.1109/5.387088; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56; Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3); Thompson B, 1997, ENVIRON HIST, V2, P113, DOI 10.2307/3985577; TORR PHS, 1993, IMAGE VISION COMPUT, V11, P180, DOI 10.1016/0262-8856(93)90034-E; UEDA N, 1992, LECT NOTES COMPUT SC, V588, P453; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wu S. F., 1993, Journal of Visual Communication and Image Representation, V4, DOI 10.1006/jvci.1993.1003; YAO YS, 1995, IEEE T IMAGE PROCESS, V4; YUILLE A, 1992, ACTIVE VISION; ZHONG D, 1998, ICIP 98 OCT CHIC, V2, P647; *ISO IEC, 1997, JTC1SC29WG11 ISOIEC	55	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-3124-9	P SOC PHOTO-OPT INS			1998	3653		1-2				806	820		10.1117/12.334733		15	Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Engineering; Optics; Imaging Science & Photographic Technology	BM50M	WOS:000078907300077	
B	Sheppard, JW		Sheppard, JW; Simpson, WR		Sheppard, JW			Inducing diagnostic inference models from case data	RESEARCH PERSPECTIVES AND CASE STUDIES IN SYSTEM TEST AND DIAGNOSIS	FRONTIERS IN ELECTRONIC TESTING : A KLUWER INTERNATIONAL BOOK SERIES		English	Proceedings Paper	2nd International Workshop on System Test and Diagnosis	APR , 1998	ALEXANDRIA, VA			diagnostic inference models; case based reasoning; diagnostics; system test; Dempster-Shafer; nearest neighbor		Recent attention to using "case-based" reasoning for intelligent fault diagnosis has led to the development of very large, complex databases of diagnostic cases. The performance of case-based reasoners is dependent upon the size of the case base such that as case bases increase in size, it is usually reasonable to expect accuracy to improve but computational performance to degrade. Given one of these large case bases, it is advantageous to attempt to induce structure from the case base whereby the diagnostic process can be made more efficient. In addition, certainty properties of case based reasoning make fault diagnosis difficult, in which case inducing structure and applying a method for reasoning under uncertainty becomes advantageous. In this chapter, we discuss an approach to analyzing a diagnostic case base and inducing a compact knowledge base using the diagnostic inference model with which efficient diagnostics can be performed. We then apply an approach to reasoning using Dempster-Shafer theory to improve the diagnostics further with the resultant model.	ARINC Inc, Annapolis, MD 21401 USA	Sheppard, JW (reprint author), ARINC Inc, Annapolis, MD 21401 USA.						AAMODT A, 1994, AI COMMUN, V7, P39; Abramovici M., 1990, DIGITAL SYSTEMS TEST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; DEBANEY WH, 1995, AUTOTESTCON 95 C REC; DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Devijver P. A., 1982, PATTERN RECOGNITION; GRANT F, 1986, ELECT TEST; KLIGER S, 1995, 4 INT S INT NETW MAN; Mingers J., 1989, Machine Learning, V4, DOI 10.1023/A:1022604100933; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RICHMAN J, 1985, P INT TEST C LOS AL; RYAN P, 1994, THESIS U ILLINOIS UR; Shafer G., 1976, MATH THEORY EVIDENCE; Sheppard J., 1994, SYSTEM TEST DIAGNOSI; SHEPPARD JW, 1996, AUTOTESTCON 96 C REC; SHEPPARD JW, 1998, SYSTEM TEST DIAGNOSI; SHEPPARD JW, 1991, IEEE DES TEST COMPUT, V8, P25, DOI 10.1109/54.107203; Shortliffe E. H., 1976, COMPUTER BASED MED C; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Tulloss R., 1980, P 1980 TEST C NOV, P368; Tulloss R. E., 1978, P 1978 SEM TEST C, P264; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	25	0	0	KLUWER ACADEMIC PUBLISHERS	NORWELL	101 PHILIP DRIVE, ASSINIPPI PARK, NORWELL, MA 02061 USA		0-7923-8263-3	FR ELECTR T			1998							69	102				34	Engineering, Electrical & Electronic	Engineering	BN28C	WOS:000081415400005	
J	Bagui, SC; Mehra, KL; Vaughn, BK				Bagui, SC; Mehra, KL; Vaughn, BK			An M-stage version of the k-RNN rule in statistical discrimination	JOURNAL OF STATISTICAL PLANNING AND INFERENCE			English	Article						classification; discrimination; 1-NN rule; k-NN rule; 1-RNN rule; k-RNN rule		In this article a multi-stage (M-stage) k-rank nearest-neighbor (k-RNN) rule is used to discriminate an unknown observation into one of two populations (or classes). The asymptotic risk (i.e., the total probability of misclassification (TPMC)) of this rule is derived and shown that, as the number of stages increases, the limiting TPMC of the M-stage k-RNN rule decreases. (C) 1997 Elsevier Science B.V.	Univ W Florida, Dept Math & Stat, Pensacola, FL 32514 USA; Univ Alberta, Dept Math Sci, Edmonton, AB T6G 2G1, Canada		sbagui@math-stat.math.uwf.edu					ANDERSON TW, 1966, P 1 INT S AN; BAGUI SC, 1997, IN PRESS STAT DECISI, V16; BAGUI SC, 1993, PATTERN RECOGN LETT, V14, P537, DOI 10.1016/0167-8655(93)90102-J; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1980, SANKHYA A, V42, P219; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; Fix E, 1951, 4 US AIR FORC SCH AV; FIX E, 1952, 11 US AIR FORC SCH A; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; XIRU C, 1985, SCI SINICIA A, V29, P673	12	1	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-3758		J STAT PLAN INFER	J. Stat. Plan. Infer.	DEC 15	1997	65	2					323	333		10.1016/S0378-3758(97)00055-4		11	Statistics & Probability	Mathematics	YR571	WOS:000071508600010	
J	Ng, HT; Zelle, J				Ng, HT; Zelle, J			Corpus-based approaches to semantic interpretation in natural language processing	AI MAGAZINE			English	Article								In recent years, there has been a flurry of research into empirical, corpus-based learning approaches to natural language processing (NLP). Most empirical NLP work to date has focused on relatively low-level language processing such as part-of-speech lagging, text segmentation, and syntactic parsing. The success of these approaches has stimulated research in using empirical learning techniques in other facets of NLP, including semantic analysis-uncovering the meaning of an utterance. This article is an introduction to some of the emerging research in the application of corpus-based learning techniques to problems in semantic interpretation. In particular, we focus on two important problems in semantic interpretation, namely, word-sense disambiguation and semantic parsing.	DSO Natl Labs, Singapore, Singapore; Drake Univ, Des Moines, IA USA	Ng, HT (reprint author), DSO Natl Labs, Singapore, Singapore.						Abramson H., 1989, LOGIC GRAMMARS; AGIRRRE E, 1996, P 16 INT C COMP LING; Anderson J. A., 1977, COGNITIVE SCI, V1, P125, DOI 10.1207/s15516709cog0102_1; Brown J. S., 1975, REPRESENTATION UNDER; Brown P.F., 1991, P 29 ANN M ASS COMP, P264, DOI 10.3115/981344.981378; Bruce R, 1994, P 32 ANN M ASS COMP, P139, DOI 10.3115/981732.981752; CARDIE C, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P798; CHOUEKA Y, 1985, COMPUT HUMANITIES, V19, P147, DOI 10.1007/BF02259530; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagan I., 1994, Computational Linguistics, V20; Duda R., 1973, PATTERN CLASSIFICATI; GALE W, 1992, P 30 ANN M ASS COMP, P249, DOI 10.3115/981967.981999; GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984; Hendrix G. G., 1978, ACM Transactions on Database Systems, V3, DOI 10.1145/320251.320253; Hirst G., 1987, SEMANTIC INTERPRETAT; Kelly E. F., 1975, COMPUTER RECOGNITION; KLEIN S, 1970, TR97 U WISC COMP SCI; KUHN R, 1995, IEEE T PATTERN ANAL, V17, P44; LANGLEY P, 1982, COGNITION BRAIN THEO, V5; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LEACOCK C, 1993, P ARPA WORKSH HUM LA, P260, DOI 10.3115/1075671.1075730; Levin E., 1991, P SPEECH NAT LANG WO, P121, DOI 10.3115/112405.112423; LIN DK, 1997, P 35 ANN M ASS COMP; LUK AK, 1995, P 33 ANN M ASS COMP, P181, DOI 10.3115/981658.981683; Magerman D., 1994, THESIS STANFORD U; Miller G, 1994, P ARPA HUM LANG TECH, P240, DOI 10.3115/1075812.1075866; Miller George A., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235; MILLER S, 1994, P 32 ANN M ASS COMP, P25, DOI 10.3115/981732.981736; MILLER S, 1996, P 34 ANN M ASS COMP, P55, DOI 10.3115/981863.981871; Mooney R. J., 1996, P C EMP METH NAT LAN, P82; MOONEY RJ, 1995, MACH LEARN, V19, P79, DOI 10.1007/BF00994661; MUGGLETON S., 1992, INDUCTIVE LOGIC PROG; Ng HT, 1996, P 34 ANN M ASS COMP, P40, DOI 10.3115/981863.981869; NG HT, 1997, P 2 C EMP METH NAT L, P208; NG HT, 1997, P ACL SIGLEX WORKSH, P1; Pedersen T., 1997, P 2 C EMP METH NAT L, P197; PEDERSEN T, 1997, P 14 NAT C ART INT M; PEDERSEN T, 1997, P 5 C APPL NAT LANG, P388, DOI 10.3115/974557.974613; PEH LS, 1997, P 5 WORKSH VER LARG, P56; Procter Paul, 1978, LONGMAN DICT CONT EN; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; REEKER L, 1976, ADV COMPUTERS, V15; RESNIK P, 1997, P ACL SIGLEX WORKSH, P52; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Schutze H., 1992, Proceedings. Supercomputing '92. (Cat. No.92CH3216-9), DOI 10.1109/SUPERC.1992.236684; Schutze H., 1995, P 4 ANN S DOC AN INF, P161; SELFRIDGE M, 1981, P 7 INT JOINT C ART, P106; SEMBUGAMOORTHY V, 1981, P 7 INT JOINT C ART, P106; SIKLOSSY L, 1972, REPRESENTATION MEANI; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Warren D. H. D., 1982, American Journal of Computational Linguistics, V8; WILKINSON YA, 1990, MUTAGENESIS, V5, P99, DOI 10.1007/BF00393758; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773; Yarowsky D., 1992, P 14 INT C COMP LING, P454; Yarowsky D., 1994, P 32 ANN M ASS COMP, P88, DOI 10.3115/981732.981745; Yarowsky D., 1995, P 33 ANN M ASS COMP, P189, DOI 10.3115/981658.981684; Yarowsky David, 1993, P ARPA HUM LANG TECH, P266, DOI 10.3115/1075671.1075731; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; ZELLE JM, 1995, THESIS U TEXAS AUSTI	61	14	14	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602		AI MAG	AI Mag.	WIN	1997	18	4					45	64				20	Computer Science, Artificial Intelligence	Computer Science	YN301	WOS:000071153200006	
J	Blum, AL; Langley, P				Blum, AL; Langley, P			Selection of relevant features and examples in machine learning	ARTIFICIAL INTELLIGENCE			English	Review						relevant features; relevant examples; machine learning	IRRELEVANT ATTRIBUTES; LEARNABILITY; ALGORITHMS; INFERENCE; QUERIES	In this survey, we review work in machine learning on methods for handling data sets containing large amounts of irrelevant information. We focus on two key issues: the problem of selecting relevant features, and the problem of selecting relevant examples, We describe the advances that have been made on these topics in both empirical and theoretical work in machine learning, and we present a general framework that we use to compare different methods. We close with some challenges for future work in this area, (C) 1997 Elsevier Science B.V.	Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; Inst Study Learning & Expertise, Palo Alto, CA 94306 USA; Daimler Benz AG, Res & Technol Ctr, Intelligent Syst Lab, Palo Alto, CA 94304 USA	Blum, AL (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.						AHA D, 1990, THESIS U CALIFORNIAC; AHA DW, 1996, ARTIFICIAL INTELLIGE, V5; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; ANGLUIN D, 1993, J ACM, V40, P185, DOI 10.1145/138027.138061; ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6; ARMSTRONG R, 1993, P AAAI SPR S INF GAT; Baluja S, 1997, ARTIF INTELL, V97, P381, DOI 10.1016/S0004-3702(97)00065-9; Blum A., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195147; BLUM A, 1995, J COMPUT SYST SCI, V50, P32, DOI 10.1006/jcss.1995.1004; Blum A., 1993, Proceedings. 34th Annual Symposium on Foundations of Computer Science (Cat. No.93CH3368-8), DOI 10.1109/SFCS.1993.366856; BLUM A, 1995, P 12 INT C MACH LEAR, P64; BLUM A, 1992, MACH LEARN, V9, P373, DOI 10.1007/BF00994112; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Breiman L, 1984, CLASSIFICATION REGRE; Bshouty N. H., 1993, Proceedings. 34th Annual Symposium on Foundations of Computer Science (Cat. No.93CH3368-8), DOI 10.1109/SFCS.1993.366857; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, AAAI FALL S REL NEW, P25; Caruana R., 1994, P 11 INT C MACH LEAR, P28; CATLETT J, 1992, P 9 INT C MACH LEARN, P49; Cesa-Bianchi N., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167198; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 1994, Computational Linguistics, V20; Devijver P. A., 1982, PATTERN RECOGNITION; Dhagat A., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), DOI 10.1109/SFCS.1994.365704; Doak J, 1992, CSE9218 U CAL DEP CO; DRUCKER H, 1992, ADV NEURAL INFORMATI, V4; Drucker H., 1994, P 11 INT C MACH LEAR, P53; Dyer M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, DOI 10.1145/73007.73043; Fayyad U, 1996, P 2 INT C KNOWL DISC, P367; Freund Y., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Freund Y., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130429; Garey M.R., 1979, COMPUTERS INTRACTABI; GIL Y, 1993, P 10 INT C MACH LEAR, P128; Greiner R, 1997, ARTIF INTELL, V97, P345, DOI 10.1016/S0004-3702(97)00048-9; GROSS K, 1991, THESIS CARNEGIE MELL; Haussler D., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; JACKSON J, 1994, P IEEE S FDN COMP SC; John G. H., 1994, P 11 INT C MACH LEAR, P121; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Kearns M. J., 1994, INTRO COMPUTATIONAL; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kivinen J., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225121; Kivinen J, 1997, ARTIF INTELL, V97, P325, DOI 10.1016/S0004-3702(97)00039-8; KNOBE B, 1977, INFORM CONTR, V31, P129; KOHAVI R, 1995, P 8 EUR C MACH LEARN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1997, P 9 EUR C MACH LEARN; Koller D., 1996, P 13 INT C MACH LEAR; KONONENKO I, 1994, P 7 EUR C MACH LEARN; KUBAT M, 1993, P 1993 EUR C MACH LE, P367; KULKAMI D, 1990, COMPUTATIONAL MODELS; LANGLEY P, 1994, AAAI 94 WORKSH CAS B, P113; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1993, P 13 INT JOINT C ART, P889; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; LEWIS D, 1992, UMCS1991093 U MASS D; LEWIS D. D., 1992, P SPEECH NAT LANG WO, P212, DOI 10.3115/1075527.1075574; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; LIN LJ, 1992, MACH LEARN, V8, P293, DOI 10.1007/BF00992699; LITTLESTONE N, 1997, ADV NEURAL INFORMATI, V9; LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; LITTLESTONE N., 1991, P 23 ACM S THEOR COM, P465, DOI 10.1145/103418.103467; Lovasz L., 1992, Proceedings 33rd Annual Symposium on Foundations of Computer Science (Cat. No.92CH3188-0), DOI 10.1109/SFCS.1992.267803; Lund C., 1993, Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/167088.167172; Matheus C.J., 1989, P 11 INT JOINT C ART, P645; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349; Minsky M., 1969, PERCEPTRONS INTRO CO; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; NORTON S. W., 1989, P 11 INT JOINT C ART, P800; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PAZZANI MJ, 1992, MACH LEARN, V9, P349, DOI 10.1007/BF00994111; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J.R., 1983, MACHINE LEARNING ART; RAJAMONEY S, 1990, COMPUTATIONAL MODELS; RIVEST RL, 1993, INFORM COMPUT, V103, P299, DOI 10.1006/inco.1993.1021; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAMMUT C, 1986, MACHINE LEARNING ART, V2; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; SCOTT PD, 1991, CONCEPT FORMATION KN; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; Shen W., 1989, P IJCAI 89 DETR MI, P675; SINCLAIR A, 1989, INFORM COMPUT, V82, P93, DOI 10.1016/0890-5401(89)90067-9; Singh M, 1995, P 12 INT C MACH LEAR, P497; SINGH M, 1996, P 13 INT C MACH LEAR; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; STANFILL C, 1987, P 6 NAT C ART INT AA, P577; TING KM, 1994, 491 U SYDN BASS DEP; TOWNSENDWEBER T, 1994, AAAI 94 WORKSH CAS B, P30; Verbeurgt K., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; VERE SA, 1975, P 4 INT JOINT C ART, P281; Vovk V. G., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory; Widrow B., 1960, IRE WESCON CONV RE 4, P96; Winston P. H., 1975, PSYCHOL COMPUTER VIS	102	704	725	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	DEC	1997	97	1-2					245	271		10.1016/S0004-3702(97)00063-5		27	Computer Science, Artificial Intelligence	Computer Science	YP845	WOS:000071321500008	
J	Mandal, DP				Mandal, DP			Partitioning of feature space for pattern classification	PATTERN RECOGNITION			English	Article						pattern classification; fuzzy partitioning; fuzzy if-then rules; fuzzy sets; compositional rule of inference; management of uncertainty	RECOGNITION SYSTEM; FUZZY RULES; SETS; REPRESENTATION; DIAGNOSIS	The article proposes a simple approach for finding a fuzzy partitioning of a feature space for pattern classification problems. A feature space is initially decomposed into some overlapping hyperboxes depending on the relative positions of the pattern classes found in the training samples. A few fuzzy if-then rules reflecting the pattern classes by the generated hyperboxes are then obtained in terms of a relational matrix. The relational matrix is utilized in the modified compositional rule of inference in order to recognize an unknown pattern. The proposed system is capable of handling imprecise information both in the learning and the processing phases. The imprecise information is considered to be either incomplete or mixed or interval or linguistic in form. Ways of handling such imprecise information are also discussed. The effectiveness of the system is demonstrated on some synthetic data sets in two-dimensional feature space. The practical applicability of the system is verified on four real data such as the Iris data set, an appendicitis data set, a speech data set and a hepatic disease data set. (C) 1997 Pattern Recognition Society. Published by Elsevier Science Ltd.	Univ Osaka Prefecture, Dept Ind Engn, Sakai, Osaka 593, Japan	Mandal, DP (reprint author), Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Calcutta 700035, W Bengal, India.	dpmandal@isical.ernet.in					ABE S, 1995, IEEE T FUZZY SYST, V3, P18, DOI 10.1109/91.366565; AHMAD S, 1993, P IEEE INT C NEUR NE, P1949; Bezdek J., 1981, PATTERN RECOGNITION; Bezdek J.C., 1992, FUZZY MODELS PATTERN; Breiman L, 1984, CLASSIFICATION REGRE; Burkhardt D., 1992, P 1992 IEEE INT C FU, P179; CACOULLOS T, 1966, ANN I STAT MATH, V18, P178; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fu K. S., 1982, SYNTACTIC PATTERN RE; Grabisch M., 1992, P 1 IEEE C FUZZ SYST, P47; Grabisch M, 1992, P 2 INT C FUZZ LOG N, P659; GRENANDER U, 1981, INFERENCE; Hayashi I., 1992, International Journal of Approximate Reasoning, V6, DOI 10.1016/0888-613X(92)90019-V; ISHIBUCHI H, 1993, FUZZY SET SYST, V59, P295, DOI 10.1016/0165-0114(93)90474-V; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; ISHIBUCHI H, 1993, P IEEE INT JOINT C N, P1871; JANG JSR, 1992, P FUZZ IEEE 92, P287; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LEE CC, 1990, IEEE T SYST MAN CYB, V20, P404, DOI 10.1109/21.52551; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MANDAL DP, 1992, IEEE T SYST MAN CYB, V22, P607, DOI 10.1109/21.156575; MANDAL DP, 1992, THESIS INDIAN STAT I; MANDAL DP, 1992, INT J GEN SYST, V20, P307, DOI 10.1080/03081079208945038; MANDAL DP, 1996, IN PRESS INT J GEN S; MARCHAND A, 1983, AM J CLIN PATHOL, V80, P369; Murthy C.A., 1988, THESIS INDIAN STAT I; OWENS AJ, 1989, P IEEE INNS INT JOIN, P381; PAL SK, 1992, INFORM SCIENCES, V61, P135, DOI 10.1016/0020-0255(92)90037-9; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; PAL SK, 1986, FUZZY MATH APPPROACH; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SCHWARTZ DG, 1985, FUZZY SET SYST, V17, P153, DOI 10.1016/0165-0114(85)90053-3; Sridharan NS, 1989, P 11 INT JOINT C ART, P781; SUGENO M, 1985, INFORM SCIENCES, V36, P59, DOI 10.1016/0020-0255(85)90026-X; Sugeno M., 1985, IEEE T SYST MAN CYB, V15, P116; TANAKA H, 1992, INT J GEN SYST, V21, P83, DOI 10.1080/03081079208945054; TANAKA H, 1993, INTELLIGENT DECISION, P111; WANG LX, 1991, 169 U SO CAL; WEISS SM, 1990, ARTIF INTELL, V45, P47, DOI 10.1016/0004-3702(90)90037-Z; Zadeh L., 1975, SYNTHESE, V30, P407, DOI DOI 10.1007/BF00485052; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; Zadeh L.A., 1975, FUZZY SETS THEIR APP, P1	51	10	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	DEC	1997	30	12					1971	1990		10.1016/S0031-3203(97)00012-5		20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	ZH243	WOS:000073087700003	
J	Zhao, QF				Zhao, QF			Stable on-line evolutionary learning of NN-MLP	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						nearest-neighbor-based multilayer perceptron; nongenetic evolutionary learning; on-line learning; R-4-rule; supervised competitive learning	NEIGHBOR PATTERN-CLASSIFICATION; DESIGN	To design the nearest-neighbor-based multilayer perceptron (NN-MLP) efficiently, the author has proposed a nongenetic-based evolutionary algorithm called the R-4-rule, For off-line learning, the R-4-rule can produce the smallest or nearly smallest networks with high generalization ability by iteratively performing four basic operations: recognition, remembrance, reduction, and review, This algorithm, however, cannot be applied directly to on-line learning because its inherent instability, which is caused by over-reduction and over-review, To stabilize the R-4-rule, this paper proposes some improvements for reduction and review, The improved reduction is more robust for on-line learning because the fitness of each hidden neuron is defined by its overall behavior in many learning cycles, The new review is more efficient because hidden neurons are adjusted in a more careful way, The performance of the improved R-4-rule for on-line learning is shown by experimental results.		Zhao, QF (reprint author), UNIV AIZU,AIZU WAKAMATSU 96580,JAPAN.						BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CHANG EJ, 1991, ADV NEURAL INFORMATI, P797; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; ZHAO QF, 1994, P INT C NEUR INF PRO, P1398; ZHAO QF, 1995, P WORLD C NEUR NETW, P636; ZHAO QF, 1994, P IEICE KAUR WORKSH, P121; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762	18	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	NOV	1997	8	6					1371	1378		10.1109/72.641460		8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	YE466	WOS:A1997YE46600013	
J	Weng, J; Ahuja, N; Huang, TS				Weng, J; Ahuja, N; Huang, TS			Learning recognition and segmentation using the Cresceptron	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual learning; face recognition; face detection; object recognition; object segmentation; feature selection; feature extraction; shape representation; self-organization; associative memory	3-D OBJECT RECOGNITION; NEURAL NETWORK MODEL; PATTERN-RECOGNITION; MECHANISM; VISION; NEOCOGNITRON	This paper presents a framework called Cresceptron for view-based learning, recognition and segmentation. Specifically, it recognizes and segments image patterns that are similar to those learned, using a stochastic distortion model and view-based interpolation, allowing other view points that are moderately different from those used in learning. The learning phase is interactive. The user trains the system using a collection of training images. For each training image, the user manually draws a polygon outlining the region of interest and types in the label of its class. Then, from the directional edges of each of the segmented regions, the Cresceptron uses a hierarchical self-organization scheme to grow a sparsely connected network automatically, adaptively and incrementally during the learning phase. At each level, the system detects new image structures that need to be learned and assigns a new neural plane for each new feature. The network grows by creating new nodes and connections which memorize the new image structures and their context as they are detected. Thus, the structure of the network is a function of the training exemplars. The Cresceptron incorporates both individual learning and class learning; with the former, each training example is treated as a different individual while with the latter, each example is a sample of a class. In the performance phase, segmentation and recognition are tightly coupled. No foreground extraction is necessary, which is achieved by backtracking the response of the network down the hierarchy to the image parts contributing to recognition. Several stochastic shape distortion models are analyzed to show why multilevel matching such as that in the Cresceptron can deal with more general stochastic distortions that a single-level matching scheme cannot. The system is demonstrated using images from broadcast television and other video segments to learn faces and other objects, and then later to locate and to recognize similar, but possibly distorted, views of the same objects.	UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801	Weng, J (reprint author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.						Anderson J. R., 1990, COGNITIVE PSYCHOL IT; ARMAN F, 1991, JUN IEEE WORKSH DIR, P124; Bichsel M., 1991, THESIS SWISS FEDERAL; Breiman L, 1984, CLASSIFICATION REGRE; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CARBONETTO S, 1982, CURR TOP DEV BIOL, V17, P33; CAREW TJ, 1989, TRENDS NEUROSCI, V12, P389, DOI 10.1016/0166-2236(89)90078-7; Carey S., 1985, CONCEPTUAL CHANGE CH; CHEN CH, 1989, IEEE T SYST MAN CYB, V19, P1535, DOI 10.1109/21.44070; COVER TM, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESMOND N L, 1988, P265; DREHER B, 1973, J PHYSIOL-LONDON, V234, P95; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Fu K, 1968, SEQUENTIAL METHODS P; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826; FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; GOOL LV, 1991, P IEEE C COMP VIS PA, P454; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GUTH L, 1975, EXPT NEUROLOGY, V48; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; HEBB DO, 1949, ORG BEHAVIOR; HIGHLEYMAN WH, 1962, P IRE, V50, P1501, DOI 10.1109/JRPROC.1962.288194; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; HUBEL DH, 1988, EYE BRAIN VISION, P22; HUTTENLOCHER DP, 1987, 1ST P INT C COMP VIS, P102; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JAIN AK, 1988, IEEE T PATTERN ANAL, V10, P783, DOI 10.1109/34.9102; KANDEL ER, 1982, SCIENCE, V218, P433, DOI 10.1126/science.6289442; KEEHN DG, 1965, IEEE T INFORM THEORY, V11, P126, DOI 10.1109/TIT.1965.1053726; Kohonen T., 1988, SELF ORG ASS MEMORY; KOLERS PA, 1985, J EXP PSYCHOL HUMAN, V11, P726, DOI 10.1037//0096-1523.11.6.726; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1); Levy-Schoen A., 1981, EYE MOVEMENTS COGNIT, P299; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Lowe D. G, 1985, PERCEPTUAL ORG VISUA; Martinez J. L., 1991, LEARNING MEMORY BIOL; MICHALSKI RS, 1986, 5TH P NAT C ART INT, P1041; NAZIR T A, 1990, Spatial Vision, V5, P81, DOI 10.1163/156856890X00011; Pavlidis T., 1977, STRUCTURAL PATTERN R; PAVLIDIS T, 1992, PATTERN RECOGN LETT, V13, P221, DOI 10.1016/0167-8655(92)90072-8; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Pomerleau D., 1989, ADV NEURAL INFORMATI, V1, P305; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RAKIC P, 1988, SCIENCE, V241, P170, DOI 10.1126/science.3291116; RAMACHANDRAN VS, 1990, PERCEPTUAL WORLD, P127; ROWLEY HA, 1995, CMUCS95158; ROYDEN HL, REAL ANAL; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Sacks O., 1993, NEW YORKER, P59; Sato H., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), DOI 10.1109/CVPR.1992.223198; SHATZ CJ, 1992, SCI AM           SEP, P61; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; SUNG K, 1994, 1521 AI; SWETS D, 1995, P INT C IM PROC WASH, P22; THOMPSON P, 1980, PERCEPTION, V9, P483, DOI 10.1068/p090483; TREISMAN A, 1983, PHYSICAL BIOL PROCES; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536; WENG J, 1993, P WORLD C NEUR NETW, V4, P149; WENG J, 1996, EARLY VISUAL LEARNIN; Weng J., 1992, P INT JOINT C NEUR N, V1, P576, DOI 10.1109/IJCNN.1992.287150; Weng J., 1993, P 4 INT C COMP VIS B, P121; WILSON HR, 1977, VISION RES, V17, P1177, DOI 10.1016/0042-6989(77)90152-3; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; YANG GZ, 1994, PATTERN RECOGN, V27, P53, DOI 10.1016/0031-3203(94)90017-5; Yarbus AL, 1967, EYE MOVEMENTS VISION	72	15	15	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1997	25	2					109	143		10.1023/A:1007967800668		35	Computer Science, Artificial Intelligence	Computer Science	YG836	WOS:A1997YG83600002	
J	Ros, F; Guillaume, S; Rabatel, G; Sevila, F; Bertrand, D				Ros, F; Guillaume, S; Rabatel, G; Sevila, F; Bertrand, D			Combining global and individual image features to characterize granular product populations	JOURNAL OF CHEMOMETRICS			English	Article						image analysis; granular product; selection; classification		The characterization of granular product populations using image analysis is a difficult problem because it often requires the extraction and combination of many different features. We propose to study in a general way these problems of granular product classification, considering the image analysis phase, the processing of the information extracted and the decision making, In this paper we focus rather on the decision system development. It is based on a hierarchical approach to the problem, in eluding a generalist system whose outputs are ambiguous (an approximative solution), connected to specialist systems trained to give non-ambiguous solutions, The inputs of the generalist system are the components of a vector containing the most important information for discriminating all the decision classes, while the inputs of the specialist systems are those which best distinguish a given class from another. This strategy enables us to overcome the multiclass aspect of the problem. It is independent of the choice of the techniques to select the pertinent information and to take the decision, This method is applied in the framework of a meal classification where three types of classifier (discriminant analysis, k nearest neighbours and multilayer neural networks) are compared. (C) 1997 John Wiley & Sons, Ltd.	CTR NATL MACHINISME AGR GENIE RURAL EAUX & FORETS,F-34033 MONTPELLIER 1,FRANCE; INRA,F-44026 NANTES 03,FRANCE			Guillaume, Serge/H-2112-2011				BERTRAND D, 1990, J CHEMOMETR, V4, P413, DOI 10.1002/cem.1180040605; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOUCART T, 1982, ANAL FACTORIELLE MIC; KHOTANZAD A, 1987, IEEE T SYST MAN CYB, V17, P1087; Lebart L, 1982, TRAITEMENT DONNEES S; LECUN Y, 1990, NEURAL INFORMATION P, V2, P396; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; LOH HH, 1988, IEEE T IND ELECTRON, V35, P323, DOI 10.1109/41.192665; Pao Y. H., 1989, ADAPTIVE PATTERN REC; ROS F, 1993, P INT WORKSH ART NEU, P726; ROS F, IN PRESS J CHEMOMETR; ROS F, 1993, P SPIE C VIS SENS CO, P120; Serra J., 1982, IMAGE ANAL MATH MORP; SINFORT N, 1993, THESIS U MONTPELLIER	14	2	2	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX, ENGLAND PO19 1UD	0886-9383		J CHEMOMETR	J. Chemometr.	NOV-DEC	1997	11	6					483	500		10.1002/(SICI)1099-128X(199711/12)11:6<483::AID-CEM490>3.0.CO;2-8		18	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	YJ419	WOS:A1997YJ41900002	
J	Chowdhury, N; Murthy, CA				Chowdhury, N; Murthy, CA			Minimal spanning tree based clustering technique: Relationship with Bayes Classifier	PATTERN RECOGNITION			English	Article						pattern recognition; clustering; minimal spanning tree; Bayes classifier; triangular distribution; truncated normal distribution; error probability	GENETIC ALGORITHMS	A minimal spanning tree (MST) based clustering technique along with its theoretical formulation is presented in this paper. The proposed technique is compared with Bayes Classifier and it is shown theoretically that the clustering technique, although an unsupervised one, approaches the performance of Bayes Classifier under a condition, as the number of sample points from each class increases. Experimental results with many synthetic data sets in 2-D and 3-D validate the theoretical prediction. (C) 1997 Pattern Recognition Society. Published by Elsevier Science Ltd.	Ramakrishna Mission Shilpapitha, Dept Elect Engn, Calcutta 700035, W Bengal, India; Indian Stat Inst, Machine Intelligence Unit, Calcutta 700035, W Bengal, India	Chowdhury, N (reprint author), Ramakrishna Mission Shilpapitha, Dept Elect Engn, Calcutta 700035, W Bengal, India.						Anderberg M. R., 1973, CLUSTER ANAL APPL; ANKENBRANDT CA, 1990, PATTERN RECOGN LETT, V11, P285, DOI 10.1016/0167-8655(90)90067-C; CHAUDHURI D, 1994, IEEE SMC, V9, P1416; CHAUDHURI D, IN PRESS PATTERN REC; CHOWDHURY N, 1994, IN PRESS FINDING NAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R., 1973, PATTERN CLASSIFICATI; Fukunaga K, 1972, INTRO STAT PATTERN R; Jain A., 1988, ALGORITHMS CLUSTERIN; Johnson R.A., 1982, APPL MULTIVARIATE ST; JULIUS TT, 1974, PATTERN RECOGNITION; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171; MANDAL DP, 1995, IN PRESS INT J GEN S; MANDAL DP, 1995, INT J UNCERTAIN FUZZ, V4, P401; MANDAL DP, 1995, IN PRESS PATTERN REC; Murthy CA, 1996, PATTERN RECOGN LETT, V17, P825, DOI 10.1016/0167-8655(96)00043-8; MURTHY CA, 1989, THESIS ISI CALCUTTA; Reiss R.-D., 1978, Metrika, V25, DOI 10.1007/BF02204347; Richards J. A., 1986, REMOTE SENSING DIGIT; RYZIN V, 1973, COMMUN STAT, V2, P493; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; Spath H, 1980, CLUSTER ANAL ALGORIT	23	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	1997	30	11					1919	1929		10.1016/S0031-3203(96)00188-4		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	YN133	WOS:000071136400010	
J	Ho, TK; Baird, HS				Ho, TK; Baird, HS			Large-scale simulation studies in image pattern recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; classifier; document image analysis; character recognition; image defect model; simulation; intrinsic error; Bayes risk; asymptotic accuracy	ERROR	Many obstacles to progress in image pattern recognition result from the fact that per-class distributions are often too irregular to be well-approximated by simple analytical functions. simulation studies offer one way to circumvent these obstacles. We present three closely related studies of machine-printed character recognition that rely on synthetic data generated pseudorandomly in accordance with an explicit stochastic model of document image degradations. The unusually large scale of experiments-involving several million samples-that this methodology makes possible has allowed us to compute sharp estimates of the intrinsic difficulty (Bayes risk) of concrete image recognition problems, as well as the asymptotic accuracy and domain of competency of classifiers.		Ho, TK (reprint author), AT&T BELL LABS, 700 MT AVE, 2C-425, MURRAY HILL, NJ 07974 USA.						Baird H. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), DOI 10.1109/ICDAR.1993.395781; Baird H. S., 1993, Proceedings. Second Annual Symposium on Document Analysis and Information Retrieval; BAIRD HS, 1991, P 1 INT C DOC AN REC, P332; BAIRD HS, 1992, STRUCTURED DOCUMENT, P546; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HO TK, 1992, THESIS SUNY BUFFALO; HO TK, 1998, IN PRESS COMPUTER VI; Ho T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), DOI 10.1109/ICDAR.1993.395665; HO TK, 1994, INT C PATT RECOG, P178; Ho TK, 1995, P 3 INT C DOC AN REC, P278; HO TK, 1994, P 3 ANN S DOC AN INF, P275; HO TK, 1995, P 4 ANN S DOC AN INF, P413; KANUNGO T, 1995, P 1 IARP WORKSH GRAP, P217; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; RICE SV, 1993, INFORMATION SCI RES, P9; RICE SV, 1994, INFORMATION SCI RES, P11; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; Vapnik V., 1982, ESTIMATION DEPENDENC; *U WASH DEP EL ENG, 1993, ENGL DOC DAT 1 2 CD	21	41	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1067	1079				13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	YB678	WOS:A1997YB67800003	
J	Ros, F; Guillaume, S; BellonMaurel, V				Ros, F; Guillaume, S; BellonMaurel, V			Classification of a granular product using high-level fusion of vision features	JOURNAL OF AGRICULTURAL ENGINEERING RESEARCH			English	Article							IMAGE-ANALYSIS	The characterization of a granular product based on image analysis can be a difficult problem because it often requires the combination of a large number of features of different natures extracted from the image. This problem of classification can be solved by two approaches. One of these approaches consists of aggregating the qualitative information which is obtained by considering each individual feature, as a virtual sensor. This is a triple-step system: first, for each feature (i.e. virtual sensor), the samples are given a probability of belonging to a class (clustering); second, these probabilities are aggregated in order to give a global probability of the sample of belonging to each class (supervised neural network); third, the sample is assigned to the class which shows the maximal global probability. This procedure was applied to classify semolina samples. These were obtained by grinding wheat grains. Three classes were defined using three grinding roll gaps of 0.3, 0.4 and 0.5 mm, respectively. The average of correct classification was better than 80%. This methodology is particularly interesting because it gives a very satisfactory result and is quite versatile new features added to the classification process require an update of one part of the procedure only. (C) 1997 Silsoe Research Institute.		Ros, F (reprint author), CEMAGREF,361 RUE JF BRETON,BP 5095,F-34033 MONTPELLIER 1,FRANCE.		Guillaume, Serge/H-2112-2011				BERTRAND D, 1991, POWDER TECHNOL, V66, P171, DOI 10.1016/0032-5910(91)80098-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GALLOWAY M, COMPUTER GRAPHICS IM, V4, P171; Guillaume S, 1996, J FOOD ENG, V27, P311, DOI 10.1016/0260-8774(95)00013-5; HALL LD, 1992, MATH TECHNIQUES MULT; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; ROS F, 1993, P INT WORKSH ART NEU, P726; ROS F, 1997, IN PRESS J CHEMOMETR; SAPIRSTEIN HD, 1987, J CEREAL SCI, V6, P3; Serra J., 1982, IMAGE ANAL MATH MORP; Steinmetz V, 1996, J AGR ENG RES, V64, P15, DOI 10.1006/jaer.1996.0042; ZAYAS I, 1989, CEREAL CHEM, V66, P233	13	1	1	ACADEMIC PRESS LTD	LONDON	24-28 OVAL RD, LONDON, ENGLAND NW1 7DX	0021-8634		J AGR ENG RES	J. Agr. Eng. Res.	OCT	1997	68	2					115	124		10.1006/jaer.1997.0189		10	Agricultural Engineering	Agriculture	YF256	WOS:A1997YF25600005	
J	Duval, R; Vanhee, P; Ferry, D				Duval, R; Vanhee, P; Ferry, D			Detection of edge tears and classification of their severity level on the 50'' cleaning line at Sollac Florange	REVUE DE METALLURGIE-CAHIERS D INFORMATIONS TECHNIQUES			French	Article; Proceedings Paper	1996 ATS International Steelmaking Conference	DEC 11-12, 1996	PARIS, FRANCE	Assoc Tech Siderurg Francaise				Edge rears may cause strip breaking during various cold processes following tandem mill rolling. In ol-der to prevent such incidents, an optical detection system has been developed at Sollac Florange. The system uses modern linear high speed cameras and image processing techniques.								BOUCHONMEUNIER B, LOGIQUE FLOUE COLLEC; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1979, T INFORM THEORY, V25, P749; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580	7	0	0	REVUE DE METALLURGIE	NANTERRE CEDEX	LES FONTENELLES, 1 RUE DE CRAIOVA, 92024 NANTERRE CEDEX, FRANCE	0035-1563		REV METALL-PARIS	Rev. Metall.-Cah. Inf. Techn.	OCT	1997	94	10					1243	1249				7	Metallurgy & Metallurgical Engineering	Metallurgy & Metallurgical Engineering	YG034	WOS:A1997YG03400008	
J	Lipman, A; Yang, WW				Lipman, A; Yang, WW			VLSI hardware for example-based learning	IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS			English	Article								Example-based learning, as performed by neural networks and other approximation and classification techniques, is both computationally intensive and I/O intensive, typically involving the optimization of hundreds or thousands of parameters during repeated network evaluations over a database of example vectors, Although there is currently no dominant approach or technique among the various neural networks and learning algorithms, the basic functionality of most neural networks can be conceptually realized as a multidimensional look-up table, While multidimensional look-up tables are clearly impractical due to the exponential memory requirements, we are pursuing an approach using interpolation based only on the sparse data provided by an initial example database, In particular, we have designed prototype VLSI components for searching multidimensional example databases for the k closest examples to an input query as determined by a programmable metric using a massively parallel search, This nearest-neighbor approach can be used directly for classification, or in conjunction with any number of neural network algorithms that exploit local fitting, The hardware removes the I/O bottleneck from the learning task by supplying a reduced set of examples for localized training or classification, Though nearest-neighbor retrieval algorithms have efficient software implementations for low-dimensional databases, exhaustive searching is the only effective approach for handling high-dimensional data, The parallel VLSI hardware we have designed can accelerate the exhaustive search by three orders of magnitude, We believe this special purpose VLSI will have direct application in systems requiring learning functionality and in accelerating learning applications on large, high-dimensional databases.		Lipman, A (reprint author), HARVARD UNIV,DIV ENGN & APPL SCI,CAMBRIDGE,MA 02138, USA.						ANLAUF J, 1995, TR95011 U MANNH; CHEN C, 1995, P WORLD C NEUR NETW; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ELLIOTT DG, 1992, P CICC 1992 MAY; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219; HEGT JA, 1993, P MEASUREMENT ARTIFI; IENNE P, 1995, SPIE OPTICAL ENG CR, V57, P314; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Kramer A, 1997, ISSCC DIG TECH PAP I, V40, P44, DOI 10.1109/ISSCC.1997.585253; Lindsey C., 1994, P 3 WORKSH NEUR NETW; NIEMANN H, 1988, PATTERN RECOGN LETT, V7, P67, DOI 10.1016/0167-8655(88)90120-1; Omohundro S. M., 1987, Complex Systems, V1; Omohundro S. M., 1989, TR89063 INT COMP SCI; PAPADIMITRIOU CH, 1980, LECT NOTES COMPUTER, V85, P470; PARK C, 1993, P INT JOINT C NEUR N, V3, P3035; *CURR TECHN INC, 1995, MM325 PREL DOC	17	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1063-8210		IEEE T VLSI SYST	IEEE Trans. Very Large Scale Integr. (VLSI) Syst.	SEP	1997	5	3					320	328		10.1109/92.609875		9	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	XU131	WOS:A1997XU13100010	
J	Edelman, S; DuvdevaniBar, S				Edelman, S; DuvdevaniBar, S			A model of visual recognition and categorization	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY OF LONDON SERIES B-BIOLOGICAL SCIENCES			English	Article							INFEROTEMPORAL CORTEX; 3-DIMENSIONAL SHAPES; OBJECT RECOGNITION; REPRESENTATION; ORGANIZATION; PROTOTYPES; SURFACE	To recognize a previously seen object, the visual system must overcome the variability in the object's appearance caused by factors such as illumination and pose. Developments in computer vision suggest that it may be possible to counter the influence of these factors, by learning to interpolate between stored views of the target object, taken under representative combinations of viewing conditions. Daily life situations, however, typically require categorization, rather than recognition, of objects. Due to the open-ended character of both natural and artificial categories, categorization cannot rely on interpolation between stored examples. Nonetheless, knowledge of several representative members, or prototypes, of each of the categories of interest can still provide the necessary computational substrate for the categorization of new instances. The resulting representational scheme based on similarities to prototypes appears to be computationally viable, and is readily mapped onto the mechanisms of biological vision revealed by recent psychophysical and physiological studies.	WEIZMANN INST SCI,DEPT APPL MATH & COMP SCI,IL-76100 REHOVOT,ISRAEL	Edelman, S (reprint author), MIT,CTR BIOL & COMPUTAT LEARNING,CAMBRIDGE,MA 02142, USA.						Basri R, 1996, INT J COMPUT VISION, V19, P147, DOI 10.1007/BF00055802; BAXTER J, 1995, NCTR95047 U LOND; BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037//0033-295X.94.2.115; Broomhead D. S., 1988, Complex Systems, V2; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cutzu F, 1996, P NATL ACAD SCI USA, V93, P12046, DOI 10.1073/pnas.93.21.12046; Duda R., 1973, PATTERN CLASSIFICATI; EDELMAN S, 1992, LECT NOTES COMPUT SC, V588, P787; EDELMAN S, 1997, IN PRESS VISION; EDELMAN S, 1995, MIND MACH, V5, P45, DOI 10.1007/BF00974189; EDELMAN S, 1997, IN PRESS BEHAV BRAIN; EDELMAN S, 1997, IN PRESS MECH PERCEP; Edelman S., 1995, NEURAL COMPUT, V7, P407; Edelman S, 1997, NEURAL COMPUT, V9, P701, DOI 10.1162/neco.1997.9.4.701; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P330, DOI 10.1109/34.485561; JOLICOEUR P, 1984, COGNITIVE PSYCHOL, V16, P243, DOI 10.1016/0010-0285(84)90009-4; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MEL B, 1996, SEEMORE COMBINING CO; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Palmer S., 1981, ATTENTION PERFORM, VIX, P135; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; PRICE CJ, 1989, Q J EXP PSYCHOL-A, V41, P797; Rosch E., 1978, COGNITION CATEGORIZA, P27; SCHIELE B, 1996, LECT NORES COMPUTER, P610; SHAPIRA Y, 1991, P IJCAI, P1257; SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390; SHEPARD RN, 1973, COGNITIVE PSYCHOL, V4, P351, DOI 10.1016/0010-0285(73)90018-2; SMITH EE, 1990, INVITATION COGNITIVE, V2, P33; SUGIHARA T, 1996, P ARVO INVEST OPHT S, V37; Tanaka K, 1996, ANNU REV NEUROSCI, V19, P109, DOI 10.1146/annurev.neuro.19.1.109; Tanaka K, 1992, Curr Opin Neurobiol, V2, P502, DOI 10.1016/0959-4388(92)90187-P; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Ullman S, 1996, HIGH LEVEL VISION; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Wang G, 1996, SCIENCE, V272, P1665, DOI 10.1126/science.272.5268.1665	41	53	53	ROYAL SOC LONDON	LONDON	6 CARLTON HOUSE TERRACE, LONDON, ENGLAND SW1Y 5AG	0962-8436		PHILOS T ROY SOC B	Philos. Trans. R. Soc. Lond. Ser. B-Biol. Sci.	AUG 29	1997	352	1358					1191	1202				12	Biology	Life Sciences & Biomedicine - Other Topics	XU805	WOS:A1997XU80500009	
J	Chen, YQ; Damper, RI; Nixon, MS				Chen, YQ; Damper, RI; Nixon, MS			On neural-network implementations of k-nearest neighbor pattern classifiers	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-FUNDAMENTAL THEORY AND APPLICATIONS			English	Article						Logic circuits; neural-network applications; neural-network hardware; pattern recognition	VORONOI DIAGRAMS; FAULT-TOLERANCE; CLASSIFICATION; PERCEPTRONS; ALGORITHM; DESIGN	The k-nearest neighbor (k-NN) decision rule is the basis of a well-established, high-performance pattern-recognition technique but its sequential implementation is inherently slow. More recently, feedforward neural networks trained on error backpropagation have been widely used to solve a variety of pattern-recognition problems. However, it is arguably unnecessary to learn such a computationally intensive solution when one (i.e., the k-NN rule) is effectively available a priori, especially given the well-known pitfalls of backpropagation. Accordingly, there is some interest in the literature in network implementations of this rule, so as to combine its known, good performance with the speed of a massively parallel realization. In this paper, we present a novel neural-network architecture which implements the L-NN rule and whose distinctive feature relative to earlier work is its synchronous (i.e., clocked) nature. Essentially, it has a layered, feedforward structure but, in its basic form, also incorporates feedback to control sequential selection of the k neighbors. The principal advantages of this new scheme are the avoidance of the stability problems which can arise with alternative asynchronous feedback (lateral-inhibition) circuits, the restriction of analog weights to the first hidden layer and the fact that network design uses noniterative weight calculations rather than iterative backpropagation. Analysis of the network shows that it will converge to the desired solution (faithfully classifying the input pattern according to the k-NN rule) within (2k - 1) clock cycles. Apart from minor changes which can be effected externally, the same design serves for any value of X. The space complexity of the ('brute-force'' network implementation is O(N-2) units, where N is the number of training patterns, and it has O(N(2)d) analog weights where d is the dimensionality of these patterns. Thus, some modifications to reduce the required number of units (and, thereby, weighted connections) are considered. Overall, this paper affords for high-speed, parallel implementations of proven pattern-classification techniques.	UNIV SOUTHAMPTON,DEPT ELECT & COMP SCI,SOUTHAMPTON SO17 1BJ,HANTS,ENGLAND	Chen, YQ (reprint author), NANYANG TECHNOL UNIV,SCH ELECT & ELECT ENGN,NANYANG AVE,SINGAPORE 639798,SINGAPORE.						AURENHAMMER F, 1991, COMPUT SURV, V23, P345; BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; CHEN YQ, 1994, NEURAL NETWORKS, V7, P1477; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R., 1973, PATTERN CLASSIFICATI; DWYER RA, 1993, COMPUT MATH APPL, V26, P13, DOI 10.1016/0898-1221(93)90068-7; EMMERSON MD, 1993, IEEE T NEURAL NETWOR, V4, P788, DOI 10.1109/72.248456; GAZULA S, 1995, IEEE T PATTERN ANAL, V17, P1239, DOI 10.1109/34.476519; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HUANG WY, 1988, P IEEE C NEUR INF PR, P42; HUANG WY, 1987, 1ST IEEE INT C NEUR, V4, P485; JAIN AK, 1991, P INT JOINT C NEUR N, V2, P515; JUDD S, 1987, 1ST P IEEE C NEUR NE, V2, P685; Lippmann R. P., 1987, IEEE ASSP MAGAZI APR, P4; MEZARD M, 1989, J PHYS A-MATH GEN, V22, P2191, DOI 10.1088/0305-4470/22/12/019; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; O'Rourke J., 1993, COMPUTATIONAL GEOMET; PARK YH, 1991, P IEEE INT JOINT C N, V3, P2386; PHATAK DS, 1995, IEEE T NEURAL NETWOR, V6, P446, DOI 10.1109/72.363479; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Rumelhart D. E., 1995, BACKPROPAGATION THEO, P1; Schalkoff R, 1992, PATTERN RECOGNITION; SHI PN, 1993, IEEE T NEURAL NETWOR, V4, P234, DOI 10.1109/72.207611; TANK DW, 1986, IEEE T CIRCUITS SYST, V33, P533, DOI 10.1109/TCS.1986.1085953; WEIDEMAN WE, 1995, IEEE T NEURAL NETWOR, V6, P1524, DOI 10.1109/72.471357	27	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1057-7122		IEEE T CIRCUITS-I	IEEE Trans. Circuits Syst. I-Fundam. Theor. Appl.	JUL	1997	44	7					622	629				8	Engineering, Electrical & Electronic	Engineering	XH371	WOS:A1997XH37100006	
J	Linial, M; Linial, N; Tishby, N; Yona, G				Linial, M; Linial, N; Tishby, N; Yona, G			Global self-organization of all known protein sequences reveals inherent biological signatures	JOURNAL OF MOLECULAR BIOLOGY			English	Article						sequence alignment; database searching; clustering; protein families; protein classification	LARGE NUMBERS; DATABASE; SEARCH; BLOCKS	A global classification of all currently known protein sequences is performed. Every protein sequence is partitioned into segments of 50 amino acid residues and a dynamic programming distance is calculated between each pair of segments. This space of segments is initially embedded into Euclidean space. The algorithm that we apply embeds every finite metric space into Euclidean space so that (1) the dimension of the host space is small, (2) the metric distortion is small. A novel self-organized, cross-validated clustering algorithm is then applied to the embedded space with Euclidean distances. We monitor the validity of our clustering by randomly splitting the data into two parts and performing an hierarchical clustering algorithm independently on each part. At every level of the hierarchy we cross-validate the clusters in one part with the clusters in the other. The resulting hierarchical tree of clusters offers a new representation of protein sequences and families, which compares favorably with the most updated classifications based on functional and structural data about proteins. Same of the known families clustered into well distinct clusters. Motifs and domains such as the zinc finger, EF hand, homeobox, EGF-like and others are automatically correctly identified, and relations between protein families are revealed by examining the splits along the tree. This clustering leads to a novel representation of protein families, from which functional biological kinship of protein families can be deduced, as demonstrated for the transporter family. Finally, we introduce a new concise representation for complete proteins that is very useful in presenting multiple alignments, and in searching for close relatives in the database. The self-organization method presented is very general and applies to any data with a consistent and computable measure of similarity between data items. (C) 1997 Academic Press Limited.	HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL; HEBREW UNIV JERUSALEM,INST LIFE SCI,DEPT BIOL CHEM,IL-91904 JERUSALEM,ISRAEL							ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; BAIROCH A, 1993, NUCLEIC ACIDS RES, V21, P3097, DOI 10.1093/nar/21.13.3097; BAIROCH A, 1992, NUCLEIC ACIDS RES, V20, P2019; Barak A., 1995, B IEEE TECHNICAL COM, V7, P5; BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078; Cover TM, 1991, ELEMENTS INFORMATION, P12; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUKIERMAN E, 1995, SCIENCE, V270, P1999, DOI 10.1126/science.270.5244.1999; Duda R.O., 1973, PATTERN CLASSIFICATI, P189; FERRAN EA, 1994, PROTEIN SCI, V3, P507; GONNET GH, 1992, SCIENCE, V256, P1443, DOI 10.1126/science.1604319; GRAY RM, 1980, INFORM CONTROL, V45, P178, DOI 10.1016/S0019-9958(80)90313-7; Gray Robert M., 1984, IEEE ASSP MAG    APR, P4; GRIBSKOV M, 1987, P NATL ACAD SCI USA, V84, P4355, DOI 10.1073/pnas.84.13.4355; HAN KF, 1995, J MOL BIOL, V251, P176, DOI 10.1006/jmbi.1995.0424; Hanke J, 1996, PROTEIN SCI, V5, P72; Hardison RC, 1996, P NATL ACAD SCI USA, V93, P5675, DOI 10.1073/pnas.93.12.5675; HARRIS N, 1992, P 10 NAT C ART INT, P837; HENIKOFF S, 1991, NUCLEIC ACIDS RES, V19, P6565, DOI 10.1093/nar/19.23.6565; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; KEARNS MJ, 1994, INTRO COMPUTATIONAL, P1; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; LIPMAN DJ, 1985, SCIENCE, V227, P1435, DOI 10.1126/science.2983426; PEARSON WR, 1995, PROTEIN SCI, V4, P1145; Pereira F., 1993, P 31 ANN M ASS COMP, P183, DOI 10.3115/981574.981598; Press W. H., 1988, NUMERICAL RECIPES C, P60; SHERIDAN RP, 1992, PROTEINS, V14, P16, DOI 10.1002/prot.340140105; Smith T., 1981, ADV APPL MATH, V2, P482, DOI 10.1016/0196-8858(81)90046-4; SONNHAMMER ELL, 1994, PROTEIN SCI, V3, P482; TAYLOR WR, 1990, METHOD ENZYMOL, V183, P456, DOI 10.1016/0076-6879(90)83031-4; VANHEEL M, 1991, J MOL BIOL, V220, P877, DOI 10.1016/0022-2836(91)90360-I; VAPNIK VN, 1982, ESTIMATION DEPENDENC, P162; WATANABE H, 1995, COMPUT APPL BIOSCI, V11, P159; WOOTTON JC, 1994, CURR OPIN STRUC BIOL, V4, P413, DOI 10.1016/S0959-440X(94)90111-2; WU C, 1992, PROTEIN SCI, V1, P667	35	36	36	ACADEMIC PRESS LTD	LONDON	24-28 OVAL RD, LONDON, ENGLAND NW1 7DX	0022-2836		J MOL BIOL	J. Mol. Biol.	MAY 2	1997	268	2					539	556		10.1006/jmbi.1997.0948		18	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	WX564	WOS:A1997WX56400025	
J	Chandran, V; Carswell, B; Boashash, B; Elgar, S				Chandran, V; Carswell, B; Boashash, B; Elgar, S			Pattern recognition using invariants defined from higher order spectra: 2-D image inputs	IEEE TRANSACTIONS ON IMAGE PROCESSING			English	Article							MOMENT INVARIANTS; SCALE-INVARIANT	A new algorithm for extracting features from images for object recognition is described, The algorithm uses higher order spectra to provide desirable invariance properties, to provide noise immunity, and to incorporate nonlinearity into the feature extraction procedure thereby allowing the use of simple classifiers, An image can be reduced to a set of one-dimensional (1-D) functions via the Radon transform, or alternatively, the Fourier transform of each 1-D projection can be obtained from a radial slice of the two-dimensional (2-D) Fourier transform of the image according to the Fourier slice theorem, A triple product of Fourier coefficients, referred to as the deterministic bispectrum, is computed for each 1-D function and is integrated along radial lines in bifrequency space, Phases of the integrated bispectra are shown to be translation- and scale-invariant. Rotation invariance is achieved by a regrouping of these invariants at a constant radius followed by a second stage of invariant extraction, Rotation invariance is thus converted to translation invariance in the second step, Results using synthetic and actual images show that isolated, compact clusters are formed in feature space, These clusters are linearly separable, indicating that the nonlinearity required in the mapping from the input space to the classification space is incorporated well into the feature extraction stage, The use of higher order spectra results in good noise immunity, as verified with synthetic and real images, Classification of images using the higher order spectra-based algorithm compares favorably to classification using the method of moment invariants.	WASHINGTON STATE UNIV,SCH ELECT ENGN & COMP SCI,PULLMAN,WA 99164	Chandran, V (reprint author), QUEENSLAND UNIV TECHNOL,SCH ELECT ELECT & SYST ENGN,SIGNAL PROC RES CTR,BRISBANE,QLD 4001,AUSTRALIA.		Boashash, Boualem/A-9687-2010; Chandran, Vinod/I-9691-2012	Chandran, Vinod/0000-0003-3185-0852			ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698; ALTMANN J, 1984, IEEE T PATTERN ANAL, V6, P46; AUBER T, 1994, UNINOVATR1094 GR; Brillinger D., 1967, SPECTRAL ANAL TIME S, P189; BRILLINGER DR, 1965, ANN MATH STAT, V36, P1351, DOI 10.1214/aoms/1177699896; Capodiferro L., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0); Carrato S., 1993, IEEE Signal Processing Workshop on Higher-Order Statistics (Cat. No.93TH0539-7), DOI 10.1109/HOST.1993.264595; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CHANDRAN V, 1991, IEEE T SIGNAL PROCES, V40, P205; CHANDRAN V, P ICASSP 92; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DUDANI SA, 1977, IEEE T COMPUT, V26, P39; Gonzalez R., 1992, DIGITAL IMAGE PROCES; HASSELMAN K, 1963, TIME SERIES ANAL, P48; HU M, 1962, IRE T INFORM THEOR, V8, P179; NIKIAS CL, 1987, P IEEE, V75, P869, DOI 10.1109/PROC.1987.13824; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; Rauber T. W., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems, DOI 10.1109/ICPR.1992.201819; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; SADLER BM, 1989, JUN P WORKSH HIGH OR, P106; Sayrol E., 1993, IEEE Signal Processing Workshop on Higher-Order Statistics (Cat. No.93TH0539-7), DOI 10.1109/HOST.1993.264593; TSATANIS M, P SOC PHOTOPTICAL IN, V1348, P103	23	30	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1057-7149		IEEE T IMAGE PROCESS	IEEE Trans. Image Process.	MAY	1997	6	5					703	712		10.1109/83.568927		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	WU726	WOS:A1997WU72600007	
J	Ling, CX; Parry, JJ; Wang, HD				Ling, CX; Parry, JJ; Wang, HD			Setting attribute weights for nearest neighbor learning algorithms using C4.5	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						nearest neighbor learning algorithms; decision trees; inductive learning from examples		Nearest Neighbour (NN) learning algorithms utilize a distance function to determine the classification of testing examples. The attribute weights in the distance function should be set appropriately. We study situations where a simple approach of setting attribute weights using decision trees does not work well, and design three improvements. We test these new methods thoroughly using artificially generated datasets and datasets from the machine learning repository.	UNIV WESTERN ONTARIO,DEPT COMP SCI,LONDON,ON N6A 5B7,CANADA							Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; AHA DW, 1989, 6TH P INT WORKSH MAC, P387; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, P 11 INT C MACH LEAR, P28; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1993, 43 ITK TILB U I LANG; DASARATHY B, 1993, NEAREST NEIGHBOR NN; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; KIBLER D, 1987, 4TH P INT WORKSH MAC, P24; Ling CX, 1997, ARTIF INTELL REV, V11, P255, DOI 10.1023/A:1006560730186; MOHRI M, 1994, WS9401 CAS BAS REAS; Murphy PM, 1992, UCI REPOSITORY MACHI; PARRY JJ, 1994, THESIS U W ONTARIO; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1993, C4 5 PROGR MACH LEAR; SCHAFFER C, 1994, P 1994 INT CD MACH L; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658	22	4	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 9128, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	1997	11	3					405	415		10.1142/S0218001497000184		11	Computer Science, Artificial Intelligence	Computer Science	XQ593	WOS:A1997XQ59300004	
J	Djouadi, A; Bouktache, E				Djouadi, A; Bouktache, E			A fast algorithm for the nearest-neighbor classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor; pattern recognition; feature partition; fast algorithm; classification performance		A fast algorithm that finds the nearest neighbor (NN) of an unknown sample from a design set of labeled samples is proposed. This algorithm requires a quite moderate preprocessing effort and a rather excessive storage, but it accomplishes substantial computational savings during classification. The performance of the algorithm is described and compared to the performance of the conventional one. Results on simulated data are provided to illustrate the computational savings' that may be achieved using this fast algorithm.	PURDUE UNIV CALUMET,DEPT ELECT ENGN TECHNOL,HAMMOND,IN 46323	Djouadi, A (reprint author), LUCENT TECHNOL,COLUMBUS,OH, USA.						BELUR, 1979, P IEEE, V67, P708; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1975, IEEE T COMP, V24, P1000; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SETHI IK, 1981, IEEE T SYST MAN CYB, V11, P245; VASSAIRE C, 1982, IEEE T PATTERN ANAL, V4, P663	9	27	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					277	282		10.1109/34.584107		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	WR582	WOS:A1997WR58200011	
J	Grother, PJ; Candela, GT; Blue, JL				Grother, PJ; Candela, GT; Blue, JL			Fast implementations of nearest neighbor classifiers	PATTERN RECOGNITION			English	Article						non-parametric classifiers; kd trees; k nearest neighbors; distance metrics; Karhunen-Loeve transform; OCR		Standard implementations of non-parametric classifiers have large computational requirements. Parzen classifiers use the distances of an unknown vector to all N prototype samples, and consequently exhibit O(N) behavior in both memory and time. We describe four techniques for expediting the nearest neighbor methods: replacing the linear search with a new kd tree method, exhibiting approximately O(N-1/2) behavior; employing an L-infinity instead of L-2 distance metric; using variance-ordered features; and rejecting prototypes by evaluating distances in low dimensionality subspaces. We demonstrate that variance-ordered features yield significant efficiency gains over the same features linearly transformed to have uniform variance. We give results for a large OCR problem, but note that the techniques expedite recognition for arbitrary applications. Three of four techniques preserve recognition accuracy. (C) 1997 Pattern Recognition Society.	NIST,INFORMAT TECHNOL LAB,MATH MODELLING GRP,GAITHERSBURG,MD 20899	Grother, PJ (reprint author), NIST,INFORMAT TECHNOL LAB,IMAGE PROC GRP,GAITHERSBURG,MD 20899, USA.						BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BLUE JL, 1994, PATTERN RECOGN, V27, P485, DOI 10.1016/0031-3203(94)90031-0; CANDELA GT, 1993, 5163 NISTIR NAT I ST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P423, DOI 10.1109/34.19040; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P254; GARRIS MD, 1994, 5469 NISTIR NAT I ST; GROTHER PJ, 1995, 19 HFCD NAT I STAND; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; TOUSSAINT GT, 1984, COMP SCI STAT 16 S I; WILKINSON RA, 1992, 4912 NISTIR NAT I ST	14	29	29	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	1997	30	3					459	465		10.1016/S0031-3203(96)00098-2		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	WV667	WOS:A1997WV66700008	
J	Ling, CX; Wang, HD				Ling, CX; Wang, HD			Computing optimal attribute weight settings for nearest neighbor algorithms	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						nearest neighbor learning algorithms; lazy learning; attribute weight setting; theoretical analyses		Nearest neighbor (NN) learning algorithms, examples of the lazy learning paradigm, rely on a distance function to measure the similarity of testing examples with the stored training examples. Since certain attributes are more discriminative, while others can be less or totally irrelevant, attributes should be weighed differently in the distance function. Most previous studies on weight setting for NN learning algorithms are empirical. In this paper we describe our attempt on deciding theoretically optimal weights that minimize the predictive error for NN algorithms. Assuming a uniform distribution of examples in a 2-d continuous space, we first derive the average predictive error introduced by a linear classification boundary, and then determine the optimal weight setting for any polygonal classification region. Our theoretical results of optimal attribute weights can serve as a baseline or lower bound for comparing other empirical weight setting methods.		Ling, CX (reprint author), UNIV WESTERN ONTARIO,DEPT COMP SCI,MC,LONDON,ON N6A 5B7,CANADA.						AHA DW, 1994, P AAAI 94 WORKSH CAS; AHA DW, 1989, 6TH P INT WORKSH MAC, P387; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALBERT MK, 1991, P 9 NAT C ART INT, P553; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, P 11 INT C MACH LEAR, P28; CHAR B, 1992, FIRST LEAVES TUTORIA, V5; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 1993, 43 ITK I LANG TECHN; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; KIBLER D, 1987, 4TH P INT WORKSH MAC, P24; Langley P., 1993, P 13 INT JOINT C ART, P889; LING CX, 1994, UNPUB DECIDING WEIGH; MOHRI M, 1994, CAS BAS REAS PAP 199; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; OKAMOTO S, 1995, P 1 INT C CAS BAS RE, P253; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SATOH K, 1994, CAS BAS REAS PAP 199; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D., 1995, P 1 INT C CAS BAS RE, P347; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658	27	16	16	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	FEB	1997	11	1-5					255	272		10.1023/A:1006560730186		18	Computer Science, Artificial Intelligence	Computer Science	XE777	WOS:A1997XE77700010	
J	Wettschereck, D; Aha, DW; Mohri, T				Wettschereck, D; Aha, DW; Mohri, T			A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms	ARTIFICIAL INTELLIGENCE REVIEW			English	Review						lazy learning; k-nearest neighbor; feature weights; comparison	NEAREST-NEIGHBOR; CLASSIFICATION; SIMILARITY; KNOWLEDGE; NETWORK	Many lazy learning algorithms are derivatives of the k-nearest neighbor (Ic-NN) classifier, which uses a distance function to generate predictions from stored instances. Several studies have shown that K-NN's performance is highly sensitive to the definition of its distance function. Many K-NN variants have been proposed to reduce this sensitivity by parameterizing the distance function with feature weights. However, these variants have not been categorized nor empirically compared. This paper reviews a class of weight-setting methods for lazy learning algorithms. We introduce a framework for distinguishing these methods and empirically compare them. We observed four trends from our experiments and conducted further studies to highlight them. Our results suggest that methods which use performance feedback to assign weight settings demonstrated three advantages over other methods: they require less pre-processing, perform better in the presence of interacting features, and generally require less training data to learn good settings. We also found that continuous weighting methods tend to outperform feature selection algorithms for tasks where some features are useful but less important than others.	USN, RES LAB, CTR APPL RES ARTIFICIAL INTELLIGENCE, WASHINGTON, DC 20375 USA; UNIV TOKYO, DEPT ELECT ENGN, HIDEHIKO TANAKA LAB, BUNKYO KU, TOKYO 113, JAPAN	Wettschereck, D (reprint author), GMD, GERMAN NATL RES CTR INFORMAT TECHNOL, SCHLOZZ BIRLINGHOVEN, D-53754 ST AUGUSTIN, GERMANY.						AHA DW, 1994, CAS BAS REAS PAP 199; AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alia D.W., 1991, P 8 INT WORKSH MACH, P117; ASHLEY KD, 1988, 7TH P NAT C ART INT, P239; ATKESON C, 1989, ADV NEURAL INFORMATI, V2; Bakiri G., 1991, THESIS OREGON STATE; BAREISS R, 1989, P CAS BAS REAS WORKS, P162; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; BOUNDS DG, 1990, NEURAL NETWORKS, V3, P583, DOI 10.1016/0893-6080(90)90008-9; Broomhead D. S., 1988, Complex Systems, V2; CAIN T, 1991, P CAS BAS REAS WORKS, P191; Cardie C., 1993, P 10 INT C MACH LEAR, P25; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P693; CLEVELAND WS, 1994, 11 AT T BELL LAB STA; CONNELL ME, 1987, P 6 NAT C ART INT, P456; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DAELEMANS W, 1993, 43 TILB U I LANG TEC; DAELEMANS W, 1992, P TWLT, V3, P27; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Doak J, 1992, CSE9218 U CAL DEP CO; Duda R., 1973, PATTERN CLASSIFICATI; Dudani S., 1975, IEEE T SYST MAN CYB, V6, P325; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Fu K, 1968, SEQUENTIAL METHODS P; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; Fukunaga K., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90043-5; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; HASTIE TJ, 1994, DISCRIMINANT ADAPTIV; Hayashi C., 1952, ANN I STATISTICAL MA, V3, P69; John G. H., 1994, P 11 INT C MACH LEAR, P121; KAWAGUCHI M, 1978, INTRO MULTIVARIATE A, V2; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; KIBLER D, 1987, 4TH P INT WORKSH MAC, P24; Kira K., 1992, P 9 INT C MACH LEARN, P249; KOHAVI R, 1995, UNPUB HEURISTIC SEAR; KOHONEN T, 1988, P IEEE INT C NEURAL, P61; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kolodner J., 1993, CASE BASED REASONING; Kononenko I, 1994, P EUR C MACH LEARN, P171; KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037//0033-295X.99.1.22; Kshirsagar A. M., 1972, MULTIVARIATE ANAL; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Langley P., 1993, P 13 INT JOINT C ART, P889; LANGLEY P, 1994, CAS BAS REAS PAP 199; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; LUCASSEN J, 1984, P INT C AC SPEECH SI; Luce R. Duncan, 1963, HDB MATH PSYCHOL; MCGILL W, 1955, IEEE T INFORMATION T, V1, P93; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Michie D, 1994, MACHINE LEARNING NEU; MITCHELL T, 1990, READINGS MACHINE LEA; Mitchell T. M., 1986, Machine Learning, V1, DOI 10.1007/BF00116250; MOHRI T, 1993, 2 INT WORKSH PAR PRO, P40; MOHRI T, 1995, UNPUB COMP ATTRIBUTE; MOHRI T, 1994, CAS BAS REAS PAP 199; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; Murphy P. M., 1995, UCI REPOSITORY MACHI; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978; PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W; Press W. H., 1992, NUMERICAL RECIPES C; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RICCI F, 1995, P 1 INT C CAS BAS RE, P301; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SATOH K, 1994, CAS BAS REAS PAP 199; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; SCHLIMMER JC, 1987, 4 INT WORKSH MACH LE, P79; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition; SIMARD P, 1993, ADV NEURAL INFORMATI; SKALAK DB, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P325; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TING KM, 1994, DISCRETIZATION CONTI; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Turney P.D., 1993, P EUR C MACH LEARN, P402; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; VANDENBOSCH A, 1993, 42 TILB U I LANG TEC; VAPNIK V, 1992, ADV NEURAL INFORMATI, V3; VOLPER DJ, 1987, BIOL CYBERN, V57, P57, DOI 10.1007/BF00318716; WEISS S, 1989, 11TH IJCAI 89 INT JO, P781; WETTSCHERECK D, 1995, 944 GERM NAT RES CTR; WETTSCHERECK D, 1994, THESIS OREGON STATE; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1992, NEURAL INFORMATION P, V4; WETTSCHERECK D, 1995, 943 GERM NAT RES CTR; WOLPERT DH, 1994, COMMUNICATION; WOLPERT DH, 1990, NEURAL NETWORKS, V3, P445, DOI 10.1016/0893-6080(90)90027-I; YAU HC, 1991, NEURAL NETWORKS, V4, P517, DOI 10.1016/0893-6080(91)90048-A; ZHANG JP, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P31, DOI 10.1109/TAI.1990.130306	104	254	261	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0269-2821		ARTIF INTELL REV	Artif. Intell. Rev.	FEB	1997	11	1-5					273	314		10.1023/A:1006593614256		42	Computer Science, Artificial Intelligence	Computer Science	XE777	WOS:A1997XE77700011	
J	VanderHeiden, R; Groen, FCA				VanderHeiden, R; Groen, FCA			The Box-Cox metric for nearest neighbour classification improvement	PATTERN RECOGNITION			English	Article						discrimination; nearest neighbour method; Box-Cox transformation; metric; radar; range profiles; target recognition	TRANSFORMATION	The Nearest Neighbour rule is a distribution-free classification method. In the literature it has been shown, however, that the performance of the method improves if complex, often locally defined metrics are chosen. In this paper we demonstrate that in many real world discrimination problems comparable or even better classification results can be obtained with a simple global metric based on the Box-Cox transformation. In three case studies this is demonstrated: synthetic data, the IRIS data and real radar data In the latter experiment, a large reduction in classification error of more than a factor four is achieved. Copyright (C) 1997 Pattern Recognition Society.	UNIV AMSTERDAM,FAC MATH & COMP SCI,NL-1098 SJ AMSTERDAM,NETHERLANDS	VanderHeiden, R (reprint author), TNO,PHYS & ELECT LAB,POB 96864,NL-2509 JG THE HAGUE,NETHERLANDS.						BEAUCHAMP JJ, 1986, COMMUN STAT SIMULAT, V15, P147, DOI 10.1080/03610918608812498; BOX GEP, 1964, J ROY STAT SOC B, V26, P211; CARROLL RJ, 1980, J ROY STAT SOC B MET, V42, P71; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; PERICCHI LR, 1981, BIOMETRIKA, V68, P35, DOI 10.1093/biomet/68.1.35; SAKIA RM, 1992, STATISTICIAN, V41, P169, DOI 10.2307/2348250; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Ulaby FT, 1982, MICROWAVE REMOTE SEN	12	22	22	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.	FEB	1997	30	2					273	279		10.1016/S0031-3203(96)00077-5		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	WR189	WOS:A1997WR18900009	
J	TschicholdGurman, N				TschicholdGurman, N			The neural network model RuleNet and its application to mobile robot navigation	FUZZY SETS AND SYSTEMS			English	Article; Proceedings Paper	Workshop on Fuzzy Systems 1994, Classification, Decision Support and Control	OCT, 1994	MUNICH, GERMANY			neuro-fuzzy systems; decision making; robotics	FUZZY-LOGIC	In this paper the neural network models RuleNet and its extension, Fuzzy RuleNet, are described in detail. RuleNet is a feedforward network model with a supervised learning algorithm, a dynamic architecture and discrete outputs. The main characteristics of RuleNet are its efficient learning and propagation algorithms and the possibility to translate symbolic knowledge into the network and vice versa without loss of information. Fuzzy RuleNet is an extension to RuleNet with Fuzzy Logic. The main application area of this neuro-fuzzy model is fuzzy classification. An important characteristic of Fuzzy RuleNet is the possibility of knowledge transfer into and from the network without loss of information, therefore it can also be used for the generation of fuzzy systems (i.e. fuzzy rules and the corresponding membership functions). RuleNet and Fuzzy RuleNet have been applied to a hierarchic behavior based navigation system for mobile robots. As a first step, a wall following behavior has been implemented utilizing these network models. The achieved results in the simulation environment as well as on a mobile robot experimental platform are very encouraging.		TschicholdGurman, N (reprint author), ETH ZURICH,INST ROBOT,CH-8092 ZURICH,SWITZERLAND.						ADAMS M, 1994, INTELLIGENT ROBOTS S, V1, P150; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BERENJI HR, 1992, IEEE T NEURAL NETWOR, V3, P724, DOI 10.1109/72.159061; Connell Jonathan H., 1993, ROBOT LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DABIJA V, 1993, P 1993 INT JOINT C N; Kohonen T., 1989, SELF ORG ASS MEMORY; Kosko B, 1992, NEURAL NETWORKS FUZZ; Latombe J., 1991, ROBOT MOTION PLANNIN; Murphy PM, 1992, UCI REPOSITORY MACHI; Nauck D., 1994, NEURONALE NETZE FUZZ; RUMELHART D. E., 1986, PARALLEL DISTRIBUTED, P45; SCHWEITZER G, VDI BER, P331; STEGMAIER P, 1995, P 1995 ACM S APPL CO, P440, DOI 10.1145/315891.316064; SULZBERGER S, 1993, P IEEE INT C NEUR NE, V1, P312; Takagi H., 1991, International Journal of Approximate Reasoning, V5, DOI 10.1016/0888-613X(91)90008-A; TSCHICHOLDGURMA.N, 1995, THESIS ETH ZURICH; TSCHICHOLDGURMA.N, 1993, P IEEE INT C NEUR NE, V1, P281; Tschichold-Gurman N., 1995, P ACM S APPL COMP NA, P466, DOI 10.1145/315891.316069; VESTLI SJ, 1995, THESIS ETH; ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255; ZIMMERMANN M, 1993, THESIS ETH	22	18	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JAN 23	1997	85	2					287	303		10.1016/0165-0114(95)00351-7		17	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	VX744	WOS:A1997VX74400013	
S	Zupan, B; Dzeroski, S		Keravnou, E; Garbay, C; Baud, R; Wyatt, J		Zupan, B; Dzeroski, S			Acquiring and validating background knowledge for machine learning using function decomposition	ARTIFICIAL INTELLIGENCE IN MEDICINE	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	6th Conference on Artificial Intelligence in Medicine Europe (AIME 97)	MAR 23-26, 1997	GRENOBLE, FRANCE	Univ Joseph fourier, Grenoble, CNRS, Grenoble Isere Dev, France, Assoc Francaise Intelligence Artificielle				Domain or background knowledge is often needed in order to solve difficult problems of learning medical diagnostic rules. Earlier experiments have demonstrated the utility of background knowledge when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences of several groups of attributes was provided by a medical expert. This paper explores the possibility to automate the process of acquiring background knowledge of this kind. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set of attributes, The method is evaluated by comparing the typical co-occurrences it identifies, as well as their contribution to the performance of machine learning algorithms, to the ones provided by a medical expert.		Zupan, B (reprint author), JOZEF STEFAN INST, DEPT INTELLIGENT SYST, LJUBLJANA 1000, SLOVENIA.						ASHENHURST RL, 1952, BL111, P541; BIERMANN AW, 1982, IEEE T SYST MAN CYB, V12, P635, DOI 10.1109/TSMC.1982.4308882; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Curtis H. A., 1962, NEW APPROACH DESIGN; DZEROSKI S, 1996, TECHNOLOGY HLTH CARE; FIX E, 1957, 4 US AIR FORC SCH AV; Harmon P., 1988, EXPERT SYSTEMS TOOLS; KARALIC A, 1990, SISTEMICA, V1, P113; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; Lavrac N., 1994, INDUCTIVE LOGIC PROG; LAVRAC N, 1993, APPL ARTIF INTELL, V7, P273, DOI 10.1080/08839519308949989; LAVRAC N, 1991, 3RD P SCAND C ART IN, P138; PERKOWSKI M, 1995, SURVEY LIT FUNCTION; Dzeroski S., 1993, Journal of Computing and Information Technology - CIT, V1; PIRNAT V, 1989, 2ND P EUR C ART INT, P24; SAMUEL AL, 1967, IBM J RES DEV, V11, P601; SHANNON CE, 1948, AT&T TECH J, V27, P379; WETTSCHERECK D, 1994, THESIS OREGON STATE; ZUPAN B, 1996, IJSDP7455 URL J STEF	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-62709-X	LECT NOTES ARTIF INT			1997	1211						86	97				12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	BJ62U	WOS:A1997BJ62U00010	
B	Lee, D; Kang, J; Ryu, KR; Lee, KH		Leake, DB; Plaza, E		Lee, D; Kang, J; Ryu, KR; Lee, KH			Applying memory-based learning to indexing of reference ships for case-based conceptual ship design	CASE-BASED REASONING RESEARCH AND DEVELOPMENT	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Case-Based Reasoning (ICCBR-97)	JUL 25-27, 1997	PROVIDENCE, RHODE ISLAND					This paper presents a method of applying a memory-based learning (MBL) technique to automatic building of an indexing scheme for accessing reference cases during the conceptual design phase of a new ship. The conceptual ship design process begins with selecting previously designed reference ships of the same type with similar sizes and speeds. These reference ships are used for deriving an initial design of a new ship, and then the initial design is kept modified and repaired until the design reaches a level of satisfactory quality. The selection of good reference ships is essential for deriving a good initial design, and the quality of the initial design affects the efficiency and quality of the whole conceptual design process. The selection of reference ships has so far been done by design experts relying on their experience and engineering knowledge of ship design and structural mechanics. We developed an MBL method that can build an effective indexing scheme for retrieving good reference cases from a case base of previous ship designs. Empirical results show that the indexing scheme generated by MBL outperforms those by other learning methods such as the decision tree learning.	Korean Res Inst Ships & Ocean Engn, Shipbldg Syst Dept, Yusung Ku, Taejon 305600, South Korea; Pusan Natl Univ, Dept Comp Engn, Kumjeong Ku, Pusan 609735, South Korea	Lee, D (reprint author), Korean Res Inst Ships & Ocean Engn, Shipbldg Syst Dept, Yusung Ku, POB 101, Taejon 305600, South Korea.						AHA WD, 1991, P 1991 DARPA CAS BAS, P147; AHA WD, 1997, IN PRESS ARTIFICIAL; ANDREWS D, 1981, CREATIVE SHIP DESIGN, P447; ATEKSON C, 1997, IN PRESS ARTIFICIAL; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1996, P 13 NAT C ART INT P; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RICCI F, 1995, P 1 INT C CAS BAS RE, P23; SCHWABACHER M, 1994, P 10 IEEE C ART INT; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY		3-540-63233-6	LECT NOTES ARTIF INT			1997	1266						74	83				10	Computer Science, Artificial Intelligence	Computer Science	BK96Z	WOS:000073947800008	
B	Okamoto, S; Yugami, N		Leake, DB; Plaza, E		Okamoto, S; Yugami, N			Theoretical analysis of case retrieval method based on neighborhood of a new problem	CASE-BASED REASONING RESEARCH AND DEVELOPMENT	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Case-Based Reasoning (ICCBR-97)	JUL 25-27, 1997	PROVIDENCE, RHODE ISLAND				LEARNING ALGORITHMS	The retrieval of similar cases is often performed by using the neighborhood of a new problem. The neighborhood is usually defined by a certain fixed number of most similar cases (Ic nearest neighbors) to the problem. This paper deals with an alternative definition of neighborhood that comprises the cases within a certain distance, d, from the problem. We present an average-case analysis of a classifier, the d-nearest neighborhood method (d-NNh); that retrieves cases in this neighborhood and predicts their majority class as the class of the problem. Our analysis deals with m-of-n/l target concepts, and handles three types of noise. We formally compute the expected classification accuracy of d-NNh, then we explore the predicted behavior of d-NNh. By combining this exploration for d-NNh and one for k-nearest neighbor method (k-NN) in our previous study, we compare the predicted behavior of each in noisy domains. Our formal analysis is supported with Monte Carlo simulations.	Fujitsu Labs Ltd, Sawara Ku, Fukuoka 814, Japan	Okamoto, S (reprint author), Fujitsu Labs Ltd, Sawara Ku, 2-2-1 Momochihama, Fukuoka 814, Japan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALBERT MK, 1991, P 9 NAT C ART INT, P553; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DRAKOPOULOS JA, 1995, P 12 INT C MACH LEAR, P203; Langley P., 1993, P 13 INT JOINT C ART, P889; Murphy P.M., 1991, P 8 INT WORKSH MACH, P183; OCALLAGHAN JF, 1975, IEEE T COMPUT, V24, P1121, DOI 10.1109/T-C.1975.224144; OKAMOTO S, 1996, P 13 INT C MACH LEAR, P355; OKAMOTO S, 1995, LNAI, V1010, P243; OKAMOTO S, 1997, IN PRESS P IJCAI 97; PAZZANI MJ, 1992, MACH LEARN, V9, P349, DOI 10.1007/BF00994111; WETTSCHERECK D, 1995, LECT NOTES ARTIF INT, V1010, P347	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY		3-540-63233-6	LECT NOTES ARTIF INT			1997	1266						349	358				10	Computer Science, Artificial Intelligence	Computer Science	BK96Z	WOS:000073947800033	
J	Ji, CY; Ma, S				Ji, CY; Ma, S			Combinations of weak classifiers	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						weak classifiers; combinations of classifiers; supervised learning; generalization error; space-complexity; time-complexity	NEURAL NETWORKS; RECOGNITION	To obtain classification systems with both good generalization performance and efficiency in space and time, we propose a learning method based on combinations of weak classifiers, where weak classifiers are linear classifiers (perceptrons) which can do a little better than making random guesses. A randomized algorithm is proposed to find the weak classifiers. They are then combined through a majority vote. As demonstrated through systematic experiments, the method developed is able to obtain combinations of weak classifiers with good generalization performance and a fast training time on a variety of test problems and real applications. Theoretical analysis on one of the test problems investigated in our experiments provides insights on when and why the proposed method works. In particular, when the strength of weak classifiers is properly chosen, combinations of weak classifiers can achieve a good generalization performance with polynomial space- and time-complexity.		Ji, CY (reprint author), RENSSELAER POLYTECH INST,DEPT ELECT COMP & SYST ENGN,TROY,NY 12180, USA.						AVILESCRUZ C, 1995, 6891 ESPRIT; Barron A. R., 1984, SELF ORG METHODS MOD; BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500; Barron A.R., 1994, MACH LEARN, V14, P113; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BERLIND RS, 1994, THESIS STATE U BUFF; BLAYO F, 1995, 6891 ESPRIT; BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3; BREIMAN L, 1992, TR367 U CAL DEP STAT; CESABIANCHI N, 1993, 25TH P ANN ACM S THE, P382; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; DRUCKER H, 1993, P NEUR INF PROC S, P42; DRUCKER H, 1995, NEUR INF PROC S; Duda R., 1973, PATTERN CLASSIFICATI; FELLER W, 1968, INTRO PROBABILITY TH, V1, P195; Freund Y., 1990, 3 ANN WORKSH COMP LE, P202; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; JI C, 1991, P 4 WKSHP COMP LEARN; Judd S., 1990, NEURAL NETWORK DESIG; Kleinberg EM, 1990, ANN MATH ARTIFICIAL, V1, P207, DOI 10.1007/BF01531079; KLEINBERG EM, 1993, P 3 INT WORKSH FRONT, P175; LITTLE N, 1989, P 3 WKSHP COMP LEARN; MEIR R, 1994, BIAS VARIANCE COMBIN; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; NILSSON N, 1990, LEARNING MACHINES; NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473; PERRONE MP, 1993, ARTIFICIAL NEURAL NE, pCH10; PRECHELT L, 1994, 2194 U KARL; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; RANDY SJ, 1994, IEEE T PATTERN ANAL, V13, P252; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; STWART A, 1987, KANDELLS ADV THEORY; TISHBY N, 1989, P INT JOINT C NEUR N; TUMER K, 1995, IEEE T NEURAL NETWOR; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1982, ESTIMATION DEPENDENC; VENKATESH SS, 1993, J COMPUT SYST SCI, V46, P198, DOI 10.1016/0022-0000(93)90003-F; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Xu L., 1995, ADV NEURAL INFORM PR, P633; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	44	71	76	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JAN	1997	8	1					32	42				11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	WA612	WOS:A1997WA61200004	
J	Ridella, S; Rovetta, S; Zunino, R				Ridella, S; Rovetta, S; Zunino, R			Circular backpropagation networks for classification	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						feedforward neural networks; backpropagation; pattern classification; knowledge representation	LAYER NETWORKS; NEURAL NETS; PATTERNS; BOUNDS; NUMBER	The class of mapping networks is a general family of tools to perform a wide variety of tasks; however, no unifying framework exists to describe their theoretical and practical properties. This paper presents a standardized, uniform representation for this class of networks, and introduces a simple modification of the multilayer perceptron with interesting practical properties, especially well suited to cope with pattern classification tasks. The proposed model unifies the two main representation paradigms found in the class of mapping networks for classification, namely, the surface-based and the prototype-based schemes, while retaining the advantage of being trainable by backpropagation. The enhancement in the representation properties and the generalization performance are assessed through results about the worst-case requirement in terms of hidden units and about the Vapnik-Chervonenkis dimension and Cover capacity. The theoretical properties of the network also suggest that the proposed modification to the multilayer perceptron is in many senses optimal. A number of experimental verifications also confirm theoretical results about the model's increased performances, as compared with the multilayer perceptron and the Gaussian radial basis Functions network.		Ridella, S (reprint author), UNIV GENOA,DEPT BIOPHYS & ELECT ENGN,VIA OPERA PIA 11A,I-16145 GENOA,ITALY.		Rovetta, Stefano/H-5718-2012				Anthony M., 1992, COMPUTATIONAL LEARNI; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BERTHOLD MR, 1994, ADV NEURAL INFORMATI, V7, P521; Bishop C. M., 1995, NEURAL NETWORKS PATT; Burgess N, 1994, Int J Neural Syst, V5, P59, DOI 10.1142/S0129065794000074; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; DETERDING DH, 1989, THESIS CAMBRIDGE U C; DEVILLIERS J, 1992, IEEE T NEURAL NETWOR, V4, P136; Duda R., 1973, PATTERN CLASSIFICATI; Duin RPW, 1996, PATTERN RECOGN LETT, V17, P529, DOI 10.1016/0167-8655(95)00113-1; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; GUYON I, 1992, ADV NEURAL INFORMATI, V5; Hecht-Nielsen R., 1989, NEUROCOMPUTING; HOLDEN SB, 1995, IEEE T NEURAL NETWOR, V6, P368, DOI 10.1109/72.363472; Homilc K., 1989, NEURAL NETWORKS, V2; HUANG SC, 1991, IEEE T NEURAL NETWOR, V2, P47, DOI 10.1109/72.80290; KOEALCZYK A, IN PRESS NEURAL NETW; KOWALCZYK A, 1993, ADV NEURAL INFORMATI, V6, P375; LANG K, 1989, P CONNECTIONIST MODE; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; MIRCHANDANI G, 1989, IEEE T CIRCUITS SYST, V36, P661, DOI 10.1109/31.31313; MITCHISON GJ, 1989, BIOL CYBERN, V60, P345; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Niyogi P, 1996, NEURAL COMPUT, V8, P819, DOI 10.1162/neco.1996.8.4.819; OMOHUNDRO SM, 1990, PHYSICA D, V42, P307, DOI 10.1016/0167-2789(90)90085-4; PARK SK, 1988, COMMUN ACM, V31, P1192, DOI 10.1145/63039.63042; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Press W. H., 1992, NUMERICAL RECIPES C; RIDELLA S, 1995, NEURAL COMPUT APPL, V3, P222, DOI 10.1007/BF01414647; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; SONTAG ED, 1996, 9601 RUTG U DEP MATH; SONTAG ED, 1989, 8912 SYCON RUTG CTR; Sontag E. D., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.470; TELFER BA, 1993, NEURAL NETWORKS, V6, P1117; Vapnik V.N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1968, DOKL AKAD NAUK SSR, V4; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VASCONCELOS GC, 1995, PATTERN RECOGN LETT, V16, P207, DOI 10.1016/0167-8655(94)00092-H; VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914; WENOCUR RS, 1981, DISCRETE MATH, V33, P313, DOI 10.1016/0012-365X(81)90274-0; ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591	44	69	76	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JAN	1997	8	1					84	97		10.1109/72.554194		14	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	WA612	WOS:A1997WA61200009	
J	Hamamoto, Y; Uchimura, S; Tomita, S				Hamamoto, Y; Uchimura, S; Tomita, S			A bootstrap technique for nearest neighbor classifier design	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						bootstrap; nearest neighbor classifier; error rate; peaking phenomenon; small training sample size; high dimensions; outlier	ERROR RATE ESTIMATION	A bootstrap technique for nearest neighbor classifier design is proposed. Our primary interest in designing a classifier is in small training sample size situations. Conventional bootstrapping techniques sample the training samples with replacement. On the other hand, our technique generates bootstrap samples by locally combining original training samples. The nearest neighbor classifier is designed on the bootstrap samples and is tested on the test samples independent of training samples. The performance of the proposed classifier is demonstrated on three artificial data sets and one real data set. Experimental results show that the nearest neighbor classifier designed on the bootstrap samples outperforms the conventional k-NN classifiers as well as the edited 1-NN classifiers, particularly in high dimensions.	OSHIMA NATL COLL MARITIME TECHNOL,OSHIMA 74221,JAPAN	Hamamoto, Y (reprint author), YAMAGUCHI UNIV,FAC ENGN,UBE,YAMAGUCHI 755,JAPAN.						Chandrasekaran B., 1979, Journal of Cybernetics and Information Science, V2; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 11 USAF SCH AV MED; FUKUNAGA K, 1990, INTRO STATISTICAL PA; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Gabor D., 1946, Journal of the Institution of Electrical Engineers. III. Radio and Communication Engineering, V93; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Hamamoto Y., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, DOI 10.1109/ICDAR.1995.602027; Hamamoto Y., 1996, P 13 INT C PATT REC, V3, P250, DOI 10.1109/ICPR.1996.546948; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326	22	58	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					73	79		10.1109/34.566814		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	WE528	WOS:A1997WE52800009	
S	Dzeroski, S; Schulze-Kremer, S; Heidtke, KR; Siems, K; Wettschereck, D		Muggleton, S		Dzeroski, S; Schulze-Kremer, S; Heidtke, KR; Siems, K; Wettschereck, D			Applying ILP to diterpene structure elucidation from C-13 NMR spectra	INDUCTIVE LOGIC PROGRAMMING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Workshop on Logic Program Synthesis and Transformation (LOPSTR 96) / 6th Inductive Logic Programming Workshop (ILP 96)	AUG 28-30, 1996	STOCKHOLM, SWEDEN	Network Computat Log, European Commiss, ESPRIT Compulog Net				We present a novel application of ILP to the problem of diterpene structure elucidation from C-13 NMR spectra. Diterpenes are organic compounds of low molecular weight that are based on a skeleton of 20 carbon atoms. They are of significant chemical and commercial interest because of their use as lead compounds in the search for new pharmaceutical effecters. The structure elucidation of diterpenes based on C-13 NMR spectra is usually done manually by human experts with specialized background knowledge on peak patterns and chemical structures. In the process, each of the 20 skeletal atoms is assigned an atom number that; corresponds to its proper place in the skeleton and the diterpene is classified into one of the possible skeleton types. We address the problem of learning classification rules from a database of peak patterns for diterpenes with known structure. Recently, propositional learning was successfully applied to learn classification rules from spectra with assigned atom numbers. As the assignment of atom numbers is a difficult process in itself (and possibly indistinguishable from the classification process), we apply ILP, i.e., relational learning, to the problem of classifying spectra without assigned atom numbers.	FORTH, ICS, Heraklion 71110, Crete, Greece; Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia; Max Planck Inst Mol Genet, Otto Warburg Lab, Dept Lehrach, D-14195 Berlin, Germany; AnalytiCon GMBH, D-13335 Berlin, Germany; GMD, FIT KI, Schloss Birlinghoven, D-53745 St Augustin, Germany	Dzeroski, S (reprint author), FORTH, ICS, POB 1385, Heraklion 71110, Crete, Greece.						Abraham RJ, 1978, PROTON CARBON 13 NMR; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERAEDT L, 1995, P 6 INT WORKSH ALG L, P80; DZEROSKI S, 1993, P 4 SCAND C ART INT, P111; DZEROSKI S, 1996, P ECAI 96 WORKSH INT; Emde W., 1996, P 13 INT C MACH LEAR, P122; GRAY NAB, 1982, PROG NUCL MAG RES SP, V15, P201, DOI 10.1016/0079-6565(82)80003-4; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Muggleton S., 1990, P 1 C ALG LEARN THEO, P368; MUGGLETON S, 1995, NEW GENERAT COMPUT, V13, P245; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SCHULZEKREMER S, 1995, MOL BIOINFORMATICS A; TVETER DR, 1995, FAST BACKPROPAGATION; WETTSCHERECK D, 1994, THESIS OREGON STATE; 1995, STUTGART NEURAL NETW; 1995, NATURAL PRODUCTS CD	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-63494-0	LECT NOTES ARTIF INT			1997	1314						41	54				14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BN72G	WOS:000082727500003	
J	Wilson, DR; Martinez, TR				Wilson, DR; Martinez, TR			Improved heterogeneous distance functions	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							NEAREST-NEIGHBOR; LEARNING ALGORITHMS; SIMILARITY; FEATURES	Instance-based learning techniques typically handle continuous and linear input values well, but often do not handle nominal input attributes appropriately. The Value Difference Metric (VDM) was designed to find reasonable distance values between nominal attribute values, but it largely ignores continuous attributes, requiring discretization to map continuous values into nominal values. This paper proposes three new heterogeneous distance functions, called the Heterogeneous Value Difference Metric (HVDM), the Interpolated Value Difference Metric (IVDM), and the Windowed Value Difference Metric (WVDM). These new distance functions are designed to handle applications with nominal attributes, continuous attributes, or both. In experiments on 48 applications the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.		Wilson, DR (reprint author), BRIGHAM YOUNG UNIV, DEPT COMP SCI, PROVO, UT 84602 USA.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ATKESON C, 1996, IN PRESS ARTIFICIAL; ATKESON C, 1989, ADV NEURAL INFORMATI, V2; BATCHELOR BG, 1978, PATTERN RECOGN, P71; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Broomhead D. S., 1988, Complex Systems, V2; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CLEVELAND WS, 1994, 11 AT T BELL LAB STA; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DENG K, 1995, IN PRESS P INT JOINT; DIDAY E, 1974, 2 INT JOINT C PATT R, P534; DOMINGOS P, 1995, IN PRESS 1995 INT JO; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GIRAUDCARRIER C, 1995, THEO DECI L, V15, P341; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; KIBLER D, 1987, 4TH P INT WORKSH MAC, P24; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LEBOWITZ M, 1985, COGNITIVE SCI, V9, P285, DOI 10.1016/S0364-0213(85)80001-X; Merz C. J., 1996, UCI REPOSITORY MACHI; MICHALSKI RS, 1981, PROGR PATTERN RECOGN, V1, P33; MITCHELL TM, 1980, READINGS MACHINE LEA, P184; Mohri T., 1994, CASE BASED REASONING, P123; NADLER M, 1993, PATTERN RECOGN, P293; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; PAPADIMITRIOU CH, 1980, LECT NOTES COMPUTER, V85, P470; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Quinlan J. R., 1989, 6TH P INT WORKSH MAC, P164; RENALS S, 1989, P INT JOINT C NEURAL, V1, P461; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Salzberg S., 1991, MACH LEARN, V6, P277; SCHAFFER C, 1993, MACHINE LEARNING, V13; SCHAFFER C, 1994, P 11 INT C MACH LEAR; SCHLIMMER JC, 1987, P 6 NAT C ART INT, V2, P511; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tapia R. A., 1978, NONPARAMETRIC PROBAB; TING KM, 1994, 491 U SYDN BASS DEP; TING KM, 1996, IN PRESS ARTIFICIAL; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TURNEY P, 1994, J EXPT THEORETICAL A, P331; TURNEY P, 1993, APPL INTELL, V3, P109, DOI 10.1007/BF00871892; Turney P.D., 1993, P EUR C MACH LEARN, P402; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; Ventura D., 1995, P 10 INT S COMP INF, P443; VENTURA D, 1995, THESIS B YOUNG U; Wasserman PD, 1993, ADV METHODS NEURAL N, P147; Wess S., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1995, AIC95012 NAV RES LAB	60	351	368	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757		J ARTIF INTELL RES	J. Artif. Intell. Res.		1997	6						1	34				34	Computer Science, Artificial Intelligence	Computer Science	WE463	WOS:A1997WE46300001	
B	Priebe, CE; Cowen, LJ		Scott, DW		Priebe, CE; Cowen, LJ			Approximate distance clustering	MINING AND MODELING MASSIVE DATA SETS IN SCIENCE, ENGINEERING, AND BUSINESS WITH A SUBTHEME IN ENVIRONMENTAL STATISTICS	COMPUTING SCIENCE AND STATISTICS (SERIES)		English	Proceedings Paper	29th Symposium on the Interface between Computing Science and Statistics	MAY 14-17, 1997	HOUSTON, TX	Univ Texas M D Anderson Cancer Ctr, Univ Texas Hlth Sci Ctr, Sch Public Hlth, W M Keck Ctr Computational Biol				We address the problem of statistical pattern recognition (clustering, classification, discriminant analysis) for n observations in d-dimensionaI Euclidean space when n much less than d. As such, we are concerned with circumventing the "curse of dimensionality." Our approach, termed "approximate distance clustering," is motivated by dimensionality reduction methods which embed points from a high-dimensional Euclidean space into a lower dimensional space while approximately preserving pairwise distances between points. The methodology involves non-linear projections based on inter-point distances to random subsets. Combinatorial algorithms are developed and theoretical, simulation, and experimental results are presented indicating that approximate distance clustering has application in many challenging pattern recognition scenarios.	Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA	Priebe, CE (reprint author), Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA.		Priebe, Carey E./A-3305-2010				Anderson E., 1935, B AM IRIS SOC, V59, P2; ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011; BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; CARR DB, 1984, COMP GRAPH 84 P 5 AN, V2, P743; Cho Z. H., 1993, FDN MED IMAGING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWEN LJ, 1996, RANDOMIZED NONLINEAR; Devroye L, 1996, PROBABILISTIC THEORY; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friston KJ, 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; LINIAL M, 1996, GLOBAL SELF ORG ALL; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; Mangasarian O. L., 1993, ORSA Journal on Computing, V5; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Minnote Michael C., 1993, J COMPUT GRAPH STAT, V2, P51, DOI 10.2307/1390955; MINNOTTE MC, 1996, BUMPY ROAD MODE FORE; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; PRIEBE CE, 1996, IN PRESS P 1996 JOIN; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scott D. W., 1992, MULTIVARIATE DENSITY; Silverman B, 1986, DENSITY ESTIMATION; Small C. G., 1996, STAT THEORY SHAPE; Sridharan NS, 1989, P 11 INT JOINT C ART, P781; Talairach J., 1988, COPLANAR STEREOTAXIC; TELFER BA, 1994, NEURAL NETWORKS, V7, P809, DOI 10.1016/0893-6080(94)90102-3; WEGMAN EJ, 1990, J AM STAT ASSOC, V85, P664, DOI 10.2307/2290001	29	0	0	INTERFACE FOUNDATION NORTH AMERICA	FAIRFAX	PO BOX 7460, FAIRFAX, VA 22039-7460 USA		1-886658-04-8	COMP SCI STAT			1997	29	1					337	346				10	Operations Research & Management Science; Mathematics, Applied; Statistics & Probability	Operations Research & Management Science; Mathematics	BM60M	WOS:000079222400085	
B	Nguyen, SH; Skowron, A		Komorowski, J; Zytkow, J		Nguyen, SH; Skowron, A			Searching for relational patterns in data	PRINCIPLES OF DATA MINING AND KNOWLEDGE DISCOVERY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	1st European Symposium on Principles of Data Mining and Knowledge Discovery (PKDD 97)	JUN 24-27, 1997	TRONDHEIM, NORWAY					We consider several basic classes of tolerance relations among objects. These (global) relations are defined from some predefined similarity measures on Values of attributes. A tolerance relation in a given class of tolerance relations is optimal with respect to a given decision table A if it contains only pairs of objects with the same decision and the number of such pairs contained in the relation is maximal among all relations from the class. We present a method for (sub-)optimal tolerance relation learning from data (decision table). The presented method is based on rough set approach. We show that for some basic families of tolerance relations this problem can be transformed to a relative geometrical problem in a real affine space. Hence geometrical computations are becoming useful tools for solving the problem of global tolerance relation construction. The complexity of considered problems can be evaluated by the complexity of the corresponding geometrical problems. We propose some efficient heuristics searching for an approximation of optimal tolerance relations in considered families of tolerance relations. The global tolerance relations can be treated as patterns in the cartesian product of the object set. We show how to apply the relational patterns (global tolerance relations) in clustering and classification of objects.	Univ Warsaw, Math Inst, PL-02097 Warsaw, Poland	Nguyen, SH (reprint author), Univ Warsaw, Math Inst, Banacha Str 2, PL-02097 Warsaw, Poland.	hoa@mimuw.edu.pl; skowron@mimuw.edu.pl	Nguyen, Sinh Hoa/G-8901-2013				BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HU X, 1995, P 1 INT C KNOWL DISC, P162; KRAWIEC K, 1996, P 4 INT WORKSH ROUGH, P23; LIN TY, 1989, P 4 INT S METH INT S; Marcus S., 1994, B POLISH ACAD SCI TE, V42, P471; NGUYEN SH, 1996, P INT C INF SYST AN, P26; Nguyen S.H., 1996, P 4 INT WORKSH ROUGH, P153; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; Pawlak Z., 1991, ROUGH SETS THEORETIC; Polkowski L., 1995, SOFT COMPUTING ROUGH, P55; Skowron A., 1996, Fundamenta Informaticae, V27; SKOWRON A, 1996, P 4 INT WORKSH ROUGH, P11; STEPANIUK J, 1996, P 4 INT WORKSH ROUGH, P18; STEPANIUK J, 1995, P INT WORKSH STAT MA; WINDHAM MP, 1983, FUZZY SET SYST, V10, P271, DOI 10.1016/S0165-0114(83)80120-1; ZIARKO WP, 1994, ROUGH SET FUZZY SET	17	8	10	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY		3-540-63223-9	LECT NOTES ARTIF INT			1997	1263						265	276				12	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BK96X	WOS:000073947600026	
S	Vinitski, S; Mohamed, F; Gonzalez, C; Knobler, R; Andrews, D; Iwanaga, T; Madi, S			IEEE; IEEE	Vinitski, S; Mohamed, F; Gonzalez, C; Knobler, R; Andrews, D; Iwanaga, T; Madi, S			Fast tissue segmentation based on a 3D and 4D feature map: Comparison study	PROCEEDINGS OF THE 19TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOL 19, PTS 1-6: MAGNIFICENT MILESTONES AND EMERGING OPPORTUNITIES IN MEDICAL ENGINEERING	PROCEEDINGS OF ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY		English	Proceedings Paper	International Conference of the IEEE Engineering-in-Medicine-and-Biology-Society	OCT 30-NOV 02, 1997	CHICAGO, IL	IEEE Engn Med & Biol Soc, Natl Inst Hlth		MRI; tissue segmentation; 4D feature map; brain tumor; multiple sclerosis	RECONSTRUCTION; CONNECTIVITY; IMAGES	The aim of this work was to develop a fast and accurate method for tissue segmentation in MRI based on 4D feature map and compare it with that derived from the 3D feature map. High resolution MR imaging was performed in five normals, six patients with brain MS, and six with malignant brain tumors. Three inputs: proton density, T2 weighted fast spin-echo, T1-weighted spin echo MR images were routinely utilized. As a fourth input, either magnetization transfer MRI was used in normals and some patients or T1 weighted post contract MRI in other patients. Modified k-Nearest Neighbor segmentation algorithm was optimized for maximum computation speed and high quality segmentation. In that regard: 1) we discarded the redundant seed points, 2) discarded the points within 0.5 standard deviation from the cluster center that were non overlapping with other tissue classes, 3) we removed outlying seed points outside 5 times the standard deviation from the cluster center of each tissue class. Our new technique utilizing all four MRI inputs provided better segmentation than that based on three inputs. (p<0.001) The tissues were smoother and the delineation of the tissues was increased. Details that were previously blurred or invisible now became apparent. In normals, detailed depiction of deep gray matter nuclei was obtained. In malignant tumors, up to five abnormal tissue were identified: 1) solid tumor core, 2) cyst, 3) edema in white matter 4) edema in gray matter and 5) necrosis. Delineation of MS plaque in different stages of demyelination, became much sharper. In conclusion, proposed methodology warrants further development and clinical evaluation.	Thomas Jefferson Univ, Philadelphia, PA 19107 USA	Vinitski, S (reprint author), Thomas Jefferson Univ, Philadelphia, PA 19107 USA.						BRASCH R, 1993, MRI CONTAST ENHANCEM; CLINE HE, 1987, MAGN RESON IMAGING, V5, P345, DOI 10.1016/0730-725X(87)90124-X; CLINE HE, 1990, J COMPUT ASSIST TOMO, V14, P1037, DOI 10.1097/00004728-199011000-00041; CLINE HE, 1988, MED PHYS, V15, P320, DOI 10.1118/1.596225; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAWSONSAUNDERS RG, 1990, BASIC CLIN BIOSTATIS; GERIG G, 1992, IEEE T MED IMAG, V2; GONZALEZ CF, 1991, NEURORADIOLOGY S, P123; Mohamed FB, 1995, P IEEE ENG MED BIOL, V17, P36; VINITSKI, 1997, PROCED ISMRM, V5, P416; VINITSKI S, 1996, PROCEED IEEE BIO MED, V18; VINITSKI S, 1993, IMAGE PROCESSING THE, P325; Vinitski S., 1995, Image Analysis and Processing. 8th International Conference, ICIAP '95. Proceedings; Vinitski S, 1997, MAGNET RESON MED, V37, P457, DOI 10.1002/mrm.1910370325; VINITSKI S, 1994, P IEEE ENG MED BIOL, V16, P577; VINITSKI S, 1988, MAGN RESON IMAGING, V6, P707, DOI 10.1016/0730-725X(88)90095-1; *MONTR NEUR I, 1995, PROC NIH WORKSH	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1094-687X	0-7803-4262-3	P ANN INT IEEE EMBS			1997	19		1-6				505	508				4	Engineering, Biomedical	Engineering	BM91F	WOS:000080103400148	
J	Kleinberg, EM				Kleinberg, EM			An overtraining-resistant stochastic modeling method for pattern recognition	ANNALS OF STATISTICS			English	Article						pattern recognition; machine learning	WEAK	We will introduce a generic approach for solving problems in pattern recognition based on the synthesis of accurate multiclass discriminators from large numbers of very inaccurate ''weak'' models through the use of discrete stochastic processes. Contrary to the standard expectation held for the many statistical and heuristic techniques normally associated with the field, a significant feature of this method of ''stochastic modeling'' is its resistance to so-called ''overtraining.'' The drop in performance of any stochastic model in going from training to test data remains comparable to that of the component weak models from which it is synthesized; and since these component models are very simple, their performance drop is small, resulting in a stochastic model whose performance drop is also small despite its high level of accuracy.		Kleinberg, EM (reprint author), SUNY BUFFALO,DEPT MATH,BUFFALO,NY 14214, USA.						AMIT Y, 1996, UNPUB RECOGNIZING SH; BERLIND R, 1994, UNPUB ALMOST UNIFORM; BERLIND R, 1994, THESIS STAT U NEW YO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GOLDMAN SA, 1995, INFORM COMPUT, V117, P276, DOI 10.1006/inco.1995.1045; GUYON I, 1991, CHARACTER HANDWRITIN; HARALICK RM, 1976, COMMUN STAT A-THEOR, V5, P1163, DOI 10.1080/03610927608827433; Hecht-Nielsen R, 1990, NEUROCOMPUTING; Ho T. K., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), DOI 10.1109/ICDAR.1993.395612; Ho TK, 1995, P 3 INT C DOC AN REC, P278; HO TK, 1992, THESIS STATE U NEW Y; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KLEINBERG EM, 1996, P 13 INT C PATT REC, P880; KLEINBERG EM, 1993, ANN MATH ARTIFICIAL, V1, P207; KLEINBERG EM, 1993, P 3 INT WORKSH FRONT, P175; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; *PROJ STATL, 1992, LIACC	20	17	18	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 6 3401 INVESTMENT BLVD, HAYWARD, CA 94545	0090-5364		ANN STAT	Ann. Stat.	DEC	1996	24	6					2319	2349				31	Statistics & Probability	Mathematics	WK459	WOS:A1996WK45900002	
J	Neri, F; Saitta, L				Neri, F; Saitta, L			Exploring the power of genetic search in learning symbolic classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						genetic algorithms; distributed genetic algorithms; classification rules; machine learning; disjunctive concept learning; universal suffrage selection; mushroom dataset; splice junctions dataset; empirical comparison	ALGORITHMS; SELECTION; FEATURES	In this paper we show, in a constructive way, that there are problems for which the use of genetic algorithm based learning systems can be at least as effective as traditional symbolic or connectionist approaches. To this aim, the system REGAL* is briefly described, and its application to two classical benchmarks for Machine Learning is discussed, by comparing the results with the best ones published in the literature.		Neri, F (reprint author), UNIV TURIN,DIPARTIMENTO INFORMAT,CORSO SVIZZERA 185,I-10149 TURIN,ITALY.		Neri, Filippo/E-1182-2011	Neri, Filippo/0000-0002-2529-2287			ANKENBRANDT CA, 1990, PATTERN RECOGN LETT, V11, P285, DOI 10.1016/0167-8655(90)90067-C; Bala J., 1991, Proceedings of the First International Workshop on Multistrategy Learning (MSL-91); Bonelli P., 1990, P INT C MACH LEARN 1, P153; BOSWELL R, 1990, MANUAL NEW2D VERSION; Botta M., 1993, P 13 INT JOINT C ART, P937; Botta M., 1993, P 2 IEEE INT C FUZZ, P18, DOI 10.1109/FUZZY.1993.327470; Breiman L, 1984, CLASSIFICATION REGRE; BREZELLEC P, 1993, P 10 MACH LEARN C AM, P9; BRILL FZ, 1992, IEEE T NEURAL NETWOR, V3, P324, DOI 10.1109/72.125874; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COHOON JP, 1987, P 2 INT C GEN ALG CA, P153; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Jong K., 1975, THESIS U MICHIGAN; Deb K., 1989, 3RD P INT C GEN ALG, P42; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; Giordana A., 1994, P 11 INT C MACH LEAR, P96; Giordana A., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); Giordana A, 1992, P 9 INT WORKSH MACH, P169; GIORDANA A, 1996, EVOLUTIONARY COMPUTA, V3, P375; Giordana A., 1994, P WORKSHOP KNOWLEDGE, P56; Goldberg D. E., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms; Goldberg D.E., 1989, GENETIC ALGORITHMS; GREENE DP, 1993, MACH LEARN, V13, P229, DOI 10.1023/A:1022622013558; Hekanaho J., 1995, P 12 INT C MACH LEAR, P278; Holland J. H., 1986, MACHINE LEARNING ART, V2, P593; HOLLAND JH, THESIS U MICHIGAN AN; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Horn J, 1994, EVOL COMPUT, V2, P37, DOI 10.1162/evco.1994.2.1.37; Janikow C. Z., 1993, MACH LEARN, V13, P198; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; KOPPEL M, 1994, P 1 INT C MACH LEARN, P139; LEWIN B, 1994, GENE, V5; Mahfoud S. W., 1995, THESIS U ILLINOIS UR; McCallum R. A., 1990, P 7 INT C MACH LEARN, P149; Michalski R. S., 1983, MACH LEARN, V1, P83; MICHALSKI RS, 1986, 5TH P NAT C ART INT, P1041; Neri F., 1995, P 6 INT C GEN ALG, p[436, Morgan]; Neri F., 1995, P 6 INT C GEN ALG, p[32, 39]; NOORDEWIER M, 1991, NIPS, V3; NORTON SW, 1993, P 10 INT C MACH LEAR, P220; OPITZ DW, P 11 INT C MACH LEAR, P208; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHLIMMER JS, 1987, 8719 TR U CAL DEP IN; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Smith S. F., 1983, P 8 INT JOINT C ART, P422; Spears W.M., 1994, P 3 ANN C EV PROGR, P296; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Syswerda G., 1989, 3RD P INT C GEN ALG, P2; Towell G. G., 1991, Proceedings of the First International Workshop on Multistrategy Learning (MSL-91); TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Vafaie H., 1991, Proceedings of the First International Workshop on Multistrategy Learning (MSL-91); Venturini G., 1993, P EUR C MACH LEARN V, P280; WEISS SM, 1994, P 11 INT C MACH LEAR, P335; Wilson S. W., 1987, Machine Learning, V2, DOI 10.1007/BF00058679; Yeung D. Y., 1991, P 8 INT C MACH LEARN, P228	61	20	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1996	18	11					1135	1141		10.1109/34.544085		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	VU159	WOS:A1996VU15900011	
J	Morales, D; Pardo, L; Vajda, I				Morales, D; Pardo, L; Vajda, I			Uncertainty of discrete stochastic systems: General theory and statistical inference	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND HUMANS			English	Article							ENTROPY; DIVERSITY	Uncertainty is defined in a new manner, as a function of discrete probability distributions satisfying a simple and intuitively appealing weak monotocity condition, It is shown that every uncertainty is Schur-concave and conversely, every Schur-concave function of distributions is an uncertainty. General properties of uncertainties are systematically studied, Many characteristics of distributions introduced previously in statistical physics, mathematical statistics, econometrics and information theory are shown to be particular examples of uncertainties, New examples are introduced, and traditional as well as some new methods for obtaining uncertainties are discussed, The information defined by decrease of uncertainty resulting from an observation is investigated and related to previous concepts of information, Further, statistical inference about uncertainties is investigated, based on independent observations of system states. In particular, asymptotic distributions of maximum likelihood estimates of uncertainties and uncertainty-related funtions are derived, and asymptotically alpha-level Neyman-Pearson tests of hypotheses about these system characteristics are presented.	ACAD SCI CZECH REPUBL,CR-18208 PRAGUE,CZECH REPUBLIC	Morales, D (reprint author), UNIV COMPLUTENSE MADRID,FAC MATEMAT,E-28043 MADRID,SPAIN.						ACZEL J, 1975, MEASURES INFORMATION; ARIMOTO S, 1971, INFORM CONTROL, V19, P181, DOI 10.1016/S0019-9958(71)90065-9; BASHARIN GP, 1959, THEORY PROBABILITY I, V4, P361; BENBASSAT M, 1978, INFORM CONTROL, V39, P227, DOI 10.1016/S0019-9958(78)90587-9; Breman L., 1984, CLASSIFICATION REGRE; Chambers JM, 1992, STAT MODELS; COHEN JE, 1993, OCNT MATH, V149, P251; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CSISZAR I, 1978, T 7 PRAG C INF THEOR, VB, P73; CSISZAR I, 1995, IEEE T INFORM THEORY, V41, P26, DOI 10.1109/18.370121; DALTON H, 1925, INEQUALITY INCOMES; DeGroot M. H., 1970, OPTIMAL STATISTICAL; DEGROOT MH, 1970, ANN MATH STAT; DEGROOT MH, 1962, ANN MATH STAT, V33, P404, DOI 10.1214/aoms/1177704567; Devijver P. A., 1982, PATTERN RECOGNITION; Dik J. J., 1985, STAT NEERL, V39, P14, DOI 10.1111/j.1467-9574.1985.tb01121.x; Dobrushin R L, 1956, THEOR PROBAB APPL, V1, P329, DOI 10.1137/1101029; Dobrushin R.L., 1956, THEOR PROBAB APPL, V1, p[65, 329], DOI 10.1137/1101006; Emlen J. M., 1973, ECOLOGY EVOLUTIONARY; ESTEBAN MD, 1994, THESIS COMPLUTENSE U; FADEEV DK, 1957, ARBEIT INFORMATIONST, V1; FEISTAUEROVA J, IEEE T SYST MAN CYB, V23, P1352; FERRERI C, STATISTICA, V40, P55; Gini C, 1912, STUDI EC GIURIDICI 2, V3, P80; GOEL PK, 1979, ANN STAT, V7, P1066, DOI 10.1214/aos/1176344790; Hall E.L., 1979, COMPUTER IMAGE PROCE; Hardy GH, 1929, MESSENGER MATHEMATIC, V58, P145; Hartley RVL, 1928, BELL SYST TECH J, V7, P535; Havrda J., 1967, KYBERNETIKA, V3, p[1, 30]; JONES LK, 1990, IEEE T INFORM THEORY, V36, P23, DOI 10.1109/18.50370; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KAPUR JN, 1988, B UMI, P253; Klir G.J., 1988, FUZZY SETS UNCERTAIN; Kovalevsky V.A., 1968, CHARACTER READERS PA, P3; LEHMANN EL, 1959, TESTING STATISTICAL; Liese F., 1987, CONVEX STAT DISTANCE; Lorenz MO, 1905, J AM STAT ASSOC, V9, P209; MARSHALL AW, 1970, INEQUALITIES THEORY; MCINTOSH RP, 1967, ECOLOGY, V48, P392, DOI 10.2307/1932674; MENENDEZ ML, 1993, FUZZY SET SYST, V58, P171, DOI 10.1016/0165-0114(93)90493-2; MORALES D, 1992, THEORY PROBABILITY I, V37, P191; OSTERREICHER F, 1993, KYBERNETIKA, V29, P105; PAL NR, 1991, IEEE T SYST MAN CYB, V21, P1260, DOI 10.1109/21.120079; PAL SK, 1986, IEEE T SYST MAN CYB, V16, P754, DOI 10.1109/TSMC.1986.289321; PARDO L, 1992, J FRANKLIN I, V329, P907, DOI 10.1016/S0016-0032(92)90048-L; Pigou A. C., 1912, WEALTH WELFARE; RAO CR, 1982, THEOR POPUL BIOL, V21, P24, DOI 10.1016/0040-5809(82)90004-1; READ TRC, 1988, GOODNESS FIT STAT DI; RENYI A, 1965, REV INST INT STAT, V33, P1, DOI 10.2307/1401301; Renyi A., 1961, 4TH P BERK S MATH ST, V1, P547; RIPLEY BD, 1993, NETWORKS CHAOS, P403; SALICRU M, 1993, COMMUN STAT THEORY M, V22, P20715; SANTANNA AP, 1985, INFORM SCIENCES, V35, P145, DOI 10.1016/0020-0255(85)90046-5; Schur I, 1923, SITZBER BERL MATH GE, V22, P9; Schutz RR, 1951, AM ECON REV, V41, P107; Serfling R. J, 1980, APPROXIMATION THEORE; SHANNON CE, 1948, AT&T TECH J, V27, P379; SHANNON CE, 1948, AT&T TECH J, V27, P623; SHARMA BD, 1975, J COMB INFORM SYST S, V2, P122; SIMPSON EH, 1949, NATURE, V163, P68; TANEJA IJ, 1975, THESIS J DELHI DELHI; TEBBE DL, 1968, IEEE T INFORM THEORY, V14, P516, DOI 10.1109/TIT.1968.1054135; Vajda I., 1985, Problems of Control and Information Theory, V14; Vajda I, 1989, THEORY STAT INFERENC; Vajda I., 1969, METHODOLOGIES PATTER; Vajda I., 1968, INFORM TRANSMISSION, V4, P9; Vajda I., 1968, KYBERNETIKA, V4, P105; VEJNAROVA J, 1993, INT J GEN SYST, V22, P25, DOI 10.1080/03081079308935193; VOSATKA P, 1969, THESIS CHARLES U PRA; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599; ZVAROVA J, 1973, 6 PRAG C INF THEOR S, P919; Zvarova J, 1974, CASOPIS PRO PESTOVAN, V99, P15	73	20	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1083-4427		IEEE T SYST MAN CY A	IEEE Trans. Syst. Man Cybern. Paart A-Syst. Hum.	NOV	1996	26	6					681	697		10.1109/3468.541329		17	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	VP078	WOS:A1996VP07800002	
J	Zhao, QF; Higuchi, T				Zhao, QF; Higuchi, T			Efficient learning of NN-MLP based on individual evolutionary algorithm	NEUROCOMPUTING			English	Article						multilayer perceptron; nearest neighbor classifier; individual evolutionary algorithm; neural network learning; supervised organization	NEIGHBOR PATTERN-CLASSIFICATION; ARTIFICIAL NEURAL NETWORKS; DESIGN; TREES; NETS	The nearest neighbor based multilayer perceptron (NN-MLP) is a suitable model for self-organization, and has been studied by many authors in different forms. However, a large number of neurons are usually required in this kind of networks. To obtain smaller or the smallest NN-MLP, this paper introduces the concept of individual evolutionary algorithm (IEA), and proposes a new method for NN-MLP learning, There are four basic operations in the IEA: competition, gain, loss and retraining. The basic rule is: all individuals compete for surviving, winners gain more, losers lose more, and the individuals are retrained to function better than before. The learning algorithm based on the IEA is simple and suitable for parallel realization, and is able to produce the 'smallest-at-present' networks from random ones in an evolutionary manner, Its efficiency is shown by experimental results.		Zhao, QF (reprint author), TOHOKU UNIV,GRAD SCH INFORMAT SCI,SENDAI,MIYAGI 980,JAPAN.						BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; BRENT RP, 1991, IEEE T NEURAL NETWOR, V2, P346, DOI 10.1109/72.97911; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHANG TS, 1992, IEEE T SIGNAL PROCES, V40, P3022, DOI 10.1109/78.175745; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P423, DOI 10.1109/34.19040; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; ISHIKAWA M, 1992, P INT JOINT C NEUR N, P375; KAMEYAMA K, 1991, IEICE TRANS COMMUN, V74, P4198; Kangas J A, 1990, IEEE Trans Neural Netw, V1, P93, DOI 10.1109/72.80208; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kosko B, 1990, IEEE Trans Neural Netw, V1, P44, DOI 10.1109/72.80204; KOSKO B, 1991, IEEE T NEURAL NETWOR, V2, P522, DOI 10.1109/72.134289; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MATSUNAGA Y, 1991, IEICE T, V74, P1118; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; OKAMOTO Y, 1990, IEICE T J, V73, P1186; OSHINO T, 1993, IEICE T, V76, P1414; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; SIETSMA J, 1991, NEURAL NETWORKS, V4, P67, DOI 10.1016/0893-6080(91)90033-2; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326; Yao X, 1993, Int J Neural Syst, V4, P203, DOI 10.1142/S0129065793000171; ZHAO QF, 1994, P INT C NEUR INF PRO, P1398; ZHAO QF, 1994, P INT C FUZZ LOG NEU, P77; ZHAO QF, 1994, P IEICE KAUR WORKSH, P121; ZHAO QF, 1993, NC9365 IEICE, P83	39	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	OCT	1996	13	2-4					201	215		10.1016/0925-2312(95)00088-7		15	Computer Science, Artificial Intelligence	Computer Science	VN056	WOS:A1996VN05600009	
J	Swets, DL; Weng, JJ				Swets, DL; Weng, JJ			Using discriminant eigenfeatures for image retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						principal component analysis; discriminant analysis; eigenfeature; image retrieval; feature selection; face recognition; object recognition; content-based image retrieval	RECOGNITION; SYSTEM; FACES	This paper describes the automatic selection of features from an image training set using the theories of multidimensional discriminant analysis and the associated optimal linear projection. We demonstrate the effectiveness of these Most Discriminating Features for view-based class retrieval from a large database of widely varying real-world objects presented as ''well-framed'' views, and compare it with that of the principal component analysis.	MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Swets, DL (reprint author), AUGUSTANA COLL,DEPT COMP SCI,2001 S SUMMIT AVE,SIOUX FALLS,SD 57197, USA.						BACH JR, 1993, IEEE T KNOWL DATA EN, V5, P619, DOI 10.1109/69.234774; Beymer D., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466898; Bregler C., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466899; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1938, ANN EUGENIC, V8, P376; FUKUNAGA K, 1990, INTRO STATISTICAL PA; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain R., 1994, SIGMOD Record, V23; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Loeve M., 1955, PROBABILITY THEORY; Moghaddam B., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), DOI 10.1109/ICCV.1995.466858; Murase H., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323807; OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775; Pentland A., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), DOI 10.1109/CVPR.1994.323814; Swets D. L., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), DOI 10.1109/ICIP.1995.537549; SWETS DL, 1996, CPS9603 MICH STAT U; SWETS DL, 1995, P INT C NEUR NETW PE; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Weng J., 1993, P 4 INT C COMP VIS B, P121; WILKS S, 1963, MATH STATISTICS	22	665	742	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					831	836		10.1109/34.531802		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	VE318	WOS:A1996VE31800006	
J	Domingos, P				Domingos, P			Unifying instance-based and rule-based induction	MACHINE LEARNING			English	Article						concept learning; multi-strategy learning; rule induction; instance-based learning; nearest-neighbor classification; case-based reasoning	NEAREST-NEIGHBOR; ALGORITHMS; KNOWLEDGE	Several well-developed approaches to inductive learning now exist, but each has specific limitations that are hard to overcome. Multi-strategy learning attempts to tackle this problem by combining multiple methods in one algorithm. This article describes a unification of two widely-used empirical approaches: rule induction and instance-based learning. In the new algorithm, instances are treated as maximally specific rules, and classification is performed using a best-match strategy. Rules are learned by gradually generalizing instances until no improvement in apparent accuracy is obtained. Theoretical analysis shows this approach to be efficient. It is implemented in the RISE 3.1 system. In an extensive empirical study, RISE consistently achieves higher accuracies than state-of-the-art representatives of both its parent approaches (PEBLS and CN2), as well as a decision tree learner (C4.5). Lesion studies show that each of RISE's components is essential to this performance. Most significantly, in 14 of the 30 domains studied, RISE is more accurate than the best of PEELS and CN2, showing that a significant synergy can be obtained by combining multiple empirical methods.		Domingos, P (reprint author), UNIV CALIF IRVINE,DEPT INFORMAT & COMP SCI,IRVINE,CA 92717, USA.						Aha D.W., 1994, P AAAI 94 WORKSH CAS, P106; AHA DW, 1990, 9042 U CAL IRV DEP I; AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; AHA DW, IN PRESS ARTIFICIAL; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ATKESON CG, IN PRESS ARTIFICIAL; BELEW RK, 1992, ARTIFICIAL LIFE, V2; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; BOOKER LB, 1989, ARTIF INTELL, V40, P235, DOI 10.1016/0004-3702(89)90050-7; BRODLEY CE, 1995, MACH LEARN, V20, P63, DOI 10.1007/BF00993475; BUNTINE W, 1989, 6TH P INT WORKSH MAC, P94; Cameron-Jones R. M., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; CATLETT J, 1991, P 8 INT C MACH LEARN, P589; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeGroot MH, 1986, PROBABILITY STAT; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; DOMINGOS P, IN PRESS ARTIFICIAL; DOMINGOS P, 1994, PROC INT C TOOLS ART, P704, DOI 10.1109/TAI.1994.346421; DOMINGOS P, 1995, 952 U CAL IRV DEP IN; Domingos P, 1995, PROC INT C TOOLS ART, P182, DOI 10.1109/TAI.1995.479512; Duda R., 1973, PATTERN CLASSIFICATI; DUDA RO, 1973, P 9 NAT C ART INT, P22; HOLTE RC, 1989, 11TH P INT JOINT C A, P813; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; Kohavi R., 1995, P 14 INT JOINT C ART, P1071; Kolodner J., 1993, CASE BASED REASONING; MICHALSKI RS, 1986, 5TH P NAT C ART INT, P1041; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; MICHALSKI RS, 1993, P 2 INT WORKSH MULT; MITCHELL TM, 1980, NEED BIASES LEARNING; MOHRI T, 1994, P 1994 AAAI WORKSH C, P123; Murphy P. M., 1995, UCI REPOSITORY MACHI; Niblett T, 1987, PROGR MACHINE LEARNI, P67; OLIVEIRA AL, 1995, P 12 INT C MACH LEAR, P421; OURSTON D, 1994, ARTIF INTELL, V66, P273, DOI 10.1016/0004-3702(94)90028-0; PAGALLO G, 1990, MACH LEARN, V5, P71, DOI 10.1023/A:1022611825350; PAZZANI M, 1992, MACH LEARN, V9, P57, DOI 10.1007/BF00993254; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C 4 5 PROGRAMS MACHI; Quinlan JR, 1993, P 10 INT C MACH LEAR, P236; QUINLAN JR, 1987, 10TH P INT JOINT C A, P304; Rao R.B., 1995, P 12 INT C MACH LEAR, P471; Rendell L., 1986, Machine Learning, V1, DOI 10.1007/BF00114117; Riesbeck C., 1989, INSIDE CASE BASED RE; Rivest R. L., 1987, Machine Learning, V2, DOI 10.1007/BF00058680; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; SCHAFFER C, 1994, SELECTING MODELS DAT, V4; SCOTT PD, 1992, P 10 EUR C ART INT, P484; SMYTH P, 1995, P 12 INT C MACH LEAR, P506; SMYTH P, 1990, P EUR C ART INT STOC, P610; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TING KM, 1994, 49 U SYDN BASS DEP C; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; Townsend-Weber T., 1994, P 1994 AAAI WORKSH C, P30; Utgoff P. E., 1989, Connection Science, V1, DOI 10.1080/09540098908915648; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WNEK J, 1994, MACH LEARN, V14, P139, DOI 10.1023/A:1022622132310; ZHANG JP, 1990, PROCEEDINGS OF THE 2ND INTERNATIONAL IEEE CONFERENCE ON TOOLS FOR ARTIFICIAL INTELLIGENCE, P31, DOI 10.1109/TAI.1990.130306	68	98	103	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	AUG	1996	24	2					141	168				28	Computer Science, Artificial Intelligence	Computer Science	UZ380	WOS:A1996UZ38000004	
J	Dommermuth, F				Dommermuth, F			Target classification using radar range Profiles	FREQUENZ			German	Article							IDENTIFICATION; PERFORMANCE	Based on the large amount of data provided by a measurement campaign in 1992, it has been examined whether high resolution radar range profiles are suitable tools in order to discriminate between different types of aircraft. The nearest-neighbour-type, correlation-based classification rule proposed in this paper already supports optimistic expectations. A conspicous finding is the pronounced dependence of the classification error on target aspect, which is attributed to the dependence of the range profiles on target bank angle.		Dommermuth, F (reprint author), FGAN,FORSCH INST HOCHFREQUENZPHYS,D-53343 WACHTBERG,GERMANY.						BELL MR, 1993, IEEE T AERO ELEC SYS, V29, P73, DOI 10.1109/7.249114; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; FARAGO A, 1993, IEEE T INFORM THEORY, V39, P1146, DOI 10.1109/18.243433; HUDSON S, 1993, IEEE T AERO ELEC SYS, V29, P741, DOI 10.1109/7.220924; ILAVARASAN P, 1993, IEEE T ANTENN PROPAG, V41, P582, DOI 10.1109/8.222277; JOUNY I, 1995, IEEE T AERO ELEC SYS, V31, P69, DOI 10.1109/7.366294; JOUNY I, 1993, IEEE T AERO ELEC SYS, V29, P336, DOI 10.1109/7.210072; JOUNY I, 1992, IEEE T AERO ELEC SYS, V28, P473, DOI 10.1109/7.144573; KSIENSKI AA, 1975, P IEEE, V63, P1651, DOI 10.1109/PROC.1975.10033; LI HJ, 1993, IEEE T ANTENN PROPAG, V41, P261, DOI 10.1109/8.233138; Magura K, 1996, FREQUENZ, V50, P147; Mehrholz D, 1996, FREQUENZ, V50, P138; ROTHWELL E, 1985, IEEE T ANTENN PROPAG, V33, P929, DOI 10.1109/TAP.1985.1143697; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STRAUSBERGER DJ, 1992, IEEE T AERO ELEC SYS, V28, P396	16	1	1	FACHVERLAG SCHIELE SCHON	BERLIN	MARKGRAFENSTRASSE 11, D-10969 BERLIN, GERMANY	0016-1136		FREQUENZ	Frequenz	JUL-AUG	1996	50	7-8					157	164				8	Engineering, Electrical & Electronic	Engineering	VG313	WOS:A1996VG31300003	
J	Warfield, S				Warfield, S			Fast k-NN classification for multichannel image data	PATTERN RECOGNITION LETTERS			English	Article						k-nearest neighbour rule; distance transform; pattern classification; magnetic resonance image (MRI) segmentation	ARBITRARY DIMENSIONS; DISTANCE TRANSFORM; SEGMENTATION	A new fast and exact algorithm for determining the k-NN classification of multichannel image data, and a new distance transform algorithm are described. Complexity analysis and empirical studies with magnetic resonance images (MRI) demonstrate the effectiveness of the new classification algorithm.		Warfield, S (reprint author), UNIV NEW S WALES,SCH COMP SCI & ENGN,SYDNEY,NSW 2052,AUSTRALIA.		Warfield, Simon/B-3352-2009				BELKASIM SO, 1992, PATTERN RECOGN, V25, P1269, DOI 10.1016/0031-3203(92)90028-H; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; CLINE HE, 1990, J COMPUT ASSIST TOMO, V14, P1037, DOI 10.1097/00004728-199011000-00041; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; JIANG QY, 1993, PATTERN RECOGN LETT, V14, P531, DOI 10.1016/0167-8655(93)90101-I; MULLIKIN JC, 1992, CVGIP-GRAPH MODEL IM, V54, P526, DOI 10.1016/1049-9652(92)90072-6; PAGLIERONI DW, 1992, CVGIP-GRAPH MODEL IM, V54, P56, DOI 10.1016/1049-9652(92)90034-U; RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4	13	44	44	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN 10	1996	17	7					713	721		10.1016/0167-8655(96)00036-0		9	Computer Science, Artificial Intelligence	Computer Science	UT363	WOS:A1996UT36300006	
J	Zakarauskas, P; Ozard, JM				Zakarauskas, P; Ozard, JM			Complexity analysis for partitioning nearest neighbor searching algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest-neighbor search; nearest-neighbor search; complexity analysis; cost analysis; Minkowski p-metric; k-d tree partitioning; ordered partitioning; product partitioning		In this paper we present cost estimates for finding the k-nearest neighbors to a test pattern according to a Minkowski p-metric, as a function of the size of the buckets in partitioning searching algorithms. The asymptotic expected number of operations to find the nearest neighbor is presented as a function of the average number of patterns per bucket n and is shown to contain a global minimum.	DEF RES ESTAB PACIFIC,FMO,ESQUIMALT DEF RES DETACHMENT,VICTORIA,BC V0S 1B0,CANADA	Zakarauskas, P (reprint author), UNIV BRITISH COLUMBIA,DEPT OPHTHALMOL,VANCOUVER,BC V5Z 3N9,CANADA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; EASTMAN CM, 1987, INFORM SYST, V12, P375, DOI 10.1016/0306-4379(87)90029-9; EASTMAN CM, 1981, INFORM PROCESS LETT, V12, P165, DOI 10.1016/0020-0190(81)90092-2; FIX E, 1952, 1 USAF SCH AV; FIX E, 1951, 4 USAF SCH AV; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HAMMING RW, 1980, CODING INFORMATION T; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KAMGARPARSI B, 1985, PATTERN RECOGN LETT, V3, P7, DOI 10.1016/0167-8655(85)90036-4; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; SHASHA D, 1990, ACM T INFORM SYST, V8, P140, DOI 10.1145/96105.96111; SHEN CW, 1978, IEEE P COMPS CHIC IL, P470, DOI 10.1109/CMPSAC.1978.810467; VIDAL E, 1994, PATTERN RECOGN LETT, V15, P1, DOI 10.1016/0167-8655(94)90094-9; YUNK TP, 1976, IEEE T SYST MAN CYB, V6, P678; ZAKARAUSKAS P, IN PRESS COMPLEXITY	17	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					663	668		10.1109/34.506419		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	UR254	WOS:A1996UR25400012	
J	Chen, LH; Kao, C; Kuo, S; Wang, TY; Jang, YC				Chen, LH; Kao, C; Kuo, S; Wang, TY; Jang, YC			Productivity diagnosis via fuzzy clustering and classification: An application to machinery industry	OMEGA-INTERNATIONAL JOURNAL OF MANAGEMENT SCIENCE			English	Article						productivity diagnosis; fuzzy clustering; fuzzy classification; pattern recognition; machinery industry	FIRM-LEVEL; MANAGEMENT	Business units are always faced with intensifying pressure in a competitive economy, Increasing productivity is an effective solution for a firm to survive and prosper, The relative productivity in an industry has evolved into a significant determinant of the competitive position for a firm, This paper proposes a productivity diagnosis process for a firm on the basis of the productivity characters of an industry to gain an insight into the firm's relative productivity and to find the shortcomings in its management of resources, Firstly, productivity structure is determined, Pattern recognition technologies, namely fuzzy clustering and fuzzy classification, are then employed, After fuzzily clustering a training set according to three feature spares, the productivity characters of the industry can be determined, A business unit can be diagnosed through fuzzily classifying its productivity features in a particular feature space and productivity indications can be furnished based on the associated productivity characters, As an illustration, data from 23 machinery firms in Taiwan are collected as a training set to analyze the productivity characters in each space, and two hypothetical firms are diagnosed. Copyright (C) 1996 Elsevier Science Ltd.		Chen, LH (reprint author), NATL CHENG KUNG UNIV,GRAD SCH IND MANAGEMENT,TAINAN 70101,TAIWAN.						ARUNKUMAR S, 1991, DECIS SUPPORT SYST, V7, P199, DOI 10.1016/0167-9236(91)90038-D; BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAIG CE, 1973, SLOAN MANAGE REV, V14, P13; Duda R., 1973, PATTERN CLASSIFICATI; EILON S, 1993, OMEGA-INT J MANAGE S, V21, P551, DOI 10.1016/0305-0483(93)90023-E; ESOGBUE AO, 1983, FUZZY SET SYST, V10, P223, DOI 10.1016/S0165-0114(83)80117-1; Esogbue A. O., 1980, Fuzzy Sets and Systems, V3, DOI 10.1016/0165-0114(80)90002-0; Esogbue A. O., 1979, Fuzzy Sets and Systems, V2, DOI 10.1016/0165-0114(79)90002-2; FORDON WA, 1979, ADV FUZZY SETS THEOR; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GU T, 1990, FUZZY SET SYST, V34, P213, DOI 10.1016/0165-0114(90)90160-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KENDRICK JW, 1965, STUDIES BUSINESS EC, V89; KUROSAWA K, 1991, PRODUCTIVITY MEASRUE; LIEBERMAN MB, 1990, MANAGE SCI, V36, P1193, DOI 10.1287/mnsc.36.10.1193; LIU SY, 1992, COMPUT IND, V19, P271, DOI 10.1016/0166-3615(92)90064-T; MARIN R, 1991, FUZZY SET SYST, V44, P421, DOI 10.1016/0165-0114(91)90247-N; ROUBENS M, 1982, EUR J OPER RES, V10, P294, DOI 10.1016/0377-2217(82)90228-4; Sumanth D. J., 1984, PRODUCTIVITY ENG MAN; SUMANTH DJ, 1987, COMPUT IND ENG, V13, P21, DOI 10.1016/0360-8352(87)90043-X; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; Zimmermann H.J., 1991, FUZZY SET THEORY ITS	24	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0305-0483		OMEGA-INT J MANAGE S	Omega-Int. J. Manage. Sci.	JUN	1996	24	3					309	319		10.1016/0305-0483(96)00002-3		11	Management; Operations Research & Management Science	Business & Economics; Operations Research & Management Science	UU412	WOS:A1996UU41200006	
J	Zhao, QF; Higuchi, T				Zhao, QF; Higuchi, T			Evolutionary learning of nearest-neighbor MLP	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article							PATTERN-CLASSIFICATION; DESIGN	The nearest neighbor multilayer perceptron (NN-MLP) is a single hidden-layer network suitable for pattern recognition. To design an NN-MLP efficiently, this paper proposes a new evolutionary algorithm consisting of four basic operations: recognition, remembrance, reduction, and review. Experimental results show that this algorithm can produce the smallest or nearly smallest networks from random initial ones.	TOHOKU UNIV,GRAD SCH INFORMAT SCI,SENDAI,MIYAGI 98077,JAPAN	Zhao, QF (reprint author), UNIV AIZU,MULTIMEDIA DEVICE LAB,AIZU WAKAMATSU 96580,JAPAN.						BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; ZHAO QF, 1994, P IEICE KAUR WORKSH, P121; ZHAO WF, 1994, P INT C NEUR INF PRO, P1398	15	30	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	1996	7	3					762	767				6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	UL259	WOS:A1996UL25900020	
J	VanderMeer, F				VanderMeer, F			Classification of remotely-sensed imagery using an indicator kriging approach: Application to the problem of calcite-dolomite mineral mapping	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							IMAGING SPECTROMETER DATA; REFLECTANCE; NEVADA	A new image classification technique for analysis of remotely-sensed data based on geostatistical indicator kriging is introduced. Conventional classification techniques require ground truth information, use only the spectral characteristics of an unknown pixel in comparison, rely on a Gaussian probability distribution for the spectral signature of the training data, and work on a pixel support or spatial resolution without allowing classification on larger or smaller volumes. The indicator kriging classifier overcomes such problems because: (1) it relies on spectral information from laboratory studies rather than on ground truth data, (2) through the kriging estimation variances an estimate of uncertainty is derived, (3) it incorporates spatial aspects because it uses local estimation techniques, (4) it is distribution-free, (5) and may be applied on different supports if the data are corrected for support changes. Comparison of classification results applied to the problem of mapping calcite and dolomite from GER imaging spectrometry data shows that indicator kriging performs better than the conventional classification algorithms and gives insight in the accuracy of the results without prior held knowledge.		VanderMeer, F (reprint author), INT INST AEROSP SURVEY & EARTH SCI,DEPT EARTH RESOURCES SURVEYS,GEOL SURVEY DIV,350 BLVD 1945,7500 AA ENSCHEDE,NETHERLANDS.		Van der Meer, Marga/A-4273-2010				CLARK RN, 1990, J GEOPHYS RES-SOLID, V95, P12653, DOI 10.1029/JB095iB08p12653; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; GAFFEY SJ, 1986, AM MINERAL, V71, P151; Grove C.I., 1992, NASA JPL PUBLICATION; Journel A, 1983, MATH GEOL, V15, P445; KRUSE FA, 1988, REMOTE SENS ENVIRON, V24, P31, DOI 10.1016/0034-4257(88)90004-1; KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N; Richards J. A., 1993, REMOTE SENSING DIGIT; STRAHLER AH, 1980, REMOTE SENS ENVIRON, V10, P135, DOI 10.1016/0034-4257(80)90011-5; Van der Meer F., 1994, NONRENEWABLE RESOURC, V3, P146; VANDERMEER F, 1994, INT J REMOTE SENS, V15, P2193; VANDERMEER F, 1994, GEOCARTO INT, V9, P23, DOI 10.1080/10106049409354457; WINDELER DS, 1991, PHOTOGRAMM ENG REM S, V57, P1171	14	13	13	TAYLOR & FRANCIS LTD	LONDON	ONE GUNDPOWDER SQUARE, LONDON, ENGLAND EC4A 3DE	0143-1161		INT J REMOTE SENS	Int. J. Remote Sens.	APR	1996	17	6					1233	1249				17	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	UG095	WOS:A1996UG09500009	
J	Chenoweth, T; Obradovic, Z				Chenoweth, T; Obradovic, Z			A multi-component nonlinear prediction system for the S&P 500 Index	NEUROCOMPUTING			English	Article						stock market prediction; hierarchical systems; hybrid systems; neural networks		The proposed stock market prediction system is comprised of two preprocessing components, two specialized neural networks, and a decision rule base. First, the preprocessing components determine the most relevant features for stock market prediction, remove the noise, and separate the remaining patterns into two disjoint sets. Next, the two neural networks predict the market's rate of return, with one network trained to recognize positive and the other negative returns. Finally, the decision rule base takes both return predictions and determines a buy/sell recommendation. Daily and monthly experiments are conducted and performance measured by computing the annual rate of return and the return per trade. Comparison of the results achieved by the dual neural network system to that of the single neural network shows that the dual neural network system gives much larger returns with fewer trades. In addition, dual neural network experiments with the appropriately selected filtering and decision thresholds managed to achieve an almost twice larger annual rate of return when compared to that of the buy and hold strategy over a seventy month period. However, no claims are made that the proposed system is better than the buy and hold strategy when considering transaction costs.	WASHINGTON STATE UNIV,SCH ELECT ENGN & COMP SCI,PULLMAN,WA 99164; WASHINGTON STATE UNIV,DEPT MANAGEMENT & SYST,PULLMAN,WA 99164; WASHINGTON STATE UNIV,DEPT ECON,PULLMAN,WA 99164							ABUMOSTAFA YS, 1994, NEURAL NETWORKS CAPI; Black F, 1973, J POLITICAL EC, V81; BREIMAN L, 1994, 416 U CAL STAT DEP; BURGESS A, 1994, P 1994 NEUR NETW CAP; CHENOWETH T, 1995, NEUROVEST J, V3, P14; CHENOWETH T, 1995, P 3 INT C ART INT AP, P74; CHENOWETH T, 1994, P 1994 NEUR NETW CAP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Fletcher J., 1993, Connection Science, V5; FUKUNAGA K, 1990, INTRO STATISTICAL PA; HUTCHINSON J, 1993, THESIS MIT CAMBRIDGE; JENSEN MC, 1978, J FINANC ECON, V6, P95, DOI 10.1016/0304-405X(78)90025-9; Markowitz H., 1959, PORTFOLIO SELECTION; RUMELHART, 1986, PARALLEL DISTRIBUTED, V1; SHARPE WF, 1964, J FINANCE        SEP	16	18	18	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312		NEUROCOMPUTING	Neurocomputing	APR	1996	10	3					275	290		10.1016/0925-2312(95)00109-3		16	Computer Science, Artificial Intelligence	Computer Science	UH428	WOS:A1996UH42800005	
J	Tzionas, P; Thanailakis, A; Tsalides, P				Tzionas, P; Thanailakis, A; Tsalides, P			A hybrid cellular automaton neural network classifier for multi-valued patterns and its VLSI implementation	INTEGRATION-THE VLSI JOURNAL			English	Article						pattern recognition; cellular automata; neural networks; VLSI	SYSTEMS; DESIGN	A multi-valued pattern classifier with high discrimination sensitivity and its VLSI implementation proposal on a single chip are presented in this paper. The classification scheme is based on the combination of a reconfigurable Cellular Automaton and a Neural Network architecture. A 2-D Reconfigurable Hybrid Additive Cellular Automaton (RHACA) architecture amplifies the Hamming distance between patterns, whereas a neural network architecture, implemented in digital form, assigns vectors of weighing coefficients which take into account the relative significance of the sites on the 2-D lattice. The proposed classifier is able to operate successfully even for pattern classes of small difference, or for patterns that lie on the decision boundaries between classes. If the training and processing phases are not partitioned, the proposed classification scheme is able to operate in partially exposed environments. With the proper setting of admittance levels into the classes of multi-valued patterns involved, the proposed classifier can also operate on patterns with partly missing data. The proposed multi-valued pattern classifier can be realized on a single VLSI chip with dimensions 7.73 mm x 8.14 mm = 62.96 mm(2) and the expected frequency of operation for the chip is 50 MHz.	DEMOCRITUS UNIV THRACE,DEPT ELECT ENGN,DIV ELECT & INFORMAT SYST TECHNOL,ELECTR LAB,GR-67100 XANTHI,GREECE	Tzionas, P (reprint author), DEMOCRITUS UNIV THRACE,DEPT ELECT ENGN,DIV ELECTR & INFORMAT SYST TECHNOL,GR-67100 XANTHI,GREECE.						BRODER AZ, 1985, IEEE T SYST MAN CYB, V15, P136; CONZALEZ RC, 1972, P NAT ELEC C, V27, P27; CONZALEZ RC, 1977, DIGITAL IMAGE PROCES, P382; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY VB, 1991, NN PATTERN CLASSIFIC, P259; DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090; FAIRHURST MC, 1988, COMPUTER VISION ROBO, pCH4; FIX E, 1991, NN PATTERN CLASSIFIC, P40; FIX E, 1991, NEAREST NEIGHBOR NN, P32; FUKUNAGA K, 1972, INTRO STATISTICAL PA, pCH2; HORTENSIUS PD, 1989, IEEE T COMPUT AID D, V8, P842, DOI 10.1109/43.31545; JOUSSELLIN A, 1987, PATTERN RECOGN LETT, V6, P287, DOI 10.1016/0167-8655(87)90011-0; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149; KWAN HK, 1992, ELECTRON LETT, V28, P1583, DOI 10.1049/el:19921008; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P8689; MONTGOMERY BL, 1986, APPL OPTICS, V25, P3759; PACKARD NH, 1985, J STAT PHYS, V38, P901, DOI 10.1007/BF01010423; Preston K., 1984, MODERN CELLULAR AUTO; PRIES W, 1986, IEEE T COMPUT, V35, P1013; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; ROSENFELD A, 1976, DIGITAL PICTURE PROC, P36; Rumelhart D. E., 1986, EXPLORATIONS MICROST, VI; SCALTOCK J, 1982, COMPUT J, V25, P130; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Tsalides P., 1992, Computer Journal, V35; TSALIDES P, 1990, ELECTRON LETT, V26, P1350, DOI 10.1049/el:19900869; Tzionas P., 1991, Proceedings of the SPIE - The International Society for Optical Engineering; TZIONAS P, 1992, IEE PROC-G, V139, P661; Wasserman P.D., 1989, NEURAL COMPUTING; WOLFRAM S, 1983, REV MOD PHYS, V55, P601, DOI 10.1103/RevModPhys.55.601; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8; YORK TA, 1991, IEE PROC-E, V138, P351	32	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9260		INTEGRATION	Integration-VLSI J.	MAR	1996	20	2					211	237		10.1016/0167-9260(95)00025-9		27	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	UC330	WOS:A1996UC33000005	
J	Peng, XTT; Wang, PH; Kandel, A				Peng, XTT; Wang, PH; Kandel, A			Knowledge acquisition by random sets	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							FUZZY-SETS; REPRESENTATION; LANGUAGES	In this article we investigate knowledge acquisition (KA) and its relationships to random sets. Based on random set theory, we develop some estimation theorems and procedures for set-valued statistics such as nonparametric estimators. Under random interval assumption, we establish some special possibility distributions that can be easily implemented in KA tools. The knowledge studied here are rules describing relationships between various concepts, as used in diagnosis (pattern recognition) expert systems. (C) 1996 John Wiley & Sons, Inc.	NATL UNIV SINGAPORE, INST SYST SCI, SINGAPORE 117548, SINGAPORE; UNIV S FLORIDA, DEPT COMP SCI & ENGN, TAMPA, FL 33620 USA	Peng, XTT (reprint author), ADOBE SYST INC, MT VIEW, CA 94039 USA.						AGRWWALA AK, 1977, MACHINE RECOGNITION, P261; Araujo A, 1980, CENTRAL LIMIT THEORE; Billingsley P., 1979, PROBABILITY MEASURE; Boose J. H., 1988, KNOWLEDGE ACQUISITIO; BOOZE JH, 1990, FDN KNOWLEDGE ACQUIS; BUCHANAN B, 1983, BUILDING EXPERT SYST; Castillo E., 1988, EXTREME VALUE THEORY; Choquet G., 1953, ANN I FOURIER GRENOB, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVI BB, 1985, INFORM SCIENCES, V35, P43, DOI 10.1016/0020-0255(85)90040-4; DINOLA A, 1985, FUZZY SET SYST, V16, P87, DOI 10.1016/S0165-0114(85)80008-7; DOMBI J, 1990, FUZZY SET SYST, V35, P1, DOI 10.1016/0165-0114(90)90014-W; Dubois D., 1988, POSSIBILITY THEORY; Dubois D, 1980, FUZZY SETS SYSTEMS; FIX E, 1977, MACHINE RECOGNITION, P280; Fix E., 1952, DISCRIMINATORY ANAL; GAINES BR, 1988, KNOWLEDGE ACQUISITIO; GOGUEN JA, 1974, INT J MAN MACH STUD, V6, P513, DOI 10.1016/S0020-7373(74)80017-9; GOGUEN JA, 1969, SYNTHESE, V19, P325, DOI 10.1007/BF00485654; GOODMAN IR, 1987, SYSTEMS CONTROL ENCY, P2293; Goodman IR, 1985, UNCERTAINTY MODELS K; GRUBER TR, 1988, INT J MAN MACH STUD, V29, P579, DOI 10.1016/S0020-7373(88)80014-2; Harmon P., 1985, EXPERT SYSTEMS; HODGES JL, 1951, DISCRIMINATORY ANAL; KANDEL A, 1990, CYBERNET SYST, V21, P43, DOI 10.1080/01969729008902223; Kandel A, 1982, FUZZY TECHNIQUES PAT; KANDEL A, 1994, FUZZY CONTROL SYSTEM; KANDEL A, 1992, HYBRID ARCHITECTURES; Kandel A, 1991, FUZZY EXPERT SYSTEMS; Kandel A., 1986, FUZZY MATH TECHNIQUE; KELLEY JL, 1956, GENERAL TOPOLOGY; Kendall DG., 1974, STOCHASTIC GEOMETRY; KOBSA A, 1984, CYBERNET SYST, V15, P41, DOI 10.1080/01969728408927736; LAMPERTI J, 1966, PROBABILITY SURVEY M; Matheron G., 1975, RANDOM SETS INTEGRAL; MCGRAW KL, 1990, READINGS KNOWLEDGE A; NGUYEN HT, 1984, INFORM SCIENCES, V34, P265, DOI 10.1016/0020-0255(84)90052-5; NGUYEN HT, 1987, ANAL FUZZY INFORMATI, V1, P145; NGUYEN HT, 1978, J MATH ANAL APPL, V65, P531, DOI 10.1016/0022-247X(78)90161-0; Olson J. R., 1987, Expert Systems, V4, DOI 10.1111/j.1468-0394.1987.tb00139.x; PENG XT, 1990, THESIS FLORIDA STATE; PENG XT, 1991, IEEE T SYST MAN CYB, V21, P194, DOI 10.1109/21.101149; PRATT JW, 1961, J AM STAT ASSOC, V56, P549, DOI 10.2307/2282079; ROBBINS HE, 1945, ANN MATH STAT, V16, P342, DOI 10.1214/aoms/1177731060; Robbins HE, 1944, ANN MATH STAT, V15, P70, DOI 10.1214/aoms/1177731315; Smith E. E., 1981, CATEGORIES CONCEPTS; SMITH EE, 1984, COGNITIVE SCI, V8, P337, DOI 10.1207/s15516709cog0804_2; Tapia R. A., 1978, NONPARAMETRIC PROBAB; VOTAW DF, 1946, ANN MATH STAT, V17, P240, DOI 10.1214/aoms/1177730986; Wang P. Z., 1985, FUZZY SETS FALLING S; WANG PH, 1983, KEXUE TONGBAO, V28, P1583; WANG PZ, 1982, FUZZY MATH, V2, P45; Waterman D. A., 1986, GUIDE EXPERT SYSTEMS; WEBER S, 1983, FUZZY SET SYST, V11, P115; Wheeden R. L., 1977, MEASURE INTEGRAL; YAGER RR, 1987, INFORM SCIENCES, V41, P1, DOI 10.1016/0020-0255(87)90002-8; ZADEH LA, 1978, INT J MAN MACH STUD, V10, P395, DOI 10.1016/S0020-7373(78)80003-0; ZADEH LA, 1986, ARTIF INTELL, P198; Zadeh L.A., 1987, FUZZY SETS APPL; ZADEH LA, 1976, INT J MAN MACH STUD, V8, P249, DOI 10.1016/S0020-7373(76)80001-6; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; ZHANG LW, 1987, KEXUE TONGBAO, V23, P1596	62	7	10	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	MAR	1996	11	3					113	147		10.1002/(SICI)1098-111X(199603)11:3<113::AID-INT1>3.0.CO;2-T		35	Computer Science, Artificial Intelligence	Computer Science	TX810	WOS:A1996TX81000001	
J	Zhao, Q; Higuchi, T				Zhao, Q; Higuchi, T			Minimization of nearest neighbor classifiers based on individual evolutionary algorithm	PATTERN RECOGNITION LETTERS			English	Article						evolutionary algorithm; genetic algorithm; individual evolutionary algorithm; nearest neighbor classifier		This paper proposes the individual evolutionary algorithm (IEA). Using IEA, the minimum or nearly minimum nearest neighbor classifiers can be obtained iteratively by performing four operations: competition, gain, loss and retraining. The efficiency of IEA is verified by experimental results.	TOHOKU UNIV,SENDAI,MIYAGI 980,JAPAN	Zhao, Q (reprint author), UNIV AIZU,AIZU WAKAMATSU,FUKUSHIMA 96580,JAPAN.						Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CHANG EJ, 1991, ADV NEURAL INFORMATI, P797; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Yao X, 1993, Int J Neural Syst, V4, P203, DOI 10.1142/S0129065793000171	13	2	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB 8	1996	17	2					125	131		10.1016/0167-8655(95)00102-6		7	Computer Science, Artificial Intelligence	Computer Science	TV874	WOS:A1996TV87400003	
S	Tirri, H; Kontkanen, P; Myllymaki, P		Smith, I; Faltings, B		Tirri, H; Kontkanen, P; Myllymaki, P			A Bayesian framework for case-based reasoning	ADVANCES IN CASE-BASED REASONING	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	3rd European Workshop on Case-Based Reasoning	NOV 14-16, 1996	LAUSANNE, SWITZERLAND				EM ALGORITHM; CLASSIFICATION	In this paper we present a probabilistic framework for case-based reasoning in data-intensive domains, where only weak prior knowledge is available. In such a probabilistic viewpoint the attributes are interpreted as random variables, and the case base is used to approximate the underlying joint probability distribution of the attributes. Consequently structural case adaptation (and parameter adjustment in particular) can be viewed as prediction based on the full probability model constructed from the case history. The methodology addresses several problems encountered in building case-based reasoning systems. It provides a computationally efficient structural adaptation algorithm, avoids over-fitting by using Bayesian model selection and uses directly probabilities as measures of similarity. The methodology described has been implemented in the D-SIDE software package, and the approach is validated by presenting empirical results of the method's classification prediction performance for a set of public domain data sets.	Univ Helsinki, Dept Comp Sci, Complex Syst Computat Grp, FIN-00014 Helsinki, Finland	Tirri, H (reprint author), Univ Helsinki, Dept Comp Sci, Complex Syst Computat Grp, POB 26, FIN-00014 Helsinki, Finland.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Barletta R., 1991, AI Expert, V6; Bernardo J. M., 1994, BAYESIAN THEORY; CESTNIK B, 1991, LECT NOTES ARTIF INT, V482, P138; Cheeseman P., 1988, P 5 INT C MACH LEARN, P54; CHICKERING DM, 1996, MSRTR9608 MICR ADV T; CLANCEY WJ, 1985, ARTIF INTELL, V27, P289, DOI 10.1016/0004-3702(85)90016-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeGroot M.H., 1970, OPTIMAL STAT DECISIO; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Everitt B.S., 1981, FINITE MIXTURE DISTR; FRIEDMAN N, 1996, IN PRESS P AAAI 96; FRIEDMAN N, 1996, IN PRESS MACHINE LEA; Gelman AB, 1995, BAYESIAN DATA ANAL; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; John G. H., 1995, P 11 C UNC ART INT; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KASS RE, 1994, 254 U WASH DEP STAT; KEANE M, 1994, TOPICS CASE BASED RE, V837, P21; Kolodner J., 1993, CASE BASED REASONING; KONONENKO I, 1993, INFORMATICA, V17, P167; KONONENKO I, 1991, MACH LEARN, V6, P67, DOI 10.1007/BF00153760; KONTKANEN P, 1996, C19969 U HELS DEP CO; KONTKANEN P, 1996, IN PRESS P ISIS INF; KONTKANEN P, UNPUB UNSPERVISED BA; Koton P., 1989, THESIS MIT; Little R. J. A., 1987, STAT ANAL MISSING DA; Michie D, 1994, MACHINE LEARNING NEU; MYLLYMAKI P, 1993, P IEEE INT C NEUR NE, V1, P422; MYLLYMAKI P, 1994, TOPICS CASE BASED RE, V837, P144; MYLLYMAKI P, 1995, PROBABILISTIC REASON, P237; OWENS C, 1993, MACH LEARN, V10, P311, DOI 10.1023/A:1022691111431; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Schank R. C., 1982, DYNAMIC MEMORY THEOR; Scott D. W., 1992, MULTIVARIATE DENSITY; Skalak D.B., 1994, MACH LEARN P 11 INT, P293; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; WATSON I, 1994, KNOWL ENG REV, V9, P327	38	4	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-61955-0	LECT NOTES ARTIF INT			1996	1168						413	427				15	Computer Science, Artificial Intelligence	Computer Science	BK96G	WOS:000073946100030	
J	Klein, HM; Eisele, T; Klose, KC; Stauss, I; Brenner, M; Ameling, W; Gunther, RW				Klein, HM; Eisele, T; Klose, KC; Stauss, I; Brenner, M; Ameling, W; Gunther, RW			Pattern recognition system for focal liver lesions using ''crisp'' and ''fuzzy'' classifiers	INVESTIGATIVE RADIOLOGY			English	Article						liver, computed tomography; liver, diseases; computers, diagnostic aid	CONTRAST ENHANCEMENT; COMPUTED-TOMOGRAPHY; HEPATIC MASSES; DELAYED CT; HEMANGIOMA	RATIONALE AND OBJECTIVES. To determine the diagnostic performance of an artificial intelligence system for classification of focal liver lesions, in comparison to human observers. METHODS. One hundred forty-three focal hepatic lesions were evaluated with dynamic computed tomography. The study comprised 59 hemangiomas, 24 other benign lesions (focal nodular hyperplasia, adenoma), and 60 malignant liver lesions (18 primary, 42 secondary). All lesions but the hemangiomas were histologically examined by needle biopsy. For delineation of the lesion, a region of interest was defined interactively. The pattern recognition was performed in two steps with initial extraction of textural features: training of a classifier and classification of the lesions. The accuracy of classification of hepatic lesions into three groups (hemangioma, other benign processes, malignant lesions) was tested. The results were compared with those achieved by human observers using receiver operating characteristic statistical analysis. RESULTS. The accuracy (total rate of correct diagnoses) was 90.2%. False classifications were found owing to small size, weak contrast enhancement after bolus injection, respiratory movement, and atypical morphology of the lesion. The area under the receiver operating characteristic curve was not significantly different for computer and human observers. CONCLUSIONS. The system demonstrated a diagnostic accuracy comparable to human observers. Further improvement with increasing numbers of typical computed tomographic series for training of the classifier can be expected.	RHEIN WESTFAL TH AACHEN,ROGOWSKI INST ELECTR ENGN,AACHEN,GERMANY							BARAKOS JA, 1990, GASTROINTEST RADIOL, V15, P93, DOI 10.1007/BF01888748; BRESSLER EL, 1987, RADIOLOGY, V162, P49; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNN J, 1965, J CYBERNETICS, V3, P32; FERRUCCI JT, 1990, AM J ROENTGENOL, V155, P473; FOLEY WD, 1983, RADIOLOGY, V147, P797; FREENY PC, 1986, AM J ROENTGENOL, V147, P711; FREENY PC, 1986, RADIOLOGY, V160, P613; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HEIKEN JP, 1989, RADIOLOGY, V171, P47; ITAI Y, 1983, AM J ROENTGENOL, V141, P315; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Maclin Philip S., 1992, Journal of Medical Systems, V16, P215, DOI 10.1007/BF01000274; METZ CE, 1986, INVEST RADIOL, V21, P720; NELSON TR, 1990, INVEST RADIOL, V25, P1140; SCHILD H, 1987, FORTSCHR RONTG NEUEN, V147, P623; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101; WILLIAMS DM, 1989, INVEST RADIOL, V24, P768, DOI 10.1097/00004424-198910000-00008; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	20	6	6	LIPPINCOTT-RAVEN PUBL	PHILADELPHIA	227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106	0020-9996		INVEST RADIOL	Invest. Radiol.	JAN	1996	31	1					6	10		10.1097/00004424-199601000-00002		5	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	TP149	WOS:A1996TP14900002	
J	Smith, A; Sinha, A; Grodsinsky, CM				Smith, A; Sinha, A; Grodsinsky, CM			Neural-network-based classification of space acceleration measurement systems (SAMS) data via supervised learning	MICROGRAVITY SCIENCE AND TECHNOLOGY			English	Article								This paper illustrates the applicability of neural networks in classifying events using Space Acceleration Measurement System (SAMS) data. Computer programs have been written in the MATLAB environment for the following purposes: automatic retrieval of SAMS data from NASA CDROM disks, computation of power spectral densities for SAMS data and construction of input patterns for the training of a multi-layer neural network (MNN). The MNN has been trained using the backpropagation learning algorithm and the SAMS data collected on the STS-50 Space Shuttle mission for three crew exercise events. It is found that the trained MNN is highly successful in classifying events. In addition, the performance of MNN is found to be better than that of the nearest neighbor classifier.	NASA,LEWIS RES CTR,CLEVELAND,OH 44135	Smith, A (reprint author), PENN STATE UNIV,DEPT MECH ENGN,UNIVERSITY PK,PA 16802, USA.						BAUGHER CR, 1993, NASATM106059; BURKE LI, 1992, COMPUT OPER RES, V19, P179, DOI 10.1016/0305-0548(92)90043-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELOMBARD R, 1993, NASATM105960; DEMUTH H, 1994, NEURAL NETWORK TOOLB; DESILETS L, 1992, COMPUT OPER RES, V19, P277, DOI 10.1016/0305-0548(92)90049-B; GRANIER JP, 1993, PRES 11 MICR MEAS GR; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUANG WY, 1987, 1ST IEEE INT C NEUR, V4, P485; Lippmann R. P., 1987, IEEE ASSP MAGAZI APR, P4; Oppenheim A., 1975, DIGITAL SIGNAL PROCE; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901; *MATHW INC, 1993, MATLAB	14	0	0	CARL HANSER VERLAG	MUNICH	KOLBERGERSTRASSE 22, POSTFACH 860420, W-8163 MUNICH, GERMANY	0938-0108		MICROGRAVITY SCI TEC	Microgravity Sci. Technol.		1996	9	2					117	124				8	Engineering, Aerospace; Thermodynamics; Mechanics	Engineering; Thermodynamics; Mechanics	WM693	WOS:A1996WM69300009	
J	Cardillo, J; SidAhmed, MA				Cardillo, J; SidAhmed, MA			Target recognition in a cluttered scene using mathematical morphology	PATTERN RECOGNITION			English	Article						image processing; target recognition; mathematical morphology; machine vision; pattern recognition		This paper deals with the problem of locating targets within a cluttered gray-level digital image. The proposed new method is derived from principles in mathematical morphology. Basic morphological operations combined with some statistical techniques are used to generate a target recognition error function whose surface is minimized to estimate the probable location of a target. An automatic training procedure accompanies the new algorithm. The training provides the means by which the algorithm may automatically learn to deal with subtle differences in a target's appearance. A novel decomposition technique that provides some size invariance is also presented.	UNIV WINDSOR,DEPT ELECT ENGN,WINDSOR,ON N9B 3P4,CANADA							CHEN CH, 1969, IEEE T SYST SCI  JAN, V5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRIMMINS TR, 1985, IEEE T AERO ELEC SYS, V21, P60, DOI 10.1109/TAES.1985.310539; DESSIMOZ JD, 1984, IEEE T PATTERN ANAL, V6, P686; Duda R., 1973, PATTERN CLASSIFICATI; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532; HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O; LEVYMANDEL AD, 1986, COMPUT BIOMED RES, V19, P282, DOI 10.1016/0010-4809(86)90023-6; MARAGOS P, 1988, JUN P COMP SOC C COM; Matheron G., 1975, RANDOM SETS INTEGRAL; MEYER F, 1986, COMPUT VISION GRAPH, V35, P356, DOI 10.1016/0734-189X(86)90005-8; PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617; Rosenfeld A, 1982, DIGITAL PICTURE PROC; ROTH MW, 1990, IEEE T NEURAL NE MAR, V1; Serra J., 1982, IMAGE ANAL MATH MORP; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Shapiro L. G., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4); SHIH FY, 1988, JUN P COMP SOC C COM, P774; SIDAHMED MA, 1989, COMPUT IND, V12, P307, DOI 10.1016/0166-3615(89)90011-0; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; WONG RY, 1979, IEEE T PATTERN ANAL, V1, P325	21	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.	JAN	1996	29	1					27	49		10.1016/0031-3203(95)00065-8		23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	TQ849	WOS:A1996TQ84900003	
J	Henley, WE; Hand, DJ				Henley, WE; Hand, DJ			A k-nearest-neighbour classifier for assessing consumer credit risk	STATISTICIAN			English	Article						classification rule; credit risk; nearest neighbour methods		The last 30 years have seen the development of credit scoring techniques for assessing the creditworthiness of consumer loan applicants. Traditional credit scoring methodology has involved the use of techniques such as discriminant analysis, linear or logistic regression, linear programming and decision trees. In this paper we look at the application of the k-nearest-neighbour (k-NN) method, a standard technique in pattern recognition and nonparametric statistics, to the credit scoring problem. We propose an adjusted version of the Euclidean distance metric which attempts to incorporate knowledge of class separation contained in the data. Our k-NN methodology is applied to a real data set and we discuss the selection of optimal values of the parameters k and D included in the method. To assess the potential of the method we make comparisons with linear and logistic regression and decision trees and graphs. We end by discussing a practical implementation of the proposed k-NN classifier.	OPEN UNIV,DEPT STAT,MILTON KEYNES MK7 6AA,BUCKS,ENGLAND; ABBEY NATL PLC,MILTON KEYNES,BUCKS,ENGLAND							APILADO VP, 1974, J FINAN QUANT AN MAR, P275; BOYLE M, 1992, P C CRED SCOR CRED C, P75; Breiman L, 1984, CLASSIFICATION REGRE; CHANKONG V, 1983, LARGE SCALE SYST, V5, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROOK JN, 1992, P C CRED SCOR CRED C, P217; DURAND D, 1941, FINANCIAL RES PROGR, V8; Eisenbeis R., 1978, J BANK FINANC, V2, P205, DOI 10.1016/0378-4266(78)90012-2; FIX E, 1952, 4 US AIR FORC SCH AV; FOGARTY TC, 1993, IMA J MATH APPL BUSI, V5, P63, DOI 10.1093/imaman/5.1.63; FUKANAGA K, 1984, IEEE T PATTN ANAL MA, V1, P25; FUKANAGA K, 1975, IEEE T COMPUT, V24, P750; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gilbert L. R., 1990, J BUSINESS FINANCE A, V17, P161, DOI 10.1111/j.1468-5957.1990.tb00555.x; GRABLOWSKY BJ, 1981, J ECON BUS, V33, P254; Hand D. J., 1982, KERNEL DISCRIMINANT; HAND DJ, 1978, INFORM SCIENCES, V14, P171, DOI 10.1016/0020-0255(78)90040-3; HANDEL S, 1981, PERCEPT PSYCHOPHYS, V30, P1, DOI 10.3758/BF03206130; HENLEY WE, 1995, THESIS OPEN U M KEYN; LEONARD KJ, 1993, STAT PROBABIL LETT, V18, P289, DOI 10.1016/0167-7152(93)90017-D; MYERS JH, 1963, J AM STAT ASSOC, V58, P799, DOI 10.2307/2282727; MYLES J, 1991, THESIS OPEN U M KEYN; OLIVER JJ, 1992, 92173 MON U COMP SCI; ORGLER YE, 1970, J MONEY CREDIT B NOV, P435; Reichert A. K., 1983, J BUS ECON STAT, V1, P101, DOI 10.2307/1391851; SHORT RD, 1982, IEEE T INFORM THEORY, V27, P622; SRINIVASAN V, 1987, J FINANC, V92, P665; TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768; WIGINTON JC, 1980, J FINANC QUANT ANAL, V15, P757, DOI 10.2307/2330408	29	59	66	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD, OXON, ENGLAND OX4 1JF	0039-0526		STATISTICIAN	Statistician		1996	45	1					77	95		10.2307/2348414		19	Statistics & Probability	Mathematics	UB943	WOS:A1996UB94300009	
J	WEIDEMAN, WE; MANRY, MT; YAU, HC; GONG, W				WEIDEMAN, WE; MANRY, MT; YAU, HC; GONG, W			COMPARISONS OF A NEURAL-NETWORK AND A NEAREST-NEIGHBOR CLASSIFIER VIA THE NUMERIC HANDPRINT RECOGNITION PROBLEM	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Note								A comparison is made of two techniques for recognizing numeric handprint characters using a variety of features including two-dimensional (2-D) fast Fourier transform (FFT) coefficients, geometrical moments, and topological features. A backpropagation network and a nearest neighbor classifier are evaluated in terms of recognition performance and computational requirements. The results indicate that for complex problems, the neural network performs comparably to the nearest-neighbor classifier while being significantly more cost effective.	UNIV TEXAS,DEPT ELECT ENGN,ARLINGTON,TX 76019; KAOHSIUNG POLYTECH INST,DEPT INFORMAT ENGN,KAOHSIUNG 84008,TAIWAN; UNIV TEXAS,SW MED CTR,DEPT RADIOL,DALLAS,TX 75235	WEIDEMAN, WE (reprint author), VOICE CONTROL SYST,DALLAS,TX 75244, USA.						ANDREWS HC, 1971, IEEE T COMPUT, P1045; BURR DJ, 1988, IEEE T ACOUST SPEECH, V36, P1162, DOI 10.1109/29.1643; BURR DJ, 1987, 1ST P INT C NEURAL N, V4, P717; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GONG W, 1989, P IJCNN WASH, V2; GONG W, 1994, PROGR NEURAL NETWORK, V2, P253; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; GRANLUND G, 1970, IEEE R7098 COMP GROU; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hartigan J., 1975, CLUSTERING ALGORITHM; JACKEL LD, 1988, P INT C NEURAL NETWO, V2, P107; JACKEL LD, 1990, P INT C NEURAL NETWO, V2, P855; Kwan C. C., 1979, Proceedings of the International Conference on Cybernetics and Society; LIPPMANN RP, 1987, P INT C NEUR NETW IC, V4, P417; Preparata F. P., 1985, COMPUTATIONAL GEOMET; RUMELHART DE, 1986, PARALLEL DISTRIBUTED, P318; TALLMAN OH, 1969, THESIS AIR FORCE I T; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOU JT, 1974, PATTERN RECOGNITION, pCH3; Wang Q. R., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4); Werbos P.J., 1974, THESIS HARVARD U	22	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	NOV	1995	6	6					1524	1530		10.1109/72.471357		7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	TC776	WOS:A1995TC77600022	
J	IFTEKHARUDDIN, KM; SCHECHINGER, TD; JEMILI, K; KARIM, MA				IFTEKHARUDDIN, KM; SCHECHINGER, TD; JEMILI, K; KARIM, MA			FEATURE-BASED NEURAL WAVELET OPTICAL CHARACTER-RECOGNITION SYSTEM	OPTICAL ENGINEERING			English	Article						OPTICAL REMOTE SENSING; IMAGE PROCESSING; FEATURE EXTRACTION; IMAGE COMPRESSION; WAVELET TRANSFORM; OPTICAL CHARACTER RECOGNITION; OPTICAL MATCHED FILTER; OPTICAL BLUR	PHASE-ONLY FILTER; TRANSFORM; IMPLEMENTATION; DECOMPOSITION	A hybrid character recognition system that uses a feature-extraction method is proposed. The features are extracted using a wavelet transform, preclassified using a k-nearest-neighbor-based neural net and subsequently postprocessed using an optical correlator. This feature-based neural wavelet optical architecture is then tested on blurred character images.	UNIV DAYTON,CTR ELECTROOPT,DEPT ELECT ENGN,DAYTON,OH 45469	IFTEKHARUDDIN, KM (reprint author), BDM FED,1900 FOUNDERS DR,KETTERING,OH 45420, USA.						AWWAL AAS, 1990, APPL OPTICS, V29, P233, DOI 10.1364/AO.29.000233; CHAO TH, 1993, APPL OPTICS, V32, P1359, DOI 10.1364/AO.32.001359; CHAO TH, 1990, OSA TECHNICAL DIGEST, V14, P24; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; FARHAT NH, 1985, APPL OPTICS, V24, P1469; FUJII H, 1980, APPL OPTICS, V19, P1190, DOI 10.1364/AO.19.001190; KAMEMARU S, 1989, OPT COMMUN, V69, P211, DOI 10.1016/0030-4018(89)90101-6; KAMEMARU S, 1993, OPT ENG, V32, P26, DOI 10.1117/12.60071; KARCH BK, 1993, OPT ENG, V32, P2709, DOI 10.1117/12.148111; Lippmann R. P., 1987, IEEE ASSP MAGAZI APR, P4; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MOLLER AR, 1983, AUDITORY PHYSL; NAKAJIMA M, 1972, APPL OPTICS, V11, P362, DOI 10.1364/AO.11.000362; PAEK EG, 1987, OPT ENG, V26, P428; PARK JJ, 1994, FUZZY SETS NEURAL NE, P265; SCHMIDT WAC, 1994, OPT ENG, V33, P3388, DOI 10.1117/12.179387; VANDERLUGT A, 1964, IEEE T INFORM THEORY, V10, P139; Wasserman P. D., 1993, ADV METHODS NEURAL C, P35; WINTZER G, 1972, OPT LASER TECHNOL, V4, P222; WONG PW, 1994, IEEE T IMAGE PROCESS, V3, P302; WONG PW, 1993, IEEE T INFORM THEORY, V39, P7, DOI 10.1109/18.179337; ZHENG SH, 1992, OPT COMMUN, V89, P296, DOI 10.1016/0030-4018(92)90176-R	23	4	4	SOC PHOTO-OPT INSTRUM ENG	BELLINGHAM	PO BOX 10, BELLINGHAM, WA 98227-0010	0091-3286		OPT ENG	Opt. Eng.	NOV	1995	34	11					3193	3199		10.1117/12.213654		7	Optics	Optics	TF307	WOS:A1995TF30700015	
J	VAMOS, T; KOCH, P; KATONA, F				VAMOS, T; KOCH, P; KATONA, F			A STRATEGY OF KNOWLEDGE REPRESENTATION FOR UNCERTAIN PROBLEMS - EXPERIMENTS AND RELATIONS TO SIMILAR CONCEPTS	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Article							EXPERT SYSTEMS; CLASSIFICATION	The companion paper outlined the general schemes of pattern representation of knowledge. Extensive experiments proved the feasibility of the methods, e.g., a twelve-year project in early brain developmental problems, a sociolegal project and a search for patterns in economy. All these are characterized by overwhelming soft-type knowledge, The paper presents an overview of these research efforts, discussing similarities to and differences from the pattern method.	INST PEDIAT,DEPT DEV NEUROL & NEUROHABIL,BUDAPEST,HUNGARY	VAMOS, T (reprint author), HUNGARIAN ACAD SCI,COMP & AUTOMAT RES INST,H-1111 BUDAPEST,HUNGARY.						Aha D. W., 1991, P DARPA CAS BAS REAS, P147; AIKINS JS, 1983, ARTIF INTELL, V20, P163, DOI 10.1016/0004-3702(83)90017-6; ALKON DL, 1987, MEMORY TRACES NEURAL; Alkon D.L., 1989, Scientific American, V261, P26; Arbib M., 1992, ENCY ARTIFICIAL INTE, P1427; ARBIB MA, 1993, ARTIF INTELL, V59, P265, DOI 10.1016/0004-3702(93)90195-H; BERLINER H, 1989, ARTIF INTELL, V38, P161, DOI 10.1016/0004-3702(89)90056-8; BRATKO L, 1980, ADV COMPUTER CHESS; Buchanan B.G, 1984, RULE BASED EXPERT SY; CAIN T, 1991, P CAS BAS REAS WORKS, P191; CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077; CLANCEY WJ, 1992, ARTIF INTELL, V53, P1, DOI 10.1016/0004-3702(92)90037-X; CLANCEY WJ, 1993, ARTIF INTELL, V60, P313, DOI 10.1016/0004-3702(93)90007-X; CLANCEY WJ, 1993, ARTIF INTELL, V59, P191, DOI 10.1016/0004-3702(93)90185-E; CLANCEY WJ, 1981, 7TH P INT JOINT C AR, P829; COLLINS A, 1989, COGNITIVE SCI, V13, P1; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CSANYI V, 1989, EVOLUTIONARY SYSTEMS; DANYI P, 1989, 3RD P INT C EXP SYST, V1, P157; Dassow J., 1993, International Journal of Foundations of Computer Science, V4, DOI 10.1142/S012905419300002X; DEJONG AK, 1993, MACH LEARN, V13, P61; DHAR V, 1993, IEEE T KNOWL DATA EN, V5, P926, DOI 10.1109/69.250075; DIEDERICH J, 1988, KNOWLEDGE BASED SYST, V2, P83; Edelman G.M., 1989, NEURAL DARWINISM; ERENFELS C, 1887, FUHLEN WOLLEN PSYCHO; ERICSSON K. A., 1984, PROTOCOL ANAL; FEHLING MR, 1993, ARTIF INTELL, V59, P295, DOI 10.1016/0004-3702(93)90197-J; FU KS, 1983, IEEE T PATTERN ANAL, V5, P200; GAINES BR, 1988, KNOWLEDGE BASED SYST, P3; Gappa U, 1993, Artif Intell Med, V5, P185, DOI 10.1016/0933-3657(93)90024-W; GELSEMA ES, 1988, PATTERN RECOGNITION; Grenander U., 1970, ADV COMPUT, V10, P175, DOI 10.1016/S0065-2458(08)60436-2; GRENANDE.U, 1969, Q APPL MATH, V27, P1; HALL RP, 1989, ARTIF INTELL, V39, P39, DOI 10.1016/0004-3702(89)90003-9; HANSON SJ, 1988, MACH LEARN, V3, P343; Hart A., 1986, KNOWLEDGE ACQUISITIO; Hayek FA, 1973, LAW LEGISLATION LIBE, VI; HECKERMAN D, 1990, NETWORKS, V20, P607, DOI 10.1002/net.3230200508; HIEB M, 1992, MLI927 G MAS U CTR A; HIROTA K, 1993, FUZZY SETS SYSTEMS, V59, P231; KANAL LN, 1983, PATTERN RECOGN LETT, V14, P241; KATONA F, 1989, CHALLENGES TO DEVELOPMENTAL PARADIGMS : IMPLICATIONS FOR THEORY, ASSESSMENT AND TREATMENT, P167; Katona F, 1988, EARLY IDENTIFICATION, P121; KATONA F, 1992, KINDERARZT, P195; KATONI F, 1991, KINDERARZT, V22, P1166; Kauffman S. A., 1993, ORIGINS ORDER SELF O; KETLER K, 1993, EXPERT SYST APPL, V6, P3, DOI 10.1016/0957-4174(93)90014-W; Koch P., 1987, Intelligent Autonomous Systems. An International Conference; KOCH P, 1989, P AUSTRO HUNGARIAN C, P177; LANZOLA G, 1990, COMPUT BIOMED RES, V23, P560, DOI 10.1016/0010-4809(90)90041-A; LEE KF, 1988, ARTIF INTELL, V36, P1, DOI 10.1016/0004-3702(88)90076-8; LEVINSON R, 1990, PATTERN ASS RETRIEVA; LEVINSON R, 1991, UCSCCRL9115 U CAL CO; MATHEUS CJ, 1993, IEEE T KNOWL DATA EN, V5, P903, DOI 10.1109/69.250073; MICHALSKI RS, 1983, MACHINE LEARNING, V1; MICHALSKI RS, 1990, MLI901 G MAS U CTR A; MICHALSKI RS, 1985, ARTIF INTELL, V25, P187; MILLER RA, 1982, NEW ENGL J MED, V307, P468, DOI 10.1056/NEJM198208193070803; MINSKY M, 1993, ARTIF INTELL, V59, P343, DOI 10.1016/0004-3702(93)90199-L; Ortony A., 1988, COGNITIVE STRUCTURE; PAO YH, 1985, INFORMATION SYSTEMS, V9, P221; PAO YH, 1986, P SOCOCO 86, P4; Peng Y., 1990, ABDUCTIVE INFERENCE; Polya G., 1954, MATH PLAUSIBLE REASO, V1-2; POLYA G, 1954, INTRO ANALOGY MATH, V2; POPLE HE, 1985, P INT C ARTIF INTELL, P128; Pribram K., 1991, BRAIN PERCEPTION; SHAW GG, 1987, KNOWLEDGE ACQUISITIO; SHAW LG, 1988, KNOWLEDGE BASED SYST, V2, P309; SLADE S, 1991, AI MAG, P42; SLATTER E, 1988, BUILDING EXPERT SYST; SMETS P, 1988, NONSTANDARD LOGICS A; SMOLENSKY P, 1988, BEHAV BRAIN SCI, V11, P1; SOBAJIC DJ, 1987, 1987 P ANN C SYST MA, P390; TORASSO P, 1989, DIAGNOSTIC PROBLEM S; Tufte E. R., 1983, VISUAL DISPLAY QUANT; TUFTE ER, 1990, ENVISIONING INFORMAT; VAMOS T, 1991, P EXPERT SYST WORLD, V4, P2759; VAMOS T, 1992, ANAL DESIGN EVALUATI; VAMOS T, 1995, IEEE T SYST MAN CYB, V25, P1365, DOI 10.1109/21.464445; VELOSO M, 1991, P CAS BAS REAS WORKS, P93; WATERMAN DA, 1978, PATTERN DIRECTED INF; WEIGEND AS, 1993, ARTIF INTELL, V62, P93, DOI 10.1016/0004-3702(93)90048-G; ZADEH L. A., 1989, IEEE T KNOWL DATA EN, V1, P89, DOI [DOI 10.1109/69.43406, 10.1109/69.43406]; ZADEH LA, 1965, INFORM CONTR, V8, P421	86	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.	OCT	1995	25	10					1371	1383		10.1109/21.464444		13	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	RW045	WOS:A1995RW04500003	
J	COSTA, MCA; BARATA, LES; TAKAHATA, Y				COSTA, MCA; BARATA, LES; TAKAHATA, Y			SAR ANALYSIS OF SYNTHETIC NEOLIGNANS AND RELATED-COMPOUNDS WHICH ARE ANTI-LEISHMANIASIS ACTIVE COMPOUNDS USING PATTERN-RECOGNITION METHODS	THEOCHEM-JOURNAL OF MOLECULAR STRUCTURE			English	Article							SEMIEMPIRICAL METHODS; OPTIMIZATION; PARAMETERS	Potentially active new neolignan and analogues against leishmaniasis are proposed. Structure-activity relationship (SAR) techniques were employed. Physicochemical properties such as log P, molecular volume, atomic charge and quantum chemical parameters were calculated for a group of synthetic substances for which the biological activities against leishmaniasis are known. Only about half a dozen out of more than twenty parameters were found to be efficient for the classification of the compounds into active and inactive groups.	UNIV ESTADUAL CAMPINAS,INST QUIM,BR-13083970 CAMPINAS,SP,BRAZIL							BARATA LES, 1976, THESIS U ESTADUAL CA; BARATA LES, 1978, PHYTOCHEMISTRY, V17, P783, DOI 10.1016/S0031-9422(00)94227-4; BARATA LES, 1991, 2 S BRAS AL PROD NAT; BARATA LES, UNPUB ANTILEISHMANIA; BURKET U, 1982, ACS MONOGRAPH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; GAUDIO AC, 1992, COMPUT CHEM, V16, P277, DOI 10.1016/0097-8485(92)80047-4; GOTTLIEB OR, 1977, FORTSCHR CHEM ORG NA, V35, P1; HIGO J, 1989, J COMPUT CHEM, V10, P376, DOI 10.1002/jcc.540100311; KARCHER W, 1990, CHEM ENV SCI, V1, P1; KOWALSKI BR, 1984, CHEMOMETRICS MATH ST, P51; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; NYS GG, 1974, EUR J MED CHEM, V9, P361; SANTOS LS, 1991, THESIS U ESTADUAL CA; SCARMINIO IS, 1989, TRAC-TREND ANAL CHEM, V8, P326, DOI 10.1016/0165-9936(89)87038-4; STEWART JJP, 1989, J COMPUT CHEM, V10, P221, DOI 10.1002/jcc.540100209; STEWART JJP, 1989, J COMPUT CHEM, V10, P209, DOI 10.1002/jcc.540100208; WHITING DA, 1990, NAT PROD REP, V7, P349, DOI 10.1039/np9900700349	19	14	14	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-1280		THEOCHEM-J MOL STRUC	Theochem-J. Mol. Struct.	SEP 20	1995	340						185	192				8	Chemistry, Physical	Chemistry	RU765	WOS:A1995RU76500016	
J	KULKARNI, SR; POSNER, SE				KULKARNI, SR; POSNER, SE			RATES OF CONVERGENCE OF NEAREST-NEIGHBOR ESTIMATION UNDER ARBITRARY SAMPLING	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	1994 IEEE International Symposium on Information Theory	JUN 27-JUL 01, 1994	TRONDHEIM, NORWAY	IEEE		NEAREST NEIGHBOR; NONPARAMETRIC REGRESSION ESTIMATION; RATES OF CONVERGENCE; METRIC ENTROPY; COVERING NUMBERS; WORST CASE; CONSISTENCY; DETERMINISTIC SAMPLING; ARBITRARY SAMPLING	CLASSIFICATION RULES; REGRESSION	Rates of convergence for nearest neighbor estimation are established in a general framework in terms of metric covering numbers of the underlying space. Our first result is to find explicit finite sample upper bounds for the classical independent and identically distributed (i.i.d.) random sampling problem in a separable metric space setting. The convergence rate is a function of the covering numbers of the support of the distribution. For example, for bounded subsets of R(r), the convergence rat is O(1/n(2/r)). Our main result is to extend the problem to allow samples drawn from a completely arbitrary random process in a separable metric space and to examine the performance in terms of the individual sample sequences. We show that for every sequence of samples the asymptotic time-average of nearest neighbor risks equals twice the time-average of the conditional Bayes risks of the sequence. Finite sample upper bounds under arbitrary sampling are again obtained in terms of the covering numbers of the underlying space. In particular, for bounded subsets of R(r) the convergence rate of the time-averaged risk is O(1/n(2/r)). We then establish a consistency result for k(n)-nearest neighbor estimation under arbitrary sampling and prove a convergence rate matching established rates for i.i.d. sampling. Finally, we show how our arbitrary sampling results lead to some classical i.i.d. sampling results and in fact extend them to stationary sampling. Our framework and results are quite general while the proof techniques are surprisingly elementary.		KULKARNI, SR (reprint author), PRINCETON UNIV,DEPT ELECT ENGN,PRINCETON,NJ 08544, USA.						Beck J., 1979, Problems of Control and Information Theory, V8; CHENG PE, 1984, J MULTIVARIATE ANAL, V15, P63, DOI 10.1016/0047-259X(84)90067-8; Cover T. M., 1991, MATH FINANC, V1, P1, DOI 10.1111/j.1467-9965.1991.tb00002.x; COVER TM, 1968, 1ST P ANN HAW C SYST, P413; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1982, Z WAHRSCHEINLICHKEIT, V61, P467, DOI 10.1007/BF00531618; DEVROYE LP, 1978, IEEE T INFORM THEORY, V24, P142, DOI 10.1109/TIT.1978.1055865; DEVROYE LP, 1981, ANN STAT, V9; FEDER M, 1992, IEEE T INFORM THEORY, V38, P1258, DOI 10.1109/18.144706; Fix E, 1951, DISCRIMINATORY ANAL; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; Gyorfi L., 1981, Problems of Control and Information Theory, V10; Kolmogorov A.N., 1961, AM MATH SOC TRANSL, V17, P277; KRZYZAK A, 1986, IEEE T INFORM THEORY, V32, P668, DOI 10.1109/TIT.1986.1057226; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Parthasarathy K. R., 1967, PROBABILITY MEASURES; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STUTE W, 1984, ANN STAT, V12, P917, DOI 10.1214/aos/1176346711; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	21	34	34	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	JUL	1995	41	4					1028	1039		10.1109/18.391248		12	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	RF599	WOS:A1995RF59900012	
J	MCKENZIE, DP; FORSYTH, RS				MCKENZIE, DP; FORSYTH, RS			CLASSIFICATION BY SIMILARITY - AN OVERVIEW OF STATISTICAL-METHODS OF CASE-BASED REASONING	COMPUTERS IN HUMAN BEHAVIOR			English	Article							LEARNING ALGORITHMS; NEURAL-NETWORK; ERROR RATE	There has recently been a great deal of interest in case-based reasoning, the generation of solutions to new problems using methods which have served for similar problems in the past. Much of the commonly available computer software is however concerned with ''case-retrieval.'' The fatter involves the matching of an observation for which the outcome is not known, to a database of examples for which the outcome is known. Various types of case retrieval, or ''classification by similarity'' (CBS), algorithms are discussed. Several CBS algorithms, as well as various other techniques, were applied to two small datasets. Although more comparisons are required the CBS algorithms were found to perform significantly better than a linear discriminant analysis on a predominantly binary dataset. A single-nearest-nsighbor technique, first developed in the 1950s, performed particularly well on this dataset. A more sophisticated CBS algorithm, based upon a type of neural network, performed consistently well on bath datasets. As CBS techniques generally encourage the researcher to work closely with databases, they should be developed further Progress needs to be made in the identification of ''good'' subsets of classifier variables, as well as in bridging the gap between statistical techniques and artificial intelligence.	MONASH UNIV,DEPT PSYCHOL MED,CLAYTON,VIC,AUSTRALIA; UNIV W ENGLAND,DEPT MATH SCI,BRISTOL,AVON,ENGLAND							AFIFI AA, 1979, STATISTICAL ANAL COM; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; ATTNEAVE F, 1959, APPLICATIONS INFORMA; BARLETTA R, 1991, AI EXPERT, V6, P43; BOUNDS DG, 1990, NEURAL NETWORKS, V3, P583, DOI 10.1016/0893-6080(90)90008-9; Breiman L, 1984, CLASSIFICATION REGRE; BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V4, P458; Caudill M., 1992, UNDERSTANDING NEURAL, V2; COLERIDGE ST, 1906, BIOGRAPHIA LITERARIA, V1; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijer P. A., 1982, PATTERN RECOGNITION; DWINNELL W, 1994, AI EXPERT, V9, P38; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; ELIOT LB, 1992, AI EXPERT, V7, P9; FIX E, 1951, USAF4 SCH AV MED REP; FORSYTH R, 1989, MACHINE LEARNING PRI, P65; FORSYTH RS, 1992, RES DEV EXPERT SYSTE, V9, P183; FORSYTH RS, 1990, 3RD P C NEUR NETS TH, P301; Garson G.D., 1991, AI EXPERT, V6, P47; Hale R. L., 1986, Computers in Human Behaviour, V2, DOI 10.1016/0747-5632(86)90003-8; HAUCK WW, 1991, STAT MED, V10, P711, DOI 10.1002/sim.4780100505; Institute SAS, 1989, SAS STAT US GUID VER; Jain A. K., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop; James M., 1985, CLASSIFICATION ALGOR; JENNRICH R, 1988, BMDP STATISTICAL SOF, V1, P347; Kaufman L., 1990, FINDING GROUPS DATA; KELLY JD, 1991, 4TH P INT C GEN ALG, P377; Kohonen T., 1988, SELF ORG ASS MEMORY; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LUK A, 1986, PATTERN RECOGN LETT, V4, P375, DOI 10.1016/0167-8655(86)90059-0; Martindale C., 1991, COGNITIVE PSYCHOL NE; MCKENZIE D, 1992, COMPUT HUM BEHAV, V8, P155, DOI 10.1016/0747-5632(92)90001-U; MCKENZIE DP, 1993, METHOD INFORM MED, V32, P161; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; MUSAVI MT, 1993, NEURAL NETWORKS, V6, P397, DOI 10.1016/0893-6080(93)90007-J; Nelson MM, 1991, PRACTICAL GUIDE NEUR; PATRICK EA, 1990, PATTERN RECOGN, V23, P1427, DOI 10.1016/0031-3203(90)90088-3; PATRICK J, 1991, 91151 MON U TECH REP; Rich E., 1991, ARTIFICIAL INTELLIGE; Riesbeck C., 1989, INSIDE CASE BASED RE; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; RISSLAND EL, 1989, 5TH P C ART INT APPL, P45; Rothman P., 1992, AI Expert, V7; SLADE S, 1991, AI MAG, V12, P42; Specht D.F., 1992, INT JOINT C NEURAL N, VI, P761; SPECHT DF, 1991, P INT JOINT C NEUR N, P887; SPECHT DF, 1990, JUL P INT NEUR NETW, P440; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Tabachnick B., 1989, USING MULTIVARIATE S; Tulving E., 1972, ORG MEMORY, P381; TYRON WW, 1993, CLIN PSYCHOL REV, V13, P341; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; *CAL SCI SOFTW, 1989, BRAINM US GUID MAN; *FIRSTM TECHN, 1990, KNOWL SEEK US GUID; *HESS CONSL, 1992, MOD APPL UN PROC MOD; *IMSL, 1987, IMSL STAT LIBR US MA; *TER IA INC, 1992, MOD MOD PROF US MAN; *WARD SYST GROUP, 1992, NEUR NEUR NETW DYN L; 1989, STAT SCI, V4, P34	60	8	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0747-5632		COMPUT HUM BEHAV	Comput. Hum. Behav.	SUM	1995	11	2					273	288		10.1016/0747-5632(94)00036-H		16	Psychology, Multidisciplinary; Psychology, Experimental	Psychology	RA128	WOS:A1995RA12800009	
J	SALZBERG, S; DELCHER, AL; HEATH, D; KASIF, S				SALZBERG, S; DELCHER, AL; HEATH, D; KASIF, S			BEST-CASE RESULTS FOR NEAREST-NEIGHBOR LEARNING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MACHINE LEARNING; NEAREST-NEIGHBOR; GEOMETRIC CONCEPTS		In this paper we propose a theoretical model for analysis of classification methods, in which the teacher knows the classification algorithm and chooses examples in the best way possible. We apply this model using the nearest-neighbor learning algorithm, and develop upper and lower bounds on sample complexity for several different concept classes. For some concept classes, the sample complexity turns out to be exponential even using this best-case model, which implies that the concept class is inherently difficult for the NN algorithm. We identify several geometric properties that make learning certain concepts relatively easy. Finally we discuss the relation of our work to helpful teacher models, its application to decision tree learning algorithms, and some of its implications for current experimental work.	LOYOLA COLL,DEPT COMP SCI,BALTIMORE,MD 21210	SALZBERG, S (reprint author), JOHNS HOPKINS UNIV,DEPT COMP SCI,BALTIMORE,MD 21218, USA.		Salzberg, Steven/F-6162-2011				Aha D., 1991, MACHINE LEARNING, V6; ANGLUIN D, 1987, INFORM COMPUT, V75, P87, DOI 10.1016/0890-5401(87)90052-6; BAKER BS, 1988, DISCRETE COMPUT GEOM, V3, P147, DOI 10.1007/BF02187904; BERN M, 1992, LATIN 92, P46; BERN M, 1994, 10TH P ANN ACM S COM, P221; BERN M, 1991, 7TH P ANN S COMP GEO, P342; BHATTACHARYA B, 1992, SOCS9219 TECH REP; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NN NORMS NN PATTERN; Devijver P. A., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; FIX E, 1952, USAF11 SCH AV MED RE; GOLDMAN SA, 1991, 4TH P ANN WORKSH COM, P303; HART PE, 1968, IEEE T INFORMATION T, V14; HEATH D, 1992, GEOMETRIC FRAMEWORK; Minsky M., 1969, PERCEPTRONS; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; ROMANIK K, 1995, COMP GEOM-THEOR APPL, V5, P33, DOI 10.1016/0925-7721(94)00016-O; SALZBERG S, 1991, 12TH P INT JOINT C A, P705; SALZBERG S, 1992, 9014 J HOPK U DEP CO; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SALZBERG SL, 1990, LEARNING NESTED GENE; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOUSSAINT G, 1984, 16 S COMP SCI STAT, P97; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	30	15	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					599	608		10.1109/34.387506		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	QZ940	WOS:A1995QZ94000005	
J	BAGUI, SC; PAL, NR				BAGUI, SC; PAL, NR			A MULTISTAGE GENERALIZATION OF THE RANK NEAREST-NEIGHBOR CLASSIFICATION RULE	PATTERN RECOGNITION LETTERS			English	Article						BAYES ERROR RATE; CLASSIFICATION; RANK NEAREST NEIGHBOR; KAPPA-NEAREST NEIGHBOR		We consider the problem of classifying an unknown observation from one of s (greater than or equal to 2) univariate classes (or populations) using a multi-stage left and right rank nearest neighbor (RNN) rule. We derive the asymptotic error rate (i.e., total probability of misclassification (TPMC)) of the m-stage univariate RNN (m-URNN) rule, and show that as the number of stages increases, the limiting TPMC of the m-stage univariate rule decreases. Monte Carlo simulations are used to study the behavior of the m-URNN rule and compare it with the conventional R-NN rule. Finally, we incorporate an extension of the m-URNN rule to multivariate observations with empirical results.	UNIV W FLORIDA,DIV COMP SCI,PENSACOLA,FL 32514	BAGUI, SC (reprint author), UNIV W FLORIDA,DEPT MATH & STAT,PENSACOLA,FL 32514, USA.						ANDERSON TW, 1966, 1ST P INT S AN; BAGUI SC, 1993, PATTERN RECOGN LETT, V14, P537, DOI 10.1016/0167-8655(93)90102-J; BAGUI SC, 1989, THESIS U ALBERTA; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1980, SANKHYA A, V42, P419; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Fix E, 1951, 4 US AIR FORC SCH AV; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GESSAMAN MP, 1970, ANN MATH STAT, V41, P1344, DOI 10.1214/aoms/1177696909; Johnson R. A., 1988, APPLIED MULTIVARIATE; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	14	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	1995	16	6					601	614		10.1016/0167-8655(95)80006-F		14	Computer Science, Artificial Intelligence	Computer Science	RD539	WOS:A1995RD53900006	
J	OEHLER, KL; GRAY, RM				OEHLER, KL; GRAY, RM			COMBINING IMAGE COMPRESSION AND CLASSIFICATION USING VECTOR QUANTIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE COMPRESSION; IMAGE CLASSIFICATION; VECTOR QUANTIZATION; IMAGE CODING; STATISTICAL CLUSTERING	QUANTIZERS; DESIGN	Statistical clustering methods have long been used for a variety of signal processing applications,including both classification and vector quantization for signal compression. We describe a method of combining classification and compression into a single vector quantizer by incorporating a Bayes risk term into the distortion measure used in the quantizer design algorithm. Once trained, the quantizer can operate to minimize the Bayes risk weighted distortion measure if there is a model providing the required posterior probabilities, or it can operate in a suboptimal fashion by minimizing only squared error. Comparisons are made with other vector quantizer based classifiers, including the independent design of quantization and minimum Bayes risk classification and Kohonen's LVQ, A variety of examples demonstrate that the proposed method can provide classification ability close to or superior to LVQ while simultaneously providing superior compression performance.	STANFORD UNIV,DEPT ELECT ENGN,INFORMAT SYST LAB,STANFORD,CA 94305	OEHLER, KL (reprint author), TEXAS INSTRUMENTS INC,INTEGRATED SYST LAB MS 446,DALLAS,TX 75265, USA.						Abut H., 1990, VECTOR QUANTIZATION; BENITZ GR, 1989, IEEE T INFORM THEORY, V35, P316, DOI 10.1109/18.32125; Breiman L, 1984, CLASSIFICATION REGRE; CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498; CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124; COSMAN PC, 1994, RADIOLOGY, V190, P517; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; Fix E, 1951, DISCRIMINATORY ANAL; FORGY EW, 1965, BIOMETRICS, V21, P768; GERSHO A, 1992, VECTOR QUANTIZATIONS; HAMABE R, 1981, JUN P ANN C I TEL EN; HILBERT EE, 1977, PUBLICATION JET PROP, V7743; HUANG SS, 1988, SPEECH COMMUN, V7, P41, DOI 10.1016/0167-6393(88)90020-9; KOHENEN T, 1988, JUL IEEE INT C NEUR, P61; KOHENEN T, 1992, LVQ AK LEARNING VECT; KOHONEN T, 1989, SELF ORG ASS MEM; KRAMER J, 1990, 19900805 STANF U CTR; LLOYD SP, 1957, UNPUB IEEE T INFORMA; LUGOSI G, 1993, UIUCBI9301 U ILL URB; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; MCLEAN GF, 1993, IEEE T SYST MAN CYB, V23, P637, DOI 10.1109/21.256539; NOBEL AB, UNPUB HISTOGRAM REGR; NOBEL AB, UNPUB TERMINATION CO; OEHLER KL, 1991, 25TH AS C SIGN SYST, P439; OEHLER KL, 1993, 1993 P IEEE DAT COMP, P2; OEHLER KL, 1993, THESIS STAFORD U; PERLMUTTER K, 1993, APR P IEEE DAT COMPR, P274; PERLMUTTER KO, 1994, UNPUB BYES RISK WEIG; POOR HV, 1977, IEEE T COMMUN, V25, P893, DOI 10.1109/TCOM.1977.1093935; POPAT K, 1994, P ICASSP ADELAIDE; POPAT K, 1993, NOV P SPIE VIS COMM; RISKIN EA, 1991, IEEE T SIGNAL PROCES, V39, P2500, DOI 10.1109/78.98004; SHORE JE, 1982, MAY P ICASSP 82, P907; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WESEL RD, 1994, APR P IEEE DAT COMPR; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326	37	55	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					461	473		10.1109/34.391396		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	QW394	WOS:A1995QW39400002	
J	DENOEUX, T				DENOEUX, T			A K-NEAREST NEIGHBOR CLASSIFICATION RULE-BASED ON DEMPSTER-SHAFER THEORY	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Article							DECISION	In this paper, the problem of classifying an unseen pattern on the basis of its nearest neighbors in a recorded data set is addressed from the point of view of Dempster-Shafer theory. Each neighbor of a sample to be classified is considered as an item of evidence that supports certain hypotheses regarding the class membership of that pattern. The degree of support is defined as a function of the distance between the two vectors, The evidence of the k nearest neighbors is then pooled by means of Dempster's rule of combination. This approach provides a global treatment of such issues as ambiguity and distance rejection, and imperfect knowledge regarding the class membership of training patterns, The effectiveness of this classification scheme as compared to the voting and distance-weighted k-NN procedures is demonstrated using several sets of simulated and real-world data.		DENOEUX, T (reprint author), UNIV TECHNOL COMPIEGNE,CNRS,URA,817 HEUDIASYC,BP 649,F-60206 COMPIEGNE,FRANCE.						BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; CASELTON WF, 1992, WATER RESOUR RES, V28, P3071, DOI 10.1029/92WR01818; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, IEEE COMPUTER SOC PR; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DEMPSTER AP, 1987, STAT SCI, V2, P32, DOI 10.1214/ss/1177013430; Deterding DH, 1989, THESIS U CAMBRIDGE; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1951, 4 USAF SCH AV MED TE; HELLMAN ME, 1970, IEEE T SYST SCI CYB, V3, P179; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; Murphy P., 1994, UCI REPOSITORY MACHI; ROBINSON AJ, 1989, THESIS CAMBRIDGE U; Shafer G., 1976, MATH THEORY EVIDENCE; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; TESSEM B, 1993, ARTIF INTELL, V61, P315, DOI 10.1016/0004-3702(93)90072-J	21	277	293	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.	MAY	1995	25	5					804	813		10.1109/21.376493		10	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	QT095	WOS:A1995QT09500008	
J	ROVATTI, R; RAGAZZONI, R; KOVACS, ZM; GUERRIERI, R				ROVATTI, R; RAGAZZONI, R; KOVACS, ZM; GUERRIERI, R			ADAPTIVE VOTING RULES FOR K-NEAREST NEIGHBORS CLASSIFIERS	NEURAL COMPUTATION			English	Article							RECOGNITION; ALGORITHMS	A simple form of cooperation between the k-nearest neighbors (NN) approach to classification and the neural-like property of adaptation is explored. A tunable, high level k-nearest neighbors decision rule is defined that comprehends most previous generalizations of the common majority rule. A learning procedure is developed that applies to this rule and exploits those statistical features that can be induced from the training set. The overall approach is tested on a problem of handwritten character recognition. Experiments show that adaptivity in the decision rule may improve the recognition and rejection capability of standard k-NN classifiers.		ROVATTI, R (reprint author), UNIV BOLOGNA,DEPT ELECTR,BOLOGNA,ITALY.						BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Cao J., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems, DOI 10.1109/ICPR.1992.201859; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S., 1976, IEEE, V4, P325; Garris M. D., 1992, NIST SPECIAL DATABAS; HEBB DO, 1949, ORG BEHAVIOR; Kawabata T., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.3.409; KOVACS ZM, 1992, ELECTRON LETT, V28, P1825; KOVACS ZM, 1993, ELECTRON LETT, V14, P1308; KOVACS ZM, 1993, P WORLD C NEURAL NET, P186; Lee Y., 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; MACKAY DJC, 1992, NEURAL COMPUT, V3, P415; MACKAY DJC, 1992, NEURAL COMPUT, V5, P720; Martin G. L., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.258; PARTHASARATHY G, 1990, IEEE T SYST MAN CYB, V3, P715; RICHARD MD, 1991, NEURAL COMPUT, V4, P461; Takahashi H., 1991, P 1 INT C DOC AN REC, P821; TOMEK I, 1976, IEEE T INFORM THEORY, V2, P121; VAPNIK V, 1993, NEURAL COMPUT, V5, P893, DOI 10.1162/neco.1993.5.6.893	19	3	3	MIT PRESS	CAMBRIDGE	55 HAYWARD ST JOURNALS DEPT, CAMBRIDGE, MA 02142	0899-7667		NEURAL COMPUT	Neural Comput.	MAY	1995	7	3					594	605		10.1162/neco.1995.7.3.594		12	Computer Science, Artificial Intelligence	Computer Science	QQ866	WOS:A1995QQ86600010	
J	GALVEZ, J; GARCIADOMENECH, R; DEJULIANORTIZ, JV; SOLER, R				GALVEZ, J; GARCIADOMENECH, R; DEJULIANORTIZ, JV; SOLER, R			TOPOLOGICAL APPROACH TO DRUG DESIGN	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article								In this paper we demonstrate that by an adequate combination of different topological indices it is possible to select and design new active compounds in different therapeutical scopes, with a very high efficiency level. Particularly successful in the search of new ''lead drugs'', the results show the surprising ability of the topological methods to describe molecular structures.		GALVEZ, J (reprint author), UNIV VALENCIA,FAC PHARM,DEPT PHYS CHEM,RES MOLEC CONNECT & DRUG DESIGN UNIT,C CISCAR 40,E-46005 VALENCIA,SPAIN.						ANTONFOS GM, 1994, ARZNEIMITTEL-FORSCH, V44-2, P821; Burket U., 1982, ACS MONOGRAPH, V177; COLLOUS T, 1973, DISCRIMINANT ANAL AP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANKE R, 1984, THEORETICAL DRUG DES, V7, P25; FRANKE R, 1984, THEORETICAL DRUG DES, V7, P316; GALVEZ J, 1991, Anales de la Real Academia de Farmacia, V57, P533; GALVEZ J, 1991, Patent No. 9101034; GALVEZ J, 1994, J CHEM INF COMP SCI, V34, P1198, DOI 10.1021/ci00021a030; GALVEZ J, 1991, Patent No. 9101134; GALVEZ J, 1994, J CHEM INF COMP SCI, V34, P520, DOI 10.1021/ci00019a008; GARCIA F, 1991, THESIS U VALENCIA SP, P67; GARCIA R, 1992, REV TOXICOL, V9, P15; Garcia-Domenech R., 1991, DRUG INVEST, V3, P344; HETNARSKI B, 1975, J MED CHEM, V18, P29, DOI 10.1021/jm00235a007; Kier LB, 1976, MOL CONNECTIVITY CHE, P46; MOLINER R, 1991, AN R ACAD FARM, V57, P287; MUNOZ C, 1994, REV ESP QUIMIOTER, V7, P279; Nilsson Nils J., 1965, LEARNING MACHINES; RANDIC M, 1991, J CHEM INF COMP SCI, V31, P311, DOI 10.1021/ci00002a018; Richards WG, 1977, QUANTUM PHARM; Soler Roca R. M., 1992, Anales de Quimica, V88, P382; Soler-Roca R.M., 1992, J CHROMATOGR, V607, P91; SPINKS A, 1973, CHEM IND, V12, P885	24	166	167	AMER CHEMICAL SOC	WASHINGTON	PO BOX 57136, WASHINGTON, DC 20037-0136	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	MAR-APR	1995	35	2					272	284		10.1021/ci00024a017		13	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	QP330	WOS:A1995QP33000018	
J	ANDREE, HMA; LOURENS, W; TAAL, A; VERMEULEN, JC				ANDREE, HMA; LOURENS, W; TAAL, A; VERMEULEN, JC			FEEDFORWARD NEURAL NETWORKS FOR SHOWER RECOGNITION - CONSTRUCTION AND GENERALIZATION	NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT			English	Article							ALGORITHM	Strictly layered feed-forward neural networks are explored as recognition tools for energy deposition patterns in a calorimeter. This study is motivated by possible applications for on-line event selection. Networks consisting of linear threshold units are generated by a constructive learning algorithm, the Patch algorithm. As a non-constructive counterpart the back-propagation algorithm is applied. This algorithm makes use of analogue neurons. The generalization capabilities of the neural networks resulting from both methods are compared to those of nearest-neighbour classifiers and of Probabilistic Neural Networks implementing Parzen-windows. The latter non-parametric statistical method is applied to estimate the optimal Bayesian classifier. For all methods the generalization capabilities are determined for different ways of pre-processing of the input data. The complexity of the feed-forward neural networks studied does not grow with the training set size. This favours a hardwired implementation of these neural networks as any implementation of the other two methods grows linearly with the training set size.	NIKHEF H,1009 DB AMSTERDAM,NETHERLANDS	ANDREE, HMA (reprint author), UNIV UTRECHT,DEPT PHYS & ASTRON,POB 8000,3508 TA UTRECHT,NETHERLANDS.						ANDREE HMA, 1992, SEP P C COMP HIGH EN, P21; BADIER J, EASTNOTE9110; BADIER J, 1993, IEEE T NUCL SCI, V40, P45, DOI 10.1109/23.199486; BARKEMA GT, 1993, NETWORK-COMP NEURAL, V4, P393, DOI 10.1088/0954-898X/4/3/009; BOCK RK, EASTNOTE9410; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENBY B, 1992, 2ND P INT WORKSH SOF, P287; Digby P.G.N., 1987, MULTIVARIATE ANAL EC; Duda R., 1973, PATTERN CLASSIFICATI; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Frean M., 1990, NEURAL COMPUT, V2, P198, DOI 10.1162/neco.1990.2.2.198; Gallant S I, 1990, IEEE Trans Neural Netw, V1, P179, DOI 10.1109/72.80230; GOLEA M, 1990, EUROPHYS LETT, V12, P205, DOI 10.1209/0295-5075/12/3/003; Hertz J., 1991, INTRO THEORY NEURAL; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; KEIBEK SAJ, 1992, EUROPHYS LETT, V18, P555, DOI 10.1209/0295-5075/18/6/014; KLYUCHNIKOV G, 1992, EASTNOTE9223; MARCHAND M, 1990, EUROPHYS LETT, V11, P487, DOI 10.1209/0295-5075/11/6/001; MARCHAND M, 1993, NETWORK-COMP NEURAL, V4, P67, DOI 10.1088/0954-898X/4/1/005; MARTINEZ D, 1992, EUROPHYS LETT, V18, P95, DOI 10.1209/0295-5075/18/2/001; MEZARD M, 1989, J PHYS A-MATH GEN, V22, P2191, DOI 10.1088/0305-4470/22/12/019; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Press WH, 1988, NUMERICAL RECIPES C; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266; RUJAN P, 1989, COMPLEX SYSTEMS, V3, P229; RUJAN P, 1993, J PHYS I, V3, P277; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; SCHIOLER H, 1992, NEURAL NETWORKS, V5, P903; SEIXAS JM, EASTNOTE9317; Sirat JA, 1990, NETWORK-COMP NEURAL, V1, P423, DOI 10.1088/0954-898X/1/4/003; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; 1992, CERNDRDC9211 PROP ST; 1990, CERNDRDC9056 PROP ST	35	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-9002		NUCL INSTRUM METH A	Nucl. Instrum. Methods Phys. Res. Sect. A-Accel. Spectrom. Dect. Assoc. Equip.	FEB 15	1995	355	2-3					589	599		10.1016/0168-9002(94)01156-7		11	Instruments & Instrumentation; Nuclear Science & Technology; Physics, Particles & Fields; Spectroscopy	Instruments & Instrumentation; Nuclear Science & Technology; Physics; Spectroscopy	QJ706	WOS:A1995QJ70600051	
S	Zhao, QF; Higuchi, T		Mira, J; Sandoval, F		Zhao, QF; Higuchi, T			Individual evolutionary algorithm and its application to learning of nearest neighbor based MLP	FROM NATURAL TO ARTIFICIAL NEURAL COMPUTATION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Workshop on Artificial Neural Networks	JUN 07-09, 1995	MALAGA-TORREMOLINOS, SPAIN	EC, DG XII Human Capital & Mobil, Spanish CICYT, Spanish DGICYT, Junta Andalucia, Univ Malaga, UNED		evolutionary algorithm; genetic algorithm; individual evolutionary algorithm; multi-individual-multi-task problem; nearest neighbor based multilayer perceptron	PATTERN-CLASSIFICATION; DESIGN	A society S(I,T) is defined as a system consisting of an individual set I and a task set T. This paper studies the problem to find an efficient S such that all tasks in T can be fulfilled using the smallest I. The individual evolutionary algorithm (IEA) is proposed to solve this problem. By IEA, each individual finds and adapts itself to a class of tasks through evolution, and an efficient S can be obtained automatically. The EIA consists of four operations: competition, gain, less and retraining. Competition tests the performance of the recent I and the fitness of each individual; gain increases the performance of I by adding new individuals; loss makes I more compact by removing individuals with very low fitness, and individuals are adjusted by retraining to make them better. An evolution cycle is: competition boolean AND (gain boolean OR loss) boolean AND retraining, and the evolution is performed cycle after cycle until some criterion is satisfied. The performance of IEA is verified by applying it to the learning of nearest neighbor based multilayer perceptrons.		Zhao, QF (reprint author), TOHOKU UNIV,GRAD SCH INFORMAT SCI,SENDAI,MIYAGI 980,JAPAN.						BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kangas J A, 1990, IEEE Trans Neural Netw, V1, P93, DOI 10.1109/72.80208; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kosko B, 1990, IEEE Trans Neural Netw, V1, P44, DOI 10.1109/72.80204; KOSKO B, 1991, IEEE T NEURAL NETWOR, V2, P522, DOI 10.1109/72.134289; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; OKAMOTO Y, 1990, IEICE T J, V73, P1186; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; XIE QB, 1993, IEEE T PATTERN ANAL, V15, P1326; Yao X, 1993, Int J Neural Syst, V4, P203, DOI 10.1142/S0129065793000171; ZHAO QF, 1994, P INT C NEUR INF PRO, P1398; ZHAO QF, 1994, P INT C FUZZ LOG NEU, P77; ZHAO QF, 1994, P IEICE KAUR WORKSH, P121; ZHAO QF, 1993, NC9365 IEICE, P83	24	0	0	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY	0302-9743	3-540-59497-3	LECT NOTES COMPUT SC			1995	930						396	403				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BF02K	WOS:A1995BF02K00053	
S	Echanobe, J; deMendivil, JRG; Garitagoitia, JR		Mira, J; Sandoval, F		Echanobe, J; deMendivil, JRG; Garitagoitia, JR			A text recognition system based on a Neural Network and on a Deformed System	FROM NATURAL TO ARTIFICIAL NEURAL COMPUTATION	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Workshop on Artificial Neural Networks	JUN 07-09, 1995	MALAGA-TORREMOLINOS, SPAIN	EC, DG XII Human Capital & Mobil, Spanish CICYT, Spanish DGICYT, Junta Andalucia, Univ Malaga, UNED				This paper shows a text recognition system based on a Neural Network which is used as Isolated Character Classifier (ICC), and on a Deformed System that incorporates the contextual knowledge defined by a dictionary. The Neural Network provides for every input character a fuzzy character built up with the ouput unit values. The fuzzy characters are the inputs for the Deformed System which is defined as an automaton representing the dictionary and whose behaviour is fuzzily constrained by fuzzy inputs. Therefore the classification and contextual processes are computed together. Experimental results show good performance for the system.		Echanobe, J (reprint author), UNIV BASQUE COUNTRY,DEPT ELECT & ELECT,POB 644,E-48080 BILBAO,SPAIN.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; ECHANOVE J, 1994, INT C ART NEUR NETW; ELLIMAN DG, 1990, PATTERN RECOGN, V23, P337, DOI 10.1016/0031-3203(90)90021-C; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826; Hopcroft J.E., 1979, INTRO AUTOMATA THEOR; HULL JJ, 1983, IEEE T PATTERN ANAL, V5, P384; LANDAU GM, 1988, J COMPUT SYST SCI, V37, P63, DOI 10.1016/0022-0000(88)90045-1; NEGOITA CV, 1975, APPLICATIONS FUZZY S; REINA R, 1992, 2 INT C FUZZ LOG NEU; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184; SHINGHAL R, 1983, PATTERN RECOGN, V16, P184; VIDAL E, 1985, NATO ASI SERIES F, V16, P427	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN 33	HEIDELBERGER PLATZ 3, W-1000 BERLIN 33, GERMANY	0302-9743	3-540-59497-3	LECT NOTES COMPUT SC			1995	930						913	918				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BF02K	WOS:A1995BF02K00119	
J	LOWE, DG				LOWE, DG			SIMILARITY METRIC LEARNING FOR A VARIABLE-KERNEL CLASSIFIER	NEURAL COMPUTATION			English	Article								Nearest-neighbor interpolation algorithms have many useful properties for applications to learning, but they often exhibit poor generalization. In this paper, it is shown that much better generalization can be obtained by using a variable interpolation kernel in combination with conjugate gradient optimization of the similarity metric and kernel size. The resulting method is called variable-kernel similarity metric (VSM) learning. It has been tested on several standard classification data sets, and on these problems it shows better generalization than backpropagation and most other learning methods. The number of parameters that must be determined through optimization are orders of magnitude less than for backpropagation or radial basis function (RBF) networks, which may indicate that the method better captures the essential degrees of variation in learning. Other features of VSM learning are discussed that make it relevant to models for biological learning in the brain.		LOWE, DG (reprint author), UNIV BRITISH COLUMBIA,DEPT COMP SCI,VANCOUVER,BC V6T 1Z4,CANADA.						ATKESON CG, 1989, ANNU REV NEUROSCI, V12, P157, DOI 10.1146/annurev.neuro.12.1.157; ATKESON CG, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P958; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Broomhead D. S., 1988, Complex Systems, V2; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR NN, P1; Duda R., 1973, PATTERN CLASSIFICATI; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; NOSOFSKY RM, 1988, J EXP PSYCHOL LEARN, V15, P282; OMOHUNDRO SM, 1992, ADV NEUR IN, V4, P958; POGGIO T, 1990, AI1167 MIT ART INT L; Poggio T., 1989, AI1140 MIT ART INT L; ROBINSON AJ, 1989, THESIS CAMBRIDGE U E; Sejnowski T. J., 1987, Complex Systems, V1; Silverman B.W., 1986, DENSITY ESTIMATION S; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WETTSCHERECK D, 1992, ADV NEUR IN, V4, P1133; WOLPERT DH, 1990, NEURAL NETWORKS, V3, P445, DOI 10.1016/0893-6080(90)90027-I	24	101	103	MIT PRESS	CAMBRIDGE	55 HAYWARD ST JOURNALS DEPT, CAMBRIDGE, MA 02142	0899-7667		NEURAL COMPUT	Neural Comput.	JAN	1995	7	1					72	85		10.1162/neco.1995.7.1.72		14	Computer Science, Artificial Intelligence	Computer Science	QG833	WOS:A1995QG83300007	
J	ALPAYDIN, E; GURGEN, F				ALPAYDIN, E; GURGEN, F			COMPARISON OF KERNEL ESTIMATORS, PERCEPTRONS AND RADIAL-BASIS FUNCTIONS FOR OCR AND SPEECH CLASSIFICATION	NEURAL COMPUTING & APPLICATIONS			English	Article						KERNEL ESTIMATORS; PERCEPTRONS; BACKPROPAGATION; RADIAL-BASIS FUNCTIONS; OPTICAL CHARACTER RECOGNITION; SPEECH RECOGNITION	NEURAL NETWORKS; FEEDFORWARD NETWORKS; RECOGNITION; APPROXIMATION	We compare kernel estimators, single and multi-layered perceptrons and radial-basis functions for the problems of classification of handwritten digits and speech phonemes. By taking two different applications and employing many techniques, we report here a two-dimensional study whereby a domain-independent assessment of these learning methods can be possible. We consider a feed-forward network with one hidden layer. As examples of the local methods, we use kernel estimators like k-nearest neighbour (k-nn), Parzen windows, generalised k-nn, and Grow and Learn (Condensed Nearest Neighbour). We have also considered fuzzy k-nn due to its similarity. As distributed networks, we use linear perceptron, pairwise separating linear perceptron and multi-layer perceptrons with sigmoidal hidden units. We also tested the radial-basis function network, which is a combination of local and distributed networks. Four criteria are taken for comparison: correct classification of the test set; network size; learning time; and the operational complexity. We found that perceptrons, when the architecture is suitable, generalise better than local, memory-based kernel estimators, but require a longer training and more precise computation. Local networks are simple, learn very quickly and acceptably, but use more memory.		ALPAYDIN, E (reprint author), BOGAZICI UNIV,DEPT COMP ENGN,ISTANBUL 80815,TURKEY.		ALPAYDIN, ETHEM/E-6127-2013				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALPAYDIN E, 1990, THESIS EC POL FED LA; ALPAYDIN E, 1993, INT C NEURAL NETWORK, V1, P9; ALPAYDIN E, 1991, NETWORKS GROW WHEN T; ALPAYDIN E, 1993, NATO ASI SER, P194; BLUM EK, 1991, NEURAL NETWORKS, V4, P511, DOI 10.1016/0893-6080(91)90047-9; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1993, NEURAL NETWORKS, V6, P351, DOI 10.1016/0893-6080(93)90003-F; Duda R., 1973, PATTERN CLASSIFICATI; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8; Gallant S. I., 1993, NEURAL NETWORK LEARN; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GUYON I, 1989, IJCNN, V2, P127; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Kanerva P, 1988, SPARSE DISTRIBUTED M; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1988, SELF ORG ASS MEMORY; LECUN Y, 1990, NEURAL INFORMATION P, V2, P396; LEE S, 1990, Molecular and Cellular Neuroscience, V1, P168; Lee Y., 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; Lippmann R. P., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.1; MARTIN GL, 1990, ADV NEURAL INFORMATI, V2, P405; MATAN O, 1992, COMPUTER, V25, P59, DOI 10.1109/2.144441; MILLER WT, 1990, P IEEE, V78, P61; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Ng K., 1991, ADV NEURAL INFORMATI, V<IT>3</IT>, P970; Omohundro S. M., 1987, Complex Systems, V1; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SENIOR AW, 1992, CUEDFINFENGTR105 CAM; Silverman B.W., 1986, DENSITY ESTIMATION S; WAIBEL A, 1991, NEURAL NETWORKS CONC, V1, P54; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701	37	2	2	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0941-0643		NEURAL COMPUT APPL	Neural Comput. Appl.		1995	3	1					38	49		10.1007/BF01414175		12	Computer Science, Artificial Intelligence	Computer Science	RK324	WOS:A1995RK32400005	
J	BASSOE, CF				BASSOE, CF			AUTOMATED DIAGNOSES FROM CLINICAL NARRATIVES - A MEDICAL SYSTEM BASED ON COMPUTERIZED MEDICAL RECORDS, NATURAL-LANGUAGE PROCESSING, AND NEURAL-NETWORK TECHNOLOGY	NEURAL NETWORKS			English	Article						COMPUTERIZED MEDICAL RECORD; EXPERT SYSTEM; NEURAL NETWORK; NATURAL LANGUAGE PROCESSING; KNOWLEDGE ACQUISITION; SUPERVISED LEARNING		A collection of artificial, associative neural networks (PROMNET) interfaced to a computerized medical record is described Clinical narratives were subject to automated natural language processing, and relations were established between 14,323 diagnoses and 31,381 patient findings. Patient diagnoses and findings were counted, grouped into clinical entities, and used to train PROMNET. Training was completed in a few minutes. PROMNET's dictionary contained about 20,000 words, and the neural network recognized more than 2800 disorders. Its performance was evaluated by an automated double-blind Turing test. PROMNET made clinical decisions in a few seconds with sensitivity of 96.6%, and specificity of 95.7%. The most pertinent clinical entity was usually ranked highest. PROMNET is a powerful inference engine that learns from clinical narratives and interacts with medical personnel or patients in natural language.								ANDERSON JA, 1988, NEUROCOMPUTING, V1; Anderson JA, 1990, NEUROCOMPUTING; BASSOE CF, 1985, UTPOSTEN, V14, P10; BASSOE CF, 1988, MED INFORMATICS EURO, P195; BASSOE CF, 1989, ADV RES CLIN APPL, P95; BAXT WG, 1991, ANN INTERN MED, V115, P843; BRODAL A, 1981, NEUROLOGICAL ANATOMY, P605; CHENEY W, 1985, NUMERICAL MATH COMPU, P335; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FURLONG JW, 1991, AM J CLIN PATHOL, V96, P134; GORRY GA, 1968, COMPUT BIOMED RES, V1, P490, DOI 10.1016/0010-4809(68)90016-5; HAMMOND N, 1988, MED INFORMATICS EURO, P620; HARPER PS, 1981, PRACTICAL GENETIC CO; MANBER U, 1989, INTRO ALGORITHMS, P160; MCCLELLAND JL, 1988, PARALLEL DISTRIBUTED, V2; Mehra P., 1992, ARTIFICIAL NEURAL NE; Minsky M., 1988, PERCEPTRONS; RASMUSSEN JENG, 1993, METHOD INFORM MED, V32, P66; Rumelhart DE, 1988, PARALLEL DISTRIBUTED; SCHNEIDER W, 1987, BEHAV RES METH INSTR, V19, P73, DOI 10.3758/BF03203762; SCHOOLMAN HM, 1978, SCIENCE, V200, P926, DOI 10.1126/science.347580; STONE GO, 1988, PARALLEL DISTRIBUTED, V1, P444; WEISS S, 1989, 11TH IJCAI 89 INT JO, P781; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; WYATT J, 1991, LANCET, V338, P1431	25	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080		NEURAL NETWORKS	Neural Netw.		1995	8	2					313	319		10.1016/0893-6080(94)00076-X		7	Computer Science, Artificial Intelligence	Computer Science	QN844	WOS:A1995QN84400012	
J	HUANG, YS; LIU, K; SUEN, CY				HUANG, YS; LIU, K; SUEN, CY			A NEW METHOD OF OPTIMIZING PROTOTYPES FOR NEAREST-NEIGHBOR CLASSIFIERS USING A MULTILAYER NETWORK	PATTERN RECOGNITION LETTERS			English	Article						NEAREST NEIGHBOR CLASSIFIER; PROTOTYPE OPTIMIZATION; MULTILAYER NETWORK; K-MEANS CLUSTERING; BACKPROPAGATION ERROR CORRECTION		This paper proposes a new method of optimizing the prototypes for a nearest neighbor classifier which uses a network with a hidden layer. After training, the neural network is mapped back to a nearest neighbor classifier with optimized prototypes. The main characteristic of the present method is that both the trained neural network and the mapped nearest classifier have the same recognition performance. Experimental results show that this method outperforms the method recently proposed by Yan (1994).	IND TECHNOL RES INST,COMP & COMMUN RES LABS,DEPT APPLICAT SOFTWARE,HSINCHU 310,TAIWAN; NANJING UNIV SCI & TECHNOL,DEPT COMP SCI,NANJING 210014,PEOPLES R CHINA	HUANG, YS (reprint author), CONCORDIA UNIV,CTR PATTERN RECOGNIT & MED INTELLIGENCE,SUITE GM-606,1455 MAISONNEUVE BLVD W,MONTREAL,PQ H3G 1M8,CANADA.						CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1990, P IEEE, V78, P1468; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; YAN H, 1994, PATTERN RECOGN LETT, V15, P207, DOI 10.1016/0167-8655(94)90050-7; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	11	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN	1995	16	1					77	82		10.1016/0167-8655(94)00070-J		6	Computer Science, Artificial Intelligence	Computer Science	QE080	WOS:A1995QE08000010	
J	MAZROUA, AA; BARTNIKAS, R; SALAMA, MMA				MAZROUA, AA; BARTNIKAS, R; SALAMA, MMA			DISCRIMINATION BETWEEN PD PULSE SHAPES USING DIFFERENT NEURAL-NETWORK PARADIGMS	IEEE TRANSACTIONS ON DIELECTRICS AND ELECTRICAL INSULATION			English	Article							PARTIAL DISCHARGE; RECOGNITION	A comparison has been carried out on the partial discharge (PD) pulse shape recognition capabilities of neural networks, using the nearest neighbor classifier, learning vector quantization and multilayer perceptron paradigms. The PD pattern recognition capabilities were assessed on artificial cylindrical cavities of different sizes. The performance of the three neural network paradigms was found to be equivalent in all respects, with the exception of the case where a distinction was required between small cavity sizes; under those circumstances, the learning vector quantization paradigm was distinctly superior to the two other paradigms. The experimental results also demonstrated that, even with simple metallic electrode cavities, the discrimination capabilities of the three types of neural networks are not always perfect.	INST RECH HYDRO QUEBEC,VARENNES,PQ,CANADA	MAZROUA, AA (reprint author), UNIV WATERLOO,DEPT ELECT & COMP ENGN,WATERLOO,ON,CANADA.						AMIRA A, 1993, IEEE T ELECTRICAL IN, V28, P1082; AMIRA A, 1994, IN PRESS IEEE T POWE; BARTNIKAS R, 1993, IEEE T ELECTR INSUL, V28, P956, DOI 10.1109/14.249369; BARTNIKAS R, 1969, ARCH ELEKTROTECH, V7, P348; BARTNIKA.R, 1972, IEEE T ELECTR INSUL, VEI 7, P3, DOI 10.1109/TEI.1972.299182; BARTNIKA.R, 1969, J APPL PHYS, V40, P1974, DOI 10.1063/1.1657880; BEALE R, 1985, NEURAL COMPUTING INT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; GISH H, 1990, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.1990.115636; GULSKI E, 1993, IEEE T ELECTR INSUL, V28, P984, DOI 10.1109/14.249372; HOZUMI N, 1992, IEEE T ELECTR INSUL, V27, P550, DOI 10.1109/14.142718; HUDON C, 1993, IEEE T ELECTR INSUL, V28, P1, DOI 10.1109/14.192234; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; Kohonen T., 1988, SELF ORG ASS MEMORY; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KRANS HG, 1989, 6TH INT S HV ENG NEW; KRANZ HG, 1992, IEEE T ELECTR INSUL, V27, P93, DOI 10.1109/14.123444; KRANZ HG, 1993, IEEE T ELECTR INSUL, V28, P1016, DOI 10.1109/14.249375; Kung S. Y., 1993, DIGITAL NEURAL NETWO; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; SCHNETTLER A, 1993, ARCH ELEKTROTECH, V76, P149, DOI 10.1007/BF01597593; Simpson PK, 1990, ARTIFICIAL NEURAL SY; SUZUKI H, 1992, IEEE T ELECTR INSUL, V27, P543, DOI 10.1109/14.142717; VANBRUNT RJ, 1992, IEEE T ELECTRICAL IN, V28, P905	25	39	46	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1070-9878		IEEE T DIELECT EL IN	IEEE Trns. Dielectr. Electr. Insul.	DEC	1994	1	6					1119	1131		10.1109/94.368651		13	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	QC349	WOS:A1994QC34900019	
J	HARDIN, PJ				HARDIN, PJ			PARAMETRIC AND NEAREST-NEIGHBOR METHODS FOR HYBRID CLASSIFICATION - A COMPARISON OF PIXEL ASSIGNMENT ACCURACY	PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			English	Article								Nearest-neighbor classifiers have not been widely used for pixel assignment, probably because their computational requirements make them too slow for practical application to large images. Regardless, when properly specified, the nearest-neighbor classifier is a Bayesian classifier, and does not require conditions of multivariate normality as a prerequisite for optimum pixel assignment. In this study, six nearest-neighbor classifiers and four parametric classifiers are applied to six Landsat images embracing a broad variety of land cover. The accuracy of the parametric- and neighbor-based methods is compared for significant differences in the assignment of pixels to spectral-classes, In a majority of hybrid experiments, classifiers predicated on spectral neighborhoods were significantly superior to parametric classifiers for pixel assignment when training sample proportions matched the true population proportions. In experiments where this condition was violated, there was no clear advantage to choosing a neighbor-based classifier in preference to a linear discriminant function employing prior probabilities.		HARDIN, PJ (reprint author), BRIGHAM YOUNG UNIV,DEPT GEOG,690 SWKT,PROVO,UT 84602, USA.						Campbell J. B., 1987, INTRO REMOTE SENSING; CONGALTON RG, 1983, PHOTOGRAMM ENG REM S, V49, P1671; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1951, USAF4 SCH AV MED REP; HARDIN PJ, 1992, PROF GEOGR, V44, P191, DOI 10.1111/j.0033-0124.1992.00191.x; INCE F, 1987, INT J REMOTE SENS, V8, P1829; James M., 1985, CLASSIFICATION ALGOR; Jensen J.R., 1986, INTRO DIGITAL IMAGE; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; NORUSIS MJ, 1988, SPSS PC PLUS ADV STA; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; SKIDMORE AK, 1989, PHOTOGRAMM ENG REM S, V55, P1449; SWAIN PH, 1978, REMOTE QUANTITATIVE, pCH3	15	28	30	AMER SOC PHOTOGRAMMETRY	BETHESDA	5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160	0099-1112		PHOTOGRAMM ENG REM S	Photogramm. Eng. Remote Sens.	DEC	1994	60	12					1439	1448				10	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	PY045	WOS:A1994PY04500004	
J	LIN, JH; VITTER, JS				LIN, JH; VITTER, JS			A THEORY FOR MEMORY-BASED LEARNING	MACHINE LEARNING			English	Article						MEMORY-BASED LEARNING; PAC LEARNING; CLUSTERING; APPROXIMATION; LINEAR PROGRAMMING; RELAXATION; COVERING; HASHING	ROBOTIC MANIPULATORS; ALGORITHM	A memory-based learning system is an extended memory management system that decomposes the input space either statistically or dynamically into subregions for the purpose of storing and retrieving functional information. The main generalization techniques employed by memory-based learning systems are the nearest-neighbor search, space decomposition techniques, and clustering. Research on memory-based learning is still in its early stage. In particular, there are very few rigorous theoretical results regarding memory requirement, sample size, expected performance, and computational complexity. In this paper, we propose a model for memory-based learning and use it to analyze several methods-is-an-element-of-covering, hashing, clustering, tree-structured clustering, and receptive-fields-for learning smooth functions. The sample size and system complexity are derived for each method. Our model is built upon the generalized PAC learning model of Haussler (Haussler, 1989) and is closely related to the method of vector quantization in data compression. Our main result is that we can build memory-based learning systems using new clustering algorithms (Lin & Vitter, 1992a) to PAC-learn in polynomial time using only polynomial storage in typical situations.	DUKE UNIV, DEPT COMP SCI, DURHAM, NC 27708 USA	LIN, JH (reprint author), MOTOROLA INC, APPL RES COMMUN LAB, PAGING PROD GRP, BOYNTON BEACH, FL 33426 USA.						Albus J., 1975, J DYNAMIC SYSTEMS ME, V97, P220; ALBUS JS, 1975, J DYNAMIC SYSTEMS ME, P228; ALBUS JS, 1981, BRAINS BEHAVIOR ROBO; Carter L., 1979, J CSS, V18, P143; Chvatal V., 1979, Mathematics of Operations Research, V4, DOI 10.1287/moor.4.3.233; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANTZIG GB, 1951, ACTIVITY ANAL PRODUC, P19; Dean T. L., 1991, PLANNING CONTROL; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; Duda R., 1973, PATTERN CLASSIFICATI; DUDLEY RM, 1984, LECTURE NOTES MATH, V1097; DUDLEY RM, 1978, ANN PROBAB, V6, P899, DOI 10.1214/aop/1176995384; FRIEDMAN JH, 1988, 102 STANDF U LAB COM; Garey M.R., 1979, COMPUTERS INTRACTABI; GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457; Gersho A, 1991, VECTOR QUANTIZATION; Gray Robert M., 1984, IEEE ASSP MAG    APR, P4; HAUSSLER D, 1991, INFORM COMPUT, V95, P129, DOI 10.1016/0890-5401(91)90042-Z; HAUSSLER D, 1990, UCSCCRL9015 DEP COMP; HAUSSLER D, 1989, ANN IEEE SYMP FOUND, P40, DOI 10.1109/SFCS.1989.63453; JOHNSON DS, 1974, J COMPUT SYST SCI, V9, P256; KARIV O, 1979, SIAM J APPL MATH, V37, P539, DOI 10.1137/0137041; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; Khachiyan L. G., 1979, SOV MATH DOKL, V20, P191; Lin J.H., 1992, 24TH P ANN ACM S THE, P771; LIN JH, 1992, P IEEE DATA COMPRESS, P22; LOVASZ L, 1975, DISCRETE MATH, V13, P383, DOI 10.1016/0012-365X(75)90058-8; MEGIDDO N, 1984, SIAM J COMPUT, V13, P182, DOI 10.1137/0213014; MILLER WT, 1987, INT J ROBOT RES, V6, P84, DOI 10.1177/027836498700600207; MILLER WT, 1987, IEEE T ROBOTIC AUTOM, V3, P157; MOODY J, 1988, 1988 P CONN MOD SUMM, P133; Moody J., 1989, ADV NEURAL INFORMATI, V1, P29; MOORE AW, 1989, UNPUB ACQUISITION DY; PAPADIMITRIOU CH, 1981, SIAM J COMPUT, V10, P542, DOI 10.1137/0210040; POGGIO T, 1990, MIT1167 ART INT LAB; POGGIO T, 1989, MIT1140 ART INT LAB; Pollard D., 1990, NSF CBMS REGIONAL C, V2; Pollard D., 1984, CONVERGENCE STOCHAST; RAMAKRISHNA MV, 1991, UNPUB SURVEY PERFECT; RISKIN EA, 1990, THESIS STANFORD U; Sauer N., 1972, Journal of Combinatorial Theory, Series A, V13, DOI 10.1016/0097-3165(72)90019-2; SIEGEL A, 1991, UNPUB COALESCED HASH; Vapnik V., 1982, ESTIMATION DEPENDENC; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VITTER JS, 1987, DESIGN ANAL COALESCE; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	46	5	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	NOV-DEC	1994	17	2-3					143	167		10.1007/BF00993469		25	Computer Science, Artificial Intelligence	Computer Science	PW046	WOS:A1994PW04600003	
J	GURGEN, F; ALPAYDIN, R; UNLUAKIN, U; ALPAYDIN, E				GURGEN, F; ALPAYDIN, R; UNLUAKIN, U; ALPAYDIN, E			DISTRIBUTED AND LOCAL NEURAL CLASSIFIERS FOR PHONEME RECOGNITION	PATTERN RECOGNITION LETTERS			English	Article						SPEECH RECOGNITION; ARTIFICIAL NEURAL NETWORKS; DISTRIBUTED NEURAL NETWORK; BACKPROPAGATION; LOCAL NETWORKS; K-NEAREST NEIGHBOR RULE; GROW AND LEARN METHOD; LEARNING VECTOR QUANTIZATION	NETWORKS	The comparative performances of distributed and local neural networks for the speech recognition problem are investigated. We consider a feed-forward network with one or more hidden layers. Depending on the response characteristics of the hidden units, we name the network distributed or local. If the hidden units use the sigmoid non-linearity, then hidden units have a global response and we call such networks distributed. If each hidden unit responds only to inputs in a certain local region in the input space, then the network is local. Neighbor and prototype based approaches are of this type. As examples of the distributed approach with sigmoidal units, we employ the back-propagation rule with three error measures: mean square error, cross entropy, and combinational performance. As for the local methods, we use k-nearest neighbor, learning Vector quantization, grow and learn, and Gaussian-based weighted approximation methods. Phoneme recognition experiments are conducted using the /b, d, g, m, n, N/ set of the Japanese vocabulary for the speaker dependent case. Three criteria are taken for comparison: correct classification of the test set, network size, and learning time. We found that distributed networks generalize better than local networks but require longer training and more precise computation. Local networks learn very quickly, but do not generalize well and use more memory.		GURGEN, F (reprint author), BOGAZICI UNIV,DEPT COMP ENGN,ISTANBUL 80815,TURKEY.		ALPAYDIN, ETHEM/E-6127-2013				ALPAYDIN E, 1991, 91032 INT COMP SCI I; ALPAYDIN E, 1993, NATO ARW SERIES; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Furui S., 1989, DIGITAL SPEECH PROCE; GURGEN FS, 1991, 1991 IEEE INT JOINT, P572; GURGEN FS, 1992, JUN IEEE INT JOINT C; HAFFNER P, 1988, 10058 ATR INT TEL RE, P11; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hertz J., 1991, INTRO THEORY NEURAL; HOLT MJJ, 1990, ELECTRON LETT, V26, P1964, DOI 10.1049/el:19901270; KARAYIANNIS NB, 1992, IEEE T CIRCUITS-II, V39, P453, DOI 10.1109/82.160170; KOHONEN T, 1988, P IEEE INT C NEURAL, P61; Kohonen T., 1984, SELF ORG ASS MEMORY; Lippmann R. P., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.1; Omohundro S. M., 1987, Complex Systems, V1; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701	20	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV	1994	15	11					1111	1118		10.1016/0167-8655(94)90126-0		8	Computer Science, Artificial Intelligence	Computer Science	PQ224	WOS:A1994PQ22400006	
J	TURNEY, P				TURNEY, P			THEORETICAL ANALYSES OF CROSS-VALIDATION ERROR AND VOTING IN INSTANCE-BASED LEARNING	JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE			English	Article						CROSS-VALIDATION; SIMPLICITY; BIAS; VARIANCE; VOTING; INSTANCE-BASED LEARNING		This paper begins with a general theory of error in cross-validation testing of algorithms for supervised learning from examples. It is assumed that the examples are described by attribute-value pairs, where the values are symbolic. Cross-validation requires a set of training examples and a set of testing examples. The value of the attribute that is to be predicted is known to the learner in the training set, but unknown in the testing set. The theory demonstrates that cross-validation error has two components: error on the training set (inaccuracy) and sensitivity to noise (instability). This general theory is then applied to voting in instance-based learning. Given an example in the testing set, a typical instance-based learning algorithm predicts the designated attribute by voting among the k nearest neighbours (the k most similar examples) to the testing example in the training set. Voting is intended to increase the stability (resistance to noise) of instance-based learning, but a theoretical analysis shows that there are circumstances in which voting can be destabilising. The theory suggests ways to minimize cross-validation error, by insuring that voting is stable and does not adversely affect accuracy.		TURNEY, P (reprint author), NATL RES COUNCIL CANADA,INST INFORMAT TECHNOL,KNOWLEDGE SYST LAB,OTTAWA K1A 0R6,ON,CANADA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; FIX E, 1991, USAF4 SCH AV MED REP, P261; FRASER DAS, 1976, PROBABILITY STATISTI; Kibler D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00315.x; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; LANGLEY P, 1993, 13TH P INT JOINT C A; SAKAMOTO Y, 1986, AKAIKE INFORMATION C; TOMEK I, 1991, IEEE T SYST MAN CYB, V6, P121; TURNEY P, 1994, J EXP THEOR ARTIF IN, V6, P361, DOI 10.1080/09528139408953794; TURNEY P, 1990, BRIT J PHILOS SCI, V41, P509, DOI 10.1093/bjps/41.4.509	12	2	2	TAYLOR & FRANCIS LTD	LONDON	ONE GUNDPOWDER SQUARE, LONDON, ENGLAND EC4A 3DE	0952-813X		J EXP THEOR ARTIF IN	J. Exp. Theor. Artif. Intell.	OCT-DEC	1994	6	4					331	360		10.1080/09528139408953793		30	Computer Science, Artificial Intelligence	Computer Science	PT794	WOS:A1994PT79400002	
J	TODD, BS; STAMPER, R				TODD, BS; STAMPER, R			THE RELATIVE ACCURACY OF A VARIETY OF MEDICAL DIAGNOSTIC PROGRAMS	METHODS OF INFORMATION IN MEDICINE			English	Article						COMPUTER-AIDED DIAGNOSIS; NEAREST NEIGHBORS; ABDOMINAL PAIN	COMPUTER-AIDED DIAGNOSIS; ACUTE ABDOMINAL-PAIN; DECISION-SUPPORT SYSTEMS; CORONARY-ARTERY DISEASE; NEURAL NETWORK; BAYES THEOREM; ACUTE ABDOMEN; ASSUMING INDEPENDENCE; ASSISTED DIAGNOSIS; EXPERT SYSTEMS	Acute abdominal pain is one of the most widely studied applications of computer-aided diagnosis. The usual approach is to apply Bayes' theorem with the assumption of conditional independence (''independence Bayes''). We compared various approaches to designing diagnostic programs for abdominal pain of suspected gynaecological origin. The methods range from statistical to knowledge-based. All programs were evaluated using a database of 1,270 cases collected retrospectively. Our results suggest that in this application no significant improvement in accuracy can be made by taking interactions into account, either by statistical or by knowledge-based means; independence Bayes is near-optimal. As far as accuracy is concerned, there appears to be little point in pursuing knowledge-based approaches. However, the ''nearest neighbours'' method using a new metric appears to be at least as accurate as independence Bayes. We argue that the nearest neighbours method is more suitable than independence Bayes for clinical use because of greater accountability.		TODD, BS (reprint author), UNIV OXFORD,COMP LAB,PROGRAMMING RES GRP,WOLFSON BLDG,OXFORD OX1 3QD,ENGLAND.						ADAMS ID, 1986, BRIT MED J, V293, P800; AKAY M, 1992, BIOL CYBERN, V67, P361, DOI 10.1007/BF02414891; Anderson J.A., 1982, HDB STATISTICS, P169, DOI 10.1016/S0169-7161(82)02010-0; BAXT WG, 1991, ANN INTERN MED, V115, P843; BOUNDS DG, 1990, NEURAL NETWORKS, V3, P583, DOI 10.1016/0893-6080(90)90008-9; Breiman L, 1984, CLASSIFICATION REGRE; CESTNIK B, 1990, 9 EUR C ART INT ECAI, P147; CHAMBERLAIN G, 1984, CONT GYNAECOLOGY; CHARD T, 1989, INT J BIOMED COMPUT, V24, P133, DOI 10.1016/0020-7101(89)90016-0; CLARK LA, 1992, STATISTICAL MODELS S; COOPER GF, 1986, COMPUT METH PROG BIO, V22, P223; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRICHTON NJ, 1987, STAT MED, V6, P945, DOI 10.1002/sim.4780060809; CRICHTON NJ, 1989, STAT MED, V8, P1351, DOI 10.1002/sim.4780081107; CROFT D, 1987, ANN BIOMED ENG, V2, P69; DAN Q, 1992, ARTIF INTELL MED, V4, P21, DOI 10.1016/0933-3657(92)90035-N; DEDOMBAL FT, 1991, ANN CHIR, V45, P273; DEDOMBAL FT, 1972, BRIT MED J, V2, P9; DEDOMBAL FT, 1989, INT J BIOMED COMPUT, V24, P9, DOI 10.1016/0020-7101(89)90003-2; DEDOMBAL FT, 1992, THEOR SURG, V7, P111; Dickson J A, 1988, Scand J Gastroenterol Suppl, V144, P43; DIXON JM, 1991, BRIT MED J, V302, P386; Duda R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; EBEHART RC, 1991, 4TH P ANN IEEE S COM, P298; EDWARDS FH, 1984, SURG GYNECOL OBSTET, V158, P219; Emparanza J. I., 1988, Expert Systems and Decision Support in Medicine. 33rd Annual Meeting of the GMDS EFMI Special Topic Meeting. Peter L. Reichertz Memorial Conference; FOX J, 1980, METHOD INFORM MED, V19, P210; FRANKLIN RCG, 1991, BRIT MED J, V302, P935; FRYBACK DG, 1978, COMPUT BIOMED RES, V11, P423, DOI 10.1016/0010-4809(78)90001-0; GAMMERMAN A, 1991, METHOD INFORM MED, V30, P15; GUNN AA, 1991, BAILLIERE CLIN GASTR, V5, P639, DOI 10.1016/0950-3528(91)90046-4; GUPPY KH, 1989, MED DECIS MAKING, V9, P181, DOI 10.1177/0272989X8900900306; Harris N., 1990, Fourteenth Annual Symposium on Computer Applications in Medical Care. Standards in Medical Informatics. A Conference of the American Medical Informatics Association; HART A, 1989, 2ND P EUR C ART INT, P115; HECKERMAN DE, 1988, UNCERTAINTY ARTIFICI, V2, P23; HECKERMAN DE, 1992, COMPUT BIOMED RES, V25, P56, DOI 10.1016/0010-4809(92)90035-9; HECKERMAN DE, 1992, METHOD INFORM MED, V31, P90; HILDEN J, 1984, COMPUT BIOL MED, V14, P429, DOI 10.1016/0010-4825(84)90043-X; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; MACARTNEY FJ, 1987, BRIT MED J, V295, P1325; MACLIN P S, 1991, Journal of Medical Systems, V15, P11, DOI 10.1007/BF00993877; Mosteller F, 1952, BIOMETRICS, V8, P220, DOI 10.2307/3001552; Neapolitan R. E., 1989, PROBABILISTIC REASON; NORDYKE RA, 1971, COMPUT BIOMED RES, V4, P374, DOI 10.1016/0010-4809(71)90022-X; NORUSIS MJ, 1975, COMPUT BIOMED RES, V8, P173, DOI 10.1016/0010-4809(75)90037-3; NORUSIS MJ, 1975, COMPUT BIOMED RES, V8, P156, DOI 10.1016/0010-4809(75)90036-1; OHMANN C, 1986, STAT MED, V5, P503, DOI 10.1002/sim.4780050515; ORIENT JM, 1986, SOUTHERN MED J, V79, P793; PATERSONBROWN S, 1989, BRIT J SURG, V76, P1011, DOI 10.1002/bjs.1800761007; PATERSONBROWN S, 1991, BRIT MED J, V303, P1115; PAUERSTEIN CJ, 1982, GYNECOLOGICAL DISORD; PHILLIPS S, 1991, 2ND P AUSTR C NEUR N, P283; REGGIA JA, 1985, COMPUT BIOL MED, V15, P161, DOI 10.1016/0010-4825(85)90057-5; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; RUSSEK E, 1983, COMPUT BIOMED RES, V16, P537, DOI 10.1016/0010-4809(83)90040-X; SALZBERG S, 1991, LECT NOTES ARTIF INT, V542, P399; SEROUSSI B, 1986, METHOD INFORM MED, V25, P194; SEROUSSI B, 1985, LECTURE NOTES MED IN, V28, P12; Shortliffe E. H., 1976, COMPUTER BASED MED C; SHORTLIFFE EH, 1979, P IEEE, V67, P1207, DOI 10.1109/PROC.1979.11436; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737; STAMPER R, 1992, 4TH P INT C SOFTW EN, P341; STAMPER T, 1994, METHOD INFORM MED, V33, P205; STONEBRIDGE PA, 1992, ARCH EMERG MED, V9, P271; SUTTON GC, 1989, BRIT J SURG, V76, P82, DOI 10.1002/bjs.1800760126; TEACH RL, 1981, COMPUT BIOMED RES, V14, P542, DOI 10.1016/0010-4809(81)90012-4; TELFER S, 1988, SCAND J GASTROENTERO, V23, P47; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; TODD BS, 1993, MED INFORM, V18, P255; TODD BS, 1993, INT J BIOMED COMPUT, V33, P129, DOI 10.1016/0020-7101(93)90030-A; TODD BS, 1993, TECHNICAL MONOGR PRG, V109; TODD BS, 1994, COMPUT METH PROG BIO, V42, P77, DOI 10.1016/0169-2607(94)90044-2; TODESCHINI R, 1989, CHEMOMETR INTELL LAB, V6, P213, DOI 10.1016/0169-7439(89)80086-3; WELLWOOD J, 1992, ANN ROY COLL SURG, V74, P40; WELLWOOD JM, 1989, BRIT J HOSP MED, V41, P564; WHITFIELD CR, 1986, DEWHURSTS TXB OBSTET; WONG WSF, 1990, INT J BIOMED COMPUT, V25, P223; YOUNG D, 1990, BRIT J HEALTHC COMP, V7, P16	78	11	11	F K SCHATTAUER VERLAG GMBH	STUTTGART	P O BOX 10 45 45, LENZHALDE 3, D-70040 STUTTGART, GERMANY	0026-1270		METHOD INFORM MED	Methods Inf. Med.	OCT	1994	33	4					402	416				15	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	PN899	WOS:A1994PN89900012	
J	DEVROYE, L; GYORFI, L; KRZYZAK, A; LUGOSI, G				DEVROYE, L; GYORFI, L; KRZYZAK, A; LUGOSI, G			ON THE STRONG UNIVERSAL CONSISTENCY OF NEAREST-NEIGHBOR REGRESSION FUNCTION ESTIMATES	ANNALS OF STATISTICS			English	Article						REGRESSION FUNCTION; NONPARAMETRIC ESTIMATION; CONSISTENCY; STRONG CONVERGENCE; NEAREST NEIGHBOR ESTIMATE	NONPARAMETRIC REGRESSION; CONVERGENCE; DENSITY; CLASSIFICATION; EQUIVALENCE; WEAK; L1	Two results are presented concerning the consistency of the k-nearest neighbor regression estimate. We show that all modes of convergence in L(1) (in probability, almost sure, complete) are equivalent if the regression variable is bounded. Under the additional condition k/log n --> infinity we also obtain the strong universal consistency of the estimate.	CONCORDIA UNIV,DEPT COMP SCI,MONTREAL,PQ H3G 1M8,CANADA; TECH UNIV BUDAPEST,DEPT MATH,H-1521 BUDAPEST,HUNGARY	DEVROYE, L (reprint author), MCGILL UNIV,SCH COMP SCI,MONTREAL,PQ H3A 2A7,CANADA.						AZUMA K, 1967, TOHOKU MATH J, V37, P357; Beck J., 1979, Problems of Control and Information Theory, V8; BHATTACHARYA PK, 1987, ANN STAT, V15, P976, DOI 10.1214/aos/1176350487; CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330; COLLOMB G, 1981, INT STAT REV, V49, P75, DOI 10.2307/1403039; COLLOMB G, 1985, STATISTICS, V16, P300; Collomb G., 1980, LECT NOTES MATH, V821, P159; COLLOMB G, 1979, CR ACAD SCI A MATH, V289, P245; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; DEVROYE L, 1978, 1978 P IEEE COMP SOC, P142; DEVROYE L, 1983, 4TH P PANN S MATH ST, P67; DEVROYE L, 1989, J STAT PLAN INFER, V23, P71, DOI 10.1016/0378-3758(89)90040-2; DEVROYE L, 1991, NONPARAMETRIC FUNCTI, P31; DEVROYE L, 1982, Z WAHRSCHEINLICHKEIT, V61, P467, DOI 10.1007/BF00531618; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1988, PROBAB THEORY REL, V77, P521, DOI 10.1007/BF00959615; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; Devroye L.P., 1985, NONPARAMETRIC DENSIT; Glick N., 1974, UTILITAS MATHEMATICA, V6, P61; GREBLICKI W, 1984, ANN STAT, V12, P1570, DOI 10.1214/aos/1176346815; Gyorfi L., 1981, Problems of Control and Information Theory, V10; GYORFI L, 1991, NONPARAMETRIC FUNCTI, P329; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; KRZYZAK A, 1986, IEEE T INFORM THEORY, V32, P668, DOI 10.1109/TIT.1986.1057226; KRZYZAK A, 1984, IEEE T INFORM THEORY, V30, P78, DOI 10.1109/TIT.1984.1056842; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; MCDIARMID C, 1989, LOND MATH S, V141, P148; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; NADARAYA EA, 1970, THEOR PROBAB APPL+, V15, P134, DOI 10.1137/1115015; ROYALL RM, 1966, THESIS STANFORD U; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Stout W.F., 1974, ALMOST SURE CONVERGE; STUTE W, 1984, ANN STAT, V12, P917, DOI 10.1214/aos/1176346711; Watson G.S., 1964, SANKHYA A, V26, P359; Wheeden R. L., 1977, MEASURE INTEGRAL; ZHAO LC, 1987, J MULTIVARIATE ANAL, V21, P168, DOI 10.1016/0047-259X(87)90105-9	40	57	57	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 6 3401 INVESTMENT BLVD, HAYWARD, CA 94545	0090-5364		ANN STAT	Ann. Stat.	SEP	1994	22	3					1371	1385		10.1214/aos/1176325633		15	Statistics & Probability	Mathematics	QJ599	WOS:A1994QJ59900014	
J	SMITH, SJ; BOURGOIN, MO; SIMS, K; VOORHEES, HL				SMITH, SJ; BOURGOIN, MO; SIMS, K; VOORHEES, HL			HANDWRITTEN CHARACTER CLASSIFICATION USING NEAREST-NEIGHBOR IN LARGE DATABASES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							DISTANCE	We show that systems built on a simple statistical technique and a large training database can be automatically optimized to produce classification accuracies of 99% in the domain of handwritten digits. It is also shown that the performance of these systems scale consistently with the size of the training database, where the error rate is cut by more than half for every tenfold increase in the size of the training set from 10 to 100,000 examples. Three distance metrics for the standard Nearest Neighbor classification system are investigated: a simple Hamming distance metric, a pixel distance metric, and a metric based on the extraction of penstroke features. Systems employing these metrics were trained and tested on a standard, publicly available, database of nearly 225,000 digits provided by the National Institute of Standards and Technology. Additionally, a confidence metric is both introduced by the authors and also discovered and optimized by the system. The new confidence measure proves to be superior to the commonly used Nearest Neighbor distance.	TASC,READING,MA 01867	SMITH, SJ (reprint author), THINKING MACHINES CORP,245 1ST ST,CAMBRIDGE,MA 02142, USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AHMED P, 1987, INT J PATTERN RECOGN; ATKESON C, 1986, MIT942 AI LAB TECH R; BORGEFORS G, 1990, SIGNAL PROCESS, V21, P61, DOI 10.1016/0165-1684(90)90027-V; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708; CHURCH K, 1986, UNPUB STOCHASTIC PAR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DASRATHY B, 1990, NEAREST NEIGHBOR PAT; Garris M.D., NIST SPECIAL DATABAS; HINTON G, 1992, ADV NEURAL INFORMATI, V4; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274; KELLY J, 1991, 4TH P INT C GEN ALG; KELLY J, 1991, 12TH P INT JOINT C A; MASAND B, 1993, APR AIAA SPR S CAS B; Pavlidis T, 1982, ALGORITHMS GRAPHICS; ROSENFEL.A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; SMITH S, 1992, SUPERCOMPUTING S 92, P377; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; WILKINDON RA, 1992, NISTIR4912 NAT I STA	22	30	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					915	919		10.1109/34.310689		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	PE802	WOS:A1994PE80200009	
J	TOUSSAINT, GT				TOUSSAINT, GT			A COUNTEREXAMPLE TO TOMEK CONSISTENCY THEOREM FOR A CONDENSED NEAREST-NEIGHBOR DECISION RULE	PATTERN RECOGNITION LETTERS			English	Article							GRAPHS	The condensed nearest neighbor rule (CNN) was proposed by Hart (1968) as a method to reduce the storage requirements of the original data set D for the efficient implementation of the nearest neighbor decision rule in pattern classification problems. Tomek (1976a) suggested two modifications of CNN in order to improve its performance. As a first step in Tomek's second method he computes a subset C of D, for subsequent use in CNN, and claims that C is training-set-consistent, i.e., that all data points in D are correctly classified by the nearest neighbor rule using C. In this note we provide a counterexample to this claim. We also analyze Tomek's algorithm in the context of more recent graph-theoretical condensing schemes.		TOUSSAINT, GT (reprint author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2A7,QUEBEC,CANADA.						AURENHAMMER F, 1991, COMPUT SURV, V23, P345; AVIS D, 1983, ADV COMPUTING RES, P159; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; FISHER FP, 1970, P NATIONAL ELECTRONI, P481; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GABRIEL KR, 1969, SYST ZOOL, V18, P259, DOI 10.2307/2412323; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; IMAI H, 1985, SIAM J COMPUT, V14, P93, DOI 10.1137/0214006; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Klein R., 1987, CONCRETE ABSTRACT VO; MATULA DW, 1980, GEOGR ANAL, V12, P205; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1984, 16TH P COMP SCI STAT; ULLMANN VR, 1974, IEEE T INFORM THEORY, V20, P541; WILFONG G, 1992, NEAREST NEIGHBOR PRO	24	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	AUG	1994	15	8					797	801		10.1016/0167-8655(94)90007-8		5	Computer Science, Artificial Intelligence	Computer Science	PB484	WOS:A1994PB48400007	
J	VEZJAK, M; STEPHANCIC, M				VEZJAK, M; STEPHANCIC, M			AN ANTHROPOLOGICAL MODEL FOR AUTOMATIC RECOGNITION OF THE MALE HUMAN FACE	ANNALS OF HUMAN BIOLOGY			English	Article								The human face is a characteristic pattern most familiar to us when distinguishing people. Although recognizing human faces is one of our everyday activities, we are mostly not aware how the mechanisms of recognition actually work. Attempts to recognize the human face by machine are rarer (less frequent) than those of the recognition of some other phenomena in everyday life. This paper describes the automated analysis of a human face from the grey level picture, defined as an individual description of a face, given in the form of its sub-objects and the relations among them. The model-based analysis is founded on the anthropological model of a human face that incorporates 19 facial parameters of a male face in norma facialis. On the basis of these parameters it is possible to analyse, recognize and identify the human face. The contour image is used as an input to the pattern analysis program. Some algorithms for the search of characteristic face areas are presented. The Hough transform for an ellipse is used to determine the position of the head in a grey image, and to define the eye region within a face. The integral projections of the contour picture are proved to be useful techniques for picture processing to define the nose and the mouth regions within a face. Furthermore, a few algorithms for the precise determination of the facial parameters based on sharp edge transitions are developed. The method is illustrated using photographs of human faces from our data base and the results obtained are also given. The system is realized on a PC/AT computer.	UNIV LJUBLJANA,FAC BIOTECHNOL,DEPT BIOL,61000 LJUBLJANA,SLOVENIA	VEZJAK, M (reprint author), UNIV LJUBLJANA,FAC ELECT & COMP ENGN,61000 LJUBLJANA,SLOVENIA.						BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BARON RJ, 1981, INT J MAN MACH STUD, V15, P137, DOI 10.1016/S0020-7373(81)80001-6; BLADSOE WW, 1966, MAN MACHINE FACIAL R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAW I, 1987, PATTERN RECOGN LETT, V5, P183, DOI 10.1016/0167-8655(87)90039-0; EHRICH RW, 1976, IEEE T COMPUT, V25, P725; Fetter V, 1967, ANTROPOLOGIE; FISCHER SR, 1989, SURFACES OBJECTS; HALL JG, 1989, HDB NORMAL PHYSICAL, P81; HARMON LD, 1977, COMPUT VISION GRAPH, V6, P135, DOI 10.1016/S0146-664X(77)80009-9; KELLY MD, 1970, THESIS STANFORD U; Kohonen T., 1984, SELF ORG ASS MEMORY; KOROSEC J, 1990, AUTOMATIKA, V31, P71; LAPRESTE JT, 1988, NATO ASI SER, V45, P303; MARTIN R., 1957, LEHRBUCH ANTHR; NAGAO M, 1972, PICTURE RECOGNITION, P48; NIEMAN H, 1990, PATTERN ANAL UNDERST; SMON V, 1989, STATISTICNA ANAL ANT; STEFANCIC M, 1965, GLASNIK ADJ, V18, P121; STEFANCIC M, 1981, Bioloski Vestnik, V29, P29; STONHAM J, 1986, ASPECTS FACE PROCESS; Thorwald Jurgen, 1965, CENTURY DETECTIVE; TOMAZORAVNIK T, 1976, ZBORNIK RADOVA ADJ, P126; VEZJAK M, 1991, INT C DIGITAL SIGNAL, P473; Vezjak M., 1990, Elektrotehniski Vestnik, V57; VEZJAK M, 1991, THESIS LJUBLJANA	26	7	7	TAYLOR & FRANCIS LTD	LONDON	ONE GUNDPOWDER SQUARE, LONDON, ENGLAND EC4A 3DE	0301-4460		ANN HUM BIOL	Ann. Hum. Biol.	JUL-AUG	1994	21	4					363	380		10.1080/03014469400003362		18	Anthropology; Biology; Public, Environmental & Occupational Health	Anthropology; Life Sciences & Biomedicine - Other Topics; Public, Environmental & Occupational Health	NN573	WOS:A1994NN57300006	
J	GARTH, LM; POOR, HV				GARTH, LM; POOR, HV			DETECTION OF NON-GAUSSIAN SIGNALS - A PARADIGM FOR MODERN STATISTICAL SIGNAL-PROCESSING	PROCEEDINGS OF THE IEEE			English	Review							HIDDEN MARKOV-MODELS; NEURAL NETWORKS; WIGNER DISTRIBUTION; SPEECH RECOGNITION; TRANSIENT SIGNALS; OPTIMUM DETECTION; DEPENDENT NOISE; CLASSIFICATION; TRANSFORMS; WAVELETS	Non-Gaussian signals arise in a wide variety of applications, including sonar, digital communications, seismology, and radio astronomy. In this tutorial overview, a hierarchical approach to signal modeling and detector design for non-Gaussian signals is described. In addition to being of interest in applications, this problem serves as a paradigm within which most of the areas of active research in statistical signal processing arise. In particular, the methodologies of nonlinear signal processing, higher order statistical analysis, signal representations, and learning algorithms, all can be juxtaposed quite naturally in this framework.	PRINCETON UNIV,DEPT ELECT ENGN,PRINCETON,NJ 08544	GARTH, LM (reprint author), TECHNOSCI INC,URBANA,IL 61801, USA.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147, DOI 10.1016/S0364-0213(85)80012-4; AHALT SC, 1989, ADV NEURAL INFORMATI, P281; AMBLARD PO, 1993, JUN IEEE SIGN PROC W, P265; ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; ANDERSON JA, 1988, NEUROCOMPUTING F RES; DAVIS MHA, 1977, IEEE T INFORM THEORY, V23, P768, DOI 10.1109/TIT.1977.1055783; AZAZHANG B, 1992, IEEE T COMMUN, V40, P1212; BAKER CR, 1969, IEEE T INFORM THEORY, V15, P16, DOI 10.1109/TIT.1969.1054267; BAKER CR, 1986, PROBAB THEORY REL, V71, P159, DOI 10.1007/BF00332309; BAKER CR, 1986, LECT NOTES CONTR INF, V85, P154; BAKER CR, 1993, ADV STAT S, V2, P1; BAKER CR, 1966, IEEE T COMMUN TECHN, VCO14, P802, DOI 10.1109/TCOM.1966.1089403; BARBAROSSA S, 1992, 1992 P IEEE INT C AC, pV173; BARKER RW, 1993, JUN P IEEE WORK HIGH, P187; BASSEVILLE M, 1989, 1989 P IEEE INT C AC, P2065; BATALAMA SN, 1993, IEEE T COMMUN, V41, P1047, DOI 10.1109/26.231936; Baum L. E., 1972, INEQUALITIES, V3, P1; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BENES VE, 1987, ADV STATISTICAL SIGN, V1, P1; BENES VE, 1990, STOCHASTICS MONOGRAP, V5, P447; BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; BEZDEK JC, 1992, SEP IEEE COMM MAG, P24; BOASHASH B, 1991, ADV SPECRUM ANAL ARR, V1; BOASHASH B, 1992, 1992 P IEEE INT C AC, pV193; BOASHASH B, 1988, P SOC PHOTO-OPT INS, V975, P209; BOASHASH B, 1990, IEEE T ACOUST SPEECH, V38, P1829, DOI 10.1109/29.103085; BRADY ML, 1989, IEEE T CIRCUITS SYST, V36, P665, DOI 10.1109/31.31314; Brillinger D., 1967, SPECTRAL ANAL TIME S, P153; Brillinger D.R., 1981, TIME SERIES DATA ANA; BROCKETT PL, 1984, ANN STAT, V12, P737, DOI 10.1214/aos/1176346519; BROCKETT PL, 1978, J MULTIVARIATE ANAL, V8, P233, DOI 10.1016/0047-259X(78)90074-X; BROCKETT R, 1980, ANAL OPTIMIZATION ST; CARPENTER G, 1992, IEEE COMMUN MAG, P38; CARPENTER GA, 1986, AAAS S SER; CHANDRAN V, 1994, IEEE T SIGNAL PROCES, V42, P229, DOI 10.1109/78.258147; CHOU KC, 1991, 1991 P IEEE INT C AC, P1709; COAST DA, 1990, IEEE T BIO-MED ENG, V37, P826, DOI 10.1109/10.58593; COHEN L, 1989, P IEEE, V77, P941, DOI 10.1109/5.30749; Combes J. M., 1989, WAVELETS TIME FREQUE; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1968, 1ST P ANN HAW C SYST, P413; COVER TM, 1969, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANDAWATE AV, 1993, 27TH P AS C SIGN SYS; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; DAUBECHIES I, 1989, WAVELETS TIME FREQUE; DELLOMO MR, 1991, J ACOUST SOC AM, V89, P2355, DOI 10.1121/1.400924; Devijver P. A., 1982, PATTERN RECOGNITION; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Duda R., 1973, PATTERN CLASSIFICATI; DUNCAN TE, 1970, INFORM CONTROL, V16, P303, DOI 10.1016/S0019-9958(70)90150-6; DWYER RF, 1983, 1983 P IEEE INT C AC, P607; DWYER RF, 1982, 16TH P ANN C INF SCI, P604; DWYER RF, 1984, IEEE J OCEANIC ENG, V9, P85, DOI 10.1109/JOE.1984.1145602; DWYER RF, 1993, JUN P IEEE WORK HIGH, P250; DWYER RF, 1985, IEEE J OCEANIC ENG, V10, P303, DOI 10.1109/JOE.1985.1145100; DWYER RF, 1986, IEEE J OCEANIC ENG, V11, P136, DOI 10.1109/JOE.1986.1145152; EASTWOOD LF, 1977, IEEE T INFORM THEORY, V23, P482, DOI 10.1109/TIT.1977.1055751; EHRICH RW, 1976, IEEE T COMPUT, V25, P725; EPPS TW, 1987, ANN STAT, V15, P1683, DOI 10.1214/aos/1176350618; FERGUSON TS, 1961, 4TH BERK S MATH STAT, P253; FLANDRIN P, 1988, 4TH P IEEE ANN ASSP; FLANDRIN P, 1986, 1986 P IEEE INT C AC, P2331; FLANDRIN P, 1988, 1988 P IEEE INT C AC, P2725; FLANDRIN P, 1988, IEEE T ACOUST SPEECH, V36, P1377, DOI 10.1109/29.90365; FRIEDLANDER B, 1989, IEEE T ACOUST SPEECH, V37, P169, DOI 10.1109/29.21680; FRISCH M, 1991, 1991 P IEEE INT C AC, P1313; FU LM, 1990, J NEURAL NETWORK COM, V1, P42; FUKUNAGA K, 1990, INTRO STATISTICAL PA; GARREAU D, 1990, 1990 P IEEE INT C AC, P2495; GARTH LM, 1994, 28TH P ANN C INF SCI; GIANNAKIS GB, 1992, IEEE T INFORM THEORY, V38, P386, DOI 10.1109/18.119695; GIANNAKIS GB, 1990, IEEE T ACOUST SPEECH, V38, P1284, DOI 10.1109/29.57557; GIANNAKIS GB, 1991, OCT P UND SIGN PROC; Girsanov I V, 1960, THEOR PROBAB APPL, V5, P285, DOI 10.1137/1105027; GISH H, 1992, 1992 P IEEE INT C AC, P289; GORMAN RP, 1988, IEEE T ACOUST SPEECH, V36, P1135, DOI 10.1109/29.1640; GOUPILLAUD P, 1984, GEOEXPLORATION, V23, P85, DOI 10.1016/0016-7142(84)90025-5; GROSSMANN A, 1984, SIAM J MATH ANAL, V15, P723, DOI 10.1137/0515056; GUALTIEROTTI AF, 1976, IEEE T INFORM THEORY, V22, P610, DOI 10.1109/TIT.1976.1055592; HAJEK B, 1985, MATH OPERATIONS RES; Hartigan J., 1975, CLUSTERING ALGORITHM; HAYKIN S, 1991, IEEE T NEURAL NETWOR, V2, P589, DOI 10.1109/72.97936; HEIL CE, 1989, SIAM REV, V31, P628, DOI 10.1137/1031129; HELSTROM CW, 1968, STATISTICAL THEORY S; HIBEY JL, 1978, IEEE T INFORM THEORY, V24, P608, DOI 10.1109/TIT.1978.1055925; HINICH MJ, 1968, REV GEOPHYS, V6, P347, DOI 10.1029/RG006i003p00347; HINICH MJ, 1990, IEEE T ACOUST SPEECH, V38, P1277, DOI 10.1109/29.57556; Hinich MJ, 1982, J TIME A, V3, P169, DOI 10.1111/j.1467-9892.1982.tb00339.x; HINICH MJ, 1990, IEEE T ACOUST SPEECH, V38, P1126, DOI 10.1109/29.57541; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUANG SC, 1991, IEEE T NEURAL NETWOR, V2, P47, DOI 10.1109/72.80290; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; Jain A., 1988, ALGORITHMS CLUSTERIN; JOUNY I, 1991, 1991 P IEEE INT C AC, P3429; JOUNY I, 1993, JUN P IEEE WORK HIGH, P245; JOUNY I, 1992, 1992 P IEEE INT C AC, pIV289; KADOTA TT, 1970, IEEE T INFORM THEORY, V16, P291, DOI 10.1109/TIT.1970.1054459; KAILATH T, 1969, IEEE T INFORM THEORY, V15, P350, DOI 10.1109/TIT.1969.1054307; Kassam S. A., 1988, SIGNAL DETECTION NON; KASSAM SA, 1985, P IEEE, V73, P433, DOI 10.1109/PROC.1985.13167; KAY S, 1985, 1985 P IEEE INT C AC, P1017; KHOTANZAD A, 1989, 1989 P IEEE INNS INT, pI335; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KLETTER D, 1990, IEEE T ACOUST SPEECH, V38, P901, DOI 10.1109/29.56051; Kohonen T., 1984, SELF ORG ASS MEMORY; Kosko B, 1992, NEURAL NETWORKS FUZZ; Kronland-Martinet R, 1987, INT J PATTERN RECOGN, V1, P273, DOI 10.1142/S0218001487000205; KUMAR BVKV, 1984, OPT ENG, V23, P732; KWAN HK, 1989, 1989 P IEEE INNS INT, P75; LEBLANC MJ, 1991, SEP P IEEE WORKSH NE, P208; Lehmann E. L, 1986, TESTING STATISTICAL; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; LIPPMANN RP, 1991, SEP P IEEE WORKSH NE, P266; LIPTSER RS, 1977, STATISTICS RANDOM PR, V1; MACCATO A, 1989, P OCEANS 89 SEATTLE, P1118; MACCATO A, 1990, 1990 P IEEE INT C AC, P877; MALKOFF DB, 1990, P SOC PHOTO-OPT INS, V1297, P329, DOI 10.1117/12.21327; MALKOFF DB, 1990, 1990 P IEEE INT C AC, P2739; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MARANDA BH, 1990, 1990 P IEEE INT C AC, P1357; MAZO JE, 1965, AT&T TECH J, V44, P2165; MERHAV N, 1991, IEEE T SIGNAL PROCES, V39, P2157, DOI 10.1109/78.91172; MICHALOPOULOU Z, 1992, 1992 P IEEE INT C AC, P309; MIDDLETO.D, 1973, IEEE T COMMUN, VCO21, P1232, DOI 10.1109/TCOM.1973.1091566; Minsky M., 1988, PERCEPTRONS; MIRCHANDANI G, 1989, IEEE T CIRCUITS SYST, V36, P661, DOI 10.1109/31.31313; MITRA U, 1993, 4TH P INT C ADV COMM; MITRA U, 1993, 1993 P IEEE NEUR NET; MITRA U, 1992, 3RD P S PERS IND MOB, P639; MIYAKE S, 1991, IEEE T NEURAL NETWOR, V2, P538, DOI 10.1109/72.134293; MOULINES E, 1993, JUN P IEEE SP WORKSH, P336; Nikias C. L., 1993, HIGHER ORDER SPECTRA; NIKIAS CL, 1987, P IEEE, V75, P869, DOI 10.1109/PROC.1987.13824; Nikias CL, 1993, IEEE SIGNAL PROC MAG, V10, P10, DOI 10.1109/79.221324; Nilsson Nils J., 1965, LEARNING MACHINES; PAL K, 1986, FUZZY MATH APPROACH; PARIS BP, 1989, ADV NEURAL INF PROCE, V1, P272; PEARSON ES, 1930, BIOMETRIKA, V16, P237; PETROPULU AP, 1992, 1992 P IEEE INT C AC, P477; PICINBON.B, 1970, IEEE T INFORM THEORY, V16, P77, DOI 10.1109/TIT.1970.1054398; PIERCE RD, 1993, JUN P IEEE WORK HIGH, P314; PIKE CM, 1991, 1991 P IEEE INT C AC, P1489; Poor H. V., 1994, INTRO SIGNAL DETECTI; POOR HV, 1985, J ACOUST SOC AM, V78, P1652, DOI 10.1121/1.392803; POOR HV, 1990, J ACOUST SOC AM, V87, P1227, DOI 10.1121/1.398797; POOR HV, 1981, J COMBINATORICS INFO, V6, P111; POOR HV, 1978, J ACOUST SOC AM, V63, P75, DOI 10.1121/1.381698; POOR HV, 1986, COMMUNICATIONS NETWO, P131; POOR HV, 1982, IEEE T INFORM THEORY, V28, P735, DOI 10.1109/TIT.1982.1056545; PORAT B, 1992, 1992 P IEEE INT C AC, P473; Porat B., 1989, International Journal of Adaptive Control and Signal Processing, V3, DOI 10.1002/acs.4480030302; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAO P, 1991, J ACOUST SOC AM, V90, P1423, DOI 10.1121/1.401934; RAO SS, 1991, SEP P IEEE WORKSH NE, P580; Rao TS, 1980, J TIME SER ANAL, V1, P145, DOI 10.1111/j.1467-9892.1980.tb00308.x; REICHERT J, 1992, 1992 P IEEE INT C AC, pV221; Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217; Rissanen J., 1989, STOCHASTIC COMPLEXIT; RISSANEN J, 1993, P US JAPAN C FRONTIE; Rosenblatt Frank, 1959, PRINCIPLES NEURODYNA; ROTH MW, 1989, 1989 P IEEE INNS INT, pI275; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SADLER BM, 1991, 1991 P IEEE INT C AC, P3525; SANGFELT E, 1993, JUN P IEEE WORK HIGH, P182; SCHWARTZ SC, 1977, IEEE T INFORM THEORY, V23, P93, DOI 10.1109/TIT.1977.1055660; SELVIAH DR, 1989, IEE PROC-F, V136, P143; SHAW SW, 1990, IEEE T ACOUST SPEECH, V38, P328, DOI 10.1109/29.103068; SHIELDS MK, 1990, 1990 P IEEE INT C AC, P2731; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; TOU JT, 1967, COMPUTER INFORMATION, V2, P57; TRUNK GV, 1972, IEEE T INFORM THEORY, V18, P126, DOI 10.1109/TIT.1972.1054736; TRUNK GV, 1968, INFORM CONTROL, V12, P508, DOI 10.1016/S0019-9958(68)90591-3; TUTEUR FB, 1988, 1988 INT C AC SPEECH, P1435; VEERAVALLI VV, 1991, J ACOUST SOC AM, V89, P811, DOI 10.1121/1.1894641; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; WALLACE DJ, 1986, 1985 P WORKSH LATT G; WATANABE S, 1965, 4TH T PRAG C INF THE; Watterson J W, 1990, IEEE Trans Neural Netw, V1, P298, DOI 10.1109/72.80267; Widrow B., 1960, 1960 IRE WESCON CONV, P96; WIDROW B, 1988, IEEE T ACOUST SPEECH, V36, P1109, DOI 10.1109/29.1638; Widrow B., 1985, ADAPTIVE SIGNAL PROC; WILSON GR, 1993, JUN P IEEE WORK HIGH; WOODARD JP, 1992, IEEE T SIGNAL PROCES, V40, P1833, DOI 10.1109/78.143457; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; YAO CY, 1990, MAY P IEEE INT S CIR, P727; YAO K, 1973, IEEE T INFORM THEORY, V19, P600; YU X, 1992, 1992 P IEEE INT C AC, pV141; ZERVAKIS ME, 1992, OPT ENG, V31, P2174, DOI 10.1117/12.59978; ZERVAKIS ME, 1993, 1996 P IEEE INT C AC, pV289; ZOUBIR AM, 1993, JUN P IEEE SP WORKSH, P327; 1992, IEEE T INFORMAT THEO, V38	200	21	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9219		P IEEE	Proc. IEEE	JUL	1994	82	7					1061	1095		10.1109/5.293163		35	Engineering, Electrical & Electronic	Engineering	NX707	WOS:A1994NX70700010	
J	CARDILLO, J; SIDAHMED, MA				CARDILLO, J; SIDAHMED, MA			AN IMAGE-PROCESSING SYSTEM FOR LOCATING CRANIOFACIAL LANDMARKS	IEEE TRANSACTIONS ON MEDICAL IMAGING			English	Article							MATHEMATICAL MORPHOLOGY; DECOMPOSITION; CEPHALOGRAMS	A new automatic target recognition algorithm has been developed to extract craniofacial landmarks from lateral skull x-rays (cephalograms). The locations of these landmarks are used by orthodontists in what is referred to as a cephalometric evaluation. The evaluation assists in the diagnosis of anomalies and in the monitoring of treatments. The algorithm is based on gray-scale mathematical morphology. A statistical approach to training was used to overcome subtle differences in skeletal topographies. Decomposition was used to desensitize the algorithm to size differences. A system was trained to locate 20 landmarks. Tests on 40 x-rays showed an 85/recognition rate on average.		CARDILLO, J (reprint author), UNIV WINDSOR,DEPT ELECT ENGN,WINDSOR N9B 3P4,ONTARIO,CANADA.						CHEN CH, 1969, IEEE T SYST SCI CYBE, V5; Cohen A M, 1986, Br J Orthod, V13, P105; Cohen A M, 1984, Br J Orthod, V11, P143; COUNTERARASVIDA.JL, 1990, P CANADIAN C ELECTRI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRIMMINS TR, 1985, IEEE T AERO ELEC SYS, V21, P60, DOI 10.1109/TAES.1985.310539; Duda R., 1973, PATTERN CLASSIFICATI; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532; HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O; Jackson P H, 1985, Br J Orthod, V12, P122; LEVYMANDEL AD, 1986, COMPUT BIOMED RES, V19, P282, DOI 10.1016/0010-4809(86)90023-6; LOUGHEED RM, 1980, P WORKSHOP PICTURE D, P282; MARAGOS P, 1988, P INT C COMP VIS, P695; Matheron G., 1975, RANDOM SETS INTEGRAL; MERO L, 1975, 4TH P INT JOINT C AR, P650; MEYER F, 1986, COMPUT VISION GRAPH, V35, P356, DOI 10.1016/0734-189X(86)90005-8; MOYRS RE, 1988, HDB ORTHODONTICS; NUGENT ST, 1988, 25TH P INT ISA BIOM, P5; PARTHASARATHY S, 1989, COMPUT BIOMED RES, V22, P248, DOI 10.1016/0010-4809(89)90005-0; PITAS I, 1990, IEEE T PATTERN ANAL, V12, P38, DOI 10.1109/34.41382; PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617; Rakosi T., 1982, ATLAS MANUAL CEPHALO; Rosenfeld A, 1982, DIGITAL PICTURE PROC; ROTH MW, 1990, IEEE T NEURAL NETWOR, V1; Serra J., 1982, IMAGE ANAL MATH MORP; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Shapiro L. G., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4); Shih F. Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), DOI 10.1109/CVPR.1988.196322; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; WONG RY, 1979, IEEE T PATTERN ANAL, V1, P325; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	31	42	43	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0278-0062		IEEE T MED IMAGING	IEEE Trans. Med. Imaging	JUN	1994	13	2					275	289		10.1109/42.293920		15	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	NV753	WOS:A1994NV75300007	
J	NAKAMURA, M; SUGIMOTO, I; KUWANO, H; LEMOS, R				NAKAMURA, M; SUGIMOTO, I; KUWANO, H; LEMOS, R			CHEMICAL SENSING BY ANALYZING DYNAMICS OF PLASMA POLYMER FILM-COATED SENSORS	SENSORS AND ACTUATORS B-CHEMICAL			English	Article; Proceedings Paper	7th International Conference on Solid-State Sensors and Actuators (Transducers 93)	JUN 07-10, 1993	YOKOHAMA, JAPAN				PROBES	A chemical sensing system that incorporates unique sensor films and uses pattern recognition of their dynamic responses is presented. This system consists of a sensor array of quartz-crystal microbalances coated with plasma polymer films. The films, synthesized by radio-frequency sputtering, are useful because of their high density of radical sites and unsaturated bonds. When this sensor array is exposed to a gas, the adsorption and desorption of the target gas causes a dynamic frequency response in each piezoelectric sensor. The sensor response is analysed by an autoregressive model typically used to estimate the parameters of dynamic systems. This model's coefficients reflect the sensor dynamics, providing pattern vectors that characterize the target gas. Based on this model, classification maps for single gases can be created with these pattern vectors. These maps show that the dynamic sensor response provides useful information for gas classification. This model also confirms that our sensing system can identify and quantify the components of a gas mixture.	NIPPON TELEGRAPH & TEL PUBL CORP,MUSASHINO ELECT COMMUN LAB,INTELLIGENT TECHNOL CORP LTD,MUSASHINO,TOKYO 180,JAPAN	NAKAMURA, M (reprint author), NIPPON TELEGRAPH & TEL PUBL CORP,MUSASHINO ELECT COMMUN LAB,INTERDISCIPLINARY RES LABS,MUSASHINO,TOKYO 180,JAPAN.						BROWNLEE KA, 1965, STATISTICAL THEORY M; COOPER JB, 1981, IEEE T BIO-MED ENG, V28, P459, DOI 10.1109/TBME.1981.324819; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KAY SM, 1981, P IEEE, V69, P1380, DOI 10.1109/PROC.1981.12184; KINDLUND A, 1982, SENSOR ACTUATOR, V3, P63, DOI 10.1016/0250-6874(82)80007-3; KING WH, 1964, ANAL CHEM, V36, P1735, DOI 10.1021/ac60215a012; NAKAMOTO T, 1991, SENSOR ACTUAT B-CHEM, V3, P1, DOI 10.1016/0925-4005(91)85001-Y; Oppenheim A., 1975, DIGITAL SIGNAL PROCE; ROSEPEHRSSON SL, 1988, ANAL CHEM, V60, P2801, DOI 10.1021/ac00175a032; SUGIMOTO I, 1991, J APPL PHYS, V70, P2887, DOI 10.1063/1.349358; SUGIMOTO I, 1988, J APPL PHYS, V64, P2700, DOI 10.1063/1.341611; SUGIMOTO I, 1993, SENSOR ACTUAT B-CHEM, V10, P117, DOI 10.1016/0925-4005(93)80034-9; SUNDGREN H, 1991, 6TH INT C SOL STAT S, P574; VAIHINGER S, 1991, SENSOR ACTUAT B-CHEM, V4, P337, DOI 10.1016/0925-4005(91)80133-5; WINQUIST F, 1992, SENSOR ACTUAT B-CHEM, V6, P157, DOI 10.1016/0925-4005(92)80048-3	15	21	21	ELSEVIER SCIENCE SA LAUSANNE	LAUSANNE 1	PO BOX 564, 1001 LAUSANNE 1, SWITZERLAND	0925-4005		SENSOR ACTUAT B-CHEM	Sens. Actuator B-Chem.	JUN	1994	20	2-3					231	237		10.1016/0925-4005(94)01197-4		7	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	PK672	WOS:A1994PK67200024	
J	PAL, NR; BEZDEK, JC				PAL, NR; BEZDEK, JC			MEASURING FUZZY UNCERTAINTY	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article							SETS; FUZZINESS; ENTROPY; INFORMATION; SPECIFICITY; NEGATION	First, this paper reviews several well known measures of fuzziness for discrete fuzzy sets. Then new multiplicative and additive classes are defined. We show that each class satisfies five well-known axioms for fuzziness measures, and demonstrate that several existing measures are relatives of these classes. The multiplicative class is based on nan-negative, monotone increasing concave functions. The additive class requires only non-negative concave functions. Some relationships between several existing and the new measures are established, and some new properties are derived. The relative merits and drawbacks of different measures for applications are discussed. A weighted fuzzy entropy which is flexible enough to incorporate subjectivness in the measure of fuzziness is also introduced. Finally, we comment on the construction of measures that may assess all of the uncertainties associated with a physical system.	UNIV W FLORIDA,DEPT COMP SCI,PENSACOLA,FL 32514	PAL, NR (reprint author), INDIAN STAT INST,MACHINE INTELLIGENCE UNIT,CALCUTTA 700035,W BENGAL,INDIA.						BELIS M, 1968, IEEE T INFORM THEORY, V14, P593, DOI 10.1109/TIT.1968.1054185; Bezdek J.C., 1973, THESIS CORNELL U ITH; BHANDARI D, 1992, IN PRESS INFORM SCI; CAPOCELL.RM, 1973, INFORM CONTROL, V23, P446, DOI 10.1016/S0019-9958(73)80009-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELUCA A, 1974, INFORM CONTROL, V24, P55, DOI 10.1016/S0019-9958(74)80023-9; DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4; DUBOIS D, 1985, INT J GEN SYST, V10, P279, DOI 10.1080/03081078508934893; DUBOIS D, 1986, INT J GEN SYST, V12, P193, DOI 10.1080/03081078608934937; DUBOIS D, 1987, FUZZY SET SYST, V24, P161, DOI 10.1016/0165-0114(87)90088-1; DUJET C, 1988, FUZZY SET SYST, V28, P245, DOI 10.1016/0165-0114(88)90032-2; EBANKS BR, 1983, J MATH ANAL APPL, V94, P24, DOI 10.1016/0022-247X(83)90003-3; EMPTOZ H, 1981, FUZZY SET SYST, V5, P307, DOI 10.1016/0165-0114(81)90058-0; Higashi M., 1983, INT J GEN SYST, V9, P43; HIGASHI M, 1982, INT J GEN SYST, V8, P169, DOI 10.1080/03081078208547446; HOHLE U, 1982, 12TH P IEEE INT S MU, P167; HOHLE U, 1981, 3RD P INT SEM FUZZ S, P7; JUMARIE G, 1990, RELATIVE INFORMATION; JUMARIE G, 1986, SUBJECTIVITY INFORMA; Kaufmann A., 1975, INTRO THEORY FUZZY S, V1; KLIR GJ, 1990, INT J GEN SYST, V18, P155, DOI 10.1080/03081079008935135; KLIR GJ, 1985, SYST RES, V2, P131, DOI 10.1002/sres.3850020205; KNOPFMACHER J, 1975, J MATH ANAL APPL, V49, P529, DOI 10.1016/0022-247X(75)90196-1; KOSKO B, 1986, INFORM SCIENCES, V40, P165, DOI 10.1016/0020-0255(86)90006-X; LAMATA MT, 1987, INT J GEN SYST, V14, P297; LOO SG, 1977, CYBERNETICA, V20, P201; Pal N. R., 1992, International Journal of Approximate Reasoning, V7, DOI 10.1016/0888-613X(92)90009-O; PAL NR, 1989, IEE PROC-E, V136, P284; PAL NR, 1992, INFORM SCIENCES, V61, P211, DOI 10.1016/0020-0255(92)90051-9; PAL NR, 1993, INT J APPROX REASON, V8, P1, DOI 10.1016/S0888-613X(05)80003-9; Pal S. K, 1986, FUZZY MATH APPROACH; Pal S. K., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90053-3; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1983, INT J MAN MACH STUD, V19, P33, DOI 10.1016/S0020-7373(83)80040-6; TRILLAS E, 1978, INFORM SCIENCES, V15, P159, DOI 10.1016/0020-0255(78)90005-1; XIE WX, 1984, IEEE T SYST MAN CYB, V14, P151; YAGER RR, 1979, INT J GEN SYST, V5, P221, DOI 10.1080/03081077908547452; YAGER RR, 1980, INFORM CONTROL, V44, P236, DOI 10.1016/S0019-9958(80)90156-4; YAGER RR, 1983, INT J GEN SYST, V9, P249, DOI 10.1080/03081078308960825; YAGER RR, 1982, INT J GEN SYST, V8, P139, DOI 10.1080/03081078208547443; Zadeh L.A., 1975, FUZZY SETS THEIR APP; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4	42	89	100	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	MAY	1994	2	2					107	118		10.1109/91.277960		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	PT989	WOS:A1994PT98900002	
J	PSALTIS, D; SNAPP, RR; VENKATESH, SS				PSALTIS, D; SNAPP, RR; VENKATESH, SS			ON THE FINITE-SAMPLE PERFORMANCE OF THE NEAREST-NEIGHBOR CLASSIFIER	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						NEAREST NEIGHBOR CLASSIFIER; PATTERN CLASSIFICATION; CURSE OF DIMENSIONALITY; LAPLACES METHOD OF INTEGRATION		The finite sample performance of a nearest neighbor classifier is analyzed for a two-class pattern recognition problem. An exact integral expression is derived for the m-sample risk R(m) given that a reference m-sample of labeled points is available to the classifier. The statistical setup assumes that the pattern classes arise in nature with fixed a priori probabilities and that points representing the classes are drawn from Euclidean n-space according to fixed class-conditional probability distributions. The sample is assumed to consist of m independently generated class-labeled points. For a family of smooth class-conditional distributions characterized by asymptotic expansions in general form, it is shown that the m-sample risk R(m) has a complete asymptotic series expansion [GRAPHICS] where R(infinity) denotes the nearest neighbor risk in the infinite-sample limit and the coefficients c(k) are distribution-dependent constants independent of the sample size m. This analysis thus provides further analytic validation of Bellman's curse of dimensionality. Numerical simulations corroborating the formal results are included, and extensions of the theory discussed. The analysis also contains a novel application of Laplace's asymptotic method of integration to a multidimensional integral where the integrand attains its maximum on a continuum of points.	UNIV VERMONT,DEPT COMP SCI & ELECT ENGN,BURLINGTON,VT 05405; UNIV PENN,DEPT ELECT ENGN,PHILADELPHIA,PA 19104; UNIV PENN,DAVID MAHONEY INST NEUROL SCI,PHILADELPHIA,PA 19104	PSALTIS, D (reprint author), CALTECH,DEPT ELECT ENGN,PASADENA,CA 91125, USA.						Billingsley P., 1986, PROBABILITY MEASURE; COVER TM, 1968, 1ST P ANN HAW C SYST, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Erdelyi A, 1956, ASYMPTOTIC EXPANSION; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; FUKUNAGA K, 1990, INTRO STATISTICAL PA; FULKS W, 1961, PAC J MATH, V11, P185; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; SNAPP RR, 1991, ADV NEURAL INFORMATI, V3; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Watson GN, 1918, P LOND MATH SOC, V17, P116; Wolfram S, 1991, MATH SYSTEM DOING MA	14	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	MAY	1994	40	3					820	837		10.1109/18.335893		18	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	PA611	WOS:A1994PA61100019	
J	NAKAMURA, M; SUGIMOTO, I; KUWANO, H				NAKAMURA, M; SUGIMOTO, I; KUWANO, H			CHEMICAL SENSING SYSTEM USING PLASMA POLYMER-FILMS AND PATTERN-RECOGNITION ALGORITHM	JOURNAL OF INTELLIGENT MATERIAL SYSTEMS AND STRUCTURES			English	Article							PROBES	A chemical sensing system using a sensor array with sensitive but durable plasma polymer films is developed. Plasma polymer films have unsaturated bonds and radical sites which cause several unique characteristics. These films contain high concentrations of unsaturated bonds and radical sites, which act as interactive sites. These sites, scattered throughout an inert fluorocarbon framework, are believed to induce specific interactions with small molecules through pi and spin interactions. We have tried to apply our knowledge of these interactions to molecular recognition. For sensing small molecules, these films are deposited on both sides of an AT-cut quartz crystal microbalance (QCM) with a resonant frequency of 9 MHz by radio-frequency (rf) sputtering of polymers such as polychlorotrifluoroethylene. The QCM is connected to an oscillator circuit and its resonant shift is proportional to the mass of the adsorbed molecules. The affinity of plasma polymer films can be shifted by changing sputtering conditions such as the target materials, temperature, or rf power. The chemical sensing system studied here uses a sensor array having modified films with various sensitivities. Because the sensor films have an affinity for several kinds of gases, a pattern recognition algorithm is needed to discern unique gas information from sensors that have overlapping selectivities. The equilibrium mass of adsorbed gas and a time constant are first extracted from the time-dependent sensor outputs, which show that the adsorption process resembles Langmuir adsorption, and then the parameters are mapped to a classification space and used for classification. The addition of a time constant increases the selectivity of our sensor system for single-gas analysis and mixture analysis.		NAKAMURA, M (reprint author), NIPPON TELEGRAPH & TEL PUBL CORP,INTERDISCIPLINARY RES LABS,MUSASHINO,TOKYO 180,JAPAN.						ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; COOPER JB, 1981, IEEE T BIO-MED ENG, V28, P459, DOI 10.1109/TBME.1981.324819; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KINDLUND A, 1982, SENSOR ACTUATOR, V3, P63, DOI 10.1016/0250-6874(82)80007-3; KING WH, 1964, ANAL CHEM, V36, P1735, DOI 10.1021/ac60215a012; Langmuir I, 1916, J AM CHEM SOC, V38, P2221, DOI 10.1021/ja02268a002; NAKAMOTO T, 1991, SENSOR ACTUAT B-CHEM, V3, P1, DOI 10.1016/0925-4005(91)85001-Y; ROSEPEHRSSON SL, 1988, ANAL CHEM, V60, P2801, DOI 10.1021/ac00175a032; SUGIMOTO I, 1991, J APPL PHYS, V70, P2887, DOI 10.1063/1.349358; SUGIMOTO I, 1993, SENSOR ACTUAT B-CHEM, V10, P117, DOI 10.1016/0925-4005(93)80034-9; VAIHINGER S, 1991, SENSOR ACTUAT B-CHEM, V4, P337, DOI 10.1016/0925-4005(91)80133-5	11	11	11	TECHNOMIC PUBL CO INC	LANCASTER	851 NEW HOLLAND AVE, BOX 3535, LANCASTER, PA 17604	1045-389X		J INTEL MAT SYST STR	J. Intell. Mater. Syst. Struct.	MAY	1994	5	3					315	320		10.1177/1045389X9400500304		6	Materials Science, Multidisciplinary	Materials Science	NQ322	WOS:A1994NQ32200004	
J	STAMPER, R; TODD, BS; MACPHERSON, P				STAMPER, R; TODD, BS; MACPHERSON, P			CASE-BASED EXPLANATION FOR MEDICAL DIAGNOSTIC PROGRAMS, WITH AN EXAMPLE FROM GYNECOLOGY	METHODS OF INFORMATION IN MEDICINE			English	Article						COMPUTER-AIDED DIAGNOSIS; NEAREST NEIGHBORS; DATABASE RETRIEVAL; ABDOMINAL PAIN; EXPLANATIONS	COMPUTER-AIDED DIAGNOSIS; ACUTE ABDOMINAL-PAIN; DECISION-SUPPORT SYSTEMS; PHYSICIAN ATTITUDES; CLASSIFICATION; PROBABILITIES	One of the most accountable methods of providing machine assistance in medical diagnosis is to retrieve and display similar previously diagnosed cases from a database. In practice, however, classifying cases according to the diagnoses of their nearest neighbours is often significantly less accurate than other statistical classifiers. In this paper the transparency of the nearest neighbours method is combined with the accuracy of another statistical method. This is achieved by using the other statistical method to define a measure of similarity between the presentations of two cases. The diagnosis of abdominal pain of suspected gynaecological origin is used as a case study to evaluate this method. Bayes' theorem, with the usual assumption of conditional independence, is used to define a metric on cases. This new metric was found to correspond as well as Hamming distance to the clinical notion of ''similarity'' between cases, while significantly increasing accuracy to that of the Bayes' method itself.	JOHN RADCLIFFE HOSP,NUFFIELD DEPT OBSTET & GYNAECOL,OXFORD OX3 9DU,ENGLAND	STAMPER, R (reprint author), UNIV OXFORD,COMP LAB,PROGRAMMING RES GRP,11 KEBLE RD,OXFORD QX1 3QD,ENGLAND.						ADAMS ID, 1986, BRIT MED J, V293, P800; BOUNDS DG, 1990, NEURAL NETWORKS, V3, P583, DOI 10.1016/0893-6080(90)90008-9; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROFT DJ, 1972, COMPUT BIOMED RES, V5, P351, DOI 10.1016/0010-4809(72)90068-7; DEDOMBAL FT, 1972, BRIT MED J, V2, P9; DEDOMBAL FT, 1984, BR J HEALTHCARE COMP, V1, P7; FENYO G, 1990, DIGEST DIS, V8, P639; FOX J, 1980, METHOD INFORM MED, V19, P210; FRIES JF, 1986, WESTERN J MED, V145, P798; FUKUNAGA K, 1990, INTRO STATISTICAL PA; GAMMERMAN A, 1991, METHOD INFORM MED, V30, P15; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; GUNN AA, 1991, BAILLIERE CLIN GASTR, V5, P639, DOI 10.1016/0950-3528(91)90046-4; KONONENKO I, 1987, LECTURE NOTES MED IN, V33, P190; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; LUDWIG D, 1983, METHOD INFORM MED, V22, P156; MACARTNEY FJ, 1987, BRIT MED J, V295, P1325; PIRNAT V, 1989, LECTURE NOTES MED IN, V38, P24; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; REGGIA JA, 1985, COMPUT BIOL MED, V15, P161, DOI 10.1016/0010-4825(85)90057-5; SEROUSSI B, 1986, METHOD INFORM MED, V25, P194; SEROUSSI B, 1985, OBJECTI MED SECISON, V28, P12; SEYMOUR DG, 1990, BRIT MED J, V300, P223; SINGER J, 1983, JAMA-J AM MED ASSOC, V249, P1610, DOI 10.1001/jama.249.12.1610; SPIEGELHALTER DJ, 1984, J ROY STAT SOC A STA, V147, P35, DOI 10.2307/2981737; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE CJ, 1977, ANN STAT, V5, P596; SUTTON GC, 1989, LANCET, V2, P905; SUTTON GC, 1989, BRIT J SURG, V76, P82, DOI 10.1002/bjs.1800760126; TEACH RL, 1981, COMPUT BIOMED RES, V14, P542, DOI 10.1016/0010-4809(81)90012-4; TITTERINGTON DM, 1981, J ROY STAT SOC A STA, V144, P145, DOI 10.2307/2981918; WEYL S, 1975, COMPUT BIOMED RES, V8, P279, DOI 10.1016/0010-4809(75)90045-2; YOUNG D, 1990, BRIT J HEALTHC COMP, V7, P16	35	2	2	F K SCHATTAUER VERLAG GMBH	STUTTGART	P O BOX 10 45 45, LENZHALDE 3, D-70040 STUTTGART, GERMANY	0026-1270		METHOD INFORM MED	Methods Inf. Med.	MAY	1994	33	2					205	213				9	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	NN172	WOS:A1994NN17200009	
J	BOUTEN, M; VANDENBROECK, C				BOUTEN, M; VANDENBROECK, C			NEAREST-NEIGHBOR CLASSIFIER FOR THE PERCEPTRON	EUROPHYSICS LETTERS			English	Article							EXAMPLES; RULE	We calculate the generalization error for the nearest-neighbour classifier based on a set of random examples generated by a teacher perceptron. Explicit results are given for dimensions N = 2, N = 3 and N --> infinity. For a natural extension of the nearest-neighbour rule which includes the k-nearest-neighbour rule and the Hebbian perceptron as particular cases it is found that the Hebbian perceptron gives the smallest generalization error.		BOUTEN, M (reprint author), LIMBURGS UNIV CENTRUM,B-3610 DIEPENBEEK,BELGIUM.		Van den Broeck, Christian/E-5490-2012	Van den Broeck, Christian/0000-0002-7001-2512			BAUM EB, 1990, LECT NOTES COMPUT SC, V412, P2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GARDNER E, 1989, J PHYS A-MATH GEN, V22, P1983, DOI 10.1088/0305-4470/22/12/004; GYORGYI G, 1990, 17 P STATPHYS WORKSH; GYORGYI G, 1990, PHYS REV LETT, V64, P2957, DOI 10.1103/PhysRevLett.64.2957; OPPER M, 1991, PHYS REV LETT, V66, P2677, DOI 10.1103/PhysRevLett.66.2677; OPPER M, 1990, J PHYS A-MATH GEN, V23, pL581, DOI 10.1088/0305-4470/23/11/012; SEUNG HS, 1992, PHYS REV A, V45, P6056, DOI 10.1103/PhysRevA.45.6056; VALLET F, 1989, EUROPHYS LETT, V8, P747, DOI 10.1209/0295-5075/8/8/007; VANDENBROECK C, 1993, PHYS REV LETT, V71, P2355, DOI 10.1103/PhysRevLett.71.2355; VANDENBROECK C, 1993, EUROPHYS LETT, V22, P223; WATKIN TLH, 1993, REV MOD PHYS, V65, P499, DOI 10.1103/RevModPhys.65.499	12	0	0	EDITIONS PHYSIQUE	LES ULIS CEDEX	Z I DE COURTABOEUF AVE 7 AV DU HOGGAR, BP 112, 91944 LES ULIS CEDEX, FRANCE	0295-5075		EUROPHYS LETT	Europhys. Lett.	APR 1	1994	26	1					69	74		10.1209/0295-5075/26/1/012		6	Physics, Multidisciplinary	Physics	NH191	WOS:A1994NH19100012	
J	BLUE, JL; CANDELA, GT; GROTHER, PJ; CHELLAPPA, R; WILSON, CL				BLUE, JL; CANDELA, GT; GROTHER, PJ; CHELLAPPA, R; WILSON, CL			EVALUATION OF PATTERN CLASSIFIERS FOR FINGERPRINT AND OCR APPLICATIONS	PATTERN RECOGNITION			English	Article						EVALUATION OF CLASSIFIERS; OPTICAL CHARACTER RECOGNITION; FINGERPRINTS; PROBABILISTIC NEURAL NETWORKS; RADIAL BASIS FUNCTIONS; STATISTICAL CLASSIFIERS; NEURAL NETWORKS	RECOGNITION; NETWORKS	The classification accuracy of four statistical and three neural network classifiers for two image based pattern classification problems is evaluated, These are optical character recognition (OCR) for isolated handprinted digits, and fingerprint classification. It is hoped that the evaluation results reported will be useful for designers of practical systems for these two important commercial applications. For the OCR problem, the Karhunen Loeve (K-L) transform of the images is used to generate the input feature set. Similarly for the fingerprint problem, the K-L transform of the ridge directions is used to generate the input feature set. The statistical classifiers used are Euclidean minimum distance, quadratic minimum distance, normal, and k-nearest neighbor. The neural network classifiers used are multi-layer perceptron, radial basis function, and probabilistic neural network- The OCR data consist of 7480 digit images for training and 23,140 digit images for testing. The fingerprint data used consist of 2000 training and 2000 testing images. In addition to evaluation for accuracy. the multi-layer perceptron and radial basis function networks are evaluated for size and generalization capability. For the evaluated datasets the best accuracy obtained for either problem is provided by a probabilistic neural network. Minimum classification error is 2.5% for OCR and 7.2%) for fingerprints.	UNIV MARYLAND,DEPT ELECT ENGN,COLLEGE PK,MD 20742; UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742; UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742; UNIV MARYLAND,INST ADV COMP STUDIES,COLLEGE PK,MD 20742	BLUE, JL (reprint author), NATL INST STAND & TECHNOL,MATH MODELING GRP,GAITHERSBURG,MD 20899, USA.						ALT FL, 1962, OPTICAL CHARACTER RE, P159; ATICK JJ, 1992, NETWORK-COMP NEURAL, V3, P213, DOI 10.1088/0954-898X/3/2/009; BALDI P, 1992, P NEURAL INFORMATION; BLUE JL, 1992, C CHARACTER RECOGNIT, V1661, P179; CANDELA GT, 1993, NISTIR5163 NAT I STA; CAO J, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P643; CASEY RG, 1970, IBM J RES DEV; CASEY RG, 1991, P INT WORKSHOP FRONT; CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBOUR NN; DENKER JS, 1989, ADV NEURAL INFORMATI, V1, P323; FLETCHER R, 1964, COMPUT J, V7, P149, DOI 10.1093/comjnl/7.2.149; Fu K. S., 1982, SYNTACTIC PATTERN RE; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; FUKUNAGA K, 1990, INTRO STATISTICAL PA; FUKUSHIMA K, 1991, P IJCNN, V1, P593; GARRIS MD, 1992, HANDWRITTEN SEGMENTE; GILES CL, 1992, NEURAL COMPUT, V4, P380; GROTHER PJ, 1990, CROSS VALIDATION COM, V1906; GUYON I, 1992, ADV NEUR IN, V4, P471; Hartigan J., 1975, CLUSTERING ALGORITHM; HRECHAK AK, 1990, PATTERN RECOGN, V23, P893, DOI 10.1016/0031-3203(90)90134-7; ISENOR DK, 1986, PATTERN RECOGN, V19, P113, DOI 10.1016/0031-3203(86)90017-8; JOHANSSON EM, IN PRESS IEEE T NEUR; Le Cun Y, 1990, ADV NEURAL INFORMATI, V2, P598; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Martin G. L., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.258; MARTIN GL, 1991, ADV NEURAL INFORMATI, V4, P504; MOAYER B, 1976, PATTERN RECOGN, V8, P173, DOI 10.1016/0031-3203(76)90018-2; MOAYER B, 1976, IEEE T COMPUT, V25, P262; MOAYER B, 1975, PATTERN RECOGN, V7, P1, DOI 10.1016/0031-3203(75)90011-4; MOLLER MF, 1990, PB339 AARH U TECHN R; MOLLER MF, 1990, PB339 U AARH TECHN R; MUSAVI MT, 1992, PATTERN RECOGN, V25, P1241, DOI 10.1016/0031-3203(92)90025-E; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; NILSSON NJ, 1965, LEARNING MACHINES F, P45; OMIDVAR OM, 1992, P IJCNN, V4, P594, DOI 10.1109/IJCNN.1992.227254; OMIDVAR OM, 1992, NEURAL STOCHASTIC ME, V1766; PAVLIDIS T, 1992, SPECIAL ISSUE OPTICA, V80; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; RAO K, 1980, IEEE T PATTERN ANAL, V2, P223; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SPARROW MK, 1985, SW124 NBS TECHN REP; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STOCK RM, 1969, CAL XM2478X1 TECHN R, P13; WATSON CI, 1992, FINGERPRINT DATABASE; WETTSCHERECK D, 1991, ADV NEURAL INFORMATI, V4, P1133; WILKINSON RA, 1992, 1ST OPT CHAR REC C; WILSON CL, 1992, NISTIR4880 TECHN REP; WILSON CL, 1990, HANDPRINTED CHARACTE	53	64	65	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.	APR	1994	27	4					485	501		10.1016/0031-3203(94)90031-0		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	NK592	WOS:A1994NK59200003	
J	YANG, MS; CHEN, CT				YANG, MS; CHEN, CT			CONVERGENCE RATE OF THE FUZZY GENERALIZED NEAREST-NEIGHBOR RULE	COMPUTERS & MATHEMATICS WITH APPLICATIONS			English	Article						FUZZY-K NEAREST NEIGHBOR RULE; BAYES RISK; POSTERIOR RISK; STRONG CONSISTENCY; CONVERGENCE RATE; EXPONENTIALLY FAST		Fuzzy k nearest neighbor rule (k-NNR) has been applied in a variety of substantive areas. Yang and Chen [1] described a fuzzy generalized k-NN algorithm which is a unified approach to a variety of fuzzy k-NNR's. They created the strong consistency of posterior risk of the fuzzy generalized NNR. In this paper, we give their convergence rate. That is, the convergence rate of posterior risk of the fuzzy generalized NNR is exponentially fast.		YANG, MS (reprint author), CHUNG YUAN CHRISTIAN UNIV,DEPT MATH,CHUNGLI 32023,TAIWAN.						BAI ZD, 1985, 8515 U PITTSB CTR MU; BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; CHAN KP, 1992, PATTERN RECOGN, V25, P211, DOI 10.1016/0031-3203(92)90102-O; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KISSIOV VT, 1992, FUZZY SET SYST, V49, P323, DOI 10.1016/0165-0114(92)90284-B; Pal S. K, 1986, FUZZY MATH APPROACH; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; YANG MS, IN PRESS FUZZY SETS; YANG MS, 1993, FUZZY SET SYST, V57, P365, DOI 10.1016/0165-0114(93)90030-L	16	49	49	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0898-1221		COMPUT MATH APPL	Comput. Math. Appl.	MAR	1994	27	5					1	8		10.1016/0898-1221(94)90071-X		8	Computer Science, Interdisciplinary Applications; Mathematics, Applied	Computer Science; Mathematics	MV466	WOS:A1994MV46600001	
J	RIZZO, DM; DOUGHERTY, DE				RIZZO, DM; DOUGHERTY, DE			CHARACTERIZATION OF AQUIFER PROPERTIES USING ARTIFICIAL NEURAL NETWORKS - NEURAL KRIGING	WATER RESOURCES RESEARCH			English	Article							COUNTERPROPAGATION NETWORKS; CLASSIFICATION; DISCRIMINATION; IMAGERY	A method for pattern completion based on the application of artificial neural networks and possessing many operational objectives of the ordinary kriging approach, neural kriging, is developed. A neural kriging (NK) network is described, implemented in a parallelizing algorithm, and applied to develop maps of discrete spatially distributed fields (e.g., log hydraulic conductivity). NK is, in the case df two discrete field values, similar to indicator kriging. It uses a feed-forward counterpropagation training approach because field observations are available and because fast yet reliable results are obtained. NK is data-driven and requires no estimate of a covariance function. The optimal design of the NK network is found to depend on the number of hidden units in a more complex way than expected. The quality of the estimate of each pixel of the NK maps can be presented as well, as in kriging, to help identify areas in which additional information will be most beneficial. A comparison with a reference field shows that the NK network produces unbiased errors relative to sample bias and reproduces the variogram of a quantized random field with reasonable accuracy. Ordinary kriging (OK) followed by quantization can also perform well; however, estimation errors in the variogram selected for use in OK (in this case the range coefficient in particular) must be carefully examined and treated. The NK method can provide multiple realizations of the estimated field, all of which respect observations; hence conditional simulation is demonstrably possible. The combination of simplicity, interpolation, reasonably accurate prediction statistics, ability to provide conditional simulations, and computational speed suggest that artificial neural networks can be useful tools in geohydrology when applied to specific well-defined problems for which they are well suited, such as aquifer characterization.		RIZZO, DM (reprint author), UNIV VERMONT,DEPT CIVIL & ENVIRONM ENGN,GROUNDWATER REMEDIAT DESIGN RES CTR,213 VOTEY BLDG,BURLINGTON,VT 05405, USA.						AZIZ ARA, 1992, GROUND WATER, V30, P164, DOI 10.1111/j.1745-6584.1992.tb01787.x; CHIU C, 1990, INT J NEURAL SYST, V1, P211, DOI 10.1142/S0129065790000114; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeSieno D., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), DOI 10.1109/ICNN.1988.23839; DOWLA FU, 1990, B SEISMOL SOC AM, V80, P1346; Duda R., 1973, PATTERN CLASSIFICATI; DYSART PS, 1990, B SEISMOL SOC AM, V80, P1920; EPPING WJM, 1992, REV I FR PET, V47, P243; FITCH JP, 1991, IEEE T GEOSCI REMOTE, V29, P718, DOI 10.1109/36.83986; GOMEZHERNANDEZ JJ, 1990, COMPUT GEOSCI, V16, P395; GROSSBER.S, 1969, J MATH MECH, V19, P53; Grossberg S., 1982, STUDIES MIND BRAIN N; Handcock M.S., 1989, MATH GEOL, V21, P171, DOI 10.1007/BF00893213; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; HECHTNIELSEN R, 1987, P INT C NEURAL NETWO, V2, P19; HECHTNIELSEN R, 1988, NEURAL NETWORKS, V1, P131, DOI 10.1016/0893-6080(88)90015-9; HEPNER GF, 1990, PHOTOGRAMM ENG REM S, V56, P469; Hertz J., 1991, INTRO THEORY NEURAL; Johansson E.M., 1992, INT J NEURAL SYST, V2, P291; Journel A., 1978, MINING GEOSTATISTICS; JOURNEL AG, 1984, GEOSTATISTICS NATURA, P307; JOURNEL AG, 1989, SHORT COURSE GEOL SE, V8; KANELLOPOULOS I, 1992, INT J REMOTE SENS, V13, P917; Kohonen T., 1988, SELF ORG ASS MEMORY; MASSMANN JW, 1989, WATER RESOUR RES, V25, P1763, DOI 10.1029/WR025i007p01763; MATHERON G, 1971, CAH CTR MORPHOL MATH, V5; Minsky M., 1969, PRECEPTRONS; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; PULLI JJ, 1990, GEOPHYS RES LETT, V17, P977, DOI 10.1029/GL017i007p00977; RANJITHAN S, 1993, WATER RESOUR RES, V29, P563, DOI 10.1029/92WR02129; RITTER ND, 1990, COMPUT GEOSCI, V16, P873, DOI 10.1016/0098-3004(90)90009-I; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; STEIN ML, 1990, ANN STAT, V118, P1116; STEIN ML, 1991, ANN I STAT MATH, V43, P61, DOI 10.1007/BF00116469; Sullivan J., 1984, GEOSTATISTICS NATURA, P365; TOMPSON AFB, 1989, WATER RESOUR RES, V25, P2227, DOI 10.1029/WR025i010p02227; ZITKO V, 1991, CHEMOSPHERE, V23, P305, DOI 10.1016/0045-6535(91)90186-H	39	68	71	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009	0043-1397		WATER RESOUR RES	Water Resour. Res.	FEB	1994	30	2					483	497		10.1029/93WR02477		15	Environmental Sciences; Limnology; Water Resources	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	MV707	WOS:A1994MV70700027	
J	STONE, M; JONATHAN, P				STONE, M; JONATHAN, P			STATISTICAL THINKING AND TECHNIQUE FOR QSAR AND RELATED STUDIES .2. SPECIFIC METHODS	JOURNAL OF CHEMOMETRICS			English	Review						DISCRIMINANT ANALYSIS; LEAST SQUARES; PREDICTION; REGRESSION; RELATIONSHIP; STRUCTURE	PARTIAL-LEAST-SQUARES; MULTIVARIATE CALIBRATION; REGRESSION	Twenty-two contrasting statistical methods are reviewed for their applicability to QSAR studies and similar prediction-oriented fields. Each method is concisely specified prior to explanatory or critical comment.	SHELL RES LTD, SITTINGBOURNE ME9 8AG, KENT, ENGLAND	STONE, M (reprint author), UCL, DEPT STAT SCI, GOWER ST, LONDON WC1 E6BT, ENGLAND.						Breiman L, 1984, CLASSIFICATION REGRE; Collett D., 1991, MODELLING BINARY DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEJONG S, 1993, CHEMOMETR INTELL LAB, V18, P251, DOI 10.1016/0169-7439(93)85002-X; DEJONG S, 1992, CHEMOMETR INTELL LAB, V14, P155, DOI 10.1016/0169-7439(92)80100-I; DRAPER NR, 1981, APPLIED REGRESSION A; DUNNE TT, 1993, J ROY STAT SOC B MET, V55, P369; Fisher RA, 1936, ANN EUGENIC, V7, P179; Flury B, 1988, COMMON PRINCIPAL COM; FRANK I E, 1989, Journal of Chemometrics, V3, P463, DOI 10.1002/cem.1180030304; FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656; FRANK IE, 1988, CHEMOMETR INTELL LAB, V4, P215, DOI 10.1016/0169-7439(88)80096-0; FRANK IE, 1987, CHEMOMETR INTELL LAB, V1, P233, DOI 10.1016/0169-7439(87)80067-9; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Hansch C., 1990, COMPREHENSIVE MED CH, V4; HELLAND IS, 1988, COMMUN STAT SIMULAT, V17, P581, DOI 10.1080/03610918808812681; HO YC, 1966, J SIAM CONTROL, V4, P112; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; Jolliffe IT, 1986, PRINCIPAL COMPONENTS; KOWALSKI BR, 1991, J CHEMOMETR, V5, P129, DOI 10.1002/cem.1180050303; KOWALSKI BR, 1974, J AM CHEM SOC, V96, P916, DOI 10.1021/ja00810a047; Lorber A., 1987, J CHEMOMETR, V1, P19, DOI 10.1002/cem.1180010105; MABBETT A, 1980, APPL STAT, V29, P198, DOI 10.2307/2986306; MANNE R, 1987, CHEMOMETR INTELL LAB, V2, P187, DOI 10.1016/0169-7439(87)80096-5; MARBACH R, 1990, CHEMOMETR INTELL LAB, V9, P45, DOI 10.1016/0169-7439(90)80052-8; MATHEWS RJ, 1975, J AM CHEM SOC, V97, P935, DOI 10.1021/ja00837a064; Nilsson Nils J., 1965, LEARNING MACHINES; RIPLEY BD, IN PRESS STATISTICAL; ROUSSEEUW PJ, 1991, J CHEMOMETR, V5, P1, DOI 10.1002/cem.1180050103; Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266; SONQUIST JA, 1973, SEARCHING STRUCTURE; STONE M, 1993, J CHEMOMETR, V7, P455, DOI 10.1002/cem.1180070603; STONE M, 1990, J ROY STAT SOC B MET, V52, P237; STONE M, 1993, 124 U COLL LOND DEP; SUNDBERG R, 1993, J R STAT SOC B, V55, P653; Wan E A, 1990, IEEE Trans Neural Netw, V1, P303, DOI 10.1109/72.80269; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; Wold S., 1984, CHEMOMETRICS MATH ST, P17; WOLD S, 1984, DRUG DESIGN FACT FAN; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	40	16	16	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0886-9383		J CHEMOMETR	J. Chemometr.	JAN-FEB	1994	8	1					1	20		10.1002/cem.1180080103		20	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	MV743	WOS:A1994MV74300001	
J	WHITE, AP				WHITE, AP			CROSS-VALIDATION OF NEAREST-NEIGHBOR DISCRIMINANT-ANALYSIS - A WARNING TO SAS USERS	JOURNAL OF STATISTICAL COMPUTATION AND SIMULATION			English	Article						CROSS-VALIDATION; NEAREST NEIGHBOR DISCRIMINANT ANALYSIS; SAS; OPTIMISTIC BIAS		The SAS statistical package contains a general-purpose discriminant procedure, DISCRIM. Among the options available for this procedure are ones for performing nearest-neighbour discriminant analysis and cross-validation. Each of these works well enough when used separately but, when the two options are used together, an optimistic bias in cross-validated performance emerges. For certain parameter values, this bias can be dramatically large. The cause of the problem is analyzed mathematically for the two-class case with uniformly distributed data and demonstrated by simulation for normal data. The corresponding misbehaviour for multiple classes is also demonstrated by Monte Carlo simulation. A modification to the procedure, which would remove the bias, is proposed.	UNIV BIRMINGHAM,DEPT MATH & STAT,BIRMINGHAM B15 2TT,W MIDLANDS,ENGLAND	WHITE, AP (reprint author), UNIV BIRMINGHAM,CTR COMP,ELMS RD,BIRMINGHAM B15 2TT,W MIDLANDS,ENGLAND.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Edgington E. S., 1980, RANDOMIZATION TESTS; Hand D. J., 1981, DISCRIMINATION CLASS; STILL AW, 1981, BRIT J MATH STAT PSY, V34, P243; TOCHER KD, 1950, BIOMETRIKA, V37, P130, DOI 10.2307/2332156; WHITE AP, 1984, 6TH P S COMP STAT PR; WHITE AP, 1987, BRIT J MATH STAT PSY, V40, P188; White AP, 1993, J APPL STAT, V20, P187, DOI 10.1080/02664769300000015; 1989, SAS STAT USERS GUIDE	9	2	2	GORDON BREACH SCI PUBL LTD	READING	C/O STBS LTD PO BOX 90, READING, BERKS, ENGLAND RG1 8JL	0094-9655		J STAT COMPUT SIM	J. Stat. Comput. Simul.		1994	49	3-4					129	140		10.1080/00949659408811566		12	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	PM040	WOS:A1994PM04000001	
J	YANG, MS; CHEN, CT				YANG, MS; CHEN, CT			ON STRONG CONSISTENCY OF THE FUZZY GENERALIZED NEAREST-NEIGHBOR RULE	FUZZY SETS AND SYSTEMS			English	Article						FUZZY K NEAREST NEIGHBOR RULE; FUZZY SET; STRONG CONSISTENCY; LOSS FUNCTION; BAYES RISK; POSTERIOR RISK		The k nearest neighbor rule (k-NNR) is a well-known nonparametric decision rule in pattern classification. Fuzzy set theory has been widely used to represent the uncertainty of class membership. Several researchers extended conventional k-NNR to fuzzy k-NNR, such as Bezdek et al. [Fuzzy Sets and Systems 18 (1986) 237-256], Keller et al. [IEEE Trans. Syst. Man, and Cybern. 15(4) (1985) 580-585], Bereau and Dubuisson [Fuzzy Sets and Systems 44 (1991) 17-32]. In this paper, we describe a fuzzy generalized k-NN algorithm. This algorithm is a unified approach to a variety of fuzzy k-NNR's. Then we create the strong consistency of posterior risk of the fuzzy generalized NNR.		YANG, MS (reprint author), CHUNG YUAN CHRISTIAN UNIV,DEPT MATH,CHUNGLI 32023,TAIWAN.						BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; CHAN KP, 1992, PATTERN RECOGN, V25, P211, DOI 10.1016/0031-3203(92)90102-O; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUIN RPW, 1982, PATTERN RECOGN, P15; FIX E, 1951, USAF4 SCH AV MED REP; HUNTSBERGER TL, 1985, PATTERN RECOGN, V18, P131, DOI 10.1016/0031-3203(85)90036-6; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Klir G.J., 1988, FUZZY SETS UNCERTAIN; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; YANG MS, 1990, INT J GEN SYST, V16, P397, DOI 10.1080/03081079008935091; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	15	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	DEC 24	1993	60	3					273	281		10.1016/0165-0114(93)90438-N		9	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	MR457	WOS:A1993MR45700003	
J	MAZROUA, AA; SALAMA, MMA; BARTNIKAS, R				MAZROUA, AA; SALAMA, MMA; BARTNIKAS, R			PD PATTERN-RECOGNITION WITH NEURAL NETWORKS USING THE MULTILAYER PERCEPTRON TECHNIQUE	IEEE TRANSACTIONS ON ELECTRICAL INSULATION			English	Note							PARTIAL-DISCHARGE	The partial discharge (PD) pattern recognition capability of a neural network, employing the multilayer perceptron technique with data input based on five discharge pulse form parameters, was examined. Simple discharge sources, consisting of artificially created cylindrical cavities with metallic and dielectric electrodes, were employed. The PD pattern discrimination capability was tested using cavities of equal depth but with different electrodes, and cavities of varying depths but with similar electrodes.	INST RECH HYDRO QUEBEC,VARENNES,PQ,CANADA	MAZROUA, AA (reprint author), UNIV WATERLOO,DEPT ELECT & COMP ENGN,WATERLOO N2L 3G1,ON,CANADA.						BARTNIKAS R, 1993, IN PRESS IEEE T ELEC; BARTNIKAS R, 1975, IEEE T POWER AP SYST, VPA94, P716, DOI 10.1109/T-PAS.1975.31899; BARTNIKAS R, 1983, IEEE T ELECTR INSUL, V18, P458, DOI 10.1109/TEI.1983.298686; BARTNIKA.R, 1969, ARCH ELEKTROTECH, V52, P348, DOI 10.1007/BF01573780; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FRUTH B, 1992, IEEE T ELECTR INSUL, V27, P60, DOI 10.1109/14.123441; Fuhr J, 1990, 1990 IEEE INT S EL I, P129; GISH H, 1990, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.1990.115636; GULSKI E, 1992, IEEE T ELECTR INSUL, V27, P82, DOI 10.1109/14.123443; HOZUMI N, 1992, IEEE T ELECTR INSUL, V27, P550, DOI 10.1109/14.142718; HUDON C, 1993, IEEE T ELECTR INSUL, V28, P1, DOI 10.1109/14.192234; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KRANZ HG, 1989, 6TH INT S HIGH VOLT; KRANZ HG, 1992, IEEE T ELECTR INSUL, V27, P93, DOI 10.1109/14.123444; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; OGI H, 1991, 1ST P INT FOR APPL N, P112; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SUZUKI H, 1992, IEEE T ELECTR INSUL, V27, P543, DOI 10.1109/14.142717; SWARUP KS, 1991, 1ST P INT FOR APPL N, P102; VANBRUNT RJ, 1991, IEEE T ELECTR INSUL, V26, P902, DOI 10.1109/14.99099	21	38	38	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9367		IEEE T ELECTR INSUL		DEC	1993	28	6					1082	1089		10.1109/14.249382		8	Engineering, Electrical & Electronic	Engineering	MM978	WOS:A1993MM97800023	
J	YANG, MS				YANG, MS			A SURVEY OF FUZZY CLUSTERING	MATHEMATICAL AND COMPUTER MODELLING			English	Article						CLUSTER ANALYSIS; FUZZY CLUSTERING; FUZZY C-PARTITIONS; FUZZY RELATION; FUZZY C-MEANS; FUZZY GENERALIZED K-NEAREST NEIGHBOR RULE; CLUSTER VALIDITY	C-MEANS ALGORITHM; CLASSIFICATION; CONVERGENCE; IMAGES; SEGMENTATION; VALIDITY; SETS; CONSISTENCY; RECOGNITION; OPTIMALITY	This paper is a survey of fuzzy set theory applied in cluster analysis. These fuzzy clustering algorithms have been widely studied and applied in a variety of substantive areas. They also become the major techniques in cluster analysis. In this paper, we give a survey of fuzzy clustering in three categories. The first category is the fuzzy clustering based on fuzzy relation. The second one is the fuzzy clustering based on objective function. Finally, we give an overview of a nonparametric classifier. That is the fuzzy generalized k-nearest neighbor rule.		YANG, MS (reprint author), CHUNG YUAN CHRISTIAN UNIV,DEPT MATH,CHUNGLI 32023,TAIWAN.						BEZDEK JC, 1985, IEEE T SYST MAN CYB, V15, P637; ANDERSON IA, 1982, SYSTEMS SCI SCI, V1, P295; Bellman R., 1966, J MATH ANAL APPL, V2, P581; BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK J, 1980, J MATH ANAL APPL, V67, P490; Bezdek J. C., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90012-X; BEZDEK JC, 1975, IEEE T COMPUT, V24, P835, DOI 10.1109/T-C.1975.224317; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; BEZDEK JC, 1974, J MATH BIOL, V1, P57, DOI 10.1007/BF02339490; BEZDEK JC, 1977, IEEE T SYST MAN CYB, V7, P87, DOI 10.1109/TSMC.1977.4309659; Bezdek J.C., 1974, J CYBERNETICS, V3, P58; BEZDEK JC, 1981, SIAM J APPL MATH, V40, P358, DOI 10.1137/0140030; BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873; BEZDEK JC, 1991, PATTERN RECOGN, V24, P783; BEZDEK JC, 1984, IEEE T PATTERN ANAL, V6, P27; BEZDEK JC, 1986, J OPTIMIZATION THEOR, V54, P471; BEZDEK JC, 1990, INT J GEN SYST, V16, P385, DOI 10.1080/03081079008935090; BEZDEK JC, 1979, ADV FUZZY SET THEORY, P445; BEZDEK JC, 1992, IEEE T NEURAL NETWOR, V3, P787, DOI 10.1109/72.159067; BEZDEK JC, 1985, PATTERN RECOGN LETT, V3, P79, DOI 10.1016/0167-8655(85)90012-1; Bloomfield P., 1983, LEAST ABSOLUTE DEVIA; BOBROWSKI L, 1984, PATTERN RECOGN, V17, P205, DOI 10.1016/0031-3203(84)90059-1; BOBROWSKI L, 1991, IEEE T SYST MAN CYB, V21, P545, DOI 10.1109/21.97475; Brown CM, 1982, COMPUTER VISION; CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248; CANNON RL, 1986, IEEE T GEOSCI REMOTE, V24, P400, DOI 10.1109/TGRS.1986.289598; CHAN KP, 1992, PATTERN RECOGN, V25, P211, DOI 10.1016/0031-3203(92)90102-O; CHATTERJI BN, 1982, APPROXIMATE REASONIN, P131; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVE RN, 1990, INT J GEN SYST, V16, P343, DOI 10.1080/03081079008935087; DAVE RN, 1992, PATTERN RECOGN, V25, P713, DOI 10.1016/0031-3203(92)90134-5; DAVE RN, 1992, IEEE T NEURAL NETWOR, V3, P643, DOI 10.1109/72.159055; DAVENPORT JW, 1988, COMPUT MATH APPL, V15, P819, DOI 10.1016/0898-1221(88)90119-8; DAVIES ER, 1989, PATTERN RECOGN LETT, V9, P87, DOI 10.1016/0167-8655(89)90041-X; Devijver P. A., 1982, PATTERN RECOGNITION; DUBES R, 1979, PATTERN RECOGN, V11, P235, DOI 10.1016/0031-3203(79)90034-7; Duda R., 1973, PATTERN CLASSIFICATI; Duin R. P. W., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90045-9; Dunn J., 1974, J CYBERNETICS, V3, P32; DUNN JC, 1974, IEEE T SYST MAN CYB, VSMC4, P310; FIX E, 1951, 4 USAF SCH AV MED RE; GRANATH G, 1984, J INT ASS MATH GEOL, V16, P283, DOI 10.1007/BF01032692; BEZDEK JC, 1981, SIAM J APPL MATH, V40, P339, DOI 10.1137/0140029; GUNDERSON RW, 1983, INT J MAN MACH STUD, V19, P97, DOI 10.1016/S0020-7373(83)80044-3; Gustafson D., 1978, P IEEE CDC, P761; HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057; HATHAWAY RJ, 1986, PATTERN RECOGN, V19, P477, DOI 10.1016/0031-3203(86)90047-6; HATHAWAY RJ, 1989, PATTERN RECOGN, V22, P205, DOI 10.1016/0031-3203(89)90066-6; HATHAWAY RJ, 1986, COMMUN STAT THEORY, V15, P505, DOI 10.1080/03610928608829134; HUNTSBERGER TL, 1990, INT J GEN SYST, V16, P357, DOI 10.1080/03081079008935088; HUNTSBERGER TL, 1985, PATTERN RECOGN LETT, V3, P205, DOI 10.1016/0167-8655(85)90054-6; HUNTSBERGER TL, 1985, PATTERN RECOGN, V18, P131, DOI 10.1016/0031-3203(85)90036-6; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; ISMAIL MA, 1986, IEEE T PATTERN ANAL, V8, P284; ISMAIL MA, 1986, PATTERN RECOGN, V19, P481, DOI 10.1016/0031-3203(86)90048-8; Jain A., 1988, ALGORITHMS CLUSTERIN; JAIN AK, 1987, PATTERN RECOGN, V20, P547, DOI 10.1016/0031-3203(87)90081-1; JAJUGA K, 1991, FUZZY SET SYST, V39, P43, DOI 10.1016/0165-0114(91)90064-W; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KAMEL MS, 1991, PATTERN RECOGN, V24, P825, DOI 10.1016/0031-3203(91)90002-M; KANDEL A, 1974, IEEE T SYST MAN CYB, P472; KELLER JM, 1990, INT J GEN SYST, V16, P331, DOI 10.1080/03081079008935086; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM T, 1988, PATTERN RECOGN, V21, P651, DOI 10.1016/0031-3203(88)90037-4; KRISHNAPURAM R, 1992, IEEE T NEURAL NETWOR, V3, P663, DOI 10.1109/72.159056; LIBERT G, 1982, FUZZY INFORMATION DE, P417; MCBRATNEY AB, 1985, AGR FOREST METEOROL, V35, P165, DOI 10.1016/0168-1923(85)90082-6; McLachlan G. J., 1988, MIXTURE MODELS INFER; Pal S. K, 1986, FUZZY MATH APPROACH; PAL SK, 1990, PATTERN RECOGN LETT, V11, P525, DOI 10.1016/0167-8655(90)90021-S; PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6; RIVER FF, 1990, PATTERN RECOGN LETT, V11, P7, DOI 10.1016/0167-8655(90)90050-C; ROUBENS M, 1982, EUR J OPER RES, V10, P294, DOI 10.1016/0377-2217(82)90228-4; Roubens M., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90016-7; RUSPINI EH, 1973, INFORM SCIENCES, V6, P273, DOI 10.1016/0020-0255(73)90043-1; RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SABIN MJ, 1987, IEEE T PATTERN ANAL, V9, P661; SELIM SZ, 1992, FUZZY SET SYST, V49, P181, DOI 10.1016/0165-0114(92)90323-V; TAMURA S, 1971, IEEE T SYST MAN CYB, VSMC1, P61, DOI 10.1109/TSMC.1971.5408605; TRAUWAERT E, 1988, FUZZY SET SYST, V25, P217, DOI 10.1016/0165-0114(88)90189-3; TRAUWAERT E, 1991, FUZZY SET SYST, V42, P213, DOI 10.1016/0165-0114(91)90147-I; TRIVEDI MM, 1986, IEEE T SYST MAN CYB, V16, P589, DOI 10.1109/TSMC.1986.289264; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; WINDHAM CT, 1985, J AM DIET ASSOC, V85, P1306; WINDHAM MP, 1982, IEEE T PATTERN ANAL, V4, P357; WINDHAM MP, 1985, J CLASSIF, V2, P157, DOI 10.1007/BF01908073; WONG MA, 1983, J ROY STAT SOC B MET, V45, P362; WONG MA, 1985, J STAT COMPUT SIM, V22, P99, DOI 10.1080/00949658508810837; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; YANG MS, UNPUB PARAMETER ESTI; YANG MS, 1993, IN PRESS FUZZY SETS, V60; YANG MS, IN PRESS COMPUTERS M; YANG MS, 1993, COMPUT MATH APPL, V25, P3, DOI 10.1016/0898-1221(93)90181-T; YANG MS, 1993, FUZZY SET SYST, V57, P365, DOI 10.1016/0165-0114(93)90030-L; YANG MS, UNPUB ASYMPTOTIC NOR; YANG MS, 1992, CYBERNET SYST, V23, P583, DOI 10.1080/01969729208927483; YANG MS, 1990, INT J GEN SYST, V16, P397, DOI 10.1080/03081079008935091; ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	103	136	144	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0895-7177		MATH COMPUT MODEL	Math. Comput. Model.	DEC	1993	18	11					1	16		10.1016/0895-7177(93)90202-A		16	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	MP911	WOS:A1993MP91100001	
J	DIZENZO, S; BURGESS, N; FERRAGINA, P; GRANIERI, MN				DIZENZO, S; BURGESS, N; FERRAGINA, P; GRANIERI, MN			RECOGNITION BY CONSTRUCTIVE NEURAL ALGORITHMS	PATTERN RECOGNITION LETTERS			English	Article								The usability of the constructive neural algorithms as pattern classifiers is investigated. It is pointed out that the unboundedness of the decision regions formed by most neural recognizers leads to substantial limitations of the generalization capabilities of these nets. We specify a constructive neural recognizer that forms bounded decision regions, and report the results of this algorithm on a series of benchmark problems that resemble the usual pattern recognition problems.	UCL,DEPT ANAT,LONDON WC1E 6BT,ENGLAND	DIZENZO, S (reprint author), IBM SEMEA,CTR SCI & TECH SOLUT,VIA OCEANO PACIFICO 173,I-00144 ROME,ITALY.		Burgess, Neil/B-2420-2009				Anderson T., 1984, INTRO MULTIVARIATE S; BURGESS N, 1992, INT J NEURAL SYST, V2, P275; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DIZENZO S, 1987, IEEE T GEOSCI REMOTE, V25, P805; DIZENZO S, 1992, IBM J RES DEV, V36; Duda R., 1973, PATTERN CLASSIFICATI; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Fahlman S.E., 1988, 1988 P CONN MOD SUMM, P38; FREAN M, 1990, NEURAL COMPUTATION, V2; FREAN M, 1991, UNPUB THERMAL PERCEP; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Gallant S I, 1990, IEEE Trans Neural Netw, V1, P179, DOI 10.1109/72.80230; Gallant S. I., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.3.293; Hinton G., 1986, PARALLEL DISTRIBUTED; KOHONEN T, 1988, NEURAL NETWORKS MODE; KOHONEN T, 1990, SELF ORG ASS MEMORIC; Lee Y., 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; LIPPMAN RP, 1987, P IEEE 1 INT C NEUR, P485; Martin G. L., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.258; Minsky M., 1988, PERCEPTRONS; Nadal J.-P., 1989, International Journal of Neural Systems, V1, DOI 10.1142/S0129065789000463; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Rosenblatt F., 1958, PSYCHOL REV, V65; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; SANGER T, 1989, NEURAL NETWORKS, V2; SIRAT JA, 1991, INT J NEURAL SYSTEMS, V2, P147, DOI 10.1142/S0129065791000145; Sirat JA, 1990, NETWORK-COMP NEURAL, V1, P423, DOI 10.1088/0954-898X/1/4/003	28	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC	1993	14	12					997	1007		10.1016/0167-8655(93)90008-2		11	Computer Science, Artificial Intelligence	Computer Science	MQ731	WOS:A1993MQ73100008	
J	BECRAFT, WR; LEE, PL				BECRAFT, WR; LEE, PL			AN INTEGRATED NEURAL-NETWORK EXPERT-SYSTEM APPROACH FOR FAULT-DIAGNOSIS	COMPUTERS & CHEMICAL ENGINEERING			English	Article							PATTERN-RECOGNITION; 1ST PRINCIPLES; KNOWLEDGE; MODEL; NEOCOGNITRON	The main thrust of this research is the development of an artificially intelligent system to be used as an operators' aid in the diagnosis of faults in large-scale chemical process plants. The operator advisory system involves the integration of two fundamentally different artificial intelligence techniques: expert systems and neural networks. A diagnostic strategy based on the hierarchical use of neural networks is used as a first-level filter to diagnose faults commonly encountered in chemical process plants. Once the faults are localized within the process by the neural networks, the deep knowledge expert system analyzes the results, and either confirms the diagnosis or else offers an alternative solution. The model-based expert system contains information of the plant's structure and function within its object-oriented knowledge base. The diagnostic strategy can handle multiple faults, novel or previously unencountered faults, and noisy process sensory measurements. The operator advisory system is demonstrated using a multi-column distillation plant as a case study.		LEE, PL (reprint author), OSAKA UNIV,DEPT BIOPHYS ENGN,TOYONAKA,OSAKA 560,JAPAN.						BECRAFT WR, 1991, THESIS U QUEENSLAND; BECRAFT WR, 1991, 4TH INT C IND ENG AP, V1, P345; BECRAFT WR, 1991, 4TH INT S PROC SYST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS R, 1983, INT J MAN MACH STUD, V19, P403, DOI 10.1016/S0020-7373(83)80063-7; DAVIS R, 1984, ARTIF INTELL, V24, P347, DOI 10.1016/0004-3702(84)90042-0; DIETZ WE, 1988, 1ST INT C IND ENG AP; DOIG ID, 1986, PROCESS DIAGNOSTIC E; DVORAK D, 1991, IEEE EXPERT, V6, P67, DOI 10.1109/64.87688; FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; GRANTHAM SD, 1990, COMPUT CHEM ENG, V14, P783, DOI 10.1016/0098-1354(90)87086-5; Handelman D. A., 1990, IEEE Control Systems Magazine, V10, DOI 10.1109/37.55128; Himmelblau D. M., 1978, FAULT DETECTION DIAG; HOSKINS JC, 1988, COMPUT CHEM ENG, V12, P881, DOI 10.1016/0098-1354(88)87015-7; JACKEL LD, 1992, SYNAPSE 92; KOSHIJIMA I, 1992, IFAC S ONLINE FAULT; KRAMER MA, 1990, COMPUT CHEM ENG, V14, P1323, DOI 10.1016/0098-1354(90)80015-4; Leonard J. A., 1991, IEEE Control Systems Magazine, V11, DOI 10.1109/37.75576; MAVROVOUNIOTIS ML, 1990, COMPUT CHEM ENG, V14, P347; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Naidu S. R., 1990, IEEE Control Systems Magazine, V10, DOI 10.1109/37.55124; Passino K. M., 1989, IEEE Control Systems Magazine, V9, DOI 10.1109/37.24811; PETTI TF, 1990, AICHE J, V36, P565, DOI 10.1002/aic.690360408; RUMELHHART DE, 1986, PARALLEL DISTRIBUTED, V1; SCARL EA, 1987, IEEE T SYST MAN CYB, V17, P360, DOI 10.1109/TSMC.1987.4309053; SORSA T, 1991, IEEE T SYST MAN CYB, V21, P815, DOI 10.1109/21.108299; UNGAR LH, 1990, COMPUT CHEM ENG, V14, P561, DOI 10.1016/0098-1354(90)87027-M; VENKATASUBRAMANIAN V, 1989, AICHE J, V35, P1993, DOI 10.1002/aic.690351210; VENKATASUBRAMANIAN V, 1990, COMPUT CHEM ENG, V14, P699, DOI 10.1016/0098-1354(90)87081-Y; VENKATASUBRAMANIAN V, 1988, COMPUT CHEM ENG, V12, P903, DOI 10.1016/0098-1354(88)87017-0; WATANABE K, 1989, AICHE J, V35, P1803, DOI 10.1002/aic.690351106; Waterman D. A., 1986, GUIDE EXPERT SYSTEMS; WEISS SM, 1990, ARTIF INTELL, V45, P47, DOI 10.1016/0004-3702(90)90037-Z; 1987, INTELLIGENCE COMPILE; 1989, HYSIM USERS GUIDE VE	37	23	28	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0098-1354		COMPUT CHEM ENG	Comput. Chem. Eng.	OCT	1993	17	10					1001	1014		10.1016/0098-1354(93)80081-W		14	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	LN368	WOS:A1993LN36800005	
J	KONEN, W; VONDERMALSBURG, C				KONEN, W; VONDERMALSBURG, C			LEARNING TO GENERALIZE FROM SINGLE EXAMPLES IN THE DYNAMIC LINK ARCHITECTURE	NEURAL COMPUTATION			English	Article							INVARIANT PATTERN-RECOGNITION; VISUAL-CORTEX; SYMMETRY; MECHANISM; CAT	A large attraction of neural systems lies in their promise of replacing programming by learning. A problem with many current neural models is that with realistically large input patterns learning time explodes. This is a problem inherent in a notion of learning that is based almost entirely on statistical estimation. We propose here a different learning style where significant relations in the input pattern are recognized and expressed by the unsupervised self-organization of dynamic links. The power of this mechanism is due to the very general a priori principle of conservation of topological structure. We demonstrate that style with a system that learns to classify mirror symmetric pixel patterns from single examples.		KONEN, W (reprint author), RUHR UNIV BOCHUM,INST NEUROINFORMAT,W-4630 BOCHUM,GERMANY.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147, DOI 10.1016/S0364-0213(85)80012-4; BARLOW HB, 1979, VISION RES, V19, P783, DOI 10.1016/0042-6989(79)90154-8; BIENENSTOCK E, 1987, EUROPHYS LETT, V4, P121, DOI 10.1209/0295-5075/4/1/020; BORNSTEIN MH, 1981, DEV PSYCHOL, V17, P82, DOI 10.1037/0012-1649.17.1.82; Buhmann J., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), DOI 10.1109/IJCNN.1989.118574; BUHMANN J, 1991, NEURAL NETWORKS DYNA, V7, P121; COOLEN ACC, 1989, NEURAL NETWORKS, V2, P495, DOI 10.1016/0893-6080(89)90046-4; CORBALLI.MC, 1974, PERCEPT PSYCHOPHYS, V16, P136, DOI 10.3758/BF03203266; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRICK F, 1984, P NATL ACAD SCI-BIOL, V81, P4586, DOI 10.1073/pnas.81.14.4586; DELIUS JD, 1982, PSYCHOL RES-PSYCH FO, V44, P199, DOI 10.1007/BF00308420; ECKHORN R, 1988, BIOL CYBERN, V60, P121, DOI 10.1007/BF00202899; FIX E, 1951, USAF4 SCH AV MED TEC; GRAY CM, 1989, NATURE, V338, P334, DOI 10.1038/338334a0; JULESZ B, 1975, SCI AM, V4; KOHONEN T, 1988, P IEEE ICNN SAN DIEG; LADES M, 1993, IEEE T COMPUT, V10, P300; RAMACHANDRAN V, 1988, SCI AM, V10, P76; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SCHNEIDER W, 1986, THESIS U GOTTINGEN G; SEJNOWSKI TJ, 1986, PHYSICA D, V22, P260, DOI 10.1016/0167-2789(86)90245-9; VONDERMALSBURG C, 1988, NEURAL NETWORKS, V1, P141, DOI 10.1016/0893-6080(88)90016-0; von der Malsburg C, 1981, 812 MAX PLANCK I BIO; VONDERMALSBURG C, 1992, BIOL CYBERN, V67, P233; WILLSHAW DJ, 1976, PROC R SOC SER B-BIO, V194, P431, DOI 10.1098/rspb.1976.0087	27	20	21	MIT PRESS	CAMBRIDGE	55 HAYWARD ST JOURNALS DEPT, CAMBRIDGE, MA 02142	0899-7667		NEURAL COMPUT	Neural Comput.	SEP	1993	5	5					719	735		10.1162/neco.1993.5.5.719		17	Computer Science, Artificial Intelligence	Computer Science	LR843	WOS:A1993LR84300004	
J	COSMAN, PC; OEHLER, KL; RISKIN, EA; GRAY, RM				COSMAN, PC; OEHLER, KL; RISKIN, EA; GRAY, RM			USING VECTOR QUANTIZATION FOR IMAGE-PROCESSING	PROCEEDINGS OF THE IEEE			English	Article							HISTOGRAM EQUALIZATION; WORD RECOGNITION; PREPROCESSOR	Image compression is the process of reducing the number of bits required to represent an image. Vector quantization, the mapping of pixel intensity vectors into binary vectors indexing a limited number of possible reproductions, is a popular image compression algorithm. Compression has traditionally been done with little regard for image processing operations that may precede or follow the compression step. Recent work has used vector quantization both to simplify image processing tasks-such as enhancement, classification, halftoning, and edge detection-and to reduce the computational complexity by performing them simultaneously with the compression. After briefly reviewing the fundamental ideas of vector quantization, we present a survey of vector quantization algorithms that perform image processing.	UNIV WASHINGTON,DEPT ELECT ENGN,SEATTLE,WA 98195	COSMAN, PC (reprint author), STANFORD UNIV,DEPT ELECT ENGN,INFORMAT SYST LAB,STANFORD,CA 94305, USA.		Gray, Robert/A-1433-2012				Abut H., 1990, VECTOR QUANTIZATION; ARNOLD DV, 1988, 1988 P IEEE NAT RAD, P134; Breiman L, 1984, CLASSIFICATION REGRE; BURTON D, 1991, 1991 P INT C AC SPEE, V2, P1493; CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498; CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124; COSMAN PC, 1992, INFORM PROCESS MANAG, V28, P681, DOI 10.1016/0306-4573(92)90061-4; COSMAN PC, 1992, 6 P MED IM; COSMAN PC, 1993, SID 93; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Curlander J. C., 1991, SYNTHETIC APERTURE R; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; Drebin R. A., 1988, Computer Graphics, V22; Duchon A., 1993, Journal of the Acoustical Society of Japan (E), V14; EPHRAIM Y, 1988, IEEE T INFORM THEORY, V34, P826, DOI 10.1109/18.9780; EPRAHIM Y, 1992, P IEEE, V80, P1526; Fix E, 1951, DISCRIMINATORY ANAL; Floyd R., 1975, SID INT S, P36; FURUI S, 1988, IEEE T ACOUST SPEECH, V36, P980, DOI 10.1109/29.1619; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GHOSH J, 1991, P IEEE C NEURAL NETW, P41; GISH H, 1990, P ICASSP, V1, P117; Gray R. M., 1984, IEEE ASSP Magazine, V1, DOI 10.1109/MASSP.1984.1162229; Haralick RM, 1991, COMPUTER ROBOT VISIO; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58; HARGER RO, 1992, P SPIE INT SOC OPTIC, V1630, P76; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HELMS EH, 1988, THESIS SO METHODIST; HILLBERT EE, 1977, 7743 JET PROP LAB PU; HUANG SS, 1988, SPEECH COMMUN, V7, P41, DOI 10.1016/0167-6393(88)90020-9; HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7; JAISIMHA MY, 1992, P ICASSP, V3, P441, DOI 409238792,12,1; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; Kohonen T., 1989, SELF ORG ASS MEMORY; KOHONEN T, 1988, P IEEE INT C NEURAL, P61; KOPEC GE, 1985, IEEE T ACOUST SPEECH, V33, P850, DOI 10.1109/TASSP.1985.1164652; Lee K. F., 1989, AUTOMATIC SPEECH REC; LI KP, 1983, P ICASSP, V2, P555; MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340; MCLEAN GF, 1990, P SOC PHOTO-OPT INS, V1360, P1332, DOI 10.1117/12.24148; MERELO JJ, 1991, ARTIFICIAL NEURAL NE, P415; NATARAJAN BK, 1993, 1993 P IEEE DAT COMP, P60; NETRAVALI AN, 1988, DIGITAL PRICTURES RE; NEUMANN EK, 1992, BIOL CYBERN, V66, P485, DOI 10.1007/BF00204113; NING P, 1993, THESIS STANFORD U ST; NING P, 1992, 1992 WORKSH VOL VIS, P69; NING P, 1993, IN PRESS OCT IEEE VI; OEHLER KL, 1991, 25TH AS C SIGN SYST, P439; OEHLER KL, 1993, 1993 P IEEE DAT COMP, P2; OLSHEN RA, 1991, OCT P COMCON 3, P830; OWLSEY LM, 1993, IN PRESS P IEEE WORK; PAN KC, 1985, IEEE T ACOUST SPEECH, V33, P546; PICCONE J, 1990, IEEE ASSP MAG, V7, P26; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; POOK PK, 1993, IEEE INT C ROB AUT, V2, P578; RABBANI M, 1991, TUTORIAL TEXTS OP TT, V7; Read C. J., 1988, IEEE Aerospace and Electronics Systems Magazine, V3, DOI 10.1109/62.9367; READ CJ, 1989, MAY P ICASSP GLASG, P1015; RISKIN EA, 1991, IEEE T SIGNAL PROCES, V39, P2500, DOI 10.1109/78.98004; SOONG FK, 1987, AT&T TECH J, V66, P14; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Ulichney R., 1987, DIGITAL HALFTONING; VANDERKAM RA, 1993, MAY SID 93; VANDERKAM RA, 1992, P IEEE INT C AC SPEE, V3, P497, DOI 115307015,12,1; YANG J, 1993, IEEE T ROBOTIC AUTOM, V1, P396	65	51	51	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9219		P IEEE	Proc. IEEE	SEP	1993	81	9					1326	1341		10.1109/5.237540		16	Engineering, Electrical & Electronic	Engineering	MB647	WOS:A1993MB64700012	
J	BAGUI, SC				BAGUI, SC			CLASSIFICATION OF MULTIPLE OBSERVATIONS USING A RANK NEAREST-NEIGHBOR RULE	PATTERN RECOGNITION LETTERS			English	Article						BAYES RISK; CLASSIFICATION; MONTE-CARLO; RANK NEAREST NEIGHBOR		We consider the problem of classifying multiple (k) univariate observations into one of two populations using a rank nearest neighbor (RNN) type rule. We derive the limiting total probability of misclassification (TPMC) (limiting risk) R(k) of the proposed RNN rule for k = 2 and obtain an upper bound of the limiting TPMC. Finally, with k varying from 1 to 5, some Monte Carlo results are reported to study the performance of the proposed rule.		BAGUI, SC (reprint author), UNIV W FLORIDA,DEPT MATH & STAT,PENSACOLA,FL 32514, USA.						BAGUI SC, 1989, THESIS U ALBERTA; CHOI SC, 1972, BIOMETR Z, V14, P8, DOI 10.1002/bimj.19720140103; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1980, SANKHYA A, V42, P29; FIX E, 1952, 4 US AIR FORC SCH AV	5	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	AUG	1993	14	8					611	617		10.1016/0167-8655(93)90045-F		7	Computer Science, Artificial Intelligence	Computer Science	LQ197	WOS:A1993LQ19700001	
J	ROMANIUK, SG; HALL, LO				ROMANIUK, SG; HALL, LO			SC-NET - A HYBRID CONNECTIONIST, SYMBOLIC SYSTEM	INFORMATION SCIENCES			English	Article								This paper describes the SC-net system that has been developed to provide expert systems capability augmented with learning in a hybrid connectionist/symbolic approach. A distributed connectionist representation of cells connected by links is used to represent symbolic knowledge. Rules may be directly encoded in the connectionist network or learned from examples. The learning method is a form of instance-based learning in which some of the individual instances in the training set are encoded by adding structure to the network and others cause modifications to biases in the network. Both continuous and nominal attributes are directly represented in the network structure. A limited form of variables in the form of attribute value bindings on the right-hand side of rules is supported. Relational comparators in the form of cell groups are also supported. Relational comparators and attribute value structures are represented by groups of connected cells in the network. The learning algorithm is presented and methods for providing generalization in an instance-based connectionist environment are presented. Empirical results are presented, which include learning in domains (fevers and gems) that contain uncertainty and the well-known iris, and soybean data sets together with a real world domain for semiconductor wafer fault diagnosis. The generalization ability of the learned network is shown to be good in several domains including iris. The system is shown to compare favorably with a nonneural instance-based learning algorithm IBL.		ROMANIUK, SG (reprint author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.						AHA DW, 1991, INSTANCE BASED LEARN, P37; ASH T, 1989, ICS8901 U CAL I COGN; BARTELL B, 1989, IJCNN 89; CHAN SC, 1989, JUN P IJCNN 89 WASH; CHANDRASEKARAN B, 1988, AI MAG, V9, P24; CHERKASSKY V, 1991, INFORMATIVE DATA REP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAHLMAN S, 1990, CMUCS90100 CARNEGIEM; FAHLMAN SE, 1987, IEEE COMPUT      JAN, P100; FAHLMAN SE, 1988, 1988 P CONN MOD SUMM, V1, P788; FELDMAN JA, 1982, BIOLCYBERNETICS, P46; GAINES BR, 1989, OUNCE KNOWLEDGE WORT; GALLANT SI, 1988, COMMUN ACM, V31, P152, DOI 10.1145/42372.42377; HALL LO, 1990, AAAI 90; HALSTEAD RH, 1985, ACM T PROGR LANG SYS, V7, P501, DOI 10.1145/4472.4478; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hecht-Nielson R, 1990, NEUROCOMPUTING; HONAVAR V, 1988, SUM P CONN SCH; JUDD S, 1988, COLT 88; Kandel A., 1986, FUZZY MATH TECHNIQUE; KELLER JM, IN PRESS INF SCI; KELLER JM, 1989, NEURAL NETWORK IMPLE; KIBLER D, 1990, READINGS MACHINE LEA; LEE H, 1991, 4TH FLOR AI RES S CO, P125; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4; Michalski R. S., 1983, MACHINE LEARNING; Minsky M., 1988, PERCEPTRONS; Mooney R., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence; ODEN GC, 1989, IEEE ICNN; PEREZ RA, 1992, JAN HAW INT C SYST S; PEREZ RA, 1991, ISL9101 U S FLOR DEP; POLLACK J, 1988, AI MAG, V9, P65; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; REINKE R, 1984, THESIS U ILLINOIS UR; ROMANIUK S, 1989, CSE8907 U S FLOR DEP; ROMANIUK S, 1991, THESIS U S FLORIDA; ROMANIUK SG, 1990, INNC 90; ROMANIUK SG, 1989, FUZZNET SC NET USERS; ROMANIUK SG, 1990, JAN P IJCNN WASH; Rummelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAMAD T, 1988, P INT C NEURAL NETWO, V2; SANOU K, 1992, ISL192 U S FLOR DEP; Shavlik J. W., 1990, READINGS MACHINE LEA; SHAVLIK JW, 1989, 857 U WISC MAD COMP; TOURETZKY DS, 1988, COGNITIVE SCI, V12, P423, DOI 10.1207/s15516709cog1203_4; VANMELLE W, 1984, RULE BASED EXPERT SY, P302; VICTOR P, 1990, 3RD FLOR C  COMP INT, P51; Waterman D. A., 1986, GUIDE EXPERT SYSTEMS; WEISS SM, 1989, P IJCAI 89	49	2	2	ELSEVIER SCIENCE INC	NEW YORK	655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010	0020-0255		INFORM SCIENCES	Inf. Sci.	JUL	1993	71	3					223	268		10.1016/0020-0255(93)90058-T		46	Computer Science, Information Systems	Computer Science	LG800	WOS:A1993LG80000001	
J	BEZDEK, JC; HALL, LO; CLARKE, LP				BEZDEK, JC; HALL, LO; CLARKE, LP			REVIEW OF MR IMAGE SEGMENTATION TECHNIQUES USING PATTERN-RECOGNITION	MEDICAL PHYSICS			English	Article							MAGNETIC-RESONANCE IMAGES; MULTISPECTRAL TISSUE CLASSIFICATION; ANALYSIS SYSTEM; NEURAL NETWORK; BRAIN; ALGORITHM; QUANTITATION; PROBABILITY; VALIDATION; RULES		UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33647; UNIV S FLORIDA,DEPT RADIOL,TAMPA,FL 33647; UNIV S FLORIDA,H LEE MOFFITT CANC & RES CTR,TAMPA,FL 33647	BEZDEK, JC (reprint author), UNIV W FLORIDA,DIV COMP SCI,PENSACOLA,FL 32514, USA.						ALPERT N, 1990, J NUCL MED, V31, P717; ARBIBV M, 1987, BRAINS MACHINES MATH; BENSAID AM, 1991, 13TH P ANN IEEE ENG; BENSAID AM, 1992, P SOC PHOTO-OPT INS, V1710, P522, DOI 10.1117/12.140120; BERGER RK, 1986, MAGNET RESON MED, V3, P649; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1992, P SOC PHOTO-OPT INS, V1826, P280, DOI 10.1117/12.131608; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bezdek J.C., 1992, FUZZY MODELS PATTERN; BOTTOMLEY PA, 1984, MED PHYS, V11, P425, DOI 10.1118/1.595535; CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CHANEY EL, 1992, J 3 DIM TREATMENT PL, V2, P215; CHEESEMAN P, 1988, COMPUT INTELL, V4, P57; CHOI HS, 1991, IEEE T MED IMAGING, V10, P395, DOI 10.1109/42.97590; CLARK JW, 1991, PHYS MED BIOL, V36, P1259, DOI 10.1088/0031-9155/36/10/001; CLARKE LP, 1991, MED PHYS, V18, P673; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; CLARKE LP, 1993, APR P SPAC EARTH SCI, P63; CLARKE LP, 1993, J MAG RES IMAG, V3, P31; CLARKE P, 1993, MAG RES IMAG, V11, P95; COGGINS JMN, 1990, 1ST P INT C VIS BIOM, P123, DOI 10.1109/VBC.1990.109311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Dubois D, 1980, FUZZY SETS SYSTEMS; Duda R., 1973, PATTERN CLASSIFICATI; FAHLMAN S. E., 1990, ADV NEURAL INFORMATI, V2, P524; FAHLMAN SE, 1988, 1988 P CONN MOD SUMM; GERIG G, 1991, 12TH P INT C INF PRO, P175; GLENNON DT, 1991, 13TH P ANN IEEE ENG; GOHOGAN K, 1987, RADIOLGOY, V3163, P703; HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057; Hartigan J., 1975, CLUSTERING ALGORITHM; HIDEMOTO S, 1991, COMP MED IMAG GRAPH, V15, P233; HYMAN TJ, 1989, MAGNET RESON MED, V11, P22, DOI 10.1002/mrm.1910110103; JUNGKE M, 1988, MAGN RESON IMAGING, V6, P683, DOI 10.1016/0730-725X(88)90093-8; JUST M, 1988, RADIOLOGY, V169, P779; Karssemeijer N., 1990, Machine Vision and Applications, V3, DOI 10.1007/BF01212192; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KERR DA, 1992, P SOC PHOTO-OPT INS, V1710, P510, DOI 10.1117/12.140119; KING MA, 1991, MED PHYS, V18, P184, DOI 10.1118/1.596705; Klir G.J., 1988, FUZZY SETS UNCERTAIN; KOENIG HA, 1988, P SPIE M MED IMAGING; KOHN MI, 1991, RADIOLOGY, V178, P115; Kohonen T., 1989, SELF ORG ASS MEMORY; KOSKO B, 1990, INT J GEN SYST, V17, P211, DOI 10.1080/03081079008935108; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; KUBLER O, 1990, P NATO C 3D IMAGING, P63; LEVIN DN, 1989, RADIOLOGY, V172, P783; LI C, 1992, P IAPR WORKSHOP STRU; LI H, 1989, IEEE T SYST MAN CYB, V19, P276; LIANG Z, 1993, IEEE ENG MED BIOL, V12, P81, DOI 10.1109/51.195944; LIM YW, 1990, PATTERN RECOGN, V23, P935; LIN WC, 1992, PATTERN RECOGN, V25, P679; LINDLEY DV, 1982, INT STAT REV, V50, P1, DOI 10.2307/1402448; MENHARDT W, 1988, PATTERN RECOGN LETT, V8, P73, DOI 10.1016/0167-8655(88)90049-9; MERICKEL MB, 1991, P ANN INT C IEEE ENG, V13, P1323; MERICKEL MB, 1991, COMPUT MED IMAG GRAP, V15, P207, DOI 10.1016/0895-6111(91)90078-A; ODONNELL M, 1986, MED PHYS, V13, P293, DOI 10.1118/1.595916; PAL N, 1993, IN PRESS IEEE T NEUR; PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494; PAL SK, 1986, IEEE T SYST MAN CYB, V16, P754, DOI 10.1109/TSMC.1986.289321; Pao Y. H., 1989, ADAPTIVE PATTERN REC; QIAN W, 1993, IN PRESS IEEE T MED; RAJANAYAGAM V, 1991, MAGN RESON IMAGING, V9, P621, DOI 10.1016/0730-725X(91)90050-V; RAMAN SV, 1991, IEEE T MED IMAGING, V10, P109, DOI 10.1109/42.79468; RAMAN SV, 1991, UNPUB IEEE T MED IMA; ROMANIUK SG, 1992, P IEEE INT JOINT C N, V1, P658, DOI 10.1109/IJCNN.1992.287112; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SCHELLENBERG D, 1990, APPLICATION ARTIFICI; SMITH AR, 1991, INT J RADIAT ONCOL, V21, P1; STALLINGS W, 1977, IEEE T SYST MAN CYB, V7, P216; TAN KK, 1990, RADIOLOGY P, V177, P217; Tanaka K., 1991, International Journal of Approximate Reasoning, V5, DOI 10.1016/0888-613X(91)90009-B; TITTERINGTON DM, 1985, STATISTICAL ANAL FIN; Tou J.T., 1974, PATTERN RECOGNITION; TSAO E, 1992, 1ST P IEEE C FUZZ SY, P1035; TSAO E, 1992, 5TH P ANN FLAIRS C F, P24; VANNIER MW, 1988, NEWS PHYSIOL SCI, V3, P148; VANNIER MW, 1985, RADIOLOGY, V154, P221; VANNIER MW, 1991, COMPUT MED IMAG GRAP, V15, P217, DOI 10.1016/0895-6111(91)90079-B; WINDHAM JP, 1991, MED PHYS, V8, P619; XIAOPING H, 1991, J MAG RES IMAG, V1, P539; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zimmermann H.-J., 1990, FUZZY SET THEORY ITS; 1988, DARPA NEURAL NETWORK	86	440	450	AMER INST PHYSICS	WOODBURY	CIRCULATION FULFILLMENT DIV, 500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2999	0094-2405		MED PHYS	Med. Phys.	JUL-AUG	1993	20	4					1033	1048		10.1118/1.597000		16	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	LU093	WOS:A1993LU09300010	
J	JIANG, QY; ZHANG, WS				JIANG, QY; ZHANG, WS			AN IMPROVED METHOD FOR FINDING NEAREST NEIGHBORS	PATTERN RECOGNITION LETTERS			English	Article						NEAREST NEIGHBOR CLASSIFICATION; BRANCH-AND-BOUND ALGORITHM		This paper develops a more efficient branch-and-bound tree searching algorithm for finding the nearest neighbor to a new pattern in the design set, and a simplified version is given. Experimental results using samples from multi-dimensional Gaussian distributions demonstrate the efficiencies of our algorithms.		JIANG, QY (reprint author), TSING HUA UNIV, DEPT APPL MATH, BEIJING 100084, PEOPLES R CHINA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KAMGARPARSI B, 1985, PATTERN RECOGN LETT, V3, P7, DOI 10.1016/0167-8655(85)90036-4; NIEMANN H, 1988, PATTERN RECOGN LETT, V7, P67, DOI 10.1016/0167-8655(88)90120-1; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769	9	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL	1993	14	7					531	535		10.1016/0167-8655(93)90101-I		5	Computer Science, Artificial Intelligence	Computer Science	LL591	WOS:A1993LL59100001	
J	BAGUI, SC				BAGUI, SC			CLASSIFICATION USING 1ST-STAGE RANK NEAREST-NEIGHBOR RULE FOR MULTIPLE CLASSES	PATTERN RECOGNITION LETTERS			English	Article						BAYES RISK; MISCLASSIFICATION; RANK NEAREST NEIGHBOR; RISK BOUNDS		In this article, the first-stage rank nearest neighbor (RNN) rule is used to classify an unknown observation into one of the s (greater-than-or-equal-to 2) populations (or classes). We derive the asymptotic risk (i.e., the total probability of misclassification) (TPMC)) of this rule, which turns out to be exactly the same as the limiting risk of the 1-NN rule of Cover and Hart (1967) for s classes. The proposed estimate of the limiting TPMC of the first-stage RNN rule is shown to be asymptotically unbiased and consistent. Finally, Monte Carlo results are reported to learn the performance of the first-stage RNN rule in comparison with the 1-NN rule in a small sample situation.		BAGUI, SC (reprint author), UNIV W FLORIDA,DEPT MATH & STAT,PENSACOLA,FL 32514, USA.						ANDERSON TW, 1966, 1ST P INT S AN; BAGUI SC, 1989, THESIS U ALBERTA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1980, SANKHYA A, V42, P419; FIX E, 1952, 4 US AIR FORC SCH AV; Serfling R. J, 1980, APPROXIMATION THEORE	6	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL	1993	14	7					537	544		10.1016/0167-8655(93)90102-J		8	Computer Science, Artificial Intelligence	Computer Science	LL591	WOS:A1993LL59100002	
J	WU, FY; SLATER, JD; HONIG, LS; RAMSAY, RE				WU, FY; SLATER, JD; HONIG, LS; RAMSAY, RE			A NEURAL-NETWORK DESIGN FOR EVENT-RELATED POTENTIAL DIAGNOSIS	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						ELECTROENCEPHALOGRAM (EEG); EVENT-RELATED POTENTIAL (ERP); P300 LATENCY; MULTIPLE SCLEROSIS (MS); ARTIFICIAL NEURAL NETWORK (ANN); NEAREST NEIGHBOR (NN) CLASSIFICATION	MULTILAYER FEEDFORWARD NETWORKS; NONPARAMETRIC REGRESSION; P300; APPROXIMATION; DISEASE	Many diseases resulting in neuropsychological impairment show abnormalities by EEG (electroencephalogram) tests. However, EEG analysis is complicated by a wide spectrum of normal patterns. Cerebral evoked potentials are stimulus-induced, averaged EEG potentials that have been found useful in patients with dementing illness. A recent report using the P300 auditory evoked potential shows that simple latency and waveform criteria result in classification accuracy of 65% for multiple sclerosis (MS) patients versus 91% for control subjects. Analysis on the same data set was performed using an artificial neural network (ANN) and a nearest neighbor (NN) classifier. An ANN classifier demonstrated a classification accuracy of 75% versus 87% on MS and control subject groups. Thus prediction accuracy was improved on average, compared with that obtained by NN classifiers or P300 statistical analysis. The classification strategy discovered by a trained ANN was analyzed by a weight pattern analysis method and compared with the P300 latency criteria.	UNIV MIAMI,SCH MED,DEPT NEUROL,MIAMI,FL 33136; STANFORD UNIV,MED CTR,SCH MED,DEPT NEUROL & NEUROL SCI,STANFORD,CA 94305	WU, FY (reprint author), UNIV MIAMI,DEPT ELECT & COMP ENGN,POB 248294,CORAL GABLES,FL 33124, USA.		Ramsay, R. Eugene/D-4491-2011				APLSAN D, 1991, P IJCNN SINGAPORE, P1266; BARUAH AB, 1990, 1990 P IEEE ICNN, P383; CHAYASIRISOBHON S, 1985, CLIN ELECTROENCEPHAL, V161, P48; CHERKASSKY V, 1991, NEURAL NETWORKS, V4, P27, DOI 10.1016/0893-6080(91)90028-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EBERHART RC, 1990, NEURAL NETWORK PC TO, P215; GINDI GR, 1991, IEEE T BIO-MED ENG, V38, P246, DOI 10.1109/10.133205; GOODIN DS, 1987, ANN NEUROL, V21, P90, DOI 10.1002/ana.410210116; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; HOLDEN ADC, 1989, 1989 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-3, P2, DOI 10.1109/ICSMC.1989.71243; HONIG LS, 1992, ARCH NEUROL-CHICAGO, V49, P44; HONIG LS, 1986, NEUROLOGY, V36, P157; HORNIK K, 1990, NEURAL NETWORKS, V3, P551, DOI 10.1016/0893-6080(90)90005-6; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; KARKHANIS PA, 1990, INT J MICROCOMPUT AP, V9, P99; NEWTON MR, 1989, BRAIN, V112, P1636; PATTERSON JV, 1988, ELECTROEN CLIN NEURO, V71, P450, DOI 10.1016/0168-5597(88)90049-4; POLI R, 1991, COMPUTER         MAR, P64; POLICH J, 1988, J CLIN NEUROPHYSIOL, V5, P287, DOI 10.1097/00004691-198807000-00004; PRITCHARD WS, 1981, PSYCHOL BULL, V89, P506, DOI 10.1037//0033-2909.89.3.506; ROSENBERG C, 1985, ARCH NEUROL-CHICAGO, V42, P984; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, P319; SANGER TD, 1991, IEEE T NEURAL NETWOR, V2, P285, DOI 10.1109/72.80339; TOURETZKY DS, 1989, BYTE             AUG, P227; Tourtellotte W W, 1984, Acta Neurol Scand Suppl, V101, P32; Weiss SM, 1991, COMPUTER SYSTEMS LEA, P17; WHITE H, 1990, NEURAL NETWORKS, V3, P535, DOI 10.1016/0893-6080(90)90004-5; WU FY, 1992, MAR P ISMM C ORL, P14; WU FY, 1992, COMPUT BIOL MED, V22, P23, DOI 10.1016/0010-4825(92)90049-S	30	12	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0010-4825		COMPUT BIOL MED	Comput. Biol. Med.	MAY	1993	23	3					251	264		10.1016/0010-4825(93)90024-U		14	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	LH552	WOS:A1993LH55200005	
J	JANG, GS; DOWLA, F; VEMURI, V				JANG, GS; DOWLA, F; VEMURI, V			A COMPARISON OF NEURAL-NETWORK PERFORMANCE FOR SEISMIC PHASE IDENTIFICATION	JOURNAL OF THE FRANKLIN INSTITUTE-ENGINEERING AND APPLIED MATHEMATICS			English	Article								Traditional techniques of analysis and interpretation of seismic events involve a series of complex steps involving sophisticated signal processing as well as many manual tasks. Automating each of these steps is an important goal of this ongoing research. The paper discusses the use of neural networks in performing phase identification, namely the discrimination of distinct seismic waves within a seismogram. The scope is further restricted to the identification of only two of the regional principal phases, Pg and Lg, among the signals collected in the western United States. Using a database of 75 earthquakes and 75 underground nuclear explosions, the performance of several types of neural networks was compared. The performance of probabilistic neural network (PNN), radial basis function (RBF) network and learning vector quantization (LVQ) network is compared with a back-propagation network that combines the conjugate-gradient method with a weight-elimination strategy. The results indicate that the latter outperformed all other methods tested.	LAWRENCE LIVERMORE NATL LAB,LIVERMORE,CA 94550; UNIV CALIF DAVIS,LIVERMORE,CA 94550	JANG, GS (reprint author), UNIV CALIF DAVIS,DEPT ELECT & COMP ENGN,DAVIS,CA 95626, USA.						CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOWLA FU, 1990, B SEISMOL SOC AM, V80, P1346; Johansson E. M., 1991, International Journal of Neural Systems, V2, DOI 10.1142/S0129065791000261; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; MACQUEEN J, 1977, 5TH P BERK S MATH ST, P281; MOOD AM, 1962, INTRO THEORY STATIST; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Powell MJD, 1987, ALGORITHMS APPROXIMA, P143; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; TAYLOR S, 1990, ENERGY TECHNOLOGY RE, P28; Weigend AS, 1990, ADV NEURAL INFORMATI, V3, P875; 1988, MATLAB USERS GUIDE	14	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0016-0032		J FRANKLIN I	J. Frankl. Inst.-Eng. Appl. Math.	MAY	1993	330	3					505	524		10.1016/0016-0032(93)90096-D		20	Automation & Control Systems; Engineering, Multidisciplinary; Engineering, Electrical & Electronic; Mathematics, Interdisciplinary Applications	Automation & Control Systems; Engineering; Mathematics	LB384	WOS:A1993LB38400007	
J	CRECENTE, RP; LATORRE, CH				CRECENTE, RP; LATORRE, CH			PATTERN-RECOGNITION ANALYSIS APPLIED TO CLASSIFICATION OF HONEYS FROM 2 GEOGRAPHIC ORIGINS	JOURNAL OF AGRICULTURAL AND FOOD CHEMISTRY			English	Article							WINES	Eleven legal parameters of quality control of honey were determined in 67 honey samples from Galicia (northwestern Spain) which were obtained from two production areas: Lugo and Orense. Classification of these honeys according to their geographic origin was achieved by pattern recognition techniques to the chemical data. Humidity and free acidity were found to be the most important features for the classification. In this case the use of pollen data to achieve a correct geographic classification of the honey samples is not necessary.	FAC CIENCIAS LUGO,DEPT QUIM ANAL NUTR & BROMATOL,AUGAS FERREAS S-N,E-27002 LUGO,SPAIN							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERDE MP, 1984, J ASSOC OFF ANA CHEM, V18, P49; ETIEVANT P, 1988, J SCI FOOD AGR, V45, P21; Forina M, 1988, PARVUS EXTENDABLE PA; FORINA M, 1984, CHEMOMETRICS MATH ST; HERRERO-LATORRE C, 1990, Connaissance de la Vigne et du Vin, V24, P147; HERRERO C, 1992, CONNAISS VIGNE VIN, V26, P185; HUIDOBRO JF, 1983, THESIS U SANTIAGO CO; KWAN WO, 1980, J AGR FOOD CHEM, V28, P356, DOI 10.1021/jf60228a029; KWAN WO, 1978, J FOOD SCI, V43, P1320, DOI 10.1111/j.1365-2621.1978.tb15299.x; Kwan W., 1980, Analytica Chimica Acta, V122, P215, DOI 10.1016/S0003-2670(01)83881-2; MAARSE H, 1987, Z LEBENSM UNTERS FOR, V184, P198, DOI 10.1007/BF01042207; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; BAYER S, 1980, J AGR FOOD CHEM, V28, P1306, DOI 10.1021/jf60232a064; ROMEDER JM, 1973, METHODES PROGRAMMES; SANCHO MT, 1990, THESIS U SANTIAGO CO; Saxberg B. E. H., 1978, Analytica Chimica Acta, V103, P201, DOI 10.1016/S0003-2670(01)84039-3; VANDERSCHEE HA, 1989, Z LEBENSM UNTERS FOR, V188, P324; VASCONCELOS AMP, 1989, J AGR FOOD CHEM, V37, P931, DOI 10.1021/jf00088a023; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; [Anonymous], 1990, OFFICIAL METHODS ANA, P780; 1986, B OFICIAL ESTADO; 1987, STATGRAPHICS USERS G	23	18	19	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0021-8561		J AGR FOOD CHEM	J. Agric. Food Chem.	APR	1993	41	4					560	564				5	Agriculture, Multidisciplinary; Chemistry, Applied; Food Science & Technology	Agriculture; Chemistry; Food Science & Technology	KY528	WOS:A1993KY52800011	
J	NEIFELD, MA; PSALTIS, D				NEIFELD, MA; PSALTIS, D			OPTICAL IMPLEMENTATIONS OF RADIAL BASIS CLASSIFIERS	APPLIED OPTICS			English	Article							MEMORY DISKS; NETWORKS	We describe two optical systems based on the radial basis function approach to pattern classification. An optical-disk-based system for handwritten character recognition is demonstrated. The optical system computes the Euclidean distance between an unknown input and 650 stored patterns at a demonstrated rate of 26,000 pattern comparisons/s. The ultimate performance of this system is limited by optical-disk resolution to 1011 binary operations/s. An adaptive system is also presented that facilitates on-line learning and provides additional robustness.	CALTECH, DEPT ELECT ENGN, PASADENA, CA 91125 USA	NEIFELD, MA (reprint author), UNIV ARIZONA, DEPT ELECT & COMP ENGN, TUCSON, AZ 85721 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRABIK TJ, 1990, APPL OPTICS, V29, P5220, DOI 10.1364/AO.29.005220; DUDA R, 1973, PATTERN CLASSIFICATI, P141; JARED DA, 1990, OPT COMMUN, V76, P97, DOI 10.1016/0030-4018(90)90300-I; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; NEIFELD MA, 1991, P SOC PHOTO-OPT INS, V1469, P250, DOI 10.1117/12.44963; NEIFELD MA, 1990, P SOC PHOTO-OPT INS, V1347, P4, DOI 10.1117/12.23389; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Poggio T., 1989, AI1140 MIT ART INT L; PSALTIS D, 1990, APPL OPTICS, V29, P2038, DOI 10.1364/AO.29.002038; PSALTIS D, 1989, OPT LETT, V14, P429, DOI 10.1364/OL.14.000429; PSALTIS D, 1988, APPL OPTICS, V27, P1752, DOI 10.1364/AO.27.001752; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318	14	10	10	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	0003-6935		APPL OPTICS	Appl. Optics	MAR 10	1993	32	8					1370	1379				10	Optics	Optics	KT614	WOS:A1993KT61400014	
J	POSTAIRE, JG; ZHANG, RD; LECOCQBOTTE, C				POSTAIRE, JG; ZHANG, RD; LECOCQBOTTE, C			CLUSTER-ANALYSIS BY BINARY MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BINARY MORPHOLOGY; CLUSTER ANALYSIS; DILATION; EROSION; UNSUPERVISED CLASSIFICATION		A new approach to unsupervised pattern classification, which is based on the use of mathematical morphology operations, is developed. The way a set of multidimensional observations can be represented as a mathematical discrete binary set is shown. Clusters are then detected as well separated subsets by means of binary morphological transformations.		POSTAIRE, JG (reprint author), UNIV LILLE 1,CTR AUTOMAT,F-59655 VILLENEUVE DASCQ,FRANCE.						BALL G, 1965, AD699616; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Duda R., 1973, PATTERN CLASSIFICATI; DYNOC JTT, 1979, INT J COMPUT INF SCI, V8, P541; GOLDER PA, 1973, APPL STAT, V22, P213, DOI 10.2307/2346922; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532; MacQueen J., 1967, 5 BERK S MATH STAT P, P281; MATHERON G, 1985, RANDOM SETS INTEGRAL; Minkowski H, 1903, MATH ANN, V57, P447, DOI 10.1007/BF01445180; NARENDRA PM, 1978, P IEEE C PATT RECOGN; POSTAIRE JG, 1985, FOREST SCI, V31, P53; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163; Serra J., 1982, IMAGE ANAL MATH MORP; TOUZANI A, 1988, IEEE T PATTERN ANAL, V10, P970, DOI 10.1109/34.9120	16	43	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					170	180		10.1109/34.192490		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	KL910	WOS:A1993KL91000009	
J	HICKEY, RJ; BAIRD, BW				HICKEY, RJ; BAIRD, BW			AN EVALUATION OF IB3 USING ARTIFICIAL UNIVERSES	IRISH JOURNAL OF PSYCHOLOGY			English	Article; Proceedings Paper	1993 Artificial Intelligence and Cognitive Science Conference	1993	BELFAST, NORTH IRELAND		QUEENS UNIV					HICKEY, RJ (reprint author), UNIV ULSTER,DEPT COMP SCI,COLERAINE BT52 1SA,LONDONDERRY,NORTH IRELAND.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HICKEY RJ, 1992, 9TH INT C MACH LEARN, P196; HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037//0033-295X.93.4.411; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877	7	0	0	PSYCHOLOGICAL SOC IRELAND	DUBLIN	TRINITY COLLEGE DEPT PSYCHOLOGY 25 WESTLAND ROW, DUBLIN 2, IRELAND	0303-3910		IRISH J PSYCHOL	Irish J. Psychol.		1993	14	3					510	511				2	Psychology	Psychology	MV534	WOS:A1993MV53400027	
J	COST, S; SALZBERG, S				COST, S; SALZBERG, S			A WEIGHTED NEAREST NEIGHBOR ALGORITHM FOR LEARNING WITH SYMBOLIC FEATURES	MACHINE LEARNING			English	Article						NEAREST NEIGHBOR; EXEMPLAR-BASED LEARNING; PROTEIN STRUCTURE, TEXT PRONUNCIATION, INSTANCE-BASED LEARNING	SECONDARY-STRUCTURE; PATTERN-RECOGNITION; GLOBULAR PROTEINS; CONTEXT THEORY; PREDICTION; CLASSIFICATION	In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. in such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in domains with symbolic features. Our algorithm calculates distance tables that allow it to produce real-valued distances between instances. and attaches weights to the instances to further modify the structure of feature space. We show that this technique produces excellent classification accuracy on three problems that have been studied by machine learning researchers: predicting protein secondary structure, identifying DNA promoter sequences, and pronouncing English text. Direct experimental comparisons with the other learning algorithms show that our nearest neighbor algorithm is comparable or superior in all three domains. In addition, our algorithm has advantages in training speed, simplicity, and perspicuity. We conclude that experimental evidence favors the use and continued development of nearest neighbor algorithms for domains such as the ones studied here.		COST, S (reprint author), JOHNS HOPKINS UNIV,DEPT COMP SCI,BALTIMORE,MD 21218, USA.		Salzberg, Steven/F-6162-2011				AHA D, 1990, 9042 U CAL DEP INF C; AHA DW, 1989, 6TH P INT WORKSH MAC, P387; AHA DW, 1989, 11TH P INT JOINT C A, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Chou P Y, 1978, Adv Enzymol Relat Areas Mol Biol, V47, P45; CHOU PY, 1974, BIOCHEMISTRY-US, V13, P222, DOI 10.1021/bi00699a002; COHEN FE, 1986, BIOCHEMISTRY-US, V25, P266, DOI 10.1021/bi00349a037; COST S, 1990, P S COMPUTER APPLICA, P114; COST S, 1990, THESIS J HOPKINS U; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crick F., 1986, PARALLEL DISTRIBUTED, V2; DIETTERICH TG, 1990, 7TH P INT C MACH LEA, P24; FERTIG S, 1991, 12TH P INT JOINT C A, P796; Fisher D.H., 1989, 11TH P INT JOINT C A, P788; GARNIER J, 1978, J MOL BIOL, V120, P97, DOI 10.1016/0022-2836(78)90297-8; HANSON SJ, 1990, BEHAV BRAIN SCI, V13, P471; HOLLEY LH, 1989, P NATL ACAD SCI USA, V86, P152, DOI 10.1073/pnas.86.1.152; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; KONTOGIORGIS S, 1988, JHU8822 J HOPK U DEP; LATHROP RH, 1987, COMMUN ACM, V30, P909, DOI 10.1145/32206.32207; LIM VI, 1974, J MOL BIOL, V88, P873, DOI 10.1016/0022-2836(74)90405-7; Mathews B.W., 1975, BIOCHIM BIOPHYS ACTA, V405, P442; McClelland JL, 1986, PARALLEL DISTRIBUTED, V2; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MOONEY R, 1989, 11TH IJCAI 89 INT JO, P775; NOSOFSKY RM, 1984, J EXP PSYCHOL LEARN, V10, P104, DOI 10.1037/0278-7393.10.1.104; ONEILL MC, 1989, J BIOL CHEM, V264, P5522; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; REED SK, 1972, COGNITIVE PSYCHOL, V3, P382, DOI 10.1016/0010-0285(72)90014-X; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALZBERG S, 1989, ANALOGICAL INDUCTIVE; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SALZBERG SL, 1990, LEARNING NESTED GENE; SEJNOWSKI T, JHUEECS8601 J HOPK U; Sejnowski T. J., 1987, Complex Systems, V1; SHAVLIK J, 1989, 57 U WISC COMP SCI D; SIGILLITO V, 1989, COMMUNICATION; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOWELL GG, 1990, 8TH P NAT C ART INT, P861; WALTZ D, 1990, 8TH P NAT C ART INT, P1117; WEISS S, 1989, 11TH IJCAI 89 INT JO, P781	44	240	248	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JAN	1993	10	1					57	78		10.1007/BF00993481		22	Computer Science, Artificial Intelligence	Computer Science	KL354	WOS:A1993KL35400002	
J	CORNE, SA; JOHNSON, AP; FISHER, J				CORNE, SA; JOHNSON, AP; FISHER, J			AN ARTIFICIAL NEURAL NETWORK FOR CLASSIFYING CROSS PEAKS IN 2-DIMENSIONAL NMR-SPECTRA	JOURNAL OF MAGNETIC RESONANCE			English	Article							AUTOMATIC RECOGNITION; H-1-NMR SPECTRA			CORNE, SA (reprint author), UNIV LEEDS,SCH CHEM,MAXWELL INST COMP APPLICAT MOLEC SCI,LEEDS LS2 9JT,W YORKSHIRE,ENGLAND.						Beale R, 1990, NEURAL COMPUTING INT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAYHOFF JE, 1990, NEURAL NETWORK ARCH; GARRETT DS, 1991, J MAGN RESON, V95, P214, DOI 10.1016/0022-2364(91)90341-P; GLASER S, 1987, J MAGN RESON, V74, P450, DOI 10.1016/0022-2364(87)90267-8; GRAHN H, 1988, J MAGN RESON, V77, P394; KJAER M, 1991, J MAGN RESON, V94, P659; KLEYWEGT GJ, 1990, J MAGN RESON, V88, P601, DOI 10.1016/0022-2364(90)90291-G; McClelland J. L, 1986, PARALLEL DISTRIBUTED, V1; NEIDIG KP, 1984, BIOCHEM BIOPH RES CO, V125, P1143, DOI 10.1016/0006-291X(84)91403-7; PFANDLER P, 1988, MAGN RESON CHEM, V26, P888, DOI 10.1002/mrc.1260261014; STOVEN V, 1989, J MAGN RESON, V82, P163, DOI 10.1016/0022-2364(89)90177-7; THOMSEN JU, 1989, J MAGN RESON, V84, P212, DOI 10.1016/0022-2364(89)90021-8; Wasserman P.D., 1989, NEURAL COMPUTING; WYTHOFF BJ, 1990, ANAL CHEM, V62, P2702, DOI 10.1021/ac00223a011	15	18	19	ACADEMIC PRESS INC JNL-COMP SUBSCRIPTIONS	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495	0022-2364		J MAGN RESON	J. Magn. Reson.	NOV	1992	100	2					256	266		10.1016/0022-2364(92)90260-E		11	Biochemical Research Methods; Physics, Atomic, Molecular & Chemical; Spectroscopy	Biochemistry & Molecular Biology; Physics; Spectroscopy	JY558	WOS:A1992JY55800003	
J	PAZZANI, MJ; SARRETT, W				PAZZANI, MJ; SARRETT, W			A FRAMEWORK FOR AVERAGE CASE ANALYSIS OF CONJUNCTIVE LEARNING ALGORITHMS	MACHINE LEARNING			English	Article						AVERAGE-CASE ANALYSIS; COMBINING EMPIRICAL AND ANALYTICAL LEARNING		We present an approach to modeling the average case behavior of learning algorithms. Our motivation is to predict the expected accuracy of learning algorithms as a function of the number of training examples. We apply this framework to a purely empirical learning algorithm, (the one-sided algorithm for pure conjunctive concepts), and to an algorithm that combines empirical and explanation-based learning. The model is used to gain insight into the behavior of these algorithms on a series of problems. Finally, we evaluate how well the average case model performs when the training examples violate the assumptions of the model.		PAZZANI, MJ (reprint author), UNIV CALIF IRVINE,DEPT INFORMAT & COMP SCI,IRVINE,CA 92717, USA.						Atkinson R.C., 1965, INTRO MATH LEARNING; BENEDEK G, 1987, 1988 P WORKSH COMP L, P81; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Bruner J. S., 1956, STUDY THINKING; BUNTINE W, 1989, 11TH P JOINT C ART I, P837; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dejong G., 1986, Machine Learning, V1, DOI 10.1023/A:1022898111663; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; HAUSSLER D, 1990, USCSCRL9054 U CAL TE; HAUSSLER D, 1987, 8TH P NAT C ART INT, P564; HAUSSLER D, 1990, 8 AAAI NAT C ART INT, P1101; HEMBOLD D, 1990, MACH LEARN, V5, P165; HIRSCHBERG D, 1992, 9TH P INT MACH LEARN, P206; HIRSH H, 1989, 6TH P INT WORKSH MAC, P29; KEARNS M, 1987, 19TH P ACM S THEOR C, P285; KIBLER D, 1988, 3RD P EUR WORK SESS, P63; LANGLEY P, 1989, MACHINE LEARNING, V3; MINTON S, 1988, 7TH P NAT C ART INT, P564; Mitchell T. M., 1986, Machine Learning, V1, DOI 10.1007/BF00116250; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; NATARAJAN B, 1987, 19TH P ANN ACM S THE, P295; OBLOW E, 1991, MACHINE LEARNING, V8; PAZZANI M, 1989, 6TH P INT WORKSH MAC, P72; RESTLE F, 1959, STUDIES MATH LEARNIN, P415; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SARRETT W, 1989, AVERAGE CASE ANAL EM; SARRETT W, 1989, 6TH P INT WORKSH MAC, P26; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Winer B. J., 1971, STATISTICAL PRINCIPL	30	10	10	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	OCT	1992	9	4					349	372		10.1007/BF00994111		24	Computer Science, Artificial Intelligence	Computer Science	JQ511	WOS:A1992JQ51100003	
J	BEZDEK, JC				BEZDEK, JC			COMPUTING WITH UNCERTAINTY	IEEE COMMUNICATIONS MAGAZINE			English	Article							IMAGE SEGMENTATION; FUZZY-SETS; ALGORITHM; CLASSIFICATION; PROBABILITY; SYSTEMS; VISION			BEZDEK, JC (reprint author), UNIV W FLORIDA,DIV COMP SCI,PENSACOLA,FL 32514, USA.						BEZDEK JC, 1985, IEEE T SYST MAN CYB, V15, P637; BACKER E, 1981, IEEE T PATTERN ANAL, P66; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BELLMAN R, 1966, J MATH ANAL APPL, V13, P1, DOI 10.1016/0022-247X(66)90071-0; Berenji H. R., 1992, International Journal of Approximate Reasoning, V6, DOI 10.1016/0888-613X(92)90020-Z; BEZDEK, 1990, P INT C FUZZY LOGIC, P575; BEZDEK ECK, 1992, 1ST P IEEE C FUZZY S, P1035; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK J, 1983, FUZZY SETS SYSTEMS, V1, P237; Bezdek J. C., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90012-X; BEZDEK JC, 1975, IEEE T COMPUT, V24, P835, DOI 10.1109/T-C.1975.224317; BEZDEK JC, 1977, IEEE T SYST MAN CYB, V7, P87, DOI 10.1109/TSMC.1977.4309659; BEZDEK JC, 1988, COMPUT VISION GRAPH, V41, P186, DOI 10.1016/0734-189X(88)90019-9; Bezdek J.C., 1992, FUZZY MODELS PATTERN; Bezdek J.C., 1974, J CYBERNETICS, V3, P58; BEZDEK JC, 1991, PATTERN RECOGN, V24, P783; CANNON RL, 1986, IEEE T GEOSCI REMOTE, V24, P400, DOI 10.1109/TGRS.1986.289598; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; CHEESEMAN P, 1988, COMPUT INTELL, V4, P57; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; DAVE RN, 1990, INT J GEN SYST, V16, P343, DOI 10.1080/03081079008935087; Devijver P. A., 1982, PATTERN RECOGNITION; DIGESU V, 1986, PATTERN RECOGN, V9, P63; Duda R., 1973, PATTERN CLASSIFICATI; Dunn J., 1974, J CYBERNETICS, V3, P32; DUNN JC, 1974, IEEE T SYST MAN CYB, VSMC4, P310; Gustafson E. E., 1979, P IEEE CDC SAN DIEG, P761; HALL LO, 1991, P N AM FUZZ INF PROC, P329; HATHAWAY R, 1986, COMM STAT, V5, P505; Hertz J., 1991, INTRO THEORY NEURAL; HUNTSBERGER T, 1990, INT J GENERAL SYS, P357; HUNTSBERGER TL, 1986, IEEE T COMPUT, V35, P145; HUNTSBERGER TL, 1985, PATTERN RECOGN, V18, P131, DOI 10.1016/0031-3203(85)90036-6; Jain A., 1988, ALGORITHMS CLUSTERIN; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; Kandel A, 1982, FUZZY TECHNIQUES PAT; KELLER, 1992, INT J APPROX REASONI, V6, P221; KELLER JM, 1987, IEEE T SYST MAN CYB, V17, P676, DOI 10.1109/TSMC.1987.289360; KELLER JM, 1985, IEEE T PATTERN ANAL, V7, P693; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Klir G.J., 1988, FUZZY SETS UNCERTAIN; KOHONEN, 1989, SELF ORG ASS MEMORY; KOSKO B, 1990, INT J GEN SYST, V17, P211, DOI 10.1080/03081079008935108; KRISHNAPURAM R, 1991, P SPIE C INT ROB COM, V10, P458; LEE CC, 1990, IEEE T SYST MAN CYB, V20, P404, DOI 10.1109/21.52551; LEE S C, 1975, Mathematical Biosciences, V23, P151, DOI 10.1016/0025-5564(75)90125-X; LIM YW, 1990, PATTERN RECOGN, V23, P935; LINDLEY DV, 1982, INT STAT REV, V50, P1, DOI 10.2307/1402448; Lippmann R. P., 1987, IEEE ASSP MAGAZI APR, P4; Pal S. K, 1986, FUZZY MATH APPROACH; PAL SK, 1986, IEEE T SYST MAN CYB, V16, P754, DOI 10.1109/TSMC.1986.289321; Pao Y. H., 1989, ADAPTIVE PATTERN REC; PEDRYCZ W, 1991, IEEE T PATTERN ANAL, V13, P289, DOI 10.1109/34.75517; Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; Sneath P.H.A., 1973, NUMERICAL TAXONOMY P; TITTERINGTON DM, 1985, STATISTICAL ANAL FIN; TRIVEDI M, 1986, IEEE T SYST MAN CYB, V16, P580; Werbos P. J., 1992, International Journal of Approximate Reasoning, V6, DOI 10.1016/0888-613X(92)90017-T; WINDHAM MP, 1982, IEEE T PATTERN ANAL, V4, P357; WINDHAM MP, 1985, J CLASSIF, V2, P157, DOI 10.1007/BF01908073; Xie X.L., 1991, IEEE T PAMI, V3, P841; ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	65	14	14	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0163-6804		IEEE COMMUN MAG	IEEE Commun. Mag.	SEP	1992	30	9					24	36		10.1109/35.156801		13	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	JM711	WOS:A1992JM71100005	
J	SIMPSON, PK				SIMPSON, PK			FUZZY MIN MAX NEURAL NETWORKS .1. CLASSIFICATION	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Note							ALGORITHM	A supervised learning neural network classifier that utilizes fuzzy sets as pattern classes is described. Each fuzzy set is an aggregate (union) of fuzzy set hyperboxes. A fuzzy set hyperbox is an n-dimensional box defined by a min point and a max point with a corresponding membership function. The min-max points are determined using the fuzzy min-max learning algorithm, an expansion-contraction process that can learn nonlinear class boundaries in a single pass through the data and provides the ability to incorporate new and refine existing classes without retraining. The use of a fuzzy set approach to pattern classification inherently provides degree of membership information that is extremely useful in higher level decision making. This paper will describe the relationship between fuzzy sets and pattern classification. It explains the fuzzy min-max classifier neural network implementation, it outlines the learning and recall algorithms, and it provides several examples of operation that demonstrate the strong qualities of this new neural network classifier.		SIMPSON, PK (reprint author), ORINCON CORP,9363 TOWNE CTR DR,SAN DIEGO,CA 92121, USA.						BELLMAN R, 1964, RM4307PR RAND MEM; BELLMAN R, 1966, J MATH ANAL APPL, V13, P1, DOI 10.1016/0022-247X(66)90071-0; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK J, 1991, AUG IEEE C NEUR NETW; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; BEZDEK JC, 1987, NATO ASI SERIES G, V14; Broomhead D. S., 1988, Complex Systems, V2; CARPENTER G, NEURAL NETWORKS, V4, P565; CARPENTER GA, 1991, 1991 P INT JOINT C N, V2, P411; COTTER N, 1991, IEEE T NEURAL NETWOR, V1, P290; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DUBOIS D, 1985, INFORM SCIENCES, V36, P85, DOI 10.1016/0020-0255(85)90027-1; Duda R., 1973, PATTERN CLASSIFICATI; FAHLMAN SE, 1990, CMUCS90100 CARN U SC; Fisher RA, 1936, ANN EUGENIC, V7, P179; FU S, 1971, SOIFTWARE ENG, V2, P155; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GRANATH G, 1984, J INT ASS MATH GEOL, V16, P283, DOI 10.1007/BF01032692; GROSSBERG S, 1980, PSYCHOL REV, V87, P1; HO YC, 1965, IEEE TRANS ELECTRON, VEC14, P683, DOI 10.1109/PGEC.1965.264206; HUNTSBERGER TL, 1990, INT J GEN SYST, V16, P357, DOI 10.1080/03081079008935088; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; Kandel A., 1986, FUZZY MATH TECHNIQUE; KELLER JM, 1985, IEEE T PATTERN ANAL, V7, P693; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KENNEDY R, 1991, P WNN AIND 91, P241; Kohonen T., 1984, SELF ORG ASS MEMORY; LEE S C, 1975, Mathematical Biosciences, V23, P151, DOI 10.1016/0025-5564(75)90125-X; Minsky M., 1969, PERCEPTRONS; MITRA S, IN PRESS IEEE T SYST; MOORE B, 1988 P CONN SUMM SCH, P174; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SIMPSON P, 1990, SEP SO ILL U NEUR WO; SIMPSON P, UNPUB IEEE T FUZZY S; SIMPSON P, 1990, NOV P GD AI90 FT WOR; SIMPSON P, 1991 P INT JOINT C N; SIMPSON PK, 1991, HEURISTICS J KNOWLED, V4, P1; Simpson PK, 1990, ARTIFICIAL NEURAL SY; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STREIT R, IN PRESS IEEE T NEUR; Wee WG, 1967, THESIS PURDUE U LAFA; WERBOS P, IN PRESSS INT J APPR; Werbos P., 1974, THESIS HARVARD U CAM; Widrow B., 1960, IRE WESCON CONV RE 4, P96; YAGER RR, 1979, INT J MAN MACH STUD, V11, P189, DOI 10.1016/S0020-7373(79)80016-4; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	51	382	395	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	SEP	1992	3	5					776	786		10.1109/72.159066		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	JQ506	WOS:A1992JQ50600013	
J	JAROMCZYK, JW; TOUSSAINT, GT				JAROMCZYK, JW; TOUSSAINT, GT			RELATIVE NEIGHBORHOOD GRAPHS AND THEIR RELATIVES	PROCEEDINGS OF THE IEEE			English	Review						COMPUTATIONAL GEOMETRY; COMPUTATIONAL MORPHOLOGY; GEOMETRIC GRAPHS; NEIGHBORHOOD GRAPHS; SPATIAL ANALYSIS	COMPARING DISSIMILARITY MATRICES; LINEAR-TIME ALGORITHM; VORONOI DIAGRAMS; EUCLIDEAN PLANE; SET; GEOMETRY; POINTS	This is a survey of results on neighborhood graphs. The paper discusses properties, bounds on the size, algorithms, and variants of the neighborhood graphs. Numerous applications including computational morphology, spatial analysis, pattern classification, and data bases for computer vision are described. A rich bibliography of the subject concludes the paper.	MCGILL UNIV, SCH COMP SCI, MONTREAL H3A 2A7, QUEBEC, CANADA	JAROMCZYK, JW (reprint author), UNIV KENTUCKY, DEPT COMP SCI, LEXINGTON, KY 40506 USA.						AGARWAL PK, IN PRESS COMPUTATION; AGARWAL PK, 1992, 3RD P ANN S DISCR AL, P58; AGARWAL PK, 1990, 6TH P ANN ACM S COMP, P203; ASH FP, 1985, GEOMETRIAE DEDICATA, V19, P175; AURENHAMMER F, 1991, COMPUT SURV, V23, P345; AURENHAMMER F, 1988, J ALGORITHM, V9, P151, DOI 10.1016/0196-6774(88)90035-1; Avis D, 1985, DISCRETE GEOMETRY CO, P323; Bateman P., 1951, AM MATH MONTHLY, V58, P306, DOI 10.2307/2307717; BENTLEY JL, 1979, IEEE T COMPUT, V28, P643; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Boland J.W., 1987, C NUMERANTIUM, V58, P151; CHANG M, 1991, ALGORITHMICA; CHANG MS, 1992, DISCRETE APPL MATH, V39, P1, DOI 10.1016/0166-218X(92)90111-M; CHANG MS, 1990, LECT NOTES COMPUT SC, V450, P53; CHAZELLE B, 1990, 6TH P ACM S COMP GEO, P116; CHAZELLE B, 1990, 6TH P ACM S COMP GEO, P23; CHAZELLE B, 1986, SIAM J COMPUT, V15, P703, DOI 10.1137/0215051; CLARKSON KL, 1989, 29TH P ANN S F COMP, P568; CLARKSON KL, 1990, DISCRETE COMPUT GEOM, V5, P99, DOI 10.1007/BF02187783; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEARHOLT DW, 1987, 21ST P AS C SIGN SYS, P859; DEARHOLT DW, 1988, 22ND P AS C SIGN SYS, P548; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1988, COMPUT MATH APPL, V15, P53, DOI 10.1016/0898-1221(88)90071-5; DODGE CW, 1972, EUCLIDEAN GEOMETRY T; Dunham W., 1990, JOURNEY GENIUS GREAT; DWYER RA, 1988, THESIS CARNEGIEMELLO; EDELSBRUNNER H, 1983, IEEE T INFORM THEORY, V29, P551, DOI 10.1109/TIT.1983.1056714; EDELSBRUNNER H, 1991, QUADRATIC TIME ALGOR; EDELSBRUNNER H, 1992, UNPUB 3 DIMENSIONAL; Edelsbrunner H., 1987, ALGORITHMS COMBINATO; EDELSBRUNNER H, 1989, THEOR COMPUT SCI, V66, P157, DOI 10.1016/0304-3975(89)90133-3; EDELSBRUNNER H, 1990, LECT NOTES COMPUT SC, V450, P419; EDELSBRUNNER H, 1985, J ALGORITHM, V6, P515, DOI 10.1016/0196-6774(85)90030-6; ELGINDY HA, 1988, COMPUTATIONAL MORPHO, P53; FAIRFIELD J, 1983, IEEE T PATTERN ANAL, P104; Fairfield J., 1979, Proceedings of the International Conference on Cybernetics and Society; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; GABOW HN, 1985, J COMPUT SYST SCI, V30, P209, DOI 10.1016/0022-0000(85)90014-5; Gabow H.N., 1984, 16 ANN ACM S THEOR C, P135; GABRIEL KR, 1969, SYST ZOOL, V18, P259, DOI 10.2307/2412323; Getis A., 1978, MODELS SPATIAL PROCE; GUIBAS L, 1992, UNPUB GENERALIZED SP; GUIBAS LJ, 1983, INFORM PROCESS LETT, V17, P219, DOI 10.1016/0020-0190(83)90045-5; GUTTING RH, 1985, 1ST P ANN ACM S COMP, P81; HARARY F, 1990, UNPUB SPHERE OF INFL; HWANG NF, 1990, BIT, V30, P196; ICHINO M, 1985, PATTERN RECOGN, V18, P161, DOI 10.1016/0031-3203(85)90040-8; IMAI H, 1985, SIAM J COMPUT, V14, P93, DOI 10.1137/0214006; JACOBSON MS, 1989, TREES ARE SPHERE OF; JAROMCZYK JW, 1991, DISCRETE APPL MATH, V31, P181, DOI 10.1016/0166-218X(91)90069-9; JAROMCZYK JW, IN PRESS SIAM J COMP; JAROMCZYK JW, 1987, 3RD P ACM S COMP GEO, P233; KATAJAINEN J, 1988, COMPUTING, V40, P147, DOI 10.1007/BF02247943; KATAJAINEN J, 1987, RAIRO-INF THEOR APPL, V21, P199; KATAJAINEN J, 1986, PATTERN RECOGN, V19, P221, DOI 10.1016/0031-3203(86)90012-9; KATAJAINEN J, 1987, THESIS U TURKU FINLA; KATAJAINEN J, 1987, INFORM PROCESS LETT, V25, P77, DOI 10.1016/0020-0190(87)90225-0; KENNEDY JM, 1978, PERCEPTION, P191; Kirkpatrick D., 1985, COMP GEOM-THEOR APPL, P217; KLINSCEK GT, 1980, ANN DISCRETE MATH, P121; KURUP G, 1991, THESIS NEW MEXICO ST; LANKFORD PM, 1969, GEOGR ANAL, V1, P196; LAWROR R, 1982, SACRED GEOMETRY PHIL; LEE DT, 1985, PATTERN RECOGN, V18, P327, DOI 10.1016/0031-3203(85)90023-8; LEE DT, 1980, J ACM, V27, P604, DOI 10.1145/322217.322219; Lee D. T., 1977, SIAM Journal on Computing, V6, DOI 10.1137/0206043; LEE DT, 1991, 1ST P WORKSH PROX GR, P57; LEFKOVITCH LP, 1985, MATH BIOSCI, V73, P71, DOI 10.1016/0025-5564(85)90077-X; LEFKOVITCH LP, 1987, NATO ASI SERIES G, V14, P309; LEFKOVITCH LP, 1984, AM NAT, V123, P484, DOI 10.1086/284218; MADEK V, 1981, COMPUTER GRAPHICS IM, V15, P93; MARR D, 1976, PHILOS T ROY SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; Matheron G., 1975, RANDOM SETS INTEGRAL; MATULA DW, 1980, GEOGR ANAL, V12, P205; MAUS A, 1984, BIT, V24, P151, DOI 10.1007/BF01937482; MILES R E, 1970, Mathematical Biosciences, V6, P85, DOI 10.1016/0025-5564(70)90061-1; MOSS WW, 1967, SYST ZOOL, V16, P177, DOI 10.2307/2412066; OLARIU S, 1989, INFORM PROCESS LETT, V31, P243, DOI 10.1016/0020-0190(89)90081-1; OROURKE J, 1982, PATTERN RECOGN, P45; OVERMARS MH, 1988, 4THH P ACM S COMP GE, P164; PERNUS F, 1988, PATTERN RECOGN LETT, V8, P197, DOI 10.1016/0167-8655(88)90099-2; PREPARATA F, 1986, COMPUTATIONAL GEOMET; RADKE JD, 1988, COMPUTATIONAL MORPHO, P105; REINFERBERG ER, 1948, MATH GAZ, V32, P290; ROSENBERG B, 1973, PERCEPTION, P415; ROTE G, 1988, THESIS TU GRAZ AUSTR; SAITO T, 1991, FORMA, V6, P9; SENDOV B, 1991, CR HEBD ACAD SCI, V44, P23; Serra J., 1982, IMAGE ANAL MATH MORP; SMITH WS, 1989, THESIS PRINCETON U; SU TH, 1990, LECT NOTES COMPUT SC, V450, P66; SU TH, 1991, PATTERN RECOGN, V24, P231, DOI 10.1016/0031-3203(91)90065-D; SU TH, 1991, COMPUTING, V46, P121, DOI 10.1007/BF02239166; SU TH, 1991, PATTERN RECOGN, V24, P221, DOI 10.1016/0031-3203(91)90064-C; SUPOWIT KJ, 1983, J ACM, V30, P428, DOI 10.1145/2402.322386; Tarjan RE, 1983, DATA STRUCTURES NETW; TORIWAKI J, 1988, COMPUTATIONAL MORPHO, P207; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TOUSSAINT GT, 1988, COMPUTATIONAL MORPHO, P229; TOUSSAINT GT, 1980, OCT P ALL C, P20; TOUSSAINT GT, 1984, P COMPUTER SCI STATI, V16, P14; TOUSSAINT GT, 1980, 5TH P S OP RES KOLN, P425; TOUSSAINT GT, 1985, 1ST P INT S SCI FORM, P395; TOUSSAINT GT, 1991, 1ST P WORKSH PROX GR; URQUHART RB, 1983, PATTERN RECOGN, P317; URQUHART RB, 1980, ELECTRON LETT, V14, P556; VAIDYA PM, 1989, DISCRETE COMPUT GEOM, V4, P101, DOI 10.1007/BF02187718; VELTKAMP RC, 1990, GAMMA NEIGHBORHOOD G; WEE YC, 1989, 898 U ALB DEP COMP T; WILLARD DE, 1985, SIAM J COMPUT, V14, P232, DOI 10.1137/0214019; YAO ACC, 1982, SIAM J COMPUT, V11, P721, DOI 10.1137/0211059; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	114	237	239	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9219		P IEEE	Proc. IEEE	SEP	1992	80	9					1502	1517		10.1109/5.163414		16	Engineering, Electrical & Electronic	Engineering	JW646	WOS:A1992JW64600010	
J	CREECY, RH; MASAND, BM; SMITH, SJ; WALTZ, DL				CREECY, RH; MASAND, BM; SMITH, SJ; WALTZ, DL			TRADING MIPS AND MEMORY FOR KNOWLEDGE ENGINEERING	COMMUNICATIONS OF THE ACM			English	Article						AUTOMATED SYSTEM BUILDING; CASE-BASED REASONING; EMPIRICAL LEARNING; MEMORY-BASED REASONING; TEXTUAL DATABASE CLASSIFICATION			THINKING MACHINES CORP,245 1ST ST,CAMBRIDGE,MA 02142; US BUR CENSUS,DIV STAT RES 3215-4,INTEGRATED STAT LAB,WASHINGTON,DC 20233; THINKING MACHINES CORP,ADV INFORMAT SYST,CAMBRIDGE,MA 02142							AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; APPEL M, 1987, DEC DEV STAT TOOLS S; APPEL M, 1983, P AM STAT ASSOC, P32; APPEL MV, 1987, DEC DEV STAT EXP SYS; ATKESON C, 1986, MIT942 AI LAB TECHN; CHEN BC, 1991, IN PRESS P AM STATIS; CHURCH K, 1986, UNPUB STOCHASTIC PAR; CHURCH K, 1989, ENHANCED GOOD TURING; CORBETT JP, 1972, ENCODING FREE WORD D; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1990, P AM STATISTICAL ASS; DASRATH BV, 1990, NEAREST NEIGHBOR NN; DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; HARMAN D, 1991, J AM SOC INFORM SCI, V42, P7, DOI 10.1002/(SICI)1097-4571(199101)42:1<7::AID-ASI2>3.0.CO;2-P; Hillis D., 1985, CONNECTION MACHINE; LORINGY J, 1988, SURV METHOD, V14, P289; LYBERG L, 1990, APR ADV COMP SOC SCI; OREAGAN RT, 1972, COMMUN ACM, V15, P455, DOI 10.1145/361405.361419; PEARL J, 1968, PROBABILISTIC REASON; Quinlan J. R., 1983, MACHINE LEARNING ART, P463; RUMELHART C, 1986, PARALLEL DISTRIBUTED; Shannon C. E., 1949, MATH THEORY COMMUNIC; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STANFILL C, 1988, MAY P CAS BAS REAS W, P414; STANFILL C, 1986, COMMUN ACM, V29, P1229, DOI 10.1145/7902.7907; WALTZ DL, 1990, AUG P NAT C AI BOST; WALTZ DL, 1990, NATURAL ARTIFICIAL P, P251; WOLPERT D, 1989, THESIS U CALIFORNIA; ZADEH LA, 1989, IEEE T KNOWL DATA EN, V1, P1	32	81	83	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036	0001-0782		COMMUN ACM	Commun. ACM	AUG	1992	35	8					48	64		10.1145/135226.135228		17	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	JF436	WOS:A1992JF43600010	
J	YAMADA, S; KAGE, H; NAKASHIMA, M; SHIONO, S; MAEDA, M				YAMADA, S; KAGE, H; NAKASHIMA, M; SHIONO, S; MAEDA, M			DATA-PROCESSING FOR MULTICHANNEL OPTICAL-RECORDING - ACTION-POTENTIAL DETECTION BY NEURAL NETWORK	JOURNAL OF NEUROSCIENCE METHODS			English	Article						MULTISITE OPTICAL RECORDING; DATA PROCESSING; ACTION POTENTIAL DETECTION; MULTILAYERED NEURAL NETWORK; BACKPROPAGATION LEARNING ALGORITHM; APLYSIA; GILL-WITHDRAWAL REFLEX	UNSUPERVISED WAVEFORM CLASSIFICATION; SOFTWARE-BASED SYSTEM; INVERTEBRATE GANGLIA; NEUROELECTRIC DATA; REAL-TIME; NEURONS	Using a neural network, we have developed a program for fast and precise detection of action potentials (AP) in raw multi-channel optical recording data. The AP detection was performed in two steps: first, peaks were detected in raw optical data, and, second, the peaks were classified by the neural network into APs, noise and undecided peaks. The network was optimized and trained by the backpropagation learning algorithm, employing some thousands of manually classified peaks. The performance of the optimized network was found to be not completely satisfactory, although it was better than the classification by template matching and nearest-neighbor rules. The addition of a signal-to-noise ratio (SNR) of a peak to the network classification improved the classification performance: in comparison with the manual classification results, 96% of manually classified APs were detected. The causes of classification errors were discussed. In spite of the fact that the program required a slight amount of human intervention for undecided peaks, the program could allow mostly automatic AP detection.		YAMADA, S (reprint author), MITSUBISHI ELECTR CO,CENT RES LAB,DEPT BIOTECHNOL,AMAGASAKI,HYOGO 661,JAPAN.						ABELES M, 1977, P IEEE, V65, P762, DOI 10.1109/PROC.1977.10559; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GORMAN RP, 1988, IEEE T ACOUST SPEECH, V36, P1135, DOI 10.1109/29.1640; GRINVALD A, 1981, J NEUROPHYSIOL, V45, P829; JANSEN RF, 1990, J NEUROSCI METH, V35, P203, DOI 10.1016/0165-0270(90)90125-Y; NAKASHIMA M, 1992, IEEE T BIO-MED ENG, V39, P26, DOI 10.1109/10.108124; NAKASHIMA M, 1989, Society for Neuroscience Abstracts, V15, P1046; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALGANICOFF M, 1988, J NEUROSCI METH, V25, P181, DOI 10.1016/0165-0270(88)90132-X; SARNA MF, 1988, J NEUROSCI METH, V25, P189, DOI 10.1016/0165-0270(88)90133-1; SCHMIDT EM, 1984, J NEUROSCI METH, V12, P95, DOI 10.1016/0165-0270(84)90009-8; SCHMIDT EM, 1984, J NEUROSCI METH, V12, P1, DOI 10.1016/0165-0270(84)90042-6; SHIONIO S, 1988, 2ND P INT S BIOE MOL, P57; WU JY, 1988, EXPERIENTIA, V44, P369, DOI 10.1007/BF01940529; YAMADA S, 1990, 10TH INT BIOPH C, P412; YANG XW, 1988, IEEE T BIO-MED ENG, V35, P806, DOI 10.1109/10.7287; ZECEVIC D, 1989, J NEUROSCI, V9, P3681	17	13	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270		J NEUROSCI METH	J. Neurosci. Methods	JUN	1992	43	1					23	33		10.1016/0165-0270(92)90063-J		11	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	JG371	WOS:A1992JG37100003	
J	CASASENT, DP				CASASENT, DP			AN OPTICAL CORRELATOR FEATURE EXTRACTOR NEURAL NET SYSTEM	OPTICAL ENGINEERING			English	Article						INFORMATION PROCESSING; CORRELATORS; DETECTION; FEATURE EXTRACTORS; IDENTIFICATION; MORPHOLOGY; NEURAL NETS; PATTERN RECOGNITION	FILTERS	The three optical information processing techniques of detection, recognition, and identification can and should be combined to achieve the best benefits of each. All methods are required for difficult pattern recognition problems. We consider the identification of multiple objects in the field of view in clutter. A morphological correlator is used to achieve detection. Hierarchical and symbolic pattern recognition correlators can also achieve detection as well as recognition. For very large class problems, feature extractors are required for identification, but first require detection. For difficult multiclass discrimination problems, neural net methods (rather than linear discriminant functions) are needed for identification.		CASASENT, DP (reprint author), CARNEGIE MELLON UNIV,CTR EXCELLENCE OPT DATA PROC,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213, USA.						CASASENT D, 1990, P SOC PHOTO-OPT INS, V1350, P380, DOI 10.1117/12.23606; CASASENT D, 1991, P SOC PHOTO-OPT INS, V1568, P313, DOI 10.1117/12.46126; CASASENT D, 1991, P SOC PHOTO-OPT INS, V1469, P256, DOI 10.1117/12.44964; CASASENT D, 1991, UNPUB APPL OPT; CASASENT D, 1985, OPT ENG, V24, P26; CASASENT DP, 1990, APPL OPTICS, V29, P2603, DOI 10.1364/AO.29.002603; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; GILES CL, 1988, NEURAL INFORMATION P, P301; GREGORY DA, 1990, P SOC PHOTO-OPT INS, V1296, P2, DOI 10.1117/12.21249; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532; KUMAR BVK, 1990, OPT ENG, V29, P994; KUMAR BVKV, 1986, J OPT SOC AM A, V3, P777, DOI 10.1364/JOSAA.3.000777; LENDARIS GG, 1970, PR INST ELECTR ELECT, V58, P198, DOI 10.1109/PROC.1970.7593; MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633; MAKI TR, 1990, P SOC PHOTO-OPT INS, V1151, P248; MARAGOS P, 1987, OPT ENG, V26, P623; O'Neill K. S., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V638; POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790; CASASENT D, 1992, APPL OPTICS, V31, P1109, DOI 10.1364/AO.31.001109; RAVICHANDRAN G, IN PRESS APPL OPT; TELFER B, 1990, APPL OPTICS, V29, P1191, DOI 10.1364/AO.29.001191	22	10	10	SOC PHOTO-OPT INSTRUM ENG	BELLINGHAM	PO BOX 10, BELLINGHAM, WA 98227-0010	0091-3286		OPT ENG	Opt. Eng.	MAY	1992	31	5					971	978		10.1117/12.57138		8	Optics	Optics	HU370	WOS:A1992HU37000013	
J	HARDIN, PJ; THOMSON, CN				HARDIN, PJ; THOMSON, CN			FAST NEAREST NEIGHBOR CLASSIFICATION METHODS FOR MULTISPECTRAL IMAGERY	PROFESSIONAL GEOGRAPHER			English	Article						NEAREST NEIGHBOR CLASSIFIER; DISTANCE MEASURE OPTIMIZATION; HIERARCHICAL STRUCTURES		Nearest neighbor classifiers have not been widely used by remote sensing practitioners. The lack of acceptance of these classifiers may be partially due to their notoriously slow speed of execution which makes them impractical for the classification of mega-pixel images. However, training data reduction, distance measure optimization, and neighbor searching algorithms based on the modified k-d tree can speed nearest neighbor classification substantially.	UNIV IDAHO,GEOG,MOSCOW,ID 83843	HARDIN, PJ (reprint author), BRIGHAM YOUNG UNIV,INTERGRAPH LAB GEOG INFORMAT ANAL,PROVO,UT 84602, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P32; FIX E, 1951, USAF2149004 PROJ; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HODGSON ME, 1988, REMOTE SENS ENVIRON, V25, P117, DOI 10.1016/0034-4257(88)90045-4; INCE F, 1987, INT J REMOTE SENS, V8, P1829; James M., 1985, CLASSIFICATION ALGOR; Jensen J.R., 1986, INTRO DIGITAL IMAGE; LUK A, 1986, PATTERN RECOGN LETT, V4, P375, DOI 10.1016/0167-8655(86)90059-0; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Samet H., 1989, DESIGN ANAL SPATIAL; SKIDMORE AK, 1989, PHOTOGRAMM ENG REM S, V55, P1449	14	11	11	BLACKWELL PUBLISHERS	CAMBRIDGE	350 MAIN STREET, STE 6, CAMBRIDGE, MA 02148-5023	0033-0124		PROF GEOGR	Prof. Geogr.	MAY	1992	44	2					191	202		10.1111/j.0033-0124.1992.00191.x		12	Geography	Geography	HV979	WOS:A1992HV97900006	
J	NEUMANN, EK; WHEELER, DA; BERNSTEIN, AS; BURNSIDE, JW; HALL, JC				NEUMANN, EK; WHEELER, DA; BERNSTEIN, AS; BURNSIDE, JW; HALL, JC			ARTIFICIAL NEURAL NETWORK CLASSIFICATION OF DROSOPHILA COURTSHIP SONG MUTANTS	BIOLOGICAL CYBERNETICS			English	Article							CENTRAL NERVOUS-SYSTEM; PATTERN-RECOGNITION; PRINCIPAL COMPONENTS; SPECTRAL-ANALYSIS; MELANOGASTER; BEHAVIOR; MOSAICS; CYTOGENETICS; MUTATIONS; ELEMENTS	Courtship songs produced by Drosophila males - wild-type, plus the cacophony and dissonance behavioral mutants - were examined with the aid of newly developed strategies for adaptive acoustic analysis and classification. This system used several techniques involving artificial neural networks (a.k.a. parallel distributed processing), including learned vector quantization of signals and non-linear adaption (back-propagation) of data analysis. "Pulse" song from several individual wild-type and mutant males were first vector-quantized according to their frequency spectra. The accumulated quantized data of this kind, for a given song, were then used to "teach" or adapt a multiple-layered feedforward artificial neural network, which classified that song according to its original genotype. Results are presented on the performance of the final adapted system when faced with novel test data and on acoustic features the system decides upon for predicting the song-mutant genotype in question. The potential applications and extensions of this new system are discussed, including how it could be used to screen for courtship mutants, search novel behavior patterns or cause-and-effect relationships associated with reproduction, compress these kinds of data for digital storage, and analyze Drosophila behavior beyond the case of courtship song.	BRANDEIS UNIV,DEPT BIOL,WALTHAM,MA 02254; MIT,LINCOLN LAB,LEXINGTON,MA 02173							AHALT S, 1989, INT JOINT C NEURAL N, V1, P241; ATAL BS, 1982, IEEE T COMMUN, V30, P600, DOI 10.1109/TCOM.1982.1095501; BERNSTEIN AS, 1992, J INSECT BEHAV, V5, P15, DOI 10.1007/BF01049155; BOUNDS DG, 1990, NEURAL NETWORKS, V3, P583, DOI 10.1016/0893-6080(90)90008-9; BRUNAK S, 1990, NATURE, V343, P123, DOI 10.1038/343123a0; CHATFIEL.C, 1970, J THEOR BIOL, V29, P427, DOI 10.1016/0022-5193(70)90107-4; COOK R, 1979, BIOL CYBERN, V34, P91, DOI 10.1007/BF00365473; COOK R, 1980, BIOL CYBERN, V37, P41, DOI 10.1007/BF00347641; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWLING DE, 1981, ANIM BEHAV, V29, P924, DOI 10.1016/S0003-3472(81)80030-9; DIETZ WE, 1989, J NEURAL NETWORK COM, V1, P5; DOWSE HB, 1989, J THEOR BIOL, V139, P487, DOI 10.1016/S0022-5193(89)80067-0; ELMAN JL, 1988, 8801 U CAL CTR RES L; EWING A W, 1968, Behaviour, V31, P287; EWING AW, 1983, BIOL REV, V58, P275, DOI 10.1111/j.1469-185X.1983.tb00390.x; EWING AW, 1977, ANIMALS COMMUNICATE, P403; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826; GAILEY DA, 1989, GENETICS, V121, P773; GAILEY DA, 1986, BEHAV GENET, V16, P375, DOI 10.1007/BF01071319; Gorczyca M., 1987, DROS INFO SERV, V66, P157; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; GREENSPAN RJ, 1980, J COMP NEUROL, V189, P741, DOI 10.1002/cne.901890409; GROSSBERG S, 1988, NEURAL NETWORKS, V1, P17, DOI 10.1016/0893-6080(88)90021-4; HAKEN H, 1990, NEURAL NETWORKS, V3, P395, DOI 10.1016/0893-6080(90)90022-D; HALL JC, 1986, TRENDS NEUROSCI, V9, P414, DOI 10.1016/0166-2236(86)90135-9; HALL JC, 1990, DEV BEHAV GENETICS, P100; HALL JC, 1979, GENETICS, V92, P437; HAMBLEN M, 1986, J NEUROGENET, V3, P249, DOI 10.3109/01677068609106855; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOY RR, 1988, SCIENCE, V240, P217, DOI 10.1126/science.3127882; HU MJC, 1964, 67751 STANF EL LABS; JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; JONES KR, 1990, NEURON, V4, P711, DOI 10.1016/0896-6273(90)90197-N; KOHONEN T, 1988, IEEE INT C NEUR NETW, P61; Kohonen T., 1987, SELF ORG ASS MEMORY; KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995; KRZANOWSKI WJ, 1982, J STAT COMPUT SIM, V15, P141, DOI 10.1080/00949658208810577; KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V76, P1022; KULKARNI SJ, 1987, GENETICS, V115, P461; KULKARNI SJ, 1988, GENETICS, V118, P267; KYRIACOU CP, 1982, ANIM BEHAV, V30, P794, DOI 10.1016/S0003-3472(82)80152-8; KYRIACOU CP, 1990, BEHAV GENET, V20, P617, DOI 10.1007/BF01065875; KYRIACOU CP, 1980, P NATL ACAD SCI-BIOL, V77, P6729, DOI 10.1073/pnas.77.11.6729; KYRIACOU CP, 1984, NATURE, V308, P62, DOI 10.1038/308062a0; LOGAN BF, 1977, AT&T TECH J, V56, P487; MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; MARKOW TA, 1987, P NATL ACAD SCI USA, V84, P6200, DOI 10.1073/pnas.84.17.6200; MARKOW TA, 1981, P NATL ACAD SCI-BIOL, V78, P430, DOI 10.1073/pnas.78.1.430; MENON MM, 1988, NEURAL NETWORKS, V1, P201, DOI 10.1016/0893-6080(88)90026-3; MIYAMOTO H, 1988, NEURAL NETWORKS, V1, P251, DOI 10.1016/0893-6080(88)90030-5; NEUMANN EK, 1990, P INT JOINT C NEURAL, V2, P257; PAULUS MP, 1990, P NATL ACAD SCI USA, V87, P723, DOI 10.1073/pnas.87.2.723; ROGERS D, 1989, NEURAL INFORMATION P, V2, P455; Rosenberg C. R., 1987, COMPLEX SYSTEMS, V1, P145; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; SHANNON CE, 1948, AT&T TECH J, V27, P379; SIEGEL RW, 1984, BEHAV GENET, V14, P383, DOI 10.1007/BF01065442; Skinner BF, 1933, J GEN PSYCHOL, V9, P3; SMITH AW, 1990, P INT JOINT C NEURAL, V1, P645; Sokal R.R, 1981, BIOMETRY; SPIETH HT, 1974, ANNU REV ENTOMOL, V19, P385, DOI 10.1146/annurev.en.19.010174.002125; TOMPKINS L, 1984, BEHAV GENET, V14, P411, DOI 10.1007/BF01065443; Von Schilcher F., 1976, Animal Behav, V24, P18, DOI 10.1016/S0003-3472(76)80095-4; VONSCHILCHER F, 1979, J COMP PHYSIOL, V129, P85; von Schilcher F., 1977, Behavior Genet, V7, P251; VONSCHILCHER F, 1976, ANIM BEHAV, V24, P622; WEBB AR, 1990, NEURAL NETWORKS, V3, P367, DOI 10.1016/0893-6080(90)90019-H; WERBOS P, 1984, THESIS HARVARD U CAM; WERBOS P, 1988, NEURAL NETWORKS, V1, P21; WHEELER DA, 1988, BEHAV GENET, V18, P675, DOI 10.1007/BF01066850; WHEELER DA, 1989, BEHAV GENET, V19, P503, DOI 10.1007/BF01066251; WIDROW G, 1960, ADAPTIVE SWITCHING 4, P96; YAMAMOTO D, 1991, J NEUROGENET, V7, P152	75	9	9	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0340-1200		BIOL CYBERN	Biol. Cybern.	APR	1992	66	6					485	496		10.1007/BF00204113		12	Computer Science, Cybernetics; Neurosciences	Computer Science; Neurosciences & Neurology	HR815	WOS:A1992HR81500003	
J	MUNIZ, EC; VASQUEZ, PAM; BRUNS, RE; NUNES, SP; WOLF, BA				MUNIZ, EC; VASQUEZ, PAM; BRUNS, RE; NUNES, SP; WOLF, BA			POLYMER-POLYMER MISCIBILITY EVALUATION BY ACOUSTIC-EMISSION	MAKROMOLEKULARE CHEMIE-RAPID COMMUNICATIONS			English	Article							POLYVINYL-CHLORIDE) BLENDS; BEHAVIOR		UNIV MAINZ,INST PHYS CHEM,WELDER WEG 13,W-6500 MAINZ,GERMANY; UNIV MARINGA,DEPT CHEM,MARINGA,BRAZIL; UNIV CAMPINAS,INST CHEM,BR-13081 CAMPINAS,SP,BRAZIL							BIKULCIUS GD, 1990, J ADHES SCI TECHNOL, V4, P169, DOI 10.1163/156856190X00199; COLEMAN MM, 1990, POLYMER, V31, P1187, DOI 10.1016/0032-3861(90)90208-G; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRUZRAMOS CA, 1989, MACROMOLECULES, V22, P1289, DOI 10.1021/ma00193a049; DUNN WJ, 1984, ANAL CHEM, V56, P1308, DOI 10.1021/ac00272a026; GALESKI A, 1990, J POLYM SCI POL PHYS, V28, P1171, DOI 10.1002/polb.1990.090280714; HASLAM J, 1972, IDENTIFICATION ANAL, P143; HOLLMANN K, 1989, POLYM ENG SCI, V29, P513, DOI 10.1002/pen.760290805; PRESS WH, 1987, NUMERICAL RECIPES, P381; QIAN R, 1987, APPLIED POLYM ANAL C, P157; QIAN RY, 1983, EUR POLYM J, V19, P947; RELLICK GS, 1986, J POLYM SCI POL PHYS, V24, P279, DOI 10.1002/polb.1986.090240206; RELLICK GS, 1986, J POLYM SCI POL PHYS, V24, P313, DOI 10.1002/polb.1986.090240208; TAKEUCHI T, 1965, ANAL CHEM, V37, P589, DOI 10.1021/ac60223a039; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; WOLD S, 1984, MULTIVAR DATA ANAL, P17; WOOL RP, 1989, POLYM ENG SCI, V29, P1340, DOI 10.1002/pen.760291906; Wu S., 1982, POLYM INTERFACE ADHE	18	8	8	HUTHIG & WEPF VERLAG	BASEL	AUF DEM WOLF 4, CH-4052 BASEL, SWITZERLAND	0173-2803		MAKROMOL CHEM-RAPID		JAN	1992	13	1					45	53				9	Polymer Science	Polymer Science	HD205	WOS:A1992HD20500008	
J	CASASENT, D				CASASENT, D			MULTIFUNCTIONAL HYBRID NEURAL NET	NEURAL NETWORKS			English	Article						ADAPTIVE CLUSTERING NEURAL NET; FEATURE SPACE NEURONS; HO-KASHYAP ASSOCIATIVE PROCESSOR; HYBRID OPTICAL DIGITAL NEURAL NET; MULTIFUNCTIONAL NEURAL NET; SYMBOLIC CORRELATOR NEURAL NET	PATTERN-RECOGNITION; SYSTEMS	New associative processor, optimization, and adaptive learning neural net algorithms are presented. A new symbolic correlator and production system optical neural net to handle multiple objects in the field of view is also reviewed. Attention is given to optically-generated input neuron representation spaces and to the implementation of a wide variety of neural net functions on a multifunctional hybrid optical/digital neural net system.		CASASENT, D (reprint author), CARNEGIE MELLON UNIV,CTR EXCELLENCE OPT DATA PROC,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213, USA.						BARNARD E, 1989, IEEE T SYST MAN CYB, V19, P1030, DOI 10.1109/21.44018; Baum E. B., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90020-9; BOTHA E, 1988, APPL OPTICS, V27, P5185, DOI 10.1364/AO.27.005185; BRUCK J, 1990, P IEEE, V78, P1579, DOI 10.1109/5.58341; CASASENT D, 1991, P SOC PHOTO OPT INST, V1544; CASASENT D, IN PRESS NEURAL NETW; CASASENT D, 1991, P SOC PHOTO OPT INST, V1564; CASASENT D, 1991, APPLIED OPTICS   DEC; CASASENT D, 1985, OPT ENG, V24, P724; CASASENT D, 1985, OPT ENG, V24, P26; CASASENT DP, 1990, APPL OPTICS, V29, P2603, DOI 10.1364/AO.29.002603; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GILES CL, 1988, NEURAL INFORMATION P, P301; GOODMAN JW, 1984, P IEEE, V72, P850, DOI 10.1109/PROC.1984.12943; KUCZEWSKI RM, 1987, P IEEE ICNN, P619; Lapedes A., 1988, NEURAL INFORMATION P, P442; LENDARIS GG, 1970, PR INST ELECTR ELECT, V58, P198, DOI 10.1109/PROC.1970.7593; MIRCHANDANI G, 1989, IEEE T CIRCUITS SYST, V36, P661, DOI 10.1109/31.31313; OHTA J, 1989, P INT JOINT C NEUR N, V2, P2; POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790; PSALTIS D, 1988, NEURAL NETWORKS, V1, P149, DOI 10.1016/0893-6080(88)90017-2; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; YEE M, 1991, APPLIED OPTICS   DEC	23	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0893-6080		NEURAL NETWORKS	Neural Netw.		1992	5	3					361	370		10.1016/0893-6080(92)90001-Y		10	Computer Science, Artificial Intelligence	Computer Science	HY508	WOS:A1992HY50800001	
J	LUGOSI, G				LUGOSI, G			LEARNING WITH AN UNRELIABLE TEACHER	PATTERN RECOGNITION			English	Article						NONPARAMETRIC CLASSIFICATION; IMPERFECT SUPERVISION; NONPARAMETRIC ESTIMATION; MAP DECISION; NEAREST NEIGHBOR RULE; BAYES METHODS		In nonparametric pattern recognition problems one has to "learn" a good decision rule from a long training sequence, that is, independent pairs of observations and corresponding labels. In many practical situations there may be errors among the labels of the training sequence, that is, "the teacher may sometimes lie". In this paper we investigate the behavior of two widely used methods in this situation under very general conditions. One of these methods is based on the maximization of the estimated a posteriori probabilities, the other is the nearest neighbor classification.		LUGOSI, G (reprint author), TECH UNIV BUDAPEST,INST COMMUN ELECTR,STOCZEK U 2,H-1111 BUDAPEST,HUNGARY.						BICKEL PJ, 1983, ANN PROBAB, V11, P185, DOI 10.1214/aop/1176993668; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; Devroye L.P., 1985, NONPARAMETRIC DENSIT; Duda R., 1973, PATTERN CLASSIFICATI; FRITZ J, 1973, PROBLEMS CONTROL INF; GIMLIN DR, 1974, IEEE T SYST MAN CYB, VSMC4, P304, DOI 10.1109/TSMC.1974.5409138; Gyorfi L., 1989, NONPARAMETRIC CURVE; SHANMUGA.K, 1971, IEEE T SYST MAN CYB, VSMC1, P223, DOI 10.1109/TSMC.1971.4308289; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206	10	14	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.	JAN	1992	25	1					79	87		10.1016/0031-3203(92)90008-7		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	GY736	WOS:A1992GY73600007	
J	RONG, YM; TZOU, HS				RONG, YM; TZOU, HS			DIAGNOSTIC MONITORING AND SENSITIVITY ANALYSIS OF CONTACT DYNAMICS IN JOINTED STRUCTURES	AIAA JOURNAL			English	Article							MINIMUM CROSS-ENTROPY; SPACE STRUCTURES; CLASSIFICATION; FAULTS	The operation and performance of elastically jointed structures can be degraded by dynamic contacts arising from a number of factors including excessive levels of vibration, inadequate lubrication, and improper joint clearance. In many applications, such as a space structure, periodic disassembly and inspection are impractical; thus, a monitoring and diagnosis system is desired to automatically detect and diagnose significant changes in the dynamic contact state of jointed structures. A time-series-based monitoring and diagnosis system has been formulated to address this need. The system incorporates a cross-entropy minimization method, based on the nearest neighbor classification rule, and a cross-entropy dissimilarity measure to classify a new observation of vibration states into one of a set of prestudied "standard" vibration patterns. The approach is applied to a unit truss cell, representative of space structures, and laboratory experiments are conducted to evaluate its performance and assess its sensitivities. The experimental results indicate that the system can satisfactorily detect and classify changes in the vibration states of such structures.	UNIV KENTUCKY,DEPT MECH ENGN,LEXINGTON,KY 40506	RONG, YM (reprint author), SO ILLINOIS UNIV,DEPT TECHNOL,CARBONDALE,IL 62901, USA.						BENVENISTE A, 1986, 25TH P C DEC CONTR N, P776; BOWDEN M, 1990, AIAA J, V28, P740, DOI 10.2514/3.10454; Box G., 1970, TIME SERIES ANAL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWLEY EF, 1987, AIAA J, V25, P1003, DOI 10.2514/3.9733; Duda R., 1973, PATTERN CLASSIFICATI; FOELSCHE GA, 1988, AIAA J, V26, P1278; FU KS, 1982, APPLICATIONS PATTERN; GERSCH W, 1983, J VIB ACOUST STRESS, V105, P178; GERSCH W, 1978, P IEEE C DECISION CO, P767; HARDY NW, 1989, ROBOTICA, V7, P25; KULLBACK S, 1959, INFORMATION THEORY S; MOON FC, 1990, AIAA J, V28, P915, DOI 10.2514/3.25139; PANDIT SM, 1978, TIME SERIES SYSTEM A; RONG Y, 1989, THESIS U KENTUCKY LE; RONG Y, 1988, P INT C MACHINE DYNA, pD32; SATA T, 1986, ASME WAM PED, V23, P279; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; SHORE JE, 1984, IEEE T INFORM THEORY, V30, P851, DOI 10.1109/TIT.1984.1056967; SHORE JE, 1982, IEEE T PATTERN ANAL, V4, P11; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SOONG K, 1990, J MECH DESIGN, V112, P183, DOI 10.1115/1.2912591; Tou J.T., 1974, PATTERN RECOGNITION; TZOU HS, 1991, AIAA J, V29, P81, DOI 10.2514/3.10548; TZOU HS, 1989, 3RD S ADV MAN LEX, P143; TZOU HS, 1988, P S ROBOTICS ASME DS, V11, P61	26	1	1	AMER INST AERONAUT ASTRONAUT	RESTON	1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091	0001-1452		AIAA J	AIAA J.	DEC	1991	29	12					2215	2221		10.2514/3.10862		7	Engineering, Aerospace	Engineering	GX692	WOS:A1991GX69200028	
J	BEREAU, M; DUBUISSON, B				BEREAU, M; DUBUISSON, B			A FUZZY EXTENDED K-NEAREST NEIGHBORS RULE	FUZZY SETS AND SYSTEMS			English	Article						CLASSIFICATION; WEIGHTED K-NEAREST NEIGHBORS RULES; MEMBERSHIP FUNCTION; FUZZY CLUSTERING; FUZZY DISCRIMINATION	SETS	The purpose of this paper is to describe an automatic fuzzy classification algorithm working in a partially supervised environment. This algorithm is based on the fuzzy labeling of samples by means of a membership function. As long as the membership function carries more information than the classical characteristic function, the concepts of clustering and discrimination are extended to the fuzzy field. First the learning set is fuzzily clustered. The membership function is based on a weighted k-nearest neighbors rule and does not require the optimization of any criterion. Second the test set is analyzed and a new membership function is proposed. As the learning set is generally incomplete, the creation of new fuzzy classes is studied. The measure of fuzziness involves some analogies with Statistical Thermodynamics, and the link between the membership function and the Fermi-Dirac statistical function is discussed. Finally results on simulated data are reported.		BEREAU, M (reprint author), UNIV TECHNOL COMPIEGNE,CNRS,URA 817,BP 233,F-60206 COMPIEGNE,FRANCE.						Bezdek J., 1981, PATTERN RECOGNITION; BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; CAPOCELL.RM, 1973, INFORM CONTROL, V23, P446, DOI 10.1016/S0019-9958(73)80009-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DELUCA A, 1972, INFORM CONTROL, V20, P301, DOI 10.1016/S0019-9958(72)90199-4; Devijver P. A., 1982, PATTERN RECOGNITION; Diday E, 1979, OPTIMISATION CLASSIF; Dubois D, 1980, FUZZY SETS SYSTEMS; DUDANI SA, 1978, IEEE T SYST MAN CYB, V8, P325; Dunn J., 1974, J CYBERNETICS, V3, P32; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GU T, 1985, IEEE T PATTERN ANAL, P366; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HELMAN ME, 1970, IEEE T SYST SCI CYB, V6, P179; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; Kandel A, 1982, FUZZY TECHNIQUES PAT; KITTLER J, 1978, KYBERNETES, V7, P313, DOI 10.1108/eb005497; LOO SG, 1977, CYBERNETICA, V20, P201; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SHORT RD, 1980, 5TH INT C PATT REC M, P81; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Usai M., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1); WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P696, DOI 10.1109/TIT.1973.1055059; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	27	13	14	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	NOV 5	1991	44	1					17	32		10.1016/0165-0114(91)90029-P		16	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	GR252	WOS:A1991GR25200002	
J	SALZBERG, S				SALZBERG, S			A NEAREST HYPERRECTANGLE LEARNING-METHOD	MACHINE LEARNING			English	Article						EXEMPLAR; INDUCTION; GENERALIZATION; PREDICTION; INCREMENTAL LEARNING; EXCEPTIONS	PROTOTYPE	This paper presents a theory of learning called nested generalized exemplar (NGE) theory, in which learning is accomplished by storing objects in Euclidean n-space, E(n), as hyperrectangles. The hyperrectangles may be nested inside one another to arbitrary depth. In contrast to generalization processes that replace symbolic formulae by more general formulae, the NGE algorithm modifies hyperrectangles by growing and reshaping them in a well-defined fashion. The axes of these hyperrectangles are defined by the variable measured for each example. Each variable can have any range on the real line; thus the theory is not restricted to symbolic or binary values. This paper describes some advantages and disadvantages of NGE theory, positions it as a form of exemplar-based learning, and compares it to other inductive learning theories. An implementation has been tested in three different domains, for which results are presented below: prediction of breast cancer, classification of iris flowers, and prediction of survival times for heart attack patients. The results in these domains support the claim that NGE theory can be used to create compact representations with excellent predictive accuracy.		SALZBERG, S (reprint author), JOHNS HOPKINS UNIV,DEPT COMP SCI,BALTIMORE,MD 21218, USA.		Salzberg, Steven/F-6162-2011				AHA DW, 1989, 6TH P INT WORKSH MAC, P387; AHA DW, 1989, 11TH P INT JOINT C A, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ASHLEY D, 1987, 1ST P INT C ART INT, P67; BARR RA, 1987, MEM COGNITION, V15, P397, DOI 10.3758/BF03197730; BAREISS R, 1988, CS8810 VAND U DEP CO; BAREISS R, 1989, AI8996 U TEX ART INT; BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; Breiman L, 1984, CLASSIFICATION REGRE; BUCHANAN BG, 1978, PATTERN DIRECTED INF; BUNDY A, 1985, ARTIF INTELL, V27, P137, DOI 10.1016/0004-3702(85)90052-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; DIETTERICH TG, 1983, MACHINE LEARNING; Everitt B, 1980, CLUSTER ANAL; FISHER DH, 1989, P INT JOINT C ART IN, P825; Fisher RA, 1936, ANN EUGENIC, V7, P179; HELMBOLD D, 1989, 1989 P WORKSH COMP L; KAN G, 1986, BRIT HEART J, V56, P422; KASIF S, 1989, COMMUNICATION; KIBLER D, 1987, 4TH P INT WORKSH MAC, P24; KINNEY E, 1988, COMMUNICATION; KOLODNER J, 1984, 1ST P ANN WORKSH THE, P1; KOLODNER JL, 1980, 187 YAL U DEP COMP S; MEDIN DL, 1983, PERCEPTION COGNITION; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MICHALSKI RS, 1986, 5TH P NAT C ART INT, P1041; OSHERSON DN, 1981, COGNITION, V9, P35, DOI 10.1016/0010-0277(81)90013-5; PORTER B, 1989, AI8996 U TEX ART INT; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REED SK, 1972, COGNITIVE PSYCHOL, V3, P382, DOI 10.1016/0010-0285(72)90014-X; RISSLAND EL, 1987, 1ST P INT C ART INT, P60; SALZBERG S, 1985, P 9 INT JOINT C ART, P603; SALZBERG S, 1989, TR1489 HARV U DEP CO; SAZBERG S, 1983, ARTIFICIAL INTELLIGE; SMITH EE, 1984, COGNITIVE SCI, V8, P337, DOI 10.1207/s15516709cog0804_2; THORNTON C, 1987, P INT JOINT C ART IN, P301; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VERE S, 1980, ARTIF INTELL, V14, P138; WARMUTH M, 1989, COMMUNICATION; WEISS S, 1989, 11TH IJCAI 89 INT JO, P781	41	129	133	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAY	1991	6	3					251	276		10.1023/A:1022661727670		26	Computer Science, Artificial Intelligence	Computer Science	FK366	WOS:A1991FK36600003	
J	MANN, NH; BROWN, MD				MANN, NH; BROWN, MD			ARTIFICIAL-INTELLIGENCE IN THE DIAGNOSIS OF LOW-BACK-PAIN	ORTHOPEDIC CLINICS OF NORTH AMERICA			English	Article							CROSS-VALIDATION; BOOTSTRAP; JACKKNIFE; DRAWINGS		UNIV MIAMI,SCH MED,DEPT ORTHOPAED & REHABIL R-2,POB 016960,MIAMI,FL 33101							BOOTH DE, 1986, COMPUT BIOMED RES, V19, P1, DOI 10.1016/0010-4809(86)90002-9; BORENSTEIN DG, 1989, LOW BACK PAIN; Bow S.T., 1984, PATTERN RECOGNITION; BROWN MD, 1983, AAOS INSTRUCT COURSE, V118, P162; BROWNLEE KA, 1960, STATISTICAL THEORY M, P155; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUMMINGS G S, 1987, Journal of Orthopaedic and Sports Physical Therapy, V8, P391; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; ENGER I, UNPUB COMPUTERS BIOM; Fisher RA, 1936, ANN EUGENIC, V7, P179; GILBERT ES, 1968, J AM STAT ASSOC, V63, P1399, DOI 10.2307/2285893; GONG G, 1986, J AM STAT ASSOC, V81, P108, DOI 10.2307/2287975; HARMSRINGDAHL K, 1986, SCAND J REHABIL MED, V18, P117; HIELDEBRANT J, 1988, SPINE, V13, P681; Kohonen T., 1988, SELF ORG ASS MEMORY; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL; LEAVITT F, 1978, PAIN, V4, P273, DOI 10.1016/0304-3959(77)90139-7; LEAVITT F, 1979, PAIN, V7, P187, DOI 10.1016/0304-3959(79)90010-1; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; MARGOLIS RB, 1986, PAIN, V24, P57, DOI 10.1016/0304-3959(86)90026-6; MARGOLIS RB, 1985, PAIN, V23, P289, DOI 10.1016/0304-3959(85)90107-1; MARGOLIS RB, 1988, PAIN, V33, P49, DOI 10.1016/0304-3959(88)90202-3; Marr D., 1982, VISION; MINSKY M, 1964, PERCEPTRONS; PARKER DB, 1987, 1ST P INT C NEUR NET; PLAUT DC, 1986, CMUCS86126 CARN U CO; Ransford AO, 1976, SPINE, V1, P127, DOI 10.1097/00007632-197606000-00007; REGGIA JA, 1985, COMPUTER ASSISTED ME, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHWARTZ DP, 1984, PAIN, V19, P383, DOI 10.1016/0304-3959(84)90084-8; Stone G. O., 1986, PARALLEL DISTRIBUTED, V1, P444; TAYLOR WP, 1984, SPINE, V9, P313, DOI 10.1097/00007632-198404000-00017; UDEN A, 1987, CLIN ORTHOPAEDICS, V216, P124; VONBAEYER CL, 1983, PAIN, V16, P10; WADDELL G, 1980, SPINE, V5, P117, DOI 10.1097/00007632-198003000-00005; 1987, SPINE, V12, P522	36	31	31	W B SAUNDERS CO	PHILADELPHIA	INDEPENDENCE SQUARE WEST CURTIS CENTER, STE 300, PHILADELPHIA, PA 19106-3399	0030-5898		ORTHOP CLIN N AM	Orthop. Clin. North Am.	APR	1991	22	2					303	314				12	Orthopedics	Orthopedics	GM541	WOS:A1991GM54100013	
J	GEVA, S; SITTE, J				GEVA, S; SITTE, J			ADAPTIVE NEAREST NEIGHBOR PATTERN-CLASSIFICATION	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Letter								We describe a variant of nearest neighbor pattern classification (NN) [1] and supervised learning by learning vector quantization (LVQ) [2], [3]. The decision surface mapping method, which we call DSM, is a fast supervised learning algorithm, and is a member of the LVQ family of algorithms. A relatively small number of prototypes are selected from a training set of correctly classified samples. The training set is then used to adapt these prototypes to map the decision surface separating the classes. This algorithm is compared with NN pattern classification, learning vector quantization (LVQ1) [2], and a two-layer perception trained by error backpropagation [4]. When the class boundaries are sharply defined (i.e., no classification error in the training set) the DSM algorithm outperforms these methods with respect to error rates, learning rates, and the number of prototypes required to describe class boundaries.		GEVA, S (reprint author), QUEENSLAND UNIV TECHNOL,FAC INFORMAT TECHNOL,GPO BOX 2434,BRISBANE,QLD 4001,AUSTRALIA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1990, ADVANCED NEURAL COMPUTERS, P137; KOHONEN T, 1988, SELF ORG ASS MEMORY, P199; RUMMELHART DE, PARALEL DISTRIBUTED, V1, P318	5	53	53	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	1991	2	2					318	322		10.1109/72.80344		5	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	FB858	WOS:A1991FB85800017	
J	WEISS, SM				WEISS, SM			SMALL SAMPLE ERROR RATE ESTIMATION FOR K-NN CLASSIFIERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						BOOTSTRAP; CROSS-VALIDATION; ERROR RATE ESTIMATOR; LEAVING-ONE-OUT; NEAREST NEIGHBOR	BOOTSTRAP	Small sample error rate estimators for nearest neighbor classifiers are reexamined and contrasted with the same estimators for three-nearest neighbor classifiers. The performance of the bootstrap estimators, e0 and 0.632B, is considered relative to leaving-one-out and other cross-validation estimators. Monte Carlo simulations are used to measure the performance of the error rate estimators. The experimental results are compared to previously reported simulations for both nearest neighbor classifiers and alternative classifiers. It is shown that each of the estimators has strengths and weaknesses for varying apparent and true error rate situations. A combined estimator that corrects the leaving-one-out estimator (by combining bootstrap and cross-validation estimators) gave strong results over a broad range of situations and warrants further investigation for other classifiers.		WEISS, SM (reprint author), RUTGERS STATE UNIV,DEPT COMP SCI,NEW BRUNSWICK,NJ 08903, USA.						Breiman L, 1984, CLASSIFICATION REGRE; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD SL, 1989, INT J MAN MACH STUD, V31, P197, DOI 10.1016/0020-7373(89)90027-8; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; KANAL L, 1971, PATTERN RECOGN, V3, P225, DOI 10.1016/0031-3203(71)90013-6; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; McClelland J. L., 1988, EXPLORATIONS PARALLE; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Raudys S., 1988, P 9 INT C PATT REC R, P1230; STONE M, 1974, J R STAT SOC B, V36, P111	13	22	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1991	13	3					285	289		10.1109/34.75516		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	FG360	WOS:A1991FG36000008	
J	CABELLO, D; BARRO, S; SALCEDA, JM; RUIZ, R; MIRA, J				CABELLO, D; BARRO, S; SALCEDA, JM; RUIZ, R; MIRA, J			FUZZY K-NEAREST NEIGHBOR CLASSIFIERS FOR VENTRICULAR ARRHYTHMIA DETECTION	INTERNATIONAL JOURNAL OF BIO-MEDICAL COMPUTING			English	Article						FUZZY K-NN CLASSIFIERS; ECG PROCESSING; VENTRICULAR ARRHYTHMIA DETECTION; FUZZY C-MEANS ALGORITHM; FUZZY COVARIANCE ALGORITHM	RECOGNITION; SYSTEM	We report a study of the efficiency of 4 classifiers (the K-nearest-neighbor and single-nearest-prototype algorithms, each as parametrized by both Fuzzy C-Means and Fuzzy Covariance clustering) in the detection of ventricular arrhythmias in ECG traces characterized by 4 features derived from 7 spectral parameters. Principal components analysis was used in conjunction with a cardiologist's deterministic classification of 90 ECG traces to fix the number of trace classes to 5 (ventricular fibrillation/flutter, sinus rhythm, ventricular rhythms with aberrant complexes and 2 classes of artefact). Forty of the 90 traces were then defined as a test set; 5 different learning sets (numbering 25, 30, 35, 40 and 45 traces) were randomly selected from the remaining 50 traces; each learning set was used to parametrize both the classification algorithms using both fuzzy clustering algorithms and the parametrized classification algorithms were then applied to the test set. Optimal K for K-nearest-neighbor algorithms and optimal cluster volumes for Fuzzy Covariance algorithms were sought by trial error to minimize classification differences with respect to the cardiologist's classification. Fuzzy Covariance clustering afforded significantly better perception of cluster structure than the Fuzzy C-Means algorithm, and the classifiers performed correspondingly with an overall empirical error ratio of just 0.10 for the K-nearest-neighbor algorithm parametrized by Fuzzy Covariance.	UNIV MURCIA,ETSII CARTAGENA,DEPT INGN ELECTROMECAN,MURCIA,SPAIN; UNIV NACL EDUC DISTANCIA,FAC CIENCIAS,DEPT INFORMAT,MADRID,SPAIN	CABELLO, D (reprint author), UNIV SANTIAGO DE COMPOSTELA,FAC FIS,DEPT ELECTR,E-15706 SANTIAGO,SPAIN.						AUBERT AE, 1988, COMPUT CARDIOL, P341; AUBERT AE, 1985, INGENIEURSBLAD, V5, P269; BARRO S, 1988, THESIS U SANTIAGO CO; BARRO S, 1989, J BIOMED ENG, V11, P320, DOI 10.1016/0141-5425(89)90067-8; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bezdek J.C., 1982, PATTERN RECOGNITION; Brekelmans F. E. M., 1980, Computers in Cardiology; CABELLO D, 1988, P ANN INT C EMBS, V10, P5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DUMN JC, 1974, J CYBERNETICS, V3, P32; FOSTER FK, 1982, COMPUT CARDIOL, P245; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gustafson D. E., 1979, P IEEE CDC, V2, P761; HUNG BN, 1988, 10TH P IEEE ANN INT, P9; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KITTLER J, 1981, PATTERN RECOGN, V13, P245, DOI 10.1016/0031-3203(81)90101-1; Mitchell R. H., 1986, Automedica, V7; NOLLE FM, 1988, COMPUT CARDIOL, P337; Nolle F. M., 1980, Computers in Cardiology; Nygards M.-E., 1977, Computers in Cardiology; RIPLEY KL, 1989, IEEE T BIO-MED ENG, V36, P618, DOI 10.1109/10.29456; SALCEDA JM, 1988, THESIS U SANTIAGO; ZHU Y, 1987, 9TH P IEEE ANN C EMB, P918	24	11	11	ELSEVIER SCI IRELAND LTD	CLARE	CUSTOMER RELATIONS MANAGER, BAY 15, SHANNON INDUSTRIAL ESTATE CO, CLARE, IRELAND	0020-7101		INT J BIOMED COMPUT	Int. J. Bio-Med. Comput.	FEB	1991	27	2					77	93		10.1016/0020-7101(91)90089-W		17	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	EZ246	WOS:A1991EZ24600005	
J	SALZBERG, S				SALZBERG, S			DISTANCE METRICS FOR INSTANCE-BASED LEARNING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE			English	Article							CONTEXT THEORY; CLASSIFICATION; SIMILARITY	Instance-based learning techniques use a set of stored training instances to classify new examples. The most common such learning technique is the nearest neighbor method, in which new instances are classified according to the closest training instance. A critical element of any such method is the metric used to determine distance between instances. Euclidean distance is by far the most commonly used metric; no one, however, has systematically considered whether a different metric, such as Manhattan distance, might perform equally well on naturally occurring data sets. Some evidence from psychological research indicates that Manhattan distance might be preferable in some circumstances. This paper examines three different distance metrics and presents experimental comparisons using data from three domains: malignant cancer classification, heart disease diagnosis, and diabetes prediction. The results of these studies indicate that the Manhattan distance metric works works quite well, although not better than the Euclidean metric that has become a standard for machine learning experiments. Because the nearest neighbor technique provides a good benchmark for comparisons with other learning algorithms, the results below include a number of such comparisons, which show that nearest neighbor, using any distance metric, compares quite well to other machine learning techniques.		SALZBERG, S (reprint author), JOHNS HOPKINS UNIV,DEPT COMP SCI,BALTIMORE,MD 21218, USA.		Salzberg, Steven/F-6162-2011				AHA D, 1991, MACH LEARN, V6, P1; AHA DW, 1989, 11TH P INT JOINT C A, P794; BENNETT PH, 1971, LANCET, V2, P125; COST S, 1990, 1990 P S COMP APPL M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5; MANGASARIAN O, 1989, 878 U WISC MAD COMP; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; NOSOFSKY RM, 1984, J EXP PSYCHOL LEARN, V10, P104, DOI 10.1037/0278-7393.10.1.104; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SMITH JW, 1988, 12TH P ANN S COMP AP, P261; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TVERSKY A, 1982, PSYCHOL REV, V89, P123, DOI 10.1037/0033-295X.89.2.123; WOLBERG W, 1989, UNPUB MULTISURFACE M	16	0	0	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010			LECT NOTES ARTIF INT	Lect. Notes Artif. Intell.		1991	542						398	408				11	Computer Science, Artificial Intelligence	Computer Science	KV083	WOS:A1991KV08300041	
J	AHA, DW; KIBLER, D; ALBERT, MK				AHA, DW; KIBLER, D; ALBERT, MK			INSTANCE-BASED LEARNING ALGORITHMS	MACHINE LEARNING			English	Article						SUPERVISED CONCEPT LEARNING; INSTANCE-BASED CONCEPT DESCRIPTIONS; INCREMENTAL LEARNING; LEARNING THEORY; NOISE; SIMILARITY		Storing and using specific instances improves the performance of several supervised learning algorithms. These include algorithms that learn decision trees, classification rules, and distributed networks. However, no investigation has analyzed algorithms that use only specific instances to solve incremental learning tasks. In this paper, we describe a framework and methodology, called instance-based learning, that generates classification predictions using only specific instances. Instance-based learning algorithms do not maintain a set of abstractions derived from specific instances. This approach extends the nearest neighbor algorithm, which has large storage requirements. We describe how storage requirements can be significantly reduced with, at most, minor sacrifices in learning rate and classification accuracy. While the storage-reducing algorithm performs well on several real-world databases, its performance degrades rapidly with the level of attribute noise in training instances. Therefore, we extended it with a significance test to distinguish noisy instances. This extended algorithm's performance degrades gracefully with increasing noise levels and compares favorably with a noise-tolerant decision tree algorithm.		AHA, DW (reprint author), UNIV CALIF IRVINE,DEPT INFORMAT & COMP SCI,IRVINE,CA 92717, USA.		Albert, Marc/A-1693-2009				AHA DW, 1989, 8910 U CAL DEP INF C; AHA DW, 1989, 6TH P INT WORKSH MAC, P387; AHA DW, 1989, 1989 P IJCAI WORKSH; AHA DW, 1989, 11TH P INT JOINT C A, P794; BAREISS ER, 1987, 4TH P INT WORKSH MAC, P12; BARSALOU LW, 1983, MEM COGNITION, V11, P211, DOI 10.3758/BF03196968; BLUMER A, 1986, 18TH P ACM S THEOR C, P273; BRADSHAW G, 1987, 4TH P INT WORKSH MAC, P1; Breiman L, 1984, CLASSIFICATION REGRE; BROOKS L, 1989, VANCOUVER STUDIES CO, V1; Brooks L. R., 1978, COGNITION CATEGORIZA; CESTNIK B, 1987, PROGR MACHINE LEARNI; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CLARK PE, 1989, 89034 TUR I TECHN RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1980, PATTERN ANAL MACHINE, V2, P67; DETRANO R, 1988, UNPUB INT APPLICATIO; DIETTERICH T, 1983, MACHINE LEARNING ART; FISHER D, 1989, 11TH P INT JOINT C A, P825; GATES GW, 1972, IEEE T INFORM THEORY, P431; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037//0033-295X.93.4.411; HOGG RV, 1983, PROBABILITY STATISTI; JABBOUR K, 1987, 1987 P IEEE POW ENG; KIBLER D, 1988, UNPUB 1988 P CAS BAS, P62; Kibler D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00315.x; KIBLER D, 1989, CHANGE REPRESENTATIO; Koton P., 1988, 7TH P NAT C ART INT, P256; MARKOVITCH S, 1989, 6TH P INT WORKSH MAC, P404; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Michalski R. S., 1978, 867 U ILL DEP COMP S; MICHALSKI RS, 1986, 5TH P NAT C ART INT, P1041; MICHIE D, 1984, 1984 C ART INT APPL; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1986, 2ND P AUSTR C APPL E; QUINLAN JR, 1987, 10TH P INT JOINT C A, P304; QUINLAN JR, 1988, 5TH P INT C MACH LEA, P135; RENDELL L, 1988, 3RD P EUR WORK SESS, P177; RISSLAND EL, 1989, P CASE BASED REASONI, P1; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart D.E., 1987, PARALLEL DISTRIBUTED; SALZBERG S, 1988, TR1088 HARV U CTR RE; SCHLIMMER JC, 1986, 5 NAT C ART INT, P496; Shamos M. I., 1975, 16TH P IEEE S F COMP, P151, DOI 10.1109/SFCS.1975.8; Smith E. E., 1981, CATEGORIES CONCEPTS; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Utgoff P. E., 1989, Machine Learning, V4, DOI 10.1023/A:1022699900025; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; VANDEVELDE W, 1989, 4TH P EUR WORK SESS, P211; VOLPER DJ, 1987, BIOL CYBERN, V57, P57, DOI 10.1007/BF00318716	51	1219	1238	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	JAN	1991	6	1					37	66		10.1023/A:1022689900470		30	Computer Science, Artificial Intelligence	Computer Science	EW468	WOS:A1991EW46800002	
J	FARAGO, A; LINDER, T; LUGOSI, G				FARAGO, A; LINDER, T; LUGOSI, G			NEAREST NEIGHBOR SEARCH AND CLASSIFICATION IN O(1) TIME	PROBLEMS OF CONTROL AND INFORMATION THEORY-PROBLEMY UPRAVLENIYA I TEORII INFORMATSII			English	Article								A method of finding the nearest neighbor is presented. The effectiveness of the algorithm has been shown in computer simulations. This paper gives a probabilistic analysis of the performance. The algorithm is shown to have O(1) expected asymptotic complexity, measured in the number of distance calculations for n sample points. A reduced complexity classification rule is derived which has the same error probability as that of the nearest neighbor discrimination rule.	TECH UNIV BUDAPEST,H-1521 BUDAPEST,HUNGARY							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FARAGO A, 1986, HIRADASTECHNIKA, V39; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; KAMGARPARSI B, 1985, PATTERN RECOGN LETT, V3, P7, DOI 10.1016/0167-8655(85)90036-4; LINDER T, 1990, IEEE INT S INFORMATI; MOTOISHI K, 1984, 7TH S INF THEOR ITS; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; Wheeden R. L., 1977, MEASURE INTEGRAL	9	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0370-2529		PROBL CONTROL INFORM			1991	20	6					383	395				13	Automation & Control Systems; Computer Science, Information Systems	Automation & Control Systems; Computer Science	KF212	WOS:A1991KF21200002	
J	KRAMER, MA; LEONARD, JA				KRAMER, MA; LEONARD, JA			DIAGNOSIS USING BACKPROPAGATION NEURAL NETWORKS - ANALYSIS AND CRITICISM	COMPUTERS & CHEMICAL ENGINEERING			English	Article								Artificial neural networks based on a feedforward architecture and trained by the backpropagation technique have recently been applied to static fault diagnosis problems. The networks are used to classify measurement vectors into a set of predefined categories that represent the various functional and malfunctional states of the process. While the networks can usually produce decision surfaces that correctly classify the training examples, regions of the input space not occupied by training data are classified arbitrarily. As a result, the networks may not accurately extrapolate from the training data. Although extrapolation is not required under ideal circumstances, in practice the network may be required to extrapolate when undersized training sets are used, when parent distributions of fault classes undergo shifts subsequent to training, and when the input data is corrupted by missing or biased sensors. These situations cause relatively high error rates for the neural classifier. A related probem is that the networks cannot detect when they lack the data for a reliable classification, a serious deficiency in many practical applications. Classifiers based on distance metrics assign regions of the input space according to their proximity to the training data, and thus extrapolation is not arbitrary but based on the most relevant data. Distance-based classifiers perform better under nonideal conditions and are to be preferred to neural network classifiers in diagnostic applications.		KRAMER, MA (reprint author), MIT,DEPT CHEM ENGN,INTELLIGENT SYST PROC ENGN,CAMBRIDGE,MA 02139, USA.						Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BERENBLUT BJ, 1977, CHEM ENG-LONDON, V318, P175; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Duda R., 1973, PATTERN CLASSIFICATI; FERRADA JJ, 1989, AICHE NATL MTG SAN F; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; HOSKINS JC, 1988, SPR AICHE M HOUST; HOSKINS JC, 1988, COMPUT CHEM ENG, V12, P881, DOI 10.1016/0098-1354(88)87015-7; HUANG W, 1987, 1ST IEE INT C NEUR N; LEE Y, 1989, C NEURAL INFORMATION; LEONARD J, 1990, COMPUT CHEM ENG, V14, P337, DOI 10.1016/0098-1354(90)87070-6; LEONARD JA, 1989, AICHE NATL M SAN FRA; Lippmann R. P., 1987, IEEE First International Conference on Neural Networks; Lippmann R. P., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.1; MAH RSH, 1987, F COMPUTER AIDED PRO; MAKHOUL J, P INT JOINT C NEURAL, P455; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; NAIDU S, 1989, AM CONTROL C PITTSBU; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; UNGAR LH, 1990, COMPUT CHEM ENG, V14, P561, DOI 10.1016/0098-1354(90)87027-M; VENKATASUBRAMAN.V, 1989, COMPUT CHEM ENG, V35, P1993; WATANABE K, 1989, AICHE J, V35, P1803, DOI 10.1002/aic.690351106	23	79	81	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0098-1354		COMPUT CHEM ENG	Comput. Chem. Eng.	DEC	1990	14	12					1323	1338		10.1016/0098-1354(90)80015-4		16	Computer Science, Interdisciplinary Applications; Engineering, Chemical	Computer Science; Engineering	EQ494	WOS:A1990EQ49400002	
J	KLEYWEGT, GJ; BOELENS, R; KAPTEIN, R				KLEYWEGT, GJ; BOELENS, R; KAPTEIN, R			A VERSATILE APPROACH TOWARD THE PARTIALLY AUTOMATIC RECOGNITION OF CROSS PEAKS IN 2D H-1-NMR SPECTRA	JOURNAL OF MAGNETIC RESONANCE			English	Note									STATE UNIV UTRECHT,DEPT CHEM,PADUALAAN 8,3584 CH UTRECHT,NETHERLANDS			Boelens, Rolf/B-4702-2009	Boelens, Rolf/0000-0002-6939-8913			CIESLAR C, 1988, J MAGN RESON, V80, P119, DOI 10.1016/0022-2364(88)90063-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EADS CD, 1989, J MAGN RESON, V82, P467, DOI 10.1016/0022-2364(89)90210-2; GLASER S, 1987, J MAGN RESON, V74, P450, DOI 10.1016/0022-2364(87)90267-8; GRAHN H, 1988, J MAGN RESON, V77, P294, DOI 10.1016/0022-2364(88)90179-5; GRIESINGER C, 1987, J AM CHEM SOC, V109, P7227, DOI 10.1021/ja00257a074; HOCH JC, 1987, CARLSBERG RES COMMUN, V52, P111, DOI 10.1007/BF02907530; HOLLEY LH, 1989, P NATL ACAD SCI USA, V86, P152, DOI 10.1073/pnas.86.1.152; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; KAPTEIN R, 1988, BIOCHEMISTRY-US, V27, P5389, DOI 10.1021/bi00415a001; KLEYWEGT GJ, 1989, J MAGN RESON, V85, P186, DOI 10.1016/0022-2364(89)90335-1; KRAULIS PJ, 1989, J MAGN RESON, V84, P627, DOI 10.1016/0022-2364(89)90130-3; LUKASHIN AV, 1989, J BIOMOL STRUCT DYN, V6, P1123; MADI Z, 1987, J MAGN RESON, V72, P584, DOI 10.1016/0022-2364(87)90167-3; MEIER BU, 1987, J MAGN RESON, V74, P565, DOI 10.1016/0022-2364(87)90278-2; MEIER BU, 1984, J MAGN RESON, V60, P161, DOI 10.1016/0022-2364(84)90043-X; MEIER BU, 1988, J MAGN RESON, V79, P540, DOI 10.1016/0022-2364(88)90089-3; NEIDIG KP, 1984, BIOCHEM BIOPH RES CO, V125, P1143, DOI 10.1016/0006-291X(84)91403-7; NEIDIG KP, 1988, MAGN RESON CHEM, V26, P848, DOI 10.1002/mrc.1260261008; NOVIC M, 1987, J MAGN RESON, V73, P493, DOI 10.1016/0022-2364(87)90012-6; NOVIC M, 1988, ANAL CHEM, V60, P582, DOI 10.1021/ac00157a018; NOVIC M, 1988, J MAGN RESON, V77, P394; OSCHKINAT H, 1988, NATURE, V332, P374, DOI 10.1038/332374a0; PFANDLER P, 1988, MAGN RESON CHEM, V26, P888, DOI 10.1002/mrc.1260261014; PFANDLER P, 1985, ANAL CHEM, V57, P2610; PFANDLER P, 1986, J MAGN RESON, V70, P71, DOI 10.1016/0022-2364(86)90363-X; Press W. H., 1986, NUMERICAL RECIPES AR; REICH G, 1988, SOFTWAREENTWICKLUNGE, V2, P291; STOVEN V, 1989, J MAGN RESON, V82, P163, DOI 10.1016/0022-2364(89)90177-7; VUISTER GW, 1990, BIOCHEMISTRY-US, V29, P1829, DOI 10.1021/bi00459a024; VUISTER GW, 1988, J MAGN RESON, V80, P176, DOI 10.1016/0022-2364(88)90072-8; WEBER PL, 1989, J MAGN RESON, V82, P419, DOI 10.1016/0022-2364(89)90049-8; WIDMER H, 1987, J MAGN RESON, V74, P316, DOI 10.1016/0022-2364(87)90341-6; WUTHRICH K, 1989, SCIENCE, V243, P45, DOI 10.1126/science.2911719; Wuthrich K, 1986, NMR PROTEINS NUCLEIC	35	30	31	ACADEMIC PRESS INC JNL-COMP SUBSCRIPTIONS	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495	0022-2364		J MAGN RESON		JUL	1990	88	3					601	608		10.1016/0022-2364(90)90291-G		8	Biochemical Research Methods; Physics, Atomic, Molecular & Chemical; Spectroscopy	Biochemistry & Molecular Biology; Physics; Spectroscopy	DM905	WOS:A1990DM90500012	
J	CASASENT, DP; BARNARD, E				CASASENT, DP; BARNARD, E			ADAPTIVE-CLUSTERING OPTICAL NEURAL NET	APPLIED OPTICS			English	Article										CASASENT, DP (reprint author), CARNEGIE MELLON UNIV,CTR EXCELLENCE OPT DATA PROC,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213, USA.						ANDERSON DZ, 1987, APPL OPTICS, V26, P5031, DOI 10.1364/AO.26.005031; BARNARD E, 1988, NEURAL NETWORKS S73, V1; BARNARD E, 1989, INT JOINT C NEURAL N; BARNARD E, 1989, IEEE T SYST MAN CYBE, V19; Baum E. B., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90020-9; BOTHA EC, 1988, INT C NEURAL NETWORK; CLARK D, 1988, OPT ENG, V27, P365; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FARHAT NH, 1987, APPL OPTICS, V26, P5093, DOI 10.1364/AO.26.005093; FISHER AD, 1987, APPL OPTICS, V26, P5039, DOI 10.1364/AO.26.005039; Hinton G. E., 1981, PARALLEL MODELS ASS; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; HSU K, 1988, INT C NEURAL NETWORK; IRIE B, 1988, INT C NEURAL NETWORK; KASDAN H, 1975, P ELECTROOPTICAL SYS, P248; KOHONEN T, 1988, INT C NEURAL NETWORK; KOSKO B, 1988, IEEE T SYST MAN CYB, V18, P49, DOI 10.1109/21.87054; Lapedes A., 1988, NEURAL INFORMATION P, P442; LEE LS, 1989, OPT LETT, V14, P162, DOI 10.1364/OL.14.000162; LENDARIS GG, 1979, P IEEE, V58, P198; MIRCHANDANI G, 1989, IEEE T CIRCUITS SYST, V36, P661, DOI 10.1109/31.31313; MONTGOMERY BL, 1986, APPL OPTICS, V25, P3759; POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790; PSALTIS D, 1985, OPT LETT, V10, P98, DOI 10.1364/OL.10.000098; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SOFFER BH, 1986, OPT LETT, V11, P118, DOI 10.1364/OL.11.000118; STINCHCOMBE M, 1989, INT C NEURAL NETWORK; WAGNER K, 1987, APPL OPTICS, V26, P5061, DOI 10.1364/AO.26.005061; WARDE C, 1983, OPT ENG, V22, P695; YOSHINAGA H, 1989, OPT LETT, V14, P202, DOI 10.1364/OL.14.000202; 1988, INT C NEURAL NETWORK; 1988, ADV NEURAL INFORMATI; 1989, INT JOINT C NEURAL N	34	21	21	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036	0003-6935		APPL OPTICS	Appl. Optics	JUN 10	1990	29	17					2603	2615				13	Optics	Optics	DJ528	WOS:A1990DJ52800015	
J	KETZ, JE				KETZ, JE			THE RELATIONSHIP OF ASSET FLOW MEASURES TO BOND RATINGS	AKRON BUSINESS AND ECONOMIC REVIEW			English	Article									LEHIGH UNIV,ACCOUNTING,BETHLEHEM,PA 18015; PENN STATE UNIV,MANAGEMENT INFORMAT SCI,UNIVERSITY PK,PA 16802	KETZ, JE (reprint author), PENN STATE UNIV,ACCOUNTING,UNIVERSITY PK,PA 16802, USA.						ALTMAN EI, 1985, FINANCIAL ANAL J, V41, P25, DOI 10.2469/faj.v41.n4.25; ALTMAN ER, 1981, APPLICATION CLASSIFI; Anderson T. W., 1958, INTRO MULTIVARIATE S; BALKAOUI A, 1983, IND BONDS RATING PRO; BELKAOUI A, 1980, FINANC MANAGE, V9, P44, DOI 10.2307/3664892; CASEY C, 1985, J ACCOUNTING RES, V23, P384, DOI 10.2307/2490926; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOYLE P, 1977, J BUS RES, V5, P235, DOI 10.1016/0148-2963(77)90013-3; DRTINA RE, 1985, ACCOUNT REV, V60, P314; EISENBEIS RA, 1972, DISCIRMINANT ANAL CL; Financial Accounting Standards Board, 1984, Statement of Financial Accounting Concepts No. 5 "Recognition and Measurement in Financial Statements of Business Enterprises"; Foster G., 1986, FINANCIAL STATEMENT; GENTRY JA, 1985, J ACCOUNTING RES, V23, P146, DOI 10.2307/2490911; GILBERT ES, 1968, J AM STAT ASSOC, V63, P1399, DOI 10.2307/2285893; GOMBOLA MJ, 1983, ACCOUNT REV, V58, P105; GOMBOLA MJ, 1983, FINANC MANAGE, V12, P45, DOI 10.2307/3665210; Hand D. J., 1981, DISCRIMINATION CLASS; HEATH L, 1978, FINANCIAL REPORTING; HORRIGAN JO, 1966, J ACCOUNTING RES, V4, P44, DOI 10.2307/2490168; IJIRI Y, 1979, ACCOUNTING SIMPILIFI, P57; IJIRI Y, 1978, J ACCOUNTING AUDITIN, V1, P331; IJIRI Y, 1980, FINANC EXECUTIVE, V48, P54; INGRAM FJ, 1982, J FINANC QUANT ANAL, V17, P227, DOI 10.2307/2330848; KAPLAN RS, 1979, J BUS, V52, P231, DOI 10.1086/296045; KENDALL MG, 1983, ADV THEORY STATISTIC; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL; LARGAY J, 1980, FINANCIAL ANAL J, V36, P51, DOI 10.2469/faj.v36.n4.51; MAHER JJ, 1987, ACCOUNT REV, V62, P785; MCKELVEY RD, 1975, J MATH SOCIOL, V4, P103; PERLES B, 1969, MODERN BUSINESS STAT; PINCHES GE, 1973, J FINANC, V28, P1, DOI 10.2307/2978164; POGUE TF, 1969, J FINANC QUANT ANAL, V4, P201, DOI 10.2307/2329840; PRESS SJ, 1978, J AM STAT ASSOC, V73, P699, DOI 10.2307/2286261; THOMAS BS, 1982, J ACCOUNTANCY, V154, P98; WEST RR, 1970, J ACCOUNTING RES, V8, P118, DOI 10.2307/2674717; *FIN ACC STAND BOA, 1981, EXP DRAFT REP INC CA; *FIN ACC STAND BOA, 1987, STAT CASH FLOWS, V95	37	0	0	AKRON BUS ECON REV	AKRON	UNIV AKRON, KOLBE HALL, AKRON, OH 44325	0044-7048		AKRON BUS ECON REV		SUM	1990	21	2					7	17				11	Business; Economics	Business & Economics	DP467	WOS:A1990DP46700001	
J	OMOHUNDRO, SM				OMOHUNDRO, SM			GEOMETRIC LEARNING ALGORITHMS	PHYSICA D			English	Article										OMOHUNDRO, SM (reprint author), INT COMP SCI INST,1947 CTR ST,SUITE 600,BERKELEY,CA 94704, USA.						BALLARD DH, 1987, BIOL CYBERN, V57, P389, DOI 10.1007/BF00354984; Breiman L, 1984, CLASSIFICATION REGRE; Charniak E., 1985, INTRO ARTIFICIAL INT; CHOU PBL, 1988, 258 U ROCH DEP COMP; CHURCHLAND PM, 1990, PHYSICA D, V42, P281, DOI 10.1016/0167-2789(90)90083-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWAN JD, 1989, COMMUNICATION; CRUTCHFIELD JP, 1987, COMPLEX SYSTEMS, V1; Devroye L.P., 1985, NONPARAMETRIC DENSIT; EDELSBRUNNER H, 1983, 104 TU GRAZ AUSTR RE; FARMER JD, 1987, LAUR871502 LOS AL NA; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; HOUGEN DR, 1988, UIUCDCSR881409 U ILL; Kohonen T., 1984, SELF ORG ASS MEMORY; LEE DT, 1984, IEEE T COMPUT, V33, P1072; LINSKER R, 1988, IEEE COMPUTER    MAR, P105; LINSKER R, 1987, NEURAL INFORMATION P, P485; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MCCLELLAND JL, 1986, MICROSTRUCTURE COGNI, V1; MEL BW, 1989, CCSR8917A U ILL CTR; MICHALSKI RS, 1986, MACHINE LEARNING, V1; MOODY J, 1988, YALEUDCSRR649 RES RE; Omohundro S. M., 1987, Complex Systems, V1; OMOHUNDRO SM, TR89063 INT COMP SCI; OMOHUNDRO SM, 1988, UIUCDCSR881408 U ILL; PAUL R, 1981, MANIPULATORS MATH PR; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Preparata F. P., 1985, COMPUTATIONAL GEOMET; REDDY R, 1988, F GRAND CHALLENGES A, P9; Samet H., 1984, ACM COMPUT SURV, V16, P187, DOI 10.1145/356924.356930; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; Tesauro G., 1987, Complex Systems, V1; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WALTERS D, 1987, 1ST P IEEE C NEUR NE, V3, P79	35	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-2789		PHYSICA D	Physica D	JUN	1990	42	1-3					307	321		10.1016/0167-2789(90)90085-4		15	Mathematics, Applied; Physics, Multidisciplinary; Physics, Mathematical	Mathematics; Physics	DR770	WOS:A1990DR77000024	
J	MAILHES, C; VERMANDE, P; CASTANIE, F				MAILHES, C; VERMANDE, P; CASTANIE, F			SPECTRAL IMAGE COMPRESSION	JOURNAL OF OPTICS-NOUVELLE REVUE D OPTIQUE			English	Article									CTR NATL ETUD SPATIALES,F-31055 TOULOUSE,FRANCE	MAILHES, C (reprint author), ECOLE NATL SUPER ELECTR ELECTROTECH INFORMAT & HYDRAUL TOULOUSE,GAPSE,2 RUE CAMICHEL,F-31071 TOULOUSE,FRANCE.						CHOW CK, IRE T ELECTRON COM, V6, P247; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KAY M, P IEEE, V69, P1380; MAIHES C, THESIS I NATIONAL PO; MAILHES C, APR INT C OPT SCI EN; MAILHES C, SPIE, V89, P6; MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792; MAX J, IRE T INFORM THEORY, V6, P7; ONEAL JB, 1972, IEEE T COMMUN, VCO20, P900, DOI 10.1109/TCOM.1972.1091281; VERMANDE P, 3RD P INT C SPECTR S, P227	10	13	19	MASSON EDITEUR	PARIS 06	120 BLVD SAINT-GERMAIN, 75280 PARIS 06, FRANCE	0150-536X		J OPT	J. Opt.-Nouv. Rev. Opt.	MAY-JUN	1990	21	3					121	132		10.1088/0150-536X/21/3/006		12	Optics	Optics	DY985	WOS:A1990DY98500006	
J	GEYER, ALM; MOREIRA, JC; FAIGLE, JF; BRUNS, RE; CURTIUS, AJ				GEYER, ALM; MOREIRA, JC; FAIGLE, JF; BRUNS, RE; CURTIUS, AJ			LOCAL AND TEMPORAL VARIATIONS IN ESSENTIAL ELEMENTS AND AGAR OF THE MARINE-ALGAE PTEROCLADIA-CAPILLACEA	HYDROBIOLOGIA			English	Article									UNIV FED RURAL RIO DE JANEIRO,DEPT QUIM,BR-23851 RIO DE JANEIRO,BRAZIL; UNIV ESTADUAL CAMPINAS,INST QUIM,BR-13100 CAMPINAS,SP,BRAZIL	GEYER, ALM (reprint author), PONTIFICIA UNIV CATOLICA RIO DE JANEIRO,DEPT QUIM,BR-22453 RIO DE JANEIRO,BRAZIL.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HORTA AMTC, 1978, ANAL CHIM ACTA, V96, P207, DOI 10.1016/S0003-2670(01)93417-8; KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233; Mardia K.V., 1979, MULTIVARIATE ANAL, P213; RAMIREZ M, 1985, HEAVY METALS ENV, V2, P271; SAWIDIS T, 1985, HEAVY METALS ENV, V1, P390; SHIBER JG, 1979, HYDROBIOLOGIA, V63, P105, DOI 10.1007/BF00030073; SHIBER JG, 1980, HYDROBIOLOGIA, V69, P147, DOI 10.1007/BF00016544; VARMUZA K, 1980, PATTERN RECOGN, P107; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; YAMAMOTO T, 1979, MARINE ALGAE PHARM S, P570; 1960, ANALYST, V85, P643	12	2	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0018-8158		HYDROBIOLOGIA	Hydrobiologia	APR 17	1990	194	2					143	148		10.1007/BF00028415		6	Marine & Freshwater Biology	Marine & Freshwater Biology	DB762	WOS:A1990DB76200005	
J	BAUM, EB				BAUM, EB			WHEN ARE K-NEAREST NEIGHBOR AND BACK PROPAGATION ACCURATE FOR FEASIBLE SIZED SETS OF EXAMPLES	LECTURE NOTES IN COMPUTER SCIENCE			English	Article										BAUM, EB (reprint author), NEC RES INST, 4 INDEPENDENCE WAY, PRINCETON, NJ 08540 USA.						ABUMOSTAFA YS, 1987, SCI AM, V256, P88; ANGLUIN D, 1979, J COMPUT SYST SCI, V18, P155, DOI 10.1016/0022-0000(79)90045-X; Baum E. B., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90020-9; BAUM EB, 1989, UNPUB PERCEPTRON ALG; Baum E.B., 1989, NEURAL COMPUTATION, V1; BAUM EB, 1989, J COMPLEXITY, V5; Baum E. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.1.151; BLUM A, 1989, ADV NEURAL INFORMATI, V1, P494; BLUMER A, IN PRESS J ACM; BLUMER A, 1987, UCSCCRL8720 U CAL SA; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1968, 1ST P ANN HAW C SYST, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENKER JS, 1988, NEURAL INFORMATION P, V1, P323; Duda R., 1973, PATTERN CLASSIFICATI; EHRENFEUCHT A, 1988, 1988 P WORKSH COMP L, P139; FRIEDMAN JH, 1977, ACM T MATH SOFTWARE, V3, P200; HAUSSLER D, 1969, UCSCCRL8930 U CAL SA; Judd S., 1988, Journal of Complexity, V4, DOI 10.1016/0885-064X(88)90019-2; PITT L, 1986, TR0586 HARV U TECH R; RIDGEWAY WC, 1962, 15561 STANF U SOL ST; RIVEST R, 1989, 2ND P ANN WORKSH COM; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WALTZ DL, 1988, DAEDALUS, V117, P191	24	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0302-9743		LECT NOTES COMPUT SC	Lect. Notes Comput. Sci.		1990	412						2	25				24	Computer Science, Theory & Methods	Computer Science	CX066	WOS:A1990CX06600001	
B	BAUM, EB		ALMEIDA, LB; WELLEKENS, CJ		BAUM, EB			WHEN ARE K-NEAREST NEIGHBOR AND BACK PROPAGATION ACCURATE FOR FEASIBLE SIZED SETS OF EXAMPLES	NEURAL NETWORKS /	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	WORKSHOP ON NEURAL NETWORKS	FEB 15-17, 1990	SESIMBRA, PORTUGAL	EUROPEAN ASSOC SIGNAL PROC, PHILIPS RES LAB BRUSSELS, BELL COMMUN RES						BAUM, EB (reprint author), NEC RES INST,4 INDEPENDENCE WAY,PRINCETON,NJ 08540, USA.							0	5	5	SPRINGER-VERLAG BERLIN	BERLIN	BERLIN		3-540-52255-7	LECT NOTES COMPUT SC			1990	412						2	25				24	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	BQ42C	WOS:A1990BQ42C00001	
J	SPECHT, DF				SPECHT, DF			PROBABILISTIC NEURAL NETWORKS	NEURAL NETWORKS			English	Article										SPECHT, DF (reprint author), LOCKHEED PALO ALTO RES LABS,O-91-10,B-256,3251 HANOVER ST,PALO ALTO,CA 94304, USA.						CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; MALONEY PS, 1988, 6TH ANN INT COMM AI; MARCHETTE D, 1987, 1987 P TRIS DAT FUS, V1, P230; Meisel W, 1972, COMPUTER ORIENTED AP; MOOD AM, 1962, INTRO THEORY STATIST; Murthy V. K., 1966, MULTIVARIATE ANAL, P43; MURTHY VK, 1965, ANN MATH STAT, V36, P1027, DOI 10.1214/aoms/1177700074; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SPECHT DF, 1967, IEEE T BIO-MED ENG, VBM14, P90, DOI 10.1109/TBME.1967.4502476; SPECHT DF, 1966, THESIS STANFORD U; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; Specht D.F., 1988, P IEEE INT C NEURAL, V1, P525; SPECHT DF, SUSEL66029 STANF EL; WIDROW B, 1963, 1963 WESCON CONV REC	16	1191	1255	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0893-6080		NEURAL NETWORKS	Neural Netw.		1990	3	1					109	118		10.1016/0893-6080(90)90049-Q		10	Computer Science, Artificial Intelligence	Computer Science	CM513	WOS:A1990CM51300008	
J	MAZZOLA, S				MAZZOLA, S			A K-NEAREST NEIGHBOR-BASED METHOD FOR THE RESTORATION OF DAMAGED IMAGES	PATTERN RECOGNITION			English	Article										MAZZOLA, S (reprint author), CNR,IST FISIOPATOL RESP,PALERMO,ITALY.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1980, PATTERN RECOGNITION; DIGESU V, 1984, SIGNAL PROCESS, V6, P201; FEUSTEL CD, 1982, PATTERN RECOGNITION, V1; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6; FUKUNAGA K, 1982, PATTERN RECOGNITION, V1; GULL SF, 1978, NATURE, V22, P688; Hall E.L., 1979, COMPUTER IMAGE PROCE; KATSINIS C, 1987, IEEE T PATTERN ANAL, V9; SHORT RD, 1981, IEEE T INF THEORY, V27; WOODS JW, 1981, 2 DIMENSIONAL DIGITA; XIE WX, 1985, 1ST P ISFA C PALM DE	12	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1990	23	1-2					179	184		10.1016/0031-3203(90)90058-S		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	CY742	WOS:A1990CY74200014	
J	MYLES, JP; HAND, DJ				MYLES, JP; HAND, DJ			THE MULTICLASS METRIC PROBLEM IN NEAREST NEIGHBOR DISCRIMINATION RULES	PATTERN RECOGNITION			English	Article									OPEN UNIV,FAC MATH,MILTON KEYNES MK7 6AA,BUCKS,ENGLAND							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1983, TREE8236 PURD U TECH; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; Fukunaga K., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90043-5; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SHORT RD, 1980, 5TH INT C PATT REC M, P81	6	36	37	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1990	23	11					1291	1297		10.1016/0031-3203(90)90123-3		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	EE540	WOS:A1990EE54000012	
J	PATRICK, EA				PATRICK, EA			THE OUTCOME ADVISER	PATTERN RECOGNITION			English	Article									UNIV CINCINNATI,ELECT & COMP ENGN,CINCINNATI,OH 45221; PURDUE UNIV,ELECT ENGN,W LAFAYETTE,IN 47907; DEACONESS HOSP,INFORMAT,CINCINNATI,OH; HEIMLICH INST,CINCINNATI,OH	PATRICK, EA (reprint author), PATRICK CONSULT INC,810 MATSON PL,CINCINNATI,OH 45204, USA.						Cooper G. R., 1971, PROBABILISTIC METHOD; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FATTU JM, 1987, 1987 P SMAC, P171; GROSSBER.S, 1969, J MATH MECH, V19, P53; HECHTNIELSEN R, 1987, APPL OPTICS, V26; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; KOHONEN T, 1988, JUL IEEE INT C NEUR, P161; Lorentz G. G., 1976, MATH DEV ARISING HIL; Minsky M., 1969, PERCEPTRONS; Patrick E. A., 1972, FUNDAMENTALS PATTERN; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; PATRICK EA, 1968, IEEE T COMPUT, VC 17, P949, DOI 10.1109/TC.1968.226443; PATRICK EA, 1979, DECISION ANAL MED; PATRICK EA, 1986, ARTIFICIAL INTELLIGE; PATRICK EA, 1987, TR1020487ECE U CINC; PATRICK EA, 1969, TREE6924 PURD U SCH; PATRICK EA, 1987, TD1101087ECE U CINC; Pearl J., 1985, HEURISTICS; Rosenblatt Frank, 1959, PRINCIPLES NEURODYNA; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; WIDROW B, 1973, IEEE T SYST MAN CYBE, V3	22	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1990	23	12					1427	1439		10.1016/0031-3203(90)90088-3		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	EJ795	WOS:A1990EJ79500012	
J	SILVERMAN, BW; JONES, MC				SILVERMAN, BW; JONES, MC			FIX,E, AND HODGES,JL, (1951) - AN IMPORTANT CONTRIBUTION TO NONPARAMETRIC DISCRIMINANT-ANALYSIS AND DENSITY-ESTIMATION - COMMENTARY ON FIX AND HODGES (1951)	INTERNATIONAL STATISTICAL REVIEW			English	Article										SILVERMAN, BW (reprint author), UNIV BATH,SCH MATH SCI,BATH BA2 7AY,AVON,ENGLAND.		Jones, Chris/A-3687-2009; Silverman, Bernard/K-6417-2012	Silverman, Bernard/0000-0002-4059-2376			Agrawala A.K., 1977, MACHINE RECOGNITION; CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; Coomans D., 1986, POTENTIAL PATTERN RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1973, DISCRIMINANT ANAL AP, P77; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L.P., 1985, NONPARAMETRIC DENSIT; Fisher RA, 1936, ANN EUGENIC, V7, P179; FIX E, 1977, DISCRIMINATORY ANAL; Hand D. J., 1981, DISCRIMINATION CLASS; Hand D. J., 1982, KERNEL DISCRIMINANT; HOEL PG, 1949, ANN MATH STAT, V20, P433, DOI 10.1214/aoms/1177729995; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MARRON JS, 1989, EMPIRICAL EC, V13, P187; Prakasa Rao B. L. S., 1983, NONPARAMETRIC FUNCTI; PRAZEN E, 1962, ANN MATH STAT, V33, P1605; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Silverman B.W., 1986, DENSITY ESTIMATION S	18	22	22	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	0306-7734		INT STAT REV	Int. Stat. Rev.	DEC	1989	57	3					233	247		10.2307/1403796		15	Statistics & Probability	Mathematics	CE419	WOS:A1989CE41900004	
J	BENIGNI, R; ANDREOLI, C; GIULIANI, A				BENIGNI, R; ANDREOLI, C; GIULIANI, A			QUANTITATIVE STRUCTURE ACTIVITY RELATIONSHIPS - PRINCIPLES, AND APPLICATIONS TO MUTAGENICITY AND CARCINOGENICITY	MUTATION RESEARCH			English	Review										BENIGNI, R (reprint author), IST SUPER SANITA,TOXICOL & ECOTOXICOL LAB,I-00161 ROME,ITALY.						ARIENS EJ, 1984, DRUG METAB REV, V15, P425, DOI 10.3109/03602538409029970; BAWDEN D, 1983, J CHEM INF COMP SCI, V23, P14, DOI 10.1021/ci00037a003; BENZECRI JP, 1980, PRATIQUE ANAL DONNEE; CHAO MV, 1986, SCIENCE, V232, P518, DOI 10.1126/science.3008331; CHOU JT, 1979, J MED CHEM, V22, P792, DOI 10.1021/jm00193a008; CHU KC, 1975, J MED CHEM, V18, P539, DOI 10.1021/jm00240a001; COATS E, 1970, J MED CHEM, V13, P913, DOI 10.1021/jm00299a027; COLLANDER R, 1954, PHYSIOL PLANTARUM, V7, P420, DOI 10.1111/j.1399-3054.1954.tb07589.x; COLLOUS T, 1973, DISCRIMINANT ANAL AP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMER RD, 1974, J MED CHEM, V17, P533, DOI 10.1021/jm00251a014; Daniel C, 1980, FITTING EQUATIONS DA; DOVE S, 1980, J MED CHEM, V23, P1456, DOI 10.1021/jm00186a033; DUNN WJ, 1981, J CHEM INF COMP SCI, V21, P8, DOI 10.1021/ci00029a003; DUNN WJ, 1978, J MED CHEM, V21, P1001, DOI 10.1021/jm00208a001; DUNN WJ, 1981, BIOORG CHEM, V10, P29, DOI 10.1016/0045-2068(81)90041-9; Eakin D. R., 1974, Computer representation and manipulation of chemical information; ENSLEIN K, 1982, J TOXICOL ENV HEALTH, V10, P521; ENSLEIN K, 1983, TERATOGEN CARCIN MUT, V3, P503, DOI 10.1002/1520-6866(1990)3:6<503::AID-TCM1770030606>3.0.CO;2-O; FRANKE R, 1979, FARMACO-ED SCI, V34, P545; FRANKE R, 1984, THEORETICAL DRUG DES; FRANKE R, 1985, ENV HLTH PERSPECT, V61, P275; FREE SM, 1964, J MED CHEM, V7, P395, DOI 10.1021/jm00334a001; FRIEDBERG MA, 1985, DNA REPAIR; FRIERSON MR, 1986, ENVIRON MOL MUTAGEN, V8, P283, DOI 10.1002/em.2860080210; FUJITA T, 1964, J AM CHEM SOC, V86, P5175, DOI 10.1021/ja01077a028; HAGEMANN R, 1976, PHARMAZIE, V31, P130; HANSCH C, 1980, J MED CHEM, V23, P459, DOI 10.1021/jm00178a019; HANSCH C, 1973, J MED CHEM, V16, P1207, DOI 10.1021/jm00269a003; HANSCH C, 1964, J AM CHEM SOC, V86, P1616, DOI 10.1021/ja01062a035; Hansch C., 1977, BIOL ACTIVITY CHEM S; HANSCH C, 1979, J MED CHEM, V22, P473; Hansch C., 1979, SUBSTITUENT CONSTANT; HANSCH C, 1976, J MED CHEM, V19, P1, DOI 10.1021/jm00223a001; HASEMAN JK, 1987, ENVIRON HEALTH PERSP, V74, P229, DOI 10.2307/3430453; HENRY DR, 1980, EUR J MED CHEM, V15, P133; HODES L, 1981, J CHEM INF COMP SCI, V21, P132, DOI 10.1021/ci00031a004; HOPFINGER AJ, 1982, MOL PHARMACOL, V21, P187; JURS PC, 1979, J MED CHEM, V22, P476, DOI 10.1021/jm00191a004; JURS PC, 1983, FUND APPL TOXICOL, V3, P343, DOI 10.1016/S0272-0590(83)80002-5; JURS PC, 1985, J CHEM INF COMP SCI, V25, P296, DOI 10.1021/ci00047a028; Kier LB, 1976, MOL CONNECTIVITY CHE; KIER LB, 1978, J PHARM SCI, V67, P725, DOI 10.1002/jps.2600670548; KIRSCHNER GL, 1979, DRUG DESIGN, V8, P73; KLOPMAN G, 1985, MUTAT RES, V147, P343, DOI 10.1016/0165-1161(85)90003-2; KLOPMAN G, 1984, MUTAT RES, V126, P139, DOI 10.1016/0027-5107(84)90055-1; KLOPMAN G, 1985, J COMPUT CHEM, V6, P28, DOI 10.1002/jcc.540060106; KLOPMAN G, 1985, MOL BASIS CANC, P287; KLOPMAN G, 1984, J AM CHEM SOC, V106, P7315, DOI 10.1021/ja00336a004; KLOPMAN G, 1985, ENVIRON MUTAGEN, V7, P625, DOI 10.1002/em.2860070503; KUNTZ ID, 1980, BURGERS MED CHEM; Lebart L., 1984, MULTIVARIATE DESCRIP; LEHNINGER AL, 1981, BIOCH MOL BASIS CELL; LEO A, 1985, ENVIRON HEALTH PERSP, V61, P275, DOI 10.2307/3430078; LEWI PJ, 1980, DRUG DESIGN, V10, P308; LOEW G, 1980, CHEM-BIOL INTERACT, V31, P319, DOI 10.1016/0009-2797(80)90020-4; MACKAY D, 1977, KINETICS DRUG ACTION; MARTIN YC, 1981, J MED CHEM, V24, P229, DOI 10.1021/jm00135a001; MARTIN YC, 1978, QUANTITATIVE DRUG DE; MARTIN YC, 1974, J MED CHEM, V17, P409, DOI 10.1021/jm00250a008; MAUTNER HG, 1980, BURGERS MED CHEM; MAYER H, 1899, ARCH EXP PATHOL PHAR, V42, P110; MCCOY EC, 1985, MUTAT RES, V149, P311, DOI 10.1016/0027-5107(85)90146-0; NEELY WB, 1975, INT J QUANT CHEM QUA, V2, P171; NORDEN B, 1978, ACTA CHEM SCAND B, V32, P602, DOI 10.3891/acta.chem.scand.32b-0602; OSMAN R, 1979, ACS SYM SER, V112, P71; Overton E., 1901, STUDIEN NARKOSE; Richards W. G., 1983, QUANTUM PHARM; ROSE SL, 1982, J MED CHEM, V25, P769, DOI 10.1021/jm00349a002; ROSENKRANZ HS, 1983, MUTAT RES, V114, P217, DOI 10.1016/0165-1110(83)90034-9; ROSENKRANZ HS, 1988, MUTAT RES, V199, P95, DOI 10.1016/0165-1161(88)90236-1; ROZENBLIT AB, 1982, STRATEGY DRUG DESIGN, P287; SINGER GM, 1977, CHEM-BIOL INTERACT, V19, P133, DOI 10.1016/0009-2797(77)90026-6; SINGER GM, 1986, J MED CHEM, V29, P40, DOI 10.1021/jm00151a006; SNEDECOR GW, 1967, METHODES STATISTIQUE; Stuper AJ, 1979, COMPUTER ASSISTED ST; TINKER J, 1981, J CHEM INF COMP SCI, V21, P3, DOI 10.1021/ci00029a002; TINKER JF, 1981, J COMPUT CHEM, V2, P231, DOI 10.1002/jcc.540020304; TOPLISS JG, 1972, J MED CHEM, V15, P1066, DOI 10.1021/jm00280a017; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; WALSH DB, 1987, MUTAT RES, V182, P55, DOI 10.1016/0165-1161(87)90054-9; WISHNOK JS, 1976, BRIT J CANCER, V33, P307, DOI 10.1038/bjc.1976.44; WISHNOK JS, 1978, CHEM-BIOL INTERACT, V20, P43, DOI 10.1016/0009-2797(78)90079-0; WOLD S, 1984, ANALUSIS, V12, P477; YUAN M, 1980, TOXICOL APPL PHARM, V52, P294, DOI 10.1016/0041-008X(80)90117-9; YUTA K, 1981, J MED CHEM, V24, P241, DOI 10.1021/jm00135a003; 1986, HDI TOXICOL NEWSLETT, V5; 1985, HDI TOXICOL NEWSLETT, V4	88	30	30	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0921-8262		MUTAT RES		NOV	1989	221	3					197	216		10.1016/0165-1110(89)90036-5		20	Genetics & Heredity; Toxicology	Genetics & Heredity; Toxicology	AZ960	WOS:A1989AZ96000004	
J	CABELLO, D; SALCEDA, JM; BARRO, S; RUIZ, R; MIRA, J				CABELLO, D; SALCEDA, JM; BARRO, S; RUIZ, R; MIRA, J			STATISTICS TECHNIQUES FOR DIAGNOSIS OF VENTRICULAR ARRHYTHMIAS	REVISTA DE INFORMATICA Y AUTOMATICA			Spanish	Article										CABELLO, D (reprint author), UNIV SANTIAGO DE COMPOSTELA,FAC FIS,DEPT ELECTR,SANTIAGO,SPAIN.						BARRO S, 1988, THESIS U SANTIAGO CO; BARRO S, IN PRESS J BIOMEDICA; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bezdek J.C., 1982, PATTERN RECOGNITION; Bezdek J.C., 1973, THESIS CORNELL U ITH; CABELLO D, 1988, 10TH EMBS ANN C NEW; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Dunn J., 1974, J CYBERNETICS, V3, P32; FOSTER FK, 1983, COMPUT CARDIOL, P319; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gustafson D. E., 1979, P IEEE CDC, V2, P761; Herbschleb J. N., 1980, Computers in Cardiology; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KITTLER J, 1981, PATTERN RECOGN, V13, P245, DOI 10.1016/0031-3203(81)90101-1; Nygards M.-E., 1977, Computers in Cardiology; RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1; SALCEDA JM, 1988, CLASIFICADORES FUZZY	18	0	0	ASOC ESPANOLA INFORM AUTOMAT	MADRID	FACULTAD CIENCIAS FISICAS CIUDAD UNIV, 28040 MADRID, SPAIN			REV INFORM AUTOMAT		OCT-DEC	1989	22	4					45	52				8	Computer Science, Interdisciplinary Applications	Computer Science	CP661	WOS:A1989CP66100004	
J	ELSHEIKH, TS; SYIAM, MM				ELSHEIKH, TS; SYIAM, MM			AN EFFICIENT TECHNIQUE FOR LITHOLOGY CLASSIFICATION	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article										ELSHEIKH, TS (reprint author), UNIV CAIRO,FAC ENGN,DEPT ELECTR & COMMUN,GIZA,EGYPT.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1980, 6TH P INT C PATT REC, P72; Duda R., 1973, PATTERN CLASSIFICATI; FU KS, 1980, IEEE T COMPUT, V29, P845; HALLIDAY DL, 1985, IEEE T SYST MAN CYBE, V15; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; SERRA O, 1985, SPE13290, P1; SERRA O, 1982, 55TH P ANN TECH C SP, P90; SINVHAL A, 1987, SEISMIC EXPLORATION, V20; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; WASFI S, 1986, 8TH EGPC EXPL C; 1972, LOG INTERPRETATION, V1	12	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	SEP	1989	27	5					629	632		10.1109/TGRS.1989.35946		4	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	AL207	WOS:A1989AL20700019	
J	BRECKENRIDGE, JN				BRECKENRIDGE, JN			REPLICATING CLUSTER-ANALYSIS - METHOD, CONSISTENCY, AND VALIDITY	MULTIVARIATE BEHAVIORAL RESEARCH			English	Article										BRECKENRIDGE, JN (reprint author), PALO ALTO VET ADM MED CTR,DEPT PSYCHOL 116B PAD,3801 MIRANDA AVE,PALO ALTO,CA 94304, USA.						BEASLY JD, 1985, APPL STAT ALGORITHMS, P188; Blashfield R. K., 1984, CLASSIFICATION PSYCH; BLASHFIELD RK, 1976, PSYCHOL BULL, V83, P377, DOI 10.1037//0033-2909.83.3.377; BOX GEP, 1949, BIOMETRIKA, V36, P317, DOI 10.2307/2332671; Bradley L A, 1978, J Behav Med, V1, P253, DOI 10.1007/BF00846678; Breiman L, 1984, CLASSIFICATION REGRE; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRONBACH LJ, 1953, PSYCHOL BULL, V50, P456, DOI 10.1037/h0057173; CYR JJ, 1986, J CLIN PSYCHOL, V42, P92, DOI 10.1002/1097-4679(198601)42:1<92::AID-JCLP2270420114>3.0.CO;2-2; Devijver P. A., 1982, PATTERN RECOGNITION; EDELBROCK C, 1980, MULTIVAR BEHAV RES, V15, P299, DOI 10.1207/s15327906mbr1503_5; EDELBROCK C, 1979, MULTIVAR BEHAV RES, V14, P367, DOI 10.1207/s15327906mbr1403_6; Gordon A.D, 1981, CLASSIFICATION METHO; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; KENNEDY WJ, 1980, STATISTICAL COMPUTIN; Knuth D. E., 1981, ART COMPUTER PROGRAM, V2; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; LIN SP, 1985, APPL STAT-J ROY ST C, V34, P193, DOI 10.2307/2347377; McIntyre R, 1980, MULTIVARIATE BEHAV R, V2, P225; MCLEOD AI, 1985, APPL STAT-J ROY ST C, V34, P198, DOI 10.2307/2347378; MILLIGAN GW, 1987, APPL PSYCH MEAS, V11, P329, DOI 10.1177/014662168701100401; MOREY LC, 1983, MULTIVAR BEHAV RES, V18, P309, DOI 10.1207/s15327906mbr1803_4; OVERALL JE, 1983, APPLIED MULTIVARIATE; SCHEIBLER D, 1985, MULTIVAR BEHAV RES, V20, P283, DOI 10.1207/s15327906mbr2003_4; SKINNER HA, 1978, EDUC PSYCHOL MEAS, V38, P297, DOI 10.1177/001316447803800211; STONE M, 1974, J R STAT SOC B, V36, P111; TVERSKY A, 1983, J MATH PSYCHOL, V27, P235, DOI 10.1016/0022-2496(83)90008-1; TVERSKY A, 1986, PSYCHOL REV, V93, P3, DOI 10.1037/0033-295X.93.1.3; WALLER WG, 1978, IEEE T INFORM THEORY, V24, P392, DOI 10.1109/TIT.1978.1055877; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; WICHMANN BA, 1985, APPLIED STATISTICS A, P238	34	81	82	LAWRENCE ERLBAUM ASSOC INC	MAHWAH	10 INDUSTRIAL AVE, MAHWAH, NJ 07430-2262	0027-3171		MULTIVAR BEHAV RES	Multivariate Behav. Res.	APR	1989	24	2					147	161		10.1207/s15327906mbr2402_1		15	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Psychology, Experimental; Statistics & Probability	Mathematics; Mathematical Methods In Social Sciences; Psychology	U8059	WOS:A1989U805900001	
J	NIESSNER, R; HEMMERICH, B; PANNE, U				NIESSNER, R; HEMMERICH, B; PANNE, U			POSSIBILITIES AND LIMITATIONS OF THE PHOTOELECTRIC AEROSOL SENSOR ARRAY APPLIED TO HEAVY-METAL AEROSOLS	FRESENIUS ZEITSCHRIFT FUR ANALYTISCHE CHEMIE			English	Article										NIESSNER, R (reprint author), UNIV DORTMUND,POB 500500,D-4600 DORTMUND 50,FED REP GER.		Niessner, Reinhard/C-1414-2010; Niessner, Reinhard/D-1502-2010; Panne, Ulrich/C-7136-2009				BURTSCHER H, 1984, SCI TOTAL ENVIRON, V36, P233, DOI 10.1016/0048-9697(84)90271-7; BUSIGIN A, 1980, J AEROSOL SCI, V11, P359, DOI 10.1016/0021-8502(80)90044-0; CHENG YS, 1980, J AEROSOL SCI, V11, P549, DOI 10.1016/0021-8502(80)90127-5; CHENG YS, 1980, J AEROSOL SCI, V11, P313, DOI 10.1016/0021-8502(80)90105-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EHRENHAFT F, 1910, WIEN BER, P836; EICHHORN F, 1988, DVS BERICHTE, V112, P25; EICHHORN F, 1988, DVS BERICHTE, V112, P29; GLINSMANN PW, 1985, AM IND HYG ASSOC J, V46, P391, DOI 10.1202/0002-8894(1985)046<0391:EOAAPF>2.3.CO;2; HAHN JU, 1988, STAUB REINHALT LUFT, V48, P95; JOCKEL W, 1988, STAUB REINHALT LUFT, V46, P250; KANAPILLY GM, 1970, J AEROSOL SCI, V1, P313, DOI 10.1016/0021-8502(70)90005-4; KAPADIA A, 1980, THESIS U MINNESOTA M; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KVALHEIM OM, 1987, THESIS U BERGEN NORW; LAM HF, 1988, AM IND HYG ASSOC J, V49, P333, DOI 10.1202/0002-8894(1988)049<0333:PFOGPE>2.0.CO;2; Lorber A., 1987, J CHEMOMETR, V1, P19, DOI 10.1002/cem.1180010105; Malinowski E., 1980, FACTOR ANAL CHEM; MARKOWSKI GR, 1987, AEROSOL SCI TECH, V7, P127, DOI 10.1080/02786828708959153; MARTENS H, 1987, Journal of Chemometrics, V1, P201, DOI 10.1002/cem.1180010403; MARTENS H, 1985, THESIS U TRONDHEIM N; Massart D.L., 1988, CHEMOMETRICS TXB; Massart DL, 1983, INTERPRETATION ANAL; MASUDA S, 1983, 1ST S AER SCI TECHN, P35; MORETON J, 1980, ANAL SCI MONOGRAPHS, V52, P17; NIESSNER R, 1989, FRESEN Z ANAL CHEM, V333, P129, DOI 10.1007/BF00474022; NIESSNER R, 1986, J AEROSOL SCI, V17, P705, DOI 10.1016/0021-8502(86)90050-9; NIESSNER R, 1989, ANAL CHEM, V61, P708, DOI 10.1021/ac00182a014; NIESSNER R, 1988, FRESENIUS Z ANAL CHE, V329, P406; NORTH MR, 1988, J ANAL ATOM SPECTROM, V3, P687, DOI 10.1039/ja9880300687; RAMAMURTHI M, 1987, J AEROSOL SCI, V18, P175, DOI 10.1016/0021-8502(87)90054-1; ROEDER M, 1987, METALLVERARBEITUNG, V41, P168; Sharaf MA, 1986, CHEMOMETRICS; Sinclair D., 1979, AEROSOL MEASUREMENTS, P544; SINCLAIR D, 1975, AM IND HYG ASSOC J, V36, P39, DOI 10.1080/0002889758507205; TWOMEY S, 1975, J COMPUT PHYS, V18, P188, DOI 10.1016/0021-9991(75)90028-5; Wold H., 1966, RES PAPERS STAT, V2, P411; Wold H., 1966, MULTIVARIATE ANAL, P391; Wold S., 1984, NATO ASI SER C-MATH, V138, P17; WOLD S, 1984, SIAM J SCI STAT COMP, V5, P735, DOI 10.1137/0905052; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; WU JJ, 1989, REV SCI INSTRUM, V60, P258, DOI 10.1063/1.1140418; 1986, STAUBREINHAULT LUFT, V44, pM66	43	1	1	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0016-1152		FRESEN Z ANAL CHEM			1989	335	7					728	737		10.1007/BF01204077		10	Chemistry, Analytical	Chemistry	CC288	WOS:A1989CC28800017	
J	BAUMANN, P; JURGENSEN, T; HEUCK, CC				BAUMANN, P; JURGENSEN, T; HEUCK, CC			COMPUTERIZED ANALYSIS OF THE INVITRO ACTIVATION OF THE PLASMATIC CLOTTING SYSTEM	HAEMOSTASIS			English	Article									UNIV HEIDELBERG,KINDERKLIN,ZENT LAB,D-6900 HEIDELBERG,FED REP GER							BECKER U, 1984, THROMB RES, V35, P475, DOI 10.1016/0049-3848(84)90280-9; BECKER U, 1985, THROMB RES, V40, P721, DOI 10.1016/0049-3848(85)90310-X; BECKER U, 1984, CLIN CHEM, V30, P524; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAREED J, 1983, CLIN CHEM, V29, P225; Fareed J, 1981, Ann N Y Acad Sci, V370, P765, DOI 10.1111/j.1749-6632.1981.tb29784.x; HEMKER HC, 1969, PROC R SOC SER B-BIO, V173, P411, DOI 10.1098/rspb.1969.0068; HEMKER HC, 1977, THROMB HAEMOSTASIS, V37, P81; HEMKER HC, 1965, THROMB DIATH HAEMOST, V13, P155; HEMKER HC, 1979, THROMB HAEMOSTASIS, V41, P309; LOTTENBERG R, 1983, BIOCHIM BIOPHYS ACTA, V742, P539, DOI 10.1016/0167-4838(83)90272-8; LOTTENBERG R, 1986, BIOCHIM BIOPHYS ACTA, V874, P326, DOI 10.1016/0167-4838(86)90032-4; MASYS DR, 1982, BLOOD, V60, P1143; Messmore H L Jr, 1981, Ann N Y Acad Sci, V370, P785, DOI 10.1111/j.1749-6632.1981.tb29785.x; OSTERUD B, 1977, P NATL ACAD SCI USA, V74, P5260, DOI 10.1073/pnas.74.12.5260; RAPAPORT SI, 1963, BLOOD, V21, P221; SVENDSEN L, 1972, THROMB RES, V1, P267, DOI 10.1016/0049-3848(72)90023-0	17	9	9	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0301-0147		HAEMOSTASIS	Haemostasis		1989	19	6					309	321				13	Hematology	Hematology	CB218	WOS:A1989CB21800002	
J	PARK, Y; SKLANSKY, J				PARK, Y; SKLANSKY, J			AUTOMATED DESIGN OF MULTIPLE-CLASS PIECEWISE LINEAR CLASSIFIERS	JOURNAL OF CLASSIFICATION			English	Article										PARK, Y (reprint author), UNIV CALIF IRVINE,DEPT ELECT ENGN,IRVINE,CA 92717, USA.						CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1980, PATTERN RECOGNITION; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55; Duda R., 1973, PATTERN CLASSIFICATI; DUDANI SA, 1977, IEEE T COMPUT, V26, P39; FORGY EW, 1965, BIOMETRICS, V21, P768; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HU M, 1962, IRE T INFORM THEOR, V8, P179; Jacoby S. L. S., 1972, ITERATIVE METHODS NO; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; MANGASAR.OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; SANTIAGO HL, 1983, THESIS U CALIFORNIA; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101; Sklansky J., 1981, PATTERN CLASSIFIERS; TAKIYAMA R, 1980, PATTERN RECOGN, V12, P75, DOI 10.1016/0031-3203(80)90005-9; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	19	25	25	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0176-4268		J CLASSIF	J. Classif.		1989	6	2					195	222		10.1007/BF01908599		28	Mathematics, Interdisciplinary Applications; Psychology, Mathematical	Mathematics; Psychology	AY904	WOS:A1989AY90400003	
J	GORMAN, RP; SEJNOWSKI, TJ				GORMAN, RP; SEJNOWSKI, TJ			LEARNED CLASSIFICATION OF SONAR TARGETS USING A MASSIVELY PARALLEL NETWORK	IEEE TRANSACTIONS ON ACOUSTICS SPEECH AND SIGNAL PROCESSING			English	Article									JOHNS HOPKINS UNIV,DEPT BIOPHYS,BALTIMORE,MD 21218	GORMAN, RP (reprint author), ALLIED SIGNAL AEROSP TECHNOL CTR,TECH STAFF,COLUMBIA,MD 21045, USA.						ACKLEY DH, 1985, COGNITIVE SCI, V9, P147, DOI 10.1016/S0364-0213(85)80012-4; CHEN CH, 1976, PATTERN RECOGN, P135; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denker J., 1987, Complex Systems, V1; fu K. S., 1970, Adaptive, learning, and pattern recognition systems: theory and applications; FU KS, 1980, IEEE T COMPUT, V29, P845; FU KS, 1970, IEEE T SYST SCI CYB, VSSC6, P33, DOI 10.1109/TSSC.1970.300326; FU KS, 1982, PATTERN RECOGN, P139; GORMAN RP, 1987, UNPUB J ACOUST S JUL; HARALICK RM, 1983, IEEE T PATTERN ANAL, V5, P417; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; LEVINSON SE, 1985, P IEEE, V73, P1625, DOI 10.1109/PROC.1985.13344; LIPPMANN RP, 1987, IEEE ASSP MAG    APR; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sejnowski T. J., 1987, Complex Systems, V1; SEJNOWSKI TJ, 1986, PHYSICA D, V22, P260, DOI 10.1016/0167-2789(86)90245-9; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; WAIBEL A, 1987, ATR TR10006 INT TEL; WATROUS RL, 1987, 9TH P ANN COGN SCI C, P518; WIDROW G, 1960, P IRE W ELECTRON S 4, P96	20	105	109	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0096-3518		IEEE T ACOUST SPEECH		JUL	1988	36	7					1135	1140		10.1109/29.1640		6	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	N9867	WOS:A1988N986700024	
J	DAVIES, ER				DAVIES, ER			TRAINING SETS AND A-PRIORI PROBABILITIES WITH THE NEAREST NEIGHBOR METHOD OF PATTERN-RECOGNITION	PATTERN RECOGNITION LETTERS			English	Article										DAVIES, ER (reprint author), ROYAL HOLLOWAY & BEDFORD NEW COLL,DEPT PHYS,MACHINE VIS GRP,EGHAM HILL,EGHAM TW20 OEX,SURREY,ENGLAND.						CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; Duda R., 1973, PATTERN CLASSIFICATI; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	7	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL	1988	8	1					11	13		10.1016/0167-8655(88)90017-7		3	Computer Science, Artificial Intelligence	Computer Science	P9140	WOS:A1988P914000003	
J	GARBER, FD; DJOUADI, A				GARBER, FD; DJOUADI, A			BOUNDS ON THE BAYES CLASSIFICATION ERROR BASED ON PAIRWISE RISK FUNCTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter										GARBER, FD (reprint author), OHIO STATE UNIV,DEPT ELECT ENGN,ELECTROSCI LAB,COLUMBUS,OH 43210, USA.						CHEN C, 1973, STATISTICAL PATTERN; CHEN CH, 1978, MAY P IEEE COMP SOC, P188; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; Devijver P. A., 1982, PATTERN RECOGNITION; DJOUADI A, 1987, THESIS OHIO STATE U; DJOUADI A, 7180483 EL LAB REP; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779; JAIN AK, 1976, IEEE T SYST MAN CYB, V6, P763; KAMIS A, 1985, 7165591 OH STAT U DE; KITTLER J, 1982, IEEE T PATTERN ANAL, V4, P215; KSIENSKI AA, 1975, P IEEE, V63, P1651, DOI 10.1109/PROC.1975.10033; LAINIOTI.DG, 1969, IEEE T INFORM THEORY, V15, P730, DOI 10.1109/TIT.1969.1054374; LAINIOTIS DG, 1971, IEEE T SYST MAN CYBE, V11, P175; LISSACK TSVI, 1976, IEEE T INFORM THEORY, V22, P34, DOI 10.1109/TIT.1976.1055512; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TOUSSAINT GT, 1977, P IEEE, V65, P275, DOI 10.1109/PROC.1977.10469	18	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					281	288		10.1109/34.3891		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	M2974	WOS:A1988M297400013	
J	NIEMANN, H; GOPPERT, R				NIEMANN, H; GOPPERT, R			AN EFFICIENT BRANCH-AND-BOUND NEAREST NEIGHBOR CLASSIFIER	PATTERN RECOGNITION LETTERS			English	Article										NIEMANN, H (reprint author), UNIV ERLANGEN NURNBERG,LEHRSTUHL INFORMAT 5 MUSTERERKENNUNG,MARTENSSTR 3,D-8520 ERLANGEN,FED REP GER.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KAMGARPARSI B, 1985, PATTERN RECOGN LETT, V3, P7, DOI 10.1016/0167-8655(85)90036-4; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769	8	21	21	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB	1988	7	2					67	72		10.1016/0167-8655(88)90120-1		6	Computer Science, Artificial Intelligence	Computer Science	M4509	WOS:A1988M450900001	
J	KELLER, JM; QIU, HJ				KELLER, JM; QIU, HJ			FUZZY SET METHODS IN PATTERN-RECOGNITION	LECTURE NOTES IN COMPUTER SCIENCE			English	Article										KELLER, JM (reprint author), UNIV MISSOURI,COLUMBIA,MO 65211, USA.						Bezdek J., 1981, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fu K. S., 1974, SYNTACTIC METHODS PA; Kandel A, 1982, FUZZY TECHNIQUES PAT; KELLER JM, 1985, P INT C CYB SOC AR U, P210; KELLER JM, 1985, IEEE T PATTERN ANAL, V7, P693; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; QIU H, 1987, P NAFIPS 87 PURD U, P374; ROSENBLATT F, 1957, PARA854601 CORN U CO; Sugeno M., 1974, THESIS TOKYO I TECHN; Tou J.T., 1974, PATTERN RECOGNITION; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zadeh L.A., 1975, FUZZY SETS THEIR APP, P1	14	1	1	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0302-9743		LECT NOTES COMPUT SC	Lect. Notes Comput. Sci.		1988	301						173	182				10	Computer Science, Theory & Methods	Computer Science	N2584	WOS:A1988N258400016	
J	GORMAN, RP; SEJNOWSKI, TJ				GORMAN, RP; SEJNOWSKI, TJ			ANALYSIS OF HIDDEN UNITS IN A LAYERED NETWORK TRAINED TO CLASSIFY SONAR TARGETS	NEURAL NETWORKS			English	Article									JOHNS HOPKINS UNIV,DEPT BIOPHYS,BALTIMORE,MD 21218							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GORMAN RP, 1987, UNPUB IEEE T ACOUSTI; GORMAN RP, 1987, UNPUB J ACOUSTIC SOC; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; LAPEDES A, 1987, UNPUB P IEEE; LEHKY S R, 1987, Society for Neuroscience Abstracts, V13, P1451; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; Rosenberg C. R., 1987, COMPLEX SYSTEMS, V1, P145; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SEJNOWSKI TJ, 1986, PHYSICA D, V22, P260, DOI 10.1016/0167-2789(86)90245-9; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; WATROUS RL, 1987, 9TH P ANN C COGN SCI, V9, P518; WIDROW G, 1960, I RADIO ENG W ELECT, V4, P96	13	420	426	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0893-6080		NEURAL NETWORKS	Neural Netw.		1988	1	1					75	89		10.1016/0893-6080(88)90023-8		15	Computer Science, Artificial Intelligence	Computer Science	P0022	WOS:A1988P002200004	
J	ZAKI, FW; ELFATTAH, AIA; ENAB, YM; ELKONYALY, SH				ZAKI, FW; ELFATTAH, AIA; ENAB, YM; ELKONYALY, SH			AN ENSEMBLE AVERAGE CLASSIFIER FOR PATTERN-RECOGNITION MACHINES	PATTERN RECOGNITION			English	Article									CLEMSON UNIV,DEPT ELECT & COMP ENGN,BOX 7453,UNIV STN,CLEMSON,SC 29632; EL MANSOURA UNIV,FAC ENGN,DEPT COMP & CONTROL ENGN,MANSOURA,EGYPT; EL MANSOURA UNIV,FAC ENGN,DEPT COMMUN ENGN,MANSOURA,EGYPT							Anderson T. W., 1958, INTRO MULTIVARIATE S; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Young T. Y., 1974, CLASSIFICATION ESTIM; ZAKI FW, 1986, 11TH P INT C STAT CO, P171	6	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1988	21	4					327	332		10.1016/0031-3203(88)90046-5		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	P5388	WOS:A1988P538800006	
J	JOUSSELLINGRENIER, A; DUBUISSON, B				JOUSSELLINGRENIER, A; DUBUISSON, B			ADAPTIVE REPRESENTATION METHOD FOR INCOMPLETE-KNOWLEDGE DIAGNOSIS	RAIRO-AUTOMATIQUE-PRODUCTIQUE INFORMATIQUE INDUSTRIELLE-AUTOMATIC CONTROL PRODUCTION SYSTEMS			French	Article									UNIV COMPIEGNE,F-60206 COMPIEGNE,FRANCE	JOUSSELLINGRENIER, A (reprint author), ELECT FRANCE DER,SERV EP,6 QUAI WATIER,F-78400 CHATOU,FRANCE.						CHARPENTIER G, 1984, RAIRO AUTOMATIQUE, V18; CHOW CK, 1970, IEEE IT, V16; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1983, PATTERN RECOGNITION; Diday E, 1979, OPTIMISATION CLASSIF; DUBUISSON B, 1983, NOUVEL AUTOMATISME, P49; Fu K, 1968, SEQUENTIAL METHODS P; GRENIER D, 1985, C AUTOMATIQUE AFCET; JOUSSELLINGRENI.A, 1985, THESIS U COMPIEGNE; MIZOGUCHI R, 1980, IEEE PAMI, V2; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; PAPIN B, 1979, C ANS PASCO; POSTAIRE JG, 1979, RAIRO AUTOMATIQUE, V13, P177; SMOLARZ A, 1982, 6E C INT REC FORM MU; USAI M, 1984, 7E C INT REC FORM MO; ZADEH LA, 1965, INFORMATION CONTROL	16	0	0	DUNOD	MONTROUGE CEDEX	15 RUE GOSSIN, 92543 MONTROUGE CEDEX, FRANCE	0296-1598		RAIRO-AUTOM PROD INF	Rairo-Autom.-Prod. Inform. Ind.-Autom. Control Prod. Syst.		1988	22	4					393	412				20	Automation & Control Systems; Engineering, Industrial	Automation & Control Systems; Engineering	P0166	WOS:A1988P016600005	
J	HENZE, N				HENZE, N			ON THE FRACTION OF RANDOM POINTS WITH SPECIFIED NEAREST-NEIGHBOR INTERRELATIONS AND DEGREE OF ATTRACTION	ADVANCES IN APPLIED PROBABILITY			English	Article										HENZE, N (reprint author), UNIV HANOVER,INST MATH STOCHAST,WELFENGARTEN 1,D-3000 HANOVER 1,FED REP GER.						BICKEL PJ, 1983, ANN PROBAB, V11, P185, DOI 10.1214/aop/1176993668; Billingsley P., 1968, CONVERGENCE PROBABIL; CLARK PJ, 1955, SCIENCE, V121, P397, DOI 10.1126/science.121.3142.397; CLARK PJ, 1955, SCIENCE, V123, P373; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX TF, 1981, BIOMETRICS, V37, P367, DOI 10.2307/2530424; DACEY MF, 1969, GEOGR ANAL, V1, P385; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; HALL P, 1983, J MULTIVARIATE ANAL, V13, P24, DOI 10.1016/0047-259X(83)90003-9; HENZE N, 1983, METRIKA, V30, P245, DOI 10.1007/BF02056931; HENZE N, 1986, 2ND CAT INT S STAT, V2, P145; HENZE N, 1986, J APPL PROBAB, V23, P221, DOI 10.2307/3214132; HENZE N, 1986, ANN STATIST; HENZE N, 1984, METRIKA, V31, P259, DOI 10.1007/BF01915210; HENZE N, 1985, THESIS U HANNOVER; MACK YP, 1979, J MULTIVARIATE ANAL, V9, P1, DOI 10.1016/0047-259X(79)90065-4; MALONEY LT, 1983, J MATH PSYCHOL, V27, P251, DOI 10.1016/0022-2496(83)90009-3; Miles RE, 1974, STOCHASTIC GEOMETRY, P202; MOORE DS, 1977, ANN STAT, V5, P143, DOI 10.1214/aos/1176343747; NEWMAN CM, 1983, ADV APPL PROBAB, V15, P726, DOI 10.2307/1427321; NEWMAN CM, 1985, ADV APPL PROBAB, V17, P794, DOI 10.2307/1427088; PICKARD DK, 1982, J APPL PROBAB, V19, P444, DOI 10.2307/3213499; ROBERTS FDK, 1969, BIOMETRIKA, V56, P401, DOI 10.2307/2334432; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; SCHILLING MF, 1986, ADV APPL PROBAB, V18, P388, DOI 10.2307/1427305; SCHILLING MF, 1983, ANN STAT, V11, P1, DOI 10.1214/aos/1176346051; SCHWARZ G, 1980, J MATH PSYCHOL, V22, P157, DOI 10.1016/0022-2496(80)90017-6; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STUTE W, 1984, ANN STAT, V12, P917, DOI 10.1214/aos/1176346711; TVERSKY A, 1983, J MATH PSYCHOL, V27, P235, DOI 10.1016/0022-2496(83)90008-1	30	12	13	APPLIED PROBABILITY TRUST	SHEFFIELD	THE UNIVERSITY DEPT PROB AND STATISTICS, SHEFFIELD, ENGLAND S3 7RH	0001-8678		ADV APPL PROBAB	Adv. Appl. Probab.	DEC	1987	19	4					873	895		10.2307/1427106		23	Statistics & Probability	Mathematics	L3474	WOS:A1987L347400007	
J	JOUSSELLIN, A; DUBUISSON, B				JOUSSELLIN, A; DUBUISSON, B			A LINK BETWEEN K-NEAREST NEIGHBOR RULES AND KNOWLEDGE BASED SYSTEMS BY SEQUENCE-ANALYSIS	PATTERN RECOGNITION LETTERS			English	Article									UNIV COMPIEGNE,UNITE 817,F-60206 COMPIEGNE,FRANCE	JOUSSELLIN, A (reprint author), ELECT FRANCE,DER EP,DEPT SDM,6 QUAI WATIER,F-78400 CHATOU,FRANCE.						CHOW CK, 1970, IEEE IT, V16; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1970, IEEE PAMI, V2; Devijver P. A., 1982, PATTERN CLASSIFICATI; HELLMAN ME, 1970, IEEE SSC, V6; JOUSSELINGRENIE.A, 1986, 8TH P ICPR PAR; KOWALSKI AA, 1979, LOGIC PROBLEM SOLVIN; Waterman D. A., 1986, GUIDE EXPERT SYSTEMS	8	8	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC	1987	6	5					287	295		10.1016/0167-8655(87)90011-0		9	Computer Science, Artificial Intelligence	Computer Science	L1096	WOS:A1987L109600002	
J	GOLIC, JD				GOLIC, JD			ON THE RELATIONSHIP BETWEEN THE INFORMATION MEASURES AND THE BAYES PROBABILITY OF ERROR	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article									UNIV BELGRADE,FAC ELECT ENGN,YU-11000 BELGRADE,YUGOSLAVIA	GOLIC, JD (reprint author), INST APPL MATH & ELECTR,BELGRADE,YUGOSLAVIA.						BAZARA MS, 1973, NONLINEAR PROGRAMMIN; BOEKEE DE, 1979, PATTERN RECOGN, V11, P353, DOI 10.1016/0031-3203(79)90047-5; BURBEA J, 1982, IEEE T INFORM THEORY, V28, P489, DOI 10.1109/TIT.1982.1056497; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHU JT, 1966, J FRANKLIN I, V282, P121, DOI 10.1016/0016-0032(66)90359-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; FANO RM, 1961, TRANSMISSION INFORMA; GOLIC JD, 1987, IEEE T INFORM THEORY, V33, P531, DOI 10.1109/TIT.1987.1057332; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; KOVALEVSKY VA, 1968, CHARACTER READERS PA; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; RENYI A, 1967, 5TH P BERK S MATH ST, V1, P531; RENYI A, 1965, PUBLICATIONS MATH I, V9, P617; TEBBE DL, 1968, IEEE T INFORM THEORY, V14, P516, DOI 10.1109/TIT.1968.1054135; TOUSSAINT GT, 1972, THESIS U BRIT COLUMB; Vajda I., 1968, INFORM TRANSMISSION, V4, P9	17	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	SEP	1987	33	5					681	693		10.1109/TIT.1987.1057357		13	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	K7696	WOS:A1987K769600008	
J	GOLIC, JD				GOLIC, JD			ON THE RELATIONSHIP BETWEEN THE SEPARABILITY MEASURES AND THE BAYES PROBABILITY OF ERROR	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article									UNIV BELGRADE,FAC ELECT ENGN,YU-11000 BELGRADE,YUGOSLAVIA	GOLIC, JD (reprint author), INST APPL MATH & ELECTR,BELGRADE,YUGOSLAVIA.						CHU JT, 1967, J ACM, V14, P273, DOI 10.1145/321386.321390; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOLIC JD, 1987, IEEE T INFORM THEORY, V33, P681, DOI 10.1109/TIT.1987.1057357; GOLIC JD, 1987, IEEE T INFORM THEORY, V33, P531, DOI 10.1109/TIT.1987.1057332; LAINIOTI.DG, 1971, IEEE T SYST MAN CYB, VSMC1, P175; LISSACK TSVI, 1976, IEEE T INFORM THEORY, V22, P34, DOI 10.1109/TIT.1976.1055512; TOUSSAIN.GT, 1971, IEEE T COMPUT, VC 20, P943, DOI 10.1109/T-C.1971.223380; Vajda I., 1968, INFORM TRANSMISSION, V4, P9	8	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	SEP	1987	33	5					694	701		10.1109/TIT.1987.1057349		8	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	K7696	WOS:A1987K769600009	
J	FUKUNAGA, K; HUMMELS, DM				FUKUNAGA, K; HUMMELS, DM			BAYES ERROR ESTIMATION USING PARZEN AND K-NN PROCEDURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article										FUKUNAGA, K (reprint author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.						CACOULLOS T, 1966, ANN I STAT MATH, V18, P178; Chandrasekaran B., 1979, Journal of Cybernetics and Information Science, V2; CHOW YS, 1983, ANN STAT, V11, P25, DOI 10.1214/aos/1176346053; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; DEVROYE L, 1982, Z WAHRSCHEINLICHKEIT, V61, P467, DOI 10.1007/BF00531618; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; Devroye L.P., 1985, NONPARAMETRIC DENSIT; DUIN RPW, 1976, IEEE T COMPUT, V25, P1175; FIX E, 1952, 11 SCH AV MED REP; FIX E, 1951, 4 SCH AV MED REP; FUKUNAGA K, 1972, INTRO STATISTICAL PA; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779; FUKUNAGA K, 1986, IEEE T PATTERN ANAL, V9, P103; FUKUNAGA K, 1982, IEEE T PATTERN ANAL, V4, P427; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Habbema J. D. F., 1974, COMPSTAT 1974, V1974, P101; HALL P, 1983, ANN STAT, V11, P1156; Hand D. J., 1982, KERNEL DISCRIMINANT; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MOORE DS, 1977, ANN STAT, V5, P143, DOI 10.1214/aos/1176343747; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SILVERMAN BW, 1978, BIOMETRIKA, V65, P1; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; WAGNER TJ, 1975, IEEE T INFORM THEORY, V21, P438, DOI 10.1109/TIT.1975.1055408	28	57	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					634	643				10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	J7393	WOS:A1987J739300005	
J	GOLIC, JD				GOLIC, JD			ON THE RELATIONSHIP BETWEEN THE EFFICIENCY MEASURES OF MULTICATEGORY INFORMATION-SYSTEMS	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article									INST APPL MATH & ELECTR,BELGRADE,YUGOSLAVIA	GOLIC, JD (reprint author), UNIV BELGRADE,FAC ELECT ENGN,BULEVAR REVOLUCIJE 73,YU-11000 BELGRADE,YUGOSLAVIA.						Bazara M.S., 1979, NONLINEAR PROGRAMMIN; BENBASSAT M, 1978, IEEE T INFORM THEORY, V24, P769, DOI 10.1109/TIT.1978.1055952; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; EGGLESTON HG, 1963, CONVEXITY; Halmos P.R., 1950, MEASURE THEORY; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Kolmogorov A. N., 1981, ELEMENTS THEORY FUNC; KOVALEVSKY VA, 1968, CHARACTER READERS PA; LAINIOTI.DG, 1969, IEEE T INFORM THEORY, V15, P730, DOI 10.1109/TIT.1969.1054374; Natanson I. P., 1974, THEORY FUNCTIONS REA; PROHOROV YV, 1973, THEORY PROBABILITY; TEBBE DL, 1968, IEEE T INFORM THEORY, V14, P516, DOI 10.1109/TIT.1968.1054135; WITSENHAUSEN HS, 1980, IEEE T INFORM THEORY, V26, P265, DOI 10.1109/TIT.1980.1056173	14	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	JUL	1987	33	4					531	538		10.1109/TIT.1987.1057332		8	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	J6684	WOS:A1987J668400005	
J	MACLEOD, JES; LUK, A; TITTERINGTON, DM				MACLEOD, JES; LUK, A; TITTERINGTON, DM			A REEXAMINATION OF THE DISTANCE-WEIGHTED K-NEAREST NEIGHBOR CLASSIFICATION RULE	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Letter									UNIV GLASGOW,DEPT STAT,GLASGOW G12 8QQ,SCOTLAND	MACLEOD, JES (reprint author), UNIV GLASGOW,DEPT ELECTR & ELECT ENGN,GLASGOW G12 8QQ,SCOTLAND.						BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society; Devijver P. A., 1982, PATTERN RECOGNITION; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FUKUNAGA K, 1985, IEEE T PATTERN ANAL, V7, P107; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241	9	32	32	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.	JUL-AUG	1987	17	4					689	696		10.1109/TSMC.1987.289362		8	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	K2190	WOS:A1987K219000017	
J	LAHAT, M; NIEDERJOHN, RJ; KRUBSACK, DA				LAHAT, M; NIEDERJOHN, RJ; KRUBSACK, DA			A SPECTRAL AUTOCORRELATION METHOD FOR MEASUREMENT OF THE FUNDAMENTAL-FREQUENCY OF NOISE-CORRUPTED SPEECH	IEEE TRANSACTIONS ON ACOUSTICS SPEECH AND SIGNAL PROCESSING			English	Article									MARQUETTE UNIV,DEPT ELECT ENGN & COMP SCI,MILWAUKEE,WI 53233	LAHAT, M (reprint author), RAFAEL,HAIFA,ISRAEL.						ATAL BS, 1976, IEEE T ACOUST SPEECH, V24, P201, DOI 10.1109/TASSP.1976.1162800; CHANG JJQ, 1986, THESIS MARQUETTE U M; CHILDERS D, 1975, DIGITAL FILTERING SI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX BV, 1980, IEEE T ACOUST SPEECH, V28, P550, DOI 10.1109/TASSP.1980.1163444; DUIFHUIS H, 1982, J ACOUST SOC AM, V71, P1568, DOI 10.1121/1.387811; LAHAT M, 1983, THESIS MARQUETTE U M; MCGONEGAL CA, 1975, IEEE T ACOUST SPEECH, V23, P570, DOI 10.1109/TASSP.1975.1162750; MILLER RL, 1970, J ACOUST SOC AM, V47, P1593, DOI 10.1121/1.1912093; MOORER JA, 1974, IEEE T ACOUST SPEECH, VAS22, P330, DOI 10.1109/TASSP.1974.1162596; NOLL AM, 1964, J ACOUST SOC AM, V36, P296, DOI 10.1121/1.1918949; NOLL AM, 1973, SIGNAL PROCESSING; NOLL AM, 1967, J ACOUST SOC AM, V41, P293, DOI 10.1121/1.1910339; NOLL AM, 1969, APR P S COMP PROC CO, P779; PALIWAL KK, 1983, SPEECH COMMUN, V2, P37, DOI 10.1016/0167-6393(83)90062-6; Rabiner L., 1978, DIGITAL PROCESSING S; RABINER LR, 1975, IEEE T ACOUST SPEECH, V23, P552, DOI 10.1109/TASSP.1975.1162749; RABINER LR, 1977, IEEE T ACOUST SPEECH, V25, P24, DOI 10.1109/TASSP.1977.1162905; RABINER LR, 1976, IEEE T ACOUST SPEECH, V24, P399, DOI 10.1109/TASSP.1976.1162846; RAMAMOORTY V, 1980, P INT C AC SPEECH SI, P57; Sarma V. V. S., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing; SCHAFER RW, 1975, P IEEE, V63, P662, DOI 10.1109/PROC.1975.9799; SCHROEDE.MR, 1968, J ACOUST SOC AM, V43, P829, DOI 10.1121/1.1910902; SENEFF S, 1978, IEEE T ACOUST SPEECH, V26, P358, DOI 10.1109/TASSP.1978.1163118; SIEGEL LJ, 1982, IEEE T ACOUST SPEECH, V30, P451, DOI 10.1109/TASSP.1982.1163910; SIEGEL LJ, 1979, IEEE T ACOUST SPEECH, V27, P83, DOI 10.1109/TASSP.1979.1163186; SIEGEL LJ, 1980, P IEEE INT C ACOUST, P53; SONDHI MM, 1968, IEEE T ACOUST SPEECH, VAU16, P262, DOI 10.1109/TAU.1968.1161986; SREENIVAS TV, 1979, J ACOUST SOC AM, V65, P223, DOI 10.1121/1.382239; UN CK, 1977, IEEE T ACOUST SPEECH, V25, P565; WALICKI JS, 1981, THESIS MARQUETTE U M; WALICKI JS, 1981, P NAT ELECTRON C, P342; WARREN JH, 1971, IEEE T ACOUST SPEECH, VAU19, P281, DOI 10.1109/TAU.1971.1162201; WISE JD, 1976, IEEE T ACOUST SPEECH, V24, P418, DOI 10.1109/TASSP.1976.1162852	34	19	19	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0096-3518		IEEE T ACOUST SPEECH		JUN	1987	35	6					741	750		10.1109/TASSP.1987.1165224		10	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	H4013	WOS:A1987H401300004	
J	HECHTNIELSEN, R				HECHTNIELSEN, R			NEAREST MATCHED-FILTER CLASSIFICATION OF SPATIOTEMPORAL PATTERNS	APPLIED OPTICS			English	Article									TRW, ELECTR SYST GRP, SAN DIEGO, CA USA	HECHTNIELSEN, R (reprint author), HECHT NIELSEN NEUROCOMP CORP, 5893 OBERLIN DR, SAN DIEGO, CA 92121 USA.						AMARI S, 1982, COMPETITION COOPERAT; AMARI SI, 1971, PR INST ELECTR ELECT, V59, P35, DOI 10.1109/PROC.1971.8087; AMARI SI, 1974, KYBERNETIK, V14, P201; AMARI SI, 1983, IEEE T SYST MAN CYB, V13, P741; ANDERSON J A, 1972, Mathematical Biosciences, V14, P197, DOI 10.1016/0025-5564(72)90075-2; ANDERSON JA, 1983, IEEE T SYST MAN CYB, V13, P799; ANDERSON JA, 1986, P SOC PHOTOOPT INSTR, V634, P260; BARTO AG, 1984, ADA140295; BARTO AG, 1981, BIOL CYBERN, V42; BROWN C, 1986, ELECTRON ENG TI 0203, P1; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CASASENT D, 1986, P SOC PHOTOOPT INSTR, V634; COHEN M, 1986, HUM NEUROBIOL, V5, P1; COHEN MA, 1983, IEEE T SYST MAN CYBE, V13; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRUZYOUNG C, 1983, IBM G3203446 PAL ALT; CRUZYOUNG C, 1982, IBM G3203474 PAL ALT; CRUZYOUNG C, 1985, IBM G3203475 PAL ALT; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DUNNING GJ, 1986, P SOC PHOTOOPT INSTR, V625; FAHLMAN S, 1984, COMMUNICATION; FISHER AD, 1984, J OPT SOC AM A, V1, P1337; FISHER AD, 1985, FEB P IEEE COMPCOM M, P342; FISHER AD, 1986, P SOC PHOTOOPT INSTR, V625, P1; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; GEMAN S, 1981, MATH PSYCHOL PSYCHOP; GROSSBER.S, 1969, J MATH MECH, V19, P53; GROSSBERG S, 1970, STUD APPL MATH, V49; GROSSBERG S, 1985, PERCEPT PSYCHOPHYS, V38, P141, DOI 10.3758/BF03198851; GROSSBERG S, 1986, PSYCHOL REV, V93, P46, DOI 10.1037//0033-295X.93.1.46; GROSSBERG S, 1984, FIGURAL SYNTHESIS; GROSSBER.S, 1969, J MATH PSYCHOL, V6, P209, DOI 10.1016/0022-2496(69)90003-0; GROSSBER.S, 1967, P NATL ACAD SCI USA, V58, P1329, DOI 10.1073/pnas.58.4.1329; Grossberg S., 1982, STUDIES MIND BRAIN; Grossberg S., 1986, NEURAL DYNAMICS ADAP; GROSSBERG S, 1971, Journal of Cybernetics, V1, P28; HECHTNIELSEN R, 1986, P SOC PHOTO-OPT INS, V634, P277; HECHTNIELSEN R, 1982, P SOC PHOTO-OPT INST, V360, P180; HECHTNIELSEN R, 1981, P SOC PHOTO-OPT INST, V298, P138; HECHTNIELSEN R, 1983, J MATH PSYCHOL, V27, P335, DOI 10.1016/0022-2496(83)90017-2; Hinton G. E., 1981, PARALLEL MODELS ASS; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HOPFIELD JJ, 1986, 2ND P ANN C NEUR NET; KLOPF AH, 1982, HEDONISTIC NEURON; KLOPF AH, 1969, IEEE T SYST SCI CYB, VSSC5, P247, DOI 10.1109/TSSC.1969.300268; Kohonen T., 1984, SELF ORG ASS MEMORY; KOSKO B, 1986, UNPUB FUZZY KNOWLEDG; Kosko B., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V579; Kosko B., 1986, INT J MAN MACHINE ST; MCCLELLAND JL, 1985, J EXP PSYCHOL GEN, V114, P159, DOI 10.1037//0096-3445.114.2.159; MCELIECE RJ, UNPUB IEEE T INFOR T; MITCHELL RL, 1978, AD A089574; PORT O, 1986, BUS WEEK        0602, P92; PSALTIS D, 1985, OPT LETT, V10, P98, DOI 10.1364/OL.10.000098; PSALTIS D, 1985, INFORMATION STORAGE; PSALTIS D, 1985, COMPUTATION POWER PA; RUMELHART D, 1985, UCSD8506 I COGN SCI; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; SEJNOWSKI TJ, 1981, PARALLEL MODELS ASS; SEJNOWSKI TJ, 1986, NETALK PARALLEL NETW; SOFFER BH, 1986, OPT LETT, V11, P118, DOI 10.1364/OL.11.000118; Steinbuch K., 1963, IEEE Transactions on Electronic Computers, VEC-12, DOI 10.1109/PGEC.1963.263565; STEINBUCH K, 1961, KYBERNETIK, V1, P36, DOI 10.1007/BF00293853; Widrow B., 1960, IRE WESCON CONV RE 4, P96; WIDROW B, 1962, SELF ORG SYSTEMS; Widrow B., 1985, ADAPTIVE SIGNAL PROC; Willshaw D. J., 1971, THESIS U EDINBURGH; WILLSHAW DJ, 1969, NATURE, V222, P960, DOI 10.1038/222960a0; WILLSHAW DJ, 1970, MACHINE INTELLIGENCE; WOODWARD PM, 1953, PROBABILITY INFORMAT; WYNER AD, 1984, IEEE T INFORM THEORY, V30, P615, DOI 10.1109/TIT.1984.1056934	75	16	16	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	0003-6935		APPL OPTICS	Appl. Optics	MAY 15	1987	26	10					1892	1899				8	Optics	Optics	H4380	WOS:A1987H438000010	
J	WANG, QR				WANG, QR			A FLEXIBLE TREE DESIGN IN AN EDIT PARTITION SCHEME	PATTERN RECOGNITION LETTERS			English	Article										WANG, QR (reprint author), NANKAI UNIV,DEPT COMP & SYST SCI,TIANJIN,PEOPLES R CHINA.						ARGENTIERO P, 1982, IEEE T PATTERN ANAL, P51; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESOUZA P, 1982, PATTERN RECOGN, V15, P193, DOI 10.1016/0031-3203(82)90071-1; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; DEVROYE L, 1980, 5TH P INT C PATT REC, P103; HERRICHON EG, 1969, IEEE T COMPUTER, V18, P614; KULKANI AV, 1984, 3RD P INT JOINT C PA, V17, P359; LIN YK, 1983, PATTERN RECOGN, V16, P69, DOI 10.1016/0031-3203(83)90010-9; MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429; SHAMOS MI, 1975, 7TH P ACM S THEOR CO; SHI QY, 1983, PATTERN RECOGN, V16, P593; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142; WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P696, DOI 10.1109/TIT.1973.1055059; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406; WANG QR, 1986, IN PRESS ACTA MATH P; WANG QR, 1987, IN PRESS SCI SINICA; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	17	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	APR	1987	5	4					261	265		10.1016/0167-8655(87)90055-9		5	Computer Science, Artificial Intelligence	Computer Science	H2184	WOS:A1987H218400002	
J	LOIZOU, G; MAYBANK, SJ				LOIZOU, G; MAYBANK, SJ			THE NEAREST NEIGHBOR AND THE BAYES ERROR RATES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MARCONI COMMAND & CONTROL SYST,SURREY GU16 5PE,ENGLAND	LOIZOU, G (reprint author), UNIV LONDON BIRKBECK COLL,DEPT COMP SCI,MALET ST,LONDON WC1E 7HX,ENGLAND.						ABRAMOWITZ M, 1964, APPLIED MATH SERIES, V55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1978, NATO ADV STUDY I E, P61; Devijver P. A., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; DEVIJVER PA, 1985, PATTERN RECOGN LETT, V3, P1, DOI 10.1016/0167-8655(85)90035-2; DEVIJVER PA, 1982, NATO ADV STUDY I C, P3; DEVIJVER PA, 1977, NATO ADV STUDY I E, P1; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; Devroye L.P., 1985, NONPARAMETRIC DENSIT; Duda R., 1973, PATTERN CLASSIFICATI; Feustel C. D., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90025-3; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; Fukunaga K., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90043-5; GOIN JE, 1984, IEEE T PATTERN ANAL, V6, P379; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; LOIZOU G, UNPUB INCOMPLETE BET; Marshall AW, 1979, INEQUALITIES THEORY; Maybank S. J., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90065-X; Miclet L., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90063-6; Mitrinovic D. S., 1970, ANAL INEQUALITIES; NI L, 1984, VLSI PATTERN RECOGNI, P65; PALIWAL KK, 1983, IEEE T PATTERN ANAL, V5, P229; PAPADIMITRIOU CH, 1980, LECT NOTES COMPUTER, V85, P470; Shamos M.I., 1978, THESIS YALE U NEW HA; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Tatsumi S., 1983, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part A, VJ66A; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; TOUSSAINT GT, 1982, NATO ADV STUDY I C, P569; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Williamson J. H., 1962, LEBESGUE INTEGRATION	34	7	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					254	262				9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	G1633	WOS:A1987G163300006	
J	WANG, QR				WANG, QR			K-NN PREEDITING DESIGN OF TREE CLASSIFIER	SCIENTIA SINICA SERIES A-MATHEMATICAL PHYSICAL ASTRONOMICAL & TECHNICAL SCIENCES			English	Article										WANG, QR (reprint author), NANKAI UNIV,DEPT COMP & SYST SCI,TIANJIN,PEOPLES R CHINA.						ARGENTIERO P, 1982, IEEE T PATTERN ANAL, V4, P51; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DATTATREYA GR, 1981, IEEE T PATTERN ANAL, V3, P293; DESOUZA P, 1982, PATTERN RECOGN, V15, P193, DOI 10.1016/0031-3203(82)90071-1; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; DEVROYE L, 1980, 5TH P INT C PATT REC, P103; Fu K. S., 1982, SYNTACTIC PATTERN RE; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HERRICHON EG, 1969, IEEE T COMPUTER, V18, P614; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; Kulkarni A. V., 1976, 3rd International Joint Conference on Pattern Recognition; LANDEWEERD GH, 1983, PATTERN RECOGN, V16, P571, DOI 10.1016/0031-3203(83)90073-0; LIN YK, 1983, PATTERN RECOGN, V16, P69, DOI 10.1016/0031-3203(83)90010-9; MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429; NILSSON NJ, 1965, LEARNING MACHINES, P118; PAYNE HJ, 1977, IEEE T COMPUT, V26, P905; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; ROUNDS EM, 1980, PATTERN RECOGN, V12, P313, DOI 10.1016/0031-3203(80)90029-1; SCHUERMANN J, 1984, PATTERN RECOGN, V17, P359, DOI 10.1016/0031-3203(84)90087-6; SETHI IK, 1982, IEEE T PATTERN ANAL, V4, P441; SHAMOS MI, 1975, 7TH P ACM S THEOR CO; SHI QY, 1983, PATTERN RECOGN, V16, P593; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142; WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P92; WANG QG, 1984, THESIS CONCORDIA U; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406; WANG QR, 1986, J COMPUTER SCI TECHN, V1, P70, DOI 10.1007/BF02943303; WANG QR, 1986, ACTA MATH SCI, V6; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YUNCK TP, 1980, IEEE T PATTERN ANAL, V2, P420	32	0	0	SCIENCE CHINA PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA			SCI CHINA SER A		MAR	1987	30	3					326	336				11	Multidisciplinary Sciences	Science & Technology - Other Topics	G8060	WOS:A1987G806000010	
J	STEIGSTRA, H; JANSEN, AP; KATEMAN, G				STEIGSTRA, H; JANSEN, AP; KATEMAN, G			SOLOMON, A CLASSIFICATION PROGRAM BASED ON A STATISTICAL MULTIVARIATE DISJOINT MODEL	ANALYTICA CHIMICA ACTA			English	Article									CATHOLIC UNIV NIJMEGEN,DEPT ANALYT CHEM,6525 ED NIJMEGEN,NETHERLANDS; ST RADBOUD HOSP,CLIN CHEM LAB,6500 HB NIJMEGEN,NETHERLANDS							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HERMANS J, 1982, ALLOC80 DISCRIMINANT; KOWALSKI BR, 1969, ANAL CHEM, V41, P695, DOI 10.1021/ac60275a026; KREIZIG E, 1970, INTRO MATH STATISTIC; RALSTON A, 1966, MATH METHODS DIGITAL, P191; STEIGSTRA H, 1986, ANAL CHIM ACTA, V186, P175, DOI 10.1016/S0003-2670(00)81786-9; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	7	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta	FEB 14	1987	193						269	276		10.1016/S0003-2670(00)86158-9		8	Chemistry, Analytical	Chemistry	J2839	WOS:A1987J283900026	
J	WOJCIECHOWSKI, TJ				WOJCIECHOWSKI, TJ			NEAREST NEIGHBOR CLASSIFICATION RULE FOR MIXTURES OF DISCRETE AND CONTINUOUS RANDOM-VARIABLES	BIOMETRICAL JOURNAL			English	Article									UNIV MASSACHUSETTS,DEPT MATH & STAT,AMHERST,MA 01003; ADAM MICKIEWICZ UNIV,INST MATH,PL-61712 POZNAN,POLAND							ANDERSON JA, 1972, BIOMETRIKA, V59, P19, DOI 10.2307/2334611; ANDERSON JA, 1981, HDB STATISTICS, V2; CHANG PC, 1974, J AM STAT ASSOC, V69, P336, DOI 10.2307/2285653; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HABBEMA JDF, 1978, COMPSTAT 1978; HALL P, 1983, ANN STAT, V11, P1004, DOI 10.1214/aos/1176346268; KRZANOWSKI WJ, 1980, BIOMETRICS, V36, P493, DOI 10.2307/2530217; KRZANOWSKI WJ, 1975, J AM STAT ASSOC, V70, P782, DOI 10.2307/2285437; TU CT, 1982, J AM STAT ASSOC, V77, P447, DOI 10.2307/2287266	9	0	0	AKADEMIE VERLAG GMBH	BERLIN	MUHLENSTRASSE 33-34, D-13187 BERLIN, GERMANY	0323-3847		BIOMETRICAL J	Biom. J.		1987	29	8					953	959		10.1002/bimj.4710290808		7	Mathematical & Computational Biology; Statistics & Probability	Mathematical & Computational Biology; Mathematics	L6435	WOS:A1987L643500006	
J	FUKUNAGA, K; HUMMELS, DM				FUKUNAGA, K; HUMMELS, DM			BIAS OF NEAREST NEIGHBOR ERROR-ESTIMATES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article										FUKUNAGA, K (reprint author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.						Beck J., 1979, Problems of Control and Information Theory, V8; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; FRASER DA, 1957, NONPARAMETRIC METHOD, pCH4; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779; FUKUNAGA K, 1972, INTRO STATISTICAL PA, pCH2; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	18	31	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					103	112				10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	F3785	WOS:A1987F378500008	
J	DUCHENE, J				DUCHENE, J			A NEW FORM OF DISCRIMINANT SURFACES USING POLAR COORDINATES	PATTERN RECOGNITION			English	Article										DUCHENE, J (reprint author), UNIV COMPIEGNE,DEPT BIOMED ENGN,CNRS,UNITE 858,BP 233,F-60206 COMPIEGNE,FRANCE.						BASHKIROV DA, 1964, AUTOMN REMOTE CONTRO, V25, P629; CARNAHAN B, 1969, APPLIED NUMERICAL ME; CHEN CH, 1969, IEEE T SYST SCI CYB, VSSC5, P30, DOI 10.1109/TSSC.1969.300241; Chien Y. T., 1978, INTERACTIVE PATTERN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRAPER NR, 1981, APPLIED REGRESSION A; DUCHENE J, 1986, IEEE T PATTERN ANAL, V4, P557; Duda R., 1973, PATTERN CLASSIFICATI; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; HO YC, 1968, PR INST ELECTR ELECT, V56, P2101; HO YC, 1965, IEEE TRANS ELECTRON, VEC14, P683, DOI 10.1109/PGEC.1965.264206; KOFORD JS, 1966, IEEE T INFORM THEORY, V12, P42, DOI 10.1109/TIT.1966.1053856; MOTZKIN TS, 1954, CAN J MATH, V6, P393, DOI 10.4153/CJM-1954-038-x; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATTERSO.JD, 1966, IEEE T SYST SCI CYB, VSSC2, P62, DOI 10.1109/TSSC.1966.300080; Rao C. R., 1964, SANKHYA A, V26, P329; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; YAU SS, 1972, FRONTIER PATTERN REC, P575	18	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1987	20	4					437	442		10.1016/0031-3203(87)90070-7		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	J3593	WOS:A1987J359300010	
J	KIM, BS; PARK, SB				KIM, BS; PARK, SB			A FAST K NEAREST NEIGHBOR FINDING ALGORITHM BASED ON THE ORDERED PARTITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									KOREA ADV INST SCI & TECHNOL,DEPT ELECT ENGN,SEOUL 131,SOUTH KOREA	KIM, BS (reprint author), HANYANG UNIV,COLL MED,DEPT MED INFORMAT MANAGEMENT,17 HAENGDANG DONG,SEONGDONG KU,SEOUL 133,SOUTH KOREA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FISCHER FP, 1970 P NEC, P481; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; KIM BS, 1985, THESIS KOREA ADV I S; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	9	48	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1986	8	6					761	766				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	E4469	WOS:A1986E446900009	
J	NETO, BB; RAMOS, MN; BRUNS, RE				NETO, BB; RAMOS, MN; BRUNS, RE			SIMILARITY TRANSFERENCE OF MOLECULAR-PARAMETERS .1. THE ATOMIC POLAR TENSORS OF CYANOACETYLENE	JOURNAL OF CHEMICAL PHYSICS			English	Article									UNIV FED PERNAMBUCO,DEPT QUIM FUNDAMENTAL,BR-50000 RECIFE,PE,BRAZIL	NETO, BB (reprint author), UNIV ESTADUAL CAMPINAS,INST QUIM,BR-13100 CAMPINAS,SP,BRAZIL.						APPLEQUIST J, 1977, ACCOUNTS CHEM RES, V10, P79, DOI 10.1021/ar50111a002; APPLEQUIST J, 1977, J CHEM PHYS, V66, P3455, DOI 10.1063/1.434431; BASSI ABMS, 1978, J CHEM PHYS, V68, P5667, DOI 10.1063/1.435669; BRUNS RE, 1970, J CHEM PHYS, V53, P1413, DOI 10.1063/1.1674189; BRUNS RE, 1978, J CHEM PHYS, V68, P847, DOI 10.1063/1.435818; CONSTAIN CC, 1968, J CHEM PHYS, V29, P864; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNCAN JL, 1973, J MOL SPECTROSC, V46, P232, DOI 10.1016/0022-2852(73)90039-8; DUPUIS M, 1978, QUANTUM CHEM PROGRAM, V403; GREADY JE, 1978, CHEM PHYS, V31, P467, DOI 10.1016/0301-0104(78)85136-2; HALONEN L, 1978, J MOL SPECTROSC, V73, P494, DOI 10.1016/0022-2852(78)90114-5; HORNIG DF, 1978, J CHEM PHYS, V68, P5668, DOI 10.1063/1.435670; KIM K, 1984, J CHEM PHYS, V80, P974, DOI 10.1063/1.446791; KING WT, 1976, J PHYS CHEM-US, V80, P2521, DOI 10.1021/j100563a018; KOGA Y, 1984, J PHYS CHEM-US, V88, P3152, DOI 10.1021/j150658a048; KROHN BJ, 1976, J CHEM PHYS, V65, P969, DOI 10.1063/1.433169; LIN B, 1978, J CHEM PHYS, V69, P1425; Mardia K. V., 1979, MULTIVARIATE ANAL; Meisel W, 1972, COMPUTER ORIENTED AP; MILLS IM, 1963, INFRARED SPECTROSCOP, pCH5; Pauling L., 1960, NATURE CHEM BOND; PERSON WB, 1974, J CHEM PHYS, V61, P1040, DOI 10.1063/1.1681972; PERSON WB, 1977, J CHEM PHYS, V66, P1443; RAMOS MN, 1986, J MOL STRUCT, V142, P209, DOI 10.1016/0022-2860(86)85097-9; SJOSTROM M, 1983, ANAL CHIM ACTA, V150, P61, DOI 10.1016/S0003-2670(00)85460-4; STREY G, 1976, J MOL SPECTROSC, V59, P103, DOI 10.1016/0022-2852(76)90046-1; SUTTON LE, 1963, TABLES INTERATOMIC S; SUZUKI I, 1966, J CHEM PHYS, V44, P3561, DOI 10.1063/1.1727265; TAMIMOTO M, 1971, B CHEM SOC JPN, V44, P386; TAMIMOTO M, 1969, B CHEM SOC JPN, V42, P2519; UYEMURA M, 1974, B CHEM SOC JPN, V47, P2930, DOI 10.1246/bcsj.47.2930; UYEMURA M, 1982, B CHEM SOC JPN, V55, P384, DOI 10.1246/bcsj.55.384; Wold H., 1982, SYSTEMS INDIRECT OBS, VII; WOLD S, 1984, CHEMOMETRICS MATH ST, pCH2; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; WOLD S, 1978, TECHNOMETRICS, V20, P397, DOI 10.2307/1267639	36	10	10	AMER INST PHYSICS	WOODBURY	CIRCULATION FULFILLMENT DIV, 500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2999	0021-9606		J CHEM PHYS	J. Chem. Phys.	OCT 15	1986	85	8					4515	4523		10.1063/1.451772		9	Physics, Atomic, Molecular & Chemical	Physics	E2944	WOS:A1986E294400037	
J	LUK, A; MACLEOD, JES				LUK, A; MACLEOD, JES			AN ALTERNATIVE NEAREST NEIGHBOR CLASSIFICATION SCHEME	PATTERN RECOGNITION LETTERS			English	Article										LUK, A (reprint author), UNIV GLASGOW,DEPT ELECTR & ELECT ENGN,GLASGOW G12 8QQ,SCOTLAND.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1977, THESIS U PARIS 6; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	8	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	OCT	1986	4	5					375	381		10.1016/0167-8655(86)90059-0		7	Computer Science, Artificial Intelligence	Computer Science	F1112	WOS:A1986F111200008	
J	FORBES, RA; TEWS, EC; FREISER, BS; WISE, MB; PERONE, SP				FORBES, RA; TEWS, EC; FREISER, BS; WISE, MB; PERONE, SP			DEVELOPMENT OF A NOVEL WEIGHTING SCHEME FOR THE K-NEAREST-NEIGHBOR ALGORITHM	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article									PURDUE UNIV,DEPT CHEM,W LAFAYETTE,IN 47907; OAK RIDGE NATL LAB,OAK RIDGE,TN 37831; UNIV CALIF LAWRENCE LIVERMORE NATL LAB,LIVERMORE,CA 94550							BINK JCWG, 1983, ANAL CHIM ACTA, V150, P53, DOI 10.1016/S0003-2670(00)85459-8; BRAUNER A, 1982, ORG MASS SPECTROM, V17, P161, DOI 10.1002/oms.1210170403; BRENT DA, 1981, BIOMED MASS SPECTROM, V8, P440, DOI 10.1002/bms.1200080916; BURGARD DR, 1978, ANAL CHEM, V50, P1366, DOI 10.1021/ac50031a043; BURNIER RC, 1981, J AM CHEM SOC, V103, P4360, DOI 10.1021/ja00405a012; BYERS WA, 1980, ANAL CHEM, V52, P2173, DOI 10.1021/ac50063a041; BYERS WA, 1983, ANAL CHEM, V55, P620, DOI 10.1021/ac00255a009; BYERS WA, 1983, ANAL CHEM, V55, P615, DOI 10.1021/ac00255a008; BYRD GD, 1982, J AM CHEM SOC, V104, P3565, DOI 10.1021/ja00377a004; CHIEN M, 1985, ANAL CHEM, V57, P348, DOI 10.1021/ac00279a078; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNN WJ, 1984, ANAL CHEM, V56, P1308, DOI 10.1021/ac00272a026; FRANKEL DS, 1984, ANAL CHEM, V56, P1011, DOI 10.1021/ac00270a032; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GRAY NAB, 1976, ANAL CHEM, V48, P2265, DOI 10.1021/ac50008a054; HABBEMA JDF, 1983, ANAL CHIM ACTA, V150, P1, DOI 10.1016/S0003-2670(00)85454-9; HIPPE Z, 1983, ANAL CHIM ACTA, V150, P11, DOI 10.1016/S0003-2670(00)85455-0; JACOBSON DB, 1983, J AM CHEM SOC, V105, P7484, DOI 10.1021/ja00364a002; JACOBSON DB, 1983, J AM CHEM SOC, V105, P5197, DOI 10.1021/ja00354a003; JACOBSON DB, 1983, J AM CHEM SOC, V105, P7492, DOI 10.1021/ja00364a003; JELLUM E, 1981, J CHROMATOGR, V217, P231, DOI 10.1016/S0021-9673(00)88077-2; JURS PC, 1975, CHEM APPLICATIONS PA; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; Leegwater D. C., 1984, TRAC Trends in Analytical Chemistry, V3, DOI 10.1016/0165-9936(84)87064-8; PARRISH ME, 1983, ANAL CHIM ACTA, V150, P163, DOI 10.1016/S0003-2670(00)85468-9; RITTER GL, 1975, ANAL CHEM, V47, P1951, DOI 10.1021/ac60362a005; Rotter H., 1978, Analytica Chimica Acta, Computer Techniques and Optimization, V103, DOI 10.1016/S0003-2670(01)83807-1; SCHACHTERLE SD, 1981, ANAL CHEM, V53, P1672, DOI 10.1021/ac00234a028; THOMAS QV, 1977, ANAL CHEM, V49, P1369, DOI 10.1021/ac50017a021; THOMAS QV, 1977, ANAL CHEM, V49, P1376, DOI 10.1021/ac50017a022; TSAO R, 1984, ANAL CHEM, V56, P368, DOI 10.1021/ac00267a015; VANDERGREEF J, 1983, ANAL CHIM ACTA, V150, P45, DOI 10.1016/S0003-2670(00)85458-6; Varmuza K, 1980, PATTERN RECOGNITION; VERESS GE, 1982, TRENDS ANAL CHEM TRA, V1, P374, DOI 10.1016/0165-9936(82)88006-0	35	4	4	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	AUG	1986	26	3					93	98		10.1021/ci00051a002		6	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	D9880	WOS:A1986D988000003	
J	DYER, RAG; DYER, SA; BHAGAT, PK				DYER, RAG; DYER, SA; BHAGAT, PK			MYOCARDIAL TISSUE CHARACTERIZATION USING PATTERN-RECOGNITION PROCEDURES ON BACKSCATTERED ULTRASONIC SIGNALS	ULTRASONIC IMAGING			English	Article									UNIV KENTUCKY,DEPT MECH ENGN,LEXINGTON,KY 40506	DYER, RAG (reprint author), KANSAS STATE UNIV AGR & APPL SCI,DEPT ELECT & COMP ENGN,MANHATTAN,KS 66506, USA.						Ahmed N, 1975, ORTHOGONAL TRANSFORM; Andrews H., 1970, COMPUTER TECHNIQUES; BHAGAT PK, 1980, MED INSTRUM, V14, P220; COHEN RD, 1982, AM J CARDIOL, V50, P838, DOI 10.1016/0002-9149(82)91242-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CZERWINSKI M, 1978, 3RD P INT S ULTR IM, P64; DYER RAG, 1980, THESIS U KENTUCKY LE; DYER SA, 1977, THESIS KANSAS STATE; FINETTE S, 1983, ULTRASONIC IMAGING, V5, P71, DOI 10.1016/0161-7346(83)90102-5; FRANKLIN T, 1979, 4TH P INT S ULTR IM, P115; GOOD MS, 1982, ULTRASONIC IMAGING, V4, P378, DOI 10.1016/0161-7346(82)90020-7; GRAMIAK R, 1979, RADIOLOGY, V130, P713; GUPTA VN, 1982, ULTRASOUND MED BIOL, V8, P249, DOI 10.1016/0301-5629(82)90031-X; LERSKI RA, 1981, ULTRASONIC IMAGING, V3, P164, DOI 10.1016/0161-7346(81)90087-0; MILNE PJ, 1973, THESIS KANSAS STATE; MIMBS JW, 1981, CIRC RES, V49, P89; Nilsson Nils J., 1965, LEARNING MACHINES; ODONNELL M, 1979 IEEE ULTR S P, P175; PETERSON DW, 1970, IEEE T INFORM THEORY, V16, P26, DOI 10.1109/TIT.1970.1054408; PIPBERGER H, 1970, CLIN ELECTROCARDIOGR; PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869; PRESTON K, 1977, NBS SPEC PUBL, V525, P303; RASMUSSEN S, 1978, CIRCULATION, V57, P230; TRIBOLET JM, 1979, IEEE T ACOUST SPEECH, V27, P512, DOI 10.1109/TASSP.1979.1163283; Young T. Y., 1974, CLASSIFICATION ESTIM; ZELINSKI R, 1977, IEEE T ACOUST SPEECH, V25, P299, DOI 10.1109/TASSP.1977.1162974	26	0	0	ACADEMIC PRESS INC JNL-COMP SUBSCRIPTIONS	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495	0161-7346		ULTRASONIC IMAGING	Ultrason. Imaging	JUL	1986	8	3					181	195		10.1016/0161-7346(86)90008-8		15	Acoustics; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Acoustics; Engineering; Radiology, Nuclear Medicine & Medical Imaging	F7641	WOS:A1986F764100003	
J	COBURN, JT; FORBES, RA; FREISER, BS; BECKER, L; LYTLE, FE; HUBER, DM				COBURN, JT; FORBES, RA; FREISER, BS; BECKER, L; LYTLE, FE; HUBER, DM			THE APPLICATION OF PATTERN-RECOGNITION TO THE IDENTIFICATION OF PATHOGENS BY LASER-EXCITED FLUOROMETRY	ANALYTICA CHIMICA ACTA			English	Article									PURDUE UNIV,DEPT CHEM,W LAFAYETTE,IN 47907; PURDUE UNIV,DEPT BOT & PLANT PATHOL,W LAFAYETTE,IN 47907							COBURN JT, 1985, ANAL CHEM, V57, P1669, DOI 10.1021/ac00285a035; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARLAND G, 1975, J CLIN MICROBIOL, V2, P391; FORBES RA, 1986, ANAL CHEM, V58, P684, DOI 10.1021/ac00295a006; FORBES RA, J COMPUT CHEM; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GODSEY JH, 1981, J CLIN MICROBIOL, V13, P483; HUBER DM, 1969, PHYTOPATHOLOGY, V59, P1032; JURS PC, 1975, CHEM APPLICATIONS PA; Massart D. L., 1978, EVALUATION OPTIMIZAT; MCINTYRE JL, 1975, PHYTOPATHOLOGY, V65, P1206; SIELAFF BH, 1982, J CLIN MICROBIOL, V15, P1103; THOMAS QV, 1977, ANAL CHEM, V49, P1376, DOI 10.1021/ac50017a022; VARMUZA K, 1975, PATTERN RECOGNITION	14	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta	JUN 30	1986	184						65	76		10.1016/S0003-2670(00)86470-3		12	Chemistry, Analytical	Chemistry	D9647	WOS:A1986D964700005	
J	LESIAK, B; MROZEK, P; JABLONSKI, A; JOZWIK, A				LESIAK, B; MROZEK, P; JABLONSKI, A; JOZWIK, A			ANALYSIS OF THE AUGER KLL SPECTRA OF CARBON BY THE PATTERN-RECOGNITION METHOD	SURFACE AND INTERFACE ANALYSIS			English	Article									POLISH ACAD SCI,INST BIOCYBERNET & BIOMED ENGN,PL-00818 WARSZAWA,POLAND	LESIAK, B (reprint author), POLISH ACAD SCI,INST PHYS CHEM,KASPRZAKA 44-52,PL-01224 WARSAW,POLAND.						ASHLEY JC, 1982, SURF INTERFACE ANAL, V4, P52, DOI 10.1002/sia.740040205; BONZEL HP, 1980, SURF SCI, V91, P499, DOI 10.1016/0039-6028(80)90347-7; BONZEL HP, 1982, SURF SCI, V117, P639, DOI 10.1016/0039-6028(82)90545-3; BRIGGS D, 1983, PRACTICAL SURFACE AN; COAD JP, 1971, SURF SCI, V25, P609, DOI 10.1016/0039-6028(71)90148-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAIG S, 1983, SURF SCI, V124, P591, DOI 10.1016/0039-6028(83)90813-0; DEMUTH JE, 1974, SURF SCI, V45, P249, DOI 10.1016/0039-6028(74)90167-8; Devijver P. A., 1982, PATTERN RECOGNITION; DUCROS R, 1976, SURFACE SCI, V54, P519; Duda R., 1973, PATTERN CLASSIFICATI; EASTMAN DE, 1974, J VAC SCI TECHNOL, V11, P273, DOI 10.1116/1.1318592; ERGUN S, 1968, CARBON, V6, P141, DOI 10.1016/0008-6223(68)90299-6; ERLEY W, 1978, SURF SCI, V74, P333, DOI 10.1016/0039-6028(78)90030-4; GAARENSTROOM SW, 1979, J VAC SCI TECHNOL, V16, P600, DOI 10.1116/1.570009; HAAS TW, 1972, J APPL PHYS, V43, P1853, DOI 10.1063/1.1661409; HAAS TW, 1971, ADSORPTION DESORPTIO; HALL PM, 1979, SURF SCI, V83, P391, DOI 10.1016/0039-6028(79)90052-9; HOOKER MP, 1977, SURF SCI, V62, P21, DOI 10.1016/0039-6028(77)90425-3; HOOKER MP, 1976, SURF SCI, V55, P741, DOI 10.1016/0039-6028(76)90277-6; JABLONSKI A, 1982, SURF INTERFACE ANAL, V4, P135, DOI 10.1002/sia.740040403; JOYNER RW, 1974, J CHEM SOC F1, P1819; JURS PC, 1975, CHEM APPLICATIONS PA; KOPLOWITZ J, 1972, ANAL CHEM, V44, P1415; KOWALCZY.SP, 1973, PHYS REV B, V8, P2387, DOI 10.1103/PhysRevB.8.2387; MADDEN HH, 1973, J CHEM PHYS, V58, P3401, DOI 10.1063/1.1679668; PENN DR, 1976, J ELECTRON SPECTROSC, V9, P29, DOI 10.1016/0368-2048(76)85004-9; POWELL CJ, 1976, REV MOD PHYS, V48, P33, DOI 10.1103/RevModPhys.48.33; PUNGARO E, 1984, MODERN TRENDS ANAL C; Seah M. P., 1979, Surface and Interface Analysis, V1, DOI 10.1002/sia.740010103; SINHAROY S, 1978, SURF SCI, V72, P710, DOI 10.1016/0039-6028(78)90355-2; SMITH MA, 1979, J VAC SCI TECHNOL, V16, P462, DOI 10.1116/1.569982; SOKOLSKY DV, 1975, ELECTROCHIM ACTA, V20, P71, DOI 10.1016/0013-4686(75)85047-X; Varmuza K, 1980, PATTERN RECOGNITION; WAGNER CD, 1975, FARADAY DISCUSS, V60, P291, DOI 10.1039/dc9756000291; ZOLTOWSKI P, 1980, ELECTROCHIM ACTA, V25, P1547, DOI 10.1016/0013-4686(80)80003-X	36	21	21	JOHN WILEY & SONS LTD	W SUSSEX	BAFFINS LANE CHICHESTER, W SUSSEX, ENGLAND PO19 1UD	0142-2421		SURF INTERFACE ANAL	Surf. Interface Anal.	JUN	1986	8	3					121	126		10.1002/sia.740080304		6	Chemistry, Physical	Chemistry	C8325	WOS:A1986C832500003	
J	GAIL, MH; MUENZ, L; MCINTIRE, KR; RADOVICH, B; BRAUNSTEIN, G; BROWN, PR; DEFTOS, L; DNISTRIAN, A; DUNSMORE, M; ELASHOFF, R; GELLER, N; GO, VLW; HIRJI, K; KLAUBER, MR; PEE, D; PETRONI, G; SCHWARTZ, M; WOLFSEN, AR				GAIL, MH; MUENZ, L; MCINTIRE, KR; RADOVICH, B; BRAUNSTEIN, G; BROWN, PR; DEFTOS, L; DNISTRIAN, A; DUNSMORE, M; ELASHOFF, R; GELLER, N; GO, VLW; HIRJI, K; KLAUBER, MR; PEE, D; PETRONI, G; SCHWARTZ, M; WOLFSEN, AR			MULTIPLE MARKERS FOR LUNG-CANCER DIAGNOSIS - VALIDATION OF MODELS FOR ADVANCED LUNG-CANCER	JOURNAL OF THE NATIONAL CANCER INSTITUTE			English	Article									SRA TECHNOL,ARLINGTON,VA 22204; INFORMAT MANAGEMENT SERV,SILVER SPRING,MD 20910; NIADDKD,BETHESDA,MD 20892; CEDARS SINAI MED CTR,DEPT ENDOCRINOL,LOS ANGELES,CA 90048; UNIV RHODE ISL,DEPT CHEM,KINGSTON,RI 02881; VET ADM MED CTR,DEPT MED,SAN DIEGO,CA 92161; MEM SLOAN KETTERING CANC CTR,DEPT CLIN CHEM,NEW YORK,NY 10021; UNIV CALIF LOS ANGELES,DIV BIOSTAT,LOS ANGELES,CA 90024; MEM SLOAN KETTERING CANC CTR,DIV BIOSTAT,NEW YORK,NY 10021; UNIV CALIF SAN DIEGO,DEPT STAT,LA JOLLA,CA 92093; UNIV WASHINGTON,DIV BIOSTAT,SEATTLE,WA 98195	GAIL, MH (reprint author), NCI,BIOSTAT BRANCH,LANDOW BLDG,ROOM 3C37,BETHESDA,MD 20892, USA.						ANDERSON JA, 1973, DISCRIMINATION ANAL, P1; Anderson T.W., 1958, INTRO MULTIVARIATE S, P126; BACHELOT I, 1977, J CLIN ENDOCR METAB, V44, P939; BEAHRS OH, 1983, MANUAL STAGING CANCE, P99; BRAUNSTEIN GD, 1978, AM J OBSTET GYNECOL, V131, P25; BRAUNSTEIN GD, 1979, CANCER, V44, P1644, DOI 10.1002/1097-0142(197911)44:5<1644::AID-CNCR2820440517>3.0.CO;2-B; Brieman L, 1984, CLASSIFICATION REGRE; CATHERWOOD BD, 1984, ASSAYS CALCIUM REGUL, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DNISTRIAN AM, 1982, P AM ASSOC CANC RES, V23, P155; Downs F, 1976, METHODS CARBOHYDRATE, VVII, P233; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; GAIL MH, 1979, IMMUNODIAGNOSIS CANC, P20; KATOPODIS N, 1980, RES COMMUN CHEM PATH, V30, P171; LACHENBRUCH PA, 1980, METHOD INFORM MED, V19, P220; MCINTIRE KR, 1982, HUMAN CANCER MARKERS, P359; MCINTIRE KR, 1983, ANN NY ACAD SCI, V417, P435, DOI 10.1111/j.1749-6632.1983.tb32885.x; MIETTINEN T, 1959, ACTA CHEM SCAND, V13, P856, DOI 10.3891/acta.chem.scand.13-0856; MUNJAL DD, 1984, DIAGN CLIN IMMUNOL, V2, P36; ODELL WD, 1979, AM J MED, V66, P631, DOI 10.1016/0002-9343(79)91174-4; PARTHEMORE JG, 1978, J CLIN ENDOCR METAB, V47, P184; SCHLEGEL G, 1981, TUMORDIAGNOSTIK, V2, P6; SCHWARTZ KE, 1979, J CLIN ENDOCR METAB, V49, P438; SNEDECOR GW, 1967, STATISTICAL METHODS, P213; SVENNERHOLM L, 1957, BIOCHIM BIOPHYS ACTA, V24, P604, DOI 10.1016/0006-3002(57)90254-8; WARREN L, 1959, J BIOL CHEM, V234, P1971; 1982, SAS USERS GUIDE STAT, P381; 1982, SAS USERS GUIDE STAT, P397; 1980, SAS SUPPLEMENTAL LIB, P83	29	50	50	NATL CANCER INSTITUTE	BETHESDA	9030 OLD GEORGETOWN RD, BETHESDA, MD 20814	0027-8874		J NATL CANCER I	J. Natl. Cancer Inst.	MAY	1986	76	5					805	816				12	Oncology	Oncology	C2672	WOS:A1986C267200004	
J	FORBES, RA; TEWS, EC; FREISER, BS; WISE, MB; PERONE, SP				FORBES, RA; TEWS, EC; FREISER, BS; WISE, MB; PERONE, SP			APPLICATION OF PATTERN-RECOGNITION TO METAL-ION CHEMICAL IONIZATION MASS-SPECTRA	ANALYTICAL CHEMISTRY			English	Article									PURDUE UNIV,DEPT CHEM,W LAFAYETTE,IN 47907; OAK RIDGE NATL LAB,OAK RIDGE,TN 37831; UNIV CALIF LAWRENCE LIVERMORE NATL LAB,LIVERMORE,CA 94550							ABE H, 1975, ANAL CHEM, V47, P1829, DOI 10.1021/ac60361a007; BEAUCHAM.JL, 1971, ANNU REV PHYS CHEM, V22, P527, DOI 10.1146/annurev.pc.22.100171.002523; BINK JCWG, 1983, ANAL CHIM ACTA, V150, P53, DOI 10.1016/S0003-2670(00)85459-8; BRAUNER A, 1982, ORG MASS SPECTROM, V17, P161, DOI 10.1002/oms.1210170403; BRENT DA, 1981, BIOMED MASS SPECTROM, V8, P440, DOI 10.1002/bms.1200080916; BUGARD DR, 1978, ANAL CHEM, V50, P1366; BURNIER RC, 1981, J AM CHEM SOC, V103, P4360, DOI 10.1021/ja00405a012; BYERS WA, 1983, ANAL CHEM, V55, P620, DOI 10.1021/ac00255a009; BYERS WA, 1983, ANAL CHEM, V55, P615, DOI 10.1021/ac00255a008; BYRD GD, 1982, J AM CHEM SOC, V104, P3565, DOI 10.1021/ja00377a004; CHIEN M, 1985, ANAL CHEM, V57, P348, DOI 10.1021/ac00279a078; COMISAROW ML, 1982, LECTURE NOTES CHEM, V31, P484; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMOKOS L, 1983, ANAL CHIM ACTA, V150, P37, DOI 10.1016/S0003-2670(00)85457-4; DOMOKOS L, 1984, SPECTRA, V10, P11; DROMEY RG, 1984, SPECTRA, V10, P3; DUNN WJ, 1984, ANAL CHEM, V56, P1308, DOI 10.1021/ac00272a026; FORBES RA, UNPUB J COMPUTATIONA; FRANKEL DS, 1984, ANAL CHEM, V56, P1011, DOI 10.1021/ac00270a032; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HABBEMA JDF, 1983, ANAL CHIM ACTA, V150, P1, DOI 10.1016/S0003-2670(00)85454-9; HIPPE Z, 1983, ANAL CHIM ACTA, V150, P11, DOI 10.1016/S0003-2670(00)85455-0; JACOBSON DB, 1983, J AM CHEM SOC, V105, P7484, DOI 10.1021/ja00364a002; JACOBSON DB, 1983, J AM CHEM SOC, V105, P5197, DOI 10.1021/ja00354a003; JACOBSON DB, 1983, J AM CHEM SOC, V105, P7492, DOI 10.1021/ja00364a003; JELLUM E, 1981, J CHROMATOGR, V217, P231, DOI 10.1016/S0021-9673(00)88077-2; JENNINGS KR, 1979, GAS PHASE ION CHEM, V2, P123; JURS PC, 1975, CHEM APPLICATIONS PA; JUSTICE JB, 1974, ANAL CHEM, V46, P223, DOI 10.1021/ac60338a010; KANG H, 1985, J PHYS CHEM-US, V89, P3364, DOI 10.1021/j100261a041; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; Leegwater D. C., 1984, TRAC Trends in Analytical Chemistry, V3, DOI 10.1016/0165-9936(84)87064-8; LEHMAN TA, 1976, ION CYCLOTRON RESONA; MUNSON B, 1977, ANAL CHEM, V49, pA772, DOI 10.1021/ac50017a001; MUNSON MSB, 1966, J AM CHEM SOC, V88, P2621, DOI 10.1021/ja00964a001; PARRISH ME, 1983, ANAL CHIM ACTA, V150, P163, DOI 10.1016/S0003-2670(00)85468-9; RITTER GL, 1975, ANAL CHEM, V47, P1951, DOI 10.1021/ac60362a005; Rotter H., 1978, Analytica Chimica Acta, Computer Techniques and Optimization, V103, DOI 10.1016/S0003-2670(01)83807-1; SCHACHTERLE SD, 1981, ANAL CHEM, V53, P1672, DOI 10.1021/ac00234a028; THOMAS QV, 1977, ANAL CHEM, V49, P1369, DOI 10.1021/ac50017a021; THOMAS QV, 1977, ANAL CHEM, V49, P1376, DOI 10.1021/ac50017a022; TSAO R, 1984, ANAL CHEM, V56, P368, DOI 10.1021/ac00267a015; VANDERGREEF J, 1983, ANAL CHIM ACTA, V150, P45, DOI 10.1016/S0003-2670(00)85458-6; VARMUZA K, 1975, PATTERN RECOGNITION; VERESS GE, 1982, TRENDS ANAL CHEM TRA, V1, P374, DOI 10.1016/0165-9936(82)88006-0; WANCZEK KP, 1984, INT J MASS SPECTROM, V60, P11, DOI 10.1016/0168-1176(84)80075-0; WISE MB, 1984, THESIS PURDUE U W LA; WRONKA J, 1982, REV SCI INSTRUM, V53, P107	49	23	23	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0003-2700		ANAL CHEM	Anal. Chem.	APR	1986	58	4					684	689		10.1021/ac00295a006		6	Chemistry, Analytical	Chemistry	A6387	WOS:A1986A638700010	
J	BEZDEK, JC; CHUAH, SK; LEEP, D				BEZDEK, JC; CHUAH, SK; LEEP, D			GENERALIZED K NEAREST NEIGHBOR RULES	FUZZY SETS AND SYSTEMS			English	Article									BOEING CO,SEATTLE,WA 98124	BEZDEK, JC (reprint author), UNIV S CAROLINA,DEPT COMP SCI,COLUMBIA,SC 29208, USA.						Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1975, IEEE T COMPUT, V24, P835, DOI 10.1109/T-C.1975.224317; BEZDEK JC, 1977, IEEE T SYST MAN CYB, V7, P87, DOI 10.1109/TSMC.1977.4309659; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; BEZDEK JC, 1985, PATTERN RECOGN LETT, V3, P79, DOI 10.1016/0167-8655(85)90012-1; CHUAH S, 1986, UNPUB SOFT OPTIMIZAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1974, PATTERN CLASSIFICATI; Duin R. P. W., 1982, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(82)90045-9; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUKUNAGA K, 1985, UNPUB IEEE T PATTERN; GARNETT JM, 1977, IEEE T COMPUT, V26, P46; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KITTLER J, 1981, PATTERN RECOGN, V13, P245, DOI 10.1016/0031-3203(81)90101-1; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403	15	63	64	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	APR	1986	18	3					237	256		10.1016/0165-0114(86)90004-7		20	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	A7957	WOS:A1986A795700004	
J	ENAS, GG; CHOI, SC				ENAS, GG; CHOI, SC			CHOICE OF THE SMOOTHING PARAMETER AND EFFICIENCY OF K-NEAREST NEIGHBOR CLASSIFICATION	COMPUTERS & MATHEMATICS WITH APPLICATIONS-PART A			English	Article									VIRGINIA COMMONWEALTH UNIV,MED COLL VIRGINIA,DEPT BIOSTAT,RICHMOND,VA 23298	ENAS, GG (reprint author), ELI LILLY & CO,LILLY RES LAB,INDIANAPOLIS,IN 46285, USA.						COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, ANN STAT, V6, P1320; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; FISHER FP, 1971, THESIS PURDUE U LAFE; Fix E, 1951, 4 US AIR FORC SCH AV; FIX E, 1952, 11 US AIR FORC SCH A; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GOLDSTEI.M, 1972, IEEE T INFORM THEORY, V18, P627, DOI 10.1109/TIT.1972.1054888; Patrick E. A., 1972, FUNDAMENTALS PATTERN; RABINER LR, 1979, IEEE T ACOUSTICS SPE, V27, P339	11	31	32	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0886-9553		COMPUT MATH APPL-A		FEB	1986	12	2					235	244		10.1016/0898-1221(86)90076-3		10	Mathematics, Applied	Mathematics	A9598	WOS:A1986A959800008	
J	DEVIJVER, PA				DEVIJVER, PA			ON THE EDITING RATE OF THE MULTIEDIT ALGORITHM	PATTERN RECOGNITION LETTERS			English	Article										DEVIJVER, PA (reprint author), PHILIPS RES LAB,AVE VAN BECELAERE 2,BOX 8,B-1170 BRUSSELS,BELGIUM.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1984, ADV INFORMATION SCI, P84; DEVIJVER PA, 1982, PATTERN RECOGN, P3; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; DEVIJVER PA, 1979, R410 PHIL RES LAB RE; SHORT RD, 1980, 5TH INT C PATT REC M, P81; VOISIN J, 1985, IRSIA137 PHIL MBLE A; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	9	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB	1986	4	1					9	12		10.1016/0167-8655(86)90066-8		4	Computer Science, Artificial Intelligence	Computer Science	C0585	WOS:A1986C058500002	
J	ROSENTHAL, RJ; LOWRY, SR				ROSENTHAL, RJ; LOWRY, SR			EFFECTS OF SAMPLING METHODOLOGIES ON FT-IR DATABASE SEARCHING	MIKROCHIMICA ACTA			English	Article										ROSENTHAL, RJ (reprint author), NICOLET INSTRUMENT CORP,SPECT RES CTR,5225-1 VERONA RD,MADISON,WI 53711.						ANDERSON DH, 1967, ANAL CHEM, V39, P1288, DOI 10.1021/ac60255a008; Bell A.G., 1881, PHILOS MAG, V11, P510; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ERLY DS, 1968, ANAL CHEM, V40, P894; Griffiths P. R., 1986, CHEM ANAL, V83; GRIFFITHS PR, 1981, ADV INFRARED RAMAN S, V9, pCH2; HANNA A, 1979, J CHROMATOGR SCI, V17, P434; Harrick N. J., 1979, INTERNAL REFLECTION; HIRSCHFELD T, 1974, TRANSFORM, V3, P2; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KUBELKA P, 1948, J OPT SOC AM, V38, P448, DOI 10.1364/JOSA.38.000448; Kubelka P., 1931, Zeitschrift fur Technische Physik, V12; KUEHL D, 1983, 10TH ANN FED AN CHEM; LEARY JJ, 1973, J CHROMATOGR SCI, V11, P201; LOWRY SR, 1985, J CHEM INF COMP SCI, V25, P235, DOI 10.1021/ci00047a019; MESSERSCHMIDT RG, 1985, APPL SPECTROSC, V39, P737, DOI 10.1366/0003702854250167; MIRABELLA FM, 1985, APPL SPECTROSC REV, V21, P45, DOI 10.1080/05704928508060428; ROSENCWAIG A, 1980, CHEM ANAL, V54; SMITH AL, 1979, APPLIED INFRARED SPE, P84; SPARKS RA, 1964, STORAGE RETRIEVAL WY; TILGNER R, 1980, APPL OPTICS, V20, P3780; VIDRINE DW, COMMUNICATION	22	4	4	SPRINGER-VERLAG WIEN	VIENNA	SACHSENPLATZ 4-6, PO BOX 89, A-1201 VIENNA, AUSTRIA	0026-3672		MIKROCHIM ACTA	Mikrochim. Acta		1986	2	1-6					291	302				12	Chemistry, Analytical	Chemistry	J5327	WOS:A1986J532700021	
J	HERMIDA, RC; HALBERG, F; DELPOZO, F				HERMIDA, RC; HALBERG, F; DELPOZO, F			CHRONOBIOLOGIC PATTERN-DISCRIMINATION OF PLASMA HORMONES, NOTABLY DHEA-S AND TSH, CLASSIFIES AN EXPANSIVE PERSONALITY	CHRONOBIOLOGIA			English	Article									UNIV POLITECN MADRID,ETSI TELECOMUN,CATEDRA BIOINGENN,MADRID,SPAIN	HERMIDA, RC (reprint author), UNIV MINNESOTA,DEPT LAB MED & PATHOL,CHRONOBIOL LABS,5-187 LYON LABS,420 WASHINGTON AU SE,MINNEAPOLIS,MN 55455, USA.						AGRIMENTI F, 1981, INT J CHRONOBIOL, V7, P196; AGRIMONTI F, 1981, INT J CHRONOBIOL, V7, P195; Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; Aizerman M.A., 1964, Avtomatika i Telemekhanika, V25; AIZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P1175; Andrews H.C., 1972, INTRO MATH TECHNIQUE; BABU CC, 1969, P IEEE, V57, P2086, DOI 10.1109/PROC.1969.7482; Ball G. H., 1965, ISODATA NOVEL METHOD; BARNES GE, 1983, BIOL ALCOHOLISM, V6; BARTTER FC, 1962, ANN NY ACAD SCI, V98, P969; BENTLEY JL, 1978, IEEE T COMPUT, V27, P97; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Cleary J. G., 1979, ACM Transactions on Mathematical Software, V5, DOI 10.1145/355826.355832; CORNELISSEN G, 1983, MINN ACAD SCI, V51, P9; CORPECHOT C, 1981, P NATL ACAD SCI-BIOL, V78, P4704, DOI 10.1073/pnas.78.8.4704; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1969, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX WM, 1983, IDENTIFYING MEASURIN, V5, P83; DEVROYE L, 1982, HDB STAT, V2, P193, DOI 10.1016/S0169-7161(82)02011-2; DEVROYE LP, 1978, IEEE T INFORM THEORY, V24, P142, DOI 10.1109/TIT.1978.1055865; DOE RP, 1966, THESIS U MINNESOTA, P222; DOMINGUEZ RCH, 1984, CHRONOBIOLOGIA, V11, P249; DOMINGUEZ RCH, 1985, CHRONOBIOLOGIA, V12, P184; DOMINGUEZ RCH, 1984, 15 P C INT SOC CHRON, P399; DOMINGUEZ RCH, 1981, METODOS ANAL MULTIVA, V1; DOMINGUEZ RCH, 1983, IEEE FRONTIERS ENG C, P296; DOMINGUEZ RCH, 1984, THESIS U MINNESOTA M, P225; DOMINGUEZ RCH, 1983, IEEE T BIOMED ENG, V30, P520; DOMINGUEZ RCH, 1983, MINN ACAD SCI, V51, P10; DOMINGUEZ RCH, 1984, 1982 SIRMCE C VIENN, P74; DOMINGUEZ RCH, 1984, UNPUB PATTERN DISCRI; DOMINGUEZ RCH, 1981, SIRMCE C MADRID, P181; DOMINGUEZ R C H, 1982, Revista Espanola de Oncologia, V29, P199; DOMINGUEZ RH, 1982, CHRONOBIOLOGIA, V9, P341; Duda R., 1973, PATTERN CLASSIFICATI; DUDA RO, 1966, IEEE TRANS ELECTRON, VEC15, P220, DOI 10.1109/PGEC.1966.264302; EFRON B, 1981, BIOMETRIKA, V68, P589, DOI 10.1093/biomet/68.3.589; Efron B, 1981, CANADIAN J STATISTIC, V9, P139, DOI 10.2307/3314608; EFRON B, 1982, 75 STANF U DIV STAT, P43; ERB JL, 1981, J CLIN ENDOCR METAB, V52, P181; FIX E, 1951, USAF4 SCH AV MED REP; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; FU KS, 1970, MATH SCI ENG, V52; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gnanadesikan R., 1977, B INT STAT I, V47, P451; GONDA KC, 1979, IEEE T INFORMATION T, V25, P488; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; HALBERG E, 1979, CHRONOBIOLOGIA, V6, P231; HALBERG E, 1981, CHRONOBIOLOGIA, V8, P253; HALBERG E, 1978, CHRONOBIOLOGIA, V5, P241; HALBERG E, 1981, CHRONOBIOLOGIA, V8, P351; Halberg F, 1981, NEOPLASMS COMP PATHO, P553; Halberg F, 1965, ACTA ENDOCR-COP    S, V103, P5; HALBERG FRANZ, 1953, JOUR LANCET, V73, P20; Halberg F, 1967, CELLULAR ASPECTS BIO, P20; HALBERG F, 1982, 1ST P AFR MED C CLIN, P113; HALBERG F, 1960, AM J MENT DEF, V65, P156; HALBERG F, 1980, CHRONOBIOLOGY PRINCI, P541; HALBERG F, 1978, EXPERIENTIA, V34, P713, DOI 10.1007/BF01947276; HALBERG F, 1970, SYSTEMS APPROACH APP, P31; HALBERG F, 1977, CHRONOBIOLOGIA S1, V4, P189; HALBERG F, 1964, W REED ARM I RES S M, P1; HALBERG F, 1968, S BIOL CYCLES PSYCHI, V3, P73; Halberg F, 1972, PHYSIOL TEACH, V1, P1; HALBERG F, 1969, ANNU REV PHYSIOL, V31, P675, DOI 10.1146/annurev.ph.31.030169.003331; HALBERG F, 1980, CHRONOBIOLOGY PRINCI, pR5; HALBERG F, 1981, HORMONES DEV AGING, P451; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HART PE, 1966, 18282SEL60016 STANF; HAUS E, 1970, THESIS U MINNESOTA, P361; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Hermida Dominguez R, 1982, CLIN CHEM NEWSL, V2, P191; HIRAYAMA T, 1977, COMP EPIDEMIOLOGY CA, P122; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JENNER FA, 1970, BIOCH SCHIZOPHRENIAS, P29; KAWASAKI T, 1980, AM J MED, V68, P91, DOI 10.1016/0002-9343(80)90177-1; KINCANNO.JC, 1968, J CONSULT CLIN PSYCH, V32, P319, DOI 10.1037/h0025891; KLEISER B, 1984, ANN REV CHRONOPHARMA, V1, P41; KNAPP MS, 1967, THESIS U BRISTOL, P158; KOBAYASHI M, 1970, IEEE T INFORMATION T, V16; KRIEGER DT, 1980, NEUROENDOCRINOLOGY, P352; LANDWEHR JM, 1972, THESIS U CHICAGO CHI; LANG AR, 1983, COMMONALITIES SUBSTA; LOPER RG, 1973, J ABNORM PSYCHOL, V82, P159, DOI 10.1037/h0034959; MACANDREW C, 1981, J STUD ALCOHOL, V42, P604; MCKAY RJ, 1982, BRIT J MATH STAT PSY, V35, P1; MCMAHON B, 1973, J NATL CANCER I, V50, P21; MEISEL WS, 1969, IEEE T COMPUT, VC 18, P911, DOI 10.1109/T-C.1969.222546; Mendel J.M., 1970, ADAPTIVE LEARNING PA; NELSON W, 1980, J GERONTOL, V35, P512; NELSON W, 1983, CHRONOBIOLOGIA, V10, P179; NIE NH, 1975, SPSS MANUAL; OCALLAGHAN JF, 1975, IEEE T COMPUT, V24, P1121, DOI 10.1109/T-C.1975.224144; ORTHGOMER K, 1982, CHRONOPHARMACOLOGY, P191; Patrick E. A., 1972, FUNDAMENTALS PATTERN; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; PETERSON DW, 1970, IEEE T INFORM THEORY, V16, P26, DOI 10.1109/TIT.1970.1054408; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SCHEVING LE, 1976, ENDEAVOUR, V35, P66, DOI 10.1016/0160-9327(76)90030-2; SEGI M, 1977, CANCER INCIDENCE 5 C, V3, P42; SOM A, 1980, IEEE T SYST MAN CYB, V10, P524; STATLAND BE, 1977, ADV AUTOMATED ANAL, P1; STATLAND BE, 1978, AM J CLIN PATHOL, V69, P48; STATLAND BE, 1976, CLIN CHEM, V22, P1212; TARQUINI B, 1979, CHRONOBIOLOGIA, V6, P162; TARQUINI B, 1979, GIORN GERONT, V26, P629; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Tou J.T., 1974, PATTERN RECOGNITION; TOURNEY G, 1973, BIOL PSYCHIAT, V6, P23; WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P696, DOI 10.1109/TIT.1973.1055059; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WINKEL P, 1975, AM J CLIN PATHOL, V64, P433; WINKEL P, 1977, CONT TOPICS ANAL CLI, P287; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; ZUCKER RA, 1982, ALCOHOL HLTH MONOGRA, V1	126	22	22	ASSOCIATED CHRONOBIOLOGIA RESEARCHERS	MILAN	VIA R. DI LAURIA, 12/A, 20149 MILAN, ITALY	0390-0037		CHRONOBIOLOGIA			1985	12	2					105	136				32	Biology	Life Sciences & Biomedicine - Other Topics	ANA69	WOS:A1985ANA6900001	
J	DYER, SA; AHMED, N; HUMMELS, DR				DYER, SA; AHMED, N; HUMMELS, DR			CLASSIFICATION OF VECTORCARDIOGRAMS USING WALSH AND COSINE ORTHOGONAL-TRANSFORMS	IEEE TRANSACTIONS ON ELECTROMAGNETIC COMPATIBILITY			English	Article									UNIV NEW MEXICO,DEPT ELECT & COMP ENGN,ALBUQUERQUE,NM 87131	DYER, SA (reprint author), KANSAS STATE UNIV AGR & APPL SCI,DEPT ELECT & COMP ENGN,MANHATTAN,KS 66506, USA.						Ahmed N, 1975, ORTHOGONAL TRANSFORM; AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; ANDREWS H, 1971, IEEE T COMPUT, V20, P1040; Andrews H., 1970, COMPUTER TECHNIQUES; Andrews H.C., 1972, INTRO MATH TECHNIQUE; CACERES CA, 1970, CLIN ELECTROCARDIOGR; CADY LD, 1961, CIRC RES, V9, P1078; CHANDRAS.B, 1971, IEEE T INFORM THEORY, V17, P452, DOI 10.1109/TIT.1971.1054665; CHIEN YT, 1967, IEEE T INFORM THEORY, V13, P518, DOI 10.1109/TIT.1967.1054021; CORNFIELD J, 1975, COMPUT BIOMED RES, V6, P97; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DYER SA, 1977, THESIS KANSAS STATE; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; HAMBLEY AR, 1974, IEEE T BIO-MED ENG, VBM21, P469, DOI 10.1109/TBME.1974.324335; HAMIDI M, 1976, IEEE T ACOUSTICS SPE, V25, P428; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; HUNT BR, 1975, P IEEE, V63, P693, DOI 10.1109/PROC.1975.9801; KELLY KK, 1971, IEEE T COMPUT, VC 20, P1109, DOI 10.1109/T-C.1971.223413; KITTLER J, 1973, PATTERN RECOGN, V5, P335, DOI 10.1016/0031-3203(73)90025-3; LACKEY RB, 1973 P NAT EL C, P267; LEVINE MD, 1969, P IEEE, V57, P1391, DOI 10.1109/PROC.1969.7277; MCFEE R, 1972, PR INST ELECTR ELECT, V60, P290, DOI 10.1109/PROC.1972.8621; MILNE PJ, 1972, THESIS KANSAS STATE; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; NATARAJAN T, 1976, THESIS KANSAS STATE; Nilsson Nils J., 1965, LEARNING MACHINES; PIPBERGER HV, 1963, PROG CARDIOVASC DIS, V5, P378, DOI 10.1016/S0033-0620(63)80006-7; PIPBERGER HV, 1975, ANNU REV BIOPHYS BIO, V4, P15, DOI 10.1146/annurev.bb.04.060175.000311; PRATT WK, 1972 P S APPL WALSH, P14; PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869; SCHER AM, 1960, CIRC RES, V8, P519; Walsh JL, 1923, AM J MATH, V45, P5, DOI 10.2307/2387224; WARTAK J, 1970, COMPUTERS ELECTROCAR; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Young T. Y., 1974, CLASSIFICATION ESTIM; YOUNG TY, 1963, IEEE T BIO-MED ENG, VBM10, P86, DOI 10.1109/TBMEL.1963.4322805	37	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9375		IEEE T ELECTROMAGN C	IEEE Trans. Electromagn. Compat.		1985	27	1					35	40		10.1109/TEMC.1985.304243		6	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	AAS26	WOS:A1985AAS2600006	
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			THE 2-NN RULE FOR MORE ACCURATE NN RISK-ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter										FUKUNAGA, K (reprint author), PURDUE UNIV,DEPT ELECT ENGN,W LAFAYETTE,IN 47907, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; FUKUNAGA K, 1972, INTRO STATISTICAL PA; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SHORT RD, 1980, 5TH INT C PATT REC M, P81	7	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					107	112				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	ABF09	WOS:A1985ABF0900012	
J	BRODER, AZ; BRUCKSTEIN, AM; KOPLOWITZ, J				BRODER, AZ; BRUCKSTEIN, AM; KOPLOWITZ, J			ON THE PERFORMANCE OF EDITED NEAREST NEIGHBOR RULES IN HIGH DIMENSIONS	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Letter									STANFORD UNIV,DEPT ELECT ENGN,STANFORD,CA 94305; CLARKSON COLL TECHNOL,DEPT ELECT & COMP ENGN,POTSDAM,NY 13676	BRODER, AZ (reprint author), STANFORD UNIV,DEPT COMP SCI,STANFORD,CA 94305, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEBRUIJN NG, 1970, ASYMPTOTIC METHODS A; Devijver P.A., 1980, 5TH P INT C PATT REC, P72; KARLIN S, 1981, 2ND COURSE STOCHASTI; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Sommerville D. M. Y, 1929, INTRO GEOMETRY N DIM; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	9	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1985	15	1					136	139				4	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	AFX09	WOS:A1985AFX0900013	
J	KELLER, JM; GRAY, MR; GIVENS, JA				KELLER, JM; GRAY, MR; GIVENS, JA			A FUZZY K-NEAREST NEIGHBOR ALGORITHM	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Letter										KELLER, JM (reprint author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65211, USA.						BATCHELOR BG, 1978, PATTERN RECOGNITION; Bezdek J., 1981, PATTERN RECOGNITION; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DEVIJVER PA, 1979, IEEE T INFORM THEORY, V25, P749, DOI 10.1109/TIT.1979.1056099; Dodwell P. C., 1970, VISUAL PATTERN RECOG; Duda R., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GNANADESIKAN R, 1977, METHODS STATISTICAL; GUPTA MM, 1979, ADV FUZZY SET THEORY; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Hunt E., 1975, ARTIFICIAL INTELLIGE; JACQUEZ JA, 1972, COMPUTER DIAGNOSIS D; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; Kandel A, 1982, FUZZY TECHNIQUES PAT; Kaufmann A., 1975, INTRO THEORY FUZZY S, V1; KELLER J, UNPUB IEEE T PATTERN; REYNOLDS AG, 1977, COGNITIVE PSYCHOL; SCHEINOK PERRY A., 1967, COMPUT BIO MED RES, V1, P221, DOI 10.1016/S0010-4809(67)80010-7; SPOEHR KT, 1982, VISUAL INFORMATION P; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; TOUSSAINT G T, 1975, Computers in Biology and Medicine, V4, P269, DOI 10.1016/0010-4825(75)90038-4; WANG PP, 1980, THEORY APPLICATIONS; WARDLE A, 1978, METHOD INFORM MED, V17, P15; WHITNEY AW, 1966, 4TH P ANN ALL C CIRC; Winston P. H., 1977, ARTIFICIAL INTELLIGE; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	31	503	526	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1985	15	4					580	585				6	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	AMJ28	WOS:A1985AMJ2800016	
J	LOWRY, SR; HUPPLER, DA; ANDERSON, CR				LOWRY, SR; HUPPLER, DA; ANDERSON, CR			DATA-BASE DEVELOPMENT AND SEARCH ALGORITHMS FOR AUTOMATED INFRARED SPECTRAL IDENTIFICATION	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Review									NICOLET INSTRUMENT CORP, RES & DEV, MADISON, WI 53711 USA	LOWRY, SR (reprint author), NICOLET INSTRUMENT CORP, SPECTRAL DATA BASE DEV GRP, MADISON, WI 53711 USA.						ANDERSON DH, 1967, ANAL CHEM, V39, P1288, DOI 10.1021/ac60255a008; AZARRAGA LV, 1979, ERL GC FT IR SOFTWAR; BAKER AW, 1953, ANAL CHEM, V25, P1457, DOI 10.1021/ac60082a011; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEHASETH JA, 1981, ANAL CHEM, V53, P2292, DOI 10.1021/ac00237a037; DELANEY MF, 1979, ANAL CHEM, V51, P1242, DOI 10.1021/ac50044a031; ERICKSON MD, 1981, APPL SPECTROSC, V35, P181, DOI 10.1366/0003702814731563; ERLY DS, 1968, ANAL CHEM, V40, P894; GRIFFITHS PR, 1979, APPL SPECTROSC, V33, P543, DOI 10.1366/0003702794925110; HANNA A, 1979, J CHROMATOGR SCI, V17, P434; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KUENTZEL LE, 1952, ANAL CHEM, V23, P1413; LEARY JJ, 1973, J CHROMATOGR SCI, V11, P201; LOWRY SR, 1983, ANAL CHEM, V55, P1288, DOI 10.1021/ac00259a024; LOWRY SR, 1981, ANAL CHEM, V53, P889, DOI 10.1021/ac00229a034; MILNE GWA, 1980, J CHEM INF COMP SCI, V20, P204, DOI 10.1021/ci60024a003; RANN CS, 1972, ANAL CHEM, V40, P1669; SCHAARSC.K, 1974, Z CHEM, V14, P374; SMALL GW, 1979, APPL SPECTROSC, V33, P444, DOI 10.1366/0003702794925282; SPARKS RA, 1964, STORAGE RETRIEVAL WY; TANABE K, 1975, ANAL CHEM, V47, P118, DOI 10.1021/ac60351a041; TOMELLINI SA, 1984, ANAL CHEM, V56, P67, DOI 10.1021/ac00265a018; WOODRUFF HB, 1980, ANAL CHEM, V52, P2321, DOI 10.1021/ac50064a019; 1975, ANAL CHEM, V47, pA945	24	31	31	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.		1985	25	3					235	241		10.1021/ci00047a019		7	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	APN30	WOS:A1985APN3000020	
J	DEVIJVER, PA				DEVIJVER, PA			A MULTICLASS, K-NN APPROACH TO BAYES RISK-ESTIMATION	PATTERN RECOGNITION LETTERS			English	Article										DEVIJVER, PA (reprint author), PHILIPS RES LAB,AVE EM VAN BECELAERE 2,BOX 8,BRUSSELS,BELGIUM.						CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1979, IEEE T INFORM THEORY, V25, P749, DOI 10.1109/TIT.1979.1056099; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; Devijver P. A., 1982, PATTERN RECOGNITION; DEVIJVER PA, 1978, 4TH P INT C PATT REC, P217; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1972, IEEE T INFORM THEORY, V18, P814, DOI 10.1109/TIT.1972.1054919; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P434, DOI 10.1109/TIT.1973.1055049; GARNETT JM, 1977, IEEE T COMPUT, V26, P46; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; KITTLER J, 1982, IEEE T PATTERN ANAL, V4, P215; KITTLER J, 1980, IEEE T PATTERN ANAL, V2, P259; KITTLER J, 1981, PATTERN RECOGN, V13, P245, DOI 10.1016/0031-3203(81)90101-1; SIMON JC, 1984, RECONNAISSANCE FORME	15	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.		1985	3	1					1	6		10.1016/0167-8655(85)90035-2		6	Computer Science, Artificial Intelligence	Computer Science	ACT28	WOS:A1985ACT2800001	
J	LEVINSON, SE				LEVINSON, SE			STRUCTURAL METHODS IN AUTOMATIC SPEECH RECOGNITION	PROCEEDINGS OF THE IEEE			English	Review										LEVINSON, SE (reprint author), AT&T BELL LABS,ACOUST RES DEPT,MURRAY HILL,NJ 07974, USA.						AHO AV, 1980, 14TH P ANN C INF SCI; ALDEFELD B, 1980, AT&T TECH J, V59, P1343; ALLEN JB, 1977, J ACOUST SOC AM, V62, P930, DOI 10.1121/1.381586; ALTER R, 1968, IEEE T ACOUST SPEECH, VAU16, P6, DOI 10.1109/TAU.1968.1161943; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179; Bahl L. R., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing; Bahl L. R., 1979, P IEEE INT C AC SPEE, P442; Bahl L. R., 1979, P IEEE INT C AC SPEE, P418; Bahl L.R., 1980, P 1980 IEEE INT C AC, P872; BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; Baker J, 1979, 97 M AC SOC AM, P547; BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650; Baker JK, 1975, SPEECH RECOGNITION, P521; Baum L. E., 1972, INEQUALITIES, V3, P1; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; BAUM LE, 1968, PAC J MATH, V27, P211; Bekesy G., 1960, EXPT HEARING; Bellman R., 1957, DYNAMIC PROGRAMMING; Billi R., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; BOURLARD H, 1984, P INT C ACOUSTICS SP; Bridle J. S., 1979, P I AC AUT C, P25; Cave R. L., 1980, P S APPL HIDD MARK M, P16; CHAN DSK, 1973, AT&T TECH J, V52, P347; Chomsky N., 1959, INFORM CONTR, V2, P137, DOI 10.1016/S0019-9958(59)90362-6; CHOMSKY NOAM, 1968, SOUND PATTERNS ENGLI; Cohen P. S., 1975, SPEECH RECOGNITION, P275; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; DEMORI R, 1973, IEEE T ACOUST SPEECH, VAU21, P89, DOI 10.1109/TAU.1973.1162442; DEMORI R, 1985, IEEE T PATTERN ANAL, V7, P56; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DENES P, 1960, J ACOUST SOC AM, V32, P1450, DOI 10.1121/1.1907936; Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; DUDLEY H, 1958, J ACOUST SOC AM, V30, P721, DOI 10.1121/1.1909742; ERMAN LD, 1976, IEEE T COMPUT, V25, P422; FAN K, 1950, MEMORIAL SCI MATH, V114; FANO RM, 1961, TRANSMISSION INFORMA; Fant G., 1970, ACOUSTIC THEORY SPEE; Ferguson J., 1980, P S APPL HIDD MARK M, P143; Fitch H. L., 1983, J ACOUST SOC AM S1, V74, P816; Flanagan J, 1972, SPEECH ANAL SYNTHESI; Fletcher H., 1953, SPEECH HEARING COMMU; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95; Fu K. S., 1974, SYNTACTIC METHODS PA; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; Fujisaki T., 1984, 10th International Conference on Computational Linguistics. 22nd Annual Meeting of the Association for Computational Linguistics. Proceedings of Coling 84; FUNG LW, 1975, IEEE T COMPUT, VC 24, P662; Garey M.R., 1979, COMPUTERS INTRACTABI; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; Greibach S. A., 1979, 20th Annual Symposium of Foundations of Computer Science, DOI 10.1109/SFCS.1979.19; HALL JL, 1977, J ACOUST SOC AM, V61, P802, DOI 10.1121/1.381369; HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686; Harrison M. A., 1979, INTRO FORMAL LANGUAG; Haton J. P., 1980, P INT C AC SPEECH SI, P892; Hopcroft J. E., 1969, FORMAL LANGUAGES THE; Hunt M. J., 1980, P INT C AC SPEECH SI, P880; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; James W., 1899, TALKS TEACHERS PSYCH; JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384; JELINEK F, 1982, HDB STATISTICS, V2; Jelinek F., 1969, IBM Journal of Research and Development, V13; Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; JUANG BH, UNPUB IEEE T INFORM; KLATT DH, 1977, J ACOUST SOC AM, V62, P1345, DOI 10.1121/1.381666; KLATT DH, 1973, IEEE T ACOUST SPEECH, VAU21, P210, DOI 10.1109/TAU.1973.1162453; Knuth D., 1968, ART COMPUTER PROGRAM, V<IT>1</IT>; Knuth D. E., 1973, ART COMPUTER PROGRAM, V3; KOHONEN T, 1980, 5 INT C PATT REC MIA, P158; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LEA WA, 1975, IEEE T ACOUST SPEECH, VAS23, P30; LESSER VR, 1975, IEEE T ACOUST SPEECH, VAS23, P11, DOI 10.1109/TASSP.1975.1162648; Levinson S. E., 1977, BELL SYST TECH J, V57, P1627; LEVINSON SE, 1983, AT&T TECH J, V62, P1035; LEVINSON SE, 1975, 4TH P INF C ART INT, P499; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LIPORACE LA, 1982, IEEE T INFORM THEORY, V28, P729, DOI 10.1109/TIT.1982.1056544; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; LOWERRE BT, 1976, THESIS CARNEGIEMELLO; MacQueen J. B., 1967, 5TH P BERK S MATH ST, V1, P281; Marcus M., 1980, THEORY SYNTACTIC REC; Markel J.D., 1976, LINEAR PREDICTION SP; Markov A. A., 1913, P ACAD SCI ST PETERS, V7, P153; MERCIER G, 1979, SPOKEN LANGUAGE GENE, P525; MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P351, DOI 10.1109/TASSP.1981.1163586; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P284, DOI 10.1109/TASSP.1981.1163527; MYERS CS, 1982, IEEE T ACOUST SPEECH, V30, P561, DOI 10.1109/TASSP.1982.1163932; NADAS A, 1984, IEEE T ACOUST SPEECH, V32, P859, DOI 10.1109/TASSP.1984.1164378; NAKANO M, 1978, CHEM PHARM BULL, V26, P1505; Newell A., 1973, SPEECH UNDERSTANDING; NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320; Nilsson N.J., 1971, PROBLEM SOLVING METH; OSHIKA BT, 1975, IEEE T ACOUST SPEECH, VAS23, P104, DOI 10.1109/TASSP.1975.1162639; Oshika B. T., 1976, P IEEE INT C AC SPEE, P577; Pant G., 1973, SPEECH SOUNDS FEATUR; PASSMAN DS, 1973, PAC J MATH, V44, P281; Patrick E. A., 1972, FUNDAMENTALS PATTERN; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Perennou G., 1982, Automatic Speech Analysis and Recognition. Proceedings of the NATO Advanced Study Institute; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Poritz A. B., 1980, P S APPL HIDD MARK M, P88; Poritz A. B., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; Potter R. K., 1968, VISIBLE SPEECH; RABINER LR, 1984, AT&T TECH J, V63, P627; RABINER LR, 1981, IEEE T COMMUN, V29, P621, DOI 10.1109/TCOM.1981.1095031; RABINER LR, 1983, AT&T TECH J, V62, P1075; RABINER LR, 1984, AT&T TECH J, V63, P721; RABINER LR, 1982, AT&T TECH J, V61, P981; REDDY DR, 1967, J ACOUST SOC AM, V42, P329, DOI 10.1121/1.1910582; ROSENBERG AE, 1976, J ACOUST SOC AM, V60, pS12, DOI 10.1121/1.2003178; ROSENBERG AE, 1983, IEEE T ACOUST SPEECH, V31, P713, DOI 10.1109/TASSP.1983.1164132; Ruske G., 1982, Automatic Speech Analysis and Recognition. Proceedings of the NATO Advanced Study Institute; Russell M. J., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing; SAKOE H, 1979, IEEE T ACOUST SPEECH, V27, P588, DOI 10.1109/TASSP.1979.1163310; SAKOE H, 1971, 7TH P INT C AC BUD, V3, P65; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SCAGLIOLA C, 1983, SPEECH COMMUN, V2, P199, DOI 10.1016/0167-6393(83)90028-6; SHIKANO K, 1978, REV ECL, V26, P1486; Shikano K., 1978, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE61; Shipman D. W., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; Silverman H. F., 1974, IEEE T ACOUST SPEECH, VASSP-23, P369; Sondhi M. M., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing; STEBE PF, 1972, PAC J MATH, V43, P765; STEVENS KN, 1980, J ACOUST SOC AM, V68, P836, DOI 10.1121/1.384823; TANAKA E, 1978, IEEE T COMPUT, V27, P605; TAPPERT CC, 1977, INT J MAN MACH STUD, V9, P363, DOI 10.1016/S0020-7373(77)80032-1; Turing A. M., 1936, P LOND MATH SOC, V42, P230; Turing Alan, 1936, P LOND MATH SOC, V43, P544; Velichko V. M., 1969, INT J MAN MACH STUD, V2, P223; Vintsyuk T. K., 1968, KIBERNETIKA, V81; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; WALKER DE, 1975, IEEE T ACOUST SPEECH, V23, P397, DOI 10.1109/TASSP.1975.1162726; Weinstock R., 1974, CALCULUS VARIATIONS; WOODS WA, 1975, IEEE T ACOUST SPEECH, VAS23, P2, DOI 10.1109/TASSP.1975.1162647; Woods W. A., 1975, SPEECH RECOGNITION; WOODS WA, 1982, ARTIF INTELL, V18, P295, DOI 10.1016/0004-3702(82)90025-X; WOODS WA, 1974, 2976 BOLT BER NEWM I; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773; YOUNGER DM, 1967, INFORM CONTR, V10; ZUE VW, 1983, SPEECH COMMUN, V2, P181, DOI 10.1016/0167-6393(83)90023-7	147	55	56	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9219		P IEEE	Proc. IEEE		1985	73	11					1625	1650		10.1109/PROC.1985.13344		26	Engineering, Electrical & Electronic	Engineering	AUG24	WOS:A1985AUG2400007	
J	ALLEY, WM				ALLEY, WM			THE PALMER DROUGHT SEVERITY INDEX AS A MEASURE OF HYDROLOGIC DROUGHT	WATER RESOURCES BULLETIN			English	Article										ALLEY, WM (reprint author), US GEOL SURVEY,SYST ANAL GRP,WRD,410 NATL CTR,RESTON,VA 22092, USA.						ALLEY WM, 1984, J CLIM APPL METEOROL, V23, P1100, DOI 10.1175/1520-0450(1984)023<1100:TPDSIL>2.0.CO;2; BARKSDALE HC, 1966, US GEOL SURVEY HYDRO; BOWLES DS, 1980, UWRLP8008 UT WAT RES; Conover W, 1980, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIAZ HF, 1983, J CLIM APPL METEOROL, V22, P3, DOI 10.1175/1520-0450(1983)022<0003:DITUS>2.0.CO;2; DRACUP JA, 1980, WATER RESOUR RES, V16, P297, DOI 10.1029/WR016i002p00297; DRAPER SH, 1981, 72 U WASH CW HARR HY; Feller W., 1957, INTRO PROBABILITY TH, V1; FIELDHOUSE DJ, 1965, U DELAWARE AGR EXP S, V353; GIBBS W.J., 1967, B BUREAU METEOROLOGY, V48; HAVENS AV, 1968, DROUGHT FREQUENCY IN; KARL TR, 1982, J CLIMATOL, V2, P313; KARL TR, 1983, J CLIM APPL METEOROL, V22, P1356, DOI 10.1175/1520-0450(1983)022<1356:SSCODD>2.0.CO;2; KARL TR, 1981, MON WEATHER REV, V109, P2055, DOI 10.1175/1520-0493(1981)109<2055:TSHWAD>2.0.CO;2; KLUGMAN MR, 1978, J APPL METEOROL, V17, P1425, DOI 10.1175/1520-0450(1978)017<1425:DITUM>2.0.CO;2; LANGBEIN WB, 1982, 82751 US GEOL SURV O; LAWSON MP, 1971, 1 U NEBR DEP GEOGR O; Mood AM, 1940, ANN MATH STAT, V11, P367, DOI 10.1214/aoms/1177731825; Palmer WC, 1965, 45 US WEATH BUR RES; PALMER WC, 1967, P C DROUGHT NE US; RAO AR, 1984, J HYDROL, V68, P211, DOI 10.1016/0022-1694(84)90212-9; Shafer BA, 1982, W SNOW C REN NV COL, P164; TASE N, 1976, 87 COL STAT U HYDR P; YEVJEVICH VM, 1967, 23 COL STAT U HYDR P; ZAPOROZEC A, 1980, GEOSCIENCE WISCONSIN, V5; 1981, CLIMATE ANAL CTR USE	27	34	38	AMER WATER RESOURCES ASSOC	HERNDON	950 HERNDON PARKWAY SUITE 300, HERNDON, VA 20170-5531	0043-1370		WATER RESOUR BULL	Water Resour. Bull.		1985	21	1					105	114				10	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	AEP34	WOS:A1985AEP3400014	
J	BAUM, BR; BAILEY, LG				BAUM, BR; BAILEY, LG			RELATIONSHIPS BETWEEN HORDEUM-BULBOSUM L SUBSP BULBOSUM AND HORDEUM-BULBOSUM SUBSP NODOSUM COMB ET STAT-NOV	CANADIAN JOURNAL OF BOTANY-REVUE CANADIENNE DE BOTANIQUE			English	Article										BAUM, BR (reprint author), AGR CANADA,BIOSYSTEMAT RES INST,RES BRANCH,CENTR EXPTL FARM,OTTAWA K1A 0C6,ONTARIO,CANADA.						ASHTON EH, 1957, PROC R SOC SER B-BIO, V146, P552, DOI 10.1098/rspb.1957.0030; BAUM BR, 1984, BARLEY GENE POOL; BOISSIER E, 1884, FLORA ORIENTALIS, V5; CAUDERON Y, 1956, ANN AMELIOR PL, V3, P307; COOLEY NW, 1971, MULTIVARIATE DATA AN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis PH, 1963, PRINCIPLES ANGIOSPER; de Lamarck J.B.P.A.M, 1791, TABLEAU ENCY METHODI; DELAMARCK JBA, 1798, ENCY METHODIQUE; DESFONTAINES R., 1798, FLORA ATLANTICA, V2; FORSSKAL P, 1875, FLORA AEGYPTIACA ARA, pR15; GNANADESIKAN R, 1977, METHODS STATISTICAL; GUEDES M, 1976, BOT J LINN SOC, V73, P317, DOI 10.1111/j.1095-8339.1976.tb01812.x; Holmgren P. K., 1974, INDEX HERBARIORUM 1; JORGENSEN R B, 1982, Nordic Journal of Botany, V2, P421, DOI 10.1111/j.1756-1051.1982.tb01205.x; KATZNELS.J, 1967, ISRAEL J BOT, V16, P57; KLECKA WR, 1980, 07019 SAG U PAP SER; Lewis WH, 1980, POLYPLOIDY BIOL RELE; LINNAEUS C, 1756, CENTURIA, V2; Linnaeus C., 1762, SPECIES PLANTARUM; Mayr E, 1953, METHODS PRINCIPLES S; MORRISON J. W., 1959, CANADIAN JOUR BOT, V37, P527; MORRISON JW, 1960, CHROMOSOMA, V11, P297, DOI 10.1007/BF00328656; Pimentel RA, 1979, MORPHOMETRICS MULTIV; POST GE, 1893, B HERBIER BOISSIER, V1, P393; Rao CR, 1973, LINEAR STATISTICAL I; SCHULTES JA, 1827, MANTISSA VOLUMEN TER, V3; SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.2307/2333709; STEARN WT, 1973, SYNOPSIS METHODICA S; Stearn WT, 1957, SPECIES PLANTARUM; STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009; Tukey J. W, 1977, EXPLORATORY DATA ANA; 1982, SAS USERS GUIDE BASI; 1983, SPSSX USERS GUIDE	34	6	6	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA ON K1A 0R6, CANADA	0008-4026		CAN J BOT	Can. J. Bot.-Rev. Can. Bot.		1985	63	4					735	743				9	Plant Sciences	Plant Sciences	AHA54	WOS:A1985AHA5400010	
J	GUDZINOWICZ, BJ; DRISCOLL, JL; MARTIN, HF; YOUNKIN, B				GUDZINOWICZ, BJ; DRISCOLL, JL; MARTIN, HF; YOUNKIN, B			INSTRUMENT OPTIMIZATION AND RELIABILITY	ANALYTICAL INSTRUMENTATION			English	Article									RHODE ISL HOSP,DEPT PATHOL,CLIN CHEM SECT,PROVIDENCE,RI 02902	GUDZINOWICZ, BJ (reprint author), RHODE ISL HOSP,DEPT PATHOL,BIOCHEM SECT,DEV GRP,PROVIDENCE,RI 02902, USA.						BERTIN EP, 1975, PRINCIPLES XRAY SPEC, P3; Beveridge G. S., 1970, OPTIMIZATION THEORY; BLACK WW, 1969, NUCL INSTRUM METHODS, V71, P317, DOI 10.1016/0029-554X(69)90321-8; CHEN C, 1973, STATISTICAL PATTERN; CHINLOY T, 1953, J AGR SCI, V43, P1; Cochran W. G., 1957, EXPT DESIGNS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARVAS F, 1974, J MED CHEM, V17, P799, DOI 10.1021/jm00254a004; DAVIS OL, 1963, DESIGN ANAL IND EXPT; Davis R. H., 1972, Mathematical Biosciences, V13, DOI 10.1016/0025-5564(72)90049-1; DEAN WK, 1975, SCIENCE, V189, P805, DOI 10.1126/science.189.4205.805; DEMING SN, 1976, AM LABORATORY    OCT, P13; DEMING SN, 1973, ANAL CHEM, V45, pA278; DENTON MB, 1975, MAR PITTSB C AN CHEM; DRISCOLL JL, 1979, UNPUB CLIN CHEM SECT; DRISCOLL JL, 1981, CHEM BIOMED ENV INST, V11, P127; DRIVER RM, 1970, CHEM BRIT, V6, P154; ERNST RR, 1968, REV SCI INSTRUM, V39, P998, DOI 10.1063/1.1683586; FORST AJ, 1978, THESIS MEDICAL U S C; GOLDSTEIN JI, 1975, PRACTICAL SCANNING E, pCH12; GUDZINOWICZ BJ, 1980, CHEM BIOMED ENV INST, V10, P1; GUDZINOWICZ BJ, 1981, CHEM BIOMED ENV INST, V11, P107; GUDZINOWICZ BJ, 1979, CHEM BIOMED ENV INST, V9, P315; HUANG TC, 1961, ANAL CHEM, V33, P1405, DOI 10.1021/ac60178a040; INOUYE T, 1972, NUCL INSTR METHODS, V104, P542; JOHNSON EA, 1967, NBS US PHOTOELEC SPE, V17, P505; JUSTICE JB, 1974, ANAL CHEM, V46, P223, DOI 10.1021/ac60338a010; JUSTICE JB, UNPUB; Kaiser R. E., 1960, GAS CHROMATOGRAPHIE, P33; KING PG, 1974, ANAL CHEM, V46, P1476, DOI 10.1021/ac60347a009; KING PG, 1974, THESIS EMORY U ATLAN; KRAUSE RD, 1974, CLIN CHEM, V20, P775; LAM CF, 1979, APPL SPECTROSC, V33, P273, DOI 10.1366/0003702794925868; LAM TF, 1976, ANAL CHEM, V48, P1768, DOI 10.1021/ac50006a036; LONG DE, 1969, ANAL CHIM ACTA, V46, P193, DOI 10.1016/S0003-2670(01)95619-3; LOTT JA, 1975, CLIN CHEM, V21, P1754; MARISCOT.MA, 1967, NUCL INSTRUM METHODS, V50, P309, DOI 10.1016/0029-554X(67)90058-4; MIELING GE, 1976, ANAL CHEM, V48, P1686, DOI 10.1021/ac50006a015; MORGAN SA, UNPUB; MORGAN SL, 1975, J CHROMATOGR, V112, P267; MORGAN SL, 1974, ANAL CHEM, V46, P1170, DOI 10.1021/ac60345a035; NELDER JA, 1965, COMPUT J, V7, P308; NEUSS JD, 1934, J AM CHEM SOC, V56, P2242; PARKER LR, 1975, APPL SPECTROSC, V29, P429, DOI 10.1366/000370275774455743; PENNOCK CA, 1973, CLIN CHIM ACTA, V48, P193, DOI 10.1016/0009-8981(73)90365-3; Polovko A.M., 1968, FUNDAMENTALS RELIABI; RITTER GL, 1975, ANAL CHEM, V47, P1951, DOI 10.1021/ac60362a005; ROBERTSON A, 1972, NUCL INSTR METHODS, V100, P31; ROBINSON R, 1971, CLIN CHEM AUTOMATION; ROTTER H, 1975, ORG MASS SPECTROM, V10, P874, DOI 10.1002/oms.1210101011; RUSS JC, 1976, EDAX ED, V6, P3; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; SCHAMBER F, 1973, 8TH P NAT C EL PROB, P85; SCHAMBER FH, 1976, MODIFICATION LINEAR; SHARP P, 1972, CLIN CHIM ACTA, V40, P115, DOI 10.1016/0009-8981(72)90257-4; SONOWANE M, 1976, CLIN CHEM, V22, P1100; SPENDLEY W, 1962, TECHNOMETRICS, V4, P441, DOI 10.2307/1266283; SZASZ G, 1974, Z CLIN CHEM KLIN BIO, V12, P1256; TONG JYP, 1953, J AM CHEM SOC, V75, P6180, DOI 10.1021/ja01120a022; Trinder P., 1969, ANNALS CLINICAL BIOC, V6, P24; VICKERS TJ, 1975, MAR PITTSB C AN CHEM; Vosburgh W. C., 1941, J AM CHEM SOC, V63, P437, DOI DOI 10.1021/JA01847A025; WILSON AL, 1970, TALANTA, V17, P21, DOI 10.1016/0039-9140(70)80046-7; N2B TECHN INSTR CORP	64	0	0	MARCEL DEKKER INC	NEW YORK	270 MADISON AVE, NEW YORK, NY 10016	0743-5797		ANAL INSTRUM			1984	13	1					1	54				54	Chemistry, Analytical; Instruments & Instrumentation	Chemistry; Instruments & Instrumentation	TB351	WOS:A1984TB35100001	
J	LI, KC				LI, KC			CONSISTENCY FOR CROSS-VALIDATED NEAREST NEIGHBOR ESTIMATES IN NONPARAMETRIC REGRESSION	ANNALS OF STATISTICS			English	Article										LI, KC (reprint author), PURDUE UNIV,DEPT STAT,W LAFAYETTE,IN 47907, USA.						AGARWAL GG, 1980, ANN STAT, V8, P1307, DOI 10.1214/aos/1176345203; ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; CHOW YS, 1983, ANN STAT, V11, P25, DOI 10.1214/aos/1176346053; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAVEN P, 1979, NUMER MATH, V31, P377; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; FIX E, 1951, 4 RAND FIELD REP; GEISSER S, 1975, J AM STAT ASSOC, V70, P320, DOI 10.2307/2285815; HALL P, 1982, BIOMETRIKA, V69, P383, DOI 10.1093/biomet/69.2.383; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; SPECKMAN P, 1982, EFFICIENT NONPARAMET; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; STONE M, 1974, J R STAT SOC B, V36, P111; WAHBA G, 1975, COMMUN STAT, V4, P1; Watson G.S., 1964, SANKHYA A, V26, P359; WONG WH, 1983, ANN STATIST, V11, P1257	18	20	23	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 6 3401 INVESTMENT BLVD, HAYWARD, CA 94545	0090-5364		ANN STAT	Ann. Stat.		1984	12	1					230	240		10.1214/aos/1176346403		11	Statistics & Probability	Mathematics	SH350	WOS:A1984SH35000014	
J	BAUM, BR; BAILEY, LG				BAUM, BR; BAILEY, LG			TAXONOMIC STUDIES IN WALL BARLEY (HORDEUM-MURINUM-SENSU-LATO) AND SEA BARLEY (HORDEUM-MARINUM-SENSU-LATO) .2. MULTIVARIATE MORPHOMETRICS	CANADIAN JOURNAL OF BOTANY-REVUE CANADIENNE DE BOTANIQUE			English	Article										BAUM, BR (reprint author), AGR CANADA,INST BIOSYST RES,CENT EXPTL FARM,OTTAWA K1A 0C6,ONTARIO,CANADA.						ASHTON EH, 1957, PROC R SOC SER B-BIO, V146, P552, DOI 10.1098/rspb.1957.0030; BAUM BR, 1984, CAN J BOT, V62, P753; BOOTH TA, 1976, BOT J LINN SOC, V72, P149, DOI 10.1111/j.1095-8339.1976.tb01356.x; BOOTH TA, 1978, BOT J LINN SOC, V76, P115, DOI 10.1111/j.1095-8339.1978.tb01501.x; BOR NL, 1968, FLORA IRAQ, V9, P244; Bor NL, 1960, GRASSES BURMA CEYLON; BOWDEN WRAY M., 1962, CANADIAN JOUR BOT, V40, P1675; COOLEY NW, 1971, MULTIVARIATE DATA AN; COVAS GUILLERMO, 1949, MADRONO, V10, P1; COVAS G, 1970, FLORA PROVINCIA BUEN, V2, P175; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FROST S, 1979, HEREDITAS, V90, P251; GILBERT ES, 1968, J AM STAT ASSOC, V63, P1399, DOI 10.2307/2285893; GNANADESIKAN R, 1977, METHODS STATISTICAL; KLECKA WR, 1980, 07019 SAG U PAP SER; PANKHURST RJ, 1970, COMPUT J, V12, P145; Pimentel RA, 1979, MORPHOMETRICS MULTIV; RAO CR, 1952, ADV STATISTICAL METH; Rao CR, 1973, LINEAR STATISTICAL I; RICHARDS AJ, 1976, CURRENT CHROMOSOME R, P167; Tutin T. G., 1980, FLORA EUROPAEA, V5; Tzvelev N. N., 1973, NOV SIST VYSSH RAST, V10, P19; Tzvelev N.N., 1976, POACEAE URSS; Urbakh V. Yu., 1972, Journal of Multivariate Analysis, V2, DOI 10.1016/0047-259X(72)90016-4; 1975, STATISTICAL PACKAGE; 1982, SAS USERS GUIDE BASI; 1981, STATISTICAL PACKAGE	27	26	26	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA ON K1A 0R6, CANADA	0008-4026		CAN J BOT	Can. J. Bot.-Rev. Can. Bot.		1984	62	12					2754	2764				11	Plant Sciences	Plant Sciences	ACA68	WOS:A1984ACA6800032	
J	CARANDENTE, F; HALBERG, F				CARANDENTE, F; HALBERG, F			CHRONOBIOLOGY OF BLOOD-PRESSURE IN 1985	CHRONOBIOLOGIA			English	Review									UNIV MINNESOTA,DEPT LAB MED & PATHOL,CHRONOBIOL LABS,MINNEAPOLIS,MN 55455	CARANDENTE, F (reprint author), UNIV MILAN,IST ANAT UMANA NORMALE,CTR UNIV STUDI CRONOMORFOL & TECN RITMOMETRICHE,I-20122 MILAN,ITALY.						Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; Aizerman M.A., 1964, Avtomatika i Telemekhanika, V25; AIZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P1175; ALBONI P, 1982, CHRONOBIOLOGIA, V9, P173; ANDERSON TW, 1978, INT ENCY STATISTICS, P628; Andrews H.C., 1972, INTRO MATH TECHNIQUE; ARBOGAST B, 1983, CHRONOBIOLOGIA, V10, P59; ASBOTH F, 1977, CHRONOBIOLOGIA, V4, P97; ASISHI T, 1979, ARTIF ORGANS, V3, P237; ASLANIAN NL, 1978, CHRONOBIOLOGIA, V5, P251; ATHANASS.D, 1969, CLIN SCI, V36, P147; BABU CC, 1969, P IEEE, V57, P2086, DOI 10.1109/PROC.1969.7482; BACHMANN K, 1981, BIOTELEM PAT MON, V8, P15; BACHMANN K, 1981, BIOTELEM PAT MON, V8, P47; BALASUBRAMANIAN V, 1979, BRIT J CLIN PHARM S, V2, P1198; Ball G. H., 1965, ISODATA NOVEL METHOD; BALLAMY GR, 1982, AUST NZ J MED, V12, P467; Bartter FC, 1974, CHRONOBIOLOGY, P6; BARTTER FC, 1976, CHRONOBIOLOGIA, V3, P199; BENTLEY JL, 1978, IEEE T COMPUT, V27, P97; BERGLUND GB, 1980, ACTA MED SCAND, V204, P241; BEVAN AT, 1969, CLIN SCI, V36, P329; BINGHAM C, 1983, CHRONOBIOLOGIA, V10, P111; BINGHAM C, 1982, CHRONOBIOLOGIA, V9, P397; BOCK HH, SANKHYA; BOUGAS J, 1964, ALDOSTERONE, P25; BOUGAS J, 1964, CIOMS S ALDOSTERONE; Brush CE, 1901, AM J PHYSIOL, V5, P199; BUCH CW, 1973, J CHRON DIS, V26, P101; CARANDENTE F, 1980, RICERCA CLIN LAB S1, V10, P1; CARANDENTE F, 1982, CHRONOBIOLOGIA, V9, P153; CARANDENTE F, 1983, CHRONOBIOLOGIA, V10, P392; CARANDENTE F, 1982, I QUADERNI IL PONTE, V7, P79; CARANDENTE F, 1982, 1982 ATT S ASP MED S, P57; CARANDENTE F, 1982, FED MED ROMA, V36, P551; CARROLL JD, 1978, INT ENCY STATISTICS, P892; CLEMENT DL, 1979, BLOOD PRESSURE VARIA, P31; COLOMBO C, 1899, G ACCAD MED TORINO, V62, P23; CORNELISSEN G, 1983, CHRONOBIOLOGIA, V10, P117; CORNELISSEN G, 1980, RES CLIN LAB, V10, P333; CORNELISSEN G, 1983, MINN ACAD SCI, V51, P9; CORNELISSENGUIL.G, 1982, BIOMEDICAL THERMOLOG, P167; COVER TM, 1969, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAIG MWM, 1979, BRIT MED J, V1, P237; CUGINI P, 1980, 30 P C NAZ ASS IT PA, P95; CUGINI P, 1981, MATURITAS, V3, P173, DOI 10.1016/0378-5122(81)90009-8; CUGINI P, 1982, MATURITAS, V4, P139, DOI 10.1016/0378-5122(82)90040-8; CUGINI P, 1982, J GERONTOL, V37, P403; CUGINI P, 1981, G ITAL CHIM CLIN, V6, P227; CUGINI P, 1983, CHRONOBIOLOGIA, V10, P118; CUGINI P, 1981, HORM RES, V15, P7, DOI 10.1159/000179430; CUGINI P, 1982, CHRONOBIOLOGIA, V9, P229; CUNEO RA, 1977, MED CLIN N AM, V6, P565; DAVIS JO, 1963, J CLIN INVEST, V42, P597, DOI 10.1172/JCI104750; DELAPENA SS, 1982, CLIN CHEM NEWSL, V2, P129; DELAPENA SS, 1983, BRAIN RES BULL, V10, P559, DOI 10.1016/0361-9230(83)90155-7; DELAPENA SS, 1983, BRAIN RES BULL, V11, P117, DOI 10.1016/0361-9230(83)90060-6; DELEA CS, 1979, NEPHRON, V23, P91, DOI 10.1159/000181615; DELEA C, 1977, CHRONOBIOLOGIA, V4, P172; DEREMIGIS P, 1982, NOTIZIARIO SIBIOC, V6, P249; DESCOMBES BJ, 1983, SCHWEIZ MED WSCHR, V113, P371; Diehl HS, 1929, ARCH INTERN MED, V43, P835; DOE RP, 1966, THESIS; DOMINGUEZ RCH, 1981, 15 P C INT SOC CHRON; DOMINGUEZ RCH, 1983, MINN ACAD SCI, V51, P10; DOMINGUEZ RCH, 1984, 1982 SIRMCE C VIENN, P74; DOMINGUEZ RCH, 1981, SIRMCE C MADRID, P181; DOMINGUEZ RCH, 1981, METODOS ANALISIS MUL; DOMINGUEZ R C H, 1982, Revista Espanola de Oncologia, V29, P199; DOMINGUEZ RH, 1982, CHRONOBIOLOGIA, V9, P341; DOMINGUEZ RH, 1982, NOTIZIARIO SIBIOC CL, V2, P191; DRAYER JIM, 1983, ARCH INTERN MED, V143, P90, DOI 10.1001/archinte.143.1.90; DRAYER JIM, RATIONAL DRUG THERAP; DRAYER JIM, 1983, ARCH INTERN MED, V143, P888; DRAYER JIM, 1982, AM J MED, V73, P493, DOI 10.1016/0002-9343(82)90327-8; DUDA RO, 1966, IEEE TRANS ELECTRON, VEC15, P220, DOI 10.1109/PGEC.1966.264302; EFRON B, 1981, BIOMETRIKA, V68, P589, DOI 10.1093/biomet/68.3.589; Efron B, 1981, CANADIAN J STATISTIC, V9, P139, DOI 10.2307/3314608; EFRON B, 1982, 75 STANF U DIV STAT, P43; ELIOT RS, 1983, HOSP PRACT, V18, P189; ENGEL R, 1979, International Journal of Chronobiology, V6, P163; ERNSBERGER P, 1979, CHRONOBIOLOGIA, V6, P338; FITZGERALD DJ, 1982, BRIT HEART J, V48, P572; FIX E, 1951, USAF4 SCH AV MED REP; FIXLER DE, 1979, PEDIATRICS, V63, P32; FLORAS JS, 1981, LANCET, V2, P107; FLORAS JS, 1982, BRIT MED J, V285, P1387; FLORAS JS, 1981, J CARDIOVASC PHARM, V3, P958, DOI 10.1097/00005344-198109000-00005; FOUAD FM, 1978, AM HEART J, V96, P646, DOI 10.1016/0002-8703(78)90202-8; Freude J, 1983, ZFA (Stuttgart), V59, P479; FU KS, 1970, MATH SCI ENG, V52; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GARRETT BN, 1981, J CLIN PHARMACOL, V21, P173; Gauss K. F., 1809, THEORIA MOTUS CORPOR; GHISTA DN, 1978, MED BIOL ENG COMPUT, V16, P715, DOI 10.1007/BF02442452; Gnanadesikan R., 1977, B INT STAT I, V47, P451; GOLDBERG AD, 1976, POSTGRAD MED J, V52, P128; GOLDBERG AD, 1976, POSTGRAD MED J, V52, P104; GOLDBERG AD, 1978, BRIT HEART J, V40, P656; GOLDRING D, 1977, J PEDIATR, V91, P884, DOI 10.1016/S0022-3476(77)80882-2; GOLDRING D, 1978, J PEDIATR, V93, P156, DOI 10.1016/S0022-3476(78)80641-6; GORDON RD, 1967, J CLIN INVEST, V46, P599, DOI 10.1172/JCI105561; GOULD BA, 1982, J CARDIOVASC PHAR S3, V4, P8369; GOULD BA, 1982, BRIT J CLIN PHARMACO, V14, P827; Gould B A, 1982, Clin Exp Pharmacol Physiol Suppl, V6, P113; GOULD BA, 1982, CIRCULATION, V65, P22; GULLNER HG, 1979, CHRONOBIOLOGIA, V6, P105; GULLNER HG, 1979, LANCET, V2, P527; HALBERG E, 1979, CHRONOBIOLOGIA, V6, P231; HALBERG E, 1981, CHRONOBIOLOGIA, V8, P253; HALBERG E, 1980, CHRONOBIOLOGIA, V7, P95; HALBERG E, 1980, PHYSIOLOGIST, V23, P772; HALBERG E, 1978, CHRONOBIOLOGIA, V5, P241; HALBERG E, 1981, CHRONOBIOLOGIA, V8, P185; HALBERG E, 1980, MENSTRUAL CYCLE SYNT, P99; HALBERG E, 1976, CHRONOBIOLOGIA, V3, P72; HALBERG E, 1981, CHRONOBIOLOGIA, V8, P145; HALBERG E, 1981, J GERONTOL, V36, P31; HALBERG E, 1981, CHRONOBIOLOGIA, V8, P351; HALBERG E, 1978, CHRONOBIOLOGIA, V5, P447; HALBERG E, 1983, CHRONOBIOLOGIA, V10, P129; Halberg F, 1981, NEOPLASMS COMP PATHO, P553; HALBERG F, 1965, ACTA ENDOCRINOL-COP, VS 50, P5; HALBERG F, 1981, HYPERTENSION CHILDRE, P45; HALBERG F, 1965, CIRCADIAN CLOCKS, P13; HALBERG F, 1982, BRAIN PEPTIDES HORMO, P241; Halberg F, 1967, CELLULAR ASPECTS BIO, P20; Halberg F, 1973, Fortschr Med, V91, P131; HALBERG F, 1983, AM J ANAT, V168, P543, DOI 10.1002/aja.1001680408; HALBERG F, 1982, CELLULAR PACEMAKERS, P146; HALBERG F, 1966, CIRCULATION, V34, P715; HALBERG F, 1962, MANS DEPENDENCE EART, P48; HALBERG F, 1978, CHRONOBIOLOGIA, V5, P96; HALBERG F, 1984, 1ST P INT MONTR C; HALBERG F, 1973, INT J CHRONOBIOL, V2, P87; HALBERG F, 1980, CHRONOBIOLOGY PRINCI, P541; HALBERG F, 1978, EXPERIENTIA, V34, P713, DOI 10.1007/BF01947276; HALBERG F, 1983, SEMEIOTICA MED LINEA, V2, P2351; HALBERG F, 1978, 14TH P C INT MED ROM; HALBERG F, 1983, International Journal of Chronobiology, V8, P225; HALBERG F, 1983, B MOL BIOL MED, V8, P75; HALBERG F, 1970, SYSTEMS APPROACH APP, P31; HALBERG F, 1977, CHRONOBIOLOGIA S1, V4, P189; HALBERG F, 1976, RICER CLIN LAB, V6, P1; HALBERG F, 1974, CHRONOBIOLOGY, P372; HALBERG F, 1984, AMBULATORY BLOOD PRE, P137; Halberg F, 1972, PHYSIOL TEACH, V1, P1; HALBERG F, 1969, ANNU REV PHYSIOL, V31, P675, DOI 10.1146/annurev.ph.31.030169.003331; HALBERG F, 1980, CHRONOBIOLOGY PRINCI, pR5; HALBERG F, 1979, RADIOIMMUNOASSAY DRU, P107; HALBERG F, 1983, ADV IMMUNOPHARMACOL, P463; HALBERG F, 1981, HORMONES DEV AGING, P451; HALBERG J, 1980, CHRONOBIOLOGIA, V7, P382; HALBERG J, 1977, FED P, V36, P348; HALBERG J, 1983, CHRONOBIOLOGIA, V10, P131; HALBERG J, 1981, J GERONTOL, V36, P28; HALBERG J, 1978, 8 P INT S PROPH APPR, P51; HALBERG J, 1980, International Journal of Chronobiology, V7, P17; HALBERG JU, 1982, THESIS U MINNESOTA; HANSON BR, CARDIOLOGIA; HARSHFIELD G, 1979, AMBULATORY ELECTROCA, V4, P7; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HART PE, 1966, 18282SEL60016 STANF; HASSEN A, 1977, 12TH P INT C INT SOC, P343; HAUFF A, 1981, BIOTELEM PAT MON, V8, P106; HAUS E, 1980, CHRONOBIOLOGY PRINCI, P47; HEYDEN S, 1969, J AMER MED ASSOC, V209, P1683, DOI 10.1001/jama.209.11.1683; Hill L, 1898, LANCET, P282; HINMAN AT, 1962, AM HEART J, V63, P663, DOI 10.1016/0002-8703(62)90011-X; HIRAYAMA T, 1977, COMP EPIDEMIOLOGY CA; HIRAYAMA T, 1978, COMP EPIDEMIOLOGY CA; HORAN MJ, 1981, ANN INTERN MED, V94, P466; HORAN MJ, 1981, AM HEART J, V101, P843, DOI 10.1016/0002-8703(81)90623-2; HORNUNG RS, 1982, BRIT J CLIN PHARM, V14, P283; HORNUNG RS, 1982, BRIT J CLIN PHARMACO, V14, P415; HORNUNG RS, 1983, FORTSCHR MED, V101, P438; Howell W H, 1897, J Exp Med, V2, P313, DOI 10.1084/jem.2.3.313; HOWLETT PH, 1979, J MED ENG TECHNOL, V3, P192; IRVING JB, 1976, POSTGRAD MED J, V52, P137; JACOBSON M, 1980, NEW ENGL J MED, V303, P817; Janeway TO, 1904, CLIN STUDY BLOOD PRE; JORES A, 1935, MED KLIN, V31, P1139; JULIUS S, 1978, PEDIATR CLIN N AM, V25, P35; JULIUS S, 1974, JAMA-J AM MED ASSOC, V229, P663, DOI 10.1001/jama.229.6.663; KAIN HK, 1964, CIRCULATION, V30, P882; KANABROCKI EL, 1983, AM J ANAT, V166, P121, DOI 10.1002/aja.1001660202; KANNEL WB, 1971, AM J CARDIOL, V27, P335, DOI 10.1016/0002-9149(71)90428-0; KATZ FH, 1975, J CLIN ENDOCR METAB, V40, P125; KAWASAKI T, 1980, AM J MED, V68, P91, DOI 10.1016/0002-9343(80)90177-1; KAWASAKI T, 1978, CHRONOBIOLOGIA, V5, P399; KAWASAKI T, 1977, CHRONOBIOLOGIA, V4, P122; KENNEDY HL, 1979, AMBULATORY ELECTROCA, V4, P13; KILCOYNE MM, 1974, CIRCULATION, V50, P758; KINCANNO.JC, 1968, J CONSULT CLIN PSYCH, V32, P319, DOI 10.1037/h0025891; KNAPP MS, 1979, BRIT MED J, V1, P490; KNIGHT JL, 1979, ANN BIOMED ENG, V7, P369, DOI 10.1007/BF02364123; KOGA Y, 1982, JPN HEART J, V23, P661; KOLATA G, 1983, SCIENCE, V220, P591, DOI 10.1126/science.6836302; Kolata G, 1983, Science, V219, P832, DOI 10.1126/science.219.4586.832-a; KRONIG B, 1974, BIOTELEMETRY, V1, P117; KRUSKAL JB, 1978, INT ENCY STAT, P307; KUZEL M, 1981, CHRONOPHARMACOLOGY C, P145; LABARTHE DR, 1977, HYPERTENSION MANUAL, P585; LAKATUA D, 1981, CHRONOBIOLOGIA, V8, P183; LANDWEHR JM, 1972, THESIS U CHICAGO; LARAGH JOHN H., 1966, CIRCULATION RES, V18, P158; LASALLE D, 1983, CHRONOBIOLOGIA, V10, P138; LAUER RM, 1975, J PEDIATR, V86, P697, DOI 10.1016/S0022-3476(75)80353-2; LEACH C, 1983, CHRONOBIOLOGIA, V10, P138; LEE JK, 1982, CHRONOBIOLOGIA, V9, P347; LEE JY, 1982, CHRONOPHARMACOLOGY, P375; LEE JY, 1981, INT J CHRONOBIOL, V7, P276; LEVINE H, 1974, CHRONOBIOLOGY, P406; LEVINE H, 1977, CHRONOBIOLOGIA, V4, P129; LEVINE H, 1972, CIRCADIAN RHYTHMS CI; LEVINE H, 1973, International Journal of Chronobiology, V1, P337; LEVINE H, 1977, 12 P INT C INT SOC C, P139; LEVINE H, 1978, INT J CHRONOBIOL, V5, P423; LEVINE LS, 1976, NEW YORK STATE J MED, V76, P40; Lieberman E, 1978, Clin Symp, V30, P3; LITTLER WA, 1978, AM HEART J, V95, P180, DOI 10.1016/0002-8703(78)90461-1; LITTLER WA, 1975, CIRCULATION, V51, P1101; LITTLER WA, 1979, BRIT MED J, V1, P491; LITTLER WA, 1976, POSTGRAD MED J, V52, P119; LOGGIE JMH, 1977, JUVENILE HYPERTENSIO, P1; LONDE S, 1977, J PEDIATR, V90, P93, DOI 10.1016/S0022-3476(77)80776-2; LONDE S, 1966, CLIN PEDIATR, V5, P71, DOI 10.1177/000992286600500204; LOPER RG, 1973, J ABNORM PSYCHOL, V82, P159, DOI 10.1037/h0034959; LUCE GG, 1970, DHEW ADM78247 PUBL; LUDWIG C, 1847, ARCH ANAT PHYSL WISS, V261, P242; MACANDREW C, 1981, J STUD ALCOHOL, V42, P604; MACMAHON B, 1973, J NATL CANCER I, V50, P21; MAGNUS G, 1982, CHRONOBIOLOGIA, V9, P348; MALBECQ W, 1981, J INTERDISCIPL CYCLE, V12, P97; MALLION JM, 1979, ARCH MAL COEUR, V73, P95; MANCIA G, 1983, CHEST S, V2, P317; MANN S, 1980, CLIN SCI, V59, P497; MANN S, 1980, BRIT J CLIN PHARMACO, V10, P443; MANN S, 1979, CLIN SCI, V57, pS291; MANN S, 1979, CLIN SCI S5, V57, P3755; MANTERO F, 1981, J ENDOCR INVEST S1, V4, P243; MARKIEWICZ A, 1980, RECENT ADV CHRONOBIO, P185; MAY K, 1972, DICT SCI BIOG, V5, P298; MCCALL WC, 1981, J FAM PRACTICE, V13, P25; MEFFERD RB, 1959, J APPL PHYSIOL, V14, P995; MEHTA SK, 1979, INT S AMBULATORY MON, P197; MEIS PJ, 1981, CHRONOPHARMACOLOGY C, P159; MEISEL WS, 1969, IEEE T COMPUT, VC 18, P911, DOI 10.1109/T-C.1969.222546; Mendel J.M., 1970, ADAPTIVE LEARNING PA; MENZEL W, 1962, MENSCHLICHE TAG NACH; MESSERLI FH, 1981, AM J CARDIOL, V47, P480, DOI 10.1016/0002-9149(81)90993-0; MEYER WJ, 1974, TEMPORAL ASPECTS THE, P143; Michelakis A M, 1970, Circ Res, V27, P185; MILLARCRAIG MW, 1983, EUR J CLIN PHARMACOL, V24, P713, DOI 10.1007/BF00607076; MILLARCRAIG MW, 1981, SCOT MED J, V26, P309; MILLAR-CRAIG M W, 1980, Clinical Cardiology, V3, P236; MILLARCRAIG MW, 1978, MED BIOL ENG COMPUT, V16, P727, DOI 10.1007/BF02442453; MILLARCRAIG MW, 1978, LANCET, V1, P795; MITCHELL RH, 1979, BLOOD PRESSURE VARIA, P81; Moore-Ede M, 1982, CLOCKS TIME US PHYSL; Mueller SC, 1930, ANN INTERN MED, V3, P1190; MURNAGHAN GA, 1976, POSTGRAD MED J, V52, P123; NATALI G, 1982, CHRONOBIOLOGIA, V9, P257; NATALI G, 1982, CHRONOBIOLOGIA, V9, P99; NATALI G, 1982, CHRONOBIOLOGIA, V9, P249; NELSON W, 1980, J GERONTOL, V35, P512; NELSON W, 1983, CHRONOBIOLOGIA, V10, P179; NELSON W, 1983, CHRONOBIOLOGIA, V10, P143; NORTH AF, 1978, J PEDIATR, V92, P156; OBRIEN ET, 1979, BRIT MED J, V2, P1124; OLDHAM PD, 1960, LANCET, V1, P1085; OMAE T, 1978, CHRONOBIOLOGIA, V5, P95; ORTHGOMER K, 1982, CHRONOPHARMACOLOGY, P191; Palatini P, 1980, G Ital Cardiol, V10, P301; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; PATRICK EA, 1972, PRENTICEHALL ELECTRI; PAUL OGLESBY, 1967, P365; PERERA GA, 1958, ANN INTERN MED, V49, P1348; PESSINA AC, 1979, BLOOD PRESSURE VARIA, P95; PESSINA AC, 1980, BIOTELEM PAT MON, V7, P96; PICKERING GW, 1960, ESSENTIAL HYPERTENSI, P31; PICKERING GW, 1978, HYPERTENSION PHYSIOP, P598; PICKERING T, 1981, LANCET, V2, P416; PICKERING TG, 1980, CARDIOVASC REV REP, V1, P37; PICKERING TG, 1982, CLIN EXP HYPERTENS, V4, P675, DOI 10.3109/10641968209061606; PICKERING TG, 1982, JAMA-J AM MED ASSOC, V247, P992, DOI 10.1001/jama.247.7.992; PRIEST RT, 1979, AMBULATORY ELECTROCA, V1, P1; PRINEAS RJ, 1978, BLOOD PRESSURE SOUND; PRINEAS RJ, 1980, HYPERTENSION      S1, V2, P24; PRINEAS RJ, 1980, HYPERTENSION S1, V2, P8; PRITCHARD BNC, 1983, BRIT MED J, V283, P306; RABATIN JS, 1981, CHRONOBIOLOGY, P373; RADKE AQ, 1979, P MINN ACAD SCI, P16; RADKE AQ, 1980, CHRONOBIOLOGIA, V7, P134; RADKE AQ, 1979, 3RD P C IND SOC CHRO; RAFTERY EB, 1983, EUR HEART J, V4, P61; RAFTERY EB, 1978, BRIT J CLIN PHARMACO, V6, P193; RAFTERY EB, 1979, BLOOD PRESSURE VARIA, P67; RAMACCI CA, 1980, RIV MED AERONAUT, V44, P230; RAMES LK, 1978, PEDIATRICS, V61, P245; RAMLOW J, UNPUB AUTOMATIC CIRC; RAMSAY LE, 1977, BRIT HEART J, V39, P795; REEKER F, 1974, CHRONOBIOLOGY, P394; REINBERG A, 1970, ANN ENDOCRINOL-PARIS, V31, P277; REINBERG A, 1976, CHRONOBIOLOGIA, V3, P151; RESKE S, 1978, P MINN ACAD SCI, P26; RICHARDSON DW, 1964, CLIN SCI, V26, P445; ROMANO S, 1978, 14 P INT C INT MED R, P1482; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; ROWLANDS DB, 1980, CLIN SCI, V58, P115; RUBLER S, 1982, CLIN CARDIOL, V5, P447; SCARPELLI PT, 1978, PROBLEMI PROSPETTIVE, P173; SCARPELLI PT, 1978, CHRONOBIOLOGIA, V5, P407; Scarpelli P T, 1968, Rass Neurol Veg, V22, P5; SCHEVING LA, 1974, CHRONOBIOLOGY, P386; SCHEVING LE, 1982, CHRONOBIOLOGIA, V9, P346; SCHEVING LE, 1976, ENDEAVOUR, V35, P66, DOI 10.1016/0160-9327(76)90030-2; SCHNEIDE.RA, 1971, J CHRON DIS, V23, P647, DOI 10.1016/0021-9681(71)90160-3; SCHNEIDE.RA, 1972, ARCH ENVIRON HEALTH, V24, P10; SCHNEIDER RA, 1981, BIOTELEM PAT MON, V8, P81; SEGI M, 1977, CANCER INCIDENCE 5 C, V3, P42; SELIGMAN SA, 1971, J OBSTET GYN BR COMM, V78, P417; SEMPLICINI A, 1981, BIOTELEM PATIENT MON, V8, P81; SHEPS SG, 1981, MAYO CLIN PROC, V56, P740; SHIOTSUKA R, 1973, International Journal of Chronobiology, V1, P358; SHOWMAN A, 1981, Anesthesiology (Hagerstown), V55, P717; SINZ R, 1980, BIOLOGIE, V217; SLEIGHT P, 1979, BLOOD PRESSURE VARIA, P55; SMIRK JH, 1957, HIGH ARTERIAL PRESSU; SMITH WM, 1977, CIRC RES, V40, P98; Smolensky M, 1972, ADV CLIMATIC PHYSL, P281; SMOLENSKY MH, 1976, CHRONOBIOLOGIA, V3, P337; SOKOLOW M, 1979, BLOOD PRESSURE VARIA, P25; SOKOLOW M, 1966, CIRCULATION, V34, P279; SOKOLOW M, 1973, CLIN SCI MOL MED   S, V45, P195; SOKOLOW M, 1980, CARDIOVASC REV REP, V1, P295; SOTHERN RB, 1983, MINN ACAD SCI, V51, P11; STATLAND BE, 1977, ADV AUTOMATED ANAL, P1; STATLAND BE, 1978, AM J CLIN PATHOL, V69, P48; STATLAND BE, 1976, CLIN CHEM, V22, P1212; SUCKI WN, 1977, CONTRIB NEPHROL, V7, P290; WETTERBERG L, 1979, Experientia (Basel), V35, P416, DOI 10.1007/BF01964386; TARQUINI B, 1979, AM J MED, V66, P229, DOI 10.1016/0002-9343(79)90536-9; TARQUINI B, 1982, CHRONOBIOLOGIA, V9, P143; TARQUINI B, 1979, CHRONOBIOLOGIA, V6, P162; TARQUINI B, 1979, GIORN GERONT, V26, P629; Tou J.T., 1974, PATTERN RECOGNITION; VOORS AW, 1976, CIRCULATION, V54, P319; WAEBER B, 1980, HYPERTENSION, V2, P236; WALLACE DL, 1978, INT ENCY STATISTICS, P47; WALLACH LA, 1977, CHRONOBIOLOGIA, V4, P160; WATSON RDS, 1980, HYPERTENSION, V2, P333; WEBER MA, 1982, JAMA-J AM MED ASSOC, V248, P1626, DOI 10.1001/jama.248.13.1626; WEBER MA, 1982, CLIN EXP HYPERTENS A, V4, P1377, DOI 10.3109/10641968209060796; Wenger MA, 1943, J LAB CLIN MED, V28, P1101; WERTHEIMER L, 1977, 12TH P INT C INT SOC, P349; WERTHEIMER L, 1976, POSTGRAD MED J, V52, P114; Weysse AW, 1915, AM J PHYSIOL, V37, P330; WILLIAMS WP, 1980, PHOTOBIOCH PHOTOBIOP, V1, P91; WINKEL P, 1975, AM J CLIN PATHOL, V64, P433; WINKEL P, 1977, CONT TOPICS ANAL CLI, P287; YUNIS EJ, 1975, CHRONOBIOLOGIA S1, V2, P79; ZADEK M, 1881, Z KLIN MED, V2, P509; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; ZERZAWY R, 1981, BIOTELEM PATIENT MON, V8, P71; ZERZAWY R, 1981, BIOTELEM PAT MON, V8, P90; 1979, LANCET, V2, P1279; 1979, J AM MED ASS, V242, P2562; 1977, PEDIATRICS S, V59, P797; 1976, DHEW NIH771179 PUBL; 1964, BLOOD PRESSURE ADULT	372	21	22	ASSOCIATED CHRONOBIOLOGIA RESEARCHERS	MILAN	VIA R. DI LAURIA, 12/A, 20149 MILAN, ITALY	0390-0037		CHRONOBIOLOGIA			1984	11	3					189	&				0	Biology	Life Sciences & Biomedicine - Other Topics	TR895	WOS:A1984TR89500001	
J	BODA, K; PAP, A				BODA, K; PAP, A			DIAGNOSTICS OF PANCREATIC INSUFFICIENCY USING MULTIVARIATE STATISTICAL AND PATTERN-RECOGNITION METHODS	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article									UNIV MED SCH SZEGED,INTERNAL MED CLIN,DEPT MED 1,H-6720 SZEGED,HUNGARY	BODA, K (reprint author), UNIV MED SCH SZEGED,CTR COMP,H-6720 SZEGED,HUNGARY.						APARISI L, 1979, 12TH EUR PANCR CLUB; BODA K, 1980, STATISTICAL PROGRAMM, P33; CAPITAINE Y, 1971, Biologie et Gastro-Enterologie, V4, P301; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DURBEC JP, 1978, METHOD INFORM MED, V17, P36; KENDALL M, 1976, ADV THEORY STATISTIC, V3, P327; Pap A, 1981, Orv Hetil, V122, P623; Pap A, 1977, Orv Hetil, V118, P2078; Sarles H, 1970, Acta Gastroenterol Belg, V33, P303; SCHMIDT B, 1977, CR SEANC SOC BIOL, V164, P1813; Young T. Y., 1974, CLASSIFICATION ESTIM	11	3	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0010-4825		COMPUT BIOL MED	Comput. Biol. Med.		1984	14	1					91	97		10.1016/0010-4825(84)90023-4		7	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	SN111	WOS:A1984SN11100009	
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			AN OPTIMAL GLOBAL NEAREST NEIGHBOR METRIC	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									USN,RES LAB,WASHINGTON,DC 20375	FUKUNAGA, K (reprint author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.						BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1979, IEEE T INFORM THEORY, V25, P749, DOI 10.1109/TIT.1979.1056099; Devijver P. A., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition; Duda R. O., 1973, PATTERN CLASSIFICATI; FRASER DA, 1957, NONPARAMETRIC METHOD, pCH4; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P434, DOI 10.1109/TIT.1973.1055049; FUKUNAGA K, 1972, INTRO STATISTICAL PA, pCH2; FUKUNAGA K, 1982, TREE8236 PURD U TECH; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GARNETT JM, 1977, IEEE T COMPUT, V26, P46; Patrick E. A., 1972, FUNDAMENTALS PATTERN; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SHORT RD, 1980, 5TH INT C PATT REC M, P81; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260	18	51	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					314	318				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	SR542	WOS:A1984SR54200006	
J	GOIN, JE				GOIN, JE			CLASSIFICATION BIAS OF THE K-NEAREST NEIGHBOR ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter										GOIN, JE (reprint author), GEOMETR DATA,999 W VALLEY RD,WAYNE,PA 19087, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1977, SEP P INT C CYB SOC, P630; Duda R., 1973, PATTERN CLASSIFICATI; FIX E, 1951, NONPARAMETRIC DISCRI; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GOIN JE, 1982, PATTERN RECOGN, V15, P263, DOI 10.1016/0031-3203(82)90077-2; GOIN JE, 1983, PATTERN RECOGN, V16, P125, DOI 10.1016/0031-3203(83)90015-8; SAMMON JW, 1970, 9TH P IEEE C AD PROC	8	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					379	381				3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	SR542	WOS:A1984SR54200016	
J	LAHART, MJ				LAHART, MJ			ESTIMATION OF ERROR RATES IN CLASSIFICATION OF DISTORTED IMAGERY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									USN,RES LAB,WASHINGTON,DC 20375							BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; CASASENT D, 1977, APPL OPTICS, V16, P1652, DOI 10.1364/AO.16.001652; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1973, PATTERN CLASSIFICATI, P100; FUKUNAGA K, 1982, TREE8236 PURD U TECH; JOHN S, 1960, SANKHYA SER A, V22, P301; LAHART MJ, 1970, J OPT SOC AM, V60, P319, DOI 10.1364/JOSA.60.000319; LAHART MJ, 1971, J OPT SOC AM, V61, P985; MOSTAFAVI H, 1978, IEEE T AERO ELEC SYS, V14, P487, DOI 10.1109/TAES.1978.308610; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403	10	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	4					535	542				8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	SY289	WOS:A1984SY28900016	
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			CLASSIFICATION ERROR FOR A VERY LARGE NUMBER OF CLASSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article										FUKUNAGA, K (reprint author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.						ALBRECHT G, 1979, WEYERS FLOTTEN TASCH; BLACKMAN RVB, 1973, JANES FIGHTING SHIPS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRASER DA, 1957, NONPARAMETRIC METHOD, pCH4; FUKUNAGA K, 1972, INTRO STATISTICAL PA; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P258; FUKUNAGA K, 1982, TREE8236 PURD TECH R; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208	8	14	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					779	788				10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	TX361	WOS:A1984TX36100011	
J	MORET, I; DILEO, F; GIROMINI, V; SCARPONI, G				MORET, I; DILEO, F; GIROMINI, V; SCARPONI, G			MULTIPLE DISCRIMINANT-ANALYSIS IN THE ANALYTICAL DIFFERENTIATION OF VENETIAN WHITE WINES .4. APPLICATION TO SEVERAL VINTAGE YEARS AND COMPARISON WITH THE K NEAREST-NEIGHBOR CLASSIFICATION	JOURNAL OF AGRICULTURAL AND FOOD CHEMISTRY			English	Article									UNIV VENEZIA,FAC CHIM IND,CATTEDRA CHIM ANALIT,I-30123 VENEZIA,ITALY; IST TECN AGR ORDINAMENTO SPECIALE VITICULTURA & ENOL,I-31015 CONEGLIANO,ITALY							Albano C., 1978, ANAL CHIM ACTA-COMP, V103, P429, DOI 10.1016/S0003-2670(01)83107-X; CHATFIELD C, 1980, INTRO MULTIVARIATE A; COOMANS D, 1982, ANAL CHIM ACTA, V138, P167, DOI 10.1016/S0003-2670(01)85299-5; COOMANS D, 1982, ANAL CHIM ACTA, V136, P15, DOI 10.1016/S0003-2670(01)95359-0; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUEWER DL, 1978, COMPUT BIOMED RES, V11, P567, DOI 10.1016/0010-4809(78)90035-6; HULL CH, 1981, SPSS UPDATE 7 9, P292; KENDALL MG, 1979, ADV THEORY STATISTIC, V2, P139; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KOWALSKI BR, 1975, ANAL CHEM, V47, P1152; Sjostrom M., 1979, Analytica Chimica Acta, Computer Techniques and Optimization, V112, DOI 10.1016/S0003-2670(01)93026-0; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL, P33; MANDEL J, 1978, TREATISE ANAL CHEM 1, V1, P252; MASSART DL, 1978, EVALUATION OPTIMIZAT, P422; MORET I, 1980, AM J ENOL VITICULT, V31, P245; NIE NH, 1975, STATISTICAL PACKAGE, P434; PETERSON DW, 1970, IEEE T INFORM THEORY, V16, P26, DOI 10.1109/TIT.1970.1054408; Saxberg B. E. H., 1978, Analytica Chimica Acta, V103, P201, DOI 10.1016/S0003-2670(01)84039-3; SCARPONI G, 1982, J AGR FOOD CHEM, V30, P1135, DOI 10.1021/jf00114a033; Scarponi G., 1981, Rivista di Viticoltura e di Enologia, V34, P254; VARMUZA K, 1980, PATTERN RECOGN, P62; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wold S, 1977, CHEMOMETRICS THEORY, P243; 1976, GAZZ UFF REPUB ITAL, P6399; 1969, GAZZ UFF REPUB ITAL, P3349; 1971, GAZZ UFF REPUB ITAL, P5946; 1968, GAZZ UFF REPUB ITAL, P6349	29	24	25	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0021-8561		J AGR FOOD CHEM	J. Agric. Food Chem.		1984	32	2					329	333		10.1021/jf00122a037		5	Agriculture, Multidisciplinary; Chemistry, Applied; Food Science & Technology	Agriculture; Chemistry; Food Science & Technology	SJ548	WOS:A1984SJ54800037	
J	MORET, I; SCARPONI, G; CESCON, P				MORET, I; SCARPONI, G; CESCON, P			AROMA COMPONENTS AS DISCRIMINATING PARAMETERS IN THE CHEMOMETRIC CLASSIFICATION OF VENETIAN WHITE WINES	JOURNAL OF THE SCIENCE OF FOOD AND AGRICULTURE			English	Article										MORET, I (reprint author), UNIV VENEZIA, FAC CHIM IND, CATTEDRA CHIM ANAL, I-30123 VENICE, ITALY.						CORDONNIER R, 1981, Connaissance de la Vigne et du Vin, V15, P269; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEROSA T, 1983, AM J ENOL VITICULT, V34, P98; Drawert F., 1969, CHROMATOGRAPHIA, V2, P57, DOI 10.1007/BF02341319; JOSLIN WS, 1978, AM J ENOL VITICULT, V29, P11; Kendall M., 1983, ADV THEORY STAT, V3, P370; KOWALSKI BR, 1972, ANAL CHEM, V44, P128; KWAN WO, 1980, J AGR FOOD CHEM, V28, P356, DOI 10.1021/jf60228a029; KWAN WO, 1978, J FOOD SCI, V43, P1320, DOI 10.1111/j.1365-2621.1978.tb15299.x; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL; Marais J., 1981, S AFR J ENOL VITIC, V2, P19; MARAIS J, 1980, VITIS, V19, P151; MARAIS J, 1978, VITIS, V17, P396; MARAIS J, 1981, S AFR J ENOL VITIC, V2, P45; MASSART DL, 1978, EVALUATION OPTIMIZAT, P412; MORET I, 1980, AM J ENOL VITICULT, V31, P245; MORET I, 1984, J AGR FOOD CHEM, V32, P329, DOI 10.1021/jf00122a037; MORET I, 1984, ANN CHIM-ROME, V74, P73; Moret I., 1983, Rassegna Chimica, V35, P319; NIE NH, 1975, STATISTICAL PACKAGE, P434; NOBLE AC, 1980, P S OENOLOGY, P288; RAMEY DD, 1980, J AGR FOOD CHEM, V28, P928, DOI 10.1021/jf60231a021; RAPP A, 1978, FLAVOR FOODS BEVERAG, P203; SCARPONI G, 1982, J AGR FOOD CHEM, V30, P1135, DOI 10.1021/jf00114a033; Scarponi G., 1981, Rivista di Viticoltura e di Enologia, V34, P254; SCHREIER P, 1980, J AGR FOOD CHEM, V28, P926, DOI 10.1021/jf60231a020; Schreier P., 1976, Mitteilungen, Rebe und Wein, Obstbau und Fruchteverwertung, V26, P225; SCHREIER P, 1978, J SCI FOOD AGR, V29, P728, DOI 10.1002/jsfa.2740290811; SIMPSON RF, 1978, VITIS, V17, P274; Spirov N., 1977, Lozarstvo i Vinarstvo, V26, P22; VANDERMERWE CA, 1981, AM J ENOL VITICULT, V32, P41; VARMUZA K, 1980, PATTERN RECOGN, P62; Versini G., 1979, Vini d'Italia, V21, P269; WILDENRADT HL, 1975, AM J ENOL VITICULT, V26, P148; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; 1971, GAZZETTA UFFICI 0901, P5478; 1968, GAZZETTA UFFICI 1022, P6349; 1971, GAZZETTA UFFICI 0924, P5946; 1976, GAZZETTA UFFICI 0827, P6399	40	37	37	WILEY-BLACKWELL	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0022-5142		J SCI FOOD AGR	J. Sci. Food Agric.		1984	35	9					1004	1011		10.1002/jsfa.2740350909		8	Agriculture, Multidisciplinary; Chemistry, Applied; Food Science & Technology	Agriculture; Chemistry; Food Science & Technology	TK085	WOS:A1984TK08500008	
J	PRESTON, K				PRESTON, K			4-DIMENSIONAL LOGICAL TRANSFORMS - DATA-PROCESSING BY CELLULAR AUTOMATA	PHYSICA D			English	Article									UNIV PITTSBURGH,DEPT RADIAT HLTH,PITTSBURGH,PA 15213; KENSAL CONSULTING,TUCSON,AZ 85712	PRESTON, K (reprint author), CARNEGIE MELLON UNIV,DEPT ELECT ENGN,PITTSBURGH,PA 15213, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Graham M. D., 1980, Real-Time Medical Image Processing. Proceedings of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; PRESTON K, 1980, J COMB INFORM SYST S, V5, P281; STAUDHAMMER J, 1975, COMPUT GRAPH, V9, P181; Ulam S, 1962, P S APPL MATH, V14, P215	7	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-2789		PHYSICA D	Physica D		1984	10	1-2					205	212		10.1016/0167-2789(84)90262-8		8	Mathematics, Applied; Physics, Multidisciplinary; Physics, Mathematical	Mathematics; Physics	SJ933	WOS:A1984SJ93300019	
J	NAGY, G				NAGY, G			ADVANCES IN INFORMATION EXTRACTION TECHNIQUES	REMOTE SENSING OF ENVIRONMENT			English	Article										NAGY, G (reprint author), UNIV NEBRASKA,DEPT COMP SCI,LINCOLN,NE 68588, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANIELSSON PE, 1981, COMPUTER, V14, P53, DOI 10.1109/C-M.1981.220251; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; FEIN L, 1968, PATTERN RECOGNITION, P443; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; GOLDFARB L, 1980, THESIS U WATERLOO; HARALICK R, 1980, IEEE T PATTERN ANAL, V2, P263; HARALICK RM, 1982, UNPUB IEEE T PATTERN; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173; Hartigan J., 1975, CLUSTERING ALGORITHM; Horowitz E, 1978, FUNDAMENTALS COMPUTE; LANDGREBE DA, 1980, PATTERN RECOGN, V12, P165, DOI 10.1016/0031-3203(80)90041-2; LANDGREBE DA, 1981, P IEEE, V69, P628, DOI 10.1109/PROC.1981.12030; LEVINE MD, 1981, IEEE T PATTERN ANAL, V3, P540; NAGY G, 1979, COMPUT SURV, V11, P139; SHAHEEN SI, UNPUB PATTERN RECOGN; TOUSSAINT G, 1982, PATTERN RECOGNITION; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; WASSERMAN AI, 1982, COMMUN ACM, V25, P196, DOI 10.1145/358453.358459; WHEELER SG, 1980, PATTERN RECOGN, V12, P219, DOI 10.1016/0031-3203(80)90061-8; WONG AKC, 1981, PATTERN RECOGNITION, P157; ZOBRIST AL, 1981, COMPUTER, V14, P34, DOI 10.1109/C-M.1981.220246; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41	24	2	2	ELSEVIER SCIENCE INC	NEW YORK	655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010	0034-4257		REMOTE SENS ENVIRON	Remote Sens. Environ.		1984	15	2					167	175		10.1016/0034-4257(84)90044-0		9	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	SK152	WOS:A1984SK15200005	
J	MULLIGAN, TJ; LAPI, L; KIESER, R; YAMADA, SB; DUEWER, DL				MULLIGAN, TJ; LAPI, L; KIESER, R; YAMADA, SB; DUEWER, DL			SALMON STOCK IDENTIFICATION BASED ON ELEMENTAL COMPOSITION OF VERTEBRAE	CANADIAN JOURNAL OF FISHERIES AND AQUATIC SCIENCES			English	Article										MULLIGAN, TJ (reprint author), FISHERIES & OCEANS CANADA,FISHERIES RES BRANCH,PACIFIC BIOL STN,NANAIMO V9R 5K6,BC,CANADA.		Duewer, David/B-7410-2008				Bevington P. R., 1969, DATA REDUCTION ERROR; BILTON HT, 1972, J FISH RES BOARD CAN, V29, P295; CALAPRICE J R, 1975, International North Pacific Fisheries Commission Bulletin, V32, P81; CALAPRIC.JR, 1971, J FISH RES BOARD CAN, V28, P369; CALAPRIC.JR, 1971, J FISH RES BOARD CAN, V28, P1583; CHILD AR, 1976, J FISH BIOL, V8, P35, DOI 10.1111/j.1095-8649.1976.tb03905.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUEWER DL, 1977, ARTHUR VERSION 3777; DUEWER DL, 1978, COMPUT BIOMED RES, V11, P567, DOI 10.1016/0010-4809(78)90035-6; DZUBAY TG, 1977, XRAY FLUORESCENCE AN; HARPER AM, 1977, ACS S SER, V52; KIESER R, 1979, X-RAY SPECTROM, V8, P164, DOI 10.1002/xrs.1300080406; KIESER R, 1975, ADV XRAY ANAL, V19, P487; KITTLER J, 1977, IEEE T COMPUT, V26, P604; Klokov V. K, 1970, Izv. tikhookean. nauchno-issled. Inst. ryb. Khoz. Oceanogr., V71, P159; KOWALSKI BR, 1974, COMPUTERS CHEM BIOL, V2; LAPI LA, 1981, CAN J FISH AQUAT SCI, V38, P744; MARGOLIS L, 1963, INT N PAC FISH COMM, V11; MILLER RG, 1974, BIOMETRIKA, V61, P1; NIE NH, 1975, STATISTICAL PACKAGE; QUICK JE, 1981, 16TH P NATL C EL PRO, P143; RUSS JC, 1981, MICROBEAM ANAL 1981, P186; WITHLER RE, 1982, 1098 CAN TECH REP FI; WOLDSETH R, 1973, ALL YOU EVER WANTED; YAMADA SB, 1979, J FISH BIOL, V14, P267, DOI 10.1111/j.1095-8649.1979.tb03518.x; YAMADA SB, 1982, J FISH BIOL, V20, P5, DOI 10.1111/j.1095-8649.1982.tb03889.x; YONEMORI T, 1972, STUDIES SPECIAL TRAC; 1967, STUDY IDENTIFICATION	28	25	26	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA ON K1A 0R6, CANADA	0706-652X		CAN J FISH AQUAT SCI	Can. J. Fish. Aquat. Sci.		1983	40	2					215	229		10.1139/f83-032		15	Fisheries; Marine & Freshwater Biology	Fisheries; Marine & Freshwater Biology	QC088	WOS:A1983QC08800014	
J	GILPIN, E; OLSHEN, R; HENNING, H; ROSS, J				GILPIN, E; OLSHEN, R; HENNING, H; ROSS, J			RISK PREDICTION AFTER MYOCARDIAL-INFARCTION - COMPARISON OF 3 MULTIVARIATE METHODOLOGIES	CARDIOLOGY			English	Article									UNIV CALIF SAN DIEGO,DEPT MED,DIV CARDIOL,LA JOLLA,CA 92093; UNIV CALIF SAN DIEGO,DEPT MATH,LA JOLLA,CA 92093							BATTLER A, 1980, CIRCULATION, V61, P1004; BEAUNE J, 1978, EUR J CARDIOL, V8, P629; BIGGER JT, 1978, AM J CARDIOL, V42, P202, DOI 10.1016/0002-9149(78)90901-3; BISHOP YMM, 1974, DISCRETE MULTIVARIAT, P357; BREIMAN L, 1981, GROWING PRUNING TREE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIXON WJ, 1979, BMDP BIOMEDICAL CO P, P711; DUMOUCHEL WH, 1981, DREG27 MIT DEP MATH; EFRON B, 1980, 63 STANF U DIV BIOST, P68; FRIEDMAN JH, 1977, IEEE T COMP, V26, P104; GILPIN EA, 1980, CORONARY CARE; GORDON L, 1978, ANN STAT, V6, P515, DOI 10.1214/aos/1176344197; GORFINKEL HJ, 1978, ARCH INTERN MED, V138, P193, DOI 10.1001/archinte.138.2.193; HELMERS C, 1974, ACTA MED SCAND S, V555, P7; HELVIG JT, 1979, SAS USERS GUIDE, P307; HENNING H, 1979, CIRCULATION, V59, P1124; JAMES TN, 1961, CIRCULATION, V24, P761; LURIA MH, 1979, AM J MED, V67, P9; LURIA MH, 1976, ANN INTERN MED, V85, P561; MCNEER JF, 1978, NEW ENGL J MED, V298, P229, DOI 10.1056/NEJM197802022980501; MOSS AJ, 1974, CIRCULATION, V49, P460; MOSS AJ, 1976, CIRCULATION, V54, P58; PEEL AA, 1962, BR HEART J, V26, P745; Rosenbaum FF, 1941, ARCH INTERN MED, V68, P913; SCHNUR S, 1953, ANN INTERN MED, V39, P1018; SHUBIN H, 1968, CARDIOVASC RES, V4, P329; STONE M, 1974, J R STAT SOC B, V36, P111; Swan H J, 1976, Am J Cardiol, V37, P413, DOI 10.1016/0002-9149(76)90292-7; WEINBERG SL, 1978, ARCH INTERN MED, V138, P1775, DOI 10.1001/archinte.138.12.1775; 1974, J CHRON DIS, V27, P267	30	30	30	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0008-6312		CARDIOLOGY	Cardiology		1983	70	2					73	84		10.1159/000173573		12	Cardiac & Cardiovascular Systems	Cardiovascular System & Cardiology	QT958	WOS:A1983QT95800002	
J	PALIWAL, KK; RAO, PVS				PALIWAL, KK; RAO, PVS			APPLICATION OF K-NEAREST-NEIGHBOR DECISION RULE IN VOWEL RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter										PALIWAL, KK (reprint author), TATA INST FUNDAMENTAL RES,SPEECH & DIGITAL SYST GRP,BOMBAY 400005,INDIA.						ATAL BS, 1974, J ACOUST SOC AM, V55, P1304, DOI 10.1121/1.1914702; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROCHIERE RE, 1980, IEEE T ACOUST SPEECH, V28, P318, DOI 10.1109/TASSP.1980.1163417; GUPTA VN, 1978, IEEE T ACOUST SPEECH, V26, P27, DOI 10.1109/TASSP.1978.1163054; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; LEVINSON SE, 1981, IEEE T ACOUST SPEECH, V29, P450, DOI 10.1109/TASSP.1981.1163593; MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792; NADAS A, 1981, IEEE T ACOUST SPEECH, V29, P449, DOI 10.1109/TASSP.1981.1163578; RABINER LR, 1979, IEEE T ACOUST SPEECH, V27, P336, DOI 10.1109/TASSP.1979.1163259; RABINER LR, 1980, IEEE T ACOUST SPEECH, V28, P377, DOI 10.1109/TASSP.1980.1163422; RABINER LR, 1979, IEEE T ACOUST SPEECH, V27, P583, DOI 10.1109/TASSP.1979.1163323; WAKITA H, 1976, IEEE T ACOUST SPEECH, V24, P270, DOI 10.1109/TASSP.1976.1162797	12	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					229	231				3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	QJ974	WOS:A1983QJ97400015	
J	GERSCH, W; BROTHERTON, T; BRAUN, S				GERSCH, W; BROTHERTON, T; BRAUN, S			NEAREST NEIGHBOR TIME-SERIES ANALYSIS CLASSIFICATION OF FAULTS IN ROTATING MACHINERY	JOURNAL OF VIBRATION ACOUSTICS STRESS AND RELIABILITY IN DESIGN-TRANSACTIONS OF THE ASME			English	Article									TECHNION ISRAEL INST TECHNOL,FAC MECH ENGN,HAIFA,ISRAEL	GERSCH, W (reprint author), UNIV HAWAII,DEPT INFORMAT & COMP SCI,HONOLULU,HI 96822, USA.						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Akaike H., 1976, SYSTEM IDENTIFICATIO, P27; BAHADUR R. R., 1971, SOME LIMIT THEOREMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CSISZAR I, 1975, ANN PROBAB, V3, P146, DOI 10.1214/aop/1176996454; GERSCH W, 1979, SCIENCE, V205, P193, DOI 10.1126/science.451587; GERSCH W, 1973, IEEE T AUTOMAT CONTR, VAC18, P367, DOI 10.1109/TAC.1973.1100350; GERSCH W, 1980, UNPUB COMPUTERS BIOM, V16; GERSCH W, 1980, UNPUB IEEE T INFORMA, V22; GERSCH W, 1977, TR30 STANF U DEP STA; GERSH W, 1979, 1978 P IEEE C DEC CO, P767; GOOD IJ, 1963, ANN MATH STAT, V34, P911, DOI 10.1214/aoms/1177704014; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; KITAGAWA G, 1978, ANN I STAT MATH, V30, P351, DOI 10.1007/BF02480225; KULLBACK S, 1958, INFORMATION THEORY S; OZAKI T, 1975, 8TH P HAW INT C SYST; Rozanov Y. A, 1967, STATIONARY RANDOM PR	17	5	5	ASME-AMER SOC MECHANICAL ENG	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017	0739-3717		J VIB ACOUST STRESS			1983	105	2					178	184				7	Engineering, Mechanical	Engineering	QP110	WOS:A1983QP11000007	
J	COOMANS, D; BROECKAERT, I; JONCKHEER, M; MASSART, DL				COOMANS, D; BROECKAERT, I; JONCKHEER, M; MASSART, DL			COMPARISON OF MULTIVARIATE DISCRIMINATION TECHNIQUES FOR CLINICAL-DATA - APPLICATION TO THE THYROID FUNCTIONAL-STATE	METHODS OF INFORMATION IN MEDICINE			English	Article									VRIJE UNIV BRUSSEL,AKAD ZIEKENHUIS,B-1090 BRUSSELS,BELGIUM	COOMANS, D (reprint author), VRIJE UNIV BRUSSEL,INST FARMACEUT,B-1090 BRUSSELS,BELGIUM.						ANDERSON TW, 1951, PSYCHOMETRIKA, V16, P31; Brier G. W., 1951, COMPENDIUM METEOROLO, P841; Bryan JG, 1951, HARVARD EDUC REV, V21, P90; CHIEN YT, 1968, INFORM CONTROL, V12, P394, DOI 10.1016/S0019-9958(68)90420-8; COOMANS D, 1982, ANAL CHIM ACTA, V138, P167, DOI 10.1016/S0003-2670(01)85299-5; Coomans D., 1981, Analytica Chimica Acta, Computer Techniques and Optimization, V133, DOI 10.1016/S0003-2670(01)83196-2; COOMANS D, 1981, ANAL CHIM ACTA, V132, P69, DOI 10.1016/S0003-2670(01)93878-4; COOMANS D, 1982, THESIS FREE U BRUSSE; Coomans D., 1981, Analytica Chimica Acta, Computer Techniques and Optimization, V133, DOI 10.1016/S0003-2670(01)83198-6; COOMANS D, 1982, ANAL CHIM ACTA, V136, P15, DOI 10.1016/S0003-2670(01)95359-0; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROFT DJ, 1974, ANN BIOMED ENG, V2, P69; CROFT DJ, 1972, COMPUT BIOMED RES, V5, P351, DOI 10.1016/0010-4809(72)90068-7; DIXON WD, 1981, BIOMEDICAL COMPUTER; Fisher RA, 1936, ANN EUGENIC, V7, P179; FIX E, 1951, 4 UN AIR FORC SCH AV; Galen R.S., 1975, NORMALITY; GEISSER S, 1964, J ROY STAT SOC B, V26, P69; GILBERT ES, 1968, J AM STAT ASSOC, V63, P1399, DOI 10.2307/2285893; GILBERT ES, 1969, BIOMETRICS, V25, P505, DOI 10.2307/2528902; HABBEMA JDF, 1977, TECHNOMETRICS, V19, P487, DOI 10.2307/1267890; Harper A.M., 1977, ACS SYM SER, P14; HEALY MJR, 1965, DESCRIPTIVE USES DIS; HERMANS J, 1975, EDV MED BIOL, V6, P14; HERMANS J, 1976, MANUAL ALLOC DISCRIM; HERMANS J, 1976, COMPSTAT 1976; HILDEN J, 1978, METHOD INFORM MED, V17, P227; HILDEN J, 1978, METHOD INFORM MED, V17, P238; HOEL PG, 1949, ANN MATH STAT, V20, P433, DOI 10.1214/aoms/1177729995; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LACHENBRUCH PA, 1973, DISCRIMINANT ANAL AP, P193; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MARKS S, 1974, J AM STAT ASSOC, V69, P555, DOI 10.2307/2285696; Massart D. L., 1980, Analytica Chimica Acta, Computer Techniques and Optimization, V122; MASSART DL, 1975, ANAL CHEM, V47, P1244; Meisel W, 1972, COMPUTER ORIENTED AP; MOORE DH, 1973, J AM STAT ASSOC, V68, P399; NAKACHE J P, 1976, P113; NIE NH, 1975, STATISTICAL PACKAGE; Nilsson Nils J., 1965, LEARNING MACHINES; NORDYKE RA, 1971, COMPUT BIOMED RES, V4, P374, DOI 10.1016/0010-4809(71)90022-X; PATRICK EA, 1979, DECISION ANAL MED ME; RAO CR, 1948, J ROY STAT SOC B, V10, P159; RAO CR, 1954, ANN MATH STAT, V25, P651, DOI 10.1214/aoms/1177728653; RAO CR, 1947, NATURE, V160, P835, DOI 10.1038/160835a0; RIOUX P, 1979, COMPUT PROG BIOMED, V10, P43, DOI 10.1016/0010-468X(79)90049-7; Sadegh-Zadeh K., 1980, METAMEDICINE, V1, P107, DOI 10.1007/BF00883523; SCHMITZ PIM, 1982, COMP 6 DISCRIMINANT; SMITH CAB, 1947, ANN EUGENIC, V13, P272; VICTOR N, 1976, P515; WAHL PW, 1977, BIOMETRICS, V33, P479, DOI 10.2307/2529362; Wald A, 1944, ANN MATH STAT, V15, P145, DOI 10.1214/aoms/1177731280; WATANABE S, 1965, 4TH P C INF THEOR PR; Welch BL, 1939, BIOMETRIKA, V31, P218, DOI 10.2307/2334985	56	50	51	F K SCHATTAUER VERLAG GMBH	STUTTGART	P O BOX 10 45 45, LENZHALDE 3, D-70040 STUTTGART, GERMANY	0026-1270		METHOD INFORM MED	Methods Inf. Med.		1983	22	2					93	101				9	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	QS447	WOS:A1983QS44700008	
J	GUNDEL, A				GUNDEL, A			EEG BACKGROUND ACTIVITY IN CHILDHOOD EPILEPSY - VALID PARAMETERIZATION BY THE PARTIAL AUTO-CORRELATION FUNCTION	NEUROPEDIATRICS			English	Article										GUNDEL, A (reprint author), UNIV KIEL,DEPT NEUROPEDIAT,D-2300 KIEL 1,FED REP GER.						Box G., 1970, TIME SERIES ANAL; COOLEY WW, 1971, MULTIVARIATE DATA AN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOOSE H, 1972, NEUROPADIATRIE, V3, P386, DOI 10.1055/s-0028-1091777; DOOSE H, 1970, Neuropaediatrie, V2, P59, DOI 10.1055/s-0028-1091841; DOOSE H, 1977, NEUROPADIATRIE, V8, P10, DOI 10.1055/s-0028-1091500; DOOSE H, 1982, GENETIC BASIS EPILEP, P83; GUNDEL A, 1981, NEUROPEDIATRICS, V12, P110, DOI 10.1055/s-2008-1059644; GUNDEL A, 1981, NEUROPEDIATRICS, V12, P62, DOI 10.1055/s-2008-1059640; LACHENBRUCH PA, 1979, BIOMETRICS, V35, P69, DOI 10.2307/2529937; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL; RAMSEY FL, 1974, ANN STAT, V2, P1296, DOI 10.1214/aos/1176342881; Rao C.R., 1970, ESSAYS PROBABILITY S, P587; VANNESS JW, 1976, TECHNOMETRICS, V18, P175, DOI 10.2307/1267520	14	4	4	HIPPOKRATES VERLAG GMBH	STITTGART	PO BOX 30 05 04 RUDIGERSTRASSE 14, 70469 STITTGART, GERMANY	0174-304X		NEUROPEDIATRICS	Neuropediatrics		1983	14	3					166	169		10.1055/s-2008-1059572		4	Clinical Neurology; Pediatrics	Neurosciences & Neurology; Pediatrics	RD413	WOS:A1983RD41300007	
J	COOMANS, D; MASSART, DL				COOMANS, D; MASSART, DL			ALTERNATIVE K-NEAREST NEIGHBOR RULES IN SUPERVISED PATTERN-RECOGNITION .2. PROBABILISTIC CLASSIFICATION ON THE BASIS OF THE KNN METHOD MODIFIED FOR DIRECT DENSITY-ESTIMATION	ANALYTICA CHIMICA ACTA			English	Article										COOMANS, D (reprint author), VRIJE UNIV BRUSSEL,INST FARMACEUT,B-1090 BRUSSELS,BELGIUM.						ALBANO C, 1981, S ANVENDT STATISTIC; Box GE, 1973, BAYESIAN INFERENCE S; Coomans D., 1981, Analytica Chimica Acta, Computer Techniques and Optimization, V133, DOI 10.1016/S0003-2670(01)83196-2; COOMANS D, 1981, ANAL CHIM ACTA, V132, P69, DOI 10.1016/S0003-2670(01)93878-4; Coomans D., 1981, Analytica Chimica Acta, Computer Techniques and Optimization, V133, DOI 10.1016/S0003-2670(01)83198-6; COOMANS D, 1982, ANAL CHIM ACTA, V136, P15, DOI 10.1016/S0003-2670(01)95359-0; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; Coomans D, 1979, ANAL CHIM ACTA, V112, P97, DOI 10.1016/S0003-2670(01)83513-3; COOMANS D, 1982, ANAL CHIM ACTA, V134, P139, DOI 10.1016/S0003-2670(01)84185-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FIX E, 1951, USAF4 SCH AV MED REP; FIX E, 1952, USAF11 SCH AV MED RE; Gradshtein I., 1965, TABLES INTEGRALS SER; HABBEMA JDF, 1978, METHOD INFORM MED, V17, P217; HARPER AM, 1977, AM CHEM SOC S SER, V52; HERMANS J, 1976, MANUAL ALLOC DISCRIM; HILDEN J, 1978, METHOD INFORM MED, V17, P227; HILDEN J, 1978, METHOD INFORM MED, V17, P238; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Meisel W, 1972, COMPUTER ORIENTED AP; NIE NH, 1975, STATISTICAL PACKAGE; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; PATRICK EA, 1979, DECISION ANAL MED ME; QUESENBE.CP, 1968, ANN MATH STAT, V39, P664, DOI 10.1214/aoms/1177698425; VICTOR N, 1978, METHOD INF MED, V17, P121; VICTOR N, 1980, METAMEDICINE, V1, P85, DOI 10.1007/BF00883521; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	29	19	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta		1982	138	JUN					153	165		10.1016/S0003-2670(01)85298-3		13	Chemistry, Analytical	Chemistry	NV636	WOS:A1982NV63600019	
J	COOMANS, D; MASSART, DL				COOMANS, D; MASSART, DL			ALTERNATIVE K-NEAREST NEIGHBOR RULES IN SUPERVISED PATTERN-RECOGNITION .3. CONDENSED NEAREST NEIGHBOR RULES	ANALYTICA CHIMICA ACTA			English	Article										COOMANS, D (reprint author), VRIJE UNIV BRUSSEL,INST FARMACEUT,B-1090 BRUSSELS,BELGIUM.						COOMANS D, 1981, ANAL CHIM ACTA, V132, P69, DOI 10.1016/S0003-2670(01)93878-4; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COOMANS D, 1982, ANAL CHIM ACTA, V134, P139, DOI 10.1016/S0003-2670(01)84185-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HABBEMA JDF, 1978, METHOD INFORM MED, V17, P217; HABBEMA JDF, 1981, METHOD INFORM MED, V20, P97; HARPER AM, 1977, AM CHEM SOC S SER, V52; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HERMAN J, 1976, MANUAL ALLOC DISCRIM; HILDEN J, 1978, METHOD INFORM MED, V17, P227; HILDEN J, 1978, METHOD INFORM MED, V17, P238; KAUFMAN L, 1975, THESIS VRIJE U BRUSS; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Massart D. L., 1978, EVALUATION OPTIMIZAT; Massart D. L., 1980, Analytica Chimica Acta, Computer Techniques and Optimization, V122; MASSART DL, 1981, S ANVENDT STATISTIC, P315; MASSART DL, 1975, ANAL CHEM, V47, P1244; Meisel W, 1972, COMPUTER ORIENTED AP; MURPHY AH, 1977, WEATHER FORCASTING W, P807; NIE NH, 1975, STATISTICAL PACKAGE; PATRICK EA, 1979, DECISION ANAL MED ME	21	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta		1982	138	JUN					167	176		10.1016/S0003-2670(01)85299-5		10	Chemistry, Analytical	Chemistry	NV636	WOS:A1982NV63600020	
J	COOMANS, D; MASSART, DL				COOMANS, D; MASSART, DL			ALTERNATIVE KAPPA-NEAREST NEIGHBOR RULES IN SUPERVISED PATTERN-RECOGNITION .1. KAPPA-NEAREST NEIGHBOR CLASSIFICATION BY USING ALTERNATIVE VOTING RULES	ANALYTICA CHIMICA ACTA			English	Article										COOMANS, D (reprint author), VRIJE UNIV BRUSSEL,INST FARMACEUT,B-1090 BRUSSELS,BELGIUM.						Albano C., 1978, ANAL CHIM ACTA-COMP, V103, P429, DOI 10.1016/S0003-2670(01)83107-X; Coomans D., 1981, Analytica Chimica Acta, Computer Techniques and Optimization, V133, DOI 10.1016/S0003-2670(01)83196-2; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COOMANS D, 1982, ANAL CHIM ACTA, V134, P139, DOI 10.1016/S0003-2670(01)84185-4; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DUEWER DL, 1978, COMPUT BIOMED RES, V11, P567, DOI 10.1016/0010-4809(78)90035-6; FIX E, 1952, USAF4 SCH AV MED REP; HERMANS J, 1976, MANUAL ALLOC DISCRIM; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Sjostrom M., 1979, Analytica Chimica Acta, Computer Techniques and Optimization, V112, DOI 10.1016/S0003-2670(01)93026-0; Massart D. L., 1978, EVALUATION OPTIMIZAT; PETERSON DW, 1970, IEEE T INFORM THEORY, V16, P26, DOI 10.1109/TIT.1970.1054408; Saxberg B. E. H., 1978, Analytica Chimica Acta, V103, P201, DOI 10.1016/S0003-2670(01)84039-3	15	24	24	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta		1982	136	APR					15	27		10.1016/S0003-2670(01)95359-0		13	Chemistry, Analytical	Chemistry	NL486	WOS:A1982NL48600003	
J	REILLY, DL; COOPER, LN; ELBAUM, C				REILLY, DL; COOPER, LN; ELBAUM, C			A NEURAL MODEL FOR CATEGORY LEARNING	BIOLOGICAL CYBERNETICS			English	Article									BROWN UNIV,DEPT PHYS,PROVIDENCE,RI 02912	REILLY, DL (reprint author), BROWN UNIV,CTR NEURAL SCI,PROVIDENCE,RI 02912, USA.						AMARI SI, 1977, BIOL CYBERN, V26, P175, DOI 10.1007/BF00365229; ANDERSON J A, 1970, Mathematical Biosciences, V8, P137, DOI 10.1016/0025-5564(70)90147-1; ANDERSON J A, 1972, Mathematical Biosciences, V14, P197, DOI 10.1016/0025-5564(72)90075-2; ANDERSON JA, 1978, PLURISCIENCE, P168; BARTO AG, 1981, BIOL CYBERN, V40, P201, DOI 10.1007/BF00453370; BLOMFIEL.S, 1974, BRAIN RES, V69, P115, DOI 10.1016/0006-8993(74)90375-8; BOBROWSKI L, 1982, BIOL CYBERN, V43, P23, DOI 10.1007/BF00337284; Brooks L., 1978, COGNITION CATEGORIZA, P169; COOPER LN, 1979, BIOL CYBERN, V33, P9, DOI 10.1007/BF00337414; COOPER LN, 1973, P NOBEL S COLLECTIVE, V24, P252; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS TL, 1979, J COMP NEUROL, V188, P599, DOI 10.1002/cne.901880407; DEAN AF, 1980, J PHYSIOL-LONDON, V308, pP84; Duda R., 1973, PATTERN CLASSIFICATI; FRANKS JJ, 1971, J EXP PSYCHOL, V90, P65, DOI 10.1037/h0031349; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; KOGH C, UNPUB PHILOS T R SOC; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353; Kohonen T, 1977, ASS MEMORY SYSTEM TH; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; NASS MM, 1975, BIOL CYBERN, V19, P1, DOI 10.1007/BF00319777; POGGIO T, 1981, THEORETICAL APPROACH, P28; POSNER MI, 1970, J EXP PSYCHOL, V83, P304, DOI 10.1037/h0028558; POSNER MI, 1968, J EXP PSYCHOL, V77, P353, DOI 10.1037/h0025953; REILLY DL, UNPUB APPLICATION 2; ROSE D, 1977, EXP BRAIN RES, V28, P221; WHITE EL, 1980, J NEUROCYTOL, V9, P615, DOI 10.1007/BF01205029	27	188	191	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0340-1200		BIOL CYBERN	Biol. Cybern.		1982	45	1					35	41		10.1007/BF00387211		7	Computer Science, Cybernetics; Neurosciences	Computer Science; Neurosciences & Neurology	PF885	WOS:A1982PF88500005	
J	COVER, TM				COVER, TM			CITATION CLASSIC - NEAREST NEIGHBOR PATTERN-CLASSIFICATION	CURRENT CONTENTS/ENGINEERING TECHNOLOGY & APPLIED SCIENCES			English	Article									STANFORD UNIV,DEPT STAT,STANFORD,CA 94305; STANFORD UNIV,DEPT ELECT ENGN,STANFORD,CA 94305							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	2	0	0	INST SCI INFORM INC	PHILADELPHIA	3501 MARKET ST, PHILADELPHIA, PA 19104	0011-3395		CC/ENG TECH APPL SCI			1982		13					20	20				1	Multidisciplinary Sciences; Social Sciences, Interdisciplinary	Science & Technology - Other Topics; Social Sciences - Other Topics	NF377	WOS:A1982NF37700001	
J	LEE, DT				LEE, DT			ON KAPPA-NEAREST NEIGHBOR VORONOI DIAGRAMS IN THE PLANE	IEEE TRANSACTIONS ON COMPUTERS			English	Article										LEE, DT (reprint author), NORTHWESTERN UNIV,DEPT ELECT ENGN & COMP SCI,EVANSTON,IL 60201, USA.						BENTLEY JL, 1975, STANCS75513 U STANF; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; BURKHARD WA, 1973, COMMUN ACM, V16, P230, DOI 10.1145/362003.362025; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Finkel R. A., 1974, Acta Informatica, V4, DOI 10.1007/BF00288933; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1001; FRIEDMAN JH, 1975, STANCS75482 STANF U; FUGUNAGA K, 1975, IEEE T COMPUT, V24, P750; GOWDA IG, 1980, THESIS U BRIT COLUMB; KIRKPATRICK DG, 1979, OPTIMAL SEARCH PLANA; LEE DT, 1980, J ACM, V27, P604, DOI 10.1145/322217.322219; Lee D. T., 1977, SIAM Journal on Computing, V6, DOI 10.1137/0206043; LEE DT, 1976, R728 U ILL COORD SCI; LEE DT, 1980, 8011FC04 NW U DEP EL; Lipton R. J., 1977, 18th Annual Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.1977.6; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; PREPARATA FP, 1981, SIAM J COMPUT, V10, P473, DOI 10.1137/0210035; Rogers C. A., 1964, PACKING COVERING; Shamos M. I., 1975, 16TH P IEEE S F COMP, P151, DOI 10.1109/SFCS.1975.8; SHAMOS MI, 1977, UNPUB COMPUTATIONAL	22	104	104	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0018-9340		IEEE T COMPUT	IEEE Trans. Comput.		1982	31	6					478	487				10	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	NS631	WOS:A1982NS63100001	
J	HECHTNIELSEN, R				HECHTNIELSEN, R			NEURAL ANALOG PROCESSING	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS			English	Article										HECHTNIELSEN, R (reprint author), MOTOROLA INC,GOVT ELECTR GRP,TEMPE,AZ 85283, USA.						ANDERSON J A, 1972, Mathematical Biosciences, V14, P197, DOI 10.1016/0025-5564(72)90075-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FREEMAN WJ, 1979, BIOL CYBERN, V35, P221, DOI 10.1007/BF00344205; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; GROSSBERG S, 1980, PSYCHOL REV, V87, P1; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; GROSSBERG S, 1976, BIOL CYBERN, V21, P145, DOI 10.1007/BF00337422; GROSSBERG S, 1978, PROGR THEORETICAL BI, V5; GROSSBERG S, 1976, BIOL CYBERN, V23, P121, DOI 10.1007/BF00344744; GROSSBERG S, 1974, PROGR THEORETICAL BI, V3; HECHTNIELSEN R, 1982, SPIE P, V298; HECHTNIELSEN R, UNPUB TIME VARYING P; KOHONEN T, 1978, ASS MEMORY; KOHONEN T, 1972, IEEE T COMPUT, VC 21, P353; NOBACK CR, 1975, HUMAN NERVOUS SYSTEM; PEELE TL, 1977, NEUROANATOMIC BASIS; von der Malsburg C, 1973, Kybernetik, V14, P85	17	4	4	SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS	BELLINGHAM	PO BOX 10, BELLINGHAM, WA 98227-0010	0361-0748		P SOC PHOTO-OPT INST			1982	360						180	189				10	Optics; Spectroscopy	Optics; Spectroscopy	QV539	WOS:A1982QV53900024	
J	GREENE, FM; BEACH, K; STRANDNESS, DE; FELL, G; PHILLIPS, DJ				GREENE, FM; BEACH, K; STRANDNESS, DE; FELL, G; PHILLIPS, DJ			COMPUTER-BASED PATTERN-RECOGNITION OF CAROTID ARTERIAL-DISEASE USING PULSED DOPPLER ULTRASOUND	ULTRASOUND IN MEDICINE AND BIOLOGY			English	Article										GREENE, FM (reprint author), UNIV WASHINGTON,DEPT SURG,SEATTLE,WA 98195, USA.						Andrews H.C., 1972, INTRO MATH TECHNIQUE; ARTS M, 1972, CARDIOVASC RES, V10, P368; BLACKSHEAR WM, 1979, SURGERY, V86, P698; BRODY WR, 1974, IEEE T BIO-MED ENG, VBM21, P183, DOI 10.1109/TBME.1974.324381; CHIKOS PM, 1980, UNPUB OBSERVER VARIA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROFT JC, 1980, LANCET, P997; Duda R., 1973, PATTERN CLASSIFICATI; DUEWER DL, 1975, BG10 U WASH DEP CHEM; FELL G, 1981, UNPUB CIRCULATION; Flanagan J, 1972, SPEECH ANAL SYNTHESI; FORSTER FK, 1977, ULTRASOUND MED B, V3, P1223; GERZBERG L, 1977, ULTRASOUND MEDICIN B, V3, P1173; GILL R W, 1979, Ultrasound in Medicine and Biology, V5, P237, DOI 10.1016/0301-5629(79)90015-2; Gosling Gosling RG, 1974, CARDIOVASCULAR APPL, P266; GREENE FM, 1979, THESIS U WASHINGTON; Hass WK, 1968, JAMA-J AM MED ASSOC, V203, P159; Hsu F. M., 1977, IEEE Transactions on Acoustics, Speech and Signal Processing, VASSP-25, DOI 10.1109/TASSP.1977.1162993; JOHNSTON K W, 1978, Ultrasound in Medicine and Biology, V4, P209, DOI 10.1016/0301-5629(78)90053-4; KELLER HM, 1976, STROKE, V7, P370; Knuth D. E., 1973, ART COMPUTER PROGRAM, V3; KOWALSKI BR, 1974, COMPUTERS CHEM BIOCH, V2; KOWALSKI BR, 1976, PATTERN RECOGN, V8, P1, DOI 10.1016/0031-3203(76)90023-6; LACKENBRUCH PA, 1975, DISCRIMINANT ANAL; LACKENBRUCK PA, 1968, TECHNOMETRICS, V10, P1; LERSKI R A, 1979, Ultrasound in Medicine and Biology, V5, P341, DOI 10.1016/0301-5629(79)90004-8; McCarthy P.J., 1976, J AM STAT ASSOC, V71, P596, DOI 10.2307/2285588; Mosteller F, 1977, DATA ANAL REGRESSION; Oppenheim A., 1975, DIGITAL SIGNAL PROCE; PHILLIPS DJ, 1980, ULTRASOUND MED BIOL, V6, P205, DOI 10.1016/0301-5629(80)90015-0; PIETRANT.L, 1972, PATTERN RECOGN, V4, P391, DOI 10.1016/0031-3203(72)90038-6; RENEMAN RS, 1974, CARDIOVASCULAR APPLI; RUTHERFORD RB, 1977, SURGERY, V82, P695; Sebestyen G. S., 1962, DECISION MAKING PROC; SHERRIF SB, 1980, BLOOD FLOW THEORY PR; Siegel S., 1956, NONPARAMETRIC STATIS; TUKEY JW, 1958, ANN MATH STAT, V29, P614; WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901; WOLD S, 1975, 2 U WASH RES GRP CHE	39	43	43	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0301-5629		ULTRASOUND MED BIOL	Ultrasound Med. Biol.		1982	8	2					161	176		10.1016/0301-5629(82)90095-3		16	Acoustics; Radiology, Nuclear Medicine & Medical Imaging	Acoustics; Radiology, Nuclear Medicine & Medical Imaging	NH232	WOS:A1982NH23200004	
J	KWAN, PW; CLARK, RC				KWAN, PW; CLARK, RC			ASSESSMENT OF OIL CONTAMINATION IN THE MARINE-ENVIRONMENT BY PATTERN-RECOGNITION ANALYSIS OF PARAFFINIC HYDROCARBON CONTENT OF MUSSELS	ANALYTICA CHIMICA ACTA-COMPUTER TECHNIQUES AND OPTIMIZATION			English	Article									UNIV WASHINGTON,DEPT CHEM,CHEMOMETR LAB,SEATTLE,WA 98195; NOAA,NATL MARINE FISHERIES SERV,NW & ALASKA FISHERIES CTR,DIV ENVIRONM CONSERVAT,SEATTLE,WA 98112							ANDERSON JW, 1974, MARINE BIOASSAYS WOR, P36; BLUMER M, 1969, OIL SEA, P5; CLARK RC, 1976, MAR FISH REV, V38, P20; CLARK R C JR, 1973, Marine Pollution Bulletin, V4, P172, DOI 10.1016/0025-326X(73)90178-1; CLARK RC, 1973, 1973 P JOINT C PREV, P793; CLARK RC, 1975, 1975 P C PREV CONTR, P479; CLARK RC, 1978, J FISH RES BOARD CAN, V35, P754; CLARK RC, 1974, NBS409 SPEC PUBL, P302; CLARK RC, 1971, 1971 P JOINT C PREV, P139; CLARK RL, 1973, 1973 P JOINT C PREV, P161; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUEWER DL, 1975, ANAL CHEM, V47, P1573, DOI 10.1021/ac60359a051; DUEWER DL, 1975, ANAL CHEM, V47, P526, DOI 10.1021/ac60353a034; FARRINGTON JW, 1976, STRATEGIES MARINE PO, P3; Gabbott P. A., 1976, MARINE MUSSELS THEIR, P293; GOLDBERG ED, 1978, ENVIRON CONSERV, V5, P101; HARPER AM, 1977, ACS52 AM CHEM SOC S; KOWALSKI BR, 1969, ANAL CHEM, V41, P1945, DOI 10.1021/ac50159a026; KOWALSKI BR, 1974, CHEM TECHNOL, V5, P300; KOWALSKI BR, 1975, ANAL CHEM, V47, P1152; KOWALSKI BR, 1976, PATTERN RECOGN, V8, P1, DOI 10.1016/0031-3203(76)90023-6; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KOWALSKI BR, 1972, ANAL CHEM, V44, P2176, DOI 10.1021/ac60321a002; MALINS DC, EFFECTS PETROLEUM AR, V2; MALINS DC, 1980, MAY INT C EXH PETR M; MALINS DC, 1977, EFFECTS PETROLEUM AR, V1; Tissot B., 1978, PETROLEUM FORMATION; VARANASI U, 1977, EFFECTS PETROLEUM AR, V2, P175; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	29	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA-COMP			1981	5	2					151	168				18	Chemistry, Analytical; Engineering, Electrical & Electronic	Chemistry; Engineering	LQ554	WOS:A1981LQ55400004	
J	SCHACHTERLE, SD; PERONE, SP				SCHACHTERLE, SD; PERONE, SP			CLASSIFICATION OF VOLTAMMETRIC DATA BY COMPUTERIZED PATTERN-RECOGNITION	ANALYTICAL CHEMISTRY			English	Review									PURDUE UNIV,DEPT CHEM,W LAFAYETTE,IN 47907							ANDERSON JL, 1976, CHEM INSTRUM, V7, P25; BEYERLEI.FH, 1972, ANAL CHEM, V44, P1647, DOI 10.1021/ac60317a007; BOUDREAU PA, 1978, THESIS PURDUE U W LA; BRIGHAM EO, 1974, FAST FOURIER TRANSFO, pCH8; Brown E.R., 1971, PHYS METHODS CHEM 2A, pChapter; BURGARD DR, 1978, ANAL CHEM, V50, P1366, DOI 10.1021/ac50031a043; BYERS WA, 1980, ANAL CHEM, V52, P2173, DOI 10.1021/ac50063a041; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS DG, 1966, ANAL CHEM, V38, P179, DOI 10.1021/ac60234a007; DEPALMA RA, 1979, ANAL CHEM, V51, P825, DOI 10.1021/ac50043a012; DEPALMA RA, 1979, ANAL CHEM, V51, P829, DOI 10.1021/ac50043a013; FERRIER DR, 1973, J ELECTROANAL CHEM, V45, P343, DOI 10.1016/S0022-0728(73)80045-2; FUKANAGA K, 1972, INTRO STATISTICAL PA; GOTO M, 1979, J ELECTROANAL CHEM, V102, P49, DOI 10.1016/0368-1874(79)87301-3; HAYES JW, 1973, ANAL CHEM, V45, P277; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KOWALSKI BR, 1974, COMPUT CHEM BIOCH RE, V2, P1; LAM KWL, 1974, THESIS WAYNE STATE U; MIAW LHL, 1978, ANAL CHEM, V50, P1988, DOI 10.1021/ac50036a016; MIAW LHL, 1979, ANAL CHEM, V51, P1645, DOI 10.1021/ac50047a015; NICHOLSO.RS, 1965, ANAL CHEM, V37, P1351, DOI 10.1021/ac60230a016; Nicholson R.S., 1972, COMPUTERS CHEMISTRY, V2, P119; NICHOLSON RS, 1964, ANAL CHEM, V36, P706, DOI 10.1021/ac60210a007; Nilsson Nils J., 1965, LEARNING MACHINES; OLMSTEAD ML, 1966, ANAL CHEM, V38, P150, DOI 10.1021/ac60233a049; PICHLER MA, 1974, ANAL CHEM, V46, P1790, DOI 10.1021/ac60348a012; REINMUTH WH, 1957, J AM CHEM SOC, V79, P6358, DOI 10.1021/ja01581a004; RYAN D, 1977, J ELECTROANAL CH INF, V79, P105; Saveant J. M., 1965, ELECTROCHIM ACTA, V10, P905, DOI 10.1016/0013-4686(65)80003-2; SCHACHTERLE SD, 1980, THESIS PURDUE U W LA; STAPELFE.HE, 1969, ANAL CHEM, V41, P623, DOI 10.1021/ac60273a008; SYBRANDT LB, 1972, ANAL CHEM, V44, P2331, DOI 10.1021/ac60322a009; Tamamushi R., 1975, KINETIC PARAMETERS E; TANAKA N, 1975, PURE APPL CHEM, V44, P627, DOI 10.1351/pac197544030627; THOMAS QV, 1977, ANAL CHEM, V49, P1369, DOI 10.1021/ac50017a021; THOMAS QV, 1976, ANAL CHEM, V48, P761, DOI 10.1021/ac60368a042; THOMAS QV, 1977, ANAL CHEM, V49, P1376, DOI 10.1021/ac50017a022; Varmuza K., 1980, ANAL CHIM ACTA, V122, P227, DOI 10.1016/S0003-2670(01)83219-0; WOPSCHAL.RH, 1967, ANAL CHEM, V39, P1514, DOI 10.1021/ac50156a018; ZIPPER JJ, 1973, ANAL CHEM, V45, P452, DOI 10.1021/ac60325a013	40	24	24	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0003-2700		ANAL CHEM	Anal. Chem.		1981	53	11					1672	1678		10.1021/ac00234a028		7	Chemistry, Analytical	Chemistry	MD381	WOS:A1981MD38100031	
J	DEVROYE, L				DEVROYE, L			ON THE ALMOST EVERYWHERE CONVERGENCE OF NONPARAMETRIC REGRESSION FUNCTION ESTIMATES	ANNALS OF STATISTICS			English	Article										DEVROYE, L (reprint author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2K6,QUEBEC,CANADA.						BENNETT G, 1962, J AM STAT ASSOC, V57, P33, DOI 10.2307/2282438; COLLOMB G, 1981, INT STAT REV, V49, P75, DOI 10.2307/1403039; Collomb G., 1976, THESIS U P SABATIER; COLLOMB G, 1977, CR HEBD ACAD SCI, V285, P282; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1978, SOCS7810 MCGILL U SC; DEVROYE LP, 1980, Z WAHRSCHEINLICHKEIT, V51, P15, DOI 10.1007/BF00533813; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; DEVROYE LP, 1978, IEEE T INFORM THEORY, V24, P142, DOI 10.1109/TIT.1978.1055865; FIX E, 1951, 4 SCH AV MED REP; Glick N., 1974, UTILITAS MATHEMATICA, V6, P61; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; Gyorfi L., 1981, Problems of Control and Information Theory, V10; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Marcinkiewicz J., 1937, FUND MATH, V29, P60; NADARAYA EA, 1965, THEOR PROBAB APPL+, V10, P186, DOI 10.1137/1110024; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; Petrov W, 1975, SUMS INDEPENDENT RAN; Revesz P., 1979, Problems of Control and Information Theory, V8; SCHUSTER E, 1979, ANN STAT, V7, P139, DOI 10.1214/aos/1176344560; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Watson G.S., 1964, SANKHYA A, V26, P359; Wheeden R. L., 1977, MEASURE INTEGRAL	25	97	103	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 6 3401 INVESTMENT BLVD, HAYWARD, CA 94545	0090-5364		ANN STAT	Ann. Stat.		1981	9	6					1310	1319		10.1214/aos/1176345647		10	Statistics & Probability	Mathematics	MS215	WOS:A1981MS21500016	
J	DEVROYE, L				DEVROYE, L			ON THE ASYMPTOTIC PROBABILITY OF ERROR IN NONPARAMETRIC DISCRIMINATION	ANNALS OF STATISTICS			English	Article										DEVROYE, L (reprint author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2K6,QUEBEC,CANADA.						BUCHNER P, 1951, ELEM MATH, V6, P8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, P INT S STATISTICS R; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; Feller W., 1968, INTRO PROBABILITY TH; FIX E, 1951, 4 SCH AV MED REP; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, UNPUBLISHED; Mitrinovic D. S., 1970, ANAL INEQUALITIES; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Wheeden R. L., 1977, MEASURE INTEGRAL	15	16	16	INST MATHEMATICAL STATISTICS	HAYWARD	IMS BUSINESS OFFICE-SUITE 6 3401 INVESTMENT BLVD, HAYWARD, CA 94545	0090-5364		ANN STAT	Ann. Stat.		1981	9	6					1320	1327		10.1214/aos/1176345648		8	Statistics & Probability	Mathematics	MS215	WOS:A1981MS21500017	
J	LIN, H; KSIENSKI, AA				LIN, H; KSIENSKI, AA			OPTIMUM FREQUENCIES FOR AIRCRAFT CLASSIFICATION	IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS			English	Article									OHIO STATE UNIV,DEPT ELECT ENGN,ELECTROSCI LAB,COLUMBUS,OH 43212	LIN, H (reprint author), HARRIS CORP,DIV GOVT INFORMAT SYST,POB 37,MELBOURNE,FL 32901, USA.						COVER TM, 1977, IEEE T SYSTEMS MAN C, V7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; ELASHOFF JD, 1967, BIOMETRIKA, V54; GOGGINS WB, 159 AFCRLTR0126 SPEC; GOGGINS WB, 1973, THESIS AIR FORCE I T; KENNAUGH EM, 1965, PR INST ELECTR ELECT, V53, P893, DOI 10.1109/PROC.1965.4068; KSIENSKI AA, 1975, P IEEE, V63, P1651, DOI 10.1109/PROC.1975.10033; LEWIS RM, 1969, IEEE T ANTENN PROPAG, VAP17, P308, DOI 10.1109/TAP.1969.1139417; MOFFATT DL, 1968, 24151 OH STAT U EL L; Repjar A. G., 1975, Radio and Electronic Engineer, V45; Van Trees H. L., 1968, DETECTION ESTIMATI 1; WHITE LJ, 1974, PATTERN RECOGN, V6, P35, DOI 10.1016/0031-3203(74)90006-5	13	12	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9251		IEEE T AERO ELEC SYS	IEEE Trans. Aerosp. Electron. Syst.		1981	17	5					656	665		10.1109/TAES.1981.309097		10	Engineering, Aerospace; Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	ML315	WOS:A1981ML31500007	
J	GYORFI, L				GYORFI, L			THE RATE OF CONVERGENCE OF KN-NN REGRESSION ESTIMATES AND CLASSIFICATION RULES	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Letter										GYORFI, L (reprint author), TECH UNIV BUDAPEST,H-1111 BUDAPEST,HUNGARY.						Beck J., 1979, Problems of Control and Information Theory, V8; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, UNPUBLISHED; Federer H., 1969, GEOMETRIC MEASURE TH; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; Gyorfi L., 1981, Problems of Control and Information Theory, V10; GYORFI L, 1977, TOPICS INFORMATION T, P298; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	10	21	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory		1981	27	3					362	364		10.1109/TIT.1981.1056344		3	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	LV070	WOS:A1981LV07000015	
J	SHORT, RD; FUKUNAGA, K				SHORT, RD; FUKUNAGA, K			THE OPTIMAL DISTANCE MEASURE FOR NEAREST NEIGHBOR CLASSIFICATION	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	SHORT, RD (reprint author), SPERRY RES CTR,100 N RD,SUDBURY,MA 01776, USA.						BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; FRASER DA, 1957, NONPARAMETRIC METHOD, pCH4; FUKUNAGA K, 1976, INTRO STATISTICAL PA, pCH6; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; SHORT RD, 1980, 5TH INT C PATT REC M, P81; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	8	98	98	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory		1981	27	5					622	627		10.1109/TIT.1981.1056403		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	ML782	WOS:A1981ML78200010	
J	DEVROYE, L				DEVROYE, L			ON THE INEQUALITY OF COVER AND HART IN NEAREST NEIGHBOR DISCRIMINATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article										DEVROYE, L (reprint author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3C 3G1,QUEBEC,CANADA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; Glick N., 1974, UTILITAS MATHEMATICA, V6, P61; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Wheeden R. L., 1977, MEASURE INTEGRAL	6	35	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					75	78				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	LK116	WOS:A1981LK11600008	
J	YOUNG, TY; LIU, PS; RONDON, RJ				YOUNG, TY; LIU, PS; RONDON, RJ			STATISTICAL PATTERN-CLASSIFICATION WITH BINARY VARIABLES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article										YOUNG, TY (reprint author), UNIV MIAMI,DEPT ELECT ENGN,CORAL GABLES,FL 33124, USA.						ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827; Bahadur R.R., 1961, STUDIES ITEM ANAL PR, P158; CHIEN YT, 1968, INFORM CONTR, V12, P395; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHOW CK, 1966, IEEE T SYST SCI CYB, VSSC2, P101; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GOOD IJ, 1963, ANN MATH STAT, V34, P911, DOI 10.1214/aoms/1177704014; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KU HH, 1969, IEEE T INFORM THEORY, V15, P444, DOI 10.1109/TIT.1969.1054336; KUGUNAGA K, 1971, IEEE T COMPUT, V20, P1521; MOORE DH, 1973, J AM STAT ASSOC, V68, P399; NORDYKE RA, 1971, COMPUT BIOMED RES, V4, P374, DOI 10.1016/0010-4809(71)90022-X; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATRICK EA, 1974, IEEE T SYST MAN CYB, VSMC4, P1; SCHEINOK PERRY A., 1967, COMPUT BIO MED RES, V1, P221, DOI 10.1016/S0010-4809(67)80010-7; STOFFEL JC, 1974, IEEE T COMPUT, VC 23, P428, DOI 10.1109/T-C.1974.223958; TOU JT, 1967, COMPUTER INFORMATION, V2, P41; Watanabe S., 1965, 4 PRAG C INF THEOR, P635; WONG AKC, 1975, IEEE T COMPUT, VC 24, P158, DOI 10.1109/T-C.1975.224183; Young T. Y., 1974, CLASSIFICATION ESTIM; YOUNG TY, 1980, IEEE T SOFTWARE ENG, V6, P340, DOI 10.1109/TSE.1980.234490; YOUNG TY, 1978, IEEE T INFORM THEORY, V24, P152; YOUNG TY, 1971, IEEE T COMPUT, VC 20, P967, DOI 10.1109/T-C.1971.223390	24	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					155	163				9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	MN968	WOS:A1981MN96800005	
J	COLLOMB, G				COLLOMB, G			NONPARAMETRIC-ESTIMATION OF REGRESSION - BIBLIOGRAPHICAL SURVEY	INTERNATIONAL STATISTICAL REVIEW			French	Review										COLLOMB, G (reprint author), UNIV PAUL SABATIER,STAT PROBABIL LAB,F-31062 TOULOUSE,FRANCE.						AHMAD IA, 1976, B MATH STAT, V17, P63; Aizerman M., 1970, AM MATH SOC TRANSL, V87, P281; BENEDETTI J, 1975, 8TH P COMP SCI STAT, P405; BENEDETTI JK, 1977, J ROY STAT SOC B MET, V39, P248; BHATTACHARYA PK, 1961, SANKHYA A, V23, P91; BICKEL PJ, 1973, ANN STAT, V1, P1071, DOI 10.1214/aos/1176342558; BICKEL PJ, 1969, ANN MATH STAT, V40, P1523, DOI 10.1214/aoms/1177697370; BLEUEZ J, 1978, ANN I H POINCARE, V14, P479; BLUM JR, 1954, ANN MATH STAT, V25, P382, DOI 10.1214/aoms/1177728794; Bochner S., 1955, HARMONIC ANAL THEORY; BORDET JP, 1973, THESIS U PARIS 6; BOSQ D, 1970, PUBLIC I STATIT U PA, V19; BOSQ D, 1979, PUBLICATION INT UER, P1; BREIMAN L, 1976, J AM STAT ASSOC, V71, P301, DOI 10.2307/2285301; BRENOT J, 1975, PRATIQUE REGRESSION; BRETAGNOLLE J, 1978, ESTIMATION DENSITES; Buldakov V. M., 1977, Problems of Information Transmission, V13; BUTLER GA, 1975, 8TH P COMP SCI STAT, P398; CACOULLOS T, 1973, DISCRIMINANT ANAL AP; CAZES P, 1976, REV STAT APPL, V24, P5; Cencov NN, 1962, SOV MATH, V3, P1559; CLARK RM, 1977, J ROY STAT SOC B MET, V39, P107; COLLOMB G, 1980, CR ACAD SCI A MATH, V291, P427; COLLOMB G, 1977, C R ACAD SCI PARIS A, V285, P289; COLLOMB G, 1979, LECT NOTES MATH, V821, P159; Collomb G., 1976, THESIS U P SABATIER; COLLOMB G, UNPUBLISHED; COLLOMB G, 1979, CR ACAD SCI A MATH, V289, P245; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox D. R., 1977, Mathematische Operationsforschung und Statistik, V8; DEHEUVEL.P, 1974, CR ACAD SCI A MATH, V278, P1217; DEHEUVELS P, 1979, ESTIMATION SEQUENTIE, P156; DEMICHEAUX D, 1978, THESIS U NICE; DEVROYE LP, 1978, SOCS7810 MCGILL U TE; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; DEVROYE LP, UNPUBLISHED; DEVROYE LP, 1978, IEEE T INFORM THEORY, V24, P142, DOI 10.1109/TIT.1978.1055865; DEVROYE LP, 1979, CAN J STAT, V6, P179; DUHAMEL C, 1978, REV STATISTIQUE ANAL, P47; FISHER L, 1976, SIAM J CONTROL, V14, P95, DOI 10.1137/0314007; FIX E, 1951, 2149004 PROJ; FRALICK SC, 1977, IEEE T INFO THEORY, V17, P440; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; FRYER, 1977, J I MATH APPLIC, V20, P335; GASSER T, 1979, LECTURE NOTES MATH, V757; GEFFROY J, 1975, 1974 1975 SEM STAT M; HABBEMA JDF, 1976, COMPSTAT 1976; KOMLOS J, 1975, Z WAHRSCHEINLICHKEIT, V32, P111, DOI 10.1007/BF00533093; KONAKOV VD, 1977, THEOR PROBAB APPL+, V22, P858; KONAKOV VD, 1973, J MULT ANAL, V5, P454; LEBEAUX MO, 1974, THESIS U PARIS 6; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MAHALANOBIS PC, 1961, SANKHYA SER A, V23, P41; MAJOR P, 1975, STUDIA SCI MATH HUNG, V8, P347; MONNEZ JM, UNPUBLISHED; NADARAYA EA, 1965, THEOR PROBAB APPL+, V10, P186, DOI 10.1137/1110024; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; NADARAYA EA, 1970, THEOR PROBAB APPL+, V15, P134, DOI 10.1137/1115015; NODA K, 1976, ANN I STAT MATH, V28, P221, DOI 10.1007/BF02504741; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pearson K., 1903, BIOMETRIKA, V2, P357, DOI 10.1093/biomet/2.4.357; PENKOV B, 1978, 11TH EUR M STAT OSL; PERENNOU G, 1973, 4EME JOURN COMM PARL; PIEDNOIR JL, 1977, CETHEDEC PARIS; PRIESTLE.MB, 1972, J ROY STAT SOC B, V34, P385; QUIDEL P, 1978, CR ACAD SCI A MATH, V286, P647; RETALI MB, 1977, PUBLIC I STATIST U P, V22, P1; REVESZ P, 1978, NONPARAMETRIC ESTIMA; Revesz P., 1973, STUD SCI MATH HUNG, V8, P391; REVESZ P, 1976, ANN PROBAB, V4, P729, DOI 10.1214/aop/1176995981; Revesz P., 1977, Mathematische Operationsforschung und Statistik, V8; ROBBINS H, 1964, ANN MATH STATIST, V34, P284; Rosenblatt M., 1969, MULTIVARIATE ANALYSI, P25; Rosenblatt M., 1956, ANN MATH STAT, V27, P642; ROSENBLATT M, 1976, ANN PROBAB, V4, P1009, DOI 10.1214/aop/1176995945; ROYALL RM, 1966, THESIS STANFORD U; RUSCHENDORF L, UNPUBLISHED; SABATON C, 1977, CAHIERS ANAL DONNEES, V2, P79; SABRY H, 1978, CR ACAD SCI A MATH, V286, P941; SCHLEE W, 1979, NONPARAMETRIC ESTIMA; SCHUSTER E, 1979, ANN STAT, V7, P139, DOI 10.1214/aos/1176344560; SCHUSTER EF, 1972, ANN MATH STAT, V43, P84, DOI 10.1214/aoms/1177692703; SILVERMAN BW, 1978, ANN STAT, V6, P177, DOI 10.1214/aos/1176344076; SINGH RS, 1977, J ROY STAT SOC B MET, V39, P357; SINGH RS, 1977, Z WAHRSCHEINLICHKEIT, V40, P339, DOI 10.1007/BF00533087; SPIELGELMAN G, 1980, ANN STATIST, V8, P240; STONE CJ, 1976, 8TH P COMP SCI STAT, P413; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tapia R. A., 1978, NONPARAMETRIC PROBAB; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TUKEY JW, 1961, 4TH P BERK S, P681; VANRYZIN J, 1966, SANKHYA SER A, V28, P261; VANRYZIN J, 1967, 4TH T PRAG C INF THE; VANRYZIN J, 1977, P ADV SEMINARY CONDU; VANRYZIN J, 1977, ANN STAT, V5, P172; WAHBA G, 1978, J ROY STAT SOC B MET, V40, P364; WAHBA G, 1975, COMMUN STAT, V4, P1; WAHBA G, 1976, J ROY STAT SOC B MET, V38, P140; WANDL H, 1980, 41ST SCI SESS STOCH; Watson G.S., 1964, SANKHYA A, V26, P359; WERTZ W, 1978, STATISTICAL DENSITY; WOLD S, 1974, TECHNOMETRICS, V16, P1, DOI 10.2307/1267485; YAMATO H, 1971, B MATH STAT, V14, P1	104	90	90	INT STATISTICAL INST	VOORBURG	428 PRINSES BEATRIXLAAN, 2270 AZ VOORBURG, NETHERLANDS	0306-7734		INT STAT REV	Int. Stat. Rev.		1981	49	1					75	93		10.2307/1403039		19	Statistics & Probability	Mathematics	LQ166	WOS:A1981LQ16600006	
J	KOPLOWITZ, J; BROWN, TA				KOPLOWITZ, J; BROWN, TA			ON THE RELATION OF PERFORMANCE TO EDITING IN NEAREST NEIGHBOR RULES	PATTERN RECOGNITION			English	Article									GE,SYRACUSE,NY 13221	KOPLOWITZ, J (reprint author), CLARKSON COLL TECHNOL,POTSDAM,NY 13676, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P696, DOI 10.1109/TIT.1973.1055059; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	7	27	27	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1981	13	3					251	255		10.1016/0031-3203(81)90102-3		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	LM680	WOS:A1981LM68000008	
J	TAKIYAMA, R				TAKIYAMA, R			A 2-LEVEL COMMITTEE MACHINE - A REPRESENTATION AND A LEARNING PROCEDURE FOR GENERAL PIECEWISE LINEAR DISCRIMINANT FUNCTIONS	PATTERN RECOGNITION			English	Article										TAKIYAMA, R (reprint author), KYUSHU INST DESIGN,DEPT VISUAL COMMUN DESIGN,MINAMI KU,FUKUOKA 815,JAPAN.						ABLOW CM, 1965, IEEE T INFORM THEORY, V11, P453, DOI 10.1109/TIT.1965.1053785; AMARI S, 1967, IEEE TRANS ELECTRON, VEC16, P299, DOI 10.1109/PGEC.1967.264665; CADZOW JA, 1968, IEEE T COMPUT, VC 17, P1165, DOI 10.1109/TC.1968.226882; CHANG CL, 1973, IEEE T COMPUT, VC 22, P859; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANCALANGIA JL, 1969, THESIS U WASHINGTON; MANGASAR.OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; NILSSON NJ, 1965, LEARNING MACHINES F; OSBORNE M, 1977, IEEE T COMPUT, V26, P1302; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; RIDGWAY WC, 1962, 15561 STANF U STANF; TAKIYAMA R, 1978, PATTERN RECOGN, V10, P27, DOI 10.1016/0031-3203(78)90045-6; TAKIYAMA R, 1978, PATTERN RECOGN, V10, P255, DOI 10.1016/0031-3203(78)90034-1; TAKIYAMA R, 1980, PATTERN RECOGN, V12, P75, DOI 10.1016/0031-3203(80)90005-9; WEAVER CS, 1975, IEEE T COMPUT, VC 24, P290, DOI 10.1109/T-C.1975.224209; Young T. Y., 1974, CLASSIFICATION ESTIM	16	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1981	13	3					269	274		10.1016/0031-3203(81)90104-7		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	LM680	WOS:A1981LM68000010	
J	LEVINSON, SE				LEVINSON, SE			A NOTE ON SOME STATISTICAL ASPECTS OF SPEAKER-INDEPENDENT RECOGNITION OF ISOLATED WORDS USING CLUSTERING-TECHNIQUES - REPLY	IEEE TRANSACTIONS ON ACOUSTICS SPEECH AND SIGNAL PROCESSING			English	Letter										LEVINSON, SE (reprint author), BELL TEL LABS INC,DEPT ACOUST RES,MURRAY HILL,NJ 07974.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LEVINSON SE, 1978, J ACOUST SOC AM, V64, pS180, DOI 10.1121/1.2004058; LEVINSON SE, 1975, 4TH P IJCAI TBIL; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; NADAS A, 1981, IEEE T ACOUST SPEECH, V29, P449, DOI 10.1109/TASSP.1981.1163578; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; WILKS SS, 1962, MATHEMATICAL STATIST, P234; YUNCK TP, 1980, IEEE T PATTERN ANAL, V2, P420	8	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0096-3518		IEEE T ACOUST SPEECH			1981	29	3					450	452		10.1109/TASSP.1981.1163593		3	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	LV080	WOS:A1981LV08000017	
J	COCHRANE, TT; JONES, PG				COCHRANE, TT; JONES, PG			SAVANNAS, FORESTS AND WET SEASON POTENTIAL EVAPO-TRANSPIRATION IN TROPICAL SOUTH-AMERICA	TROPICAL AGRICULTURE			English	Article										COCHRANE, TT (reprint author), CTR INT AGR TROP,APARTADO AEREO 67-13,CALI,COLOMBIA.						BARR HJ, 1976, USERS GUIDE SAS, V76, P184; COCHRANE TT, 1980, IEEE CAT, V80, P227; COCHRANE TT, 1979, EXPLANATORY MANUAL C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EITEN G, 1972, BOT REV, V38, P201, DOI 10.1007/BF02859158; EYRE SR, 1968, VEGETATION SOILS WOR, P195; GOODLAND R, 1970, MCGILL U SAVANNA RES, V15; HARGREAVES GH, 1972, IRRIG DRAINAGE SPEC, V273, P290; HARGREAVES GH, 1977, AIDTAC1103 CONTR, P2; 1979, 1979 CIAT CTR INT AG	10	4	4	TROPICAL AGRICULTURE	TRINIDAD	UNIV WEST INDIES FAC OF AGRICULTURE ST AUGUSTINE, TRINIDAD, WEST INDIES	0041-3216		TROP AGR	Trop. Agric.		1981	58	3					185	190				6	Agriculture, Multidisciplinary	Agriculture	LW404	WOS:A1981LW40400001	
J	GERSCH, W; MARTINELLI, F; YONEMOTO, J; LOW, MD; MCEWEN, JA				GERSCH, W; MARTINELLI, F; YONEMOTO, J; LOW, MD; MCEWEN, JA			A KULLBACK LEIBLER NEAREST NEIGHBOR RULE CLASSIFICATION OF EEGS - THE EEG POPULATION SCREENING PROBLEM, AN ANESTHESIA LEVEL EEG CLASSIFICATION APPLICATION	COMPUTERS AND BIOMEDICAL RESEARCH			English	Article									VANCOUVER GEN HOSP,DEPT ELECTROENCEPHALOG,VANCOUVER V5Z 1M9,BC,CANADA	GERSCH, W (reprint author), UNIV HAWAII,DEPT INFORMAT & COMP SCI,HONOLULU,HI 96822, USA.						COVER TM, 1969, METHODOLOGIES PATTER; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GERSCH W, 1978 ASA P VOLUME; GERSCH W, UNPUBLISHED; GERSCH W, 1977, COMPUT BIOMED RES, V10, P113, DOI 10.1016/0010-4809(77)90029-5; GEVINS A, IEEE T PATTERN RECOG; GEVINS AS, 1975, P IEEE, V63, P1382, DOI 10.1109/PROC.1975.9966; GLICK N, 1977, SAMPLE MEAN ITS OBSE; GRAY RM, IEEE T ACOUSTICS SPE; KELLAWAY P, 1973, AUTOMATION CLIN ELEC; MCEWEN JA, 1975, THESIS U BRIT COLUMB; MCEWEN JA, 1975, IEEE T BIO-MED ENG, VBM22, P299, DOI 10.1109/TBME.1975.324448; MOSTELLER F, 1968, HDB SOCIAL PSYCHOL, V2, P133; Ozaki T., 1975, 8th Hawaii International Conference on System Sciences; ROGERS WH, 1976, THESIS STANFORD U; WALTER DO, 1967, ELECTROEN CLIN NEURO, V22, P22, DOI 10.1016/0013-4694(67)90005-3	16	6	6	ACADEMIC PRESS INC JNL-COMP SUBSCRIPTIONS	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495	0010-4809		COMPUT BIOMED RES	Comput. Biomed. Res.		1980	13	3					283	296		10.1016/0010-4809(80)90022-1		14	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	JY012	WOS:A1980JY01200006	
J	GARDNER, WA				GARDNER, WA			A UNIFYING VIEW OF 2ND-ORDER MEASURES OF QUALITY FOR SIGNAL CLASSIFICATION	IEEE TRANSACTIONS ON COMMUNICATIONS			English	Article										GARDNER, WA (reprint author), UNIV CALIF DAVIS,DEPT ELECT & COMP ENGN,SIGNAL & IMAGE PROCESSING LAB,DAVIS,CA 95616, USA.						ALGAZI VR, 1965, PR INST ELECTR ELECT, V53, P725, DOI 10.1109/PROC.1965.3996; BAKER CR, 1969, IEEE T INFORM THEORY, V15, P16, DOI 10.1109/TIT.1969.1054267; BAKER CR, 1966, IEEE T COMMUN TECHN, VCO14, P802, DOI 10.1109/TCOM.1966.1089403; CAPON J, 1964, IEEE T INFORM THEORY, V10, P152, DOI 10.1109/TIT.1964.1053664; CHEN C, 1973, STATISTICAL PATTERN; CHERNOFF H, 1971, JAN P INT C FRONT PA, P55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; DEVIJVER PA, PATTERN RECOGNITION, pCH2; Devijver P. A., 1973, 1st International Joint Conference on Pattern Recognition; Duda R., 1973, PATTERN CLASSIFICATI; EPSTEIN B, 1970, LINEAR FUNCTIONAL AN; FEINTUCH PL, 1976, IEEE T COMMUN, V24, P913, DOI 10.1109/TCOM.1976.1093394; FISHER L, 1973, J AM STAT ASSOC, V68, P603, DOI 10.2307/2284785; Fisher R. A., 1950, CONTRIBUTIONS MATH S; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUKUNAGA K, 1972, INTRO STATISTICAL PA; FUKUNAGA K, 1968, IEEE T INFORM THEORY, V14, P780, DOI 10.1109/TIT.1968.1054204; FUKUNAGA K, 1977, IEEE T INFORM THEORY, V23, P453, DOI 10.1109/TIT.1977.1055755; GARDNER WA, 1979, IEEE T INFORM THEORY, V25, P743, DOI 10.1109/TIT.1979.1056100; GARDNER WA, 1976, IEEE T COMMUN, V24, P578, DOI 10.1109/TCOM.1976.1093340; GARDNER WA, 1976, IEEE T COMMUN, V24, P917, DOI 10.1109/TCOM.1976.1093388; GARDNER WA, 1976, JUN IEEE INT S INF T, P144; GARDNER WA, 1973, IEEE T INFORM THEORY, V19, P240, DOI 10.1109/TIT.1973.1054968; GEORGE DA, 1965, IEEE T INFORM THEORY, V11, P153, DOI 10.1109/TIT.1965.1053716; KANEFSKY M, 1966, IEEE T INFORM THEORY, V12, P260, DOI 10.1109/TIT.1966.1053870; KASSAM SA, 1978, IEEE T COMMUN, V26, P124, DOI 10.1109/TCOM.1978.1093976; KOFORD JS, 1966, IEEE T INFORM THEORY, V12, P42, DOI 10.1109/TIT.1966.1053856; Lawson J. L, 1950, THRESHOLD SIGNALS; Meisel W, 1972, COMPUTER ORIENTED AP; MIDDLETON D, 1962, J ACOUST SOC AM, V34, P1598, DOI 10.1121/1.1909059; MODESTINO JW, 1977, IEEE T COMMUN, V25, P1022, DOI 10.1109/TCOM.1977.1093931; Nilsson Nils J., 1965, LEARNING MACHINES; PATTERSO.JD, 1966, IEEE T SYST SCI CYB, VSSC2, P62, DOI 10.1109/TSSC.1966.300080; PICINBON.B, 1966, IEEE T INFORM THEORY, V12, P256, DOI 10.1109/TIT.1966.1053869; POOR HV, 1978, 12TH P ANN C INF SCI; POULSEN RS, 1977, THESIS U CALIFORNIA; PRICE R, 1960, MIT234 LINC LAB TECH; PRICE R, 1965, MIT388 LINC LAB TECH; RUBIN J, 1967, J THEOR BIOL, V15, P103, DOI 10.1016/0022-5193(67)90046-X; RUDNICK P, 1962, NATURE, V193, P604, DOI 10.1038/193604a0; Sebestyen G. S., 1962, DECISION MAKING PROC; SMITH SE, 1972, IEEE T INFORM THEORY, V18, P673, DOI 10.1109/TIT.1972.1054882; SOM A, 1972, IEEE T SYST MAN CYB, VSMC2, P439; TURIN GL, 1976, P IEEE, V64, P1092, DOI 10.1109/PROC.1976.10274; Van Trees H. L., 1968, DETECTION ESTIMATI 1; Van Trees H. L., 1971, DETECTION ESTIMATI 3; VENETSAN.AN, 1971, IEEE T COMMUN TECHN, VCO19, P649, DOI 10.1109/TCOM.1971.1090724; VENETSAN.AN, 1971, IEEE T INFORM THEORY, V17, P753, DOI 10.1109/TIT.1971.1054711; WEE WG, 1968, IEEE T COMPUT, VC 17, P1157, DOI 10.1109/TC.1968.226881	50	29	29	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0090-6778		IEEE T COMMUN	IEEE Trans. Commun.		1980	28	6					807	816		10.1109/TCOM.1980.1094735		10	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	JV346	WOS:A1980JV34600004	
J	VASSEUR, CPA; POSTAIRE, JG				VASSEUR, CPA; POSTAIRE, JG			A CONVEXITY TESTING METHOD FOR CLUSTER-ANALYSIS	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Letter										VASSEUR, CPA (reprint author), UNIV LILLE 1,CTR AUTOMAT,F-59650 VILLENEUVE DASCQ,FRANCE.						CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; COOPER PW, 1969, METHODOLOGY PATTERN, P97; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EAGEN DJ, 1974, IEEE T SYST MAN CYBE, V4, P284; EGGLESTON HG, 1963, CAMBRIDGE TRACTS MAT; KANAL L, 1974, IEEE T INFORM THEORY, V20; KOONTZ WLG, 1976, IEEE T COMPUT, V25, P936; Papoulis A, 1965, PROBABILITY RANDOM V; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; 1976, 3RD 4TH P INT JOINT	10	18	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1980	10	3					145	149				5	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	JN999	WOS:A1980JN99900004	
J	BENBASSAT, M				BENBASSAT, M			MULTI-MEMBERSHIP AND MULTI-PERSPECTIVE CLASSIFICATION - INTRODUCTION, APPLICATIONS, AND A BAYESIAN MODEL	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Letter									UNIV SO CALIF,SCH MED,INST CRIT CARE MED,LOS ANGELES,CA 90027; TEL AVIV UNIV,FAC MANAGEMENT,TEL AVIV,ISRAEL	BENBASSAT, M (reprint author), UNIV SO CALIF,SCH MED,DIV CRIT CARE MED,LOS ANGELES,CA 90027, USA.						ADIZES I, 1976, CALIF MANAGE REV, V19, P5; BENBASSAT M, 1976, MULTIMEMBERSHIP PATT; BENBASSAT M, 1977, PATTERN RECOGN, V9, P99, DOI 10.1016/0031-3203(77)90021-8; BENBASSAT M, 1977, 1ST P INT S DAT AN I; BENBASSAT M, 1976, 3RD P INT JOINT C PA; BENBASSAT M, 1978, IEEE T COMPUT, V27, P170; BENBASSAT M, 1980, IEEE T PATTERN ANAL, V2, P148; BENBASSAT M, 1978, IEEE T COMPUT, V27, P746; CARDILO GP, 1967, INT J MATH BIOSCIENC, V1, P463; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEGROOT MH, 1970, OPTIMAL STATISTICAL, P121; FLEHINGER B, 1975, IBM J RES DEV    NOV, P557; FREEDY A, 1975, 1975 P IEEE C DEC CO; Fu K. S., 1974, SYNTACTIC METHODS PA; Fu K. S., 1976, Digital pattern recognition; FUKUNAGA K, 1972, INTRO STATISTICAL PA; MAKESHWARI SN, 1976, IEEE T COMPUTERS, V25, P228; PREPARAT.FP, 1967, IEEE TRANS ELECTRON, VEC16, P848, DOI 10.1109/PGEC.1967.264747	19	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1980	10	6					331	336				6	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	KB126	WOS:A1980KB12600007	
J	SOM, A; DAS, TK; TALUKDER, AK; NATH, AK				SOM, A; DAS, TK; TALUKDER, AK; NATH, AK			ON A METHOD OF SELECTION OF REPRESENTATIVE PATTERNS USING BINARY DISTANCE MATRIX	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Article									JADAVPUR UNIV,DEPT ELECTR & TELECOMMUN ENGN,CALCUTTA 700032,INDIA; JADAVPUR UNIV,APPL ECON UNIT,CALCUTTA 700032,INDIA	SOM, A (reprint author), BKC COLL,DEPT PHYS,CALCUTTA 700035,INDIA.						BEAKLEY GW, 1972, IEEE T COMPUT, VC 21, P1337, DOI 10.1109/T-C.1972.223505; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sebestyen G. S., 1962, DECISION MAKING PROC; SOM A, 1972, IEEE T COMPUT, VC 21, P1433, DOI 10.1109/T-C.1972.223520; TOMEK I, 1972, COMPUT BIOMED RES, V5, P621, DOI 10.1016/0010-4809(72)90042-0; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	13	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1980	10	8					524	529				6	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	KH948	WOS:A1980KH94800016	
J	DUBUISSON, B; LAVISON, P				DUBUISSON, B; LAVISON, P			SURVEILLANCE OF A NUCLEAR-REACTOR BY USE OF A PATTERN-RECOGNITION METHODOLOGY	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Article										DUBUISSON, B (reprint author), UNIV TECHNOL COMPIEGNE,CONTROL SYST LAB,F-60206 COMPIEGNE,FRANCE.						CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1977, R346 MBLE RES LAB RE; EPANECHN.VA, 1969, THEOR PROBAB APPL+, V14, P153, DOI 10.1137/1114019; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GONZALEZ RC, 1974, IEEE T NUCL SCI, VNS21, P750, DOI 10.1109/TNS.1974.4327544; GONZALEZ RC, 1977, IEEE T SYST MAN CYB, V7, P717, DOI 10.1109/TSMC.1977.4309606; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MOZGALEVSKII AV, 1978, AUTOMATIKA TELEMEKHA, V1, P145; Nadaraya E. A., 1974, Theory of Probability and Its Applications, V19, DOI 10.1137/1119010; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAU LF, 1974, IEEE T RELIAB, VR 23, P202; ROSENBLA.M, 1971, ANN MATH STAT, V42, P1815, DOI 10.1214/aoms/1177693050; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SINGH RS, 1977, ANN STAT, V5, P394, DOI 10.1214/aos/1176343805; WAGNER TJ, 1975, IEEE T INFORM THEORY, V21, P438, DOI 10.1109/TIT.1975.1055408; WOODROOF.M, 1970, ANN MATH STAT, V41, P1665, DOI 10.1214/aoms/1177696810	17	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1980	10	10					603	609		10.1109/TSMC.1980.4308364		7	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	KW194	WOS:A1980KW19400002	
J	KWAN, WO; KOWALSKI, BR				KWAN, WO; KOWALSKI, BR			PATTERN-RECOGNITION ANALYSIS OF GAS-CHROMATOGRAPHIC DATA - GEOGRAPHIC CLASSIFICATION OF WINES OF VITIS-VINIFERA CV PINOT-NOIR FROM FRANCE AND THE UNITED-STATES	JOURNAL OF AGRICULTURAL AND FOOD CHEMISTRY			English	Article									UNIV WASHINGTON,DEPT CHEM,CHEMOMETR LAB,SEATTLE,WA 98195							AMERINE MA, 1954, ADV FOOD RES, V5, P353, DOI 10.1016/S0065-2628(08)60226-8; BRANDER CF, 1974, AM J ENOL VITICULT, V25, P13; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HARPER AM, 1977, ARTHUR EXPT DATA ANA; KOWALSKI BR, 1976, PATTERN RECOGN, V8, P1, DOI 10.1016/0031-3203(76)90023-6; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KWAN WO, 1978, J FOOD SCI, V43, P1320, DOI 10.1111/j.1365-2621.1978.tb15299.x; KWAN WO, 1979, J AGR FOOD CHEM, V27, P1321, DOI 10.1021/jf60226a039; SAKATO KH, 1975, AM J ENOL VITICULT, V26, P70; STERN DJ, 1967, J AGR FOOD CHEM, V15, P1100, DOI 10.1021/jf60154a028; VANWYK CJ, 1967, J FOOD SCI, V32, P660; WEBB AD, 1976, BIOTECHNOL BIOENG, V18, P939, DOI 10.1002/bit.260180707; WEBB A. DINSMOOR, 1967, AMER J ENOL VITICULT, V18, P190; Webb A. D., 1972, Advances in Applied Microbiology, V15, P75, DOI 10.1016/S0065-2164(08)70090-X; WEBB AD, 1969, AM J ENOL VITICULT, V20, P16; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	16	63	64	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0021-8561		J AGR FOOD CHEM	J. Agric. Food Chem.		1980	28	2					356	359		10.1021/jf60228a029		4	Agriculture, Multidisciplinary; Chemistry, Applied; Food Science & Technology	Agriculture; Chemistry; Food Science & Technology	JJ877	WOS:A1980JJ87700035	
J	HENRY, DR; BLOCK, JH				HENRY, DR; BLOCK, JH			PATTERN-RECOGNITION OF STEROIDS USING FRAGMENT MOLECULAR CONNECTIVITY	JOURNAL OF PHARMACEUTICAL SCIENCES			English	Article									OREGON STATE UNIV,SCH PHARM,CORVALLIS,OR 97331							ANDREWS DF, 1972, BIOMETRICS, V28, P125, DOI 10.2307/2528964; ANDREWS DF, 1973, DISCRIMINANT ANAL AP, P37; CAMMARATA A, 1976, J MED CHEM, V19, P739, DOI 10.1021/jm00228a001; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUTTING WC, 1972, CUTTINGS HDB PHARMAC; DIXON WJ, 1977, BMDP BIOCH COMPUTE P, P711; DUNN WJ, 1978, J MED CHEM, V21, P1001, DOI 10.1021/jm00208a001; DUNN WJ, 1978, J MED CHEM, V21, P922, DOI 10.1021/jm00207a015; EISENBEIS R, 1972, DISCRIMINANT ANAL CL; FIX E, 1951, 4 US SCH AV MED REP; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FULLERTON DC, 1977, TXB ORGANIC MED PHAR, P731; GNANADESIKAN R, 1977, METHODS STATISTICAL, P203; GREEN MJ, 1976, ANNU REP MED CHEM, V11, P149, DOI 10.1016/S0065-7743(08)61399-8; HARPER AM, 1977, CHEMOMETRICS THEORY, P14; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HENRY DR, 1979, J MED CHEM, V22, P465, DOI 10.1021/jm00191a002; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KIER LB, 1977, EUR J MED CHEM, V12, P307; LACHENBRUCH PA, 1975, DISCRIMINANT ANAL, P40; MARTIN YC, 1977, QUANTITATIVE DRUG DE; MENON GK, 1977, J PHARM SCI, V66, P304, DOI 10.1002/jps.2600660303; Nilsson Nils J., 1965, LEARNING MACHINES; STUPER AJ, 1978, J PHARM SCI, V67, P745, DOI 10.1002/jps.2600670604; TOU JT, 1974, PATTERN RECOGNITION, P181; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wold S, 1977, CHEMOMETRICS THEORY, P243	27	8	8	AMER PHARMACEUTICAL ASSN	WASHINGTON	2215 CONSTITUTION AVE NW, WASHINGTON, DC 20037	0022-3549		J PHARM SCI	J. Pharm. Sci.		1980	69	9					1030	1034		10.1002/jps.2600690913		5	Chemistry, Medicinal; Chemistry, Multidisciplinary; Pharmacology & Pharmacy	Pharmacology & Pharmacy; Chemistry	KG725	WOS:A1980KG72500012	
J	CHITTINENI, CB				CHITTINENI, CB			LEARNING WITH IMPERFECTLY LABELED PATTERNS	PATTERN RECOGNITION			English	Article										CHITTINENI, CB (reprint author), LOCKHEED ELECTR CO INC,DIV SYST & SERV,HOUSTON,TX 77058, USA.						CHITTINENI CB, 1973, IEEE T SYST MAN CYBE, P290; CHITTINENI CB, 1972, 6TH P ANN PRINC C IN; Chitti Babu C., 1973, International Journal of Computer & Information Sciences, V2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1964, AUG WESCON CONV LOS; GIMLIN DR, 1974, IEEE T SYSTEMS MAN C, P304; KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532; KASHYAP RL, 1966, PR INST ELECTR ELECT, V54, P1127, DOI 10.1109/PROC.1966.5051; SHANMUGAM K, 1971, IEEE T SYST MAN CYBE, P223; SKLANSKY J, 1968, TP682 U CAL SCH ENG; WHITNEY AW, 1966, 4 P ANN ALL C CIRC S, P96; WILKS S, 1963, MATH STATISTICS	12	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1980	12	5					281	291		10.1016/0031-3203(80)90026-6		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	KQ905	WOS:A1980KQ90500002	
J	SRIHARI, SN; SNABB, T; WHITE, LJ				SRIHARI, SN; SNABB, T; WHITE, LJ			AN ALGORITHM FOR DETERMINING IDENTITY OF NEAREST-NEIGHBOR AND POTENTIAL FUNCTION DECISION RULES	PATTERN RECOGNITION			English	Article									UNIV MICHIGAN,DEPT MATH & STAT,DEARBORN,MI 48128; OHIO STATE UNIV,DEPT COMP & INFORMAT SCI,COLUMBUS,OH 43210	SRIHARI, SN (reprint author), SUNY BUFFALO,DEPT COMP SCI,AMHERST,NY 14226, USA.						AIZERMANN MA, 1969, METHODOLOGIES PATTER, P1; BASHKIROV DA, 1964, AUTOMN REMOTE CONTRO, V25, P629; BATCHELO.BG, 1973, INFORM SCIENCES, V5, P171, DOI 10.1016/0020-0255(73)90011-X; Bentley J., 1976, 8TH P ANN ACM S THEO, P220; COVER TM, 1976, COMMUNICATIONS CYBER, V10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; FIX E, 1977, MACHINE RECOGNITION; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; Shamos M. I., 1975, 16TH P IEEE S F COMP, P151, DOI 10.1109/SFCS.1975.8; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; SRIHARI SN, 1979, INFORM SCIENCES, V19, P21, DOI 10.1016/0020-0255(79)90030-6; SRIHARI SN, 1978, MAY P IEEE COMP SOC, P173; ZOLNOWSKY JE, 1978, SLAC206 STANF U REP	14	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1980	12	5					293	299		10.1016/0031-3203(80)90027-8		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	KQ905	WOS:A1980KQ90500003	
J	RICHETIN, M; RIVES, G; NARANJO, M				RICHETIN, M; RIVES, G; NARANJO, M			THE USE OF RAPID ALGORITHM DEDUCTION IN ASCERTAINING THE K NEAREST NEIGHBORS	RAIRO-INFORMATIQUE-COMPUTER SCIENCE			French	Article										RICHETIN, M (reprint author), UNIV CLERMONT FERRAND 2,CNRS,EQUIPE RECH 90,LERM,F-63170 AUBIERE,FRANCE.						Batchelor B. G., 1974, PRACTICAL APPROACH P; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1977, THESIS U PARIS 6; DEVIJVER PA, 1979, R410 MBLE PHIL RES L; DEVIJVER PA, 1978, PATTERN RECOGN, V10, P297, DOI 10.1016/0031-3203(78)90039-0; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HAND DJ, 1978, INFORM SCIENCES, V14, P171, DOI 10.1016/0020-0255(78)90040-3; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KITTLER J, 1978, KYBERNETES, V7, P313, DOI 10.1108/eb005497; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	14	2	2	GAUTHIER-VILLARS	PARIS CEDEX O6	120 BLVD SAINT-GERMAIN, 75280 PARIS CEDEX O6, FRANCE	0752-4072		RAIRO-INF-COMPUT SCI			1980	14	4					369	378				10	Computer Science, Information Systems; Information Science & Library Science	Computer Science; Information Science & Library Science	LF185	WOS:A1980LF18500003	
J	SJOSTROM, M; KOWALSKI, BR				SJOSTROM, M; KOWALSKI, BR			COMPARISON OF 5 PATTERN-RECOGNITION METHODS BASED ON THE CLASSIFICATION RESULTS FROM 6 REAL DATA-BASES	ANALYTICA CHIMICA ACTA-COMPUTER TECHNIQUES AND OPTIMIZATION			English	Article									UNIV WASHINGTON,DEPT CHEM,CHEMOMETR LAB,SEATTLE,WA 98195	SJOSTROM, M (reprint author), UNIV UMEA,DEPT CHEM,CHEMOMETR RES GRP,S-90187 UMEA,SWEDEN.						Albano C., 1978, ANAL CHIM ACTA-COMP, V103, P429, DOI 10.1016/S0003-2670(01)83107-X; BOX GEP, 1973, BAYESIAN INTERFERENC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUEWER DL, 1975, ANAL CHEM, V47, P1573, DOI 10.1021/ac60359a051; Fisher RA, 1936, ANN EUGENIC, V7, P179; GRAY NAB, 1976, ANAL CHEM, V48, P2265, DOI 10.1021/ac50008a054; HARPER AM, 1977, AM CHEM SOC S SER; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KOWALSKI BR, 1975, ANAL CHEM, V47, P1152; KOWALSKI BR, 1976, PATTERN RECOGN, V8, P1, DOI 10.1016/0031-3203(76)90023-6; KOWALSKI BR, 1972, ANAL CHEM, V44, P2176, DOI 10.1021/ac60321a002; KOWALSKI BR, 1973, J AM CHEM SOC, V95, P686, DOI 10.1021/ja00784a007; KOWALSKI BR, 1974, COMPUTERS CHEM BIOL, V2; MCGILL JR, 1978, J CHEM INF COMP SCI, V18, P52, DOI 10.1021/ci60013a012; MECKE R, 1960, CHEM BER-RECL, V93, P210, DOI 10.1002/cber.19600930132; NIE N, 1975, SPSS STATISTICAL PAC; Nilsson Nils J., 1965, LEARNING MACHINES; SJOSTROM M, 1977, J MAGN RESON, V25, P285, DOI 10.1016/0022-2364(77)90023-3; STOTHERS JB, 1975, J MAGN RESON, V20, P570, DOI 10.1016/0022-2364(75)90016-5; ULFVARSSON U, 1977, J WORK ENV HLTH, V3, P183; WEISEL CP, 1977, ANAL CHEM, V49, P2114, DOI 10.1021/ac50021a055; WOLD S, 1977, AM CHEM SOC S SER; WOLD S, SIMCA 2T MANUAL; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; WOLD S, TECHNOMETRICS; WOLD S, 1978, CORRELATION ANAL CHE; WONG AKC, 1975, IEEE T COMPUT, VC 24, P158, DOI 10.1109/T-C.1975.224183	27	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA-COMP			1979	3	1					11	30				20	Chemistry, Analytical; Engineering, Electrical & Electronic	Chemistry; Engineering	GT961	WOS:A1979GT96100002	
J	DEPALMA, RA; PERONE, SP				DEPALMA, RA; PERONE, SP			ONLINE PATTERN-RECOGNITION OF VOLTAMMETRIC DATA - PEAK MULTIPLICITY CLASSIFICATION	ANALYTICAL CHEMISTRY			English	Review									PURDUE UNIV,DEPT CHEM,W LAFAYETTE,IN 47907							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GABRIELLI C, 1977, ELECTROCHIM ACTA, V22, P255, DOI 10.1016/0013-4686(77)85070-6; HAYES JW, 1973, ANAL CHEM, V45, P277; HORLICK G, 1972, ANAL CHEM, V44, P943, DOI 10.1021/ac60314a014; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; LAMY C, 1975, J ELECTROANAL CHEM, V59, P113, DOI 10.1016/S0022-0728(75)80027-1; MEITES L, 1958, ANAL CHIM ACTA, V18, P364, DOI 10.1016/S0003-2670(00)87158-5; NICHOLSO.RS, 1965, ANAL CHEM, V37, P1351, DOI 10.1021/ac60230a016; NICHOLSON RS, 1964, ANAL CHEM, V36, P706, DOI 10.1021/ac60210a007; THOMAS QV, 1977, ANAL CHEM, V49, P1369, DOI 10.1021/ac50017a021; THOMAS QV, 1976, THESIS PURDUE U; THOMAS QV, 1976, ANAL CHEM, V48, P761, DOI 10.1021/ac60368a042; THOMAS QV, 1977, ANAL CHEM, V49, P1376, DOI 10.1021/ac50017a022	13	12	12	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0003-2700		ANAL CHEM	Anal. Chem.		1979	51	7					825	828		10.1021/ac50043a012		4	Chemistry, Analytical	Chemistry	GW661	WOS:A1979GW66100017	
J	RABINER, LR; LEVINSON, SE; ROSENBERG, AE; WILPON, JG				RABINER, LR; LEVINSON, SE; ROSENBERG, AE; WILPON, JG			SPEAKER-INDEPENDENT RECOGNITION OF ISOLATED WORDS USING CLUSTERING TECHNIQUES	IEEE TRANSACTIONS ON ACOUSTICS SPEECH AND SIGNAL PROCESSING			English	Article										RABINER, LR (reprint author), BELL TEL LABS INC,DEPT ACOUST RES,MURRAY HILL,NJ 07974, USA.						Ball G. H., 1965, P IFIPS C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fraser D. A. S., 1957, NONPARAMETRIC METHOD; GOLD B, 1966, 452 MASS I TECH RES; GUPTA VN, 1978, IEEE T ACOUST SPEECH, V26, P27, DOI 10.1109/TASSP.1978.1163054; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; LEVINSON SE, UNPUBLISHED; LEVINSON SE, 1978, AT&T TECH J, V57, P1619; LOFTSGAARDEN DO, 1965, ANN MATH STATIST, V36; MACQUEEN J, 1967, 5TH P BERK S PROB ST; MARTIN TB, 1976, P IEEE, V64, P487, DOI 10.1109/PROC.1976.10157; Patrick E. A., 1972, FUNDAMENTALS PATTERN; PATRICK EA, 1941, FUNDAMENTALS PATTERN, P12; PATRICK EA, 1970, INFORM CONTR, V16; RABINER LR, 1977, IEEE T ACOUST SPEECH, V25, P434, DOI 10.1109/TASSP.1977.1162987; RABINER LR, 1978, IEEE T ACOUST SPEECH, V26, P34, DOI 10.1109/TASSP.1978.1163037; RABINER LR, 1978, IEEE T ACOUST SPEECH, V26; ROSENBERG AE, 1976, J ACOUST SOC AM, V60, pS12, DOI 10.1121/1.2003178; ROSENBERG AE, 1977, J ACOUST SOC AM   S1, V62, P563; SAKOE H, 1971, P INT C ACOUSTICS BU; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SAMBUR MR, 1976, IEEE T ACOUST SPEECH, V24, P550, DOI 10.1109/TASSP.1976.1162879; SAMBUR MR, 1975, AT&T TECH J, V54, P81; Scott P. B., 1976, 1976 IEEE International Conference on Acoustics, Speech and Signal Processing; SHEARME JN, 1968, IEEE T ACOUST SPEECH, VAU16, P256, DOI 10.1109/TAU.1968.1161985; Tou J.T., 1974, PATTERN RECOGNITION; TRIBOLET JM, UNPUBLISHED; WILKS SS, ANN MATH STATIST	29	79	79	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0096-3518		IEEE T ACOUST SPEECH			1979	27	4					336	349		10.1109/TASSP.1979.1163259		14	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	HJ002	WOS:A1979HJ00200004	
J	DEVROYE, LP; WAGNER, TJ				DEVROYE, LP; WAGNER, TJ			DISTRIBUTION-FREE INEQUALITIES FOR THE DELETED AND HOLDOUT ERROR ESTIMATES	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article									RICE UNIV,DEPT ELECT ENGN,HOUSTON,TX 77001	DEVROYE, LP (reprint author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3C 3G1,QUEBEC,CANADA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1976, IEEE T INFORM THEORY, V22, P586, DOI 10.1109/TIT.1976.1055604; DEVROYE LP, 1977, 1977 P COMP SOC C PA, P323; DEVROYE LP, 1976, 183 U TEX INF SYST R; Feller W., 1968, INTRO PROBABILITY TH, V1; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; ROGERS C. A., 1963, MATHEMATIKA, V10, P157; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; Roussas G. G., 1973, 1 COURSE MATH STAT; VAPNIK VN, 1971, AUTOMAT REM CONTR+, V32, P207	10	23	23	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory		1979	25	2					202	207		10.1109/TIT.1979.1056032		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	GL039	WOS:A1979GL03900008	
J	GOWDA, KC; KRISHNA, G				GOWDA, KC; KRISHNA, G			CONDENSED NEAREST NEIGHBOR RULE USING THE CONCEPT OF MUTUAL NEAREST NEIGHBORHOOD	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Note									INDIAN INST SCI,SCH AUTOMAT,BANGALORE 560012,INDIA	GOWDA, KC (reprint author), SRI JAYACHAMARAJENDRA COLL ENGN,DEPT ELECTR ENGN,MYSORE 570006,INDIA.						COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1978, EE49 IND I SCI DEP E; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; GOWDA KC, 1977, EE43 IND I SCI DEP E; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SWONGER CW, 1971, JAN INT C FRONT PATT; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769	12	37	39	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory		1979	25	4					488	490		10.1109/TIT.1979.1056066		3	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	HC934	WOS:A1979HC93400019	
J	DEVIJVER, PA				DEVIJVER, PA			NEW ERROR BOUNDS WITH THE NEAREST NEIGHBOR RULE	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Letter										DEVIJVER, PA (reprint author), PHILIPS RES LAB,2 AV VAN BECELAERE,B-1170 BRUSSELS,BELGIUM.						COVER TM, 1969, METHODOLOGIES PATTER, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1977, THESIS U PARIS 6; DEVIJVER PA, 1978, 4TH P INT C PATT REC, P217; DEVIJVER PA, 1978, PATTERN RECOGN, V10, P297, DOI 10.1016/0031-3203(78)90039-0; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P434, DOI 10.1109/TIT.1973.1055049; GARNETT JM, 1977, IEEE T COMPUT, V26, P46; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410	12	12	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory		1979	25	6					749	753		10.1109/TIT.1979.1056099		5	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	HW433	WOS:A1979HW43300022	
J	PENROD, CS; WAGNER, TJ				PENROD, CS; WAGNER, TJ			RISK ESTIMATION FOR NONPARAMETRIC DISCRIMINATION AND ESTIMATION RULES - SIMULATION STUDY	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Letter										PENROD, CS (reprint author), UNIV TEXAS,DEPT ELECT ENGN,AUSTIN,TX 78712, USA.						COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1976, THESIS U TEXAS AUSTI; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; PENROD CS, 1976, THESIS U TEXAS AUSTI; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	9	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory		1979	25	6					753	758		10.1109/TIT.1979.1056101		6	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	HW433	WOS:A1979HW43300023	
J	PETTIS, KW; BAILEY, TA; JAIN, AK; DUBES, RC				PETTIS, KW; BAILEY, TA; JAIN, AK; DUBES, RC			INTRINSIC DIMENSIONALITY ESTIMATOR FROM NEAR-NEIGHBOR INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article										PETTIS, KW (reprint author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.						BALL GH, 1965, FAL P JOINT COMP C W, P533; BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; BREIMAN L, 1968, PROBABILITY, P237; CALVERT TW, 1970, IEEE T COMPUT, VC 19, P447, DOI 10.1109/T-C.1970.222943; CHANG CL, 1973, IEEE T SYST MAN CYB, VSMC3, P197; CHEN CK, 1974, IEEE T COMPUT, VC 23, P178; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis P. J., 1965, HDB MATH FUNCTIONS, P253; DUDA RO, 1973, PATTERN CLASSIFICATI, P87; FRIEDMAN JH, 1975, IEEE T COMPUT, V25, P1000; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; KRUSKAL JB, 1971, IEEE T COMPUT, VC 20, P1614, DOI 10.1109/T-C.1971.223184; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; KRUSKAL JB, 1972, MULTIDIMENSIONAL SCA, V1; KRUSKAL JB, 1969, MULTIVARIATE ANAL, P639; KRUSKAL JB, 1966, AT&T TECH J, V45, P1299; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; LEE RCT, 1977, IEEE T COMPUT, V26, P288; MULLER ME, 1959, COMMUN ACM, V2, P19, DOI 10.1145/377939.377946; ROMNEY AK, 1972, MULTIDIMENSIONAL SCA, V2; ROMNEY AK, 1972, MULTIDIMENSIONAL SCA, V1; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SCHWARTZMANN DH, 1975, IEEE T COMPUT, V24, P1175, DOI 10.1109/T-C.1975.224161; SHEPARD RN, 1974, PSYCHOMETRIKA, V39, P373, DOI 10.1007/BF02291665; Shepard RN, 1966, MULTIVARIATE ANAL, P561; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; TRUNK GV, 1976, IEEE T COMPUT, V25, P165; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	29	68	71	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					25	37				13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	HA303	WOS:A1979HA30300004	
J	SRIHARI, SN				SRIHARI, SN			RECURSIVE IMPLEMENTATION OF A 2-STEP NONPARAMETRIC DECISION RULE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									WAYNE STATE UNIV,COMP SCI SECT,DETROIT,MI 48202							COVER TM, 1976, COMMUNICATION CYBERN, V10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Forsythe G., 1977, COMPUTER METHODS MAT; FRALICK SC, 1971, IEEE T INFORM THEORY, V17, P440, DOI 10.1109/TIT.1971.1054663; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; MEISEL WS, 1969, IEEE T COMPUT, VC 18, P911, DOI 10.1109/T-C.1969.222546; MURTHY VK, 1965, ANN MATH STAT, V36, P1027, DOI 10.1214/aoms/1177700074; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; WAGNER TJ, 1975, IEEE T INFORM THEORY, V21, P438, DOI 10.1109/TIT.1975.1055408	11	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					90	94				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	HA303	WOS:A1979HA30300012	
J	ICINO, M				ICINO, M			NONPARAMETRIC MULTICLASS PATTERN CLASSIFIER	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS			English	Article										ICINO, M (reprint author), TOKYO DENKI UNIV,DEPT SYST ENGN,SAITAMA 35003,JAPAN.						Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; AIZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P1175; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DUDA RO, 1966, IEEE TRANS ELECTRON, VEC15, P220, DOI 10.1109/PGEC.1966.264302; Fu K, 1968, SEQUENTIAL METHODS P; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; HIGHLEYMAN WH, 1962, P IRE, V50, P1501, DOI 10.1109/JRPROC.1962.288194; ICHINO M, 1976, IEEE T SYST MAN CYB, V6, P256; KOFORD JS, 1966, IEEE T INFORM THEORY, V12, P42, DOI 10.1109/TIT.1966.1053856; MANGASAR.OL, 1968, IEEE T INFORM THEORY, V14, P801, DOI 10.1109/TIT.1968.1054229; Meisel W, 1972, COMPUTER ORIENTED AP; Nilsson Nils J., 1965, LEARNING MACHINES; SEBESTYE.G, 1966, IEEE TRANS ELECTRON, VEC15, P908, DOI 10.1109/PGEC.1966.264472; STOFFEL JC, 1974, IEEE T COMPUT, VC 23, P428, DOI 10.1109/T-C.1974.223958; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; WEE WG, 1968, IEEE T COMPUT, VC 17, P1157, DOI 10.1109/TC.1968.226881; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	20	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394	0018-9472		IEEE T SYST MAN CYB	IEEE Trans. Syst. Man Cybern.		1979	9	6					345	352				8	Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	GY304	WOS:A1979GY30400004	
J	SRIHARI, SN; WHITE, LJ; SNABB, T				SRIHARI, SN; WHITE, LJ; SNABB, T			IDENTITY CONDITIONS FOR NEAREST-NEIGHBOR AND POTENTIAL-FUNCTION CLASSIFIERS	INFORMATION SCIENCES			English	Article									OHIO STATE UNIV,DEPT COMP & INFORMAT SCI,COLUMBUS,OH 43210; UNIV MICHIGAN,DEPT MATH & STAT,DEARBORN,MI 48128	SRIHARI, SN (reprint author), SUNY BUFFALO,DEPT COMP SCI,BUFFALO,NY 14226, USA.						AIZERMANN MA, 1969, METHODOLOGIES PATTER, P1; BASHKIROV DA, 1964, AUTOMN REMOTE CONTRO, V25, P629; BATCHELO.BG, 1973, INFORM SCIENCES, V5, P171, DOI 10.1016/0020-0255(73)90011-X; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIX E, 1977, MACHINE RECOGNITION; MEISEL WS, 1972, COMPUTER ORIENTED AP, P98; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666	7	1	1	ELSEVIER SCIENCE INC	NEW YORK	655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010	0020-0255		INFORM SCIENCES	Inf. Sci.		1979	19	1					21	31		10.1016/0020-0255(79)90030-6		11	Computer Science, Information Systems	Computer Science	HK712	WOS:A1979HK71200002	
J	KWAN, WO; KOWALSKI, BR; SKOGERBOE, RK				KWAN, WO; KOWALSKI, BR; SKOGERBOE, RK			PATTERN-RECOGNITION ANALYSIS OF ELEMENTAL DATA - WINES OF VITIS-VINIFERA CV PINOT NOIR FROM FRANCE AND THE UNITED-STATES	JOURNAL OF AGRICULTURAL AND FOOD CHEMISTRY			English	Article									UNIV WASHINGTON,DEPT CHEM,CHEMOMETR LAB,SEATTLE,WA 98195; COLORADO STATE UNIV,DEPT CHEM,FT COLLINS,CO 80521							AMERINE MA, 1967, TECHNOLOGY WINE MAKI, P225; AMERINE MA, 1970, TABLE WINES TECHNOLO, P456; AMERINE M. A., 1958, Advances in Food Research, V8, P133; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUEWER DL, 1976, ARTHUR; HARPER AM, 1977, ARTHUR EXPT DATA ANA; JURS PC, 1975, CHEM APPLICATIONS PA; KOWALSKI BR, 1975, ANAL CHEM, V47, P1152; KOWALSKI BR, 1976, PATTERN RECOGN, V8, P1, DOI 10.1016/0031-3203(76)90023-6; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KWAN WO, 1978, J FOOD SCI, V43, P1320, DOI 10.1111/j.1365-2621.1978.tb15299.x; MCGILL JR, 1977, APPL SPECTROSC, V31, P87, DOI 10.1366/000370277774463922; POWERS JJ, 1968, J FOOD SCI, V33, P207, DOI 10.1111/j.1365-2621.1968.tb01351.x; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; WU LS, 1977, J FOOD SCI, V42, P944, DOI 10.1111/j.1365-2621.1977.tb12643.x; YOUNG LL, 1970, J FOOD SCI, V35, P219, DOI 10.1111/j.1365-2621.1970.tb12142.x	16	60	61	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036	0021-8561		J AGR FOOD CHEM	J. Agric. Food Chem.		1979	27	6					1321	1326		10.1021/jf60226a039		6	Agriculture, Multidisciplinary; Chemistry, Applied; Food Science & Technology	Agriculture; Chemistry; Food Science & Technology	HU809	WOS:A1979HU80900043	
J	ZLATKIS, A; LEE, KY; POOLE, CF; HOLZER, G				ZLATKIS, A; LEE, KY; POOLE, CF; HOLZER, G			CAPILLARY COLUMN GAS-CHROMATOGRAPHIC PROFILE ANALYSIS OF VOLATILE COMPOUNDS IN SERA OF NORMAL AND VIRUS-INFECTED PATIENTS	JOURNAL OF CHROMATOGRAPHY			English	Article										ZLATKIS, A (reprint author), UNIV HOUSTON,DEPT CHEM,HOUSTON,TX 77004, USA.						ANBAR M, 1976, CLIN CHEM, V22, P1503; BERTSCH W, 1974, CHROMATOGRAPHIA, V7, P128, DOI 10.1007/BF02269823; BULTITUDE FW, 1975, CLIN CHEM, V21, P1329; CHALMERS RA, 1976, CLIN CHEM, V22, P1292; CLARK HA, 1975, ANAL CHEM, V47, P374, DOI 10.1021/ac60353a059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIRREN H, 1975, CLIN CHEM, V21, P1970; ELDJARN L, 1975, CLIN CHEM, V21, P63; GOODMAN SI, 1977, J CHROMATOGR, V142, P497, DOI 10.1016/S0021-9673(01)92062-X; JELLUM E, 1977, J CHROMATOGR, V143, P427, DOI 10.1016/S0378-4347(00)81792-2; KITAGAWA T, 1975, CLIN CHEM, V21, P735; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; KROTOSZYNSKI B, 1977, J CHROMATOGR SCI, V15, P239; LEARY JJ, 1973, J CHROMATOGR SCI, V11, P201; LEE KY, 1978, J CHROMATOGR, V158, P377, DOI 10.1016/S0021-9673(00)89981-1; LIEBICH HM, 1975, CLIN CHEM, V21, P1294; LIEBICH HM, 1975, J CHROMATOGR, V112, P539, DOI 10.1016/S0021-9673(00)99983-7; LIEBICH HM, 1977, J CHROMATOGR, V142, P505, DOI 10.1016/S0021-9673(01)92063-1; MALCOLM RD, 1976, CLIN CHEM, V22, P623; MALYA PAG, 1971, J CHROMATOGR SCI, V9, P700; McLafferty F., 1974, REGISTRY MASS SPECTR; NOVOTNY M, 1974, J AGR FOOD CHEM, V22, P765, DOI 10.1021/jf60195a013; PETERSON DW, 1970, IEEE T INFORM THEORY, V14, P26; ROBINSON AB, 1976, EXP GERONTOL, V11, P11, DOI 10.1016/0531-5565(76)90005-X; ROBINSON AB, 1974, CLIN CHEM, V20, P962; STONER E, 1975, ANAL CHEM, V47, P344, DOI 10.1021/ac60352a004; TERANISH.R, 1972, ANAL CHEM, V44, P18, DOI 10.1021/ac60309a012; ZLATKIS A, 1976, J CHROMATOGR, V126, P475, DOI 10.1016/S0021-9673(01)84094-2; ZLATKIS A, 1973, ANAL CHEM, V45, P763, DOI 10.1021/ac60326a036; ZLATKIS A, 1973, Chromatographia, V6, P67, DOI 10.1007/BF02270540; 1974, 8 PEAK INDEX MASS SP	31	28	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0021-9673		J CHROMATOGR			1979	163	2					125	133		10.1016/S0378-4347(00)81455-3		9	Chemistry, Analytical	Chemistry	HD790	WOS:A1979HD79000001	
J	MACK, YP; ROSENBLATT, M				MACK, YP; ROSENBLATT, M			MULTIVARIATE K-NEAREST NEIGHBOR DENSITY ESTIMATES	JOURNAL OF MULTIVARIATE ANALYSIS			English	Article										MACK, YP (reprint author), UNIV CALIF SAN DIEGO,LA JOLLA,CA 92093, USA.						BREIMAN L, 1977, TECHNOMETRICS, V19, P135, DOI 10.2307/1268623; CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; FIX E, 1951, 4 USAF SCH AV MED RE; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MOORE DS, 1977, ANN STAT, V5, P143, DOI 10.1214/aos/1176343747; MOORE DS, 1977, STATISTICAL DECISION; ROSENBLA.M, 1971, ANN MATH STAT, V42, P1815, DOI 10.1214/aoms/1177693050; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; WAGNER TJ, 1975, IEEE T INFORM THEORY, V21, P438, DOI 10.1109/TIT.1975.1055408	12	88	88	ACADEMIC PRESS INC JNL-COMP SUBSCRIPTIONS	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495	0047-259X		J MULTIVARIATE ANAL	J. Multivar. Anal.		1979	9	1					1	15		10.1016/0047-259X(79)90065-4		15	Statistics & Probability	Mathematics	GW126	WOS:A1979GW12600001	
J	BYERS, WA; PERONE, SP				BYERS, WA; PERONE, SP			COMPUTERIZED PATTERN-RECOGNITION APPLIED TO NI-CD CELL LIFETIME PREDICTION	JOURNAL OF THE ELECTROCHEMICAL SOCIETY			English	Article										BYERS, WA (reprint author), PURDUE UNIV,DEPT CHEM,W LAFAYETTE,IN 47907, USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ELDER JP, 1969, J ELECTROCHEM SOC, V116, P687, DOI 10.1149/1.2412020; FUKUNAGA K, 1972, INTRO STATISTICAL PA, P341; Hartigan J., 1975, CLUSTERING ALGORITHM; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; PICHLER MA, 1974, ANAL CHEM, V46, P1790, DOI 10.1021/ac60348a012; SOMMERFELDT EE, 1977, X71177193 GSFC DOC; 1973, X76173183 NASAGSFC D	9	7	7	ELECTROCHEMICAL SOC INC	PENNINGTON	10 SOUTH MAIN STREET, PENNINGTON, NJ 08534	0013-4651		J ELECTROCHEM SOC	J. Electrochem. Soc.		1979	126	5					720	725		10.1149/1.2129127		6	Electrochemistry; Materials Science, Coatings & Films	Electrochemistry; Materials Science	GT757	WOS:A1979GT75700003	
J	HESS, CF; BRODDA, K				HESS, CF; BRODDA, K			OPTIMUM CHOICE OF CATEGORIES FOR THE CLASSIFICATION OF BIOMEDICAL DATA PATTERNS	METHODS OF INFORMATION IN MEDICINE			English	Article										HESS, CF (reprint author), UNIV MAINZ,INST PHYSIOL,D-6500 MAINZ,FED REP GER.						Anderson T. W., 1958, INTRO MULTIVARIATE S; ASH RB, 1965, INFORMATION THEORY; BLACKWELL D, 1954, THEORY GAMES STATIST; CATTANEO AD, 1974, METHOD INFORM MED, V13, P238; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CHU JT, 1967, J ACM, V14, P273, DOI 10.1145/321386.321390; CHU JT, 1965, J ACM, V12, P213, DOI 10.1145/321264.321271; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fu K, 1968, SEQUENTIAL METHODS P; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; HERMANS J, 1975, METHOD INFORM MED, V14, P87; HEYDORN RP, 1968, IEEE T INFORM THEORY, V14, P783, DOI 10.1109/TIT.1968.1054198; KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532; KLINGEMAN JACK, 1967, COMP BIOMED RES, V1, P1, DOI 10.1016/0010-4809(67)90003-1; KULLBACK S, 1959, INFORMATION THEORY S; LAINIOTI.DG, 1969, IEEE T INFORM THEORY, V15, P730, DOI 10.1109/TIT.1969.1054374; LOW DA, 1971, COMPUT BIOMED RES, V4, P561, DOI 10.1016/0010-4809(71)90067-X; MICHAELIS J, 1972, THESIS MAINZ; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; OKAJIMA M, 1963, IEEE T BIO-MED ENG, VBM10, P106, DOI 10.1109/TBMEL.1963.4322808; PIPBERGE.HV, 1968, METHOD INFORM MED, V7, P79; STARK L, 1962, COMM ACM, V5, P537; STARMER CF, 1976, COMPUT BIOMED RES, V9, P531, DOI 10.1016/0010-4809(76)90012-4; Young T. Y., 1974, CLASSIFICATION ESTIM; YOUNG TY, 1964, IEEE T BIO-MED ENG, VBM11, P60, DOI 10.1109/TBME.1964.4502308	25	2	2	F K SCHATTAUER VERLAG GMBH	STUTTGART	P O BOX 10 45 45, LENZHALDE 3, D-70040 STUTTGART, GERMANY	0026-1270		METHOD INFORM MED	Methods Inf. Med.		1979	18	4					222	227				6	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	HU040	WOS:A1979HU04000006	
J	FOWLER, HG				FOWLER, HG			SEED PREDATOR RESPONSES	OECOLOGIA			English	Article									UNIV NACL ASUNCION CIUDAD,INST CIENCIAS BASICAS,ASUNCION,PARAGUAY							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; JANZEN D H, 1971, Principes, V15, P89; JANZEN DH, 1970, AM NAT, V104, P501, DOI 10.1086/282687; JANZEN DH, ESCAPE SAPCE STERCUL; MORRISON D, 1976, MULTIVARIATE STATIST; SMITH CAB, 1947, ANN EUGENIC, V13, P272; WILSON DE, 1972, ECOLOGY, V53, P954, DOI 10.2307/1934315	7	2	2	SPRINGER VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010	0029-8549		OECOLOGIA	Oecologia		1979	41	3					361	363		10.1007/BF00377440		3	Ecology	Environmental Sciences & Ecology	HL350	WOS:A1979HL35000011	
J	PETERS, C				PETERS, C			FEATURE-SELECTION FOR BEST MEAN-SQUARE APPROXIMATION OF CLASS DENSITIES	PATTERN RECOGNITION			English	Article										PETERS, C (reprint author), UNIV HOUSTON,DEPT MATH,HOUSTON,TX 77004, USA.						BAHADUR RR, 1954, ANN MATH STAT, V25, P423, DOI 10.1214/aoms/1177728715; CHIEN YT, 1967, IEEE T INFORM THEORY, V15, P518; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIVIJVER PA, 1974, IEEE T             C, V23, P70; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FUKANAGA K, 1978, IEEE T, V24, P600; FUKANAGA K, 1976, 3RD P INT J C PATT R; FUKANAGA K, 1970, IEEE T             C, V19, P311; FUKANAGA K, 1972, INTRO STATISTICAL PA; KITTLER J, 1973, PATTERN RECOGN, V5, P335, DOI 10.1016/0031-3203(73)90025-3; KITTLER J, 1975, INT J MAN MACH STUD, V7, P609, DOI 10.1016/S0020-7373(75)80023-X	11	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB	0031-3203		PATTERN RECOGN	Pattern Recognit.		1979	11	5-6					361	364		10.1016/0031-3203(79)90048-7		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	HZ685	WOS:A1979HZ68500009	
