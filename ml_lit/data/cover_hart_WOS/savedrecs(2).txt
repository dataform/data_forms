PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	PU	PI	PA	SN	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT
J	Tang, YH; Gao, JH				Tang, Yaohua; Gao, Jinghuai			Improved classification for problem involving overlapping patterns	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						boundary pattern; rough set; classification; support vector machine		The support vector machine has received wide acceptance for its high generalization ability in real world classification applications. But a drawback is that it uniquely classifies each pattern to one class or none. This is not appropriate to be applied in classification problem involves overlapping patterns. In this paper, a novel multi-model classifier (DR-SVM) which combines SVM classifier with kNN algorithm under rough set technique is proposed. Instead of classifying the patterns directly, patterns lying in the overlapped region are extracted firstly. Then, upper and lower approximations of each class are defined on the basis of rough set technique. The classification operation is carried out on these new sets. Simulation results on synthetic data set and benchmark data sets indicate that, compared with conventional classifiers, more reasonable and accurate information about the pattern's category could be obtained by use of DR-SVM.	Xian Jiaotong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China	Tang, YH (reprint author), Xian Jiaotong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.	tangsl@mail.xjtu.edu.cn					Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; GRA G, 2002, FUNDAMENTA INFORM, V51, P369; Gunn S, 1998, SUPPORT VECTOR MACHI; KORM F, 2000, P ACM SIGMOD, P201; LINGRAS P, 2005, INF SCI, V172, P216; LINGRAS P, 2004, P NAFIPS 04 IEEE ANN, V2, P27; LINGRAS P, 2004, P N AM FUZZ INF PROC, P17; Lingras P, 2001, J INTELL INF SYST, V16, P215, DOI 10.1023/A:1011219918340; LINGRAS P, 2005, P IEEE INT C GRAN CO, V1, P193; Pawlak Z, 2004, LECT NOTES COMPUT SC, V3100, P1; Quinlan R., 1996, J ARTIFICIAL INTELLI, V4, P77; Vapnik VN, 2000, NATURE STAT LEARNING; WANG LS, 2005, P INT C MACH LEARN C, V3, P18; Xia C., 2004, P 30 INT C VER LARG, P756, DOI 10.1016/B978-012088469-8/50067-X; Xia CY, 2006, IEEE T KNOWL DATA EN, V18, P289; ZHANG B, 2006, P INT JOINT C NEUR N, P2583	18	4	5	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	NOV	2007	E90D	11					1787	1795		10.1093/ietisy/e90-d.11.1787		9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	235IK	WOS:000251226900007	
J	Ghosh, AK; Bose, S				Ghosh, Anil Kumar; Bose, Smarajit			Feature extraction for classification using statistical networks	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						artificial neural networks; backfitting; classification using splines; cross-validation; feature selection; projection pursuit regression	DISCRIMINANT-ANALYSIS; NEURAL-NETWORKS; PROJECTION PURSUIT; REGRESSION	In a classification problem, quite often the dimension of the measurement vector is large. Some of these measurements may not be important for separating the classes. Removal of these measurement variables not only reduces the computational cost but also leads to better understanding of class separability. There are some methods in the existing literature for reducing the dimensionality of a classification problem without losing much of the separability information. However, these dimension reduction procedures usually work well for linear classifiers. In the case where competing classes are not linearly separable, one has to look for ideal "features" which could be some transformations of one or more measurements. In this paper, we make an attempt to tackle both, the problems of dimension reduction and feature extraction, by considering a projection pursuit regression model. The single hidden layer perceptron model and some other popular models can be viewed as special cases of this model. An iterative algorithm based on backfitting is proposed to select the features dynamically, and cross-validation method is used to select the ideal number of features. We carry out an extensive simulation study to show the effectiveness of this fully automatic method.	[Ghosh, Anil Kumar] Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India; [Bose, Smarajit] Indian Stat Inst, Theoret Stat & Math Unit, Calcutta 700108, India	Ghosh, AK (reprint author), Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India.	anilkghosh@rediffmail.com; smarajit@isical.ac.in					Anderson T., 1984, INTRO MULTIVARIATE S; Bose S, 2003, COMPUT STAT DATA AN, V42, P685, DOI 10.1016/S0167-9473(02)00171-8; Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; BOSE S, 1992, THESIS U CALIFORNIA; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Breiman L, 1984, CLASSIFICATION REGRE; BREIMAN L, 1993, COMPUT STAT DATA AN, V15, P13, DOI 10.1016/0167-9473(93)90217-H; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristiani N, 2000, INTRO SUPPORT VECTOR; de Boor C., 1978, PRACTICAL GUIDE SPLI; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FIX E, 1951, 2149004 RAND FIELD; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Fukunaga K., 1990, INTRO STAT PATTERN R; Ghosh AK, 2005, BERNOULLI, V11, P1, DOI 10.3150/bj/1110228239; Ghosh AK, 2004, COMPUTATION STAT, V19, P193, DOI 10.1007/BF02892056; Hand D. J., 1982, KERNEL DISCRIMINANT; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; Laarhoven P., 1987, SIMULATED ANNEALING; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mika S, 2000, ADV NEUR IN, V12, P526; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Ripley B. D., 1996, PATTERN RECOGNITION; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; ROOSEN CB, 1994, J COMPUTA GRAPHICAL, V3, P235, DOI 10.2307/1390909; Scholkopf S, 1999, ADV KERNEL METHODS S; Scott D. W., 1992, MULTIVARIATE DENSITY; Seber GAF, 1989, NONLINEAR REGRESSION; Silverman B.W., 1986, DENSITY ESTIMATION S; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Vapnik V.N., 1998, STAT LEARNING THEORY; Zhu M, 2003, J COMPUT GRAPH STAT, V12, P101, DOI 10.1198/1061860031220	43	5	5	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	NOV	2007	21	7					1103	1126		10.1142/S0218001407005855		24	Computer Science, Artificial Intelligence	Computer Science	242IY	WOS:000251720000001	
J	Morrison, D; De Silva, LC				Morrison, Donn; De Silva, Liyanage C.			Voting ensembles for spoken affect classification	JOURNAL OF NETWORK AND COMPUTER APPLICATIONS			English	Article; Proceedings Paper	3rd International Conference on Information Technology and Applications	JUL 04-07, 2005	Sydney, AUSTRALIA	IEEE NSW Sect, Univ Technol, FIT, Univ Technol, IICT		affect recognition; emotion recognition; ensemble methods; speech processing	EMOTION; SPEECH	Affect or emotion classification from speech has much to benefit from ensemble classification methods. In this paper we apply a simple voting mechanism to an ensemble of classifiers and attain a modest performance increase compared to the individual classifiers. A natural emotional speech database was compiled from 11 speakers. Listener-judges were used to validate the emotional content of the speech. Thirty-eight prosody-based features correlating characteristics of speech with emotional states were extracted from the data. A classifier ensemble was designed using a multi-layer perceptron, support vector machine, K* instance-based learner, K-nearest neighbour, and random forest of decision trees. A simple voting scheme determined the most popular prediction. The accuracy of the ensemble is compared with the accuracies of the individual classifiers. (c) 2006 Elsevier Ltd. All rights reserved.	Massey Univ, Inst Informat Sci & Technol, Palmerston North, New Zealand	De Silva, LC (reprint author), Massey Univ, Inst Informat Sci & Technol, Private Bag 11222, Palmerston North, New Zealand.	l.desilva@massey.ac.nz					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cleary J., 1995, ICML, P108; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWAN M, 1936, PITCH INTENSITY CHAR, P1; Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970; DEVILLERS L, 2002, ISLE WORKSH DIAL TAG; Fairbanks G, 1941, SPEECH MONOGR, V8, P85; Fairbanks G, 1939, SPEECH MONOGR, V6, P87; Fonagy I., 1981, RES ASPECTS SINGING, P51; FONAGY I, 1978, LANG SPEECH, V21, P34; FRICK RW, 1986, AGGRESSIVE BEHAV, V12, P121, DOI 10.1002/1098-2337(1986)12:2<121::AID-AB2480120206>3.0.CO;2-F; HAYKIN S, 1999, NEURAL NETWORKS COMP; HUBER R, 2000, INT C SPOK LANG PROC, V1, P665; MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; Petrushin V.A., 2000, P 6 INT C SPOK LANG; Picard R., 1997, AFFECTIVE COMPUTING; Platt J, 1998, ADV KERNEL METHODS S; POLZIN TS, 2000, ISCA WORKSH SPEECH E; Rabiner L., 1978, DIGITAL PROCESSING S; SCHERER KR, 1996, INT C SPOK LANG PROC; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Talkin D, 1995, SPEECH CODING SYNTHE, P495; Vapnik V.N., 1995, NATURE STAT LEARNING; WILLILAMS CE, 1972, NONVERBAL COMMUNICAT; YACOUB S, 2003, EUROSPEECH 2003	28	5	7	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1084-8045		J NETW COMPUT APPL	J. Netw. Comput. Appl.	NOV	2007	30	4					1356	1365		10.1016/j.jnca.2006.09.005		10	Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	217LN	WOS:000249949500009	
J	Koukal, T; Suppan, F; Schneider, W				Koukal, Tatjana; Suppan, Franz; Schneider, Werner			The impact of relative radiometric calibration on the accuracy of kNN-predictions of forest attributes	REMOTE SENSING OF ENVIRONMENT			English	Article; Proceedings Paper	Conference on Operational Tools in Forestry Using Remote Sensing Techniques (ForestSAT 2005)	MAY 31-JUN 03, 2005	Boras, SWEDEN	Swedish Forest Agcy		scene-to-scene radiometric normalisation; k-nearest-neighbour method; cross-validation; forest inventory; phenology	NORMALIZATION; INVENTORY; IMAGES; VOLUME	The k-nearest-neighbour (kNN) algorithm is widely applied for the estimation of forest attributes using remote sensing data. It requires a large amount of reference data to achieve satisfactory results. Usually, the number of available reference plots for the kNN-prediction is limited by the size of the area covered by a terrestrial reference inventory and remotely sensed imagery collected from one overflight. The applicability of kNN could be enhanced if adjacent images of different acquisition dates could be used in the same estimation procedure. Relative radiometric calibration is a prerequisite for this. This study focuses on two empirical calibration methods. They are tested on adjacent LANDSAT TM scenes in Austria. The first, quite conventional one is based on radiometric control points in the overlap area of two images and on the determination of transformation parameters by linear regression. The other, recently developed method exploits the kNN-cross-validation procedure. Performance and applicability of both methods as well as the impact of phenology are discussed. (C) 2007 Elsevier Inc. All rights reserved.	Univ Nat Resources & Appl Life Sci, Inst Survejing Remote Sensing & Land Informat, Dept Landscape Spatial & Infrastruct Sci, Vienna, Austria	Koukal, T (reprint author), Univ Nat Resources & Appl Life Sci, Inst Survejing Remote Sensing & Land Informat, Dept Landscape Spatial & Infrastruct Sci, Vienna, Austria.	tariana.koukal@boku.ac.at					Congalton R. G., 1999, ASSESSING ACCURACY R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Du Y, 2002, REMOTE SENS ENVIRON, V82, P123, DOI 10.1016/S0034-4257(02)00029-9; Efron B., 1993, MONOGRAPHS STAT APPL, V57; ELVIDGE CD, 1995, PHOTOGRAMM ENG REM S, V61, P1255; Fazakas Z, 1999, AGR FOREST METEOROL, V98-9, P417, DOI 10.1016/S0168-1923(99)00112-4; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HALL FG, 1991, REMOTE SENS ENVIRON, V35, P11, DOI 10.1016/0034-4257(91)90062-B; Katila M, 2001, REMOTE SENS ENVIRON, V76, P16, DOI 10.1016/S0034-4257(00)00188-7; KILKKI P, 1987, REMOTE SENSING AIDED, P209; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOUKAL T, 2004, THESIS U NATURAL RES; McRoberts RE, 2002, REMOTE SENS ENVIRON, V82, P457, DOI 10.1016/S0034-4257(02)00064-0; OVER M, 2003, P IEEE INT GEOSC RE; Richards J. A., 2006, REMOTE SENSING DIGIT; SANDMEIER S, 1995, PHYS BASED RADIOMET; SCHOTT JR, 1988, REMOTE SENS ENVIRON, V26, P1, DOI 10.1016/0034-4257(88)90116-2; Steinwendner J, 2001, DIGITAL IMAGE ANALYSIS: SELECTED TECHNIQUES AND APPLICATIONS, P337, DOI 10.1007/0-387-21643-X_16; Tomppo E., 1991, INT ARCH PHOTOGRAMME, V28, P419; Tomppo E, 2004, REMOTE SENS ENVIRON, V92, P1, DOI 10.1016/j.rse.2004.04.003; VERMOTE E, 1997, 2 U MAR DEP GEOGR	23	12	13	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0034-4257		REMOTE SENS ENVIRON	Remote Sens. Environ.	OCT 30	2007	110	4					431	437		10.1016/j.rse.2006.08.016		7	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	216QT	WOS:000249894800004	
J	Aluja-Banet, T; Daunis-I-Estadella, J; Pellicer, D				Aluja-Banet, Tomas; Daunis-i-Estadella, Josep; Pellicer, David			GRAFT, a complete system for data fusion	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						data fusion; statistical matching; imputation; k-nn	MISSING-DATA	Data fusion concerns the problem of merging information coming from independent sources. Also known as statistical matching, file grafting or microdata merging, it is a challenging problem for statisticians. The increasing growth of collected data makes combining different sources of information an attractive alternative to single source data. The interest in data fusion derives, in certain cases, from the impossibility of attaining specific information from one source of data and the reduction of the cost entailed by this operation and, in all cases, from taking greater advantage of the available collected information. The GRAFT system is presented. It is a multipurpose data fusion system based on the k-nearest neighbor (k-nn) hot deck imputation method. The system aim is to cope with many data fusion problems and domains. The k-nn is a very demanding algorithm. The solutions envisaged and their cost, which allow this methodology to be used in a wide range of real problems, are presented. (C) 2006 Elsevier B.V. All rights reserved.	[Aluja-Banet, Tomas] Univ Politecn Cataluna, E-08034 Barcelona, Spain; [Daunis-i-Estadella, Josep] Univ Girona, E-17071 Girona, Spain; [Pellicer, David] TNS Audiencia Medios, E-08173 Sant Cugat Del Valles, Spain	Aluja-Banet, T (reprint author), Univ Politecn Cataluna, Jordi Girona Salgado 1-3,CN C5204, E-08034 Barcelona, Spain.	tomas.aluja@upc.edu					Ahuja R. K., 1993, NETWORK FLOWS THEORY; ALUJA T, 2001, TRAITEMENT FICHIERS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fix E., 1951, 4 USAF SCH AV MED; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1975, IEEE T COMPUT C, V26, P917; Hastie T, 2001, ELEMENTS STAT LEARNI; LEJEUNE M, 1995, P 50 SESS ISI BEIJ, V56, P923; Little R. J. A., 1987, STAT ANAL MISSING DA; Marcello D'Orazio, 2006, STAT MATCHING THEORY; Papadimitriou C., 1982, COMBINATORIAL OPTIMI; Ripley B. D., 1996, PATTERN RECOGNITION; Rius R, 1999, APPL STOCH MODEL BUS, V15, P451, DOI 10.1002/(SICI)1526-4025(199910/12)15:4<451::AID-ASMB408>3.0.CO;2-C; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; SANTINI G, 2004, METHODE FUSION REFER; Schafer JL, 1998, MULTIVAR BEHAV RES, V33, P545, DOI 10.1207/s15327906mbr3304_5; TENNENHAUS M, 1998, REGRESSION PLS THEOR; WINKLER WE, 1995, WILEY S PRO, P355	19	4	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	OCT 15	2007	52	2					635	649		10.1016/j.csda.2006.11.029		15	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	265ND	WOS:000253365300003	
J	Angiulli, F				Angiulli, Fabrizio			Condensed nearest neighbor data domain description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; data domain description; data condensation; nearest neighbor rule; novelty detection	CLASSIFICATION	A simple yet effective unsupervised classification rule to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors' distances in a reference data set, assumed to model normal behavior, lie within a certain threshold. This work investigates the effect of using a subset of the original data set as the reference set of the classifier. With this aim, the concept of a reference-consistent subset is introduced and it is shown that finding the minimum-cardinality reference-consistent subset is intractable. Then, the Condensed Nearest Neighbor Domain Description (CNNDD) algorithm is described, which computes a reference-consistent subset with only two reference set passes. Experimental results revealed the advantages of condensing the data set and confirmed the effectiveness of the proposed approach. A thorough comparison with related methods was accomplished, pointing out the strengths and weaknesses of one-class nearest-neighbor-based training-set-consistent condensation.	Univ Calabria, Dipartimento Elettron Informat & Sistemist, I-87036 Arcavacata Di Rende, Italy	Angiulli, F (reprint author), Univ Calabria, Dipartimento Elettron Informat & Sistemist, Via P Bucci 41C, I-87036 Arcavacata Di Rende, Italy.	f.angiulli@deis.unical.it					Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); ANGIULLI F, 2005, P 22 INT C MACH LEAR, P7; Blake CL, 1998, UCI REPOSITORY MACHI; Breunig M., 2000, P ACM INT C MAN DAT; CERVERON V, 2001, IEEE T SYST MAN CYB, V31, P304; CHANG CC, 2001, LIBSVM LIB SUPORT VE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L, 1996, PROBABILISTIC THEORY; Eskin E., 2002, APPL DATA MINING COM; FIX E, 1951, 4 SCH AV MED US AIR; Floyd S, 1995, MACH LEARN, V21, P269, DOI 10.1007/BF00993593; Garey M. R., 1979, COMPUTER INTRACTABIL; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Littlestone N, 1986, RELATING DATA COMPRE; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Ritter G, 1997, PATTERN RECOGN LETT, V18, P525, DOI 10.1016/S0167-8655(97)00049-4; SCHOLKOPF B, 1999, 87 MICR RES REDM WAS; Scholkopf B., 1995, P INT C KNOWL DISC D, P251; STONE C, 1977, ANN STAT, V8, P1348; Tax D. M. J., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.906164; Tax D, 1999, P EUR S ART NEUR NET, P251; TAX DMJ, 2001, THESIS U TECHN DELFT; TOUSSAINT G, 2002, SOCS025 MCG U SCH CO; YPMA A, 1998, P INT CORP ASS NAM N	28	6	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1746	1758		10.1109/TPAMI.2007.1086		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	199LA	WOS:000248696100005	
J	Pateritsas, C; Stafylopatis, A				Pateritsas, Christos; Stafylopatis, Andreas			Memory-based classification with dynamic feature selection using self-organizing maps for pattern evaluation	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						classification; memory-based learning; self-organizing maps; feature weighting; hybrid systems	FEATURE SUBSET-SELECTION; NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	Memory-based learning is one of the main fields of machine learning. We Propose a new methodology for addressing the classification task that relies on the main idea of the k-nearest neighbors algorithm, which is the most important representative of this field. In the proposed approach, given an unclassified pattern, a set of neighboring patterns is found, not necessarily using all input feature dimensions. Also, following the concept of the naive Bayesian classifier, we adopt the assumption of independence of input features in the outcome of the classification task. The two concepts are merged in an attempt to take advantage of their good performance features. In order to further improve the performance of our approach, we propose a novel weighting scheme of the memory-base. Using the self-organizing maps model during the execution of the algorithm, dynamic weights of the memory-base patterns are produced. Experimental results have shown improved performance of the proposed method in comparison with the aforementioned algorithms and their variations.	Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15780 Athens, Greece	Pateritsas, C (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15780 Athens, Greece.	pater@softlab.ntua.gr; andreas@cs.ntua.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake C.L., UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEMIROZ G, 1997, P 9 EUR C MACH LEAR; GUNN S, 2003, NIPS FEATURE SELECTI; GUVENIR HA, 1997, P 12 INT S COMP INF; GUYON I, 2006, FEATURES EXTRACTION; HAMMERTON J, 2001, P C COMP NAT LANG LE, P9; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KASKI S, 1997, THESIS U TECHNOLOGY; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T, 1997, SELF ORGANIZING MAPS; KONONENKO I, 1992, INFORMATICA, V16, P1; Liu H., 1998, FEATURE EXTRACTION C; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; OH KS, 2002, P CHALL IM VID RETR, P299; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATERITSAS C, 2005, P INT C COMP INT MOD, V2, P781; PATERITSAS C, 2004, P IEEE INT C SYST MA, P4832; RAUBER A, 1999, P INT JOINT C NEUR N; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Salzberg S., 1991, MACH LEARN, V6, P277; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TONG X, 2004, P 3 INT C MACH LEARN, V4, P2406; VESANTO J, 2000, USING SOM DATA MININ; Vesanto J, 2000, SOM TOOLBOX MATLAB 5; Wettschereck D., 1995, P 1 INT C CAS BAS RE, P347; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Yang Y., 2001, P 12 EUR C MACH LEAR, P564	39	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	OCT	2007	16	5					875	899		10.1142/S0218213007003588		25	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	237QH	WOS:000251390300006	
J	Zhu, M; Chen, W; Hirdes, JP; Stolee, P				Zhu, Mu; Chen, Wenhong; Hirdes, John P.; Stolee, Paul			The K-nearest neighbor algorithm predicted rehabilitation potential better than current Clinical Assessment Protocol	JOURNAL OF CLINICAL EPIDEMIOLOGY			English	Article						Bayes' theorem; clinical decision making; diagnostic likelihood ratio; interRAI; machine learning; rehabilitation	HOME-CARE; MDS-HC; COMMUNITY	Objective: There may be great potential for using computer-modeling techniques and machine-learning algorithms in clinical decision making, if these can be shown to produce results superior to clinical protocols currently in use. We aim to explore the potential to use an automatic, data-driven, machine-learning algorithm in clinical decision making. Study Design and Setting: Using a database containing comprehensive health assessment information (the interRAI-HC) on home care clients (N = 24,724) from eight community-care regions in Ontario, Canada, we compare the performance of the K-nearest neighbor (KNN) algorithm and a Clinical Assessment Protocol (the "ADLCAP") currently used to predict rehabilitation potential. For our purposes, we define a patient as having rehabilitation potential if the patient had functional improvement or remained at home over a follow-up period of approximately 1 year. Results: The KNN algorithm has a lower false positive rate in all but one of the eight regions in the sample, and lower false negative rates in all regions. Compared using likelihood ratio statistics, KNN is uniformly more informative than the ADLCAP. Conclusion: This article illustrates the potential for a machine-learning algorithm to enhance clinical decision making. (C) 2007 Elsevier Inc. All rights reserved.	Univ Waterloo, Dept Hlth Studies & Gerontol, Waterloo, ON N2L 3G1, Canada; Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada; Homewood Hlth Ctr, Homewood Res Inst, Guelph, ON, Canada; Univ Waterloo, Sch Optometry, Waterloo, ON N2L 3G1, Canada	Stolee, P (reprint author), Univ Waterloo, Dept Hlth Studies & Gerontol, Waterloo, ON N2L 3G1, Canada.	m3zhu@uwaterloo.ca; wchen@uwaterloo.ca; hirdes@uwaterloo.ca; stolee@uwaterloo.ca					Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSBL.1763.0053; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diwan S, 2004, J APPL GERONTOL, V23, P193, DOI 10.1177/0733464804267970; Greenhalgh T, 1997, BRIT MED J, V315, P540; HARRELL FE, 1998, STAT MED, V4, P361; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirdes JP, 2004, GERONTOLOGIST, V44, P665; Hirdes J P, 1999, Healthc Manage Forum, V12, P30; Landi F, 2000, MED CARE, V38, P1184, DOI 10.1097/00005650-200012000-00005; Mitnitski AB, 2003, J CLIN EPIDEMIOL, V56, P116, DOI 10.1016/S0895-4356(02)00581-4; Morris JN, 1997, J AM GERIATR SOC, V45, P1017; MORRIS JN, 1999, PRIMER USE MINIMUM D; Morris JN, 1999, J GERONTOL A-BIOL, V54, pM546, DOI 10.1093/gerona/54.11.M546; Ottenbacher KJ, 2004, ANN EPIDEMIOL, V14, P551, DOI 10.1016/j.annepidem.2003.10.005; Pepe M. S, 2003, STAT EVALUATION MED; R Development Core Team, 2006, R LANG ENV STAT COMP; Sackett DL, 1991, CLIN EPIDEMIOLOGY BA; Stoke P, 2004, GERIATR TODAY J CAN, V7, P38; Tam SF, 2004, INT J REHABIL RES, V27, P65, DOI 10.1097/01.mrr.0000119282.12233.0f; TREMBLAY M, 2005, PREDICTIVE HLTH POLI	20	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0895-4356		J CLIN EPIDEMIOL	J. Clin. Epidemiol.	OCT	2007	60	10					1015	1021		10.1016/j.jclinepi.2007.06.001		7	Public, Environmental & Occupational Health	Public, Environmental & Occupational Health	217OF	WOS:000249956500005	
J	Garrow, AG; Westhead, DR				Garrow, Andrew G.; Westhead, David R.			A consensus algorithm to screen genomes for novel families of transmembrane beta barrel proteins	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						transmembrane beta-barrel; outer membrane; porin; prediction; algorithm; TMB-hunt	OUTER-MEMBRANE PROTEINS; AMINO-ACID-COMPOSITION; GRAM-NEGATIVE BACTERIA; HIDDEN MARKOV-MODELS; DATA-BANK; SECONDARY STRUCTURE; TMB-HUNT; PREDICTION; CLASSIFICATION; DATABASE	The ability to search sequence datasets for membrane spanning proteins is an important requirement for genome annotation. However, the development of algorithms to identify novel types of transmembrane beta-barrel (TMB) protein has proven substantially harder than for transmembrane helical proteins, owing to a shorter TM domain in which only alternate residues are hydrophobic. Although recent reports have described important improvements in the development Of such algorithms, there is still concern over their ability to confidently screen genomes. Here we describe a new algorithm combining composition and hidden Markov model topology based classifiers (called TMB-Hunt2), which achieves a crossvalidation accuracy of > 95%, with 96.7% precision and 94.2% recall. An overview is given of the algorithm design, with a thorough assessment of performance and application to a number of genomes. Of particular note is that TMB/extracellular protein discrimination is significantly more difficult than TMB/cytoplasmic protein discrimination, with the predictor correctly rejecting just 74% of extracellular proteins, in comparison to 98% of cytoplasmic proteins. Focus is given to directions for further improvements in TMB/non-TMB protein discrimination, with a call for the development of standardized tests and assessments of such algorithms. Tools and datasets are made available through a website called TMB-Web.	Univ Leeds, Inst Biol Mol & Cellulaire, Leeds LS2 9JT, W Yorkshire, England	Westhead, DR (reprint author), Univ Leeds, Inst Biol Mol & Cellulaire, Leeds LS2 9JT, W Yorkshire, England.	d.r.westhead@leeds.ac.uk					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bagos PG, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-7; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, pD154, DOI 10.1093/nar/gki070; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Barker GC, 1999, GENE, V229, P131, DOI 10.1016/S0378-1119(99)00039-6; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Berven FS, 2004, NUCLEIC ACIDS RES, V32, pW394, DOI 10.1093/nar/gkh351; Bigelow HR, 2004, NUCLEIC ACIDS RES, V32, P2566, DOI 10.1093/nar/gkh580; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Casadio R, 2003, PROTEIN SCI, V12, P1158, DOI 10.1110/ps.0223603; Chen Chien Peter, 2002, Appl Bioinformatics, V1, P21; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DURBIN R, 2006, BIOL SEQUENCE ANAL P, P63; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; Fariselli P, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S4-S12; Fichera ME, 1997, NATURE, V390, P407, DOI 10.1038/37132; Fischer D, 2003, PROTEINS, V53, P503, DOI 10.1002/prot.10538; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Garrow AG, 2005, NUCLEIC ACIDS RES, V33, pW188, DOI 10.1093/nat/gki384; Garrow AG, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-56; Gobert GN, 2003, INT J PARASITOL, V33, P1561, DOI 10.1016/S0020-7519(03)00255-8; Liu Q, 2003, COMPUT BIOL CHEM, V27, P69, DOI 10.1016/S0097-8485(02)00051-7; Liu Q, 2003, COMPUT BIOL CHEM, V27, P355, DOI 10.1016/S1476-9271(02)00085-3; Marani P, 2006, PROTEIN SCI, V15, P884, DOI 10.1110/ps.051889506; MARTELLI PL, 2002, BIOINFORMATICS, V18, P46; Mirus O, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-254; Moller S, 2000, BIOINFORMATICS, V16, P1159, DOI 10.1093/bioinformatics/16.12.1159; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Park KJ, 2005, BIOINFORMATICS, V21, P4223, DOI 10.1093/bioinformatics/bti697; Postle K, 2000, NAT STRUCT BIOL, V7, P527, DOI 10.1038/76726; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rey S, 2005, NUCLEIC ACIDS RES, V33, pD164, DOI 10.1093/nar/gki027; Rost Burkhard, 2003, Methods Biochem Anal, V44, P559; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Schleiff E, 2003, PROTEIN SCI, V12, P748, DOI 10.1110/ps.0237503; Schulz GE, 2000, CURR OPIN STRUC BIOL, V10, P443, DOI 10.1016/S0959-440X(00)00120-2; Song LZ, 1996, SCIENCE, V274, P1859, DOI 10.1126/science.274.5294.1859; Tusnady GE, 2005, NUCLEIC ACIDS RES, V33, pD275, DOI 10.1093/nar/gki002; Wimley WC, 2002, PROTEIN SCI, V11, P301, DOI 10.1110/ps.29402; Wimley WC, 2003, CURR OPIN STRUC BIOL, V13, P404, DOI 10.1016/S0959-440X(03)00099-X; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K; Zhai YF, 2002, PROTEIN SCI, V11, P2196, DOI 10.1110/ps.0209002	49	7	7	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	OCT	2007	69	1					8	18		10.1002/prot.21439		11	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	206NA	WOS:000249189000002	
J	Verduijn, M; Sacchi, L; Peek, N; Bellazzi, R; de Jonge, E; de Mol, BAJM				Verduijn, Marion; Sacchi, Lucia; Peek, Niels; Bellazzi, Riccardo; de Jonge, Evert; de Mol, Bas A. J. M.			Temporal abstraction for feature extraction: A comparative case study in prediction from intensive care monitoring data	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						temporal classification; feature extraction; temporal abstraction; monitoring data; prognosis; cardiac surgery; intensive care	PROLONGED MECHANICAL VENTILATION; CARDIAC-SURGERY; PREOPERATIVE PREDICTION; RISK-FACTORS; TIME-SERIES; SAPS-II; CLASSIFICATION; MULTICENTER; MODELS; SCORE	Objectives: To compare two temporal abstraction procedures for the extraction of meta features from monitoring data. Feature extraction prior to predictive modeling is a common strategy in prediction from temporal data. A fundamental dilemma in this strategy, however, is the extent to which the extraction should be guided by domain knowledge, and to which extent it should be guided by the available data. The two temporal abstraction procedures compared in this case study differ in this respect. Methods and material: The first temporal abstraction procedure derives symbolic descriptions from the data that are predefined using existing concepts from the medical language. In the second procedure, a large space of numerical meta features is searched through to discover relevant features from the data. These procedures were applied to a prediction problem from intensive care monitoring data. The predictive value of the resulting meta features were compared, and based on each type of features, a class probability tree model was developed. Results: The numerical meta features extracted by the second procedure were found to be more informative than the symbolic meta features of the first procedure in the case study, and a superior predictive performance was observed for the associated tree model. Conclusion: The findings indicate that for prediction from monitoring data, induction of numerical meta features from data is preferable to extraction of symbolic meta features using existing clinical concepts. (c) 2007 Elsevier B.V. All rights reserved.	Acad Med Ctr, Dept Med Informat, NL-1100 DE Amsterdam, Netherlands; Acad Med Ctr, Dept Intens Care Med, NL-1100 DE Amsterdam, Netherlands; Acad Med Ctr, Dept Cardio Thorac Surg, NL-1100 DE Amsterdam, Netherlands; Univ Pavia, Lab Med Informat, I-27100 Pavia, Italy; Tech Univ Eindhoven, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands	Verduijn, M (reprint author), Acad Med Ctr, Dept Med Informat, PO Box 22700, NL-1100 DE Amsterdam, Netherlands.	m.verduijn@amc.uva.nl					Abu-Hanna A, 2001, METHOD INFORM MED, V40, P1; BELLAZZI R, 1998, INTELL DATA ANAL, V2, P1; Bezanson JL, 2004, NURS RES, V53, P46, DOI 10.1097/00006199-200401000-00007; BICEGO M, 2003, MACHINE LEARNING DAT, V12, P86; BREIMAN L, 1984, CLASSIFIACATION REGR; Brier G.W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Burr Ridge I, 1997, MACHINE LEARNING; Combi C, 1999, ARTIF INTELL MED, V17, P271, DOI 10.1016/S0933-3657(99)00022-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diggle P. J., 2002, ANAL LONGITUDINAL DA; Dunning J, 2003, EUR J CARDIO-THORAC, V24, P270, DOI 10.1016/S1010-7940(03)00269-0; Habib RH, 1996, ANN THORAC SURG, V62, P1164, DOI 10.1016/0003-4975(96)00565-6; Haimowitz IJ, 1996, ARTIF INTELL MED, V8, P299, DOI 10.1016/0933-3657(95)00037-2; Harrell Jr FE, 2001, REGRESSION MODELING; Hastie T, 2001, ELEMENTS STAT LEARNI; Kadous MW, 2005, MACH LEARN, V58, P179, DOI 10.1007/s10994-005-5826-5; Keogh E., 2003, DATA MINING TIME SER, P1; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347153; Kern H, 2001, INTENS CARE MED, V27, P407, DOI 10.1007/s001340000802; Laxman S, 2006, SADHANA-ACAD P ENG S, V31, P173, DOI 10.1007/BF02719780; LEGALL JR, 1993, JAMA-J AM MED ASSOC, V270, P2957, DOI 10.1001/jama.270.24.2957; Legare JF, 2001, EUR J CARDIO-THORAC, V20, P930, DOI 10.1016/S1010-7940(01)00940-X; Magenes G, 2004, METHOD INFORM MED, V43, P47; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Miksch S, 1996, ARTIF INTELL MED, V8, P543, DOI 10.1016/S0933-3657(96)00355-7; Roddick JF, 2002, IEEE T KNOWL DATA EN, V14, P750, DOI 10.1109/TKDE.2002.1019212; Rodriguez JJ, 2005, KNOWL-BASED SYST, V18, P171, DOI 10.1016/j.knosys.2004.10.007; Shahar Y, 1996, ARTIF INTELL MED, V8, P267, DOI 10.1016/0933-3657(95)00036-4; Shahar Y, 1997, ARTIF INTELL, V90, P79, DOI 10.1016/S0004-3702(96)00025-2; Spivack SD, 1996, CHEST, V109, P1222, DOI 10.1378/chest.109.5.1222; Stacey M, 2007, ARTIF INTELL MED, V39, P1, DOI 10.1016/j.artmed.2006.08.002; Therneau T, 1997, INTRO RECURSIVE PART; Verduijn M, 2007, METHOD INFORM MED, V46, P352, DOI 10.1160/ME0368; Vincent JL, 1998, CRIT CARE MED, V26, P1793; WU C, 1995, MACH LEARN, V21, P177, DOI 10.1007/BF00993384; Xi X., 2006, P 23 INT C MACH LEAR, P1033, DOI 10.1145/1143844.1143974; ZHANG H, 2006, P 3 INT S NEUR NETW, P1394	37	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	SEP	2007	41	1					1	12		10.1016/j.artmed.2007.06.003		12	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	215PJ	WOS:000249821200001	
J	Huang, WL; Chen, HM; Hwang, SF; Ho, SY				Huang, Wen-Lin; Chen, Hung-Ming; Hwang, Shiow-Fen; Ho, Shinn-Ying			Accurate prediction of enzyme subfamily class using an adaptive fuzzy k-nearest neighbor method	BIOSYSTEMS			English	Article						amino acid composition; enzyme subfamily class prediction; fuzzy theory; k-nearest neighbor; support vector machine	AMINO-ACID-COMPOSITION; PROTEIN SORTING SIGNALS; SUBCELLULAR-LOCALIZATION; STRUCTURAL CLASSES; NEURAL-NETWORKS; RECOGNITION; ALGORITHM; LOCATION	Amphiphilic pseudo-amino acid composition (Am-Pse-AAC) with extra sequence-order information is a useful feature for representing enzymes. This study first utilizes the k-nearest neighbor (k-NN) rule to analyze the distribution of enzymes in the Am-Pse-AAC feature space. This analysis indicates the distributions of multiple classes of enzymes are highly overlapped. To cope with the overlap problem, this study proposes an efficient non-parametric classifier for predicting enzyme subfamily class using an adaptive fuzzy r-nearest neighbor (AFK-NN) method, where k and a fuzzy strength parameter m are adaptively specified. The fuzzy membership values of a query sample Q are dynamically determined according to the position of Q and its weighted distances to the k nearest neighbors. Using the same enzymes of the oxidoreductases family for comparisons, the prediction accuracy of AFK-NN is 76.6%, which is better than those of Support Vector Machine (73.6%), the decision tree method C5.0 (75.4%) and the existing covariant-discriminate algorithm (70.6%) using a jackknife test. To evaluate the generalization ability of AFK-NN, the datasets for all six families of entirely sequenced enzymes are established from the newly updated SWISS-PROT and ENZYME database. The accuracy of AFK-NN on the new large-scale dataset of oxidoreductases family is 83.3%, and the mean accuracy of the six families is 92.1 %. (c) 2006 Elsevier Ireland Ltd. All rights reserved.	Feng Chia Univ, Inst Comp Sci & Informat Engn, Taichung 40724, Taiwan; Natl Chiao Tung Univ, Dept Biol Sci & Technol, Hsinchu, Taiwan; Natl Chiao Tung Univ, Inst Bioinformat, Hsinchu, Taiwan	Ho, SY (reprint author), 75 Bo Ai St, Hsinchu, Taiwan.	syho@mail.nctu.edu.tw					Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; Cai YD, 2000, BBA-PROTEIN STRUCT M, V1476, P1, DOI 10.1016/S0167-4838(99)00217-4; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Ho SY, 2004, IEEE T EVOLUT COMPUT, V8, P522, DOI 10.1109/TEVC.2004.835176; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Joachims T., 1999, ADV KERNEL METHODS S; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lei ZD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-291; Leszczynski K, 1999, PHYS MED BIOL, V44, P253, DOI 10.1088/0031-9155/44/1/018; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Quinlan J. R., 2003, C5 0 ONLINE TUTORIAL; SNEDECOR GW, 1989, STAT METHODS, P142; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Webb EC, 1992, ENZYME NOMENCLATURE; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	30	10	11	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0303-2647		BIOSYSTEMS	Biosystems	SEP-OCT	2007	90	2					405	413		10.1016/j.biosystems.2006.10.004		9	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	220VD	WOS:000250184500011	
J	Li, X; Cripps, RJ				Li, X.; Cripps, R. J.			Algorithm for finding all k-nearest neighbours in three-dimensional scattered points and its application in reverse engineering	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF ENGINEERING MANUFACTURE			English	Article						k-nearest neighbours; three-dimensional scattered point data; reverse engineering	CLASSIFICATION	A fast and exact algorithm for computing the k-nearest neighbours, or k-closest points in terms of Euclidean distance, for all data in three-dimensional point clouds is presented that avoids using complicated Voronoi diagrams or Dirichlet tessellations. Experimental evidence suggests that the algorithm has a timing of O(n) for most practical values of k under the condition: k < 0.05n, where n is the number of three-dimensional points in the cloud. Case studies are presented to illustrate the robustness and efficiency of the method and a comparison is made to an existing exact method.	Nathan S Kline Inst Psychiat Res, Ctr Adv Brain Imaging, New York, NY USA; Univ Birmingham, Goemetr Modelling Grp, Birmingham, W Midlands, England	Cripps, RJ (reprint author), Univ Birmingham, Sch Mfg & Mech Engn, Birmingham B15 2TT, W Midlands, England.	r.cripps@bham.ac.uk					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cripps RJ, 2004, PROCEEDINGS OF THE 34TH INTERNATIONAL MATADOR CONFERENCE, P75; DAVIS P, 1975, INERPOLATION APPROXI; Dey T. K., 1991, Proceedings. Symposium on Solid Modeling Foundations and CAD/CAM Applications, DOI 10.1145/112515.112578; Dickerson M. T., 1992, International Journal of Computational Geometry & Applications, V2, DOI 10.1142/S0218195992000147; Duda R., 1979, PATTERN CLASSIFICATI; Duda R. O., 2001, PATTERN CLASSIFICATI; EDELSBRUNNER H, 1987, ALGORITHMS COMBINAT; Goodsell G, 2000, COMPUT AIDED GEOM D, V17, P387, DOI 10.1016/S0167-8396(00)00009-1; HOPPE H, 1992, COMP GRAPH, V26, P71; LI X, 2004, THESIS U BIRMINGHAM; Piegl LA, 2002, COMPUT AIDED DESIGN, V34, P167, DOI 10.1016/S0010-4485(00)00141-X; Preparata F. P., 1985, COMPUTATIONAL GEOMET; SARKAR M, 2000, P 2000 AMIA ANN S; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; DATASET 4 KINDLY SUP	16	0	0	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4054		P I MECH ENG B-J ENG	Proc. Inst. Mech. Eng. Part B-J. Eng. Manuf.	SEP	2007	221	9					1467	1472		10.1243/09544054JEM477		6	Engineering, Manufacturing; Engineering, Mechanical	Engineering	216KQ	WOS:000249877300009	
J	Omachi, S; Omachi, M; Aso, H				Omachi, Shinichiro; Omachi, Masako; Aso, Hirotomo			An approximation method of the quadratic discriminant function and its application to estimation of high-dimensional distribution	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						pattern recognition; quadratic discriminant function; small sample size problem; simplified quadratic discriminant function; normal mixture	DENSITY-FUNCTION; RECOGNITION	In statistical pattern recognition, it is important to estimate the distribution of patterns precisely to achieve high recognition accuracy. In general, precise estimation of the parameters of the distribution requires a great number of sample patterns, especially when the feature vector obtained from the pattern is high-dimensional. For some pattern recognition problems, such as face recognition or character recognition, very high-dimensional feature vectors are necessary and there are always not enough sample patterns for estimating the parameters. In this paper, we focus on estimating the distribution of high-dimensional feature vectors with small number of sample patterns. First, we define a function, called simplified quadratic discriminant function (SQDF). SQDF can be estimated with small number of sample patterns and approximates the quadratic discriminant function (QDF). SQDF has fewer parameters and requires less computational time than QDF. The effectiveness of SQDF is confirmed by three types of experiments. Next, as an application of SQDF, we propose an algorithm for estimating the parameters of the normal mixture. The proposed algorithm is applied to face recognition and character recognition problems which require high-dimensional feature vectors.	Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan; Tohoku Bunka Gakuen Univ, Fac Sci & Technol, Sendai, Miyagi 9818551, Japan	Omachi, S (reprint author), Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan.	machi@ecei.tohoku.ac.jp					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BUTUROVIC LJ, 1994, IEEE T PATTERN ANAL, V16, P420, DOI 10.1109/34.277596; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; FIX E, 1951, 4 SCH AV MED RAND FI; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; FUKUNAGA K, 1990, INTRO STAT PATERN RE; Grother P. J., 1995, NIST SPECIAL DATABAS; Hartigan J., 1975, CLUSTERING ALGORITHM; Hastie T, 2001, ELEMENTS STAT LEARNI; HONGO H, 2000, PRMU2000108 IEICE; ICHIMURA N, 1995, IEICE T INF SYST, P1184; IWAMURA M, 2003, IEICE T INF SYST, P22; Kato N, 1999, IEEE T PATTERN ANAL, V21, P258, DOI 10.1109/34.754617; KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; OMACHI S, 2004, P 17 INT C PATT REC, V1, P220, DOI 52214785,12,1; Omachi S, 2000, LECT NOTES COMPUT SC, V1876, P601; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Sakai M., 1998, Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170), DOI 10.1109/ICPR.1998.711089; TAKESHITA T, 1987, IEICE T D, V70, P567; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728	26	5	5	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	AUG	2007	E90D	8					1160	1167		10.1093/ietisy/e90-d.8.1160		8	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	202WE	WOS:000248934000005	
J	Sanchez, JS; Mollineda, RA; Sotoca, JM				Sanchez, J. S.; Mollineda, R. A.; Sotoca, J. M.			An analysis of how training data complexity affects the nearest neighbor classifiers	PATTERN ANALYSIS AND APPLICATIONS			English	Article							PATTERN-RECOGNITION; CLASSIFICATION; ALGORITHMS	The k-nearest neighbors (k-NN) classifier is one of the most popular supervised classification methods. It is very simple, intuitive and accurate in a great variety of real-world domains. Nonetheless, despite its simplicity and effectiveness, practical use of this rule has been historically limited due to its high storage requirements and the computational costs involved. On the other hand, the performance of this classifier appears strongly sensitive to training data complexity. In this context, by means of several problem difficulty measures, we try to characterize the behavior of the k-NN rule when working under certain situations. More specifically, the present analysis focuses on the use of some data complexity measures to describe class overlapping, feature space dimensionality and class density, and discover their relation with the practical accuracy of this classifier.	Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Castellon de La Plana 12071, Spain	Sanchez, JS (reprint author), Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Vicent Sos Baynat S-N, Castellon de La Plana 12071, Spain.	sanchez@uji.es					BERNARDO E, 2004, P 17 INT C PATT REC, P136; Beyer K., 1999, P 7 INT C DAT THEOR, P217; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1991, IEEE COMPUTER SOC; Devijver P., 1992, PATTERN RECOGNITION; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GAMA J, 1995, P 7 PORT C AI EPIA 9, P83; Hand DJ, 2003, PATTERN RECOGN LETT, V24, P1555, DOI 10.1016/S0167-8655(02)00394-X; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Hoekstra A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547429; Jain A. K., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047451; Japkowicz N., 2002, Intelligent Data Analysis, V6; KUBAT M, 1998, P 1 SO S COMP, P27; Little RJA, 2002, STAT ANAL MISSING DA; Mollineda RA, 2005, LECT NOTES COMPUT SC, V3523, P27; Okamoto S, 2003, THEOR COMPUT SCI, V298, P207, DOI 10.1016/S0304-3975(02)00424-3; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Singh S, 2003, PATTERN ANAL APPL, V6, P134, DOI 10.1007/s10044-002-0186-2; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Zhang J., 2003, P WORKSH LEARN IMB D	22	20	20	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	AUG	2007	10	3					189	201		10.1007/s10044-007-0061-2		13	Computer Science, Artificial Intelligence	Computer Science	194ZT	WOS:000248383000003	
J	Roggo, Y; Chalus, P; Maurer, L; Lema-Martinez, C; Edmond, A; Jent, N				Roggo, Yves; Chalus, Pascal; Maurer, Lene; Lema-Martinez, Carmen; Edmond, Aurelie; Jent, Nadine			A review of near infrared spectroscopy and chemometrics in pharmaceutical technologies	JOURNAL OF PHARMACEUTICAL AND BIOMEDICAL ANALYSIS			English	Review						near infrared spectroscopy; chemometrics; pharmaceuticals; on-line; quality control; identification; qualification; quantification	ARTIFICIAL NEURAL-NETWORKS; CELL-CULTURE-MEDIA; DIFFUSE-REFLECTANCE SPECTROSCOPY; SUPPORT VECTOR MACHINES; SUPERVISED PATTERN-RECOGNITION; ORTHOGONAL SIGNAL CORRECTION; SUBMERGED FUNGAL BIOPROCESS; ALPHA-LACTOSE-MONOHYDRATE; LINE MOISTURE MEASUREMENT; LEAST-SQUARES REGRESSION	Near-infrared spectroscopy (NIRS) is a fast and non-destructive analytical method. Associated with chemometrics, it becomes a powerful tool for the pharmaceutical industry. Indeed, NIRS is suitable for analysis of solid, liquid and biotechnological pharmaceutical forms. Moreover, NIRS can be implemented during pharmaceutical development, in production for process monitoring or in quality control laboratories. This review focuses on chemometric techniques and pharmaceutical NIRS applications. The following topics are covered: qualitative analyses, quantitative methods and on-line applications. Theoretical and practical aspects are described with pharmaceutical examples of NIRS applications. (c) 2007 Elsevier B.V. All rights reserved.	F Hoffmann La Roche & Co Ltd, CH-4002 Basel, Switzerland	Roggo, Y (reprint author), F Hoffmann La Roche & Co Ltd, CH-4002 Basel, Switzerland.	yves.roggo@roche.com	roggo, yves/F-2214-2011				ADAMS MJ, 1995, CHEMOMETRICS ANAL SP; Andersson M, 2000, ANAL CHEM, V72, P2099, DOI 10.1021/ac990256r; Andersson M, 1999, J PHARMACEUT BIOMED, V20, P27, DOI 10.1016/S0731-7085(98)00237-4; Andre M, 2003, ANAL CHEM, V75, P3460, DOI 10.1021/ac026393x; Arnold SA, 2003, BIOTECHNOL BIOENG, V84, P13, DOI 10.1002/bit.10738; ARNOLD SA, 2002, BIOPHARM INTERN  NOV; Arnold SA, 2000, ENZYME MICROB TECH, V27, P691, DOI 10.1016/S0141-0229(00)00271-4; ARNOLD SA, 2003, BIOPHARM INT     JAN; Atti E, 2002, BONE, V31, P675, DOI 10.1016/S8756-3282(02)00905-5; Bai SJ, 2004, J PHARM SCI-US, V93, P2439, DOI 10.1002/jps.20153; Bai SJ, 2005, J PHARM SCI-US, V94, P2030, DOI 10.1002/jps.20416; Baratieri SC, 2006, J PHARMACEUT BIOMED, V40, P51, DOI 10.1016/j.jpba.2005.05.025; Barnes RJ, 1993, J NEAR INFRARED SPEC, V1, P185; Bergman EL, 2006, J PHARMACEUT BIOMED, V41, P89, DOI 10.1016/j.jpba.2005.10.042; Berntsson O, 1999, ANAL CHEM, V71, P617, DOI 10.1021/ac980652u; Berntsson O, 1998, ANAL CHIM ACTA, V364, P243, DOI 10.1016/S0003-2670(98)00196-2; Berntsson O, 1997, J PHARMACEUT BIOMED, V15, P895, DOI 10.1016/S0731-7085(96)01926-7; Berntsson O, 2002, POWDER TECHNOL, V123, P185, DOI 10.1016/S0032-5910(01)00456-9; Berntsson O, 2000, ANAL CHIM ACTA, V419, P45, DOI 10.1016/S0003-2670(00)00975-2; BLANCO, 1998, ANALYST, V123, pR135; Blanco M, 2001, APPL SPECTROSC, V55, P834, DOI 10.1366/0003702011952857; Blanco M, 2002, J PHARMACEUT BIOMED, V30, P467, DOI 10.1016/S0731-7085(02)00093-6; Blanco M, 1999, ANAL CHIM ACTA, V384, P207, DOI 10.1016/S0003-2670(98)00814-9; Blanco M, 2002, TALANTA, V56, P203, DOI 10.1016/S0039-9140(01)00559-8; Blanco M, 2004, TALANTA, V64, P597, DOI 10.1016/j.talanta.2004.03.027; Blanco M, 2000, ANAL CHIM ACTA, V407, P247, DOI 10.1016/S0003-2670(99)00828-4; Blanco M, 2001, ANALYST, V126, P2212, DOI 10.1039/b105012p; Blanco M, 1997, ANALYST, V122, P761, DOI 10.1039/a700630f; Blanco M, 2006, ANAL CHIM ACTA, V557, P353, DOI 10.1016/j.aca.2005.09.070; Blanco M, 2000, FRESEN J ANAL CHEM, V368, P534, DOI 10.1007/s002160000506; Blanco M, 1998, ANALYST, V123, P2307, DOI 10.1039/a805946b; Blanco M, 1999, J PHARM SCI, V88, P551, DOI 10.1021/js980338f; Blanco M, 2004, ANAL CHIM ACTA, V502, P221, DOI 10.1016/j.aca.2003.10.016; Bokobza L, 1998, J NEAR INFRARED SPEC, V6, P3, DOI DOI 10.1255/JNIRS.116; BOUVERESSE E, 1994, ANAL CHIM ACTA, V297, P405, DOI 10.1016/0003-2670(94)00237-1; Breiman L, 1984, CLASSIFICATION REGRE; Brereton RG, 2003, CHEMOMETRICS DATA AN; Broad NW, 2000, ANALYST, V125, P2054, DOI 10.1039/b006789j; Broad NW, 2001, ANALYST, V126, P2207, DOI 10.1039/b106741a; BRULLS, 2003, PHARM RES-DORDR, P494; Buckton G, 1998, INT J PHARM, V168, P231, DOI 10.1016/S0378-5173(98)00095-7; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burns D. A., 2001, HDB NEAR INFRARED AN; Candolfi A, 1998, J PHARMACEUT BIOMED, V16, P1329, DOI 10.1016/S0731-7085(97)00154-4; Candolfi A, 1999, J PHARMACEUT BIOMED, V21, P115, DOI 10.1016/S0731-7085(99)00125-9; Candolfi A, 2000, APPL SPECTROSC, V54, P48, DOI 10.1366/0003702001948105; Candolfi A, 1999, J PHARMACEUT BIOMED, V19, P923, DOI 10.1016/S0731-7085(98)00234-9; CAO, 2006, J PHARM SCI, V95, P2077; Chalus P, 2005, TALANTA, V66, P1294, DOI 10.1016/j.talanta.2005.01.051; CHALUS P, 2005, SPECTRA ANAL, P44; Chauchard F, 2004, CHEMOMETR INTELL LAB, V71, P141, DOI 10.1016/j.chemolab.2004.01.003; Chen YX, 2001, DRUG DEV IND PHARM, V27, P623, DOI 10.1081/DDC-100107318; Cho J, 1997, ANAL CHIM ACTA, V348, P303, DOI 10.1016/S0003-2670(97)00094-9; Cimander C, 2002, J CHEM TECHNOL BIOT, V77, P1157, DOI 10.1002/jctb.691; Ciurczak EW, 2002, PHARM MED APPL NEARI; Cogdill Robert P, 2005, AAPS PharmSciTech, V6, pE273, DOI 10.1208/pt060238; Cogdill Robert P, 2005, AAPS PharmSciTech, V6, pE262, DOI 10.1208/pt060237; COGDILL RP, 2005, AAPS PHARMSCI, V6; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; Corti P, 1999, ANALYST, V124, P755, DOI 10.1039/a809800j; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cui XJ, 2004, TALANTA, V64, P943, DOI 10.1016/j.talanta.2004.04.009; Danzer K., 2001, CHEMOMETRIK GRUNDLAG; Daszykowski M, 2002, ANAL CHIM ACTA, V468, P91, DOI 10.1016/S0003-2670(02)00651-7; Daszykowski M, 2001, CHEMOMETR INTELL LAB, V56, P83, DOI 10.1016/S0169-7439(01)00111-3; Davis TD, 2004, PHARM RES, V21, P860, DOI 10.1023/B:PHAM.0000026440.00508.cf; de Groot PJ, 2001, APPL SPECTROSC, V55, P173, DOI 10.1366/0003702011951470; de Maesschalck R, 2005, J PHARMACEUT BIOMED, V37, P109, DOI 10.1016/j.jpba.2004.10.016; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Derksen MWJ, 1998, J PHARMACEUT BIOMED, V17, P473, DOI 10.1016/S0731-7085(97)00216-1; Dhanoa M., 1994, J NEAR INFRARED SPEC, V2, P43, DOI [DOI 10.1255/JNIRS.30, 10.1255/jnirs.30]; Donoso M, 2004, PHARM DEV TECHNOL, V9, P247, DOI 10.1081/PDT-200031423; Dou Y, 2005, ANAL CHIM ACTA, V528, P55, DOI 10.1016/j.aca.2004.10.050; Dou Y, 2005, J PHARMACEUT BIOMED, V37, P543, DOI 10.1016/j.jpba.2004.11.017; Duponchel L, 1999, J NEAR INFRARED SPEC, V7, P155; Ebube NK, 1999, PHARM DEV TECHNOL, V4, P19, DOI 10.1081/PDT-100101335; El-Hagrasy AS, 2001, J PHARM SCI, V90, P1298, DOI 10.1002/jps.1082; Eustaquio A, 1999, ANAL CHIM ACTA, V383, P283, DOI 10.1016/S0003-2670(98)00815-0; Fearn T, 2000, CHEMOMETR INTELL LAB, V50, P47, DOI 10.1016/S0169-7439(99)00045-3; Fearn T, 2001, J NEAR INFRARED SPEC, V9, P229; Fertig CC, 2004, EUR J PHARM SCI, V21, P155, DOI 10.1016/j.ejps.2003.09.011; Feudale R. N., 2002, CHEMOM INTELL LAB SY, V64, P181, DOI DOI 10.1016/S0169-7439(02)00085-0; Fevotte G, 2004, INT J PHARM, V273, P159, DOI 10.1016/j.ijpharm.2004.01.003; Dantas HA, 2004, CHEMOMETR INTELL LAB, V72, P83, DOI 10.1016/j.chemolab.2004.02.008; Findlay WP, 2005, J PHARM SCI-US, V94, P604; Fix I, 2004, DRUG DEV IND PHARM, V30, P513, DOI 10.1081/DDC-120037482; Forbes RA, 2001, J PHARMACEUT BIOMED, V25, P239, DOI 10.1016/S0731-7085(00)00497-0; Fountain W, 2003, J PHARMACEUT BIOMED, V33, P181, DOI 10.1016/S0731-7085(03)00345-5; Frake P, 1997, INT J PHARM, V151, P75, DOI 10.1016/S0378-5173(97)04894-1; FRAZIER BL, 2000, BIOTECHNOL BIOENG, V72, P364; Freitas MP, 2005, J PHARMACEUT BIOMED, V39, P17, DOI 10.1016/j.jpba.2005.03.023; Galvao RKH, 2005, TALANTA, V67, P736, DOI 10.1016/j.talanta.2005.03.025; Gaub M, 2004, J PHARMACEUT BIOMED, V36, P859, DOI 10.1016/j.jpba.2004.06.030; Gerhausser CI, 1997, APPL SPECTROSC, V51, P1504, DOI 10.1366/0003702971939000; BUICE RG, 1995, PHARMACEUT RES, V12, P161; Gombas A, 2003, INT J PHARMACEUT, V256, P25, DOI 10.1016/S0378-5173(03)00059-0; Gonzalez-Arjona D, 1999, ANAL CHIM ACTA, V381, P257, DOI 10.1016/S0003-2670(98)00764-8; Gupta A, 2005, J PHARM SCI-US, V94, P1589, DOI 10.1002/jps.20375; Gupta A, 2004, J PHARM SCI-US, V93, P1047, DOI 10.1002/jps.20003; Habib IHI, 2003, TALANTA, V60, P185, DOI 10.1016/S0039-9140(03)00123-1; Hailey PA, 1996, J PHARMACEUT BIOMED, V14, P551, DOI 10.1016/0731-7085(95)01674-0; Han SM, 1996, J PHARMACEUT BIOMED, V14, P1681, DOI 10.1016/0731-7085(96)01814-6; HAYKIN S, 1999, NEURAL NETWORKS COMP; Herkert T, 2001, EUR J PHARM BIOPHARM, V51, P9, DOI 10.1016/S0939-6411(00)00126-0; Huang ES, 2005, DRUG DISCOV TODAY, V10, P69, DOI 10.1016/S1359-6446(04)03349-5; Iyer M, 2002, J NEAR INFRARED SPEC, V10, P233; Izutsu KI, 2005, INT J PHARM, V301, P161, DOI 10.1016/j.ijpharm.2005.05.019; Izutsu KI, 2006, J PHARM SCI-US, V95, P781, DOI 10.1002/jps.20580; Jiang JH, 2002, ANAL CHEM, V74, P3555, DOI 10.1021/ac011177u; JONES JA, 1993, J PHARMACEUT BIOMED, V11, P1227, DOI 10.1016/0731-7085(93)80108-D; Jung BJ, 2002, APPL SPECTROSC, V56, P51, DOI 10.1366/0003702021954421; Kalivas JH, 2001, ANAL CHIM ACTA, V428, P31, DOI 10.1016/S0003-2670(00)01225-3; KAMAT MS, 1989, PHARMACEUT RES, V6, P961, DOI 10.1023/A:1015997530367; KEMPER MS, 2001, AAPS PHARMSCI, V3; Kirsch JD, 1999, J PHARMACEUT BIOMED, V19, P351, DOI 10.1016/S0731-7085(98)00132-0; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kramer K, 2000, ANAL CHIM ACTA, V420, P155, DOI 10.1016/S0003-2670(00)00877-1; Kreft K, 1999, INT J PHARM, V177, P1, DOI 10.1016/S0378-5173(98)00265-8; Laasonen M, 2004, EUR J PHARM SCI, V21, P493, DOI 10.1016/j.ejps.2003.11.011; Laasonen M, 2003, ANAL CHEM, V75, P754, DOI 10.1021/ac026262w; Larrechi MS, 2003, TRAC-TREND ANAL CHEM, V22, P634, DOI 10.1016/S0165-9936(03)01005-7; LAST IR, 1993, J PHARMACEUT BIOMED, V11, P1071, DOI 10.1016/0731-7085(93)80084-E; LAVINE, 2000, ANAL CHEM, V72; Leardi R, 2003, NATURE INSPIRED METH; Leion H, 2005, J PHARMACEUT BIOMED, V37, P47, DOI 10.1016/j.jpba.2004.09.046; Lewis CB, 2000, APPL SPECTROSC, V54, P1453, DOI 10.1366/0003702001948592; Li WY, 2005, J PHARM SCI-US, V94, P2800, DOI 10.1002/jps.20501; LIN TP, 2001, PHARM SCI TECHNOL, P196; Liu JS, 2006, PHARM DEV TECHNOL, V11, P3, DOI 10.1080/10837450500463729; Lopes JA, 2004, CHEMOMETR INTELL LAB, V74, P269, DOI 10.1016/j.chemolab.2004.07.006; Luypaert J, 2007, TALANTA, V72, P865, DOI 10.1016/j.talanta.2006.12.023; Marini F, 2004, CHEMOMETR INTELL LAB, V73, P85, DOI 10.1016/j.chemolab.2003.12.007; Mark H.L., 1985, ANAL CHEM, V57, P1449, DOI 10.1021/ac00284a061; Markopoulou CK, 2005, J PHARMACEUT BIOMED, V37, P249, DOI 10.1016/j.jpba.2004.10.024; Martens H., 1996, MULTIVARIATE CALIBRA; Martens H, 2001, MULTIVARIATE ANAL QU; Massart D. L., 1997, HDB CHEMOMETRICS QUA; Massart DL, 2003, CHEMOMETRICS TXB; McShane MJ, 1998, APPL SPECTROSC, V52, P1073, DOI 10.1366/0003702981944968; Merckle P, 1998, J PHARMACEUT BIOMED, V17, P365, DOI 10.1016/S0731-7085(97)00194-5; Morisseau KM, 1997, PHARMACEUT RES, V14, P108, DOI 10.1023/A:1012071904673; Naes T, 2002, USER FRIENDLY GUIDE; Naes T, 2002, MULTIVARIATE CALIBRA; Navratil M, 2005, J BIOTECHNOL, V115, P67, DOI 10.1016/j.jbiotec.2004.07.013; Norris KH, 1996, J NEAR INFRARED SPEC, V4, P31; Otsuka M, 2004, POWDER TECHNOL, V141, P244, DOI 10.1016/j.powtec.2004.01.025; Otto M., 1999, CHEMOMETRICS STAT CO; Patel AD, 2000, INT J PHARM, V206, P63, DOI 10.1016/S0378-5173(00)00530-5; PEREZRAMOS JD, 2005, AAPS PHARMSCI, V6; Plumb AP, 2005, EUR J PHARM SCI, V25, P395, DOI 10.1016/j.ejps.2005.04.010; Plumb AP, 2002, EUR J PHARM SCI, V16, P281, DOI 10.1016/S0928-0987(02)00112-4; Popo Manuel, 2002, AAPS PharmSciTech, V3, pE24, DOI 10.1208/pt030324; Pretsch E., 2006, TRENDS ANAL CHEM, V25, P1043; Rager I, 2002, J PHARMACEUT BIOMED, V28, P439, DOI 10.1016/S0731-7085(01)00602-1; Ramirez J L, 2001, AAPS PharmSciTech, V2, pE11; Rantanen J, 1998, POWDER TECHNOL, V99, P163, DOI 10.1016/S0032-5910(98)00100-4; Rantanen J, 2000, EUR J PHARM BIOPHARM, V50, P271, DOI 10.1016/S0939-6411(00)00096-5; Rantanen J, 2001, CHEMOMETR INTELL LAB, V56, P51, DOI 10.1016/S0169-7439(01)00108-3; Rantanen J, 2000, PHARM DEV TECHNOL, V5, P209, DOI 10.1081/PDT-100100536; Reich G, 2005, ADV DRUG DELIVER REV, V57, P1109, DOI 10.1016/j.addr.2005.01.020; Rhiel M, 2002, BIOTECHNOL BIOENG, V77, P73, DOI 10.1002/bit.10093; Riley MR, 1997, BIOTECHNOL BIOENG, V55, P11, DOI 10.1002/(SICI)1097-0290(19970705)55:1<11::AID-BIT2>3.0.CO;2-#; Rodionova OY, 2005, ANAL CHIM ACTA, V549, P151, DOI 10.1016/j.aca.2005.06.018; Rodriguez-Saona LE, 2001, J AGR FOOD CHEM, V49, P574, DOI 10.1021/jf000776j; Rodriguez-Saona LE, 2004, J FOOD PROTECT, V67, P2555; Roggo Y, 2005, EUR J PHARM BIOPHARM, V61, P100, DOI 10.1016/j.ejpb.2005.04.005; Roggo Y, 2004, J PHARMACEUT BIOMED, V36, P777, DOI 10.1016/j.jpba.2004.08.009; Roggo Y, 2004, J AGR FOOD CHEM, V52, P1051; Roggo Y, 2005, ANAL CHIM ACTA, V535, P79, DOI 10.1016/j.aca.2004.12.037; Savage M, 1998, BIOLOGICALS, V26, P119, DOI 10.1006/biol.1998.0140; SAVOLAINEN M, IN PRESS EUR J PHARM; Scafi SHF, 2001, ANALYST, V126, P2218, DOI 10.1039/b106744n; Schneider RC, 2003, FORENSIC SCI INT, V134, P187, DOI 10.1016/S0379-0738(03)00125-7; Sekulic SS, 1996, ANAL CHEM, V68, P509, DOI 10.1021/ac950964m; Sekulic SS, 1998, J PHARMACEUT BIOMED, V17, P1285, DOI 10.1016/S0731-7085(98)00025-9; Seyer JJ, 2001, PHARM DEV TECHNOL, V6, P573, DOI 10.1081/PDT-120000295; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; Sharaf MA, 1986, CHEMOMETRICS; SHENK JS, 1991, CROP SCI, V31, P1548; Siesler H. W., 2002, NEAR INFRARED SPECTR; Simon L, 2001, BIOCHEM ENG J, V7, P41, DOI 10.1016/S1369-703X(00)00102-9; Sjoblom J, 1998, CHEMOMETR INTELL LAB, V44, P229, DOI 10.1016/S0169-7439(98)00112-9; Skibsted ETS, 2006, J PHARMACEUT BIOMED, V41, P26, DOI 10.1016/j.jpba.2005.10.009; Skibsted ETS, 2007, J PHARMACEUT BIOMED, V43, P1297, DOI 10.1016/j.jpba.2006.10.037; Smith MR, 2004, ANALYST, V129, P806, DOI 10.1039/b401267d; Sondermann N, 1999, FORENSIC SCI INT, V102, P133, DOI 10.1016/S0379-0738(99)00047-X; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STAHLE L, 1987, Journal of Chemometrics, V1, P185, DOI 10.1002/cem.1180010306; Stokvold A, 2002, J PHARMACEUT BIOMED, V28, P867, DOI 10.1016/S0731-7085(01)00668-9; Sukowski L, 2005, PHARM IND, V67, P830; Tamburini E, 2003, APPL SPECTROSC, V57, P132, DOI 10.1366/000370203321535024; Tenenhaus M., 1998, REGRESSION PLS THEOR; The European Agency for the Evaluation of Medicinal Products, 2003, EMEACVMP96101; Thissen U, 2004, ANAL CHEM, V76, P3099, DOI 10.1021/ac035522m; Thissen U, 2004, CHEMOMETR INTELL LAB, V73, P169, DOI 10.1016/j.chemolab.2004.01.002; Thosar SS, 2001, PHARM DEV TECHNOL, V6, P19, DOI 10.1081/PDT-100000010; Tosi S, 2003, BIOTECHNOL PROGR, V19, P1816, DOI 10.1021/bp034101n; Trafford AD, 1999, ANALYST, V124, P163, DOI 10.1039/a806629i; Tumuluri SVS, 2004, DRUG DEV IND PHARM, V30, P505, DOI 10.1081/DDC-120037481; Ulmschneider M, 1999, ANALUSIS, V27, P854, DOI 10.1051/analusis:1999153; Ulmschneider M, 2000, ANALUSIS, V28, P336, DOI 10.1051/analusis:2000124; Ulmschneider M, 2000, ANALUSIS, V28, P83, DOI 10.1051/analusis:2000101; Ulmschneider M, 2000, PHARM IND, V62, P374; Vaidyanathan S, 2001, ANAL CHIM ACTA, V428, P41, DOI 10.1016/S0003-2670(00)01205-8; Vaidyanathan S, 2001, APPL SPECTROSC, V55, P444, DOI 10.1366/0003702011951957; Vaidyanathan S, 2000, BIOTECHNOL PROGR, V16, P1098, DOI 10.1021/bp0000656; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; VANDERVLIES C, 1994, EUR J PHARM SCI, V2, P79, DOI 10.1016/0928-0987(94)90078-7; Vora KL, 2004, EUR J PHARM SCI, V22, P97, DOI 10.1016/j.ejps.2004.01.009; Vredenbregt MJ, 2003, EUR J PHARM BIOPHARM, V56, P489, DOI 10.1016/S0939-6411(03)00119-X; Vredenbregt MJ, 2006, J PHARMACEUT BIOMED, V40, P840, DOI 10.1016/j.jpba.2005.07.048; Wang HF, 2004, CHEMOMETR INTELL LAB, V70, P23, DOI 10.1016/j.chemolab.2003.09.003; Wang YB, 2005, SPECTROSC SPECT ANAL, V25, P398; Wargo DJ, 1996, J PHARMACEUT BIOMED, V14, P1415, DOI 10.1016/0731-7085(96)01739-6; Webster GK, 2003, J PHARMACEUT BIOMED, V33, P21, DOI 10.1016/S0731-7085(03)00341-8; Westenberger BJ, 2005, INT J PHARM, V306, P56, DOI 10.1016/j.ijpharm.2005.08.027; WILLIAMS PC, 1987, NEAR INFRARED TECHNO; Wilson ND, 2001, J PHARM PHARMACOL, V53, P95, DOI 10.1211/0022357011775064; Wilson ND, 2002, J PHARM PHARMACOL, V54, P1257, DOI 10.1211/002235702320402107; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P131, DOI 10.1016/S0169-7439(01)00156-3; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0; WU W, 1995, ANAL CHIM ACTA, V315, P243, DOI 10.1016/0003-2670(95)00347-3; Wu W, 1996, CHEMOMETR INTELL LAB, V33, P35, DOI 10.1016/0169-7439(95)00077-1; Yang H, 2002, J PHARM PHARMACOL, V54, P1247, DOI 10.1211/002235702320402099; YEUNG KSY, 1998, BIOTECHNOL BIOENG, V63; Yoon JG, 2002, CHEMOMETR INTELL LAB, V64, P1, DOI 10.1016/S0169-7439(02)00042-4; Yoon WL, 1998, ANALYST, V123, P1029, DOI 10.1039/a800358k; YOON WL, 1999, P 9 INT C NEAR INFR, P547; Yoon WL, 2004, J PHARMACEUT BIOMED, V34, P933, DOI 10.1016/j.jpba.2003.11.014; YOON WL, 2002, AM PHARM REV, V5, P106; Yoon WL, 1999, ANALYST, V124, P1197; Zhou GX, 2003, J PHARM SCI, V92, P1058, DOI 10.1002/jps.10375; Zhou XJ, 1998, J PHARMACEUT BIOMED, V17, P219, DOI 10.1016/S0731-7085(97)00182-9; *COE, 2006, EUR PHARM; 2001, INT C HARM Q7A, V66, P49028; 1995, INT C HARM Q2A, V60, P11260; 2000, INT C HARM Q6A, V65, P83041; 1997, INT C HARM Q6B, V62, P27463	240	208	223	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0731-7085		J PHARMACEUT BIOMED	J. Pharm. Biomed. Anal.	JUL 27	2007	44	3			SI		683	700		10.1016/j.jpba.2007.03.023		18	Chemistry, Analytical; Pharmacology & Pharmacy	Chemistry; Pharmacology & Pharmacy	200BF	WOS:000248738200010	
J	Alfo, M; Farcomeni, A; Tardella, L				Alfo, Marco; Farcomeni, Alessio; Tardella, Luca			Robust semiparametric mixing for detecting differentially expressed genes in microarray experiments	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article; Proceedings Paper	Conference on Computational Statistics and Data Analysis	OCT 28-31, 2005	Limassol, CYPRUS	IASC-CSDA		microarray data; up-regulated genes; mixture models; counting distribution; false discovery rate	FALSE DISCOVERY RATE; CLASSIFICATION; MODELS; POWER	An important goal of microarray studies is the detection of genes that show significant changes in observed expressions when two or more classes of biological samples such as treatment and control are compared. Using the c-fold rule, a gene is declared to be differentially expressed if its average expression level varies by more than a constant factor c between treatment and control (typically c = 2). While often used, however, this simple rule is not completely convincing. By modeling this filter, a binary variable is defined at the gene x experiment level, allowing for a more powerful treatment of the corresponding information. A gene-specific random term is introduced to control for both dependence among genes and variability with respect to the c-fold threshold. Inference is carried out via a two-level finite mixture model under a likelihood approach. Then, parameter estimates are also derived using the counting distribution under a Bayesian nonparametric approach which allows to keep under control some error rate of erroneous discoveries. The effectiveness of both proposed approaches is illustrated through a large-scale simulation study and a well known benchmark data set. (C) 2006 Elsevier B.V. All rights reserved.	Univ Roma La Sapienza, Dipartimento Stat Probabil & Stat Applicate, I-00185 Rome, Italy	Alfo, M (reprint author), Univ Roma La Sapienza, Dipartimento Stat Probabil & Stat Applicate, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	marco.alfo@uniroma1.it					ALON U, 1999, P NATL ACAD SCI USA, V96, P6746; Amaratunga D, 2004, EXPLORATION ANAL DNA; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Boulesteix AL, 2006, COMPUT STAT DATA AN, V50, P783, DOI 10.1016/j.csda.2004.10.004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeCook R, 2006, COMPUT STAT DATA AN, V50, P518, DOI 10.1016/j.csda.2004.09.004; DETTE H, 1997, PROBABILITY ANAL; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; GEORGE EO, 1995, BIOMETRICS, V51, P512, DOI 10.2307/2532939; GIESEG M, 2002, BMC BIOINFORMATICS, P3; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; GILKS WR, 1998, MARKOV CHAIN MONTE; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gusnanto A, 2005, STAT APPL GENET MO B, V4; HOCHBERG Y, 1987, MULITIPLE COMPARISIO; Huang SG, 2006, J COMPUT BIOL, V13, P786, DOI 10.1089/cmb.2006.13.786; Kerr MK, 2001, BIOSTATISTICS, V2, P183, DOI DOI 10.1093/BIOSTATISTICS/2.2.183; Landgrebe J, 2006, COMPUT STAT DATA AN, V50, P499, DOI 10.1016/j.csda.2004.08.014; Lee MLT, 2005, J BIOPHARM STAT, V15, P783, DOI 10.1081/BIP-200067778; Parmigiani G., 2003, ANAL GENE EXPRESSION; POLLARD K, 2003, 107 DIV BIOST UC BER; Sabatti C, 2002, MATH BIOSCI, V176, P17, DOI 10.1016/S0025-5564(01)00102-X; Schena M, 2000, MICROARRAY BIOCHIP T; Skubitz KM, 2006, J LAB CLIN MED, V147, P250, DOI 10.1016/j.lab.2006.04.001; Steibel JP, 2005, STAT APPL GENET MO B, V4; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Tardella L, 2002, BIOMETRIKA, V89, P807, DOI 10.1093/biomet/89.4.807; TUSCHER VG, 2001, P NATL ACAD SCI USA, V98, P5116; Wolfinger RD, 2001, J COMPUT BIOL, V8, P625, DOI 10.1089/106652701753307520	30	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUL 15	2007	51	11					5253	5265		10.1016/j.csda.2006.08.009		13	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	192NB	WOS:000248207700006	
J	Ball, NM; Brunner, RJ; Myers, AD; Strand, NE; Alberts, SL; Tcheng, D; Llora, X				Ball, Nicholas M.; Brunner, Robert J.; Myers, Adam D.; Strand, Natalie E.; Alberts, Stacey L.; Tcheng, David; Llora, Xavier			Robust machine learning applied to astronomical data sets. II. quantifying photometric redshifts for quasars using instance-based learning	ASTROPHYSICAL JOURNAL			English	Article						catalogs; cosmology : miscellaneous; methods : data analysis; quasars : general	DIGITAL-SKY-SURVEY; HUBBLE DEEP FIELD; ARTIFICIAL NEURAL-NETWORKS; LUMINOUS RED GALAXIES; EARLY DATA RELEASE; CLASSIFIED QUASARS; CLUSTERING ANALYSES; EVOLUTION; CATALOG; SDSS	We apply instance- based machine learning in the form of a k- nearest neighbor algorithm to the task of estimating photometric redshifts for 55,746 objects spectroscopically classified as quasars in the Fifth Data Release of the SloanDigital Sky Survey. We compare the results obtained to those froman empirical color- redshift relation ( CZR). In contrast to previously published results using CZRs, we find that the instance- based photometric redshifts are assigned with no regions of catastrophic failure. Remaining outliers are simply scattered about the ideal relation, in a manner similar to the pattern seen in the optical for normal galaxies at redshifts z less than or similar to 1. The instance- based algorithm is trained on a representative sample of the data and pseudoYblind- tested on the remaining unseen data. The variance between the photometric and spectroscopic redshifts is sigma(2) =0.123 +/- 0: 002 ( compared to sigma (2) =0.265 +/- 0. 006 for the CZR), and 54. 9% +/- 0: 7%, 73. 3% +/- 0.6%, and 80.7% +/- 0.3% of the objects are within Delta z < 0.1, 0.2, and 0.3, respectively. We also match our sample to the Second Data Release of the Galaxy Evolution Explorer legacy data, and the resulting 7642 objects show a further improvement, giving a variance of sigma(2) = 0.054 +/- 0. 005, with 70. 8% +/- 1. 2%, 85.8% +/- 1. 0%, and 90. 8% +/- 0.7% of objects within Delta z < 0. 1, 0.2, and 0.3. We show that the improvement is indeed due to the extra information provided by GALEX, by training on the same data set using purely SDSS photometry, which has a variance of sigma (2) = 0. 090 +/- 0. 007. Each set of results represents a realistic standard for application to further data sets for which the spectra are representative.	Univ Illinois, Dept Astron, Urbana, IL 61801 USA; Univ Illinois, Natl Ctr Supercomp Applicat, Urbana, IL 61801 USA; Univ Illinois, Dept Phys, Urbana, IL 61801 USA	Ball, NM (reprint author), Univ Illinois, Dept Astron, 1002 W Green St, Urbana, IL 61801 USA.						Abazajian K, 2004, ASTRON J, V128, P502, DOI 10.1086/421365; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Babbedge TSR, 2004, MON NOT R ASTRON SOC, V353, P654, DOI 10.1111/j.1365-2966.2004.08105.x; Ball NM, 2006, ASTROPHYS J, V650, P497, DOI 10.1086/507440; Ball NM, 2004, MON NOT R ASTRON SOC, V348, P1038, DOI 10.1111/j.1365-2966.2004.07429.x; BAUM WA, 1962, IAU S, V15, P390; Beckwith SVW, 2006, ASTRON J, V132, P1729, DOI 10.1086/507302; Benitez N, 2000, ASTROPHYS J, V536, P571, DOI 10.1086/308947; Brunner R. J., 1997, APJ, V482, P21; Brunner RJ, 2000, ASTROPHYS J, V541, P527, DOI 10.1086/309488; Budavari T, 2001, ASTRON J, V122, P1163, DOI 10.1086/322131; Cannon R, 2006, MON NOT R ASTRON SOC, V372, P425, DOI 10.1111/j.1365-2966.2006.10875.x; CARDELLI JA, 1989, ASTROPHYS J, V345, P245, DOI 10.1086/167900; Coe D, 2006, ASTRON J, V132, P926, DOI 10.1086/505530; Collister A, 2007, MON NOT R ASTRON SOC, V375, P68, DOI 10.1111/j.1365-2966.2006.11305.x; Collister AA, 2004, PUBL ASTRON SOC PAC, V116, P345, DOI 10.1086/383254; CONNOLLY AJ, 1998, APJ, V499, P125; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Croom SM, 2004, MON NOT R ASTRON SOC, V349, P1397, DOI 10.1111/j.1365-2966.2004.07619.x; Csabai I, 2003, ASTRON J, V125, P580, DOI 10.1086/345883; Eisenstein DJ, 2001, ASTRON J, V122, P2267, DOI 10.1086/323717; Firth AE, 2003, MON NOT R ASTRON SOC, V339, P1195, DOI 10.1046/j.1365-8711.2003.06271.x; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Goldberg DE, 2002, DESIGN INNOVATION; Gwyn SDJ, 1996, ASTROPHYS J, V468, pL77, DOI 10.1086/310237; Hastie T, 2001, ELEMENTS STAT LEARNI; Haupt R., 1998, PRACTICAL GENETIC AL; Hogg DW, 1998, ASTRON J, V115, P1418, DOI 10.1086/300277; HOLLAND JH, 1975, ADAPTATION NATURAL A; KOO DC, 1985, ASTRON J, V90, P418, DOI 10.1086/113748; Lanzetta KM, 1996, NATURE, V381, P759, DOI 10.1038/381759a0; LAWRENCE A, 2006, UNPUB MNRAS; LOH ED, 1986, ASTROPHYS J, V303, P154, DOI 10.1086/164062; Martin DC, 2005, ASTROPHYS J, V619, pL1, DOI 10.1086/426387; MOBASHER B, 1996, MNRAS, V282, P7; Myers AD, 2006, ASTROPHYS J, V638, P622, DOI 10.1086/499093; Myers AD, 2007, ASTROPHYS J, V658, P85, DOI 10.1086/511519; Myers AD, 2007, ASTROPHYS J, V658, P99, DOI 10.1086/511520; Padmanabhan N, 2005, MON NOT R ASTRON SOC, V359, P237, DOI 10.1111/j.1365-2966.2005.08915.x; Richards GT, 2001, ASTRON J, V122, P1151, DOI 10.1086/322132; Sawicki MJ, 1997, ASTRON J, V113, P1, DOI 10.1086/118231; Schlegel DJ, 1998, ASTROPHYS J, V500, P525, DOI 10.1086/305772; Skrutskie MF, 2006, ASTRON J, V131, P1163, DOI 10.1086/498708; Stoughton C, 2002, ASTRON J, V123, P485, DOI 10.1086/324741; TAGLIAFERRI R, 2002, ASTROPH0203445; Vanden Berk DE, 2005, ASTRON J, V129, P2047, DOI 10.1086/427856; Vanzella E, 2004, ASTRON ASTROPHYS, V423, P761, DOI 10.1051/0004-6361:20040176; Wadadekar Y, 2005, PUBL ASTRON SOC PAC, V117, P79, DOI 10.1086/427710; Wang Y, 1998, ASTRON J, V116, P2081, DOI 10.1086/300592; Way MJ, 2006, ASTROPHYS J, V647, P102, DOI 10.1086/505293; Weinstein MA, 2004, ASTROPHYS J SUPPL S, V155, P243, DOI 10.1086/425355; WELGE M, 2003, DATA KNOWLEDGE; Werner MW, 2004, ASTROPHYS J SUPPL S, V154, P1, DOI 10.1086/422992; Williams RE, 2000, ASTRON J, V120, P2735, DOI 10.1086/316854; Williams RE, 1996, ASTRON J, V112, P1335, DOI 10.1086/118105; Witten I. H., 2000, DATA MINING; Wolf C, 2003, ASTRON ASTROPHYS, V408, P499, DOI 10.1051/0004-6361:20030990; Wolf C, 2004, ASTRON ASTROPHYS, V421, P913, DOI 10.1051/0004-6361:20040525; Wu XB, 2004, CHINESE J ASTRON AST, V4, P17; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513	60	23	24	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X		ASTROPHYS J	Astrophys. J.	JUL 10	2007	663	2	1				774	780		10.1086/518362		7	Astronomy & Astrophysics	Astronomy & Astrophysics	189PR	WOS:000248001500007	
J	Shen, HB; Yang, J; Chou, KC				Shen, H.-B.; Yang, J.; Chou, K.-C.			Euk-PLoc: an ensemble classifier for large-scale eukaryotic protein subcellular location prediction	AMINO ACIDS			English	Article						cellular networking; subcellular compartment; KNN classifier; fusion; voting; gene ontology; amphiphilic pseudo amino acid composition	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; SORTING SIGNALS; GENE ONTOLOGY; LOCALIZATION; SEQUENCE; REPRESENTATION; SPECTRUM	With the avalanche of newly-found protein sequences emerging in the post genomic era, it is highly desirable to develop an automated method for fast and reliably identifying their subcellular locations because knowledge thus obtained can provide key clues for revealing their functions and understanding how they interact with each other in cellular networking. However, predicting subcellular location of eukaryotic proteins is a challenging problem, particularly when unknown query proteins do not have significant homology to proteins of known subcellular locations and when more locations need to be covered. To cope with the challenge, protein samples are formulated by hybridizing the information derived from the gene ontology database and amphiphilic pseudo amino acid composition. Based on such a representation, a novel ensemble hybridization classifier was developed by fusing many basic individual classifiers through a voting system. Each of these basic classifiers was engineered by the KNN ( K-Nearest Neighbor) principle. As a demonstration, a new benchmark dataset was constructed that covers the following 18 localizations: ( 1) cell wall, ( 2) centriole, ( 3) chloroplast, ( 4) cyanelle, ( 5) cytoplasm, ( 6) cytoskeleton, ( 7) endoplasmic reticulum, ( 8) extracell, ( 9) Golgi apparatus, ( 10) hydrogenosome, ( 11) lysosome, ( 12) mitochondria, ( 13) nucleus, ( 14) peroxisome, ( 15) plasma membrane, ( 16) plastid, ( 17) spindle pole body, and ( 18) vacuole. To avoid the homology bias, none of the proteins included has >= 25% sequence identity to any other in a same subcellular location. The overall success rates thus obtained via the 5-fold and jackknife cross-validation tests were 81.6 and 80.3%, respectively, which were 40-50% higher than those performed by the other existing methods on the same strict dataset. The powerful predictor, named "Euk-PLoc'', is available as a web-server at http:// 202.120.37.186/ bioinf/euk. Furthermore, to support the need of people working in the relevant areas, a downloadable file will be provided at the same website to list the results predicted by Euk-PLoc for all eukaryotic protein entries ( excluding fragments) in Swiss-Prot database that do not have subcellular location annotations or are annotated as being uncertain. The large-scale results will be updated twice a year to include the new entries of eukaryotic proteins and reflect the continuous development of Euk-PLoc.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Shen, HB (reprint author), Gordon Life Sci Inst, 13784 Torrey Mar Dr, San Diego, CA 92130 USA.	kchow@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Camon E, 2004, NUCLEIC ACIDS RES, V32, P262; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 1997, PROTEINS, V28, P99, DOI 10.1002/(SICI)1097-0134(199705)28:1<99::AID-PROT10>3.0.CO;2-C; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2000, ANAL BIOCHEM, V286, P1, DOI 10.1006/abio.2000.4757; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hoglund A, 2006, BIOINFORMATICS, V22, P1158, DOI 10.1093/bioinformatics/btl002; Juty N, 2012, NUCLEIC ACIDS RES, V40, P580; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lee Vivian, 2005, In Silico Biology, V5, P5; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Liu H, 2005, BIOCHEM BIOPH RES CO, V338, P1005, DOI 10.1016/j.bbrc.2005.10.046; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Radford T, 2003, SCIENTIST, V17, P24; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, AMINO ACIDS, V28, P395, DOI 10.1007/s00726-005-0189-6; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang SQ, 2006, J THEOR BIOL, V242, P941, DOI 10.1016/j.jtbi.2006.05.006; WEN Z, 2007, IN PRESS AMINO ACIDS; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	68	87	88	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0939-4451		AMINO ACIDS	Amino Acids	JUL	2007	33	1					57	67		10.1007/s00726-006-0478-8		11	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	192FM	WOS:000248186200006	
J	Read, I; Cox, S				Read, Ian; Cox, Stephen			Stochastic and syntactic techniques for predicting phrase breaks	COMPUTER SPEECH AND LANGUAGE			English	Article						text-to-speech; prosody; phrase breaks	PERFORMANCE STRUCTURES; SPEECH	Determining the position of breaks in a sentence is a key task for a text-to-speech system. A synthesized sentence containing incorrect breaks at best requires increased listening effort, and at worst, may have lower intelligibility and different semantics from a correctly phrased sentence. In addition, the position of breaks must be known before other components of the sentence's prosodic structure can be determined. We consider here some methods for phrase break prediction in which the whole sentence is analysed, in contrast to most previous work which has focused on analysing an area around an individual juncture. One of the main features we use is part-of-speech tags. First, we report an algorithm that reduces the number of tags in the tagset whilst improving break prediction accuracy. We then describe three approaches to break prediction: by analogy, in which we find the best-matching sentence in our training data to the unseen sentence; by phrase modelling, in which we build stochastic models of phrases and use these, together with a "phrase grammar", to segment the unseen sentence; and finally, using features derived from a syntactic parse of the sentence. All techniques achieve well above our baseline performance, which used punctuation symbols to determine break positions, and performance increased with each successive technique. Our best result, obtained on the MARSEC corpus and using a combination of parse tree derived features and a local feature, gave an F score of 81.6%, which we believe to be the highest published on this dataset. (c) 2006 Published by Elsevier Ltd.	Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England	Read, I (reprint author), Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.	ihr@cmp.uea.ac.uk; sjc@cmp.uea.ac.uk					ALLEN J, 1979, SPEECH COMM 7 M ASA, P507; Bachenko J., 1990, Computational Linguistics, V16; Beckman Mary E., 1986, PHONOLOGY YB, V3, P255; BELLMAN R, 1962, J ACM, V9, P61, DOI 10.1145/321105.321111; Breiman L, 1984, CLASSIFICATION REGRE; Brill E, 1995, COMPUT LINGUIST, V21, P543; Busser G., 2001, P 4 ISCA TUT RES WOR, P29; CAMPBELL WN, 1991, J PHONETICS, V19, P37; CHARNIAK E, 2000, P ANLP NAACL SEATTL; Church K. W., 1991, Computer Speech and Language, V5, DOI 10.1016/0885-2308(91)90016-J; Collins M., 1999, THESIS U PENNSYLVANI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX S, 2005, P EUR LISB PORT; DAELEMANS W, 2004, ILK RES GROUP TECHNI, V402; DAELEMANS W, 1996, 4 WORKSH VER LARG CO, P14; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DOMMERGUES JY, 1981, MEM COGNITION, V9, P478, DOI 10.3758/BF03202342; Duda R.O., 2000, PATTERN CLASSIFICATI; FACH M, 1999, EUROSPEECH, V1, P527; FORNEY GD, 1973, P IEEE, V61, P3; GEE JP, 1983, COGNITIVE PSYCHOL, V15, P411, DOI 10.1016/0010-0285(83)90014-2; GOOD IJ, 1953, BIOMETRIKA, V40, P16; GROSJEAN F, 1979, COGNITIVE PSYCHOL, V11, P58, DOI 10.1016/0010-0285(79)90004-5; Hirschberg J, 1996, SPEECH COMMUN, V18, P281, DOI 10.1016/0167-6393(96)00017-9; Hirschberg J., 1993, ARTIFICIAL INTELLIGE, V63; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KOEHN P, 2000, P INT C AC SPEECH SI; Levenshtein V. I., 1966, CYBERNETICS CONTROL, V10, P707; MARSI E, 2003, P 41 ANN M ASS COMP; Ostendorf M., 1995, ECS95001 BOST U; Pearl J., 1984, HEURISTICS INTELLIGE; Pierrehumbert J, 1980, THESIS MIT; Pitrelli J., 1994, P 3 INT C SPOK LANG, P123; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; READ IH, 2004, P INT C SPOK LANG PR; ROACH P, 1992, J INT PHONETIC ASS, V23, P47; SANTORINI B, 1990, PART OF SPEECH TAGGI; Silverman K., 1987, THESIS U CAMBRIDGE; Silverman K., 1992, P INT C SPOK LANG PR, V2, P867; SORIN C, 1987, P INT C PHON SCI, V1, P125; Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041; VANRIJSBERGEN CJ, 1975, INFORM RETRIEVAL; van Santen J, 1998, MULTILINGUAL TEXT-TO-SPEECH SYNTHESIS: THE BELL LABS APPROACH, P115; Ostendorf M., 1994, Computational Linguistics, V20; WANG M, 1992, COMPUTER SPEECH LANG, V6; Young S., 2002, HTK BOOK HTK VERSION	46	4	5	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0885-2308		COMPUT SPEECH LANG	Comput. Speech Lang.	JUL	2007	21	3					519	542		10.1016/j.csl.2006.09.004		24	Computer Science, Artificial Intelligence	Computer Science	152IM	WOS:000245355600006	
J	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Qu, YL; Wang, ZH				Shang, Wenqian; Huang, Houkuan; Zhu, Haibin; Lin, Yongmin; Qu, Youli; Wang, Zhihai			A novel feature selection algorithm for text categorization	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						text feature selection; text categorization; Gini index; kNN classifier; text preprocessing	NEAREST NEIGHBOR	With the development of the web, large numbers of documents are available on the Internet. Digital libraries, news sources and inner data of companies surge more and more. Automatic text categorization becomes more and more important for dealing with massive data. However the major problem of text categorization is the high dimensionality of the feature space. At present there are many methods to deal with text feature selection. To improve the performance of text categorization, we present another method of dealing with text feature selection. Our study is based on Gini index theory and we design a novel Gini index algorithm to reduce the high dimensionality of the feature space. A new measure function of Gini index is constructed and made to fit text categorization. The results of experiments show that our improvements of Gini index behave better than other methods of feature selection. (c) 2006 Elsevier Ltd. All rights reserved.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; Nipissing Univ, Dept Comp Sci, N Bay, ON P1B 8L7, Canada	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	shangwenqian@hotmail.com; haibinz@npissingu.ca					Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gupta S. K., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707410; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D.D., 1994, P 3 ANN S DOC AN INF, P81; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Rijsbergen V., 1979, INFORM RETRIEVAL; SHANG W, 2005, P INT C COMP INT SEC, P741; Shankar S., FEATURE WEIGHT ADJUS; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vapnik V.N., 1995, NATURE STAT LEARNING; Yang Y, 1997, INFORM RETRIEVAL, V1, P76; Yang Y, 1997, P 14 INT C MACH LEAR, P412; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647	16	37	40	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174		EXPERT SYST APPL	Expert Syst. Appl.	JUL	2007	33	1					1	5		10.1016/j.eswa.2006.04.001		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	134UV	WOS:000244110600001	
J	Srdoc, A; Bratko, I; Sluga, A				Srdoc, Alira; Bratko, Ivan; Sluga, Alojzij			Machine learning applied to quality management - A study in ship repair domain	COMPUTERS IN INDUSTRY			English	Article						quality management; knowledge acquisition; deep quality concept; delivery time estimate; dock works	KNOWLEDGE	The awareness about the importance of knowledge within the quality management community is increasing. For example, the Malcolm Baldrige Criteria for Performance Excellence recently included knowledge management into one of its categories. However, the emphasis in research related to knowledge management is mostly on knowledge creation and dissemination, and not knowledge formalisation process. On the other hand, identifying the expert knowledge and experience as crucial for the output quality, especially in dynamic industries with high share of incomplete and unreliable information such as ship repair, this paper argues how important it is to have such knowledge formalised. The paper demonstrates by example of delivery time estimate how for that purpose the deep quality concept (DQC)-a novel knowledge-focused quality management framework, and machine learning methodology could be effectively used. In the concluding part of the paper, the accuracy of the obtained prediction models is analysed, and the chosen model is discussed. The research indicates that standardisation of problem domain notions and expertly designed databases with possible interface to machine learning algorithms need to be considered as an integral part of any quality management system in the future, in addition to conventional quality management concepts. (C) 2006 Elsevier B.V. All rights reserved.	Dept Res & Dev, Rijeka 51000, Croatia; Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia; Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia; Jozef Stefan Inst, Fac Mech Engn, Ljubljana 1000, Slovenia	Srdoc, A (reprint author), Dept Res & Dev, 3 Maj Shipyard,Liburnijska 3, Rijeka 51000, Croatia.	alira.srdoc@3maj.hr	Sluga, Alojzij/A-7161-2008				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Al-Hawamdeh S., 2002, INFORM RES, V8; Armstrong J.S., 2001, PRINCIPLES FORECASTI; BRATKO I, 2001, PROLOG PROGRAMMING A; Breiman L, 1984, CLASSIFICATION REGRE; Burr Ridge I, 1997, MACHINE LEARNING; Chryssolouris G, 2003, CIRP J MANUFACTURING, V32; Coff RW, 2002, J MANAGE, V28, P107, DOI 10.1177/014920630202800107; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOOLEY K, 2000, PARADIGMS QUALITY EV; DOOLEY K, 2000, J QUALITY MANAGEMENT, V4, P207; DZEROSKI S, 2003, ECOLOGICAL MODELLING, V170, P19; FILIPIC B, 1994, P 8 INT C COMP APPL; KARALIC A, 1992, LINEAR REGRESSION RE; Linderman K, 2004, J OPER MANAG, V22, P589, DOI 10.1016/j.jom.2004.07.001; MASSOW C, 2005, P COMPIT; Meziane F., 2000, Integrated Manufacturing Systems, V11, DOI 10.1108/09576060010326221; MONOSTORI L, 1996, ANN CIRP, V45, P675; PEKLENIK J, 1995, MANUFACTURING SYSTEM, V24, P17; PETERAF MA, 1993, STRATEGIC MANAGE J, V14, P179, DOI 10.1002/smj.4250140303; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shigaki I, 2001, PROD PLAN CONTROL, V12, P379, DOI 10.1080/09537280010014695; Shigaki I, 1999, PROD PLAN CONTROL, V10, P727, DOI 10.1080/095372899232551; Simon H. A., 1981, SCI ARTIFICIAL; SIRE RA, 1992, INT J PRES VES PIP, V50, P297, DOI 10.1016/0308-0161(92)90044-G; Sluga A, 1998, COMPUT IND, V37, P185, DOI 10.1016/S0166-3615(98)00098-0; Spindler GR, 2001, QUAL PROG, V34, P83; Srdoc A., 2005, International Journal of Quality Reliability Management, V22, DOI 10.1108/02656710510582499; STIMSON WA, 1993, NAV ENG J, V105, P59; Todd J, 1999, NAV ENG J, V111, P257; Witten I. H., 2000, DATA MINING PRACTICA	31	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-3615		COMPUT IND	Comput. Ind.	JUN	2007	58	5					464	473		10.1016/j.compind.2006.09.013		10	Computer Science, Interdisciplinary Applications	Computer Science	168UI	WOS:000246549100008	
J	Scott, C; Davenport, M				Scott, Clayton; Davenport, Mark			Regression level set estimation via cost-sensitive classification	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						cost-sensitive classification; learning reduction; regression level set estimation; supervised learning		Regression level set estimation is an important yet understudied learning task. It lies somewhere between regression function estimation and traditional binary classification, and in many cases is a more appropriate setting for questions posed in these more common frameworks. This note explains how estimating the level set of a regression function from training examples can be reduced to cost-sensitive classification. We discuss the theoretical and algorithmic benefits of this learning reduction, demonstrate several desirable properties of the associated risk, and report experimental results for histograms, support vector machines, and nearest neighbor rules on synthetic and real data.	Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA; Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA	Scott, C (reprint author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.	cscott@eecs.umich.edu; md@rice.edu					Beygelzimer A., 2005, P 22 INT MACH LEARN; Cavalier L, 1997, STATISTICS, V29, P131, DOI 10.1080/02331889708802579; Chang C-C., 2001, LIBSVM LIB SUPPORT V; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Elkan C, 2001, P 17 INT JOINT C ART, P973; Joachims T., 1999, ADV KERNEL METHODS S; Man TK, 2005, CANCER RES, V65, P8142, DOI 10.1158/0008-5472.CAN-05-0985; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; Scholkopf B., 2002, LEARNING KERNELS; Tsybakov AB, 2004, ANN STAT, V32, P135; Vapnik V., 1995, NATURE STAT LEARNIN; WILLETT R, 2006, IEEE T IMAGE PROCESS; WILLETT R, 2005, P SPIE, V5914; ZADROZNY B, 2003, P 3 INT C DAT MIN ME	17	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X		IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	JUN	2007	55	6	1				2752	2757		10.1109/TSP.2007.893758		6	Engineering, Electrical & Electronic	Engineering	170ZQ	WOS:000246705100035	
J	Carrizosa, E; Martin-Barragan, B; Plastria, F; Morales, DR				Carrizosa, Emilio; Martin-Barragan, Belen; Plastria, Frank; Morales, Dolores Romero			On the selection of the globally optimal prototype subset for nearest-neighbor classification	INFORMS JOURNAL ON COMPUTING			English	Article						classification; optimal prototype subset; nearest neighbor; dissimilarities; integer programming; variable neighborhood search; missing values	PATTERN-CLASSIFICATION; GENETIC ALGORITHMS; SEARCH	The nearest-neighbor classifier has been shown to be a powerful tool for multiclass classification. We explore both theoretical properties and empirical behavior of a variant method, in which the nearest-neighbor rule is applied to a reduced set of prototypes. This set is selected a priori by fixing its cardinality and minimizing the empirical misclassification cost. In this way we alleviate the two serious drawbacks of the nearest-neighbor method: high storage requirements and time-consuming queries. Finding this reduced set is shown to be NP-hard. We provide mixed integer programming (MIP) formulations, which are theoretically compared and solved by a standard MIP solver for small problem instances. We show that the classifiers derived from these formulations are comparable to benchmark procedures. We solve large problem instances by a metaheuristic that yields good classification rules in reasonable time. Additional experiments indicate that prototype-based nearest-neighbor classifiers remain quite stable in the presence of missing values.	Univ Seville, Fac Matemat, Seville 41012, Spain; Univ Carlos III Madrid, Dept Estadist, Madrid 28903, Spain; Vrije Univ Brussels, Dept Math Operat Res Stat & Informat Syst Managem, MOSI, B-1050 Brussels, Belgium; Univ Oxford, Said Sch Business, Oxford OX1 1HP, England	Carrizosa, E (reprint author), Univ Seville, Fac Matemat, Seville 41012, Spain.	ecarrizosa@us.es; belen.martin@uc3m.es; frank.plastria@vub.ac.be; dolores.romero-morales@sbs.ox.ac.uk					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; ALTSCHUL SF, 1994, NAT GENET, V6, P119, DOI 10.1038/ng0294-119; Bennett MV, 2004, INFORMS J COMPUT, V16, P68, DOI 10.1287/ijoc.1020.0004; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; BLAKE C, 1998, UCI REPOSITORY MACH; Breiman L, 1984, CLASSIFICATION REGRE; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CARRIZOSA E, 2005, RM02027 U MASSTR; Cochran W. G, 1977, SAMPLING TECHNIQUES; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Devroye L, 1996, PROBABILISTIC THEORY; FREED N, 1981, EUR J OPER RES, V7, P44, DOI 10.1016/0377-2217(81)90048-5; Garey M.R., 1979, COMPUTERS INTRACTABI; GEHRLEIN WV, 1986, OPER RES LETT, V5, P299, DOI 10.1016/0167-6377(86)90068-4; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; Gochet W, 1997, OPER RES, V45, P213, DOI 10.1287/opre.45.2.213; Hansen P, 2001, EUR J OPER RES, V130, P449, DOI 10.1016/S0377-2217(00)00100-4; Hansen P, 2001, J HEURISTICS, V7, P335, DOI 10.1023/A:1011336210885; Hansen P., 1997, Location Science, V5, DOI 10.1016/S0966-8349(98)00030-8; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 2001, ELEMENTS STAT LEARNI; Kaufman L., 1990, FINDING GROUPS DATA; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; MANGASARIAN OL, 1994, J GLOBAL OPTIM, V5, P309, DOI 10.1007/BF01096681; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Plastria F, 2002, EUR J OPER RES, V140, P338, DOI 10.1016/S0377-2217(02)00073-5; PLASTRIA F, 2001, LOCATOR PUBLICATION, V2, P15; Plastria F, 1995, FACILITY LOCATION SU, P229; Thompson S. K., 2002, SAMPLING; Yang MS, 2001, FUZZY SET SYST, V120, P197, DOI 10.1016/S0165-0114(99)00146-3; ZIMMERMANN HJ, 1991, FUZZY SET THEORY APP	39	4	4	INFORMS	HANOVER	7240 PARKWAY DRIVE, STE 310, HANOVER, MD 21076-1310 USA	1091-9856		INFORMS J COMPUT	INFORMS J. Comput.	SUM	2007	19	3					470	479		10.1287/ijoc.1060.0183		10	Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	203RD	WOS:000248990800014	
J	Ghosh, AK				Ghosh, Anil K.			On nearest neighbor classification using adaptive choice of k	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Bayesian strength function; cross-validation; misclassification rate; noninformative prior; optimal bayes risk; posterior probability; p value; robustness		Nearest neighbor classification is one of the simplest and popular methods for statistical pattern recognition. It classifies an observation x to the class, which is the most frequent in the neighborhood of x. The size of this neighborhood is usually determined by a predefined parameter k. Normally, one uses cross-validation techniques to estimate the optimum value of this parameter, and that estimated value is used for classifying all observations. However, in classification problems, in addition to depending on the training sample, a good choice of k depends on the specific observation to be classified. Therefore, instead of using a fixed value of k over the entire measurement space, a spatially adaptive choice of k may be more useful in practice. This article presents one such adaptive nearest neighbor classification technique, where the value of k is selected depending on the distribution of competing classes in the vicinity of the observation to be classified. The utility of the proposed method has been illustrated using some simulated examples and well-known benchmark datasets. Asymptotic optimality of its misclassification rate has been derived under appropriate regularity conditions.	Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India	Ghosh, AK (reprint author), Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India.	anilkghosh@rediffmail.com					Aho A.V., 1974, DESIGN ANAL COMPUTER; Anderson T., 1984, INTRO MULTIVARIATE S; Andrews D. F., 1985, DATA COLLECTION PROB; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Efron B., 1993, INTRO BOOTSTRAP; Fix E., 1951, 4 USAF SCH AV MED, P261; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Ghosh AK, 2006, IEEE T SYST MAN CY B, V36, P1139, DOI 10.1109/TSMCB.2006.873186; GHOSH AK, 2004, THESIS INDIAN STAT I; Gilks W.R., 1996, MARKOV CHAIN MONTE C; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2001, ELEMENTS STAT LEARNI; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Ripley B. D., 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; SEIGMUND D, 1985, SEQUENTIAL ANAL TEST; Silverman B.W., 1986, DENSITY ESTIMATION S; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Wald A., 1973, SEQUENTIAL ANAL; WETTSCHERECK D, 1994, ADV NEURAL INFORMATI, V6, P184; Wichern D. W., 1992, APPL MULTIVARIATE ST	34	3	3	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600		J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2007	16	2					482	502		10.1198/106186007x208380		21	Statistics & Probability	Mathematics	176AY	WOS:000247056300011	
J	Chin, CM; Popovic, MR; Thrasher, A; Cameron, T; Lozano, A; Chen, R				Chin, Cesar Marquez; Popovic, Milos R.; Thrasher, Adam; Cameron, Tracy; Lozano, Andres.; Chen, Robert			Identification of arm movements using correlation of electrocorticographic spectral components and kinematic recordings	JOURNAL OF NEURAL ENGINEERING			English	Article							BRAIN-COMPUTER-INTERFACE; HUMAN SENSORIMOTOR CORTEX; EVENT-RELATED DESYNCHRONIZATION; THOUGHT TRANSLATION DEVICE; LOCAL-FIELD POTENTIALS; SELF-PACED MOVEMENT; HUMAN MOTOR CORTEX; PARKINSONS-DISEASE; VISUOMOTOR TASKS; P300 SPELLER	The purpose of this study was to explore the possibility of using electrocorticographic (ECoG) recordings from subdural electrodes placed over the motor cortex to identify the upper limb motion performed by a human subject. More specifically, we were trying to identify features in the ECoG signals that could help us determine the type of movement performed by an individual. Two subjects who had subdural electrodes implanted over the motor cortex were asked to perform various motor tasks with the upper limb contralateral to the site of electrode implantation. ECoG signals and. upper limb kinematics were recorded while the participants were performing the movements. ECoG frequency components were identified that correlated well with the performed movements measured along 6D coordinates (X, Y, Z, roll, yaw and pitch). These frequencies were grouped using histograms. The resulting histograms had consistent and unique shapes that were representative of individual upper limb movements performed by the participants. Thus, it was possible to identify which movement was performed by the participant without prior knowledge of the arm and hand kinematics. To confirm these findings, a nearest neighbour classifier was applied to identify the specific movement that each participant had performed. The achieved classification accuracy was 89%.	Univ Toronto, Inst Biomat & Biomed Engn, Toronto, ON M5S 3G9, Canada; Toronto Rehabil Inst, Rehabil Engn Lab, Toronto, ON M4G 3V9, Canada; Univ Toronto, Univ Hlth Network, Toronto Western Res Inst, Toronto, ON M5T 2S8, Canada; Univ Toronto, Dept Surg, Toronto, ON M5T 2S8, Canada; Univ Toronto, Dept Med, Div Neurol, Toronto, ON M5T 2S8, Canada	Chin, CM (reprint author), Univ Toronto, Inst Biomat & Biomed Engn, 164 Coll St, Toronto, ON M5S 3G9, Canada.	cesar.marquezchin@utoronto.ca; milos.popovic@utoronto.ca	Chen, Robert/B-3899-2009				AN KN, 1988, J BIOMECH, V21, P613, DOI 10.1016/0021-9290(88)90225-4; Aoki F, 2001, BIOSYSTEMS, V63, P89, DOI 10.1016/S0303-2647(01)00149-6; Aoki F, 1999, CLIN NEUROPHYSIOL, V110, P524, DOI 10.1016/S1388-2457(98)00064-9; Birbaumer N, 2000, IEEE T REHABIL ENG, V8, P190, DOI 10.1109/86.847812; COOPER R, 2005, TECHNIQUES CLIN NEUR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crone NE, 1998, BRAIN, V121, P2301, DOI 10.1093/brain/121.12.2301; Crone NE, 1998, BRAIN, V121, P2271, DOI 10.1093/brain/121.12.2271; Deng Jie, 2005, J Neural Eng, V2, P131, DOI 10.1088/1741-2560/2/4/009; Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808; Duda R. O., 2001, PATTERN CLASSIFICATI; Friehs GM, 2004, STROKE, V35, P2702, DOI 10.1161/01.STR.0000143235.93497.03; Gonzalez SL, 2006, NEUROIMAGE, V32, P170, DOI 10.1016/j.neuroimage.2006.02.041; Graimann B, 2003, IEEE T NEUR SYS REH, V11, P276, DOI 10.1109/TNSRE.2003.816863; Graimann B, 2004, IEEE T BIO-MED ENG, V51, P954, DOI 10.1109/TBME.2004.826671; Hanajima R, 2002, CLIN NEUROPHYSIOL, V113, P635, DOI 10.1016/S1388-2457(02)00042-1; Heldman DA, 2006, IEEE T NEUR SYS REH, V14, P180, DOI 10.1109/TNSRE.2006.875549; Hill NJ, 2006, IEEE T NEUR SYS REH, V14, P183, DOI 10.1109/TNSRE.2006.875548; Hinterberger T, 2004, IEEE T BIO-MED ENG, V51, P1011, DOI 10.1109/TBME.2004.827067; Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970; Kauhanen L, 2006, IEEE T NEUR SYS REH, V14, P190, DOI 10.1109/TNSRE.2006.875546; Kauhanen L, 2006, CLIN NEUROPHYSIOL, V117, P430, DOI 10.1016/j.clinph.2005.10.024; Kennedy PR, 2000, IEEE T REHABIL ENG, V8, P198, DOI 10.1109/86.847815; Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007; Kubler A, 1999, EXP BRAIN RES, V124, P223, DOI 10.1007/s002210050617; Leuthardt EC, 2006, IEEE T NEUR SYS REH, V14, P194, DOI 10.1109/TNSRE.2006.875536; Leuthardt Eric C, 2004, J Neural Eng, V1, P63, DOI 10.1088/1741-2560/1/2/001; Levine SP, 1999, J CLIN NEUROPHYSIOL, V16, P439, DOI 10.1097/00004691-199909000-00005; Levine SP, 2000, IEEE T REHABIL ENG, V8, P180, DOI 10.1109/86.847809; Lozano AM, 2001, PARKINSONISM RELAT D, V7, P199, DOI 10.1016/S1353-8020(00)00057-2; Magnani G, 1998, MOVEMENT DISORD, V13, P653, DOI 10.1002/mds.870130408; Mayberg HS, 2005, NEURON, V45, P651, DOI 10.1016/j.neuron.2005.02.014; Mehring C, 2003, NAT NEUROSCI, V6, P1253, DOI 10.1038/nn1158; Mehring C, 2004, J PHYSIOLOGY-PARIS, V98, P498, DOI 10.1016/j.jphysparis.2005.09.016; Muller-Putz GR, 2005, NEUROSCI LETT, V382, P169, DOI 10.1016/j.neulet.2005.03.021; Naeem M, 2006, J NEURAL ENG, V3, P208, DOI 10.1088/1741-2560/3/3/003; Neuper C, 2003, CLIN NEUROPHYSIOL, V114, P399, DOI 10.1016/S1388-2457(02)00387-5; Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003; Pfurtscheller G, 2006, IEEE T NEUR SYS REH, V14, P205, DOI 10.1109/TNSRE.2006.875528; Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3; Pfurtscheller G, 2003, CLIN NEUROPHYSIOL, V114, P1226, DOI 10.1016/S1388-2457(03)00067-1; PFURTSCHELLER G, 1977, ELECTROEN CLIN NEURO, V42, P817, DOI 10.1016/0013-4694(77)90235-8; Pfurtscheller G, 2003, NEUROSCI LETT, V351, P33, DOI 10.1016/S0304-3940(03)00947-9; Popovic MR, 2001, IEEE ENG MED BIOL, V20, P82, DOI 10.1109/51.897831; Rickert J, 2005, J NEUROSCI, V25, P8815, DOI 10.1523/JNEUROSCI.0816-05.2005; Scherberger H, 2005, NEURON, V46, P347, DOI 10.1016/j.neuron.2005.03.004; Sellers EW, 2006, CLIN NEUROPHYSIOL, V117, P538, DOI 10.1016/j.clinph.2005.06.027; Sellers EW, 2006, IEEE T NEUR SYS REH, V14, P221, DOI 10.1109/TNSRE.2006.875580; Sellers EW, 2006, BIOL PSYCHOL, V73, P242, DOI 10.1016/j.biopsycho.2006.04.007; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; TORO C, 1994, ELECTROEN CLIN NEURO, V93, P390, DOI 10.1016/0168-5597(94)90127-9; Weiskopf N, 2004, IEEE T BIO-MED ENG, V51, P966, DOI 10.1109/TBME.2004.827063; Wessberg J, 2000, NATURE, V408, P361; Wilson JA, 2006, IEEE T NEUR SYS REH, V14, P246, DOI 10.1109/TNSRE.2006.875570; Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807; Yamawaki N, 2006, IEEE T NEUR SYS REH, V14, P250, DOI 10.1109/TNSRE.2006.875567	57	8	9	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1741-2560		J NEURAL ENG	J. Neural Eng.	JUN	2007	4	2					146	158		10.1088/1741-2560/4/2/014		13	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	188VL	WOS:000247947300020	
J	Shen, HB; Chou, KC				Shen, H.-B.; Chou, K.-C.			Using ensemble classifier to identify membrane protein types	AMINO ACIDS			English	Article						Type-I; Type-II; multi-pass transmembrane; lipid-chain-anchored; GPI-anchored; pseudo-amino acid composition; ensemble classifier; fusion; voting	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; SUBCELLULAR LOCATION; FOLDING TYPES	Predicting membrane protein type is both an important and challenging topic in current molecular and cellular biology. This is because knowledge of membrane protein type often provides useful clues for determining, or sheds light upon, the function of an uncharacterized membrane protein. With the explosion of newly-found protein sequences in the post-genomic era, it is in a great demand to develop a computational method for fast and reliably identifying the types of membrane proteins according to their primary sequences. In this paper, a novel classifier, the so-called "ensemble classifier", was introduced. It is formed by fusing a set of nearest neighbor (NN) classifiers, each of which is defined in a different pseudo amino acid composition space. The type for a query protein is determined by the outcome of voting among these constituent individual classifiers. It was demonstrated through the self-consistency test, jackknife test, and independent dataset test that the ensemble classifier outperformed other existing classifiers widely used in biological literatures. It is anticipated that the idea of ensemble classifier can also be used to improve the prediction quality in classifying other attributes of proteins according to their sequences.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				ALBERTS B, 1994, MOL BIOL CELL, pCH1; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, CURR PROTEIN PEPT SC, V6, P423, DOI 10.2174/138920305774329368; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; LODISH H, 1995, MOL CELL BIOL, pCH3; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; ROST B, 1995, PROTEIN SCI, V4, P521; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, J THEOR BIOL, V235, P555, DOI 10.1016/j.jtbi.2005.02.008; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251	38	63	66	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0939-4451		AMINO ACIDS	Amino Acids	MAY	2007	32	4					483	488		10.1007/s00726-006-0439-2		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	170BP	WOS:000246636500004	
J	Kohler, M; Krzyzak, A				Kohler, Michael; Krzyzak, Adam			On the rate of convergence of local averaging plug-in classification rules under a margin condition	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	IEEE International Symposium on Information Theory	JUL 09-14, 2006	Seattle, WA	IEEE Informat Theory Soc, USN, Dept Navy Sci & Technol, Microsoft, Natl Sci Fdn		classification; plug-in classifiers; rate of convergence; statistical learning	NONPARAMETRIC REGRESSION; POINTWISE CONSISTENCY; NEIGHBOR; DISCRIMINATION; CLASSIFIERS	The rates of convergence of plug-in kernel, partitioning, and nearest neighbors classification rules are analyzed. A margin condition, which measures how quickly the a posteriori probabilities cross the decision boundary, smoothness conditions on the a posteriori probabilities, and boundedness of the feature vector are imposed. The rates of convergence of the plug-in classifiers shown in this paper are faster than previously known.	Univ Saarland, Fachrichtung Math 6 1, D-66041 Saarbrucken, Germany; Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada	Kohler, M (reprint author), Univ Saarland, Fachrichtung Math 6 1, D-66041 Saarbrucken, Germany.	kohler@math.uni-sb.de; krzyzak@cs.concordia.ca					AUDIBERT JY, 2004, CLASSIFICATION POLYN; Audibert JY, 2007, ANN STAT, V35, P608, DOI 10.1214/009053606000001217; Beck J., 1979, Problems of Control and Information Theory, V8; Beirlant J, 1998, J STAT PLAN INFER, V71, P93, DOI 10.1016/S0378-3758(98)00008-1; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1982, Z WAHRSCHEINLICHKEIT, V61, P467, DOI 10.1007/BF00531618; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DEVROYE L, 1983, P 4 PANN S MATH STAT, P67; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; GREBLICKI W, 1984, ANN STAT, V12, P1570, DOI 10.1214/aos/1176346815; Gyorfi L., 2002, SPRINGER SERIES STAT; GYORFI L, 1991, NATO ADV SCI I C-MAT, V335, P329; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; Kohler M, 2006, J MULTIVARIATE ANAL, V97, P311, DOI 10.1016/j.jmva.2005.03.006; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mammen E, 1999, ANN STAT, V27, P1808; Massart P, 2006, ANN STAT, V34, P2326, DOI 10.1214/009053606000000786; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; Tsybakov AB, 2005, ANN STAT, V33, P1203, DOI 10.1214/009053604000001066; Tsybakov AB, 2004, ANN STAT, V32, P135; Vapnik V.N., 1998, STAT LEARNING THEORY; Walk H, 2001, ANN I STAT MATH, V53, P691, DOI 10.1023/A:1014692616736; Watson G.S., 1964, SANKHYA A, V26, P359	27	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	MAY	2007	53	5					1735	1742		10.1109/TIT.2007.894625		8	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	161RY	WOS:000246034600008	
J	Abbas, SR; Arif, M				Abbas, Syed Rahat; Arif, Muhammad			Modified nearest neighbor method for multistep ahead time series forecasting	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						multistep ahead forecasting; pattern selection; nearest neighbor; cross-correlation; long range forecasting; time series forecasting	CLASSIFICATION	Multistep ahead time series forecasting has become an important activity in various fields of science and technology due to its usefulness in future events management. Nearest neighbor search is a pattern matching algorithm for forecasting, and the accuracy of the method considerably depends on the similarity of the pattern found in the database with the reference pattern. Original time series is embedded into optimal dimension. The optimal dimension is determined by using autocorrelation function plot. The last vector in the embedded matrix is taken as the reference vector and all the previous vectors as candidate vectors. In nearest neighbor algorithm, the reference vector is matched with all the candidate vectors in terms of Euclidean distance and the best matched pattern is used for forecasting. In this paper, we have proposed a hybrid distance measure to improve the search of the nearest neighbor. The proposed method is based on cross-correlation and Euclidean distance. The candidate patterns are shortlisted by using cross-correlation and then Euclidean distance is used to select the best matched pattern. Moreover, in multistep ahead forecasting, standard nearest neighbor method introduces a bias in the search which results in higher forecasting errors. We have modified the search methodology to remove the bias by ignoring the latest forecasted value during the search of the nearest neighbor in the subsequent iteration. The proposed algorithm is evaluated on two benchmark time series as well as two real life time series.	Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Islamabad, Pakistan	Abbas, SR (reprint author), Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Islamabad, Pakistan.	rahatabbas@gmail.com; syedmarif2003@yahoo.com					ABBS SR, 2006, INT J PATTERN RECOGN, V20, P1261; ANDERSON O, 1976, SERIES ANAL FORECAST; Andrews D. F., 1985, DATA COLLECTION PROB; Atiya AF, 1999, IEEE T NEURAL NETWOR, V10, P402, DOI 10.1109/72.750569; BABOVIC V, 2000, 4 INT C HYDROINFORMA; BOX GEP, 1976, FORECASTING CONTROL; Chow TWS, 1996, IEEE T POWER SYST, V11, P1736, DOI 10.1109/59.544636; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANGELMAYR G, 1999, APPL SCI NEURAL NETW, V2; DAY SB, 1998, 5 INT C MACHINE LEAR; DJOUADI A, 2002, IEEE T PATTERN ANAL, V24, P1281; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fernandez-Rodriguez F, 1999, INT J FORECASTING, V15, P383, DOI 10.1016/S0169-2070(99)00003-5; GAUTAMA T, 2003, IEEE INT C ACOUSTICS; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Makridakis S, 1998, FORECASTING METHODS; Metaxiotis K, 2003, ENERG CONVERS MANAGE, V44, P1525, DOI 10.1016/S0196-8904(02)00148-6; Nock R, 2003, INT J PATTERN RECOGN, V17, P1369, DOI 10.1142/S0218001403002952; Principe JC, 1998, P IEEE, V86, P2240, DOI 10.1109/5.726789; SAUER T, 1993, TIME SERIES PREDICTI, P175; Small M, 2004, PHYSICA D, V194, P283, DOI 10.1016/j.physd.2004.03.006; SMALL M, 2002, PHYS REV E, V66, P701; SMALL M, 2000, IEEE INTELLIGENT TRA, P252; Takens F., 1981, LECT NOTES MATH, V898, P366; Weigend A, 1994, TIME SERIES PREDICTI	26	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	2007	21	3					463	481		10.1142/S0218001407005545		19	Computer Science, Artificial Intelligence	Computer Science	234PH	WOS:000251175500002	
J	Bai, MR; Chen, MC				Bai, Mingsain R.; Chen, Meng-Chun			Intelligent preprocessing and classification of audio signals	JOURNAL OF THE AUDIO ENGINEERING SOCIETY			English	Article								An audio processor that integrates intelligent classification and preprocessing algorithms is presented. Audio features in the time and frequency domains are extracted and processed prior to classification. Classification algorithms, including the nearest neighbor rule (NNR), artificial neural networks (ANN), fuzzy neural networks (FNN), and hidden Markov models (HMM), are used to classify and identify singers and musical instruments. A training phase is required to establish a feature space template, followed by a test phase in which the audio features of the test data are calculated and matched to the feature space template. In addition to audio classification, the proposed system provides several independent component analysis (ICA)-based preprocessing functions for blind source separation, voice removal, and noise reduction. The proposed techniques were applied to process various kinds of audio program materials. The test results reveal that the performance of the methods is satisfactory, but varies slightly with the algorithm and program materials used in the tests.	Natl Chiao Tung Univ, Dept Mech Engn, Hsinchu 300, Taiwan	Bai, MR (reprint author), Natl Chiao Tung Univ, Dept Mech Engn, Hsinchu 300, Taiwan.	msbai@mail.nctu.edu.tw; MaggieChen@tp.cmcs.com.tw					Chai W, 2001, P INT C ART INT LAS; CHANG WS, 2001, THESIS NATL CHIAO TU; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRYSANDT H, 2003, P SPIE STORAGE RETRI; Demuth H., 1998, NEURAL NETWORK TOOLB; Harma A, 2001, IEEE T SPEECH AUDI P, V9, P769, DOI 10.1109/89.966080; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; HYVARINEN A, 1998, A51 HELS U TECHN HEL; LAMBROU T, 1998, P INT C AC SPEECH SI, V6, P3621, DOI 10.1109/ICASSP.1998.679665; LI CJ, 2001, INT MECH ENG C EXP N; Lin CT, 1996, NEURAL FUZZY SYSTEMS; Livshin A.A., 2004, P 7 INT C DIG AUD EF; LIVSHIN AA, 2003, P INT COMP MUS C; Logan Beth, 2000, P INT S MUS INF RETR; Martin K.D., 1998, 136 M AC SOC AM; MARTINEZ JM, MPEG 7 OVERVIEW VERS; Peeters G., 2004, LARGE SET AUDIO FEAT; PEETERS G, 2002, P 2002 INT COMP MUS, P455; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SCOTT P, 2001, MUSIC CLASIFICATION; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; TZANETAKIS G, 2001, INT S MUS INF RETR; Wang CH, 2001, IEEE T SYST MAN CY B, V31, P467, DOI 10.1109/3477.931548; ZHANG T, 2003, IEEE INT C MULT EXP; ZONGKER D, 1996, P 13 INT C PATT REC	25	0	0	AUDIO ENGINEERING SOC	NEW YORK	60 E 42ND ST, NEW YORK, NY 10165-2520 USA	1549-4950		J AUDIO ENG SOC	J. Audio Eng. Soc.	MAY	2007	55	5					372	384				13	Acoustics; Engineering, Multidisciplinary	Acoustics; Engineering	175CI	WOS:000246989800003	
J	Nicoletti, MD; Figueira, LB; Hruschka, ER				Nicoletti, Maria do Carmo; Figueira, Lucas Baggio; Hruschka, Estevarn R., Jr.			Transferring neural network based knowledge into an exemplar-based learner	NEURAL COMPUTING & APPLICATIONS			English	Article						knowledge transfer; RuleNet; NGE; hybrid systems	NEAREST-NEIGHBOR; CLASSIFICATION	This paper investigates knowledge transfer from a neural network based system into an exemplar-based learning system. In order to examine the possibilities of such transfer, it proposes and evaluates a system that implements a collaborative scheme, where a particular type of neural network induced by the neural system RuleNet is used by an exemplar-based system (NGE) to carry on a learning task. The proposed collaboration between the two learning models implemented as the hybrid system RuleNet -> NGE is feasible due to the similarity of the concept description languages employed by both. The paper also describes a few experiments conducted; results show that the RuIeNet-NGE collaboration is plausible and, in some domains, it improves the performance of NGE on its own.	UFCar, Dept Comp Sci, Sao Carlos, SP, Brazil; Univ Sao Paulo, Dept Math & Phys, DFM, FFCLRP, Sao Carlos, SP, Brazil	Nicoletti, MD (reprint author), UFCar, Dept Comp Sci, Sao Carlos, SP, Brazil.	carmo@dc.ufscar.br; lucas@neuron.ffclrp.usp.br; estevam@dc.ufscar.br	Hruschka Jr., Estevam/B-1073-2008				Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hettich S., 1998, UCI REPOSITORY MACHI; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Nauck D, 1997, FDN NEUROFUZZY SYSTE; NICOLETTI MC, 2004, P INT C COMP CYB 200, P175; NICOLETTI MC, 2005, P HYBR INT SYST HIS, P125; NICOLETTI MC, 2005, INTELLIGENT SYSTEMS, V2, P365; SALZBERG S, 1991, MACH LEARN, V6, P252; SALZBERG SL, 1989, THESIS HARVARD U CAM; TschicholdGurman N, 1997, FUZZY SET SYST, V85, P287, DOI 10.1016/0165-0114(95)00351-7; TSCHICHOLDGURMA.NN, 1995, THESIS ETH ZURICH; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658	15	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0941-0643		NEURAL COMPUT APPL	Neural Comput. Appl.	MAY	2007	16	3					257	265		10.1007/s00521-007-0088-8		9	Computer Science, Artificial Intelligence	Computer Science	175HN	WOS:000247004800006	
J	Tripathy, M; Maheshwari, RP; Verma, HK				Tripathy, M.; Maheshwari, R. P.; Verma, H. K.			Application of probabilistic neural network for differential relaying of power transformer	IET GENERATION TRANSMISSION & DISTRIBUTION			English	Article							PROTECTION; ALGORITHM; FAULT	Investigations towards the applicability of probabilistic neural networks (PNNs) as core classifiers to discriminate between magnetising inrush and internal fault of power transformer are made. An algorithm has been developed around the theme of conventional differential protection of transformer. It makes use of the ratio of the voltage-to-frequency and the amplitude of differential current for the detection of the operating condition of the transformer. The PNN has a significant advantage in terms of a much faster learning capability because it is constructed with a single pass of exemplar pattern set and without any iteration for weight adaptation. For the evaluation of the developed algorithm, transformer modelling and simulation of fault are carried out in power system computer-aided designing PSCAD/EMTDC. The operating condition detection algorithm is implemented in MATLAB.	Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India	Tripathy, M (reprint author), Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.	rudrafee@iitr.ernet.in					AIBE N, 2002, P IEEE INT C NEUR NE, V3, P2270; BASTARD P, 1995, IEE P-GENER TRANSM D, V142, P386, DOI 10.1049/ip-gtd:19951817; Berthold MR, 1998, NEUROCOMPUTING, V19, P167, DOI 10.1016/S0925-2312(97)00063-5; Bose N. K., 1996, NEURAL NETWORK FUNDA; BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Pihler J, 1997, IEEE T POWER DELIVER, V12, P1128, DOI 10.1109/61.636919; Hammond MH, 2004, CHEMOMETR INTELL LAB, V71, P73, DOI 10.1016/j.chemolab.2003.12.001; Ma XX, 2000, ELECTR POW SYST RES, V56, P43, DOI 10.1016/S0378-7796(00)00099-7; MAHESHWARI RP, 1997, TAYLOR FRANCIS ELECT, V25, P459; MINCHIN G, 1999, P IEEE ICONIP 99, P556; MORAVEJ Z, 2003, J ELECT LETT, V84, P1; Moravej Z, 2003, COMPUT ELECTR ENG, V29, P421, DOI 10.1016/S0045-7906(01)00033-7; MURTY YVVS, 1990, IEEE T POWER DELIVER, V5, P1299, DOI 10.1109/61.57970; MUSAVI M, 1992, P IEEE INT JOINT C N, V1, P595, DOI 10.1109/IJCNN.1992.287147; PEREZ LG, 1994, IEEE T POWER DELIVER, V9, P431; PHADKE AG, 1983, IEEE T POWER AP SYST, V102, P3624, DOI 10.1109/TPAS.1983.317711; RAHMAN MA, 1988, IEEE T POWER DELIVER, V3, P534, DOI 10.1109/61.4290; SACHDEV MS, 1988, PUBLICATION IEEE TUT; Shin MC, 2003, IEEE T POWER DELIVER, V18, P718, DOI 10.1109/TPWRD.2003.813598; Specht D., 1992, P INT JOINT C NEUR N, V1, P761, DOI 10.1109/IJCNN.1992.287095; SPECHT D. F., 1991, IJCNN 91 SEATTLE INT, V1, P887; Specht D.F., 1988, P IEEE INT C NEURAL, V1, P525; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; Stigant SA, 1973, J P TRANSFORMER BOOK; Tan KC, 2004, IEEE T NEURAL NETWOR, V15, P1562, DOI 10.1109/TNN.2004.830801; Torfs P, 2001, PHYS CHEM EARTH PT B, V26, P9, DOI 10.1016/S1464-1909(01)85006-1; VERMA HK, 1986, J MICROCOMPUT APPL, V9, P313, DOI 10.1016/0745-7138(86)90028-X; VERMA HK, 1990, ELECTR POW SYST RES, V18, P125, DOI 10.1016/0378-7796(90)90015-U; WASHBURNE TP, 1991, INT JOINT C NEUR NET, V1, P513; Webb A., 2002, STAT PATTERN RECOGNI; Zaman MR, 1998, IEEE T POWER DELIVER, V13, P510, DOI 10.1109/61.660922	33	5	5	INSTITUTION ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-8687		IET GENER TRANSM DIS	IET Gener. Transm. Distrib.	MAR	2007	1	2					218	222		10.1049/iet-gtd:20050273		5	Engineering, Electrical & Electronic	Engineering	167PV	WOS:000246464500003	
J	Manouselis, N; Costopoulou, C				Manouselis, Nikos; Costopoulou, Constantina			Experimental analysis of design choices in multiattribute utility collaborative filtering	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	International Workshop on Web Personalization, Recommender Systems and Intelligent User Interfaces	OCT, 2005	Reading, ENGLAND			recommender systems; multi-criteria decision making (MCDM); evaluation	RECOMMENDER SYSTEMS; EMPIRICAL-ANALYSIS; ALGORITHMS; INFORMATION; SIMILARITY	Recommender systems have already been engaging multiple criteria for the production of recommendations. Such systems, referred to as multicriteria recommenders, demonstrated early the potential of applying Multi-Criteria Decision Making (MCDM) methods to facilitate recommendation in numerous application domains. On the other hand, systematic implementation and testing of multicriteria recommender systems in the context of real-life applications still remains rather limited. Previous studies dealing with the evaluation of recommender systems have outlined the importance of carrying out careful testing and parameterization of a recommender system, before it is actually deployed in a real setting. In this paper, the experimental analysis of several design options for three proposed multiattribute utility collaborative filtering algorithms is presented for a particular application context (recommendation of e-markets to online customers), under conditions similar to the ones expected during actual operation. The results of this study indicate that the performance of recommendation algorithms depends on the characteristics of the application context, as these are reflected on the properties of evaluations' data set. Therefore, it is judged important to experimentally analyze various design choices for multicriteria recommender systems, before their actual deployment.	Agr Univ Athens, Div Informat Math & Stat, Informat Lab, GR-11855 Athens, Greece	Manouselis, N (reprint author), Agr Univ Athens, Div Informat Math & Stat, Informat Lab, 75 Iera Odos Str, GR-11855 Athens, Greece.	nikosm@ieee.org; tina@aua.gr					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bakos Y, 1998, COMMUN ACM, V41, P35, DOI 10.1145/280324.280330; Barnes S. J., 2002, J ELECTRON COMMER RE, V3, P114; Breese J, 1998, P 14 C UNC ART INT M; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; CARENINI G, 2005, P PERS WORKSH INT US; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELGADO J, 1999, P ACM SIGIR 99; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Guan S., 2002, ELECTRON COMMER R A, V1, P314, DOI 10.1016/S1567-4223(02)00023-6; Ha V, 2003, ARTIF INTELL, V146, P149, DOI 10.1016/S0004-3702(03)000134; Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Jacquet-Lagreze E, 2001, EUR J OPER RES, V130, P233, DOI 10.1016/S0377-2217(00)00035-7; Keeney RL, 1992, VALUE FOCUSED THINKI; Konstan JA, 2004, ACM T INFORM SYST, V22, P1, DOI 10.1145/963770.963771; Lee WP, 2004, EXPERT SYST APPL, V27, P665, DOI 10.1016/j.eswa.2004.07.001; Liu DR, 2005, INFORM MANAGE-AMSTER, V42, P387, DOI 10.1016/j.im.2004.01.008; MANOUSELIS N, IN PRESS ENG LETT; MANOUSELIS N, 2006, 181 TR AGR U ATH; MANOUSELIS N, 2005, INFORM SERV USE, V25, P95; MARITZA L, 2004, P 2004 ACM S APPL CO; Masthoff J, 2003, LECT NOTES ARTIF INT, V2702, P258; Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618; MONTANER M, P 6 INT C ENT INF SY, P303; NGUYEN H, 1998, P AAAI WORKSH REC SY; Papagelis M, 2005, ENG APPL ARTIF INTEL, V18, P781, DOI 10.1016/j.engappai.2005.06.010; PERNY P, 2001, INFORMATION INTERACT, V1, P9; PRICE B, 2005, P INF ANN M DENV 200; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Riedl J., 1994, P ACM C COMP SUPP CO, P175, DOI 10.1145/192844.192905; Roy B., 1996, MULTICRITERIA METHOD; SARWAR B, 2000, P ACM EC 00; SCHICKELZUBER V, 2005, P WORKSH KNOWL DISCO; SCHMITT C, 2002, P ABIS WORKSH AD BEN; STOLZE M, 2003, P 2 WORLD C MASS CUS; Tewari G, 2003, DECIS SUPPORT SYST, V34, P127, DOI 10.1016/S0167-9236(02)00076-3; VINCKE P., 1992, MULTICRITERIA DECISI; Wolfinbarger M, 2003, J RETAILING, V79, P183, DOI 10.1016/S0022-4359(03)00034-4; YU K, 2001, P 2 INT WORKSH MAN I; Zeng C, 2004, INT J ELECTRON COMM, V8, P115	44	7	8	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAR	2007	21	2					311	331		10.1142/S021800140700548X		21	Computer Science, Artificial Intelligence	Computer Science	231NK	WOS:000250955100008	
J	Tahir, MA; Bouridane, A; Kurugollu, F				Tahir, Muhammad Atif; Bouridane, Ahmed; Kurugollu, Fatih			Simultaneous feature selection and feature weighting using Hybrid Tabu Search/K-nearest neighbor classifier	PATTERN RECOGNITION LETTERS			English	Article						Tabu Search; K-NN classifier; feature selection; feature weighting; prostate cancer diagnosis	GENETIC ALGORITHMS	Feature selection and feature weighting are useful techniques for improving the classification accuracy of K-nearest-neighbor (K-NN) rule. The term feature selection refers to algorithms that select the best subset of the input feature set. In feature weighting, each feature is multiplied by a weight value proportional to the ability of the feature to distinguish pattern classes. In this paper, a novel hybrid approach is proposed for simultaneous feature selection and feature weighting of K-NN rule based on Tabu Search (TS) heuristic. The proposed TS heuristic in combination with K-NN classifier is compared with several classifiers on various available data sets. The results have indicated a significant improvement in the performance in classification accuracy. The proposed TS heuristic is also compared with various feature selection algorithms. Experiments performed revealed that the proposed hybrid TS heuristic is superior to both simple TS and sequential search algorithms. We also present results for the classification of prostate cancer using multispectral images, an important problem in biomedicine. (c) 2006 Elsevier B.V. All rights reserved.	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England; Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.	muhammad.tahir@uwe.ac.uk					Blake C.L., UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 2001, PATTERN CLASSIFICATI; EBLE JN, 1996, UROLOGIC SURG PATHOL; Glover F., 1990, ORSA J COMP, V1, P4; Glover F., 1993, Annals of Operations Research, V41; Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547; GUVERENIR HA, 1997, P 12 INT S COMP INF; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LOWE D, 1995, NEURAL COMPUT, V7; Michie D, 1994, MACHINE LEARNING NEU; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PUCH WF, 1993, P 5 INT C GEN ALG IC; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Roula M. A., 2002, IEEE INT S BIOM IM; SAIT SM, 1999, GEN ITERATIVE ALGORI; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; TAHIR MA, 2004, LNCS, V3177; TAHIR MA, 2005, IN PRESS ADV INTELLI; TAHIR MA, 2004, P 1M INT C PATT REC; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	31	38	43	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAR 1	2007	28	4					438	446		10.1016/j.patrec.2006.08.016		9	Computer Science, Artificial Intelligence	Computer Science	127ZP	WOS:000243625400005	
J	Ramamohanarao, K; Fan, HJ				Ramamohanarao, Kotagiri; Fan, Hongjian			Patterns based classifiers	WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS			English	Article						data mining; classification; emerging pattern	GENE-EXPRESSION PROFILES; EMERGING PATTERNS; DISCOVERY; DATABASES; CLASSIFICATION; RULES	Data mining is one of the most important areas in the 21 century for its applications are wide ranging. This includes medicine, finance, commerce and engineering, to name a few. Pattern mining is amongst the most important and challenging techniques employed in data mining. Patterns are collections of items which satisfy certain properties. Emerging Patterns are those whose frequencies change significantly from one dataset to another. They represent strong contrast knowledge and have been shown very successful for constructing accurate and robust classifiers. In this paper, we examine various kinds of patterns. We also investigate efficient pattern mining techniques and discuss how to exploit patterns to construct effective classifiers.	Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic, Australia	Fan, HJ (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic, Australia.	hfan@csse.unimelb.edu.au; rao@csse.unimelb.edu.au					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alhammady H, 2004, P 4 IEEE INT C DAT M, P315; ALHAMMADY H, 2005, P 2005 SIAM INT DAT; ALHAMMADY H, 2004, P 8 PAC AS C KNOWL D, P207; BAILEY J, 2003, P 4 INT C WEB AG INF, P226; BAILEY J, 2003, P 3 IEEE INT C DAT M, P485; BAILEY J, 2002, P 6 EUR C PRINC PRAC; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; BAYUARDO RJ, 1998, P 1998 ACM SIGMOD IN, P85; Bethea R.M., 1995, STAT METHODS ENG SCI; Bishop C. M., 1995, NEURAL NETWORKS PATT; Blake CL, 1998, UCI REPOSITORY MACHI; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L, 1984, CLASSIFICATION REGRE; Burr Ridge I, 1997, MACHINE LEARNING; Cheeseman P., 1996, P 2 INT C KNOWL DISC, P153; Christensen R., 1997, LOG LINEAR MODELS LO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Dong G., 1999, P 2 INT C DISC SCI, P30; Duda R., 1973, PATTERN CLASSIFICATI; FAN H, 2003, P 4 INT C WEB AG INF, P189; FAN H, 2005, P IEEE INT C GRAN CO; Fan H, 2006, IEEE T KNOWL DATA EN, V18, P721, DOI 10.1109/TKDE.2006.95; Fan H, 2003, P 14 AUSTR DAT C ADC, P39; Fan H., 2002, P 6 PAC AS C KNOWL D, P456; Fayyad U, 1996, AI MAG, V17, P37; Freitas A.A., 2002, DATA MINING KNOWLEDG; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; Han J, 2000, P 2000 ACM SIGMOD IN, p1 12, DOI 10.1145/342009.335372; HAN JW, 1992, PROC INT CONF VERY L, P547; Han J. W., 2000, DATA MINING CONCEPTS; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; JOSHI MV, 2001, P ACM SIGMOD C SANT, P91, DOI 10.1145/375663.375673; KOHAVI R, 1994, MLC MACHINE LEARNING, P740; Li J., 2003, BIOINFORMATICS S2, V19, pii93; LI J, 2001, P 5 PAC AS C KNOWL D, P455; Li J, 2000, P 4 EUR C PRINC PRAC, P191; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; Mitchell T. M., 1982, ARTIF INTELL, V18; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ripley B. D., 1996, PATTERN RECOGNITION; Sebag M., 1996, P 13 INT C MACH LEAR, P444; WANG Z, 2004, P 17 AUSTR JOINT C A, P1062; Zhang X., 2000, P 6 INT C KNOWL DISC, P310, DOI 10.1145/347090.347158; *RULEQUEST, 2000, SEE5C C5 0	54	10	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-145X		WORLD WIDE WEB	World Wide Web	MAR	2007	10	1					71	83		10.1007/s11280-006-0012-7		13	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	146SR	WOS:000244955500003	
J	Du, JX; Wang, XF; Zhang, GJ				Du, Ji-Xiang; Wang, Xiao-Feng; Zhang, Guo-Jun			Leaf shape based plant species recognition	APPLIED MATHEMATICS AND COMPUTATION			English	Article; Proceedings Paper	International Conference on Intelligent Computing	AUG 23-26, 2005	Hefei, PEOPLES R CHINA	Inst Intelligent Machines, Univ Sci & Technol, IEEE Computat Intelligence Soc, IEEE Hong Kong Computat Intelligence Chapter		digital morphological feature; plant recognition; leaf database; hypersphere classifier		Plant has plenty use in foodstuff, medicine and industry. And it is also vitally important for environmental protection. However, it is an important and difficult task to recognize plant species on earth. Designing a convenient and automatic recognition system of plants is necessary and useful since it can facilitate fast classifying plants, and understanding and managing them. In this paper, a leaf database from different plants is firstly constructed. Then, a new classification method, referred to as move median centers (MMC) hypersphere classifier, for the leaf database based on digital morphological feature is proposed. The proposed method is more robust than the one based on contour features since those significant curvature points are hard to find. Finally, the efficiency and effectiveness of the proposed method in recognizing different plants is demonstrated by experiments. (c) 2006 Elsevier Inc. All rights reserved.	Univ Sci & Technol China, Dept Automat, Anhua 230027, Peoples R China; Chinese Acad Sci, Inst Intelligent Machines, Intelligent Comp Lab, Anhua 230031, Peoples R China	Du, JX (reprint author), Univ Sci & Technol China, Dept Automat, Anhua 230027, Peoples R China.	du_jx@iim.ac.cn; xfwang@iim.ac.cn					ABBASI S, 1997, INT C SCAL SPAC THEO, P284; CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, MCGRAW HILL COMPUTER; DU JX, 2004, AUTOMATIC PLANT LEAV; Gonzalez R. C., 2004, DIGITAL IMAGE PROCES; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HEISTERKAMP D, 2001, P IEEE C COMP VIS PA, P236; HONG AX, 2003, ICASSP, V3, P589; Huang D. S., 1996, SYSTEMATIC THEORY NE; Huang DS, 1998, IEEE T SYST MAN CY B, V28, P477, DOI 10.1109/3477.678658; IM C, 1999, VISION INTERF, P397; Li Baoli, 2003, P 20 INT C COMP PROC; Paredes R., 2000, Pattern Recognition and Applications (Frontiers in Artificial Intelligence and Applications Vol.56); SAITOH T, 2000, P IEEE INT C PATT RE, V2, P507, DOI 10.1109/ICPR.2000.906123; SONKA M, 2003, IMAGE PROCESSING ANA; Wan YY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P482; Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160; Wang Zhiyong, 2002, P FUZZY SYSTEMS, V1, P372; Zhang G.J., 2004, P 2004 INT S INT MUL, P165	20	20	27	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0096-3003		APPL MATH COMPUT	Appl. Math. Comput.	FEB 15	2007	185	2					883	893		10.1016/j.amc.2006.07.072		11	Mathematics, Applied	Mathematics	158AI	WOS:000245762700012	
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Virus-PLoc: A fusion classifier for predicting the subcellular localization of viral proteins within host and virus-infected cells	BIOPOLYMERS			English	Article						viral protein; subcellular compartment; gene ontology; amphiphilic pseudo amino acid composition; fusion; KNN rule; virus-infected cell	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; LOCATION PREDICTION; SORTING SIGNALS; PROTEASE TYPES; GENE ONTOLOGY; BIOINFORMATICS	Viruses can reproduce their progenies only within a host cell, and their actions depend both on its destructive tendencies toward a specific host cell and on environmental conditions. Therefore, knowledge of the subcellular localization of viral proteins in a host cell or virus-infected cell is very useful for in-depth studying of their functions and mechanisms as well as designing antiviral drugs. An analysis on the Swiss-Prot database (version 50.0, released on May 30, 2006) indicates that only 23.5% of viral protein entries are annotated for their subcellular locations in this regard. As for the gene ontology database, the corresponding percentage is 23.8%. Such a gap calls for the development of high throughput tools for timely annotating the localization of viral proteins within host and virus-infected cells. In this article, a predictor called "Virus-PLoc" has been developed that is featured by fusing many basic classifiers with each engineered according to the K-nearest neighbor rule. The overall jackknife success rate obtained by Virus-PLoc in identifying the subcellular compartments of viral proteins was 80% for a benchmark dataset in which none of proteins has more than 25% sequence identity to any other in a same location site. Virus-PLoc will be freely available as a web-server at http://202.120.37.1861bioinf/ virus for the public usage. Furthermore, Virus-PLoc has been used to provide large-scale predictions of all viral protein entries in Swiss-Prot database that do not have subcellular location annotations or are annotated as being uncertain. The results thus obtained have been deposited in a downloadable file prepared with Microsoft Excel and named "Tab_Virus-PLoc.xls." This file is available at the same website and will be updated twice a year to include the new entries of viral proteins and reflect the continuous development of Virus-PLoc. (c) 2006 Wiley Periodicals, Inc.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 1954 Hua Shan Rd, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 2000, NUCLEIC ACIDS RES, V25, P31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 1999, BIOCHEM BIOPH RES CO, V264, P216, DOI 10.1006/bbrc.1999.1325; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2004, J CELL BIOCHEM, V91, P1085, DOI 10.1002/jcb.20083; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2005, CURR PROTEIN PEPT SC, V6, P423, DOI 10.2174/138920305774329368; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; Chou KC, 2006, BIOCHEM BIOPH RES CO, V339, P1015, DOI 10.1016/j.bbrc.2005.10.196; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dunker AK, 2002, ADV PROTEIN CHEM, V62, P25; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Liu H, 2005, BIOCHEM BIOPH RES CO, V338, P1005, DOI 10.1016/j.bbrc.2005.10.046; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Qian ZL, 2006, BIOCHEM BIOPH RES CO, V347, P141, DOI 10.1016/j.bbrc.2006.06.060; Rubenstein R, 1999, J NEUROVIROL, V5, P401, DOI 10.3109/13550289909029481; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yu XJ, 2006, J THEOR BIOL, V240, P175, DOI 10.1016/j.jtbi.2005.09.018; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	55	90	92	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0006-3525		BIOPOLYMERS	Biopolymers	FEB 15	2007	85	3					233	240		10.1002/bip.20640		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	133AS	WOS:000243984600005	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Large-scale plant protein subcellular location prediction	JOURNAL OF CELLULAR BIOCHEMISTRY			English	Article						plant protein; fusion classifier; gene ontology; GO discrete model; amphiphilic pseudo amino acid composition; KNN rule; plant-PLoc	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; GENE ONTOLOGY; SECONDARY STRUCTURE; SORTING SIGNALS; NEURAL-NETWORKS; LOCALIZATION; SEQUENCE	Current plant genome sequencing projects have called for development of novel and powerful high throughput tools for timely annotating the subcellular location of uncharacterized plant proteins. In view of this, an ensemble classifier, Plant-PLoc, formed by fusing many basic individual classifiers, has been developed for large-scale subcellular location prediction for plant proteins. Each of the basic classifiers was engineered by the K-Nearest Neighbor (KNN) rule. Plant-PLoc discriminates plant proteins among the following 11 subcellular locations: (1) cell wall, (2) chloroplast, (3) cytoplasm, (4) endoplasmic reticulum, (5) extracell, (6) mitochondrion, (7) nucleus, (8) peroxisome, (9) plasma membrane, (10) plastid, and (11) vacuole. As a demonstration, predictions were performed on a stringent benchmark dataset in which none of the proteins included has >= 25% sequence identity to any other in a same subcellular location to avoid the homology bias. The overall success rate thus obtained was 32-51 % higher than the rates obtained by the previous methods on the same benchmark dataset. The essence of Plant-PLoc in enhancing the prediction quality and its significance in biological applications are discussed. Plant-PLoc is accessible to public as a free web-server at http://202.1 20.37.186/bioinf/plant. Furthermore, for public convenience, results predicted by Plant-PLoc have been provided in a downloadable file at the same website for all plant protein entries in the Swiss-Prot database that do not have subcellular location annotations, or are annotated as being uncertain. The large-scale results will be updated twice a year to include new entries of plant proteins and reflect the continuous development of Plant-PLoc.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Ashburner M, 2000, NAT GENET, V25, P25; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2000, BIOCHIMIE, V82, P783, DOI 10.1016/S0300-9084(00)01161-5; Camon E, 2004, NUCLEIC ACIDS RES, V32, pD262, DOI 10.1093/nar/gkh021; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; Chou K. C., 2006, EXCLI J, V5, P55; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Emanuelsson O, 1999, PROTEIN SCI, V8, P978; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Harris MA, 2004, NUCLEIC ACIDS RES, V32, pD258, DOI 10.1093/nar/gkh036; Jackson S, 2006, PLANT CELL, V18, P1100, DOI 10.1105/tpc.106.042192; Jorgensen R, 2006, PLANT CELL, V18, P1099, DOI 10.1105/tpc.106.180580; Juty N, 2012, NUCLEIC ACIDS RES, V40, P580; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lee S, 2006, PROTEINS, V62, P1107, DOI 10.1002/prot.20821; LEE Y, 2005, SILICO BIOL, V5, P5; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Liu WM, 1998, J PROTEIN CHEM, V17, P209, DOI 10.1023/A:1022576400291; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; MAO BY, 1994, PROTEIN ENG, V7, P319, DOI 10.1093/protein/7.3.319; MARDIA KV, 1979, MULTIVARIATE ANAL, P332; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	65	137	140	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0730-2312		J CELL BIOCHEM	J. Cell. Biochem.	FEB 15	2007	100	3					665	678		10.1002/jcb.21096		14	Biochemistry & Molecular Biology; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	130CB	WOS:000243775700010	
J	Bondugula, R; Xu, D				Bondugula, Rajkumar; Xu, Dong			MUPRED: A tool for bridging the gap between template based methods and sequence profile based methods for protein secondary structure prediction	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein secondary structure prediction; fuzzy nearest neighbor; neural network; hybrid prediction system; sequence profile; template; prediction accuracy assessment	ALIGNMENTS; DATABASE	Predicting secondary structures from a protein sequence is an important step for characterizing the structural properties of a protein. Existing methods for protein secondary structure prediction can be broadly classified into template based or sequence profile based methods. We propose a novel framework that bridges the gap between the two fundamentally different approaches. Our framework integrates the information from the fuzzy k-nearest neighbor algorithm and position-specific scoring matrices using a neural network. It combines the strengths of the two methods and has a better potential to use the information in both the sequence and structure databases than existing methods. We implemented the framework into a software system MUPRED. MUPRED has achieved three-state prediction accuracy (Q(3)) ranging from 79.2 to 80.14%, depending on which benchmark dataset is used. A higher Q(3) can be achieved if a query protein has a significant sequence identity (> 25%) to a template in PDB. MUPRED also estimates the prediction accuracy at the individual residue level more quantitatively than existing methods. The MUPRED web server and executables are freely available at http://digbio.missouri.edu/mupred. Proteins 2007; 66:664-670. (c) 2006 Wiley-Liss, Inc.	Univ Missouri, Christopher S Bond Life Sci Ctr 271C, Digital Biol Lab, Dept Comp Sci, Columbia, MO 65211 USA	Xu, D (reprint author), Univ Missouri, Christopher S Bond Life Sci Ctr 271C, Digital Biol Lab, Dept Comp Sci, Columbia, MO 65211 USA.	xudong@missouri.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BONDUGULA R, 2001, P 3 AS PAC BIOINF C; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Cheng HT, 2005, POLYMER, V46, P4314, DOI 10.1016/j.polymer.2005.02.040; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GEOURJON C, 1994, PROTEIN ENG, V7, P157, DOI 10.1093/protein/7.2.157; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Mathews B.W., 1975, BIOCHIM BIOPHYS ACTA, V405, P442; Meiler J, 2003, P NATL ACAD SCI USA, V100, P12105, DOI 10.1073/pnas.1831973100; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; Rost B, 2001, J STRUCT BIOL, V134, P204, DOI 10.1006/jsbi.2000.4336; Salamov AA, 1997, J MOL BIOL, V268, P31, DOI 10.1006/jmbi.1997.0958; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R	23	17	17	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585		PROTEINS	Proteins	FEB 15	2007	66	3					664	670		10.1002/prot.21177		7	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	126BR	WOS:000243487700015	
J	Sun, TK; Chen, SC				Sun, Tingkai; Chen, Songcan			Class label versus sample label-based CCA	APPLIED MATHEMATICS AND COMPUTATION			English	Article						canonical correlation analysis (CCA); class label encoding; separability between classes; feature extraction	CANONICAL CORRELATION-ANALYSIS; CLASSIFICATION	When correlating the samples with the corresponding class labels, canonical correlation analysis (CCA) can be used for supervised feature extraction and subsequent classification. Intuitively, different encoding modes for class label can result in different classification performances. However, actually, when the samples in each class share a common class label as in usual cases, a unified formulation of CCA is not only derived naturally, but also more importantly from it, we can get some insight into the shortcoming of the existing feature extraction using CCA for sequent classification: the existing encodings for class label fail to reflect the difference among the samples such as in central region of class and those in mixture overlapping region among classes, consequently resulting in its equivalence to the traditional linear discriminant analysis (LDA) for some commonly-used class-label encodings. To reflect such a difference between the samples, we elaborately design an independent soft label for each sample of each class rather than a common label for all the samples of the same class. A purpose of doing so is to try to promote CCA classification performance. The experiments show that this soft label based CCA is better than or comparable to the original CCA/LDA in terms of the recognition performance. (c) 2006 Elsevier Inc. All rights reserved.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	s.chen@nuaa.edu.cn					BAEK J, 2004, PATTERN RECOGN, V37, P303; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Bishop CM, 1995, NEURAL NETWORK PATTE; BORGA M, 1999, CANONICAL CORRELATIO; Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Duda R. O., 2001, PATTERN CLASSIFICATI; GESTEL TV, 2001, P INT C ART NEUR NET, P384; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; HELOR Y, 2004, HPL2003164 HP; Horikawa Y, 2004, LECT NOTES COMPUT SC, V3316, P1235; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.2307/2333955; JOHANSSON B, 2001, LITHISYR2375 LINK U; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LOOG M, 2004, P EUR C COMP VIS PRA, P562; Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X; YAN SC, 2005, P IEEE CVPR 05	18	15	18	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0096-3003		APPL MATH COMPUT	Appl. Math. Comput.	FEB 1	2007	185	1					272	283		10.1016/j.amc.2006.06.103		12	Mathematics, Applied	Mathematics	147FB	WOS:000244987700025	
J	Dragovic, S; Onjia, A				Dragovic, Snezana; Onjia, Antonije			Classification of soil samples according to geographic origin using gamma-ray spectrometry and pattern recognition methods	APPLIED RADIATION AND ISOTOPES			English	Article						radionuclides; soil classification; multivariate analysis; LDA; kNN; SIMCA; ANN	ARTIFICIAL NEURAL-NETWORKS; K-NEAREST NEIGHBOR; SPECTRA; RADIOCESIUM; MONTENEGRO; SERBIA	Multivariate data analysis methods were used to recognize and classify soils of unknown geographic origin. A total of 103 soil samples were differentiated into classes, according to regions in Serbia and Montenegro from which they were collected. Their radionuclide (Ra-226, U-238, U-235, K-40, Cs-134, Cs-137, Th-232 and Be-7) activities detected by gamma-ray spectrometry were then used as the inputs in different pattern recognition methods. For the classification of soil samples using eight selected radionuclides, the prediction ability of linear discriminant analysis (LDA), k-nearest neighbours (kNN), soft independent modelling of class analogy (SIMCA) and artificial neural network (ANN) were 82.8%, 88.6%, 60.0% and 92.1%, respectively. (c) 2006 Elsevier Ltd. All rights reserved.	INEP, Belgrade 11080, Serbia	Dragovic, S (reprint author), INEP, Banatska 31B, Belgrade 11080, Serbia.	sdragovic@inep.co.yu					Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Antonic O, 2003, ECOL MODEL, V170, P363, DOI 10.1016/S0304-3800(03)00239-4; Beebe KR, 1998, CHEMOMETRICS PRACTIC; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; DIMITRIJEVIC M, 1995, GEOLOGY YUGOSLAVIA G; Di Natale C, 2001, SENSOR ACTUAT B-CHEM, V77, P561, DOI 10.1016/S0925-4005(01)00705-5; Dragovic S, 2004, J ENVIRON RADIOACTIV, V77, P381, DOI [10.1016/j.jenvrad.2004.04.007, 10.1016/j.jenvard.2004.04.007]; Dragovic S, 2005, NUCL INSTRUM METH A, V540, P455, DOI 10.1016/j.nima.2004.11.045; Dragovic S, 2005, APPL RADIAT ISOTOPES, V63, P363, DOI 10.1016/j.apradiso.2005.03.009; Dragovic S, 2006, RADIAT MEAS, V41, P611, DOI 10.1016/j.radmeas.2006.03.007; EINAX JW, 1997, CHEMOMETRICS ENV CHE; ESWARAN H, 2002, SOIL CLASSIFICATION; Fidencio PH, 2001, ANALYST, V126, P2194, DOI 10.1039/b107533k; Goovaerts P, 1998, BIOL FERT SOILS, V27, P315, DOI 10.1007/s003740050439; HOWARD BJ, 1991, HEALTH PHYS, V61, P715, DOI 10.1097/00004032-199112000-00002; KANEVSKI M, 1997, C ICANN 1997 LAUS; Kanevsky M., 1996, GEOINFORMATICS, V7, P5; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; Massart D.L., 1998, CHEMOMETRICS TXB; McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4; OLMOS P, 1994, IEEE T NUCL SCI, V41, P637, DOI 10.1109/23.299814; OLMOS P, 1991, IEEE T NUCL SCI, V38, P971, DOI 10.1109/23.83860; Otto M., 1999, CHEMOMETRICS; Pilato V, 1999, NUCL INSTRUM METH A, V422, P423, DOI 10.1016/S0168-9002(98)01110-3; Ramadan Z, 2001, ANAL CHIM ACTA, V446, P233; Rumelhart DE, 1986, P PARALLEL DISTRIBUT, V1; Salisbury RT, 2005, J ENVIRON RADIOACTIV, V78, P353, DOI 10.1016/j.jenvrad.2004.05.013; Slavkovic L, 2004, ENVIRON CHEM LETT, V2, P105, DOI 10.1007/s10311-004-0073-8; Stein A, 2003, AGR ECOSYST ENVIRON, V94, P31, DOI 10.1016/S0167-8809(02)00013-0; UNSCEAR (United Nations Scientific Committee on the Effects of Atomic Radiation), 2000, SOURC EFF ION RAD RE; VANDEGINSTE G, 1988, HDB CHEMOMETRICS QUA, P207; Vigneron V, 1996, NUCL INSTRUM METH A, V369, P642, DOI 10.1016/S0168-9002(96)80068-4; Werbos P., 1974, THESIS HARVARD U CAM; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Yoshida E, 2002, NUCL INSTRUM METH A, V484, P557, DOI 10.1016/S0168-9002(01)01962-3; Zhu AX, 2000, WATER RESOUR RES, V36, P663, DOI 10.1029/1999WR900315	40	6	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0969-8043		APPL RADIAT ISOTOPES	Appl. Radiat. Isot.	FEB	2007	65	2					218	224		10.1016/j.apradiso.2006.07.005		7	Chemistry, Inorganic & Nuclear; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	Chemistry; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	128PO	WOS:000243670300010	
J	Yang, MQ; Yang, JY; Ersoy, OK				Yang, Mary Q.; Yang, Jack Y.; Ersoy, Okan K.			Classification of proteins multiple-labelled and single-labelled with protein functional classes	INTERNATIONAL JOURNAL OF GENERAL SYSTEMS			English	Article						computational intelligence; machine learning; classification; multifunctional proteins; bioinformatics	DATABASE	Advances in high-throughput genome sequencing technology have led to an explosion in the amount of sequence data that are available. The determination of protein function using experimental techniques is time-consuming and expensive; the use of machine-learning techniques rapidly to assess protein function may be useful in streamlining this process. The problem of assigning functional classes to proteins is complicated by the fact that a single protein can participate in several different pathways and thus can have multiple functions. We have developed a tree-based classifier that is capable of handling multiple-labelled data and gaining an insight into the multi-functional nature of proteins. We call the resulting tree a recursive maximum contrast tree (RMCT) and the resulting classifier a multiple-labelled instance classifier (MLIC). We investigate the synergy of machine-learning-based ensemble methods and physiochemical-based feature augments. We test our algorithm on protein phylogenetic profiles generated from 60 completely sequenced genomes and we compare our results with those achieved by algorithms such as support vector machines and decision trees.	Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA; US Dept HHS, NHGRI, NIH, Rockville, MD 20852 USA; Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA; Harvard Univ, Massachusetts Gen Hosp, Boston, MA 02114 USA	Yang, JY (reprint author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.	jyang@hadron.mgh.harvard.edu	jia, lp/H-5750-2011				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Choe W, 2000, BIOINFORMATICS, V16, P1062, DOI 10.1093/bioinformatics/16.12.1062; CODRINGTON CW, 1997, THESIS PURDUE U; CODRINGTON CW, 2001, P INT C MACH LEARN W; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daughdrill GW, 2005, PROTEIN FOLDING HANDBOOK; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; Dunker A K, 2000, Genome Inform Ser Workshop Genome Inform, V11, P161; DUNKER AK, 2005, JBCB, V3, P35; ERSOY OK, 1993, IEEE T CIRCUITS SYST, V40, P556; ERSOY OK, 2002, INT J SMART ENG SYST, P225; Frishman D, 2003, NUCLEIC ACIDS RES, V31, P207, DOI 10.1093/nar/gkg005; Joachims T., 2002, LEARNING CLASSIFY TE; Liu Li-Ping, 1998, Biopolymers, V47, P41, DOI 10.1002/(SICI)1097-0282(1998)47:1<41::AID-BIP6>3.0.CO;2-X; NEUHAUS D, 2002, NUCL OVERHAUSER EFFE; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Pavlidis P., 2001, P 5 INT C COMP MOL B, P249, DOI 10.1145/369133.369228; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Quinlan J. R, DATA MINING TOOLS SE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Radivojac P, 2004, J BIOMED INFORM, V37, P224, DOI 10.1016/j.jbi.2004.07.008; ROMERO P, 2002, AI REV, V14, P447; Uversky VN, 2002, FEBS LETT, V515, P79, DOI 10.1016/S0014-5793(02)02441-9; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; YANG JY, 2003, P ART NEUR NETW ENG; YANG JY, 2004, 1 IND BIOINF C IND I; YANG JY, 2002, P ART NEUR NETW ENG; YANG MQ, 2006, WILEY SERIES BIOINFO; YANG MQ, 2006, P INTC BIOINF COMP B	29	4	5	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0308-1079		INT J GEN SYST	Int. J. Gen. Syst.	FEB	2007	36	1					91	109		10.1080/03081070600950868		19	Computer Science, Theory & Methods; Ergonomics	Computer Science; Engineering	115XN	WOS:000242767200005	
J	Morrison, D; Wang, RL; De Silva, LC				Morrison, Donn; Wang, Ruili; De Silva, Liyanage C.			Ensemble methods for spoken emotion recognition in call-centres	SPEECH COMMUNICATION			English	Article						affect recognition; emotion recognition; ensemble methods; speech processing; speech databases	SPEECH; COMMUNICATION; FEATURES	Machine-based emotional intelligence is a requirement for more natural interaction between humans and computer interfaces and a basic level of accurate emotion perception is needed for computer systems to respond adequately to human emotion. Humans convey emotional information both intentionally and unintentionally via speech patterns. These vocal patterns are perceived and understood by listeners during conversation. This research aims to improve the automatic perception of vocal emotion in two ways. First, we compare two emotional speech data sources: natural, spontaneous emotional speech and acted or portrayed emotional speech. This comparison demonstrates the advantages and disadvantages of both acquisition methods and how these methods affect the end application of vocal emotion recognition. Second, we look at two classification methods which have not been applied in this field: stacked generalisation and unweighted vote. We show how these techniques can yield an improvement over traditional classification methods. (C) 2006 Elsevier B.V. All rights reserved.	Massey Univ Turutea, Inst Informat Sci & Technol, Palmerston North, New Zealand	Wang, RL (reprint author), Massey Univ Turutea, Inst Informat Sci & Technol, Private Bag 11222, Palmerston North, New Zealand.	d.morrison@massey.ac.nz; r.wang@massey.ac.nz					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ang J., 2002, P INT C SPOK LANG PR; Anton H., 2000, ELEMENTARY LINEAR AL; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cleary J., 1995, ICML, P108; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVITZ JR, 1994, COMMUNICATION EMOTIO; Dellaert F., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.608022; DEVILLERS L, 2002, P ISLE WORKSH DIAL T; DIETERLE F, 2003, THESIS; Dietterich T. G., 2002, HDB BRAIN THEORY NEU, P405; Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203; EMMANOUILIDIS C, 1999, P INT JOINT C NEUR N, P4387; Fairbanks G, 1941, SPEECH MONOGR, V8, P85; Fairbanks G, 1939, SPEECH MONOGR, V6, P87; Fonagy I., 1963, Z PHONETIK SPRACHWIS, V16, P293; Fonagy I., 1981, RES ASPECTS SINGING, P51; FONAGY I, 1978, LANG SPEECH, V21, P34; FRICK RW, 1986, AGGRESSIVE BEHAV, V12, P121, DOI 10.1002/1098-2337(1986)12:2<121::AID-AB2480120206>3.0.CO;2-F; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HAYKIN S, 1999, NEURAL NETWORKS COMP; HUBER R, 1998, P WORKSH TEXT SPEECH, P223; Huber R, 2000, P INT C SPOK LANG PR, P665; JOHNSON WF, 1986, ARCH GEN PSYCHIAT, V43, P280; Lee C. M., 2004, P INT C SPOK LANG PR; Liscombe J., 2005, INTERSPEECH, P1845; McGilloway S., 2000, P ISCA WORKSH SPEECH, P200; MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558; NAKATSU R, 1999, P INT C MULT COMP SY; NWE TL, 2003, THESIS NATL U SINGAP; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; O'Shaughnessy D., 2000, SPEECH COMMUNICATION; OSTER A, 1986, Q PROG STAT REP, V4, P79; Petrushin V.A., 2000, P 6 INT C SPOK LANG; Platt J, 1998, ADV KERNEL METHODS S; POLZIN T, 2000, P ISCA WORKSH SPEECH; Rabiner L., 1978, DIGITAL PROCESSING S; SALOVEY P, 2004, FEELINGS EMOTIONS, P321; SCHERER KR, 1996, P INT C SPOK LANG PR; Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5; SEEWALD A, 2002, P 19 INT C MACH LEAR; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Skinner ER, 1935, SPEECH MONOGR, V2, P81; Talkin D, 1995, SPEECH CODING SYNTHE, P495; VAFAIE H, 1992, P 4 INT C TOOLS ART; Vapnik V.N., 1995, NATURE STAT LEARNING; WILLIAMS CE, 1972, EMOTIONS SPEECH SOME; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YACOUB S, 2003, P EUR 2003 8 EUR C S	52	57	63	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393		SPEECH COMMUN	Speech Commun.	FEB	2007	49	2					98	112		10.1016/j.specom.2006.11.004		15	Acoustics; Communication; Computer Science, Interdisciplinary Applications; Language & Linguistics	Acoustics; Communication; Computer Science; Linguistics	149OB	WOS:000245155200002	
J	Bankert, RL; Wade, RH				Bankert, Richard L.; Wade, Robert H.			Optimization of an instance-based GOES cloud classification algorithm	JOURNAL OF APPLIED METEOROLOGY AND CLIMATOLOGY			English	Article							LEARNING ALGORITHMS; AVHRR; IMAGERY; SURFACE	An instance-based nearest-neighbor algorithm was developed for a Geostationary Operational Environmental Satellite ( GOES) cloud classifier. Expert-labeled samples serve as the training sets for the various GOES image classification scenes. The initial implementation of the classifier using the complete set of available training samples has proven to be an inefficient method for real-time image classifications, requiring long computational run times and significant computer resources. A variety of training-set reduction methods were examined to find smaller training sets that provide quicker classifier run times with minimal reduction in classifier testing set accuracy. General differences within real-time image classifications as a result of using the various reduction methods were also analyzed. The fast condensed nearest-neighbor (FCNN)method reduced the size of the individual training sets by 68.3% ( fourfold cross-validation testing average) while the average overall accuracy of the testing sets decreased by only 4.1%. Training sets resulting from these reduction methods were also applied within a real-time classifier using a one-nearest-neighbor subroutine. Using the FCNN-reduced set, the subroutine run time on a 30 degrees latitude x 30 degrees longitude image (GOES-10 daytime) with 11 289 600 total pixels decreased by an average of 60.7%.	USN, Res Lab, Monterey, CA 93943 USA; Sci Appl Inst Corp, Monterey, CA USA	Bankert, RL (reprint author), USN, Res Lab, 7 Grace Hopper Ave, Monterey, CA 93943 USA.	rich.bankert@nrlmry.navy.mil					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; Bankert RLL, 1996, J APPL METEOROL, V35, P2036, DOI 10.1175/1520-0450(1996)035<2036:ITANNC>2.0.CO;2; Baum BA, 1997, J APPL METEOROL, V36, P1519, DOI 10.1175/1520-0450(1997)036<1519:ACCOGA>2.0.CO;2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERRIEN M, 1999, P 1999 EUMETSAT MET, P545; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hong Y, 2004, J APPL METEOROL, V43, P1834, DOI 10.1175/JAM2173.1; Lee Y, 2004, J ATMOS OCEAN TECH, V21, P159, DOI 10.1175/1520-0426(2004)021<0159:CCOSRD>2.0.CO;2; Lewis HG, 1997, INT J REMOTE SENS, V18, P899, DOI 10.1080/014311697218827; Li J, 2003, J APPL METEOROL, V42, P204, DOI 10.1175/1520-0450(2003)042<0204:HSRSAC>2.0.CO;2; LI Z, 2005, AM METEOR SOC; LIU GS, 1995, J GEOPHYS RES-ATMOS, V100, P13811, DOI 10.1029/95JD00823; Miller SW, 1997, J APPL METEOROL, V36, P1346, DOI 10.1175/1520-0450(1997)036<1346:AANNCC>2.0.CO;2; Pankiewicz G.S., 1995, METEOROL APPL, V2, P257; Pavolonis MJ, 2005, J APPL METEOROL, V44, P804, DOI 10.1175/JAM2236.1; Tag PM, 2000, J APPL METEOROL, V39, P125, DOI 10.1175/1520-0450(2000)039<0125:AAMCTC>2.0.CO;2; Tian B, 1999, IEEE T NEURAL NETWOR, V10, P138, DOI 10.1109/72.737500; Uddstrom MJ, 1996, J APPL METEOROL, V35, P839, DOI 10.1175/1520-0450(1996)035<0839:SCCARR>2.0.CO;2; WELCH RM, 1992, J APPL METEOROL, V31, P405, DOI 10.1175/1520-0450(1992)031<0405:PCASCU>2.0.CO;2; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	21	5	5	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	1558-8424		J APPL METEOROL CLIM	J. Appl. Meteorol. Climatol.	JAN 22	2007	46	1					36	49		10.1175/JAM2451.1		14	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	128DT	WOS:000243638900004	
J	Yu, XY; Liong, SY				Yu, Xinying; Liong, Shie-Yui			Forecasting of hydrologic time series with ridge regression in feature space	JOURNAL OF HYDROLOGY			English	Article						time series analysis; support vector machine; Gaussian kernel; features approximation; chaotic technique; evolutionary algorithm	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORKS; PREDICTION; RECONSTRUCTION; MODELS	Support vector machine (SVM) is one of the most elegant data mining engines developed most recently. It has been shown in various studies that SVM provides higher accuracy level than the local model in the chaotic time series analysis. Chaotic time series analysis usually requires a long data record and it is therefore computationally time consuming in addition to possible storage capacity problems. In this study a ridge linear regression is applied in a feature space. The feature space dimension of Gaussian kernel is infinite. With the use of a data sample set, the number of dimensions of feature space of Gaussian kernel can be estimated. The scheme can computationally be guaranteed to be faster and, at the same time, stable while the accuracy remains close to or much better than other existing techniques. Existing techniques used for comparisons are: (1) standard chaos technique; (2) Naive; (3) ARIMA; (4) Inverse Approach; and (5) SVM coupled the decomposition method. The parameters involved are calibrated with an evolutionary algorithm, Shuffled Complex Evolution (SCE). The performance of the proposed method is tested on Tryggevaelde catchment runoff and Mississippi river flow. Significantly higher prediction accuracies are obtained from the proposed scheme than from other existing techniques. In addition, the training speed of the scheme is very much faster than that of its counterparts (197 words < 300 words). (c) 2006 Elsevier B.V. All rights reserved.	Natl Univ Singapore, Dept Civil Engn, Singapore 119260, Singapore	Liong, SY (reprint author), Natl Univ Singapore, Dept Civil Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.	tmslsy@nus.edu.sg					Anctil F, 2004, J HYDROL, V286, P155, DOI 10.1016/j.jhydrol.2003.09.006; BABOVIC V, 2000, P 4 INT C HYDR IOW C; Burr Ridge I, 1997, MACHINE LEARNING; CASDAGLI M, 1989, PHYSICA D, V35, P335, DOI 10.1016/0167-2789(89)90074-2; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibike YB, 2001, J COMPUT CIVIL ENG, V15, P208, DOI 10.1061/(ASCE)0887-3801(2001)15:3(208); Doan CD, 2005, J HYDROINFORM, V7, P219; DUAN QY, 1992, WATER RESOUR RES, V28, P1015, DOI 10.1029/91WR02985; GIBSON JF, 1992, PHYSICA D, V57, P1, DOI 10.1016/0167-2789(92)90085-2; Girolami M, 2002, NEURAL COMPUT, V14, P669, DOI 10.1162/089976602317250942; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; KARUNANITHI N, 1994, J COMPUT CIVIL ENG, V8, P201, DOI 10.1061/(ASCE)0887-3801(1994)8:2(201); Liong SY, 2002, J AM WATER RESOUR AS, V38, P173, DOI 10.1111/j.1752-1688.2002.tb01544.x; LIONG SY, 2002, ROBUST EFFICIENT SCH; Phoon KK, 2002, J HYDROL ENG, V7, P116, DOI 10.1061/(ASCE)1084-0699(2002)7:2(116); Sivakumar B, 2002, J HYDROL, V265, P225, DOI 10.1016/S0022-1694(02)00112-9; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Takens F., 1981, DYNAMICAL SYSTEMS TU, V898, P366, DOI 10.1007/BFb0091924; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Vapnik V, 1997, ADV NEUR IN, V9, P281; VAPNIK V, 1992, ADV NEUR IN, V4, P831; Williams CKI, 2001, ADV NEUR IN, V13, P682; Williams C.K.I., 2000, P 17 INT C MACH LEAR; Yu XY, 2004, J HYDROINFORM, V6, P209; Zaldivar J., 2000, J HYDROINFORM, V2, P61; Zealand CM, 1999, J HYDROL, V214, P32, DOI 10.1016/S0022-1694(98)00242-X	27	28	30	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694		J HYDROL	J. Hydrol.	JAN 15	2007	332	3-4					290	302		10.1016/j.jhydrol.2006.07.003		13	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	133BH	WOS:000243986100004	
J	Wang, JG; Neskovic, P; Cooper, LN				Wang, Jigang; Neskovic, Predrag; Cooper, Leon N.			Improving nearest neighbor rule with a simple adaptive distance measure	PATTERN RECOGNITION LETTERS			English	Article						pattern classification; nearest neighbor rule; adaptive distance measure; adaptive metric; generalization error	CLASSIFICATION	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. However, it faces serious challenges when patterns of different classes overlap in some regions in the feature space. In the past, many researchers developed various adaptive or discriminant metrics to improve its performance. In this paper, we demonstrate that an extremely simple adaptive distance measure significantly improves the performance of the k-nearest neighbor rule. (c) 2006 Elsevier B.V. All rights reserved.	Brown Univ, Inst Brain & Neural Syst, Dept Phys, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Inst Brain & Neural Syst, Dept Phys, POB 1843, Providence, RI 02912 USA.	jigang@physics.brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1951, 4 USAF SCH AV MED; Friedman J ., 1994, 113 STANF U STAT DEP; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WANG J, 2005, LECT NOTES ARTIFICIA; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; WEINBERGER K, 2005, ADV NEURAL INFORM PR, P18	10	44	48	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 15	2007	28	2					207	213		10.1016/j.patrec.2006.07.002		7	Computer Science, Artificial Intelligence	Computer Science	116CT	WOS:000242780800004	
S	Wang, JJ; Hong, WX; Li, X		Huang, DS; Heutte, L; Loog, M		Wang, Jinjia; Hong, Wenxue; Li, Xin			The new graphical features of star plot for K nearest neighbor classifier	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF ARTIFICIAL INTELLIGENCE	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	3rd International Conference on Intelligent Computing	AUG 21-24, 2007	Qingdao, PEOPLES R CHINA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China		star plot; graphical features; features extraction; K nearest neighbor classifier		The graphical representation or graphical analysis for multidimensional data in multivariate analysis is a very useful method. But it rarely is used to the pattern recognition field. The paper we use the stat plot to represent one observation or sample with multi variances and extract the new graphical features of star plot: sub-area features and sub-barycentre features. The new features are used for the K nearest neighbor classifier (KNN) with leave one out cross validation. Experiments with several standard benchmark data sets show the effectiveness of the new graphical features.	Yanshan Univ, Dept Biomed Engineer, Qinhuangdao 066004, Peoples R China	Wang, JJ (reprint author), Yanshan Univ, Dept Biomed Engineer, Qinhuangdao 066004, Peoples R China.						ANSCOMBE FJ, GRAPHS STAT ANAL, V27, P17; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARINKA BV, 2005, CHEMOMETRICS INTELLI, V75, P31; Duda R.O., 2000, PATTERN CLASSIFICATI; Duin R.P.W., 2004, PRTOOLS4 MATLAB TOOL; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Joachims T, 1999, MAKING LARGE SCALE S; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7	8	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74201-2	LECT NOTES ARTIF INT			2007	4682						926	933				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Operations Research & Management Science	Computer Science; Operations Research & Management Science	BGU28	WOS:000250577100096	
S	Wang, B; Zhang, H		Kobti, Z; Wu, D		Wang, Bin; Zhang, Harry			Probability based metrics for locally weighted naive bayes	Advances in Artificial Intelligence	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	20th Conference of the Canadian-Society-for-Computational-Studies-of-Intelligence	MAY 28-30, 2007	Montreal, CANADA	Canadian Soc Computat Studies Intelligence		LWNB; probability based metrics; IVDM; SF2; SF2LOG; MRM	NEAREST-NEIGHBOR CLASSIFICATION	Locally weighted naive Bayes (LWNB) is a successful instance-based classifier, which first finds the neighbors of the test instance using Euclidean metric, and then builds a naive Bayes model in the local neighborhood. However, Euclidean metric is not the best choice for LWNB. For nominal attributes, Euclidean metric has to order and number the values of attributes, or judge whether the attribute values are identical or not. For numeric attributes, Euclidean metric is not appropriate for different attribute scales and variability, and encounters the problem of attribute value outliers when normalizing values. In this paper, we systematically study probability based metrics, such as Interpolated Value Difference Metric (IVDM), Extended Short and Fukunaga Metric (SF2), SF2 calibrated by logarithm (SF2LOG) and Minimum Risk Metric (MRM), and apply them to LWNB. These probability based metrics can solve the above problems of Euclidean metric since they depend on the difference between the probabilities to evaluate the distances between the instances. We conduct the experiments to compare the performances of LWNB classifiers using Euclidean metric and probability based metrics on UCI datasets. The results show that LWNB classifiers using IVDM outperform the ones using Euclidean metric and other probability based metrics. We also observe that SF2, SF2LOG and MRM do not perform well due to their inaccurate probability estimates. An artificial dataset is built by logical sampling in a Bayesian network, where accurate probability estimates can be produced. We conduct the experiment on the artificial dataset. The results show that SF2, SF2LOG and MRM using accurate probability estimates perform better than Euclidean metric and IVDM in LWNB.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Wang, B (reprint author), Univ New Brunswick, Fac Comp Sci, PO Box 4400, Fredericton, NB E3B 5A3, Canada.						Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Hastie T, 2001, ELEMENTS STAT LEARNI; Henrion M., 1988, UNCERTAINTY ARTIFICI, V2, P317; KNORR EM, 2001, P 7 ACM SIGKDD INT C, P126, DOI 10.1145/502512.502532; Loader C., 1999, LOCAL REGRESSION LIK; Merz C., 1997, UCI REPOSITORY MACHI; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Pfahringer B., 2003, P C UNC ART INT, P249; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I. H., 2000, DATA MINING PRACTICA; Zadrozny B., 2001, P 18 INT C MACH LEAR, P609; Zadrozny B., 2002, P 8 ACM SIGKDD INT C, P694	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-72664-7	LECT NOTES COMPUT SC			2007	4509						180	191				12	Computer Science, Artificial Intelligence	Computer Science	BGG73	WOS:000246691800016	
S	Hwang, S; Cho, S		Liu, DR; Fei, SM; Hou, ZG; Zhang, HG; Sun, CY		Hwang, Seongseob; Cho, Sungzoon			Clustering-based reference set reduction for k-nearest neighbor	Advances in Neural Networks - ISNN 2007, Pt 2, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Nanjing, PEOPLES R CHINA	Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago			PATTERN-CLASSIFICATION; SELECTION; SYSTEMS	Response Modeling is concerned with computing the likelihood of a customer to respond to a marketing campaign. A major problem encountered in response modeling is huge volume of data or patterns. The k-NN has been used in various classification problems for its simplicity and ease of implementation. However, it has not been applied to problems for which fast classification is needed since the classification time rapidly increases as the size of reference set increases. In this paper, we propose a clustering-based preprocessing step in order to reduce the size of reference set. The experimental results showed an 85% decrease in classification time without a loss of accuracy.	Seoul Natl Univ, Seoul 151744, South Korea	Cho, S (reprint author), Seoul Natl Univ, San 56-1, Seoul 151744, South Korea.						Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; EGAN JP, 1975, SIGNAL DETECTION THE; Eick CF, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P375, DOI 10.1109/ICDM.2004.10044; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237; Ha K, 2005, J INTERACT MARK, V19, P17, DOI 10.1002/dir.20028; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; He C, 2004, PATTERN RECOGN, V37, P1085, DOI 10.1016/j.patcog.2004.02.002; Likas A, 2003, PATTERN RECOGN, V36, P451; Malthouse E. C., 2001, J INTERACTIVE MARKET, V15, P49, DOI 10.1002/1520-6653(200124)15:1<49::AID-DIR1003>3.3.CO;2-6; Shin HJ, 2006, EXPERT SYST APPL, V30, P746, DOI 10.1016/j.eswa.2005.07.037; Swets JA, 2000, SCI AM, V283, P82; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yu EZ, 2006, EXPERT SYST APPL, V30, P352, DOI 10.1016/j.eswa.2005.07.026	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-72392-9	LECT NOTES COMPUT SC			2007	4492						880	888				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BGJ86	WOS:000247831300105	
S	Xiao, Y; Hope, BA; Tien, D		Qiu, GP; Leung, C; Xue, XY; Laurini, R		Xiao, Yi; Hope, Brian A.; Tien, David			Compound geospatial object detection in an aerial image	ADVANCES IN VISUAL INFORMATION SYSTEMS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	9th International Conference on Visual Information Systems	JUN 28-29, 2007	Shanghai, PEOPLES R CHINA		Fudan Univ, Dept Comp Sci & Engn	compound geospatial object detection; knowledge based system	SYSTEM	This paper introduces a knowledge based approach that can be used for the identification of jetty/bridge locations in aerial imagery. With the proposed method, the semantic network formalism to represent declarative knowledge embodied in a jetty/bridge image and the appropriate procedural knowledge, the control procedure was established. A knowledge based system was then introduced through image analysis and interpretation, aiming at accurately locating the desired objects from primary vague identification. With the advanced image processing techniques proposed here, the complexity of using knowledge based system for image analysis is reduced and the proposed method can effectively locate the compound geospatial objects of jetties and bridges.	[Xiao, Yi; Hope, Brian A.; Tien, David] Charles Sturt Univ, Dept Lands, Bathurst, NSW 2795, Australia	Xiao, Y (reprint author), Charles Sturt Univ, Dept Lands, Bathurst, NSW 2795, Australia.						Bhagavathy S, 2006, IEEE T GEOSCI REMOTE, V44, P3706, DOI 10.1109/TGRS.2006.881741; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3; Fradkin M, 2001, COMPUT VIS IMAGE UND, V82, P181, DOI 10.1006/cviu.2001.0917; Gonzalez R., 1992, DIGITAL IMAGE PROCES; Heipke C., 1997, INT ARCH PHOTOGRAMME, V32, P47; KNUDSEN T, 2004, P IEEE INT GEOSC REM, V5, P2830; MATSUYAMA T, 1987, IEEE T GEOSCI REMOTE, V25, P305, DOI 10.1109/TGRS.1987.289802; NICOLIN B, 1987, IEEE T GEOSCI REMOTE, V25, P317, DOI 10.1109/TGRS.1987.289803; NIEMANN H, 1990, IEEE T PATTERN ANAL, V12, P883, DOI 10.1109/34.57683; PETERI R, 2003, INT C IMAG PROC, V1, P301; QINT F, 1997, I PHOTOGRAMMETRIC FE, P213; Tupin F, 2003, ISPRS J PHOTOGRAMM, V58, P71, DOI 10.1016/S0924-2716(03)00018-2; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4	15	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-76413-7	LECT NOTES COMPUT SC			2007	4781						549	558				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHB25	WOS:000252060300053	
S	Takacs, G; Pataki, B		Basili, R; Pazienza, MT		Takacs, Gabor; Pataki, Bela			Nearest local hyperplane rules for pattern classification	AI(ASTERISK)IA 2007: ARTIFICIAL INTELLIGENCE AND HUMAN-ORIENTED COMPUTING	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	10th Congress of the Italian-Association-for-Artificial-Intelligence	SEP 10-13, 2007	Rome, ITALY	Italian Assoc Artificial Intelligence, CELI, ENEA, Exprivia, Fond IBM Italia, Google, Univ Rome, Tor Vergata			RECOGNITION; DISTANCE	Predicting the class of an observation from its nearest neighbors is one of the earliest approaches in pattern recognition. In addition to their simplicity, nearest neighbor rules have appealing theoretical properties, e.g. the asymptotic error probability of the plain 1-nearest-neighbor (NN) rule is at most twice the Bayes bound, which means zero asymptotic risk in the separable case. But given only a finite number of training examples, NN classifiers are often outperformed in practice. A possible modification of the NN rule to handle separable problems better is the nearest local hyperplane (NLH) approach. In this paper we introduce a new way of NLH classification that has two advantages over the original NLH algorithm. First, our method preserves the zero asymptotic risk property, of NN classifiers in the separable case. Second, it usually provides better finite sample performance.	[Takacs, Gabor; Pataki, Bela] Budapest Univ Technol & Econ, Dept Measurement & Informat Syst, H-1117 Budapest, Hungary	Takacs, G (reprint author), Budapest Univ Technol & Econ, Dept Measurement & Informat Syst, Magyar Tudosok Korutja 2, H-1117 Budapest, Hungary.		Pataki, Bela/G-8934-2012				Akaho S, 2002, P 9 INT C NEUR INF P, V2, P1069, DOI 10.1109/ICONIP.2002.1198224; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Boser B., 1992, P 5 ANN WORKSH COMP, P144, DOI DOI 10.1145/130385.130401; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Fisher RA, 1936, ANN EUGENIC, V7, P179; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; LECUNN Y, MNIST DATABASE HANDW; Newman D.J., UCI REPOSITORY MACHI; OKUN O, 2004, P 2 EUR WORKSH DAT M, P47; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; Vincent P, 2002, ADV NEUR IN, V14, P985	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74781-9	LECT NOTES COMPUT SC			2007	4733						302	313				12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Mathematical & Computational Biology; Robotics	Computer Science; Mathematical & Computational Biology; Robotics	BGW03	WOS:000250857400025	
S	Bosin, A; Dessi, N; Pes, B		Masulli, F; Mitra, S; Pasi, G		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			A cost-sensitive approach to feature selection in micro-array data classification	Applications of Fuzzy Sets Theory	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	7th International Workshop on Fuzzy Logic and Applications	JUL 07-10, 2007	Camogli, ITALY	Univ Genova, DISI, IEEE Computat Intelligence Soc, Italian Chapter, Int Neural Network Soc, SIGs Italy & Bioinformat, Bioinformat Italian Soc, Italian Neural Networks Soc, SCIP Working Grp, Univ Studi Milano, DSI, Univ Salerno, DMI, Gruppo Nazl Calcolo Sci		data mining; machine learning; bio-informatics	MODEL	In analyzing gene expression data from rnicro-array, a major challenge is the definition of a feature selection criterion to judge the goodness of a subset of features with respect to a particular classification model. This paper presents a cost-sensitive approach feature selection that focuses on two fundamental requirements: (1) the quality of the features in order to promote the classifier accuracy and (2) the cost of computation due to the complexity that occurs during training and testing the classifier. The paper describes the approach in detail and includes a case study for a publicly available micro-array dataset. Results show that the proposed process yields state-of-art performance and uses only a small fraction of features that are generally used in competitive approaches on the same dataset.	Univ Cagliari, Dipartimento Matemat & Informat, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dipartimento Matemat & Informat, Via Osped 72, I-09124 Cagliari, Italy.						AIKAKE H, 1973, P 2 INT S INF THEORY, P267; Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; BOSIN A, 2006, IEA AIE 2006, V4031, P790; BOSIN A, 2006, APPL ARTIF INTELL, P29; BOSIN A, 2006, LNCS, V3849; CHAI X, 2004, LNCS, V3275, P51; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRAGOS D, 2000, ICML, P583; Drummond C, 2006, MACH LEARN, V65, P95, DOI 10.1007/s10994-006-8199-5; Elkan C, 2001, P 17 INT JOINT C ART, P973; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; John G. H., 1994, P 11 INT C MACH LEAR; KAI MT, 1998, 2 EUR S PRINC DAT MI, P139; LING CX, 2004, DECISION TRESS MINIM; Liu Huiqing, 2002, Genome Inform, V13, P51; Lo YT, 2001, BIOMETRIKA, V88, P767, DOI 10.1093/biomet/88.3.767; Mukherjee S., 2003, UNDERSTANDING USING; O'Hagan A., 1994, KENDALLS ADV THEOR B, V2B; Pawitan Y, 2001, ALL LIKELIHOOD STAT; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; STATNIKOV A, 2005, BIOINFORMATICS, V21; Tao L., 2004, BIOINFORMATICS, V20, P2429; Tung WL, 2005, ARTIF INTELL MED, V33, P61, DOI 10.1016/j.artmed.2004.03.009; TURNEY PD, 2000, INT C MACH LEARN WOR, P15; Vapink V, 1998, STAT LEARNING THEORY; VUONG QH, 1989, ECONOMETRICA, V57, P307, DOI 10.2307/1912557; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; YAN L, 2003, ICML, P848; YARMUS JS, 2003, FAST GREEDY BAYESIAN; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; ZUBEK VB, 2002, ICML, P19	31	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-73399-7	LECT NOTES ARTIF INT			2007	4578						571	579				9	Computer Science, Artificial Intelligence	Computer Science	BGK97	WOS:000248082000073	
S	van den Bosch, A; Marsi, E; Soudi, A		Soudi, A; VandenBosch, A; Neumann, G		van den Bosch, Antal; Marsi, Erwin; Soudi, Abdelhadi			Memory-based Morphological Analysis and Part-of-speech Tagging of Arabic	ARABIC COMPUTATIONAL MORPHOLOGY: KNOWLEDGE-BASED AND EMPIRICAL METHODS	Text Speech and Language Technology		English	Article; Book Chapter								We explore the application of memory-based learning to morphological analysis and part-of-speech tagging of written Arabic, based on data from the Arabic Treebank. Morphological analysis is performed as a letter-by-letter classification task. Classification is performed by the k-nearest neighbor algorithm. Each classification produces a trigram of position-bound operations, each encoding segmentation, part-of-speech information, and letter transformations. The overlapping operation trigrams generated on the basis of an input word are converted into a lattice, from which all morphological analyses of the word are generated. Part-of-speech tagging is carried out separately from the morphological analyzer. A memory-based modular tagger is developed with a subtagger for known words and one for unknown words. On words not seen in training, the morphological analyzer attains a peak F-score of 0.47, while the tagger produces 66.4% correct tags. On all words, including words seen in training, the combination assigns a correct part-of-speech tag and generates all morphological analyses to about 91% of word tokens in running text	[van den Bosch, Antal; Marsi, Erwin] Tilburg Univ, Fac Arts, ILK Dept Language & Informat Sci, NL-5000 LE Tilburg, Netherlands; [Soudi, Abdelhadi] Ecole Natl Ind Minerale, Rabat, Morocco	van den Bosch, A (reprint author), Tilburg Univ, Fac Arts, ILK Dept Language & Informat Sci, POB 90153, NL-5000 LE Tilburg, Netherlands.	Antal.vdnBosch@uvt.nl; E.C.Marsi@uvt.nl; asoudi@gmail.com; asoudi@gmail.com					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Beesley K, 1990, P 2 CAMBR C BIL COMP; BEESLEY K, 1998, P COLING 98, P117; Buckwalter T., 2002, LDC2002L49; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2004, 0402 ILK TILB U ILK; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; DAELEMANS W, 2003, 0313 ILK TILB U ILK; FREEMAN A, 2001, ACL EACL 2001 WORKSH; Jurafsky Daniel, 2004, P 5 M N AM CHAPT ASS, P149, DOI 10.3115/1613984.1614022; KAY M, 1987, P 3 C EUR CHAPT ASS, P2, DOI 10.3115/976858.976860; Khoja S., 2001, P STUD WORKSH NAACL, P20; KIRAZ G, 1994, P COLING 94, V1, P180, DOI 10.3115/991886.991917; SOUDI A, 2002, THESIS MOHAMED V U M; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; van den Bosch A., 1999, P 37 ANN M ASS COMP, P285, DOI 10.3115/1034678.1034726; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; VANDENBOSCH A, 2006, P 5 INT C LANG RES E; VANDENBOSCH A, 2006, P 9 C NAT LANG LEARN, P80; ZAVREL J, 1999, 6 S INT COM SOC SANT, P590	22	0	0	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1386-291X	978-1-4020-6046-5	TEXT SPEECH LANG TEC			2007	38						201	217				17	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Computer Science; Linguistics	BLA54	WOS:000269769700012	
S	Prijs, M; Peelen, L; Bresser, P; Peek, N		Bellazzi, R; AbuHanna, A; Hunter, J		Prijs, Maurice; Peelen, Linda; Bresser, Paul; Peek, Niels			A nearest neighbor approach to predicting survival time with an application in chronic respiratory disease	Artificial Intelligence in Medicine, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	11th Conference on Artificial Intelligence in Medicine (AIME 2007)	JUL 07-11, 2007	Amsterdam, NETHERLANDS		Univ Amsterdam		CLASSIFICATION; MODELS	The care for patients with chronic and progressive diseases often requires that reliable estimates of their remaining lifetime are made. The predominant method for obtaining such individual prognoses is to analyze historical data using Cox regression, and apply the resulting model to data from new patients. However, the black-box nature of the Cox regression model makes it unattractive for clinical practice. Instead most physicians prefer to relate a new patient to the histories of similar, individual patients that were treated before. This paper presents a prognostic inference method that combines the k-nearest neighbor paradigm with Cox regression. It yields survival predictions for individual patients, based on small sets of similar patients from the past, and can be used to implement a prognostic case-retrieval system. To evaluate the method, it was applied to data from patients with idiopathic interstitial pneumonia, a progressive and lethal lung disease. Experiments pointed out that the method competes well with Cox regression. The best predictive performance was obtained with a neighborhood size of 20.	Univ Amsterdam, Acad Med Ctr, Dept Med Informat, NL-1105 AZ Amsterdam, Netherlands	Prijs, M (reprint author), Univ Amsterdam, Acad Med Ctr, Dept Med Informat, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.						AHA D, 1998, CASE BASE REASONING; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Anand SS, 2001, METHOD INFORM MED, V40, P18; Bichindaritz I, 2006, ARTIF INTELL MED, V36, P127, DOI 10.1016/j.artmed.2005.10.008; Brier G.W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2; Collard HR, 2003, AM J RESP CRIT CARE, V168, P538, DOI 10.1164/rccm.200211-1311OC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DR, 1972, J ROY STAT SOC B, V34, P187; DUDA RO, 1973, CLASSIFICATION SCENE; Graf E, 1999, STAT MED, V18, P2529, DOI 10.1002/(SICI)1097-0258(19990915/30)18:17/18<2529::AID-SIM274>3.0.CO;2-5; Hamilton PW, 1999, ANAL QUANT CYTOL, V21, P283; HANLEY JA, 1982, RADIOLOGY, V143, P29; Hastie T, 2001, ELEMENTS STAT LEARNI; KAPLAN EL, 1958, J AM STAT ASSOC, V53, P457, DOI 10.2307/2281868; Latsi PI, 2003, AM J RESP CRIT CARE, V168, P531, DOI 10.1164/rccm.200210-1245OC; PEREZ A, 2003, AM J RESP CELL MO S3, V129, P19; Schmidt R, 2001, INT J MED INFORM, V64, P355, DOI 10.1016/S1386-5056(01)00221-0; Therneau TM, 2000, MODELING SURVIVAL DA; American Thoracic Society/European Respiratory Society, 2002, AM J RESP CRIT CARE, V165, P277	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-73598-4	LECT NOTES ARTIF INT			2007	4594						77	86				10	Computer Science, Artificial Intelligence; Medical Informatics; Medicine, General & Internal	Computer Science; Medical Informatics; General & Internal Medicine	BGL69	WOS:000248222900009	
S	Wu, L; Neskovic, P		MarquesDeSa, J; Alexandre, LA; Duch, W; Mandic, D		Wu, Liang; Neskovic, Predrag			Classifying EEG data into different memory loads across subjects	Artificial Neural Networks - ICANN 2007, Pt 2, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	17th International Conference on Artificial Neural Networks (ICANN 2007)	SEP 09-13, 2007	Oporto, PORTUGAL	European Neural Networks Soc, Int Neural Networks Soc, Japanese Neural Network Soc, IEEE Comp Intelligence Soc, European Assoc Signal & Image Proc, Inst Engenhar Biomed, Univ Beira Interior, Inst Super Engenhar Porto, Reitor Univ Porto, UP, Dept Engenhar Elect Computadores, Inst Politecn Porto, Fund Cienc Tecnol, Fund Luso-Amer Desenvolvimento, Fund Calouste Gulbenkian, Microsoft Res Cambridge Lab, Portugal Telecom			FEATURE-SELECTION; CLASSIFICATION	In this paper we consider the question of whether it is possible to classify n-back EEG data into different memory loads across subjects. To capture relevant information from the EEG signal we use three types of features: power spectrum, conditional entropy, and conditional mutual information. In order to reduce irrelevant and misleading features we use a feature selection method that maximizes mutual information between features and classes and minimizes redundancy among features. Using a selected group of features we show that all classifiers can successfully generalize to the new subject for bands 1-40Hz and 1-60Hz. The classification rates are statistically. significant and the best classification rates, close to 90%, are obtained using conditional entropy features.	Brown Univ, Dept Phys, Providence, RI 02906 USA	Wu, L (reprint author), Brown Univ, Dept Phys, Providence, RI 02906 USA.						Christopher J. C. B., 1998, DATA MIN KNOWL DISC, V2, P121; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HJORTH B, 1975, ELECTROEN CLIN NEURO, V39, P526, DOI 10.1016/0013-4694(75)90056-5; KAPER M, 2004, ENG MED BIOL SOC, P4363; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; SCHRODER M, 2005, EURASIP J APPL SIG P, P3103; WU L, 2007, EUR S ART NEUR NETW, P567	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74693-5	LECT NOTES COMPUT SC			2007	4669						149	158				10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BGQ65	WOS:000249783400016	
S	Fayyaz, M; Khan, A; Mujahid, A; Kavokin, A		Mandoiu, I; Zelikovsky, A		Fayyaz, Mudassir; Khan, Asifullah; Mujahid, Adrian; Kavokin, Alex			Using multi level nearest neighbor classifiers for G-protein coupled receptor sub-families prediction	Bioinformatics Research and Applications, Proceedings	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd International Symposium on Bioinformatics Research and Applications	MAY 07-10, 2007	Atlanta, GA			fast fourier transform; G-proteins coupled receptors; multilevel classification; nearest neighbor classifier	FAST FOURIER-TRANSFORM; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; HIDDEN MARKOV-MODELS; GPCR RECOGNITION; CLASSIFICATION; SEQUENCE; SUBFAMILIES	Prediction based on the hydrophobicity of the protein yields potentially good classification rate as compared to the other compositions for G-Proteins coupled receptor (GPCR's) families and their respective subfamilies. In the current study, we make use of the hydrophobicity of the proteins in order to obtain a fourier spectrum of the protein sequence, which is then used for classification purpose. The classification of 17 GPCR subfamilies is based on Nearest Neighbor (NN) method, which is employed at two levels. At level-1 classification, the GPCR super-family is recognized and at level-2, the respective sub-families for the predicted super-family are classified. As against Support Vector Machine (SVM), NN approach has shown better performance using both jackknife and independent data set testing. The results are formulated using three performance measures, the Mathew's Correlation Coefficient (MCC), overall accuracy (ACC) and reliability (R) on both training and independent data sets. Comparison of our results is carried out with the overall class accuracies obtained for super-families using existing technique. The multilevel classifier has shown promising performance and has achieved overall ACC and MCC of 97.02% and 0.95 using jackknife test, and 87.50 % and 0.85 for independent data set test respectively.	Fac Comp Sci & Engn, GIK Inst Engn Sci & Technol, Swabi, Pakistan	Fayyaz, M (reprint author), Fac Comp Sci & Engn, GIK Inst Engn Sci & Technol, Swabi, Pakistan.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; COSIC I, 1994, IEEE T BIO-MED ENG, V41, P1101, DOI 10.1109/10.335859; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI, P1; Eisenhaber F, 1998, TRENDS CELL BIOL, V8, P69; FAUCHERE JL, 1983, EUR J MED CHEM, V18, P369; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; Guo YZ, 2005, ACTA BIOCH BIOPH SIN, V37, P759, DOI 10.1111/j.1745-7270.2005.00110.x; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hiramoto T, 2002, J PROTEIN CHEM, V21, P537, DOI 10.1023/A:1022429722651; Horn F, 2001, NUCLEIC ACIDS RES, V29, P346, DOI 10.1093/nar/29.1.346; ILMAN AG, GOODMAN GILMANS PHAR; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; Katoh K, 2002, NUCLEIC ACIDS RES, V30, P3059, DOI 10.1093/nar/gkf436; Khan A., 2005, International Journal of Knowledge-Based and Intelligent Engineering Systems, V9; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; LUDMILA I, 2004, COMBINING PATTERN CL; Majid A, 2006, INT J HYBRID INTELLI, V3, P109; Mandell AJ, 1997, PHYSICA A, V244, P254, DOI 10.1016/S0378-4371(97)00294-X; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; NOVIC M, 1995, J CHEM INF COMP SCI, V35, P454, DOI 10.1021/ci00025a013; Papasaikas PK, 2004, NUCLEIC ACIDS RES, V32, pW380, DOI 10.1093/nar/gkh431; Papasaikas PK, 2003, SAR QSAR ENVIRON RES, V14, P413, DOI 10.1080/10629360310001623999; Shepherd AJ, 2003, PROTEINS, V50, P290, DOI 10.1002/prot.10290; Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320; TRAMANTANO A, 2005, 10 MOST WANTED SOLUT	34	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-72030-0	LECT N BIOINFORMAT			2007	4463						564	576				13	Biochemistry & Molecular Biology; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BGE97	WOS:000246369100051	
S	Neuhaus, M; Bunke, H				Neuhaus, M; Bunke, H			Bridging the Gap between Graph Edit Distance and Kernel Machines	BRIDGING THE GAP BETWEEN GRAPH EDIT DISTANCE AND KERNEL MACHINES	Series in Machine Perception and Artificial Intelligence		English	Book							MINIMUM COMMON SUPERGRAPH; SUPPORT VECTOR MACHINES; STRUCTURAL PATTERN-RECOGNITION; ATTRIBUTED RELATIONAL GRAPHS; FINGERPRINT CLASSIFICATION; NEURAL-NETWORKS; STATISTICAL VARIABLES; PRINCIPAL COMPONENTS; CHINESE CHARACTERS; GENETIC ALGORITHMS									Alpaydin E., 1998, PEN BASED RECOGNITIO; Ambauen R, 2003, LECT NOTES COMPUT SC, V2726, P95; ANDREU G, 1997, P ICNN 97, V2, P1341, DOI 10.1109/ICNN.1997.616230; Bahlmann C., 2002, Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition, DOI 10.1109/IWFHR.2002.1030883; Barsi A, 2003, LECT NOTES ARTIF INT, V2734, P343; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; BAXTER K, 2000, P VIS INT MONTR, P179; Berg C., 1984, HARMONIC ANAL SEMIGR; Bishop CM, 1996, NEURAL NETWORKS PATT; Borgwardt K. M., 2005, P 5 IEEE INT C DAT M, P74; Borgwardt KM, 2005, BIOINFORMATICS, V21, P47; BUNKE H, 1993, PATTERN RECOGN, V26, P1797, DOI 10.1016/0031-3203(93)90177-X; Bunke H, 2003, LECT NOTES COMPUT SC, V2726, P235; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 2000, COMPUTING, V65, P13; Bunke H., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90033-8; BURGES C, 1995, N0001494C0186 AT T B; Byun H, 2003, INT J PATTERN RECOGN, V17, P459, DOI 10.1142/S0218001403002460; Caelli T, 2004, INT J PATTERN RECOGN, V18, P329, DOI 10.1142/S0218001404003186; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Cappelli R, 1999, IEEE T PATTERN ANAL, V21, P402, DOI 10.1109/34.765653; Cesar R., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1048339; Chang C-C., 2001, LIBSVM LIB SUPPORT V; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; CORDELLA L, 2002, P 15 INT C PATT REC, V2, P1038; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox T.F., 1994, MULTIDIMENSIONAL SCA; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Dickinson PJ, 2004, INT J PATTERN RECOGN, V18, P425, DOI 10.1142/S021800140400323X; Du Buf H, 2002, AUTOMATIC DIATOM IDE; Duda R.O., 2000, PATTERN CLASSIFICATI; EHRIG H, 1992, COMPUT MATH APPL, V23, P557, DOI 10.1016/0898-1221(92)90124-Z; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398; Feng J., 1994, PATTERN RECOGN, P177; Fernandez ML, 2001, PATTERN RECOGN LETT, V22, P753, DOI 10.1016/S0167-8655(01)00017-4; Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151; Friedman M, 1999, INTRO PATTERN RECOGN; Garey M.R., 1979, COMPUTERS INTRACTABI; Gartner T., 2003, SIGKDD EXPLORATIONS, V5, P49; GARTNER T, 2002, P NIPS WORKSH UNR DA; Gartner T., 2003, P 16 ANN C LEARN THE, P129; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; GOMILA C, 2001, P 3 IAPR TC 15 WORKS, P1; Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138; Gunter S, 2002, PATTERN RECOGN LETT, V23, P405, DOI 10.1016/S0167-8655(01)00173-8; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; Hartigan J., 1975, CLUSTERING ALGORITHM; Haussler D., 1999, UCSCCRL9910; Henry E.R., 1900, CLASSIFICATION USES; Hopcroft JE, 1974, P 6 ANN ACM S THEOR, P172, DOI 10.1145/800119.803896; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hotelling H, 1933, J EDUC PSYCHOL, V24, P498, DOI 10.1037/h0070888; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265; JAIN B, 2004, NEUROCOMPUTING, V63, P169; JAIN B, 2005, THESIS TU BERLIN; Jain BJ, 2005, NEUROCOMPUTING, V64, P93, DOI 10.1016/j.neucom.2004.11.011; Jain BJ, 2003, NEURAL PROCESS LETT, V17, P205, DOI 10.1023/A:1023657727387; Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Justice D, 2006, IEEE T PATTERN ANAL, V28, P1200, DOI 10.1109/TPAMI.2006.152; KANDOLA J, 2002, NEURAL INFORM PROCES, V15; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; Kashima H, 2003, P 20 INT C MACH LEAR, P321; Kashima H., 2002, P ICDM WORKSH ACT MI, P31; KAWAGOE M, 1984, PATTERN RECOGN, V17, P295, DOI 10.1016/0031-3203(84)90079-7; Kondor RI, 2002, P 19 INT C MACH LEAR, P315; Kuncheva L., 2004, COMBINING PATTERN CL; Lafferty J., 2003, ADV NEURAL INFORM PR, V15, P375; Lafferty J, 2005, J MACH LEARN RES, V6, P129; Le Saux B, 2005, LECT NOTES COMPUT SC, V3523, P147; Leslie Christina, 2002, Pac Symp Biocomput, P564; Leslie CS, 2004, BIOINFORMATICS, V20, P467, DOI 10.1093/bioinformatics/btg431; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; Levi G, 1973, CALCOLO, V9, P341; Llados J, 2001, IEEE T PATTERN ANAL, V23, P1137, DOI 10.1109/34.954603; Llados J, 2004, INT J PATTERN RECOGN, V18, P455, DOI 10.1142/S0218001404003204; LU SW, 1991, PATTERN RECOGN, V24, P617; LUKS EM, 1982, J COMPUT SYST SCI, V25, P42, DOI 10.1016/0022-0000(82)90009-5; Lumini A., 1999, Machine Graphics & Vision, V8; LUNDSTEEN C, 1980, CLIN GENET, V18, P355; Luo B, 2003, PATTERN RECOGN, V36, P2213, DOI 10.1016/S0031-3203(03)00084-0; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120; Mahe P., 2004, P 21 INT C MACH LEAR, P552; Maio D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547013; Maltoni D., 2003, HDB FINGERPRINT RECO; Marcialis GL, 2003, LECT NOTES COMPUT SC, V2688, P310; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.2307/2975974; MIKA S, 2001, P IEEE WORKSH NEUR N, P41; MILNE GWA, 1986, J CHEM INF COMP SCI, V26, P154, DOI 10.1021/ci00052a002; Mollineda R. A., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047429; MONTESYGOMEZ M, 2000, LECT NOTES COMPUTER, V1873, P312; More J. J., 1991, SIAM J OPTIMIZ, V1, P93, DOI 10. 1137/0801008; MORENO PJ, 2004, P ADV NEUR INF PROC, V16, P1385; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32; Neuhaus M, 2005, IEEE T SYST MAN CY B, V35, P503, DOI 10.1109/TSMCB.2005.846635; Neuhaus M, 2007, INFORM SCIENCES, V177, P239, DOI 10.1016/j.ins.2006.02.013; Neuhaus M., 2004, P 17 INT C PATT REC, V3, p[389, 2]; Nocedal J., 2000, NUMERICAL OPTIMIZATI; Parzen E., 1962, ANN MATH STAT, V33, P1064; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PERIS G, 2002, P 16 INT C PATT REC, V4, P184; Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56; Robles-Kelly A, 2004, INT J PATTERN RECOGN, V18, P315, DOI 10.1142/S0218001404003277; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; Rouvray DH, 1979, APPL GRAPH THEORY, P177; Sanfeliu A, 2004, INT J PATTERN RECOGN, V18, P375, DOI 10.1142/S0218001404003253; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353; Saunders C, 1998, P 15 INT C MACH LEAR, P515; Schadler K, 1999, APPL INTELL, V11, P15, DOI 10.1023/A:1008320413168; Schenker A, 2004, INT J PATTERN RECOGN, V18, P475, DOI 10.1142/S0218001404003241; Schenker A, 2004, LECT NOTES COMPUT SC, V3077, P214; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; SELKOW SM, 1977, INFORM PROCESS LETT, V6, P184, DOI 10.1016/0020-0190(77)90064-3; SERRAU, 2005, LNCS, V3434, P281; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shimodaira H, 2002, ADV NEUR IN, V14, P921; Shokoufandeh A., 2001, LECT NOTES COMPUTER, V2059, P67; Shokoufandeh A, 2005, IEEE T PATTERN ANAL, V27, P1125, DOI 10.1109/TPAMI.2005.142; Siddiqi K, 1999, INT J COMPUT VISION, V30, P1; Singh M, 1997, PATTERN RECOGN, V30, P1451, DOI 10.1016/S0031-3203(96)00181-1; Smola A., 2003, P 16 ANN C LEARN THE, P144; SPILLMANN B, 2005, THESIS U BERN SWITZE; SUGANTHAN PN, 1995, PATTERN RECOGN, V28, P997, DOI 10.1016/0031-3203(94)00166-J; SUGANTHAN PN, 1995, IMAGE VISION COMPUT, V13, P45, DOI 10.1016/0262-8856(95)91467-R; Suganthan PN, 1998, IMAGE VISION COMPUT, V16, P191, DOI 10.1016/S0262-8856(97)00066-8; Suganthan PN, 2002, PATTERN RECOGN, V35, P1883, DOI 10.1016/S0031-3203(01)00136-4; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Wyk M., 2003, IEEE T PATTERN ANAL, V24, P988; VANWYK MA, 2000, PROBLEMS APPL MATH C, P67; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vert J.-P., 2003, ADV NEURAL INFORMATI, V15, P1425; Voigt JH, 2001, J CHEM INF COMP SCI, V41, P702, DOI 10.1021/ci000150t; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wallis WD, 2001, PATTERN RECOGN LETT, V22, P701, DOI 10.1016/S0167-8655(01)00022-8; Wang YK, 1997, IEEE T SYST MAN CY B, V27, P588; Watkins C, 2000, ADV NEUR IN, P39; Watkins C, 1999, CSDTR9807 ROYAL HOLL; Watson C., 1992, 4 NIST, V4; WEISLOW OS, 1989, J NATL CANCER I, V81, P577, DOI 10.1093/jnci/81.8.577; Wilson R., 2004, P 17 INT C PATT REC, V2, P489; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599; XU L, 1990, LECT NOTES COMPUT SC, V412, P151; Yager N, 2004, PATTERN ANAL APPL, V7, P77, DOI 10.1007/s10044-004-0204-7; Yao Y, 2003, PATTERN RECOGN, V36, P397; ZHANG X, 1998, COMPUTATIONAL OPTIMI; Zhou RW, 1995, PATTERN RECOGN LETT, V16, P1267, DOI 10.1016/0167-8655(95)00078-X; *INT BIOM GROUP, 2006, BIOM MARK IND REP 20	160	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE	1793-0839	978-9-81270-817-5	SER MACH PERCEPT ART			2007	68						1	232		10.1142/9789812770202		232	Computer Science, Artificial Intelligence	Computer Science	BKV88	WOS:000269438200008	
S	Massie, S; Craw, S; Wiratunga, N		Weber, RO; Richter, MM		Massie, Stewart; Craw, Susan; Wiratunga, Nirmalie			When similar problems don't have similar solutions	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	7th International Conference on Case-Based Reasoning	AUG 13-16, 2007	Belfast, NORTH IRELAND	DFKI, Drexel iSch, empolis, Univ Ulster, Zerosolution			LEARNING ALGORITHMS	The performance of a Case-Based Reasoning system relies on the integrity of its case base but in real life applications the available data used to construct the case base invariably contains erroneous, noisy cases. Automated removal of these noisy cases can improve system accuracy. In addition, error rates for nearest neighbour classifiers can often be reduced by removing cases to give smoother decision boundaries between classes. In this paper we argue that the optimal level of boundary smoothing is domain dependent and, therefore, our approach to error reduction reacts to the characteristics of the domain to set an appropriate level of smoothing. We present a novel, yet transparent algorithm, Threshold Error Reduction, which identifies and removes noisy and boundary cases with the aid of a local complexity measure. Evaluation results confirm it to be superior to benchmark algorithms.	Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland	Massie, S (reprint author), Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland.	sm@comp.rgu.ac.uk; smc@comp.rgu.ac.uk; nw@comp.rgu.ac.uk					Blake CL, 1998, UCI REPOSITORY MACHI; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Delany SJ, 2004, LECT NOTES COMPUT SC, V3155, P128; Keane M. T., 1995, P 14 INT JOINT C ART, P377; LOPEZ R, 2006, KNOWL ENG REV, V20, P215; Maletic J.I., 2000, P C INF QUAL, P200; MASSIE S, 2005, P 20 NAT C ART INT, P216; Massie S, 2006, LECT NOTES ARTIF INT, V4106, P325; Orr K, 1998, COMMUN ACM, V41, P66, DOI 10.1145/269012.269023; Roth-Berghofer TR, 2004, LECT NOTES COMPUT SC, V3155, P389; Smyth B, 2001, COMPUT INTELL-US, V17, P235, DOI 10.1111/0824-7935.00142; SMYTH B, 1999, P 3 INT C CAS BAS RE, P329; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Witten I. H., 2000, DATA MINING PRACTICA; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8	20	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74138-1	LECT NOTES COMPUT SC			2007	4626						92	106				15	Computer Science, Artificial Intelligence	Computer Science	BGQ79	WOS:000249814900007	
S	Duin, RPW; Pekalska, E		Duch, W; Mandziuk, J		Duin, Robert P. W.; Pekalska, Elzbieta			The Science of Pattern Recognition. Achievements and Perspectives	CHALLENGES FOR COMPUTATIONAL INTELLIGENCE	Studies in Computational Intelligence		English	Article; Book Chapter							FEATURE-SELECTION; CLASSIFICATION; COMPLEXITY; DISTANCE; MODEL	Automatic pattern recognition is usually considered as an engineering area which focusses on the development and evaluation of systems that imitate or assist humans in their ability of recognizing patterns. It may, however, also be considered as a science that studies the faculty of human beings (and possibly other biological systems) to discover, distinguish, characterize patterns in their environment and accordingly identify new observations. The engineering approach to pattern recognition is in this view an attempt to build systems that simulate this phenomenon. By doing that, scientific understanding is gained of what is needed in order to recognize patterns, in general. Like in any science understanding can be built from different, sometimes even opposite viewpoints. We will therefore introduce the main approaches to the science of pattern recognition as two dichotomies of complementary scenarios. They give rise to four different schools, roughly defined under the terms of expert systems, neural networks, structural pattern recognition and statistical pattern recognition. We will briefly describe what has been achieved by these schools, what is common and what is specific, which limitations are encountered and which perspectives arise for the future. Finally, we will focus on the challenges facing pattern recognition in the decennia to come. They mainly deal with weaker assumptions of the models to make the corresponding procedures for learning and recognition wider applicable. In addition, new formalisms need to be developed.	[Duin, Robert P. W.] Delft Univ Technol, Fac Electr Eng Math & Comp Sci, ICT Grp, NL-2600 AA Delft, Netherlands; [Pekalska, Elzbieta] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	Duin, RPW (reprint author), Delft Univ Technol, Fac Electr Eng Math & Comp Sci, ICT Grp, NL-2600 AA Delft, Netherlands.	r.duin@ieee.org; pekalska@cs.man.ac.uk					ARKADEV AG, 1966, COMPUTERS PATTERN RE; Basu M., 2006, DATA COMPLEXITY PATT; BERGMANN R, 2004, DEV IND CASE BASED R; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; BUNKE H, 2001, INT C ADV PATTERN RE, P1; BUNKE H, 2000, ICPR00, V2, P117; Burr Ridge I, 1997, MACHINE LEARNING; Cherkassky V, 1998, LEARNING DATA CONCEP; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; de Diego IM, 2004, LECT NOTES COMPUT SC, V3077, P102; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devroye L, 1996, PROBABILISTIC THEORY; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R., 2004, PATTERN REPRESENTATI, P43; Duin RPW, 2005, ADV SOFT COMP, P27; DUIN RPW, 2001, 4 QUINQUENNIAL REV 1, P331; DUIN RPW, 2004, INT C PATT REC CAMBR, V2, P140; Duin RPW, 2002, PATTERN RECOGN LETT, V23, P493, DOI 10.1016/S0167-8655(01)00181-7; EDELMAN Shimon, 1999, REPRESENTATION RECOG; Efron B., 1993, INTRO BOOTSTRAP; Flach P. A., 2000, ABDUCTION INDUCTION; FRED A, 2002, C COMP VIS PATT REC, P442; Fred ALN, 2002, INT C PATT RECOG, P276; Fu K. S., 1982, SYNTACTIC PATTERN RE; Fukunaga K., 1990, INTRO STAT PATTERN R; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; GOLDFARB L, 1998, INT C ADV PATT REC S, P405; GOLDFARB L, 2005, TR05175 U NEW BRUNSW; Goldfarb L., 2001, TR01147 U NEW BRUNSW; GOLDFARB L, 1995, PATTERN RECOGN LETT, V16, P719, DOI 10.1016/0167-8655(95)00024-B; GOLDFARB L, 1990, PATTERN RECOGN, V23, P595, DOI 10.1016/0031-3203(90)90037-L; Graepel T, 2000, ADV NEUR IN, V12, P456; Graepel T, 1999, IEE CONF PUBL, P304, DOI 10.1049/cp:19991126; Grenander U., 1981, ABSTRACT INFERENCE; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Hacking Ian, 1974, EMERGENCE PROBABILIT; HARMAN G, RELIABLE RE IN PRESS; HAYKIN S, 1999, NEURAL NETWORKS COMP; Heckerman D., 1999, LEARNING GRAPHICAL M, P301; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JOACHIMS T, 2003, INT C MACH LEARN; Joachims T., 1999, INT C MACH LEARN ICM, P200; Kuhn T. S., 1970, STRUCTURE SCI REVOLU; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Kuncheva L., 2004, COMBINING PATTERN CL; Laub J, 2004, J MACH LEARN RES, V5, P801; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MICHALSKI RS, 1993, MACH LEARN, V11, P111, DOI 10.1007/BF00993074; Neapolitan R. E., 1990, PROBABILISTIC REASON; Ong C., 2004, INT C MACH LEARN BRI; PEKALSKA E, 2004, JOINT IAPR INT WORKS, P1145; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Pekalska E, 2004, LECT NOTES COMPUT SC, V3077, P122; Pekalska E, 2005, SER MACH PERCEPT ART, V64, P1, DOI 10.1142/9789812703170; Perlovsky LI, 1998, IEEE T PATTERN ANAL, V20, P666, DOI 10.1109/34.683784; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ripley B. D., 1996, PATTERN RECOGNITION; Robert C. P., 2001, BAYESIAN CHOICE; Sayre K., 1965, RECOGNITION STUDY PH; SCHLESINGER MI, 2002, 10 LECT STAT STRUCT; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Tax D., 2001, THESIS DELFT U TECHN; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; van der Heiden F., 2004, CLASSIFICATION PARAM; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1998, STAT LEARNING THEORY; WANG LX, 1992, IEEE T SYST MAN CYB, V22, P1414, DOI 10.1109/21.199466; Watanabe S., 1985, PATTERN RECOGNITION; Webb A., 2002, STAT PATTERN RECOGNI; Wilson RC, 2005, IEEE T PATTERN ANAL, V27, P1112, DOI 10.1109/TPAMI.2005.145; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; Wolfram S., 2002, NEW KIND SCI; Wolpert D. H., 1995, MATH GEN; Yager R, 1994, ADV DEMPSTER SHAFER; YU CH, 2006, ANN M AM ED RES ASS	83	2	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	978-3-540-71983-0	STUD COMPUT INTELL			2007	63						221	259			10.1007/978-3-540-71984-7	39	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BLW84	WOS:000271240200011	
S	Yang, CY; Hsu, CC; Yang, JS		Wang, Y; Cheung, YM; Liu, H		Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu			Learning SVM with varied example cost: A kNN evaluating approach	COMPUTATIONAL INTELLIGENCE AND SECURITY	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	International Conference on Computational-Intelligence and Security	NOV 03-06, 2006	Guangzhou, PEOPLES R CHINA	IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Univ		learning cost; support vector machine; k nearest neighbor; classification; pattern recognition	CLASSIFICATION; CONSISTENCY	The paper proposes a model merging a non-parametric k-nearest-neighbor (kNN) method into an underlying support vector machine (SVM) to produce an instance-dependent loss function. In this model, a filtering stage of the kNN searching was employed to collect information from training examples and produced a set of emphasized weights which can be distributed to every example by a class of real-valued class labels. The emphasized weights changed the policy of the equal-valued impacts of the training examples and permitted a more efficient way to utilize the information behind the training examples with various sionificance levels. Due to the property of estimating density locally, the kNN method has the advantage to distinguish the heterogeneous examples from the regular examples by merely considering the situation of the examples themselves. The paper shows the model is promising with both the theoretical derivations and consequent experimental results.	[Yang, Chan-Yun] Technol & Sci Inst No Taiwan, Dept Mech Engn, Taipei 112, Taiwan	Yang, CY (reprint author), Technol & Sci Inst No Taiwan, Dept Mech Engn, 2 Xue Yuan Rd, Taipei 112, Taiwan.						Bartlett P.L, 2003, 638 U CAL BERK DEP S; BREIMAN L, 1996, 460 U CAL BERK DEP S; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fukunaga K., 1990, STAT PATTERN RECOGNI; Hastie T, 2001, ELEMENTS STAT LEARNI; Hsu CC, 2005, LECT NOTES ARTIF INT, V3801, P550; Lin Y, 2004, STAT PROBABIL LETT, V68, P73, DOI 10.1016/j.spl.2004.03.002; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Steinwart I, 2005, IEEE T INFORM THEORY, V51, P128, DOI 10.1109/TIT.2004.839514; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang CY, 2004, LECT NOTES COMPUT SC, V3173, P506; Zhang T, 2004, ANN STAT, V32, P56	17	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74376-7	LECT NOTES ARTIF INT			2007	4456						326	335				10	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BGY38	WOS:000251348000035	
B	Thulasiram, RK; Bamgbade, AY		Chen, SH; Wang, PP; Kuo, TW		Thulasiram, Ruppa K.; Bamgbade, Adenike Y.			Application of an instance based learning algorithm for predicting the stock market index	Computational Intelligence in Economics and Finance, Vol II			English	Proceedings Paper	4th International Workshop on Computer Intelligence in Economics and Finance (CIEF 2005)	JUL 21-26, 2005	Salt Lake City, UT			stock market; financial forecasting; computational intelligence; instance based learning; stock price index	CLASSIFICATION	Instance based learning is a class of data mining learning paradigms that applies specific cases or experiences to new situations by matching known cases and experiences with new cases. This paper presents an application of the instance-based learning algorithm for predicting daily stock index price changes of the S&P 500 stock index between October 1995 and September 2000, given the daily changes in the exchange rate of the Canadian Dollar, the Pound Sterling, the French Franc, the Deutsche Mark and the Yen, the monthly changes in the consumer price index, GDP, and the changes in the monthly rates of certificates of deposit. The algorithm is used to predict an increase, decrease or no change in the S&P 500 stock index between a business day and the previous business day. The predictions are carried out using the IB3 variant of the IBL algorithms. The objective is to determine the feasibility of stock price prediction using the IB3 variant of the IBL algorithms. Various testing proportions and normalization methods are experimented with to obtain good predictions.	Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada							AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; APPADOO SS, 2000, FUZZY ALGEBRAIC APPR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowles A, 1937, ECONOMETRICA, V5, P280, DOI 10.2307/1905515; Dixit A., 1994, INVESTMENT UNDER UNC; HERBERT J, 2005, P CDROM COMP INT EC; Hogg RV, 2001, PROBABILITY STAT INF; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; KNORR E, 1998, ALGORITHMS MINING DI, P392; KOVALERCHUK B, 2000, DATA MINING USING NE; LEUNG CK, 2005, P CDROM COMP INT EC; LIU Y, 2001, P 2001 IEEE C EV COM, P256; Lo AW, 2000, J AM STAT ASSOC, V95, P629, DOI 10.2307/2669406; MAKRIDAKIS S, 1978, FORECASTING MEHTODS; MENDELBROT B, 2004, MISBEHAVIOR MARKETS; OLIKER S, 1997, FINANCE TECHNOLOGY, P183; Pawlak Z., 1991, ROUGH SETS THEORETIC; RAHMAN MR, 2002, DISTRIBUTED MULTIHRE; RAHMAN MR, 2002, P 14 IASTED INT C PA, P465; REFENSES APN, 1995, NERUAL NETWORKS CAPI; SAMUELSON PA, 1965, IMR-IND MANAG REV, V6, P41; WEIGEND AS, 1997, DECISION TECHNOLOGIE; YAO JT, 1999, INT J THEORETICAL AP, V2, P221, DOI 10.1142/S0219024999000145; *YAH, INC YAH FIN HIST PR	24	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY		978-3-540-72820-7				2007							145	155		10.1007/978-3-540-72821-4_9		11	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Economics; Information Science & Library Science; Statistics & Probability	Business & Economics; Computer Science; Information Science & Library Science; Mathematics	BGQ55	WOS:000249778600009	
S	Martin, JAH; de Lope, J		Diaz, RM; Pichler, F; Arencibia, AQ		Antonio Martin, Jose H.; de Lope, Javier			A k-NN based perception scheme for Reinforcement Learning	COMPUTER AIDED SYSTEMS THEORY- EUROCAST 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	11th International Conference on Computer Aided Systems Theory	FEB 12-16, 2007	Las Palmas, SPAIN		Elder Museum Sci & Technol	Reinforcement Learning; k-nearest-neighbors; collective; decision making		A perception scheme for Reinforcement Learning (RL) is developed as a function approximator. The main motivation for the development of this scheme is the need for generalization when the problem to be solved has continuous state variables. We propose a solution to the generalization problem in RL algorithms using a k-nearest-neighbor pattern classification (k-NN). By means of the k-NN technique we investigate the effect of collective decision making as a mechanism of perception and action-selection and a sort of back-propagation of its proportional influence in the action-selection process as the factor that moderate the learning of each decision making unit. A very well known problem is presented as a case study to illustrate the results of this k-NN based perception scheme.	[Antonio Martin, Jose H.] Univ Complutense Madrid, Dept Sistemas Informat & Computac, E-28040 Madrid, Spain	Martin, JAH (reprint author), Univ Complutense Madrid, Dept Sistemas Informat & Computac, E-28040 Madrid, Spain.		Martin H., Jose Antonio/A-2388-2009				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; SUTTON R, 2006, REINFORCEMENT LEARNI; Sutton R. S., 1992, REINFORCEMENT LEARNI; Sutton R. S., 1998, REINFORCEMENT LEARNI; SUTTON RS, 1992, SECS, V173; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	7	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-75866-2	LECT NOTES COMPUT SC			2007	4739						138	145				8	Computer Science, Theory & Methods	Computer Science	BGZ50	WOS:000251543000018	
J	Zitouni, I				Zitouni, Imed			Backoff hierarchical class n-gram language models: effectiveness to model unseen events in speech recognition	COMPUTER SPEECH AND LANGUAGE			English	Article								In this paper, we introduce the backoff hierarchical class n-gram language models to better estimate the likelihood of unseen n-gram events. This multi-level class hierarchy language modeling approach generalizes the well-known backoff n-gram language modeling technique. It uses a class hierarchy to define word contexts. Each node in the hierarchy,is a class that contains all the words of its descendant nodes. The closer a node to the root, the more general the class (and context) is. We investigate the effectiveness of the approach to model unseen events in speech recognition. Our results illustrate that the proposed technique outperforms backoff n-gram language models. We also study the effect of the vocabulary size and the depth of the class hierarchy on the performance of the approach. Results are presented on Wall Street Journal (WSJ) corpus using two vocabulary set: 5000 words and 20,000 words. Experiments with 5000 word vocabulary, which contain a small numbers of unseen events in the test set, show up to 10% improvement of the unseen event perplexity when using the hierarchical class n-gram language models. With a vocabulary of 20,000 words, characterized by a larger number of unseen events, the perplexity of unseen events decreases by 26%, while the word error rate (WER) decreases by 12% when using the hierarchical approach. Our results suggest that the largest gains in performance are obtained when the test set contains a large number of unseen events. (c) 2006 Elsevier Ltd. All rights reserved.		Zitouni, I (reprint author), IBM Corp, Thomas J Watson Res Ctr, Multilingual NLP, POB 218,20-136, Yorktown Hts, NY 10598 USA.	izitouni@us.ibm.com					BAHL L, 1987, IEEE T ACOUSTICS SPE, V37, P1001; BAI S, 1998, P ICASSP 1998; Bellegarda J., 2000, P IEEE, V88; BILMES JA, 2003, P HLT NAACL CAN MAY; Breiman L, 1984, CLASSIFICATION REGRE; Brown P. F., 1992, Computational Linguistics, V18; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darken C., 1990, IEEE INNS INT J C NE, VII, P233; DUPONT P, 1997, CMUCS97173; GOODMAN J, 2001, COMPUTER SPEECH  OCT, P403; GUPTA V, 1992, COMPUTER SPEECH LANG, P331; HEEMAN PA, 1999, JOINT SIGDAT C EMP M, P129; Jelinek F., 1990, READINGS SPEECH RECO, P450; KATZ SM, 1987, IEEE T ACOUSTIC SPEE, V35; LI H, 1995, EUR 95 MADR SPAIN; MACQUEEN J, 1967, P 5 BERK S MATH STAT, V281; MILLER JW, 1996, P ICSLP 1996; Rosenfeld R., 2000, P IEEE, V88; SAMUELSSON C, 1999, P ICASSP 1999; SUHM B, 1994, P ICSLP 1994; XU P, 2004, C EMP METH NAT LANG; ZHOU Q, 1997, P IEEE INT C AC SPEE, P1779; ZITOUNI I, 2003, P EUR 2003 GEN SWITZ; ZITOUNI I, 2003, P IEEE NLPKE 2003 BE; ZITOUNI I, 2003, P IEEE ASRU 2003 ST; ZITOUNI L, 2002, P ICSLP 2002 DENV US	27	10	10	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0885-2308		COMPUT SPEECH LANG	Comput. Speech Lang.	JAN	2007	21	1					88	104		10.1016/j.csl.2006.01.001		17	Computer Science, Artificial Intelligence	Computer Science	102EW	WOS:000241794800005	
J	Jung, JJ				Jung, Jason J.			Semantic co-browsing system based on contextual synchronization on peer-to-peer environment	COMPUTING AND INFORMATICS			English	Article						context-awareness; focused crawling; peer-to-peer	WEB; CLASSIFICATION; NETWORK	In this paper, we focus on a personalized information retrieval system based on multi-agent platform. Especially, they are capable of sharing information between them, for supporting collaborations between people. Personalization module has to be exploited to be aware of the corresponding user's browsing contexts (e.g., purposes, intention, and goals) at the specific moment. We want to recommend as relevant information to the estimated user context as possible, by analyzing the interaction results (e.g., clickstreams or query results). Thereby, we propose a novel approach to self-organizing agent groups based on contextual synchronization. Synchronization is an important requirement for online collaborations among them. This synchronization method exploits contextual information extracted from a set of personal agents in the same group, for real-time information sharing. Through semantically tracking of the users' information searching behaviors, we model the temporal dynamics of personal and group context. More importantly, in a certain moment, the contextual outliers can be detected, so that the groups can be automatically organized again with the same context. The cobrowsing system embedding our proposed method was shown 52.7% and 11.5% improvements of communication p, erformance, compared to single browsing system and asynchronous collaborative browsing system, respectively.	Yeungnam Univ, Dept Comp Engn, Gyeungsan, South Korea	Jung, JJ (reprint author), Yeungnam Univ, Dept Comp Engn, Gyeungsan, South Korea.	j2jung@intelligent.pe.kr	Jung, Jason J./B-9622-2012	Jung, Jason J./0000-0003-0050-7445			Androutsellis-Theotokis S, 2004, ACM COMPUT SURV, V36, P335, DOI 10.1145/1041680.1041681; BERNERSLEE T, 2001, SEMANTIC WEB SCI AM, V285, P34; BRA PD, 1994, COMPUTER NETWORKS IS, V27, P183; Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3; Chakrabarti S., 2002, P 11 INT WORLD WID W, P148; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dieng R., 1998, P 13 EUR C ART INT E, P341; Euzenat J., 2005, J DATA SEMANTICS, V4, P146, DOI DOI 10.1007/11603412\-5; EUZENAT J, 1994, P 4 ASIS SIG CR WORK, P69; Jung JJ, 2005, J UNIVERS COMPUT SCI, V11, P213; JUNG JJ, IN PRESS INFORM RETR; Jung JJ, 2005, J UNIVERS COMPUT SCI, V11, P1383; Jung JJ, 2005, IEICE T INF SYST, VE88D, P843, DOI 10.1093/ietisy/e88-d.5.843; Kalfoglou Y, 2003, KNOWL ENG REV, V18, P1, DOI 10.1017/S0269888903000651; KLEINBERG J. M., 1999, JACM, V46, P5; Levenshtein V, 1966, CYBERNETICS CONTROL, V10, P707; Madhavan J., 2001, P 27 INT C VER LARG, P48; Menczer F., 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773; Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875; Papadimitriou S., 2005, P 31 INT C VER LARG, P697; Papadimitriou S, 2004, VLDB J, V13, P222, DOI 10.1007/s00778-004-0130-8; Puttagunta V., 2002, P 2002 INT C MACH LE, P197; Sahami M, 1998, P AAAI 98 WORKSH LEA; Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5; Stumme G., 2001, P 17 INT JOINT C ART, P225; Xiao L, 2005, IEEE T PARALL DISTR, V16, P1078; Yang B, 2003, PROC INT CONF DATA, P49; ZHUGE H, 2004, SEMANTICS RESOURCE G, V21, P1; Ziegler CN, 2004, LECT NOTES COMPUT SC, V3291, P840	30	1	1	SLOVAK ACAD SCIENCES INST INFORMATICS	BRATISLAVA	DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA	1335-9150		COMPUT INFORM	Comput. Inform.		2007	26	5					469	488				20	Computer Science, Artificial Intelligence	Computer Science	238LW	WOS:000251450100002	
S	Elghazel, H; Kheddouci, H; Deslandres, V; Dussauchoy, A		Corruble, V; Takeda, M; Suzuki, E		Elghazel, Haytham; Kheddouci, Hamamache; Deslandres, Veronique; Dussauchoy, Alain			A partially dynamic clustering algorithm for data insertion and removal	Discovery Science, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	10th International Conference on Discovery Science	OCT 01-04, 2007	Sendai, JAPAN	AF Off Sci Res, Asian Off Aerosp Res & Dev, Grad Sch Informat Sci		dynamic clustering; graph b-coloring; dissimilarity; dominance		We consider the problem of dynamic clustering which has been addressed in many contexts and applications including dynamic information retrieval, Web documents classification, etc. The goal is to efficiently maintain homogenous and well-separated clusters as new data are inserted or existing data are removed. We propose a framework called dynamic b-coloring clustering based solely on pairwise dissimilarities among all pairs of data and on cluster dominance. In experiments on benchmark data sets, we show improvements in the performance of clustering solution in terms of quality and computational complexity.	Univ Lyon 1, LIESP Lab, F-69622 Villeurbanne, France	Elghazel, H (reprint author), Univ Lyon 1, LIESP Lab, 43 Bd,11 Novembre 1918, F-69622 Villeurbanne, France.						Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elghazel H, 2006, LECT NOTES ARTIF INT, V4203, P473; Irving RW, 1999, DISCRETE APPL MATH, V91, P127, DOI 10.1016/S0166-218X(98)00146-2; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kalyani M., 2003, PATTERN RECOGN, V24, P2367	6	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-75487-9	LECT NOTES ARTIF INT			2007	4755						78	90				13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BGU93	WOS:000250717900009	
S	Andra, S; Nagy, G; Liu, CL		Lin, X; Yanikoglu, BA		Andra, Srinivas; Nagy, George; Liu, Cheng-Lin			Frequency coding: An effective method for combining dichotomizers - art. no. 650004	Document Recognition and Retrieval XIV	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Document Recognition and Retrieval XIV	JAN 30-FEB 01, 2007	San Jose, CA	Soc Imaging Sci & Technol, SPIE		frequency coding; dichotomizers; nonparametric classification	CLASSIFICATION	Binary classifiers (dichotomizers) are combined for multi-class classification. Each rep-ion formed by the pairwise decision boundaries is assigned to the class with the highest frequency of training samples in that region. With more samples and classifiers, the frequencies converge to increasingly accurate non-parametric estimates of the posterior class probabilities in the vicinity of the decision boundaries. The method is applicable to non-parametric discrete or continuous class distributions dichotomized by either linear or non-linear classifiers (like support vector machines). We present a formal description of the method and place it in context with related methods. We present experimental results on machine-printed and handwritten digits that demonstrate the viability of frequency coding in a classification task.	Rensselaer Polytech Inst, ECSE Dept, DocLab, Troy, NY 12180 USA	Andra, S (reprint author), Rensselaer Polytech Inst, ECSE Dept, DocLab, Troy, NY 12180 USA.						Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; ANDRA S, 2006, P 18 INT C PATT REC; ANDRA S, 2006, THESIS RENSSELAER PO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Hastie T, 1998, ANN STAT, V26, P451; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Platt J. C., 2000, ADV LARGE MARGIN CLA; Sarkar P, 2005, IEEE T PATTERN ANAL, V27, P88, DOI 10.1109/TPAMI.2005.18; SAVICKY P, 2003, P 5 INT S INT DAT AN, P219; Vapnik V.N., 1998, STAT LEARNING THEORY; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wu TF, 2004, J MACH LEARN RES, V5, P975; ZASLAVSKY T, 1975, MEM AM MATH SOC, V1, P154; ZHANG X, 2006, P SPIE, V6067	17	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-6613-6	P SOC PHOTO-OPT INS			2007	6500						50004	50004	650004	10.1117/12.708803		8	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BGG59	WOS:000246686900003	
S	Angiulli, F; Folino, G		Kermarrec, AM; Bouge, L; Priol, T		Angiulli, Fabrizio; Folino, Gianluigi			Efficient distributed data condensation for nearest neighbor classification	Euro-Par 2007 Parallel Processing, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	13th International Euro-Par Conference on Parallel Processing	AUG 28-31, 2007	Rennes, FRANCE	Int Federat Informat Proc, ACM				In this work, PFCNN, a distributed method for computing a consistent subset of very large data sets for the nearest neighbor decision rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. Experimental results, performed on a class of synthetic datasets revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale-up well and are efficient in memory consumption and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule.	Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.						Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Foster I., 2003, GRID2 BLUEPRINT NEW; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KARACALI B, 2002, IEEE T NEURAL NETWOR, V14, P127; STONE C, 1977, ANN STAT, V8, P1348	8	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74465-8	LECT NOTES COMPUT SC			2007	4641						338	347				10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BGS81	WOS:000250368200036	
B	Hu, JN; Deng, WH; Guo, J; Xu, WR		Lei, JS; Yu, J; Zhou, SG		Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran			Learning locality discriminating indexing for text categorization	FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Fuzzy Systems and Knowledge Discovery	AUG 24-27, 2007	Haikou, PEOPLES R CHINA	Hainan Univ, IEEE Reliabil Soc, Asia Pacific Neural Network Assembly				This paper introduces a locality discriminating indexing (LDI) algorithm for text categorization. The LDI algorithm offers a manifold way of discriminant analysis. Based on the hypothesis that samples from different classes reside in class-specific manifold structures, the algorithm depicts the manifold structures by a nearest-native graph and a invader graphs. And a new locality discriminant criterion is proposed, which best preserves the within-class local structures while suppresses the between-class overlap. Using the notion of the Laplacian of the graphs, the LDI algorithm finds the optimal linear transformation by solving the generalized eigenvalue problem. The feasibility of the LDI algorithm has been successfully tested in text categorization using 20NG and Reuters-21578 databases. Experiment results show LDI is an effective technique for document modeling and representations for classification.	[Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China	Hu, JN (reprint author), Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.						Chung F.R.K., 1997, AM MATH SOC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; HE X, 2000, P ACM SIGIR; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA						2007							239	242		10.1109/FSKD.2007.383		4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHE44	WOS:000252460600047	
B	Wedge, DC; Kell, DB; Gaskell, SJ; Lau, KW; Hubbard, SJ; Eyers, C			ACM	Wedge, David C.; Kell, Douglas B.; Gaskell, Simon J.; Lau, King Wai; Hubbard, Simon J.; Eyers, Claire			Peptide Detectability following ESI Mass Spectrometry: Prediction using Genetic Programming	GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2			English	Proceedings Paper	Annual Conference of Genetic and Evolutionary Computation Conference	JUL 07-11, 2007	London, ENGLAND	ACM		Genetic Programming; input selection; classification; AUROC; proteomics; mass spectrometry	MULTIPLEXED ABSOLUTE QUANTIFICATION; CONCATENATED SIGNATURE PEPTIDES; PROTEOMICS; PROTEINS	The accurate quantification of proteins is important in several areas of cell biology, biotechnology and medicine. Both relative and absolute quantification of proteins is often determined following mass spectrometric analysis of one or more of their constituent peptides. However, in order for quantification to be successful, it is important that the experimenter knows which peptides are readily detectable under the mass spectrometric conditions used for analysis. In this paper, genetic programming is used to develop a function which predicts the delectability of peptides from their calculated physico-chemical properties. Classification is carried out in two stages: the selection of a good classifier using the AUROC objective function and the setting of an appropriate threshold. This allows the user to select the balance point between conflicting priorities in an intuitive way. The success of this method is found to be highly dependent on the initial selection of input parameters. The use of brood recombination and a modified version of the multi-objective FOCUS method are also investigated. While neither has a significant effect on predictive accuracy, the use of the FOCUS method leads to considerably more compact Solutions.	[Wedge, David C.; Kell, Douglas B.; Gaskell, Simon J.] Univ Manchester, Manchester Interdisciplinary Bioctr, Sch Chem, Manchester M1 7DN, Lancs, England	Wedge, DC (reprint author), Univ Manchester, Manchester Interdisciplinary Bioctr, Sch Chem, 131 Princess St, Manchester M1 7DN, Lancs, England.	david.wedge@manchester.ac.uk; dbk@manchester.ac.uk; Simon.Gaskell@manchester.ac.uk; k.lau@manchester.ac.uk; Simon.Hubbard@manchester.ac.uk; Claire.Eyers@manchester.ac.uk	Hubbard, Simon/B-9006-2009; Kell, Douglas/E-8318-2011				Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Altenberg L., 1994, ADV GENETIC PROGRAMM, P47; Beynon RJ, 2005, NAT METHODS, V2, P587, DOI 10.1038/NMETH774; Breiman L, 1984, CLASSIFICATION REGRE; Broadhurst DI, 2006, METABOLOMICS, V2, P171, DOI 10.1007/s11306-006-0037-z; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DE JONG E. D., 2001, P GEN EV COMP C GECC, P11; Eriksson J, 2000, ANAL CHEM, V72, P999, DOI 10.1021/ac990792j; FENN JB, 1989, SCIENCE, V246, P64, DOI 10.1126/science.2675315; Francone F., 1998, GENETIC PROGRAMMING; Gay S, 2002, PROTEOMICS, V2, P1374, DOI 10.1002/1615-9861(200210)2:10<1374::AID-PROT1374>3.0.CO;2-D; Gerber SA, 2003, P NATL ACAD SCI USA, V100, P6940, DOI 10.1073/pnas.0832254100; Gianazza E, 2003, J NUTR, V133, P9; Langdon W. B., 1998, GENETIC PROGRAMMING; Pratt JM, 2006, NAT PROTOC, V1, P1029, DOI 10.1038/nprot.2006.129; Rifai N, 2006, NAT BIOTECHNOL, V24, P971, DOI 10.1038/nbt1235; Tackett W., 1994, THESIS U SO CALIFORN; Tang HX, 2006, BIOINFORMATICS, V22, pE481, DOI 10.1093/bioinformatics/btl237; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; WESTIN LK, 2001, UNINF0118 UM U	20	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA		978-1-59593-697-4				2007							2219	2225				7	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BKI74	WOS:000268226900397	
B	Verron, S; Tiplica, T; Kobi, A		Zaytoon, J; Ferrier, JL; Cetto, JA; Filipe, J		Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessarnad			Multivariate control charts with a bayesian network	ICINCO 2007: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL ICSO: INTELLIGENT CONTROL SYSTEMS AND OPTIMIZATION			English	Proceedings Paper	4th International Conference on Informatics in Control, Automation and Robotics	MAY 09-12, 2007	Angers, FRANCE	Inst Syst & Technol Informat, Control & Commun, Univ Angers, Int Federat Automat Control, GDR MACS, CNRS, EEA, Assoc Advancement Artificial Intelligence		SPC; bayesian network; multivariate control charts; T-2; MEWMA	CLASSIFICATION	The purpose of this article is to present an approach allowing the fault detection of a multivariate process with a bayesian network. As a discriminant analysis is easily modeled with a bayesian network, we will show that we we can consider the multivariate T-2 and MEWMA control charts as particular cases of the discriminant analysis. So, we give the structure of the bayesian network as well as the parameters of the network in order to detect faults in the multivariate space in the same manners as if we used multivariate control charts. The resulting bayesian network, with a computed threshold, is similar to the multivariate control charts.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessarnad] LASQUO ISTIA, F-49000 Angers, France	Verron, S (reprint author), LASQUO ISTIA, 62 Ave Notre Dame du Lac, F-49000 Angers, France.						Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; Bodden KM, 1999, J QUAL TECHNOL, V31, P120; Chiang L.H., 2001, FAULT DETECTION DIAG; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hotelling H., 1947, TECHNIQUES STAT ANAL, P111; JACKSON JE, 1985, COMMUN STAT-THEOR M, V14, P2657, DOI 10.1080/03610928508829069; Jensen FV, 1996, INTRO BAYESIAN NETWO; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; KONONENKO I, 1991, EUR WORK SESS LEARN, P206; Kourti T, 1996, J QUAL TECHNOL, V28, P409; LANGLEY P, 1992, NAT C ART INT; LOWRY CA, 1992, TECHNOMETRICS, V34, P46, DOI 10.2307/1269551; MACGREGOR H, 1995, CHROMOSOME RES, V3, P3, DOI 10.1007/BF00711155; Montgomery DC., 1997, INTRO STAT QUALITY C; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; PIGNATIELLO JJ, 1990, J QUAL TECHNOL, V22, P173; Shewhart W. A., 1931, EC CONTROL QUALITY M; VAPNIK V, 1995, NATURE STAT LEARING	21	0	0	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL		978-972-8865-82-5				2007							228	233				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems	Automation & Control Systems; Computer Science	BHF14	WOS:000252639500032	
B	Han, DW; Zhang, J		Wani, MA; Kantardzic, MM; Li, T; Liu, Y; Kurgan, L; Ye, J; Ogihara, M; Sagiroglu, S; Chen, XW; Peterson, L; Hafeez, K		Han, Dianwei; Zhang, Jun			A comparison of two algorithms for predicting the condition number	ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	6th International Conference on Machine Learning and Applications	DEC 13-15, 2007	Cincinnati, OH	Assoc Machine Learning & Applicat, IEEE				We present experimental results of comparing the Modified K-Nearest Neighbor (MkNN) algorithm with Support Vector Machine (SVM) in the prediction of condition numbers of sparse matrices. Condition number of a matrix is an important measure in numerical analysis and linear algebra. However the direct computation of the condition number of a matrix is very expensive in terms of CPU and memory cost, and becomes prohibitive for large size matrices. We use data mining techniques to estimate the condition number of a given sparse matrix. In our previous work, we used Support Vector Machine (SVM) to predict the condition numbers. While SVM is considered a state-of-the-art classification/regression algorithm, kNN is usually used for collaborative filtering tasks. Since prediction can also be interpreted as a classsfication/regression task, virtually any supervised learning algorithm (such as kNN) can also be applied. Experiments are performed on a publicly available dataset. We conclude that Modified kNN (MkNN) performs much better than SVM on this particular dataset.	[Han, Dianwei; Zhang, Jun] Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA	Han, DW (reprint author), Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.						BAI Z, 1993, ACM T MATH SOFTWARE, V19, P202, DOI 10.1145/152613.152617; BISCHOF C, 1990, SIAM J MATRIX ANAL A, V11, P31; BISCHOF CH, 1992, J NUMER LINEAR ALG A, V1, P149; CAMPBELL C., 2000, SIGKDD EXPLORATIONS, V2, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIX E, 1951, 2149004 USAF SCH AV; Golub GH, 1996, MATRIX COMPUTATION; HIGHAM NJ, 1988, ACM T MATH SOFTWARE, V14, P381, DOI 10.1145/50063.214386; Joachims T, 1999, MAKING LARGE SCALE S; Ma JS, 2003, NEURAL COMPUT, V15, P2683, DOI 10.1162/089976603322385117; Smola AJ, 1998, TECHNICAL REPORT SER; THEODORE B, 2000, INT JOINT C NEUR NET, V6, P6348; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; XU S, 2004, COMMUNICATIONS INFOR, V4, P325; XU S, 2005, P 8 WORKSH MIN SCI E, P49; YANG H, 2002, P 3 INT C INT DAT EN	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3069-7				2007							223	228				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHF84	WOS:000252793400037	
J	Lee, H; Kim, E; Park, M				Lee, Heesung; Kim, Euntai; Park, Mignon			A genetic feature weighting scheme for pattern recognition	INTEGRATED COMPUTER-AIDED ENGINEERING			English	Article							SCALE FEATURE-SELECTION; CLASSIFICATION; ALGORITHMS	This paper proposes a new pattern recognition scheme, combining a new adaptive feature weighting and modified k-Nearest Neighbor (k-NN) rule. The proposed feature weighting method named adaptive-3FW. It uses three non-uniform weight levels (zero weight, middle weight and full weight) to weight each feature. The middle weight value is determined using genetic algorithms (GAs). The proposed adaptive-3FW overcomes overfitting issues and achieves high recognition performance. Novel GA operators tailored for this formulation are introduced to implement the proposed scheme. Further, a modified k-NN is proposed which uses a class-dependent feature weighting strategy. Whilst the conventional pattern recognition systems use the same set of feature weights for all classes, the proposed algorithm uses different sets of feature weights for different classes. Experiments were performed with the UCI repository for machine learning databases and the unconstrained handwritten numeral database of Concordia University in Canada to show the performance of the proposed method.	Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea	Kim, E (reprint author), Yonsei Univ, Sch Elect & Elect Engn, C613,134 Shinchon Dong, Seoul 120749, South Korea.	etkim@yonsei.ac.kr					Coley D.A., 1999, INTRO GENETIC ALGORI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L, 1991, HDB GENETIC ALGORITH; DUDA RO, 2001, PATTERN CLASSIFICAT; GOSE E, 1996, PATTEN RECOGNITION I; Hong JH, 2006, PATTERN RECOGN LETT, V27, P143, DOI 10.1016/j.patrec.2005.07.009; Hussein F, 2001, SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, PROCEEDINGS, P1240; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; KOHAVI R, 1997, EUR C MACH LEARN ECM; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P648; Liu YX, 1998, PROC CVPR IEEE, P800; Murphy P., 1994, UCI REPOSITORY MACHI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Oliveira LS, 2003, INT J PATTERN RECOGN, V17, P903, DOI 10.1142/S021800140300271X; Piramuthu S, 1998, P ANN HICSS, P294, DOI 10.1109/HICSS.1998.648324; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; SUEN CY, 1990, P 1 INT WORKSH FRONT, P131	20	25	25	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1069-2509		INTEGR COMPUT-AID E	Integr. Comput.-Aided Eng.		2007	14	2					161	171				11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Computer Science; Engineering	161VF	WOS:000246043800004	
S	Smith, JE; Tahir, MA		Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Smith, J. E.; Tahir, M. A.			Stop wasting time: On predicting the success or failure of learning for industrial applications	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND				VARIANCE; BIAS	The successful application of machine learning techniques to industrial problems places various demands on the collaborators. The system designers must possess appropriate analytical skills and technical expertise, and the management of the industrial or commercial partner must be sufficiently convinced of the potential benefits that they are prepared to invest in money and equipment. Vitally, the collaboration also requires a significant investment in time from the end-users in order to provide training data from which the system can (hopefully) learn. This poses a problem if the developed Machine Learning system is not sufficiently accurate, as the users and management; may view their input as wasted effort, and lose faith with the process. In this paper we investigate techniques for making early predictions of the error rate achievable after further interactions. In particular we show how decomposing the error in different components can lead to useful predictors of achievable accuracy, but; that this is dependent on the choice of an appropriate sampling methodology.	[Smith, J. E.; Tahir, M. A.] Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Smith, JE (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 460 U CAL STAT DEP; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRIAN D, 1999, P 4 AUSTR KNOWL ACQ, P117; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Duda R.O., 2000, PATTERN CLASSIFICATI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Geman S., 1995, NEURAL COMPUT, V4, P1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Kohavi R., 1996, P 13 INT C MACH LEAR; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KONG BE, 1995, P 12 INT C MACH LEAR, P313; Platt J, 1998, ADV KERNEL METHODS S; Putten P.V.D., 2004, MACH LEARN, V57, P177; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rodriguez JJ, 2005, LECT NOTES COMPUT SC, V3512, P779; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; WEBB GI, 2003, ESTIMATING BIAS VARI; Witten I., 2005, DATA MINING PRACTICA	22	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-77225-5	LECT NOTES COMPUT SC			2007	4881						673	683				11	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHE04	WOS:000252394900068	
S	Bosin, A; Dessi, N; Pes, B		Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			Capturing heuristics and intelligent methods for improving micro-array data classification	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND				CLASSIFIERS; CANCER	Classification of micro-array data has been studied extensively but only a small amount of research work has been done on classification of micro-array data involving more than two classes. This paper proposes a learning strategy that deals with building a multi-target classifier and takes advantage from well known data mining techniques. To address the intrinsic difficulty of selecting features in order to promote the classification accuracy, the paper considers the use of a set of binary classifiers each of ones is devoted to predict a single class of the multi-classification problem. These classifiers are similar to local experts whose knowledge (about the features that are most correlated to each class value) is taken into account by the learning strategy for selecting an optimal set of features. Results of the experiments performed on a publicly available dataset demonstrate the feasibility of the proposed approach.	[Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara] Univ Cagliari, Dipartimento Matemat & Informat, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dipartimento Matemat & Informat, Via Osped 72, I-09124 Cagliari, Italy.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; BOSIN A, 2007, P WILF 2007; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DRUMMOND C, 2006, MACHINE LEARNING J, V65; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Everitt B. S., 1977, ANAL CONTINGENCY TAB; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Liu Huiqing, 2002, Genome Inform, V13, P51; MUKHERJEE S, 2003, CLASSIFYING MICROARR; PIATETSKYSHAPIR.G, 2003, SIGKDD 2003; SIMON R, 2003, SIGKDD EXPLORATIONS, V5, P31; SOMORJAI R, 2003, BIOINFORMATICS, V19; STATNIKOV A, 2005, BIOINFORMATICS, V21; TAO L, 2004, BIOINFORMATICS, V20; Vapnik V.N., 1998, STAT LEARNING THEORY; Witten I., 2005, DATA MINING PRACTICA	21	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-77225-5	LECT NOTES COMPUT SC			2007	4881						790	799				10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHE04	WOS:000252394900079	
S	Angiulli, F; Fionda, V; Rombo, SE		Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Angiulli, Fabrizio; Fionda, Valeria; Rombo, Simona E.			Protein data condensation for effective quaternary structure classification	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND				FUNCTIONAL DOMAIN COMPOSITION; PREDICTION; SECONDARY	Many proteins are composed of two or more subunits, each associated with different polypeptide chains. The number and the arrangement of subunits forming a protein are referred to as quaternary structure. The quaternary structure of a protein is important, since it characterizes the biological function of the protein when it is involved in specific biological processes. Unfortunately, quaternary structures are not trivially deducible from protein amino acid sequences. In this work, we propose a protein quaternary structure classification method exploiting the functional domain composition of proteins. It is based on a nearest neighbor condensation technique in order to reduce both the portion of dataset to be stored and the number of comparisons to carry out. Our approach seems to be promising, in that it guarantees an high classification accuracy, even though it does not require the entire dataset to be analyzed. Indeed, experimental evaluations show that the method here proposed selects a small dataset portion for the classification (of the order of the 6.43%) and that it is very accurate (97.74%).	[Angiulli, Fabrizio; Rombo, Simona E.] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.						Angiulli Fabrizio, 2005, P 22 INT C MACH LEAR; Bairoch A, 1996, NUCLEIC ACIDS RES, V24, P21, DOI 10.1093/nar/24.1.21; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Kim Wan Kyu, 2002, Genome Inform, V13, P42; KLOTZ IM, 1970, ANNU REV BIOCHEM, V39, P25, DOI 10.1146/annurev.bi.39.070170.000325; Lesk AM, 2001, INTRO PROTEIN ARCHIT; Meiler J, 2003, P NATL ACAD SCI USA, V100, P12105, DOI 10.1073/pnas.1831973100; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Song R, 2004, J CHEM INF COMP SCI, V44, P1324, DOI 10.1021/ci034288y; SUND H, 1966, ANGEW CHEM INT EDIT, V5, P231, DOI 10.1002/anie.196602311; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wojcik J, 2001, BIOINFORMATICS S1, V17, pS296; YU X, 2006, BMC BIOINFORMATICS, V7; Yu XJ, 2004, CHINESE SCI BULL, V49, P2379, DOI 10.1360/982004-142; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331	22	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-77225-5	LECT NOTES COMPUT SC			2007	4881						810	820				11	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHE04	WOS:000252394900081	
S	Mignani, AG; Ciaccheri, L; Cucci, C; Mencaglia, AA; Cimato, A; Attilio, C; Thienpont, H; Ottevaere, H; Paolesse, R; Mastroianni, M; Monti, D; Buonocore, G; Del Nobile, A; Mentana, A; Grimaldi, MF; Dall'Asta, C; Faccini, A; Galaverna, G; Dossena, A		Matvienko, GG; Ivanov, AP; Nikitin, PI; Voropay, ES; Khodasevich, MA; Panchenko, VY; Golubev, VS		Mignani, A. G.; Ciaccheri, L.; Cucci, C.; Mencaglia, A. A.; Cimato, A.; Attilio, C.; Thienpont, H.; Ottevaere, H.; Paolesse, R.; Mastroianni, M.; Monti, D.; Buonocore, G.; Del Nobile, A.; Mentana, A.; Grimaldi, M. F.; Dall'Asta, C.; Faccini, A.; Galaverna, G.; Dossena, A.			EAT-by-LIGHT fiber-optic and micro-optic devices for food quality and safety assessment	INTERNATIONAL CONFERENCE ON LASERS, APPLICATIONS, AND TECHNOLOGIES 2007: ENVIRONMENTAL MONITORING AND ECOLOGICAL APPLICATIONS; OPTICAL SENSORS IN BIOLOGICAL, CHEMICAL, AND ENGINEERING TECHNOLOGIES; AND FEMTOSECOND LASER PULSE FILAMENTATION	Proceedings of SPIE		English	Proceedings Paper	International Conference on Lasers, Applications, and Technologies	MAY 28-JUN 01, 2007	Minsk, BYELARUS	Natl Acad Sci, Russian Acad Sci, Moscow State Univ, M V Lomonosov, BI Stepanov Inst Phys, Int Sci & Technol Ctr, Belarus Fdn Basic Res, Belarus Phys Soc, Russian Phys Soc, SPIE Russian Chapter		food authentication; scattered colorimetry; absorption spectroscopy; fluorescence spectroscopy; olive oil; beer; aflatoxins; milk	OLIVE OIL; CLASSIFICATION	A selection is presented of fiber-optic and micro-optic devices that have been designed and tested for guaranteeing the quality and safety of typical foods, such as extra virgin olive oil, beer, and milk. Scattered colorimetry is used to authenticate various types of extra virgin olive oil and beer, while a fiber-optic-based device for UV-VIS-NIR absorption spectroscopy is exploited in order to obtain the hyperspectral optical signature of olive oil. This is done not only for authentication purposes, but also so as to correlate the spectral data with the content of fatty acids, which are important nutritional factors. A micro-optic sensor for the detection of olive oil aroma that is capable of distinguishing different ageing levels of extra virgin olive oil is also presented. It shows effective potential for acting as a smart cap of bottled olive oil in order to achieve a non-destructive olfactory perception of oil ageing. Lastly, compact portable fluorometer for the rapid monitoring of the carcinogenic M1 aflatoxin in milk, is experimented.	[Mignani, A. G.; Ciaccheri, L.; Cucci, C.; Mencaglia, A. A.] CNR IFAC, Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR IFAC, Sesto Fiorentino, FI, Italy.	a.g.mignani@ifac.cnr.it	Ottevaere, Heidi/A-9294-2010; Dall'Asta, Chiara/C-3173-2008	Dall'Asta, Chiara/0000-0003-0716-8394			ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; Buratti S, 2005, ITAL J FOOD SCI, V17, P203; CHIAVARO E, 2001, J CHROMATOGR A, V937, P257; Connolly C., 2005, Sensor Review, V25, DOI 10.1108/02602280510606453; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUCCI C, 2007, IN PRESS SENSORS A B; Di Natale C, 2007, SENSOR ACTUAT B-CHEM, V121, P238, DOI 10.1016/j.snb.2006.09.038; DOLPHIN D, 1978, PORYPHYRINS, V3; Franco CM, 1998, J CHROMATOGR A, V815, P21, DOI 10.1016/S0021-9673(98)00509-3; Harwood JL, 1999, HDB OLIVE OIL; HESTER RE, 2001, FOOD SAFETY FOOD QUA; IARC, 1993, IARC MON EV CARC RIS, V56, P1; JACKSON M, 2001, GREAT BEERS BELGUIM; JAE M, 2002, OILS FATS AUTHENTICA; KELLER JJ, 2000, COMPLIANCE MANUAL FO; Lees M., 2003, FOOD AUTHENTICITY TR; Mencaglia AA, 2003, P SOC PHOTO-OPT INS, V4763, P248, DOI 10.1117/12.508795; MIGNANI AG, 2007, IN PRESS P SPIE, V6585; Mignani AG, 2005, P SOC PHOTO-OPT INS, V5855, P38, DOI 10.1117/12.623388; Mignani AG, 2005, SENSOR ACTUAT B-CHEM, V111, P363, DOI 10.1016/j.snb.2005.03.023; MIGNANI AG, 2006, P SPIE, V6189; Ozaki Y., 2007, NEAR INFRARED SPECTR; PAOLESSE R, 2003, P 16 INT C OPT FIB S, P742; Rakow NA, 2000, NATURE, V406, P710, DOI 10.1038/35021028; SERVILI M, 1995, J SCI FOOD AGR, V67, P61, DOI 10.1002/jsfa.2740670111; Siesler H. W., 2002, NEAR INFRARED SPECTR; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; VANEGMOND HP, 1998, INTRO MYCOTOXINS DAI; WEBB T, 2005, GOOD BEER GUIDE BELG	30	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-6891-8	PROC SPIE			2007	6733								67331K	10.1117/12.753315		13	Biochemistry & Molecular Biology; Remote Sensing; Optics	Biochemistry & Molecular Biology; Remote Sensing; Optics	BGZ41	WOS:000251495000018	
J	Lisboa, FOSD; Nicoletti, MD; Ramere, A				Santos de Sa Lisboa, Flavia O.; Nicoletti, Maria do Carmo; Ramere, Arthur			A version of the NGE model suitable for fuzzy domains	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			English	Article						NGE; NN; KNN; fuzzy NGE	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; CLASSIFICATION	The Nested Generalized Exemplar (NGE) model is an incremental form of inductive learning that generalizes a given training set into hypotheses represented as a set of hyperrectangles in an n-dimensional Euclidean space. The NGE algorithm can be considered a descendent of either Nearest Neighbor (NN) or K-Nearest Neighbor (KNN) algorithms. NGE based systems classify new instances by calculating their similarity to the nearest generalized exemplar (i.e. hyperrectangle). Similarity in an NGE model is implemented by a distance metric namely the Euclidean distance. This paper describes a version of the NGE model suitable for fuzzy domains called Fuzzy NGE (F-NGE). F-NGE learns fuzzy rules for classifying instances into crisp classes. An implementation of F-NGE has been tested in several different knowledge domains for which results are presented and discussed. Results of fuzzy versions of NN and KNN using the same domains are also presented, for comparison.	Univ Fed Sao Carlos, Dept Computat, Sao Carlos, SP, Brazil; Univ Sao Paulo, Inst Fis Sao Carlos, Sao Carlos, SP, Brazil; Univ New S Wales, Sch Engn & Comp Sci, Sydney, NSW, Australia	Nicoletti, MD (reprint author), Univ Fed Sao Carlos, Dept Computat, Sao Carlos, SP, Brazil.	carmo@dc.ufscar.br	Lisboa, Flavia/I-6767-2012				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIGUEIRA LB, 2004, P 2004 IEEE SMC OCT, P3395; FIGUEIRA LB, 2004, P ITCC 2004 5 7 APR, V2, P193; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Heath D, 1996, J EXP THEOR ARTIF IN, V8, P129, DOI 10.1080/095281396147429; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Keogh E., 1997, P 14 INT C MACH LEAR, P406; Klir G.J., 1995, FUZZY SETS FUZZY LOG; KOLODNER JL, 1984, RETRIEVAL ORG STATEG; LISBOA FOS, 2003, 12 IEEE INT C FUZZ S, P90; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Merz C.J., 1998, UCI REPOSITORY MACHI; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALZBERG S, 1991, MACH LEARN, V6, P252; SPECHT DF, 1992, P IEEE INT JOINT C N, P761; TschicholdGurman N, 1997, FUZZY SET SYST, V85, P287, DOI 10.1016/0165-0114(95)00351-7; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson D. R., 1997, P INT C ART NEUR NET, P514; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WILSON DR, 1996, P INT C NEUR NETW IC, P1263; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5	26	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1064-1246		J INTELL FUZZY SYST	J. Intell. Fuzzy Syst.		2007	18	1					1	17				17	Computer Science, Artificial Intelligence	Computer Science	187PO	WOS:000247860500001	
J	Wang, CY; Sun, YF; Liang, YC				Wang, Chaoyong; Sun, Yanfeng; Liang, Yanchun			An improved SVM based on similarity metric	JOURNAL OF UNIVERSAL COMPUTER SCIENCE			English	Article						support vector machine; Riemannian metric; similarity metric		A novel support vector machine method for classification is presented in this paper. A modified kernel function based on the similarity metric and Riemannian metric is applied to the support vector machine. In general, it is believed that the similarity of homogeneous samples is higher than that of inhomogeneous samples. Therefore, in Riemannian geometry, Riemannian metric can be used to reflect local property of a curve. In order to enlarge the similarity metric of the homogeneous samples or reduce that of the inhomogeneous samples in the feature space, Riemannian metric is used in the kernel function of the SVM. Simulated experiments are performed using the databases including an artificial and the UCI real data. Simulation results show the effectiveness of the proposed algorithm through the comparison with four typical kernel functions without similarity metric.	[Wang, Chaoyong] Jilin Teachers Inst Engn & Technol, Dept Fundamental Sci, Changchun 130021, Peoples R China; [Wang, Chaoyong; Sun, Yanfeng; Liang, Yanchun] Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China	Wang, CY (reprint author), Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.	dynasty1188@126.com; sunyf@jlu.edu.cn; ycliang@jlu.edu.cn					Cherkassy V., 1998, LEARNING DATA CONCEP; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Palais R., 1988, LECT NOTES MATH, V1353; SCHOLKOPF B, 1999, ADV KERNEL METHODS C; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; Vapnik V.N., 1995, NATURE STAT LEARNING; Wu S, 2002, NEURAL PROCESS LETT, V15, P59, DOI 10.1023/A:1013848912046	10	0	0	GRAZ UNIV TECHNOLGOY, INST INFORMATION SYSTEMS COMPUTER MEDIA-IICM	GRAZ	INFFELDGASSE 16C, GRAZ, A-8010, AUSTRIA	0948-695X		J UNIVERS COMPUT SCI	J. Univers. Comput. Sci.		2007	13	10					1462	1470				9	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	268YL	WOS:000253616300006	
S	Song, Y; Huang, J; Zhou, D; Zha, H; Giles, CL		Kok, JN; Koronacki, J; DeMantaras, RL; Matwin, S; Mladenic, D; Skowron, A		Song, Yan; Huang, Jian; Zhou, Ding; Zha, Hongyuan; Giles, C. Lee			IKNN: Informative K-nearest neighbor pattern classification	Knowledge Discovery in Databases: PKDD 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	18th European Conference on Machine Learning (ECML 2007)/11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2007)	SEP 17-21, 2007	Warsaw, POLAND	Warsaw Univ, Fac Math, Informat & Mech, Polish Acad Sci, Inst Comp Sci, European Off Aerosp Res & Dev, Air Force Off Sci Res, USAF Res Lab	Warsaw Univ			The K-nearest neighbor (KNN) decision rule has been a ubiquitous classification tool with good scalability. Past experience has shown that the optimal choice of K depends upon the data, making it laborious to tune the parameter for different applications. We introduce a new metric that measures the informativeness of objects to be classified. When applied as a query-based distance metric to measure the closeness between objects, two novel KNN procedures, Locally Informative-KNN (LI-KNN) and Globally Informative-KNN (GI-KNN), are proposed. By selecting a subset of most informative objects from neighborhoods, our methods exhibit stability to the change of input parameters, number of neighbors(K) and informative points (I). Experiments on UCI benchmark data and diverse real-world data sets indicate that our approaches are application-independent and can generally outperform several popular KNN extensions, as well as SVM and Boosting methods.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Song, Y (reprint author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.						ATHITSOS V, 2005, CVPR 05 WASH DC US, P486; ATHITSOS V, 2005, CVPR 05 WASH DC US; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Friedman J ., 1994, 113 STANF U STAT DEP; HAN EH, 2001, 5 PAC AS C KNOWL DIS, P53; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; LATOURRETTE M, 2000, ECML 00 P 11 EUR C M, P238; Peng J, 2001, CVPR 01, P58; SCHAPIRE RE, 1998, COLT 98; Weinberger K. Q., 2005, NIPS; Zhang H, 2006, CVPR, P2126	14	8	8	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74975-2	LECT NOTES ARTIF INT			2007	4702						248	264				17	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BGQ47	WOS:000249743700021	
S	Suri, NR; Srinivas, VS; Murty, MN		Kok, JN; Koronacki, J; DeMantaras, RL; Matwin, S; Mladenic, D; Skowron, A		Suri, N. Rama; Srinivas, V. S.; Murty, M. Narasimha			A cooperative game theoretic approach to prototype selection	Knowledge Discovery in Databases: PKDD 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	18th European Conference on Machine Learning (ECML 2007)/11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2007)	SEP 17-21, 2007	Warsaw, POLAND	Warsaw Univ, Fac Math, Informat & Mech, Polish Acad Sci, Inst Comp Sci, European Off Aerosp Res & Dev, Air Force Off Sci Res, USAF Res Lab	Warsaw Univ			In this paper we consider the task of prototype selection whose primary goal is to reduce the storage and computational requirements of the Nearest Neighbor classifier while achieving better classification accuracies. We propose a solution to the prototype selection problem using techniques from cooperative game theory and show its efficacy experimentally.	Indian Inst Sci, Dept Comp Sci & Automat, Elect Commerce Lab, Bangalore 560012, Karnataka, India	Suri, NR (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Elect Commerce Lab, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; INARRA E, 1993, INT J GAME THEORY, V22, P13, DOI 10.1007/BF01245567; Keinan A, 2004, NEURAL COMPUT, V16, P1887, DOI 10.1162/0899766041336387; LI Y, 2005, ADV NATURA COMPOSITE; Murphy P., 1994, UCI REPOSITORY MACHI; Myerson R.B., 1997, GAME THEORY ANAL CON; SANCHEZ JS, 2001, P 14 BRAZ S COMP GRA; Shapley L. S., 1971, International Journal of Game Theory, V1, DOI 10.1007/BF01753431; STRAFFIN PD, 1993, GAME THEORY; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	10	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-74975-2	LECT NOTES ARTIF INT			2007	4702						556	564				9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BGQ47	WOS:000249743700054	
S	Vanderlooy, S; van der Maaten, L; Sprinkhuizen-Kuyper, I		Perner, P		Vanderlooy, Stijn; van der Maaten, Laurens; Sprinkhuizen-Kuyper, Ida			Off-line learning with transductive confidence machines: An empirical evaluation	Machine Learning and Data Mining in Pattern Recognition, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	5th International Conference on Machine Learning and Data Mining in Pattern Recognition	JUL 18-20, 2007	Leipzig, GERMANY				CLASSIFICATION; ALGORITHMS	The recently introduced transductive confidence machines (TCMs) framework allows to extend classifiers such that they satisfy the calibration property. This means that the error rate can be set by the user prior to classification. An analytical proof of the calibration property was given for TCMs applied in the on-line learning setting. However, the nature of this learning setting restricts the applicability of TCMs. In this paper we provide strong empirical evidence that the calibration property also holds in the off-line learning setting. Our results extend the range of applications in which TCMs can be applied. We may conclude that TCMs are appropriate in virtually any application domain.	Univ Limburg, MICC IKAT, NL-6200 MD Maastricht, Netherlands	Vanderlooy, S (reprint author), Univ Limburg, MICC IKAT, POB 616, NL-6200 MD Maastricht, Netherlands.						BELLOTTI T, 2006, THESIS ROYAL HOLLOWA; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fisher R., 1936, ANN EUGEN, V7, P178; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998); Gammerman A, 2002, THEOR COMPUT SCI, V287, P209, DOI 10.1016/S0304-3975(02)00100-7; Khardon R, 2005, J ARTIF INTELL RES, V24, P341; Melluish Thomas, 2001, LECT NOTES ARTIF INT, V2167, P360; Newman D. J., 1998, UCI REPOSITORY MACHI; PROEDROU K, 2001, 0102 ROYAL HOLL U LO; SAUNDERS C, 2000, ICALT 2000, P325; Saunders C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P722; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; VANDERLOOY S, 2007, 0703 MICCIKAT U MAAS; VOVK V, 2005, ALGORITHMIC LEANING	16	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-73498-7	LECT NOTES ARTIF INT			2007	4571						310	323				14	Computer Science, Artificial Intelligence	Computer Science	BGM77	WOS:000248523200023	
S	Gomez, O; Morales, EF; Gonzalez, JA		Gelbukh, A; Morales, AFK		Gomez, Octavio; Morales, Eduardo F.; Gonzalez, Jesus A.			Weighted instance-based learning using representative intervals	MICAI 2007: ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th Mexican International Conference on Artificial Intelligence (MICAI 2007)	NOV 04-10, 2007	Aguascalientes, MEXICO	Mexican Soc Artificial Intelligence		feature weighting; instance-based learning; K-NN	ALGORITHMS	Instance-based learning algorithms are widely used due to their capacity to approximate complex target functions; however; the performance of this kind of algorithms degrades significantly in the presence of irrelevant features. This paper introduces a new noise tolerant instance-based learning algorithm, called WIB-K, that uses one or more weights, per feature per class, to classify integer-valued databases. A set of intervals that represent the rank of values of all the features is automatically created for each class, and the nonrepresentative intervals are discarded. The remaining intervals (representative intervals) of each feature are compared against the representative intervals of the same feature in the other classes to assign a weight. The weight represents the discriminative power of the interval, and is used in the similarity function to improve the classification accuracy. The algorithm was tested on several datasets, and compared against other representative machine learning algorithms showing very competitive results.	Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Tonantzintla 72840, Mexico	Gomez, O (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1, Tonantzintla 72840, Mexico.	gomezo@ccc.inaoep.mx; emorales@ccc.inaoep.mx; jagonzalez@ccc.inaoep.mx					AHA DW, 1998, FEATURE EXTRACTION C, V1; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BLANSCHE A, 2006, PATTERN RECOGNITION, V27; Cleary J. G., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de la Torre A, 2002, SPEECH COMMUN, V38, P267, DOI 10.1016/S0167-6393(01)00068-1; Dougherty J., 1995, MACHINE LEARNING; GARTNER T, 2001, MACHINE LEARNING; GEORGE H, 1995, P 11 C UNC ART INT M, V11, P338; KIRA K, 1992, AAAI 1992; KONONENKO I, 1994, LNCS, V784; Newman D. J., 1998, UCI REPOSITORY MACHI; PLAT JC, 1998, ADV KERNEL METHODS S; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SMITH EE, 1981, CATEGORIES CONCETPS; TAHIR TA, 2007, PATTERN RECOGN, V28, P438; WEISSTEIN EW, 2002, ANOVA TEST MATHWORLD; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Witten I., 2005, DATA MINING PRACTICA; WITTEN IH, 1998, MACHINE LEARNING	21	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-76630-8	LECT NOTES ARTIF INT			2007	4827						420	430				11	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BGW96	WOS:000251037900040	
S	Liu, CP; Yuan, XH; Wang, ZH; Cui, ZM		Zhang, TX; Nardell, C; Smith, D; Lu, HQ		Liu, Chunping; Yuan, Xiaohua; Wang, Zhaohui; Cui, Zhiming			Novel color image segmentation using self-generating prototypes - art. no. 67864A	MIPPR 2007: AUTOMATIC TARGET RECOGNITION AND IMAGE ANALYSIS; AND MULTISPECTRAL IMAGE ACQUISITION, PTS 1 AND 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	5th International Symposium on Multispectral Image Processing and Pattern Recognition	NOV 15-17, 2007	Wuhan, PEOPLES R CHINA	SPIE, State Key Lab Multi Spectral Informat Proc Technol, Chinese Educ Minist Key Lab Image Proc & Intelligence Control, Huazhong Univ Sci & Technol	Wuhan Univ	competitive learning; color image segmentation; K-nearest neighbor algorithm; Learning vector quantization; hierarchical clustering; self-generating prototype		A new self-generating prototypes method based on SGNT is presented. This method uses reference patterns as initial prototype. This procedure can be implemented in a SGNT with specific architecture consisting of one root and the initial class number of reference patterns. The leaf in SGNT is defined with prototype vector, learning vector, center property vector and distant property vector. After training, prototype set are outputted. The main advantage of this method is that both the number of prototypes and their locations are learned from the training set without much human intervention. Experiments with synthesis and real color image the excellent performance of this classification scheme as compared to existing K-nearest neighbor (K-NN) and Learning vector quantization (LVQ) algorithm.	[Liu, Chunping; Wang, Zhaohui; Cui, Zhiming] Suzhou Univ, Sch Comp Sci & Technol, Suzhou 215006, Jiangsu, Peoples R China	Liu, CP (reprint author), Suzhou Univ, Sch Comp Sci & Technol, Suzhou 215006, Jiangsu, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; FANG L, 1991, P INT JOINT C NEUR N; HASTIE T, 2001, SPRINGER SERIES STAT, P1481; INOUE H, 2002, THESIS OKAYAMA U SCI; Kohonen T., 1989, SELF ORG ASS MEMORY; Kohonen T, 1995, SELF ORGANIZING MAPS; WEN WX, 1992, INT JOINT C NEUR NET, V2, P751; WEN WX, 1992, P INT JOINT C NEUR N, V4, P850, DOI 10.1109/IJCNN.1992.227211	9	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	978-0-8194-6950-2	P SOC PHOTO-OPT INS			2007	6786		1-2				A7864	A7864		10.1117/12.751169		8	Remote Sensing; Optics; Imaging Science & Photographic Technology	Remote Sensing; Optics; Imaging Science & Photographic Technology	BHK04	WOS:000253700100153	
J	Gao, QB; Wang, ZZ				Gao, Qing-Bin; Wang, Zheng-Zhi			Center-based nearest neighbor classifier	PATTERN RECOGNITION			English	Article						pattern classification; nearest neighbor; nearest feature line; centered-based nearest neighbor; computational biology	PATTERN-CLASSIFICATION; FEATURE LINE; PREDICTION	In this paper, a novel center-based nearest neighbor (CNN) classifier is proposed to deal with the pattern classification problems. Unlike nearest feature line (NFL) method, CNN considers the line passing through a sample point with known label and the center of the sample class. This line is called the center-based line (CL). These lines seem to have more capacity of representation for sample classes than the original samples and thus can capture more information. Similar to NFL, CNN is based on the nearest distance from an unknown sample point to a certain CL for classification. As a result, the computation time of CNN can be shortened dramatically with less accuracy decrease when compared with NFL. The performance of CNN is demonstrated in one simulation experiment from computational biology and high classification accuracy has been achieved in the leave-one-out test. The comparisons with nearest neighbor (NN) classifier and NFL classifier indicate that this novel classifier achieves competitive performance. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China.	qbgao@nudt.edu.cn	Gao, Qing-Bin/G-9825-2011				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gao QB, 2005, COMPUT BIOL CHEM, V29, P388, DOI 10.1016/j.compbiolchem.2005.08.002; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204	9	23	28	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JAN	2007	40	1					346	349		10.1016/j.patcog.2006.06.033		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	102TX	WOS:000241837300031	
S	Babu, VS; Viswanath, P		Ghosh, A; De, RK; Pal, SK		Babu, V. Suresh; Viswanath, P.			Weighted k-nearest leader classifier for large data sets	PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	2nd International Conference on Pattern Recognition and Machine Intelligence	DEC 18-22, 2007	Calcutta, INDIA	Indian Stat Inst, Machine Intelligence Univ, ISI Ctr Soft Comp Res, Int Assoc Pattern Recognit, Int Ctr Pure & Appl Math, Web Intelligence Consortium, Yahoo India Res & Dev, Philips Res Asia		weighted leaders method; k-NNC; noise elimination; prototypes		Leaders clustering method is a fast one and can be used to derive prototypes called leaders from a large training set which can be used in designing a classifier. Recently nearest leader based classifier is shown to be a faster version of the nearest neighbor classifier, but its performance can be a degraded one since the density information present in the training set is lost while deriving the prototypes. In this paper we present a generalized weighted k-nearest leader based classifier which is a faster one and also an on-par classifier with the k-nearest neighbor classifier. The method is to find the relative importance of each prototype which is called its weight and to use them in the classification. The design phase is extended to eliminate some of the noisy prototypes to enhance the performance of the classifier. The method is empirically verified using some standard data sets and a comparison is drawn with some of the earlier related methods.	[Babu, V. Suresh; Viswanath, P.] Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India	Babu, VS (reprint author), Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI; Ester M., 1996, P 2 INT C KNOWL DISC, P226; HART PE, 1968, IEEE T INFORMATI MAY, P515; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Spath H, 1980, CLUSTER ANAL ALGORIT; Vijaya PA, 2004, PATTERN RECOGN LETT, V25, P505, DOI 10.1016/j.patrec.2003.12.013; VISWANATH P, 2006, P 18 INT C PATT REC, V1, P912	9	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-77045-9	LECT NOTES COMPUT SC			2007	4815						17	24				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHC02	WOS:000252140200003	
S	Dehzangi, O; Jahromi, MZ; Taheri, S		Rajapakse, JC; Schmidt, B; Volkert, G		Dehzangi, Omid; Jahromi, Mansoor Zolghadri; Taheri, Shahram			High performance classification of two imagery tasks in the cue-based brain computer interface	PATTERN RECOGNITION IN BIOINFORMATICS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	2nd International Workshop on Pattern Recognition in Bioinformatics	OCT 01-02, 2007	Singapore, SINGAPORE	IAPR		nearest neighbor; weighted distance; brain-computer interface; EEG	NEAREST-NEIGHBOR RULE; EEG CLASSIFICATION	Translation of human intentions into control signals for a computer, so called Brain-Computer Interface (BCI), has been a growing research field during the last years. In this way, classification of mental tasks is under investigation in the BCI society as a basic research. In this paper, a Weighted Distance Nearest Neighbor (WDNN) classifier is presented to improve the classification rate between the left and right imagery tasks in which a weight is assigned to each stored instance. The specified weight of each instance is then used for calculating the distance of a test pattern to that instance. We propose an iterative learning algorithm to specify the weights of training instances such that the error rate of the classifier on training data is minimized. ElectroEncephaloGram (EEG) signals are caught from four familiar subjects with the cue-based BCI. The proposed WDNN classifier is applied to the band power and fractal dimension features, which are extracted from EEG signals to classify mental tasks. Results show that our proposed method performs better in some subjects in comparison with the LDA and SVM, as well-known classifiers in the BCI field.	[Dehzangi, Omid; Jahromi, Mansoor Zolghadri; Taheri, Shahram] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore	Dehzangi, O (reprint author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore, Singapore.						BOOSTANI R, 2004, J NEURAL ENG, V1, P4; BOOSTANI R, 2007, J MED BIO ENG COMP, V6; BOZORGZADEH Z, 2000, IEEE INT C AC SPEECH, V6, P2385; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DERICHE M, 2001, IEEE INT C AC SPEECH, V2, P1057; ESTELLER R, 2000, THESIS GEORGIA I TEC; Fawcett T., 2003, HPL20034; FLOTZINGER D, 1994, IEEE INT C COMP INT, V6, P3448; FUKUNAGA K, 1999, INTRO STAT PATTERN C; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Graimann B, 2004, IEEE T BIO-MED ENG, V51, P954, DOI 10.1109/TBME.2004.826671; Haselsteiner E, 2000, IEEE T REHABIL ENG, V8, P457, DOI 10.1109/86.895948; HIGUCHI T, 1988, PHYSICA D, V31, P277, DOI 10.1016/0167-2789(88)90081-4; KALCHER J, 1992, P ANN INT C IEEE, V4, P1658; LACHICHE N, 2003, 20 INT C MACH LEARN, P416; Pfurtscheller G, 1998, IEEE Trans Rehabil Eng, V6, P316, DOI 10.1109/86.712230; PFURTSCHELLER G, 1999, HDB ELECTROENCEPH CL, V6; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; Schlogl A, 1997, BIOMED TECH, V42, P162, DOI 10.1515/bmte.1997.42.6.162; Vapnic V. N., 1998, STAT LEARNING THEORY; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; WEINBERGER K, 2005, ADV NEURAL INFORM PR, P18; XIAOYUAN J, 2004, IEEE T SYS MAN CYBER, V34, P5	25	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-75285-1	LECT NOTES COMPUT SC			2007	4774						378	390				13	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BGY27	WOS:000251314800036	
B	Dehzangi, O; Jahromi, MZ		DelPobil, AP		Dehzangi, O.; Jahromi, M. Zolghadri			A proposed method of local feature-weighting to improve predictions of basic nearest neighbor rule	PROCEDINGS OF THE 11TH IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING			English	Proceedings Paper	11th IASTED International Conference on Artificial Intelligence and Soft Computing	AUG 29-31, 2007	Palma de Mallorca, SPAIN	Int Assoc Sci & Technol Dev, IASTED, TC Artificial Intelligence & Expert Syst, IASTED, TC Comm Soft Comp, Catalan Assoc Artificial Intelligence, Spanish Assoc Artificial Intelligence		pattern classification; nearest neighbor; local feature weighting; adaptive distance measure	CLASSIFICATION	predict the class of a query pattern. Several studies have shown that irrelevant, interacting, or noisy features have as much effect on distance computation as other features. Various global and local feature-weighting algorithms have been proposed to deal with this problem. In this paper, we use a local weighting scheme that allows feature weights to vary for each training instance. We propose a novel learning algorithm to learn the weight of each feature for every training instance. By associating a cost to each training instance, the proposed learning algorithm attempts to minimize the sum of costs for misclassified training instances. Using a number of data sets from the UCI-ML repository, we show that the proposed feature-weighting scheme is quite effective in improving the generalization ability of the NN classifier.	Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran	Dehzangi, O (reprint author), Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.						Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bang SL, 2006, INFORM PROCESS MANAG, V42, P387, DOI 10.1016/j.ipm.2005.04.003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R. O., 2001, PATTERN CLASSIFICATI; MORRING BD, 2003, INTELL DATA ANAL, V7, P61; RAZA M, 2005, INFORM TECHNOLOGY AP, V4, P475; Tsang E. C. C., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.943700; WANG J, 2006, PATTERN RECOGN, V31, P417; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER K, ADV NEURAL INFORM PR, V18; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Zhang J., 1992, P 9 INT MACH LEARN C, P470	13	0	0	ACTA PRESS ANAHEIM	ANAHEIM	PO BOX 5124, ANAHEIM, CA 92814-5124 USA		978-0-88986-693-5				2007							175	178				4	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	BGW63	WOS:000250957100029	
B	Ahanathapillai, V; Soraghan, JJ; Hamilton, DJ; Morison, G		Sanei, S; Chambers, JA; McWhirter, J; Hicks, Y; Constantinides, AG		Ahanathapillai, V.; Soraghan, J. J.; Hamilton, D. J.; Morison, G.			Echocardiographical sequence analysis for the diagnosis of heart wall damage	Proceedings of the 2007 15th International Conference on Digital Signal Processing			English	Proceedings Paper	15th International Conference on Digital Signal Processing	JUL 01-04, 2007	Cardiff, WALES	IEEE UK & Republic Ireland Sect	Cardiff Univ	Principal component analysis (PCA); Independent Component Analysis (ICA); heart disease; echocardiography; wall motion abnormality	INDEPENDENT COMPONENT ANALYSIS; CLASSIFICATION; RECOGNITION	Abnormality in the heart wall motion, caused by common cardiac problems (such as cardiomyopathy, coronary artery diseases, and myocardial ischemia) could eventually lead to complications such as heart failure or heart attack. Various cardiac images can be used to identify such wall motion abnormality and help diagnose the possible presence of damaged tissue in the heart wall. In this paper, an Independent Component Analysis (ICA) technique based system is proposed to diagnose the abnormality in the heart wall. Results clearly indicate that such feature extraction technique could be used effectively to diagnose cardiac problems at an early stage.	Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland	Ahanathapillai, V (reprint author), Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland.						AHANATHAPILLAI V, 2006, P MEDSIP 06 C; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bosch JG, 2005, ACAD RADIOL, V12, P358, DOI 10.1016/j.acra.2004.11.025; Cerqueira MD, 2002, CIRCULATION, V105, P539, DOI 10.1161/hc0402.102975; COOTES T, 1994, IMAGING VISION COMPU, V12, P335; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Kaddoura S., 2002, ECHO MADE EASY; MANIAM J, 2005, SUNWAY ACAD J, V2, P77; Serpen G, 2003, COMPUT BIOL MED, V33, P119, DOI 10.1016/S0010-4825(02)00063-X; Smith L, TUTORIAL PRINCIPAL C; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0881-8				2007							155	158				4	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BGQ10	WOS:000249666900040	
S	Chen, TS; Lin, CC; Chiu, YH		Xu, AP; Zhu, H; Chen, SY; Yan, B; Meng, QG; Miao, D; Fang, Y		Chen, Tung-Shou; Lin, Chih-Chiang; Chiu, Yung-Hsing			A new parameter-free classification algorithm based on nearest neighbor rule and K-means for mobile devices	Proceedings of the 6th WSEAS International Conference on Applied Computer Science	ELECTRICAL AND COMPUTER ENGINEERING		English	Proceedings Paper	6th WSEAS International Conference on Applied Computer Science (ACOS 07)	APR 15-17, 2007	Hangzhou, PEOPLES R CHINA	WSEAS		classification; parameter-free; K-means; nearest neighbor rule (NNR); support vector machine (SVM); mobile devices	SYSTEM	This paper proposes a parameter-free classifier which combines K-means with Nearest Neighbor Rule (NNR) - called Incremental Cluster-based Classification (ICC). The classifier is used in low power and capacity devices such as Personal Digital Assistant (PDA) and Smartphone. In the training phase, ICC employs K-means to group instances into several clusters, and then incrementally separates the cluster into two clusters until the cluster members belong to the same type within each cluster. Thus instances have uniform class label within each cluster. In the predicting phase, ICC adopts NNR to find a centroid which is the nearest neighbor of the unlabeled instance. Since the training data are substituted by the cluster centroids; memory and computation requirements are decreased. K-means and NNR are both simple and efficient methods. ICC is easy to redo and have efficient performance and is, hence, suitable for low capacity hardware. In this paper, the prediction accuracy of ICC is evaluated and compared with those of NNR and Support Vector Machine (SVM). Our experimental results show that the prediction accuracy of ICC is comparable to NNR. Although NNR is the easiest to use and redo, it is sensitive to noises and consumes time and memory for a large dataset. Despite the higher accuracy of LIBSVM, it is time-consuming to select an appropriate kernel function and related parameters. ICC is parameter-free, simple to operate and easy to implement. Mobile users can complete their work more conveniently and accurately.	Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung 404, Taiwan	Chen, TS (reprint author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, 129 Sec 3 Sanmin Rd, Taichung 404, Taiwan.						Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chen RC, 2005, LECT NOTES COMPUT SC, V3497, P916; Chen RC, 2005, LECT NOTES COMPUT SC, V3498, P409; CHEN TS, 2003, P INT C INF CYB SYST, P1519; Chen T.-S., 2005, P 2005 INT S INT SIG, P405; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNHAM MH, 2003, DATA MINING INTRODUC; Han J. W., 2000, DATA MINING CONCEPTS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; McQueen J, 2007, 5TH BERK S MATH STAT, V1, P281; NEWMAN DJ, 1998, UCI REPOSITORY MACH; ROIGER RJ, 2003, DATTA MINING TUTORIA; Vapnik V.N., 1995, NATURE STAT LEARNING; Zhao XM, 2004, LECT NOTES COMPUT SC, V3177, P11	14	1	1	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE	1790-5117	978-960-8457-66-9	ELE COM ENG			2007							152	155				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BGQ67	WOS:000249798700028	
B	Fayyaz, M; Mujahid, A; Khan, A; Choi, TS; Qbal, N	Yang, JY	Yang, MQ; Zhu, MM; Zhang, Y; Arabnia, HR; Deng, Y; Bourbakis, N		Fayyaz, Mudassir; Mujahid, Adnan; Khan, Asifullah; Choi, Tae-Sun; Qbal, Nadeem.	Yang, JY		G-protein coupled receptor subfamilies prediction based on nearest neighbor approach	PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II			English	Proceedings Paper	7th IEEE International Conference on Bioinformatics and Bioengineering	OCT 14-17, 2007	Boston, MA	IEEE, IEEE Comp Soc, IEEE Engn Med Biol, NSF, Int Soc Intelligent Biol Med, Syst, Man, Cybermet Soc		Fast Fourier Transform; G-Proteins Coupled Receptors; multilevel classification; Nearest Neighbor Classifier	FAST FOURIER-TRANSFORM; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; HIDDEN MARKOV-MODELS; FAMILY CLASSIFICATION; GPCR RECOGNITION; SEQUENCE; DATABASE; PFAM	Hydrophobicity has been considered as the potential measurement for the prediction of G-Proteins coupled receptor subfamilies. In the present work, using Hydrophobicity measure, we make use of Fast Fourier Transform to better analyze the sequence information. In our experiments, we have observed that sequence pattern based information could easily be exploited in the frequency domain using proximity rather than increasing margin of separation between the classes. Based on this information, a simple Nearest Neighbor (NN) method is then used to classify the 17 subfamilies. The proposed proximity based approach has outperformed the one against all implementation of Support Vector Machine (SVM) [Y. Z. Guo, et al, Acta Biochimica et Biophysica Sinica, 37(2005) 759]. Our simple proximity based approach has superior performance in terms of all three measures on both Jackknife and independent data set. For B, C, D and F subfamilies, the Mathew's correlation coefficient and overall accuracy using jackknife test are 0.96 and 96.03 %, while, using independent data set are 0.91 and 91.6 % respectively. The results validate the idea of exploiting sequence pattern based information in the frequency domain using proximity in terms of Euclidian distance. Another side advantage is that instead of training and saving 17 SVM models, we need a single NN classifier.	[Fayyaz, Mudassir; Mujahid, Adnan] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Swabi, Pakistan	Fayyaz, M (reprint author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Swabi, Pakistan.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; COSIC I, 1994, IEEE T BIO-MED ENG, V41, P1101, DOI 10.1109/10.335859; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Eisenhaber F, 1998, TRENDS CELL BIOL, V8, P69; FAUCHERE JL, 1983, EUR J MED CHEM, V18, P369; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; Guo YZ, 2005, ACTA BIOCH BIOPH SIN, V37, P759, DOI 10.1111/j.1745-7270.2005.00110.x; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hiramoto T, 2002, J PROTEIN CHEM, V21, P537, DOI 10.1023/A:1022429722651; Horn F, 2001, NUCLEIC ACIDS RES, V29, P346, DOI 10.1093/nar/29.1.346; ILMAN AG, GOODMAN GILMANS PHAR; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; Katoh K, 2002, NUCLEIC ACIDS RES, V30, P3059, DOI 10.1093/nar/gkf436; Khan A., 2005, International Journal of Knowledge-Based and Intelligent Engineering Systems, V9; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; LUDMILA I, 2004, COMBINING PATTERN CL; Majid A, 2006, INT J HYBRID INTELLI, V3, P109; Mandell AJ, 1997, PHYSICA A, V244, P254, DOI 10.1016/S0378-4371(97)00294-X; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; NOVIC M, 1995, J CHEM INF COMP SCI, V35, P454, DOI 10.1021/ci00025a013; Papasaikas PK, 2004, NUCLEIC ACIDS RES, V32, pW380, DOI 10.1093/nar/gkh431; Papasaikas PK, 2003, SAR QSAR ENVIRON RES, V14, P413, DOI 10.1080/10629360310001623999; Shepherd AJ, 2003, PROTEINS, V50, P290, DOI 10.1002/prot.10290; Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320; TRAMANTANO A, 2005, 10 MOST WANTED SOLUT; XU JH, 2005, GENOMICS PROTEOMICS	38	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1509-0				2007							1348	1354				7	Engineering, Biomedical; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BHG41	WOS:000252958200217	
B	Mhamdi, F; Elloumi, M		Rolland, C; Collard, M; Pastor, O; Flory, A; Cavarero, JL		Mhamdi, Faouzi; Elloumi, Mourad			A New Survey On knowledge Discovery And Data Mining	PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON RESEARCH CHALLENGES IN INFORMATION SCIENCE: RCIS 2008			English	Proceedings Paper	2nd International Conference on Research Challenges in Information Science	JUN 03-06, 2008	Marrakech, MOROCCO			Data Mining; Knowledge Discovery	PATTERN-CLASSIFICATION; EFFICIENT ALGORITHM; APPROXIMATION; SEQUENCES; NETWORKS; SYSTEM; MODEL	Knowledge discovery is an emerging field where we combine techniques from algorithmics, artificial intelligence, mathematics and statistics to deal with the theoretical and practical issues of extracting knowledge, i.e., new concepts or concept relationships hidden in volumes of raw data. Knowledge discovery offers the capacity to automate complex search and data analysis tasks. Data mining is the main phase in the knowledge discovery process. It consists in extracting nuggets of knowledge, i.e., pertinent patterns, pattern correlations, estimation or rules, hidden in bodies of data. The extracted nuggets of knowledge will be used in the verification of hypothesis or the prediction and explanation of knowledge. In this paper, we present a new survey on Knowledge Discovery and Data Mining (KDD).	[Mhamdi, Faouzi; Elloumi, Mourad] Higher Sch Sci & Technol Tunis, Res Unit Technol Informat & Commun, Tunis 1008, Tunisia	Mhamdi, F (reprint author), Higher Sch Sci & Technol Tunis, Res Unit Technol Informat & Commun, 5 Ave Taha Hussein, Tunis 1008, Tunisia.	Faouzi.Mhamdi@ensi.rnu.tn; Mourad.Elloumi@fsegt.rnu.tn					AARNODT A, 1994, AI COMMUN, V7, P39; Agrawal R, 1994, P 20 INT C VER LARG, P487; Ankerst M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347124; BANDYOPADHYAY S, 1995, PATTERN RECOGN LETT, V16, P801, DOI 10.1016/0167-8655(95)00052-I; BECKMANN N, 1990, P INT C GEOGR INF SY; Berkhin P, 2002, SURVEY CLUSTERING DA; BERRY MJA, 1997, DATA MINING MARKETIN; Bishop C. M., 1995, NEURAL NETWORKS PATT; BOUDJELOUD L, 2005, PAC AS C KNOWL DISC; BOUGUETTAYA A, 1996, IEEE T KNOWLEDGE DAT, V8; BOUROCHE J, 2002, ANAL DONNEES; Brachman R., 1996, ADV KNOWLEDGE DISCOV; Breiman L, 1984, CLASSIFICATION REGRE; BRUHA I, 2000, P WORKSH POST PROC M, P20; Brusic V, 1999, KNOWL ENG REV, V14, P257, DOI 10.1017/S0269888999003069; CAILIEZ F, 1976, INTRO ANAL DONNEES; Cappe O, 2004, HIDDEN MARKOV MODELS; CARLIN BP, 1995, J ROY STAT SOC B MET, V57, P473; CELEUX G., 1989, CLASSIFICATION AUTOM; CHEESSEMAN P, 1996, ADV KNOWLEDGE DISCOV; Chen M. H., 2000, MONTE CARLO METHODS; Cole R.M., 1998, THESIS U W AUSTR AUS; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX K, 1997, DATA MINING KNOWLEDG, V1; Cristianini N, 2000, INTRO SUPPORT VECTOR; CRISTIANINI N, 2000, INTOR SUPPORT VECTOR; CUSTSEM BV, 1994, CLASSIFICATION DISSI; DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115; DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364; Devroye L, 1996, PROBABILISTIC THEORY; Draper N., 1998, WILEY SERIES PROBABI; ELLOUMI M, 2002, KNOWLEDGE BASED SYST, V15; Engels R., 1998, P 13 EUR C ART INT, P430; ERRAY W, 2006, P EGC 06 LILL FRANC; ESTER M, 1995, P 1 INT C KNOWL DISC, P94; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Estivill-Castro V., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886); Falkenauer E., 1998, GENETIC ALGORITHMS G; FAMILI A, 1997, INTELL DATA ANAL, V1, P23; FAYYAD U, 2004, P PACIFIC KNOWL DISC, V2; Fayyad U., 2001, INFORM VISUALIZATION; Fayyad Usama, 1996, DATA MINING KNOWLEDG; FELDMAN R, 2002, LINK ANAL CURRENT ST; Fox J, 1997, APPL REGRESSION ANAL; FRALEY C, 1999, MCLUST SQFTWARE MODE; Frawley W., 1992, AI MAGAZINE      FAL, P213; FREITAS A. A, 2002, ADV EVOLUTIONARY COM; FRITZKE B, 1994, NEURAL NETWORKS J, V7; Gascuel O, 1999, ST CLASS DAT ANAL, P58; Goebel M., 1999, ACM SIGKDD EXPLORATI, V1, P20, DOI 10.1145/846170.846172; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; GUYON O, 1996, ADV KNOWLEDGE DISCOV, P181; Han E.-H., 1999, THESIS U MINNESOTA; Han J., 2006, DATA MINING CONCEPTS; Hartigan J., 1975, CLUSTERING ALGORITHM; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; HAYKIM S, 1994, NEURAL NETWORKS COMP; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; HILBORN R, 1997, ECOLOGIST DETECTIVE; HOLLAND JH, 1975, ADAPTATION NATURAL A; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Jain A., 1988, ALGORITHMS CLUSTERIN, P55; Jensen D., 1998, AAAI FALL S AI LINK; Jong KAD, 1993, MACH LEARN, V13, P161; JOURDAN L, 2003, THESIS U SCI TECHNOL; Kantardzic M, 2002, DATA MINING CONCEPTS; Karypis G., 1999, CHAMELEON HIERARCHIC, P68; Kaufman L., 1990, FINDING GROUPS DATA; Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847; Kelly J.D., 1991, P 12 INT JOINT C ART, P645; KHOSHGOFTAAR TM, 1999, RECENT ADV RELIABILI; KODRATOFF Y, 1998, SIGNAUX J, P38; Kolatch E, 2001, CLUSTERING ALGORITHM; Kolodner J., 1993, CASE BASED REASONING; KOLODNER JL, 1992, ARTIF INTELL REV, V6, P3, DOI 10.1007/BF00155578; KRIEGEL HP, 1990, P INT C GEOGR INF SY; KWOK TY, 1998, P 14 INT C PATT REC; Larose D., 2004, DISCOVERING KNOWLEDG; LEHN R, 2004, MESURES QUALITE FOUI, P141; LENCA P, 2004, MESURES QUALITE FOUI, P219; Leng B, 1994, J Comput Biol, V1, P25; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; LI W, 2001, CAYAR ACCURATE EFFIC; LIEBER J, 2002, P EUR C ART INT; Liu B., 1998, INTEGRATING CLASSIFI; LIU H, 1998, SERIES SPRINGER INT; Mandic D. P., 2001, RECURRENT NEURAL NET; MITCHELL T, 1997, DECISION TREE LEARNI, P52; Ng R., 1994, P 20 INT C VER LARG, P144; OVERTON CG, 1998, COMPUTATIONAL METHOD, P65; PIATETSKYSHAPIR.G, 2006, WHAT ARE GRAND CHALL, V8; POULET F, 2002, INT J IMAGE GRAPHICS, V2, P127, DOI 10.1142/S0219467802000524; POULET F, 2005, RNTIE4; Press WH, 1988, NUMERICAL RECIPES C; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAKOTOMALALA R, 2005, SPRINGER LECT NOTES; Ripley B. D., 1996, PATTERN RECOGNITION; Robert C. P., 2004, MONTE CARLO STAT MET; ROBERT CP, 2001, BAASIAN CHOICE; SAVARESI S, 2001, P SIAM ICDM 01 CHIC; Savaresi SM, 2002, SIAM PROC S, P299; SCOTT DW, 1992, MULFIVARIATE DENSITY; Sebastian F., 1999, P THAI 99 EUR S TEL, V99, P105; Shim K., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; SKALAK DB, 1994, P AAAI 93 CAS BAS RE, P64; Smola A., 1996, REGRESSION ESTIMATIO; SOIBELMAN L, 2002, J COMPUTING CIVIL EN; Spence R., 2001, INFORM VISUALIZATION; STEINBACH M, 2000, COMPARISON DOCUMENT; Tan P.-N., 2005, INTRO DATA MINING PE; Thelwall M., 2004, LINK ANAL INFORM SCI; THORNE JL, 1998, MOL BIOL EVOL, V15, P647; TOIVONEN H, 1995, ECML 99 WORKSH STAT; TSATSOULIS C, INT J QUALITY SAFETY, V12, P24; UTANS J, 1999, P AI APPL WALL STREE, P35; Vapnik V, 1997, ADV NEUR IN, V9, P281; VOORHEES EM, 1986, INFORM PROCESS MANAG, V22, P465, DOI 10.1016/0306-4573(86)90097-X; Wallace C. S., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future; Wang J., 2005, DATA MINING BIOINFOR; WANG J, 2005, HARMONY EFFICIENTLY; Wang J. T. L., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347157; WANG JTL, 1994, NUCLEIC ACIDS RES, V22, P2769, DOI 10.1093/nar/22.14.2769; Wang JTL, 1999, J COMPUT BIOL, V6, P209, DOI 10.1089/cmb.1999.6.209; WILLET P, 1990, PARALLEL DATABASE PR; WINSTON PH, 1992, ARTIF INTELL, P423; WITTEN I, 2006, DATAMINING PRACTICAL; Ye N., 2001, P 2 IEEE SMC INF ASS, P1; Yin MM, 2004, INFORM SCIENCES, V163, P201, DOI 10.1016/j.ins.2003.03.016; Yin Xiaoxin, 2003, CPAR CLASSIFICATION; YU LTH, 2003, EUR WORKSH DAT MIN T; YUAN Y, 1995, FUZZY SETS SYSTEMS J, V25, P139; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R; ZIGHED D, 2002, DATA MINING	136	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1677-6				2007							427	432				6	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BJC11	WOS:000264665900048	
B	Cheng, HB; Tan, PN; Jin, R		Apte, C; Liu, B; Parthasarathy, S; Skillicorn, D		Cheng, Haibin; Tan, Pang-Ning; Jin, Rong			Localized Support Vector Machine and Its Efficient Algorithm	PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING			English	Proceedings Paper	7th SIAM International Conference on Data Mining	APR 26-28, 2007	Minneapolis, MN	Amer Stat Assoc			CLASSIFICATION	Nonlinear Support Vector Machines employ sophisticated kernel functions to classify data sets with complex decision surfaces. Determining the right parameters of such functions is not only computationally expensive, the resulting models are also susceptible to overfitting due to their large VC dimensions. Instead of fitting a nonlinear model, this paper presents a framework called Localized Support Vector Machine (LSVM), which builds multiple linear SVM models from the training data. Since each model is designed to classify a particular test example, it has high computational cost. To overcome this limitation, we propose an efficient implementation of LSVM, termed Profile SVM (PSVM). PSVM partitions the training examples into clusters and builds a separate linear SVM model for each cluster. Our empirical results show that (1) Both LSVM and PSVM outperform nonlinear SVM on the majority of the evaluated data sets; and (2) PSVM achieves comparable accuracy as LSVM but with significant computational savings.								Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Burges C J C, 1998, KNOWLEDGE DISCOVERY, V2; Chang C-C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gunn S. R., 1997, SUPPORT VECTOR MACHI; HECHENBICHLER K, 2006, SFB, V386; JOACHIMS T, 1999, INT C MACH LEARN SAN; Newman D. J., 1998, UCI REPOSITORY MACHI; Platt JC, 2000, ADV NEUR IN, V12, P547; ZHANG H, 2006, IEEE C COMP VIS PATT	10	1	2	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA		978-0-898716-30-6				2007							461	466				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematics, Applied	Computer Science; Mathematics	BUG50	WOS:000289220200045	
B	Ghosh, AK		Pal, P		Ghosh, Anil K.			Adaptive nearest neighbor classifier	Proceedings of the Sixth International Conference on Advances in Pattern Recognition			English	Proceedings Paper	6th International Conference on Advances in Pattern Recognition	JAN 02-04, 2007	Calcutta, INDIA	Adobe, GM R&D, India Sci Lab, Reserve Bank India	Indian Stat Inst	Bayesian strength function; cross-validation; posterior probability; prior distribution; sequential technique		In nearest neighbor classification, one normally uses cross-validation type methods to estimate the optimum value of k, and that estimated value is used for classifying all observations. However, in classification problems, in addition to depending on the training sample, a good choice of k depends on the specific observation to be classified. In this article we propose an adaptive nearest neighbor classification technique, where the value of k is selected depending on the distribution of competing classes in the vicinity of the observation to be classified. Results on some simulated and benchmark examples are presented to show the utility of the proposed method.	Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India	Ghosh, AK (reprint author), Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India.						Aho A.V., 1974, DESIGN ANAL COMPUTER; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Efron B., 1993, INTRO BOOTSTRAP; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED, P261; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J ., 1994, 113 STANF U STAT DEP; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Schapire RE, 1998, ANN STAT, V26, P1651; Silverman B.W., 1986, DENSITY ESTIMATION S; Wichern D. W., 1992, APPL MULTIVARIATE ST	18	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		978-981-270-553-2				2007							281	284				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BFY86	WOS:000245470300046	
B	Su, GS; Lei, WJ; Zhang, XF		Jing, G; Gao, J; Zhou, A; Gou, P		Su Guoshao; Lei Wenjie; Zhang Xiaofei			Rockburst prediction method based on K-nearest neighbor pattern recognition	Progress in Mining Science and Safety Technology, Pts A and B			English	Proceedings Paper	International Symposium on Mining Science and Safety Technology	APR 16-19, 2007	Jiaozuo, PEOPLES R CHINA	Henan Polytech Univ, China Occupat Safety & Hlth Assoc, China Coal Assoc, Japan Muroran Inst Technol, Japan Kyushu Univ, Poland Slaska Univ, Mining Fac Penn Univ, France Lille Univ, TAFE, Australia Cent Gippsland Inst, Polland Res Inst Labor Protect, Int Journal Occupat Safety & Ergon		rockburst; mining; k-Nearest Neighbor method; pattern recognition		Rockburst is a geological disaster induced by mining at great depth. How to predict rockburst effectively for safety during mining has become an unresolved key problem. Because of poor understanding of the mechanism and influence factors of rockbust, it is very difficult to give accurate prediction using conventional methods. A new method based on k-Nearest Neighbor pattern recognition tech, which is one of the simplest and most effective tools in the field of pattern recognition, is proposed. First, the historical instances with influence factors induced rockbust are collected into database. Then, k historical instances whose influence factors similar to that of new instance are selected through scanning the database based on the neighbor similarity function. Finally, roburst risk of the new instance can be recognized by majority vote among the k nearest historical instances. The method gives accurate rockburst predictions under novel conditions when mining at great depth. The results of case studies at deep gold mines in South African show that this method is scientific, feasible, and promising.	Guangxi Univ, Dept Civil & Architecture Engn, Nanning 530004, Peoples R China	Su, GS (reprint author), Guangxi Univ, Dept Civil & Architecture Engn, Nanning 530004, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FENG XT, 2000, INTRO INTELLIGENT RO, P294; [冯夏庭 Feng Xiating], 2002, [东北大学学报. 自然科学版, Journal of Northeastern University], V23, P57; FENG XT, 1994, T NONFERR METAL SOC, V4, P9; Gu Shun-de, 2000, Journal of Shanghai Medical University, V27, P108; HE J, 2000, P PRICAI 2000 INT WO, P24; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Fujii Y, 1997, INT J ROCK MECH MIN, V34, P85, DOI 10.1016/S0148-9062(96)00030-7; Linkov AM, 1996, INT J ROCK MECH MIN, V33, P727, DOI 10.1016/0148-9062(96)00021-6; Mansurov VA, 2001, INT J ROCK MECH MIN, V38, P893, DOI 10.1016/S1365-1609(01)00055-7; SHASHA K, 2005, J HENAN NORMAL U, V33, P134; SIMIVASAN C, 1997, J ROCK MECH MINING S, V34, P1001; Wang YG, 1998, J MATER SCI LETT, V17, P493, DOI 10.1023/A:1006536612619; Yang KY, 2007, INFORM COMPUT, V205, P65, DOI 10.1016/j.ic.2006.08.004; ZHANG BY, 2006, COMPUTER ENG APPL, V6, P7; ZHANG G, 1992, P 3 NAT C ROCK DYN W, P422	16	0	0	SCIENCE PRESS BEIJING	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100707, PEOPLES R CHINA		978-7-03-018737-6				2007							840	845				6	Mining & Mineral Processing	Mining & Mineral Processing	BGM26	WOS:000248332000146	
S	Garcia, V; Sanchez, J; Mollineda, R		Rueda, L; Mery, D; Kittler, J		Garcia, Vicente; Sanchez, Jose; Mollineda, Ramon			An empirical study of the behavior of classifiers on imbalanced and overlapped data sets	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		imbalance; overlapping; classifiers; performance measures		Class imbalance has been reported as an important obstacle to apply traditional learning algorithms to real-world domains. Recent investigations have questioned whether the imbalance is the unique factor that hinders the performance of classifiers. In this paper, we study the behavior of six algorithms when classifying imbalanced, overlapped data sets under uncommon situations (e.g., when the overall imbalance ratio is different from the local imbalance ratio in the overlap region). This is accomplished by analyzing the accuracy on each individual class, thus devising how those situations affect the majority and minority classes. The experiments corroborate that overlap is more important than imbalance for the classification performance. Also, they show that the classifiers behave differently depending on the nature of each model.	[Garcia, Vicente] Inst Tecnol Toluca, Lab Reconocimiento Patrones, Metepec 52140, Mexico	Garcia, V (reprint author), Inst Tecnol Toluca, Lab Reconocimiento Patrones, Av Tecnol S-N, Metepec 52140, Mexico.						Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; BATISTA GE, 2005, P 6 INT S INT DAT AN, P24; Bishop C. M., 1995, NEURAL NETWORKS PATT; Buhmann MD, 2003, RADIAL BASIS FUNCTIO; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Duda R. O., 2001, PATTERN CLASSIFICATI; JAPKOWICZ N, 2002, INTELL DATA ANAL, V6, P40; Jo T, 2004, ACM SIGKDD EXPLORATI, V6, P40, DOI 10.1145/1007730.1007737; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Orriols A., 2005, P C GEN EV COMP, P74, DOI 10.1145/1102256.1102271; Prati R. C., 2004, P 3 MEX INT C ART IN, P312; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Vapnik V., 2006, ESTIMATION DEPENDENC; Witten I., 2005, DATA MINING PRACTICA	16	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						397	406				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900042	
S	Hernandez-Rodriguez, S; Martinez-Trinidad, JF; Carrasco-Ochoa, JA		Rueda, L; Mery, D; Kittler, J		Hernandez-Rodriguez, Selene; Martinez-Trinidad, J. Fco.; Ariel Carrasco-Ochoa, J.			Fast k most similar neighbor classifier for mixed data based on a tree structure	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		nearest neighbors rule; fast k-most similar neighbors search; mixed data	SEARCH ALGORITHMS; NEAREST	In this work, a fast k most similar neighbor (k-MSN) classifier for mixed data is presented. The k nearest neighbor (k-NN) classifier has been a widely used nonparametric technique in Pattern Recognition. Many fast k-NN classifiers have been developed to be applied on numerical object descriptions, most of them based on metric properties to avoid object comparisons. However, in some sciences as Medicine, Geology, Sociology, etc., objects are usually described by numerical and non numerical features (mixed data). In this case, we can not assume the comparison function satisfies metric properties. Therefore, our classifier is based on search algorithms suitable for mixed data and non-metric comparison functions. Some experiments and a comparison against other two fast k-NN methods, using standard databases, are presented.	[Hernandez-Rodriguez, Selene; Martinez-Trinidad, J. Fco.; Ariel Carrasco-Ochoa, J.] Natl Inst Astrophys Opt & Elect, Puebla 72840, Mexico	Hernandez-Rodriguez, S (reprint author), Natl Inst Astrophys Opt & Elect, Luis Enr Erro 1,Sta Maria Tonantzintla, Puebla 72840, Mexico.						BLAKE C, 1998, UCI REPOSITORY MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1975, IEEE T COMPUT, V24, P743; GARCIASERRANO JF, 1999, 3 EUR C PRINC PRACT, P354; Gomez-Ballester E, 2006, PATTERN RECOGN, V39, P171, DOI 10.1016/j.patcog.2005.06.007; Gomez-Ballester E, 2003, LECT NOTES COMPUT SC, V2905, P456; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Moreno-Seco F, 2003, LECT NOTES COMPUT SC, V2905, P322; Omachi S., 2000, Systems and Computers in Japan, V31; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YONGSHENG C, 2006, FAST VERSATILE ALGOR	15	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						407	416				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900043	
S	Chang, HY; Sun, CS		Rueda, L; Mery, D; Kittler, J		Chang, Hsin-Yun; Sun, Chung-Shan			A novel hybrid Taguchi-Grey-based method for feature subset selection	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		feature subset selection; taguchi methods; grey-based nearest neighbor rule; pattern classification	ALGORITHMS; CLASSIFICATION	In this paper, a novel hybrid Taguchi-Grey-based method for feature subset selection is proposed. The two-level orthogonal array is employed in the proposed method to provide a well-organized and balanced comparison of two levels of each feature (i.e., the feature is selected for pattern classification or not) and interactions among all features in a specific classification problem. That is, this two-dimensional matrix is mainly used to reduce the feature subset evaluation efforts prior to the classification procedure. Accordingly, the grey-based nearest neighbor rule and the signal-to-noise ratio (SNR) are used to evaluate and optimize the features of the specific classification problem. In this manner, important and relevant features can be identified for pattern classification. Experiments performed on different application domains are reported to demonstrate the performance of the proposed hybrid Taguchi-Grey-based method. It can be easily seen that the proposed method yields superior performance and is helpful for improving the classification accuracy in pattern classification.	[Chang, Hsin-Yun] Chin Min Inst Technol, Dept Business Adm, Toufen 305, Miaoli, Taiwan	Chang, HY (reprint author), Chin Min Inst Technol, Dept Business Adm, 110 Hsueh Fu Rd, Toufen 305, Miaoli, Taiwan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bishop C. M., 1995, NEURAL NETWORKS PATT; BLAKE C, 1998, UCI REPOSITORY MACH; Brassard G., 1996, FUNDAMENTALS ALGORIT; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Deng Julong, 1989, Journal of Grey Systems, V1; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; DOAK J, 1992, EVALUATION FEATURE S; Duda R., 1973, PATTERN CLASSIFICATI; Hall M. A., 1998, THESIS U WAIKATO; Huang CC, 2006, APPL INTELL, V25, P243, DOI 10.1007/s10489-006-0105-0; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 1986, INTRO QUALITY ENG; WU Y, 2000, TAGUCHI METHODS ROBU, P7	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						457	465				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900048	
S	Diaz, G; Gonzalez, F; Romero, E		Rueda, L; Mery, D; Kittler, J		Diaz, Gloria; Gonzalez, Fabio; Romero, Eduardo			Infected cell identification in thin blood images based on color pixel classification: Comparison and analysis	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		cell detection; supervised classification; color spaces; performance comparison		Malaria is an infectious disease which is mainly diagnosed by visual microscopical evaluation of Giemsa-stained thin blood films using a differential analysis of color features. This paper presents the evaluation of a color segmentation technique, based on standard supervised classification algorithms. The whole approach uses a general purpose classifier, which is parameterized and adapted to the problem of separating image pixels into three different classes: parasite, blood red cells and background. Assessment included not only four different supervised classification techniques - KNN, Naive Bayes, SVM and MLP - but different color spaces -RGB, normalized RGB, HSV and YCbCr-. Results show better performance for the KNN classifiers along with an improving feature characterization in the normalized RGB color space.	[Diaz, Gloria; Gonzalez, Fabio; Romero, Eduardo] Natl Univ Colombia, Bioingenium Res Grp, Bogota, Colombia	Diaz, G (reprint author), Natl Univ Colombia, Bioingenium Res Grp, Bogota, Colombia.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daskalaki S, 2006, APPL ARTIF INTELL, V20, P381, DOI 10.1080/08839510500313653; Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0; DISTEFANO L, 1999, P 10 INT C IM AN PRO; FIX E, 1951, 2149004 USAF SCH AV; HALIM S, 2006, P IEEE INT C CONTR A; Platt J, 1998, ADV KERNEL METHODS S; Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SIO SWS, 2007, MICROBIOLOGICAL METH, V68; Tek F.B., 2006, P BRIT MACH VIS C; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; *OPS, 1998, 1 PAN AM ORG HLTH; *WMR UNICEF, 2005, WORLD MAL REP	14	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						812	821				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900084	
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Gpos-PLoc: an ensemble classifier for predicting subcellular localization of Gram-positive bacterial proteins	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article						amphiphilic pseudo amino acid composition; fusion; gene ontology; Gram-positive; OET-KNN rule	AMINO-ACID-COMPOSITION; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; LOCATION PREDICTION; NEGATIVE BACTERIA; SORTING SIGNALS; GENE ONTOLOGY; FOLDING TYPES	A statistical analysis indicated that, of the 35 016 Gram-positive bacterial proteins from the recent Swiss-Prot database, similar to 57% of these entries are without subcellular location annotations. In the gene ontology database, the corresponding percentage is similar to 67%, meaning the percentage of proteins without subcellular component annotations is even higher. With the avalanche of gene products generated in the post-genomic era, the number of such location-unknown entries will continuously increase. It is highly desired to develop an automated method for timely and accurately identifying their subcellular localization because the information thus obtained is very useful for both basic research and drug discovery practice. In view of this, an ensemble classifier called 'Gpos-PLoc' was developed for predicting Gram-positive protein subcellular localization. The new predictor is featured by fusing many basic classifiers, each of which was engineered according to the optimized evidence-theoretic K-nearest neighbors rule. As a demonstration, tests were performed on Gram-positive proteins among the following five subcellular location sites: (1) cell wall, (2) cytoplasm, (3) extracell, (4) periplasm and (5) plasma membrane. To eliminate redundancy and homology bias, only those proteins which have < 25% sequence identity to any other in a same subcellular location were allowed to be included in the benchmark datasets. The overall success rates thus achieved by Gpos-PLoc were > 80% for both jackknife cross-validation test and independent dataset test, implying that Gpos-PLoc might become a very useful vehicle for expediting the analysis of Gram-positive bacterial proteins. Gpos-PLoc is freely accessible to public as a web-server at http://202.120.37.186/bioinf/Gpos/. To support the need of many investigators in the relevant areas, a downloadable file is provided at the same website to list the results identified by Gpos-PLoc for 31898 Gram-positive bacterial protein entries in Swiss-Prot database that either have no subcellular location annotation or are annotated with uncertain terms such as 'probable', 'potential', 'perhaps' and 'by similarity'. Such large-scale results will be updated once a year to include the new entries of Gram-positive bacterial proteins and reflect the continuous development of Gpos-PLoc.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 1954 Hua Shan Rd, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 2000, NUCLEIC ACIDS RES, V25, P31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2006, BIOCHEM BIOPH RES CO, V339, P1015, DOI 10.1016/j.bbrc.2005.10.196; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Juty N, 2012, NUCLEIC ACIDS RES, V40, P580; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Liu H, 2005, BIOCHEM BIOPH RES CO, V338, P1005, DOI 10.1016/j.bbrc.2005.10.046; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Shafer G., 1976, MATH THEORY EVIDENCE; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565; Zuber B, 2006, J BACTERIOL, V188, P6652, DOI 10.1128/JB.00391-06	53	90	92	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126		PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	JAN	2007	20	1					39	46		10.1093/protein-gzl053		8	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	139KR	WOS:000244431200006	
S	Dion, J; Kumar, M; Ramuhalli, P		Thompson, DO; Chimenti, DE		Dion, Juanita; Kumar, Mrityunjay; Ramuhalli, Pradeep			Multi-sensor data fusion for high-resolution material characterization	Review of Progress in Quantitative Nondestructive Evaluation, Vols 26A and 26B	AIP CONFERENCE PROCEEDINGS		English	Proceedings Paper	33rd Annual Review of Progress in Quantitative Nondestructive Evaluation	JUL 30-AUG 04, 2006	Portland, OR			material characterization; classifier; classifier fusion; eddy current; ultrasound	CLASSIFIERS	In typical nondestructive evaluation (NDE) of materials, the material tinder test is inspected using one or more NDE techniques to evaluate its condition. However, measurement data from different inspection techniques are often complementary in nature and higher accuracy may be achieved by fusing information from these different inspection modes. This paper proposes a classifier-fusion based approach to combine multifrequency eddy current and ultrasound data for material characterization. The proposed algorithm uses a hierarchy of classifiers to determine the material state (e.g. stress, heat treatment etc.) and level of exposure to this condition, with classifier fusion achieved through a majority-voting rule. Preliminary results on applying the proposed algorithm to data from Inconel 600 samples are presented.	Michigan State Univ, Dept Elect & Comp Engn, Nondestruct Evaluat Lab, E Lansing, MI 48824 USA	Dion, J (reprint author), Michigan State Univ, Dept Elect & Comp Engn, Nondestruct Evaluat Lab, E Lansing, MI 48824 USA.						Bernardo J. M., 1996, BAYESIAN THEORY; Breiman L., 1993, CLASSIFICATION REGRE; Chen C. H., 1994, Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis (Cat. No.94TH8007), DOI 10.1109/TFSA.1994.467311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R. O., 2001, PATTERN CLASSIFICATI; HAYKIN S, 1999, NEURAL NETWORKS COMP, P199; Jain Anil K., 1988, FUNDAMENTALS DIGITAL; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KUMAR A, 2003, IEEE INSIGHT, V45; KURZYNSKI MW, 1989, PATTERN RECOGN LETT, V10, P39, DOI 10.1016/0167-8655(89)90016-0; OZA N, 2005, SPRINGER LECT NOTES, V3541; SIEWERT TA, 1999, ASTM STP, V1380; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Vapnik V.N., 1995, NATURE STAT LEARNING; YIM J, 1994, P 3 ANN MIDW EL C AP, P10	17	1	1	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X	978-0-7354-0399-4	AIP CONF PROC			2007	894						1189	1196				8	Materials Science, Characterization & Testing; Optics; Physics, Multidisciplinary	Materials Science; Optics; Physics	BGB17	WOS:000245889000153	
B	Ximing, SM; Yu, XP			Alfred University	Sun, Ximing; Yu, Xiaopeng			Collaborative filtering for recommendation using DAKNNS	Sixth Wuhan International Conference on E-Business, Vols 1-4: MANAGEMENT CHALLENGES IN A GLOBAL WORLD			English	Proceedings Paper	6th Wuhan International Conference on E-Business	MAY 26-27, 2007	Wuhan, PEOPLES R CHINA	China Univ Geosci, CICER, Journal Informat Technol, Int Journal Mobile Learning & Org, Int Journal Revenue Management, Int Journal Elect Markets, Int Journal Networking & Virtual Org, Int Journal Biomed Engn & Technol, Electr Govt, Int Journal		k-nearest neighbor searching; collaborative filtering; recommendation system; e-commerce	NEAREST; ALGORITHM; CLASSIFICATION; SEARCH; RULE	Recommendation is to offer information which fits user's interests and tastes to provide better services and to reduce information overload. It recently draws attention upon Internet users and information providers. Collaborative filtering (CF) is one of the widely used methods for recommendation. It recommends an item to a user based on the reference users' preferences for the target item or the target user's preferences for the reference items. In this paper, we propose an adaptive depth-first k-nearest neighbor search (DAKNNS) based collaborative filtering method. The algorithm can find k nearest neighbors of the object user in a small hypersphere in order to improve the efficiencies and forecast the rating. The hypersphere's. size can be automatically determined. It requires a quite moderate preprocessing effort, and the cost to classify an object user is O(alpha d)+O(k)(1<=alpha<<n). Our experiment shows the algorithm performance is superior to other known algorithms.	Wuhan Univ, Econ & Management Sch, Wuhan 430072, Peoples R China							Al Aghbari Z, 2005, DATA KNOWL ENG, V52, P333, DOI 10.1016/j.datak.2004.06.015; Batko M., 2004, Databases, Information Systems, and Peer-to-Peer Computing. Second International Workshop, DBISP2P 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol.3367); BRODER AJ, 1986, OATTERN RECOGNITION, V23, P171; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KUAN J, 1997, INT C INF COMM SIGN, P9; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Samet H., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; XIAOPENG Y, 2005, INT C SERVICES SYSTE, P1016; YU C, 2002, HIGH DIMENSIONAL IND, V2341, P5; ZHANG B, 2004, IEEE T PATTERN ANAL, V26, P116	17	0	0	ALFRED UNIV	ALFRED	ONE SAXON DR, ALFRED, NY 14802 USA		978-0-9604962-9-7				2007							1578	1584				7	Business; Computer Science, Information Systems; Management; Operations Research & Management Science	Business & Economics; Computer Science; Operations Research & Management Science	BGO56	WOS:000249025701101	
J	Cen, HY; He, Y				Cen, Haiyan; He, Yong			Theory and application of near infrared reflectance spectroscopy in determination of food quality	TRENDS IN FOOD SCIENCE & TECHNOLOGY			English	Review							PARTIAL LEAST-SQUARES; ORTHOGONAL SIGNAL CORRECTION; ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; MULTIVARIATE CALIBRATION; NIR-SPECTROSCOPY; PATTERN-RECOGNITION; INSTRUMENT STANDARDIZATION; NONDESTRUCTIVE MEASUREMENT; PRINCIPAL COMPONENT	Near infrared reflectance spectroscopy (NIRS) is a non-destructive and rapid technique applied increasingly for food quality evaluation in recent years. It provides us more information to research the quality of food products. This review intends to give an overview of the type of information that can be obtained based on some developed theory and food research of NIRS. It includes the principle of NIRS technique, the specific techniques with chemometrics for data pre-processing methods, qualitative and quantitative analysis and model transfer, and the wide applications of NIRS in food science. In addition, the promise of NIRS technique for food quality evaluation is demonstrated, and some problems which need to be solved or investigated further are also discussed.	Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310029, Peoples R China	He, Y (reprint author), Zhejiang Univ, Coll Biosyst Engn & Food Sci, Kaixuan Rd 258, Hangzhou 310029, Peoples R China.	yhe@zju.edu.cn	Cen, Haiyan/F-2633-2010; He, Yong/E-3218-2010	He, Yong/0000-0001-6752-1757			Andrews DT, 1997, ANAL CHIM ACTA, V350, P341, DOI 10.1016/S0003-2670(97)00270-5; Aske N, 2001, ENERG FUEL, V15, P1304, DOI 10.1021/ef010088h; BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201; BENGERA I, 1968, ISRAEL J AGR RES, V18, P125; Blanco M, 1999, ANAL CHIM ACTA, V384, P207, DOI 10.1016/S0003-2670(98)00814-9; Blanco M, 2002, ANAL CHIM ACTA, V463, P295, DOI 10.1016/S0003-2670(02)00382-3; Bouveresse E, 1996, VIB SPECTROSC, V11, P3, DOI 10.1016/0924-2031(95)00055-0; Bras LP, 2005, CHEMOMETR INTELL LAB, V75, P91, DOI 10.1016/j.chemolab.2004.05.007; BUCCI R, 2002, J AGR FOOD CHEM, V20, P413; Byrne CE, 1998, MEAT SCI, V49, P399, DOI 10.1016/S0309-1740(98)00005-9; Candolfi A, 1999, J PHARMACEUT BIOMED, V21, P115, DOI 10.1016/S0731-7085(99)00125-9; Carlomagno G, 2004, INFRARED PHYS TECHN, V46, P23, DOI 10.1016/j.infrared.2004.03.004; Chalucova R, 2000, LEBENSM-WISS TECHNOL, V33, P489, DOI 10.1006/fstl.2000.0704; Chen DY, 2005, REMOTE SENS ENVIRON, V98, P225, DOI 10.1016/j.rse.2005.07.008; CHEN QS, SPECTROCHIMICA ACT A; Cocchi M, 2005, ANAL CHIM ACTA, V544, P100, DOI 10.1016/j.aca.2005.02.075; Cocchi M, 2006, TALANTA, V68, P1505, DOI 10.1016/j.talanta.2005.08.005; Contal L, 2002, J NEAR INFRARED SPEC, V10, P289; COOMANS D, 1983, METHOD INFORM MED, V22, P93; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; Copikova J, 2003, CHEM LISTY, V97, P571; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cozzolino D, 2005, LWT-FOOD SCI TECHNOL, V38, P821, DOI 10.1016/j.lwt.2004.10.007; Cozzolino D, 2003, J AGR FOOD CHEM, V51, P7703, DOI 10.1021/jf034959s; DENOORD OE, 1994, CHEMOMETR INTELL LAB, V25, P85, DOI 10.1016/0169-7439(94)85037-2; DEAN T, 1993, NIR NEWS, V4, P14; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Despagne F, 1998, APPL SPECTROSC, V52, P732, DOI 10.1366/0003702981944157; Duponchel L, 1999, J NEAR INFRARED SPEC, V7, P155; Fassio A, 2004, IND CROP PROD, V20, P321, DOI 10.1016/j.indcrop.2003.11.004; FERTIG CC, 2003, EUROPEAN J PHARM SCI, V21, P155; Feudale R. N., 2002, CHEMOM INTELL LAB SY, V64, P181, DOI DOI 10.1016/S0169-7439(02)00085-0; Fu XG, 2005, J FOOD ENG, V69, P461, DOI 10.1016/j.jfoodeng.2004.08.039; Galvao LS, 2005, REMOTE SENS ENVIRON, V94, P523, DOI 10.1016/j.rse.2004.11.012; Garden SW, 1998, J AM SOC BREW CHEM, V56, P159; Geesink GH, 2003, MEAT SCI, V65, P661, DOI 10.1016/S0309-1740(02)00269-3; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Gomez AH, 2006, J FOOD ENG, V77, P313, DOI 10.1016/j.jfoodeng.2005.06.036; Goodacre R, 1997, ANAL CHIM ACTA, V348, P511, DOI 10.1016/S0003-2670(97)00062-7; GORRY PA, 1990, ANAL CHEM, V62, P570, DOI 10.1021/ac00205a007; Hahn F, 2004, BIOSYST ENG, V89, P93, DOI 10.1016/j.biosystemseng.2004.02.012; HALL MN, 1988, FOOD CHEM, V27, P61, DOI 10.1016/0308-8146(88)90036-2; HE Y, 2006, J INFRARED MILLIMETE, V25; HE Y, 2006, SPECTROSCOPY SPECTRA, V26; He Y, 2006, FOOD RES INT, V39, P645, DOI 10.1016/j.foodres.2005.12.008; HELLAND IS, 1995, CHEMOMETR INTELL LAB, V29, P233, DOI 10.1016/0169-7439(95)00031-1; Hoyer H, 1997, PROCESS CONTR QUAL, V9, P143; Indahl UG, 1999, CHEMOMETR INTELL LAB, V49, P19, DOI 10.1016/S0169-7439(99)00023-4; Inon FA, 2006, ANAL CHIM ACTA, V571, P167, DOI 10.1016/j.aca.2006.04.070; ISAKSSON T, 1988, APPL SPECTROSC, V42, P1273, DOI 10.1366/0003702884429869; Karoui R, 2006, FOOD RES INT, V39, P588, DOI 10.1016/j.foodres.2005.12.002; Kasemsumran S, 2005, SPECTROSC LETT, V38, P839, DOI 10.1080/00387010500316189; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; Kim J, 2000, CHEMOMETR INTELL LAB, V51, P201, DOI 10.1016/S0169-7439(00)00070-8; Kim S, 2003, FOOD SCI BIOTECHNOL, V12, P257; Kramer K, 2000, ANAL CHIM ACTA, V420, P155, DOI 10.1016/S0003-2670(00)00877-1; Laasonen M, 2002, ANAL CHEM, V74, P2493, DOI 10.1021/ac011108f; Lammertyn J, 1998, T ASAE, V41, P1089; LANZA E, 1984, J FOOD SCI, V49, P995, DOI 10.1111/j.1365-2621.1984.tb10378.x; Laporte MF, 1999, J AGR FOOD CHEM, V47, P2600, DOI 10.1021/jf980929r; Lee KM, 2005, J CEREAL SCI, V41, P85, DOI 10.1016/j.jcs.2004.09.006; LIZUKA K, 1999, J FOOD COMPOS ANAL, V12, P197; LORBER A, 1986, ANAL CHEM, V58, P1167, DOI 10.1021/ac00297a042; Lorber A, 1997, ANAL CHEM, V69, P1620, DOI 10.1021/ac960862b; LU QY, 2006, IN PRESS J FOOD ENG; Luypaert J, 2004, J PHARMACEUT BIOMED, V36, P495, DOI 10.1016/j.jpba.2004.06.023; Maraboli A, 2002, J NEAR INFRARED SPEC, V10, P63; Mariey L, 2001, VIB SPECTROSC, V26, P151, DOI 10.1016/S0924-2031(01)00113-8; MATHIAS JA, 1987, AQUACULTURE, V61, P303, DOI 10.1016/0044-8486(87)90158-X; McGlone VA, 2002, POSTHARVEST BIOL TEC, V25, P135, DOI 10.1016/S0925-5214(01)00180-6; Munck L, 2004, J CEREAL SCI, V40, P213, DOI 10.1016/j.jcs.2004.07.006; Ni YN, 2005, FOOD CHEM, V89, P465, DOI 10.1016/j.foodchem.2004.05.037; Norgaard L, 2005, INT DAIRY J, V15, P1261, DOI 10.1016/j.idairyj.2004.12.009; Ortiz-Somovilla V, 2007, FOOD CHEM, V101, P1031, DOI 10.1016/j.foodchem.2006.02.058; Osborne B., 1993, PRACTICAL NIR SPECTR; Paradkar MM, 2002, J SCI FOOD AGR, V82, P497, DOI 10.1002/jsfa.1067; Pedro AMK, 2005, ANAL CHEM, V77, P2505, DOI 10.1021/ac048651r; PERKINS JH, 1988, SPECTROCHIM ACTA B, V43, P575, DOI 10.1016/0584-8547(88)80082-X; Pizarro C, 2004, ANAL CHIM ACTA, V509, P217, DOI 10.1016/j.aca.2003.11.008; Pontes MJC, 2005, CHEMOMETR INTELL LAB, V78, P11, DOI 10.1016/j.chemolab.2004.12.001; Pontes MJC, 2006, FOOD RES INT, V39, P182, DOI 10.1016/j.foodres.2005.07.005; Richards T. J., 1998, Agricultural and Resource Economics Review, V27, P186; Rodriguez-Nogales JM, 2006, FOOD CHEM, V98, P782, DOI 10.1016/j.foodchem.2005.07.037; RODRIGUEZOTERO JL, 1995, J AOAC INT, V78, P802; Roggo Y, 2003, J MOL STRUCT, V654, P253, DOI 10.1016/S0022-2860(03)00248-5; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; SCOTTER CNG, 1997, TRENDS FOOD SCI TECH, V17, P344; Sirisomboon P, 2007, J FOOD ENG, V78, P701, DOI 10.1016/j.jfoodeng.2005.11.009; Sjoblom J, 1998, CHEMOMETR INTELL LAB, V44, P229, DOI 10.1016/S0169-7439(98)00112-9; Slobodan S., 2001, ANAL CHEM, V73, P64; Sorensen LK, 1998, INT DAIRY J, V8, P863, DOI 10.1016/S0958-6946(98)00130-7; Szlyk E, 2005, J AGR FOOD CHEM, V53, P6980, DOI 10.1021/jf050672e; Wang L, 2006, FOOD CHEM, V95, P529, DOI 10.1016/j.foodchem.2005.04.015; WANG YD, 1992, ANAL CHEM, V64, P562, DOI 10.1021/ac00029a021; WANG YD, 1991, ANAL CHEM, V63, P2750, DOI 10.1021/ac00023a016; Whitacre E, 2003, J FOOD SCI, V68, P2618, DOI 10.1111/j.1365-2621.2003.tb05779.x; Wilson ND, 2001, J PHARM PHARMACOL, V53, P95, DOI 10.1211/0022357011775064; Wold S, 1998, CHEMOMETR INTELL LAB, V44, P175, DOI 10.1016/S0169-7439(98)00109-9; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0; Xiccato G, 1999, ANIM FEED SCI TECH, V77, P201, DOI 10.1016/S0377-8401(98)00253-3; Xie F, 2004, CEREAL CHEM, V81, P249, DOI 10.1094/CCHEM.2004.81.2.249; Xie YL, 1999, ANAL CHIM ACTA, V384, P193, DOI 10.1016/S0003-2670(98)00832-0; YAN YL, 2005, BASEMENT APPL NIR AN; Yoon JG, 2002, CHEMOMETR INTELL LAB, V64, P1, DOI 10.1016/S0169-7439(02)00042-4; Zhang MH, 2004, TALANTA, V62, P25, DOI 10.1016/S0039-9140(03)00397-7; Zhao JW, 2006, J PHARMACEUT BIOMED, V41, P1198, DOI 10.1016/j.jpba.2006.02.053	106	150	164	ELSEVIER SCIENCE LONDON	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0924-2244		TRENDS FOOD SCI TECH	Trends Food Sci. Technol.		2007	18	2					72	83		10.1016/j.tifs.2006.09.003		12	Food Science & Technology	Food Science & Technology	147GF	WOS:000244990700002	
S	Lu, BL; Li, J		Chen, K; Wang, L		Lu, Bao-Liang; Li, Jing			A min-max modular network with Gaussian-zero-crossing function	TRENDS IN NEURAL COMPUTATION	Studies in Computational Intelligence		English	Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat		min-max modular network; Gaussian-zero-crossing function; brain-style computer; incremental learning; structure pruning	COMBINING MULTIPLE CLASSIFIERS; NEAREST-NEIGHBOR RULE; NEURAL-NETWORK; TASK DECOMPOSITION; PATTERN-CLASSIFICATION; LEARNING ALGORITHMS; GZC FUNCTION; RECOGNITION; IDENTIFICATION; ARCHITECTURE	This chapter presents a min-max modular neural network with Gaussian-zero-crossing function (M(3)-GZC). This modular network has the following attractive features: the highly modular structure, the ability of incremental learning; the guarantee of learning convergence, and the ability of saying 'unknown' to unfamiliar inputs. Its relationships with two traditional models, the nearest neighbor algorithm and the radius-basis function network are discussed for better understanding of M(3)-GZC network. Since the number of modules in a M(3)-GZC network is quadratic complexity with the number of training instances, two redundancy pruning strategies, instance pruning and structure pruning, are proposed to reduce the number of modules and speed up the responding time. Experimental results on several benchmark data sets and a practical industry application show the properties of M(3)-GZC network and the validity of the two redundancy pruning strategies.	Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Lu, BL (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dong Chuan Rd, Shanghai 200240, Peoples R China.	blu@cs.sjtu.edu.cn; jinglee@sjtu.edu.cn					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BATTITI R, 1994, NEURAL NETWORKS, V7, P691, DOI 10.1016/0893-6080(94)90046-9; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; Chen C. H., 1993, Neural, Parallel & Scientific Computations, V1; Chen K, 1997, INT J PATTERN RECOGN, V11, P417, DOI 10.1142/S0218001497000196; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Fan ZG, 2005, LECT NOTES COMPUT SC, V3611, P396; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HAYKIN S, 1999, NEURAL NETWORKS COMP; Huang B, 2004, LECT NOTES COMPUT SC, V3316, P842; JACOBS RA, 1991, COGNITIVE SCI, V15, P219, DOI 10.1207/s15516709cog1502_2; JENKINS RE, 1993, IEEE T NEURAL NETWOR, V4, P718, DOI 10.1109/72.238326; Langdon W. B., 2001, P GEN EV COMP C GECC, P66; Li J, 2005, LECT NOTES COMPUT SC, V3496, P467; Li J, 2005, LECT NOTES COMPUT SC, V3610, P293; Lian HC, 2005, IEEE IJCNN, P1983; Lian HC, 2005, LECT NOTES COMPUT SC, V3611, P438; LIU FY, 2005, P INT JOINT C NEUR N, V1, P570; Lowe D., 1989, P 1 IEE INT C ART NE, P171; LU B L, 2004, P INT JOINT C NEUR N, P735; LU BL, 2002, P INT JOINT C NEUR N, V2, P1263; LU BL, 2001, P 5 INT C KNOWL BAS, P298; Lu BL, 1997, LECT NOTES COMPUT SC, V1240, P330; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; Lu BL, 2003, APPL INTELL, V19, P65, DOI 10.1023/A:1023868723792; Lu BL, 2004, IEEE T BIO-MED ENG, V51, P551, DOI 10.1109/TBME.2003.821023; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Murphy P., 1994, UCI REPOSITORY MACHI; Rumelhart DE, 1986, LEARNING INTERNAL RE; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; TUMER K, 1995, P WORLD C NEUR NETW, P31; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; Wai Lam, 2002, IEEE Transactions on Pattern Analysis and Machine Intelligence, V24, DOI 10.1109/TPAMI.2002.1023804; Wang K, 2005, LECT NOTES COMPUT SC, V3496, P887; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P431; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; YANG Y, 2006, IN PRESS P 3 INT S N; Yang Y, 2005, LECT NOTES COMPUT SC, V3496, P646; Zhang J., 1992, P 9 INT MACH LEARN C, P470	44	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X	3-540-36121-9	STUD COMPUT INTELL			2007	35						285	313				29	Computer Science, Artificial Intelligence	Computer Science	BFN80	WOS:000243355000012	
S	Stiglic, G; Kokol, P		Kokol, P; Podgorelec, V; MiceticTurk, D; Zorman, M; Verlic, M		Stiglic, Gregor; Kokol, Peter			Effectiveness of rotation forest in meta-learning based gene expression classification	Twentieth IEEE International Symposium on Computer-Based Medical Systems, Proceedings	COMPUTER-BASED MEDICAL SYSTEMS : PROCEEDINGS OF THE ANNUAL IEEE SYMPOSIUM		English	Proceedings Paper	20th IEEE International Symposium on Computer-Based Medical Systems	JUN 20-22, 2007	Maribor, SLOVENIA	IEEE Comp Soc TCCM, Fac Elect Engn & Comp Sci, Fac Hlth Sci			SELECTION	A lot of research has been done in the field of assembling classifiers in ensembles and on the other hand selecting the most appropriate single classifiers for a given problem which was solved by ineta-learning techniques. This paper presents application of recently proposed ensemble of classifiers called Rotation Forest to Grading ineta-learning scheme, where it is used as one of the base classifiers and meta-level classifier at the same time. Our proposed Grading variation is compared to four widely used classifiers on 14 datasets from the domain of gene expression classification problems. Experimental evaluations show that using Rotation Forest at meta-level most significantly impacts the accuracy of Grading scheme and confirms that it can be used for estimation of classifiers regions of strong and weak classification.	Univ Maribor, Maribor, Slovenia	Stiglic, G (reprint author), Univ Maribor, Maribor, Slovenia.		Stiglic, Gregor/E-5286-2011				Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BAY SD, 2000, 17 INT C MACH LEARN, P49; Blake C.L., UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings; LEE J, COMPUTATIONAL STAT D, V48, P869; LI J, P IEEE ICDM 2003 C, P585; Liu Huiqing, 2002, Genome Inform, V13, P51; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; SEEWALD AK, 2001, 4 INT C IDA 2001 P S, P115; SYMONS S, MACHINE LEARNING ALG; Vapnik V. N., 1998, STAT LEARN THEORY; Witten I., 2005, DATA MINING PRACTICA; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; WU W, 2005, BMC BIOINFORMATICS, V6, P1	20	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-7125	978-0-7695-2905-9	COMP MED SY			2007							243	248		10.1109/CBMS.2007.43		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Biomedical	Computer Science; Engineering	BGL02	WOS:000248094800041	
S	Pian, JX; Chai, TY; Wang, H; Su, CY			IEEE	Pian, Jinxiang; Chai, Tianyou; Wang, Hong; Su, Chunyi			Hybrid intelligent forecasting method of the laminar cooling process for hot strip	2007 AMERICAN CONTROL CONFERENCE, VOLS 1-13	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2007	JUL 09-13, 2007	New  York, NY				PARAMETER-ESTIMATION; TEMPERATURE CONTROL; SYSTEMS; TABLE	To overcome the difficulties of frequently varying operating conditions of laminar cooling processes and of measuring the strip temperature in the cooling process online, a hybrid intelligent forecasting approach of the strip temperature was developed, which combines mathematic and hybrid intelligent methods. The proposed approach is based on the hybrid multi-intelligence technology, where the RBF neural networks, CBR and fuzzy logic reasoning have been used to obtain the parameter estimates, with which a desired prediction on the coiling temperatures has been obtained together with the cooling temperature curve in the cooling process. A number of tests using industrial data have been conducted where desired numerical results have been obtained. It has been shown that the proposed algorithm has a high potential of being used to realize an effective control of the whole process.	[Pian, Jinxiang; Chai, Tianyou] Northeastern Univ, Minist Educ, Key Lab Integrated Automat Process Ind, Shenyang, Peoples R China	Pian, JX (reprint author), Northeastern Univ, Minist Educ, Key Lab Integrated Automat Process Ind, Shenyang, Peoples R China.						AAMODT A, 1994, AI COMMUN, V7, P39; BADEN N, 1982, CHEM ENG J, V223, P1; Chai Tianyou, 2000, Acta Automatica Sinica, V26; Chai T.-Y., 2002, P 15 IFAC WORLD C BA, P181; Chiu S.L, 1994, J INTELL FUZZY SYST, V2, P267; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ditzhuijzen G. V., 1993, IEEE T AUTOMAT CONTR, V38, P1060; EVANS JF, 1993, IRON STEEL ENG, P50; FLETCHER R, 1979, IMAJ NUMER ANAL, V7, P371; Guan SP, 2001, IEEE T CONTR SYST T, V9, P348; Guo RM, 1997, IEEE T IND APPL, V33, P304; Haftka R.T., 1989, STRUCTURAL OPTIMIZAT, V1, P137, DOI 10.1007/BF01637334; Hartman EJ, 1990, NEURAL COMPUT, V2, P210, DOI 10.1162/neco.1990.2.2.210; Kumar RK, 1997, IEEE T IND APPL, V33, P807; Lawrence WJ, 1996, IRONMAK STEELMAK, V23, P74; Pal SK, 2000, IEEE T NEURAL NETWOR, V11, P366, DOI 10.1109/72.839007; PENG L, 2005, P 2005 IEEE C CONTR, P992; Samaras NS, 1998, IEEE T IND APPL, V34, P1335, DOI 10.1109/28.739019; Schank R. C., 1982, DYNAMIC MEMORY THEOR; SERAJZADEH S, 2003, ELSEVIER J MAT PROCE, V146, P312; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; TJOA IB, 1991, IND ENG CHEM RES, V30, P376, DOI 10.1021/ie00050a015; UETZ G, 1991, STEEL RES, V62, P216; VARAH JM, 1982, SIAM J SCI STAT COMP, V3, P28, DOI 10.1137/0903003	24	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	978-1-4244-0988-4	P AMER CONTR CONF			2007							289	294				6	Automation & Control Systems; Engineering, Electrical & Electronic; Engineering, Mechanical	Automation & Control Systems; Engineering	BHD12	WOS:000252258800050	
S	Verron, S; Tiplica, T; Kobi, A			IEEE	Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad			Procedure based on mutual information and bayesian networks for the fault diagnosis of industrial systems	2007 AMERICAN CONTROL CONFERENCE, VOLS 1-13	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2007	JUL 09-13, 2007	New  York, NY				FISHER DISCRIMINANT-ANALYSIS; SUPPORT VECTOR MACHINES; SUPERVISED CLASSIFICATION; MULTIVARIATE	The aim of this paper is to present a new method for process diagnosis using a bayesian network. The mutual information between each variable of the system and the class variable is computed to identify the important variables. To illustrate the performances of this method, we use the Tennessee Eastman Process. For this complex process (51 variables), we take into account three kinds of faults with the minimal recognition error rate objective.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad] Univ Angers, ISTIA, LASQUO, F-49000 Angers, France	Verron, S (reprint author), Univ Angers, ISTIA, LASQUO, F-49000 Angers, France.						Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; CHARLES HK, 1991, J HOPKINS APL TECH D, V12, P4; Chiang L.H., 2001, FAULT DETECTION DIAG; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COVER TM, 1969, LEARNING PATTERN REC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMINGOS P, 1996, INT C MACH LEARN; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; Duda R. O., 2001, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; Hotelling H., 1947, TECHNIQUES STAT ANAL, P111; Inza I, 1999, PATTERN RECOGN LETT, V20, P1201, DOI 10.1016/S0167-8655(99)00095-1; JACKSON JE, 1985, COMMUN STAT-THEOR M, V14, P2657, DOI 10.1080/03610928508829069; Jensen FV, 1996, INTRO BAYESIAN NETWO; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; KONONENKO I, 1991, EUR WORK SESS LEARN, P206; Kruger U, 2004, J PROCESS CONTR, V14, P879, DOI 10.1016/j.jprocont.2004.02.002; Kulkarni A, 2005, COMPUT CHEM ENG, V29, P2128, DOI 10.1016/j.compchemeng.2005.06.006; LANGLEY P, 1992, NAT C ART INT; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MACGREGOR H, 1995, CHROMOSOME RES, V3, P3, DOI 10.1007/BF00711155; MASON RL, 1995, J QUAL TECHNOL, V27, P99; Murphy K, 2001, COMPUTING SCI STAT P; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; Ricker NL, 1996, J PROCESS CONTR, V6, P205; SAHAMI M, 1996, 2 INT C KNOWLEDGE DI; Shannon E., 1948, BELL SYST TECH J, V27, P623; Shewhart W. A., 1931, EC CONTROL QUALITY M; Vapnik V.N., 1995, NATURE STAT LEARNING; Wise BM, 1996, J PROCESS CONTR, V6, P329, DOI 10.1016/0959-1524(96)00009-1; YANG Y, 2003, 131 MON U SCH COMP S	35	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619	978-1-4244-0988-4	P AMER CONTR CONF			2007							1582	1587				6	Automation & Control Systems; Engineering, Electrical & Electronic; Engineering, Mechanical	Automation & Control Systems; Engineering	BHD12	WOS:000252258801027	
S	Sakagaito, J; Wada, T			IEEE	Sakagaito, Junya; Wada, Toshikazu			Nearest first traversing graph for simultaneous object tracking and recognition	2007 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-8	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO			APPEARANCE	This paper presents a new method for simultaneous object tracking and recognition using object image database. This application requires two searches: search for object appearance stored in the database and that for pose parameters (position, scale, orientation, and so on) of the tracking object in each image frame. For simplifying this problem, we propose a new method, pose parameter embedding (PPE) that transforms the original problem to an appearance search problem. The nearest neighbor (NN) appearance search in this problem has a special property that gradually changing queries are given. For this problem, graph based NN search is suitable, because the preceding search result can be used as the starting point of the next search. Delaunay graph can be used for this search, however, both the graph construction cost and the degree (number of mean edges connected to a vertex) drastically increase in high-dimensional space. Instead, we propose nearest first traversing graph (NFTG) for avoiding these problems. Based on these two techniques, we successfully realized video-rate tracking and recognition.	Wakayama Univ, Fac Syst Engn, Dept Comp & Commun Sci, Wakayama, Japan	Sakagaito, J (reprint author), Wakayama Univ, Fac Syst Engn, Dept Comp & Commun Sci, Wakayama, Japan.	sakajun@vrl.sys.wakayama-u.ac.jp; twada@ieee.org					Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BOZKAYA T, 1997, 1997 ACM SIGMOD; Brin S., 1995, 21 VLDB C MORG KAUFM, P574; Comaniciu D., 2000, CVPR, V2, P142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HAER G, 1998, IEEE T PATTERN ANAL, V20, P1125; Isard M., 1996, EUR C COMP VIS, VI, P343; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Okabe A, 2000, SPATIAL TESSELATIONS; YIANILOV PY, 1993, 4 ANN ACM SIAM S DIS	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919	978-1-4244-1179-5	PROC CVPR IEEE			2007							1575	1581				7	Computer Science, Software Engineering; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	Computer Science; Mathematical & Computational Biology; Remote Sensing; Imaging Science & Photographic Technology	BGT02	WOS:000250382803020	
B	Lumanpauw, E; Pasquier, M; Oentaryo, RJ			IEEE	Lumanpauw, Ernest; Pasquier, Michel; Oentaryo, Richard J.			Generic GA-based meta-level parameter optimization for pattern recognition systems	2007 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-10, PROCEEDINGS	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	IEEE Congress on Evolutionary Computation	SEP 25-28, 2007	Singapore, SINGAPORE	IEEE			FUZZY NEURAL-NETWORK; GENETIC ALGORITHMS; YAGER-INFERENCE	This paper proposes a novel generic meta-level parameter optimization framework to address the problem of determining the optimal parameters of pattern recognition systems. The proposed framework is currently implemented to control the parameters of neuro-fuzzy system, a subclass of pattern recognition system, by employing a genetic algorithm (GA) as the core optimization technique. Two neuro-fuzzy systems i.e., Generic Self-Organizing Fuzzy Neural Network realizing Yager inference (GenSoFNN-Yager) and Reduced Fuzzy Cerebellar Model Articulation Computer realizing the Yager inference (RFCMAC-Yager), are employed as the test prototypes to evaluate the proposed framework. Experimental results on several classification and regression problems have shown the efficacy and robustness of the proposed approach.	[Lumanpauw, Ernest; Pasquier, Michel; Oentaryo, Richard J.] Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Lumanpauw, E (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore.	asmbpasquier@ntu.edu.sg					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darwin C, 1859, ORIGIN SPECIES MEANS; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Han SS, 1996, PROC INT C TOOLS ART, P200; HAYKIN S, 1999, NEURAL NETWORKS COMP; Holland J. H., 1975, ADAPTATION NATURE AR; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Lin CJ, 1997, IEEE T FUZZY SYST, V5, P477; Lin CT, 1996, NEURAL FUZZY SYSTEMS; Maguire LP, 1998, INFORM SCIENCES, V112, P125, DOI 10.1016/S0020-0255(98)10026-9; Nedler J. A., 1965, COMPUT J, V7, P308; Newman D. J., 1998, UCI REPOSITORY MACHI; OENTARYO RJ, 2006, THESIS NANYANG TECHN; OENTARYO RJ, 2006, P IEEE INT JOINT C N, P705; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Quek C, 2005, EXPERT SYST APPL, V29, P229, DOI 10.1016/j.eswa.2005.03.001; Richards N, 1998, APPL INTELL, V8, P85, DOI 10.1023/A:1008224732364; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sim J, 2006, IEEE T NEURAL NETWOR, V17, P1394, DOI 10.1109/TNN.2006.880362; Ster B., 1996, P INT C ENG APPL NEU, P427; TRIMMER JD, 1950, RESPONSE PHYS SYSTEM, P13; Tung WL, 2002, IEEE T NEURAL NETWOR, V13, P1075, DOI 10.1109/TNN.2002.1031940; WALL M, 1996, GALIB A C LIB GENTIC	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1339-3	IEEE C EVOL COMPUTAT			2007							1593	1600		10.1109/CEC.2007.4424663		8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHT10	WOS:000256053701025	
B	He, JS; Yang, ZY; Yao, X			IEEE	He, Jingsong; Yang, Zhenyu; Yao, Xin			Hybridisation of evolutionary programming and machine learning with k-nearest neighbor estimation	2007 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-10, PROCEEDINGS	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	IEEE Congress on Evolutionary Computation	SEP 25-28, 2007	Singapore, SINGAPORE	IEEE				Evolutionary programming(EP) focus on the search step size which decides the ability of escaping local minima, however does not touch the issue of search in promising region. Estimation of Distribution Algorithms(EDAs) focus on where the promising region is, however have less consideration about behavior of each individual in solution search algorithms. Since the basic ideas of EP and EDAs are quite different, it is possible to make them reinforce each other. In this paper, we present a hybrid evolutionary framework to make use of both the ideas of EP and EDAs through introducing a mini estimation operator into EP's search cycle. Unlike previous EDAs that use probability density function(PDF), the estimation mechanism used in the proposed framework is the k-nearest neighbor estimation which can perform better with relative small amount of training samples. Our experimental results have shown that the incorporation of machine learning techniques, such as k-nearest neighbor estimation, can improve the performance of evolutionary optimisation algorithms for a large number of benchmark functions.	[He, Jingsong; Yang, Zhenyu; Yao, Xin] Univ Sci & Technol China, Nat Inspired Computat & Applicat Lab, Hefei 230027, Anhui, Peoples R China	He, JS (reprint author), Univ Sci & Technol China, Nat Inspired Computat & Applicat Lab, Hefei 230027, Anhui, Peoples R China.	hjss@ustc.edu.cn; zhyuyang@mail.ustc.edu.cn; X.Yao@cs.bham.ac.uk					Back T, 1993, EVOL COMPUT, V1, P1, DOI 10.1162/evco.1993.1.1.1; BOSNIAN PAN, 2001, P OPT BUILD US PROB, P208; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Fogel D. B., 1995, EVOLUTIONARY COMPUTA; FOGEL DB, 1993, CYBERNET SYST, V24, P27, DOI 10.1080/01969729308961697; Fogel D. B., 1992, THESIS U CALIFORNIA; Fogel D.B., 1991, SYSTEM IDENTIFICATIO; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; GALLAGHER M, 1999, P 1999 GEN EV COMP C, V1, P840; Gehlhaar D.K., 1996, EVOLUTIONARY PROGRAM, P419; LARRANAGA P, 2001, ESTIMATION DISTRIBUT, P101; LEE CY, 2004, IEEE T EVOLUTIONARY, V8, P456; Li B, 2002, INT J MECH SCI, V44, P987, DOI 10.1016/S0020-7403(02)00021-8; Lu Q, 2005, IEEE T SYST MAN CY C, V35, P195, DOI 10.1109/TSMCC.2004.841914; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PELIKAN M, 2000, PPSN, V6, P385; Schwefel H.-P., 1995, EVOLUTION OPTIMUM SE; Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1339-3	IEEE C EVOL COMPUTAT			2007							1693	1700				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHT10	WOS:000256053701039	
B	Alippi, C; Roveri, M			IEEE	Alippi, Cesare; Roveri, Manuel			Reducing computational complexity in k-NN based adaptive classifiers	2007 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications			English	Proceedings Paper	IEEE International Conference on Computational Intelligence for Measurement Systems and Applications	JUN 27-29, 2007	Ostuni, ITALY	IEEE			NEAREST-NEIGHBOR RULE; CLASSIFICATION	Integrating new information in intelligent measurement systems during their operational life is always profitable from the accuracy point of view but it generally induces an increment in the complexity of the classifier. Adaptive classifiers, which provide adaptive mechanisms to update their knowledge base over time, are able to exploit fresh information to improve accuracy but, traditionally, do not consider complexity issues. In this paper we propose a design solution for adaptive classifiers able to reduce the computational complexity and the memory requirements of k-NN classifiers by including condensing editing techniques. Moreover, we propose a novel approach for estimating the incoming innovation content which allows us for not including redundant or superfluous information (thus minimizing the knowledge base size).	Politecn Milan, DEI, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, DEI, I-20133 Milan, Italy.						Alippi C, 2006, Proceedings of the 2006 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications, P40; ALIPPI C, 2007, P IEEE INT JOINT C N; Bollani M, 2001, APPL SURF SCI, V175, P379, DOI 10.1016/S0169-4332(01)00129-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fu LM, 1996, IEEE T SYST MAN CY A, V26, P801; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KULKAMI SR, 1994, IEEE T INFORM THEORY, V41, P820; LINGARKAR R, 1990, IEEE T SYST MAN CYB, V20, P606, DOI 10.1109/21.57273; Meir R, 2000, IEEE T NEURAL NETWOR, V11, P323, DOI 10.1109/72.839004; NOZAKI K, 1996, IEEE T FUZZY SYST, V4, P23; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; POULSEN RS, 1981, INT S INF THEOR SANT; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P1028; Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882; RODRIGUEZ C, 2002, P 16 INT C PATT REC, V3, P98; STOCKER E, 1996, P ICPR, V4, P128; TAN SC, 2000, P TENCON SEPT, V1, P13; WANG EH, 1992, P INT JOINT C NEUR N, V3, P121, DOI 10.1109/IJCNN.1992.227182; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0823-8				2007							68	71		10.1109/CIMSA.2007.4362541		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Computer Science; Engineering; Remote Sensing; Imaging Science & Photographic Technology	BGW78	WOS:000251008000014	
S	Yu, XP; Yu, XG			IEEE	Yu, Xiaopeng; Yu, Xiaogao			An adaptive algorithm for P2P k-nearest neighbor search in high dimensions	2007 IEEE INTERNATIONAL CONFERENCE ON CONTROL AND AUTOMATION, VOLS 1-7	IEEE International Conference on Control and Automation ICCA		English	Proceedings Paper	IEEE International Conference on Control and Automation	MAY 30-JUN 01, 2007	Guangzhou, PEOPLES R CHINA	IEEE		P2P; k-nearest search; GHT; similarity measurement	CLASSIFICATION; RULE	K-Nearest Neighbors search (KNNS) in high-dimensional feature spaces is an important paradigm in pattern recognition. Existing centralized KNNS does not scale up to large volume of data because the response time is linearly increasing with the size of the searched file. In this article, an adaptive distributed k-nearest neighbor search algorithm (P2PAKNNS) for high dimension data is proposed to further improve the scalability in P2P systems. The idea adopts the generalized hypersphere partitioning and the similarity measure function HDsim((x) over bar, (y) over bar), which can adaptively determines the size of the hypersphere and avoid the problems that L-k-norm leads to the non-contrasting behavior of distance in high dimensional space. By exploiting parallelism in a dynamic network of computers, the query execution scales up very well considering the number of distance computations. The experiments indicate the algorithm is effective.	[Yu, Xiaopeng] Wuhan Univ, Sch Informat Management, Wuhan Inst Technol, Wuhan 430072, Peoples R China	Yu, XP (reprint author), Wuhan Univ, Sch Informat Management, Wuhan Inst Technol, Wuhan 430072, Peoples R China.	myhbwh@163.com; tecom_sam@163.com					Aggarwal C. C., 2001, P 20 ACM SIGMOD SIGA, P256, DOI 10.1145/375551.383213; AGGARWAL CC, 2001, P SIGMOD PODS, V1, P13; BATKO M, 2004, P DELOS WORKSH DIG L, P213; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; Canny J, 2002, P IEEE S SECUR PRIV, P45, DOI 10.1109/SECPRI.2002.1004361; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; OLSSON T, 2003, BOOTSTRAPPING DECENT; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1948-3449	978-1-4244-0817-7	IEEE INT CONF CON AU			2007							236	241				6	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BHX39	WOS:000257195300047	
S	Fadeev, A; Frigui, H; Kim, DJ; Elmaghraby, A			IEEE	Fadeev, Aleksey; Frigui, Hichem; Kim, Dae-Jin; Elmaghraby, Adel			Transformation of relational features for use with conventional classifiers	2007 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-4	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	JUL 23-26, 2007	London, ENGLAND	IEEE				In this paper, we address the problem of transforming relational features into an Euclidian space so that standard classification methods that assume that data is in a vector form could be used. Our approach has three main steps. First, a relational matrix that represents the pair-wise dissimilarities between all objects is constructed. Second, a fuzzy relational clustering algorithm is used to partition the data into groups of similar objects. Third, the relational data features are mapped to a unit hyper-cube space where each object is represented by its membership vectors in all clusters. The proposed method is validated by comparing the performance of several classifiers with different feature sets on the original and the transformed spaces. We show that the transformed space conserves the discriminative information of the original features. We also show that, using the transformed space, a richer set of standard classifiers could be used.	[Fadeev, Aleksey; Frigui, Hichem; Kim, Dae-Jin; Elmaghraby, Adel] Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA	Fadeev, A (reprint author), Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA.	aleksfadeev@gmail.com; h.frigui@louisville.edu; djkimgo@gmail.com; adel@louisville.edu					BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Chang C-C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dave RN, 2002, IEEE T FUZZY SYST, V10, P713, DOI 10.1109/TFUZZ.2002.805899; Frigui H, 2006, IEEE T FUZZY SYST, V14, P885, DOI 10.1109/TFUZZ.2006.879981; GUTTMAN L, 1968, PSYCHOMETRIKA, V33; HATHAWAY RJ, 1989, PATTERN RECOGN, V22, P205, DOI 10.1016/0031-3203(89)90066-6; KAUFMAN K, 1990, FINDING GOUPS DATA; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Li J., 2000, P 8 ACM INT C MULT, P147, DOI 10.1145/354384.354452; Manjunath B. S., 2002, INTRO MPEG; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Nasraoui O., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, DOI 10.1142/S021821300000032X; ROBNER Y, 1999, PERCEPTUAL METRICS I; SEN S, 1998, IEEE C FUZZ SYST, P1411; SNEATH PH, 1973, NUMERIAL TAXONOMY; Witten I., 2005, DATA MINING PRACTICA	18	0	0	IEEE, ELECTRON DEVICES SOC & RELIABILITY GROUP	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584	978-1-4244-1209-9	IEEE INT CONF FUZZY			2007							1999	2004				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHD83	WOS:000252371500342	
S	Alippi, C; Roveri, M			IEEE	Alippi, C.; Roveri, M.			Adaptive classifiers in stationary conditions	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			NEAREST-NEIGHBOR RULE; DISCRIMINANT-ANALYSIS; CLASSIFICATION; SYSTEMS	Integrating new information in classification systems during their operational life requires adaptive mechanisms able to identify first the presence of valuable information and update then the knowledge base onto which the classifier is configured. In this paper we provide a design solution for adaptive classifiers operating in stationary environments; information provided (whenever available by a supervisor over time) is used to improve the performance of the classification system hence mimicking the asymptotical behavior suggested by the theory. The adaptive classifier relies on k -NNs, here chosen for their learning-free modality (hence easily supporting a real time adaptation mechanism); a novel method is proposed for matching the optimal k (measuring the complexity of the classifier) with the incremental knowledge acquired over time. A large experimental campaign shows the effectiveness of the proposed approach.	[Alippi, C.; Roveri, M.] Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy.						ALIPPI C, 2006, P IEEE INT S CIRC SY, P5752; ALIPPI C, P IEEE INT JOINT C N; Alippi C, 2006, IEEE T SYST MAN CY C, V36, P649, DOI 10.1109/TSMCC.2005.855508; ALIPPI C, P IEEE INT JOINT C N, P5040; Bishop C. M., 1995, NEURAL NETWORKS PATT; Blake C, UCI MACHINE LEARNING; Bollani M, 2001, APPL SURF SCI, V175, P379, DOI 10.1016/S0169-4332(01)00129-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Fukunaga K, 1972, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; KEANS M, 1999, NEURAL COMPUT, V11, P1427; Kohlmorgen J, 2000, BIOL CYBERN, V83, P73, DOI 10.1007/s004220000144; KULKAMI SR, 1994, IEEE T INFORM THEORY, V41, P820; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LI P, P IEEE NAT RAD C 199, P372; LINGARKAR R, 1990, IEEE T SYST MAN CYB, V20, P606, DOI 10.1109/21.57273; LU F, 1996, IEEE T SYST MAN CYB, V26, P801; Meir R, 2000, IEEE T NEURAL NETWOR, V11, P323, DOI 10.1109/72.839004; NOZAKI K, 1996, IEEE T FUZZY SYST, V4, P23; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; POULSEN RS, 1981, INT S INF THEOR SANT; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P1028; Rizki MM, 2002, IEEE T EVOLUT COMPUT, V6, P594, DOI 10.1109/TEVC.2002.806167; Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882; RODRIGUEZ C, 2002, P 16 INT C PATT REC, V3, P98; STOCKER E, 1996, P ICPR, V4, P128; STONE C, 1977, ANN STAT, V8, P1348; TAN SC, 2000, P TENCON SEPT, V1, P13; Vapnik V.N., 1998, STAT LEARNING THEORY; WANG EH, 1992, P INT JOINT C NEUR N, V3, P121, DOI 10.1109/IJCNN.1992.227182; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	35	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1379-9	IEEE IJCNN			2007							1008	1013		10.1109/IJCNN.2007.4371096		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291100176	
S	Kamiya, Y; Ishii, T; Furao, S; Hasegawa, O			IEEE	Kamiya, Youki; Ishii, Toshiaki; Furao, Shen; Hasegawa, Osamu			An online semi-supervised clustering algorithm based on a self-organizing incremental neural network	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			PATTERN-CLASSIFICATION; CELL STRUCTURES; MAPS	This paper presents an online semi-supervised clustering algorithm based on a self-organizing incremental neural network (SOINN). Using labeled data and a large amount of unlabeled data, the proposed semi-supervised SOINN (ssSOINN) can automatically learn the topology of input data distribution without any prior knowledge such as the number of nodes or a good network structure; it can subsequently divide the structure into sub-structures as the need arises. Experimental results we obtained for artificial data and real-world data show that the ssSOINN has superior performance for separating data distributions with high-density overlap and that ssSOINN Classifier (S3C) is an efficient classifier.	[Kamiya, Youki; Ishii, Toshiaki] Tokyo Inst Technol, Dept Comp Intelligence & Syst Sci, Tokyo 2268503, Japan	Kamiya, Y (reprint author), Tokyo Inst Technol, Dept Comp Intelligence & Syst Sci, Tokyo 2268503, Japan.	kamiya.y.ab@m.titech.ac.jp; ishii.t.aa@m.titech.ac.jp; frshen@nju.edu.cn; hasegawa.o.aa@m.titech.ac.jp					ANAGNOSTOPOULOS GC, 2003, P IEEE INNS ENNS INT, V3, P1350; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIMITRIADOU E, 2002, P ICANN 02, P571; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; GROSSBERG S, 1976, BIOL CYBERN, V23, P187; HAMKER F, 1997, 197 TU ILM; Hamker FH, 2001, NEURAL NETWORKS, V14, P551, DOI 10.1016/S0893-6080(01)00018-1; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Le Q, 2005, IEEE IJCNN, P3121; Moody J., 1988, P 1988 CONN MOD SUMM, P133; Murphy P. M., 1998, UCI REPOSITORY MACHI; Prudent Y, 2005, IEEE IJCNN, P1211; Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006; Thomas Martinetz T. M., 1993, INT C ART NEUR NETW, P427; ZHANG R, 2006, P ICPR 06, V2, P780	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1379-9	IEEE IJCNN			2007							1061	1066		10.1109/IJCNN.2007.4371105		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291101004	
S	Furao, S; Hasegawa, O			IEEE	Furao, Shen; Hasegawa, Osamu			A nearest-neighbor method with self-organizing incremental neural network	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			CLASSIFICATION	We introduce a prototype-based nearest-neighbor method that is based on a self-organizing incremental neural network (SOINN). It automatically learns the number of prototypes necessary to determine the decision boundary, and it Is robust to noisy training data. The experiments with artificial datasets and real-world datasets illustrate the efficiency of the proposed method.	[Furao, Shen; Hasegawa, Osamu] Nanjing Univ, Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Furao, S (reprint author), Nanjing Univ, Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.						Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Hastie T, 2001, ELEMENTS STAT LEARNI; Merz C. J., 1996, UCI REPOSITORY MACHI; PASSERINI A, 2002, P 15 EUR C ART INT; SHEN F, 2005, IEEE COMP SOC INT C; Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006; Thomas Martinetz T. M., 1993, INT C ART NEUR NETW, P427; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1379-9	IEEE IJCNN			2007							1145	1150		10.1109/IJCNN.2007.4371119		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291101018	
S	Barry, M; Granger, E			IEEE	Barry, M.; Granger, E.			Face recognition in video using a what-and-where fusion neural network	2007 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	AUG 12-17, 2007	Orlando, FL	IEEE			CLASSIFICATION; TRACKING	A What-and-Where fusion neural network is applied to the recognition of human faces from video sequences. ne spatio-temporal information contained in successive video frames allows to effectively accumulate a classifier's predictions for each person being tracked in an environment. In a particular realization of this network, a fuzzy ARTMAP neural network is used to classify faces detected in each frame, while a bank of Kalman filters; is used to track blobs that contain the extracted faces moving in the environment. Performance of the What-and-Where fusion neural network is compared to that of the fuzzy ARTMAP and k-Nearest-Neighbor (k-NN) classifiers in terms of classification rate, convergence time and compression. In this paper, the impact on performance of setting different region of interest (ROI), of optimizing fuzzy ARTMAP parameters, and of selecting different training subset sizes, is assessed. Simulation results on real-world video sequences indicate that this network can achieve a classification rate that is significantly higher (by approximately 50% in some cases) than that of fuzzy ARTMAP alone, and than that of the k-NN.	[Barry, M.; Granger, E.] Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, Montreal, PQ H3C 1K3, Canada	Barry, M (reprint author), Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle, 1100 Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada.						CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CHEN S, 1992, IEEE T NEURAL NETWOR, V3, P698; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Foresti GL, 2000, INT J IMAG SYST TECH, V11, P263, DOI 10.1002/ima.1011; Gorodnichy DO, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P330, DOI 10.1109/CRV.2005.87; Granger E, 2001, NEURAL NETWORKS, V14, P325, DOI 10.1016/S0893-6080(01)00019-3; GRANGER E, 2006, INT JOINT C NEUR NET; LI B, 2001, J OPT SOC AM, V18, P530; LIEANHART R, 2002, INT C IM PROC, V1, P900; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHOU SK, 2004, IEEE T IMAGE PROCESS, V13, P263	11	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-1-4244-1379-9	IEEE IJCNN			2007							2256	2261		10.1109/IJCNN.2007.4371309		6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BHM64	WOS:000254291102030	
B	Martone, AF; Delp, EJ			IEEE	Martone, Anthony F.; Delp, Edward J.			Characterization of RF devices using two-tone probe signals	2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	14th IEEE/SP Workshop on Statistical Signal Processing	AUG 26-29, 2007	Madison, WI	IEEE, SP		RF devices; forensic characterization; intermodulation distortion; probe signals; circuit models	PATTERN-CLASSIFICATION	This paper describes a method for forensic characterization of RF devices using two-tone probe signals. When transmitted to an RF device, the two-tone signal is affected by nonlinear circuit components such as amplifiers or diodes. The nonlinear components cause intermodulation distortion to the input signal, which is reradiated by the device. Features of the intermodulation distortion products are used to construct a device fingerprint. The fingerprint is then used to characterize the device so that it can be identified from other RF devices.	[Martone, Anthony F.; Delp, Edward J.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Martone, AF (reprint author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.		Delp, Edward/C-3616-2013	Delp, Edward/0000-0002-2909-7323			Babich GA, 1996, IEEE T PATTERN ANAL, V18, P567, DOI 10.1109/34.494647; Breiman L, 1984, CLASSIFICATION REGRE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chang C. C., LIBSVM LIB SUPPORT V; COMMISSION FC, 2006, PART 15 RADIO FREQ B; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; GOLIKOV V, 2001, VEH TECHN C 2001 OCT, V4, P2623; HOFFBECK J, 1995, INT GEOSC REM SENS S, V2, P1023; KHANNA N, 2006, DIGIT INVEST, V3, P17, DOI 10.1016/j.diin.2006.06.014; MARTONE AF, 2006, P 2006 IEEE SW S IM, P149; PEDRO J, 2003, INTERMODULATION DIST; RHYNE GW, 1987, IEEE T MICROW THEORY, V35, P1248, DOI 10.1109/TMTT.1987.1133844	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-1197-9				2007							161	165		10.1109/SSP.2007.4301239		5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BHI51	WOS:000253416000034	
B	Vivencio, DP; Hruschka, ER; Nicoletti, MD; dos Santos, EB; Galvao, SDCO			IEEE	Vivencio, Diego P.; Hruschka, Estevarn R., Jr.; Nicoletti, M. do Carmo; dos Santos, Edimilson B.; Galvao, Sebastian D. C. O.			Feature-weighted k-nearest neighbor classifier	2007 IEEE Symposium on Foundations of Computational Intelligence, Vols 1 and 2			English	Proceedings Paper	IEEE Symposium on Foundations of Computational Intelligence	APR 01-05, 2007	Honolulu, HI	IEEE		feature selection; instance-based learning; feature ranking	SELECTION	This paper proposes a feature weighting method based on X-2 statistical test, to be used in conjunction with a k-NN classifier. Results of empirical experiments conducted using data from several knowledge domains are presented and discussed. Forty four out of forty five conducted experiments favoured the feature weighted approach and are empirical evidence that the proposed weighting process based on X-2 is a good weighting strategy.	DC UFSCar, Sao Carlos, SP, Brazil	Vivencio, DP (reprint author), DC UFSCar, Sao Carlos, SP, Brazil.		Hruschka Jr., Estevam/B-1073-2008; Batista dos Santos, Edimilson/G-9014-2012				Aha D.W., 1990, THESIS U CALIFORNIA; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 1992, P TWLT3 CONN NAT LAN, P27; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hruschka ER, 2004, LECT NOTES ARTIF INT, V3060, P370; Koller D., 1996, P 13 INT C MACH LEAR, P284; Langley P., 1993, P 13 INT JOINT C ART, P889; LANGLEY P, 1997, COMPUTATIONAL LEARNI, V4; Liu H., 1998, FEATURE SELECTION KN; Merz C.J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Reunanen J., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753715; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Witten I. H., 2002, DATA MINING PRACTICA	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0703-3				2007							481	486		10.1109/FOCI.2007.371516		6	Computer Science, Artificial Intelligence	Computer Science	BGM60	WOS:000248503700073	
B	Wu, WH; Batalin, MA; Kaiser, WJ; Sarrafzadeh, M; Bui, AAT				Wu, Winston H.; Batalin, Maxim A.; Kaiser, William J.; Sarrafzadeh, Majid; Bui, Alex A. T.			A Novel Method and Testbed for Sensor Management and Patient Diagnosis	2007 JOINT WORKSHOP ON HIGH CONFIDENCE MEDICAL DEVICES, SOFTWARE AND SYSTEMS AND MEDICAL DEVICE PLUG-AND PLAY INTEROPERABILITY			English	Proceedings Paper	Joint Workshop on High Confidence Medical Devices, Software, and Systems/Medical Device Plug-and-Play Interoperability	JUN 25-27, 2007	Cambridge, MA	NSF, AHRO, TATRC, CIMIT, Massachusetts Gen Hosp, Partners			TRIAXIAL ACCELEROMETER; MEDICAL DIAGNOSIS; WEARABLE SENSORS; CLASSIFICATION; SELECTION	Low-cost sensors and wireless systems can now create a constantly vigilant and pervasive monitoring capability at home, at work, and in conventional point-of-care environments. While progress in this area is underway in sensor technology, mobile computing platforms, and data transport, barriers to large scale application remain ahead, particularly in the area of patient disease diagnosis, which generally requires a diverse set of sensors and instruments that are applied at proper times in response to patient state/behavior As these sensors may, be numerous, and may not be worn comfortably and practicably at all times, a solution is required for the systematic selection of sensors at the point of use. We describe the Incremental Diagnosis Method (IDM) system, an embedded decision support system based on Bayesian statistics and decision analysis theory developed to select or deselect available sensors so that the diagnostic certainly of patient condition best improved while the set of sensors used on the patient body is minimized. IDM has been evaluated in a testbed, the Medical Embedded Device for Individualized Care (MEDIC) system, based on standard, ubiquitous wireless platforms. MEDIC supports local sensing and signal processing, autonomous decision support, and remote reconfiguration and control of wearable components. A detailed evaluation of IDM operation and performance for patient gait analysis is also given in this paper Finally, we also discuss the many new opportunities provided by IDM and the related future research introduced by this capability.	[Wu, Winston H.; Batalin, Maxim A.; Kaiser, William J.] Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA	Wu, WH (reprint author), Univ Calif Los Angeles, Dept Elect Engn, Los Angeles, CA 90095 USA.	winston@ee.ucla.edu; maxim@ee.ucla.edu; kaiser@ee.ucla.edu; majid@cs.ucla.edu; buia@mii.ucla.edu					AMFT O, 2006, P INT WORKSH WEAR IM; ANLIKER U, 2003, IEEE T COMPUTERS; Asada HH, 2003, IEEE ENG MED BIOL, V22, P28, DOI 10.1109/MEMB.2003.1213624; Bao L., 2004, P 2 INT C PERV COMP; Bernardo J. M., 2003, ENCY LIFE SUPPORT SY; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BRACHINGER HW, 2002, OPTIMIZATION OPERATI, P933; Brage S, 2005, EUR J CLIN NUTR, V59, P561, DOI 10.1038/sj.ejcn.1602118; Budinger TE, 2003, ANNU REV BIOMED ENG, V5, P383, DOI 10.1146/annurev.bioeng.5.040202.121653; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEY A, 2000, BCHI 2000 WORKSH WHA; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Farringdon J, 2005, LECT NOTES COMPUT SC, V3345, P202; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hall DL, 1997, P IEEE, V85, P6, DOI 10.1109/5.554205; Hastie T, 2001, ELEMENTS STAT LEARNI; HAUSDORFF JM, 2005, J NEUROENG REHAB, V2; Hellerstein J. L., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Herzog Almut, 2003, Technol Health Care, V11, P77; HILDEN J, 1984, COMPUT BIOL MED, V14, P429, DOI 10.1016/0010-4825(84)90043-X; Holmquist LE, 2004, IEEE COMPUT GRAPH, V24, P56, DOI 10.1109/MCG.2004.1255810; HOYT R, 2002, BIOMED INFORM ONE DI; HUSEMANN D, 2004, P INT S WEAR COMP IS, P43; HUYNH T, 2005, JOINT SOC EUSAI C OC, P159; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jovanov E., 2005, J NEUROENG REHAB, V2; JOVANOV E, 2003, IEEE ENG MED BIO MAY; Kallio S., 2003, IEEE INT C SYST MAN, P2070; Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864; Kern N., 2003, P EUR S AMB INT, P220; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993; KORHONEN I, 2003, P UB 2003 2 INT WORK; Korpipaa P, 2003, PERS UBIQUIT COMPUT, V7, P113, DOI 10.1007/s00779-003-0237-8; KRAUSE A, 2003, P 7 IEEE INT S WEAR; KRAUSE A, 2005, P 9 IEEE INT S WEAR; LAERHOVEN KV, 2000, P ISWC2000, P77; LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223; Lorincz K., 2004, IEEE PERVASIVE C OCT; Lucas Peter, 2004, Curr Opin Crit Care, V10, P399, DOI 10.1097/01.ccx.0000141546.74590.d6; Lucas PJF, 2004, ARTIF INTELL MED, V30, P201, DOI 10.1016/j.artmed.2003.11.001; LUKOWICZ P, 2001, IEEE MICRO       MAY, P16; Lukowicz P, 2004, LECT NOTES COMPUT SC, V3001, P18; LUKOWICZ P, 2004, METHODS INF MED, V3; LYMBERIS A, 2003, P 25 ANN INT C IEEE, V4, P3716; MALAN D, 2004, P MOBISYS WORKSH APP; MARIN J, 2005, HDB STAT; Mathie MJ, 2004, MED BIOL ENG COMPUT, V42, P679, DOI 10.1007/BF02347551; MORRIS S. J., 2002, P ENG MED BIOL C, V3, P2468; Moy ML, 2003, IEEE ENG MED BIOL, V22, P89, DOI 10.1109/MEMB.2003.1213631; MUHLSTEFF J, 2004, P 26 ANN INT C IEEE, P2184; Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189; OTTO C, 2006, J MOBILE MULTIMEDIA, V1; Ouchi K., 2002, Proceedings 22nd International Conference on Distributed Computing Systems Workshops, DOI 10.1109/ICDCSW.2002.1030864; PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532; Pappas IPI, 2004, IEEE SENS J, V4, P268, DOI 10.1109/JSEN.2004.823671; Parkka J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; POLLARD J, 2002, MED INFORM INTERNET, V27, P21927; Quinlan J., 1986, MACH LEARN, V1, P81106; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Sim I, 2002, J GEN INTERN MED, V17, P302, DOI 10.1046/j.1525-1497.2002.10518.x; SUNG M, 2005, MINIMALLY INVASIVE P; SUNG M, 2005, J NEUROENG REHAB, V2; Sung M, 2005, J COMPUT ASSIST LEAR, V21, P229, DOI 10.1111/j.1365-2729.2005.00130.x; TROSTER G, 2005, IMIA YB MED INFORM; Von Neumann J, 1947, THEORY GAMES EC BEHA; Winters JM, 2003, IEEE ENG MED BIOL, V22, P56, DOI 10.1109/MEMB.2003.1213627; WU WH, 2006, IEEE T INF IN PRESS; WU WH, 2006, ARTIFICIAL INT UNPUB; Yager RR, 2000, IEEE T SYST MAN CY B, V30, P60, DOI 10.1109/3477.826947; Yu L, 2004, J MACH LEARN RES, V5, P1205; *BLUEP XP, BLUET SER AD; *BLUES AD, DAT ACQ CONTR MOD; *NON, NON 4100 BLUET OX; *TEX INSTR INC, EL FRONT END; ANALOG DEVICES ADX13; INTELLISENSE INFORM; LIFESOURCE UC321 BOD; ANALOG DEVICES ADXRS	82	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-3081-9				2007							76	87		10.1109/HCMDSS-MDPnP.2007.14		12	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Biomedical	Computer Science; Engineering	BJD66	WOS:000265022300008	
S	Jafari, R; Li, WC; Bajcsy, R; Glaser, S; Sastry, S		Leonhardt, S; Falck, T; Mahonen, P		Jafari, Roozbeh; Li, Wenchao; Bajcsy, Ruzena; Glaser, Steven; Sastry, Shankar			Physical activity monitoring for assisted living at home	4th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007)	IFMBE Proceedings		English	Proceedings Paper	4th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007)	MAR 26-28, 2007	Aachen, GERMANY		RWTH Aachen Univ	fall detection; movement monitoring; wearable and ubiquitous computing; signal processing		We propose a methodology to determine the occurrence of falls from among other common human movements. The source data is collected by wearable and mobile platforms based on three-axis accelerometers to measure subject kinematics. Our signal processing consists of preprocessing, pattern recognition and classification. One problem with data acquisition is the extensive variation in the morphology of acceleration signals of different patients and under various conditions. We explore several effective key features that can be used for classification of physical movements. Our objective is to enhance the accuracy of movement recognition. We employ classifiers based on neural networks and k-nearest neighbors. Our experimental results exhibit an average of 84% accuracy in movement tracking for four distinct activities over several test subjects.	Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Jafari, R (reprint author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.						AMINIAN K, 2006, COMPUTATIONAL INTELL; AVONS P, 1988, EUR J CLIN NUTR, V42, P185; BAEK GLJ, 2004, KNOWLEDGE BASED INTE, V3215; Chuanjun L., 2006, REAL TIME CLASSIFICA, V10, P163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FARGUES MP, 1993, MODELING CLASSIFICAT, V1, P445; Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864; KEMPER HCG, 1977, EUR J APPL PHYSIOL O, V37, P71, DOI 10.1007/BF00421600; PORTEUS J, 2000, EXPLORING TECHNOLOGI; Ross PE, 2004, IEEE SPECTRUM, V41, P26, DOI 10.1109/MSPEC.2004.1363637; WILSON E, 1994, WORLD C NEUR NETW SA	11	8	8	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1680-0737	978-3-540-70993-0	IFMBE PROC			2007	13						213	219				7	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic	Computer Science; Engineering	BGF89	WOS:000246511700037	
B	Chen, TS; Chiu, YH; Lin, CC				Chen, Tung-Shou; Chiu, Yung-Hsing; Lin, Chih-Chiang			Fast Nearest Neighbor classification using class-based clustering	PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	6th International Conference on Machine Learning and Cybernetics	AUG 19-22, 2007	Hong Kong, PEOPLES R CHINA	Machine Learning & Cybernet Res Inst, Hebei Univ, IEEE Syst Man & Cybernet Soc, Harbin Inst Technol Shenzhen Grad Sch, Chinese Univ Hong Kong, City Univ Hong Kong, Hong Kong Baptist Univ, Hong Kong Univ Sci & Technol, Int Fuzzy Syst Assoc, Hebei Univ Sci & Technol		classification; Nearest Neighbor; parameter-free; accelerating; clustering	TREES; RULE	Nearest Neighbor Rule (NNR) is a parameter-free classifier which is easy to implement, simple to operate and with high accuracy. However, it is time and memory consuming for large datasets. This study proposed a parameter-free method to accelerate NNR. This method employs a class-based clustering algorithm to divide the training data to several clusters with respective members belonging to the same class. Cluster representations are extracted clustering border data based on the nearest neighbors between the different class clusters. Since the cluster representations are the clustering border data rather than the clustering centers, the predicting accuracy will not be affected by removing a cluster's internal data. In the predicting phase, the nearest neighbor search area is narrowed down by referring to a distance between a testing data and its nearest cluster. Thus the predicting process Is speeded up. In this paper, the performance of the proposed method was evaluated and compared with NNR, K-NNR, and LIBSVM by using 5 benchmark datasets. Experimental results show that the proposed parameter-free classification algorithm is very easy to operate and gives consideration to speed and accuracy.	[Chen, Tung-Shou; Chiu, Yung-Hsing] Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung 404, Taiwan	Chen, TS (reprint author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung 404, Taiwan.						BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; Chang C. C., LIBSVM LIB SUPPORT V; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen RC, 2006, INT J PATTERN RECOGN, V20, P227, DOI 10.1142/S0218001406004624; Chen TS, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P485; Chen TS, 2006, LECT NOTES ARTIF INT, V4114, P278; CHEN TS, 2005, P 5 INT C EL BUS HON, P214; CHOU CH, 2006, P 18 INT C PATT REC, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dunham M. H., 2003, DATA MINING INTRO AD; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; NEWMAN DJ, UCI RESP MACHINE LEA; Roiger R. J., 2003, DATA MINING TUTORIAL; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Vapnik V.N., 1995, NATURE STAT LEARNING; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0972-3				2007							1894	1898				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	BGZ09	WOS:000251433403014	
J	Boniatis, I; Costaridou, L; Cavouras, D; Panagiotopoulos, E; Panayiotakis, G				Boniatis, Ioannis; Costaridou, Lena; Cavouras, Dionisis; Panagiotopoulos, Elias; Panayiotakis, George			A computer-based image analysis method for assessing the severity of hip joint osteoarthritis	NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT			English	Article; Proceedings Paper	3rd International Conference on Imaging Technologies in Biomedical Sciences	SEP 25-29, 2005	Milos, GREECE			hip; osteoarthritis; radiograph; texture analysis; pattern recognition	TEXTURAL FEATURES; CLASSIFICATION	A computer-based image analysis method was developed for assessing the severity of hip osteoarthritis (OA). Eighteen pelvic radiographs of patients with verified unilateral hip OA, were digitized and enhanced employing custom developed software. Two Rots corresponding to osteoarthritic and contralateral-physiological radiographic Hip Joint Spaces (HJSs) were determined on each radiograph. Textural features were extracted from the HJS-ROIs utilizing the run-length matrices and Laws textural measures. A k-Nearest Neighbour based hierarchical tree structure was designed for classifying hips into three OA severity categories labeled as "Normal", "Mild/Moderate", and "Severe". Employing the run-length features, the overall classification accuracy of the hierarchical tree structure was 86.1%. The utilization of Laws' textural measures improved the system classification performance, providing an overall classification accuracy of 94.4%. The proposed method maybe of value to physicians in assessing the severity of hip OA. (c) 2006 Elsevier B.V. All rights reserved.	Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece; Inst Educ Technol, Dept Med Instrumentat Technol, Athens 12210, Greece; Univ Patras, Sch Med, Dept Orthopaed, Patras 26500, Greece	Panayiotakis, G (reprint author), Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece.	panayiot@upatras.gr					ALTMAN R, 1991, ARTHRITIS RHEUM, V34, P505, DOI 10.1002/art.1780340502; ALTMAN RD, 1987, ARTHRITIS RHEUM, V30, P1214, DOI 10.1002/art.1780301103; AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046; Bocchi L, 1997, MED ENG PHYS, V19, P336, DOI 10.1016/S1350-4533(96)00078-1; Boniatis IS, 2006, BRIT J RADIOL, V79, P232, DOI 10.1259/bjr/87956832; CONROZIER T, 1993, REV RHUM, V60, P105; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Creamer P, 2000, CURR OPIN RHEUMATOL, V12, P450, DOI 10.1097/00002281-200009000-00019; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI 10.1016/S0146-664X(75)80008-6; GONZALEZ RC, 2002, DIGITALIMAGE PROCESS; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Ingvarsson T, 2000, ANN RHEUM DIS, V59, P650, DOI 10.1136/ard.59.8.650; Jacobsen S, 2004, OSTEOARTHR CARTILAGE, V12, P704, DOI 10.1016/j.jocaaaa.2004.05.003; KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494; LANE NE, 1993, J RHEUMATOL, V20, P1911; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238; Ory PA, 2003, BEST PRACT RES CL RH, V17, P495, DOI 10.1016/S1521-6942(03)00022-6; Peterfy CG, 2002, CURR OPIN RHEUMATOL, V14, P590, DOI 10.1097/01.BOR.0000025608.46603.62; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Spector T D, 1993, Osteoarthritis Cartilage, V1, P203, DOI 10.1016/S1063-4584(05)80325-5; THEODORIDES S, 2003, PATTERN RECOGNITION	23	12	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0168-9002		NUCL INSTRUM METH A	Nucl. Instrum. Methods Phys. Res. Sect. A-Accel. Spectrom. Dect. Assoc. Equip.	DEC 20	2006	569	2			SI		610	613		10.1016/j.nima.2006.08.095		4	Instruments & Instrumentation; Nuclear Science & Technology; Physics, Particles & Fields; Spectroscopy	Instruments & Instrumentation; Nuclear Science & Technology; Physics; Spectroscopy	122QK	WOS:000243241300100	
J	Huang, CC; Lee, HM				Huang, Chi-Chun; Lee, Hahn-Ming			An instance-based learning approach based on grey relational structure	APPLIED INTELLIGENCE			English	Article						instance-based learning; grey relational analysis; grey relational structure; pattern classification	PATTERN-CLASSIFICATION; ALGORITHMS; RULES; NETWORK	In instance-based learning, the 'nearness' between two instances-used for pattern classification-is generally determined by some similarity functions, such as the Euclidean or Value Difference Metric (VDM). However, Euclidean-like similarity functions are normally only suitable for domains with numeric attributes. The VDM metrics are mainly applicable to domains with symbolic attributes, and their complexity increases with the number of classes in a specific application domain. This paper proposes an instance-based learning approach to alleviate these shortcomings. Grey relational analysis is used to precisely describe the entire relational structure of all instances in a specific domain. By using the grey relational structure, new instances can be classified with high accuracy. Moreover, the total number of classes in a specific domain does not affect the complexity of the proposed approach. Forty classification problems are used for performance comparison. Experimental results show that the proposed approach yields higher performance over other methods that adopt one of the above similarity functions or both. Meanwhile, the proposed method can yield higher performance, compared to some other classification algorithms.	Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan.	cchuang@mail.nkmu.edu.tw; hmlee@mail.ntust.edu.tw					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; An A, 2003, COMPUT MATH APPL, V45, P737, DOI 10.1016/S0898-1221(03)00034-8; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Blake CL, 1998, UCI REPOSITORY MACHI; Brouwer RK, 1997, NEURAL NETWORKS, V10, P529, DOI 10.1016/S0893-6080(96)00087-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng Julong, 1989, Journal of Grey Systems, V1; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Fix E., 1951, 4 USAF SCH AV MED; Freund Y., 1999, P 16 INT C MACH LEAR, P124; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; Hewett R, 2003, DATA KNOWL ENG, V46, P271, DOI 10.1016/S0169-023X(03)00020-X; Hickey RJ, 2001, KNOWL-BASED SYST, V14, P131, DOI 10.1016/S0950-7051(01)00089-2; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Hu YC, 2002, NEUROCOMPUTING, V48, P863, DOI 10.1016/S0925-2312(01)00677-4; HUANG CC, 2001, P 2001 NAT COMP S TA, pB153; Huang CC, 2003, LECT NOTES COMPUT SC, V2810, P68; Huang YP, 1997, FUZZY SET SYST, V87, P265; Hullermeier E, 2003, ARTIF INTELL, V148, P335, DOI 10.1016/S0004-3702(03)00019-5; Ignizio JP, 1996, COMPUT OPER RES, V23, P535, DOI 10.1016/0305-0548(95)00058-5; John G., 1995, P 11 C UNC ART INT, P338; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KOHAVI R, 1995, EUR C MACH LEARN, P174; LANGLEY P, 1995, COMMUN ACM, V38, P55; LIN CT, 1999, J GREY SYSTEM, V4, P359; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SALZBERG S, 1988, TR1088 HARV U CTR RE; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; Tsumoto S, 2003, EXPERT SYST APPL, V24, P189, DOI 10.1016/S0957-4174(02)00142-2; WATSON CP, 1993, STAT MANAGEMENT EC; Watson I, 1999, KNOWL-BASED SYST, V12, P303, DOI 10.1016/S0950-7051(99)00020-9; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I. H., 2000, DATA MINING PRACTICA	41	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	DEC	2006	25	3					243	251		10.1007/s10489-006-0105-0		9	Computer Science, Artificial Intelligence	Computer Science	102FO	WOS:000241796600001	
J	Abbas, SR; Arif, M				Abbas, Syed Rahat; Arif, Muhammad			Long range time series forecasting by upsampling and using cross-correlation based selection of nearest neighbor	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						time series forecasting; nearest neighbor; multistep-ahead prediction; long range forecasting; cross-correlation	CLASSIFICATION; MODEL	Long range or multistep-ahead time series forecasting is an important issue in various fields of business, science and technology. In this paper, we have proposed a modified nearest neighbor based algorithm that can be used for long range time series forecasting. In the original time series, optimal selection of embedding dimension that can unfold the dynamics of the system is improved by using upsampling of the time series. Zeroth order cross-correlation and Euclidian distance criterion are used to select the nearest neighbor from up-sampled time series. Embedding dimension size and number of candidate vectors for nearest neighbor selection play an important role in forecasting. The size of embedding is optimized by using auto-correlation function (ACF) plot of the time series. It is observed that proposed algorithm outperforms the standard nearest neighbor algorithm. The cross-correlation based criteria shows better performance than Euclidean distance criteria.	PIEAS, Dept Comp & Informat Sci, Islamabad, Pakistan	Abbas, SR (reprint author), PIEAS, Dept Comp & Informat Sci, Islamabad, Pakistan.	rahatabbas@gmail.com; syedmarif2003@yahoo.com					Abraham B., 1983, STAT METHODS FORECAS; ANDERSON OD, 1976, TIME SERIES ANAL FOR; Atiya AF, 1999, IEEE T NEURAL NETWOR, V10, P402, DOI 10.1109/72.750569; BABOVIC V, 2000, 4 INT C HYDR IOW CIT; Chow TWS, 1996, IEEE T POWER SYST, V11, P1736, DOI 10.1109/59.544636; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANGELMAYR G, 1999, APPL SCI NEURAL NETW, V3821, P86; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fernandez-Rodriguez F, 1999, INT J FORECASTING, V15, P383, DOI 10.1016/S0169-2070(99)00003-5; GAUTAMA T, 2003, IEEE INT C AC SPEECH, V6, P29; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Marin FJ, 2002, IEE P-GENER TRANSM D, V149, P121, DOI 10.1049/ip-gtd:20020224; Meade N, 2002, INT J FORECASTING, V18, P67, DOI 10.1016/S0169-2070(01)00111-X; MULHERN FJ, 1994, INT J FORECASTING, V10, P191, DOI 10.1016/0169-2070(94)90002-7; OETKEN G, 1975, IEEE T ACOUST SPEECH, VAS23, P301, DOI 10.1109/TASSP.1975.1162686; Principe JC, 1998, P IEEE, V86, P2240, DOI 10.1109/5.726789; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; SAUER T, 1993, TIME SERIES PREDICTI, P175; Small M, 2004, PHYSICA D, V194, P283, DOI 10.1016/j.physd.2004.03.006; SMALL M, 2002, PHYS REV E, V66, P701; SMITH BL, 2000, IEEE INT TRANSP SYST; Takens F., 1981, LECT NOTES MATH, V898, P366; Taylor JW, 2002, IEEE T POWER SYST, V17, P626, DOI 10.1109/TPWRS.2002.800906; Weigend A, 1994, TIME SERIES PREDICTI	25	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2006	20	8					1261	1278		10.1142/S021800140600523X		18	Computer Science, Artificial Intelligence	Computer Science	133CG	WOS:000243988600008	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Large-scale predictions of gram-negative bacterial protein subcellular locations	JOURNAL OF PROTEOME RESEARCH			English	Article						gram-negative; subcellular compartment; gene ontology; amphiphilic pseudo amino acid composition; fusion; K-nearest neighbor rule	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; SECONDARY STRUCTURE; SORTING SIGNALS; NEURAL-NETWORKS; GENE ONTOLOGY; LOCALIZATION; SEQUENCE; CLASSIFICATION	Many species of Gram-negative bacteria are pathogenic bacteria that can cause disease in a host organism. This pathogenic capability is usually associated with certain components in Gram-negative cells. Therefore, developing an automated method for fast and reliabe prediction of Gram-negative protein subcellular location will allow us to not only timely annotate gene products, but also screen candidates for drug discovery. However, protein subcellular location prediction is a very difficult problem, particularly when more location sites need to be involved and when unknown query proteins do not have significant homology to proteins of known subcellular locations. PSORT-B, a recently updated version of PSORT, widely used for predicting Gram-negative protein subcellular location, only covers five location sites. Also, the data set used to train PSORT-B contains many proteins with high degrees of sequence identity in a same location group and, hence, may bear a strong homology bias. To overcome these problems, a new predictor, called "Gneg-PLoc", is developed. Featured by fusing many basic classifiers each being trained with a stringent data set containing proteins with strictly less than 25% sequence identity to one another in a same location group, the new predictor can cover eight subcellular locations; that is, cytoplasm, extracellular space, fimbrium, flagellum, inner membrane, nucleoid, outer membrane, and periplasm. In comparison with PSORT-B, the new predictor not only covers more subcellular locations, but also yields remarkably higher success rates. Gneg-PLoc is available as a Web server at http://202.120.37.186/bioinf/Gneg. To support the demand of people working in the relevant areas, a downloadable file is provided at the same Web site to list the results identified by Gneg-PLoc for 49 907 Gram-negative protein entries in the Swiss-Prot database that have no subcellular location annotations or are annotated with uncertain terms. The large-scale results will be updated twice a year to cover the new entries of Gram-negative bacterial proteins and reflect the new development of Gneg-PLoc.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2000, BIOCHIMIE, V82, P783, DOI 10.1016/S0300-9084(00)01161-5; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lee S, 2006, PROTEINS, V62, P1107, DOI 10.1002/prot.20821; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; MAO BY, 1994, PROTEIN ENG, V7, P319, DOI 10.1093/protein/7.3.319; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	56	77	79	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893		J PROTEOME RES	J. Proteome Res.	DEC 1	2006	5	12					3420	3428		10.1021/pr060404b		9	Biochemical Research Methods	Biochemistry & Molecular Biology	111CE	WOS:000242427800020	
J	Tripathi, S; Srinivas, VV; Nanjundiah, RS				Tripathi, Shivam; Srinivas, V. V.; Nanjundiah, Ravi S.			Dowinscaling of precipitation for climate change scenarios: A support vector machine approach	JOURNAL OF HYDROLOGY			English	Review						precipitation; downscaling; climate change; general circulation model (GCM); support vector machine; neural network; hydroclimatology; India	ARTIFICIAL NEURAL-NETWORKS; GENERAL-CIRCULATION MODEL; REGIONAL FLOOD FREQUENCY; INDIAN MONSOON RAINFALL; SENSITIVITY ANALYSIS; LOCAL PRECIPITATION; DOWNSCALING METHODS; CLUSTER-ANALYSIS; NEW-ZEALAND; GCM OUTPUT	The Climate impact studies in hydrology often rely on climate change information at fine spatial resolution. However, general circulation models (GCMs), which are among the most advanced tools for estimating future climate change scenarios, operate on a coarse scale. Therefore the output from a GCM has to be downscaled to obtain the information relevant to hydrologic studies. In this paper, a support vector machine (SVM) approach is proposed for statistical downscaling of precipitation at monthly time scale. The effectiveness of this approach is illustrated through its application to meteorological sub-divisions (MSDs) in India. First, climate variables affecting spatio-temporal variation of precipitation at each MSD in India are identified. Following this, the data pertaining to the identified climate variables (predictors) at each MSD are classified using cluster analysis to form two groups, representing wet and dry seasons. For each MSD, SVM-based downscaling model (DM) is developed for season(s) with significant rainfall using principal components extracted from the predictors as input and the contemporaneous precipitation observed at the MSD as an output. The proposed DM is shown to be superior to conventional downscaling using multi-layer back-propagation artificial neural networks. Subsequently, the SVM-based DM is applied to future climate predictions from the second generation Coupled Global Climate Model (CGCM2) to obtain future projections of precipitation for the MSDs. The results are then analyzed to assess the impact of climate change on precipitation over India. It is shown that SVMs provide a promising alternative to conventional artificial neural networks for statistical downscaling, and are suitable for conducting climate impact studies. (c) 2006 Elsevier B.V. All rights reserved.	Indian Inst Sci, Dept Civil Engn, Bangalore 560012, Karnataka, India; Indian Inst Sci, Ctr Atmospher & Ocean Sci, Bangalore 560012, Karnataka, India	Srinivas, VV (reprint author), Indian Inst Sci, Dept Civil Engn, Bangalore 560012, Karnataka, India.	vvs@civit.iisc.ernet.in					Arnell NW, 2003, J GEOPHYS RES-ATMOS, V108, DOI 10.1029/2002JD002782; ASCE, 2000, J HYDROL ENG, V5, P115, DOI DOI 10.1061/(ASCE)1084-0699(2000)5:2(115); ASCE Task Committee, 2000, J HYDROL ENG, V5, P124, DOI DOI 10.1061/(ASCE)1084-0699(2000)5:2(124); Asefa T, 2004, WATER RESOUR RES, V40, DOI 10.1029/2004WR003304; BHASKAR NR, 1989, J WATER RES PL-ASCE, V115, P793; Bianchini M, 1996, NEUROCOMPUTING, V13, P313, DOI 10.1016/0925-2312(95)00032-1; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bouraoui F, 1999, CLIM DYNAM, V15, P153, DOI 10.1007/s003820050274; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buma J, 2000, CLIMATE RES, V15, P69, DOI 10.3354/cr015069; BURN DH, 1989, J WATER RES PL-ASCE, V115, P567; Cannon AJ, 2002, INT J CLIMATOL, V22, P1687, DOI 10.1002/joc.811; Cannon AJ, 2002, J HYDROL, V259, P136, DOI 10.1016/S0022-1694(01)00581-9; Cavazos T, 1997, INT J CLIMATOL, V17, P1069, DOI 10.1002/(SICI)1097-0088(199708)17:10<1069::AID-JOC183>3.0.CO;2-I; CHHABARA BM, 1999, ADV TECHNOLOGIES MET, pCH5; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crane RG, 2002, HUM ECOL RISK ASSESS, V8, P147, DOI 10.1080/20028091056782; Crane RG, 1998, INT J CLIMATOL, V18, P65, DOI 10.1002/(SICI)1097-0088(199801)18:1<65::AID-JOC222>3.0.CO;2-9; CRISTIANININ, 2000, INTRO SUPPORT VECTOR; LAL M, 1995, CURR SCI INDIA, V69, P752; Dibike YB, 2001, J COMPUT CIVIL ENG, V15, P208, DOI 10.1061/(ASCE)0887-3801(2001)15:3(208); Faucher M, 1999, CLIMATE RES, V11, P173, DOI 10.3354/cr011173; Feng XT, 2004, INT J NUMER ANAL MET, V28, P1141, DOI 10.1002/nag.381; FIX E, 1951, 2149004 US AIR FORC, P261; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Georgakakos KP, 2001, J GEOPHYS RES-ATMOS, V106, P27367, DOI 10.1029/2001JD900125; Gestel T.V., 2004, MACH LEARN, V54, P5; GOVINDARAJU S, 2000, ARTIFICIAL NEURAL NE, P329; Hassan H, 1998, WATER SCI TECHNOL, V37, P177, DOI 10.1016/S0273-1223(98)00022-5; HAUPT RL, 2004, PRACTICAL GENETIC AL, P253; HAYKIN S, 2003, NEURAL NETWORKS COMP, P842; Hernandez-Espinosa C, 2004, LECT NOTES COMPUT SC, V3213, P677; HEWITSON BC, 1992, GEOPHYS RES LETT, V19, P1835, DOI 10.1029/92GL01423; Hewitson BC, 1996, CLIMATE RES, V7, P85, DOI 10.3354/cr007085; Hush DR, 1993, IEEE SIGNAL PROC MAG, V10, P8, DOI 10.1109/79.180705; Jasper K, 2004, CLIMATE RES, V26, P113, DOI 10.3354/cr026113; Kailas SV, 2000, CURR SCI INDIA, V78, P592; Kalnay E, 1996, B AM METEOROL SOC, V77, P437, DOI 10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2; Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855; Kettle H, 2004, CLIMATE RES, V26, P97, DOI 10.3354/cr026097; Khadam IM, 2004, WATER RESOUR RES, V40, DOI 10.1029/2003WR002939; Kim MK, 2004, INT J CLIMATOL, V24, P777, DOI 10.1002/joc.1029; Kottegoda N. T., 1998, STAT PROBABILITY REL; Leggett J., 1992, CLIMATE CHANGE 1992; LIN HT, 2003, STUD SIGMOID KERNELS; LISTER R, 1995, P IEEE INT C NEUR NE, P237; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; MAINI P, 2004, J HYDROL, V228, P170; Mangasarian OL, 1999, IEEE T NEURAL NETWOR, V10, P1032, DOI 10.1109/72.788643; McCarthy J. J., 2001, CLIMATE CHANGE 2001; Meireles MRG, 2003, IEEE T IND ELECTRON, V50, P585, DOI 10.1109/TIE.2003.812470; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Misson L, 2002, AGR FOREST METEOROL, V111, P265, DOI 10.1016/S0168-1923(02)00039-4; Mpelasoka FS, 2001, INT J CLIMATOL, V21, P1415, DOI 10.1002/joc.617; Neocleous C, 2002, LECT NOTES ARTIF INT, V2308, P300; Olsson J, 2004, J HYDROL ENG, V9, P1, DOI 10.1061/(ASCE)1084-0699(2004)9:1(1); Osborn TJ, 1997, J CLIMATE, V10, P1885, DOI 10.1175/1520-0442(1997)010<1885:DOARBS>2.0.CO;2; Pai PF, 2005, ELECTR POW SYST RES, V74, P417, DOI 10.1016/j.epsr.2005.01.006; PARTHASARATHY B, 1993, P INDIAN AS-EARTH, V102, P121; PARTHASARATHY B, 1994, THEOR APPL CLIMATOL, V49, P217, DOI 10.1007/BF00867461; Pasquariello G, 2002, INT GEOSCI REMOTE SE, P509; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Poulton MM, 2002, GEOPHYSICS, V67, P979, DOI 10.1190/1.1484539; Rupa Kumar K., 1994, Geophysical Research Letters, V21; Rupa Kumar K., 1992, International Journal of Climatology, V12; Sailor DJ, 2000, RENEW ENERG, V19, P359, DOI 10.1016/S0960-1481(99)00056-7; Sastry P. S., 2003, COMPUTING INFORM SCI; Schmidt M, 2003, CLIM RES, V25, P135, DOI 10.3354/cr025135; SCHOLKOPF B, 1998, ADV KERNAL METHODS S; Schoof JT, 2001, INT J CLIMATOL, V21, P773, DOI 10.1002/joc.655; Schwenk H, 2000, NEURAL COMPUT, V12, P1869, DOI 10.1162/089976600300015178; Shannon DA, 1996, S AFR J SCI, V92, P213; SHARMA C, 2003, P YEAR END WORKSH CL, P61; SHIVAM T, 2004, DOWNSCALING GEN CIRC; Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X; Snell SE, 2000, J CLIMATE, V13, P886, DOI 10.1175/1520-0442(2000)013<0886:SIOSAT>2.0.CO;2; Solecki WD, 2004, J ENVIRON MANAGE, V72, P105, DOI 10.1016/j.jenvman.2004.03.014; STONE JV, 1994, P IEEE INT C NEUR NE, P84; Suykens J. A. K., 2001, P IEEE INSTR MEAS TE, P287; Suykens J.A.K., 2002, LEAST SQUARES SUPPOR; Tatli H, 2004, INT J CLIMATOL, V24, P161, DOI 10.1002/joc.997; Trigo RM, 1999, CLIMATE RES, V13, P45, DOI 10.3354/cr013045; Turing A. M., 1950, MIND, V59, P236; VAPNIK V, 1992, ADV NEUR IN, V4, P831; Vapnik V.N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; VAPNIK VN, 1998, STAT LEARNIN THEORY; Weisse R, 2001, CLIMATE RES, V16, P123, DOI 10.3354/cr016123; Wilby RL, 1997, PROG PHYS GEOG, V21, P530, DOI 10.1177/030913339702100403; Wilby RL, 2000, INT J CLIMATOL, V20, P641, DOI 10.1002/(SICI)1097-0088(200005)20:6<641::AID-JOC501>3.0.CO;2-1; Wilby RL, 2004, GUIDELINES USE CLIMA; WILBY RL, 1998, J HYDROL, V213, P380; Wilby RL, 1998, WATER RESOUR RES, V34, P2995, DOI 10.1029/98WR02577; WILLMOTT CJ, 1985, AM CARTOGRAPHER, V12, P5; WILTSHIRE SE, 1986, HYDROLOG SCI J, V31, P335, DOI 10.1080/02626668609491052; Winkler JA, 1997, J CLIMATE, V10, P2514, DOI 10.1175/1520-0442(1997)010<2514:TSODTT>2.0.CO;2; Xu CY, 1999, PROG PHYS GEOG, V23, P229, DOI 10.1177/030913339902300204; Zhang B, 2000, WATER RESOUR RES, V36, P753, DOI 10.1029/1999WR900264; Zhang XC, 2004, SOIL SCI SOC AM J, V68, P1376; ZHENG C, 2004, IEEE C P 5 WORLD C I, P1869; *NRC, 1998, DEC TO CENT SCAL CLI	106	82	92	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694		J HYDROL	J. Hydrol.	NOV 15	2006	330	3-4					621	640		10.1016/j.jhydrot.2006.04.030		20	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	105IN	WOS:000242023700019	
J	Ho, MC; Lin, JJ; Chen, CN; Chen, CC; Lee, H; Yang, CY; Ni, YH; Chang, KJ; Hsu, HC; Hsieh, FJ; Lee, PH				Ho, Ming-Chih; Lin, Jen-Jen; Chen, Chiung-Nien; Chen, Chaur-Chin; Lee, Hsinyu; Yang, Ching-Yao; Ni, Yen-Hsuan; Chang, King-Jen; Hsu, Hey-Chi; Hsieh, Fon-Jou; Lee, Po-Huang			A gene expression profile for vascular invasion can predict the recurrence after resection of hepatocellular carcinoma: A microarray approach	ANNALS OF SURGICAL ONCOLOGY			English	Article						hepatocellular carcinoma; microarray; gene expression; profiling; vascular invasion; liver resection; recurrence	FETOPROTEIN MESSENGER-RNA; PROGNOSTIC-FACTORS; CDNA MICROARRAY; INTRAHEPATIC RECURRENCE; MULTIVARIATE-ANALYSIS; CURATIVE RESECTION; TUMOR-GROWTH; CANCER RISK; LIVER; METASTASIS	Background: Recurrence after hepatocellular carcinoma (HCC) resection is the major obstacle to improved survival. The presence of vascular invasion (VI) in pathology specimens is a well-known unfavorable prognostic factor for HCC recurrence. Though some VI-related genes have been reported, their association with recurrence-free survival is not known. We hypothesized that a gene expression profile for VI can predict the recurrence of HCC after liver resection. Methods: Eighteen patients receiving complete HCC resection were included as a "training group". Genome-wide gene expression profile was obtained for each tumor using a microarray technique. Datasets were subjected to clustering analysis supervised by the presence or absence of VI to obtain 14 discriminative genes. We then applied those genes to execute pattern recognition using the k-Nearest Neighbor (KNN) classification method, and the best model for this VI gene signature to predict recurrence-free survival in the training group was obtained. The resulting model was then tested in an independent "test group" of 35 patients. Results: A 14-gene profile was extracted which could accurately separate ten patients with VI and eight patients without VI in the "training group". In the "test group", significant difference in disease-free survival was found between patients predicted to have and not to have recurrence (P = .02823). In patients with stage_1 disease, this model can also predict outcomes (P = .000205). Conclusions: Using the 14-gene expression profile extracted from microarrays based on the presence of VI can effectively predict recurrence after HCC resection. This approach might facilitate "personalized medicine" for HCC patients after surgical resection.	Natl Taiwan Univ Hosp, Dept Surg, Taipei 100, Taiwan; Natl Taiwan Univ, Angiogenesis Res Ctr, Taipei 10764, Taiwan; Ming Chuan Univ, Dept Appl Stat & Informat Sci, Taipei, Taiwan; Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30043, Taiwan; Natl Taiwan Univ, Dept Life Sci, Taipei 10764, Taiwan; Natl Taiwan Univ Hosp, Dept Pediat, Taipei 10016, Taiwan; Natl Taiwan Univ Hosp, Dept Pathol, Taipei 100, Taiwan; Natl Taiwan Univ Hosp, Dept Obstet & Gynecol, Taipei 100, Taiwan	Lee, PH (reprint author), Natl Taiwan Univ Hosp, Dept Surg, 7 Chung Shan S Rd, Taipei 100, Taiwan.	pohuang@ha.mc.ntu.edu.tw					BARBARA L, 1992, HEPATOLOGY, V16, P132, DOI 10.1002/hep.1840160122; Chakraborty A, 2004, UROLOGY, V63, P177, DOI 10.1016/S0090-4295(03)00786-6; Chen X, 2002, MOL BIOL CELL, V13, P1929, DOI 10.1091/mbc.02-02-0023; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deli G, 2005, WORLD J GASTROENTERO, V11, P960; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; ESNAOLA N, 2003, ANN SURG, V238, P7119; Fan ST, 1999, ANN SURG, V229, P322, DOI 10.1097/00000658-199903000-00004; Fukuda S, 2005, HEPATO-GASTROENTEROL, V52, P1163; Hanazaki K, 2001, AM J GASTROENTEROL, V96, P1243; Hermanek P, 1993, TNM S; Hernandez-Rodriguez NA, 1999, LUNG CANCER-J IASLC, V26, P157, DOI 10.1016/S0169-5002(99)00077-X; Hochberg Y., 1987, MULTIPLE COMP PROCED; Honda M, 2001, GASTROENTEROLOGY, V120, P955, DOI 10.1053/gast.2001.22468; Hsu C, 2003, ONCOLOGY-BASEL, V65, P242, DOI 10.1159/000074477; Iizuka N, 2003, LANCET, V361, P923, DOI 10.1016/S0140-6736(03)12775-4; Ijichi M, 2002, HEPATOLOGY, V35, P853, DOI 10.1053/jhep.2002.32100; Ikai Iwao, 2003, Surg Oncol Clin N Am, V12, P65, DOI 10.1016/S1055-3207(02)00082-0; Imamura H, 2003, J HEPATOL, V38, P200, DOI 10.1016/S0168-8278(02)00360-4; Imamura H, 2003, ARCH SURG-CHICAGO, V138, P1198, DOI 10.1001/archsurg.138.11.1198; Jaeck Daniel, 2004, Liver Transpl, V10, pS58, DOI 10.1002/lt.20041; Kaneko S, 2002, ONCOLOGY-BASEL, V62, P69, DOI 10.1159/000048279; Kim IJ, 2004, HUM GENET, V115, P498, DOI 10.1007/s00439-004-1186-7; Macoska JA, 2002, CA-CANCER J CLIN, V52, P50; Mathew J, 1996, J PATHOL, V179, P74; Mengus G, 2005, EMBO J, V24, P2753, DOI 10.1038/sj.emboj.7600748; Mou DC, 2002, BRIT J CANCER, V86, P110, DOI 10.1038/sj.bjc.6600016; Mukunyadzi P, 2003, APPL IMMUNOHISTO M M, V11, P334; NIERODZIK MLR, 1992, CANCER RES, V52, P3267; Okabe H, 2001, CANCER RES, V61, P2129; Palumbo JS, 2001, HAEMOSTASIS, V31, P11; Park J, 2004, PHARMACOGENETICS, V14, P103, DOI 10.1097/01.fpc.0000054153.92680.a3; Park NH, 2001, J CLIN GASTROENTEROL, V33, P397, DOI 10.1097/00004836-200111000-00011; Patt YZ, 2003, J CLIN ONCOL, V21, P421, DOI 10.1200/JCO.2003.10.103; Patt YZ, 2000, AM J CLIN ONCOL-CANC, V23, P319, DOI 10.1097/00000421-200006000-00023; Shirota Y, 2001, HEPATOLOGY, V33, P832, DOI 10.1053/jhep.2001.23003; Sudo T, 2005, BRIT J CANCER, V92, P1754, DOI 10.1038/sj.bjc.6602531; Sun HC, 2003, WORLD J GASTROENTERO, V9, P635; Suzuki K, 1999, INT J ONCOL, V15, P1227; Tackels-Horne D, 2001, CANCER, V92, P395, DOI 10.1002/1097-0142(20010715)92:2<395::AID-CNCR1335>3.0.CO;2-U; Tahara K, 1999, CANCER, V85, P1234, DOI 10.1002/(SICI)1097-0142(19990315)85:6<1234::AID-CNCR4>3.0.CO;2-7; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Tsukino H, 2004, CANCER SCI, V95, P977, DOI 10.1111/j.1349-7006.2004.tb03186.x; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vauthey JN, 2002, J CLIN ONCOL, V20, P1527, DOI 10.1200/JCO.20.6.1527; Waguri N, 2003, CLIN CANCER RES, V9, P3004; Westfall PH, 1993, RESAMPLING BASED MUL; Wilkens Ludwig, 2002, J Hepatobiliary Pancreat Surg, V9, P304, DOI 10.1007/s005340200034; Witzigmann H, 2002, SURGERY, V131, P34, DOI 10.1067/msy.2002.118954; Xia JL, 1997, J CANCER RES CLIN, V123, P383, DOI 10.1007/s004320050075; Xu L, 2001, CANCER RES, V61, P3176; Xu XR, 2001, P NATL ACAD SCI USA, V98, P15089, DOI 10.1073/pnas.241522398; Yamanaka J, 2000, J GASTROEN HEPATOL, V15, P1192, DOI 10.1046/j.1440-1746.2000.02323.x; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	54	32	34	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1068-9265		ANN SURG ONCOL	Ann. Surg. Oncol.	NOV	2006	13	11					1474	1484		10.1245/s10434-006-9057-1		11	Oncology; Surgery	Oncology; Surgery	116KY	WOS:000242803000017	
J	Kapil, A; Gudi, RD; Noronha, SB				Kapil, Ankur; Gudi, Ravindra D.; Noronha, Santosh B.			Gene expression profile analysis using discrimination and fuzzy classification methods	ASIA-PACIFIC JOURNAL OF CHEMICAL ENGINEERING			English	Article						microarray; dimensionality; fuzzy simulator; classification	PATTERNS	There is a huge incentive for gene expression analysis and identification of biologically meaningful clusters from microarray data. However, the high dimensionality of the data poses challenges for this task. Here, to reduce this problem of irrelevant dimensions, we consider three different projection methods, viz. principal components analysis (PCA), correspondence analysis (CA), and multiple discriminant analysis (DA). To account for the possibility of pleiotropy, where the expression of certain genes may be related to more than one phenotypical condition, we use fuzzy clustering on the lower dimensional space generated by PCA, CA, and DA. Fuzzy clustering permits partial belonging of an attribute, such as gene expression, to different functionalities and hence is eminently suited for this task. To determine the optimum number of clusters, we evaluate various cluster validity indices. In this paper, we compare these methodologies when applied to the data generated by a genetic network simulator (eXPatGen) and also to the experimental micro array data available for yeast S. cerevisiae. (C) 2006 Curtin University of Technology and John Wiley & Sons, Ltd.	[Kapil, Ankur; Gudi, Ravindra D.; Noronha, Santosh B.] Indian Inst Technol, Dept Chem Engn, Bombay 400076, Maharashtra, India	Gudi, RD (reprint author), Indian Inst Technol, Dept Chem Engn, Bombay 400076, Maharashtra, India.	ravigudi@che.iitb.ac.in					Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; AZUAJE F, 2002, UNDERSTANDING USING; BABUSKA R, 2001, FUZZY NEURAL CONTROL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fellenberg K, 2001, P NATL ACAD SCI USA, V98, P10781, DOI 10.1073/pnas.181597298; Fischer RA, 1936, ANN EUGEN, V7, P179; FODOR SPA, 1993, NATURE, V364, P555, DOI 10.1038/364555a0; Gasch AP, 2002, GENOME BIOL, V3; Greenacre M.J, 1993, CORRESPONDENCE ANAL; JAIN A, 1999, ACM COMPUT SURV, V31, P267; KAO KC, 2003, P NATL ACAD SCI USA, V100, P15522; KRESTA JV, 1991, CAN J CHEM ENG, V69, P35; Michaud DJ, 2003, BIOINFORMATICS, V19, P1140, DOI 10.1093/bioinformatics/btg132; Park HS, 2004, LECT NOTES ARTIF INT, V3157, P967; PAVLIDIS P, 2001, P BIOKDD 2001 WORKSH, P15; Spellman PT, 1998, MOL BIOL CELL, V9, P3273; Vapnik V.N., 1998, STAT LEARNING THEORY; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhao LP, 2001, P NATL ACAD SCI USA, V98, P5631, DOI 10.1073/pnas.101013198	20	0	0	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1932-2143		ASIA-PAC J CHEM ENG	Asia-Pac. J. Chem. Eng.	NOV-DEC	2006	1	1-2					110	121		10.1002/apj.012		12	Engineering, Chemical	Engineering	290NB	WOS:000255128400014	
J	Plaza, E; Ontanon, S				Plaza, Enric; Ontanon, Santiago			Learning collaboration strategies for committees of learning agents	AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS			English	Article						multi-agent learning; committees; meta learning; case based reasoning		A main issue in cooperation in multi-agent systems is how an agent decides in which situations is better to cooperate with other agents, and with which agents does the agent cooperate. Specifically in this paper we focus on multi-agent systems composed of learning agents, where the goal of the agents is to achieve a high accuracy on predicting the correct solution of the problems they encounter. For that purpose, when encountering a new problem each agent has to decide whether to solve it individually or to ask other agents for collaboration. We will see that learning agents can collaborate forming committees in order to improve performance. Moreover, in this paper we will present a proactive learning approach that will allow the agents to learn when to convene a committee and with which agents to invite to join the committee. Our experiments show that learning results in smaller committees while maintaining (and sometimes improving) the problem solving accuracy than forming committees composed of all agents.	CSIC, Artificial Intelligence Res Inst, IIIA, Spanish Counsel Sci Res, Bellaterra 08193, Catalonia, Spain	Ontanon, S (reprint author), Univ Barcelona, Dept Appl Math, MAiA, Gran Via 585, E-08007 Barcelona, Spain.	enric@iiia.csic.es; santi@iiia.csic.es					AAMODT A, 1994, AI COMMUN, V7, P39; Aha D.W., 1997, LAZY LEARNING; Brams S.J., 1983, APPROVAL VOTING; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CESTNIK B, 1991, LECT NOTES ARTIF INT, V482, P151; Chan PK, 1995, P 12 INT C MACH LEAR, P90; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIGNUM F, 2001, LECT NOTES COMPUTER, P150; Dutta P. S., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems; ESTEVA M, IN PRESS INTELLIGENT, V8; ESTEVA M, 2001, LNAI, V1991; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GAMA J, 1998, P 15 INT C MACH LEAR, P206; GOMEZ M, 2004, P 3 INT JOINT C AUT, P144; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; LEAKE D, 2002, P 15 FLAIRS C MENL P, P106; LEAKE DB, 2001, ICCBR, P321; Mc Ginty L, 2001, LECT NOTES ARTIF INT, V2080, P362; ONTANON S, 2006, IN PRESS P AAMAS 06; Ontanon S, 2003, LECT NOTES ARTIF INT, V2689, P392; ONTANON S, 2002, 1 INT JOINT C AUT AG; ONTANON S, 2003, INT C MACH LEARN, P576; Ontanon S, 2002, LECT NOTES ARTIF INT, V2430, P331; ONTANON S, 2005, P 22 INT C MACH LEAR, P633, DOI 10.1145/1102351.1102431; Ontanon S., 2005, THESIS U AUTONOMA BA; PERRONE M, 1993, ARTIFICIAL NEURAL NE; Plaza E, 2001, LECT NOTES ARTIF INT, V2080, P437; Plaza E, 2003, LECT NOTES ARTIF INT, V2636, P1; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Wolpert D. H., 1990, LAUR903460; WOOLDRIDGE M, 1994, P 6 EUR WORKSH MOD A, P15	31	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1387-2532		AUTON AGENT MULTI-AG	Auton. Agents Multi-Agent Syst.	NOV	2006	13	3					429	461		10.1007/s10458-006-0015-x		33	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	081KM	WOS:000240316500006	
J	Joseph, A; Fenton, NE; Neil, M				Joseph, A.; Fenton, N. E.; Neil, M.			Predicting football results using Bayesian nets and other machine learning techniques	KNOWLEDGE-BASED SYSTEMS			English	Article						Bayesian nets; machine learning; football		Bayesian networks (BNs) provide a means for representing, displaying, and making available in a usable form the knowledge of experts in a given field. In this paper, we look at the performance of an expert constructed BN compared with other machine learning (ML) techniques for predicting the outcome (win, lose, or draw) of matches played by Tottenham Hotspur Football Club. The period under study was 1995-1997 - the expert BN was constructed at the start of that period, based almost exclusively on subjective judgement. Our objective was to determine retrospectively the comparative accuracy of the expert BN compared to some alternative ML models that were built using data from the two-year period. The additional ML techniques considered were: MC4, a decision tree learner; Naive Bayesian learner; Data Driven Bayesian (a BN whose structure and node probability tables are learnt entirely from data); and a K-nearest neighbour learner. The results show that the expert BN is generally superior to the other techniques for this domain in predictive accuracy. The results are even more impressive for BNs given that, in a number of key respects, the study assumptions place them at a disadvantage. For example, we have assumed that the BN prediction is 'incorrect' if a BN predicts more than one outcome as equally most likely (whereas, in fact, such a prediction would prove valuable to somebody who could place an 'each way' bet on the outcome). Although the expert BN has now long been irrelevant (since it contains variables relating to key players who have retired or left the club) the results here tend to confirm the excellent potential of BNs when they are built by a reliable domain expert. The ability to provide accurate predictions without requiring much learning data are an obvious bonus in any domain where data are scarce. Moreover, the BN was relatively simple for the expert to build and its structure could be used again in this and similar types of problems. (c) 2006 Elsevier B.V. All rights reserved.	Univ London Queen Mary Coll, Comp Sci Dept, London, England	Joseph, A (reprint author), Univ London Queen Mary Coll, Comp Sci Dept, London, England.	adrianj@dcs.qmul.ac.uk; norman@dcs.qmul.ac.uk; martin@dcs.qmul.ac.uk					BRADLEY A, 1994, AUSTR NZ C INT INF S, P37; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FENTON NE, 2002, IEEE SOFTWARE, V10, P116; FENTON NE, 2000, B IMA, V36, P180; JOSEPH A, 2005, PREDICTING FOOTBALL; KOHAVI R, 1996, MLC MACHINE LEARNING; MITCHELL TM, 1997, MACHINE LEARNIGN; NEIL M, 2001, IEE COMPUTING CONTRO, V12, P11; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; RUE H, 1997, PREDICTION RETROSPEC, V10	12	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051		KNOWL-BASED SYST	Knowledge-Based Syst.	NOV	2006	19	7					544	553		10.1016/j.knosys.2006.04.011		10	Computer Science, Artificial Intelligence	Computer Science	113ZQ	WOS:000242636900011	
J	Huang, CC				Huang, Chi-Chun			A novel gray-based reduced NN classification method	PATTERN RECOGNITION			English	Article						gray-based reduced NN classification method; instance pruning; gray relational structure; instance-based learning; pattern classification	NEAREST-NEIGHBOR RULE; PATTERN-CLASSIFICATION; LEARNING ALGORITHMS; PROTOTYPES; ABSTRACTION; PERFORMANCE; CLASSIFIERS; REDUCTION	In pattern recognition, instance-based learning (also known as nearest neighbor rule) has become increasingly popular and can yield excellent performance. In instance-based learning, however, the storage of training set rises along with the number of training instances. Moreover, in such a case, a new, unseen instance takes a long time to classify because all training instances have to be considered when determining the 'nearness' or 'similarity' among instances. This study presents a novel reduced classification method for instance-based learning based on the gray relational structure. Here, only some training instances in the original training set are adopted for the pattern classification tasks. The relationships among instances are first determined according to the gray relational structure. In the relational structure, the inward edoes of each training instance, indicating how many times each instance is considered as the nearest neighbor or neighbors in determining the class labels of other instances can be obtained. This method excludes training instances with no or few inward edges for the pattern classification tasks. By using the proposed instance pruning approach, new instances can be classified with a few training instances. Nine data sets are adopted to demonstrate the performance of the proposed learning approach. Experimental results indicate that the classification accuracy can be maintained when most of the training instances are pruned before learning. Additionally, the number of remained training instances in the proposal presented here is comparable to that of other existing instance pruning techniques. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, 142 Hai Jhuan Rd,Nanzih Dist, Kaohsiung 811, Taiwan.	cchuang@mail.nkmu.edu.tw					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; BRODER AZ, 1985, IEEE T SYST MAN CYB, V15, P136; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 2000, P 15 INT C PATT REC, P2692; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Deng Julong, 1989, Journal of Grey Systems, V1; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; EICK C, 2004, P 4 INT C DAT MIN, P375; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FIX E, 1951, 2149004 USAF SCH AVI; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; HUANG CC, IN PRESS APPL INTELL; Arshadi N, 2005, IEEE T KNOWL DATA EN, V17, P1127, DOI 10.1109/TKDE.2005.124; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LEFEVRE F, 1999, P EUROSPEECH 99, P2733; LIN CT, 1999, J GREY SYSTEM, V4, P359; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SANCHEZ JS, 2004, P INT C SYST MAN CYB, P4757; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang J., 1992, P 9 INT MACH LEARN C, P470; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	43	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	2006	39	11					1979	1986		10.1016/j.patcog.2006.05.013		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	079DU	WOS:000240156500003	
J	Gao, QB; Wang, ZZ				Gao, Qing-Bin; Wang, Zheng-Zhi			Classification of G-protein coupled receptors at four levels	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINE; STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; FAST FOURIER-TRANSFORM; SUBCELLULAR LOCATION; HYBRIDIZATION SPACE; PSEAA PREDICTOR; GENE ONTOLOGY; SEQUENCES	G-protein coupled receptors (GPCRs) are transmembrane proteins which via G-proteins initiate some of the important signaling pathways in a cell and are involved in various physiological processes. Thus, computational prediction and classification of GPCRs can supply significant information for the development of novel drugs in pharmaceutical industry. In this paper, a nearest neighbor method has been introduced to discriminate GPCRs from non-GPCRs and subsequently classify GPCRs at four levels on the basis of amino acid composition and dipeptide composition of proteins. Its performance is evaluated on a non-redundant dataset consisted of 1406 GPCRs for six families and 1406 globular proteins using the jackknife test. The present method based on amino acid composition achieved an overall accuracy of 96.4% and Matthew's correlation coefficient (MCC) of 0.930 for correctly picking out the GPCRs from globular proteins. The overall accuracy and MCC were further enhanced to 99.8% and 0.996 by dipeptide composition-based method. On the other hand, the present method has successfully classified 1406 GPCRs into six families with an overall accuracy of 89.6 and 98.8% using amino acid composition and dipeptide composition, respectively. For the subfamily prediction of 1181 GPCRs of rhodopsin-like family, the present method achieved an overall accuracy of 76.7 and 94.5% based on the amino acid composition and dipeptide composition, respectively. Finally, GPCRs belonging to the amine subfamily and olfactory subfamily of rhodopsin-like family were further analyzed at the type level. The overall accuracy of dipeptide composition-based method for the classification of amine type and olfactory type of GPCRs reached 94.5 and 86.9%, respectively, while the overall accuracy of amino acid composition-based method was very low for both subfamilies. In comparison with existing methods in the literature, the present method also displayed great competitiveness. These results demonstrate the effectiveness of our method on identifying and classifying GPCRs correctly. GPCRsIdentifier, a corresponding stand-alone executable program for GPCR identification and classification was also developed, which can be acquired freely on request from the authors for academic purposes.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China.	qbgao@nudt.edu.cn	Gao, Qing-Bin/G-9825-2011				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; BALDWIN JM, 1994, CURR OPIN CELL BIOL, V6, P180, DOI 10.1016/0955-0674(94)90134-1; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bhasin M, 2005, NUCLEIC ACIDS RES, V33, pW143, DOI 10.1093/nar/gki351; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2005, BIOCHEM BIOPH RES CO, V327, P845, DOI 10.1016/j.bbrc.2004.12.069; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 2004, BIOCHEM BIOPH RES CO, V325, P506, DOI 10.1016/j.bbrc.2004.10.058; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2005, J PROTEOME RES, V4, P1681, DOI 10.1021/pr050145a; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Guo YZ, 2005, ACTA BIOCH BIOPH SIN, V37, P759, DOI 10.1111/j.1745-7270.2005.00110.x; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Horn F, 2003, NUCLEIC ACIDS RES, V31, P294, DOI 10.1093/nar/gkg103; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, COMPUT BIOL CHEM, V28, P275, DOI 10.1016/j.compbiolchem.2004.08.001; Inoue Y, 2004, COMPUT BIOL CHEM, V28, P39, DOI 10.1016/j.compbiolchem.2003.11.003; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Kim S, 2004, BIOINFORMATICS, V20, P40, DOI 10.1093/bioinformatics/btg368; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Li WZ, 2002, BIOINFORMATICS, V18, P77, DOI 10.1093/bioinformatics/18.1.77; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Papasaikas PK, 2004, NUCLEIC ACIDS RES, V32, pW380, DOI 10.1093/nar/gkh431; Pearson W R, 2000, Methods Mol Biol, V132, P185; Qian B, 2003, FEBS LETT, V554, P95, DOI 10.1016/S0014-5793(03)01112-8; Sadowski MI, 2003, BIOINFORMATICS, V19, P727, DOI 10.1093/bioinformatics/btg075; SPIEGEL AM, 1992, ENDOCR REV, V13, P536, DOI 10.1210/er.13.3.536; STRADER CD, 1994, ANNU REV BIOCHEM, V63, P101, DOI 10.1146/annurev.biochem.63.1.101; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Teller DC, 2001, BIOCHEMISTRY-US, V40, P7761, DOI 10.1021/bi0155091; Vaidehi N, 2002, P NATL ACAD SCI USA, V99, P12622, DOI 10.1073/pnas.122357199; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Xiao ZJ, 2006, LEUKEMIA RES, V30, P54, DOI 10.1016/j.leukres.2005.05.012; Yabuki Y, 2005, NUCLEIC ACIDS RES, V33, pW148, DOI 10.1093/nar/gki; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	56	60	60	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126		PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	NOV	2006	19	11					511	516		10.1093/protein/gzl038		6	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	097DE	WOS:000241426000005	
J	Viswanath, P; Murty, MN; Bhatnagar, S				Viswanath, P.; Murty, M. Narasimha; Bhatnagar, Shalabh			Partition based pattern synthesis technique with efficient algorithms for nearest neighbor classification	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbor classifier; pattern synthesis; artificial patterns; curse of dimensionality	ERROR RATE ESTIMATION; BOOTSTRAP; CLASSIFIERS; FEATURES	Nearest neighbor (NN) classifier is a popular non-parametric classifier. It is conceptually a simple classifier and shows good performance. Due to the curse of dimensionality effect, the size of training set needed by it to achieve a given classification accuracy becomes prohibitively large when the dimensionality of the data is high. Generating artificial patterns can reduce this effect. In this paper, we propose a novel pattern synthesis method called partition based pattern synthesis which can generate an artificial training set of exponential order when compared with that of the given original training set. We also propose suitable faster NN based methods to work with the synthetic training patterns. Theoretically, the relationship between our methods and conventional NN methods is established. The computational requirements of our methods are also theoretically established. Experimental results show that NN based classifiers with synthetic training set can outperform conventional NN classifiers and some other related classifiers. (c) 2006 Elsevier B.V. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India	Bhatnagar, S (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	viswanath@iitg.ernet.in; mnm@csa.iisc.ernet.in; shalabh@csa.iisc.ernet.in					Ananthanarayana VS, 2001, PATTERN RECOGN, V34, P2249, DOI 10.1016/S0031-3203(01)00028-0; Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; Babu TR, 2005, LECT NOTES COMPUT SC, V3776, P595; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 11 USAF SCH AV MED; FODOR IK, 2002, UCRLID148494 L LIV N; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Fukunaga K., 1990, INTRO STAT PATTERN R; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Murphy P., 1994, UCI REPOSITORY MACHI; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516	21	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	OCT 15	2006	27	14					1714	1724		10.1016/j.patrec.2006.04.015		11	Computer Science, Artificial Intelligence	Computer Science	085ZP	WOS:000240643200014	
J	Chindaro, S; Sirlantzis, K; Fairhurst, MC				Chindaro, S.; Sirlantzis, K.; Fairhurst, M. C.			ICA-based multi-colour space texture classification system	ELECTRONICS LETTERS			English	Article							FUSION	Presented is a novel method which uses independent component analysis (ICA) for systematically partitioning and combining textural features extracted from different colour spaces, in a multiple classifier based system, for colour texture classification. Results obtained illustrate that the proposed ICA-based feature-partitioning and classifier combination system produces more accurate results compared to a system that combines classifiers applied to features extracted from individual colour spaces.	Univ Kent, Dept Elect, Canterbury CT2 7NT, Kent, England	Chindaro, S (reprint author), Univ Kent, Dept Elect, Canterbury CT2 7NT, Kent, England.	S.Chindaro@kent.ac.uk					Chindaro S, 2005, ELECTRON LETT, V41, P589, DOI 10.1049/el:20050594; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duin R.P.W., 2004, PRTOOLS4 MATLAB TOOL; Fairhurst MC, 2000, IEE P-VIS IMAGE SIGN, V147, P39, DOI 10.1049/ip-vis:20000105; HAVARINEN A, 2001, INDEPENDENT COMPONEN; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; Sangwine S.J., 1998, COLOUR IMAGE PROCESS; Skurichina M, 2005, LECT NOTES COMPUT SC, V3541, P165	9	1	1	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194		ELECTRON LETT	Electron. Lett.	OCT 12	2006	42	21					1208	1210		10.1049/el:20062197		3	Engineering, Electrical & Electronic	Engineering	108IL	WOS:000242233400011	
J	Zhen, L; Zhong, J				Zhen Lou; Zhong Jin			A novel adaptive hit-distance for pattern recognition	CHINESE JOURNAL OF ELECTRONICS			English	Article						biomimetic pattern recognition; machine learning; nearest neighbor classifier; hit-distance; pattern recognition	FACE RECOGNITION; NEAREST; CLASSIFICATION; CLASSIFIERS	The better the matter is understood, the better the distance between any given point and the matter subspace can be defined, and vice verse. In this paper, a novel idea of distance, Hit-Distance, was proposed to generalize the representational capacity of available prototypes. It is more reasonable to utilize the proposed hit-distance to describe the distance between any given point and any matter subspace. The effectiveness of the proposed distance was indirectly evaluated by some experiments of matter classifications. Experiments were performed on 8 benchmark datasets from the UCI Machine Learning Repository. It was shown that the hit-distance based classifiers performed much better than the classical nearest neighbor classifier (NN), the Nearest feature line method (NFL) and the Nearest feature plane method (NFP).	Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China; Univ Autonoma Barcelona, Ctr Visio Computador, E-08193 Barcelona, Spain	Zhen, L (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; Fukunaga K., 1990, INTRO STAT PATTERN R; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Newman D. J., 1998, UCI REPOSITORY MACHI; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; Wang Shou-jue, 2002, Acta Electronica Sinica, V30; WANG SJ, 2005, INT C NEUR NETW BRAI, V3, P1487; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	10	0	0	TECHNOLOGY EXCHANGE LIMITED HONG KONG	SHATIN	26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN, 00000, PEOPLES R CHINA	1022-4653		CHINESE J ELECTRON	Chin. J. Electron.	OCT	2006	15	4A					793	796				4	Engineering, Electrical & Electronic	Engineering	103XJ	WOS:000241920200006	
J	Tahir, MA; Bouridane, A				Tahir, Muhammad Atif; Bouridane, Ahmed			Novel round-robin tabu search algorithm for prostate cancer classification and diagnosis using multispectral imagery	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						feature selection; multispectral images; nearest neighbor (1NN) classifier; prostate cancer diagnosis; round-robin (RR) classification; tabu search (TS)	FEATURE-SELECTION; GENETIC ALGORITHMS; CHROMATIN TEXTURE; CARCINOMA; FEATURES; ADENOCARCINOMA; CLASSIFIERS; BIOPSY; TISSUE	Quantitative cell imagery in cancer pathology has progressed greatly in the last 25 years. The application areas are mainly those in which the diagnosis is still critically reliant upon the analysis of biopsy samples, which remains the only conclusive method for making an accurate diagnosis of the disease. Biopsies are usually analyzed by a trained pathologist who, by analyzing the biopsies under a microscope, assesses the normality or malignancy of the samples submitted. Different grades of malignancy correspond to different structural patterns as well as to apparent textures. In the case Of prostate cancer, four major groups have to be recognized: stroma, benign prostatic hyperplasia, prostatic intraepithelial neoplasia, and prostatic carcinoma. Recently, multispectral imagery has been used to solve this multiclass problem. Unlike conventional RGB color space, multispectral images allow the acquisition of a large number of spectral bands within the visible spectrum, resulting in a large feature vector size. For such a high dimensionality, pattern recognition techniques suffer from the well-known "curse-of-dimensionality" problem. This paper proposes a novel round-robin tabu search (RR-TS) algorithm to address the curse-of-dimensionality for this multiclass problem. The experiments have been carried out on a number of prostate cancer textured multispectral images, and the results obtained have been assessed and compared with previously reported works. The system achieved 98%-100% classification accuracy when testing on two datasets. It outperformed principal component/linear discriminant classifier (PCA-LDA), tabu search/nearest neighbor classifier (TS-1NN), and bagging/boosting with decision tree (C4.5) classifier.	Univ W England, Fac Comp Engn & Math Sci, Bristol BS16 1QY, Avon, England; Queens Univ Belfast, Sch Elect Elect & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Tahir, MA (reprint author), Univ W England, Fac Comp Engn & Math Sci, Bristol BS16 1QY, Avon, England.	muhammad.tahir@uwe.ac.uk; a.bouridane@qub.ac.uk					Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1; Barshack I, 1999, BRIT J CANCER, V79, P1613, DOI 10.1038/sj.bjc.6690257; Bartels PH, 1998, ANAL QUANT CYTOL, V20, P389; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHRISTEN R, 1993, ANAL QUANT CYTOL, V15, P383; Clark GA, 2000, IEEE T GEOSCI REMOTE, V38, P304, DOI 10.1109/36.823923; CLARK TD, 1987, PROSTATE, V10, P199, DOI 10.1002/pros.2990100303; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Davies S, 1994, P 1994 AAAI FALL S R, P37; Duda R. O., 2001, PATTERN CLASSIFICATI; EBLE JN, 1996, UROLOGIC SURG PATHOL; Efron B., 1993, INTRO BOOTSTRAP; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Fukunaga K., 1990, INTRO STAT PATTERN R; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1989, ORSA Journal on Computing, V1; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jimenez LO, 1998, IEEE T SYST MAN CY C, V28, P39, DOI 10.1109/5326.661089; KHAN SA, 2002, ENG APPL ARTIF INTEL, P327; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LARSH P, 2002, TECHNOL CANCER RES T, V1, P1; LIU YX, 2002, P INT C INT INF TECH, P169; MINIMO C, 1994, ANAL QUANT CYTOL, V16, P307; MOHLER JL, 1994, ANAL QUANT CYTOL, V16, P415; PITTS DE, 1993, P SPIE MED IMAGING P, P456; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Roula M., 2002, P IEEE INT S BIOM IM, p193 , DOI 10.1109/ISBI.2002.1029226; ROULA MA, 2003, P 7 INT S SIGN PROC, P37; SAIT SM, 2000, ITERATIVE COMPUTER A; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tahir MA, 2004, INT C PATT RECOG, P335, DOI 10.1109/ICPR.2004.1334201; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; YONGGUANG B, LECT NOTES COMPUTER, V3177; Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; Zimmerman H. J., 1996, FUZZY SET THEORY ITS	45	10	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	OCT	2006	10	4					782	793		10.1109/TITB.2006.879596		12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	092VH	WOS:000241124900016	
J	Ghosh, AK; Chaudhuri, P; Murthy, CA				Ghosh, Anil K.; Chaudhuri, Probal; Murthy, C. A.			Multiscale classification using nearest neighbor density estimates	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						bootstrap; cross validation; misclassification rate; multiscale analysis; posterior probability; p-value; weighted averaging	SCALE-SPACE; VISUALIZATION; CLASSIFIERS; VIEW	Density estimates based on k-nearest neighbors have useful applications in nonparametric discriminant analysis. In classification problems, optimal values of k are usually estimated by minimizing the cross-validated misclassification rates. However, these cross-validation techniques allow only one value of k for each population density estimate, while in a classification problem, the optimum value of k for a class may also depend on its competing population densities. Further, it is computationally difficult to minimize the cross-validated error rate when there are several competing populations. Moreover, in addition to depending on the entire training data set, a good choice of k should also depend on the specific observation to be classified. Therefore, instead of using a single value of k for each population density estimate, it is more useful in practice to consider the results for multiple values of k to arrive at the final decision. This paper presents one such approach along with a graphical device, which gives more information about classification results for various choices of k and the related statistical uncertainties present there. The utility of this proposed methodology has been illustrated I using some benchmark data sets.	Australian Natl Univ, Inst Math Sci, Ctr Math & Its Applicat, Canberra, ACT 0200, Australia; Indian Stat Inst, Theoret Stat & Math Univ, Calcutta 700108, India; Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, India	Ghosh, AK (reprint author), Australian Natl Univ, Inst Math Sci, Ctr Math & Its Applicat, Canberra, ACT 0200, Australia.	anilkghosh@rediffmail.com; probal@isical.ac.in; murthy@isical.ac.in					Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Efron B., 1993, INTRO BOOTSTRAP; Fix E., 1951, DISCRIMINATORY ANAL, P261; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J, 1996, ANOTHER APPROACH POL; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; Ghosh AK, 2006, TECHNOMETRICS, V48, P120, DOI 10.1198/004017005000000391; Gilks W.R., 1996, MARKOV CHAIN MONTE C; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; Hastie T, 1998, ANN STAT, V26, P451; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; McCullagh P., 1989, GEN LINEAR MODELS; Newman D. J., 1998, UCI REPOSITORY MACHI; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Ripley B. D., 1996, PATTERN RECOGNITION; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scott D. W., 1992, MULTIVARIATE DENSITY; Serfling R. J, 1980, APPROXIMATION THEORE; SHALAK DB, 1996, THESIS U MASSACHUSET; Silverman B.W., 1986, DENSITY ESTIMATION S; STONE M, 1977, BIOMETRIKA, V64, P29, DOI 10.1093/biomet/64.1.29; Wichern D. W., 1992, APPL MULTIVARIATE ST; Yager RR, 2002, IEEE T SYST MAN CY B, V32, P512, DOI 10.1109/TSMCB.2002.1018770; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	34	5	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2006	36	5					1139	1148		10.1109/TSMCB.2006.873186		10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	087QI	WOS:000240756700014	
J	Chang, F; Lin, CC; Lu, CJ				Chang, Fu; Lin, Chin-Chin; Lu, Chi-Jen			Adaptive prototype learning algorithms: Theoretical and experimental studies	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						adaptive prototype learning; cluster-based prototypes; consistency; instance-based prototype; pattern classification	ORDERED RISK MINIMIZATION; SUPPORT VECTOR MACHINES; REGRESSION; CLASSIFICATION	In this paper, we propose a number of adaptive prototype learning (APL) algorithms. They employ the same algorithmic scheme to determine the number and location of prototypes, but differ in the use of samples or the weighted averages of samples as prototypes, and also in the assumption of distance measures. To understand these algorithms from a theoretical viewpoint, we address their convergence properties, as well as their consistency under certain conditions. We also present a soft version of APL, in which a non-zero training error is allowed in order to enhance the generalization power of the resultant classifier. Applying the proposed algorithms to twelve UCI benchmark data sets, we demonstrate that they outperform many instance-based learning algorithms, the k-nearest neighbor rule, and support vector machines in terms of average test accuracy.	Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan; Natl Taipei Univ Technol, Dept Elect Engn, Taipei, Taiwan	Chang, F (reprint author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.	FCHANG@IIS.SINICE.EDU.TW; ERIKSON@IIS.SINICA.EDU.TW; CJLU@IIS.SINICA.EDU.TW					Bartlett P., 1999, ADV KERNEL METHODS S; Bezdek J., 1981, PATTERN RECOGNITION; BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cortes C, 1995, MACH LEARN, V20, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Devi VS, 2002, PATTERN RECOGN, V35, P505; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Devroye L.P., 1985, NONPARAMETRIC DENSIT; Fix E., 1951, 4 USAF SCH AV MED; FIX E, 1991, NEAREST NEIGHBOR PAT; Fix E., 1952, 11 USAF SCH AV MED; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hoppner F., 1999, FUZZY CLUSTER ANAL M; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kim DW, 2005, PATTERN RECOGN, V38, P607, DOI 10.1016/j.patchog.2004.09.006; Knerr S., 1990, NEUROCOMPUTING ALGOR; Kohonen T., 1988, SELF ORG ASS MEMORY; KOHONEN T, 1990, ADVANCED NEURAL COMPUTERS, P137; LINDE Y, 1980, PATTERN RECOGN, V19, P84; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; MAX J, 1960, IRE T INFORM THEOR, V6, P7, DOI 10.1109/TIT.1960.1057548; MERCER T, 1909, PHILOS T R SOC A, V209, P415; Newman D. J., 1998, UCI REPOSITORY MACHI; Platt JC, 2000, ADV NEUR IN, V12, P547; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Scholkopf B., 1999, ADV KERNEL METHODS S; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; VAPNIK VN, 1974, AUTOMAT REM CONTR+, V35, P1226; VAPNIK VN, 1974, AUTOMAT REM CONTR+, V35, P1403; Vapnik V.N., 1995, NATURE STAT LEARNING; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wu Z., 2003, 5 INT C COMP INT MUL, P1; ZHAO LC, 1987, J MULTIVARIATE ANAL, V21, P168, DOI 10.1016/0047-259X(87)90105-9	38	8	8	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	OCT	2006	7						2125	2148				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152VQ	WOS:000245390500007	
J	Model, D; Zibulevsky, M				Model, Dmitri; Zibulevsky, Michael			Learning subject-specific spatial and temporal filters for single-trial EEG classification	NEUROIMAGE			English	Article						EEG; brain-computer interface; classification; spatial filters	HAND MOVEMENT; DISCRIMINATION; COMPETITION; DEVICE	There are a wide variety of electroencephalography (EEG) analysis methods. Most of them are based on averaging over multiple trials in order to increase signal-to-noise ratio. The method introduced in this article is a single trial method. Our approach is based on the assumption that the "response of interest" to each task is smooth, and is contained in several sensor channels. We propose a two-stage preprocessing method. In the first stage, we apply spatial filtering by taking weighted linear combinations of the sensor measurements. In the second stage, we perform time-domain filtering. In both steps, we derive filters that maximize a class dissimilarity measure subject to regularizing constraints on the total variation of the average estimated signal (or, alternatively, on the signal's strength in time intervals where it is known to be absent). No other spatial or spectral assumptions with regard to the anatomy or sources were made. (c) 2006 Elsevier Inc. All rights reserved.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Model, D (reprint author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	dmm@tx.technion.ac.il; mzib@ee.technion.ac.il					Anderson CW, 1998, IEEE T BIO-MED ENG, V45, P277, DOI 10.1109/10.661153; Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193; Bigman ZB, 2004, BIOL PSYCHOL, V66, P99, DOI 10.1016/j.biopsycho.2003.10.003; Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; Blankertz B, 2002, ADV NEUR IN, V14, P157; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chen Y, 1998, NONCON OPTIM ITS APP, V20, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; DUIN RP, 2000, PROTOOLS PATTERN REC; KALCHER J, 1996, MED BIOL ENG COMPUT, V34, P383; Kubler A, 1999, EXP BRAIN RES, V124, P223, DOI 10.1007/s002210050617; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8; Obermaier B, 2001, IEEE T NEUR SYS REH, V9, P283, DOI 10.1109/7333.948456; Parra L, 2002, NEUROIMAGE, V17, P223, DOI 10.1006/nimg.2002.1212; Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Sajda P, 2003, IEEE T NEUR SYS REH, V11, P184, DOI 10.1109/TNSRE.2003.814453; VIDAL J, 1973, ANNU REV BIOPHYS BIO, P157; WOLPAW JR, 1991, CLIN NEUROPHYSIOL, V78, P252; WOLPAW JR, 1997, CLIN NEUROPHYSIOL, V146, P529; Zibulevsky M, 2002, NEUROCOMPUTING, V49, P163, DOI 10.1016/S0925-2312(02)00515-5	24	6	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1053-8119		NEUROIMAGE	Neuroimage	OCT 1	2006	32	4					1631	1641		10.1016/j.neuroimage.2006.04.224		11	Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	090RR	WOS:000240969200012	
J	Vijaya, PA; Murty, MN; Subramanian, DK				Vijaya, P. A.; Murty, M. Narasimha; Subramanian, D. K.			Efficient median based clustering and classification techniques for protein sequences	PATTERN ANALYSIS AND APPLICATIONS			English	Article						clustering; protein sequences; median strings; sequences; set median; prototypes; feature selection; classification accuracy	STRUCTURE PREDICTION; SECONDARY STRUCTURE; DATABASE; ALGORITHM; STRINGS; SEARCH	In this paper, an efficient K-medians clustering (unsupervised) algorithm for prototype selection and Supervised K-medians (SKM) classification technique for protein sequences are presented. For sequence data sets, a median string/sequence can be used as the cluster/group representative. In K-medians clustering technique, a desired number of clusters, K, each represented by a median string/sequence, is generated and these median sequences are used as prototypes for classifying the new/test sequence whereas in SKM classification technique, median sequence in each group/class of labelled protein sequences is determined and the set of median sequences is used as prototypes for classification purpose. It is found that the K-medians clustering technique outperforms the leader based technique and also SKM classification technique performs better than that of motifs based approach for the data sets used. We further use a simple technique to reduce time and space requirements during protein sequence clustering and classification. During training and testing phase, the similarity score value between a pair of sequences is determined by selecting a portion of the sequence instead of the entire sequence. It is like selecting a subset of features for sequence data sets. The experimental results of the proposed method on K-medians, SKM and Nearest Neighbour Classifier (NNC) techniques show that the Classification Accuracy (CA) using the prototypes generated/used does not degrade much but the training and testing time are reduced significantly. Thus the experimental results indicate that the similarity score does not need to be calculated by considering the entire length of the sequence for achieving a good CA. Even space requirement is reduced during both training and classification.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Vijaya, PA (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	pav@csa.iisc.ernet.in; mnm@csa.iisc.ernet.in; dks@csa.iisc.ernet.in					Bandyopadhyay S, 2005, FUZZY SET SYST, V152, P5, DOI 10.1016/j.fss.2004.10.011; Bolten E, 2001, BIOINFORMATICS, V17, P935, DOI 10.1093/bioinformatics/17.10.935; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Durbin R, 1998, BIOL SEQUENCE ANAL; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; Guralnik V., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989516; Hamamoto Y, 1996, IEEE T PATTERN ANAL, V18, P571, DOI 10.1109/34.494648; HAN E, 1997, P DAT MIN KNOWL DISC; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; HUANG XQ, 1991, ADV APPL MATH, V12, P337, DOI 10.1016/0196-8858(91)90017-D; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain A. K., 1999, ACM COMPUT SURV, V31; Kaufman L., 1990, FINDING GROUPS DATA; Knuth D. E., 1998, ART COMPUTER PROGRAM, V3; KOHONEN T, 1985, PATTERN RECOGN LETT, V3, P309, DOI 10.1016/0167-8655(85)90061-3; KRAUSE A, 2002, THESIS BERLIN; Kriventseva EV, 2001, NUCLEIC ACIDS RES, V29, P33, DOI 10.1093/nar/29.1.33; Lo Conte L, 2000, NUCLEIC ACIDS RES, V28, P257, DOI 10.1093/nar/28.1.257; Martinez-Hinarejos CD, 2003, PATTERN RECOGN LETT, V24, P173, DOI 10.1016/S0167-8655(02)00209-X; MCA L, 1996, PATTERN RECOGN LETT, V17, P731; MICA L, 1994, PATTERN RECOGN LETT, V15, P9; Mitra S., 2003, DATA MINING MULTIMED; MORENO F, 2003, PATTERN RECOGN LETT, V22, P1145; MOUNT DW, 2002, BIOINFORMATICS SEQUE; NEEDLEMA.SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770; Pal S.K., 2004, PATTERN RECOGNITION; PEARSON W, 1999, FASTA PROGRAM PACKAG; PETER C, 2000, COMPUTATIONAL MOL BI; PUJARI A, 2000, DATA MINING TECHNIQU; Ramasubramanian V, 2000, PATTERN RECOGN, V33, P1497, DOI 10.1016/S0031-3203(99)00134-X; Sahni S., 1998, DATA STRUCTURES ALGO; SALZBERG S, 1992, J MOL BIOL, V227, P371, DOI 10.1016/0022-2836(92)90892-N; SCHUTZE H, 2004, SINGLE LINK COMPLETE; Sharan R., 2000, Proceedings. Eighth International Conference on Intelligent Systems for Molecular Biology; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; SOMERVUO P, 2000, P 3 INT C DISC SCI, P76; Spath H, 1980, CLUSTER ANAL ALGORIT; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; VIJAYA PA, 2003, P 5 ICAPR, P129; VIJAYA PA, 2003, P IEEE TENCON AS PAC, P409; VIJAYA PA, 2004, P 17 INT C PATT REC, V2, P447; Vijayalakshmi R, 2001, HYDROMETALLURGY, V61, P75, DOI 10.1016/S0304-386X(00)00159-6; WANG J, 1994, ELECTROANAL, V6, P571, DOI 10.1002/elan.1140060707; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Yona G, 2000, NUCLEIC ACIDS RES, V28, P49, DOI 10.1093/nar/28.1.49	47	5	5	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	OCT	2006	9	2-3					243	255		10.1007/s10044-006-0040-z		13	Computer Science, Artificial Intelligence	Computer Science	088SH	WOS:000240830900010	
J	Lozano, M; Sotoca, JM; Sanchez, JS; Pla, F; Pekalska, E; Duin, RPW				Lozano, M.; Sotoca, J. M.; Sanchez, J. S.; Pla, F.; Pekalska, E.; Duin, R. P. W.			Experimental study on prototype optimisation algorithms for prototype-based classification in vector spaces	PATTERN RECOGNITION			English	Article						dissimilarity representation; prototype selection; adaptive condensing; EM algorithm; normal density based classifier; nearest neighbour rule	DISSIMILARITY-BASED CLASSIFICATION; LEARNING ALGORITHMS; CLASSIFIERS; NEIGHBORHOOD; SELECTION	Prototype-based classification relies on the distances between the examples to be classified and carefully chosen prototypes. A small set of prototypes is of interest to keep the computational complexity low, while maintaining high classification accuracy. An experimental study of some old and new prototype optimisation techniques is presented, in which the prototypes are either selected or generated from the given data. These condensing techniques are evaluated on real data, represented in vector spaces, by comparing their resulting reduction rates and classification performance. Usually the determination of prototypes is studied in relation with the nearest neighbour rule. We will show that the use of more general dissimilarity-based classifiers can be more beneficial. An important point in our study is that the adaptive condensing schemes here discussed allow the user to choose the number of prototypes freely according to the needs. If such techniques are combined with linear dissimilarity-based classifiers, they provide the best trade-off of small condensed sets and high classification accuracy. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Juame 1, Dept Lenguajes & Sistemas Informat, Castellon de La Plana 12071, Spain; Delft Univ Technol, Fac Elect Engn Math & Comp Sci, NL-2628 CD Delft, Netherlands; Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	Lozano, M (reprint author), Univ Juame 1, Dept Lenguajes & Sistemas Informat, Campus Riu Sec, Castellon de La Plana 12071, Spain.	lozano@uji.es; sotoca@uji.es; sanchez@uji.es; pla@uji.es; e.m.pekalska@tudelft.nl; r.p.w.duin@ieee.org					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AINSLIE MC, 2002, 2 WORKSH INT COLL AS, P13; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P11, DOI 10.1016/0167-8655(95)00093-3; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1990, NORMS NN PATTERN CLA; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R. P. W., 2004, PR TOOLS MATLAB TOOL; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Hart PE, 1968, IEEE T INFORMATION T, V14, P505; Kohonen T., 1995, SELF ORG MAPS; Kohonen T., 1996, LVQ PAK LEARNING VEC; LOZANO M, 2004, LECT NOTES ARTIF INT, V3040, P618; Lozano M, 2004, FR ART INT, V113, P225; McLachlan G, 1997, EM ALGORITHM EXTENSI; McLachlan G. J., 1988, MIXTURE MODELS INFER; Merz C.J., 1998, UCI REPOSITORY MACHI; Novovicova J, 1996, IEEE T PATTERN ANAL, V18, P218, DOI 10.1109/34.481557; Paclik P, 2003, REAL-TIME IMAGING, V9, P237, DOI 10.1016/j.rti.2003.09.002; PACLIK P, 2003, CLASSIFYING SPECTRAL; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E, 2004, LECT NOTES COMPUT SC, V3138, P1145; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Pekalska E, 2005, SER MACH PERCEPT ART, V64, P1, DOI 10.1142/9789812703170; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOUSSAINT GT, 1985, COMPUTER SCI STAT IN; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	35	26	26	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	OCT	2006	39	10					1827	1838		10.1016/j.patcog.2006.04.005		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	069UV	WOS:000239475000003	
J	Perez, A; Larranaga, P; Inza, I				Perez, Aritz; Larranaga, Pedro; Inza, Inaki			Supervised classification with conditional Gaussian networks: Increasing the structure complexity from naive Bayes	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						conditional Gaussian network; Bayesian network; naive Bayes; tree augmented naive Bayes; k-dependence Bayesian classifiers; semi naive Bayes; filter; wrapper	FEATURE SUBSET-SELECTION; CLASSIFIERS; VARIANCE; BIAS; KNOWLEDGE; RELEVANCE	Most of the Bayesian network-based classifiers are usually only able to handle discrete variables. However, most real-world domains involve continuous variables. A common practice to deal with continuous variables is to discretize them, with a subsequent loss of information. This work shows how discrete classifier induction algorithms can be adapted to the conditional Gaussian network paradigm to deal with continuous variables without discretizing them. In addition, three novel classifier induction algorithms and two new propositions about mutual information are introduced. The classifier induction algorithms presented are ordered and grouped according to their structural complexity: naive Bayes, tree augmented naive Bayes, k-dependence Bayesian classifiers and semi naive Bayes. All the classifier induction algorithms are empirically evaluated using predictive accuracy, and they are compared to linear discriminant analysis, as a continuous classic statistical benchmark classifier. Besides, the accuracies for a set of state-of-the-art classifiers are included in order to justify the use of linear discriminant analysis as the benchmark algorithm. In order to understand the behavior of the conditional Gaussian network-based classifiers better, the results include bias-variance decomposition of the expected misclassification rate. The study suggests that semi naive Bayes structure based classifiers and, especially, the novel wrapper condensed semi naive Bayes backward, outperform the behavior of the rest of the presented classifiers. They also obtain quite competitive results compared to the state-of-the-art algorithms included. (c) 2006 Elsevier Inc. All rights reserved.	Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, San Sebastian 20080, Spain	Perez, A (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, POB 649, San Sebastian 20080, Spain.	aritz@si.ehu.es; ccplamup@si.ehu.es; inza@si.ehu.es	Larranaga, Pedro/F-9293-2013				ANDERSON FW, 1958, INTRO MULTIVARIATE S; BOTTCHER SG, 2004, THESIS ALLBORG U; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J, 1999, P 15 C UNC ART INT U, P101; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeGroot M.H., 1970, OPTIMAL STAT DECISIO; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos Pedro, 2000, P 17 INT C MACH LEAR, P231; Duda R., 1973, PATTERN CLASSIFICATI; Dudewicz E.J., 1988, MODERN MATH STAT; EGMONTPETERSON M, 2004, P JOINT IAPR WORKSH, P1034; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FRIEDMAN N, 1998, P 15 NAT C MACH LEAR; Geiger D., 1994, LEARNING GAUSSIAN NE; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; German S., 1992, NEURAL COMPUT, V4, P1; Giudici P, 1999, BIOMETRIKA, V86, P785, DOI 10.1093/biomet/86.4.785; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Grossman D., 2004, P 21 INT C MACH LEAR; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M., 1997, P 4 INT C NEUR INF P, P855; Iba W., 1992, P 10 NAT C ART INT, P223; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Jebara Tony, 2001, THESIS MIT; John G., 1995, P 11 C UNC ART INT, P338; Johnson R., 2002, APPL MULTIVARIATE ST; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Keogh E. J., 1999, P 7 INT WORKSH ART I, P225; KOHAVI R, 1996, INT C MACH LEARN; KOHAVI R, 1995, THESIS COMPUTER SCI; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I, 1991, P 6 EUR WORK SESS LE, p206~219; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Langley P., 1994, P 10 C UNC ART INT, P399; Larranaga P., 2002, ESTIMATION DISTRIBUT; Lauritzen S. L., 1996, GRAPHICAL MODELS, p[505, 506]; LAURITZEN SL, 1989, ANN STAT, V17; LAURITZEN SL, 1984, F848 AALB U I EL SYS; Liu H., 1998, FEATURE SELECTION KN; Minsky M., 1961, T I RADIO ENG, V49, P8; Murphy P. M., 1995, UCI REPOSITORY MACHI; Neapolitan R, 2003, LEARNING BAYESIAN NE; PAZZANI M, 1997, LEARNING DATA ARTIFI, V5, P239; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; Pernkopf F, 2005, PATTERN RECOGN, V38, P1, DOI 10.1016/j.patcog.2004.05.012; Pernkopf F., 2005, P 22 INT C MACH LEAR; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Raina R., 2003, ADV NEURAL INFORM PR, V16; Rosenblatt Frank, 1959, PRINCIPLES NEURODYNA; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SNTAFE G, 2005, P 8 EUR C SYMB QUANT, P148; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; Wang H, 1999, IEEE T PATTERN ANAL, V21, P271; WANG H, 1996, THESIS U ULSTER; Witten I., 2005, DATA MINING PRACTICA; YANG Y, 2003, 2003131 MON U SCH CO; Yu L, 2004, J MACH LEARN RES, V5, P1205	64	16	17	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X		INT J APPROX REASON	Int. J. Approx. Reasoning	SEP	2006	43	1					1	25		10.1016/j.ijar.2006.01.002		25	Computer Science, Artificial Intelligence	Computer Science	079MR	WOS:000240181200001	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Hum-PLoc: A novel ensemble classifier for predicting human protein subcellular localization	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						cellular networking; organelle; gene ontology; amphiphilic pseudo amino acid composition; KNN; fusion 25% sequence identity cutoff	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; SORTING SIGNALS; GENE ONTOLOGY; SEQUENCE; LOCATION	Predicting subcellular localization of human proteins is a challenging problem, especially when unknown query proteins do not have significant homology to proteins of known subcellular locations and when more locations need to be covered. To tackle the challenge, protein samples are expressed by hybridizing the gene ontology (GO) database and amphiphilic pseudo amino acid composition (PseAA). Based on such a representation frame, a novel ensemble classifier, called "Hum-PLoc", was developed by fusing many basic individual classifiers through a voting system. The "engine" of these basic classifiers was operated by the KNN (K-nearest neighbor) rule. As a demonstration, tests were performed with the ensemble classifier for human proteins among the following 12 locations: (1) centriole; (2) cytoplasm; (3) cytoskeleton; (4) endoplasmic reticulum; (5) extracell; (6) Golgi apparatus; (7) lysosome; (8) microsome; (9) mitochondrion; (10) nucleus; (11) peroxisome; (12) plasma membrane. To get rid of redundancy and homology bias, none of the proteins investigated here had >= 25% sequence identity to any other in a same subcellular location. The overall success rates thus obtained via the jackknife cross-validation test and independent dataset test were 81.1% and 85.0%, respectively, which are more than 50% higher than those obtained by the other existing methods on the same stringent datasets. Furthermore, an incisive and compelling analysis was given to elucidate that the overwhelmingly high success rate obtained by the new predictor is by no means due to a trivial utilization of the GO annotations. This is because, for those proteins with "subcellular location unknown" annotation in Swiss-Prot database, most (more than 99%) of their corresponding GO numbers in GO database are also annotated with "cellular component unknown". The information and clues for predicting subcellular locations of proteins are actually buried into a series of tedious GO numbers, just like they are buried into a pile of complicated amino acid sequences although with a different manner and "depth". To dig out the knowledge about their locations, a sophisticated operation engine is needed. And the current predictor is one of these kinds, and has proved to be a very powerful one. The Hum-PLoc classifier is available as a web-server at http://202.120.37.186/bioinf/hum. (c) 2006 Elsevier Inc. All rights reserved.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				ALBERTS B, 1994, MOL BIOL CELL, pCH1; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Holm L, 1999, NUCLEIC ACIDS RES, V27, P244, DOI 10.1093/nar/27.1.244; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LODISH H, 1995, MOL CELL BIOL, pCH3; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	34	176	182	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X		BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	AUG 18	2006	347	1					150	157		10.1016/j.bbrc.2006.06.059		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	065ZC	WOS:000239198000021	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Predicting eukaryotic protein subcellular location by fusing optimized evidence-theoretic K-Nearest Neighbor classifiers	JOURNAL OF PROTEOME RESEARCH			English	Article						cellular networking; organelle; gene ontology; amphiphilic pseudo amino acid composition; OET-KNN; fusion classifier; 25% sequence identity cutoff	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; GENE ONTOLOGY; STRUCTURAL CLASSES; SORTING SIGNALS; LOCALIZATION; CLASSIFICATION; REPRESENTATION; ALGORITHM; SEQUENCES	Facing the explosion of newly generated protein sequences in the post genomic era, we are challenged to develop an automated method for fast and reliably annotating their subcellular locations. Knowledge of subcellular locations of proteins can provide useful hints for revealing their functions and understanding how they interact with each other in cellular networking. Unfortunately, it is both expensive and time-consuming to determine the localization of an uncharacterized protein in a living cell purely based on experiments. To tackle the challenge, a novel hybridization classifier was developed by fusing many basic individual classifiers through a voting system. The "engine" of these basic classifiers was operated by the OET-KNN (Optimized Evidence-Theoretic K-Nearest Neighbor) rule. As a demonstration, predictions were performed with the fusion classifier for proteins among the following 16 localizations: (1) cell wall, (2) centriole, (3) chloroplast, (4) cyanelle, (5) cytoplasm, (6) cytoskeleton, (7) endoplasmic reticulum, (8) extracell, (9) Golgi apparatus, (10) lysosome, (11) mitochondria, (12) nucleus, (13) peroxisome, (14) plasma membrane, (15) plastid, and (16) vacuole. To get rid of redundancy and homology bias, none of the proteins investigated here had g25% sequence identity to any other in a same subcellular location. The overall success rates thus obtained via the jack-knife cross-validation test and independent dataset test were 81.6% and 83.7%, respectively, which were 46 similar to 63% higher than those performed by the other existing methods on the same benchmark datasets. Also, it is clearly elucidated that the overwhelmingly high success rates obtained by the fusion classifier is by no means a trivial utilization of the GO annotations as prone to be misinterpreted because there is a huge number of proteins with given accession numbers and the corresponding GO numbers, but their subcellular locations are still unknown, and that the percentage of proteins with GO annotations indicating their subcellular components is even less than the percentage of proteins with known subcellular location annotation in the Swiss- Prot database. It is anticipated that the powerful fusion classifier may also become a very useful high throughput tool in characterizing other attributes of proteins according to their sequences, such as enzyme class, membrane protein type, and nuclear receptor subfamily, among many others. A web server, called " Euk- OET- PLoc", has been designed at http:// 202.120.37.186/ bioinf/ euk- oet for public to predict subcellular locations of eukaryotic proteins by the fusion OET- KNN classifier.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				ALBERTS B, 1994, MOL BIOL CELL, pCH1; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Camon E, 2004, NUCLEIC ACIDS RES, V32, pD262, DOI 10.1093/nar/gkh021; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 1997, PROTEINS, V28, P99, DOI 10.1002/(SICI)1097-0134(199705)28:1<99::AID-PROT10>3.0.CO;2-C; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1990, ACCOUNTS CHEM RES, V23, P134, DOI 10.1021/ar00173a003; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREIGHTON TE, 1990, BIOCHEM J, V270, P1; CREIGHTON TE, 1995, CURR BIOL, V5, P353, DOI 10.1016/S0960-9822(95)00070-4; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lee Vivian, 2005, In Silico Biology, V5, P5; LODISH H, 1995, MOL CELL BIOL, pCH3; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; PTITSYN OB, 1980, Q REV BIOPHYS, V13, P339; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shafer G., 1976, MATH THEORY EVIDENCE; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	48	141	144	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893		J PROTEOME RES	J. Proteome Res.	AUG 4	2006	5	8					1888	1897		10.1021/pr060167c		10	Biochemical Research Methods	Biochemistry & Molecular Biology	070AW	WOS:000239493700008	
J	Park, SB				Park, Seong-Bae			Combining rule-based learning and memory-based learning for automatic word spacing in simple message service	APPLIED SOFT COMPUTING			English	Article						rule-based learning; memory-based learning; combined model and automatic word spacing	NETWORKS	Short message service (SMS) is a widely used service in modern mobile phones that allows users to send or receive short text messages. Current SMS, however, has two problems of inconvenient input and short message length. These problems can be resolved if a phone has an ability of automatic word spacing. This is because users need not put spaces in sending messages and longer messages are possible as they contain no space. Thus, automatic word spacing will be a very useful tool for SMS, if it can be commercially served. The practical issues of implementing it on the devices such as mobile phones are small memory and low computing power of the devices. To tackle these problems, this paper proposes a combined model of rule-based learning and memory-based learning. According to the experimental results, the model shows higher accuracy than rule-based learning or memory-based learning alone. In addition, the generated rules are so small and simple that the proposed model is appropriate for small memory devices. (C) 2005 Elsevier B.V. All rights reserved.	Kyungpook Natl Univ, Dept Comp Engn, Taegu 701702, South Korea	Park, SB (reprint author), Kyungpook Natl Univ, Dept Comp Engn, Taegu 701702, South Korea.	seongbae@knu.ac.kr					Abney S., 1999, P 1999 JOINT SIGDAT, P38; ARAUJO L, 2004, P 5 ANN C INT TEXT P, P81; Brill E, 1995, COMPUT LINGUIST, V21, P543; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2001, 0104 ILK TILB U; ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844; Lawrence S, 2000, IEEE T KNOWL DATA EN, V12, P126, DOI 10.1109/69.842255; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; KANG MY, 2004, P 17 INT C IND ENG A, P290; KANG SS, 2000, J KISS, V27, P441; Kang SW, 2004, J MATER SCI-MATER EL, V15, P231, DOI 10.1023/B:JMSE.0000012460.03209.74; Khan MS, 2004, APPL SOFT COMPUT, V4, P423, DOI 10.1016/j.asoc.2004.02.003; KIM KS, 1998, J KISS, V25, P1838; LEE DG, 2002, P 3 WORKSH AS LANG R, P51; PARK SB, 2003, P 41 ANN M ASS COMP, P497; PARK SB, 2004, P 5 ANN C INT TEXT P, P146; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1023/A:1022699322624; Quinlan R., 1993, C4 5 PROGRAMS MACHIN	22	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946		APPL SOFT COMPUT	Appl. Soft. Comput.	AUG	2006	6	4					406	416		10.1016/j.asoc.2005.11.006		11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	107KM	WOS:000242169800008	
J	Gilboa, I; Lieberman, O; Schmeidler, D				Gilboa, Itzhak; Lieberman, Offer; Schmeidler, David			Empirical similarity	REVIEW OF ECONOMICS AND STATISTICS			English	Article							DENSITY-FUNCTION; DECISION-THEORY	An agent is asked to assess a real-valued variable Y-p based on certain characteristics X-p = (X-p(1)..., X-p(m)), and on a database consisting of (X-i(1),..., X-i(m), Y-i) for i = 1,..., n. A possible approach to combine past observations of X and Y with the current values of X to generate an assessment of Y is similarity-weighted averaging. It suggests that the predicted value of Y, (Y) over bar (s)(p), be the weighted average of all previously P observed values Y-i, where the weight of Y-i for every i = 1,..., n, is the similarity between the vector X-p(1),....,X-p(m), associated with Y-p, and the previously observed vector, X-i(l),..., X-m(i). We axiomatize this rule. We assume that, given every database, a predictor has a ranking over possible values, and we show that certain reasonable conditions on these rankings imply that they are determined by the proximity to a similarity-weighted average for a certain similarity function. The axiontatization does not suggest a particular similarity function, or even a particular form of this function. We therefore proceed to suggest that the similarity function be estimated from past observations. We develop tools of statistical inference for parametric estimation of the similarity function, for the case of a continuous as well as a discrete variable. Finally, we discuss the relationship of the proposed method to other methods of estimation and prediction.	Tel Aviv Univ, IL-69978 Tel Aviv, Israel; Yale Univ, New Haven, CT 06520 USA; Tel Aviv Univ, HEC, IL-69978 Tel Aviv, Israel; Ohio State Univ, Columbus, OH 43210 USA	Gilboa, I (reprint author), Tel Aviv Univ, IL-69978 Tel Aviv, Israel.						Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; BILLOT A, 2004, 1485 COWL FDN; Billot A, 2005, ECONOMETRICA, V73, P1125, DOI 10.1111/j.1468-0262.2005.00611.x; CHANT D, 1974, BIOMETRIKA, V61, P291, DOI 10.1093/biomet/61.2.291; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 2149004 USAF SCH AV; Gayer G, 2004, 1493 COWL FDN; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; GILBOA I, 2001, THEORY CASE BASED DE; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Gilboa I, 2003, ECONOMETRICA, V71, P1, DOI 10.1111/1468-0262.00388; Hume D, 1748, ENQUIRY HUMAN UNDERS; LIEBERMAN O, 2005, UNPUB ASYMPTOTIC THE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Riesbeck C., 1989, INSIDE CASE BASED RE; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Schank Roger C., 1986, EXPLANATION PATTERNS; Scott D. W., 1992, MULTIVARIATE DENSITY; Silverman B.W., 1986, DENSITY ESTIMATION S	21	14	14	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0034-6535		REV ECON STAT	Rev. Econ. Stat.	AUG	2006	88	3					433	444		10.1162/rest.88.3.433		12	Economics; Social Sciences, Mathematical Methods	Business & Economics; Mathematical Methods In Social Sciences	095TG	WOS:000241330600002	
J	Moguerza, JM; Munoz, A				Moguerza, Javier M.; Munoz, Alberto			Support vector machines with applications	STATISTICAL SCIENCE			English	Article						support vector machines; kernel methods; regularization theory; classification; inverse problems	STATISTICAL PROPERTIES; CLASSIFICATION; NETWORKS; RECOGNITION; CLASSIFIERS; EQUATIONS	Support vector machines (SVMs) appeared in the early nineties as optimal margin classifiers in the context of Vapnik's statistical learning theory. Since then SVMs have been successfully applied to real-world data analysis problems, often providing improved results compared with other techniques. The SVMs operate within the framework of regularization theory by minimizing an empirical risk in a well-posed and consistent way. A clear advantage of the support vector approach is that sparse solutions to classification and regression problems are usually obtained: only a few samples are involved in the determination of the classification or regression functions. This fact facilitates the application of SVMs to problems that involve a large amount of data, such as text processing and bioinformatics tasks. This paper is intended as an introduction to SVMs and their applications, emphasizing their key features. In addition, some algorithmic extensions and illustrative real-world applications of SVMs are shown.	Univ Rey Juan Carlos, Sch Engn, Mostoles 28933, Spain; Univ Carlos III, Dept Stat, Getafe 28903, Spain	Moguerza, JM (reprint author), Univ Rey Juan Carlos, Sch Engn, C Tulipan S-N, Mostoles 28933, Spain.	javier.mogureza@urjc.es; alberto.munoz@uc3m.es					Aizerman M., 1964, AUTOMAT REM CONTR, V25, P821; Amari S., 1985, LECT NOTES STAT, V28; Aronszajn N., 1951, P S SPECTR THEOR DIF, P355; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.2307/1990404; BAEZA- YATES R., 1999, MODERN INFORMATION R; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bazaraa M. S., 1993, NONLINEAR PROGRAMMIN; Ben-Hur A, 2001, J MACHINE LEARNING R, V2, P125; Bennett K. P., 2000, SIGKDD EXPLORATIONS, V2, P1; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Chen BJ, 2004, IEEE T POWER SYST, V19, P1821, DOI 10.1109/TPWRS.2004.835679; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; Cressie N. A. C., 1993, STAT SPATIAL DATA; Cristianini N, 2000, INTRO SUPPORT VECTOR; Cucker F, 2002, B AM MATH SOC, V39, P1; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Green P.J, 1999, ENCY STAT SCI, V3, P578; Hastie T, 2001, ELEMENTS STAT LEARNI; Herbrich R, 2002, LEARNING KERNEL CLAS; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Ivanov V. V., 1976, THEORY APPROXIMATE M; Joachims T., 2002, LEARNING CLASSIFY TE; KANWAL RP, 1983, GEN FUNCTIONS; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lanckriet G., 2002, P 19 INT C MACH LEAR, P323; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Lin Y, 2002, MACH LEARN, V48, P115, DOI 10.1023/A:1013951620650; MARTIN I, 2004, LECT NOTES COMPUT SC, V3077, P102; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Mika S., 1999, NEURAL NETWORKS SIGN, VIX, P41; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Moguerza JM, 2002, LECT NOTES COMPUT SC, V2415, P763; Moguerza JM, 2003, MATH PROGRAM, V95, P573, DOI 10.1007/s10107-002-0360-8; MUKHERJEE S, 1999, 1653 MIT AI LAB; Mukherjee S, 2003, LECT NOTES STAT, V171, P111; Muller KR, 1999, ADVANCES IN KERNEL METHODS, P243; Muller P, 1998, NEURAL COMPUT, V10, P749, DOI 10.1162/089976698300017737; Munoz A, 2003, LECT NOTES COMPUT SC, V2714, P217; Munoz A, 2003, LECT NOTES ARTIF INT, V2774, P16; Munoz A, 2006, IEEE T PATTERN ANAL, V28, P476, DOI 10.1109/TPAMI.2006.52; O'Sullivan F., 1986, STAT SCI, V1, P502, DOI 10.1214/ss/1177013525; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; OSUNA E, 1997, 144AI CBCL MIT AI LA; OSUNA E, 1997, P IEEE WORKSH NEUR N, P276; Pavlidis P., 2001, P 5 INT C COMP MOL B, P249, DOI 10.1145/369133.369228; PHILLIPS DL, 1962, J ACM, V9, P84, DOI 10.1145/321105.321114; Platt JC, 2000, ADV NEUR IN, P61; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 2001, 198AI CBCL MIT AI LA; RAMSAY J. O., 1997, FUNCTIONAL DATA ANAL; Rosipal R., 2001, J MACHINE LEARNING R, V2, P97; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B, 2001, LECT NOTES ARTIF INT, V2111, P416; Smola A. J., 1998, NEUROCOLT2 TECHNICAL; Sollich P, 2002, MACH LEARN, V46, P21, DOI 10.1023/A:1012489924661; Tikhonov A. N., 1977, SOLUTIONS ILL POSED; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Van Kampen NG, 1981, STOCHASTIC PROCESSES; VAPNIK VN, 1964, AUTOMAT REM CONTR+, V25, P103; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Wahba G., 1980, APPROXIMATION THEORY, P905; WAHBA G, 1985, ANN STAT, V13, P1378, DOI 10.1214/aos/1176349743; Wahba G., 1990, SPLINE MODELS OBSERV; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Wu S, 2002, NEURAL PROCESS LETT, V15, P59, DOI 10.1023/A:1013848912046	83	43	43	INST MATHEMATICAL STATISTICS	BEACHWOOD	PO BOX 22718, BEACHWOOD, OH 44122 USA	0883-4237		STAT SCI	Stat. Sci.	AUG	2006	21	3					322	336		10.1214/088342306000000493		15	Statistics & Probability	Mathematics	130CG	WOS:000243776200003	
J	Lee, JW; Lee, JS; Kang, M; Su, AI; Chang, YT				Lee, Jae Wook; Lee, Jun-Seok; Kang, Mira; Su, Andrew I.; Chang, Young-Tae			Visual artificial tongue for quantitative metal-cation analysis by an off-the-shelf dye array	CHEMISTRY-A EUROPEAN JOURNAL			English	Article						alkali metals; cations; dyes/pigments; hierarchical-cluster analysis; principal-component analysis	MOLECULAR RECOGNITION; SENSOR ARRAYS; WATER	A chemical-probe array composed of 47 off-the-shelf dyes was prepared in solution format (New York Tongue 1: NYT-1) and was tested in the identification and quantitation of 47 cation analytes, including 44 metal ions, in addition to H+, NH4(+), and tetrabutylammonium (TBA). The cation solutions were tested in a series of concentrations and the fold-change in effective absorbance was analyzed by principal-component analysis (PCA), hierarchical-cluster analysis (HCA), and nearest-neighbor decision to determine both identity and quantity of the analytes. Apart from alkali-metal ions (Na+, K+, Li+, Cs+, and Rb+), which behave very similarly to each other due mainly to their low response, most of the cations were clearly distinguishable at 10 mm concentration. The practical detection limit of each analyte was also determined by a sequential dilution and the nearest-neighbor decision method. In the finalized working analyte concentration range (approximately 10 mm down to 0.33 mu m), by considering alkali metals as one analyte group, most of the analytes were correctly identified (99.4%). Furthermore, the success rate at which the concentration of each analyte was correctly determined was also high (96.8 %).	NYU, Dept Chem, New York, NY 10003 USA; Novartis Res Fdn, Genom Inst, San Diego, CA 92121 USA	Chang, YT (reprint author), NYU, Dept Chem, New York, NY 10003 USA.	yt.chang@nyu.edu	Chang, Young-Tae/B-2780-2010; Lee, Jun-Seok/D-8428-2011	Chang, Young-Tae/0000-0002-1927-3688; 			Albert KJ, 2000, CHEM REV, V100, P2595, DOI 10.1021/cr980102w; Blalock E., 2003, BEGINNERS GUIDE MICR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Drayna D, 2005, ANNU REV GENOM HUM G, V6, P217, DOI 10.1146/annurev.genom.6.080604.162340; FEIGL F., 1972, SPOT TESTS INORGANIC; FEIGL F, 1966, SPOT TESTS ORGANIC A; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; Lavigne J. J., 2001, ANGEW CHEM, V113, P3212, DOI 10.1002/1521-3757(20010903)113:17<3212::AID-ANGE3212>3.0.CO;2-T; MARY T, 2003, ANAL CHEM, V75, P4389; Mikami D, 2004, ANAL CHEM, V76, P5726, DOI 10.1021/ac040024e; Miyaji H., 2001, ANGEW CHEM, V113, P158, DOI 10.1002/1521-3757(20010105)113:1<158::AID-ANGE158>3.0.CO;2-J; MUELLERACKERMAN.E, 1995, ANAL METHOD INSTRUM, V3, P182; Prestel H, 2000, FRESEN J ANAL CHEM, V368, P182, DOI 10.1007/s002160000379; Rakow N. A., 2005, ANGEW CHEM, V117, P4604, DOI 10.1002/ange.200500939; Rakow NA, 2005, ANGEW CHEM INT EDIT, V44, P4528, DOI 10.1002/anie.200500939; Suslick KS, 2004, TETRAHEDRON, V60, P11133, DOI 10.1016/j.tet.2004.09.007; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; Zhang C, 2005, J AM CHEM SOC, V127, P11548, DOI 10.1021/ja052606z	18	23	24	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	0947-6539		CHEM-EUR J	Chem.-Eur. J.	JUL 24	2006	12	22					5691	5696		10.1002/chem.200600307		6	Chemistry, Multidisciplinary	Chemistry	069XD	WOS:000239481600004	
J	Ghosh, AK				Ghosh, AK			On optimum choice of k in nearest neighbor classification	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						accuracy index; Bayesian strength function; cross-validation; misclassification rate; neighborhood parameter; non-informative prior; optimal Bayes risk; posterior probability	DISCRIMINANT-ANALYSIS	A major issue in k-nearest neighbor classification is how to choose the optimum value of the neighborhood parameter k. Popular cross-validation techniques often fail to guide us well in selecting k mainly due to the presence of multiple minimizers of the estimated misclassification rate. This article investigates a Bayesian method in this connection, which solves the problem of multiple optimizers. The utility of the proposed method is illustrated using some benchmark data sets. (C) 2005 Elsevier B.V. All rights reserved.	Indian Stat Inst, Theoret Stat & Math Unit, Calcutta 700108, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203 BT Rd, Calcutta 700108, India.	anilkghosh@rediffmail.com					Aho A.V., 1974, DESIGN ANAL COMPUTER; Anderson T., 1984, INTRO MULTIVARIATE S; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED, P261; Friedman J, 1996, ANOTHER APPROACH POL; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; GHOSH A, 2005, IN PRESS IEEE T PATT; Ghosh AK, 2004, STAT SINICA, V14, P457; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 2001, ELEMENTS STAT LEARNI; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P., 1936, P NATL I SCI INDIA, V12, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Paik M., 2004, STAT APPL GENETICS M, V3; Ripley B. D., 1996, PATTERN RECOGNITION; Silverman B.W., 1986, DENSITY ESTIMATION S; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Wichern D. W., 1992, APPL MULTIVARIATE ST	24	20	21	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473		COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUL 20	2006	50	11					3113	3123		10.1016/j.csda.2005.06.007		11	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	055SV	WOS:000238471600010	
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Ensemble classifier for protein fold pattern recognition	BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; ENERGETIC APPROACH; STABILITY; SEQUENCE; HELICES; RULE; SCOP; NN	Motivation: Prediction of protein folding patterns is one level deeper than that of protein structural classes, and hence is much more complicated and difficult. To deal with such a challenging problem, the ensemble classifier was introduced. It was formed by a set of basic classifiers, with each trained in different parameter systems, such as predicted secondary structure, hydrophobicity, van der Waals volume, polarity, polarizability, as well as different dimensions of pseudo-amino acid composition, which were extracted from attaining dataset. The operation engine for the constituent individual classifiers was OET-KNN (optimized evidence-theoretic k-nearest neighbors) rule. Their outcomes were combined through a weighted voting to give a final determination for classifying a query protein. The recognition was to find the true fold among the 27 possible patterns. Results: The overall success rate thus obtained was 62% for a testing dataset where most of the proteins have < 25% sequence identity with the proteins used in training the classifier. Such a rate is 6-21% higher than the corresponding rates obtained by various existing NN (neural networks) and SVM (support vector machines) approaches, implying that the ensemble classifier is very promising and might become a useful vehicle in protein science, as well as proteomics and bioinformatics.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Shen, HB (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	lifesci-sjtu@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Andreeva A., 2004, NUCLEIC ACIDS RES, V32, P226; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, BIOCHEM BIOPH RES CO, V264, P216, DOI 10.1006/bbrc.1999.1325; CHOU KC, 1984, J AM CHEM SOC, V106, P3161, DOI 10.1021/ja00323a017; CHOU KC, 1991, PROTEINS, V9, P280, DOI 10.1002/prot.340090406; Chou KC, 1997, PROTEINS, V28, P99, DOI 10.1002/(SICI)1097-0134(199705)28:1<99::AID-PROT10>3.0.CO;2-C; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1990, ACCOUNTS CHEM RES, V23, P134, DOI 10.1021/ar00173a003; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1982, J MOL BIOL, V162, P89, DOI 10.1016/0022-2836(82)90163-2; Chung IF, 2003, LECT NOTES COMPUT SC, V2714, P1159; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; DUBCHAK I, 1995, P NATL ACAD SCI USA, V92, P8700, DOI 10.1073/pnas.92.19.8700; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; FINKELSTEIN AV, 1987, PROG BIOPHYS MOL BIO, V50, P171, DOI 10.1016/0079-6107(87)90013-7; Holm L, 1999, NUCLEIC ACIDS RES, V27, P244, DOI 10.1093/nar/27.1.244; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Shafer G., 1976, MATH THEORY EVIDENCE; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	34	164	170	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JUL 15	2006	22	14					1717	1722		10.1093/bioinformatics/btl170		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	073EN	WOS:000239725900006	
J	Mitani, Y; Hamamoto, Y				Mitani, Y; Hamamoto, Y			A local mean-based nonparametric classifier	PATTERN RECOGNITION LETTERS			English	Article						classifier design; nearest neighbor samples; small training sample size; dimensionality	RECOGNITION	A considerable amount of effort has been devoted to design a classifier in practical situations. In this paper, a simple nonparametric classifier based on the local mean vectors is proposed. The proposed classifier is compared with the I-NN, k-NN, Euclidean distance (ED), Parzen, and artificial neural network (ANN) classifiers in terms of the error rate on the unknown patterns, particularly in small training sample size situations. Experimental results show that the proposed classifier is promising even in practical situations. (c) 2005 Elsevier B.V. All rights reserved.	Ube Natl Coll Technol, Dept Intelligent Syst Engn, Ube, Yamaguchi 7558555, Japan; Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan	Mitani, Y (reprint author), Ube Natl Coll Technol, Dept Intelligent Syst Engn, 2-14-1 Tokiwadai, Ube, Yamaguchi 7558555, Japan.	mitani@ube-k.ac.jp					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, IEEE COMPUTER SOC PR; Devijver P. A., 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1969, IEEE T COMPUT, VC 18, P220, DOI 10.1109/T-C.1969.222635; Hamamoto Y, 1996, IEEE T PATTERN ANAL, V18, P571, DOI 10.1109/34.494648; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1988, PATTTERN RECOGNITION; Mitani Y., 2000, P 15 INT C PATT REC, V2, P773; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rumelhart D E, 1986, PARALLEL DISTRIBUTED; SCHMIDT WF, 1994, PATTERN RECOGN, V4, P391; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; Yamamoto K, 1996, IEICE T INF SYST, VE79D, P417	19	22	24	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 15	2006	27	10					1151	1159		10.1016/j.patrec.2005.12.016		9	Computer Science, Artificial Intelligence	Computer Science	049LP	WOS:000238018200012	
J	Cannas, B; Cau, F; Fanni, A; Sonato, P; Zedda, MK				Cannas, B.; Cau, F.; Fanni, A.; Sonato, P.; Zedda, M. K.		JET-EFDA Contributors	Automatic disruption classification at JET: comparison of dinerent pattern recognition techniques	NUCLEAR FUSION			English	Article; Proceedings Paper	16th Topical Conference on RF Power in Plasmas	APR, 2005	Park City, UT				MHD STABILITY; ASDEX UPGRADE; TOKAMAKS; CLASSIFIERS; PREDICTOR; NETWORKS; LIMITS; MODEL	In this paper, different pattern recognition techniques have been tested in order to implement an automatic tool for disruption classification in a tokamak experiment. The methods considered refer to clustering and classification techniques. In particular, the investigated clustering techniques are self-organizing maps and K-means, while the classification techniques are multi-layer perceptrons, support vector machines, and k- nearest neighbours. Training and testing data have been collected selecting suitable diagnostic signals recorded over 4 years of EFDA-JET experiments. Multi-layer perceptron classifiers exhibited the best performance in classifying mode lock, density limit/high radiated power, H-mode/L-mode transition and internal transport barrier plasma disruptions. This classification performance can be increased using multiple classifiers. In particular the outputs of five multi-layer perceptron classifiers have been combined using multiple classifier techniques in order to obtain a more robust and reliable classification tool, that is presently implemented at JET.	Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy; EURATOM ENEA Assoc, Consorzio RFX, I-35127 Padua, Italy	Cannas, B (reprint author), Univ Cagliari, Dept Elect & Elect Engn, Piazzi Armi, I-09123 Cagliari, Italy.						Borrass K, 2004, NUCL FUSION, V44, P752, DOI 10.1088/0029-5515/44/7/007; Cannas B, 2004, NUCL FUSION, V44, P68, DOI 10.1088/0029-5515/44/1/008; Chang C-C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Duda R.O., 2000, PATTERN CLASSIFICATI; FIELDING SJ, 1977, NUCL FUSION, V17, P1382, DOI 10.1088/0029-5515/17/6/020; FUMERA G, 2002, LNCS, V2396, P424; GREENWALD M, 1988, NUCL FUSION, V28, P2199, DOI 10.1088/0029-5515/28/12/009; Greenwald M, 2002, PLASMA PHYS CONTROL, V44, P27; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hender TC, 2002, PLASMA PHYS CONTR F, V44, P1143, DOI 10.1088/0741-3335/44/7/306; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Mirnov S, 1999, NUCL FUSION, V39, P2251, DOI 10.1088/0029-5515/39/12/303; MURAKAMI M, 1976, NUCL FUSION, V16, P347, DOI 10.1088/0029-5515/16/2/020; NAVE MFF, 1990, NUCL FUSION, V30, P2575, DOI 10.1088/0029-5515/30/12/011; NOLL P, 1985, 11TH P S FUS ENG AUS, V1, P33; PAUTASSO G, 1998, ICPP 25 EPS C CONT C, V22, P520; Pautasso G, 2002, NUCL FUSION, V42, P100, DOI 10.1088/0029-5515/42/1/314; Principe J, 2000, NEURAL ADAPTIVE SYST; Schuller FC, 1995, PLASMA PHYS CONTR F, V37, pA135, DOI 10.1088/0741-3335/37/11A/009; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; TURNER K, 1999, COMBINING ARTIFICIAL, P127; Vapnik V.N., 1998, STAT LEARNING THEORY; VASANTO J, 1999, P MATLAB DSP C ESP F, P35; WARD DJ, 1992, NUCL FUSION, V32, P1117, DOI 10.1088/0029-5515/32/7/I03; Wesson J., 2004, TOKAMAK; WESSON JA, 1989, NUCL FUSION, V29, P641, DOI 10.1088/0029-5515/29/4/009; Windsor CG, 2005, NUCL FUSION, V45, P337, DOI 10.1088/0029-5515/45/5/004; Wroblewski D, 1997, NUCL FUSION, V37, P725, DOI 10.1088/0029-5515/37/6/I02; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yoshino R, 2003, NUCL FUSION, V43, P1771, DOI 10.1088/0029-5515/43/12/021; ZEDDA MK, 2003, 30 EPS C CONTR FUS A, V27; *MATHW, 2001, NEUR NETW TOOLB US M	37	7	7	INT ATOMIC ENERGY AGENCY	VIENNA	WAGRAMERSTRASSE 5, PO BOX 100, A-1400 VIENNA, AUSTRIA	0029-5515		NUCL FUSION	Nucl. Fusion	JUL	2006	46	7					699	708		10.1088/0029-5515/46/7/002		10	Physics, Fluids & Plasmas; Physics, Nuclear	Physics	069WE	WOS:000239478900017	
J	Hammouche, K; Diaf, M; Postaire, JG				Hammouche, K; Diaf, M; Postaire, JG			A clustering method based on multidimensional texture analysis	PATTERN RECOGNITION			English	Article						cluster analysis; texture; co-occurrence matrices; feature selection	MODE BOUNDARY DETECTION; RANDOM-FIELD MODELS; PATTERN-CLASSIFICATION; SEGMENTATION; RELAXATION; SELECTION; FEATURES; IMAGES	Considering the analogy between image segmentation and cluster analysis, the aim of this paper is to adapt statistical texture measures to describe the spatial distribution of multidimensional observations. The main idea is to consider the cluster cores as domains characterized by their specific textures in the data space. The distribution of the data points is first described as a multidimensional histogram defined on a multidimensional regular array of sampling points. In order to evaluate locally a multidimensional texture, a co-occurrence matrix is introduced, which characterizes the local distribution of the data points in the multidimensional data space. Several local texture features can be computed from this co-occurrence matrix, which accumulates spatial and statistical information on the data distribution in the neighborhoods of the sampling points. Texture features are selected according to their ability to discriminate different distributions of data points. The sampling points where the local underlying texture is evaluated are categorized into different texture classes. The points assigned to these classes tend to form connected components in the data space, which are considered as the cores of the clusters. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Sci & Technol Lille, LAGIS, UMR 8146, CNRS, F-59655 Villeneuve Dascq, France; Univ Mouloud Mammeri, Dept Automat, Tizi Ouzou, Algeria	Postaire, JG (reprint author), Univ Sci & Technol Lille, LAGIS, UMR 8146, CNRS, F-59655 Villeneuve Dascq, France.	Jack-Gerard.Postaire@univ-lille1.fr					ARGENTI F, 1990, IEE PROC-F, V137, P443; Ball G. H., 1965, AD699616 NTIS STANF; BENSLIMANE R, 1996, EUR J AUTOMATION, V30, P1169; Clausi DA, 1998, IEEE T GEOSCI REMOTE, V36, P298, DOI 10.1109/36.655338; Clausi DA, 2002, CAN J REMOTE SENS, V28, P45; Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DANKER AJ, 1981, IEEE T PATTERN ANAL, V3, P79; Davis LS, 1975, COMPUTER GRAPHICS IM, V4, P248, DOI 10.1016/0146-664X(75)90012-X; Devijver P. A., 1982, PATTERN RECOGNITION; Duff I. S., 1986, DIRECT METHODS SPARS; EIGEN DJ, 1974, IEEE T SYST MAN CYB, VSMC4, P284; Haralick R. M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8; LECOCQ CB, 1991, SYMBOLIC-NUMERIC DATA ANALYSIS AND LEARNING, P173; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Porter R, 1996, IEEE T IMAGE PROCESS, V5, P662, DOI 10.1109/83.491343; POSTAIRE JG, 1989, PATTERN RECOGN, V22, P477, DOI 10.1016/0031-3203(89)90018-6; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663; POSTAIRE JG, 1993, IEEE T PATTERN ANAL, V15, P170, DOI 10.1109/34.192490; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/cviu.1993.1024; SBIHI A, 1995, DATA KNOWLEDGE THEOR, P212; SBIHI A, 2000, EUR J AUTOMATION, P247; SBIHI A, 2001, EUR J AUTOMATION, V35, P1073; Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, DOI 10.1142/S0218001488000145; TOUZANI A, 1989, PATTERN RECOGN LETT, V9, P1, DOI 10.1016/0167-8655(89)90022-6; TOUZANI A, 1988, IEEE T PATTERN ANAL, V10, P970, DOI 10.1109/34.9120; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	36	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUL	2006	39	7					1265	1277		10.1016/j.patcog.2005.11.024		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	043GR	WOS:000237588800005	
J	Gombar, VK; Alberts, JJ; Cassidy, KC; Mattioni, BE; Mohutsky, MA				Gombar, Vijay K.; Alberts, James J.; Cassidy, Kenneth C.; Mattioni, Brian E.; Mohutsky, Michael A.			In Silico Metabolism Studies in Drug Discovery: Prediction of Metabolic Stability	CURRENT COMPUTER-AIDED DRUG DESIGN			English	Article						In silico; ADME; metabolism; metabolic stability; drug discovery; QSAR models; ADME software	RELATIONSHIP 3D/4D-QSAR ANALYSES; HUMAN CYTOCHROME P4502C9; CRYSTAL-STRUCTURE; ACTIVE-SITE; MOLECULAR-DYNAMICS; CYP2C9 INHIBITORS; STATE INDEXES; JOHNS WORT; HOMOLOGY; MODELS	The strategy to screen compounds solely for pharmacological potency and selectivity in the early stages of drug discovery brought the pharmaceutical industry to face the stark reality of disproportionate attrition later in the development stage due to poor drug disposition characteristics. This attrition contributed to the exorbitant costs of discovering and developing drugs. Considering ADME (Absorption, Distribution, Metabolism, and Excretion) characteristics of compounds early in the discovery process can wisely direct resources to compounds that have greater potential to survive the clinical trial stages of drug development. However, experimental determination of ADME characteristics is not practical for large numbers of compounds. Therefore, focus is being centered on bringing in silico approaches earlier in the discovery process to assess ADME properties solely from molecular structure. Given that metabolism is one of the most important of the ADME properties, in this paper we review a number of metabolism in silico tools and models that have potential applications in drug discovery. We then describe a step-by-step process, as practiced in our laboratories, to construct and deploy reliable in silico metabolic stability and other ADME screens. Additionally, we give examples of the application of our metabolic stability in silico screens in scaffold selection, ADME space enrichment, and rationalizing synthesis and testing of compounds in the drug discovery process. Agreements between the experimental and in silico metabolic stability values ranging from 84% to 100% have convinced many discovery project teams to routinely use these in silico models. Finally, we present our ideas on the successful implementation of in silico models and tools for significant impact on drug discovery and development.	[Gombar, Vijay K.; Alberts, James J.; Cassidy, Kenneth C.; Mattioni, Brian E.; Mohutsky, Michael A.] Lilly Corp Ctr, Lilly Res Labs, Indianapolis, IN 46285 USA	Gombar, VK (reprint author), Lilly Corp Ctr, Lilly Res Labs, Indianapolis, IN 46285 USA.	gombarvi@lilly.com					ABRAHAM MH, 1993, CHEM SOC REV, V22, P73, DOI 10.1039/cs9932200073; Afzelius L, 2001, MOL PHARMACOL, V59, P909; Baurin N, 2004, J CHEM INF COMP SCI, V44, P276, DOI 10.1021/ci0341565; BOYLAND E, 1962, ANNU REV PHARMACOL, V2, P129, DOI 10.1146/annurev.pa.02.040162.001021; BRAVI G, 1977, COMPUT AIDED MOL DES, V11, P79; Cashman JR, 1996, DRUG DISCOV TODAY, V1, P209, DOI 10.1016/1359-6446(96)10017-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMER RD, 1988, J AM CHEM SOC, V110, P5959, DOI 10.1021/ja00226a005; Cristianini N, 2000, INTRO SUPPORT VECTOR; Crivori P, 2004, J COMPUT AID MOL DES, V18, P155, DOI 10.1023/B:JCAM.0000035184.11906.c2; deGroot MJ, 1996, CHEM RES TOXICOL, V9, P1079, DOI 10.1021/tx960003i; DELVIN JP, 1996, NETWORK SCI COMBI CH; DIMASI JA, 1995, CLIN PHARMACOL THER, V58, P1, DOI 10.1016/0009-9236(95)90066-7; Draper N., 1981, APPL REGRESSION ANAL; Ekins S, 2000, DRUG METAB DISPOS, V28, P994; Ekins S, 1999, PHARMACOGENETICS, V9, P477; Ekins S, 1999, J PHARMACOL EXP THER, V291, P424; Ekins S, 2002, DRUG METAB DISPOS, V30, P96, DOI 10.1124/dmd.30.1.96; GILLETTE JR, 1963, PROGRESS DRUG RESEAR, V6, P11; Gombar VK, 2003, CURR TOP MED CHEM, V3, P1205, DOI 10.2174/1568026033452014; Graupe D., 1997, PRINCIPLES ARTIFICIA; HALL LH, 1995, J CHEM INF COMP SCI, V35, P1039, DOI 10.1021/ci00028a014; HANSCH C, 1973, J MED CHEM, V16, P1207, DOI 10.1021/jm00269a003; Honkakoski P, 2003, ANN MED, V35, P172, DOI 10.1080/07853890310008224; HOUSTON JB, 1994, BIOCHEM PHARMACOL, V47, P1469; Jones JP, 1996, DRUG METAB DISPOS, V24, P1; Kemp CA, 2004, J MED CHEM, V47, P5340, DOI 10.1021/jm049934e; Kier LB, 1999, MOL STRUCTURE DESCRI; Kirton SB, 2002, PROTEINS, V49, P216, DOI 10.1002/prot.10192; Kitchen DB, 2004, NAT REV DRUG DISCOV, V3, P935, DOI 10.1038/nrd1549; Klaassen CD, 2005, CURR DRUG METAB, V6, P309, DOI 10.2174/1389200054633826; Lantz RJ, 2003, DRUG METAB DISPOS, V31, P1142, DOI 10.1124/dmd.31.9.1142; LEO AJ, 1993, CHEM REV, V93, P1281, DOI 10.1021/cr00020a001; Levy R. H., 2000, METABOLIC DRUG INTER; Lewin JL, 2004, MOL PHARMACEUT, V1, P128, DOI 10.1021/mp049977r; Lewis DFV, 1999, TOXICOLOGY, V133, P1, DOI 10.1016/S0300-483X(98)00149-8; Lewis DFV, 1998, XENOBIOTICA, V28, P235; Lewis DFV, 2000, XENOBIOTICA, V30, P1; LEWIS DVF, 2001, J CHEM TECHNOL BIOT, P237; Li AP, 2001, DRUG DISCOV TODAY, V6, P357, DOI 10.1016/S1359-6446(01)01712-3; MATHIEU MP, 2004, PAREXELS PHARM R D S; MCLACHLAN GJ, 1992, DISCRIMINAT ANAL STA; Mestres J, 2005, PROTEINS, V58, P596, DOI 10.1002/prot.20354; Nicolaou K. C, 2002, HDB COMBINATORIAL CH; Park JY, 2003, J MED CHEM, V46, P1645, DOI 10.1021/jm020538a; Pastor M, 2000, J MED CHEM, V43, P3233, DOI 10.1021/jm000941m; Rao S, 2000, J MED CHEM, V43, P2789, DOI 10.1021/jm000048n; Ratti E, 2001, PURE APPL CHEM, V73, P67, DOI 10.1351/pac200173010067; Ridderstrom M, 2001, J MED CHEM, V44, P4072, DOI 10.1021/jm0109107; RODRIGUES DA, 1997, PHARM RES, P1504; Ruschitzka F, 2000, LANCET, V355, P548, DOI 10.1016/S0140-6736(99)05467-7; Schoch GA, 2004, J BIOL CHEM, V279, P9497, DOI 10.1074/jbc.M312516200; Shen M, 2003, J MED CHEM, V46, P3013, DOI 10.1021/jm020491t; SKOLNICK JL, 1976, JAMA-J AM MED ASSOC, V236, P1382, DOI 10.1001/jama.236.12.1382; Sprague PW, 1995, PERSPECT DRUG DISCOV, V3, P1, DOI 10.1007/BF02174464; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; STROBL GR, 1993, J MED CHEM, V36, P1136, DOI 10.1021/jm00061a004; Szklarz GD, 1998, DRUG METAB DISPOS, V26, P1179; Szklarz GD, 2002, J BIOMOL STRUCT DYN, V20, P155; Szklarz GD, 1997, J COMPUT AID MOL DES, V11, P265, DOI 10.1023/A:1007956612081; Tanaka T, 2004, CHEM PHARM BULL, V52, P836, DOI 10.1248/cpb.52.836; Tanaka T, 2004, CHEM PHARM BULL, V52, P830, DOI 10.1248/cpb.52.830; Tarbit MH, 1998, CURR OPIN CHEM BIOL, V2, P411, DOI 10.1016/S1367-5931(98)80017-3; Tetko IV, 2001, J CHEM INF COMP SCI, V41, P1407, DOI 10.1021/ci010368v; Thompson TN, 2000, CURR DRUG METAB, V1, P215, DOI 10.2174/1389200003339018; Todeschini R., 2000, HDB MOL DESCRIPTORS; Vapnik V.N., 1995, NATURE STAT LEARNING; VERONESE ME, 1993, BIOCHEM J, V289, P533; Votano JR, 2005, CURR OPIN DRUG DISC, V8, P32; Wang QM, 2002, DRUG METAB DISPOS, V30, P86, DOI 10.1124/dmd.30.1.86; Watkins RE, 2001, SCIENCE, V292, P2329, DOI 10.1126/science.1060762; Watkins RE, 2003, BIOCHEMISTRY-US, V42, P1430, DOI 10.1021/bi0268753; Wester MR, 2004, J BIOL CHEM, V279, P35630, DOI 10.1074/jbc.M405427200; White RE, 2000, ANNU REV PHARMACOL, V40, P133, DOI 10.1146/annurev.pharmtox.40.1.133; Williams JA, 2004, DRUG METAB DISPOS, V32, P1201, DOI 10.1124/dmd.104.000794; Williams PA, 2004, SCIENCE, V305, P683, DOI 10.1126/science.1099736; Williams PA, 2003, NATURE, V424, P464, DOI 10.1038/nature01862; Windshugel B, 2005, J MOL MODEL, V11, P69, DOI 10.1007/s00894-004-0227-4; Wold H., 1985, ENCY STATISTICAL SCI, V6, P581; Yano JK, 2004, J BIOL CHEM, V279, P38091, DOI 10.1074/jbc.C400293200; Yano JK, 2005, NAT STRUCT MOL BIOL, V12, P822, DOI 10.1038/nsmb971; *DRUG SAF EV COS I, 2001, DEV WHIT PAP; 1995, TESTA B METABOLISM D	83	4	5	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4099		CURR COMPUT-AID DRUG	Curr. Comput.-Aided Drug Des.	JUN	2006	2	2					177	188		10.2174/157340906777441726		12	Chemistry, Medicinal; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Computer Science	V17TH	WOS:000207959000008	
J	Maas, MC; van der Laan, DJ; Schaart, DR; Huizenga, J; Brouwer, JC; Bruyndonckx, P; Leonard, S; Lemaitre, C; van Eijk, CWE				Maas, MC; van der Laan, DJ; Schaart, DR; Huizenga, J; Brouwer, JC; Bruyndonckx, P; Leonard, S; Lemaitre, C; van Eijk, CWE			Experimental characterization of monolithic-crystal small animal PET detectors read out by APD arrays	IEEE TRANSACTIONS ON NUCLEAR SCIENCE			English	Article						angle of incidence; avalanche photodiode (APD); depth-of-interaction; monolithic scintillator crystals; nearest neighbor method; positron emission tomography (PET); spatial resolution	NEURAL-NETWORK; DESIGN; SCINTILLATORS; SCANNER	Minimizing dead space is one way to increase the detection efficiency of small-animal PET scanners. By using monolithic scintillator crystals (e.g., 20 mm x 10 mm x 10 mm LSO), loss of efficiency due to inter-crystal reflective material is minimized. Readout of such crystals can be performed by means of one or more avalanche photo-diode (APD) arrays optically coupled to the crystal. The entry point of a gamma photon on the crystal surface can be estimated from the measured distribution of the scintillation light over the APD array(s). By estimating the entry point, correction for the depth-of-interaction (DOI) is automatically provided. We are studying the feasibility of such detector modules. To this end, a 64-channel test setup has been developed. Experiments to determine the effect on the spatial resolution of crystal surface finish and detector geometry have been carried out. The first results of these experiments are presented and compared to simulation results. The crystal surface finish has only a small influence on the spatial resolution. The spatial resolution of 20 mm x 10 nun x 10 mm detectors is significantly better when read out on the front side than when read out on the back side. With a 20 mm x 10 mm x 20 mm crystal coupled to two APD arrays, a very small resolution degradation of only similar to 0.2 min is observed for an incidence angle of 30 degrees compared to normal incidence.	Delft Univ Technol, NL-2629 JB Delft, Netherlands; Vrije Univ Brussels, Inter Univ Inst High Energies, B-1050 Brussels, Belgium	Maas, MC (reprint author), Delft Univ Technol, NL-2629 JB Delft, Netherlands.	m.c.maas@tnw.tudelft.nl					ADAM LE, 2000, P IEEE NSS, V3, P17; Antich P, 2002, NUCL INSTRUM METH A, V480, P782, DOI 10.1016/S0168-9002(01)01214-1; Bruyndonckx P, 2003, IEEE T NUCL SCI, V50, P1415, DOI 10.1109/TNS.2003.817348; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; CLEMENT D, 1998, P IEEE NSS, V3, P1448; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Delorme S, 1996, NUCL INSTRUM METH A, V373, P111, DOI 10.1016/0168-9002(95)01511-6; Heinrichs U, 2003, IEEE T NUCL SCI, V50, P1428, DOI 10.1109/TNS.2003.817409; KHODAVERDI M, 2001, P IEEE NSS, V3, P1605; Slates R, 1999, IEEE T NUCL SCI, V46, P565, DOI 10.1109/23.775580; Slates R, 2000, IEEE T NUCL SCI, V47, P1018, DOI 10.1109/23.856541; Tai YC, 2003, PHYS MED BIOL, V48, P1519, DOI 10.1088/0031-9155/48/11/303; van Eijk CWE, 2002, PHYS MED BIOL, V47, pR85, DOI 10.1088/0031-9155/47/8/201; VANDERLAAN DJ, 2004, P IEEE NSS MIC, V4, P2417; VANDERLAAN DJ, IN PRESS IEEE T NUCL	15	37	37	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9499		IEEE T NUCL SCI	IEEE Trans. Nucl. Sci.	JUN	2006	53	3	2				1071	1077		10.1109/TNS.2006.873711		7	Engineering, Electrical & Electronic; Nuclear Science & Technology	Engineering; Nuclear Science & Technology	057FP	WOS:000238582000002	
J	Wang, H				Wang, H			Nearest neighbors by neighborhood counting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; machine learning; nearest neighbors; distance; similarity; neighborhood counting measure	CLASSIFICATION	Finding nearest neighbors is a general idea that underlies many artificial intelligence tasks, including machine learning, data mining, natural language understanding, and information retrieval. This idea is explicitly used in the k- nearest neighbors algorithm ( kNN), a popular classification method. In this paper, this idea is adopted in the development of a general methodology, neighborhood counting, for devising similarity functions. We turn our focus from neighbors to neighborhoods, a region in the data space covering the data point in question. To measure the similarity between two data points, we consider all neighborhoods that cover both data points. We propose to use the number of such neighborhoods as a measure of similarity. Neighborhood can be defined for different types of data in different ways. Here, we consider one definition of neighborhood for multivariate data and derive a formula for such similarity, called neighborhood counting measure or NCM. NCM was tested experimentally in the framework of kNN. Experiments show that NCM is generally comparable to VDM and its variants, the state- of- the- art distance functions for multivariate data, and, at the same time, is consistently better for relatively large k values. Additionally, NCM consistently outperforms HEOM ( a mixture of Euclidean and Hamming distances), the " standard" and most widely used distance function for multivariate data. NCM has a computational complexity in the same order as the standard Euclidean distance function and NCM is task independent and works for numerical and categorical data in a conceptually uniform way. The neighborhood counting methodology is proven sound for multivariate data experimentally. We hope it will work for other types of data.	Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland; Univ Metz, LITA, F-57045 Metz, France	Wang, H (reprint author), Univ Ulster, Sch Comp & Math, Fac Engn, Jordanstown BT37 0QB, North Ireland.	h.wang@ulster.ac.uk	jia, lp/H-5750-2011				Ash R., 2000, PROBABILITY MEASURE; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Blake CL, 1998, UCI REPOSITORY MACHI; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DOMINGOS P, 1995, P 1995 INT JOINT C A; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; ELKAN C, 1999, RESULTS KDD 99 CLASS; Fix E., 1951, TR4 US AIR FORC SCH; Gardenfors P., 2000, CONCEPTUAL SPACES GE; Hand D.J., 2001, PRINCIPLES DATA MINI; HAYASHI H, 2001, OPTIMIZATION NEAREST; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; MITCHELL TM, 1997, MACHINE LEARING; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; OSBORNE H, 1997, P INT WORKSH SIM CAT, P173; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SNEDECOR GW, 2002, STAT METHODS; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STEVENS SS, 1951, MATH MEASUREMENT PSY; TOWELL GG, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P861; Wang H, 2004, INT J APPROX REASON, V36, P223, DOI 10.1016/j.ijar.2003.10.007; Widdows D., 2004, GEOMETRY MEANING; Wikipedia Foundation, WIK FREE ENC; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	29	40	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					942	953				12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	031WB	WOS:000236734400008	
J	Zhao, QF				Zhao, QF			Inducing NNC-Trees with the R-4-rule	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						decision trees; machine learning and understanding; nearest neighbor classifier; neural networks; NNC-trees; R-4-rule	NEIGHBOR PATTERN-CLASSIFICATION; FUZZY DECISION TREES; HIERARCHICAL-CLASSIFICATION; ALGORITHM; RULE; MLP	An NNC-Tree is a decision tree (DT) with each non-terminal node containing a nearest neighbor classifier (NNC). Compared with the conventional axis-parallel DTs (APDTs), the NNC-Trees can be more efficient, because the decision boundary made by an NNC is more complex than an axis-parallel hyperplane. Compared with single-layer NNCs, the NNC-Trees can classify given data in a hierarchical structure that is often useful for many applications. This paper proposes an algorithm for inducing NNC-Trees based on the R-4-rule, which was proposed by tine author for finding the smallest nearest neighbor based multilayer perceptrons (NN-MLPs). There are mainly two contributions here. 1) A heuristic but effective method is given to define the teacher signals (group labels) for the data assigned to each nonterminal node. 2) The R-4-rule is modified so that an NNC with proper size can be designed automatically in each nonterminal node. Experiments with several public databases show that the proposed algorithm can produce NNC-Trees effectively and efficiently.	Univ Aizu, Fukushima 9658580, Japan	Zhao, QF (reprint author), Univ Aizu, Fukushima 9658580, Japan.						Adams RG, 1999, NEURAL NETWORKS, V12, P541, DOI 10.1016/S0893-6080(99)00010-6; Basak J, 2004, NEURAL COMPUT, V16, P1959, DOI 10.1162/0899766041336396; Basak J, 2005, IEEE T KNOWL DATA EN, V17, P121, DOI 10.1109/TKDE.2005.11; Brieman L, 1984, CLASSIFICATION REGRE; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GOLEA M, 1990, EUROPHYS LETT, V12, P105; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Janikow CZ, 1998, IEEE T SYST MAN CY B, V28, P1, DOI 10.1109/3477.658573; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kearns M. J., 1994, INTRO COMPUTATIONAL; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LI T, 1993, NEUROCOMPUTING, V5, P119, DOI 10.1016/0925-2312(93)90032-X; LINDE Y, 1980, IEEE T COMMUN, V28, P1; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MIZUNO S, 2002, P IEEE INT C SYST MA, P239; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Suarez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409; Takeda T, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P513; TAKEDA T, 2003, P INT C HYBR INT SYS, P107; Tsukimoto H, 2000, IEEE T NEURAL NETWOR, V11, P377, DOI 10.1109/72.839008; XU QZ, 2004, ON LINE J NEURO INF, V3, P77; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; ZHAO QF, 2004, P IEEE INT C SYST MA, P5702; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	38	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	JUN	2006	36	3					520	533		10.1109/TSMCB.2005.861868		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	050EB	WOS:000238069200004	
J	Liu, T; Moore, AW; Gray, A				Liu, Ting; Moore, Andrew W.; Gray, Alexander			New algorithms for efficient high-dimensional nonparametric classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						ball-tree; k-NN classification	NEAREST-NEIGHBOR CLASSIFICATION; CLASSIFIERS; RULE; DESIGN; TREES	This paper is about non-approximate acceleration of high-dimensional nonparametric operations such as k nearest neighbor classifiers. We attempt to exploit the fact that even if we want exact answers to nonparametric queries, we usually do not need to explicitly find the data points close to the query, but merely need to answer questions about the properties of that set of data points. This offers a small amount of computational leeway, and we investigate how much that leeway can be exploited. This is applicable to many algorithms in nonparametric statistics, memory-based learning and kernel-based learning. But for clarity, this paper concentrates on pure k-NN classification. We introduce new ball-tree algorithms that on real-world data sets give accelerations from 2-fold to 100-fold compared against highly optimized traditional ball-tree-based k-NN. These results include data sets with up to 106 dimensions and 105 records, and demonstrate non-trivial speed-ups while giving exact answers.	Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA	Liu, T (reprint author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.	TINGLIU@CS.CMU.EDU; AWM@CS.CMU.EDU; AGRAY@CS.CMU.EDU					Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BAXTER J, 1998, ADV NEURAL INFORM PR, V10; BAY SD, 1999, UCI KDD ARCH; Cardie C., 1997, P 14 INT C MACH LEAR, P57; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CIACCIA P, 1997, P 23 VLDB INT C SEPT; CLARKSON KL, 2002, NEAREST NEIGHBOR SEA; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Deng K., 1995, P 12 INT JOINT C ART, P1233; Devroye L., 1982, NEAREST NEIGHBOR MET, V2; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Draper N., 1981, APPL REGRESSION ANAL; Duda R., 1973, PATTERN CLASSIFICATI; FALOUTSOS C, 1995, CSTR3514 CARN MELL U; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, DOI 10.1007/BF00962238; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FISHER FP, 1970, P NATL EL C DEC, V26, P481; Flickner M., 1995, IEEE COMPUT, V28, P23; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GIONIS A, 1999, P 25 VLDB C; Gray A. G., 2001, ADV NEURAL INFORM PR; GUTTMAN A, 1984, P 3 ACM SIGACT SIGMO; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HAMMERSLEY JM, 1950, ANN MATH STAT, V21, P447, DOI 10.1214/aoms/1177729805; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; INDYK P, 2001, J COMPUTER SYSTEM SC, V63; KOIVUNE V, 1995, IEEE WORKSH NONL SIG; Komarek P, 2003, ARTIFICIAL INTELLIGE; KREUGEL C, 2003, P 10 ACM C COMP COMM, P251; Lee EW, 1998, IEEE T PATTERN ANAL, V20, P562; LIU T, 2004, P C KNOWL DISC DAT K; Liu T, 2004, P NEUR INF PROC SYST; MANEEWONGVATANA S, 2001, P WADS 2001; MOORE AW, 2000, 12 C UNC ART INT; Omachi S., 2000, Systems and Computers in Japan, V31; Omohundro S. M., 1987, Complex Systems, V1; OMOHUNDRO SM, 1991, ADV NEURAL INFORM PR, V3; PALAU AM, 1998, P 14 INT C PATT REC; PEDNAULT EPD, 2000, HANDLING IMBALANCED; PELLEG D, 1999, P 5 INT C KNOWL DISC; PENTLAND A, 1994, PHOTOBOOK CONTENT BA; Preparata F. P., 1985, COMPUTATIONAL GEOMET; QI Y, 2003, P IEEE INT C MULT EX; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Salton G, 1983, INTRO MODERN INFORM; SETHI IK, 1981, IEEE T SYST MAN CYB, V11, P245; SMEULDERS A, 1996, IMAGE DATABASES MULT; STOLFO S, 1997, CREDIT CARD FRAUD DE; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; ZHANG T, 1996, P 15 ACM SIGACT SIGM; Zheng WF, 2000, J CHEM INF COMP SCI, V40, P185, DOI 10.1021/ci980033m	58	4	5	MICROTOME PUBLISHING	BROOKLINE	31 GIBBS STREET, BROOKLINE, MA 02446 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2006	7						1135	1158				24	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	152UV	WOS:000245388400010	
J	Everson, RM; Fieldsend, JE				Everson, RM; Fieldsend, JE			Multi-class ROC analysis from a multi-objective optimisation perspective	PATTERN RECOGNITION LETTERS			English	Article						receiver operating characteristic; evolutionary computation; multiple objectives; Pareto optimality; Gini coefficient	CLASSIFICATION; CURVE; AREA; CLASSIFIERS	The receiver operating characteristic (ROC) has become a standard tool for the analysis and comparison of classifiers when the costs of misclassification are unknown. There has been relatively little work, however, examining ROC for more than two classes. Here we discuss and present an extension to the standard two-class ROC for multi-class problems. We define the ROC surface for the Q-class problem in terms of a multi-objective optimisation problem in which the goal is to simultaneously minimise the Q(Q-1) misclassification rates, when the misclassification costs and parameters governing the classifier's behaviour are unknown. We present an evolutionary algorithm to locate the Pareto front-the optimal trade-off surface between misclassifications of different types. The use of the Pareto optimal surface to compare classifiers is discussed and we present a straightforward multi-class analogue of the Gini coefficient. The performance of the evolutionary algorithm is illustrated on a synthetic three class problem, for both k-nearest neighbour and multi-layer perceptron classifiers. (c) 2005 Elsevier B.V. All rights reserved.	Univ Exeter, Dept Comp Sci, Sch Engn Comp Sci & Math, Exeter EH4 4QF, Devon, England	Everson, RM (reprint author), Univ Exeter, Dept Comp Sci, Sch Engn Comp Sci & Math, Harrison Bldg, Exeter EH4 4QF, Devon, England.	R.M.Everson@exeter.ac.uk; J.E.Fieldsend@exeter.ac.uk					Adams NM, 1999, PATTERN RECOGN, V32, P1139, DOI 10.1016/S0031-3203(98)00154-X; Anastasio MA, 1998, IEEE T MED IMAGING, V17, P1089, DOI 10.1109/42.746726; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Coello C. A. C., 1999, Knowledge and Information Systems, V1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deb K., 2001, MULTIOBJECTIVE OPTIM; Duda R., 1973, PATTERN CLASSIFICATI; EVERSON RM, 2006, IN PRESS IEEE T EVOL; Fan J., 1996, LOCAL POLYNOMIAL MOD; Fieldsend J., 2005, P ROCML 2005 22 INT, P41; Fieldsend J. E., 2005, P ROCML 2005 22 INT, P49; FIELDSEND JE, 2004, P ROCAI 2004, P37; Fieldsend JE, 2003, IEEE T EVOLUT COMPUT, V7, P305, DOI 10.1109/TEVC.2003.810733; Flach P., 2003, DATA MINING DECISION, P81; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29; HERNANDEZORALLO J, 2004, ROC ANAL ARTIFICIAL; HOLMES CC, 2002, J ROYAL STAT SOC B, V64, P1; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Knowles JD, 2000, EVOL COMPUT, V8, P149, DOI 10.1162/106365600568167; Kupinski MA, 1999, IEEE T MED IMAGING, V18, P675, DOI 10.1109/42.796281; Mossman D, 1999, MED DECIS MAKING, V19, P78, DOI 10.1177/0272989X9901900110; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; SCOTT MJJ, 1998, CUEDFINFENGTR323; Srinivasan A., 1999, PRGTR299 OXF U COMP; Van Veldhuizen DA, 2000, EVOL COMPUT, V8, P125; Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82; ZWEIG MH, 1993, CLIN CHEM, V39, P561	31	33	35	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2006	27	8					918	927		10.1016/j.patrec.2005.10.016		10	Computer Science, Artificial Intelligence	Computer Science	041NL	WOS:000237462800008	
J	Shen, HB; Yang, J; Chou, KC				Shen, HB; Yang, J; Chou, KC			Fuzzy KNN for predicting membrane protein types from pseudo-amino acid composition	JOURNAL OF THEORETICAL BIOLOGY			English	Article						fuzzy K-nearest neighbors; pseudo-amino acid composition; type-1; type-2; multi-pass transmembrane; lipid chain-anchored; GPI-anchored	SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; SUBCELLULAR LOCATION PREDICTION; SECONDARY STRUCTURE-CONTENT; SORTING SIGNALS; FOLDING TYPES; CLASSIFICATION; LOCALIZATION; INSIGHTS	Cell membranes are vitally important to the life of a cell. Although the basic structure of biological membrane is provided by the lipid bilayer, membrane proteins perform most of the specific functions. Membrane proteins are putatively classified into five different types. Identification of their types is currently an important topic in bioinformatics and proteomics. In this paper, based on the concept of representing protein samples in terms of their pseudo-amino acid composition (Chou, K.C., 2001. Prediction of protein cellular attributes using pseudo amino acid composition. Proteins: Struct. Funct. Genet. 43, 246-255), the fuzzy K-nearest neighbors (KNN) algorithm has been introduced to predict membrane protein types, and high success rates were observed. It is anticipated that, the current approach, which is based on a branch of fuzzy mathematics and represents a new strategy, may play an important complementary role to the existing methods in this area. The novel approach may also have notable impact on prediction of the other attributes, such as protein structural class, protein subcellular localization, and enzyme family class, among many others. (c) 2005 Elsevier Ltd. All rights reserved.	Gordon Life Sci Inst, Bioinformat & Drug Discovery, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, Bioinformat & Drug Discovery, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				ALBERTS B, 1994, MOL BIOL CELL, pCH1; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; CHOU KC, 2001, PROTEIN-STRUCT FUNCT, V44, P43; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1992, EUR J BIOCHEM, V207, P429, DOI 10.1111/j.1432-1033.1992.tb17067.x; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2004, J PROTEOME RES, V3, P856, DOI 10.1021/pr049931q; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2004, BIOCHEM BIOPH RES CO, V319, P433, DOI 10.1016/j.bbrc.2004.05.016; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; CHOU KC, 2001, PROTEIN-STRUCT FUNCT, V44, P246; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Chou KC, 2004, BIOCHEM BIOPH RES CO, V325, P506, DOI 10.1016/j.bbrc.2004.10.058; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 1998, PROTEINS, V31, P97, DOI 10.1002/(SICI)1097-0134(19980401)31:1<97::AID-PROT8>3.0.CO;2-E; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2000, J PROTEIN CHEM, V19, P269, DOI 10.1023/A:1007091128394; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; LODISH H, 1995, MOL CELL BIOL, pCH3; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	55	95	98	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	MAY 7	2006	240	1					9	13		10.1016/j.jtbi.2005.08.016		5	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	041YG	WOS:000237492600002	
J	Gupta, MR; Gray, RM; Olshen, RA				Gupta, MR; Gray, RM; Olshen, RA			Nonparametric supervised learning by linear interpolation with maximum entropy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonparametric statistics; probabilistic algorithms; pattern recognition; maximum entropy; linear interpolation	REGRESSION	Nonparametric neighborhood methods for learning entail estimation of class conditional probabilities based on relative frequencies of samples that are "near-neighbors" of a test point. We propose and explore the behavior of a learning algorithm that uses linear interpolation and the principle of maximum entropy (LIME). We consider some theoretical properties of the LIME algorithm: LIME weights have exponential form; the estimates are consistent; and the estimates are robust to additive noise. In relation to bias reduction, we show that near-neighbors contain a test point in their convex hull asymptotically. The common linear interpolation solution used for regression on grids or look-up-tables is shown to solve a related maximum entropy problem. LIME simulation results support use of the method, and performance on a pipeline integrity classification problem demonstrates that the proposed algorithm has practical value.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; Stanford Univ, Informat Syst Lab, Dept Elect Engn, Stanford, CA 94305 USA; Stanford Univ, Dept Hlth Res & Policy, Stanford, CA 94305 USA; Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Gupta, MR (reprint author), Univ Washington, Dept Elect Engn, Box 352500, Seattle, WA 98195 USA.	gupta@ee.washington.edu; rmgray@stanford.edu; olshen@stanford.edu					BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; BICKEL PJ, 1968, ANN MATH STAT, V39, P442, DOI 10.1214/aoms/1177698408; BICKEL PJ, 1983, ANN PROBAB, V11, P185, DOI 10.1214/aop/1176993668; Breiman L, 1984, CLASSIFICATION REGRE; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Guzman M., 1975, DIFFERENTIATION INTE; Devroye L, 1996, PROBABILISTIC THEORY; Fix E, 1951, 4 US AIR FORC SCH AV; FRIEDLANDER MP, 2005, IEEE T INFORM THEORY, V52, P238; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Garsia A., 1970, TOPICS ALMOST EVERYW; GORDON L, 1984, J MULTIVARIATE ANAL, V15, P146; Gray R.M., 1990, ENTROPY INFORM THEOR; GRAY RM, 1997, P COMPR COMPL SEQ C, P172; HASTIE T, 1993, STAT SCI, V8, P120, DOI 10.1214/ss/1177011002; Hastie T, 2001, ELEMENTS STAT LEARNI; HESTERBERG TC, 1997, P SECT STAT COMP AM, P34; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; Kang H. R., 1997, COLOR TECHNOLOGY ELE; Kneale William, 1949, PROBABILITY INDUCTIO; KOHONEN T, 1988, IEEE INT C NEUR NETW, V1, P61; Kullback S., 1959, INFORM THEORY STAT; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Lugosi G, 1996, IEEE T INFORM THEORY, V42, P48, DOI 10.1109/18.481777; MACK YP, 1979, J MULTIVARIATE ANAL, V9, P1, DOI 10.1016/0047-259X(79)90065-4; NAJMI A, 1999, THESIS STANFORD U ST; OBRIEN DB, 2003, P IEEE INT C IM PROC; Peirce Charles S., 1956, PHILOS PEIRCE SELECT; Pollard D., 1984, CONVERGENCE STOCHAST; Press W. H., 1999, NUMERICAL RECIPES C; RICE J, 1984, COMMUN STAT-THEOR M, V13, P893; RIPLEY B, 2001, PATTERN RECOGNITION; Scott D. W., 1992, MULTIVARIATE DENSITY; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Wu N., 1997, MAXIMUM ENTROPY METH; 2002, MATLAB VERSION 6 1 M	39	14	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					766	781		10.1109/TPAMI.2006.101		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	020CO	WOS:000235885700008	
J	Ishikawa, KI; Koyama-Saegusa, K; Otsuka, Y; Ishikawa, A; Kawai, S; Yasuda, K; Suga, T; Michikawa, Y; Suzuki, M; Iwakawa, M; Imai, T				Ishikawa, KI; Koyama-Saegusa, K; Otsuka, Y; Ishikawa, A; Kawai, S; Yasuda, K; Suga, T; Michikawa, Y; Suzuki, M; Iwakawa, M; Imai, T			Gene expression profile changes correlating with radioresistance in human cell lines	INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS			English	Article						radioresistance; gene expression; cancer; microarray analysis	MAMMALIAN-CELLS; IONIZING-RADIATION; HUMAN HOMOLOG; CANCER-CELL; RADIOTHERAPY; APOPTOSIS; RADIOSENSITIVITY; CLASSIFICATION; MICROARRAYS; SENSITIVITY	Purpose: To identify gene expression profiles specific to radioresistance of human cells. Methods and Materials: Global gene expression profiles of a total of 15 tumor and normal fibroblast cell lines were analyzed using DNA microarrays and statistical clustering methods. Initially, six of the cell lines were categorized into radioresistant (RG) or nonradioresistant (NRG) groups according to the radiation dose required to reduce their survival to 10% (D-10). Genes for which expression was specific to each group at 1 or 3 h after irradiation were identified using statistical procedures including analysis of variance and a two-dimensional hierarchical clustering method. The remaining nine cell lines were subjected to the k-nearest neighbor pattern classification. Results: The nine test cell lines were successfully classified by their D-10 value using 46 and 44 genes for which transcription levels had significantly changed at 1 and 3 h after irradiation, respectively. Of these genes, 25 showed altered expression at both time points in the NRG or RG, but independently were unable to classify the test cell lines. Conclusions: Radioresistant cell lines analyzed in this study showed certain radiation-induced changes in gene expression profiles that are different from the profile changes of the more-sensitive cell lines. (c) 2006 Elsevier Inc.	Natl Inst Radiol Sci, Frontier Res Ctr, RadGenom Project, Chiba 2638555, Japan; Natl Inst Radiol Sci, Res Ctr Radiat Safety, Int Space Radiat Lab, Chiba 2638555, Japan	Imai, T (reprint author), Natl Inst Radiol Sci, Frontier Res Ctr, RadGenom Project, 4-9-1 Anagawa, Chiba 2638555, Japan.	imait@nirs.go.jp					Achary MP, 2000, CYTOGENET CELL GENET, V91, P39, DOI 10.1159/000056815; Ambrosini G, 1997, NAT MED, V3, P917, DOI 10.1038/nm0897-917; Ban S, 2005, J RADIAT RES, V46, P43, DOI 10.1269/jrr.46.43; Ban S, 2005, INT J EXP PATHOL, V86, P231, DOI 10.1111/j.0959-9673.2005.00431.x; Berns K, 2004, NATURE, V428, P431, DOI 10.1038/nature02371; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; Chen XF, 2002, CANCER RES, V62, P1213; Chung CH, 2002, NAT GENET, V32, P533, DOI 10.1038/ng1038; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Criswell T, 2003, ONCOGENE, V22, P5813, DOI 10.1038/sj.onc.1206680; DUNNE J, 1995, GENOMICS, V30, P207, DOI 10.1006/geno.1995.9884; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Elbashir SM, 2001, NATURE, V411, P494, DOI 10.1038/35078107; Gudkov AV, 2003, NAT REV CANCER, V3, P117, DOI 10.1038/nrc992; Hahn A, 2000, J BIOL CHEM, V275, P37429, DOI 10.1074/jbc.M000976200; HU MCT, 1987, CELL, V48, P555, DOI 10.1016/0092-8674(87)90234-0; Hughes TR, 2001, NAT BIOTECHNOL, V19, P342, DOI 10.1038/86730; Ito T, 2000, HEPATOLOGY, V31, P1080, DOI 10.1053/he.2000.6496; Iwakawa M, 2004, J RADIAT RES, V45, P423, DOI 10.1269/jrr.45.423; Khodarev NN, 2001, P NATL ACAD SCI USA, V98, P12665, DOI 10.1073/pnas.211443698; Lamande SR, 2002, J BIOL CHEM, V277, P1949, DOI 10.1074/jbc.M109932200; Lee CH, 2004, PHARMACOGENOMICS, V5, P611, DOI 10.1517/14622416.5.6.611; Mackay RI, 1999, RADIOTHER ONCOL, V50, P67, DOI 10.1016/S0167-8140(98)00132-7; Mischel PS, 2004, NAT REV NEUROSCI, V5, P782, DOI 10.1038/nrn1518; Ohnishi K, 2001, INT J HYPERTHER, V17, P415, DOI 10.1080/02656730110063604; Pacheco TR, 1999, GENE, V229, P125, DOI 10.1016/S0378-1119(99)00034-7; Pawlik TM, 2004, INT J RADIAT ONCOL, V59, P928, DOI 10.1016/j.ijrobp.2004.03.005; Perez C. A., 2004, PRINCIPLES PRACTICE; PETERS LJ, 1988, AM J CLIN ONCOL-CANC, V11, P275, DOI 10.1097/00000421-198806000-00005; Rajagopalan D, 2003, BIOINFORMATICS, V19, P1469, DOI 10.1093/bioinformatics/btg202; Roberts CJ, 2000, SCIENCE, V287, P873, DOI 10.1126/science.287.5454.873; SAKAI LY, 1991, J BIOL CHEM, V266, P14763; SAUNDERS S, 1988, J CELL BIOL, V106, P423, DOI 10.1083/jcb.106.2.423; SHIMADA Y, 1992, CANCER, V69, P277, DOI 10.1002/1097-0142(19920115)69:2<277::AID-CNCR2820690202>3.0.CO;2-C; Snyder AR, 2004, CANCER METAST REV, V23, P259, DOI 10.1023/B:CANC.0000031765.17886.fa; Stone EM, 1999, NAT GENET, V22, P199, DOI 10.1038/9722; Suzuki M, 2000, INT J RADIAT BIOL, V76, P1189; Suzuki M, 2000, INT J RADIAT ONCOL, V48, P241, DOI 10.1016/S0360-3016(00)00568-X; Syken J, 1999, P NATL ACAD SCI USA, V96, P8499, DOI 10.1073/pnas.96.15.8499; SZUMIEL I, 1998, RADIAT RES, V150, P92; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; Vallat L, 2003, BLOOD, V101, P4598, DOI 10.1182/blood-2002-06-1743; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; VOGELSTEIN B, 1992, CELL, V70, P523, DOI 10.1016/0092-8674(92)90421-8; WEST CML, 1995, BRIT J RADIOL, V68, P827; West CML, 2005, INT J RADIAT ONCOL, V62, P1264, DOI 10.1016/j.ijrobp.2005.05.001; Xie HQ, 1997, J CELL BIOL, V137, P203, DOI 10.1083/jcb.137.1.203; ZHANG H, 1994, J CELL BIOL, V124, P855, DOI 10.1083/jcb.124.5.855	48	11	11	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0360-3016		INT J RADIAT ONCOL	Int. J. Radiat. Oncol. Biol. Phys.	MAY 1	2006	65	1					234	245		10.1016/j.ijrobp.2005.12.048		12	Oncology; Radiology, Nuclear Medicine & Medical Imaging	Oncology; Radiology, Nuclear Medicine & Medical Imaging	051LM	WOS:000238162600033	
J	Baumes, LA				Baumes, LA			MAP: An iterative experimental design methodology for the optimization of catalytic search space structure modeling	JOURNAL OF COMBINATORIAL CHEMISTRY			English	Article							DISCOVERY; SOLIDS	One of the main problems in high-throughput research for materials is still the design of experiments. At early stages of discovery programs, purely exploratory methodologies coupled with fast screening tools should be employed. This should lead to opportunities to find unexpected catalytic results and identify the "groups" of catalyst outputs, providing well-defined boundaries for future optimizations. However, very few new papers deal with strategies that guide exploratory studies. Mostly, traditional designs, homogeneous covering, or simple random samplings are exploited. Typical catalytic output distributions exhibit unbalanced datasets for which an efficient learning is hardly carried out, and interesting but rare classes are usually unrecognized. Here is suggested a new iterative algorithm for the characterization of the search space structure, working independently of learning processes. It enhances recognition rates by transferring catalysts to be screened from "performance-stable" space zones to "unsteady" ones which necessitate more experiments to be well-modeled. The evaluation of new algorithm attempts through benchmarks is compulsory due to the lack of past proofs about their efficiency. The method is detailed and thoroughly tested with mathematical functions exhibiting different levels of complexity. The strategy is not only empirically evaluated, the effect or efficiency of sampling on future Machine Learning performances is also quantified. The minimum sample size required by the algorithm for being statistically discriminated from simple random sampling is investigated.	Max Planck Inst Kohlenforsch, D-45470 Mulheim, Germany; Inst Rech Catalyse, CNRS, F-69626 Villeurbanne, France	Baumes, LA (reprint author), Max Planck Inst Kohlenforsch, Kaiser Wilhelm Pl 1, D-45470 Mulheim, Germany.	baumesl@itq.upv.es	baumes, laurent/E-2175-2013	baumes, laurent/0000-0001-9363-9089			AHA D. W., 1992, P 9 INT C MACH LEARN, P1; BAUMES LA, 2004, QSAR COMB SCI, V29, P767; BAUMES LA, UNPUB J COMB CHEM; BAUMES LA, 2003, LECT NOTES AI LNCS L; BEM DS, 2003, EXPT DESIGN HIGH THR, P89; BLICKLE T, 1995, 6 INT C GEN ALG SAN; CAWSE JN, 2003, EXPT DESIGN COMBINAT, P109; Chakravarti IM, 1967, HDB METHODS APPL STA, P392; Christensen L.B., 1994, EXPT METHODOLOGY; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Jong K., 1975, THESIS U MICHIGAN; Deming SN, 1993, EXPT DESIGN CHEMOMET; FARRUSSENG D, 2004, 13 ICC PAR FRANC JUL; Farrusseng D, 2005, QSAR COMB SCI, V24, P78, DOI 10.1002/qsar.200420066; Farrusseng D, 2003, HIGH-THROUGHPUT ANALYSIS: A TOOL OF COMBINATORIAL MATERIALS SCIENCE, P551; Fernandez J, 2002, J PHOTOCH PHOTOBIO A, V151, P213, DOI 10.1016/S1010-6030(02)00153-3; Harmon L, 2003, J MATER SCI, V38, P4479, DOI 10.1023/A:1027325400459; HICKEY RJ, 1992, P 9 INT C MACH LEARN, P196; Klanner C, 2004, ANGEW CHEM INT EDIT, V43, P5347, DOI 10.1002/anie.200460731; Montgomery D. C., 1991, DESIGN ANAL EXPT; SAMMUT C, 1990, 7 INT MACH LEARN C A; Senkan S, 2001, ANGEW CHEM INT EDIT, V40, P312, DOI 10.1002/1521-3773(20010119)40:2<312::AID-ANIE312>3.0.CO;2-I; Serra JM, 2003, CATAL TODAY, V81, P425, DOI 10.1016/S0920-5861(03)00142-1; SJOBLOM J, 2004, 11 NORD S CAT OUL FI; Snedecor G. W., 1989, STAT METHODS; STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009; Thierens D, 1997, P 7 INT C GEN ALG MO, P152; TRIBUS M, 1989, QUAL PROG, V22, P46; Whitley D, 1996, ARTIF INTELL, V85, P245, DOI 10.1016/0004-3702(95)00124-7	29	17	17	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1520-4766		J COMB CHEM	J. Comb. Chem.	MAY	2006	8	3					304	314		10.1021/cc050130+		11	Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Chemistry; Pharmacology & Pharmacy	039YG	WOS:000237343900007	
J	Chien, BC; Lin, JY; Yang, WP				Chien, BC; Lin, JY; Yang, WP			A classification tree based on discriminant functions	JOURNAL OF INFORMATION SCIENCE AND ENGINEERING			English	Article; Proceedings Paper	Workshop on Computer Vision, Graphics and Image Processing (CVGIP)	2004	TAIWAN			knowledge discovery; machine learning; genetic programming; classification; discriminant function; decision tree; classifier	SUPPORT VECTOR MACHINES; PATTERN-CLASSIFICATION; NEURAL NETWORKS; FUZZY; RULE	The classification problem is an important topic in knowledge discovery and machine learning. Traditional classification tree methods and their improvements have been discussed widely. This work proposes a new approach to construct decision trees based on discriminant functions which are learned using genetic programming. A discriminant function is a mathematical function for classifying data into a specific class. To learn discriminant functions effectively and efficiently, a distance-based fitness function for genetic programming is designed. After the set of discriminant functions for all classes is generated. a classifier is created as a binary decision tree with the Z-value measure to resolve the problem of ambiguity among discriminant functions. Several popular datasets from the UCI Repository were selected to illustrate the effectiveness of the proposed classifiers by comparing with previous methods. The results show that the proposed classification tree demonstrates high accuracy on the selected datasets.	Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan; Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 300, Taiwan; Natl Dong Hwa Univ, Dept Informat Management, Hualien 974, Taiwan	Chien, BC (reprint author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan.						Blake CL, 1998, UCI REPOSITORY MACHI; Bojarczuk CC, 1999, P GEN EV COMP C ORL, P953; Brameier M, 2001, IEEE T EVOLUT COMPUT, V5, P17, DOI 10.1109/4235.910462; Chen KH, 1997, FUZZY SET SYST, V91, P15, DOI 10.1016/S0165-0114(96)00145-5; Chen YX, 2003, IEEE T FUZZY SYST, V11, P716, DOI 10.1109/TFUZZ.2003.819843; Chien BC, 2002, EXPERT SYST APPL, V23, P31, DOI 10.1016/S0957-4174(02)00025-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Duda R., 1973, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; FREITAS AA, 1997, P 2 ANN C GEN PROGR, P96; Han J., 2001, DATA MINING CONCEPTS; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Karacali B, 2004, PATTERN RECOGN LETT, V25, P63, DOI 10.1016/j.patrec.2003.09.002; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; Koza J. R., 1996, GENETIC PROGRAMMING; Koza J. R., 1992, GENETIC PROGRAMMING; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; Lee YJ, 2001, COMPUT OPTIM APPL, V20, P5, DOI 10.1023/A:1011215321374; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Loveard T, 2001, IEEE C EVOL COMPUTAT, P1070, DOI 10.1109/CEC.2001.934310; Mangasarian O. L., 1990, SIAM NEWS, V23; Nauck D, 1997, FUZZY SET SYST, V89, P277, DOI 10.1016/S0165-0114(97)00009-2; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654; SHI HB, 2003, P 7 PAC AS C KNOWL D, P265; SINDHWANI V, 2001, P SIAM INT C DAT MIN; SINGLETON A, 1994, BYTE             FEB, P171; STEFAOWSKI J, 2003, P S METH ART INT AI, P297; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang ZH, 2003, LECT NOTES ARTIF INT, V2903, P453; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072	35	2	2	INST INFORMATION SCIENCE	TAIPEI	ACADEMIA SINICA, TAIPEI 115, TAIWAN	1016-2364		J INF SCI ENG	J. Inf. Sci. Eng.	MAY	2006	22	3					573	594				22	Computer Science, Information Systems	Computer Science	047VX	WOS:000237907900008	
J	Matsubara, Y; Kikuchi, S; Sugimoto, M; Tomita, M				Matsubara, Yoshiya; Kikuchi, Shinichi; Sugimoto, Masahiro; Tomita, Masaru			Parameter estimation for stiff equations of biosystems using radial basis function networks	BMC BIOINFORMATICS			English	Article							GENETIC ALGORITHMS; NEURAL-NETWORKS; BIOCHEMICAL PATHWAYS; S-SYSTEM; PREDICTION; OPTIMIZATION; TIME; IDENTIFICATION; SELECTION	Background: The modeling of dynamic systems requires estimating kinetic parameters from experimentally measured time-courses. Conventional global optimization methods used for parameter estimation, e. g. genetic algorithms (GA), consume enormous computational time because they require iterative numerical integrations for differential equations. When the target model is stiff, the computational time for reaching a solution increases further. Results: In an attempt to solve this problem, we explored a learning technique that uses radial basis function networks (RBFN) to achieve a parameter estimation for biochemical models. RBFN reduce the number of numerical integrations by replacing derivatives with slopes derived from the distribution of searching points. To introduce a slight search bias, we implemented additional data selection using a GA that searches data-sparse areas at low computational cost. In addition, we adopted logarithmic transformation that smoothes the fitness surface to obtain a solution simply. We conducted numerical experiments to validate our methods and compared the results with those obtained by GA. We found that the calculation time decreased by more than 50% and the convergence rate increased from 60% to 90%. Conclusion: In this work, our RBFN technique was effective for parameter optimization of stiff biochemical models.	Keio Univ, Inst Adv Biosci, Fujisawa, Kanagawa 2528520, Japan; Mitsubishi Space Software Co Ltd, Dept Bioinformat, Amagasaki, Hyogo 6610001, Japan	Kikuchi, S (reprint author), Keio Univ, Inst Adv Biosci, Fujisawa, Kanagawa 2528520, Japan.	yoshiya@sfc.keio.ac.jp; kikuchi@sfc.keio.ac.jp; msugi@sfc.keio.ac.jp; mt@sfc.keio.ac.jp	Kikuchi, Shinichi/A-1681-2010				Agatonovic-Kustrin S, 2003, PHARMAZIE, V58, P725; Agatonovic-Kustrin S, 2003, PHARM RES, V20, P1760, DOI 10.1023/B:PHAM.0000003372.56993.39; Bentele M, 2004, J CELL BIOL, V166, P839, DOI 10.1083/jcb.200404158; Broomhead D. S., 1988, Complex Systems, V2; Chen L, 2000, CONTROL ENG PRACT, V8, P821, DOI 10.1016/S0967-0661(00)00036-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowper MR, 2002, SIGNAL PROCESS, V82, P775, DOI 10.1016/S0165-1684(02)00155-X; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; Deb K, 2002, EVOL COMPUT, V10, P371, DOI 10.1162/106365602760972767; Dhar P, 2004, BIOINFORMATICS, V20, P1319, DOI 10.1093/bioinformatics/bth067; Gardner TS, 2003, SCIENCE, V301, P102, DOI 10.1126/science.1081900; Gear C.W., 1971, NUMERICAL INITIAL VA; Germani M, 2003, CANCER CHEMOTH PHARM, V52, P507, DOI 10.1007/s00280-003-0688-7; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Hatakeyama M, 2003, BIOCHEM J, V373, P451, DOI 10.1042/BJ20021824; Haykin S., 1994, NEURAL NETWORKS COMP; Isaacs FJ, 2003, P NATL ACAD SCI USA, V100, P7714, DOI 10.1073/pnas.1332628100; Ji W, 2003, IEEE T INF TECHNOL B, V7, P218, DOI 10.1109/TITB.2003.813796; Jianyu Li, 2003, Neural Netw, V16, P729, DOI 10.1016/S0893-6080(03)00083-2; Jonikow CZ, 1991, P 4 INT C GEN ALG, P31; Kalir S, 2004, CELL, V117, P713, DOI 10.1016/j.cell.2004.05.010; Kikuchi S, 2003, BIOINFORMATICS, V19, P643, DOI 10.1093/bioinformatics/btg027; Kimura S, 2005, BIOINFORMATICS, V21, P1154, DOI 10.1093/bioinformatics/bti071; Kimura S, 2004, BIOINFORMATICS, V20, P1646, DOI 10.1093/bioinformatics/bth122; Kutalik Z, 2004, BIOSYSTEMS, V75, P43, DOI 10.1016/j.biosystems.2004.03.007; LARRY JE, 1997, P INT C GEN ALG, P354; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; MAKI Y, 2002, GENOME INFORMATICS, V13, P382; Mendes P, 1998, BIOINFORMATICS, V14, P869, DOI 10.1093/bioinformatics/14.10.869; Meng Tan Chee, 2004, In Silico Biol, V4, P293; Michalski R, 1998, COMPUT BIOMED RES, V31, P71, DOI 10.1006/cbmr.1998.1469; Moles CG, 2003, GENOME RES, V13, P2467, DOI 10.1101/gr.1262503; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; NAKAYAMA H, 2001, P INT C ART NEUR NET, P73; Niwa T, 2004, J MED CHEM, V47, P2645, DOI 10.1021/jm0302795; Ono I., 1997, P 7 INT C GEN ALG, P246; ORR MJL, 1995, NEURAL COMPUT, V7, P606, DOI 10.1162/neco.1995.7.3.606; Oyman AI, 2000, EVOL COMPUT, V8, P249, DOI 10.1162/106365600750078772; Park LJ, 1997, MED BIOL ENG COMPUT, V35, P47, DOI 10.1007/BF02510391; Pinchuk RJ, 2000, BIOTECHNOL BIOENG, V67, P19, DOI 10.1002/(SICI)1097-0290(20000105)67:1<19::AID-BIT3>3.0.CO;2-C; Rank E, 2003, SIGNAL PROCESS, V83, P1393, DOI 10.1016/S0165-1684(03)00088-4; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SA B, 1998, NEURAL NETWORKS, V11, P479; SAKUMA H, 2001, P C EV COMP, P553; Someya H, 2002, P GEN EV COMP C, P553; Sugimoto M, 2005, BIOSYSTEMS, V80, P155, DOI 10.1016/j.biosystems.2004.11.003; Swameye I, 2003, P NATL ACAD SCI USA, V100, P1028, DOI 10.1073/pnas.0237333100; Takahashi K, 2004, BIOINFORMATICS, V20, P538, DOI 10.1093/bioinformatics/btg442; Tsai KY, 2005, BIOINFORMATICS, V21, P1180, DOI 10.1093/bioinformatics/bti099; Tsutsui S, 2001, INFORM SCIENCES, V133, P229, DOI 10.1016/S0020-0255(01)00087-1; TSUTSUI S, 1999, P GEN EV COMP C, P73; Tsutsui S, 1998, LECT NOTES COMPUT SC, V1498, P428; Voit EO, 2004, BIOINFORMATICS, V20, P1670, DOI 10.1093/bioinformatics/bth140	54	8	8	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 27	2006	7								230	10.1186/1471-2105-7-230		11	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	082VN	WOS:000240415400001	
J	Yu, XJ; Wang, C; Li, YX				Yu, XJ; Wang, C; Li, YX			Classification of protein quaternary structure by functional domain composition	BMC BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINE; SUBCELLULAR-LOCALIZATION; SWISS-PROT; PREDICTION; DATABASE; PFAM; ALIGNMENTS; ALGORITHM; LOCATION	Background: The number and the arrangement of subunits that form a protein are referred to as quaternary structure. Quaternary structure is an important protein attribute that is closely related to its function. Proteins with quaternary structure are called oligomeric proteins. Oligomeric proteins are involved in various biological processes, such as metabolism, signal transduction, and chromosome replication. Thus, it is highly desirable to develop some computational methods to automatically classify the quaternary structure of proteins from their sequences. Results: To explore this problem, we adopted an approach based on the functional domain composition of proteins. Every protein was represented by a vector calculated from the domains in the PFAM database. The nearest neighbor algorithm ( NNA) was used for classifying the quaternary structure of proteins from this information. The jackknife cross-validation test was performed on the non-redundant protein dataset in which the sequence identity was less than 25%. The overall success rate obtained is 75.17%. Additionally, to demonstrate the effectiveness of this method, we predicted the proteins in an independent dataset and achieved an overall success rate of 84.11% Conclusion: Compared with the amino acid composition method and Blast, the results indicate that the domain composition approach may be a more effective and promising high-throughput method in dealing with this complicated problem in bioinformatics.	Chinese Acad Sci, Shanghai Inst Biol Sci, Bioinformat Ctr, Shanghai 200031, Peoples R China; Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China; Shanghai Ctr Bioinformat Technol, Shanghai 200235, Peoples R China	Li, YX (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, Bioinformat Ctr, 320 Yueyang Rd, Shanghai 200031, Peoples R China.	xjyu@sibs.ac.cn; cwang@sibs.ac.cn; yxli@sibs.ac.cn					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; ANFINSEN CB, 1961, P NATL ACAD SCI USA, V47, P1309, DOI 10.1073/pnas.47.9.1309; Bairoch A, 2004, BRIEF BIOINFORM, V5, P39, DOI 10.1093/bib/5.1.39; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Boeckmann B, 2003, NUCLEIC ACIDS RES, V31, P365, DOI 10.1093/nar/gkg095; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; CHOU KC, 1995, PROTEIN SCI, V4, P1365; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Doyle DA, 1998, SCIENCE, V280, P69, DOI 10.1126/science.280.5360.69; Farmer TB, 1998, J MASS SPECTROM, V33, P697, DOI 10.1002/(SICI)1096-9888(199808)33:8<697::AID-JMS711>3.3.CO;2-8; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Kim Wan Kyu, 2002, Genome Inform, V13, P42; Klotz I. M., 1975, PROTEINS, V1, P293; KLOTZ IM, 1970, ANNU REV BIOCHEM, V39, P25, DOI 10.1146/annurev.bi.39.070170.000325; Li WZ, 2001, BIOINFORMATICS, V17, P282, DOI 10.1093/bioinformatics/17.3.282; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Price N.C., 1994, MECH PROTEIN FOLDING, P160; Song R, 2004, J CHEM INF COMP SCI, V44, P1324, DOI 10.1021/ci034288y; Sonnhammer ELL, 1997, PROTEINS, V28, P405, DOI 10.1002/(SICI)1097-0134(199707)28:3<405::AID-PROT10>3.0.CO;2-L; Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320; SUND H, 1966, ANGEW CHEM INT EDIT, V5, P231, DOI 10.1002/anie.196602311; Tretter V, 1997, J NEUROSCI, V17, P2728; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wojcik J, 2001, BIOINFORMATICS S1, V17, pS296; Yu XJ, 2004, CHINESE SCI BULL, V49, P2379, DOI 10.1360/982004-142; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	38	20	20	BIOMED CENTRAL LTD	LONDON	MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	APR 4	2006	7								187	10.1186/1471-2105-7-187		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	038EN	WOS:000237201700001	
J	Watanabe, T; Komuro, Y; Kiyomatsu, T; Kanazawa, T; Kazama, Y; Tanaka, J; Tanaka, T; Yamamoto, Y; Shirane, M; Muto, T; Nagawa, H				Watanabe, T; Komuro, Y; Kiyomatsu, T; Kanazawa, T; Kazama, Y; Tanaka, J; Tanaka, T; Yamamoto, Y; Shirane, M; Muto, T; Nagawa, H			Prediction of sensitivity of rectal cancer cells in response to preoperative radiotherapy by DNA microarray analysis of gene expression profiles	CANCER RESEARCH			English	Article							ADJUVANT CHEMOTHERAPY; TUMOR-GROWTH; COLON-CANCER; THROMBOSPONDIN-2; CLASSIFICATION; ANGIOGENESIS; APOPTOSIS; SURVIVAL; THERAPY; LUMICAN	Preoperative radiotherapy has been widely used to improve local control of disease and to improve survival in the treatment of rectal cancer. However, the response to radiotherapy differs among individual tumors. Our objective here was to identify a set of discriminating genes that can be used for characterization and prediction of response to radiotherapy in rectal cancer. Fifty-two rectal cancer patients who underwent preoperative radiotherapy were studied. Biopsy specimens were obtained from rectal cancer before preoperative radiotherapy. Response to radiotherapy was determined by histopathologic examination of surgically resected specimens and classified as responders or nonresponders. By determining gene expression profiles using human U95Av2 Gene Chip, we identified 33 novel discriminating genes of which the expression differed significantly between responders and nonresponders. Using this gene set, we were able to establish a new model to predict response to radiotherapy in rectal cancer with an accuracy of 82.4%. The list of discriminating genes included growth factor, apoptosis, cell proliferation, signal transduction, or cell adhesion-related genes. Among 33 discriminating genes, apoptosis inducers (lumican, thrombospondin 2, and galectin-1) showed higher expression in responders whereas apoptosis inhibitors (cyclophilin 40 and glutathione peroxidase) showed higher expression in nonresponders. The present study suggested the possibility that gene expression profiling may be useful in predicting response to radiotherapy to establish an individualized tailored therapy for rectal cancer. Global expression profiles of responders and nonresponders may provide insights into the development of novel therapeutic targets.	Tokyo Univ Hosp, Dept Surg Oncol, Bunkyo Ku, Tokyo 113, Japan; Chugai Pharmaceut Co Ltd, Prod Res Dept, Kanagawa, Japan; JFCR, Canc Inst Hosp, Kotoh Ku, Tokyo, Japan	Watanabe, T (reprint author), Univ Tokyo, Dept Surg Oncol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138655, Japan.	toshwatanabe@yahoo.co.jp					Arango D, 2005, GASTROENTEROLOGY, V129, P874, DOI 10.1053/j.gastro.2005.06.066; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ghadimi BM, 2005, J CLIN ONCOL, V23, P1826, DOI 10.1200/JCO.2005.00.406; Gouaze V, 2001, MOL PHARMACOL, V60, P488; Horiguchi N, 2003, J BIOCHEM, V134, P869, DOI 10.1093/jb/mvg213; Kapiteijn E, 2001, NEW ENGL J MED, V345, P638, DOI 10.1056/NEJMoa010580; Kihara C, 2001, CANCER RES, V61, P6474; KOCKENBERY DM, 1993, CELL, V75, P241; LOWE SW, 1994, SCIENCE, V266, P807, DOI 10.1126/science.7973635; Nagawa H, 2001, DIS COLON RECTUM, V44, P1274, DOI 10.1007/BF02234784; Streit M, 2002, CANCER RES, V62, P2004; Streit M, 1999, P NATL ACAD SCI USA, V96, P14888, DOI 10.1073/pnas.96.26.14888; Pahlman L, 1997, NEW ENGL J MED, V336, P980; Troup S, 2003, CLIN CANCER RES, V9, P207; Vuillermoz B, 2004, EXP CELL RES, V296, P294, DOI 10.1016/j.yexcr.2004.02.005; Watanabe T, 2002, SURGERY, V132, P27, DOI 10.1067/msy.2002.125357; Watanabe T, 2001, NEW ENGL J MED, V344, P1196, DOI 10.1056/NEJM200104193441603; Wong YF, 2003, CLIN CANCER RES, V9, P5486; *JAP SOC CANC COL, 1997, RESP ASS NONS TREATM, P77	20	89	94	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	0008-5472		CANCER RES	Cancer Res.	APR 1	2006	66	7					3370	3374		10.1158/0008-5472.CAN-05-3834		5	Oncology	Oncology	030TO	WOS:000236657800008	
J	Tossavainen, T; Toppila, E; Pyykko, M; Forsman, PM; Juhola, M; Starck, J				Tossavainen, T; Toppila, E; Pyykko, M; Forsman, PM; Juhola, M; Starck, J			Virtual reality in posturography	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Meniere's disease; postural balance; posturography; virtual reality (VR)	POSTURAL CONTROL; BALANCE; FORCE; COMPENSATION; ENVIRONMENT; SELECTION; CHILDREN	Balance dysfunctions are common, especially among elderly people. Present methods for the diagnosis and evaluation of severity of dysfuntion have limited value. We present a system that makes it easy to implement different visual and mechanical perturbations for clinical investigations of balance and visual-vestibular interaction. The system combines virtual reality visual stimulation with force platform posturography on a moving platform. We evaluate our contruction's utility in a classification task between 33 healthy controls and 77 patients with Meniere's disease, using a series of tests with different visual and mechanical stimuli. Responses of patients and controls differ significantly in parameters computed from stabilograms. We also show that the series of tests achieves a classification accuracy slightly over 80% between controls and patients.	Univ Tampere, Dept Comp Sci, FI-33014 Tampere, Finland; Inst Occupat Hlth, FI-00250 Helsinki, Finland; Univ Tampere, Dept Otolaryngol, FI-33014 Tampere, Finland	Tossavainen, T (reprint author), Univ Tampere, Dept Comp Sci, POB 607, FI-33014 Tampere, Finland.	tt@cs.uta.fi					ALLUM JHJ, 1986, DISORDERS POSTURE GA, P19; Andres R O, 1980, Am J Otolaryngol, V1, P197, DOI 10.1016/S0196-0709(80)80089-5; BLACK FO, 1983, ACTA OTO-LARYNGOL, V95, P199, DOI 10.3109/00016488309130936; Brandt T, 1986, DISORDERS POSTURE GA, P157; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Desmedt J E, 1983, Adv Neurol, V39, P227; DROULEZ J, 1996, DISORDERS POSTURE GA, P83; Eberly DH, 2001, 3D GAME ENGINE DESIG; ENBOM H, 1991, ANN OTO RHINOL LARYN, V100, P472; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GURFINKEL E V, 1973, Agressologie, V14, P9; HYTONEN M, 1993, ACTA OTO-LARYNGOL, V113, P119, DOI 10.3109/00016489309135778; JACOBSON I, 2001, P ACM VRST2001, P103; JANTTI PO, 1993, PUBLIC HEALTH, V107, P89, DOI 10.1016/S0033-3506(05)80404-4; KALAWSKY RS, 1993, SCI VIRTUAL REALITY, P253; Karlsson A, 2000, CLIN BIOMECH, V15, P365, DOI 10.1016/S0268-0033(99)00096-0; Keshner EA, 2000, J VESTIBUL RES-EQUIL, V10, P207; KOCHANEK DHU, 1984, P 11 ANN C COMP GRAP, P33, DOI 10.1145/800031.808575; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kramer PD, 1998, J VESTIBUL RES-EQUIL, V8, P363; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Kuno S, 1999, JPN J PHYSIOL, V49, P417, DOI 10.2170/jjphysiol.49.417; LeClair K, 1996, CLIN BIOMECH, V11, P176, DOI 10.1016/0268-0033(95)00027-5; Lee HY, 2004, COMPUT BIOL MED, V34, P719, DOI 10.1016/j.compbiomed.2003.10.004; MAGNUSSON M, 1990, ACTA OTOLARYNGOL STO, V110; MOLLER T, 1999, REAL TIME RENDERING; Nashner L.M., 1985, VESTIBULAR VISUAL CO, P1; Onell A, 2000, GAIT POSTURE, V12, P7, DOI 10.1016/S0966-6362(00)00053-9; PAULUS WM, 1984, BRAIN, V107, P1143, DOI 10.1093/brain/107.4.1143; PROCHAZKA A, 1980, J PHYSIOL-LONDON, V303, P385; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Pyykko I, 1999, J VESTIBUL RES-EQUIL, V9, P19; PYYKKO I, 1993, AVIAT SPACE ENVIR ME, P3000; Pyykkö I, 1989, Acta Otolaryngol Suppl, V468, P175; PYYKKO I, 1990, AGE AGEING, V19, P215, DOI 10.1093/ageing/19.3.215; Pyykko I., 2000, AUTOMEDICA, V19, P39; PYYKO I, 2001, CONTROL POSTURE GAIT, P230; Redfern MS, 2001, J ANXIETY DISORD, V15, P81, DOI 10.1016/S0887-6185(00)00043-8; Shoemake K., 1985, P 12 ANN C COMP GRAP, P245, DOI 10.1145/325334.325242; TOSSAVAINEN T, 2001, P 10 WORLD C MED INF, P854; TOSSAVAINEN T, 2004, P MMVR2004, P385; Tossavainen T, 2003, INT J MED INFORM, V70, P277, DOI 10.1016/S1386-5056(03)00034-0; VANASTEN WNJC, 1988, EXP BRAIN RES, V73, P371; VIIRRE E, 1996, IEEE ENG MED BIOL, V69, P41	44	6	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771		IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	APR	2006	10	2					282	292		10.1109/TITB.2005.859874		11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	030ZR	WOS:000236674400009	
J	Alvarado, GJ; Pedrycz, W; Reformat, M; Kwak, KC				Alvarado, GJ; Pedrycz, W; Reformat, M; Kwak, KC			Deterioration of visual information in face classification using Eigenfaces and Fisherfaces	MACHINE VISION AND APPLICATIONS			English	Article						face recognition; deterioration of visual information; principal component analysis; linear discriminant analysis; Fisherfaces and Eigenfaces; FERET face database	DISCRIMINANT-ANALYSIS; RECOGNITION; ALGORITHMS; PCA; LDA	In the area of biometrics, face classification becomes one of the most appealing and commonly used approaches for personal identification. There has been an ongoing quest for designing systems that exhibit high classification rates and portray significant robustness. This feature becomes of paramount relevance when dealing with noisy and uncertain images. The design of face recognition classifiers capable of operating in presence of deteriorated (noise affected) face images requires a careful quantification of deterioration of the existing approaches vis-a-vis anticipated form and levels of image distortion. The objective of this experimental study is to reveal some general relationships characterizing the performance of two commonly used face classifiers (that is Eigenfaces and Fisherfaces) in presence of deteriorated visual information. The findings obtained in our study are crucial to identify at which levels of noise the face classifiers can still be considered valid. Prior knowledge helps us develop adequate face recognition systems. We investigate several typical models of image distortion such as Gaussian noise, salt and pepper, and blurring effect and demonstrate their impact on the performance of the two main types of the classifiers. Several distance models derived from the Minkowski family of distances are investigated with respect to the produced classification rates. The experimental environment concerns a well-known standard in this area of face biometrics such as the FERET database. The study reports on the performance of the classifiers, which is based on a comprehensive suite of experiments and delivers several design hints supporting further developments of face classifiers.	Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada	Alvarado, GJ (reprint author), Univ Alberta, Dept Elect & Comp Engn, 9107-116 St, Edmonton, AB, Canada.	gabrielj@ece.ualberta.ca; pedrycz@ece.ualberta.ca; reform@ece.ualberta.ca; kwak@ece.ualberta.ca					Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bolle RM, 2004, GUIDE BIOMETRICS; Cios Krzysztof J., 2000, DATA MINING METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ekstrom M.P., 1984, DIGITAL IMAGE PROCES; Er MJ, 2002, IEEE T NEURAL NETWOR, V13, P697, DOI 10.1109/TNN.2002.1000134; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Frey BJ, 1998, PROC CVPR IEEE, P32, DOI 10.1109/CVPR.1998.698584; LIU C, 1998, P IEEE INT C IM PROC, V1, P151; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; McGuire P, 2001, IEEE T NEURAL NETWOR, V12, P625, DOI 10.1109/72.925566; Pentland A, 2000, IEEE COMPUT, P50; Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Ripley B. D., 1996, PATTERN RECOGNITION; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341300; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; STAINVAS I, 2000, P IEEE 15 INT C PATT, V2, P805, DOI 10.1109/ICPR.2000.906198; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Zhao W., 1998, Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No.98EX107), DOI 10.1109/AFGR.1998.670971; ZHAO W, 2000, P IEEE INT C IM PROC, V1, P41, DOI 10.1109/ICIP.2000.900887	25	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0932-8092		MACH VISION APPL	Mach. Vis. Appl.	APR	2006	17	1					68	82		10.1007/s00138-006-0016-4		15	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	026ZO	WOS:000236382400006	
J	Zhuge, Y; Udupa, JK; Saha, PK				Zhuge, Y; Udupa, JK; Saha, PK			Vectorial scale-based fuzzy-connected image segmentation	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article						fuzzy connectedness; scale; vectorial image; image segmentation	THRESHOLD SELECTION METHOD; BRAIN MR-IMAGES; INTENSITY INHOMOGENEITIES; OBJECT DEFINITION; ALGORITHMS; MODELS; REGION; QUANTIFICATION; INFORMATION; GRADIENT	This paper presents an extension of previously published theory and algorithms for fuzzy-connected image segmentation. In this approach, a strength of connectedness is assigned to every pair of image elements. This is done by finding the strongest among all possible connecting paths between the two elements in each pair. The strength assigned to a particular path is defined as the weakest affinity between successive pairs of elements along the path. Affinity specifies the degree to which elements hang together locally ill the image. A scale is determined at every element in the image that indicates the size of the largest homogeneous hyperball region centered at the element. In determining affinity between any two elements, all elements within their scale regions are considered. This method has been effectively utilized in several medical applications. In this paper, we generalize this method from scalar images to vectorial images. In a vectorial image, scale is defined as the radius of the largest hyperball contained in the same homogeneous region under a predefined condition of homogeneity of the image vector field. Two different components of affinity, namely homogeneity-based affinity and object-feature-based affinity, are devised in a fully vectorial manner. The original relative fuzzy connectedness algorithm is utilized to delineate a specified object via a competing strategy among multiple objects. We have presented several studies to evaluate the performance of this method based on simulated MR images, 20 clinical MR images, and 250 mathematical phantom images. These studies indicate that the fully vectorial fuzzy connectedness formulation has generally overall better accuracy than the method using some intermediate ad hoc steps to fit the vectorial image to a scalar fuzzy connectedness formulation, and precision and efficiency are similar for these two methods. (c) 2005 Published by Elsevier Inc.	Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA	Udupa, JK (reprint author), Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA.	jay@mipg.upenn.edu	Saha, Punam /F-8833-2011				Beucher S., 1993, MATH MORPHOLOGY IMAG, V12, P433; Bezdek J.C., 1992, FUZZY MODELS PATTERN; BLOCH I, 1993, PATTERN RECOGN LETT, V14, P483, DOI 10.1016/0167-8655(93)90028-C; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503; CHANG YL, 1994, IEEE T IMAGE PROCESS, V3, P868; Cho Z. H., 1993, FDN MED IMAGING; CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883; Herman GT, 2001, IEEE T PATTERN ANAL, V23, P460, DOI 10.1109/34.922705; IMIELINSKA C, 2001, P MICCAI UTR NETH, V2208, P1048; Jones T., 1997, P INF PROC MED IM, P113; KASS M, 1987, INT J COMPUT VISION, V1, P321; KATO Z, 1999, PNAR9902 CWI; Kaufmann A., 1975, INTRO THEORY FUZZY S, V1; Lei TH, 2001, IEEE T MED IMAGING, V20, P689; LI S, 1995, RANDOM FIELD MODELIN; LIANG ZR, 1994, IEEE T MED IMAGING, V13, P441; LIM YW, 1990, PATTERN RECOGN, V23, P935; Liu JG, 2003, ACAD RADIOL, V10, P13, DOI 10.1016/S1076-6332(03)80783-3; Marroquin JL, 2002, IEEE T MED IMAGING, V21, P934, DOI 10.1109/TMI.2002.803119; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Moonis G, 2002, AM J NEURORADIOL, V23, P356; MORGENTHALER DG, 1981, IEEE T PATTERN ANAL, V3, P482; Mortensen E. N., 1995, P 22 ANN C COMP GRAP, P191, DOI 10.1145/218380.218442; Nyul LG, 2002, P SOC PHOTO-OPT INS, V4684, P1588, DOI 10.1117/12.467128; Nyul LG, 1999, MAGNET RESON MED, V42, P1072, DOI 10.1002/(SICI)1522-2594(199912)42:6<1072::AID-MRM11>3.0.CO;2-M; NYUL LG, 2003, GRAPH MODELS, V64, P259; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PEDNEKAR AS, 2003, P IND C COMP VIS GRA, P457; Rajapakse JC, 1998, IMAGE VISION COMPUT, V16, P165, DOI 10.1016/S0262-8856(97)00067-X; ROSENFELD A, 1979, INFORM CONTROL, V40, P76, DOI 10.1016/S0019-9958(79)90353-X; Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813; Saha PK, 2001, COMPUT VIS IMAGE UND, V83, P275, DOI 10.1006/cviu.2001.0927; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Saha PK, 2001, IEEE T MED IMAGING, V20, P792, DOI 10.1109/42.938247; Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562; Sethian J. A., 1996, LEVEL SET METHODS FA; Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174; TRIVEDI MM, 1986, IEEE T SYST MAN CYB, V16, P589, DOI 10.1109/TSMC.1986.289264; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Udupa JK, 2002, PROC SPIE, V4684, P266, DOI 10.1117/12.467166; Udupa JK, 1997, IEEE T MED IMAGING, V16, P598, DOI 10.1109/42.640750; Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162; UDUPA JK, 1994, P SOC PHOTO-OPT INS, V2164, P58, DOI 10.1117/12.174042; Vanhamel I, 2003, IEEE T IMAGE PROCESS, V12, P617, DOI 10.1109/TIP.2003.811490; WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424; ZHU SC, 1996, IEEE T PATTERN ANAL, V18, P88; Zhuge Y, 2002, P SOC PHOTO-OPT INS, V4684, P1103, DOI 10.1117/12.467067	58	27	28	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142		COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	MAR	2006	101	3					177	193		10.1016/j.cviu.2005.07.009		17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	000HY	WOS:000234453100004	
J	Wang, JG; Neskovic, P; Cooper, LN				Wang, JG; Neskovic, P; Cooper, LN			Neighborhood size selection in the k-nearest-neighbor rule using statistical confidence	PATTERN RECOGNITION			English	Article						pattern classification; nearest-neighbor rule; probability of error; statistical confidence	REGRESSION	The k-nearest-neighbor rule is one of the most attractive pattern classification algorithms. In practice. the choice of k is determined by the cross-validation method. In this work, we propose a new method for neighborhood size selection that is based on the concept of statistical confidence. We define the confidence associated with a decision that is made by the majority rule from a finite number of observations and use it as a criterion to determine the number of nearest neighbors needed. The new algorithm is tested on several real-world datasets and yields results comparable to the k-nearest-neighbor rule. However, in contrast to the k-nearest-neighbor rule that uses a fixed number of nearest neighbors throughout the feature space, our method locally adjusts the number of nearest neighbors until a satisfactory level of confidence is reached. In addition, the statistical confidence provides a natural way to balance the trade-off between the reject rate and the error rate by excluding patterns that have low confidence levels. We believe that this property of our method can be of great importance in applications where the confidence with which a decision is made is equally or more important than the overall error rate. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Brown Univ, Inst Brain & Neural Syst, Dept Phys, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Inst Brain & Neural Syst, Dept Phys, POB 1843, Providence, RI 02912 USA.	jigang@physics.brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Duda R.O., 2000, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WANG J, 2003, JOINT 13 INT C ART N	9	19	21	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	MAR	2006	39	3					417	423		10.1016/j.patcog.2005.08.009		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	007PO	WOS:000234981800010	
J	Paredes, R; Vidal, E				Paredes, R; Vidal, E			Learning prototypes and distances: A prototype reduction technique based on nearest neighbor error minimization	PATTERN RECOGNITION			English	Article						nearest neighbor; condensing; weighted dissimilarity distances	PATTERN-CLASSIFICATION; RULE	A prototype reduction algorithm is proposed, which simultaneously trains both a reduced set of prototypes and a suitable local metric for these prototypes. Starting with an initial selection of a small number of prototypes, it iteratively adjusts both the position (features) of these prototypes and the corresponding local-metric weights. The resulting prototypes/metric combination minimizes a suitable estimation of the classification error probability. Good performance of this algorithm is assessed through experiments with a number of benchmark data sets and with a real task consisting in the verification of images of human faces. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Univ Politecn Valencia, DSIC, Valencia 46022, Spain	Paredes, R (reprint author), Univ Politecn Valencia, DSIC, Camino Vera S-N, Valencia 46022, Spain.	rparedes@iti.upv.es; evidal@iti.upv.es					Bailly-Bailliere E, 2003, LECT NOTES COMPUT SC, V2688, P625; Blake C.L., UCI REPOSITORY MACHI; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, ADV NEUR IN, V8, P409; HOWE N, 1997, LECT NOTES ARTIF INT, P455; Kohavi R., 1997, P 9 EUR C MACH LEARN; KOHONEN T, 1988, IEEE INT C NEUR NETW, V1, P61; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KONONENKO I, 1993, ESTIMATING ATTRIBUTE; KOSTIN A, 2002, COST 275 WORKSH ADV, P9; MARCEL S, 2003, SYMMETRIC TRANSFORMA; MARCEL S, 2003, FACE VERIFICATION US; McLachlan GJ, 2000, FINITE MIXTURE MODEL; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Paredes R., 2000, P 15 INT C PATT REC, V2, P25, DOI 10.1109/ICPR.2000.906011; PAREDES R, 1999, 8 S NAC REC FORM AN, V1, P437; Paredes R, 2002, INT C PATT RECOG, P48; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PAREDES R, 2003, THESIS DSIC UPV; PENG J, 2004, IEEE T PATTERN ANAL, V26; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Titsias MK, 2003, IEEE T PATTERN ANAL, V25, P924, DOI 10.1109/TPAMI.2003.1206521; Vapnik V.N., 1998, STAT LEARNING THEORY; Wilson D. R., 1996, Proceedings of the IASTED International Conference. Artificial Intelligence, Expert Systems and Neural Networks	30	29	29	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	FEB	2006	39	2					180	188		10.1016/j.patcog.2005.06.001		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	988LZ	WOS:000233604000004	
J	Pekalska, E; Duin, RPW; Paclik, P				Pekalska, E; Duin, RPW; Paclik, P			Prototype selection for dissimilarity-based classifiers	PATTERN RECOGNITION			English	Article						dissimilarity; representation; prototype selection; normal density based classifiers; nearest neighbor rule	NEAREST-NEIGHBOR CLASSIFICATION; PATTERN-CLASSIFICATION; KERNEL CLASSIFIER; RULE; REPRESENTATION; RECOGNITION; ALGORITHMS; SEARCH	A conventional way to discriminate between objects represented by dissimilarities is the nearest neighbor method. A more efficient and sometimes a more accurate solution is offered by other dissimilarity-based classifiers. They construct a decision rule based on the entire training set, but they need just a small set of prototypes, the so-called representation set, as a reference for classifying new objects. Such alternative approaches may be especially advantageous for non-Euclidean or even non-metric dissimilarities. The choice of a proper representation set for dissimilarity-based classifiers is not yet fully investigated. It appears that a random selection may work well. In this paper, a number of experiments has been conducted on various metric and non-metric dissimilarity representations and prototype selection methods. Several procedures, like traditional feature selection methods (here effectively searching for prototypes), mode seeking and linear programming are compared to the random selection. In general, we find out that systematic approaches lead to better results than the random selection, especially for a small number of prototypes. Although there is no single winner as it depends on data characteristics, the k-centres works well, in general. For two-class problems, an important observation is that our dissimilarity-based discrimination functions relying on significantly reduced prototype sets (3-10% of the training objects) offer a similar or much better classification accuracy than the best k-NN rule on the entire training set. This may be reached for multi-class data as well, however such problems are more difficult. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Delft Univ Technol, Fac Elect Engn Math & Comp Sci, NL-2628 CD Delft, Netherlands	Pekalska, E (reprint author), Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Mekelweg 4, NL-2628 CD Delft, Netherlands.	e.pekalska@ewi.tudelft.nl; r.p.w.duin@ewi.tudelft.nl; p.paclik@ewi.tudelft.nl					Avesani P., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, DOI 10.1109/DEXA.1999.795170; BERCHTOLD S, 1998, P 14 INT C DAT ENG O; Blake C.L., UCI REPOSITORY MACHI; Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Bunke H., 2001, LNCS, V2013, P1; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790; Corpet F, 2000, NUCLEIC ACIDS RES, V28, P267, DOI 10.1093/nar/28.1.267; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L, 1996, PROBABILISTIC THEORY; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Dubuisson M. P., 1994, P 12 INT C PATT REC, V1, P566, DOI DOI 10.1109/ICPR.1994.576361; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R. P. W., 2004, PR TOOLS MATLAB TOOL; DUIN RPW, 2004, ICPR 2004 WORKSH P C, P43; Duin RPW, 1998, KYBERNETIKA, V34, P399; EDELMAN Shimon, 1999, REPRESENTATION RECOG; Goldfarb L., 1985, PROGR PATTERN RECOGN, V2, P241; GRAEPEL T, 1999, P 9 INT C ART NEUR N, P304; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Huang YS, 2002, PATTERN RECOGN, V35, P1237, DOI 10.1016/S0031-3203(01)00124-8; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Kohonen T., 1995, SELF ORG MAPS; Landgrebe D.A., 2003, SIGNAL THEORY METHOD; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; MACQUEEN J. B, 1967, BERK S MATH STAT PRO, P281; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Mico L, 1998, PATTERN RECOGN LETT, V19, P351, DOI 10.1016/S0167-8655(98)00007-5; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Moreno-Seco F, 2003, PATTERN RECOGN LETT, V24, P47, DOI 10.1016/S0167-8655(02)00187-3; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; PACLIK P, 2003, P SPECTR IM WORKSH G; Paclik P, 2003, REAL-TIME IMAGING, V9, P237, DOI 10.1016/j.rti.2003.09.002; Paclik P, 2000, PATTERN RECOGN LETT, V21, P1165, DOI 10.1016/S0167-8655(00)00078-7; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; Pekalksa E., 2001, J MACHINE LEARNING R, V2, P175; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; PEKALSKA E, 2004, P STRUCT STAT PATT R, P1143; PEKALSKA E, 2005, ASCI DISSERTATION SE, V109; Ramasubramanian V, 2000, PATTERN RECOGN, V33, P1497, DOI 10.1016/S0031-3203(99)00134-X; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Roth V., 2003, ADV NEURAL INFORM PR, P841; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Wilson C., 1992, HANDPRINTED CHARACTE; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WILSON DR, 1997, J ARTIF INTELL RES, V6	53	84	86	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	FEB	2006	39	2					189	208		10.1016/j.patcog.2005.06.012		20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	988LZ	WOS:000233604000005	
J	Ghosh, AK; Chaudhuri, P; Sengupta, D				Ghosh, AK; Chaudhuri, P; Sengupta, D			Classification using kernel density estimates: Multiscale analysis and visualization	TECHNOMETRICS			English	Article						majority voting; misclassification rates; MISE; optimal bandwidths; p value-type measure; Pairwise coupling; posterior probability; weighted posterior	DISCRIMINANT-ANALYSIS; BANDWIDTH SELECTION; NEURAL NETWORKS; SCALE-SPACE; REGRESSION; SPLINES; CURVES; VIEW	The use of kernel density estimates in discriminant analysis is quite well known among scientists and engineers interested in statistical pattern recognition. Using a kernel density estimate involves properly selecting the scale of smoothing, namely the bandwidth parameter. The bandwidth that is optimum for the mean integrated square error of a class density estimator may riot always be good for discriminant analysis, where the main emphasis is on the minimization of misclassification rates. On the other hand,, cross-validation-based methods for bandwidth selection, which try to minimize estimated misclassification rates, may require huge computation when there are several competing populations. Besides, such methods usually allow only one bandwidth for each Population density estimate, whereas in a classification problem, the Optimum bandwidth for a class density estimate may vary significantly, depending on its competing class densities and their prior probabilities. Therefore, in a multiclass problem, it would be more meaningful to have different bandwidths for a class density when it is compared with different competing class densities. Moreover, good choice of bandwidths should also depend on the specific observation to be classified. Consequently, instead of concentrating on a single optimum bandwidth for each population density estimate. it is more useful in practice to look at the results for different scales of smoothing for the kernel density estimates. This article presents such a multiscale approach along with a graphical device leading to a more informative discriminant analysis than the usual approach based on a single optimum scale of smoothing for each class density estimate. When there are more than two competing classes, this method splits the problem into a number of two-class problems, which allows the flexibility of using different bandwidths for different pairs of competing classes and at the same time reduces the computational burden that one faces for usual cross-validation-based bandwidth selection in the presence of several competing populations. We present some benchmark examples to illustrate the usefulness of the proposed methodology.	Indian Stat Inst, Theoret Stat & Math Unit, Calcutta 700108, W Bengal, India; Indian Stat Inst, Appl Stat Unit, Calcutta 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, Calcutta 700108, W Bengal, India.	anilkghosh@rediffmail.com; probal@isical.ac.in; sdebasis@isical.ac.in					Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; Coomans D., 1986, POTENTIAL PATTERN RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijer P. A., 1982, PATTERN RECOGNITION; DUDA R, 2000, PATTERN CLASSIFICATK; FRIDDMAN JH, 1996, ANOTHER APPROACH POL; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Ghosh AK, 2004, STAT SINICA, V14, P457; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; Godtliebsen F, 2004, IMAGE VISION COMPUT, V22, P1093, DOI 10.1016/j.imavis.2004.05.002; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; HALL P, 1988, BIOMETRIKA, V75, P541, DOI 10.1093/biomet/75.3.541; HALL P, 1991, BIOMETRIKA, V78, P263; HALL P, 1983, ANN STAT, V11, P1156; HALL P, 1980, MARTINGALE LIMIT THE; Hand D. J., 1982, KERNEL DISCRIMINANT; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; LEE Y, 1989, ADV NEURAL INFORMATI, P168; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; Minnote Michael C., 1993, J COMPUT GRAPH STAT, V2, P51, DOI 10.2307/1390955; Minnotte MC, 1998, J COMPUT GRAPH STAT, V7, P239, DOI 10.2307/1390816; MULLER HG, 1984, ANN STAT, V12, P766, DOI 10.1214/aos/1176346523; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; REAVEN GM, 1979, DIABETOLOGIA, V16, P17, DOI 10.1007/BF00423145; Ripley B. D., 1996, PATTERN RECOGNITION; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Schapire RE, 1998, ANN STAT, V26, P1651; Scott D. W., 1992, MULTIVARIATE DENSITY; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; Silverman B.W., 1986, DENSITY ESTIMATION S; STONE CJ, 1984, ANN STAT, V12, P1285, DOI 10.1214/aos/1176346792; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Wand M. P., 1995, KERNEL SMOOTHING	49	15	15	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	0040-1706		TECHNOMETRICS	Technometrics	FEB	2006	48	1					120	132		10.1198/004017005000000391		13	Statistics & Probability	Mathematics	009RK	WOS:000235129800012	
S	Massie, S; Craw, S; Wiratunga, N		RothBerghofer, TR; Goker, MH; Guvenir, HA		Massie, Stewart; Craw, Susan; Wiratunga, Nirmalie			Complexity profiling for informed case-base editing	ADVANCES IN CASE-BASED REASONING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th European Conference on Case-Based Reasoning	SEP 04-07, 2006	Fethiye, TURKEY	DaimlerChrysler, DFKI GmbH, Empolis, Kaidara Software, Microsoft, PricewaterhouseCoopers			NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	The contents of the case knowledge container is critical to the performance of case-based classification systems. However the knowledge engineer is given little support in the selection of suitable techniques to maintain and monitor the case-base. In this paper we present a novel technique that provides an insight into the structure of a case-base by means of a complexity profile that can assist maintenance decision-making and provide a benchmark to assess future changes to the case-base. We also introduce a complexity-guided redundancy reduction algorithm which uses a local complexity measure to actively retain cases close to boundaries. The algorithm offers control over the balance between maintaining competence and reducing case-base size. The ability of the algorithm to maintain accuracy in a compacted case-base is demonstrated on seven public domain classification datasets.	Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland	Massie, S (reprint author), Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland.	sm@comp.rgu.ac.uk; smc@comp.rgu.ac.uk; nw@comp.rgu.ac.uk					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; BRIGHTON H, 2001, INSTANCE SELECTION C, P77; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELANY SJ, 2004, P 7 EUR C CAS BAS RE, P128; FRANCIS A, 1993, P WORKSH KNOWL COMP; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Keane M. T., 1995, P 14 INT JOINT C ART, P377; MASSIE S, 2005, P 20 NAT C ART INT, P216; MCKENNA E, 2000, P 5 EUR WORKSH CAS B, P186; MCKENNA E, 1998, 9 IR C ART INT COGN; McKenna E, 2001, APPL INTELL, V14, P95, DOI 10.1023/A:1008359125752; Richter M. M., 1998, Case-based reasoning technology. From foundations to applications; SMYTH B, 1998, P 4 EUR WORKSH CAS B, P208; SMYTH B, 1999, P 3 INT C CAS BAS RE, P329; Smyth B., 1996, P392; TOMEK I, 1976, IEEE T SYST MAN CYB, V7, P679; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	21	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-36843-4	LECT NOTES ARTIF INT			2006	4106						325	339				15	Computer Science, Artificial Intelligence	Computer Science	BFB81	WOS:000240904600025	
S	Yu, J; Amores, J; Sebe, N; Tian, Q		Hawkes, PW		Yu, Jie; Amores, Jaume; Sebe, Nicu; Tian, Qi			Ranking metrics and evaluation measures	ADVANCES IN IMAGING AND ELECTRON PHYSICS, VOL 144	Advances in Imaging and Electron Physics		English	Review; Book Chapter							IMAGE RETRIEVAL; CLASSIFICATION; SIMILARITY; REPRESENTATION; ALGORITHMS; FEATURES		Univ Texas, Dept Comp Sci, San Antonio, TX 78249 USA; INRIA, IMESIA Res Grp, Rocquencourt, France; Univ Amsterdam, Fac Sci, NL-1012 WX Amsterdam, Netherlands	Yu, J (reprint author), Univ Texas, Dept Comp Sci, San Antonio, TX 78249 USA.						AIGRAIN P, 1987, INT M OPT PUBL STOR, P257; Amores J, 2006, PATTERN RECOGN LETT, V27, P201, DOI 10.1016/j.patrec.2005.08.019; Bar-Hillel A., 2003, P 20 INT C MACH LEAR, P11; CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; DUDA R, 2001, PATTERN CLASSIFICATI, pA3333; FLICKNER M, 1995, IEEE COMPUT, V28, P9; FUKUNAGA K, 1997, IEEE T PATTERN ANAL, V19, P671; GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041; HARALICK R, 1993, COMPUTER ROBOT VISIO, V2, pA3333; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HERTZ T, 2004, IEEE P CVPR, P570; HUBER PJ, 1981, ROBUST STAT, pA3333; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; JOLLIFFE IT, 2002, PRINCIPAL COMPONENT, pA3333; KATO K, 1992, C IM STOR RETR SYST, V1662, P112; LECUN Y, 1998, MNIST DATABASE, pA3333; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; MARTINEZ A, 1998, 24 COMP VIS CTR, pA3333; MATAS J, 1999, P INT C PATT REC, P858; Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6; MERZ C, 1998, UCI REPOSITORY MACHI, pA3333; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; PENG J, 2001, IEEE P CVPR, P940; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMITH JR, 1994, IEEE INT C IM PROC, pA3333; STORK DG, 2004, COMPUTER MANUAL MATL, pA3333; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P1; TANG L, 1994, P NSF ARPA WORKSH PE, pA3333; TIAN Q, 2004, IEEE INT C IM PROC O, pA3333; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; TVERSKY A, 1970, J MATH PSYCHOL, V7, P572, DOI 10.1016/0022-2496(70)90041-6; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WALLACH MA, 1958, PSYCHOL REV, V65, P103, DOI 10.1037/h0042908; Xing EP, 2003, P NIPS, P505; Zakai M., 1964, IEEE T INFORM TH JAN, P94	40	1	1	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	1076-5670	0-12-014786-6	ADV IMAG ELECT PHYS	Adv. Imag. Electron Phys.		2006	144						291	316		10.1016/S1076-5670(06)44004-0		26	Physics, Applied	Physics	BFF37	WOS:000241587000004	
S	Zhang, Y; Wu, K; Gao, JF; Vines, P		Lalmas, M; MacFarlane, A; Ruger, S; Tombros, A; Tsikrika, T; Yavlinsky, A		Zhang, Ying; Wu, Ke; Gao, Jianfeng; Vines, Phil			Automatic acquisition of Chinese-English parallel corpus from the web	ADVANCES IN INFORMATION RETRIEVAL	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	28th European Conference on Information Retrieval (ECIR 2006)	APR   10, 2005-APR 12, 2006	London, ENGLAND	Queen Mary Univ London, City Univ, Engn & Phys Sci Res Council, CEPIS, Google, GCHQ, Microsoft Res, Yahoo Res, Sharp, Apriorie, Lemur Consulting, MMKM, Elsevier	Imperial Coll London, S Kensington			Parallel corpora are a valuable resource for tasks such as cross-language information retrieval and data-driven natural language processing systems. Previously only small scale corpora have been available, thus restricting their practical use. This paper describes a system that overcomes this limitation by automatically collecting high quality parallel bilingual corpora from the web. Previous systems used a single principle feature for parallel web page verification, whereas we use multiple features to identify parallel texts via a k-nearest-neighbor classifier. Our system was evaluated using a data set containing 6500 Chinese-English candidate parallel pairs that have been manually annotated. Experiments show that the use of a k-nearest-neighbors classifier with multiple features achieves substantial improvements over the systems that use any one of these features. The system achieved a precision rate of 95% and a recall rate of 97%, and thus is a significant improvement over earlier work.	RMIT Univ, Melbourne, Vic, Australia; Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China; Microsoft Res, Redmond, WA 98052 USA	Zhang, Y (reprint author), RMIT Univ, GPO Box 2476V, Melbourne, Vic, Australia.	yzhang@cs.rmit.edu.au; wuke@sjtu.edu.cn; jfgao@microsoft.com; phil@cs.rmit.edu.au					Ballesteros L., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.290958; Brown P. F., 1990, Computational Linguistics, V16; CHAU R, 2001, P 1 AS PAC C WEB INT, P340; CHEN J, 2004, P 2 WORKSH AUSTR INF, P157; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANZ M, 2001, P ACM SIGIR C, P398, DOI 10.1145/383952.384037; Kraaij W, 2003, COMPUT LINGUIST, V29, P381, DOI 10.1162/089120103322711587; LOWRANCE R, 1975, J ACM, V22, P177; MCEWAN CJA, 2002, P 24 BCS IRSG EUR C, P303; Nie J.-Y., 1999, P 22 ANN INT ACM SIG, P74, DOI 10.1145/312624.312656; Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	12	4	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33347-9	LECT NOTES COMPUT SC			2006	3936						420	431				12	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEM01	WOS:000238083200037	
S	Le, SQ; Ho, TB; Vinh, LS		Ng, WK; Kitsuregawa, M; Li, J; Chang, K		Le, SQ; Ho, TB; Vinh, LS			Association-based dissimilarity measures for categorical data: Limitation and improvement	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR   09, 2005-APR 12, 2006	Singapore, SINGAPORE	USAF Off Sci Res, Asian Off Aerosp Res & Dev, USA ITC, PAC Asian Res Off, Informat Dev Author Singapore, Lee Fdn, SAS, SPSS Inc, Embassy United States Amer, Singapore				Measuring the similarity for categorical data is a challenging task in data mining due to the poor structure of categorical data. This paper presents a dissimilarity measure for categorical data based on the relations among attributes. This measure not only has the advantage of value variance but also overcomes the limitations of condition the probability-based measure when applied to databases whose attributes are independent, Experiments with 30 databases also showed that the proposed measure boosted the accuracy of Nearest Neighbor classification in comparison with other tested measures.	Japan Adv Inst Sci & Technol, Tatsunokuchi, Ishikawa 9231292, Japan; LIRMM, Montpellier 5, France; John Von Neumann Inst Comp, Julich, Germany; Amer Museum Nat Hist, New York, NY 10024 USA	Le, SQ (reprint author), Japan Adv Inst Sci & Technol, Tatsunokuchi, Ishikawa 9231292, Japan.	quang@jaist.ac.jp; bao@jaist.ac.jp; vinh@cs.uni-duesseldorf.de	Le, Quang/A-4861-2012				AONO M, 2004, SURVEY TEXT MINING C, P103; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOODALL DW, 1966, BIOMETRICS, V22, P882, DOI 10.2307/2528080; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; Le SQ, 2005, PATTERN RECOGN LETT, V26, P2549, DOI 10.1016/j.patrec.2005.06.002; LE SQ, 2004, LECT NOTES ARTIF INT, V3056, P580; Liu B., 1998, KNOWLEDGE DISCOVERY, P80	8	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33206-5	LECT NOTES ARTIF INT			2006	3918						493	498				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEH24	WOS:000237249600057	
S	Wang, JG; Neskovic, P; Cooper, LN		Yeung, DS; Liu, ZQ; Wang, XZ; Yan, H		Wang, Jigang; Neskovic, Predrag; Cooper, Leon N.			A statistical confidence-based adaptive nearest neighbor algorithm for pattern classification	ADVANCES IN MACHINE LEARNING AND CYBERNETICS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Guangzhou, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany			REGRESSION	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. It can be interpreted as an empirical Bayes classifier based on the estimated a posteriori probabilities from the k nearest neighbors. The performance of the k-nearest neighbor rule relies on the locally constant a posteriori probability assumption. This assumption, however, becomes problematic in high dimensional spaces due to the curse of dimensionality. In this paper we introduce a locally adaptive nearest neighbor rule. Instead of using the Euclidean distance to locate the nearest neighbors, the proposed method takes into account the effective influence size of each training example and the statistical confidence with which the label of each training example can be trusted. We test the new method on real-world benchmark datasets and compare it with the standard k-nearest neighbor rule and the support vector machines. The experimental results confirm the effectiveness of the proposed method.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.	jigang@brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					Blake C.L., UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1951, 4 USAF SCH AV MED; Friedman J ., 1994, 113 STANF U STAT DEP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-33584-6	LECT NOTES ARTIF INT			2006	3930						548	557				10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BEN35	WOS:000238282100057	
S	Dai, WY; Yu, Y; Zhang, CL; Han, J; Xue, GR		Yu, JX; Kitsuregawa, M; VaLeong, H		Dai, Wenyuan; Yu, Yong; Zhang, Cong-Le; Han, Jie; Xue, Gui-Rong			A novel web page categorization algorithm based on block propagation using query-log information	ADVANCES IN WEB-AGE INFORMATION MANAGEMENT, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	7th International Conference on Web-Age Information Management	JUN 17-19, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, City Univ Hong Kong, Hong Kong Baptist Univ, Hong Kong Polytech Univ, Hong Kong Univ Sci & Technol, Univ Hong Kong, Hong Kong Web Soc, Hong Kong Pei Hua Educ Fdn Ltd, IEEE Hong Kong Sect Comp Sci Chapter				Most existing web page classification algorithms, including content-based, link-based, or query-log analysis methods, treat the pages as smallest units. However, web pages usually contain some noisy or biased information which could affect the performance of classification. In this paper, we propose a Block Propagation Categorization (BPC) algorithm which deep mines web structure and views blocks as basic semantic units. Moreover, with query log information, BPC propagates only suitable information (block) among web pages to emphasize their topics. We also optimize the BPC algorithm to significantly speed up the block propagation process, without losing any precision. Our experiments on ODP and MSN search engine log show that BPC achieves a great improvement over traditional approaches.	Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Dai, WY (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.	dwyak@apex.sjtu.edu.cn; yyu@apex.sjtu.edu.cn; zhangcongle@apex.sjtu.edu.cn; hanjie@apex.sjtu.edu.cn; grxue@apex.sjtu.edu.cn					Beeferman D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347176; Burr Ridge I, 1997, MACHINE LEARNING; Chakrabarti S., 1998, P ACM SIGMOD INT C M, P307, DOI 10.1145/276304.276332; Chakrabarti S., 2002, MINING WEB DISCOVERI; CHUANG SL, 2003, DECISION SUPPORT SYS, V35; Cohn D, 2001, ADV NEUR IN, V13, P430; Cortes C, 1995, MACH LEARN, V20, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GLOVER EJ, 2002, P WWW 02 INT C WORLD; JOACHIMS T, CMUCS96118; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; LEWIS D, 1991, REPRESENTATION LEARN; LNANG K, 1995, P 12 INT C MACH LEAR, P331; PANTELEEVA N, USING NEIGHBORHOOD I; SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441; Salton G., 1971, SMART RETRIEVAL SYST; Slattery S, 2000, P 17 INT C MACH LEAR, P895; Wang J., 2003, P ACM SIGIR C RES DE, P274; XUE GR, 2004, P 2004 IEEE INT C DA; Yang Y., 1999, J INFORMATION RETRIE, V1, P67; Yang Y., 1997, P 14 INT C MACH LEAR	21	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-35225-2	LECT NOTES COMPUT SC			2006	4016						435	446				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BEV90	WOS:000239658700037	
S	Spencer, M; McCullagh, J; Whitfort, T		Sattar, A; Kang, BH		Spencer, Matthew; McCullagh, John; Whitfort, Tim			Clustering data manipulation method for ensembles	AI 2006: Advances in Artificial Intelligence, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	19th Australian Joint Conference on Artificial Intelligence	DEC 04-08, 2006	Hobart, AUSTRALIA			ensemble; data manipulation; clustering		Traditional data manipulation models such as Bagging and Boosting select training cases from throughout the problem space to generate diversity and improve performance. A new data manipulation model is proposed that dynamically assigns specialists to train on difficult clusters of training data. The model allows the expertise of specialists to overlap for difficult regions of the problem.. It has been coupled with a dynamic combination model to exploit the diversity of specialist members. The model has been applied to an environmental problem and has demonstrated that dynamic modelling can enhance both the diversity of members and the accuracy of the ensemble.	La Trobe Univ, Dept Comp Sci & Comp Engn, Bendigo, Vic, Australia	Spencer, M (reprint author), La Trobe Univ, Dept Comp Sci & Comp Engn, Bendigo, Vic, Australia.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); HENDERSON B, 2004, GEODERMA, V124, P383; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; Johnston RM, 2003, AUST J SOIL RES, V41, P1021, DOI 10.1071/SR02033; Kuncheva LI, 2003, IBPRIA 1 IB C PATT R, P1126; McQueen J, 2007, 5TH BERK S MATH STAT, V1, P281; QUINLAN J, 1992, WORLD SCI, P343; SPENCER MJ, 2006, ACST 2006; *CLIM CHAN SCI PRO, 2006, STRAT PLAN US CLIM C	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	978-3-540-49787-5	LECT NOTES COMPUT SC			2006	4304						1122	1126				5	Computer Science, Artificial Intelligence	Computer Science	BFV69	WOS:000244891200134	
J	Mille, A				Mille, Alain			From case-based reasoning to traces-based reasoning	ANNUAL REVIEWS IN CONTROL			English	Article; Proceedings Paper	9th IFAC Symposium on Automated Systems Based on Human Skill and Knowledge	MAY 22-24, 2006	Nancy, FRANCE	IFAC Tech Comm 9 2		problem solvers; artificial intelligence; knowledge-based systems; knowledge representation	SYSTEMS	CBR is an original At paradigm based on the adaptation of solutions of past problems in order to solve new similar problems. Hence, a case is a problem with its solution and cases are stored in a case library. The reasoning process follows a cycle that facilitates "learning" from new solved cases. This approach can be also viewed as a lazy learning method when applied for task classification. CBR is applied for various tasks as design, planning, diagnosis, information retrieval, etc. The paper is the occasion to go a step further in reusing past Unstructured experience, by considering traces of computer use as experience knowledge containers for situation based problem solving. (C) 2006 Elsevier Ltd. All rights reserved.	Univ Lyon 1, LIRIS, CNRS, UMR 5205, Lyon, France; Univ Lyon 2, Lyon, France	Mille, A (reprint author), Univ Lyon 1, LIRIS, CNRS, UMR 5205, Lyon, France.	alain.mille@liris.cnrs.fr					AAMODT A, 1994, AI COMMUN, V7, P39; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; BERGMAN R, 2002, EXPERIENCE MANAGEMEN; BERGMANN R, 2004, DEV IND CASE BASED R; BRANN DM, 1995, P 1995 INT C SYST MA; CHAMPIN PA, 2003, ICCBR 03 WORKSH STRU, P279; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crevier D., 1993, AI TUMULTUOUS HIST S; FUCHS B, 2006, GEN STRATEGY ADAPTAT; FUCHS B, 1995, LECT NOTES ARTIF INT, V1010, P23; HANNEY K, 1995, LECT NOTES ARTIF INT, P461; JURISICA I, 1996, P 5 C DAT KNOWL SYST; Kolodner J., 1993, CASE BASED REASONING; Kolodner J. L., 1996, CASE BASED REASONING; KOLODNER JL, 1985, P IJCAI 85 LOS ANGEL, P284; Leake D.B., 1996, CASE BASED REASONING; Lenz Mario, 1998, CASE BASED REASONING; Lopez de Mantaras R, 2006, KNOWL ENG REV, V20, P215; Maher M. L., 1997, ISSUES APPL CASE BAS; Maher Mary Lou, 1995, CASE BASED REASONING; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Minsky M., 1975, PSYCHOL COMPUTER VIS; Minsky M, 1974, ARTIFICIAL INTELLIGE; NEWELL A., 1960, P INT C INF PROC, P256; Portinale L, 2004, ARTIF INTELL, V158, P109, DOI 10.1016/j.artint.2004.05.005; RENAUD J, IN PRESS COLLECTION; Schank R. C., 1982, DYNAMIC MEMORY THEOR; SCHANK RC, 1989, INSIDE CASE BASED RE; SCHANK RC, 1977, SCRIPTS PLANS GOALS, pCH1; SIMOUDIS E, 1992, IEEE EXPERT, V7, P7, DOI 10.1109/64.163667; Faltings B, 1996, COMPUT AIDED DESIGN, V28, P207, DOI 10.1016/0010-4485(95)00027-5; THURMAN SDA, 1997, P 1997 IEEE INT C SY; Veloso M, 1996, AI COMMUN, V9, P128; Watson I., 1997, APPL CASE BASED REAS	34	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	1367-5788		ANNU REV CONTROL	Annu. Rev. Control		2006	30	2					223	232		10.1016/j.arcontrol.2006.09.003		10	Automation & Control Systems	Automation & Control Systems	120EG	WOS:000243065900011	
B	Bosin, A; Dessi, N; Pes, B		Ruan, D; DHondt, P; Fantoni, PF; DeCock, M; Nachtegael, M; Kerre, EE		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			Learning classifiers for high-dimensional micro-array data	Applied Artificial Intelligence			English	Proceedings Paper	7th International Conference on Fuzzy Logic and Intelligent Technologies in Nuclear Science	AUG 29-31, 2006	Genoa, ITALY				CLASSIFICATION; SELECTION	In this paper, we address the challenging task of learning accurate classifiers from microarray datasets involving a large number of features but only a small number of samples. We present a greedy step-by-step procedure (SSFS) that can be used to reduce the dimensionality of the feature space. We apply the Minimum Description Length principle to the training data for weighting each feature and then select an "Optimal" feature subset by a greedy approach tuned to a specific classifier. The Acute Lymphoblastic Leukemia dataset is used to evaluate the effectiveness of the SSFS procedure in conjunction with different state-of-the-art classification algorithms.	Univ Cagliari, Dept Math & Comp Sci, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.						Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOSIN A, 2005, LNAI, V3849; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GOLUB TR, 1999, SCIENCE, V286; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HARDIMANN G, 2003, MICROARRAY METHODS A; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Liu Huiqing, 2002, Genome Inform, V13, P51; MUKHERJEE S, 2003, CLASSIFYING MICROARR; Vapnik V.N., 1998, STAT LEARNING THEORY; YARMUS JS, 2003, ABN FAST GREEDY BAYE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	15	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE		981-256-690-2				2006							593	600		10.1142/9789812774118_0084		8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BEU34	WOS:000239525200084	
S	Ben Hariz, S; Elouedi, Z; Mellouli, K		Euzenat, J; Domingue, J		Ben Hariz, Sarra; Elouedi, Zied; Mellouli, Khaled			Clustering approach using belief function theory	ARTIFICIAL INTELLIGENCE: METHODOLOGY, SYSTEMS, AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	12th International Conference on Artificial Intelligence - Methodology, Systems, and Applications	SEP 12-15, 2006	Varna, BULGARIA	Bulgarian Artificial Intelligence Assoc, Inst Informat Technol		machine learning; clustering; K-modes method; uncertainty; belief function theory	CLASSIFICATION; MODEL; RULE	Clustering techniques are considered as efficient tools for partitioning data sets in order to get homogeneous clusters of objects. However, the reality is connected to uncertainty by nature, and these standard algorithms of clustering do not deal with this uncertainty pervaded in their parameters. In this paper we develop a clustering method in an uncertain context based on the K-modes method and the belief function theory. This so-called belief K-modes method (BKM) provides a new clustering technique handling uncertainty in the attribute values of objects in both the clusters' construction task and the classification one.	LARODEC, Inst Super Gest Tunis, Le Bardo 2000, Tunisia	Ben Hariz, S (reprint author), LARODEC, Inst Super Gest Tunis, 41 Ave Liberte, Le Bardo 2000, Tunisia.	sarra.benhariz@gmail.com; zied.eloued@gmx.fr; khaled.mellouli@ihec.rnu.tn					BAUER M, 1993, ARTTIF INTELL, V61, P315; Bosse E., 2001, INFORM FUSION, V2, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Elouedi Z, 2001, INT J APPROX REASON, V28, P91, DOI 10.1016/S0888-613X(01)00045-7; Elouedi Z, 2004, IEEE T SYST MAN CY B, V34, P782, DOI 10.1109/TSMCB.2003.817056; Fixen D., 1997, IEEE T SYST MAN CYB, V27, P96; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A., 1988, ALGORITHMS CLUSTERIN; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Quinlan J. R., 1983, MACHINE LEARNING ART, P463; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; Shafer G., 1976, MATH THEORY EVIDENCE, V30; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1998, HDB DEFEASIBLE REASO, V1, P267; TESSEM B, 1997, INT J APPROX REASON, V17, P217; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	17	7	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40930-0	LECT NOTES COMPUT SC			2006	4183						162	171				10	Computer Science, Artificial Intelligence	Computer Science	BFI88	WOS:000242122400016	
J	Sinha, SK; Fieguth, PW				Sinha, SK; Fieguth, PW			Neuro-fuzzy network for the classification of buried pipe defects	AUTOMATION IN CONSTRUCTION			English	Article						pipeline infrastructure; automated inspection; image processing; segmentation; features; neural network; backpropagation network; neuro-fuzzy projection network	ALGORITHM; SETS	Pipeline infrastructure is decaying at an accelerating rate due to reduced funding and insufficient quality control resulting in poor installation, little or no inspection and maintenance, and a general lack of uniformity and improvement in design, construction and operation practices. The current practice that is being followed to inspect the conditions of pipes is usually time consuming, tedious and expensive. It may also lead to diagnostic errors due to lack of concentration of human operators. Buried pipe defect classification is thus a practical and important pattern classification problem. These defects appear in the form of randomly shaped cracks and holes, broken joints and laterals, and others. This paper proposes a new neuro-fuzzy classifier that combines neural networks and concepts of fuzzy logic for the classification of defects by extracting features in segmented buried pipe images. A comparative evaluation of the K-NN, fuzzy K-NN, conventional backpropagation network, and proposed neuro-fuzzy projection network classifiers is carried out. Among the five neural methods implemented and tested, the proposed neuro-fuzzy classifier performs the best, with classification accuracies around 90% on real concrete pipe images. (c) 2005 Elsevier B.V. All rights reserved.	Penn State Univ, Dept Civil & Environm Engn, University Pk, PA 16802 USA; Univ Waterloo, Dept Syst Design Engn, Waterloo, ON N2L 3G1, Canada	Sinha, SK (reprint author), Penn State Univ, Dept Civil & Environm Engn, University Pk, PA 16802 USA.	sunil@engr.psu.edu; pfieguth@uwaterloo.ca					BANKERT RL, 1994, J APPL METEOROL, V33, P909, DOI 10.1175/1520-0450(1994)033<0909:CCOAII>2.0.CO;2; Bezdek J., 1981, PATTERN RECOGNITION; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Chae MJ, 2001, J COMPUT CIVIL ENG, V15, P4, DOI 10.1061/(ASCE)0887-3801(2001)15:1(4); CHENG HD, 1996, SPIE P, P140; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dodwell P. C., 1970, VISUAL PATTERN RECOG; DUDA RO, 1970, PATTERN CLASSIFICATI, P271; GNANADESIKAN R, 1977, METHODS STAT DATA AN; GUPTA MM, 1979, ADV FUZZY SET THEORY; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hunt E., 1975, ARTIFICIAL INTELLIGE; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Kandel A, 1982, FUZZY TECHNIQUES PAT; Kaseko M. S., 1993, Transportation Research Part C (Emerging Technologies), V1C, DOI 10.1016/0968-090X(93)90002-W; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1995, SELF ORG MAPS; Lin C.T., 1996, NEURO FUZZY SYSTEMS; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Moselhi O., 1999, Automation in Construction, V8, DOI 10.1016/S0926-5805(99)00007-2; Moselhi O., 2000, J INFRASTRUCT SYST, V6, P97, DOI DOI 10.1061/(ASCE)1076-0342(2000)6:3; PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058; Pineda F. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.161; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Powell M., 1987, RADIAL BASIS FUNCTIO; Ranka S., 1997, ELEMENTS ARTIFICIAL; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; REYNOLDS AG, 1977, COGNITIVE PSYCHOL; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SAFFREY J, 1991, P 1991 INT JOINT C N, V2, P441; Schalkoff R, 1992, PATTERN RECOGNITION; SHAIKH MA, 1996, P IGRASS 96, P1105; SINHA SK, IN PRESS AUTOMATION; Sinha SK, 2002, IEEE T NEURAL NETWOR, V13, P393, DOI 10.1109/72.991425; SINHA SK, 2000, THESIS U WATERLOO; SPOEHR KT, 1982, VISUAL INFORMATION P; TELFER B, 1991, P INT JOINT C NEUR N, V2, P89; WARDLE A, 1978, METHOD INFORM MED, V17, P15; WERBOS P, 1974, THESIS HARVARD; WILENSKY GD, 1992, P INT JOINT C NEUR N, V2, P358, DOI 10.1109/IJCNN.1992.226961; Winston P. H., 1977, ARTIFICIAL INTELLIGE; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	42	16	16	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0926-5805		AUTOMAT CONSTR	Autom. Constr.	JAN	2006	15	1					73	83		10.1016/j.autcon.2005.02.005		11	Construction & Building Technology; Engineering, Civil	Construction & Building Technology; Engineering	981YU	WOS:000233124700007	
B	Yang, JY; Yang, MQ			IEEE COMPUTER SOC	Yang, Jack Y.; Yang, Mary Qu			Assessing protein function using a combination of supervised and unsupervised learning	BIBE 2006: Sixth IEEE Symposium on Bioinformatics and BioEngineering, Proceedings			English	Proceedings Paper	6th IEEE Syposium on BioInformatics and BioEngineering (BIBE 2006)	OCT 16-18, 2006	Arlington, VA	IEEE Comp Soc, Biol & Artificial Intelligence Soc, ITRI				The determination of protein function using experimental techniques is time-consuming and expensive; the use of machine learning techniques to rapidly assess protein function may be useful in streamlining this process. The problem of assigning functional classes to proteins is complicated by the fact that a single protein can participate in several different pathways and thus can have multiple functions. It follows that the instances in the resulting classification problem can carry multiple class labels. We have developed a tree-based classifier that capable of handling multiply-labeled data: we call the resulting tree a Recursive Maximum-Contrast Tree (RMCT). The name derives from the way in which nodes in the tree are split; this is done by selecting the two training instances with maximum contrast (that is, the two training instances with maximum separation according to some distance measure) and using them as seeds in a clustering algorithm to form a partition of the training instances and hence of the feature space. We test our algorithm on protein phylogenetic profiles generated from 60 completely sequenced genomes, and we compare our results to those achieved using existing algorithms such as support vector machines and decision trees.	Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA	Yang, JY (reprint author), Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; CHO S, 1993, IEEE T CIRCUITS-II, V40, P556, DOI 10.1109/82.257333; CODRINGTON CW, 1997, THESIS PURDUE U; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIX E, 1951, 2149004 USAF SCH AV; Joachims T., 2002, LEARNING CLASSIFY TE; Neuhaus D, 2000, NUCL OVERHAUSER EFFE; Pavlidis P., 2001, RECOMB 2001, P249; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Quinlan J. R, DATA MINING TOOLS SE; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; YANG JY, 2003, P ART NEUR NETW ENG; YANG MQ, 2004, P ART NEUR NETW ENG	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2727-2				2006							35	41				7	Biochemical Research Methods; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BFK64	WOS:000242503800005	
S	Chen, TS; Lin, CC; Chiu, YH; Lin, HL; Chen, RC		Huang, DS; Li, K; Irwin, GW		Chen, Tung-Shou; Lin, Chih-Chiang; Chiu, Yung-Hsing; Lin, Hsin-Lan; Chen, Rong-Chang			A new binary classifier: Clustering-launched classification	COMPUTATIONAL INTELLIGENCE, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Conference on Intelligent Computing (ICIC)	AUG 16-19, 2006	Kunming, PEOPLES R CHINA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China				One of the powerful classifiers is Support Vector Machine (SVM), which has been successfully applied to many fields. Despite its remarkable achievement, SVM is time-consuming in many situations where the data distribution is unknown, causing it to spend much time on selecting a suitable kernel and setting parameters. Previous studies proposed understanding the data distribution before classification would assist the classification. In this paper, we exquisitely combined with clustering and classification to develop a novel classifier, Clustering-Launched Classification (CLC), which only needs one parameter. CLC employs clustering to group data to characterize the features of the data and then adopts the one-against-the-rest and nearest-neighbor to find the support vectors. In our experiments, CLC is compared with two well-known SVM tools: LIBSVM and mySVM. The accuracy of CLC is comparable to LIBSVM and mySVM. Furthermore, CLC is insensitive to parameter, while the SVM is sensitive, showing CLC is easier to use.	Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung, Taiwan; Natl Taichung Inst Technol, Grad Sch Business Adm, Taichung, Taiwan; Natl Taichung Inst Technol, Dept Logist Engn & Management, Taichung, Taiwan	Chen, RC (reprint author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung, Taiwan.	tschen@ntit.edu.tw; s18933102@ntit.edu.tw; s18943108@ntit.edu.tw; s18941113@ntit.edu.tw; rcchens@ntit.edu.tw					CHANG CC, 2001, LIBSVM LIB SUPPORT V, P20; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chen RC, 2006, INT J PATTERN RECOGN, V20, P227, DOI 10.1142/S0218001406004624; CHEN RC, 2004, LECT NOTES COMPUTER, P800; CHEN RC, 2005, LECT NOTES COMPUTER, P916; CHEN RC, 2005, LNCS, P409; Chen TS, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P485; CHEN TS, 2003, P INT C INF CYB SYST, P1532; Chen T.-S., 2005, P 2005 INT S INT SIG, P405; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNHAM MH, 2003, DATA MING INTRO ADV; Han J. W., 2000, DATA MINING CONCEPTS; Liang X, 2005, LECT NOTES ARTIF INT, V3584, P761; Newman D. J., 1998, UCI REPOSITORY MACHI; QIAO H, 2004, P 2004 IEEE RSJ INT, V2, P2015; Roiger R. J., 2003, DATA MINING TUTORIAL; RUPING S, 2000, MYSVM MANUAL, V8, P21; Sun BY, 2005, IEEE SIGNAL PROC LET, V12, P101, DOI 10.1109/LSP.2004.836938; Vapnik V.N., 1995, NATURE STAT LEARNING; ZHAO XM, 2004, LECT NOTES COMPUTER, P11	20	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37274-1	LECT NOTES ARTIF INT			2006	4114						278	283				6	Computer Science, Artificial Intelligence	Computer Science	BEY13	WOS:000240083300035	
S	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Qu, YL; Dong, HB		Alexandrov, VN; VanAlbada, GD; Sloot, PMA; Dongarra, J		Shang, Wenqian; Huang, Houkuan; Zhu, Haibin; Lin, Yongmin; Qu, Youli; Dong, Hongbin			An adaptive fuzzy kNN text classifier	COMPUTATIONAL SCIENCE - ICCS 2006, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Conference on Computational Science (ICCS 2006)	MAY 28-31, 2006	Reading, ENGLAND	Intel Corp, IBM, SGI, Microsoft Res, EPSRC, Springer, ACET Ctr, Univ Reading, SIAM, IMACS, UK e Sci Programme			NEAREST NEIGHBOR; CATEGORIZATION	In recent years, kNN algorithm is paid attention by many researchers and is proved one of the best text categorization algorithms. Text categorization is according to training set which is assigned class label to decide a new document which is not assigned class label belongs to some kind of document. Until now, kNN algorithm has still some issues to need to study further. Such as: improvement of decision rule; selection of k value; selection of dimensions (i.e. feature set selection); problems of multiclass text categorization; the algorithm's executive efficiency (time and space) etc. In this paper, we mainly focus on improvement of decision rule and dimension selection. We design an adaptive fuzzy kNN text classifier. Here the adaptive indicate the adaptive of dimension selection. The experiment results show that our algorithm is effective and feasible.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	shangwenqian@hotmail.com; haibinz@npissingu.ca					APTE C, 1998, P C AUT LEARN DISC W, P487; BIAN J, 2000, PATTERN RECOGNITION; Cardoso-Cachopo A, 2003, LECT NOTES COMPUT SC, V2857, P183; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1980, FUZZY SETS SYSTEMS T; Han E., 2001, P 5 PAC AS C KNOWL D, P53; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D.D., 1994, P 3 ANN S DOC AN INF, P81; Li B.L., 2004, ACM T ASIAN LANGUAGE, V3, P215; LIM H, 2002, P 9 INT C NEUR INF P, P731; MASAND B, 1992, 15 ANN INT ACM SIGIR, P59; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; NG HT, 1997, 20 ANN INT ACM SIGIR, P67; SHANKAR S, 2000, P INT WORKSH MULT DA; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Wiener E.D., 1995, P 4 ANN S DOC AN INF, P317; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; YANG Y, 1997, EVALUATION STAT APPR, V1, P76; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; ZHAO S, 1987, METHOD FUZZY MATH PA	21	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34383-0	LECT NOTES COMPUT SC			2006	3993						216	223				8	Computer Science, Theory & Methods	Computer Science	BEO20	WOS:000238417300030	
S	Martinez-Otzeta, JM; Sierra, B; Lazkano, E; Astigarraga, A		Williams, GJ; Simoff, SJ		Martinez-Otzeta, JM; Sierra, B; Lazkano, E; Astigarraga, A			K nearest neighbor edition to guide classification tree learning: Motivation and experimental results	DATA MINING: THEORY, METHODOLOGY, TECHNIQUES, AND APPLICATIONS	Lecture Notes in Artificial Intelligence		English	Article						machine learning; supervised classification; classifier combination; classification trees	FEATURE SUBSET-SELECTION; INTENSIVE-CARE-UNIT; BAYESIAN NETWORKS; COMBINATION; CLASSIFIERS; ALGORITHMS	This paper presents a new hybrid classifier that combines the Nearest Neighbor distance based algorithm with the Classification Tree paradigm. The Nearest Neighbor algorithm is used as a preprocessing algorithm in order to obtain a modified training database for the posterior learning of the classification tree structure; experimental section shows the results obtained by the new algorithm; comparing these results with those obtained by the classification trees when induced from the original training data we obtain that the new approach performs better or equal according to the Wilcoxon signed rank statistical test.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, San Sebastian 20018, Spain	Martinez-Otzeta, JM (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, P Manuel Lardizabal 1, San Sebastian 20018, Spain.	ccbmaotj@si.ehu.es					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; Breiman L, 1984, CLASSIFICATION REGRE; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cowell RG, 1999, PROBABILISTIC NETWOR; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dietterich TG, 1997, AI MAG, V18, P97; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; GAMA J, 2000, COMBINING CLASSIFICA; Gunes V, 2003, INT J PATTERN RECOGN, V17, P1303, DOI 10.1142/S0218001403002897; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Kohavi R., 1996, P 2 INT C KNOWL DISC; Lu Y, 1996, APPL INTELL, V6, P75, DOI 10.1007/BF00117809; MARTIN JK, 1997, MACHINE LEARNING, V28; Martin PD, 2004, HA CL HE PS, V2, P233; Michie D., 1995, MACHINE LEARNING NEU; MINGERS J, 1988, COMPARISON METHODS P, V1; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; PEARL J, 1987, ARTIF INTELL, V32, P245, DOI 10.1016/0004-3702(87)90012-9; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sierra B, 1999, LECT NOTES ARTIF INT, V1620, P366; Sierra B., 2002, Knowledge-Based Intelligent Information Engineering Systems and Allied Technologies. KES 2002; Sierra B, 2001, ARTIF INTELL MED, V22, P233, DOI 10.1016/S0933-3657(00)00111-1; Sierra B, 2001, LECT NOTES ARTIF INT, V2101, P20; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; STONE M, 1974, J R STAT SOC B, V36, P111; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	32	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-32547-6	LECT NOTES ARTIF INT			2006	3755						53	63				11	Computer Science, Artificial Intelligence	Computer Science	BEB23	WOS:000236545100005	
J	Hao, YL; Quirchmayr, G; Stumptner, M				Hao, YL; Quirchmayr, G; Stumptner, M			Mining MOUCLAS patterns and jumping MOUCLAS patterns to construct classifiers	DATA MINING: THEORY, METHODOLOGY, TECHNIQUES, AND APPLICATIONS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article								This paper proposes a mining novel approach which consists of two new data mining algorithms for the classification over quantitative data, based on two new pattern called MOUCLAS (MOUntain function based CLASsification) Patterns and Jumping MOUCLAS Patterns. The motivation of the study is to develop two classifiers for quantitative attributes by the concepts of the association rule and the clustering. An illustration of using petroleum well logging data for oil/gas formation identification is presented in the paper. MPs and JMPs are ideally suitable to derive the implicit relationship between measured values (well logging data) and properties to be predicted (oil/gas formation or not). As a hybrid of classification and clustering and association rules mining, our approach have several advantages which are (1) it has a solid mathematical foundation and compact mathematical description of classifiers, (2) it does not require discretization, (3) it is robust when handling noisy or incomplete data in high dimensional data space.	Univ Vienna, Inst Informat & Wirtschaftsinformat, A-1010 Vienna, Austria		Yalei.Hao@postgrads.unisa.edu.au; Gerald.Quirchmayr@unisa.edu.au; mst@cs.unisa.edu.au	Stumptner, Markus/B-5558-2009				AGRAWAL R, 1998, SIGMOD 98; Agrawal R, 1994, P 20 INT C VER LARG, P487; AHMED KM, 2000, P SIGKDD EXPLORATION, V1, P46; Chiu S.L., 1994, J INTELLIGENT FUZZY, V2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1997, INTELLIGENT DATA ANA, P1; DOUGHERTY J, 1995, P 12 INT C MACH LEAR, P94; FAYYAD U., 1996, ADV KNOWLEDGE DISCOV, P1; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Han J. W., 2000, DATA MINING CONCEPTS; Hinneburg A., 1998, KNOWLEDGE DISCOVERY, P58; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LENT B, 1997, ICDE, P220; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; LIU B, 1999, P ACM SIGKDD INT C K; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Liu H., 1998, FEATURE SELECTION KN; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SARAWAGI W, 1988, INT J PATTERN RECOGN, V2, P197; SKIKANT R, 1996, SIG MOD 96, P1; Yager RR, 1994, J INTELL FUZZY SYST, V2, P209	22	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		LECT NOTES ARTIF INT			2006	3755						118	129				12	Computer Science, Artificial Intelligence	Computer Science	BEB23	WOS:000236545100010	
S	Naiman, DQ		Kimmel, A; Oluver, B		Naiman, Daniel Q.			Random data set generation to support microarray analysis	DNA MICROARRAYS, PART B: DATABASES AND STATISTICS	Methods in Enzymology		English	Review; Book Chapter							GENE-EXPRESSION; CLASSIFICATION; ASSOCIATION; VALIDATION; DIAGNOSIS; INFERENCE	As microarray analyses become increasingly routine, involving the simultaneous investigation of huge numbers of genes, researchers can easily search for and uncover what appear to be promising patterns in their data. In such circumstances tools are needed to help decide the extent to which these patterns are meaningful or can be explained by chance alone. The purpose of this chapter is to describe examples of the use of microarray analysis for inferential purposes and how validation of inference is addressed by Monte-Carlo techniques, which essentially amounts to investigation of statistical methods on synthetic or random data sets.	Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD USA	Naiman, DQ (reprint author), Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD USA.						Cardon LR, 2001, NAT REV GENET, V2, P91, DOI 10.1038/35052543; Chen M., 2001, MONTE CARLO METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davison A.C., 1997, BOOTSTRAP METHODS TH; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; EFRON B, 1979, SIAM NSF CBMS MONOGR, V38; Ernst MD, 2004, STAT SCI, V19, P676, DOI 10.1214/088342304000000396; Fishman G. S., 1996, MONTE CARLO CONCEPTS; FRIEDMAN J, 1996, J DATA MINING KNOWLE, V1, P55; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GEMAN D, 2004, STAT APPL GENET MICR, V3; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hall P., 1992, BOOTSTRAP EDGEWORTH; KOHAVI R, 1996, MACH LEARN P 13 INT; Kreiner T, 2005, AM J HEALTH-SYST PH, V62, P296; KULLDORFF M, 1995, STAT MED, V14, P799, DOI 10.1002/sim.4780140809; LePage R, 1992, EXPLORING LIMITS BOO; Naiman DQ, 2001, J COMPUT GRAPH STAT, V10, P296, DOI 10.1198/10618600152628194; Ott J, 1991, ANAL HUMAN GENETIC L; Parisi M, 2003, SCIENCE, V299, P697, DOI 10.1126/science.1079190; Sham P, 2002, NAT REV GENET, V3, P862, DOI 10.1038/nrg930; Shao J., 1995, JACKKNIFE BOOTSTRAP; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299	28	2	2	ELSEVIER ACADEMIC PRESS INC	SAN DIEGO	525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA	0076-6879	978-0-12-182816-5	METHOD ENZYMOL	Methods Enzymol.		2006	411						312	325		10.1016/S0076-6879(06)11016-2		14	Biochemical Research Methods; Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	BFT40	WOS:000244506300016	
S	Baird, HS; Moll, MA; Nonnemaker, J; Casey, MR; Delorenzo, DL		Taghva, K; Lin, X		Baird, Henry S.; Moll, Michael A.; Nonnemaker, Jean; Casey, Matthew R.; Delorenzo, Don L.			Versatile document image content extraction - art. no. 60670R	Document Recognition and Retrieval XIII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Document Recognition and Retrieval XIII	JAN 18-19, 2006	San Jose, CA	Soc Imaging Sci & Technol, SPIE		Bayes decision theory; classification; k Nearest Neighbors; k-d trees; CART; spatial data structures; computational geometry; hashing	BINARY SEARCH TREES	We offer a preliminary, report on a research pro-ram to investigate versatile algorithms for document image content extraction. that is locating re-ions containing handwriting, machine-print text, graphics, line-art, logos, photographs, noise, etc. To solve this problem in its full generality requires coping with a vast diversity of document and image types. Automatically trainable methods are highly desirable, as well as extremely high speed in order to process large collections. Significant obstacles include the expense of preparing correctly labeled ("ground-truthed") samples, unresolved methodological questions in specifying the domain (e.g. what is a representative collection of document images?), and a lack of consensus among researchers on how to evaluate content-extraction performance. Our research strategy emphasizes versatility first: that is, we concentrate at the outset on designing methods that promise to work across the broadest possible range of cases. This strategy, has several important implications: the classifiers must be trainable in reasonable time on vast data sets: and expensive ground-truthed data sets must be complemented by amplification using generative models. These and other design and architectural issues are discussed. We propose a trainable classification methodology that marries k-d trees and hash-driven table lookup and describe preliminary experiments.	Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18017 USA	Baird, HS (reprint author), Lehigh Univ, Dept Comp Sci & Engn, 19 Mem Dr W, Bethlehem, PA 18017 USA.						Bentley JL, 1975, COMMUN ACM, V18; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2004, P S COMP GEOM; Duda R. O., 2001, PATTERN CLASSIFICATI; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Freidman J., 1977, ACM T MATH SOFTWARE, V3, P209, DOI 10.1145/355744.355745; Gionis A., 1999, P 25 INT C VER LARG; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067; LEE DT, 1977, ACTA INFORM, V9, P23; Samet H., 1990, DESIGN ANAL SPATIAL; Weber R., 1998, P 24 INT C VER LARG; Yuval G., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90064-8	14	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-6107-5	P SOC PHOTO-OPT INS			2006	6067						R670	R670	60670R	10.1117/12.650359		7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BEF49	WOS:000237093200025	
J	Gibert, K; Sanchez-Marre, M; Rodriguez-Roda, I				Gibert, K; Sanchez-Marre, M; Rodriguez-Roda, I			GESCONDA: An intelligent data analysis system for knowledge discovery and management in environmental databases	ENVIRONMENTAL MODELLING & SOFTWARE			English	Article						knowledge acquisition and management; data mining; machine learning; environmental databases	CLASSIFICATION; WWTP	In this work the GESCONDA software is presented. It is a tool for intelligent data analysis and implicit knowledge management of databases, with special focus on environmental databases. Differing from existing commercial systems, the more relevant aspects of this proposal are the incorporation of the statistical data filtering and pre-processing in the same software tool together with the intelligent data analysis techniques as well as the interaction of different data mining methods. Either statistical techniques or artificial intelligence techniques or even mixed techniques are combined and used to extract the knowledge contained within data. (c) 2005 Elsevier Ltd. All rights reserved.	Univ Politecn Catalunya, Dept Stat & Operat Res, E-08028 Barcelona, Catalonia, Spain; Univ Politecn Catalunya, Knowledge Engn & Machine Learning Grp, ES-08034 Barcelona, Catalonia, Spain; Univ Girona, Lab Engn Quim & Ambiental, Girona 17071, Catalonia, Spain	Gibert, K (reprint author), Univ Politecn Catalunya, Dept Stat & Operat Res, C Pau Gargallo 5, E-08028 Barcelona, Catalonia, Spain.	karina@eio.upc.es; miquel@lsi.upc.es; ignasi@lequia.udg.es	Sanchez-Marre, Miquel/A-8569-2011				Ball G. H., 1965, ISODATA NOVEL METHOD; BRATKO I, 2000, ANAL ENV DATA MACHIN; Breiman L, 1984, CLASSIFICATION REGRE; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; Comas J, 2001, AI COMMUN, V14, P45; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1996, MACH LEARN, V24, P141; GIBERT K, 1998, LECT NOTES ARTIF INT, V510, P83; GIBERT K, 2004, 4 ECAI WORKSH BIND E; GIBERT K, 2004, TENDENCIAS MINERIA D, P119; Gibert K, 1998, COMPUTACION SISTEMAS, V1, P213; Jain A., 1988, ALGORITHMS CLUSTERIN; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; LEBART, 1985, TRATAMIENTO ESTADIST; MCKUSICK K, 1990, FIA9061812 NASA AM R; MORABITO FC, 2001, NATO ADV RES WORKSH; PHAM, 1995, RULES SIMPLE RULER E, V8; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rodriguez-Roda I, 2002, WATER SCI TECHNOL, V45, P289; Sanchez M, 1997, APPL INTELL, V7, P147, DOI 10.1023/A:1008202113300; Sanchez-Marre M, 1999, ENVIRON MODELL SOFTW, V14, P349, DOI 10.1016/S1364-8152(98)00097-8; SANCHEZMARRE M, 2002, INTEGRATED ASSESSMEN, V3, P420; Witten I.H., 1999, DATA MINING PRACTICA	25	15	16	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1364-8152		ENVIRON MODELL SOFTW	Environ. Modell. Softw.	JAN	2006	21	1					115	120		10.1016/j.envsoft.2005.01.004		6	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Sciences	Computer Science; Engineering; Environmental Sciences & Ecology	002SO	WOS:000234631900011	
J	Okun, O; Priisalu, H				Okun, Oleg; Priisalu, Helen			Fast nonnegative matrix factorization and its application for protein fold recognition	EURASIP JOURNAL ON APPLIED SIGNAL PROCESSING			English	Article							NEURAL-NETWORKS; CLASSIFICATION; ALGORITHMS	Linear and unsupervised dimensionality reduction via matrix factorization with nonnegativity constraints is studied. Because of these constraints, it stands apart from other linear dimensionality reduction methods. Here we explore nonnegative matrix factorization in combination with three nearest-neighbor classifiers for protein fold recognition. Since typically matrix factorization is iteratively done, convergence, can be slow. To speed up convergence, we perform feature scaling ( normalization) prior to the beginning of iterations. This results in a significantly ( more than 11 times) faster algorithm. Justification of why it happens is provided. Another modification of the standard nonnegative matrix factorization algorithm is concerned with combining two known techniques for mapping unseen data. This operation is typically necessary before classifying the data in low-dimensional space. Combining two mapping techniques can yield better accuracy than using either technique alone. The gains, however, depend on the state of the random number generator used for initialization of iterations, a classifier, and its parameters. In particular, when employing the best out of three classifiers and reducing the original dimensionality by around 30%, these gains can reach more than 4%, compared to the classification in the original, high-dimensional space. Copyright (C) 2006 Hindawi Publishing Corporation. All rights reserved.	Univ Oulu, Machine Vis Grp, Infotech Oulu, Oulu 90014, Finland; Univ Oulu, Dept Elect & Informat Engn, Oulu 90014, Finland	Okun, O (reprint author), Univ Oulu, Machine Vis Grp, Infotech Oulu, POB 4500, Oulu 90014, Finland.						Behnke S., 2003, P INT JOINT C NEUR N, V4, P2758, DOI 10.1109/IJCNN.2003.1224004; BOLOGNA G, 2002, P 9 INT C NEUR INF P, V5, P2492; Buciu I., 2004, P 17 INT C PATT REC, V1, P288; CHEN X, 2001, P IEEE COMP SOC C CO, V1, pI1126; Cho YC, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P633; Chung IF, 2003, LECT NOTES COMPUT SC, V2714, P1159; COMMON P, 1991, P I WORKSH HIGH ORD, P111; Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Feng T., 2002, P 2 INT C DEV LEARN, P178; Guillamet D., 2001, Proceedings 11th International Conference on Image Analysis and Processing, DOI 10.1109/ICIAP.2001.957018; Guillamet D, 2003, PATTERN RECOGN LETT, V24, P2447, DOI 10.1016/S0167-8655(03)00089-8; Guillamet D, 2003, PATTERN RECOGN LETT, V24, P1599, DOI 10.1016/S0167-8655(02)00399-9; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Huang CD, 2003, LECT NOTES COMPUT SC, V2714, P1168; Jolliffe I. T., 1986, PRINCIPAL COMPONENT; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lawrence J, 2004, ACM T GRAPHIC, V23, P496, DOI 10.1145/1015706.1015751; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; LI Y, 2003, P 7 INT S SIGN PROC, V1, P57; Liu W, 2003, P IEEE INT C AC SPEE, P293; Lo Conte L, 2000, NUCLEIC ACIDS RES, V28, P257, DOI 10.1093/nar/28.1.257; LU J, 2003, P IEEE WIC INT C WEB, P405; Mao Y., 2004, P 4 ACM SIGCOMM C IN, P278, DOI 10.1145/1028788.1028827; NOVAK M, 2001, P 2001 IEEE C AC SPE, V1, P541; Okun OG, 2004, Proceedings of the Fourth IASTED International Conference on Visualization, Imaging, and Image Processing, P550; OKUN O, 2004, P 2 EUR WORKSH DAT M, P47; Okun O. G., 2006, Pattern Recognition and Image Analysis, V16, DOI 10.1134/S1054661806010068; Okun O., 2004, P 11 FINN ART INT C, P207; Pal NR, 2003, LECT NOTES COMPUT SC, V2714, P1176; Plumbley MD, 2004, IEEE T NEURAL NETWOR, V15, P66, DOI 10.1109/TNN.2003.820672; RAJAPAKSE M, 2003, P 3 INT S IM SIGN PR, V2, P605; RAMANATH R, 2003, P 32 APPL IM PATT RE, P33; Saul LK, 2002, ADV NEUR IN, V14, P897; Smaragdis P., 2003, P IEEE WORKSH APPL S, P177; TSUGE S, 2001, P IEEE INT C SYST MA, V2, P960; Vincent P, 2002, ADV NEUR IN, V14, P985; WANG Y, 2004, P 6 AS C COMP VIS JE; Xu BW, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P273; Yu K, 2002, NEURAL PROCESS LETT, V15, P147, DOI 10.1023/A:1015244902967	42	7	8	HINDAWI PUBLISHING CORPORATION	NEW YORK	410 PARK AVENUE, 15TH FLOOR, #287 PMB, NEW YORK, NY 10022 USA	1110-8657		EURASIP J APPL SIG P	EURASIP J Appl. Signal Process.		2006									71817	10.1155/ASP/2006/71817		8	Engineering, Electrical & Electronic	Engineering	106DF	WOS:000242080500001	
J	Phan, JH; Quo, CF; Wang, MD				Phan, John H.; Quo, Chang-Feng; Wang, May D.			Functional genomics and proteomics in the clinical neurosciences: data mining and bioinformatics	FUNCTIONAL GENOMICS AND PROTEOMICS IN THE CLINICAL NEUROSCIENCES	PROGRESS IN BRAIN RESEARCH		English	Review							MICROARRAY EXPRESSION DATA; TANDEM MASS-SPECTRA; CROSS-VALIDATION; GENE-EXPRESSION; PATTERN-CLASSIFICATION; CANCER CLASSIFICATION; SELECTION; IDENTIFICATION; NORMALIZATION; ERROR	The goal of this chapter is to introduce some of the available computational methods for expression analysis. Genomic and proteomic experimental techniques are briefly discussed to help the reader understand these methods and results better in context with the biological significance. Furthermore, a case study is presented that will illustrate the use of these analytical methods to extract significant biomarkers from high-throughput microarray data. Genomic and proteomic data analysis is essential for understanding the underlying factors that are involved in human disease. Currently, such experimental data are generally obtained by high-throughput microarray or mass spectrometry technologies among others. The sheer amount of raw data obtained using these methods warrants specialized computational methods for data analysis. Biomarker discovery for neurological diagnosis and prognosis is one such example. By extracting significant genomic and proteomlic biomarkers in controlled experiments, we come closer to understanding how biological mechanisms contribute to neural degenerative diseases such as Alzheimers' and how drug treatments interact with the nervous system. In the biomarker discovery process, there are several computational methods that must be carefully considered to accurately analyze genomic or proteomic data. These methods include quality control, clustering, classification, feature ranking, and validation. Data quality control and normalization methods reduce technical variability and ensure that discovered biomarkers are statistically significant. Preprocessing steps must be carefully selected since they may adversely affect the results of the following expression analysis steps, which generally fall into two categories: unsupervised and supervised. Unsupervised or clustering methods can be used to group similar genomic or proteomic profiles and therefore can elucidate relationships within sample groups. These methods can also assign biomarkers to sub-groups based on their expression profiles across patient samples. Although clustering is useful for exploratory analysis, it is limited due to its inability to incorporate expert knowledge. On the other hand, classification and feature ranking are supervised, knowledge-based machine learning methods that estimate the distribution of biological expression data and, in doing so, can extract important information about these experiments. Classification is closely coupled with feature ranking, which is essentially a data reduction method that uses classification error estimation or other statistical tests to score features. Biomarkers can subsequently be extracted by eliminating insignificantly ranked features. These analytical methods may be equally applied to genetic and proteomic data. However, because of both biological differences between the data sources and technical differences between the experimental methods used to obtain these data, it is important to have a firm understanding of the data sources and experimental methods. At the same time, regardless of the data quality, it is inevitable that some discovered biomarkers are false positives. Thus, it is important to validate discovered biomarkers. The validation process may be slow; yet, the overall biomarker discovery process is significantly accelerated due to initial feature ranking and data reduction steps. Information obtained from the validation process may also be used to refine data analysis procedures for future iteration. Biomarker validation may be performed in a number of ways - bench-side in traditional labs, web-based electronic resources such as gene ontology and literature databases, and clinical trials.	Georgia Inst Technol, Wallace H Coulter Dept Biomed Engn, Atlanta, GA 30322 USA; Emory Univ, Atlanta, GA 30322 USA	Wang, MD (reprint author), Georgia Inst Technol, Wallace H Coulter Dept Biomed Engn, Atlanta, GA 30322 USA.	maywang@bme.gatech.edu					Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Ashburner M, 2000, NAT GENET, V25, P25; Bern M, 2004, BIOINFORMATICS, V20, P49, DOI 10.1093/bioinformatics/bth947; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Braga-Neto U, 2004, PATTERN RECOGN, V37, P1267, DOI 10.1016/j.patcog.2003.08.017; Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419; Bruni R, 2005, J PEPT SCI, V11, P225, DOI 10.1002/psc.595; Cheng C-C., 2001, LIBSVM LIB SUPPORT V; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P403; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Devore IL, 2004, PROBABILITY STAT ENG, P687; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Elias JE, 2004, NAT BIOTECHNOL, V22, P214, DOI 10.1038/nbt930; Espina V, 2003, PROTEOMICS, V3, P2091, DOI 10.1002/pmic.200300592; Fields S, 2001, SCIENCE, V291, P1221, DOI 10.1126/science.291.5507.1221; Fu WJJ, 2005, BIOINFORMATICS, V21, P1979, DOI 10.1093/bioinformatics/bti294; Gay S, 2002, PROTEOMICS, V2, P1374, DOI 10.1002/1615-9861(200210)2:10<1374::AID-PROT1374>3.0.CO;2-D; Glish GL, 2003, NAT REV DRUG DISCOV, V2, P140, DOI 10.1038/nrd1011; Goutte C, 1997, NEURAL COMPUT, V9, P1245, DOI 10.1162/neco.1997.9.6.1245; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Ham F., 2001, PRINCIPLES NEUROCOMP; HOFFMANN R, 2002, BIOINFORMATICS, V21, P1509; Hubert M, 2004, BIOINFORMATICS, V20, P1728, DOI 10.1093/bioinformatics/bth158; Kim YH, 2004, LECT NOTES COMPUT SC, V3102, P346; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Li JN, 2002, CLIN CHEM, V48, P1296; LIAO M, 2005, BAYSIAN MODELS MACHI; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mangiameli P, 1996, EUR J OPER RES, V93, P402, DOI 10.1016/0377-2217(96)00038-0; Mlecnik B, 2005, NUCLEIC ACIDS RES, V33, pW633, DOI 10.1093/nar/gki391; Model Fabian, 2002, Bioinformatics, V18 Suppl 1, pS155; MODLICH O, 2005, J TRANSL MED, V32; Nhat VDM, 2005, LECT NOTES COMPUT SC, V3512, P899; Ni B, 2004, LECT NOTES COMPUT SC, V3242, P1153; Olshen AB, 2002, BIOINFORMATICS, V18, P961, DOI 10.1093/bioinformatics/18.7.961; Pandey A, 2000, NATURE, V405, P837, DOI 10.1038/35015709; Paul TK, 2004, LECT NOTES COMPUT SC, V3102, P414; Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576; Reilly C, 2003, J AM STAT ASSOC, V98, P868, DOI 10.1198/016214503000000800; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Steen H, 2004, NAT REV MOL CELL BIO, V5, P699, DOI 10.1038/nrm1468; Suzuki T, 2000, BIOTECHNIQUES, V29, P332; Szabo A, 2002, MATH BIOSCI, V176, P71, DOI 10.1016/S0025-5564(01)00103-1; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Theilhaber J, 2002, GENOME RES, V12, P165, DOI 10.1101/gr.182601; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V.N., 1995, NATURE STAT LEARNING; Wang AT, 2005, STAT MED, V24, P2069, DOI 10.1002/sim.2082; Wolkenhauer O, 2002, COMPAR FUNCT GENOM, V3, P375, DOI 10.1002/cfg.192; Yan B, 2005, BIOINFORMATICS, V21, P563, DOI 10.1093/bioinformatics/bti044; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15; Zeeberg BR, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-4-r28; Zien A., 2001, BIOINFORMATICS, V17, pS323; *BIOAN RES GROUP, 2005, PEPTIDESEARCH FINGER; *BIOINF LINKS DIR, 2005, PROT INT PATHW ENZ	63	12	13	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0079-6123		PROG BRAIN RES			2006	158						83	108		10.1016/S0079-6123(06)58004-5		26	Neurosciences	Neurosciences & Neurology	BGH63	WOS:000247003700004	
B	Elashoff, DA		Hofmann, WK		Elashoff, David A.			Statistical analysis of gene expression data	GENE EXPRESSION PROFILING BY MICROARRAYS: CLINICAL IMPLICATIONS			English	Article; Book Chapter							OLIGONUCLEOTIDE MICROARRAYS; CLASSIFICATION; DISCOVERY; MODEL; CANCER; ARRAYS	Statistical analysis of the complex data sets produced in DNA microarray experiments presents substantial challenges to the experimenter and statistician alike. Due to the large number of genes and small number of samples, traditional statistical analysis methods alone are not typically sufficient to make appropriate conclusions. This chapter introduces the reader to the basic concepts in the analysis of microarray data and provides a summary of some of the most commonly used techniques. The overall structure of a microarray data analysis can be divided into four distinct components. The four components of a microarray data analysis consist of data preprocessing/quality control, identification of differentially expressed genes, unsupervised clustering/data visualization, and supervised classification/prediction. As the science of microarray analysis has advanced, a wide variety of methods have been developed to address each of these components. Guidance is provided as to the situations in which the various techniques can be applied most productively and cautions given about cases where these techniques will give inappropriate answers.	Univ Calif Los Angeles, Sch Publ Hlth, Dept Biostat, Los Angeles, CA 90095 USA	Elashoff, DA (reprint author), Univ Calif Los Angeles, Sch Publ Hlth, Dept Biostat, Los Angeles, CA 90095 USA.						Affymetrix, 2002, STAT ALG DESCR DOC; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; BREIMAN L, 1999, 567 UC BERK DEP STAT; Breiman L, 1984, CLASSIFICATION REGRE; Cole SW, 2003, BIOINFORMATICS, V19, P1808, DOI 10.1093/bioinformatics/btg242; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDOIT S, 2000, 578 UC BERK; ELASHOFF D, EMPIRICAL S IN PRESS; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; HUBERT L, 1985, J CLASSIFICATIONS, V2, P194; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng015; Kerr MK, 2001, BIOSTATISTICS, V2, P183, DOI DOI 10.1093/BIOSTATISTICS/2.2.183; Lazzeroni L, 2002, STAT SINICA, V12, P61; Li C, 2001, P NATL ACAD SCI USA, V98, P31, DOI 10.1073/pnas.011404098; Rosati B, 2004, BIOTECHNIQUES, V36, P316; Shedden K, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-26; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Terrin N, 2003, J CLIN EPIDEMIOL, V56, P721, DOI 10.1016/S0895-4356(03)00120-3; Tibshirani R, 1999, CLUSTERING METHODS A; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V.N., 2000, STAT ENG INFORM SCI; Wu ZJ, 2004, J AM STAT ASSOC, V99, P909, DOI 10.1198/016214504000000683; YANG YH, 2000, NORMALIZATION CDNA M; YANG YH, 2000, 584 UC BERK; Zhang L, 2003, NAT BIOTECHNOL, V21, P818, DOI 10.1038/nbt836; *AFF SANT CLAR, 1999, AFF MICR SUIT US GUI	27	0	0	CAMBRIDGE UNIV PRESS	CAMBRIDGE	THE PITT BUILDING, TRUMPINGTON ST, CAMBRIDGE CB2 1RP, CAMBS, ENGLAND		978-0-521-85396-5				2006							47	79			10.2277/ 0521853966	33	Genetics & Heredity; Medicine, General & Internal	Genetics & Heredity; General & Internal Medicine	BXO40	WOS:000296572500005	
J	Saha, S; Heber, S				Saha, Soma; Heber, Steffen			In silico prediction of yeast deletion phenotypes	GENETICS AND MOLECULAR RESEARCH			English	Article						classification; essential genes; simulated annealing; yeast phenotype		Analysis of gene deletions is a fundamental approach for investigating gene function. We evaluated an algorithm that uses classification techniques to predict the phenotypic effects of gene deletions in yeast. We used a modified simulated annealing algorithm for feature selection and weighting. The selected features with high weights were phylogenetic conservation scores for bacteria, fungi (excluding Ascomycota), Ascomycota (excluding Saccharomyces cerevisiae), plants, and mammals, degree of paralogy, and number of protein-protein interactions. Classification was performed by weighted k-nearest neighbor and with support vector machine algorithms. To demonstrate how this approach might complement existing experimental procedures, we applied our algorithm to predict essential genes and genes causing morphological alterations in yeast.	[Saha, Soma; Heber, Steffen] N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA	Heber, S (reprint author), N Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA.	sheber@ncsu.edu					Akerley BJ, 2002, P NATL ACAD SCI USA, V99, P966, DOI 10.1073/pnas.012602299; BAUDIN A, 1993, NUCLEIC ACIDS RES, V21, P3329, DOI 10.1093/nar/21.14.3329; Chen Y, 2005, BIOINFORMATICS, V21, P575, DOI 10.1093/bioinformatics/bti058; Coghlan A, 2000, YEAST, V16, P1131, DOI 10.1002/1097-0061(20000915)16:12<1131::AID-YEA609>3.0.CO;2-F; Coulomb S, 2005, P ROY SOC B-BIOL SCI, V272, P1721, DOI 10.1098/rspb.2005.3128; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gasteiger E, 2003, NUCLEIC ACIDS RES, V31, P3784, DOI 10.1093/nar/gkg563; Giaever G, 2002, NATURE, V418, P387, DOI 10.1038/nature00935; Glover F., 1993, MODERN HEURISTIC TEC, P70; Hashimoto M, 2005, MOL MICROBIOL, V55, P137, DOI 10.1111/j.1365-2958.2004.04386.x; Hubbard T, 2005, NUCLEIC ACIDS RES, V33, pD447, DOI 10.1093/nar/gki138; Janssen P, 2003, BIOINFORMATICS, V19, P1451, DOI 10.1093/bioinformatics/btg161; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kobayashi K, 2003, P NATL ACAD SCI USA, V100, P4678, DOI 10.1073/pnas.0730515100; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krylov DM, 2003, GENOME RES, V13, P2229, DOI 10.1101/gr.1589103; Kuramochi M, 2001, 2ND ANNUAL IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS, P191; Lopez-Bigas N, 2004, NUCLEIC ACIDS RES, V32, P3108, DOI 10.1093/nar/gkh605; Salama NR, 2004, J BACTERIOL, V186, P7926, DOI 10.1128/JB.186.23.7926-7935.2004; Smalley DJ, 2003, TRENDS MICROBIOL, V11, P6, DOI 10.1016/S0966-842X(02)00008-2; Vapnik V, 1999, NATURE STAT LEARNING; von Mering C, 2002, NATURE, V417, P399; WACH A, 1994, YEAST, V10, P1793, DOI 10.1002/yea.320101310; Xenarios Ioannis, 2001, Current Opinion in Biotechnology, V12, P334, DOI 10.1016/S0958-1669(00)00224-X	24	12	12	FUNPEC-EDITORA	RIBEIRAO PRETO	RUA HUDSON 655, JARDIM CANADA, RIBEIRAO PRETO, SP, BRAZIL	1676-5680		GENET MOL RES	Genet. Mol. Res.		2006	5	1					224	232				9	Biochemistry & Molecular Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Genetics & Heredity	V44OJ	WOS:000203011700027	
S	Guillas, S; Bertet, K; Ogier, JM		Liu, W; Llados, J		Guillas, Stephanie; Bertet, Karell; Ogier, Jean-Marc			A generic description of the concept lattices' classifier: Application to symbol recognition	GRAPHICS RECOGNITION: TEN YEARS REVIEW AND FUTURE PERSPECTIVES	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Workshop on Graphic Recognition	AUG 25-26, 2005	Hong Kong, PEOPLES R CHINA	City Univ Hong Kong, IAPR, K C Wong Educ Fdn, Hong Kong Web Soc				In this paper, we present the problem of noisy images recognition and in particular the stage of primitives selection in a classification process. We suppose that segmentation and statistical features extraction on documentary images are realized. We describe precisely the use of concept lattice and compare it with a decision tree in a recognition process. From the experimental results, it appears that concept lattice is more adapted to the context of noisy images.	Univ La Rochelle, L3I, F-17042 La Rochelle 1, France	Guillas, S (reprint author), Univ La Rochelle, L3I, Av M Crepeau, F-17042 La Rochelle 1, France.	sguillas@univ-1r.fr; kbertet@univ-1r.fr; jmogier@univ-1r.fr					ADAM S, 1999, ICDAR 99, P45; Bertet K, 2004, DISCRET MATH THEOR C, V6, P315; Birkhoff G., 1967, LATTICE THEORY, V25; Bordat J. P., 1986, MATH SCI HUMAINES, V96, P31; BUNKE H, 2000, 15 INT C PATT REC, V2, P117; CANU S, 2005, NATL ICT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Derrode S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P877; GANTER B., 1999, FORMAL CONCEPT ANAL; Godin R., 1993, OOPSLA, P394; GUNES V, 2000, IJUFKS; KANUNGO T, 1994, IAPR WORKSH MACH VIS, P552; LEFEVRE E, 2000, TRAITEMENT SIGNAL, V17; MILGRAM M, 1993, RECONNAISSANCE FORME; NOURINE L, 1999, 3 INT C ORD ALG APPL; OBIEDKOV S, 2003, 4 INT C JOURN INF ME, P15; TABBONE S, 2003, TECHNIQUE SCI INFORM; TAOUIL R, 2001, P ICCS 2001 INT WORK, P290; TEAGUE M, 2003, J OPTICAL SOC AM JOS, V70, P920; Tombre K., 2003, Proceedings Seventh International Conference on Document Analysis and Recognition; GREC	21	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-34711-9	LECT NOTES COMPUT SC			2006	3926						47	60				14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BEX73	WOS:000240036000005	
B	Chen, F; Wu, SX		Li, M		Chen Fen; Wu Shunxiang			The application of classification methods in intrusion detection system	ICCSE'2006: Proceedings of the First International Conference on Computer Science & Education: ADVANCED COMPUTER TECHNOLOGY, NEW EDUCATION			English	Proceedings Paper	1st International Conference on Computer Science and Education (ICCSE 2006)	JUL 27-29, 2006	Xiamen, PEOPLES R CHINA	China Natl Res Council Comp Educ Coll & Univ, IEEE Control Syst Chapter, Singapore, Univ Virginia, Univ Melbourne	Xiamen Univ	intrusion detection; K_Nearest neighbor (KNN); support vector machine (SVM); character selection		Because of the high percent of misinformation in intrusion Detection System, we use classification methods in it in this paper. We mainly introduce the KNN and SVM. Using them we can get ideal result in processing non-structural data. If the dimension of data is not high, KNN can get more ideal result; and SVM can be applicable to the data which dimension is very high. So we create a new model for intrusion detection system based KNN and SVM; and we set a threshold for dimension to decide whether using KNN or SVM. In the end, we make some experiments to compare our system with traditional intrusion detection system.	Xiamen Univ, Dept Automat, Xiamen 361005, Peoples R China	Chen, F (reprint author), Xiamen Univ, Dept Automat, Xiamen 361005, Peoples R China.						CHENG SL, 2005, J WUHAN U, V27, P61; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., INTRO SUPPORT VECTOR; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; [马传香 Ma Chuanxiang], 2005, [计算机工程, Computer Engineering], V31, P4; Vpanik V., 1995, NATURE STAT LEARNING	6	0	0	XIAMEN UNIV PRESS	FUJIAN	XIAMEN, FUJIAN, 361005, PEOPLES R CHINA		7-5615-2582-6				2006							586	588				3	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Telecommunications	Computer Science; Telecommunications	BFD83	WOS:000241272800138	
B	Shaneck, M; Kim, Y; Kumar, V		Tsumoto, S; Clifton, CW; Zhong, N; Wu, XD; Liu, JM; Wah, BW; Cheung, YM		Shaneck, Mark; Kim, Yongdae; Kumar, Vipin			Privacy preserving nearest neighbor search	ICDM 2006: Sixth IEEE International Conference on Data Mining, Workshops			English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				Data mining is frequently obstructed by privacy concerns. In many cases data is distributed, and bringing the data together in one place for analysis is not possible due to privacy laws (e.g. HIPAA) or policies. Privacy preserving data mining techniques have been developed to address this issue by providing mechanisms to mine the data while giving certain privacy guarantees. In this work we address the issue of privacy preserving nearest neighbor search, which forms the kernel of many data mining applications. To this end, we present a novel algorithm based on secure multiparty computation primitives to compute the nearest neighbors of records in horizontally distributed data. We show how this algorithm can be used in three important data mining algorithms, namely LOF outlier detection, SNN clustering, and kNN classification.	Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA	Shaneck, M (reprint author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.						Agrawal R., 2000, P ACM INT C MAN DAT; Atallah MJ, 2001, P 17 ANN COMP SEC AP; Breunig M., 2000, P ACM INT C MAN DAT; CHITTI S, 2004, MINING MULTIPLE PRIV; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ERTOZ L, 2003, P SIAM INT C DAT MIN; EVFIMIEVSKI A, 2002, P SIGKDD; GOETHALS B, 2004, P 7 ANN INT C INF SE; Goldreich O., 2004, FDN CRYPTOGRAPHY, V2; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; JHA S, 2005, P 10 ESORICS; KANTARCIOGLU M, 2004, P 8 EUR C PRINC PRAC; KARGUPTA H, 2003, KNOWLEDGE INFORM SYS; LINDELL Y, 2000, P ADV CRYPT CRYPTO; MAYER B, 2005, ANN S AM MED INF ASS; SHANECK M, 2006, TR06014 U MINN; Tan P. N., 2006, INTRO DATA MINING; VAIDYA J, 2004, P 4 IEEE INT C DAT M; VAIDYA J, 2002, P SIGKDD; VAIDYA J, 2003, P SIGKDD; ZHAN J, 2005, INT J NETWORK SECURI, V1, P46	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-2702-4				2006							541	545				5	Computer Science, Information Systems	Computer Science	BFZ38	WOS:000245603100099	
B	Zhan, J; Matwin, S		Tsumoto, S; Clifton, CW; Zhong, N; Wu, XD; Liu, JM; Wah, BW; Cheung, YM		Zhan, Justin; Matwin, Stan			A crypto-based approach to privacy-preserving collaborative data mining	ICDM 2006: SIXTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, WORKSHOPS			English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				To conduct data mining, we often need to collect data from various parties. Privacy concerns may prevent the parties from directly sharing the data and some types of information about the data. How multiple parties collaboratively conduct data mining without breaching data privacy presents a challenge. In this paper, we propose a formal definition of privacy, develop a solution for privacy-preserving k-nearest neighbor classification which is one of data mining tasks, and show that our solution preserves data privacy according to our definition.	Carnegie Mellon Univ, Heinz Sch, Pittsburgh, PA 15213 USA; Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada	Zhan, J (reprint author), Carnegie Mellon Univ, Heinz Sch, Pittsburgh, PA 15213 USA.	justinzh@andrew.cmu.edu; stan@site.uottawa.ca					Agrawal R, 2000, P ACM SIGMOD C MAN D, P439, DOI DOI 10.1145/342009.335438; CHAUM D, 1985, COMMUN ACM, V28, P1030, DOI 10.1145/4372.4373; CLIFTON C, 2005, IEEE ICDM WORKSH SEC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dolev D., 1991, P 23 ANN ACM S THEOR, P542, DOI 10.1145/103418.103474; Goldreich O., 2004, FDN CRYPTOGRAPHY, V2; LINDELL Y, 2000, LECT NOTES COMPUTER, V1880; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; Rivest R., 1978, FDN SECURE COMPUTATI, P169; ZHAN J, 2006, THESIS U OTTAWA	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-0-7695-2702-4				2006							546	550				5	Computer Science, Information Systems	Computer Science	BFZ38	WOS:000245603100100	
S	Owotoki, P; Manojlovic, N; Mayer-Lindenberg, F; Pasche, E		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Owotoki, Peter; Manojlovic, Natasa; Mayer-Lindenberg, Friedrich; Pasche, Erik			A data mining approach for capacity building of stakeholders in integrated flood management	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE				New approaches to managing flood events are increasingly of more relevance due to recent widespread floods and the presumed changes in the climate. These approaches fall under the integrated flood management (IFM) banner and focus not only on flood prevention, but on flood resilience. This paper introduces an application (FLORETO) for IFM that utilizes the data mining approach, in a web based three tier system, devoted to the capacity building of stakeholders as a micro-scale resilience strategy of IFM. The intelligent models, which constitute the business logic in FLORETO, are used to match the input parameters or design criteria, describing properties prone to flooding, to technically justifiable flood mitigation measures. Datasets from the German city of Kellinghusen were collected and intelligent models were built. Satisfactory results have been obtained, which shows the promise of this data mining approach and opens the door for its application for IFM in other regions.	Tech Univ Hamburg, Inst Comp Technol, D-2100 Hamburg, Germany; Tech Univ Hamburg, Inst River & Coastal Engn, D-2100 Hamburg, Germany	Owotoki, P (reprint author), Tech Univ Hamburg, Inst Comp Technol, D-2100 Hamburg, Germany.						AHA DW, 1987, P 4 INT C MACH LEARN, P24; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BUCHANAN BG, 1984, RUL BAS EXP SYST; BUNTINE W, 1989, P 6 INT WORKSH MACH, P94; Cabena P., 1998, DISCOVERING DATA MIN; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAENEN BC, 2002, COMPUTATIONAL INTELL; Feigenbaum E. A, 1977, INT JOINT C ART INT, P1014; Hayes-Roth F., 1983, BUILDING EXPERT SYST; Jensen FV, 1996, INTRO BAYESIAN NETWO; PASCHE E, 2006, UNPUB HYDROINFORMATI; PASCHE E, 2004, P URB FLOOD MAN; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; Quinlan R., 1986, MACH LEARN, V1, P81; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salzberg S.L., 1990, LEARNING NESTED GEN; SANTOS E, 1996, AFITENTR9601 AIR FOR; SHAPIRO GP, 1989, WORKSH KNOWL DISC RE; Welbank M., 1983, REV KNOWLEDGE ACQUIS; Witten I., 2005, DATA MINING PRACTICA; ZIMMERMANN H, 2002, ADV COMPUTATIONAL IN; *ENV AG, 2004, FLOOD PROD GUID HOM; *FEMA, 2005, ENG PRINC PRACT RETR	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786	978-0-7695-2701-7	IEEE DATA MINING			2006							446	455				10	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900045	
S	Tahir, MA; Smith, J		Clifton, CW; Zhong, N; Liu, JM; Wah, BW; Wu, XD		Tahir, Muhammad Atif; Smith, James			Improving nearest neighbor classifier using Tabu Search and ensemble distance metrics	ICDM 2006: Sixth International Conference on Data Mining, Proceedings	IEEE International Conference on Data Mining		English	Proceedings Paper	6th IEEE International Conference on Data Mining	DEC 18-22, 2006	Hong Kong, PEOPLES R CHINA	IEEE			STATISTICAL PATTERN-RECOGNITION; ALGORITHMS	The nearest-neighbor (NN) classifier has long been used in pattern recognition, exploratory data analysis, and data mining problems. A vital consideration in obtaining good results with this technique is the choice of distance function, and correspondingly which features to consider when computing distances between samples. In this paper a new ensemble technique is proposed to improve the performance of NN classifier The proposed approach combines multiple NN classifiers, where each classifier uses a different distance function and potentially a different set of features (feature vector). These feature vectors are determined for each distance metric using Simple Voting Scheme incorporated in Tabu Search (TS). The proposed ensemble classifier with different distance metrics and different feature vectors (TS-DF/NN) is evaluated using various benchmark data sets from UCI Machine Learning Repository. Results have indicated a significant increase in the performance when compared with various well-known classifiers. Furthermore, the proposed ensemble method is also compared with ensemble classifier using different distance metrics but with same feature vector (with or without Feature Selection (FS)).	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						BAO Y, 2004, LNCS, V3177; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake C.L., UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R., 1973, PATTERN CLASSIFICATI; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Glover F., 1990, ORSA Journal on Computing, V2; Glover F., 1993, Annals of Operations Research, V41; Glover F., 1989, ORSA Journal on Computing, V1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Michie D, 1994, MACHINE LEARNING NEU; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAIT SM, 1999, GEN ITERATIVE ALGORI; TAHIR MA, 2004, LNCS, V3177; TAHIR MA, 2004, IEEE P INT C PATT RE; Witten I., 2005, DATA MINING PRACTICA; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786	978-0-7695-2701-7	IEEE DATA MINING			2006							1086	1090				5	Computer Science, Information Systems	Computer Science	BFZ37	WOS:000245601900132	
S	Nivre, J				Nivre, J			Inductive Dependency Parsing	INDUCTIVE DEPENDENCY PARSING	Text Speech and Language Technology		English	Book							CONTEXT-FREE LANGUAGES; NATURAL-LANGUAGE; SPECIAL-ISSUE; GRAMMAR; CLASSIFICATION; IMPLEMENTATION; ALGORITHM; RECOGNITION; FORMALISM; MODELS									ABEILLE A, 2003, TREEBANKS BUILDING U, pR13; ABEILLE A, 2003, TREEBANKS BUILDING U; Abeille Anne, 1988, P COLING 88, P578; Abney S., 1991, PRINCIPLE BASED PARS, P257; ABNEY S, 1996, J NATURAL LANGUAGE E, V2, P337; Abney S, 1997, TEXT SPEECH LANG TEC, V2, P118; ABNEY SP, 1991, J PSYCHOLINGUIST RES, V20, P233, DOI 10.1007/BF01067217; ADURIZ I, 2003, P 2 WORKSH TREEB LIN, P201; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aho A. V., 1986, COMPILERS PRINCIPLES; AHO AV, 1995, FDN COMPUTER SCI; Ajdukiewicz K., 1935, STUDIA PHILOS, V1, P1; ALSHAWI H, 1996, P 34 ANN M ASS COMP, P167, DOI 10.3115/981863.981886; ARGAMON S, 1998, P COLING ACL MONTR C, P67; ARUN A, 2005, P ACL 2005, P302; Backus J.W., 1959, P INT C INF PROC, P125; Baker J. K., 1979, P SPRING C AC SOC AM, P547; Bangalore S, 1999, COMPUT LINGUIST, V25, P237; BANGALORE S, 2003, DATA ORIENTED PARSIN, P283; Barbero C., 1998, P WORKSH PROC DEP BA, P58; Bar-Hillel Y., 1960, B RES COUNC ISRAEL F, V9, P1; Bar-Hillel Y, 1953, LANGUAGE, V29, P47, DOI 10.2307/410452; Barton G. Edward, 1987, COMPUTATIONAL COMPLE; BASILI R, 2002, NATURAL LANGUAGE ENG, V8, P97; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bies A., 1995, BRACKETING GUIDELINE; BIGERT J, 2005, THESIS KTH STOCKHOLM; Bikel DM, 2004, COMPUT LINGUIST, V30, P479, DOI 10.1162/0891201042544929; Bishop CM, 1996, NEURAL NETWORKS PATT; Black E., 1992, P 5 DARPA SPEECH NAT, P31; Black E., 1991, P DARPA SPEECH NAT L, P306, DOI 10.3115/112405.112467; BLACK E, 1993, STAT DRIVEN COMPUTER; Blaheta D., 2000, P 1 ANN M N AM CHAPT, P234; Bloomfield Leonard, 1933, LANGUAGE; BOD R, 2000, P COLING 2000, P69; BOD R, 2001, P 39 ANN M ASS COMP, P66, DOI 10.3115/1073012.1073022; BOD R, 1998, P 36 ANN M ASS COMP, P145; Bod R, 1995, THESIS U AMSTERDAM; BOD R, 1998, BEYOND GRAMMAR; Bod Rens, 2003, P 10 C EUR CHAPT ASS, P19; Bod Rens, 2003, PROBABILISTIC LINGUI; Bohmova Alena, 2003, TREEBANKS BUILDING U, P103; BOHNET B, 2003, P 1 INT C MEAN TEXT, P138; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; BOSCO C, 2004, P WORKSH REC ADV DEP, P9; BOULLIER P, 2003, P 8 INT WORKSH PARS, P43; Brants Sabine, 2002, P WORKSH TREEB LING, P24; BRANTS T, 1999, P 9 C EUR CHAPT ACL, P118, DOI 10.3115/977035.977052; Bresnan Joan, 2000, LEXICAL FUNCTIONAL S; BRILL E, 1993, P 3 INT WORKSH PARS, P13; BRISCOE E, 2002, COMPUTATIONAL LINGUI, V19, P25; BUCHHOLZ S, 1999, P JOINT SIGDAT C EMP, P239; BUCHHOLZ S, 2002, THESIS TILBURG U; Burr Ridge I, 1997, MACHINE LEARNING; CAHILL A, 2004, P 42 ANN M ASS COMP, P320; CAMPBELL R, 2004, P 42 ANN M ASS COMP, P646; Caraballo SA, 1998, COMPUT LINGUIST, V24, P275; Cardie C., 2000, P 4 C COMP NAT LANG; Cardie C., 1993, P 10 INT C MACH LEAR, P25; CARPENTER B, 1997, P 5 INT WORKSH PARS, P147; Carpenter B, 1992, LOGIC TYPED FEATURE; Carreras X., 2004, P 8 C COMP NAT LANG, P89; Carrol J., 2003, OXFORD HDB COMPUTATI, P233; CARROLL G, 1992, TR92 BROWN U DEP COM; Carroll J., 2003, TREEBANKS BUILDING U, P299; CARROLL J, 1996, P 1 ACL SIGDAT C EMP, P92; CARROLL J, 2000, HDB NATURAL LANGUAGE, P525; CARROLL J, 1998, P 1 INT C LANG RES E, P447; CARROLL J, 1994, P 32 ANN M ASS COMP, P287, DOI DOI 10.3115/981732.981772; CHANEV A, 2005, P 4 WORKSH TREEB LIN, P29; CHANOD JP, 2001, ROBUSTNESS LANGUAGE, P187; CHARNIAK E., 2000, P 1 C N AM CHAPT ASS, P132; Charniak E, 1997, P 14 NAT C ART INT, P598; Charniak E, 1997, AI MAG, V18, P33; Charniak E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1031; CHARNIAK E, 2003, P MACH TRANSL SUMM N, V9, P40; CHARNIAK E, 2003, P 43 ANN M ASS COMP, P173; CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113, DOI 10.1109/TIT.1956.1056813; Chomsky N., 1959, INFORM CONTR, V2, P137, DOI 10.1016/S0019-9958(59)90362-6; Chomsky N., 1965, ASPECTS THEORY SYNTA; Chomsky N., 1981, LECT GOVT BINDING; Chomsky N., 1957, SYNTACTIC STRUCTURES; Chomsky N., 1995, MINIMALIST PROGRAM; Chomsky Noam, 1970, READINGS ENGLISH TRA; CHU YJ, 1965, SCI SINICA, V14, P1396; Church K.W., 1988, P 2 C APPL NAT LANG, P136, DOI 10.3115/974235.974260; CIVIT M, 2005, P 4 WORKSH TREEB LIN; Clark S., 2004, P 42 ANN M ASS COMP, P104; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; Collins M., 1997, P 35 ANN M ASS COMP, P16; Collins M, 2005, COMPUT LINGUIST, V31, P25, DOI 10.1162/0891201053630273; Collins M., 2000, P 17 INT C MACH LEAR, P175; Collins M., 1999, THESIS U PENNSYLVANI; Collins M., 1996, P 34 ANN M ASS COMP, P184, DOI 10.3115/981863.981888; Collins Michael, 1999, P 37 ANN M ASS COMP, P505, DOI 10.3115/1034678.1034754; Collins Micheal, 1995, P 3 WORKSH VER LARG, P27; Cormen T H, 1990, INTRO ALGORITHMS; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVINGTON M. A, 2001, P 39 ANN ACM SE C AT, P95; COVINGTON MA, 1994, AI199402 U GEORG; COVINGTON MA, 1990, AI199001 U GEORG; Covington M. A., 1990, Computational Linguistics, V16; Covington Michael A., 1984, SYNTACTIC THEORY HIG; Cowie J., 2000, HDB NATURAL LANGUAGE, P241; CURRAN JR, 2004, P 20 INT C COMP LING, P282; DAELEMANS W, 1992, P TWLT3 CONN NAT LAN, P77; DAELEMANS W, 1999, P 3 C COMP NAT LANG, P77; Daelemans W, 1999, J EXP THEOR ARTIF IN, V11, P287, DOI 10.1080/095281399146436; DAELEMANS W, 2004, ILK0402 ILK CNTS; Daelemans W, 2002, P 3 INT C LANG RES E, P755; Daelemans W., 2005, MEMORY BASED LANGUAG; Daelemans W., 2003, P 14 EUR C MACH LEAR, P84; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; Daelemans W, 1996, P 4 WORKSH VER LARG, P14; Daelemans W., 1994, Computational Linguistics, V20; DAELEMANS WMP, 1996, PROGR SPEECH SYNTHES, P77; DAGAN I, 1999, MACH LEARN, V34, P11; DAGAN I, 2003, DATA ORIENTED PARSIN, P169; de Saussure F, 1916, COURS LINGUISTIQUE G; Debusmann R., 2004, P WORKSH REC ADV DEP, P78; DEBUSMANN R, 2001, DECLARATIVE GRAMMAR; Della Pietra S., 1997, IEEE T PATTERN ANAL, V19; DEMEULDER F, 2003, P 7 C NAT LANG LEARN, P208; DEPAUW G, 2003, DATA ORIENTED PARSIN, P147; Devijver P. A., 1982, PATTERN RECOGNITION; Dickinson M., 2003, P 2 WORKSH TREEB LIN, P45; DIDERICHSEN PAUL, 1946, ELEMENTAER DANSK GRA; Dowty D., 1989, PROPERTIES TYPES MEA, P69; Dubey Amit, 2003, P 41 ANN M ASS COMP, P96; DUCHIER D, 2003, RES LANGUAGE COMPUTA, V1, P307, DOI 10.1023/A:1024639523440; DUCHIER D, 1999, P 6 M MATH LANG ORL, P115; Duchier Denys, 2001, P 39 ANN M ASS COMP, P180, DOI 10.3115/1073012.1073036; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Duffy N., 2002, P 40 ANN M ASS COMP, P263; EARLEY J, 1970, COMMUN ACM, V13, P94, DOI 10.1145/362007.362035; EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032; EINARSSON J, 1976, TALBANKENS SKRIFTSPR; EINARSSON J, 1976, TALBANKENS TALSPRAKS; Eisner J., 2000, ADV PROBABILISTIC OT, P29; Eisner J., 1996, P 16 INT C COMP LING, P340; EISNER JM, 1996, IRCS9611 U PENNS I R; EJERHED E, 1997, STOCKHOLM UMEA CORPU; EJERHED E, 1983, 7 SCAND C LING HALL, P410; ESCUDERO G, 2000, P 14 EUR C ART INT E, P421; Fillmore Charles J., 1968, UNIVERSALS LINGUIST, P1; Fix E., 1952, 11 USAF SCH AV MED; FORST M, 2004, P 5 INT WORKSH LING, P31; Foth K., 2004, P 7 C VER NAT SPRACH, P45; FRASER N, 1989, UCL WORKING PAPERS L, V1, P296; FRASER N, 1993, THESIS U LONDON; Fujii A, 1998, COMPUT LINGUIST, V24, P573; FUSIJAKI T, 1989, P 1 INT WORKSH PARS, P105; GAIFMAN H, 1965, INFORM CONTROL, V8, P304, DOI 10.1016/S0019-9958(65)90232-9; GARSIDE R, 1992, LANCASTER PARSED COR; Gazdar G., 1985, GEN PHRASE STRUCTURE; Gildea D, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P167; Gildea D., 2002, P 40 ANN M ASS COMP, P239; GOODMAN J, 1998, THESIS HARVARD U; GOODMAN J, 1996, P 34 ANN M ASS COMP, P177, DOI 10.3115/981863.981887; Grimaldi R., 2004, DISCRETE COMBINATORI; GRISHMAN R, 1992, P 3 ACL C APPL NAT L, P156, DOI 10.3115/974499.974528; GRISHMAN R, 1984, P 10 INT C COMP LING, P96; Hajic J., 1998, ISSUES VALENCY MEANI, P106; Hajic Jan, 2001, PRAGUE DEPENDENCY TR; HALL J, 2003, THESIS VAXJO U; Hammerton J, 2002, J MACH LEARN RES, V2, P551, DOI 10.1162/153244302320884533; HAN C, 2002, P 3 INT C LANG RES E, P1635; HARPER MP, 1995, SOFTWARE PRACT EXPER, V25, P831, DOI 10.1002/spe.4380250802; HARPER MP, 1995, COMPUT SPEECH LANG, V9, P187, DOI 10.1006/csla.1995.0011; Hastie T, 2001, ELEMENTS STAT LEARNI; HAYS DG, 1964, LANGUAGE, V40, P511, DOI 10.2307/411934; HEIN AS, 1982, P 9 INT C COMP LING, P121; HELLWIG P, 1986, P 11 INT C COMP LING, P195, DOI 10.3115/991365.991423; HELLWIG P, 1980, REPRESENTATION PROCE, P195; Hellwig P, 2003, HANDB SPRACH KOMMUN, V25, P593; HENDERSON J, 2004, P 42 ANN M ASS COMP, P96; HENDRICKX I, 2003, P 7 C NAT LANG LEARN, P176; HINDLE D, 1991, P 29 ANN M ASS COMP, P229, DOI 10.3115/981344.981374; HINDLE D, 1994, COMPUTATIONAL APPROA, P103; Hindle Donald, 1989, P 27 ANN M ASS COMP, P118, DOI 10.3115/981623.981638; HINRICHS E, 2002, P 1 WORKSH TREEB LIN; Hjelmslev L., 1943, OMKRING SPROGTEORIEN; Hockenmaier Julia, 2003, P 41 ANN M ASS COMP, P359; Hockenmaier Julia, 2003, THESIS U EDINBURGH; HOLAN T, 1997, 5 C APPL NAT LANG PR, P147; Hopcroft J.E., 1979, INTRO AUTOMATA THEOR; Hopcroft J.E., 2001, INTRO AUTOMATA THEOR; Hudson R., 1984, WORD GRAMMAR; Hudson Richard, 1990, ENGLISH WORD GRAMMAR; ISOZAKI H, 2004, P 20 INT C COMP LING, P275, DOI 10.3115/1220355.1220395; Jackendoff Ray, 1972, SEMANTIC INTERPRETAT; Jackendoff Ray, 1977, X SYNTAX STUDY PHRAS; JARVINEN T, 2004, P WORKSH PROC DEP BA, P1; JARVINEN T, 2003, P 2 WORKSH TREEB LIN, P93; Jebara T., 2004, MACHINE LEARNING DIS; JELINEK F, 1994, P HUM LANG TECHN WOR, P272, DOI 10.3115/1075812.1075873; JENSEN K, 1983, P 1 C APPL NAT LANG, P93, DOI 10.3115/974194.974212; JENSEN K, 1988, P COLING 88, P448; JIKOUN V, 2004, P 42 ANN M ASS COMP, P312; JOHNSON M, 2001, P 39 ANN M ASS COMP, P314; Johnson Mark, 1999, P 37 ANN M ASS COMP, P535, DOI 10.3115/1034678.1034758; Johnson Mark, 2002, P 40 ANN M ASS COMP, P136; Johnson Mark, 1988, ATTRIBUTE VALUE LOGI; Joshi A., 1997, HDB FORMAL LANGUAGES, V3, P69; JOSHI A, 2003, DATA ORIENTED PARSIN, P253; Joshi A. K., 1985, NATURAL LANGUAGE PAR, P206; JUNQUA JC, 2001, ROBUSTNESS LANGUAGE; Kahane Sylvain, 1998, P COLING ACL MONTR, P646; Kaplan R., 1982, MENTAL REPRESENTATIO, P173; Kaplan Ronald M, 2004, P HUM LANG TECHN C N, P97; KARLSSON F, 1990, 13 INT C COMP LING C, P168; KARLSSON F, 1995, CONSTRAINT GRAMMAR L; Kasami T., 1965, AFCRL65758; Kay M, 1980, CSL8012 XER PARC; KAY M, 2000, P 6 INT WORKSH PARS, P6; KAY M, 1989, P 1 INT WORKSH PARS, P52; King Tracy Holloway, 2003, P 4 INT WORKSH LING, P1; Klein D., 2003, P 41 M ASS COMP LING, P423; Klein D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P9; KLEIN DAN, 2004, P 42 ANN M ASS COMP, P479; KNUTH DE, 1965, INFORM CONTROL, V8, P607, DOI 10.1016/S0019-9958(65)90426-2; KOKKINAKIS D, 1999, P 9 C EUR CHAPT ASS, P245, DOI 10.3115/977035.977072; Koskenniemi K, 1997, LANG SPEECH & COMMUN, P99; KOSKENNIEMI K, 1990, 13 INT C COMP LING C, P229; KOUCHNIR B, 2004, P 8 C COMP NAT LANG, P118; Kromann Matthias Trautner, 2003, P 2 WORKSH TREEB LIN, P217; KROMANN MT, 2004, ELECT NOTES THEORETI, V53, P163, DOI 10.1016/S1571-0661(05)82581-2; Kruijff G.-J.M., 2002, ESSLLI2002; KRUIJFF GJM, 2001, THESIS CHARLES U; KRYMOLOWSKI Y, 2000, P ACL 2000 HONG KONG, P45; KUBLER S, 2002, PARSEVAL IMPROVED EV, P9; KUBLER S, 2004, MEMORY BASED PARSING; KUBLER S, 2004, P 3 WORKSH TREEB LIN; KUBLER S, 2001, P 39 ANN M ASS COMP, P346, DOI 10.3115/1073012.1073057; Kucera H, 1967, COMPUTATIONAL ANAL P; Kudo T., 2002, P 6 C NAT LANG LEARN, P63; Kudoh Taku, 2000, P CONLL 2000 LLL 200, p142~144; KUROHASHI S, 2003, TREEBANKS BUILDING U, P249; Lambek J, 1958, AM MATH MONTHLY, V65, P154, DOI 10.2307/2310058; Lang Bernard, 1988, P 12 INT C COMP LING, P365; LECERF Y, 1960, B BIMESTRIEL ATALA, V1, P17; LECERF Y, 1960, B BIMESTRIEL ATALA, V1, P11; LEHMANN S, 1996, P INT C COMP LING CO, P711; LEHNERT W, 1987, P 6 NAT C ART INT AA, P301; Levy Roger, 2004, P 41 M ACL BARC SPAI, P328; LIN D, 1998, NATURAL LANGUAGE ENG, V4, P97, DOI 10.1017/S1351324998001958; Lin Dekang, 1995, P IJCAI 95, P1420; Lin Dekang, 1996, P 16 INT C COMP LING, P729; Lindgren BW, 1993, STAT THEORY; LJUNGLOF P, 2004, THESIS CHALMERS U TE; Lombardo V., 1996, P 16 COLING, P723; Lyons J., 1977, SEMANTICS; Maamouri M., 2004, P WORKSH COMP APPR A, P2, DOI 10.3115/1621804.1621808; Magerman D. M., 1995, P 33 ANN M ASS COMP, P276, DOI 10.3115/981658.981695; MALOUF R, 2000, NATURAL LANGUAGE ENG, V6, P29, DOI 10.1017/S1351324900002382; Manning C., 2000, FDN STAT NATURAL LAN; Marcus M., 1980, THEORY SYNTACTIC REC; Marcus M., 1994, P HUM LANG TECHN WOR, P114, DOI 10.3115/1075812.1075835; Marcus M, 1994, COMPUTATIONAL LINGUI, V19, P313; Marcus Solomon, 1965, Z MATH LOGIK GRUNDLA, V11, P181, DOI 10.1002/malq.19650110212; MARINOV S, 2005, P 4 WORKSH TREEB LIN, P89; Maruyama H., 1990, P 28 ANN M ACL PITTS, P31, DOI 10.3115/981823.981828; Masand B., 1992, P 15 ANN INT ACM SIG, P59, DOI 10.1145/133160.133177; Matthews Peter H., 1981, SYNTAX; McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI 10.3115/1219840.1219852; McDonald R., 2005, P HUM LANG TECHN C C, P523, DOI 10.3115/1220575.1220641; MEGYESI B, 2002, THESIS KTH; Mel'cuk Igor, 1988, DEPENDENCY SYNTAX TH; MELLISH CS, 1989, P 27 ANN M ASS COMP, P102, DOI 10.3115/981623.981636; Menzel W., 1998, P WORKSH PROC DEP BA, P78; MENZEL W, 1995, P 19 ANN GERM C ART, P19; MILWARD D, 1994, LINGUIST PHILOS, V17, P561, DOI 10.1007/BF00985319; Misra VidyaNiwas, 1966, DESCRIPTIVE TECHNIQU; MIYAO Y, 2003, P INT C REC ADV NAT, P285; MOHRI M, 2001, ROBUSTNESS LANGUAGE, P153; MONTAGUE R, 1970, THEORIA, V36, P373; Montague R., 1973, APPROACHES NATURAL L, P221, DOI DOI 10.1007/978-94-010-2506-5_10; MORENO A, 2003, TREEBANKS BUILDING U, P149, DOI 10.4000/terrain.1694; Morrill G., 1994, TYPE LOGICAL GRAMMAR; Morrill G, 2000, COMPUT LINGUIST, V26, P319, DOI 10.1162/089120100561728; NAKAGAWA T, 2002, P 40 ANN M ASS COMP, P497; NASR A, 2004, P WORKSH REC ADV DEP, P25; Nederhof MJ, 2000, COMPUT LINGUIST, V26, P17, DOI 10.1162/089120100561610; NEDERHOF MJ, 1998, P INT WORKSH FIN STA, P13, DOI 10.3115/1611533.1611535; Nelson Gerald, 2002, EXPLORING NATURAL LA; NEY H, 1991, IEEE T SIGNAL PROCES, V39, P336, DOI 10.1109/78.80816; Ng HT, 1996, P 34 ANN M ASS COMP, P40, DOI 10.3115/981863.981869; NIKULA H, 1986, DEPENDENSGRAMMATIK; NILSSON J, 2005, P NODALIDA SPEC SESS; NIVRE J, 2004, P 20 INT C COMP LING, P64, DOI 10.3115/1220355.1220365; Nivre J., 2003, P 8 INT WORKSH PARS, P149; NIVRE J, 2003, P 2 WORKSH TREEB LIN; NIVRE J, 2002, P 1 WORKSH TREEB LIN, P123; NIVRE J, 2004, 04070 VAXJ U SCH MAT; Nivre J., 2004, P 8 C COMP NAT LANG, P49; NIVRE J, 2004, P MEMURA 2004 WORKSH, P39; NIVRE J, HDB CORPUS IN PRESS; NIVRE J, 2005, P PROM IT 2005 STUD, P327; NIVRE J, 2005, P 4 WORKSH TREEB LIN, P137; Nivre Joakim, 2005, P 43 ANN M ASS COMP, P99, DOI 10.3115/1219840.1219853; Nivre Joakim, 2004, P WORKSH INCR PARS B, P50, DOI 10.3115/1613148.1613156; OBREBSKI T, 2003, P 8 INT WORKSH PARS, P217; Oepen S, 1998, COMPUT SPEECH LANG, V12, P411, DOI 10.1006/csla.1998.0105; Oflazer K, 2003, COMPUT LINGUIST, V29, P515, DOI 10.1162/089120103322753338; Oflazer Kemal, 2003, TREEBANKS BUILDING U, P261; PALMER DD, 2000, HDB NATURAL LANGUAGE, P11; Palmer M., 2005, NAT LANG ENG, V11, P207, DOI 10.1017/S135132490400364X; Pereira F. C. N., 1992, P 30 ANN M ASS COMP, P128, DOI 10.3115/981967.981984; Pereira FCN, 1997, LANG SPEECH & COMMUN, P149; Pollard C. J., 1994, HEAD DRIVEN PHRASE S; Pollard C. J., 1987, INFORM BASED SYNTAX; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ramshaw L. A., 1995, P 3 WORKSH VER LARG, P82; Ranta A, 2004, J FUNCT PROGRAM, V14, P145, DOI 10.1017/S0956796803004738; Ratnaparkhi A, 1997, P 2 C EMP METH NAT L, P1; Ratnaparkhi A, 1999, MACH LEARN, V34, P151, DOI 10.1023/A:1007502103375; RESNIK P, 1992, P 14 INT C COMP LING, P418; Riezler S., 2002, P 40 ANN M ASS COMP, P271; RILOFF E, 1994, ACM T INFORM SYST, V12, P296, DOI 10.1145/183422.183428; Robins R. H., 1967, SHORT HIST LINGUISTI; ROBINSON JJ, 1970, LANGUAGE, V46, P259, DOI 10.2307/412278; Roche E, 1997, LANG SPEECH & COMMUN, P241; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Rosenkrantz D.J., 1970, P 11 S SWITCH AUT TH, P139; Sagae K., 2005, P 9 INT WORKSH PARS, P125, DOI 10.3115/1654494.1654507; SAMPSON G, 2003, TREEBANKS BUILDING U, P23; Sampson G., 1995, ENGLISH COMPUTER SUS; SAMUELSSON C, 2000, HDB NATURAL LANGUAGE, P59; SAMUELSSON C, 1991, P 12 INT JOINT C ART; SAMUELSSON C, 2000, P 18 INT C COMP LING; Sang EFTK, 2001, LANG COMPUT, P177; Sapir Edward, 1921, LANGUAGE INTRO STUDY; Scha Remko, 2003, DATA ORIENTED PARSIN; SCHABES Y, 1992, P 14 INT C COMP LING, P426; SCHRODER I, 2002, THESIS HAMBURG U; Sgall Petr, 1986, MEANING SENTENCE ITS; Shieber S. M., 1983, P 21 C ASS COMP LING, P113, DOI 10.3115/981311.981334; SHIEBER SM, 1986, INTRO  UNIFICATION B; SHIEBER SM, 1995, J LOGIC PROGRAM, V24, P3, DOI 10.1016/0743-1066(95)00035-I; SIMAAN K, 1996, RECENT ADV NATURAL L, P35; SIMAAN K, 2003, P 8 INT WORKSH PARS, P183; Sima'an Khalil, 1996, P 17 INT C COMP LING, P1175; Sima'an Khalil, 1999, THESIS U AMSTERDAM; Skousen R., 1989, ANALOGICAL MODELING; Skousen Royal, 1992, ANALOGY STRUCTURE; Sleator D, 1991, CMUCS91196; Sleator D.D., 1993, 3 INT WORKSH PARS TE, P277; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Starosta S., 1988, CASE LEXICASE OUTLIN; Steedman M., 2000, SYNTACTIC PROCESS; STOLCKE A, 1995, COMPUT LINGUIST, V21, P165; STREITER O, 2001, P 15 PAC AS C LANG I, P345; STREITER O, 2001, P 19 INT C COMP PROC, P219; TANG M, 2002, P 40 ANN M ASS COMP, P406; Tapanainen P., 1997, P 5 C APPL NAT LANG, P64, DOI 10.3115/974557.974568; TELEMAN U, 1974, MANUAL GRAMMATISK BE; Tesniere L., 1959, ELEMENTS SYNTAXE STR; Thompson C.A., 1999, P 16 INT C MACH LEAR, P406; THOMSON HS, 1981, P 19 ANN M ASS COMP, P167, DOI 10.3115/981923.981966; Tjong Kim Sang E. F., 1999, P 9 C EUR CHAPT ASS, P173, DOI 10.3115/977035.977059; Tomita M., 1987, Computational Linguistics, V13; Torisawa I?., 2000, NAT LANG ENG, V6, P63, DOI 10.1017/S1351324900002412; TOUTANOVA K, 2002, P 1 WORKSH TREEB LIN, P253; Tzoukerman E., 2003, OXFORD HDB COMPUTATI, P529; ULE T, 2004, P INT C LING EV, P169; Uszkoreit H., 2000, NATURAL LANGUAGE ENG, P81, DOI 10.1017/S1351324900002394; USZKOREIT H, 1986, P COLING 86, P187, DOI 10.3115/991365.991422; van den Bosch A., 1999, P 37 ANN M ASS COMP, P285, DOI 10.3115/1034678.1034726; VANDENBEEK L, 2002, 12 CLIN M ROD, P8; VANDENBOSCH A, 2004, P 8 C COMP NAT LANG, P102; VANDENBOSCH A, 2002, P 40 ANN M ASS COMP, P443; vanNoord G, 1997, COMPUT LINGUIST, V23, P425; Vapnik V.N., 1995, NATURE STAT LEARNING; VEENSTRA J, 2000, ILK0012 TILB U; VEENSTRA J, 1998, P BENELEARN 98 8 BEL, P71; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P1260; VOUTILAINEN A, 2001, 13 NORD C COMP LING; WANG W, 2004, P WORKSH INCR PARS B, P29; WEIJTERS AJM, 1991, P INT C ART NEUR NET, P1645; WETTSCHERECK D, 1994, THESIS OREGON STATE; WHITE AP, 1994, MACH LEARN, V15, P321, DOI 10.1023/A:1022694010754; Wu TF, 2004, J MACH LEARN RES, V5, P975; Xia F., 2001, THESIS U PENNSYLVANI; XIA F, 2001, P HLT 2001 1 INT C H; Yamada H., 2003, P 8 INT WORKSH PARS, P195; Yamada K., 2001, P 39 ANN M ASS COMP, P523, DOI 10.3115/1073012.1073079; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; YLIJYRA A, 2003, P 2 WORKSH TREEB LIN, P189; YOUNGER DH, 1967, INFORM CONTROL, V10, P189, DOI 10.1016/S0019-9958(67)80007-X; Yuret D., 1998, THESIS MIT; ZAVREL J, 1997, P WORKSH COMP NAT LA, P136; Zavrel J, 1997, P 35 ANN M ASS COMP, P436; ZEEVAT H, 1991, LINGUA STILE, V26, P499; ZWICKY AM, 1985, J LINGUIST, V21, P1, DOI 10.1017/S0022226700010008	396	0	0	SPRINGER	DORDRECHT	PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	1386-291X	978-1-4020-4889-0	TEXT SPEECH LANG TEC			2006	34						1	216		10.1007/1-4020-4889-0		216	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Computer Science; Linguistics	BLN70	WOS:000270597300008	
S	Garcia, S; Cano, JR; Herrera, F		Corchado, E; Yin, H; Botti, V; Fyfe, C		Garcia, Salvador; Ramon Cano, Jose; Herrera, Francisco			Incorporating knowledge in evolutionary prototype selection	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2006, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	7th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2006)	SEP 20-23, 2006	Burgos, SPAIN		Univ Burgos		NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; INSTANCE SELECTION; REDUCTION	Evolutionary algorithms has been recently used for prototype selection showing good results. An important problem in prototype selection consist in increasing the size of data sets. This problem can be harmful in evolutionary algorithms by deteriorating the convergence and increasing the time complexity. In this paper, we offer a preliminary proposal to solve these drawbacks. We propose an evolutionary algorithm that incorporates knowledge about the prototype selection problem. This study includes a comparison between our proposal and other evolutionary and non-evolutionary prototype selection algorithms. The results show that incorporating knowledge improves the performance of evolutionary algorithms and considerably reduces time execution.	Univ Granada, Dept Comp Sci & Artificial Intelligence, ETSI Informat, E-18071 Granada, Spain; Univ Jaen, Dept Comp Sci, Jaen 23700, Spain	Garcia, S (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, ETSI Informat, E-18071 Granada, Spain.	salvagl@decsai.ugr.es; jrcano@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008	Herrera, Francisco/0000-0002-7283-312X			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Baluja S., 1994, POPULATION BASED INC; Cano JR, 2005, PATTERN RECOGN LETT, V26, P953, DOI 10.1016/j.patrec.2004.09.043; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Eshelman L.J., 1990, FDN GENETIC ALGORITH, P265; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GROCHOWSKI M, 2004, ICAISC, P580; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ishibuchi H, 1999, LECT NOTES ARTIF INT, V1585, P82; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Newman D. J., 1998, UCI REPOSITORY MACHI; Sheskin D. J., 1997, HDB PARAMETRIC NONPA; Skalak D.B., 1994, INT C MACH LEARN, P293; WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-45485-3	LECT NOTES COMPUT SC			2006	4224						1358	1366				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG81	WOS:000241790900161	
B	Pateritsas, C; Stafylopatis, A		Mohammadian, M		Pateritsas, Christos; Stafylopatis, Andreas			Independent nearest features memory-based classifier	International Conference on Computational Intelligence for Modelling, Control & Automation Jointly with International Conference on Intelligent Agents, Web Technologies & Internet Commerce, Vol 2, Proceedings			English	Proceedings Paper	International Conference on Computational Intelligence for Modelling, Control and Automation/International Conference on Intelligent Agents Web Technologies and International Commerce	NOV 28-30, 2005	Vienna, AUSTRIA	IEEE Computat Intelligence Soc, European Soc Fuzzy Log & Technol, European Neural Network Soc, Int Assoc Fuzzy Set Management & Econ, Japan Soc Fuzzy Theory & Intelligent Informat, Taiwan Fuzzy Syst Assoc, World Wide Web Business Intelligence, Hungarian Fuzzy Assoc, Univ Canberra			LEARNING ALGORITHMS; NEIGHBOR	The classification task is one of the most important problems in the area of data mining. In this paper we propose a new algorithm for addressing this problem. The main idea derives from the well-known algorithm of k-nearest-neighbors. In the proposed approach, given an unclassified pattern, a set of neighboring patterns is found, but not necessarily using all input feature dimensions. Also, following the concept of the naive Bayesian classifier, independence of input feature dimensions in the outcome of the classification task is assumed. The two concepts are merged in an attempt to take advantage of their good performance features. Experimental results have shown superior performance of the proposed method in comparison with the aforementioned algorithms and their variations.	Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece	Pateritsas, C (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Iroon Polytexneiou 9, Athens 15780, Greece.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Akkus A., 1996, P 13 INT C MACH LEAR, P12; Blake CL, 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DEMIROZ G, 1997, LECT NOTES COMPUTER; FAN H, 2003, P 14 AUSTR DAT C AD; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; GUVENIR HA, 1997, P 12 INT S COMP INF; KONONENKO I, 1992, INFORMATICA, V16, P1; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; SIRIN I, 1993, CIS9301 BILK U DEP C; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WETTSCHERECK D, 1995, 1 INT C CAS BAS REAS, P347; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YANG Y, 2001, LECT NOTES COMPUTER, P564	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7695-2504-0				2006							781	786				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BEW91	WOS:000239915100129	
B	Alizon, F; Shooter, SB; Simpson, TW		Zhang, D; Khoshgoftaar, TM; Joshi, BD		Alizon, Fabrice; Shooter, Steven B.; Simpson, Timothy W.			Provide relevant knowledge to specify product design project needs	IRI 2006: Proceedings of the 2006 IEEE International Conference on Information Reuse and Integration			English	Proceedings Paper	IEEE International Conference on Information Reuse and Intergration (IRI 2006)	SEP 16-18, 2006	Waikoloa, HI	IEEE			ADVANTAGE	In many of today's industry, knowledge is considered a strategic tool; however, knowledge is involved in so many services with so many facets that it is very complex to effectively manage for competitive advantage. In design, knowledge is recognized as important to improve the decision-making process and the commensurability of the designers' interpretative framework, but how can relevant knowledge be identified among all the knowledge within a company? This study focuses on the early stage of project development when it is important to have a clear understanding of what is known and not known in the company to correctly specify projects (e.g., teams, costs, lead-time, etc.). A method is proposed in this paper to identify knowledge, where it is, and its level of reusability. This method filters a repository to identify and extract relevant knowledge and define its level of reusability. A case study based on a new single-use camera and a repository of 18 single-use cameras is performed to highlight and validate the proposed method.	Bucknell Univ, Lewisburg, PA 17837 USA	Shooter, SB (reprint author), Bucknell Univ, Lewisburg, PA 17837 USA.						ALIZON F, 2006, J COMPUTING INFORM S, V6; ALIZON F, 2002, INT FLEX AUT INT MAN, V1, P134; BARNEY J, 1991, J MANAGE, V17, P99, DOI 10.1177/014920639101700108; BONTIS, 2000, MANAGING ORG KNOWLED; COLLIS D, 1995, HARVARD BUSINESS JUL, P127; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; McEvily SK, 2002, STRATEGIC MANAGE J, V23, P285, DOI 10.1002/smj.223; Polanyi M, 1966, TACIT DIMENSION; Prusak L., 1998, WORKING KNOWLEDGE; Sivaloganathan S, 1999, P I MECH ENG B-J ENG, V213, P641, DOI 10.1243/0954405991517092; Stone RB, 2000, J MECH DESIGN, V122, P359, DOI 10.1115/1.1289637; Thevenot HJ, 2006, J ENG DESIGN, V17, P99, DOI 10.1080/09544820500275693; TROUSSE B, 1993, ADVANCED TECHNOLOGIES, P451; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-9788-6				2006							460	465				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFI82	WOS:000242108800081	
B	Popova, V		Chen, Y; Abraham, A		Popova, Viara			Missing values in monotone data sets	ISDA 2006: Sixth International Conference on Intelligent Systems Design and Applications, Vol 1			English	Proceedings Paper	6th International Conference on Intelligent Systems Design and Applications (ISDA 2006)	OCT 16-18, 2006	Jinan, PEOPLES R CHINA	IEEE Syst Man & Cybernet Soc	Jinan Univ		ROUGH SETS; CLASSIFICATION	This paper explores the problem of missing values in the context of monotone classification. A simple preprocessing method is proposed as an extension of three general approaches for filling in the unknown values (k-nearest neighbour most frequent value and data point multiplication) so that the monotonicity property of the resulting data set is preserved. The results of the first experiments with the algorithms are reported in order to give more insight in how the method works in practice.	Vrije Univ Amsterdam, Dept Artificial Intelligence, NL-1081 HV Amsterdam, Netherlands	Popova, V (reprint author), Vrije Univ Amsterdam, Dept Artificial Intelligence, Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.						Ben-David A., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00314.x; BENDAVID A, 1995, MACH LEARN, V19, P29, DOI 10.1023/A:1022655006810; Bioch JC, 1998, ANN MATH ARTIF INTEL, V24, P69, DOI 10.1023/A:1018993014297; BIOCH JC, 2002, ERS200234LIS ER RES; Bioch J.C., 2002, P 14 BELG DUTCH C AR, P19; Bioch J.C., 2002, P 12 BELG DUTCH C MA, P3; Blake CL, 1998, UCI REPOSITORY MACHI; Bioch JC, 2000, LECT NOTES ARTIF INT, V1968, P291; Bohanec M., 1990, SISTEMICA, V1, P145; BOROS E, 1997, MATH PROGRAM, V79, P165; Boros E, 2000, IEEE T KNOWL DATA EN, V12, P292, DOI 10.1109/69.842268; CAOVAN K, 2002, UNPUB INT J INTELLIG; CLARK AJL, 1989, J MOL ENDOCRINOL, V2, P3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daniels H, 1999, NEURAL COMPUT APPL, V8, P226, DOI 10.1007/s005210050025; DANIELS HAM, 2003, 200330 TILB U; Greco S., 1998, OPERATIONAL TOOLS MA, P121; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; GRZIMALABUSSE JW, 1991, LECT NOTES ARTIF INT, V542, P368; Grzymala-Busse J. W., 2000, P 2 INT C ROUGH SETS, P340; Kononenko I., 1984, EXPT AUTOMATIC LEARN; Liu WZ, 1997, LECT NOTES COMPUT SC, V1280, P527; MAKINO K, 1996, P INT S COOP DAT SYS, P282; Olave M., 1989, EXPERT SYSTEMS PUBLI, P145; POPVOA V, 2005, LECT NOTES ARTIF INT, V3735, P203; POTHARST R, 2002, SIGKDD EXPLORATIONS, V4, P1; POTHARST R, 2000, INTELLIGENT DATA ANA, V4, P1; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; WANG S, 1994, NEURAL COMPUT APPL, V2, P160, DOI 10.1007/BF01415012	29	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2528-8				2006							627	632				6	Computer Science, Artificial Intelligence	Computer Science	BFK66	WOS:000242507000115	
J	Davidov, D; Markovitch, S				Davidov, Dmitry; Markovitch, Shaul			Multiple-goal heuristic search	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							ADMISSIBLE HEURISTICS; DISCOVERY; WEB	This paper presents a new framework for anytime heuristic search where the task is to achieve as many goals as possible within the allocated resources. We show the inadequacy of traditional distance-estimation heuristics for tasks of this type and present alternative heuristics that are more appropriate for multiple-goal search. In particular, we introduce the marginal-utility heuristic, which estimates the cost and the benefit of exploring a subtree below a search node. We developed two methods for online learning of the marginal-utility heuristic. One is based on local similarity of the partial marginal utility of sibling nodes, and the other generalizes marginal-utility over the state feature space. We apply our adaptive and non-adaptive multiple-goal search algorithms to several problems, including focused crawling, and show their superiority over existing methods.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Davidov, D (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	DMITRY@CS.TECHNION.AC.IL; SHAULM@CS.TECHNION.AC.IL					BODDY M, 1994, ARTIF INTELL, V67, P245, DOI 10.1016/0004-3702(94)90054-X; BORODIN A, 2001, 10 INT WORLD WID WEB, P415; BOYAN J, 1996, P AAAI WORKSH INT BA, P324; Breiman L, 1984, CLASSIFICATION REGRE; BRIN S., 1998, COMPUTER NETWORKS IS, V30, p[1, 107]; Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3; Cho J, 1998, COMPUT NETWORKS ISDN, V30, P161, DOI 10.1016/S0169-7552(98)00108-1; Cho Junghoo, 2000, VLDB 2000, P200; COOPER C, 2002, P 34 ANN ACM S THEOR, P419; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Culberson JC, 1998, COMPUT INTELL, V14, P318, DOI 10.1111/0824-7935.00065; Diligenti M., 2000, 26 INT C VER LARG DA, P527; DOUGLIS F, 1997, USENIX S INT TECHN S, P147; GASSER RU, 1995, THESIS SWISS FEDERAL; Hansen EA, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1229; Haveliwala T., 1999, EFFICIENT COMPUTATIO; HELD M, 1970, OPER RES, V18, P1138, DOI 10.1287/opre.18.6.1138; Hirai J., 2000, P 9 INT WORLD WID WE, P277; HOVITZ E, 1990, THESIS STANFORD U; Joachims T, 1997, P 14 INT C MACH LEAR, P143; KLEINBERG J. M., 1999, JACM, V46, P5; KORF RE, 2000, NAT C ART INT AAAI, P910; Korf RE, 2002, ARTIF INTELL, V134, P9, DOI 10.1016/S0004-3702(01)00092-3; Kumar R, 2000, P 19 ACM SIGMOD SIGA, P1, DOI 10.1145/335168.335170; Lawrence S, 1998, SCIENCE, V280, P98, DOI 10.1126/science.280.5360.98; MCCALLUM A, 1999, P AAAI SPRING S INT, P28; Menczer F., 2001, P 24 ANN INT ACM SIG, P241, DOI DOI 10.1145/383952.383995; Montgomery D. C., 2001, DESIGN ANAL EXPT; MOSTOW J, 1989, P IJCAI 89, V1, P701; NAJORK M, 1998, P 7 INT WWW C WWW7, P379; Najork M, 2001, P 10 INT WORLD WID W, P114, DOI DOI 10.1145/371920.371965; PAGE L, 1998, PAGERANK CITATION RI; PANDURANGAN G, 2002, 8 ANN INT COMP COMB, P330; PEARL J, 1982, IEEE T PATTERN ANAL, V4, P392; PRIEDITIS AE, 1993, MACH LEARN, V12, P117, DOI 10.1007/BF00993063; Rennie J, 1999, P 16 INT C MACH LEAR, P335; Russell S., 2003, ARTIFICIAL INTELLIGE; RUSSELL SJ, 1991, P IJCAI 91, P213; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schroedl S, 2005, J ARTIF INTELL RES, V23, P587; UTGOFF P, 1988, 5TH P INT C MACH LEA, P107; Yoshizumi T., 2000, AAAI IAAI, P923; ZHOU R, 2002, P 18 NAT C ART INT A, P975; Zhou R, 2003, PROC INT C TOOLS ART, P427; Zilberstein S, 1996, AI MAG, V17, P73; Zilberstein S, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1008	46	2	2	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757		J ARTIF INTELL RES	J. Artif. Intell. Res.		2006	26						417	451				35	Computer Science, Artificial Intelligence	Computer Science	077JG	WOS:000240024500002	
J	Dutta, D; Guha, R; Jurs, PC; Chen, T				Dutta, D; Guha, R; Jurs, PC; Chen, T			Scalable partitioning and exploration of chemical spaces using geometric hashing	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Proceedings Paper	4th Indo-US Workshop on Mathematical Chemistry	JAN 08-12, 2005	Pune, INDIA				MOLECULAR CONNECTIVITY; SHAPE INDEX; PREDICTION; VALIDATION; LIBRARIES; DIVERSITY; GRAPHS	Virtual screening (VS) has become a preferred tool to augment high-throughput screening(1) and determine new leads in the drug discovery process. The core of a VS informatics pipeline includes several data mining algorithms that work on huge databases of chemical compounds containing millions of molecular structures and their associated data. Thus, scaling traditional applications such as classification, partitioning, and outlier detection for huge chemical data sets without a significant loss in accuracy is very important. In this paper, we introduce a data mining framework built on top of a recently developed fast approximate nearest-neighbor-finding algorithm(2) called locality-sensitive hashing (LSH) that can be used to mine huge chemical spaces in a scalable fashion using very modest computational resources. The core LSH algorithm hashes chemical descriptors so that points close to each other in the descriptor space are also close to each other in the hashed space. Using this data structure, one can perform approximate nearest-neighbor searches very quickly, in sublinear time. We validate the accuracy and performance of our framework on three real data sets of sizes ranging from 4337 to 249 071 molecules. Results indicate that the identification of nearest neighbors using the LSH algorithm is at least 2 orders of magnitude faster than the traditional k-nearest-neighbor method and is over 94% accurate for most query parameters. Furthermore, when viewed as a data-partitioning procedure, the LSH algorithm lends itself to easy parallelization of nearest-neighbor classification or regression. We also apply our framework to detect outlying (diverse) compounds in a given chemical space this algorithm is extremely rapid in determining whether a compound is located in a sparse region of chemical space or not, and it is quite accurate when compared to results obtained using principal-component-analysis-based heuristics.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA; Univ So Calif, Dept Computat Biol, Los Angeles, CA 90089 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, University Pk, PA 16802 USA.	pcj@psu.edu					Agrafiotis DK, 2001, J CHEM INF COMP SCI, V41, P159, DOI 10.1021/ci000091j; AMES BN, 1975, MUTAT RES, V31, P347, DOI 10.1016/0165-1161(75)90046-1; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DATAR M, 2004, SCG 04; DUDA RO, 1998, PATTERN CLASSIFICATI; Ertl P, 2000, J MED CHEM, V43, P3714, DOI 10.1021/jm000942e; GAREY RM, 1979, COMPUTERS INTRACTIBI; GASTEIGER J, 1980, TETRAHEDRON, V36, P3219, DOI 10.1016/0040-4020(80)80168-2; Gasteiger J., 2003, CHEMOINFORMATICS TXB; Gasteiger J., 1978, TETRAHEDRON LETT, V19, P3181; GIONIS A, 1999, VLDB 99; Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387; HASTIE T, 2001, INTRO STAT MACHINE L; Jorgensen WL, 2004, SCIENCE, V303, P1813, DOI 10.1126/science.1096361; Kazius J, 2005, J MED CHEM, V48, P312, DOI 10.1021/jm040835a; KIER LB, 1975, J PHARM SCI, V64, P1971, DOI 10.1002/jps.2600641214; Kier L.B., 1986, MOL CONNECTIVITY STR; Kier LB, 1976, MOL CONNECTIVITY CHE; KIER LB, 1976, J PHARM SCI, V65, P1806, DOI 10.1002/jps.2600651228; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P7, DOI 10.1002/qsar.19860050103; KIER LB, 1985, QUANT STRUCT-ACT REL, V4, P109, DOI 10.1002/qsar.19850040303; PEARLMAN R, 1998, PERSPECT DRUG DISCOV, P339; Pearlman RS, 1999, J CHEM INF COMP SCI, V39, P28, DOI 10.1021/ci980137x; Schnur D, 1999, J CHEM INF COMP SCI, V39, P36, DOI 10.1021/ci980138p; Stahura FL, 2004, COMB CHEM HIGH T SCR, V7, P259; Voigt JH, 2001, J CHEM INF COMP SCI, V41, P702, DOI 10.1021/ci000150t; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; Xu HF, 2003, J CHEM INF COMP SCI, V43, P1933, DOI 10.1021/ci034150f; *CHEM COMP GROUP I, MOL OP ENV; *MDL INF SYST INC, MACCS FING	32	12	15	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	JAN-FEB	2006	46	1					321	333		10.1021/ci050403o		13	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	008DU	WOS:000235021200036	
S	Pham, TD; Ran, DT		Gabrys, B; Howlett, RJ; Jain, LC		Pham, Tuan D.; Ran, Dat T.			Image classification by fusion for high-content cell-cycle screening	KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	10th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems	OCT 09-11, 2006	Bournemouth, ENGLAND					We present a fuzzy fusion approach for combining cell-phase identification results obtained from multiple classifiers. This approach can improve the classification rates and allows the task of high-content cell-cycle screening more effective for biomedical research in the study of structures and functions of cells and molecules. Conventionally such study requires the processing and analysis of huge amounts of image data, and manual image analysis is very time consuming, thus costly, and also potentially inaccurate and poorly reproducible. The proposed method has been used to combine the results from three classifiers, and the combined result is superior to any of the results obtained from a single classifier.	James Cook Univ N Queensland, Bioinformat Applicat Res Ctr, Townsville, Qld 4811, Australia; James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4811, Australia; Univ Canberra, Sch Informat Sci & Engn, Canberra, ACT 2601, Australia	Pham, TD (reprint author), James Cook Univ N Queensland, Bioinformat Applicat Res Ctr, Townsville, Qld 4811, Australia.	tuan.pham@jcu.edu.au; dat.tran@canberra.edu.au					Bezdek J., 1981, PATTERN RECOGNITION; CHEN X, IN PRESS IEEE T BIOM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNKLE R, 2003, DRUG DISCOVERY WORLD, V5, P75; FENG Y, 2002, EUROPEAN PHARM REV, V7, P7; FOX S, 2003, DRUG DISCOVERY WORLD, V5, P21; Hiraoka Y, 1996, CHROMOSOME RES, V4, P173, DOI 10.1007/BF02254954; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; PHAM TD, 2005, P AI 2005 WORKSH LEA, P52; PHAM TD, 2006, NEURAL STEM CELL RES; Pham T. D., 2002, Proceedings 2002 IEEE International Conference on Artificial Intelligence Systems (ICAIS 2002), DOI 10.1109/ICAIS.2002.1048051; SUGEO M, 1974, THESIS TOKYO I TECHN; Tran D., 2000, P FUZZ IEEE C MAY US, V1, P152; Yarrow JC, 2003, COMB CHEM HIGH T SCR, V6, P279	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-46535-9	LECT NOTES ARTIF INT			2006	4251						524	531				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BFI87	WOS:000242122000064	
J	Sobanski, T; Modrak, I; Nitsch, K; Licznerski, BW				Sobanski, T; Modrak, I; Nitsch, K; Licznerski, BW			Application of sensor dynamic response analysis to improve the accuracy of odour-measuring systems	MEASUREMENT SCIENCE & TECHNOLOGY			English	Article; Proceedings Paper	8th Optoelectronic and Electronic Sensors Conference	JUN 27-30, 2004	Wroclaw, POLAND			sensors response analysis; odour-measuring systems; odour classification	ELECTRONIC NOSE; GAS SENSORS	A system consisting of a matrix of three semiconductor gas sensors was applied to the classification of different orange juices. The sensor matrix responses were sampled in short time intervals. Such responses were processed by discrete wavelet transform (DWT) together with the k-nearest neighbour (kNN) classification algorithm or by the probabilistic neural network (PNN). The obtained results show that both types of signal processing (DWT + kNN and PNN) applied provide very good class separation for time response analysis, while in the case of the static response analysis the correct classification coefficients are much lower. It is shown that the analysis of the sensor's time response can be an efficient way of increasing both the accuracy level and the immunity to external noise in e-nose systems. The possibility of reducing the number of sensors without decreasing the system performance is also demonstrated. Additional experiments have shown that for both processing methods, the results obtained with the dynamic response of a single sensor were better than those reached with the three-sensor array measured in static conditions.	Commiss European Communities, Joint Res Ctr, Inst Hlth & Consumer Protect, I-21020 Ispra, VA, Italy; Wroclaw Tech Univ, Fac Microsyst Elect & Photon, PL-50370 Wroclaw, Poland	Sobanski, T (reprint author), Commiss European Communities, Joint Res Ctr, Inst Hlth & Consumer Protect, I-21020 Ispra, VA, Italy.	tomasz.sobanski@jrc.it					Chimenti M, 2003, MEAS SCI TECHNOL, V14, P815, DOI 10.1088/0957-0233/14/6/315; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; Dutta R, 2003, MEAS SCI TECHNOL, V14, P190, DOI 10.1088/0957-0233/14/2/306; Ionescu R, 2002, SENSOR ACTUAT B-CHEM, V81, P289, DOI 10.1016/S0925-4005(01)00968-6; Ionescu R, 2005, SENSOR ACTUAT B-CHEM, V104, P132, DOI 10.1016/j.snb.2004.05.015; LICZNERSKI BW, 2000, MAT 6 K NAUK CZUJN O, P7; Licznerski BW, 1999, SENSOR ACTUAT B-CHEM, V57, P192, DOI 10.1016/S0925-4005(99)00156-2; Llobet E, 1999, MEAS SCI TECHNOL, V10, P538, DOI 10.1088/0957-0233/10/6/320; MISTI M, 2004, WAVELET TOOLBOX USER; NITSCH K, 2003, P 26 INT SPRING SEM, P389; SOBANSKI T, 2003, P 26 ISSE, P394; Szczurek A, 1999, SENSOR ACTUAT B-CHEM, V58, P427, DOI 10.1016/S0925-4005(99)00105-7; Wasserman P. D., 1993, ADV METHODS NEURAL C, P35; WEIMAR U, 1995, SENSOR ACTUAT B-CHEM, V26, P13, DOI 10.1016/0925-4005(94)01547-U; Weimar U, 1998, SENSOR ACTUAT B-CHEM, V52, P143, DOI 10.1016/S0925-4005(98)00268-8	16	2	2	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0957-0233		MEAS SCI TECHNOL	Meas. Sci. Technol.	JAN	2006	17	1					1	5		10.1088/0957-0233/17/1/001		5	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	007FI	WOS:000234953600002	
J	Ciosek, P; Sobanski, T; Augustyniak, E; Wroblewski, W				Ciosek, P; Sobanski, T; Augustyniak, E; Wroblewski, W			ISE-based sensor array system for classification of foodstuffs	MEASUREMENT SCIENCE & TECHNOLOGY			English	Article; Proceedings Paper	8th Optoelectronic and Electronic Sensors Conference	JUN 27-30, 2004	Wroclaw, POLAND			sensor array; electronic tongue; ion-selective electrodes	PATTERN-RECOGNITION; ELECTRONIC NOSE; BEVERAGES	A system composed of an array of polymeric membrane ion-selective electrodes and a pattern recognition block-a so-called 'electronic tongue'-was used for the classification of liquid samples: milk, fruit juice and tonic. The task of this system was to automatically recognize a brand of the product. To analyze the measurement set-up responses various non-parametric classifiers such as k-nearest neighbours, a feedforward neural network and a probabilistic neural network were used. In order to enhance the classification ability of the system, standard model solutions of salts were measured (in order to take into account any variation in time of the working parameters of the sensors). This system was capable of recognizing the brand of the products with accuracy ranging from 68% to 100% (in the case of the best classifier).	Warsaw Univ Technol, Fac Chem, Warsaw, Poland; Commiss European Communities, Joint Res Ctr, Inst Hlth & Consumer Protect, I-21020 Ispra, VA, Italy; Wroclaw Tech Univ, Dept Elect Microsyst & Photon, PL-50370 Wroclaw, Poland	Ciosek, P (reprint author), Warsaw Univ Technol, Fac Chem, Naokowskiego 3, Warsaw, Poland.	tomasz.sobanski@jrc.it					Chimenti M, 2003, MEAS SCI TECHNOL, V14, P815, DOI 10.1088/0957-0233/14/6/315; Ciosek P, 2004, SENSOR ACTUAT B-CHEM, V103, P76, DOI 10.1016/j.snb.2004.04.038; Ciosek P, 2004, ANALYST, V129, P639, DOI 10.1039/b401390e; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dutta R, 2003, MEAS SCI TECHNOL, V14, P190, DOI 10.1088/0957-0233/14/2/306; He HQ, 2003, MEAS SCI TECHNOL, V14, P1040; Massart D.L., 1988, CHEMOMETRICS TXB; Schaller Emmanuelle, 1998, Lebensmittel-Wissenschaft and Technologie, V31, P305, DOI 10.1006/fstl.1998.0376; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; Wasserman P. D., 1993, ADV METHODS NEURAL C, P35; Wojciechowski K, 2002, CHEM ANAL-WARSAW, V47, P335; Yu XH, 1997, NEURAL NETWORKS, V10, P517, DOI 10.1016/S0893-6080(96)00102-5	12	17	18	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0957-0233		MEAS SCI TECHNOL	Meas. Sci. Technol.	JAN	2006	17	1					6	11		10.1088/0957-0233/17/1/002		6	Engineering, Multidisciplinary; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	007FI	WOS:000234953600003	
S	Raicharoen, T; Lursinsap, C; Lin, F		King, I; Wang, J; Chan, L; Wang, DL		Raicharoen, Thanapant; Lursinsap, Chidchanok; Lin, Frank			A divide-and-conquer approach to the Pairwise Opposite Class-Nearest Neighbor (POC-NN) algorithm for regression problem	NEURAL INFORMATION PROCESSING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	13th International Conference on Neural Informational Processing	OCT 03-06, 2006	Hong Kong, PEOPLES R CHINA	Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, K C Wong Educ Fdn				This paper presents a method for regression problem based on divide-and-conquer approach to the selection of a set of prototypes from the training set for the nearest neighbor rule. This method aims at detecting and eliminating redundancies in a given data set while preserving the significant data. A reduced prototype set contains Pairwise Opposite Class-Nearest Neighbor (POC-NN) prototypes which are used instead of the whole given data. Before finding POC-NN prototypes, all sampling data have to be separated into two classes by using the criteria through odd and even sampling number of data, then POC-NN prototypes are obtained by iterative separation and analysis of the training data into two regions until each region is correctly grouped and classified. The separability is determined by the POC-NN prototypes essential to define the function approximator for local sampling data locating near these POC-NN prototypes. Experiments and results reported showed the effectiveness of this technique and its performance in both accuracy and prototype rate to those obtained by classical nearest neighbor techniques.	Chulalongkorn Univ, AVIC, Dept Math, Fac Sci, Bangkok 10330, Thailand; Univ Maryland Eastern Shore, Dept Math & Comp Sci, Kiah Hall Princess Anne, MD 21853 USA	Raicharoen, T (reprint author), Chulalongkorn Univ, AVIC, Dept Math, Fac Sci, Bangkok 10330, Thailand.	thanapantr@oit.rtaf.mi.th; lchidcha@chula.ac.th; linibm@attglobal.net					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dierckx P., 1993, MONOGRAPHS NUMERICAL; HART P, 1966, SEL66016 STANF EL LA, P1828; Hastie T, 2001, ELEMENTS STAT LEARNI; LORENZ E, 1963, ATMOS SCI, V26, P639; MACKEY MC, 1997, SCIENCE, P197; MITCHELL T, 1994, MACHINE LEARNING; RAICHAROEN T, 2005, PATTERN RECOGN, V35, P505; Sparrow C., 1982, LORENZ EQUATIONS; WAN E, 1997, INT C NEUR NETW; Yule GU, 1927, PHILOS T R SOC LOND, V226, P267, DOI 10.1098/rsta.1927.0007	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-46479-4	LECT NOTES COMPUT SC			2006	4232						765	772				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BFG80	WOS:000241790100085	
J	Dounias, G; Bjerregaard, B; Jantzen, J; Tsakonas, A; Ampazis, N; Panagi, G; Panourgias, E				Dounias, G; Bjerregaard, B; Jantzen, J; Tsakonas, A; Ampazis, N; Panagi, G; Panourgias, E			Automated identification of cancerous smears using various competitive intelligent techniques	ONCOLOGY REPORTS			English	Article						computer assisted pap-smear diagnosis; computational intelligence; clustering; feature selection; ANFIS; neuro-fuzzy systems; inductive machine learning; second order neural networks; nearest neighbor classification; genetic programming	TRAINING FEEDFORWARD NETWORKS; CLASSIFICATION; ALGORITHMS	In this study the performance of various intelligent methodologies is compared in the task of pap-smear diagnosis. The selected intelligent methodologies are briefly described and explained, and then, the acquired results are presented and discussed for their comprehensibility and usefulness to medical staff, either for fault diagnosis tasks, or for the construction of automated computer-assisted classification of smears. The intelligent methodologies used for the construction of pap-smear classifiers, are different clustering approaches, feature selection, neuro-fuzzy systems, inductive machine learning, genetic programming, and second order neural networks. Acquired results reveal the power of most intelligent techniques to obtain high quality solutions in this difficult problem of medical diagnosis. Some of the methods obtain almost perfect diagnostic accuracy in test data, but the outcome lacks comprehensibility. On the other hand, results scoring high in terms of comprehensibility are acquired from some methods, but with the drawback of achieving lower diagnostic accuracy. The experimental data used in this study were collected at a previous stage, for the purpose of combining intelligent diagnostic methodologies with other existing, computer imaging technologies towards the construction of an automated smear cell classification device.	Univ Aegean, Dept Financial & Management Engn, Chios 82100, Greece; Herlev Univ Hosp, DK-2730 Herlev, Denmark; Tech Univ Denmark, Oersted DTU Automat, DK-2800 Lyngby, Denmark; Aristotle Univ Salonika, Dept Informat, Artificial Intelligence & Informat Anal Lab, Thessaloniki 54124, Greece; Euroclin Hosp, Dept Radiol, Athens 11521, Greece; Gen Hosp Chios Skilits, Dept Radiol, Chios, Greece	Dounias, G (reprint author), Univ Aegean, Dept Financial & Management Engn, 31 Fostini Str, Chios 82100, Greece.	g.dounias@aegean.gr	Tsakonas, Athanasios/A-3646-2008				Ampazis N, 2002, IEEE T NEURAL NETWOR, V13, P1064, DOI 10.1109/TNN.2002.1031939; Ampazis N, 2004, LECT NOTES COMPUT SC, V3025, P230; ANGELINE PJ, 1996, ADV GENETIC PROGRAMM; Bezdek J., 1981, PATTERN RECOGNITION; BYRIEL J, 1999, THESIS TU DENMARK; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697; Hoppner F., 1999, FUZZY CLUSTER ANAL; Hunt EB, 1966, EXPT INDUCTION; Jain A., 1988, ALGORITHMS CLUSTERIN; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; JANTZEN J, 1998, 98H874 TU DNEM; Kessel W.C., 1979, FUZZY CLUSTERING FUZ, P761; KOSS L, 2000, ARTIFICIAL NEURAL NE, P51; Koza J. R., 1994, GENETIC PROGRAMMING; Koza J. R., 1992, GENETIC PROGRAMMING; Liu H., 1998, KLUWER INT SERIES EN; MARTIN E, 2003, THESIS TU DENMARK; MEISELS A, 1997, CYTOPATHOLOGY UTERUS; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SCHAPIRE R, 1990, MACH LEARN, V2, P197; TSAKONAS A, 2003, ARTIF INTELL MED, V32, P195	24	5	5	PROFESSOR D A SPANDIDOS	ATHENS	1, S MERKOURI ST, EDITORIAL OFFICE,, ATHENS 116 35, GREECE	1021-335X		ONCOL REP	Oncol. Rep.		2006	15				SI		1001	1006				6	Oncology	Oncology	022OS	WOS:000236066000005	
S	Mignani, AG; Ciaccheri, L		Culshaw, B; Mignani, AG; Bartelt, H; Jaroszewicz, LR		Mignani, A. G.; Ciaccheri, L.			Belgian beer mapping and digital fingerprinting using color and turbidity assessment - art. no. 61892E	Optical Sensing II	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Optical Sensing II	APR 03-06, 2006	Strasbourg, FRANCE	SPIE Europe, Conseil Gen Bas Rhin, Communaute Urbaine Strasbourg, Reg Alsace, Alsace Dev Agcy		absorption spectroscopy; color; turbidity; beer	CLASSIFICATION	Multi-wavelength and multi-angle absorption spectroscopy performed in the visible spectral range, that is, 'scattered colorimetry', has been used to map a library of 25 diverse and commercially-available Belgian light beers. The resulting map shows four main clusters, relative to blonde, amber, red, and weiss beers, respectively, demonstrating that scattered colorimetry is a valid method for beer authentication and fingerprinting.	CNR IFAC, Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR IFAC, Via Madonna Piano 10, Sesto Fiorentino, FI, Italy.						ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUBULLE B, 2005, GUIDE BELGIAN BEERS; HUI YH, 1991, DATA SOURCEBOOK FOOD; Jackson M., 2001, GREAT BEERS BELGIUM; Mignani AG, 2005, P SOC PHOTO-OPT INS, V5855, P38, DOI 10.1117/12.623388; Mignani AG, 2005, SENSOR ACTUAT B-CHEM, V111, P363, DOI 10.1016/j.snb.2005.03.023; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; WEBB T, 2005, GOOD BEER GUIDE BELG	10	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-6245-4	P SOC PHOTO-OPT INS			2006	6189						E1892	E1892	61892E	10.1117/12.666908		4	Instruments & Instrumentation; Optics	Instruments & Instrumentation; Optics	BER03	WOS:000238999700074	
S	Srisawat, A; Phienthrakul, T; Kijsirikul, B		Yang, Q; Webb, G		Srisawat, Anantaporn; Phienthrakul, Tanasanee; Kijsirikul, Boonserm			SV-kNNC: An algorithm for improving the efficiency of k-nearest neighbor	PRICAI 2006: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	9th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2006)	AUG 07-11, 2006	Guilin, PEOPLES R CHINA					This paper proposes SV-kNNC, a new algorithm for k-Nearest Neighbor (kNN). This algorithm consists of three steps. First, Support Vector Machines (SVMs) are applied to select some important training data. Then, k-mean clustering is used to assign the weight to each training instance. Finally, unseen examples are classified by kNN. Fourteen datasets from the UCI repository were used to evaluate the performance of this algorithm. SV-kNNC is compared with conventional kNN and kNN with two instance reduction techniques: CNN and ENN. The results show that our algorithm provides the best performance, both predictive accuracy and classification time.	Chulalongkorn Univ, Fac Engn, Dept Comp Engn, Bangkok 10330, Thailand	Srisawat, A (reprint author), Chulalongkorn Univ, Fac Engn, Dept Comp Engn, Bangkok 10330, Thailand.	anantaporn.s@student.chula.ac.th; tanasanee@yahoo.com; boonserm.k@chula.ac.th					Blake CL, 1998, UCI REPOSITORY MACHI; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JANKOWSKI N, 2004, COMP INSTANCE SELECT, V1, P598; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Vapnik V.N., 1998, STAT LEARNING THEORY; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	9	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-36667-9	LECT NOTES ARTIF INT			2006	4099						975	979				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEY22	WOS:000240091500117	
B	Yu, XG; Yu, XP			IEEE	Yu, Xiao-Gao; Yu, Xiao-Peng			The research on an adaptive k-nearest neighbors classifier	Proceedings of 2006 International Conference on Machine Learning and Cybernetics, Vols 1-7			English	Proceedings Paper	5th International Conference on Machine Learning and Cybernetics	AUG 13-16, 2006	Dalian, PEOPLES R CHINA	IEEE Syst Man & Cybernet Soc, Hebei Univ, Hong Kong Polytech Univ, Harbin Inst Technol		nearest neighbor; pattern recognition; hypersphere; classification	ALGORITHM; SEARCH; RULE	k-Nearest neighbor (KNNC) classifier is the most popular non-parametric classifier. But it requires much classification time to search k nearest neighbors of an unlabelled object point, which badly affects its efficiency and performance. In this paper, an adaptive k-nearest neighbors classifier (AKNNC) is proposed. The algorithm can find k nearest neighbors of the unlabelled point in a small hypersphere in order to improve the efficiencies and classify the point. The hypersphere's size can be automatically determined. It requires a quite moderate preprocessing effort, and the cost to classify an unlabelled point is O(ad)+O(k)(1 <= a << n). Our experiment shows the algorithm performance is superior to other known algorithms.	Hubei Univ Econ, Wuhan 430205, Peoples R China; Wuhan Univ, Wuhan 430072, Peoples R China	Yu, XG (reprint author), Hubei Univ Econ, Wuhan 430205, Peoples R China.						Aghbari Z. A., 2005, Data & Knowledge Engineering, V52, DOI 10.1016/j.datak.2004.06.015; Batko M, 2005, LECT NOTES COMPUT SC, V3367, P79; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KUAN J, 1997, INT C INF COMM SIGN, P9; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Samet H., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; YU C, 2002, HIGH DIMENSIONAL IND, V2341, P85; YU XP, 2005, INT C SERV SYST SERV, P1016; ZHANG B, 2004, IEEE T PATTERN ANAL, V26	17	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		1-4244-0060-0				2006							1241	1246				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BFE36	WOS:000241452301107	
B	Zhu, M; Chen, WH; Hirdes, J; Stolee, P		Wamkeue, R		Zhu, Mu; Chen, Wenhong; Hirdes, John; Stolee, Paul			Predicting rehabilitation potential with the K-nearest neighbors algorithm: A comparison with the current clinical assessment protocol	Proceedings of the 17th IASTED International Conference on Modelling and Simulation			English	Proceedings Paper	17th IASTED International Conference on Modelling and Simulation	MAY 24-26, 2006	Montreal, CANADA	Int Assoc Sci & Technol Dev, TCMS, World Modelling & Simulat Forum		Bayes' theorem; binary prediction; diagnostic likelihood ratio; interRAI minimum data set; machine learning; modelling and simulation methodologies	MDS	Using data from eight Community Care Access Centres (CCACs) in Ontario, we demonstrate that an automatic, data-driven, machine learning algorithm such as the K-nearest neighbors (KNN) algorithm can predict rehabilitation potential more effectively than the current Clinical Assessment Protocol (CAP). Implications for clinical decision-making and computerized health information systems are discussed.	Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada	Zhu, M (reprint author), Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada.						Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSBL.1763.0053; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirdes J P, 1999, Healthc Manage Forum, V12, P30; Morris JN, 1997, J AM GERIATR SOC, V45, P1017; MORRIS JN, 1999, PRIMER USE MINIMUM D; Morris JN, 1999, J GERONTOL A-BIOL, V54, pM546, DOI 10.1093/gerona/54.11.M546; Pepe M. S, 2003, STAT EVALUATION MED; R Development Core Team, 2004, R LANG ENV STAT COMP; Sackett DL, 1991, CLIN EPIDEMIOLOGY BA; Stoke P, 2004, GERIATR TODAY J CAN, V7, P38; TREMBLAY M, 2005, PREDICTIVE HLTH POLI	12	0	0	ACTA PRESS ANAHEIM	ANAHEIM	PO BOX 5124, ANAHEIM, CA 92814-5124 USA		978-0-88986-592-1				2006							110	115				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Automation & Control Systems; Computer Science	BGE91	WOS:000246366600021	
S	Shang, WQ; Zhu, HB; Huang, HK; Qu, Y; Lin, YM			IEEE	Shang, Wenqian; Zhu, Haibin; Huang, Houkuan; Qu, Youli; Lin, Yongmin			The improved ontology kNN algorithm and its application	PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, SENSING AND CONTROL	IEEE International Conference on Networking, Sensing and Control		English	Proceedings Paper	IEEE International Conference on Networking, Sensing and Control	APR 23-25, 2006	Ft Lauderdale, FL	IEEE Syst, Man & Cybernet Soc			NEAREST NEIGHBOR	With the advances of the Web, more and more people, especially business people, use emails to communicate with each other. Hence, how to deal with business emails is becoming more and more important for decision makers, because among these emails, there hides valuable information such as the customer's complaints about a product or the interests of customers to a product. These are important information for a manager to propose marketing policies. In this paper, we develop an improved kNN algorithm----fkNN (fuzz kNN) algorithm based on ontology ideology to classify the emails. After classifying the emails into different classes, we can mine knowledge more easily based on the classified emails. Therefore, the classification effect is very important for mining knowledge further. Fortunately, our improved algorithm behaves much better than other algorithms in classification performance for our email datasets and other datasets.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.	shangwenqian@hotmail.com; haibinz@nipissingu.ca; hkhuang@center.njtu.edu.cn; quyouli@center.njtu.edu.cn; linyongmin1208@tom.com					COST RS, 2002, IEEE INTELLIGENT JAN, P40; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; LEWIS DD, P 3 ANN S DOC AN INF; SHANG W, 2004, P IEEE C SYST MAN CY, P4084; Stevens R, 2000, BIOINFORMATICS, V16, P184, DOI 10.1093/bioinformatics/16.2.184; SUGUMARAN V, 2002, DATA KHOWL ENG, P251; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; WANG BB, 2002, P 2002 INT C COMM CI, P1230; Yang Y., 1999, INFORMATION RETRIEVA, V1, P76; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1810-7869	1-4244-0065-1	IEEE INT C NETW SENS			2006							198	203				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Automation & Control Systems; Computer Science	BER46	WOS:000239057000035	
B	Pham, TD; Tran, DT			IEEE	Pham, Tuan D.; Tran, Dat T.			Gaussian mixture and Markov models for cell-phase classification in microscopic imaging	Proceedings of the 2006 IEEE/SMC International Conference on System of Systems Engineering			English	Proceedings Paper	IEEE/SMC International Conference on System of Systems Engineering	APR 24-26, 2006	Los Angeles, CA	IEEE, SMC		cellular imaging; identification; Gaussian mixture models; Markov models		Studies of drug effects on cancer cells are performed through measuring cell cycle progression such as inter phase, prophase, metaphase and anaphase in individual cells. Such studies require the processing and analysis of huge amounts of image data. Manual image analysis is very time consuming thus costly, potentially inaccurate and poorly reproducible. Stages of an automated cellular imaging analysis consist of segmentation, feature extraction, classification, and tracking of individual cells in a dynamic cellular population. Image classfication of cell phases in a fully automatic manner presents the most difficult task of such analysis. We considered applying several versions of Gaussian mixture and Markov models for automating the classification of cell nuclei in different mitotic phases recorded over a period of twenty-four hours at every fifteen minutes with a time-lapse fluoresence microscopy. The experimental results have shown that the proposed methods are effective and have potential for higher performance.	James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4811, Australia	Pham, TD (reprint author), James Cook Univ N Queensland, Sch Informat Technol, Townsville, Qld 4811, Australia.						Bezdek J., 1981, PATTERN RECOGNITION; CHEN X, IN PRESS IEEE T BIOM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; DUNKLE R, 2003, DRUG DISCOVERY WORLD, V5, P75; FENG Y, 2002, EUROPEAN PHARM REV, V7, P7; FOX S, 2003, DRUG DISCOVERY WORLD, V5, P21; Hiraoka Y, 1996, CHROMOSOME RES, V4, P173, DOI 10.1007/BF02254954; Huang X., 1990, HIDDEN MARKOV MODELS; Kanda T, 1998, CURR BIOL, V8, P377, DOI 10.1016/S0960-9822(98)70156-3; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Murphy D. B., 2001, FUNDAMENTALS LIGHT M; PHAM TD, 2005, P AI 2005 WORKSH LEA, P52; PHAM TD, 2006, NEURAL STEM CELL RES; RABINER LR, 1983, AT&T TECH J, V62, P1075; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; TRAN D, 1999, P IEEE INT C NAFIS, P426; Tran D., 2000, P FUZZ IEEE C MAY US, V1, P152; TRAN D, 2000, P SPOKEN LANGUAGE PR, V1, P421; Yarrow JC, 2003, COMB CHEM HIGH T SCR, V6, P279; [Anonymous], 2005, P IEEE, V93	21	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0187-1				2006							303	308				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Telecommunications	Automation & Control Systems; Computer Science; Telecommunications	BFZ13	WOS:000245541700053	
B	He, J; Dai, XB; Zhao, XC			IEEE	He, Ji; Dai, Xinbin; Zhao, Xuechun			A systematic computational approach for transcription factor target gene prediction	Proceedings of the 2006 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology	SEP 28-29, 2006	Toronto, CANADA					Computational prediction of transcription factor's binding sites and regulatory target genes has great value to the biological studies of cellular process. Existing practices either look into first-hand gene expression data which could be costly for large scale analysis, or apply statistical or heuristic learning methods to discover potential binding sites which have limited accuracy due to the complexity of the data. Based on well-studied information retrieval theories, this paper proposes a novel systematic approach for transcription factor target gene prediction. The key of the approach is to model the prediction problem as a classification task by representing the features of the sequential data into vector data points in a higher-order domain. The proposed approach has produced satisfactory results in our controlled experiment on Auxin Response Factor (ARF) target gene prediction in Arabidopsis.	Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Grp, Ardmore, OK 73401 USA	He, J (reprint author), Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Grp, 2510 Sam Noble Pkwy, Ardmore, OK 73401 USA.						AKUTSU S, 1998, P 9 ANN ACM SIAM S D; BAILEY TL, 1995, MACH LEARN, V21, P51, DOI 10.1023/A:1022617714621; BILU Y, 2002, ISMB; Cavnar W. B., 1994, P 3 ANN S DOC AN INF, P161; CHEN T, 1999, P 3 ANN RECOMB; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROWDER G, 1996, P 1 IEEE MET C; DASARATHY BV, 1991, NEAREST NIGHBOR NN N; Friedman N., 2000, RECOMB 2000. Proceedings of the Fourth Annual International Conference on Computational Molecular Biology; Goda H, 2004, PLANT PHYSIOL, V134, P1555, DOI 10.1104/pp.103.034736; Good I. J., 1965, ESTIMATION PROBABILI; Goutsias J, 2006, IEEE ACM T COMPUT BI, V3, P57, DOI 10.1109/TCBB.2006.2; HE J, 2003, APPL INTELL, V18, P31; HUFFMAN S, 1996, TREC 4 P; JOCHIMS T, 1998, P EUR C MACH LEARN; LAM W, 1997, P 15 INT JOINT C ART, P745; Liu ZB, 1997, PLANT PHYSIOL, V115, P397, DOI 10.1104/pp.115.2.397; Mandel-Gutfreund Y, 2001, Pac Symp Biocomput, P139; Shannon E., 1948, BELL SYST TECH J, V27, P623; TAN AH, 1995, NEURAL NETWORKS, V8, P437, DOI 10.1016/0893-6080(94)00092-Z; Tasker B., 2002, P 18 C UNC ART INT U, P485; VANRIJSBERGEN CJ, 1979, INFOR RETIEVAL; Workman CT, 2000, PAC S BIOCOMPUT, V5, P464; Yang Y, 1999, 22 ANN INT ACM SIGIR, P42; YANG Y, 1994, 17 ANN INT ACM SIGIR; Yang Y, 1997, P 14 INT C MACH LEAR, P412	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		1-4244-0623-4				2006							385	391				7	Mathematical & Computational Biology	Mathematical & Computational Biology	BFW23	WOS:000245066100053	
B	Yu, XP; Yu, XG		Yao, Y; Shi, ZZ; Wang, YX; Kinsner, W		Yu, Xiaopeng; Yu, Xiaogao			The research on an adaptive k-nearest neighbors classifier	Proceedings of the Fifth IEEE International Conference on Cognitive Informatics, Vols 1 and 2			English	Proceedings Paper	5th IEEE International Conference on Cognitive Informatics (ICCI 2006)	JUL 17-19, 2006	Beijing, PEOPLES R CHINA	IEEE Comp Soc, Chinese Acad Sci, IEEE ICCI Steering Comm, IJCiNi, IEEE Canada, IEEE CS Press		nearest neighbor; pattern recognition; hypersphere; classification	ALGORITHM; SEARCH; RULE	K-nearest neighbor (KNNC) classifier is the most popular non-parametric classifier. But it requires much classification time to search k nearest neighbors of an unlabelled object point, which badly affects its efficiency and performance. In this paper, an adaptive k-nearest neighbors classifier (AKNNC) is proposed. The algorithm can find k nearest neighbors of the unlabelled point in a small hypersphere in order to improve the efficiencies and classify the point. The hypersphere's size can be automatically determined. It requires a quite moderate preprocessing effort, and the cost to classify an unlabelled point is O(ad) + O(k)(1 <= a << N) . Our experiment shows the algorithm performance is superior to other known algorithms.	Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China; Hubei Univ Econ, Wuhan 430070, Peoples R China	Yu, XP (reprint author), Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China.						Al Aghbari Z, 2005, DATA KNOWL ENG, V52, P333, DOI 10.1016/j.datak.2004.06.015; Batko M., 2004, Databases, Information Systems, and Peer-to-Peer Computing. Second International Workshop, DBISP2P 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol.3367); BINZHANG, 2004, IEEE T PATTERN ANAL, V26; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUI Y, 2002, HIGH DIMENSIONAL IND, V2341, P85; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KUAN J, 1997, INT C INF COMM SIGN, P9; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Samet H., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; XIAOPENG Y, 2005, NEW CLUST ALG BAS DI, P1016	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		978-1-4244-0475-9				2006							535	540				6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BGH41	WOS:000246981800080	
B	Panigrahy, R			SIAM/ACM	Panigrahy, Rina			Entropy based Nearest Neighbor Search in High Dimensions	PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS			English	Proceedings Paper	17th ACM-SIAM Symposium on Discrete Algorithms	JAN, 2006	Miami, FL	ACM SIGACT, SIAM			IMAGE	In this paper we study the problem of finding the approximate nearest neighbor of a query point in the high dimensional space, focusing on the Euclidean space. The earlier approaches use locality-preserving hash functions (that tend to map nearby points to the same value) to construct several hash tables to ensure that the query point hashes to the same bucket as its nearest neighbor in at least one table. Our approach is different we use one (or a few) hash table and hash several randomly chosen points in the neighborhood of the query point showing that at least one of them will hash to the bucket containing its nearest neighbor. We show that the number of randomly chosen points in the neighborhood of the query point q required depends on the entropy of the hash value h(p) of a random point p at the same distance from q at its nearest neighbor, given q and the locality preserving hash function h chosen randomly from the hash family. Precisely, we show that if the entropy I (h(p)vertical bar q, h) = M and g is a bound on the probability that two far-off points will hash to the same bucket, then we can find the approximate nearest neighbor in O(n(rho)) time and near linear (O) over tilde (n) space where p = M/log(l/g). Alternatively we can build a data structure of size O(n1/((1-rho)) to answer queries in 0(d) time. By applying this analysis to the locality preserving hash functions in [17, 21, 6] and adjusting the parameters we show that the c nearest neighbor can be computed in time O(nP) and near linear space where rho approximate to 2.06/c as c becomes large.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Panigrahy, R (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	rinap@cs.stanford.edu					Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2004, P S COMP GEOM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Dolev D., 1993, Proceedings of the 2nd Israel Symposium on Theory and Computing Systems (Cat. No.93TH0520-7), DOI 10.1109/ISTCS.1993.253486; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; HARPELED S, 2001, P S FDN COMP SCI; INDYK P, 2001, HIGH DIMENSIONAL COM; Indyk P., 2003, WORKSH STAT COMP THE; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; INDYK P., 1997, P 29 ANN ACM S THEOR, P618, DOI 10.1145/258533.258656; Indyk P., 2004, HDB DISCRETE COMPUTA; INDYK P, 2002, ACM S COMP GEOM; JAYRAM TS, 2003, P 35 ANN ACM S THEOR, P667; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Linial N., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237999; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; Salton G., 1989, AUTOMATIC TEXT PROCE; van Rijsbergen C. J., 1990, INFORM RETRIEVAL; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Zolotarev V M, 1986, TRANSLATIONS MATH MO, V65	28	6	8	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA		978-0-89871-605-4				2006							1186	1195		10.1145/1109557.1109688		10	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BQR14	WOS:000281596300131	
B	Ye, T; Zhu, XF; Li, XY; Li, Y		Beihai, H; Shiya, F; Fangeng, C		Ye Tao; Zhu Xuefeng; Li Xiangyang; Li Yan			Predicting the pulp kappa number with a soft sensor based on the k-nearest neighbor algorithm	Research Progress in Pulping and Papermaking, 2006			English	Proceedings Paper	3rd International Symposium on Emerging Technologies of Pulping and Papermaking	NOV 08-10, 2006	Guangzhou, PEOPLES R CHINA	State Key Lab Pulp & Paper Engn, S China Univ Technol, Natl Nat Sci Fdn China, Tech Assoc Pulp & Paper Ind		soft sensor; neural network; kappa number		Soft sensing models based on supervised learning neural networks were well studied in the recent two decades. The k-Nearest Neighbor (kNN) algorithm is a kind of instance-based learning methods. It locally generalizes a new instance within its neighborhood. This paper proposes a modified kNN regression algorithm based on the dataset editing algorithm and quadratic distance definition, with which a soft sensor is constructed. Finally, the modified kNN algorithm based soft sensor is applied to the Kappa number prediction in the batch KP process.	S China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Peoples R China	Ye, T (reprint author), S China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GUTTMAN A, 1984, ACM SIGMOD, V13, P47; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; LI HQ, 2000, SOFT SENSING TECHNOL; LI XY, 2001, THESIS S CHINA U TEC; Luo Ming, 2002, Journal of Tsinghua University (Science and Technology), V42; LUO Q, 1998, THESIS GUANGZHOU S C; MCAVOY TJ, 1992, AUTOMATICA, V28, P441, DOI 10.1016/0005-1098(92)90134-2; Mitchell Tom M., 2003, MACHINE LEARNING; Yu Jingjiang, 1996, Control Theory & Applications, V13; Zhang Hong-Bin, 2000, Acta Electronica Sinica, V28; [朱学峰 Zhu Xuefeng], 2002, [华南理工大学学报. 自然科学版, Journal of South China University of Technology Natural Sciences], V30, P61	12	0	0	SOUTH CHINA UNIV TECHNOLOGY PRESS	GUANGZHOU	GUANGZHOU 510641, GUANGDONG, PEOPLES R CHINA		978-7-5623-2514-7				2006							788	791				4	Engineering, Manufacturing; Materials Science, Paper & Wood	Engineering; Materials Science	BFR65	WOS:000244038600160	
B	Yamada, T; Yamashita, K; Ishii, N; Iwata, K		Song, YT; Lu, C	IEEE	Yamada, Takahiro; Yamashita, Kyohei; Ishii, Naohiro; Iwata, Kazunori			Text classification by combining different distance functions with weights	SNPD 2006: Seventh ACIS International Conference on Software Engineering Artificial Intelligence, Networking, and Parallel/Distributed Computing, Proceedings			English	Proceedings Paper	7th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel and Distributed Computing/7th ACIS International Workshop on Self-Assembling Networks	JUN 19-20, 2006	Las Vegas, NV	Int Assoc Comp & Informat Sci, Towson Univ, Cent Michigan Univ				Since data is becoming greatly large in the networks, the machine classification of the text data, is not easy under these computing circumstances. Though the k-nearest neighbor (kNN) classification is a simple and effective classification approach, the improving performance of the classifier is still attractive to cope with the high accuracy processing. In this paper, the WN is improved by applying the different distance functions with weights to measure data from the multi-view points. Then, the weights for the optimization, are computed by the genetic algorithms. After the learning of the trained data, the unknown data is classified by combining the multiple distance functions and ensemble computations of the kNN. In this paper we present a new approach to combine multiple kNN classifiers based on different distance functions, which improve the performance of the k-nearest neighbor method. The proposed combining algorithm shows the higher generalization accuracy when compared to other conventional learning algorithms.	Aichi Inst Technol, Toyota 4700392, Japan	Yamada, T (reprint author), Aichi Inst Technol, 1247 Yachigusa, Toyota 4700392, Japan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAO NY, 2005, LNCS, V3578, P133; BAO Y, 2002, P 5 INT C DISC SCI, P361; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LANGLEY W, 1992, P 10 NATL C AI, P223; McClelland J. L., 1988, EXPLORATIONS PARALLE; Merz C.J., 1998, UCI REPOSITORY MACHI; Michie D, 1994, MACHINE LEARNING NEU; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	13	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2611-X				2006							85	90				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BEQ48	WOS:000238913400013	
S	Mico, L; Moreno-Seco, F; Sanchez, JS; Sotoca, JM; Mollineda, RA		Yeung, DY; Kwok, JT; Fred, A; Roli, F; DeRidder, D		Mico, Luisa; Moreno-Seco, Francisco; Sanchez, Jose Salvador; Sotoca, Jose Martinez; Mollineda, Ramon Alberto			On the use of different classification rules in an editing task	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	Joint International Workshop on Structural, Syntactic, and Statistical Pattern Recognition	AUG 17-19, 2006	Hong Kong, PEOPLES R CHINA	Int Assoc Pattern Recognit, Tech Comm TC1 & TC2, Hong Kong Univ Sci & Technol		pattern recognition; classification; nearest neighbor; prototype selection; editing		Editing allows the selection of a representative subset of prototypes among the training sample to improve the performance of a classification task. The Wilson's editing algorithm was the first proposal and then a great variety of new editing techniques have been proposed based on it. This algorithm consists on the elimination of prototypes in the training set that are misclassified using the k-NN rule. From such editing scheme, a general editing procedure can be straightforward derived, where any classifier beyond k-NN can be used. In this paper, we analyze the behavior of this general editing procedure combined with 3 different neighborhood-based classification rules, including k-NN. The results reveal better performances of the 2 other techniques with respect to k-NN in most of cases.	Univ Alacant, Dept Llenguatges & Sistemes Informat, E-03071 Alacant, Spain; Univ Jaume 1, Dept Llenguatges & Sistemes Informat, E-12071 Castello La Plana, Spain	Mico, L (reprint author), Univ Alacant, Dept Llenguatges & Sistemes Informat, E-03071 Alacant, Spain.						BERNARDO E, 2004, P 17 INT C PATT REC, P136; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P11, DOI 10.1016/0167-8655(95)00093-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; DUDA RO, 1973, PATTERN CLASSFICATIO; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Moreno-Seco F, 2003, LECT NOTES COMPUT SC, V2652, P589; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	10	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-37236-9	LECT NOTES COMPUT SC			2006	4109						747	754				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BEY05	WOS:000240075100082	
B	Horng, SJ; Huang, GC; Luo, WY		Callaos, N; Lesso, W; Ham, C; DellOsso, LF; Li, Z		Horng, Shi-Jinn; Huang, Guan-Chi; Luo, Wen-Yang			Protecting Web server from DDoS attacks using three-layer detection mechanism	WMSCI 2006: 10TH WORLD MULTI-CONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL II, PROCEEDINGS			English	Proceedings Paper	10th World Multi-Conference on Systemics, Cybernetics and Informatics/12th International Conference on Information Systems Analysis and Synthesis	JUL 16-19, 2006	Orlando, FL	Int Inst Informat & System		Distributed Denial of Service Attack; network security; intrusion detection; KNN; entropy-based analysis		According to FBI 2004 Computer Crime and Security Survey Result, Distributed Denial of Service Attack is the second dangerous network attack. The attacker use abnormal activities to consume the system resource or to degrade the performance of network instead of intruding the system itself Currently, Detection mechanisms are researched that is able to detect the abnormal activities when the attackers use the large amount of packets to break the system down in the development of DDoS. However, the changeable frequency mode will be the tendency in the future. In this paper, we proposed the three-layer detection mechanism which can look for the sophisticated attack packets such as the changeable frequency attack mode. Firstly, we will analyze which fields in the packet may be our features. After analyzing, the features will be grouped into detection characteristics of each layer which quantifies the normal service behavior precisely according to their features. It is easy and immediate to detect the abnormal behavior when the attacks occur. We implement our proposed mechanism in the NTUST's Web Server. We will attack the Web server in practice to observe the difference for beginning to end. And our proposed mechanism can reach a higher performance.	[Horng, Shi-Jinn; Huang, Guan-Chi; Luo, Wen-Yang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Info Engn, TWISC, Taipei, Taiwan	Horng, SJ (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Info Engn, TWISC, Taipei, Taiwan.						A Lawrence, 2004, CSI FBI COMPUTER CRI; AHA DW, 1986, ARTIF INTELL, V29, P241; CHAITIN GJ, 1974, J ACM, V21, P403, DOI 10.1145/321832.321839; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Forouzan B. A., 2003, TCP IP PROTOCOL SUIT; Han J., 2001, DATA MINING CONCEPTS; HOWARD J, 1998, THESIS C MELLON U; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; MACGREGOR JF, 1993, J QUAL TECHNOL, V25, P106; MARKOWSKY G, 1996, J UNIVERS COMPUT SCI, V2, P245; MONTGOMETRY DC, 1997, INTRO STAT QUALITY C; Ryan T. P., 1989, STAT METHODS QUALITY; Shannon C. E., 1963, MATH THEORY COMMUNIC; YOO I, 2004, INF ASS WORKSH 2004, P74; *CERT RES, 2004 ANN REP	15	0	0	INT INST INFORMATICS & SYSTEMICS	ORLANDO	14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA		978-980-6560-67-3				2006							279	284				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BHA56	WOS:000251936800053	
S	Lou, Z; Jin, Z		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Lou, Zhen; Jin, Zhong			Novel adaptive nearest neighbor classifiers based on hit-distance	18th International Conference on Pattern Recognition, Vol 3, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ			PATTERN-CLASSIFICATION; FACE RECOGNITION	In this paper a novel idea of distance, Hit-Distance, was firstly introduced to generalize the representational capacity of available prototypes. Novel adaptive nearest neighbor classifiers based on Hit-Distance were then proposed Experiments were performed on 8 benchmark datasets from the UCI Machine Learning Repository. It was shown that the proposed classifiers performed much better than the classical nearest neighbor classifier (NN) and the nearest feature line method (NFL), the nearest feature plane method (NFP), the nearest neighbor line method (NNL) and the nearest neighbor plane method (NNP).	Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China	Lou, Z (reprint author), Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Newman D.J., UCI REPOSITORY MACHI; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	6	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2521-0	INT C PATT RECOG			2006							87	90				4	Computer Science, Artificial Intelligence	Computer Science	BFB29	WOS:000240705600021	
S	Shu, Y; Chao, Z		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Shu Yang; Chao Zhang			Regression Nearest Neighbor in face recognition	18th International Conference on Pattern Recognition, Vol 3, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ			CLASSIFICATION	In this paper, we introduce a Regression Nearest Neighbor framework for general classification tasks. To alleviate potential problems caused by nonlinearity, we propose a kernel regression nearest neighbor (KRNN) algorithm and its convex counterpart (CKRNN) as two specific extensions of nearest neighbor algorithm and present a fast and useful kernel selection method correspondingly. Comprehensive analysis and extensive experiments are used to demonstrate the effectiveness of our methods in real face datasets.	Peking Univ, Natl Lab Machine Percept, Beijing 100871, Peoples R China	Shu, Y (reprint author), Peking Univ, Natl Lab Machine Percept, Beijing 100871, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUNG G, 2001, P KDD 2001; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2001, ELEMENTS STAT LEARNI; LI S, 1998, INT C COMP VIS PATT; PENG J, 2004, IEEE T PATTERN ANAL, V26; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Poggio T., 2003, NOTICES AMS, V50, P537; Scholkopf B., 2002, LEARNING KERNELS; Sim T., 2002, INT C AUT FAC GEST R; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; VICENT P, 2001, NEURAL INFORM PROCES; YANG C, 2004, NEURAL INFORM PROCES	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2521-0	INT C PATT RECOG			2006							515	518				4	Computer Science, Artificial Intelligence	Computer Science	BFB29	WOS:000240705600123	
S	Andra, S; Nagy, G		Tang, YY; Wang, SP; Lorette, G; Yeung, DS; Yan, H		Andra, Srinivas; Nagy, George			Combining dichotomizers for MAP field classification	18th International Conference on Pattern Recognition, Vol 4, Proceedings	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	18th International Conference on Pattern Recognition (ICPR 2006)	AUG 20-24, 2006	Hong Kong, PEOPLES R CHINA	IAPR, CAA, Hong Kong Baptist Univ				A new method for combining dichotomizers like SVMs is proposed for classifying multi-class pattern fields. The novelty lies in the estimation of the style-constrained posterior field class probabilities from the frequencies of the training patterns in the regions of the feature space engendered by the pairwise decision boundaries of the dichotomizers. We show that on simulated data, this non-parametric field classifier is nearly optimal. On scanned printed digits, its accuracy is comparable to that of state-of-the-art style classifiers.	Rensselaer Polytech Inst, DocLab, ECSE, Troy, NY 12180 USA	Andra, S (reprint author), Rensselaer Polytech Inst, DocLab, ECSE, Troy, NY 12180 USA.						ANDRA S, 2005, COMBINING DICHOTOMIZ; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T., 2000, 1 INT WORKSH MULT CL, P1; Gunter S, 2004, LECT NOTES COMPUT SC, V3138, P583; Lam L., 1997, HDB CHARACTER RECOGN, P79; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Sarkar M, 2005, THER DRUG MONIT, V27, P1, DOI 10.1097/00007691-200502000-00001; SAVICKY P, 2003, P 5 INT S INT DAT AN; Vapnik V.N., 1998, STAT LEARNING THEORY; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; VEERAMACHANENI S, 2003, P 6 INT C DOC AN REC, P1060; ZASLAVSKY T, 1975, MEM AM MATH SOC, V1, P154; ZHANG X, 2006, INT C PATTERN RECOGN; ZHANG X, 2006, P SPIE ELECT IMAGING, V6067	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2521-0	INT C PATT RECOG			2006							210	214				5	Computer Science, Artificial Intelligence	Computer Science	BFB30	WOS:000240707600051	
S	Tahir, MA; Bouridane, A			IEEE	Tahir, Muhammad Atif; Bouridane, Ahmed			An FPGA based coprocessor for cancer classification using nearest neighbour classifier	2006 IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol III, Proceedings: SIGNAL PROCESSING THEORY AND METHODS, DESIGN AND IMPLEMENTATION OF SIGNAL PROCESSING SYSTEMS, INDUSTRY TECHNOLOGY TRACKS	International Conference on Acoustics Speech and Signal Processing (ICASSP)		English	Proceedings Paper	31st IEEE International Conference on Acoustics, Speech and Signal Processing	MAY 14-19, 2006	Toulouse, FRANCE	IEEE Signal Proc Soc				This paper discusses the suitability of reconfigurable computing to speedup classification problems using Nearest Neighbour (INN) classifier. INN classifier is widely used in the literature especially in real-time applications such as face recognition, on-line hand-written character recognition and medical applications where the performance enhancement in terms of speed is desirable. To evaluate the effectiveness of our implementation on Field Programmable Gate Arrays (FPGAs), experiments were carried out on two medical data sets. Results have shown that the classification accuracy is exactly same for both FPGAs and microprocessor (mu P) based solutions with FPGA has superior speed performances.	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						Bensaali F, 2005, IEE P-CIRC DEV SYST, V152, P236, DOI 10.1049/ip-cds:20040838; Blake C.L., UCI REPOSITORY MACHI; Bouridane A, 1999, J SYST ARCHITECT, V45, P809, DOI 10.1016/S1383-7621(98)00040-X; CHELLAPPA R, 1995, P IEEE, V83, P5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROOKES D, 2000, IEE P VIS IM SIGN PR; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Ferrari A, 2000, PATTERN RECOGN, V33, P2083, DOI 10.1016/S0031-3203(99)00192-2; LIPMAN A, 1997, IEEE T VLSI, V5; Michie D, 1994, MACHINE LEARNING NEU; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tahir MA, 2005, ANALOG INTEGR CIRC S, V43, P205, DOI 10.1007/s10470-005-6793-2; TAHIR MA, 2000, 14 INT C FIELD PROGR, P771; TZIONAS PG, 1994, IEEE T VLSI, V2; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHOU P, 1998, P 9 BRIT MACH VIS C	17	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		INT CONF ACOUST SPEE			2006							1012	+				5	Acoustics; Engineering, Electrical & Electronic	Acoustics; Engineering	BFW34	WOS:000245098900254	
S	Tahir, MA; Bouridane, A			IEEE	Tahir, Muhammad Atif; Bouridane, Ahmed			An FPGA based coprocessor for cancer classification using nearest neighbour classifier	2006 IEEE International Conference on Acoustics, Speech and Signal Processing, Vols 1-13	International Conference on Acoustics Speech and Signal Processing (ICASSP)		English	Proceedings Paper	31st IEEE International Conference on Acoustics, Speech and Signal Processing	MAY 14-19, 2006	Toulouse, FRANCE	IEEE Signal Proc Soc				This paper discusses the suitability of reconfigurable computing to speedup classification problems using Nearest Neighbour (1NN) classifier. 1NN classifier is widely used in the literature especially in real-time applications such as face recognition, on-line hand-written character recognition and medical applications where the performance enhancement in terms of speed is desirable. To evaluate the effectiveness of our implementation on Field Programmable Gate Arrays (FPGAs), experiments were carried out on two medical data sets. Results have shown that the classification accuracy is exactly same for both FPGAs and microprocessor (mu P) based solutions with FPGA has superior speed performances.	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						Bensaali F, 2005, IEE P-CIRC DEV SYST, V152, P236, DOI 10.1049/ip-cds:20040838; Blake C.L., UCI REPOSITORY MACHI; Bouridane A, 1999, J SYST ARCHITECT, V45, P809, DOI 10.1016/S1383-7621(98)00040-X; CHELLAPPA R, 1995, P IEEE, V83, P5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROOKES D, 2000, IEE P VIS IM SIGN PR; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Ferrari A, 2000, PATTERN RECOGN, V33, P2083, DOI 10.1016/S0031-3203(99)00192-2; LIPMAN A, 1997, IEEE T VLSI, V5; Michie D, 1994, MACHINE LEARNING NEU; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tahir MA, 2005, ANALOG INTEGR CIRC S, V43, P205, DOI 10.1007/s10470-005-6793-2; TAHIR MA, 2004, LECT NOTES COMPUTER, P771; TZIONAS PG, 1994, IEEE T VLSI, V2; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZHOU P, 1998, P 9 BRIT MACH VIS C	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149	978-1-4244-0468-1	INT CONF ACOUST SPEE			2006							3463	3466				4	Acoustics; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology	BFZ22	WOS:000245559904041	
S	Shie, JD; Chen, SM			IEEE	Shie, Jen-Da; Chen, Shyi-Ming			A new approach for handling classification problems based on fuzzy information gain measures	2006 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-5	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	JUL 16-21, 2006	Vancouver, CANADA	IEEE			MEMBERSHIP FUNCTIONS; TRAINING INSTANCES; RULES; SELECTION; FEATURES; ENTROPY	In this paper, we present a new method for handling classification problems based on fuzzy information gain measures. First, we propose a fuzzy information gain measure of a feature with respect to a set of training instances. Then, based on the proposed fuzzy information gain measure, we present an algorithm for constructing membership functions, calculating the class degree of each subset of training instances with respect to each class and calculating the fuzzy entropy of each subset of training instances, where each subset of training instances contains a part of the training instances whose values of a specific feature fall in the support of a specific fuzzy set of this feature. Finally, we propose an evaluating function for. classifying testing instances. The proposed method can deal with both numeric and nominal features. It gets higher average classification accuracy rates than the existing methods.	Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Shie, JD (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.	smchen@et.ntust.edu.tw					BAIM PW, 1988, IEEE T PATTERN ANAL, V10, P888, DOI 10.1109/34.9110; BANERJI RB, 1964, GEN SYST, V9, P135; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Burr Ridge I, 1997, MACHINE LEARNING; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Chen SM, 2003, CYBERNET SYST, V34, P217, DOI 10.1080/01969720390184399; Chen SM, 2005, CYBERNET SYST, V36, P397, DOI 10.1080/01969720490929562; Chen S.M., 2005, P 2005 IEEE INT C FU, P183, DOI 10.1109/FUZZY.2005.1452390; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Hartigan J.A., 1979, J ROYAL STAT SOC C, V28, P100; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; John G., 1995, P 11 C UNC ART INT, P338; KOSKO B, 1986, INFORM SCIENCES, V40, P165, DOI 10.1016/0020-0255(86)90006-X; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; Luca A.D., 1972, INFORM CONTR, V20, P301; ONGKOWIJAYA BT, 2004, P 7 INT C SIGN PROC, P663; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Platt J, 1999, P 13 ANN C NEUR INF, P557; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Ramesh VE, 1999, PATTERN RECOGN, V32, P217, DOI 10.1016/S0031-3203(98)00141-1; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SHANNON CE, 1948, AT&T TECH J, V27, P379; Wu TP, 1999, IEEE T SYST MAN CY B, V29, P25, DOI 10.1109/3477.740163; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1968, J MATH ANAL APPL, V23, P421, DOI 10.1016/0022-247X(68)90078-4; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5	29	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584	978-0-7803-9488-9	IEEE INT CONF FUZZY			2006							939	946				8	Computer Science, Artificial Intelligence	Computer Science	BFR68	WOS:000244063601068	
S	Zhao, Q			IEEE	Zhao, Qiangfu			Inducing NNC-Trees quickly	2006 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-6, PROCEEDINGS	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 08-11, 2006	Taipei, TAIWAN	IEEE Syst, Man & Cybernet Soc, Minist Educ, Natl Sci Council, Natl Taipei Univ Technol, Natl Chiao Tung Univ			NEIGHBOR PATTERN-CLASSIFICATION; HIERARCHICAL-CLASSIFICATION	An NNC-Tree is a decision tree (DT) with each non-terminal node containing a nearest neighbor classifier (NNC). Compared with the axis-parallel decision trees (APDTs), NNC-Trees are more comprehensible for large problems, because the decision rules corresponding to the trees are simpler. Currently, the author has proposed an algorithm for inducing NNC-Trees based on the R(4)-rule. However, compared with C4.5, which is a popular program for inducing APDTs, the computation of our algorithm is relatively expensive. This paper proposes two methods for reducing the computational cost. The efficiency of the proposed methods is verified through experiments on three public databases.	Univ Aizu, Grad Sch, Dept Informat Syst, Aizu Wakamatsu, Japan	Zhao, Q (reprint author), Univ Aizu, Grad Sch, Dept Informat Syst, Aizu Wakamatsu, Japan.	qf-zhao@u-aizu-ac.jp					Adams RG, 1999, NEURAL NETWORKS, V12, P541, DOI 10.1016/S0893-6080(99)00010-6; BASAK J, 2005, IEEE T KNOWL DATA EN, V7, P121; Brieman L, 1984, CLASSIFICATION REGRE; Cantu-Paz E, 2003, IEEE T EVOLUT COMPUT, V7, P54, DOI 10.1109/TEVC.2002.806857; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; LI T, 1993, NEUROCOMPUTING, V5, P119, DOI 10.1016/0925-2312(93)90032-X; Murthy S. K., 1994, J ARTIFICIAL INTELLI, V2, P1; Oates T., 1997, P 14 INT C MACH LEAR, P254; ZHAO QF, 2006, IN PRESS IEEE T SY B; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	978-1-4244-0099-7	IEEE SYS MAN CYBERN			2006							2784	2789		10.1109/ICSMC.2006.385295		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BGK85	WOS:000248078503015	
B	Blanzieri, E; Melgani, F			IEEE	Blanzieri, Enrico; Melgani, Farid			An Adaptive SVM Nearest Neighbor Classifier for Remotely Sensed Imagery	2006 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-8	IEEE International Symposium on Geoscience and Remote Sensing (IGARSS)		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	JUL 31-AUG 04, 2006	Denver, CO	IEEE, IEEE Geosci & Remote Sensing Soc, Canadian Remote Sensing Soc, NASA, NOAA, Off Naval Res, Natl Polar Orbiting Operat Environm Satellite Syst, Japan Aerosp Explorat Agcy, Ball Aerosp & Technologies Corp, Cooperat Inst Res Atmosphere, Colorado State Univ, Univ Colorado, Int Union Radio Sci		image classification; k-nearest neighbor algorithm; kernel methods; support vector machines	SENSING IMAGES	In this paper, we propose an extension of the kNN classifier based on the maximum margin principle. The proposed method is based on the idea to classify a given unlabeled sample by first finding its k nearest training samples. Then, a local partition of the feature space is carried out by means of local SVM decision boundaries determined after training a multiclass SVM classifier on the k training samples considered. The labeling of the unknown sample is done by looking at the local decision region it belongs to. The resulting global decision boundaries throughout the entire feature space are piecewise linear. The entire process can be however kernelized through the determination of the k nearest training samples in the kernel space by using a distance function simply reformulated on the basis of the adopted kernel. To illustrate the performance of the proposed method, an experimental analysis on different remote sensing data sets is reported and discussed.	[Blanzieri, Enrico; Melgani, Farid] Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy	Blanzieri, E (reprint author), Univ Trent, Dept Informat & Commun Technol, Via Sommarive 14, I-38050 Trento, Italy.	blanzier@dit.unitn.it; melgani@dit.unitn.it					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 2001, 4 USAF SCH AV MED, P261; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Vapnik V.N., 1998, STAT LEARNING THEORY; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	7	8	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-0-7803-9509-1	INT GEOSCI REMOTE SE			2006							3931	3934		10.1109/IGARSS.2006.1008		4	Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Geology; Remote Sensing; Imaging Science & Photographic Technology	BIN08	WOS:000260989402194	
S	Solomatine, DP; Maskey, M; Shrestha, DL			IEEE	Solomatine, Dimitri. P.; Maskey, Mahesh; Shrestha, Durga Lal			Eager and lazy learning methods in the context of hydrologic forecasting	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			ARTIFICIAL NEURAL NETWORKS; MODEL TREES; RIVER; PREDICTION	Computational intelligence techniques are becoming popular in hydrologic forecasting. Primarily these are eager learning methods. Lazy (instance-based) learning (IBL) has received relatively little attention, and the present paper explores the applicability of these methods. Their performance is compared with that of neural networks, M5 model trees, regression trees. A flow forecasting problem was solved along with the five benchmark problems. Results showed that one of the IBL methods, the locally weighted regression, especially if used with the Gaussian kernel function, often is more accurate than the eager learning methods.	Inst Water Educ, UNESCO IHE, NL-2601 DA Delft, Netherlands	Solomatine, DP (reprint author), Inst Water Educ, UNESCO IHE, POB 3015, NL-2601 DA Delft, Netherlands.	d.solomatine@unesco-ihe.org; maheshmaskey@yahoo.com; d.shrestha@unesco-ihe.org	Shrestha, Durga/B-5610-2013	Shrestha, Durga/0000-0002-5545-1736			Abrahart RJ, 2000, HYDROL PROCESS, V14, P2157, DOI 10.1002/1099-1085(20000815/30)14:11/12<2157::AID-HYP57>3.0.CO;2-S; AHA DW, 1991, MACH LEARN, P37; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BLALE CL, 1998, UCI REPOSITORY MACHI; Bray M, 2004, J HYDROINFORM, V6, P265; Burr Ridge I, 1997, MACHINE LEARNING; CLEVELAND WS, 1994, 953 AT T BELL LAB ST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibike YB, 2001, PHYS CHEM EARTH PT B, V26, P1, DOI 10.1016/S1464-1909(01)85005-X; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; GALEATI G, 1990, HYDROLOG SCI J, V35, P79, DOI 10.1080/02626669009492406; Gasser T., 1979, SMOOTHING TECHNIQUES, P23; GOVINDARAJU RS, 2001, ARTIFICIAL NEURAL NE; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; KARLSSON M, 1987, WATER RESOUR RES, V23, P1300, DOI 10.1029/WR023i007p01300; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Minns AW, 1996, HYDROLOG SCI J, V41, P399, DOI 10.1080/02626669609491511; QUINLAN JR, 1993, P ML 93 SAN MAT CA; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Scott D. W., 1992, MULTIVARIATE DENSITY; Shamseldin AY, 1996, J HYDROL, V179, P353, DOI 10.1016/0022-1694(95)02833-1; SHRESTHA DL, 2006, NEURAL COMPUTATION, V18; SHRESTHA I, 2003, THESIS IHE DELFT; Solomatine DP, 2004, J HYDROL ENG, V9, P491, DOI 10.1061/(ASCE)1084-0699(2004)9:6(491); Solomatine DP, 2006, NEURAL NETWORKS, V19, P215, DOI 10.1016/j.neunet.2006.01.008; Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; SOLOMATINE DP, 2005, ENCY HYDROLOGICAL SC; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; Witten I. H., 2000, DATA MINING PRACTICA; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	31	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-0-7803-9490-2	IEEE IJCNN			2006							4847	4853				7	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125909002	
S	Specht, DF			IEEE	Specht, Donald F.			GRNN with double clustering	2006 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORK PROCEEDINGS, VOLS 1-10	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Network	JUL 16-21, 2006	Vancouver, CANADA	IEEE			NEURAL NETWORK	The hybrid combination of three techniques has yielded a pattern recognition and estimation technique with greatly improved training speed, orders-of-magnitude speed improvement for testing and readout, and sometimes improved accuracy as well. It is useful for problems with high dimensionality and noisy data. The techniques used are clustering, kernel regression with adaptive parameters, a second level of clustering, and the formation of a binary decision tree. When previous versions of General Regression Neural Networks have been used as the system identification component for control systems, the most important problem has been that the estimation speed limits the iteration time in the feedback loop. The new hybrid technique was designed specifically to overcome this limitation.	Lockheed Martin Corp, Adv Technol Ctr, Palo Alto, CA 94304 USA	Specht, DF (reprint author), Lockheed Martin Corp, Adv Technol Ctr, 3251 Hanover St, Palo Alto, CA 94304 USA.	don.specht@lmco.com					BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P458, DOI 10.1109/72.88165; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRANTI P, 2000, IEEE T IMAGE PROCESS, V9; Nadaraya E. A., 1964, THEOR PROBAB APPL, V9, P141, DOI 10.1137/1109020; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Press WH, 1988, NUMERICAL RECIPES C; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934; SPECHT DF, 1967, IEEE TRANS ELECTRON, VEC16, P308, DOI 10.1109/PGEC.1967.264666; SPECHT DF, 2004, Patent No. 6787747; SPECHT DF, 1968, N6829513 NASA; SPECHT DF, 1994, IEEE INT C NEUR NETW; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; SPECHT DF, 1992, P IEEE INT JOINT C N; SPECHT DF, 1995, FUZZ LOGIC NEURAL NE; Watson G.S., 1964, SANKHYA A, V26, P359	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	978-0-7803-9490-2	IEEE IJCNN			2006							5074	5079				6	Computer Science, Artificial Intelligence	Computer Science	BFW67	WOS:000245125909035	
B	Rozman, D; Brezak, M; Petrovic, I		Lavoie, M; AlHaddad, K; Lagace, PJ		Rozman, D.; Brezak, M.; Petrovic, I.			Parquet sorting and grading based on color and texture analyses	2006 IEEE International Symposium on Industrial Electronics, Vols 1-7			English	Proceedings Paper	IEEE International Symposium on Industrial Electronics	JUL 09-13, 2006	Montreal, CANADA	IEEE Ind Elect Soc, ABB Canada, Ecol Technol Superieure			CLASSIFICATION; INSPECTION; FEATURES; WOOD	In this paper a computer vision algorithm for automatic parquet slab sorting is described, as a part of a real time automatic parquet slab sorting system. Various computer vision algorithms and methods for automatic visual inspection and automatic classification have been analyzed. Developed algorithm consists of three main stages: color analysis, texture analysis and defects detection. The color analysis is based on the percentile values obtained from the cumulative histogram of the image and texture analysis is based on the second order statistical features obtained from gray level co-occurrence matrix. Detection of defects is implemented as the segmentation method, based on the adaptive binary threshold algorithm, which is based on a local square regions and connected component analysis methods. This way we have achieved a very accurate classifying process with about 90 percent of accuracy, which greatly outstands results of human inspector, that are about 60-70 percent.	Univ Zagreb, Fac Elect & Comp Engn, Dept Comp Engn Automat, Zagreb 41000, Croatia	Rozman, D (reprint author), Univ Zagreb, Fac Elect & Comp Engn, Dept Comp Engn Automat, Zagreb 41000, Croatia.						CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1989, PAMI, P421; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Iivarinen J, 2000, P SOC PHOTO-OPT INS, V4197, P140, DOI 10.1117/12.403757; KAUPPINEN H, 2000, P 15 INT C PATT REC, V4, P803, DOI 10.1109/ICPR.2000.903039; Kauppinen H, 1999, THESIS U OULU OULU; MAENPAA T, 2004, PATTERN RECOGN, V8, P1629; NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017; Pan JS, 2004, IEICE T FUND ELECTR, VE87A, P961; PETKOVIC T, 2002, P ERK 2002, P283; Silven O, 1996, INT J PATTERN RECOGN, V10, P83, DOI 10.1142/S0218001496000086; VANOTTERLOO PJ, 1978, PR, P281	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0496-4				2006							655	660		10.1109/ISIE.2006.295538		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BFS70	WOS:000244382901029	
B	Wang, Q; Kulkarni, SR; Verdu, S			IEEE	Wang, Qing; Kulkarni, Sanjeev R.; Verdu, Sergio			A nearest-neighbor approach to estimating divergence between continuous random vectors	2006 IEEE International Symposium on Information Theory, Vols 1-6, Proceedings			English	Proceedings Paper	IEEE International Symposium on Information Theory	JUL 09-14, 2006	Seattle, WA	IEEE Informat Theory Soc, USN, Dept Navy Sci & Technol, Microsoft, Natl Sci Fdn			CONSISTENT	A method for divergence estimation between multidimensional distributions based on nearest neighbor distances is proposed. Given i.i.d. samples, both the bias and the variance of this estimator are proven to vanish as sample sizes go to infinity. In experiments on high-dimensional data, the nearest neighbor approach generally exhibits faster convergence compared to previous algorithms based on partitioning.	Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA	Wang, Q (reprint author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.						Bentley JL, 1975, COMMUN ACM, V18; BHATTACH.PK, 1967, ANN MATH STAT, V38, P1770, DOI 10.1214/aoms/1177698611; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASU T, 2006, IN PRESS P 38 S INT; DEVROYE L, 1996, PROBABLISTIC THEORY; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Feller W., 1970, INTRO PROBABILITY TH; Fix E, 1951, DISCRIMINATORY ANAL; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Goldberger J., 2003, P 9 IEEE INT C COMP, V1, P487, DOI 10.1109/ICCV.2003.1238387; HINNEBURG A, 2000, P 26 VLDB C CAIR EGY; Johnson DH, 2001, J COMPUT NEUROSCI, V10, P47, DOI 10.1023/A:1008968010214; Kozachenko L. F., 1987, Problems of Information Transmission, V23; Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138; KRISHNAMURTHY B, 2005, P 1 IEEE WORKSH NETW; Kulkarni SR, 2002, IEEE T INFORM THEORY, V48, P2785, DOI 10.1109/TIT.2002.802611; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Liu C., 2003, P IEEE C COMP VIS PA, V1, P587; Loeve M., 1977, PROBABILITY THEORY; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MATHIASSEN JR, 2002, P 7 EUR C COMP VIS 3, P133; Ramirez J, 2004, IEEE SIGNAL PROC LET, V11, P266, DOI 10.1109/LSP.2003.821762; Tsybakov AB, 1996, SCAND J STAT, V23, P75; VICTOR JD, 2002, PHYS REV E, V66, P51903; Wang Q, 2005, IEEE T INFORM THEORY, V51, P3064, DOI 10.1109/TIT.2005.853314; WANG Q, 2005, BIAS REDUCTION DIVER	28	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0505-3				2006							242	246		10.1109/ISIT.2006.261842		5	Telecommunications	Telecommunications	BFX53	WOS:000245289700051	
S	van der Laan, DJ; Maas, MC; Schaart, DR; Bruyndonckx, P; Lamaitre, C; van Eijk, CWE			IEEE	van der Laan, D. J. (Jan); Maas, Marnix C.; Schaart, Dennis R.; Bruyndonckx, Peter; Lamaitre, Cedric; van Eijk, Carel W. E.			Spatial Resolution in Position-Sensitive Monolithic Scintillation Detectors	2006 IEEE NUCLEAR SCIENCE SYMPOSIUM CONFERENCE RECORD, VOL 1-6	IEEE Nuclear Science Symposium Conference Record		English	Proceedings Paper	15th International Workshop on Room-Temperature Semiconductor X- and Gamma-Ray Detectors/ 2006 IEEE Nuclear Science Symposium	OCT 29-NOV 04, 2006	San Diego, CA	IEEE			PET DETECTORS	Monolithic scintillation detectors are very promising for high resolution and high sensitivity positron emission tomography. These detectors consist of a few cubic centimeters of scintillating material coupled to one or more position-sensitive APD arrays. The entry point of an impinging annihilation photon is estimated from the light distribution on the APD pixels. In this paper, a model will be derived that predicts the line spread function of these detectors. This model includes the influences of the finite width of the measurement beam, scatter of radiation inside the detector, light yield and intrinsic energy resolution of the scintillator, quantum efficiency, gain and excess noise factor of the avalanche photo-diode arrays, and electronic noise. With this model a better understanding of the behavior of the detector is possible, which can make optimization more efficient.	[van der Laan, D. J. (Jan); Maas, Marnix C.; Schaart, Dennis R.; van Eijk, Carel W. E.] Delft Univ Technol, NL-2629 JB Delft, Netherlands	van der Laan, DJ (reprint author), Delft Univ Technol, Mekelweg 15, NL-2629 JB Delft, Netherlands.	d.j.vanderlaan@tudelft.nl					Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8; Barrett H H, 2004, FDN IMAGE SCI; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; MAAS MC, 2005, IEEE NUCL SCI S, V4, P2017, DOI 10.1109/NSSMIC.2005.1596729; Stuart A., 1991, KENDALLS ADV THEORY, V2; van der Laan DJJ, 2006, IEEE T NUCL SCI, V53, P1063, DOI 10.1109/TNS.2006.873710	8	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1082-3654	978-1-4244-0561-9	IEEE NUCL SCI CONF R			2006							2506	2510		10.1109/NSSMIC.2006.354420		5	Engineering, Electrical & Electronic; Physics, Applied	Engineering; Physics	BUC53	WOS:000288875602124	
B	Yang, CY; Hsu, CC; Yang, JS		Cheung, YM; Wang, Y; Lium, H		Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu			A novel SVM to improve classification for heterogeneous learning samples	2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	International Conference on Computational-Intelligence and Security	NOV 03-06, 2006	Guangzhou, PEOPLES R CHINA	IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Univ				The paper proposes a model merging a nonparametric k-nearest-neighbor (kNN) method into an underlying support vector machine (SVM) to produce an instance-dependent loss function. In this model, a filtering stage of the kNN searching was employed to collect information from training examples and produced a set of emphasized weights which can be If distributed to every example by a class of real-valued class labels. The emphasized weights changed the policy of the equal-valued impacts of the training examples and permitted a more efficient way to utilize the information behind the training examples with various significance levels. Due to the property of estimating density locally, the kNN method has the advantage to distinguish the heterogeneous examples from the regular examples by merely considering the situation of the examples themselves. The paper shows the model is promising with both the theoretical derivations and consequent experimental results.	No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei 112, Taiwan	Yang, CY (reprint author), No Taiwan Inst Sci & Technol, Dept Mech Engn, 2 Xue Yuan Rd, Taipei 112, Taiwan.	cy.yang@ntist.edu.tw; 692342792@s92.tku.edu.tw; 096034@mail.tku.edu.tw					BARTLETT P, 2003, 638 UC BERK DEP STAT; BREIMAN L, 1996, 460 UC BERK DEP STAT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fukunaga K., 1990, STAT PATTERN RECOGNI; Hastie T, 2001, ELEMENTS STAT LEARNI; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang CY, 2004, LECT NOTES COMPUT SC, V3173, P506	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0604-3				2006							172	175				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFP93	WOS:000243679800036	
B	Kangkan, K; Kruatrachue, B			IEEE	Kangkan, Kamonnat; Kruatrachue, Boontee			Minimal consistent subset selection as integer nonlinear programming problem	2006 International Symposium on Communications and Information Technologies,Vols 1-3			English	Proceedings Paper	International Symposium on Communications and Information Technologies	OCT 18-20, 2006	Bangkok, THAILAND			prototype selection; minimal consistent subset; consistency; nearest neighbor rule	NEAREST-NEIGHBOR RULE; SET COVERING PROBLEM; CLASSIFICATION; ALGORITHM; SEARCH; DESIGN	The minimal consistent subset selection is a solution of high computational demands problem of the nearest neighbor decision system. This paper presents a new approach that aims to make the problem more clearly by stating it as a constrained optimization problem, called "integer nonlinear programming problem (INLP)". In this context, we propose method that formulates the minimal consistent subset selection problem as 0-1 integer nonlinear programming problem. We show experimental result of the minimal consistent subset of "IRIS Dataset", obtained by solving its constrained optimization model. The results obtained suggest that the approach offers exactly optimal solution of the problem.	King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand	Kangkan, K (reprint author), King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand.						Anderson E., 1935, B AM IRIS SOC, V59, P2; BARTH P, 1995, MPI952003 MAXPL I IN; BEASLEY JE, 1990, NAV RES LOG, V37, P151, DOI 10.1002/1520-6750(199002)37:1<151::AID-NAV3220370110>3.0.CO;2-2; Beasley JE, 1996, EUR J OPER RES, V94, P392, DOI 10.1016/0377-2217(95)00159-X; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Caprara A, 1999, OPER RES, V47, P730, DOI 10.1287/opre.47.5.730; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Fortet R, 1960, REV FRANCAISE RECHER, V4, P17; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; LI J, 2004, J MATH MODELLING ALG, V3, P263, DOI 10.1023/B:JMMA.0000038619.69509.bf; MOLLINEDA RA, 2000, P 4 WORLD MULT SYST; TAHA HA, 1972, MANAGE SCI B-APPL, V18, pB328; TAHA HA, 1992, OPERTATIONS RES INTR, P333	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-0-7803-9740-8				2006							922	926				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BGI18	WOS:000247284400185	
B	Jirina, M; Jirina, M			IEEE	Jirina, Marcel; Jirina, Marcel, Jr.			Simple and effective probability density estimation and classification	2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13			English	Proceedings Paper	SICE-ICASE International Joint Conference	OCT 18-21, 2006	Busan, SOUTH KOREA	SICE, ICASE		multivariate data; classification; probability distribution mapping function; power approximation		A mapping is introduced which maps the true distribution to a function of distances. The approximation of this function in the form of a suitable power of the distance is presented. The exponent in this approximation is used for probability density estimation in high-dimensional spaces and for classification.	Inst Comp Sci ASCR, Prague, Czech Republic	Jirina, M (reprint author), Inst Comp Sci ASCR, Prague, Czech Republic.	jirina@fbmi.cvut.cz; jirina@fbmi.cvut.cz					Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUA RO, 2000, PATTERN CLASSIFICATI; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; HAKL F, 2005, ATLCOMPHYS2005044 CE; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Silverman B.W., 1986, DENSITY ESTIMATION S; *CART, CART METH; *STATS INC, 2005, STATISTICA DAT AN SO	10	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-89-950038-4-8				2006							2122	2123				2	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BGE04	WOS:000246237602049	
S	Xiao, SS; Wu, YX		Tan, J		Xiao, Song-Shan; Wu, Yong-Xing			Rotation-invariant texture analysis using radon and Fourier transforms	4th International Symposium on Instrumentation Science and Technology (ISIST' 2006)	JOURNAL OF PHYSICS CONFERENCE SERIES		English	Proceedings Paper	4th International Symposium on Instrumentation Science and Technology (ISIST '2006)	AUG 08-12, 2006	Harbin, PEOPLES R CHINA	ICMI, NSFC, CSM, CIS, HIT, IC-CSM		texture analysis; rotation invariant; Radon transform Fourier transform	CLASSIFICATION	Texture analysis is a basic issue in image processing and computer vision, and how to attain the Rotation-invariant texture characterization is a key problem. This paper proposes a rotation-invariant texture analysis technique using Radon and Fourier transform. This method uses Radon transform to convert rotation to translation, then utilizes the Fourier transform and takes the modules of the Fourier transform of these functions to make the translation invariant. A k-nearest-neighbor rule is employed to classify textures images. The proposed method is robust to additive white noise as a result of summing pixel values to generate projections in the Radon transform step. To test and evaluate the method, several different kinds of experiments are employed. Experiments results show the feasibility of the proposed method and its robustness to additive white noise.	Tianjin Univ, Coll Precis Instruments & Optoelect Engn, Tianjin 300072, Peoples R China	Xiao, SS (reprint author), Tianjin Univ, Coll Precis Instruments & Optoelect Engn, Tianjin 300072, Peoples R China.						BRACEWELL, 1995, 2 DIMENSIONAL IMAGIN; BRODATZ P, 1966, PHOTOGRAPHIC ALBUM A; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Greenspan H., 1994, P IEEE INT C IM PROC; HALEY GM, 1995, P IEEE INT C IM PROC; KOUROSH, 2005, IEEE TRANSFORMS IMAG, V14; Kuthirummal S, 2004, PATTERN RECOGN, V37, P739, DOI 10.1016/j.patcog.2003.06.002; Lahajnar F, 2003, PATTERN RECOGN LETT, V24, P1151, DOI 10.1016/S0167-8655(02)00285-4; Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7	10	2	2	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1742-6588		J PHYS CONF SER			2006	48		1-2				1459	1464		10.1088/1742-6596/48/1/268		6	Instruments & Instrumentation; Physics, Applied	Instruments & Instrumentation; Physics	BGU20	WOS:000250567100267	
B	Huang, CC; Chang, HY; Yang, CH		Cheung, YM; Wang, Y; Lium, H		Huang, Chi-Chun; Chang, Hsin-Yun; Yang, Cheng-Hong			A novel grey-based feature ranking method for feature subset selection	2006 International Conference on Computational Intelligence and Security, Pts 1 and 2, Proceedings			English	Proceedings Paper	International Conference on Computational-Intelligence and Security	NOV 03-06, 2006	Guangzhou, PEOPLES R CHINA	IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Univ			ALGORITHMS; CLASSIFICATION	In this paper, a novel grey-based feature ranking method for feature subset selection is proposed. Experiments performed on various application domains are reported to demonstrate the performance of the proposed approach. It can be easily seen that the proposed approach yields high performance and is helpful for pattern classification.	Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, 142 Hai Jhuan Rd, Kaohsiung 811, Taiwan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C.L., UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NEAREST NEIGHBOUR NN; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Deng Julong, 1989, Journal of Grey Systems, V1; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Duda R., 1973, PATTERN CLASSIFICATI; HUANG CC, IN PRESS APPL INTELL; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Liu H., 1998, FEATURE SELECTION KN; Mitchell TM, 1998, MACHINE LEARNING; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; WATSON CP, 1993, STAT MANAGEMENT EC	20	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0604-3				2006							129	132		10.1109/ICCIAS.2006.294105		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BFP93	WOS:000243679800026	
B	Umamaheswari, K; Sumathi, S; Sivanandam, SN; Anburajan, KKN			IEEE	Umamaheswari, K.; Sumathi, S.; Sivanandam, S. N.; Anburajan, K. K. N.			Efficient finger print image classification and recognition using neural network data mning	2007 International Conference of Signal Processing, Communications and Networking, Vols 1 and 2			English	Proceedings Paper	International Conference on Signal Processing, Communications and Networks	FEB 22-24, 2007	Chennai, INDIA	IEEE		finger print recognition; neural network; and K nearest neighbor algorithms; data mining		This paper deals with the fingerprint classification and recognition system, which consists of extracting and matching of minutiae from the input image. The necessity for Security in fields such as improving airport security, strengthening the national borders, in travel documents, in preventing ID theft has brought the need to develop an able and efficient method for correct classification of personnel authentication. Fingerprints are the first biometric science used widely for the validation and verifications of entry into specific task, which is more reliable, efficient and accurate. Despite finger print recognition being reliable it has disadvantages such as very low recognition rate, low accuracy rate, total time of recovery and data insufficiency. To address above problem a novel Data Mining technique, Neuro Nearest Neighbour based fingerprint classification and recognition, is introduced which boosts the classification rate. The proposed method consists of different stages such as image enhancement, line detector based feature extraction, neural network classification using Learning vector quantization and Back propagation networks. The proposed system is trained and tested on Fingerprint Database obtained from the University of Bologna Italy, which consists of 900 samples. The exact image is recognized precisely from the classified database rather than the original set of database using Crisp K-Nearest Neighbour algorithm that increases recognition accuracy and reduction in time.	PSG Coll Technol, Coimbatore, Tamil Nadu, India	Umamaheswari, K (reprint author), PSG Coll Technol, Coimbatore, Tamil Nadu, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1991, NEAREST NEIGHBOUR PA; Hong L., 1996, P 1 IEEE WACV SAR FL, P202; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM YK, 2004, IEEE T ARTIFICIAL IN, V6; Lee H. C., 1991, ADV FINGERPRINT TECH; LIN H, 2004, IEEE T PATTERN ANAL, V20; RAO CV, 1980, IEEE T PATTERN ANAL, V2, P23231, DOI UNSP 223231; SHAH PSS, 2004, IEEE T SYSTEMS MAN C, V34; Sivanandam S. N., 2005, INTRO NEURAL NETWORK; Wilson C. L., 1994, Journal of Artificial Neural Networks, V1	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-1-4244-0996-9				2006							426	432				7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BGH70	WOS:000247031300086	
J	Le, SQ; Ho, TB				Le, SQ; Ho, TB			An association-based dissimilarity measure for categorical data	PATTERN RECOGNITION LETTERS			English	Article						dissimilarity measures; categorical data; conditional probability distribution; hypothesis testing; nearest neighbor	SIMILARITY; COEFFICIENTS; CLASSIFICATION; DIVERGENCE; ENTROPY	In this paper, we propose a novel method to measure the dissimilarity of categorical data. The key idea is to consider the dissimilarity between two categorical values of an attribute as a combination of dissimilarities between the conditional probability distributions of other attributes given these two values. Experiments with real data show that our dissimilarity estimation method improves the accuracy of the popular nearest neighbor classifier. (c) 2005 Elsevier B.V. All rights reserved.	Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan	Ho, TB (reprint author), Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan.	quang@jaist.ac.jp; bao@jaist.ac.jp					ALBERT ML, 1983, QUANTITATIVE APPL SO, V32; BATAGELJ V, 1995, J CLASSIF, V12, P73, DOI 10.1007/BF01202268; BAULIEU FB, 1989, J CLASSIF, V6, P233, DOI 10.1007/BF01908601; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Carvalho F., 1998, DATA SCI CLASSIFICAT, P370; de Carvalho F.A.T., 1994, STUDIES CLASSIFICATI, V5, P387; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Fisher R. A., 1950, STAT METHODS RES WOR; GOODALL DW, 1966, BIOMETRICS, V22, P882, DOI 10.2307/2528080; GOWDA KC, 1991, PATTERN RECOGN LETT, V12, P259; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; GOWDA KC, 1992, IEEE T SYST MAN CYB, V22, P368, DOI 10.1109/21.148412; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; HUBALEK Z, 1982, BIOL REV, V57, P669, DOI 10.1111/j.1469-185X.1982.tb00376.x; ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391; Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI 10.1111/j.1469-8137.1912.tb05611.x; Krantz D. H., 1971, FDN MEASUREMENT, V1-3; KULLBACK S, 1959, INFORMATION THEORY S; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LANCASTER HO, 1949, BIOMETRIKA, V36, P370, DOI 10.2307/2332674; Liebetrau A, 1983, MEASURES ASS; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Rached Z, 2001, IEEE T INFORM THEORY, V47, P1553, DOI 10.1109/18.923736; RUSSELL PAUL F., 1940, JOUR MALARIA INST INDIA, V3, P153; Sokal R. R., 1963, PRINCIPLES NUMERICAL	28	6	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC	2005	26	16					2549	2557		10.1016/j.patrec.2005.06.002		9	Computer Science, Artificial Intelligence	Computer Science	984LU	WOS:000233307200006	
J	Shen, HB; Chou, KC				Shen, HB; Chou, KC			Predicting protein subnuclear location with optimized evidence-theoretic K-nearest classifier and pseudo amino acid composition	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						nucleus; nuclear proteins; subnuclear location; gene products; evidence theory; KNN classifier; Dempster's rule; pseudo amino acid; composition; jackknife test	STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; SUBCELLULAR LOCATION; FOLDING TYPES; LOCALIZATION; RULE	The nucleus is the brain of eukaryotic cells that guides the life processes of the cell by issuing key instructions. For in-depth understanding of the biochemical process of the nucleus, the knowledge of localization of nuclear proteins is very important. With the avalanche of protein sequences generated in the post-genomic era, it is highly desired to develop an automated method for fast annotating the subnuclear locations for numerous newly found nuclear protein sequences so as to be able to timely utilize them for basic research and drug discovery. In view of this, a novel approach is developed for predicting the protein subnuclear location. It is featured by introducing a powerful classifier, the optimized evidence-theoretic K-nearest classifier, and using the pseudo amino acid composition [K.C. Chou, PROTEINS: Structure, Function, and Genetics, 43 (2001) 246], which can incorporate a considerable amount of sequence-order effects, to represent protein samples. As a demonstration, identifications were performed for 370 nuclear proteins among the following 9 subnuclear locations: (1) Cajal body, (2) chromatin, (3) heterochromatin, (4) nuclear diffuse, (5) nuclear pore, (6) nuclear speckle, (7) nucleolus, (8) PcG body, and (9) PML body. The overall success rates thus obtained by both the re-substitution test and jackknife cross-validation test are significantly higher than those by existing classifiers on the same working dataset. It is anticipated that the powerful approach may also become a useful high throughput vehicle to bridge the huge gap occurring in the post-genomic era between the number of gene sequences in databases and the number of gene products that have been functionally characterized. The OET-KNN classifier will be available at www.pami.sjtu.edu.cn/people/hbshen. (c) 2005 Elsevier Inc. All rights reserved.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dellaire G, 2003, NUCLEIC ACIDS RES, V31, P328, DOI 10.1093/nar/gkg018; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; SHFER G, 1976, MATH THEORY EVIDENCE; Vapnik V.N., 1998, STAT LEARNING THEORY; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	30	102	110	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X		BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	NOV 25	2005	337	3					752	756		10.1016/j.bbrc.2005.09.117		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	978YY	WOS:000232910300002	
J	O'Farrell, M; Lewis, E; Flanagan, C; Lyons, W; Jackman, N				O'Farrell, M; Lewis, E; Flanagan, C; Lyons, W; Jackman, N			Comparison of k-NN and neural network methods in the classification of spectral data from an optical fibre-based sensor system used for quality control in the food industry	SENSORS AND ACTUATORS B-CHEMICAL			English	Article; Proceedings Paper	18th Eurosensors Conference	SEP 12-15, 2004	Rome, ITALY			k-nearest neighbour; neural network; backpropagation; principal component analysis; optical fibre sensor; spectroscopy; visible light; classification; food industry; process control; cooking		This paper investigates simplifying the classification technique of an optical fibre sensor based system designed for the online quality control of food being cooked in a large-scale industrial oven by monitoring the product as it cooks. The system measures the colour of the food product as it cooks by examining the reflected visible light from the surface as well as in the core of the product. Accurate classification has been previously obtained using a multi layer perceptron (MLP) with a backpropagation learning algorithm and principal component analysis (PCA) as a method of feature extraction but the k-nearest neighbour (k-NN) method is investigated in order to simplify the classification techniques, especially since principal component analysis already generates disjoint clusters. Two products are used to illustrate the principal of the method of this investigation, namely minced beef burgers and pastry although it is equally applicable to many other food products. In this investigation experimentally obtained spectral data was taken from the surface of the food and then analysed allowing direct comparison of the two classification methods. Results show that although the neural network proved superior when the input spectra deviated slightly in shape from the spectra used in training, the k-NN classifier may have prove advantageous in applications where there is less deviation in the sampled product spectrum. (c) 2005 Elsevier B.V. All rights reserved.	Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland; Food Design Applicat Ltd, Limerick, Ireland	O'Farrell, M (reprint author), Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland.	marion.ofarrell@ul.ie	Lewis, Elfed/H-5125-2013	Lewis, Elfed/0000-0003-4174-7090			Beckonert O, 2003, ANAL CHIM ACTA, V490, P3, DOI 10.1016/S0003-2670(03)00060-6; Conde C., 2003, Proceedings 12th International Conference on Image Analysis and Processing; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DROUHARD JP, 1995, P 3 INT C DOC AN REC, V2, P807, DOI 10.1109/ICDAR.1995.602024; Drouhard JP, 1996, PATTERN RECOGN, V29, P415, DOI 10.1016/0031-3203(95)00092-5; ISHIZAWA H, 2000, P 17 IEEE INTSTR MEA, V3, P1524, DOI 10.1109/IMTC.2000.848727; MIGNANI AG, 2003, SENSOR ACTUAT B-CHEM, P157; MIGNANI AG, 2004, P EUROPTRODE, V7, P217; Muhammed H. H., 2002, Proceedings 31st Applied Imagery Pattern Recognition Workshop From color to Hyperspectral: Advancements in Spectral Imagery Exploitation. AIPR 2002; OFARRELL M, IN PRESS IEEE SENS J; OFARRELL M, 2003, INT J SMART ENG SYST, V5, P409, DOI 10.1080/10255810390243719; O'Farrell M, 2005, SENSOR ACTUAT B-CHEM, V107, P104, DOI 10.1016/j.snb.2004.09.050; POTTIER I, 1994, P IEEE WORLD C COMP, V5, P2948, DOI 10.1109/ICNN.1994.374701; Schalkoff R, 1992, PATTERN RECOGNITION; SWATLAND HJ, 1989, CAN I FOOD SC TECH J, V22, P390	15	15	15	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0925-4005		SENSOR ACTUAT B-CHEM	Sens. Actuator B-Chem.	NOV 11	2005	111				SI		354	362		10.1016/j.snb.2005.02.003		9	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	977RM	WOS:000232820900056	
J	Mignani, AG; Ciaccheri, L; Cimato, A; Attilio, C; Smith, PR				Mignani, AG; Ciaccheri, L; Cimato, A; Attilio, C; Smith, PR			Spectral nephelometry for the geographic classification of Italian extra virgin olive oils	SENSORS AND ACTUATORS B-CHEMICAL			English	Article; Proceedings Paper	18th Eurosensors Conference	SEP 12-15, 2004	Rome, ITALY			absorption spectroscopy; olive oil; nephelometry; scattering		Extra virgin olive oils from different regions of Italy, both made in artisan manner and industrially produced, were analyzed by means of multi-angle and multi-wavelength absorption spectroscopy in the visible spectral range, and were then compared with other edible oils. A multivariate processing of the spectral data produced maps of oils clustered according to oil type and geographic origin. (c) 2005 Elsevier B.V. All rights reserved.	CNR, Inst Appl Phys Nello Cararra, Opt & Photon Dept, I-50127 Florence, Italy; CNR, IVALSA, I-50019 Sesto Fiorentino, FI, Italy; Univ Loughborough, Dept Elect & Elect Engn, Loughborough, Leics, England	Mignani, AG (reprint author), CNR, Inst Appl Phys Nello Cararra, Opt & Photon Dept, Via Panciatichi 64, I-50127 Florence, Italy.	a.g.mignani@ifac.cnr.it					ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE, pCH3; Alessandri S, 1999, GRASAS ACEITES, V50, P369; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cresti M., 1996, Advances in Horticultural Science, V10, P105; Harwood JL, 1999, HDB OLIVE OIL; Mignani AG, 2003, SENSOR ACTUAT B-CHEM, V90, P157, DOI 10.1016/S0925-4005(03)00101-1; VANDEGINSTE BGM, 1998, HDB CHEMOMETRICS QUA, pCH17	8	16	16	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0925-4005		SENSOR ACTUAT B-CHEM	Sens. Actuator B-Chem.	NOV 11	2005	111				SI		363	369		10.1016/j.snb.2005.03.023		7	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	977RM	WOS:000232820900057	
J	Li, F; Wechsler, H				Li, F; Wechsler, H			Open set face recognition using transduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; confidence; credibility; data fusion; information quality; Kolmogorov complexity; face recognition; open set recognition; performance evaluation; PSEI (pattern specific error inhomogeneities); randomness deficiency; strangeness; face surveillance; (multiclass) transduction; watch list; clustering; outlier detection	CLASSIFICATION	This paper motivates and describes a novel realization of transductive inference that can address the Open Set face recognition task. Open Set operates under the assumption that not all the test probes have mates in the gallery. It either detects the presence of some biometric signature within the gallery and finds its identity or rejects it, i.e., it provides for the "none of the above" answer. The main contribution of the paper is Open Set TCM-kNN (Transduction Confidence Machine-k Nearest Neighbors), which is suitable for multiclass authentication operational scenarios that have to include a rejection option for classes never enrolled in the gallery. Open Set TCM-kNN, driven by the relation between transduction and Kolmogorov complexity, provides a local estimation of the likelihood ratio needed for detection tasks. We provide extensive experimental data to show the feasibility, robustness, and comparative advantages of Open Set TCM-kNN on Open Set identification and watch list (surveillance) tasks using challenging FERET data. Last, we analyze the error structure driven by the fact that most of the errors in identification are due to a relatively small number of face patterns. Open Set TCM-kNN is shown to be suitable for PSEI (pattern specific error inhomogeneities) error analysis in order to identify difficult to recognize faces. PSEI analysis improves biometric performance by removing a small number of those difficult to recognize faces responsible for much of the original error in performance and/ or by using data fusion.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Li, F (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fli@cs.gmu.edu; wechsler@cs.gmu.edu					Bailliere E., 2003, P AUD VID BAS BIOM P, P625; BENGIO S, 2001, 0121 IDIAPRR EUR PRO; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Bolle RM, 2004, GUIDE BIOMETRICS; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Conover W, 1980, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daugman J, 1997, IEEE T PATTERN ANAL, V19, P675, DOI 10.1109/34.598225; Doddington G., 1998, P ICSLD98 NOV, P1351; Furui S, 1997, PATTERN RECOGN LETT, V18, P859, DOI 10.1016/S0167-8655(97)00073-1; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998); GROTHER P, 2004, 7083 NISTIR; Jain A.K., 1999, BIOMETRICS PERSONAL; Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102; Joachims T., 1999, P 16 INT C MACH LEAR, P200; JUSZCZAK P, 2004, P 17 INT C PATT REC; Krogel MA, 2004, MACH LEARN, V57, P61, DOI 10.1023/B:MACH.0000035472.73496.0c; KUKAR M, 2002, P 13 EUR C MACH LEAR; Li Ming, 1997, INTRO KOLMOGOROV COM; LIU C, 2004, BIOMETRIC AUTHENTICA; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Mak MW, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P107, DOI 10.1109/ISIMP.2001.925343; Melluish T., 2001, TYPICALNESS FRAMEWOR; Mitchell T., 1999, P 6 INT C COGN SCI; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PANKANTI S, 2002, P 16 INT C PATT REC; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; PHILLIPS PJ, 2003, FACE RECOGNITION VEN; PROEDROU K, 2001, CLRCTR0102 U LOND RO; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; ROSS A, 2004, PATTERN RECOGN, V24, P2115; Saunders C., 1999, P 16 INT JOINT C ART; SNELICK R, 2003, P 5 INT C MULT INT; Tong S., 2001, J MACHINE LEARNING R, V2, P45, DOI 10.1162/153244302760185243; Vapnik VN, 2000, NATURE STAT LEARNING; Vapnik V.N., 1998, STAT LEARNING THEORY; VOVK V, 1999, P 16 INT C MACH LEAR; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	38	26	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1686	1697				12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	963SN	WOS:000231826300001	
J	Xiao, YD; Clauset, A; Harris, R; Bayram, E; Santago, P; Schmitt, JD				Xiao, YD; Clauset, A; Harris, R; Bayram, E; Santago, P; Schmitt, JD			Supervised self-organizing maps in drug discovery. 1. Robust behavior with overdetermined data sets	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							NEURAL-NETWORK; QSAR	The utility of the supervised Kohonen self-organizing map was assessed and compared to several statistical methods used in QSAR analysis. The self-organizing map (SOM) describes a family otnonlinear, topology preserving mapping methods with attributes of both vector quantization and clustering that provides Visualization options unavailable with other nonlinear methods. In contrast to most chemometric methods, the supervised SOM (sSOM) is shown to be relatively insensitive to noise and feature redundancy. Additionally, sSOMs can make use of descriptors having only nominal linear correlation with the tar et property. Results herein are contrasted to partial least squares, stepwise Multiple linear regression, the genetic functional algorithm, and genetic partial least Squares, collectively referred to throughout as the "standard methods". The k-nearest neighbor (kNN) classification method was also performed to provide a direct comparison with a different classification method. The widely studied dihydrofolate reductase (DHFR) inhibition data set of Hansch and Silipo is Used to evaluate the ability of sSOMs to classify unknowns as a function of increasing class resolution. The contribution of the sSOM neighborhood kernel to its predictive ability is assessed in two experiments: ( 1) training with the k-rneans Clustering limit, where the neighborhood radius is zero throughout the training regimen, and (2) training the sSOM until the neighborhood radius is reduced to zero. Results demonstrate that sSOMs provide more accurate predictions than standard linear QSAR methods.	Targacept Inc, Mol Design Grp, Winston Salem, NC 27101 USA; Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; Wake Forest Univ, Sch Biomed Engn & Sci, Virginia Tech, Winston Salem, NC 27157 USA	Schmitt, JD (reprint author), Targacept Inc, Mol Design Grp, 200 E 1st St,Suite 300, Winston Salem, NC 27101 USA.	jeff.schmitt@targacept.com					Anderberg M. R., 1973, CLUSTER ANAL APPL; ANZALI S, 1998, USE SELF ORGANIZING, P273; BAYRAM E, 2004, J COMPUT AID MOL DES, P483; Bellman R., 1961, ADAPTIVE CONTROL PRO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Draper NR, 1966, APPL REGRESSION ANAL, P407; Espinosa G, 2002, J CHEM INF COMP SCI, V42, P343, DOI 10.1021/ci010329j; GASTEIGER J, 1993, ANGEW CHEM INT EDIT, V32, P503, DOI 10.1002/anie.199305031; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; HANSCH C, 1969, ACCOUNTS CHEM RES, V2, P232, DOI 10.1021/ar50020a002; Kaski S, 1997, ACTA POLYTECHNICA SC, P57; Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7; Kohonen T., 1984, P 7 INT C PATT REC, P182; Kohonen T., 2001, SELF ORGANIZING MAPS; KOVALISHYN VV, 2000, P EUR S QUANT STRUCT, V12, P444; LARRY L, 2000, ACS NAT M WASH DC AU; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; LINDBERG W, 1983, ANAL CHEM, V55, P643, DOI 10.1021/ac00255a014; Polanski J, 2003, J CHEM INF COMP SCI, V43, P2081, DOI 10.1021/ci0341181; Polanski J, 2000, ACTA BIOCHIM POL, V47, P37; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P4; ROSE VS, 1991, QUANT STRUCT-ACT REL, V10, P6, DOI 10.1002/qsar.19910100103; SILIPO C, 1975, J AM CHEM SOC, V97, P6849, DOI 10.1021/ja00856a042; VANDERPUTTEN P, 1996, THESIS UTRECHT U NL; ZUPAN J, 1999, NEURAL NETWORK DRUG; *ACC INC, 2003, CER 2 MOD ENV REL 4; *MATHW INC, MATL 6 5; *MDL INF SYST INC, QSARIS 1 1	28	19	20	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	NOV-DEC	2005	45	6					1749	1758		10.1021/ci0500839		10	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	989QS	WOS:000233689400039	
J	Agrawal, M; Gupta, N; Shreelekshmi, R; Murty, MN				Agrawal, M; Gupta, N; Shreelekshmi, R; Murty, MN			Efficient pattern synthesis for nearest neighbour classifier	PATTERN RECOGNITION			English	Article						pattern synthesis; prototyping; classification; clustering; partitioning		Synthetic pattern generation is one of the strategies to overcome the curse of dimensionality, but it has its own drawbacks. Most of the synthetic pattern generation techniques take more time than simple classification. In this paper, we propose a new strategy to reduce the time and memory requirements by applying prototyping as an intermediate step in the synthetic pattern generation technique. Results show that through the proposed strategy, classification can be done much faster without compromising much in terms of classification accuracy, in fact for some cases it gives better accuracy in lesser time. The classification time and accuracy can be balanced according to available memory and computing power of a system to get the best possible results. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India; Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Murty, MN (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	monu@csa.iisc.ernet.in; neha@ee.iisc.ernet.in; lekshmi@csa.iisc.ernet.in; mnm@csa.iisc.ernet.in					Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Viswanath P., 2004, INFORM FUSION, V5, P239, DOI 10.1016/j.inffus.2004.02.003	3	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	2005	38	11					2200	2203		10.1016/j.patcog.2005.03.029		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	967TB	WOS:000232113000034	
J	Li, XR; Wu, FC; Hu, ZY; Luo, AL				Li, XR; Wu, FC; Hu, ZY; Luo, AL			A novel spectral classifier based on coherence measure	SPECTROSCOPY AND SPECTRAL ANALYSIS			Chinese	Article						coherence measure; knowledge discovery; active galactic nucleus(AGNs); active galaxies(AGs); principal component analysis(PCA); k-nearest neighbor(KNN)	ULTRAVIOLET; GALAXIES	Classification and discovery of new types of celestial bodies from voluminous celestial spectra are two important issues in astronomy, and these two issues are treated separately in the literature to our knowledge. In the present paper, a novel coherence measure is introduced which can effectively measure the coherence of a new spectrum of unknown type with the training samples located within its neighbourhood, then a novel classifier is designed based on this coherence measure. The proposed classifier is capable of carrying out spectral classification and knowledge discovery simultaneously. In particular, it can effectively deal with the situation where different types of training spectra exist within the neighbourhood of a new spectrum, and the traditional k-nearest neighbour method usually fails to reach a correct classification. The satisfactory performance for classification. and knowledge discovery has been obtained by the proposed novel classifier over active galactic nucleus(AGNs) and active galaxies(AGs) data.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China; Chinese Acad Sci, Natl Astron Observ, Beijing 100012, Peoples R China	Li, XR (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.						CALZETTI D, 1994, ASTROPHYS J, V429, P582, DOI 10.1086/174346; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 2003, PATTERN CLASSIFICATI, P568; Kendall MG, 1966, ADV THEORY STAT, V3; Kinney AL, 1996, ASTROPHYS J, V467, P38, DOI 10.1086/177583; LI ZW, 2000, ASTROPHYSICS; MURTAGH F, 1987, MULTIVARIATE ANAL; Qin DM, 2003, SPECTROSC SPECT ANAL, V23, P182; zhao-qi Bian, 2000, PATTERN RECOGN, P235	9	3	4	BEIJING UNIV PRESS	BEIJING	HAIDIAN-QU, BEIJING 100871, PEOPLES R CHINA	1000-0593		SPECTROSC SPECT ANAL	Spectrosc. Spectr. Anal.	NOV	2005	25	11					1889	1892				4	Spectroscopy	Spectroscopy	990NM	WOS:000233750500040	
J	Bencic-Nagale, S; Walt, DR				Bencic-Nagale, S; Walt, DR			Extending the longevity of fluorescence-based sensor arrays using adaptive exposure	ANALYTICAL CHEMISTRY			English	Article							ARTIFICIAL NOSE; ANTIFADING AGENTS; PH SENSOR; DISCRIMINATION; RECOGNITION; DESIGN; SYSTEM; DEVICE; FILMS	Fluorescent microbead sensor arrays were prepared to determine sensor array longevity. Sensor longevity is limited by photobleaching of the dyes attached to the microbeads and presents one of the biggest drawbacks of most fluorescent dye-based arrays. Responses of an array of organic vapor sensors were acquired for 2 weeks to evaluate the sensor performance over time. Photobleaching effects were overcome in two ways: (1) by limiting the excitation light power and gradually increasing the power at a rate comparable to the sensor photobleaching rates and (2) by illuminating subsections of the array through an optical slit. Both approaches extended the longevity of a sensor array. During the longevity study, the sensor arrays were employed to test their ability to correctly distinguish between responses to seven vapors. A high classification accuracy (99.8%) was obtained after 17 700 exposures for vapor responses collected over two weeks using only similar to 8% of the array's surface area.	Tufts Univ, Dept Chem, Medford, MA 02155 USA	Walt, DR (reprint author), Tufts Univ, Dept Chem, Medford, MA 02155 USA.	david.walt@tufts.edu					AGAYN V, 1993, IMMUNOMETHODS, V3, P112, DOI 10.1006/immu.1993.1045; Albert KJ, 2000, ANAL CHEM, V72, P1947, DOI 10.1021/ac991397w; Albert KJ, 2003, ANAL CHEM, V75, P4161, DOI 10.1021/ac0264776; Albert KJ, 2000, CHEM REV, V100, P2595, DOI 10.1021/cr980102w; Albert KJ, 2001, ANAL CHEM, V73, P2501, DOI 10.1021/ac001137a; Albert KJ, 2001, ENVIRON SCI TECHNOL, V35, P3193, DOI 10.1021/es010829t; BARNARD SM, 1991, SCIENCE, V251, P927, DOI 10.1126/science.2000492; Bencic S, 2004, P SOC PHOTO-OPT INS, V5269, P83, DOI 10.1117/12.516085; Berrios M, 1999, METHOD ENZYMOL, V307, P55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dickinson TA, 1999, ANAL CHEM, V71, P2192, DOI 10.1021/ac981457i; FREUND MS, 1995, P NATL ACAD SCI USA, V92, P2652, DOI 10.1073/pnas.92.7.2652; GARDNER JW, 1999, ELECT NOTES PRINCIPL; Grate JW, 2000, CHEM REV, V100, P2627, DOI 10.1021/cr980094j; Hartmann P, 2000, ANAL CHEM, V72, P2828, DOI 10.1021/ac9914723; Kermis HR, 2002, BIOTECHNOL PROGR, V18, P1047, DOI 10.1021/bp0255560; KRENIK KD, 1989, J IMMUNOL METHODS, V117, P91, DOI 10.1016/0022-1759(89)90122-1; Lonergan MC, 1996, CHEM MATER, V8, P2298, DOI 10.1021/cm960036j; Otto M., 1999, CHEMOMETRICS STAT CO; Shortreed M, 1996, ANAL CHEM, V68, P4015, DOI 10.1021/ac9605253; Song A, 1997, ANAL CHEM, V69, P863, DOI 10.1021/ac960917+; Sotzing GA, 2000, ANAL CHEM, V72, P3181, DOI 10.1021/ac991079x; Stitzel SE, 2002, P SOC PHOTO-OPT INS, V4575, P132, DOI 10.1117/12.456916; Stitzel SE, 2003, J AM CHEM SOC, V125, P3684, DOI 10.1021/ja028239y; Stitzel SE, 2001, ANAL CHEM, V73, P5266, DOI 10.1021/ac010111w; Tabacco MB, 1999, ANAL CHEM, V71, P154, DOI 10.1021/ac980513c; TAKAYAMA R, 1990, SENSOR ACTUAT A-PHYS, V22, P508; Udrea F, 1996, MICROELECTR J, V27, P449, DOI 10.1016/0026-2692(95)00112-3; White J, 1996, ANAL CHEM, V68, P2191, DOI 10.1021/ac9511197; White J, 1998, BIOL CYBERN, V78, P245, DOI 10.1007/s004220050430; Witten I. H., 2000, DATA MINING; Xu Z, 1998, J BIOMED MATER RES, V39, P9, DOI 10.1002/(SICI)1097-4636(199801)39:1<9::AID-JBM2>3.0.CO;2-U; Yang JS, 1998, J AM CHEM SOC, V120, P5321, DOI 10.1021/ja9742996	33	26	27	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0003-2700		ANAL CHEM	Anal. Chem.	OCT 1	2005	77	19					6155	6162		10.1021/ac0505021		8	Chemistry, Analytical	Chemistry	972HA	WOS:000232443700019	
J	Gao, QB; Wang, ZZ				Gao, QB; Wang, ZZ			Using nearest feature line and tunable nearest neighbor methods for prediction of protein subcellular locations	COMPUTATIONAL BIOLOGY AND CHEMISTRY			English	Article						nearest feature line; tunable nearest neighbor; subcellular location; amino acid composition; pattern classification; jackknife test	AMINO-ACID-COMPOSITION; SIGNAL PEPTIDES; TRANSMEMBRANE PROTEINS; PATTERN-CLASSIFICATION; LOCALIZATION SITES; SORTING SIGNALS; SEQUENCE; IDENTIFICATION	The subcellular location of a protein is closely correlated with it biological function. In this paper, two new pattern classification methods termed as Nearest Feature Line (NFL) and Tunable Nearest Neighbor (TNN) have been introduced to predict the subcellular location of proteins based on their amino acid composition alone. The simulation experiments were performed with the jackknife test on a previously constructed data set, which consists of 2427 eukaryotic and 997 prokaryotic proteins. All protein sequences in the data set fall into four eukaryotic subcellular locations and three prokaryotic subcellular locations. The NFL classifier reached the total prediction accuracies of 82.5% for the eukaryotic proteins and 91.0% for the prokaryotic proteins. The TNN classifier reached the total prediction accuracies of 83.6 and 92.2%, respectively. It is clear that high prediction accuracies have been achieved. Compared with Support Vector Machine (SVM) and Nearest Neighbor methods, these two methods display similar or even higher prediction accuracies. Hence, we conclude that NFL and TNN can be used as complementary methods for prediction of protein subcellular locations. (c) 2005 Elsevier Ltd. All rights reserved.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Hunan, Peoples R China.	gqb_kd@yahoo.com.cn	Gao, Qing-Bin/G-9825-2011				Fujiwara Y, 2001, Genome Inform, V12, P103; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, P414; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Graves PR, 2002, MICROBIOL MOL BIOL R, V66, P39, DOI 10.1128/MMBR.66.1.39-63.2002; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lio P, 2000, BIOINFORMATICS, V16, P376, DOI 10.1093/bioinformatics/16.4.376; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nielsen H., 1998, Proceedings Sixth International Conference on Intelligent Systems for Molecular Biology; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Rost B, 1996, PROTEIN SCI, V5, P1704; Vapnik V.N., 1998, STAT LEARNING THEORY; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204	34	12	13	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1476-9271		COMPUT BIOL CHEM	Comput. Biol. Chem.	OCT	2005	29	5					388	392		10.1016/j.compbiolchem.2005.08.002		5	Biology; Computer Science, Interdisciplinary Applications	Life Sciences & Biomedicine - Other Topics; Computer Science	987TK	WOS:000233540000009	
J	Yin, TK				Yin, TK			A characteristic-point-based fuzzy inference classifier by a closeness matrix	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						Bayes error; characteristic point; classifier; closeness matrix; fuzzy inference system	LA-TOURETTES SYNDROME; C-MEANS ALGORITHM; NEURAL NETWORKS; DIAGNOSIS; LOGIC; TECHNETIUM-99M-HMPAO; SEGMENTATION; COMPLEXITY; CHILDHOOD; PERFUSION	In this paper, a characteristic-point-based fuzzy inference classifier (CPFIC) is proposed to perform two-class classification. Through fuzzy interpolation, a subset of classified samples can be taken as representatives of all samples. They are called characteristic points (CPs). A closeness matrix representing the closeness of two samples in a same class is proposed in selecting CPs. By solving a number of constrained minimizations, the CPFIC is systematically built. Experiments were conducted on four classification problems with known Bayes errors, two benchmark classification problems, and a real-world application used in our research. The CPFIC performs well in accuracy evaluations in all the seven experiments. The summarizing abilities from the CPs into the linguistic descriptions of the fuzzy rule bases were also demonstrated in these examples.	Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan	Yin, TK (reprint author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.	tkyin@nuk.edu.tw					Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338; Auephanwiriyakul S, 2002, IEEE T FUZZY SYST, V10, P563, DOI 10.1109/TFUZZ.2002.803492; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; Blake CL, 1998, UCI REPOSITORY MACHI; Chen JL, 2000, IEEE T FUZZY SYST, V8, P730; Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chuang KH, 1999, IEEE T MED IMAGING, V18, P1117; CLEMENTZ GL, 1988, AM FAM PHYSICIAN, V38, P163; Cormen T. H., 1992, INTRO ALGORITHMS; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dave RN, 2002, IEEE T FUZZY SYST, V10, P713, DOI 10.1109/TFUZZ.2002.805899; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902; Fu K, 1986, HDB PATTERN RECOGNIT; FUKUDA K, 1989, TRENDS PHARM SCI S, V11, P4; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Fukunaga K., 1990, STAT PATTERN RECOGNI; Gordon I, 1996, NUCL MED COMMUN, V17, P1021, DOI 10.1097/00006231-199612000-00004; Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035; Haykin S., 1994, NEURAL NETWORKS COMP; Karayiannis NB, 1997, IEEE T FUZZY SYST, V5, P622, DOI 10.1109/91.649915; Kaymak U, 2002, IEEE T FUZZY SYST, V10, P705, DOI 10.1109/TFUZZ.2002.805901; Klieger PS, 1997, J NUCL MED, V38, P188; Kolen JF, 2002, IEEE T FUZZY SYST, V10, P263, DOI 10.1109/91.995126; Kuncheva LI, 2003, IEEE T FUZZY SYST, V11, P729, DOI 10.1109/TFUZZ.2003.819842; LACEY DJ, 1986, CLIN PEDIATR, V25, P433, DOI 10.1177/000992288602500901; Lampreave JL, 1998, J NUCL MED, V39, P624; Lee EW, 1998, IEEE T PATTERN ANAL, V20, P562; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; LEUNBERGER DG, 1989, LINEAR NONLINEAR PRO; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; MORIARTY J, 1995, BRIT J PSYCHIAT, V167, P249, DOI 10.1192/bjp.167.2.249; Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752; Sato K, 1996, IEEE T NUCL SCI, V43, P3230, DOI 10.1109/23.552723; SIEG KG, 1993, CLIN NUCL MED, V18, P255, DOI 10.1097/00003072-199303000-00022; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; STONE M, 1974, J R STAT SOC B, V36, P111; Theodoridis S., 1999, PATTERN RECOGNITION; Tolias YA, 1998, IEEE T MED IMAGING, V17, P263, DOI 10.1109/42.700738; Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389; Wang JS, 2002, IEEE T FUZZY SYST, V10, P790, DOI 10.1109/TFUZZ.2002.805880; Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29; ZADEH LA, 1994, IEEE SOFTWARE, V11, P48, DOI 10.1109/52.329401; 2001, SPM99	46	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-6706		IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	OCT	2005	13	5					673	687		10.1109/TFUZZ.2005.856558		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	974PT	WOS:000232604600009	
J	Ghosh, AK; Chaudhuri, P; Murthy, CA				Ghosh, AK; Chaudhuri, P; Murthy, CA			On visualization and aggregation of nearest neighbor classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian strength function; misclassification rates; multiscale visualization; neighborhood parameter; posterior probability; prior distribution; weighted averaging	CLASSIFICATION	Nearest neighbor classification is one of the simplest and most popular methods for statistical pattern recognition. A major issue in k-nearest neighbor classification is how to find an optimal value of the neighborhood parameter k. In practice, this value is generally estimated by the method of cross-validation. However, the ideal value of k in a classification problem not only depends on the entire data set, but also on the specific observation to be classified. Instead of using any single value of k, this paper studies results for a finite sequence of classifiers indexed by k. Along with the usual posterior probability estimates, a new measure, called the Bayesian measure of strength, is proposed and investigated in this paper as a measure of evidence for different classes. The results of these classifiers and their corresponding estimated misclassification probabilities are visually displayed using shaded strips. These plots provide an effective visualization of the evidence in favor of different classes when a given data point is to be classified. We also propose a simple weighted averaging technique that aggregates the results of different nearest neighbor classifiers to arrive at the final decision. Based on the analysis of several benchmark data sets, the proposed method is found to be better than using a single value of k.	Indian Stat Inst, Theoret Studies & Math Unit, Calcutta 700108, W Bengal, India; Indian Stat Inst, Machine Intelligence Unit, Calcutta 700108, W Bengal, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Studies & Math Unit, 203 BT Rd, Calcutta 700108, W Bengal, India.	anilkghosh@rediffmail.com; probal@isical.ac.in; murthy@isical.ac.in					Aho A.V., 1974, DESIGN ANAL COMPUTER; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED, P261; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1996, FLEXIBLE METRIC NEAR; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GHOSH AK, 2003, P 5 INT C ADV PATT R, P89; GHOSH AK, TECHNOMETRICS; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T, 2001, ELEMENTS STAT LEARNI; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P., 1936, P NATL I SCI INDIA, V12, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; PAIK M, 2004, STAT APPL GENETICS M, V3; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Ripley B. D., 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; SHALAK DB, 1996, THESIS U MASSACHUSET; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Wichern D. W., 1992, APPL MULTIVARIATE ST	40	17	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1592	1602		10.1109/TPAMI.2005.204		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	953OM	WOS:000231086700007	
J	Veenman, CJ; Reinders, MJT				Veenman, CJ; Reinders, MJT			The nearest subclass classifier: A compromise between the nearest mean and nearest neighbor classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; regularization; cross-validation; prototype selection	LEARNING ALGORITHMS; NEURAL NETWORKS; RULE; SELECTION; DESIGN; PROTOTYPES; SUBSET; BIAS; ABSTRACTION; SEPARATION	We present the Nearest Subclass Classifier (NSC), which is a classification algorithm that unifies the flexibility of the nearest neighbor classifier with the robustness of the nearest mean classifier. The algorithm is based on the Maximum Variance Cluster algorithm and, as such, it belongs to the class of prototype- based classifiers. The variance constraint parameter of the cluster algorithm serves to regularize the classifier, that is, to prevent overfitting. With a low variance constraint value, the classifier turns into the nearest neighbor classifier and, with a high variance parameter, it becomes the nearest mean classifier with the respective properties. In other words, the number of prototypes ranges from the whole training set to only one per class. In the experiments, we compared the NSC with regard to its performance and data set compression ratio to several other prototype- based methods. On several data sets, the NSC performed similarly to the k-nearest neighbor classifier, which is a well-established classifier in many domains. Also concerning storage requirements and classification speed, the NSC has favorable properties, so it gives a good compromise between classification performance and efficiency.	Delft Univ Technol, Dept Mediamat, NL-2600 GA Delft, Netherlands	Veenman, CJ (reprint author), Delft Univ Technol, Dept Mediamat, POB 5031, NL-2600 GA Delft, Netherlands.	C.J.Veenman@ewi.tudelft.nl; M.J.T.Reinders@ewi.tudelft.nl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bezdek J., 1981, PATTERN RECOGNITION; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Blake CL, 1998, UCI REPOSITORY MACHI; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224; Dunn J. C., 1974, Journal of Cybernetics, V4; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED, P261; Ganti V, 1999, COMPUTER, V32, P38, DOI 10.1109/2.781633; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Glover F., 1997, TABU SEARCH; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 2001, ELEMENTS STAT LEARNI; HENERY RJ, 1994, MACHINE LEARNING NEU, P107; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.2307/1267351; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Keogh E., 1997, P 14 INT C MACH LEAR, P406; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T, 1990, P INT JOINT C NEUR N, P545; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1999, IEEE T NEURAL NETWOR, V10, P1142, DOI 10.1109/72.788653; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SWONGER CW, 1972, FRONTIERS PATTERN RE, P511; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Veenman CJ, 2002, IEEE T PATTERN ANAL, V24, P1273, DOI 10.1109/TPAMI.2002.1033218; Veenman CJ, 2003, IEEE T IMAGE PROCESS, V12, P304, DOI 10.1109/TIP.2002.806256; WILFONG G, 1991, P 7 ANN ACM S COMP G, P224, DOI 10.1145/109648.109673; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193	54	45	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1417	1429		10.1109/TPAMI.2005.187		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	944XB	WOS:000230463300005	
J	Allouche, MK; Moulin, B				Allouche, MK; Moulin, B			Amalgamation in cartographic generalization using Kohonen's feature nets	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						amalgamation; cartographic generalization; Kohonen's feature nets	GESTALT	Empirical observations of the way cartographers deal with generalization problems lead to the hypothesis that they first detect patterns of anomalies in the cartographic data set and then eliminate anomalies by transforming the data. Automatically identifying patterns of anomalies on the map is a difficult task when using GIS functions or traditional algorithmic approaches. Techniques based on the use of neural networks have been widely used in artificial intelligence in order to solve pattern-recognition problems. In this paper, we explore how Kohonen-type neural networks can be used to deal with map generalization applications in which the main problem is to identify high-density regions that include cartographic elements of the same type. We also propose an algorithm to replace cartographic elements located in a region by its surrounding polygon. The use of this type of neural network permitted us to generate different levels of grouping according to the chosen zoom-scale on the map. These levels correspond to a multiple representation of the generalized cartographic elements. As an illustration, we apply our approach to the automatic replacement of a group of houses represented as a set of very close points in the original data set, by a polygon representing the corresponding urban area in the generalized map.	Def Res & Dev Canada, Val Belair, PQ G3J 1X5, Canada; Univ Laval, Dept Comp Sci, Ste Foy, PQ G1K 7P4, Canada; Univ Laval, Res Ctr Geomat, Ste Foy, PQ G1K 7P4, Canada	Allouche, MK (reprint author), Def Res & Dev Canada, 2459 Blvd,Pie XI N, Val Belair, PQ G3J 1X5, Canada.	mohamad.allouche@drdc-rddc.gc.ca	Wright, Dawn/A-4518-2011	Wright, Dawn/0000-0002-2997-7611			AHUJA N, 1989, COMPUT VISION GRAPH, V48, P304, DOI 10.1016/0734-189X(89)90146-1; ANDERS KH, 1999, SMATI 99 SEMANTIC MO; Anderson J., 1995, INTRO NEURAL NETWORK; ARMSTRONG MP, 1991, MAP GEN MAKING RULES, P86; BERGERON M, 1993, VOCABULAIRE GEOMATIQ; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bundy G., 1995, GIS GEN METHODOLOGY, P106; Cichocki A., 1993, NEURAL NETWORKS OPTI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fausett L., 1994, FUNDAMENTALS NEURAL; Friedman M, 1999, INTRO PATTERN RECOGN; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GRUNREICH D, 1992, 3 EUR C EXH GEOGR IN; HARRIE L, 2000, INT ARCH PHOTOGRAM B, V4, P348; HINTON G E, 1992, Scientific American, V267, P144; KELLER S, 1994, 6 INT S SPAT DAT HAN; Kohonen T, 1996, SOM PAK SELF ORG MAP; Kohonen T., 1995, HDB BRAIN THEORY NEU, P537; Kohonen T., 1984, SELF ORG ASS MEMORY; LAGRANGE JP, 1993, DT930538 I GEOGR NAT; McMaster R. B., 1992, GEN DIGITAL CARTOGRA; MCMASTER RB, 1991, GIS LIS C ATL GA; POHL I, 1969, BIDIRECTIONAL HEURES, P111; RIDDE D, 1996, SHARED WEIGHTS NEURA; Ripley B. D., 1996, PATTERN RECOGNITION; Ross IC, 1955, MANAGE SCI, V1, P251, DOI 10.1287/mnsc.1.3-4.251; RUAS A, 1999, MODELE GEN DONNEES G; RUMELHART DE, 1986, EXPLORATIONS MICROST, V1, P318; Sadahiro Y, 1997, CARTOGRAPHICA, V34, P49, DOI 10.3138/Y308-2422-8615-1233; SAVAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660; Sester M., 2000, INT ARCH PHOTOGRA B4, VXXXIII, P931; SESTER M, 2000, GISCIENCE 2000; SHLEGEL A, 1995, 17 INT CART C BARC E, P2211; WEIBEL R, 1998, GEN SPATIAL DATA DEA; WEIBEL R, 1995, 2 INT C SPAT INF THE, P141; Weibel R., 1991, MAP GEN MAKING RULES, P172; Weibel R., 1998, 8 INT S SPAT DAT HAN, P214; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; *ACI, 1973, DICT MULT TERM TECHN	40	4	6	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1365-8816		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	SEP-OCT	2005	19	8-9					899	914		10.1080/13658810500161211		16	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Computer Science; Geography; Physical Geography; Information Science & Library Science	975KM	WOS:000232661400003	
J	De Mantaras, RL; Mcsherry, D; Bridge, D; Leake, D; Smyth, B; Craw, S; Faltings, B; Maher, ML; Cox, MT; Forbus, K; Keane, M; Aamodt, A; Watson, I				De Mantaras, RL; Mcsherry, D; Bridge, D; Leake, D; Smyth, B; Craw, S; Faltings, B; Maher, ML; Cox, MT; Forbus, K; Keane, M; Aamodt, A; Watson, I			Retrieval, reuse, revision and retention in case-based reasoning	KNOWLEDGE ENGINEERING REVIEW			English	Review							NEAREST-NEIGHBOR RULE; RECOMMENDER SYSTEMS; SPECIAL-ISSUE; MAINTENANCE; EXPLANATION; SIMILARITY; KNOWLEDGE; ANALOGY; CLASSIFICATION; STRATEGIES	Case-based reasoning (CBR) is an approach to problem solving that emphasizes the role of prior experience during future problem solving (i.e., new problems are solved by reusing and if necessary adapting the solutions to similar problems that were solved in the past). It has enjoyed considerable success in a wide variety of problem solving tasks and domains. Following a brief overview of the traditional problem-solving cycle in CBR, we examine the cognitive science foundations of CBR and its relationship to analogical reasoning. We then review a representative selection of CBR research in the past few decades on aspects of retrieval, reuse, revision and retention.	CSIC, Artificial Intelligence Res Inst, Bellaterra 08193, Spain; Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland; Natl Univ Ireland Univ Coll Cork, Dept Comp Sci, Cork, Ireland; Indiana Univ, Dept Comp Sci, Bloomington, IN 47405 USA; Natl Univ Ireland Univ Coll Dublin, Sch Comp & Informat Sci, Dublin 4, Ireland; Robert Gordon Univ, Sch Comp, Aberdeen AB25 1HG, Scotland; Swiss Fed Inst Technol, AI Lab, CH-1015 Lausanne, Switzerland; Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia; BBN Technol, Cambridge, MA 02138 USA; Northwestern Univ, Dept EECS, Evanston, IL 60208 USA; Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway; Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand	De Mantaras, RL (reprint author), CSIC, Artificial Intelligence Res Inst, Campus UAB, Bellaterra 08193, Spain.	mantaras@iiia.csic.es; dmg.mcsherry@ulster.ac.uk; d.bridge@cs.ucc.ie; leake@cs.indiana.edu; Barry.Smyth@ucd.ie; S.Craw@comp.rgu.ac.uk; Boi.Faltings@epfl.ch; marym@it.usyd.edu.au; mcox@bbn.com; forbus@northwestern.edu; mark.keane@ucd.ie; agnar.aamodt@idi.ntnu.no; ian@cs.auckland.ac.nz	Forbus, Kenneth/B-7146-2009				Aamodt A., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; AAMODT A, 1994, AI COMMUN, V7, P39; Aamodt A., 2004, P 7 EUR C CAS BAS RE, P1; Aha D., 2000, APPL INTELL, V14, P9; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Aleven V, 2003, ARTIF INTELL, V150, P183, DOI 10.1016/S0004-3702(03)00105-X; ARCOS JL, 1997, P INT C CAS BAS REAS, P279; ARCOS JL, 1997, CSIC MONOGRAPHIES A, V3; Arcos JL, 2001, APPL INTELL, V14, P115, DOI 10.1023/A:1008311209823; ASHLEY KD, 1991, INT J MAN MACH STUD, V34, P753, DOI 10.1016/0020-7373(91)90011-U; ASHLEY KD, 1997, P IJCAI 97 NAG JAP, P335; ASHLEY KD, 1992, P 10 NAT C ART INT A, P654; ASHLEY KD, 1989, P 11 INT JOINT C ART, P537; BERGMANN R, 1999, P 7 GERM WORKSH CAS; Bergmann R., 2002, EXPERIENCE MANAGEMEN; BERGMANN R, 1998, P 4 EUR WORKSH CAS B, P25; BERGMANN R, 2001, P 9 GERM WORKSH CAS; BOGAERTS S, 2004, P 7 EUR C CAS BAS RE, P62; BONZANO A, 1997, P 2 INT C CAS BAS RE, P291; Borner K., 1993, P 1 EUR WORKSH CAS B, P197; BRANTING LK, 1991, INT J MAN MACH STUD, V34, P797, DOI 10.1016/0020-7373(91)90012-V; Bridge D, 2002, ARTIF INTELL REV, V18, P269, DOI 10.1023/A:1020743321429; BRIDGE D, 2002, P 6 EUR C CAS BAS RE, P43; Brown M. G., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Bunke H., 1993, P 1 EUR WORKSH CAS B, P106; Carbonell J., 1986, MACHINE LEARNING ART, VII, P371; Champin P. A., 2003, P 5 INT C CAS BAS RE, P80; Cohen P.R., 1985, HEURISTIC REASONING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox MT, 1999, ARTIF INTELL, V112, P1, DOI 10.1016/S0004-3702(99)00047-8; Craw S, 2001, COMPUT INTELL, V17, P346, DOI 10.1111/0824-7935.00149; CUNNINGHAM P, 2003, P 5 INT C CAS BAS RE, P122; de Mantaras RL, 2002, AI MAG, V23, P43; DOMESHEK E, 1992, THESIS NW U EVANSTON; Doyle D., 2004, P 7 EUR C CAS BAS RE, P157; Emde W., 1996, P 13 INT C MACH LEAR, P122; Falkenhainer B., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; FALTINGS B, 1997, ISSUES APPL CASE BAS, P39; FALTINGS B, 1997, P ICCBR 97, P611; Ferrario MA, 2001, COMPUT INTELL, V17, P315, DOI 10.1111/0824-7935.00147; Forbus KD, 2001, ANALOGICAL MIND, P23; FORBUS KD, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P313; Forbus K. D., 2003, Proceedings of the Fifteenth Innovative Applications of Artificial Intelligence Conference; FORBUS KD, 1995, COGNITIVE SCI, V19, P141, DOI 10.1207/s15516709cog1902_1; Fox S, 2001, J EXP THEOR ARTIF IN, V13, P63, DOI 10.1080/09528130010029794; Fox S, 1995, P 14 INT JOINT C ART, P391; FRANCIS AG, 1995, P 8 EUR C MACH LEARN, P138; FUCHS B, 1999, P 3 INT C CAS BAS RE, P118; GABEL T, 2004, P 7 EUR C CAS BAS RE, P169; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1016/S0364-0213(83)80009-3; GENTNER D, 1991, PROGRAM OF THE THIRTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P504; Gentner D, 2001, ANALOGICAL MIND PERS; GENTNER D, 1993, COGNITIVE PSYCHOL, V25, P524, DOI 10.1006/cogp.1993.1013; GICK ML, 1980, COGNITIVE PSYCHOL, V12, P306, DOI 10.1016/0010-0285(80)90013-4; GOEL A, 1991, P DARPA CAS BAS REAS, P109; GOEL AK, 1989, P DARPA WORKSH CAS B, P100; Gomez de Silva Garza A., 2000, P ART INT DES C, P393; Hammond K. J., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; HAMMOND KJ, 1990, ARTIF INTELL, V45, P173, DOI 10.1016/0004-3702(90)90040-7; Hanney K., 1997, P 2 INT C CAS BAS RE, P359; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037//0033-295X.104.3.427; IGLEZAKIS I, 2004, P 7 EUR C CAS BAS RE, P227; JANTKE KP, 1994, P JAHRESTAGUNG GES K, P29; Jarmulak J., 2001, P 17 INT JOINT C ART, P1011; KASS A, 1986, EXPLANATION PATTERNS, P232; KASS A, 1989, P CAS BAS REAS WORKS, P119; Keane M. T., 1995, P 14 INT JOINT C ART, P377; Keane M. T., 1994, COGNITIVE SCI, V18, P287; KEANE MT, 1988, P 3 EUR WORK SESS LE; KOKINOV B, 2003, ENCY COGNITIVE SCI, P113; Kolodner J., 1996, CASE BASED REASONING, P349; Kolodner J., 1993, CASE BASED REASONING; KOLODNER JL, 1994, BELIEFS REASONING DE; Kolodner JL, 2003, J LEARN SCI, V12, P495, DOI 10.1207/S15327809JLS1204_2; Koton P, 1988, P AAAI 88, P256; Larkey LB, 2003, COGNITIVE SCI, V27, P781, DOI 10.1016/S0364-0213(03)00066-1; Leake D, 2005, ARTIF INTELL REV, V24, P103, DOI 10.1007/s10462-005-4606-8; LEAKE D, 1995, P 1 INT C CAS BAS RE, P229; LEAKE D, 1998, COMPANION COGNITIVE, P465; LEAKE D, 2000, P 5 EUR WORKSH CAS B, P161; Leake D. B., 1996, CASE BASED REASONING, P3; Leake D. B., 1992, EVALUATING EXPLANATI; LEAKE DB, 1991, COGNITIVE SCI, V15, P509, DOI 10.1207/s15516709cog1504_2; LEAKE DB, 1997, P 14 NAT C ART INT, P674; Leake DB, 2001, COMPUT INTELL, V17, P193, DOI 10.1111/0824-7935.00139; Leake D. B., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, DOI 10.1142/S0218213004001508; Leake D.B., 1996, CASE BASED REASONING; LEAKE DB, 1999, P 3 INT C CAS BAS RE, P218; LEI C, 1999, P 3 INT C CAS BAS RE, P233; LENZ M, 1996, P 3 EUR WORKSH CAS B, P219; Lenz Mario, 1998, CASE BASED REASONING; Markman AB, 2001, ANNU REV PSYCHOL, V52, P223, DOI 10.1146/annurev.psych.52.1.223; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; Mcginty L., 2003, P 5 INT C CAS BAS RE, P276; MCKENNA E, 2000, P 5 EUR WORKSH CAS B, P186; Mckenna E., 1999, P 3 INT C CAS BAS RE, P343; MCKENNA E, 2001, P 21 BCS SGES INT C, P97; McKenna E., 2000, P 14 EUR C ART INT, P60; MCSHERRY D, 2004, P 7 EUR C CAS BAS RE, P317; McSherry D., 2002, P 6 EUR C CAS BAS RE, P219; MCSHERRY D, 1998, P 4 EUR WORKSH CAS B, P184; McSherry D, 2001, APPL INTELL, V14, P65, DOI 10.1023/A:1008355024844; Mcsherry D., 2003, P 5 INT C CAS BAS RE, P291; MCSHERRY D, 2004, P 7 EUR C CAS BAS RE, P331; McSherry D, 2001, COMPUT INTELL, V17, P331, DOI 10.1111/0824-7935.00148; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; MCSHERRY D, 2000, KNOWL-BASED SYST, V13, P65; McSherry D., 2003, P 18 INT JOINT C ART, P121; MCSHERRY D, 1999, P 16 INT JOINT C ART, P222; McSherry D, 2004, KNOWL-BASED SYST, V17, P113, DOI 10.1016/j.knosys.2004.03.006; MCSHERRY D, 2001, P 17 INT JOINT C ART, P993; MCSHERRY D, 2001, P 4 INT C CAS BAS RE, P392; MINTON S, 1990, ARTIF INTELL, V42, P363, DOI 10.1016/0004-3702(90)90059-9; Mougouie B., 2002, P 6 EUR C CAS BAS RE, P249; Munoz-Avila H, 2001, COMPUT INTELL, V17, P280, DOI 10.1111/0824-7935.00145; MUNOZAVILA H, 1996, P 3 EUR WORKSH CAS B, P280; Nick M, 2001, COMPUT INTELL-US, V17, P364, DOI 10.1111/0824-7935.00150; ONTANON S, 2003, P 5 INT C CAS BAS RE, P392; OSBORNE HR, 1996, P 3 EUR WORKSH CAS B, P309; OSBORNE HR, 1997, P 2 INT C CAS BAS RE, P235; PATEL VL, 1986, COGNITIVE SCI, V10, P91, DOI 10.1207/s15516709cog1001_4; PLAZA E, 1995, P 1 INT C CAS BAS RE, P265; PORTER BW, 1990, ARTIF INTELL, V45, P229, DOI 10.1016/0004-3702(90)90041-W; Portinale L, 2001, COMPUT INTELL, V17, P263, DOI 10.1111/0824-7935.00144; PURVIS L, 1995, P 1 INT C CAS BAS RE, P289; RACINE K, 1997, P 2 INT C CAS BAS RE, P553; Ramscar M, 2003, COGNITIVE SCI, V27, P41, DOI 10.1016/S0364-0213(02)00113-1; Reinartz T, 2001, COMPUT INTELL-US, V17, P214, DOI 10.1111/0824-7935.00141; RICHARDSON MJ, 1992, PRACTICAL PLACER MINING, P1; Riesbeck C., 1989, INSIDE CASE BASED RE; RISSLAND EL, 1984, P 4 NAT C ART INT, P288; RISSLAND EL, 1991, INT J MAN MACH STUD, V34, P839, DOI 10.1016/0020-7373(91)90013-W; Salamo MGolobardesE, 2002, P 6 EUR C CAS BAS RE, P365; SCHAAF JW, 1996, P 3 EUR WORKSH CAS B, P362; SCHANK R, 1990, 1 NW U I LEARN SCI; Schank R. C., 1977, SCRIPTS PLANS GOALS; Schank R. C., 1982, DYNAMIC MEMORY THEOR; Schank R. C., 1994, J LEARN SCI, V3, P305; SCHANK RC, 1989, ARTIF INTELL, V40, P353, DOI 10.1016/0004-3702(89)90053-2; Schank Roger C., 1994, INSIDE CASE BASED EX; Schank Roger C., 1986, EXPLANATION PATTERNS; SHIMAZU H, 1996, P 13 NAT C ART INT, V1, P690; SHIU SCK, 2001, COMPUT INTELL, V17, P214; SIMOUDIS E, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P310; Smyth B, 2001, COMPUT INTELL-US, V17, P235, DOI 10.1111/0824-7935.00142; Smyth B, 1996, KNOWL-BASED SYST, V9, P127, DOI 10.1016/0950-7051(95)01024-6; Smyth B, 2001, KNOWL-BASED SYST, V14, P155, DOI 10.1016/S0950-7051(01)00092-2; Smyth B., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; SMYTH B, 1995, P 1 INT C CAS BAS RE, P313; SMYTH B, 1998, P 4 EUR WORKSH CAS B, P208; SMYTH B, 1998, P 11 INT C IND ENG A, P507; Smyth B., 2001, P 4 INT C CAS BAS RE, P347; Smyth B., 1996, P392; SMYTH B, 2000, P 11 EUR C MACH LEAR, P357; Smyth B, 1998, ARTIF INTELL, V102, P249, DOI 10.1016/S0004-3702(98)00059-9; SORMO F, 2005, ARTIF INTELL, V24, P103; SORMO F, 2004, P ECCBR 2004 WORKSH, P165; Stahl A., 2003, P 5 INT C CAS BAS RE, P537; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Faltings B, 1996, COMPUT AIDED DESIGN, V28, P207, DOI 10.1016/0010-4485(95)00027-5; SURMA J, 1998, P 4 EUR WORKSH CAS B, P233; TARTAKOVSKI A, 2004, P 7 EUR C CAS BAS RE, P404; TOMEK I, 1976, IEEE T SYST MAN CYB, V7, P679; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; VELOSO M, 1994, MACH LEARN, V4, P523; VELOSO M, 1994, PLANNING LEARNING AN; Watson I., 1997, APPL CASE BASED REAS; Wess S., 1993, P 1 EUR WORKSH CAS B, P167; Wettschereck D., 1995, P 1 INT C CAS BAS RE, P347; WILKE W, 1996, P 3 EUR WORKSH CAS B, P460; Wilke W., 1997, P 5 GERM WORKSH CAS, P235; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DC, 2001, COMPUT INTELL-US, V17, P196, DOI 10.1111/0824-7935.00140; Wilson D.R., 1997, P 14 INT C MACH LEAR, P403; WIRATUNGA N, 2002, P 6 EUR C CAS BAS RE, P423; WIRATUNGA N, 2003, P 5 INT C CAS BAS RE, P637; WOLVERTON M, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P56; WOON F, 2003, P 5 INT C CAS BAS RE, P652; Yang Q, 2001, COMPUT INTELL, V17, P250, DOI 10.1111/0824-7935.00143; Zhu J, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P234	184	41	41	CAMBRIDGE UNIV PRESS	NEW YORK	40 WEST 20TH ST, NEW YORK, NY 10011-4211 USA	0269-8889		KNOWL ENG REV	Knowl. Eng. Rev.	SEP	2005	20	3					215	240		10.1017/S0269888906000646		26	Computer Science, Artificial Intelligence	Computer Science	049PF	WOS:000238027800004	
J	Shen, HB; Chou, KC				Shen, HB; Chou, KC			Using optimized evidence-theoretic K-nearest neighbor classifier and pseudo-amino acid composition to predict membrane protein types	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						evidence theory; KNN classifier; pseudo-amino acid composition; type-I membrane protein; type-II membrane protein; multipass transmembrane protein; lipid-chain-anchored membrane protein; GPI-anchored membrane protein	FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; SUBCELLULAR LOCATION PREDICTION; SORTING SIGNALS; FOLDING TYPES; LOCALIZATION; REPRESENTATION; SPACE; RULE	Knowledge of membrane protein type often provides crucial hints toward determining the function of an uncharacterized membrane protein. With the avalanche of new protein sequences emerging during the post-genomic era, it is highly desirable to develop an automated method that can serve as a high throughput tool in identifying the types of newly found membrane proteins according to their primary sequences, so as to timely make the relevant annotations on them for the reference usage in both basic research and drug discovery. Based on the concept of pseudo-amino acid composition [K.C. Chou, Proteins: Struct. Funct. Genet. 43 (2001) 246255; Erratum: Proteins: Struct. Funct. Genet. 44 (2001) 60] that has made it possible to incorporate a considerable amount of sequence-order effects by representing a protein sample in terms of a set of discrete numbers, a novel predictor, the so-called "optimized evidence-theoretic K-nearest neighbor" or "OET-KNN" classifier, was proposed. It was demonstrated via the self-consistency test, jackknife test, and independent dataset test that the new predictor, compared with many previous ones, yielded higher success rates in most cases. The new predictor can also be used to improve the prediction quality for, among many other protein attributes, structural class, subcellular localization, enzyme family class, and G-protein coupled receptor type. The OET-KNN classifier will be available as a web-server at www.pami.sjtu.edu.cn/kcchou. (c) 2005 Elsevier Inc. All rights reserved.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				ALBERTS B, 1994, MOL BIOL CELL, pCH1; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2001, J BIOMOL STRUCT DYN, V18, P607; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2005, BIOCHEM BIOPH RES CO, V327, P845, DOI 10.1016/j.bbrc.2004.12.069; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; CHOU KC, 2004, J CELL BIOCHEM, V1291, P1085; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2000, J PROTEIN CHEM, V19, P269, DOI 10.1023/A:1007091128394; LODISH H, 1995, MOL CELL BIOL, pCH3; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Shafer G., 1976, MATH THEORY EVIDENCE; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	51	103	106	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X		BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	AUG 19	2005	334	1					288	292		10.1016/j.bbrc.2005.06.087		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	948MH	WOS:000230719400040	
J	Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G				Prank, K; Schulze, E; Eckert, O; Nattkemper, TW; Bettendorf, M; Maser-Gluth, C; Sejnowski, TJ; Grote, A; Penner, E; von zur Muhlen, A; Brabant, G			Machine learning approaches for phenotype-genotype mapping: predicting heterozygous mutations in the CYP21B gene from steroid profiles	EUROPEAN JOURNAL OF ENDOCRINOLOGY			English	Article							CONGENITAL ADRENAL-HYPERPLASIA; ARTIFICIAL NEURAL NETWORKS; PCR-BASED DIAGNOSIS; 21-HYDROXYLASE DEFICIENCY; STEROID-21-HYDROXYLASE; CLASSIFICATION; INTRON-2; WOMEN	Objective: Non-linear relations between multiple biochemical parameters are the basis for the diagnosis of many diseases. Traditional linear analytical methods are not reliable predictors. Novel nonlinear techniques are increasingly used to improve the diagnostic accuracy of automated data interpretation. This has been exemplified in particular for the classification and diagnostic prediction of cancers based on expression profiling data. Our objective was to predict the genotype from complex biochemical data by comparing the performance of experienced clinicians to traditional linear analysis, and to novel non-linear analytical methods. Design and methods: As a model, we used a well-defined set of interconnected data consisting of unstimulated serum levels of steroid intermediates assessed in 54 subjects heterozygous for a mutation of the 21-hydroxylase gene (CYP21B) and in 43 healthy controls. Results: The genetic alteration was predicted from the pattern of steroid levels with an accuracy of 39% by clinicians and of 64% by linear analysis. In contrast, non-linear analysis, such as self-organizing artificial neural networks, support vector machines, and nearest neighbour classifiers, allowed for higher accuracy up to 83%. Conclusions: The successful application of these non-linear adaptive methods to capture specific biochemical problems may have generalized implications for biochemical testing in many areas. Nonlinear analytical techniques such as neural networks, support vector machines, and nearest neighbour classifiers may serve as an important adjunct to the decision process of a human investigator not ' trained ' in a specific complex clinical or laboratory setting and may aid them to classify the problem more directly.	Univ Bielefeld, Int NRW Grad Sch Bioinformat, D-33615 Bielefeld, Germany; Univ Bielefeld, Genome Res Ctr Biotechnol, D-33615 Bielefeld, Germany; Hannover Med Sch, D-30625 Hannover, Germany; Mol Genet Lab Raue, D-69121 Heidelberg, Germany; Hannover Med Sch, Dept Visceral & Transplantat Surg, D-30623 Hannover, Germany; Hannover Med Sch, Dept Clin Endocrinol, D-30623 Hannover, Germany; Univ Bielefeld, Fac Technol, Appl Neuroinformat Grp, D-33615 Bielefeld, Germany; Univ Heidelberg, Dept Pediat, D-69120 Heidelberg, Germany; Univ Heidelberg, Dept Pharmacol, D-69120 Heidelberg, Germany; Salk Inst, Howard Hughes Med Inst, San Diego, CA 92186 USA; Salk Inst, Computat Neurobiol Lab, San Diego, CA 92186 USA	Prank, K (reprint author), Univ Bielefeld, Int NRW Grad Sch Bioinformat, D-33615 Bielefeld, Germany.	klaus.prank@cebitec.uni-bielefeld.de					Azziz R, 1997, FERTIL STERIL, V68, P183; Baxt WG, 1996, LANCET, V347, P12, DOI 10.1016/S0140-6736(96)91555-X; BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3; Bishop C. M., 1995, NEURAL NETWORKS PATT; Blanche H, 1997, HUM GENET, V101, P56, DOI 10.1007/s004390050586; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2; Day DJ, 1996, HUM MOL GENET, V5, P2039, DOI 10.1093/hmg/5.12.2039; Dhanasekaran SM, 2001, NATURE, V412, P822, DOI 10.1038/35090585; FIET J, 1994, ANN CLIN BIOCHEM, V31, P56; GRUNWALD K, 1990, GYNECOL ENDOCRINOL, V4, P287, DOI 10.3109/09513599009024983; KEERTHI SS, 1999, CD9914 TR NAT U SING; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1982, BIOL CYBERN, V44, P135, DOI 10.1007/BF00317973; KOZOWER M, 1974, J CLIN ENDOCR METAB, V38, P407; Martinerie J, 1998, NAT MED, V4, P1173, DOI 10.1038/2667; MARTINETZ T, 1994, NEURAL NETWORKS, V7, P507, DOI 10.1016/0893-6080(94)90109-0; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; Mika S., 1999, NEURAL NETWORKS SIGN, VIX, P41; MOREIRA AC, 1992, J CLIN ENDOCR METAB, V74, P198, DOI 10.1210/jc.74.1.198; NEW MI, 1994, J STEROID BIOCHEM, V48, P15, DOI 10.1016/0960-0760(94)90246-1; Platt J, 1998, ADV KERNEL METHODS S; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; SCHULZE E, 1995, ENDOCR RES, V21, P359; Schulze E, 1998, ENDOCR RES, V24, P637; SPEISER PW, 2003, ENGLAND J MED, V21, P776; Tarassenko L., 1998, GUIDE NEURAL COMPUTI; Vapnik V.N., 1995, NATURE STAT LEARNING; WILSON RC, 1995, J CLIN ENDOCR METAB, V80, P2322, DOI 10.1210/jc.80.8.2322	30	1	1	BIO SCIENTIFICA LTD	BRISTOL	EURO HOUSE, 22 APEX COURT WOODLANDS, BRADLEY STOKE, BRISTOL BS32 4JT, ENGLAND	0804-4643		EUR J ENDOCRINOL	Eur. J. Endocrinol.	AUG	2005	153	2					301	305		10.1530/eje.1.01957		5	Endocrinology & Metabolism	Endocrinology & Metabolism	961YS	WOS:000231698400016	
J	Zhu, HW; Basir, O				Zhu, HW; Basir, O			An adaptive fuzzy evidential nearest neighbor formulation for classifying remote sensing images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						adaptive fuzzy evidential reasoning; Dempster-Shafer evidence theory (DSET); image classification; K-nearest neighbor algorithm; remote sensing	DEMPSTER-SHAFER THEORY; SUPERVISED CLASSIFICATION; BELIEF STRUCTURES; NEURAL-NETWORKS; SENSED DATA; SELECTION; CLASSIFIERS; RULE; UNCERTAINTY; ALGORITHMS	The paper presents a novel adaptive fuzzy evidential nearest neighbor formulation for classifying remotely sensed images. The formulation combines the generalized fuzzy version of the Dempster-Shafer evidence theory (DSET) and the K-nearest neighbor (KNN) algorithm. Each of the K nearest neighbors provides evidence on the belongingness of the input pattern to be classified, and it is evaluated based on a measure of disapproval to achieve the adaptive capability during the classification process. The disapproval measure quantifies the lack of support with respect to the belongingness of the input pattern to a given class. Pieces of evidence are ranked based on their degree of disapproval and fused in a sequential manner. The pignistic Shannon entropy is used to estimate the degree of consensus among pieces of evidence provided by nearest neighbors and as a criterion for terminating the evidence fusion process. The paper reports the results of experimental work conducted to evaluate the proposed classification scheme using real multichannel remote sensing images. As will be demonstrated using the experimental results, the proposed classification scheme demonstrated robust performance and outperformed commonly used methods such as the K-nearest neighbor algorithm of Cover and Hart (1967), the fuzzy K-nearest neighbor algorithm of Keller et aL (1985), the evidence-theoretic K-nearest neighbor algorithm of Denoex (1995), and its fuzzy version of Zouhal and Denoex (1997). The performance of these techniques is examined with respect to the K-parameter and classification accuracy.	Univ Waterloo, Dept Elect & Comp Engn, Pattern Anal & Machine Intelligence Res Grp, Waterloo, ON N2L 3G1, Canada	Zhu, HW (reprint author), Univ Waterloo, Dept Elect & Comp Engn, Pattern Anal & Machine Intelligence Res Grp, Waterloo, ON N2L 3G1, Canada.	h4zhu@engmail.uwaterloo.ca; obasir@uwaterloo.ca	Zhu, Howard/E-7683-2010				Aminzadeh F., 1994, SOFT COMPUTING FUZZY; Binaghi E, 1997, IEEE T GEOSCI REMOTE, V35, P326, DOI 10.1109/36.563272; Binaghi E, 1999, INT J INTELL SYST, V14, P559, DOI 10.1002/(SICI)1098-111X(199906)14:6<559::AID-INT2>3.0.CO;2-#; Bishop C. M., 1995, NEURAL NETWORKS PATT; Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P429, DOI 10.1109/36.823938; Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1179, DOI 10.1109/36.752239; CONGALTON RG, 1986, IEEE T GEOSCI REMOTE, V24, P169, DOI 10.1109/TGRS.1986.289546; COPPIN PR, 1994, IEEE T GEOSCI REMOTE, V32, P918, DOI 10.1109/36.298020; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dubois D., 1982, FUZZY INFORM DECISIO, P167; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fabre S, 2002, IEEE T GEOSCI REMOTE, V40, P1997, DOI 10.1109/TGRS.2002.805143; Fix E., 1951, 4 USAF SCH AV MED; Foody GM, 2000, COMPUT GEOSCI-UK, V26, P469, DOI 10.1016/S0098-3004(99)00125-9; Giacinto G, 2000, ELECTRON LETT, V36, P420, DOI 10.1049/el:20000374; Giacinto G, 2000, PATTERN RECOGN LETT, V21, P385, DOI 10.1016/S0167-8655(00)00006-4; Hastie T, 2001, ELEMENTS STAT LEARNI; HUDSON WD, 1987, PHOTOGRAMM ENG REM S, V53, P421; ISHIZUKA M, 1982, INFORM SCIENCES, V28, P179, DOI 10.1016/0020-0255(82)90047-0; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T, 1995, LVQ PAK LEARNING VEC; Le H`egarat-Mascle S, 1997, IEEE T GEOSCI REMOTE, V35, P1018; OGAWA H, 1985, INT J MAN MACH STUD, V22, P295, DOI 10.1016/S0020-7373(85)80005-5; PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684; SERPICO SB, 1995, IEEE T GEOSCI REMOTE, V33, P562, DOI 10.1109/36.387573; Serpico SB, 1996, PATTERN RECOGN LETT, V17, P1331, DOI 10.1016/S0167-8655(96)00090-6; Shafer G., 1976, MATH THEORY EVIDENCE; SINGH A, 1989, INT J REMOTE SENS, V10, P989; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smits PC, 2002, IEEE T GEOSCI REMOTE, V40, P801, DOI 10.1109/TGRS.2002.1006354; Solaiman B, 1999, IEEE T GEOSCI REMOTE, V37, P1316, DOI 10.1109/36.763295; WANG F, 1990, IEEE T GEOSCI REMOTE, V28, P194, DOI 10.1109/36.46698; Wirth N., 1986, ALGORITHMS DATA STRU; YAGER RR, 1995, IEEE T SYST MAN CYB, V25, P1221, DOI 10.1109/21.398683; Yager RR, 1996, INT J APPROX REASON, V14, P127, DOI 10.1016/0888-613X(96)00092-8; YAGER RR, 1982, INFORM SCIENCES, V28, P45, DOI 10.1016/0020-0255(82)90031-7; YEN J, 1990, IEEE T SYST MAN CYB, V20, P559, DOI 10.1109/21.57269; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5; ZHU H, 2003, P 7 JOINT C INF SCI, P26; ZHU H, 2003, P 10 IEEE INT C EL C, P1070; ZOUHAL LM, 1997, P 2 INT ICSC S FUZZ, P294	43	24	25	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	AUG	2005	43	8					1874	1889				16	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	949BX	WOS:000230761000018	
J	Wong, JWH; Cartwright, HM				Wong, JWH; Cartwright, HM			Deterministic projection by growing cell structure networks for visualization of high-dimensionally datasets	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						random projection; growing cell structure networks; high-dimensionality data; data visualization; feature transformation; topology preserving maps; self-organizing maps; clinical proteomics dataset	PROTEOMIC PATTERNS; LINDENSTRAUSS; JOHNSON; CANCER; SERUM; MAPS	Recent advances in clinical proteomics data acquisition have led to the generation of datasets of high complexity and dimensionality. We present here a visualization method for high-dimensionality datasets that makes use of neuronal vectors of a trained growing cell structure (GCS) network for the projection of data points onto two dimensions. The use of a GCS network enables the generation of the projection matrix deterministically rather than randomly as in random projection. Three datasets were used to benchmark the performance and to demonstrate the use of this deterministic projection approach in real-life scientitic applications. Comparisons are made to an existing self-organizing map projection method and random projection. The results suggest that deterministic projection outperforms existing methods and is suitable for the visualization of datasets of very high dimensionality. (c) 2005 Elsevier Inc. All rights reserved.	Univ Oxford, Dept Chem, Phys & Theoret Chem Lab, Oxford OX1 3QZ, England	Wong, JWH (reprint author), Univ Oxford, Dept Chem, Phys & Theoret Chem Lab, S Parks Rd, Oxford OX1 3QZ, England.	jason.wong@chem.ox.ac.uk	Wong, Jason/A-9466-2008	Wong, Jason/0000-0003-2953-7728			Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4; Arriaga Rosa I., 1999, P 40 ANN S FDN COMP, P616; Bingham E., 2001, ACM SIGKDD INT C KNO, P245; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073; Dasgupta S., 2000, P 16 C UNC ART INT, P143; Ferguson PL, 2003, ANNU REV BIOPH BIOM, V32, P399, DOI 10.1146/annurev.biophys.32.110601.141854; Fern XZ, 2003, P 20 INT C MACH LEAR, P186; Forina M., 1991, PARVUS EXTENDIBLE PA; FRITZKE B, 1993, ADV NEURAL INFORMATI, V5, P123; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GROUB GH, 1989, MATRIX COMP; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Jackson J E, 1991, USERS GUIDE PRINCIPA; Johnson W. B., 1984, CONT MATH, V26, P189; KASKI S, 1999, P INT JOINT C NEUR N, P413; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; ULTSCH A, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P305; Wu Zheng, 2003, Int J Neural Syst, V13, P353, DOI 10.1142/S0129065703001662	26	3	4	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	AUG	2005	38	4					322	330		10.1016/j.jbi.2005.02.002		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	959JO	WOS:000231514200010	
J	Viswanath, P; Murty, MN; Bhatnagar, S				Viswanath, P; Murty, MN; Bhatnagar, S			Overlap pattern synthesis with an efficient nearest neighbor classifier	PATTERN RECOGNITION			English	Article						nearest neighbor classifier; pattern synthesis; compact representation; data mining	ERROR RATE ESTIMATION; BOOTSTRAP	Nearest neighbor (NN) classifier is the most popular non-parametric classifier. It is a simple classifier with no design phase and shows good performance. Important factors affecting the efficiency and performance of NN classifier are (i) memory required to store the training set, (ii) classification time required to search the nearest neighbor of a given test pattern, and (iii) due to the curse of dimensionality the number of training patterns needed by it to achieve a given classification accuracy becomes prohibitively large when the dimensionality of the data is high. In this paper, we propose novel techniques to improve the performance of NN classifier and at the same time to reduce its computational burden. These techniques are broadly based on: (i) overlap based pattern synthesis which can generate a larger number of artificial patterns than the number of input patterns and thus can reduce the curse of dimensionality effect, (ii) a compact representation of the given set of training patterns called overlap pattern graph (OLP-graph) which can be incrementally built by scanning the training set only once and (iii) an efficient NN classifier called OLP-NNC which directly works with OLP-graph and does implicit overlap based pattern synthesis. A comparison based on experimental results is given between some of the relevant classifiers. The proposed schemes are suitable for applications dealing with large and high dimensional datasets like those in data mining. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Bhatnagar, S (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.	viswanath@csa.iisc.ernet.in; mnn@csa.iisc.ernet.in; shalabh@csa.iisc.ernet.in					Ananthanarayana VS, 2001, PATTERN RECOGN, V34, P2249, DOI 10.1016/S0031-3203(01)00028-0; Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; CHERNICK MR, 1985, PATTERN RECOGN LETT, V3, P167, DOI 10.1016/0167-8655(85)90049-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Draper D., 1994, P 10 C UNC ART INT, P170; Duda R.O., 2000, PATTERN CLASSIFICATI; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 11 USAF SCH AV MED; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Fukunaga K., 1990, INTRO STAT PATTERN R; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Han J., 2000, P ACM SIGMOD INT C M; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Kozlov A. V., 1995, P 11 ANN C UNC ART I, P376; Murphy P., 1994, UCI REPOSITORY MACHI; TIAN Z, 1996, P ACM SIGMOD INT C M; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516	22	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	AUG	2005	38	8					1187	1195		10.1016/j.patcog.2004.10.007		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	933YW	WOS:000229669900004	
J	Raicharoen, T; Lursinsap, C				Raicharoen, T; Lursinsap, C			A divide-and-conquer approach to the pairwise opposite class-nearest neighbor (POC-NN) algorithm	PATTERN RECOGNITION LETTERS			English	Article						pattern classification; nearest neighbor rule; prototype selection; prototype replacement	RULE; CLASSIFICATION	This paper presents a new method based on divide-and-conquer approach to the selection and replacement of a set of prototypes from the training set for the nearest neighbor rule, This method aims at reducing the computational time and the memory space as well as the sensitivity of the order and the noise of the training data. A reduced prototype set contains Pairwise Opposite Class-Nearest Neighbor (POC-NN) prototypes which are close to the decision boundary and used instead of the training patterns. POC-NN prototypes are obtained by recursively iterative separation and analysis of the training data into two regions until each region is correctly grouped and classified, The separability is determined by the POC-NN prototypes essential to define the locations of all separating hyperplaries, Our method is fast and order independent. The number of prototypes and the overfitting of the model can be reduced by the User, The experimental results signify the effectiveness of this technique and its performance in both accuracy and prototype rate as well as in training time to those obtained by classical nearest neighbor techniques. (c) 2005 Elsevier B.V. All rights reserved.	Chulalongkorn Univ, Fac Sci, Adv Virtual & Intelligent Comp Ctr AVIC, Dept Math, Bangkok 10330, Thailand	Raicharoen, T (reprint author), Chulalongkorn Univ, Fac Sci, Adv Virtual & Intelligent Comp Ctr AVIC, Dept Math, Bangkok 10330, Thailand.	thanapant@avic.sc.chula.ac.th; lchidcha@chula.ac.th					Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Burr Ridge I, 1997, MACHINE LEARNING; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Devi VS, 2002, PATTERN RECOGN, V35, P505; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L, 1996, PROBABILISTIC THEORY; Duda R. O., 2001, PATTERN CLASSIFICATI; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; HART PE, 1966, SEL66016; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T. J., 2001, SPRINGER SERIES STAT; Hayter A. J., 2002, PROBABILITY STAT ENG; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; MCCLAVE JT, 2001, STAT BUSINESS EC; Michie D, 1994, MACHINE LEARNING NEU; Murphy P., 1994, UCI REPOSITORY MACHI; RITTER GL, 1975, IEEE T INFORM THEORY, V23, P1179; ROOBAERT D, 2000, P IEEE INT WORKSH NE; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOUSSAINT G, 2002, P 34 S COMP STAT MON; TOUSSAINT GT, 1994, PATTERN RECOGN LETT, V15, P797, DOI 10.1016/0167-8655(94)90007-8; Vapnik V.N., 1998, STAT LEARNING THEORY; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; *USPS, 1994, MACH LEARN NEUR STAT	30	8	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUL 15	2005	26	10					1554	1567		10.1016/j.patrec.2005.01.003		14	Computer Science, Artificial Intelligence	Computer Science	938MF	WOS:000230006800015	
J	Domeniconi, C; Gunopulos, D; Peng, J				Domeniconi, C; Gunopulos, D; Peng, J			Large margin nearest neighbor classifiers	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						feature relevance; margin; nearest neighbor classification; support vector machines (SVMs)	SUPPORT VECTOR MACHINES; CLASSIFICATION; REGRESSION	The nearest neighbor technique is a simple and appealing approach to addressing classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. The employment of a locally adaptive metric becomes crucial in order to keep class conditional probabilities close to uniform, thereby minimizing the bias of estimates. We propose a technique that computes a locally flexible metric by means of support vector machines (SVMs). The decision function constructed by SVMs is used to determine the most discriminant direction in a neighborhood around the query. Such a direction provides a local feature weighting scheme. We formally show that our method increases the margin in the weighted space where classification takes place. Moreover, our method has the important advantage of online computational efficiency over competing locally adaptive techniques for nearest neighbor classification. We demonstrate the efficacy of our method using both real and simulated data.	George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA; Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA; Tulane Univ, Elect Engn & Comp Sci Dept, New Orleans, LA 70118 USA	Domeniconi, C (reprint author), George Mason Univ, Informat & Software Engn Dept, Fairfax, VA 22030 USA.	carlotta@ise.gmu.edu; dg@cs.ucr.edu; jp@eecs.tulane.edu					Aha D. W., 1997, ARTIF INTELL, V11, P1; AKAHO S, 2002, P 6 KERN MACH WORKSH, P1; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Hardy G.H., 1973, INEQUALITIES; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Ho T.K., 1998, LECT NOTES COMPUTER, P640; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Peng J, 2003, IEEE T NEURAL NETWOR, V14, P940, DOI 10.1109/TNN.2003.813835; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rifkin R, 2004, J MACH LEARN RES, V5, P101; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING	28	31	34	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	JUL	2005	16	4					899	909		10.1109/TNN.2005.849821		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	945MC	WOS:000230505600011	
J	Gao, QB; Wang, ZZ; Yan, C; Du, YH				Gao, QB; Wang, ZZ; Yan, C; Du, YH			Prediction of protein subcellular location using a combined feature of sequence	FEBS LETTERS			English	Article						protein subcellular location; combined feature; amino acid composition; dipeptide composition; physicochemical property; nearest neighbor; jackknife test	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; SORTING SIGNALS; TRANSMEMBRANE PROTEINS; LOCALIZATION SITES; PEPTIDES; REPRESENTATION	To understand the structure and function of a protein , an important task is to know where it occurs in the cell. Thus, a computational method for properly predicting the subcellular location of proteins would be significant in interpreting the original data produced by the large-scale genome sequencing projects. The present work tries to explore an effective method for extracting features from protein primary sequence and find a novel measurement of similarity among proteins for classifying a protein to its proper subcellular location. We considered four locations in eukaryotic cells and three locations in prokaryotic cells, which have been investigated by several groups in the past. A combined feature of primary sequence defined as a 430D (dimensional) vector was utilized to represent a protein, including 20 amino acid compositions, 400 dipeptide compositions and 10 physicochemical properties. To evaluate the prediction performance of this encoding scheme, a jackknife test based on nearest neighbor algorithm was employed. The prediction accuracies for cytoplasmic, extracellular, mitochondrial, and nuclear proteins in the former dataset were 86.3%, 89.2%, 73.5% and 89.4%, respectively, and the total prediction accuracy reached 86.3%. As for the prediction accuracies of cytoplasmic, extracellular, and periplasmic proteins in the latter dataset, the prediction accuracies were 97.4%, 860/0, and 79.7, respectively, and the total prediction accuracy of 92.5% was achieved. The results indicate that this method outperforms some existing approaches based on amino acid composition or amino acid composition and dipeptide composition. (c) 2005 Published by Elsevier B.V. on behalf of the Federation of European Biochemical Societies.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China.	gqb_kd@yahoo.com.cn	Gao, Qing-Bin/G-9825-2011				Fujiwara Y, 2001, Genome Inform, V12, P103; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, P414; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; CORNETTE JL, 1987, J MOL BIOL, V195, P659, DOI 10.1016/0022-2836(87)90189-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2002, INT J BIOCHEM CELL B, V34, P298, DOI 10.1016/S1357-2725(01)00121-2; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kim S, 2004, BIOINFORMATICS, V20, P40, DOI 10.1093/bioinformatics/btg368; Lio P, 2000, BIOINFORMATICS, V16, P376, DOI 10.1093/bioinformatics/16.4.376; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; Nair Rajesh, 2002, Bioinformatics, V18 Suppl 1, pS78; Nair R, 2003, PROTEINS, V53, P917, DOI 10.1002/prot.10507; Nair R, 2004, NUCLEIC ACIDS RES, V32, pW517, DOI 10.1093/nar/gkh441; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nielsen H., 1998, Proceedings Sixth International Conference on Intelligent Systems for Molecular Biology; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Pan YX, 2005, ACTA BIOCH BIOPH SIN, V37, P88, DOI 10.1111/j.1745-7270.2005.00013.x; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Rost B, 1996, PROTEIN SCI, V5, P1704; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	53	63	63	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0014-5793		FEBS LETT	FEBS Lett.	JUN 20	2005	579	16					3444	3448		10.1016/j.febslet.2005.05.021		5	Biochemistry & Molecular Biology; Biophysics; Cell Biology	Biochemistry & Molecular Biology; Biophysics; Cell Biology	939AV	WOS:000230045400015	
J	Nitschke, G				Nitschke, G			Emergence of cooperation: State of the art	ARTIFICIAL LIFE			English	Review						emergence; cooperative behavior; swarm intelligence; RoboCup soccer; pursuit-evasion	QUADRATIC ASSIGNMENT PROBLEM; PREDATOR-PREY INTERACTIONS; EVOLVING CONTROLLERS; MULTIAGENT SYSTEMS; SELF-ORGANIZATION; PHYSICAL ROBOTS; SOCIAL INSECTS; SOCCER SERVER; ANT COLONIES; EVOLUTION	This review presents a review of prevalent results within research pertaining to emergent cooperation in biologically inspired artificial social systems. Results reviewed maintain particular reference to biologically inspired design principles, given that current mathematical and empirical tools have provided only a partial insight into elucidating mechanisms responsible for emergent cooperation, and then only in systems of an abstract nature. ThiS review, aims to provide an overview of important and disparate research contributions that investigate utilization of biologically inspired concepts such as emergence, evolution, and self-organization as a means of attaining cooperation in artificial social systems. An introduction and overview of emergent cooperation in artificial life is presented, followed by 2 survey of emergent cooperation in swarm-based systems, the pursuit-evasion domain, and RohoCup soccer. The final section draws conclusions regarding future directions of emergent cooperation as a problem-solving methodology that is potentially applicable in a wide range of problem domains. Within each of these sections and their respective themes of research, the mechanisms deemed to he responsible for emergent cooperation are elucidated and their key limitations highlighted. The review concludes that Current studies in emergent cooperative behavior Are limited by a hick of situated and embodied approaches, and I)v the research infancy of current biologically inspired design approaches. Despite these limiting factors, emergent cooperation maintains considerable future potential in a wide variety of application domains where systems composed of many interacting components must cooperatively perform Unanticipated global tasks.	Vrije Univ Amsterdam, Dept Comp Sci, Computat Intelligence Grp, NL-1081 HV Amsterdam, Netherlands	Nitschke, G (reprint author), Vrije Univ Amsterdam, Dept Comp Sci, Computat Intelligence Grp, Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.	nitschke@cs.vu.nl					ADAMI C, 1994, 10638 CALTECH KELL R; Akiyama Eizo, 1995, Artificial Life, V2, P293; Alami R, 1998, IEEE ROBOT AUTOM MAG, V5, P36, DOI 10.1109/100.667325; AMAT J, 1995, P 4 INT S EXP ROB, P40; ANGELINE PJ, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P264; ANGELINE PJ, 1994, P 4 ART LIF  C, P353; AOKI I, 1982, B JPN SOC SCI FISH, V48, P1081; ARKIN R, 1999, ARTIFICIAL INTELLIGE; Arkin R., 1998, BEHAV BASED ROBOTICS; Arkin R. C., 1999, IEEE T ROBOTIC AUTOM, V14, P926; ASADA M, 1994, P AAAI 94 WORKSH AI, P16; AVOURIS NM, 1992, DISTRIBUTED ARTIFICI; AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396; Axelrod R., 1984, EVOLUTION COOPERATIO; Axelrod Richard, 1987, GENETIC ALGORITHMS S; BALDASSARRE G, 2002, P INT WORKSH SELF OR, P11; Beckers R., 1994, ARTIF LIFE, P181; BECKERS R, 1992, J THEOR BIOL, V159, P397, DOI 10.1016/S0022-5193(05)80686-1; Benda M., 1986, BCSG201028 BOEING AI; Bonabeau E, 1997, TRENDS ECOL EVOL, V12, P188, DOI 10.1016/S0169-5347(97)01048-3; BONABEAU E, 1994, ARTIF LIFE, V4, P307; Bonabeau E, 1998, J THEOR BIOL, V195, P157, DOI 10.1006/jtbi.1998.0789; BONABEAU F, 1998, SWARM INTELLIGENCE N; BONGARD JC, 2003, MORPHOFUNCTIONAL MAC; Braitenberg V., 1984, VEHICLES EXPT SYNTHE; BREDER CM, 1954, ECOLOGY, V35, P129; Brooks R. A., 1990, Robotics and Autonomous Systems, V6, DOI 10.1016/S0921-8890(05)80025-9; Brooks R. A., 1989, Journal of the British Interplanetary Society, V42; BRYANT B, 2003, P 2003 C EV COMP; Burr Ridge I, 1997, MACHINE LEARNING; Cao YU, 1997, AUTON ROBOT, V4, P7, DOI 10.1023/A:1008855018923; Chaimowicz L., 2001, P IEEE INT C ROB AUT, P2292; COLORNI A, 1992, PARALLEL PROBLEM SOLVING FROM NATURE, 2, P509; Colorni A, 1991, P 1 EUR C ART LIF, P134; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CULLEN JM, 1965, ANIM BEHAV, V13, P534, DOI 10.1016/0003-3472(65)90117-X; Deneubourg J.L., 1990, ANIMALS ANIMATS, P356; DENEUBOURG JL, 1991, P EUR C ART LIF ECAL, P123; DENEUBOURG JL, 1989, ETHOL ECOL EVOL, V1, P295; Deneubourg J.-L., 1987, Experientia Supplementum (Basel), V54, P177; Denzinger J., 1996, P ICMAS 96 KYOT, P48; Di Caro G, 1998, J ARTIF INTELL RES, V9, P317; DIECKMANN U, 1995, J THEOR BIOL, V176, P91, DOI 10.1006/jtbi.1995.0179; DIPIETRO A, 2002, GECCO 2002 P GEN EV, P1065; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; DORIGO M, 1995, INTELL AUTOM SOFT CO, V1, P29; DROGOUL A, 1992, PRACTICE AUTONOMOUS, P161; Drogoul A, 1995, ARTIFICIAL SOCIETIES, P190; DROGOUL A, 1992, DISTRIBUTED ARTIFICI, P53; Drogoul A., 1992, P375; DUGATKIN LA, 1990, J THEOR BIOL, V142, P123, DOI 10.1016/S0022-5193(05)80017-7; Epstein JM, 1996, GROWING ARTIFICIAL S; FLOREANO D, 1997, P 4 EUR C ART LIF; Floreano D, 2000, NEURAL NETWORKS, V13, P431, DOI 10.1016/S0893-6080(00)00032-0; FLOREANO D, 1997, GENETIC PROGRAMMING; FLOREANO D, 2000, EVOLUTIONARY ROBOTIC; Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X; FRUTIGER DR, 2002, P 5 INT C CLIMB WALK, P619; Gambardella LM, 1999, J OPER RES SOC, V50, P167, DOI 10.1057/palgrave.jors.2600676; GOMEZ F, 2001, AI02292 U TEX COMP S; Gomez F, 1997, ADAPT BEHAV, V5, P317, DOI 10.1177/105971239700500305; Gomez FJ, 2003, THESIS U TEXAS AUSTI; GOSS S, 1989, NATURWISSENSCHAFTEN, V76, P579, DOI 10.1007/BF00462870; Grefenstette J. J., 1988, Machine Learning, V3, DOI 10.1007/BF00113898; Gutowitz H., 1993, P 3 EUR C ART LIF, P10; Hackwood S., 1992, Proceedings. 1992 IEEE International Conference on Robotics And Automation (Cat. No.92CH3140-1), DOI 10.1109/ROBOT.1992.220268; Hackwood S., 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), DOI 10.1109/IROS.1991.174658; HARVEY I, 1997, P INT S ART LIF ROB, P18; Harvey I, 1997, ROBOT AUTON SYST, V20, P205, DOI 10.1016/S0921-8890(96)00067-X; Haynes T., 1995, P 1 INT C MULT SYST, P450; Haynes T., 1996, INT J COMPUT INTELL, V1, P1; HAYNES T, 1995, P 6 INT C GEN ALG, P271; Haynes T., 1996, Adaption and Learning in Multi-Agent Systems. IJCAI '95 Workshop. Proceedings; Haynes T., 1997, P 2 ANN C GEN PROGR, P162; HIEBELER D, 1994, P DEC SUPP 2001 ADV, P20; Hirsch M., 1974, DIFFERENTIAL EQUATIO; HOLLAND JH, 1992, ADAPTATION NATURAL A; HSU W, 2001, P 4 EUR C GEN PROGR, P291; HSU WH, 2002, GENETIC EVOLUTIONARY, P764; HUANG J, 1995, APPL ARTIF INTELL, V9, P401, DOI 10.1080/08839519508945482; IBA H, 1996, PARALLEL PROBLEM SOL, P23; Iba H, 1998, INFORM SCIENCES, V108, P181, DOI 10.1016/S0020-0255(97)10055-X; IJSPEERT A, 1999, COOPERATION EXPLORAT; JAMZAD M, 2000, ROBOCUP 99 ROBOT SOC, V3, P61; JBA H, 1997, P IEEE INT C EV COMP, P13; JENNINGS NR, 1995, ARTIF INTELL, V75, P195, DOI 10.1016/0004-3702(94)00020-2; Jennings N.R., 1995, P 1 INT C MULT SYST, P423; JOHNSON P, 1994, AUTON ROBOT, V2, P43; Keller L, 1998, NATURE, V394, P573, DOI 10.1038/29064; Keller L, 1999, BIOSCIENCE, V49, P899, DOI 10.2307/1313649; KIM J, 1996, P MICR WORLD CUP SOC; Kitano H, 1997, AI MAG, V18, P73; Kitano H., 1998, Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146), DOI 10.1109/ROBOT.1998.680735; Kitano H, 2000, ADV ROBOTICS, V13, P723; KORF RE, 1992, 11 INT WORKSH DISTR, P183; Koza J., 1992, P 1 EUR C ART LIF, P110; KRAUS S, 1997, ARTIF INTELL, V94, P80; KUBE C, 1999, ROBOTICS AUTONOMOUS, V1, P20; Kube C. Ronald, 1993, Adaptive Behavior, V2, P189, DOI 10.1177/105971239300200204; Kube CR, 1997, AUTON ROBOT, V4, P53, DOI 10.1023/A:1008859119831; LEVY R, 1992, DECENTRALIZED ARTIFI, V3, P129; Luke S., 1998, ROBOCUP 97 ROBOT SOC, P398; Maniezzo V, 1999, IEEE T KNOWL DATA EN, V11, P769, DOI 10.1109/69.806935; Mataric M., 1992, ANIMALS ANIMATS, P432; Mataric M, 1996, ROBOT AUTON SYST, V19, P67, DOI 10.1016/S0921-8890(96)00034-6; MATARIC M, 1997, J EXPT THEORETICAL A, V9, P62; Matsubara H., 1996, Adaptation, Coevolution and Learning in Multiagent Systems. Papers from the 1996 AAAI Symposium (TR SS-96-01); MCCAULEY E, 1993, AM NAT, V142, P412, DOI 10.1086/285547; Meeden L.A., 1998, SOFT COMPUTING INTEL, P215; MILLER G, 1994, CSRP311 U SUSS SCH C, V1; MITSUMOTO N, 1995, IEEE INT CONF ROBOT, P2187, DOI 10.1109/ROBOT.1995.525584; Mondada F, 1993, P 3 INT S EXP ROB, P501; MONDADA F, 2002, 12SLSASTI SWISS FED; Montana DJ, 1995, EVOL COMPUT, V3, P199, DOI 10.1162/evco.1995.3.2.199; MORIARTY D, 1997, THESIS U TEX DEP COM; Moriarty DE, 1997, EVOL COMPUT, V5, P373, DOI 10.1162/evco.1997.5.4.373; Nishimura Shin I., 1997, Artificial Life, V3, P243, DOI 10.1162/artl.1997.3.4.243; Noda I, 1998, APPL ARTIF INTELL, V12, P233, DOI 10.1080/088395198117848; NODA I, 2001, AUTON AGENT MULTI-AG, V7, P101; NODA I, 1996, P 4 PAC RIM INT C AR, P570; NOLFI S, 2000, EVOROBOT 1 1 1SER MA; NOLFI S, 2003, ECRIM NEW, V53, P25; Nolfi S., 2003, APPL EVOLUTIONARY CO, P581; OLIPHANT M, 1994, P 4 ART LIF WORKSH, P349; PARKER L, 1994, ADV ROBOTICS, V11, P305; PARKER LE, 1994, P ASCE SPEC C ROB CH, P131; Parker LE, 1999, INTELL AUTOM SOFT CO, V5, P5; Parker LE, 1999, NEUROCOMPUTING, V28, P75, DOI 10.1016/S0925-2312(98)00116-7; Perez-Uribe A, 2003, LECT NOTES ARTIF INT, V2801, P128; Pfeifer R., 1999, UNDERSTANDING INTELL; QUINN M, 2002, 515 U SUSS SCH COGN; QUINN M, 2002, INT WORKSH BIOL INSP; Quinn M, 2003, PHILOS T ROY SOC A, V361, P2321, DOI 10.1098/rsta.2003.1258; RAY T, 2001, ATRHIP15; Reynolds C., 1987, COMPUT GRAPH, V21, P25, DOI DOI 10.1145/37402.37406; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SAHOTA MK, 1995, IEEE INT C SYST MAN, P3690; Sandholm TW, 1997, ARTIF INTELL, V94, P99, DOI 10.1016/S0004-3702(97)00030-1; Singh M. P, 1990, P 9 EUR C ART INT, p604~609; STONE M, 1999, P SPIE SENS FUS DEC, V2, P134; STONE P, 1998, P 2 INT C AUT AG ACM, P110; STONE P, 2002, P 18 INT C MACH LEAR, P537; Stone P, 1999, ARTIF INTELL, V110, P241, DOI 10.1016/S0004-3702(99)00025-9; Stone P, 1998, INT J HUM-COMPUT ST, V48, P83, DOI 10.1006/ijhc.1997.0162; Stone P., 1998, RoboCup-97: Robot Soccer. World Cup I; Stone P, 1998, APPL ARTIF INTELL, V12, P165, DOI 10.1080/088395198117811; Sutton R., 1998, INTRO REINFORCEMENT; Theraulaz G, 1995, J THEOR BIOL, V177, P381, DOI 10.1006/jtbi.1995.0255; Trianni V, 2003, LECT NOTES ARTIF INT, V2801, P865; Van Valen L., 1973, EVOL THEORY, V1, P1, DOI DOI 10.1017/CBO9781139173179; VELOSO M, 1995, ROBOCUP 98 ROBOT SOC, V2, P491; VELOSO M, 1999, ROBOCUP 98 ROBOT SOC, V2, P77; Veloso M, 2000, ADV ROBOTICS, V13, P753; Watson R. A., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), DOI 10.1109/CEC.1999.781944; WERNER GM, 1993, P 2 INT C SIM AD BEH, P393; WHITESON S, 2003, P GEN EV COMP C, P356; WILSON EO, 1985, SCIENCE, V228, P1489, DOI 10.1126/science.228.4707.1489; YONG C, 2001, A101287 U TEX DEP CO; ZAERA N, 1996, NOT EVOLVING COLLECT; Zlatev J, 2001, MIND MACH, V11, P155, DOI 10.1023/A:1011218919464; *HOUS BOOKS LTD, 2000, DICT BIOL	162	8	8	MIT PRESS	CAMBRIDGE	55 HAYWARD STREET, CAMBRIDGE, MA 02142 USA	1064-5462		ARTIF LIFE	Artif. Life	SUM	2005	11	3					367	396		10.1162/1064546054407194		30	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	944LX	WOS:000230431600008	
J	Habrard, A; Bernard, M; Sebban, M				Habrard, A; Bernard, M; Sebban, M			Detecting irrelevant subtrees to improve probabilistic learning from tree-structured data	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	1st International Workshop on Mining Graphs, Trees and Sequences	SEP   10, 2003	Cavtat, CROATIA			data reduction; tree-structured data; noisy data; stochastic tree automata	LANGUAGES; INFERENCE; GRAMMARS	In front of the large increase of the available amount of structured data (such as XML documents), many algorithms have emerged for dealing with tree-structured data. In this article, we present a probabilistic approach which aims at a priori pruning noisy or irrelevant subtrees in a set of trees. The originality of this approach, in comparison with classic data reduction techniques, comes from the fact that only a part of a tree (i.e. a subtree) can be deleted, rather than the whole tree itself. Our method is based on the use of confidence intervals, on a partition of subtrees, computed according to a given probability distribution. We propose an original approach to assess these intervals on tree-structured data and we experimentally show its interest in the presence of noise.	Univ St Etienne, EURISE, F-42023 St Etienne 2, France	Habrard, A (reprint author), Univ St Etienne, EURISE, 23,Rue Dr Paul Michelson, F-42023 St Etienne 2, France.	amaury.habrard@univ-st-etienne.fr; marc.bernard@univ-st-etienne.fr; marc.sebban@univ-st-etienne.fr					Abe N, 1997, MACH LEARN, V29, P275, DOI 10.1023/A:1007477814995; Agrawal R., 1994, P 20 INT C VER LARG; Amoth TR, 2001, MACH LEARN, V44, P211, DOI 10.1023/A:1010971904477; BERNARD M, 1999, 9 INT C IND LOG PROG; Blake C. L., 1998, U CALIFORNIA IRVINE; Brown P. F., 1992, Computational Linguistics, V18; Calera-Rubio J, 1998, INFORM PROCESS LETT, V68, P283, DOI 10.1016/S0020-0190(98)00172-0; Carrasco RC, 2001, MACH LEARN, V44, P185, DOI 10.1023/A:1010836331703; CARRASCO RC, 2002, IN PRESS PATTERN REC; CHAUDHURI R, 1986, J ACM, V33, P702, DOI 10.1145/6490.214099; Comon H., 1997, TREE AUTOMATA TECHNI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERAEDT L, 2000, 4 EUR C PRINC PRACT; DUPONT P, 1994, LNAI, V862; GARCIA P, 1993, DSICII4793 U POL VAL; Gecseg F., 1984, TREE AUTOMATA; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; GOLDMAN SA, 1999, 10 ALG LEARN THEOR C, P1720; HABRARD A, 2003, P 9 C ART INT MED EU, P2780; HABRARD A, 2002, 6 INT C GRAMM INF IC, P2484; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; John G.H., 1994, 11 INT C MACH LEARN; KILPELAINEN P, 1992, A19926 U HELS DEP CO; KING RD, 1995, NEW GENERAT COMPUT, V13, P411; KNUUTILA T, 1994, THEOR COMPUT SCI, V129, P337, DOI 10.1016/0304-3975(94)90033-7; KOSALA R, 2003, P 18 INT JOINT C ART; KOSALA R, 2002, 6 EUR C PRINC PRACT, P2431; LYNGSO R, 1999, 7 INT C INT SYST MOL; MIYAHARA T, 2002, PAKDD 2002 TAIP TAIW; NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001; Nijssen S., 2003, P 1 INT WORKSH MIN G; NOCK R, 2000, INT C ALG LEARN THEO; RICOJUAN J, 2000, ICGI 2000 LISB PORT, P1891; RICOJUAN J, 2002, ICGI 2002 SPRING VER, P2484; SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X; TERMIER A, 2002, INT C DAT MIN ICDM 0; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZAKI MJ, 2002, P 8 INT C KNOWL DISC	38	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	JUN	2005	66	1-2					103	130				28	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	020YC	WOS:000235948300006	
J	Biau, G; Bunea, F; Wegkamp, MH				Biau, G; Bunea, F; Wegkamp, MH			Functional classification in Hilbert spaces	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						classification; Fourier expansion; nearest neighbor rule; universal consistency	DISCRIMINANT-ANALYSIS; MODEL	Let X be a random variable taking values in a separable Hilbert space X, with label Y is an element of {0, 1}. We establish universal weak consistency of a nearest neighbor-type classifier based on n independent copies (X-i, Y-i) of the pair (X, Y), extending the classical result of Stone to infinite-dimensional Hilbert spaces. Under a mild condition on the distribution of X, we also prove strong consistency. We reduce the infinite dimension of X by considering only the first d coefficients of a Fourier series expansion of each X-i, and then we perform k-nearest neighbor classification in R-d. Both the dimension and the number of neighbors are automatically selected from the data using a simple data-splitting device. An application of this technique to a signal discrimination problem involving speech recordings is presented.	Univ Montpellier 2, Inst Math & Modelisat Montpellier, CNRS, UMR 5149,Equipe Probabil & Stat, F-34095 Montpellier, France; Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA	Biau, G (reprint author), Univ Montpellier 2, Inst Math & Modelisat Montpellier, CNRS, UMR 5149,Equipe Probabil & Stat, CC 051, F-34095 Montpellier, France.	biau@math.umv-mqmp2.fr; flori@stat.fsu.edu; wegkamp@stat.fsu.edu					ABRAHAM C, 2005, KERNEL RULE FUNCTION; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BOUCHERON S, IN PRESS ESAIM PROBA; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarthy B., 1991, NEAREST NEIGHBOR NN; Devroye L, 1996, PROBABILISTIC THEORY; DIABONIANG S, 2001, NONPARAMETRIC REGRES; Ferraty F, 2003, CR MATH, V336, P1025, DOI 10.1016/S1631-073X(03)00239-5; Ferraty F, 2003, COMPUT STAT DATA AN, V44, P161, DOI 10.1016/S0167-9473(03)00032-X; Ferraty F, 2002, COMPUTATION STAT, V17, P545, DOI 10.1007/s001800200126; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 2149004 USAF SCH AV; FIX E, 1991, NEAREST NEIGHBOR NN, P32; Hall P, 2001, TECHNOMETRICS, V43, P1, DOI 10.1198/00401700152404273; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HENGARTNER N, 2002, J ROYAL STAT SOC B, V64, P1; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; Pollard D, 2002, CAMBRIDGE SERIES STA; Ramsay J. O., 2002, APPL FUNCTIONAL DATA; RAMSAY J. O., 1997, FUNCTIONAL DATA ANAL; SANSONE G, 1969, ORTHOGONAL FUNCTIONS; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; SZEGO G, 1959, ORTHOGONAL POLYNOMIA, V32; Zygmund A., 1959, TRIGONOMETRIC SERIES, V1	28	38	39	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	JUN	2005	51	6					2163	2172		10.1109/TIT.2005.847705		10	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	930XY	WOS:000229451600017	
J	Cano, JR; Herrera, F; Lozano, M				Cano, JR; Herrera, F; Lozano, M			Stratification for scaling up evolutionary prototype selection	PATTERN RECOGNITION LETTERS			English	Article						stratification; scaling up; evolutionary algorithms; prototype selection	LEARNING ALGORITHMS; GENETIC ALGORITHM; RULE; REDUCTION	Evolutionary algorithms has been recently used for prototype selection showing good results. An important problem that we can find is the scaling up problem that appears evaluating the Evolutionary Prototype Selection algorithms in large size data sets. In this paper, we offer a proposal to solve the drawbacks introduced by the evaluation of large size data sets using evolutionary prototype selection algorithms. In order to do this we have proposed a combination of stratified strategy and CHC as representative evolutionary algorithm model. This study includes a comparison between our proposal and other non-evolutionary prototype selection algorithms combined with the stratified strategy. The results show that stratified evolutionary prototype selection consistently outperforms the non-evolutionary ones, the main advantages being: better instance reduction rates, higher classification accuracy and reduction in resources consumption. &COPY; 2004 Elsevier B.V. All rights reserved.	Univ Granada, ETSI Infomat, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain; Univ Jaen, Dept Comp Sci, Jaen 23700, Spain	Cano, JR (reprint author), Univ Granada, ETSI Infomat, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jrcano@decsai.ugr.es; herrera@decsai.ugr.es; lozano@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Lozano Marquez, Manuel/B-1848-2012	Herrera, Francisco/0000-0002-7283-312X; 			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Back T, 1997, HDB EVOLUTIONARY COM; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ESHELMAN L. J., 1991, FDN GENETIC ALGORITH, V1, P265; FORREST S, 1993, MACH LEARN, V13, P285, DOI 10.1023/A:1022626114466; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Goldberg D. E, 1989, GENETIC ALGORITHMS S; HART PE, 1968, IEEE T INFORM THEORY, V18, P431; Kibbler D., 1987, P 4 INT WORKSH MACH, P24; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Merz C. J., 1996, UCI REPOSITORY MACHI; NAKASHIMA T, 1998, P INT C EV COMP, P709; Ravindra Babu T., 2001, Pattern Recognition, V34; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Shinn-Ying Ho, 2002, Pattern Recognition Letters, V23, DOI 10.1016/S0167-8655(02)00109-5; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	21	33	34	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY 15	2005	26	7					953	963		10.1016/j.patrec.2004.09.043		11	Computer Science, Artificial Intelligence	Computer Science	923WR	WOS:000228940700010	
J	Cai, YD; Zhou, GP; Chou, KC				Cai, YD; Zhou, GP; Chou, KC			Predicting enzyme family classes by hybridizing gene product composition and pseudo-amino acid composition	JOURNAL OF THEORETICAL BIOLOGY			English	Article						classification of enzyme commission; gene ontology; enzymatic attribute; quasi sequence-order effect; nearest neighbor predictor; bioinformatics; proteomics	SUBCELLULAR LOCATION PREDICTION; STRUCTURAL CLASS PREDICTION; FOLDING TYPES; PROTEINS; ONTOLOGY; DATABASE	A: new method has been developed to predict the enzymatic attribute of proteins by hybridizing the gene product composition and pseudo amino acid composition. As a demonstration, a working dataset was generated with a cutoff of 60% sequence identity to avoid redundancy and bias in statistical prediction. The dataset thus constructed contains 39 989 protein sequences, of which 27 469 are non-enzymes and 12 520 enzymes that were further classified into 6 enzyme family classes according to their 6 main EC (Enzyme Con mission) numbers (2314 are oxidoreductases, 3653 transferases, 3246 hydrolases, 1307 lyases, 676 isomerases,and 1324 ligases). The overall success rate by the jackknife test for the identification between enzyme and non-enzyme was 94%, and that for the identification among the 6 enzyme family classes was 98%. It is anticipated that, with the rapid increase of protein sequences entering into databanks, the current method will become a useful automated tool in identifying the enzymatic attribute of a newly found protein sequence. (C) 2004 Elsevier Ltd. All rights reserved.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Tianjin Normal Univ, Tianjin Inst Bioinformat & Drug Discovery, Tianjin 300074, Peoples R China; Harvard Univ, Sch Med, Beth Israel Med Ctr, Boston, MA 02115 USA; Univ Manchester, Inst Sci & Technol, Biomol Sci Dept, Manchester M60 1QD, Lancs, England	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Mar, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				ALBERTS B, 1994, MOL BIOL CELL, pCH1; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Mahalanobis P., 1936, P NAT I SCI INDIA, V2, P49; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Pillai K. C. S., 1985, ENCY STATISTICAL SCI, V5, P176; Webb EC, 1992, ENZYME NOMENCLATURE; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	25	51	51	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0022-5193		J THEOR BIOL	J. Theor. Biol.	MAY 7	2005	234	1					145	149		10.1016/j.jtbi.200.11.017		5	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	902NB	WOS:000227362700014	
J	Wang, M; Chen, S				Wang, M; Chen, S			Enhanced FMAM based on empirical kernel map	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						associative memory; empirical kernel map; face recognition; fuzzy mathematics; morphological neural networks	MORPHOLOGICAL MEMORIES; NEURAL-NETWORKS; RECOGNITION; ALGORITHMS	The existing morphological auto-associative memory models based on the morphological operations, typically including morphological auto-associative memories (auto-MAM) proposed by Ritter et al. and our fuzzy morphological auto-associative memories (auto-FMAM), have many attractive advantages such as unlimited storage capacity, one-shot recall speed and good noise-tolerance to single erosive or dilative noise. However, they suffer from the extreme vulnerability to noise of mixing erosion and dilation, resulting in great degradation on recall performance. To overcome this shortcoming, we focus on FMAM and propose an enhance FMAM (EFMAM) based on the empirical kernel map. Although it is simple, EFMAM can significantly improve the auto-FMAM with respect to the recognition accuracy under hybrid-noise and computational effort. Experiments conducted on the thumbnail-sized faces (28 x 23 and 14 x 11) scaled from the ORL database show the average accuracies of 92%, 90%, and 88% with 40 classes under 10%, 20%, and 30% randomly generated hybrid-noises, respectively, which are far higher than the auto-FMAM (67%, 46%, 31%) under the same noise levels.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China	Wang, M (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	wm_wangmin@yahoo.com.cn; s.chen@nuaa.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELMAN Shimon, 1999, REPRESENTATION RECOG; Gader PD, 2000, PATTERN RECOGN, V33, P935, DOI 10.1016/S0031-3203(99)00156-9; Goldstone R. L., 1999, MIT ENCY COGNITIVE S; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Morejon RA, 2004, IEEE T NEURAL NETWOR, V15, P874, DOI 10.1109/TNN.2004.828769; Pessoa LFC, 2000, PATTERN RECOGN, V33, P945, DOI 10.1016/S0031-3203(99)00157-0; Raducanu B, 2003, J MATH IMAGING VIS, V19, P113, DOI 10.1023/A:1024725414204; Ritter G. X., 1996, P 13 INT C PATT REC, V4, P709; Ritter GX, 2003, IEEE T NEURAL NETWOR, V14, P282, DOI 10.1109/TNN.2003.809427; Ritter GX, 1998, IEEE T NEURAL NETWOR, V9, P281, DOI 10.1109/72.661123; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 2002, LECT NOTES ARTIF INT, V2430, P511; Sussner P, 2003, J MATH IMAGING VIS, V19, P81, DOI 10.1023/A:1024721313295; SUSSNER P, 2003, P INT JOINT C NEUR N, V1, P236, DOI 10.1109/IJCNN.2003.1223350; Van Hulle MM, 2004, IEEE T NEURAL NETWOR, V15, P850, DOI 10.1109/TNN.2004.828763; Wang Min, 2003, Acta Electronica Sinica, V31; WHARTON CM, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P588; Won YG, 1997, IEEE T NEURAL NETWOR, V8, P1195	19	16	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1045-9227		IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAY	2005	16	3					557	564		10.1109/TNN.2005.847839		8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	923KX	WOS:000228909900005	
J	Pati, PB; Ramakrishnan, AG				Pati, PB; Ramakrishnan, AG			OCR in Indian scripts: A survey	IETE TECHNICAL REVIEW			English	Article							PRINTED BILINGUAL DOCUMENTS; NEAREST NEIGHBOR RULE; HIDDEN MARKOV-MODELS; CHARACTER-RECOGNITION; MACHINE RECOGNITION; PATTERN-CLASSIFICATION; TELUGU CHARACTERS; TEXT RECOGNITION; DEVANAGARI; SYSTEM	India is a multi-lingual country. A significantly large number of scripts are used to represent these languages. A desire of vision researchers is to develop an integrated Optical Character Recognition (OCR) system which will be able to process all such scripts. Such a development, if objectified, will not only enable faster flow of information across the country, but also have a profound impact on its scientific and economic development. Courageous endeavors have been successfully made towards the development of a system capable of recognizing machine-printed, or hand-written characters and/or numerals. However, most Indian scripts do not have an integrated OCR system. Further the development of a unified system which is capable of processing all Indian scripts is still a dream. This article presents a survey of the current literature on the development of OCR's in Indian scripts. Reviewing the basics of and the motivation towards the development of OCR system, the article analyzes the various methodologies employed in general purpose pattern recognition system. A critical analysis of the work towards OCR system in Indian languages, with pointers towards possible future work is also presented.	Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India	Pati, PB (reprint author), Indian Inst Sci, Dept Elect Engn, Bangalore 560012, Karnataka, India.	pati@ee.iisc.ernet.in; ramkiag@ee.iisc.ernet.in					Antani S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791813; ALBADR B, 1995, SIGNAL PROCESS, V41, P49, DOI 10.1016/0165-1684(94)00090-M; Aparna KG, 2002, LECT NOTES COMPUT SC, V2423, P53; ASHWIN TV, 2000, THESIS INDIAN I SCI; Bansal V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791811; BATI PB, 2000, P INT C INF TECH, P227; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bishnu A., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791809; Bishop C. M., 1995, NEURAL NETWORKS PATT; Burges C. J., 1998, DATA MIN KNOWL DISC, V2, P955; CHANDRASEKARAN M, 1984, P INT C SYST MAN CYB, V2, P786; CHANDRASEKARAN M, 1984, J IETE INDIA, V30, P150; CHAUDHURI BB, 1991, J IETE, V37, P499; CHAUDHURI BB, 2001, P 6 INT C DOC AN REC, P406; Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2; CHINNUSWAMY P, 1980, PATTERN RECOGN, V12, P131; Cho WY, 1995, PATTERN RECOGN, V28, P1941; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; DHANYA D, 2001, THESIS INDIAN I SCI; Dhanya D, 2002, LECT NOTES COMPUT SC, V2423, P25; Dhanya D, 2002, SADHANA-ACAD P ENG S, V27, P73, DOI 10.1007/BF02703313; Dhanya D, 2002, LECT NOTES COMPUT SC, V2423, P13; Duda R., 1973, PATTERN CLASSIFICATI; DUTTA A, 1993, PATTERN RECOGN, V26, P1757, DOI 10.1016/0031-3203(93)90174-U; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GOIN JE, 1984, IEEE T PATTERN ANAL, V6, P379; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HAYKIN S, 1999, NEURAL NETWORKS COMP; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; Hu JY, 1996, IEEE T PATTERN ANAL, V18, P1039; HYVARINEN A, 1997, NEURAL COMPUT, V9, P183; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274; KARNIK RR, 1909, P 5 INT C DOC AN REC, P669; KUMAR BV, 2002, THESIS INDIAN I SCI; Kumar BV, 2002, LECT NOTES COMPUT SC, V2423, P37; LEHAL GS, 1999, VIVEK, V12, P212; LEHAL GS, 2000, P 15 INT C PATT REC, V2, P557, DOI 10.1109/ICPR.2000.906135; Lehal G. S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791746; LPPMANN R, 1987, IEEE ASSP MAGAZINE, V4; MAHATA K, 2000, THESIS INDIAN I SCI; Marr D., 1982, VISION COMPUTATIONAL; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Mohanty S, 1998, INT J PATTERN RECOGN, V12, P1007, DOI 10.1142/S0218001498000555; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N; Murthy CNSG, 1998, NEURAL NETWORKS, V11, P315; NEGI A, 1999, INT WORKSH PERF EV I; Pal U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791810; PATI NK, 2003, P INT C INF TECH, P590; PATI PB, 2000, THESIS INDIAN I SCI; Pati PB, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P123; PRAVIN LM, 1999, THESIS INDIAN I SCI; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAJASEKARAN SNS, 1977, COMPUTER GRAPHICS IM, V6, P335, DOI 10.1016/0146-664X(77)90028-4; RAMAKRISHNAN AG, 2001, P TAM INT, P165; SEONGWHAN L, 1987, IEEE T PATTERN ANAL, V18, P1045; Sethi I. K., 1976, Journal of the Institution of Electronics and Telecommunication Engineers, V22; SETHI IK, 1977, PATTERN RECOGN, V9, P69, DOI 10.1016/0031-3203(77)90017-6; SINHA RMK, 1979, IEEE T SYST MAN CYB, V9, P435; Sinha R. M. K., 1987, Journal of the Institution of Electronics and Telecommunication Engineers, V33; SINHA RMK, 1987, PATTERN RECOGN, V20, P475, DOI 10.1016/0031-3203(87)90075-6; SIROMONEY G, 1978, PATTERN RECOGN, V10, P243, DOI 10.1016/0031-3203(78)90032-8; SIRONONEY G, 1983, IEEE T SYSTEMS MAN C, V13; Srinivasan S. H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), DOI 10.1109/ICDAR.1999.791812; SUKHASWAMI MB, 1995, INT J NEURAL SYST, V6, P317, DOI 10.1142/S0129065795000238; TOMEK I, 1976, IEEE T SYSTEMS MAN C, V6	69	2	2	INST ELECTRONICS TELECOMMUNICATION ENGINEERS	NEW DELHI	2 INSTITUTIONAL AREA, LODI ROAD, NEW DELHI 110 003, INDIA	0256-4602		IETE TECH REV	IETE Tech. Rev.	MAY-JUN	2005	22	3					217	227				11	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	984IY	WOS:000233297700007	
J	Graepel, T; Herbrich, R				Graepel, T; Herbrich, R			PAC-Bayesian compression bounds on the prediction error of learning algorithms for classification	MACHINE LEARNING			English	Article						classification; error bounds; sample compression; PAC-Bayes; kernel classifiers	MACHINE	We consider bounds on the prediction error of classification algorithms based on sample compression. We refine the notion of a compression scheme to distinguish permutation and repetition invariant and nonpermutation and repetition invariant compression schemes leading to different prediction error bounds. Also, we extend known results on compression to the case of non-zero empirical risk. We provide bounds on the prediction error of classifiers returned by mistake-driven online learning algorithms by interpreting mistake bounds as bounds on the size of the respective compression scheme of the algorithm. This leads to a bound on the prediction error of perceptron solutions that depends on the margin a support vector machine would achieve on the same training sample. Furthermore, using the property of compression we derive bounds on the average prediction error of kernel classifiers in the PAC-Bayesian framework. These bounds assume a prior measure over the expansion coefficients in the data-dependent kernel expansion and bound the average prediction error uniformly over subsets of the space of expansion coefficients.	Microsoft Res, Cambridge, England; Univ Southampton, Sch Elect & Comp Sci, Southampton, Hants, England	Graepel, T (reprint author), Microsoft Res, Cambridge, England.	thoreg@microsoft.com; rherb@microsoft.com					Bartlett P.L., 1998, ADV KERNEL METHODS S, P43; Cannon A, 2002, J MACH LEARN RES, V2, P335, DOI 10.1162/153244302760200650; CESABIANCHI N, 2002, ADV NEURAL INFORMATI, V14; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; FLOYD S, 1995, MACH LEARN, V27, P1; Graepel T., 2000, P 13 ANN C COMP LEAR, P298; Herbrich R, 2001, LEARNING KERNEL CLAS; Herbrich R, 2002, IEEE T INFORM THEORY, V48, P3140, DOI 10.1109/TIT.2002.805090; HERBRICH R, 2002, JMLR, V3, P175; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; LANGFORD J, 2003, ADV NEURAL INFORMATI, V15, P439; Littlestone N., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory; Littlestone N, 1986, RELATING DATA COMPRE; Littlestone N., 1988, Machine Learning, V2, DOI 10.1007/BF00116827; MARCHAND M, 2001, P 18 INT C MACH LEAR, P345; McAllester D. A., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, DOI 10.1145/307400.307435; McAllester D. A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279989; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; SHAWETAYLOR J, 2001, NC2TR1997013 U LOND, V1, P211; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V.N., 1998, STAT LEARNING THEORY; VITANYI P, 1997, P EUR C MACH LEARN, P14; WARMUTH M, 2003, P ANN C COMP LEARN T; WYNER AD, 1992, IEEE T INFORMATION T, V4, P415	28	7	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAY	2005	59	1-2					55	76		10.1007/s10994-005-0462-7		22	Computer Science, Artificial Intelligence	Computer Science	922HW	WOS:000228828700003	
J	Jones, LC; Tefferi, A; Vuong, PT; Desmond, JC; Hofmann, WK; Koeffler, HP				Jones, LC; Tefferi, A; Vuong, PT; Desmond, JC; Hofmann, WK; Koeffler, HP			Detection of aberrant gene expression in CD34(+) hematopoietic stem cells from patients with agnogenic myeloid metaplasia using oligonucleotide microarrays	STEM CELLS			English	Article						hematopoietic stem cells; agnogenic myeloid metaplasia; aberrant gene expression	BONE-MARROW; IDIOPATHIC MYELOFIBROSIS; CLINICAL CORRELATIONS; PROGNOSTIC-FACTORS; BREAST-CANCER; MEGAKARYOCYTES; GROWTH; DIFFERENTIATION; CLASSIFICATION; PREDICTION	Agnogenic myeloid metaplasia (AMM) is a clonal stem cell disorder that leads to ineffective hematopoiesis, bone marrow fibrosis, and extramedullary hematopoiesis. The molecular mechanisms underlying the development of this syndrome are currently unknown. Therefore, the aim of this study was to characterize aberrant gene expression in CD34(+) hematopoietic stem cells from patients with AMM. We used oligonucleotide microarrays to analyze gene expression profiles in CD34(+) hematopoietic stem cells from patients with AMM compared with expression in CD34(+) cells from healthy individuals. We identified 95 highly differentially expressed genes (48 upregulated and 47 downregulated) that are potentially involved in regulating abnormal hematopoietic proliferation and differentiation and confirmed many of them by quantitative polymerase chain reaction. Using; class membership prediction analysis, we identified 75 genes whose expression profiles can accurately differentiate AMM samples from the controls. Using these 75 genes, we were able to discriminate patients with AMM from the controls by hierarchical clustering (Spearman's confidence correlation). The predictive power of these genes was verified by applying the algorithm to an unknown test set containing expression data from eight additional CD34(+) samples (four AMM, four control). Our results indicate that a subset of genes may be used to differentiate patients with AMM from healthy individuals. Furthermore, we identify 95 genes whose aberrant expression may be involved in AMM.	Univ Calif San Francisco, Div Lab Med, San Francisco, CA 94143 USA; Mayo Clin & Mayo Fdn, Div Hematol & Internal Med, Rochester, MN 55905 USA; Univ Calif Los Angeles, Sch Med, Cedars Sinai Med Ctr, Div Hematol Oncol, Los Angeles, CA USA; Univ Hosp, Dept Hematol, Frankfurt, Germany	Jones, LC (reprint author), Univ Calif San Francisco, Div Lab Med, 513 Parnassus Ave,S864, San Francisco, CA 94143 USA.	letetia@itsa.ucsf.edu					Abdallah BM, 2004, J BONE MINER RES, V19, P841, DOI 10.1359/JBMR.040118; Bock O, 2004, EUR J HAEMATOL, V72, P239, DOI 10.1046/j.0902-4441.2003.00204.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dupriez B, 1996, BLOOD, V88, P1013; Giraudier S, 2002, BLOOD, V100, P2932, DOI 10.1182/blood-2002-02-0485; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Graf L, 2001, BIOL BLOOD MARROW TR, V7, P486, DOI 10.1053/bbmt.2001.v7.pm11669215; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Hofmann WK, 2002, BLOOD, V100, P3553, DOI 10.1182/blood.V100.10.3553; Hofmann WK, 2001, BLOOD, V98, P787, DOI 10.1182/blood.V98.3.787; Huang CC, 2004, J PATHOL, V202, P172, DOI 10.1002/path.1505; Kenney AM, 2003, DEVELOPMENT, V130, P15, DOI 10.1242/dev.00182; Kvasnicka HM, 1997, CANCER, V80, P708, DOI 10.1002/(SICI)1097-0142(19970815)80:4<708::AID-CNCR9>3.0.CO;2-I; MARTYRE MC, 1994, BRIT J HAEMATOL, V88, P9, DOI 10.1111/j.1365-2141.1994.tb04970.x; Mesa RA, 1999, BLOOD, V94, p115A; Mesa RA, 2000, BLOOD, V96, P3374; Mesa RA, 1999, AM J HEMATOL, V61, P10, DOI 10.1002/(SICI)1096-8652(199905)61:1<10::AID-AJH3>3.0.CO;2-I; Ng YY, 2004, J LEUKOCYTE BIOL, V75, P314, DOI 10.1189/jlb.0603287; Pellagatti A, 2003, CANCER RES, V63, P3940; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Smith BD, 2001, CURR OPIN ONCOL, V13, P91, DOI 10.1097/00001622-200103000-00002; Steidl U, 2002, BLOOD, V99, P2037, DOI 10.1182/blood.V99.6.2037; Tefferi A, 2000, NEW ENGL J MED, V342, P1255, DOI 10.1056/NEJM200004273421706; TERRERI A, 2001, BRIT J HAEMATOL, V113, P763; THIELE J, 1992, VIRCHOWS ARCH A, V421, P33, DOI 10.1007/BF01607136; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; Vannucchi AM, 2002, BLOOD, V100, P1123, DOI 10.1182/blood-2002-06-1913; Voehringer DW, 2000, P NATL ACAD SCI USA, V97, P2680, DOI 10.1073/pnas.97.6.2680; YAN XQ, 1995, BLOOD, V86, P4025	30	11	12	ALPHAMED PRESS	MIAMISBURG	ONE PRESTIGE PLACE, STE 290, MIAMISBURG, OH 45342-3758 USA	1066-5099		STEM CELLS	Stem Cells	MAY	2005	23	5					631	637		10.1634/stemcells.2004-0131		7	Cell & Tissue Engineering; Biotechnology & Applied Microbiology; Oncology; Cell Biology; Hematology	Cell Biology; Biotechnology & Applied Microbiology; Oncology; Hematology	925AZ	WOS:000229025200004	
J	Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G				Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G			Output-sensitive algorithms for computing nearest-neighbour decision boundaries	DISCRETE & COMPUTATIONAL GEOMETRY			English	Article							CONVEX-HULL ALGORITHM	Given a set R of red points and a set B of blue points, the nearest-neighbour decision rule classifies a new point q as red (respectively, blue) if the closest point to q in R boolean OR B comes from R (respectively, B). This rule implicitly partitions space into a red set and a blue set that are separated by a red-blue decision boundary. In this paper we develop output-sensitive algorithms for computing this decision boundary for point sets on the line and in R-2. Both algorithms run in time O(n log k), where k is the number of points that contribute to the decision boundary. This running time is the best possible when parameterizing with respect to n and k.	Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada; MIT, Comp Sci Lab, Cambridge, MA 02139 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Polytech Univ, Dept Comp & Informat Sci, MetroTech Ctr 6, Brooklyn, NY 11201 USA; Free Univ Brussels, FNRS, Charge Rech, B-1050 Brussels, Belgium; Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5BL, Canada; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada	Bremner, D (reprint author), Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada.	bremner@unb.ca; edemaine@mit.edu; jeffe@cs.uiuc.edu; jiacono@poly.edu; stefan.langerman@ulb.ac.be; morin@cs.carleton.ca; godfried@cs.mcgill.ca					Ben-Or M., 1983, P 15 ANN ACM S THEOR, P80, DOI 10.1145/800061.808735; Bhattacharya BK, 1997, J ALGORITHM, V25, P177, DOI 10.1006/jagm.1997.0869; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; Chan TM, 1996, DISCRETE COMPUT GEOM, V16, P361, DOI 10.1007/BF02712873; Chan TM, 1997, DISCRETE COMPUT GEOM, V18, P433, DOI 10.1007/PL00009327; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0; DOBKIN DP, 1983, THEOR COMPUT SCI, V27, P241, DOI 10.1016/0304-3975(82)90120-7; HOARE C. A. R., 1961, CACM, V4, P321, DOI 10.1145/366622.366644; KIRKPATRICK D, 1983, SIAM J COMPUT, V12, P28, DOI 10.1137/0212002; KIRKPATRICK DG, 1986, SIAM J COMPUT, V15, P287, DOI 10.1137/0215021; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Shamos M., 1975, P 7 ANN ACM S THEOR, P224, DOI 10.1145/800116.803772; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; TOUSSAINT GT, 2003, MANUSCRIPT; TOUSSAINT GT, 1984, P COMP SCI STAT 16 S, P97; Wenger R, 1997, ALGORITHMICA, V17, P322, DOI 10.1007/BF02523195	19	18	18	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0179-5376		DISCRETE COMPUT GEOM	Discret. Comput. Geom.	APR	2005	33	4					593	604		10.1007/s00454-004-1152-0		12	Computer Science, Theory & Methods; Mathematics	Computer Science; Mathematics	917XM	WOS:000228502600003	
J	Vasilic, S; Kezunovic, M				Vasilic, S; Kezunovic, M			Fuzzy ART neural network algorithm for classifying the power system faults	IEEE TRANSACTIONS ON POWER DELIVERY			English	Article						adaptive resonance theory; clustering methods; fuzzy logic; learning systems; neural networks; pattern classification; power system faults; protective relaying; testing; training	TRANSMISSION-LINES; DISTANCE PROTECTION; CLASSIFICATION; IMPLEMENTATION; DESIGN; NETS; TIME	This paper introduces advanced pattern recognition algorithm for classifying the transmission line faults, based on combined use of neural network and fuzzy logic. The approach utilizes self-organized, supervised Adaptive Resonance Theory (ART) neural network with fuzzy decision rule applied on neural network outputs to improve algorithm selectivity for a variety of real events not necessarily anticipated during training. Tuning of input signal preprocessing steps and enhanced supervised learning are implemented, and their influence on the algorithm classification capability is investigated. Simulation results show improved algorithm recognition capabilities when compared to a previous version of ART algorithm for each of the implemented scenarios.	Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA	Vasilic, S (reprint author), Texas A&M Univ, Dept Elect Engn, College Stn, TX 77843 USA.	svasilic@yahoo.com; kezunov@ee.tamu.ed					Aggarwal RK, 1999, IEEE T POWER DELIVER, V14, P1250, DOI 10.1109/61.796214; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; Bo ZQ, 1997, IEEE T POWER DELIVER, V12, P106, DOI 10.1109/61.568230; Butler KL, 1997, IEE P-GENER TRANSM D, V144, P429, DOI 10.1049/ip-gtd:19971433; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalstein T, 1996, IEEE T POWER DELIVER, V11, P740, DOI 10.1109/61.489330; DALSTEIN T, 1995, IEEE T POWER DELIVER, V10, P1002, DOI 10.1109/61.400828; Dash PK, 2001, IEEE T POWER DELIVER, V16, P68, DOI 10.1109/61.905593; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E; Fernandez ALO, 2002, IEEE T POWER DELIVER, V17, P894, DOI 10.1109/TPWRD.2002.803734; Fitton DS, 1996, IEEE T POWER DELIVER, V11, P748, DOI 10.1109/61.489331; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Jongepier AG, 1997, IEEE T POWER DELIVER, V12, P97, DOI 10.1109/61.568229; Keerthipala WWL, 1997, ELECTR POW SYST RES, V42, P109, DOI 10.1016/S0378-7796(96)01185-6; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kezunovic M, 1996, ENG INTELL SYST ELEC, V4, P57; Kezunovic M, 1996, IEEE COMPUT APPL POW, V9, P42, DOI 10.1109/67.539846; KEZUNOVIC M, 1995, ELECTR POW SYST RES, V34, P109, DOI 10.1016/0378-7796(95)00962-X; Kohonen T., 2001, SELF ORG MAPS, P501; Lewis W. A., 1947, AIEE T, V66, P694; Lin WM, 2001, IEEE T POWER DELIVER, V16, P473; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; PAO YH, 1989, ADAPTIVE PATTERN REC, P309; PAO YH, 1992, IEEE T POWER SYST, V7, P878, DOI 10.1109/59.141799; Poeltl A, 1999, IEEE T POWER DELIVER, V14, P1269, DOI 10.1109/61.796217; Powell MJD, 1987, ALGORITHMS APPROXIMA, P143; Pradhan AK, 2001, ELECTR POW SYST RES, V60, P1, DOI 10.1016/S0378-7796(01)00150-X; RISTANOVIC D, 2001, P 33 N AM POW S COLL, P470; Sanaye-Pasand M, 1999, IEEE T POWER DELIVER, V14, P782, DOI 10.1109/61.772315; SIDHU TS, 1995, IEEE T POWER DELIVER, V10, P697, DOI 10.1109/61.400862; Song YH, 1997, ELECTR POW SYST RES, V43, P125, DOI 10.1016/S0378-7796(97)01168-1; Udren EA, 1997, IEEE T POWER DELIVER, V12, P134, DOI 10.1109/61.568233; VASILIC S, 2001, P IEEE POW ENG SOC T; VASILIC S, 2002, P 14 POW SYST COMP C, V42, P1; VASILIC S, 2002, P IEEE POW ENG SOC P, V2, P918; WAN EA, 1990, P INT JOINT C NEUR N, P575; Wang HS, 1998, IEEE T POWER DELIVER, V13, P1093; Websper S, 1999, IEE P-GENER TRANSM D, V146, P209, DOI 10.1049/ip-gtd:19990232; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; *IEEE, 2000, IEEE GUID PROT REL A; 2002, USING MATLAB; 1992, ALTERNATIVE TRANSIEN	44	39	44	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0885-8977		IEEE T POWER DELIVER	IEEE Trans. Power Deliv.	APR	2005	20	2	2				1306	1314		10.1109/TPWRD.2004.834676		9	Engineering, Electrical & Electronic	Engineering	912RC	WOS:000228096100012	
J	Deshpande, U; Gupta, A; Basu, A				Deshpande, U; Gupta, A; Basu, A			Performance enhancement of a contract net protocol based system through instance-based learning	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						contract net protocol (CNP); distributed problem solving; instance-based learning (IBL); multiagent systems	COMMUNICATION	The contract net protocol (CNP) is a widely used coordination mechanism in multiagent systems. It has a lot of communication overhead due to the broadcast of the task announcements. The performance of the CNP degrades drastically when the number of communicating agents and the number of tasks announced increases. Hence, it has problems of scalability. In order to overcome this limitation, an instance-based learning (IBL) mechanism is designed that uses previously stored instances in order to select a target agent. This avoids the expensive bidding process. The scheme is implemented in a simulated distributed hospital system where the CNP is used for resource sharing across hospitals. Experimental results demonstrate that with the incorporation of the IBL, the system performance improves significantly. The system is better scalable with respect to the number of tasks.	VNIT, Nagpur, Maharashtra, India; Indian Inst Technol, Kharagpur 721302, W Bengal, India	Deshpande, U (reprint author), VNIT, Nagpur, Maharashtra, India.	uad@vnitnagpur.ac.in; agupta@cse.iitkgp.ernet.in; anupam@cse.iitkgp.ernet.in					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS R, 1983, ARTIF INTELL, V20, P63, DOI 10.1016/0004-3702(83)90015-2; Decker K, 2000, AUTON AGENT MULTI-AG, V3, P133, DOI 10.1023/A:1010074611407; Decker KS, 1995, P 1 INT C MULT SYST, P73; DECKER KS, 1995, THESIS UMASSACHUSETT; DESHPANDE U, 2002, IITKGPCSEAB20021; Deshpande U, 2004, IEEE T SYST MAN CY B, V34, P1299, DOI 10.1109/TSMCB.2003.818535; Deshpande U, 2004, APPL SOFT COMPUT, V5, P101, DOI 10.1016/j.asoc.2004.06.001; DESHPANDE U, 2002, P 10 INT C COOP INF, P503; Duda R., 1973, PATTERN CLASSIFICATI; DURFEE EH, 2001, IEEE COMPUT, V34, P39; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Hertz J., 1991, INTRO THEORY NEURAL; JOHASZ Z, 2002, P 2 INT WORKSH AG BA; Ohko T, 1997, LECT NOTES ARTIF INT, V1221, P242; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAMAMRITHAM K, 1989, IEEE T COMPUT, V38, P1110, DOI 10.1109/12.30866; RANA OF, 2000, AUTONOMOUS AGENTS 20; SEN S, 1999, MULTIAGENT SYSTEMS M; SMITH RG, 1980, IEEE T COMPUT, V29, P1104; Terabe M, 1997, LECT NOTES ARTIF INT, V1221, P168; WATSON I, 1994, KNOWL ENG REV, V9, P327; Yager R., 1981, DECISION SCI, V12, P589, DOI 10.1111/j.1540-5915.1981.tb00111.x; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	26	5	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	APR	2005	35	2					345	358		10.1109/TSMCB.2004.842256		14	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	907WD	WOS:000227747900015	
J	Yang, CY; Chou, JJ				Yang, CY; Chou, JJ			A comparative evaluation approach for the classification of rotifers with modified non-parametric kNN	IMAGE AND VISION COMPUTING			English	Article						biological identification; microscopic rotifer image; k-nearest-neighbor rule; pattern recognition; classification; modified model	PATTERN-RECOGNITION; MOMENT INVARIANTS	In this study-aimed to achieve optimal accuracy in the classification of rotifers according to the number of eggs carried-several modifications to the basic kNN method have been proposed and assessed. Six distinct kNN rules as well as several additional hybrid models were, in fact, devised or employed and their precision compared. Meanwhile, the data sets used in the evaluation of each of these methods were acquired from rotifer images generated via the shape moments approach. Both the original data sets and the edited ones, formed by removing outliers from the originals, were used in the evaluation of these adjusted models. Through a process of comparative evaluation, several of the modified algorithms proposed-comprising both individual and hybrid models-were found to perform better overall than the classical kNN method. Refinements related to class-size weighting, in particular, were shown to heighten the accuracy of the classical kNN model considerably. Close evaluation of the various models created revealed kNN-CCS and F-kNN-CCS, in their application to the edited data sets, to be the most reliable individual modified and hybrid models respectively, with levels of accuracy greater than 95%. (C) 2004 Elsevier B.V. All rights reserved.	Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan; No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei 112, Taiwan	Chou, JJ (reprint author), Natl Taiwan Univ, Dept Bioind Mechatron Engn, 1 Roosevelt Rd,Sect 4, Taipei 106, Taiwan.	jjchou@ntu.edu.tw					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1991, IEEE COMPUTER SOC; Dasarathy B. V., 1977, Proceedings of the International Conference on Cybernetics and Society; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fukunaga K., 1990, INTRO STAT PATTERN R; HOFF F H, 1997, PLANKTON CULTURE MAN; HU M, 1962, IRE T INFORM THEOR, V8, P179; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; SCHALFOFF JR, 1992, PATTERN RECOGNITION; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yang CY, 2000, AQUACULT ENG, V24, P33, DOI 10.1016/S0144-8609(00)00065-0	14	3	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0262-8856		IMAGE VISION COMPUT	Image Vis. Comput.	APR 1	2005	23	4					427	439		10.1016/j.imavis.2004.11.004		13	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Optics	Computer Science; Engineering; Optics	900NR	WOS:000227222100006	
J	Toussaint, G				Toussaint, G			Geometric proximity graphs for improving nearest neighbor methods in instance-based learning and data mining	INTERNATIONAL JOURNAL OF COMPUTATIONAL GEOMETRY & APPLICATIONS			English	Article; Proceedings Paper	International Conference on Computational Science and Its Applications (ICCSA 2003)3rd International Workshop on Computational Geometry and Applications (CGA 2003)	MAY 18-21, 2003MAY 18-21, 2003	MONTREAL, CANADAMontreal, CANADA	CERCA, IBM Canada, IBM, United States, Heuchera Technol, Pallas, Queens Univ Belfast, SHARCNET, Soc Ind & Appl Math, Springer Verlag		instance-based learning; proximity graphs; nearest-neighbor methods; data mining	PIECEWISE-LINEAR CLASSIFIERS; PATTERN-CLASSIFICATION PERCEPTRONS; NEURAL-NETWORK; PROTOTYPE OPTIMIZATION; VECTOR QUANTIZATION; GENETIC ALGORITHMS; FINDING PROTOTYPES; FEATURE-SELECTION; OUTLIER DETECTION; AUTOMATED DESIGN	In the typical nonparametric approach to classification in instance-based learning and data mining, random data (the training set of patterns) are collected and used to design a decision rule (classifier). One of the most well known such rules is the k-nearest-neighbor decision rule (also known as lazy learning) in which an unknown pattern is classified into the majority class among its k nearest neighbors in the training set. Several questions related to this rule have received considerable attention over the years. Such questions include the following. How can the storage of the training set be reduced without degrading the performance of the decision rule? How should the reduced training set be selected to represent the different classes? How large should k be? How should the value of k be chosen? Should all k neighbors be equally weighted when used to decide the class of an unknown pattern? If not, how should the weights be chosen? Should all the features (attributes) we weighted equally and if not how should the feature weights be chosen? What distance metric should be used? How can the rule be made robust to overlapping classes or noise present in the training data? How can the rule be made invariant to scaling of the measurements? How can the nearest neighbors of a new point be computed efficiently? What is the smallest neural network that can implement nearest neighbor decision rules? Geometric proximity graphs such as Voronoi diagrams and their many relatives provide elegant solutions to these problems, as well as other related data mining problems such as outlier detection. After a non-exhaustive review of some of the classical canonical approaches to these problems, the methods that use proximity graphs are discussed, some new observations are made, and open problems are listed.	McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada	Toussaint, G (reprint author), McGill Univ, Sch Comp Sci, 3480 Univ St,McConnell Engn Bldg,Room 318, Montreal, PQ H3A 2A7, Canada.	godfried@cs.mcgill.ca					AGUILAR JS, 2000, P 14 EUR C ART INT B, P215; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALOUPIS G, 2001, P 13 CAN C COMP GEOM, P21; Aloupis G, 2002, COMPUT STAT DATA AN, V40, P223, DOI 10.1016/S0167-9473(02)00032-4; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; ANDERSON TW, 1966, P 1 INT S MULT AN; ANDRADE DV, 2001, P 13 CAN C COMP GEOM; Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Arya S, 1996, DISCRETE COMPUT GEOM, V16, P155, DOI 10.1007/BF02716805; AVESANI P, 1999, P INT WORKSH SIM SEA; AVIS D, 1982, ANN NY ACAD SCI, V440, P323; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bandyopadhyay D., 2004, P 15 ACM SIAM S DISC, P410; Baram Y, 2000, PATTERN RECOGN, V33, P177, DOI 10.1016/S0031-3203(99)00050-3; Baras JS, 1999, IEEE T INFORM THEORY, V45, P1911, DOI 10.1109/18.782112; BARNETT V., 1994, OUTLIERS STAT DATA; BARREIS ER, 1989, EXEMPLAR BASED KNOWL; BAY SD, 2003, P ACM C KNOWL DISC D; BELUR V, 1994, IEEE T SYST MAN CYB, V24, P511; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Bermejo S, 1999, PATTERN RECOGN, V32, P2077, DOI 10.1016/S0031-3203(99)00120-X; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; BHATTACHARYA B, 1998, P 14 INT C PATT REC, V1; BHATTACHARYA B, 2005, P 55 SESS INT STAT I; BHATTACHARYA BK, 1982, THESIS MCGILL U; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; BOSE NK, 1993, IEEE T NEURAL NETWOR, V4, P778, DOI 10.1109/72.248455; Boyer E, 2000, MATH COMPUT MODEL, V32, P1071, DOI 10.1016/S0895-7177(00)00191-6; Breiman L, 1984, CLASSIFICATION REGRE; Bremner D, 2003, LECT NOTES COMPUT SC, V2748, P451; BRIGHTON H, 2001, INSTANCE SELECTION C, P1; BRIGHTON H, 1999, PRINCIPLES DATA MINI; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Brito MR, 1997, STAT PROBABIL LETT, V35, P33, DOI 10.1016/S0167-7152(96)00213-1; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; Burges C. J. C., 1996, P 13 INT C MACH LEAR, P71; Burges CJC, 1997, ADV NEUR IN, V9, P375; BUSTOS B, 2001, P 21 C CHIEL COMP SC, P33; CANO JR, 2004, PATTERN RECOGNITION; Caruana R., 1994, P 11 INT C MACH LEAR, P28; CERVERON V, 1998, LECT NOTES COMPUTER, P248; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHANG IE, 1991, ADV NEURAL INFORMATI, V3, P797; CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520; CHEN JH, 2005, INT J APPROXIMATE RE; Chen YQ, 1997, IEEE T CIRCUITS-I, V44, P622; CLARKSON KL, 1997, P 29 ANN ACM S THEOR, P609, DOI 10.1145/258533.258655; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; Dasarathy B. V., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.906169; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; DASGUPTA S, 1980, SANKHYA A, V42, P219; Datta P., 1997, P 14 NAT C ART INT, P82; DEBERG M, 2002, 18 EUR WORKSH COMP G; DECAESTECKER C, 1994, P 1994 IEEE INT C NE, P263; Decaestecker C, 1997, PATTERN RECOGN, V30, P281, DOI 10.1016/S0031-3203(96)00072-6; de Mantaras RL, 1998, DATA KNOWL ENG, V25, P99; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; Devijver P. A., 1982, PATTERN RECOGNITION; DEVINNEY J, IN PRESS DISCRETE AP; Devroye L. P., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing; Devroye L., 1991, NEAREST NEIGHBOR PAT, P101; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1988, COMPUT MATH APPL, V15, P53, DOI 10.1016/0898-1221(88)90071-5; Devroye L, 1996, PROBABILISTIC THEORY; Djouadi A, 1998, IEEE T PATTERN ANAL, V20, P567, DOI 10.1109/34.682188; Duda R., 1973, PATTERN CLASSIFICATI; Duda R. O., 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; DWYER R, 1993, TR9321 N CAR STAT U; DWYER RA, 1991, DISCRETE COMPUT GEOM, V6, P343, DOI 10.1007/BF02574694; DWYER RA, 1995, COMP GEOM-THEOR APPL, V5, P155, DOI 10.1016/0925-7721(94)00025-Q; Ekin O, 1999, INFOR, V37, P337; ESAT I, 1999, P 6 INT C NEUR INF P, V1, P366; Eskin E., 2002, DATA MINING SECURITY; Fix E., 1951, 4 USAF SCH AV MED; Florek K, 1951, C MATH, V2, P282; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUDA K, 2000, FREQUENTLY ASKED QUE; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gavrilova ML, 2002, J SUPERCOMPUT, V22, P87, DOI 10.1023/A:1014310721543; GAZULA S, 1995, IEEE T PATTERN ANAL, V17, P1239, DOI 10.1109/34.476519; Gentile C, 2001, IEEE T NEURAL NETWOR, V12, P1227, DOI 10.1109/72.950151; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; GOODMAN LA, 1954, J AM STAT ASSOC, P723; GOWDA KC, 1979, IEEE T INFORM THEORY, V25, P488, DOI 10.1109/TIT.1979.1056066; GROCHOWSKI M, 2004, LECT NOTES COMPUTER, P580; GUIBAS L, 1994, INTUITIVE GEOMETRY, P131; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; Hawkins D., 1980, IDENTIFICATION OUTLI; He ZY, 2004, EXPERT SYST APPL, V27, P681, DOI 10.1016/j.eswa.2004.07.002; HEATH D, 1993, COMP GEOM-THEOR APPL, V3, P289, DOI 10.1016/0925-7721(93)90019-3; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; HOULE ME, 2003, RT0517 IBM TOK RES L; Hoya T, 1998, IEEE T SIGNAL PROCES, V46, P2574, DOI 10.1109/78.709550; Huang YS, 2002, PATTERN RECOGN, V35, P1237, DOI 10.1016/S0031-3203(01)00124-8; HUANG YS, 1995, PATTERN RECOGN LETT, V16, P77, DOI 10.1016/0167-8655(94)00070-J; HUBER PJ, 1972, ANN MATH STAT, V43, P1041, DOI 10.1214/aoms/1177692459; ICHINO M, 1985, PATTERN RECOGN, V18, P161, DOI 10.1016/0031-3203(85)90040-8; Indyk P., 1998, P 30 ANN ACM S THEOR; Jain A., 1988, ALGORITHMS CLUSTERIN; JAIN AK, 1991, P INT JOINT C NEUR N, P515; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Jankowski N., 2004, LECT NOTES COMPUTER, P598; Jardine N., 1971, MATH TAXONOMY; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Jiang Y, 2004, LECT NOTES COMPUT SC, V3173, P356; KARACALI B, 2002, IEEE T NEURAL NETWOR, V14, P127; Keane M. T., 1995, P 14 INT JOINT C ART, P377; Keogh E., 1997, P 14 INT C MACH LEAR, P406; KEUNG CK, 2000, P 4 PAC AS C KNOWL D, P142; KIBLER D, 1988, P 3 EUR WORK SESS LE, P63; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KIM SW, 2003, IN PRESS PATTERN REC, V36; Kirkpatrick D., 1985, COMP GEOM-THEOR APPL, P217; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Kohonen T., 1995, SELF ORG MAP; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; Korn F., 2000, P 2000 ACM SIGMOD IN, P201, DOI DOI 10.1145/342009.335415; KORN F, 2002, P 28 VLDB C HONG KON; Krishna K, 2000, IEEE T NEURAL NETWOR, V11, P1361, DOI 10.1109/72.883447; KUBAT M, 2000, P 17 INT C MACH LEAR, P503; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; LALLICH S, 2005, APPL STOCHASTIC MODE; Lam W, 2002, PATTERN RECOGN, V35, P1491, DOI 10.1016/S0031-3203(01)00131-5; Lee CH, 1999, KNOWL-BASED SYST, V12, P363, DOI 10.1016/S0950-7051(99)00041-6; Limas MC, 2004, DATA MIN KNOWL DISC, V9, P171, DOI 10.1023/B:DAMI.0000031630.50685.7c; Ling CX, 1997, ARTIF INTELL REV, V11, P255, DOI 10.1023/A:1006560730186; Liotta G, 1998, COMP GEOM-THEOR APPL, V10, P1, DOI 10.1016/S0925-7721(97)00018-7; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Madigan D, 2002, DATA MIN KNOWL DISC, V6, P173, DOI 10.1023/A:1014095614948; Maheshwari A., 2002, P 14 CAN C COMP GEOM, P128; MARKOVITCH S, 1993, MACH LEARN, V10, P113, DOI 10.1007/BF00993503; MARTINEZHINAREJOS, 2003, PATTERN RECOGN LETT, V24, P173; MASS W, 2000, NEURAL COMPUT, V12, P2519; MASS W, 2000, ADV NEURAL INFOMATIO, V12; Masters A., 2001, J MACHINE LEARNING R, V2, P293; MATHAI A, 1975, BASIC CONCEPT INFORM; MATUSITA K, 1967, ANN I STAT MATH, V19, P181, DOI 10.1007/BF02911675; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; MCMORRIS FR, 2000, CONRR NUMER, V142, P149; Michael TS, 1999, MATH COMPUT MODEL, V29, P45, DOI 10.1016/S0895-7177(99)00061-8; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Mitiche A, 2001, NEURAL NETWORKS, V14, P575, DOI 10.1016/S0893-6080(01)00035-1; MOLLINEDA RA, 2002, IN PRESS PATTERN REC, V35; Moreno-Seco F, 2003, PATTERN RECOGN LETT, V24, P47, DOI 10.1016/S0167-8655(02)00187-3; MUHLENBACH F, 2004, P DISC SCE BERL HEID, P314; Muhlenbach F, 2004, J INTELL INF SYST, V22, P89, DOI 10.1023/A:1025832930864; MURPHY O, 1995, INFORM SCIENCES, V83, P133, DOI 10.1016/0020-0255(94)00066-K; MURPHY OJ, 1990, P IEEE, V78, P1595, DOI 10.1109/5.58344; NILSSON N. J., 1990, MATH FDN LEARNING MA; NOCK R, 2000, P INT C ALG LEARN TH, P224; Nock R., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000453; O'Rourke J, 1998, COMPUTATIONAL GEOMET; Okabe A., 1992, SPATIAL TESSELLATION; Olshen R., 1977, ANN STAT, V5, P632; OROURKE J, 1997, HDB DISCRETE COMPUTA, P797; OTTMANN T, 1995, 12 ANN S THEOR ASP C, P562; Pal NR, 1997, PATTERN RECOGN, V30, P847, DOI 10.1016/S0031-3203(96)00127-6; PANKAJ K, 1998, ADV DISCRETE COMPUTA; PAPADIMITRIOU C, 1980, AUTOMATA LANGUAGES P, V85, P470; PARK Y, 1989, J CLASSIF, V6, P195, DOI 10.1007/BF01908599; PARK Y, 1990, PATTERN RECOGN, V23, P1393, DOI 10.1016/0031-3203(90)90086-Z; PARK YH, 1991, P IEEE INT JOINT C N, P2386, DOI 10.1109/IJCNN.1991.170745; PATERSON MS, 1992, LECT NOTES COMPUT SC, V623, P416; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; PIERRE A, 1980, 5 INT C PATT REC MIA, P72; Porter WA, 1995, J FRANKLIN I, V332B, P155, DOI 10.1016/0016-0032(95)00032-9; PRIEBE C, 1998, 585 J HOPK U; Priebe CE, 2001, STAT PROBABIL LETT, V55, P239, DOI 10.1016/S0167-7152(01)00129-8; PRIEBE CE, 2002, 15 J HOPK U; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; RADKE JD, 1988, COMPUTATIONAL MORPHO, P105; Ramasubramanian V, 1997, DIGIT SIGNAL PROCESS, V7, P260, DOI 10.1006/dspr.1997.0300; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Rao SV, 2001, PATTERN RECOGN, V34, P2163, DOI 10.1016/S0031-3203(00)00144-8; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rosin PL, 1998, NEUROCOMPUTING, V20, P155, DOI 10.1016/S0925-2312(98)00008-3; Royall R., 1966, THESIS STANFORD U ST; SALZBERG S, 1995, IEEE T PATTERN ANAL, V17, P599, DOI 10.1109/34.387506; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Saradhi VV, 2001, PATTERN RECOGN, V34, P1047, DOI 10.1016/S0031-3203(00)00043-1; Schiavo RA, 2000, INT STAT REV, V68, P295, DOI 10.2307/1403415; SCHILLING MF, 1986, J AM STAT ASSOC, V81, P799, DOI 10.2307/2289012; SCUTURICI M, 2005, J EXPT THEORETICAL A, P1; SCUTURICI M, 2003, P 8 IB AM C PATT REC, P144; Sebban M, 2002, PATTERN RECOGN, V35, P835, DOI 10.1016/S0031-3203(01)00084-X; Sebban M, 1999, LECT NOTES ARTIF INT, V1704, P184; SEBBAN M, 1998, APPRENTISSAGE PRINCI, P139; SEBBAN M, 2001, P 18 INT C MACH LEAR; Seidel R., 1991, DIMACS SER DISCRETE, P517; SEN S, 1995, P 14 INT JOINT C ART, V1, P725; Shamos M., 1975, P 7 ANN ACM S THEOR, P224, DOI 10.1145/800116.803772; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Skalak D.B., 1993, P AAAI 93 CAS BAS RE, P64; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; SKLANSKY J, 1980, IEEE T PATTERN ANAL, V2, P101; Skurichina M, 2000, IEEE T NEURAL NETWOR, V11, P504, DOI 10.1109/72.839019; SMYTH SG, 1992, IEEE T NEURAL NETWOR, V3, P329, DOI 10.1109/72.125875; SOSS M, 1999, P 11 CAN C COMP GEOM, P43; SOSS M, 1998, P 10 CAN C COMP GEOM, P108; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STANOI I, 2002, ACM WORKSH RES ISS D; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; SU TH, 1991, COMPUTING, V46, P121, DOI 10.1007/BF02239166; Subhash C. B., 2003, PATTERN RECOGN, V36, P25; Syed N. A., 1999, P 5 ACM C KNOWL DISC, P272, DOI 10.1145/312129.312245; TAHANI H, 1996, P ICASSP, P3446; Tenmoto H, 1998, PATTERN RECOGN, V31, P1627, DOI 10.1016/S0031-3203(98)00016-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOUSSAINT GT, 1977, IEEE T SYST MAN CYB, V7, P300; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; TOUSSAINT GT, 1974, P 2 INT JOINT C PATT, P27; TOUSSAINT GT, 1974, P S STAT REL TOP OTT; Toussaint G. T., 1979, Proceedings of COMPSAC the IEEE Computer Society's Third International Computer Software and Applications Conference; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TOUSSAINT GT, 1994, PATTERN RECOGN LETT, V15, P797, DOI 10.1016/0167-8655(94)90007-8; TOUSSAINT GT, 1974, ANN I STAT MATH, V26, P389, DOI 10.1007/BF02479834; TOUSSAINT GT, 1975, IEEE T INFORM THEORY, V21, P99, DOI 10.1109/TIT.1975.1055311; TOUSSAINT GT, 1974, P C MEAS INF THEIR A; TOUSSAINT GT, 1988, COMPUTATIONAL MORPHO, P229; Toussaint G. T., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface; TOUSSAINT GT, 1977, P IEEE, V65, P275, DOI 10.1109/PROC.1977.10469; TOUSSAINT GT, 1980, P 5 S OP RES U KOLN, P425; TOUSSAINT GT, 1978, IEEE T SYST MAN CYB, V8, P482; TOUSSAIN.GT, 1971, IEEE T INFORM THEORY, V17, P618, DOI 10.1109/TIT.1971.1054686; TOUSSAINT GT, 1980, ELECTRON LETT, V16, P860, DOI 10.1049/el:19800611; Toussaint G. T., 1972, Information Processing Letters, V1, DOI 10.1016/0020-0190(72)90049-X; TSENG YH, 1995, IEEE T COMPUT, V44, P601; Tukey J. W., 1974, P INT C MATH VANC CA, P523; URQUHART R, 1982, PATTERN RECOGN, V15, P173, DOI 10.1016/0031-3203(82)90069-3; VAIDYA PM, 1989, DISCRETE COMPUT GEOM, V4, P101, DOI 10.1007/BF02187718; VAJDA I, 1969, METHODOLOGIES PATTER, P509; Vapnik N.V., 1998, STAT LEARNING THEORY; VINCENT P, 2001, 1197 U DEP IRO U MON; WAGNER TJ, 1973, IEEE T INFORM THEORY, V19, P696, DOI 10.1109/TIT.1973.1055059; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wettschereck D., 1995, P 1 INT C CAS BAS RE; WILFONG G, 1991, P 7 ANN ACM S COMP G, P224, DOI 10.1145/109648.109673; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; WONG MA, 1982, J AM STAT ASSOC, V77, P841, DOI 10.2307/2287316; Wu YQ, 2002, PATTERN RECOGN, V35, P2311, DOI 10.1016/S0031-3203(01)00132-7; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4; YANG CJ, 2002, P 7 INT DAT ENG APPL; Yen CW, 2004, PATTERN RECOGN LETT, V25, P725, DOI 10.1016/j.patrec.2004.01.012; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6; Zhang J., 1992, P 9 INT MACH LEARN C, P470; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zighed D. A., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); ZIGHED DA, 2005, APPL STOCHASTIC MODE	291	19	19	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-1959		INT J COMPUT GEOM AP	Int. J. Comput. Geom. Appl.	APR	2005	15	2					101	150		10.1142/S0218195905001622		50	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	925WX	WOS:000229085300002	
J	Amador, JJ				Amador, JJ			Markov random field approach to region extraction using Tabu Search	JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION			English	Article						Markov random field; Gibbs distribution; Tabu Search; region extraction	IMAGE INTERPRETATION; HEURISTICS; MODELS	This paper describes a region extraction algorithm based on the concept of Markov random fields. Markov random fields (MRFs) are characterized by using a Gibbs Distribution which equates back to the MRF. A heuristically developed energy functional is presented and used with the MRF in an efficient and accurate manner. Since the MRF used in this work is defined using the polar coordinate system, a very large search space exists for radial lengths and sites. To aid in pursuing these radial sites, a combinatorial optimization technique known as Tabu Search is exploited. Also provided is an extensive empirical study on aerial imagery and parts detection, in addition to a final discussion and description of future work. (c) 2004 Elsevier Inc. All rights reserved.	John F Kennedy Space Ctr, NASA, Kennedy Space Ctr, FL 32899 USA	Amador, JJ (reprint author), John F Kennedy Space Ctr, NASA, Kennedy Space Ctr, FL 32899 USA.	Jose.J.Amador@nasa.gov					AKSOY S, 1999, IEEE COMP SOC C COMP, V1, P63; ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R; Ball G. H., 1965, ISODATA NOVEL METHOD; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Blake A., 2000, ACTIVE CONTOURS; Canny J., 1986, PAMI, V8, P679; Castleman K. R., 1996, DIGITAL IMAGE PROCES; Costa L. da F., 2001, SHAPE ANAL CLASSIFIC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMARIUC B, 1997, 13 INT C DIG SIGN PR, V2, P857; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; DELAGNES P, 1996, 13 INT C PATT REC, V2, P800; Duda R., 1973, PATTERN CLASSIFICATI; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Glover F., 1997, TABU SEARCH; GLOVER F, 1990, INTERFACES, V20, P74, DOI 10.1287/inte.20.4.74; Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547; GUNSEL B, 1994, 12 IAPR INT C VIS SI, V2, P173; HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LI SZ, 1994, IEEE COMP SOC C COMP, P63; MANIEZZO V, 1995, EUR J OPER RES, V81, P188, DOI 10.1016/0377-2217(93)E0128-K; MARGALIT A, 1990, COMPUT VISION GRAPH, V51, P219, DOI 10.1016/0734-189X(90)90001-C; MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552; Nadabar SG, 1996, IEEE T PATTERN ANAL, V18, P326, DOI 10.1109/34.485560; Pirlot M, 1996, EUR J OPER RES, V92, P493, DOI 10.1016/0377-2217(96)00007-0; Roberts L. G., 1965, OPTICAL ELECTROOPTIC, P159; SCHLUTER D, 2000, INT C IM PROC, V2, P100; SINCLAIR M, 1993, COMPUT OPER RES, V20, P687, DOI 10.1016/0305-0548(93)90056-O; Tomasi C, 1998, IEEE T PATTERN ANAL, V20, P333, DOI 10.1109/34.667890	30	1	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1047-3203		J VIS COMMUN IMAGE R	J. Vis. Commun. Image Represent.	APR	2005	16	2					134	158		10.1016/j.vcir.2004.06.002		25	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	915VY	WOS:000228340700002	
J	Garrow, AG; Agnew, A; Westhead, DR				Garrow, AG; Agnew, A; Westhead, DR			TMB-Hunt: An amino acid composition based method to screen proteomes for beta-barrel transmembrane proteins	BMC BIOINFORMATICS			English	Article							OUTER-MEMBRANE PROTEINS; GRAM-NEGATIVE BACTERIA; DATA-BANK; SUBCELLULAR LOCATIONS; CRYSTAL-STRUCTURE; SIGNAL PEPTIDES; PREDICTION; IDENTIFICATION; CLASSIFICATION; ARCHITECTURE	Background: Beta-barrel transmembrane (bbtm) proteins are a functionally important and diverse group of proteins expressed in the outer membranes of bacteria ( both gram negative and acid fast gram positive), mitochondria and chloroplasts. Despite recent publications describing reasonable levels of accuracy for discriminating between bbtm proteins and other proteins, screening of entire genomes remains troublesome as these molecules only constitute a small fraction of the sequences screened. Therefore, novel methods are still required capable of detecting new families of bbtm protein in diverse genomes. Results: We present TMB-Hunt, a program that uses a k-Nearest Neighbour (k-NN) algorithm to discriminate between bbtm and non-bbtm proteins on the basis of their amino acid composition. By including differentially weighted amino acids, evolutionary information and by calibrating the scoring, an accuracy of 92.5% was achieved, with 91% sensitivity and 93.8% positive predictive value (PPV), using a rigorous cross-validation procedure. A major advantage of this approach is that because it does not rely on beta-strand detection, it does not require resolved structures and thus larger, more representative, training sets could be used. It is therefore believed that this approach will be invaluable in complementing other, physicochemical and homology based methods. This was demonstrated by the correct reassignment of a number of proteins which other predictors failed to classify. We have used the algorithm to screen several genomes and have discussed our findings. Conclusion: TMB-Hunt achieves a prediction accuracy level better than other approaches published to date. Results were significantly enhanced by use of evolutionary information and a system for calibrating k-NN scoring. Because the program uses a distinct approach to that of other discriminators and thus suffers different liabilities, we believe it will make a significant contribution to the development of a consensus approach for bbtm protein detection.	Univ Leeds, Sch Biochem & Microbiol, Leeds LS2 9JT, W Yorkshire, England	Westhead, DR (reprint author), Univ Leeds, Sch Biochem & Microbiol, Leeds LS2 9JT, W Yorkshire, England.	bmbagg@bmb.leeds.ac.uk; A.M.Agnew@leeds.ac.uk; D.R.Westhead@leeds.ac.uk					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Andrade MA, 1998, J MOL BIOL, V276, P517, DOI 10.1006/jmbi.1997.1498; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Bagos PG, 2004, NUCLEIC ACIDS RES, V32, pW400, DOI 10.1093/nar/gkh417; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, pD154, DOI 10.1093/nar/gki070; Barker GC, 1999, GENE, V229, P131, DOI 10.1016/S0378-1119(99)00039-6; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Berven FS, 2004, NUCLEIC ACIDS RES, V32, pW394, DOI 10.1093/nar/gkh351; Bigelow HR, 2004, NUCLEIC ACIDS RES, V32, P2566, DOI 10.1093/nar/gkh580; Bitter W, 2003, ARCH MICROBIOL, V179, P307, DOI 10.1007/s00203-003-0541-8; BRENNAN PJ, 1995, ANNU REV BIOCHEM, V64, P29, DOI 10.1146/annurev.biochem.64.1.29; Busch W, 2002, CRIT REV BIOCHEM MOL, V37, P287, DOI 10.1080/10409230290771528; Casadei R, 2003, GENE, V321, P185, DOI 10.1016/S0378-1119(03)00835-7; Casadio R, 2002, FEBS LETT, V520, P1, DOI 10.1016/S0014-5793(02)02758-8; Casadio R, 2003, PROTEIN SCI, V12, P1158, DOI 10.1110/ps.0223603; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chimento DP, 2003, NAT STRUCT BIOL, V10, P394, DOI 10.1038/nsb914; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eiben AE, 2002, INFORM PROCESS LETT, V82, P1, DOI 10.1016/S0020-0190(02)00204-1; ETZOLD T, 1993, COMPUT APPL BIOSCI, V9, P49; EVERETT KDE, 1995, J BACTERIOL, V177, P877; Faller M, 2004, SCIENCE, V303, P1189, DOI 10.1126/science.1094114; Fichera ME, 1997, NATURE, V390, P407, DOI 10.1038/37132; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Gardy JL, 2005, BIOINFORMATICS, V21, P617, DOI 10.1093/bioinformatics/bti057; Gobert GN, 2003, INT J PARASITOL, V33, P1561, DOI 10.1016/S0020-7519(03)00255-8; Gromiha MM, 2004, J COMPUT CHEM, V25, P762, DOI 10.1002/jcc.10386; Liu Q, 2003, COMPUT BIOL CHEM, V27, P69, DOI 10.1016/S0097-8485(02)00051-7; Liu Q, 2003, COMPUT BIOL CHEM, V27, P355, DOI 10.1016/S1476-9271(02)00085-3; Martelli Pier Luigi, 2002, Bioinformatics, V18 Suppl 1, pS46; Moller S, 2000, BIOINFORMATICS, V16, P1159, DOI 10.1093/bioinformatics/16.12.1159; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Nielsen H, 1997, PROTEIN ENG, V10, P1, DOI 10.1093/protein/10.1.1; Nielsen H, 1998, Proc Int Conf Intell Syst Mol Biol, V6, P122; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Oomen CJ, 2004, EMBO J, V23, P1257, DOI 10.1038/sj.emboj.7600148; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Postle K, 2000, NAT STRUCT BIOL, V7, P527, DOI 10.1038/76726; Rost B, 1996, PROTEIN SCI, V5, P1704; Schleiff E, 2003, PROTEIN SCI, V12, P748, DOI 10.1110/ps.0237503; Schulz GE, 2000, CURR OPIN STRUC BIOL, V10, P443, DOI 10.1016/S0959-440X(00)00120-2; Song LZ, 1996, SCIENCE, V274, P1859, DOI 10.1126/science.274.5294.1859; Thanassi DG, 2002, J BACTERIOL, V184, P6260, DOI 10.1128/JB.184.22.6260-6269.2002; Tusnady GE, 2004, BIOINFORMATICS, V20, P2964, DOI 10.1093/bioinformatics/bth340; van den Berg B, 2004, SCIENCE, V304, P1506, DOI 10.1126/science.1097524; Viklund H, 2004, PROTEIN SCI, V13, P1908, DOI 10.1110/ps.04625404; Wimley WC, 2002, PROTEIN SCI, V11, P301, DOI 10.1110/ps.29402; Wimley WC, 2003, CURR OPIN STRUC BIOL, V13, P404, DOI 10.1016/S0959-440X(03)00099-X; Yau WM, 1998, BIOCHEMISTRY-US, V37, P14713, DOI 10.1021/bi980809c; Ye JQ, 2004, EMBO J, V23, P3187, DOI 10.1038/sj.emboj.7600330; Zhai YF, 2002, PROTEIN SCI, V11, P2196, DOI 10.1110/ps.0209002; ZHANG CT, 1992, PROTEIN SCI, V1, P401; NCBI FTP	58	29	31	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2105		BMC BIOINFORMATICS	BMC Bioinformatics	MAR 15	2005	6								56	10.1186/1471-2105-6-56		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	915YC	WOS:000228346600001	
J	Muller, KR; Ratsch, G; Sonnenburg, S; Mika, S; Grimm, M; Heinrich, N				Muller, KR; Ratsch, G; Sonnenburg, S; Mika, S; Grimm, M; Heinrich, N			Classifying 'drug-likeness' with kernel-based learning methods	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							SUPPORT VECTOR MACHINE; CLASSIFICATION; COEFFICIENTS	In this article we report about a successful application of modern machine learning technology, namely Support Vector Machines, to the problem of assessing the 'drug-likeness' of a chemical from a given set of descriptors of the Substance. We were able to drastically improve the recent result by Byvatov et al. (2003) on this task and achieved an error rate of about 7% on unseen compounds using Support Vector Machines. We see a very high potential of such machine learning techniques for a variety of computational chemistry problems that occur in the drug discovery and drug design process.	Fraunhofer FIRST, D-12489 Berlin, Germany; Univ Potsdam, D-14482 Potsdam, Germany; Max Planck Soc, Friedrich Miescher Lab, D-72076 Tubingen, Germany; Idalab GmbH, D-10117 Berlin, Germany; Schering AG, Computat Chem, D-13342 Berlin, Germany	Sonnenburg, S (reprint author), Fraunhofer FIRST, Kekulestr 7, D-12489 Berlin, Germany.	soeren.sonnenburg@first.fraunhofer.de	Ratsch, Gunnar/B-8182-2009; Sonnenburg, Soeren/F-2230-2010; Muller, Klaus/C-3196-2013				Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Byvatov E, 2003, J CHEM INF COMP SCI, V43, P1882, DOI 10.1021/ci0341161; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVILLERS J, 1996, PRINCIPLES QSAR DRUG, V2; Fisher RA, 1936, ANN EUGENIC, V7, P179; GHOSE AK, 1986, J COMPUT CHEM, V7, P565, DOI 10.1002/jcc.540070419; GRAEPEL T, 1999, P ICANN 99, V1, P304; Sadowski J, 1998, J MED CHEM, V41, P3325, DOI 10.1021/jm9706776; Metz C. E., 1978, SEMINARS NUCL MED, V8, P4; MIKA S, 2001, ADV NEURAL INFORMATI, V13; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; ORR G, 1998, SPRINGER LNCS, V1524; Peterson KL, 2000, REV COMP CH, V16, P53, DOI 10.1002/9780470125939.ch2; Quinlan J. R., 1992, C4 5 PROGRAMS MACHIN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Vapnik V.N., 1995, NATURE STAT LEARNING; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; Zupan J., 1999, NEURAL NETWORKS CHEM; 1966, WORLD DRUG INDEX WDI; 1996, AVAILABLE CHEM DIREC	25	47	48	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596		J CHEM INF MODEL	J. Chem Inf. Model.	MAR-APR	2005	45	2					249	253		10.1021/ci049737o		5	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	911PZ	WOS:000228018000005	
J	Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM				Zanardelli, WG; Strangas, EG; Khalil, HK; Miller, JM			Wavelet-based methods for the prognosis of mechanical and electrical failures in electric motors	MECHANICAL SYSTEMS AND SIGNAL PROCESSING			English	Article						fault prognosis; wavelets; d.c. motors	FAULT-DETECTION; NEURAL-NETWORK; DC MOTOR; CLASSIFICATION; DIAGNOSIS	The ability to give a prognosis for failure of a system is a valuable tool and can be applied to electric motors. In this paper, three wavelet-based methods have been developed that achieve this goal. Wavelet and filter bank theory, the nearest-neighbour rule, and linear discriminant functions are reviewed. A framework for the development of a fault detection and classification algorithm based on the coefficients calculated from the discrete wavelet transform and using clustering is described. An experimental set-up based on RT-Linux is described and results from testing are presented, verifying the analysis. (C) 2003 Elsevier Ltd. All rights reserved.	Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA; Ford Motor Co, Dearborn, MI 48121 USA	Zanardelli, WG (reprint author), Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA.	zanardel@egr.msu.edu					Chen D, 2002, MECH SYST SIGNAL PR, V16, P695, DOI 10.1006/ymssp.1488; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Guo H, 1998, INTRO WAVELETS WAVEL; Liu XQ, 2000, IEEE T IND ELECTRON, V47, P1021; Moseler O, 2000, IEEE T IND ELECTRON, V47, P1015, DOI 10.1109/41.873209; Nejjari H, 2000, IEEE T IND APPL, V36, P730, DOI 10.1109/28.845047; Paya BA, 1997, MECH SYST SIGNAL PR, V11, P751, DOI 10.1006/mssp.1997.0090; Wang WJ, 2001, MECH SYST SIGNAL PR, V15, P685, DOI 10.1006/mssp.2000.1369; Webb A., 2002, STAT PATTERN RECOGNI; Young T. Y., 1974, CLASSIFICATION ESTIM; Zanardelli WG, 2002, IEEE POWER ELECTRONICS IN TRANSPORATION, P61; ZANARDELLI WG, 2001, IEEE INT S DIAGN EL, P591; ZANARDELLI WG, 2000, THESIS MICHIGAN STAT	14	18	22	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0888-3270		MECH SYST SIGNAL PR	Mech. Syst. Signal Proc.	MAR	2005	19	2					411	426		10.1016/j.umssp.2003.10.002		16	Engineering, Mechanical	Engineering	858NH	WOS:000224198000012	
J	Sanz, PJ; Marin, R; Sanchez, JS				Sanz, PJ; Marin, R; Sanchez, JS			Including efficient object recognition capabilities in online robots: From a statistical to a neural-network classifier	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS			English	Article						incremental learning; neural networks; object recognition; online robots		For those situations in which the user wants to interact with the system by using, for example, voice commands, it would be convenient to refer to the objects by their names (e.g., "cube") instead of other types of interactions (e.g., "grasp object 1"). Thus, automatic object recognition is the first step in order to acquire a higher level of interaction between the user and the robot. Nevertheless, applying object recognition techniques when the camera images are being transmitted through the web is not an easy task. In this situation, images cannot have a very high resolution, which affects enormously the recognition process due to the inclusion of more errors while digitalizing the real image. Some experiments with the Universitat Jaume I Online Robot evaluate the performance of different neural-network implementations, comparing it to that of some distance-based object recognition algorithms. Results will show which combination of object features, and algorithms (both statistical and neural networks) is more appropriate to our purpose in terms of both effectiveness and computing time.	Jaume Unvi 1, Dept Comp Sci, E-12071 Castellon de La Plana, Spain; Jaume Unvi 1, Programming Languages Dept, E-12071 Castellon de La Plana, Spain	Sanz, PJ (reprint author), Jaume Unvi 1, Dept Comp Sci, E-12071 Castellon de La Plana, Spain.	sanzp@uji.es; nnarin@uji.es; sanchez@uji.es					CHEN SC, 1994, J GASTROEN HEPATOL, V9, P1, DOI 10.1111/j.1440-1746.1994.tb01207.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox M.J., 1994, P 2 INT C WORLD WID; Dasarathy B.V., 1990, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI; FERWORN A, 1999, P IASTED C ROB APPL, P158; GOLDBERG K, 1995, P ACM SIGGRAPH, P135; GOLDBERG K, 1995, IEEE INT CONF ROBOT, P654, DOI 10.1109/ROBOT.1995.525358; GOLDBERG S, 1998, P IEEE IROS 98 WORKS, P55; Holmstrom L, 1997, IEEE T NEURAL NETWOR, V8, P5, DOI 10.1109/72.554187; HU M, 1962, IRE T INFORM THEOR, V8, P179; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013643; Marin R., 2002, Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292), DOI 10.1109/ROBOT.2002.1013644; MCKEE GT, 1996, ROBOTICS MACHINE PER, V5; PAULO E, 1999, P IEEE INT C ROB AUT, P1250; Preece J. J., 1994, HUMAN COMPUTER INTER; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Saucy P, 2000, IEEE ROBOT AUTOM MAG, V7, P41, DOI 10.1109/100.833574; Schalkoff R, 1992, PATTERN RECOGNITION; Schulz D, 2000, IEEE ROBOT AUTOM MAG, V7, P48, DOI 10.1109/100.833575; SIMMONS R, 1998, P IROS 98 WORKSH WEB, P43	22	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1094-6977		IEEE T SYST MAN CY C	IEEE Trans. Syst. Man Cybern. Part C-Appl. Rev.	FEB	2005	35	1					87	96		10.1109/TSMCC.2004.840055		10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	889YU	WOS:000226479600009	
J	Li, J; Manry, MT; Yu, CH; Wilson, DR				Li, J; Manry, MT; Yu, CH; Wilson, DR			Prototype classifier design with pruning	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article; Proceedings Paper	17th International FLAIRS Conference	MAY 17-19, 2004	Miami Beach, FL	FLAIRS		prototype selection; nearest neighbor classifier; editing; condensing; instance-based learning; pruning technology	NEAREST-NEIGHBOR RULE; CASE-BASE MAINTENANCE; LEARNING ALGORITHMS; PATTERN-CLASSIFICATION	Algorithms reducing the storage requirement of the nearest neighbor classifier (NNC) can be divided into three main categories: Fast searching algorithms, Instance-based learning algorithms and Prototype based algorithms. We propose an algorithm, LVQPRU, for pruning NNC prototype vectors and a compact classifier with good performance is obtained. The basic condensing algorithm is applied to the initial prototypes to speed up the learning process. The learning vector quantization (LVQ) algorithm is utilized to fine tune the remaining prototypes during each pruning iteration. We evaluate LVQPRU on several data sets along with 12 other algorithms using ten-fold cross-validation. Simulation results show that the proposed algorithm has high generalization accuracy and good storage reduction ratios.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA; Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.	li@wcn.uta.edu; randy@axon.cs.byu.edu					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BATCHELOR BG, 1978, PATTERN RECOGNITION; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GONG W, 1994, PROGR NEURAL NETWORK, V2, P253; Hassoun M. H., 1995, FUNDAMENTALS ARTIFIC; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Keogh E., 1997, P 14 INT C MACH LEAR, P406; Kohonen T., 1995, SELF ORG MAPS; Kohonen T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), DOI 10.1109/IJCNN.1990.137622; KUBAT M, 2000, P 17 INT C MACH LEAR, P503; LI J, 2004, P 17 INT C FLOR AI R, P706; Merz C. J., 1996, UCI REPOSITORY MACHI; Nock R., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000453; PAPADIMITRIOU HC, 1980, LECT NOTES COMPUTER, V85, P470; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Portinale L, 2001, COMPUT INTELL, V17, P263, DOI 10.1111/0824-7935.00144; ROZSYPAL A, 2001, P 18 INT C MACH LEAR, P449; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Sebban M., 2001, P 18 INT C MACH LEAR, P505; Sebban M., 2002, J MACHINE LEARNING R, V3, P863; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STEPHEN LC, 1994, J INTELL FUZZY SYST, V2, P267; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vapnik V.N., 1995, NATURE STAT LEARNING; Wan E A, 1990, IEEE Trans Neural Netw, V1, P303, DOI 10.1109/72.80269; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710; Yang Q, 2001, COMPUT INTELL, V17, P250, DOI 10.1111/0824-7935.00143; Zubek V. B., 2002, P 19 INT C MACH LEAR, P27	40	7	7	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130		INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	FEB-APR	2005	14	1-2					261	280		10.1142/S0218213005002090		20	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	986SA	WOS:000233468800015	
J	Vogt, P				Vogt, P			On the acquisition and evolution of compositional languages: Sparse input and the productive creativity of children	ADAPTIVE BEHAVIOR			English	Article; Proceedings Paper	16th Annual Meeting of the Human-Behavior-and-Evolution-Society (HBES)	JUL 21-25, 2004	Berlin, GERMANY	Human Behav & Evolut Soc		evolution of language; language acquisition; compositionality; iterated learning; language games	SIGN-LANGUAGE; EMERGENCE; COLOR	This paper investigates the productive creativity of children in a computational model of the emergence and evolution of compositional structures in language. In previous models it was shown that compositional structures can emerge in language when the language is transmitted from one generation to the next through a transmission bottleneck. Due to the fact that in these models language is transmitted only in a vertical direction where adults only speak to children and children only listen, this bottleneck needs to be imposed by the experimenter. In the current study, this bottleneck is removed and instead of having a vertical transmission of language, the language is-in most simulations-transmitted horizontally (i.e., any agent can speak to any other agent). It is shown that Such a horizontal transmission scenario does not need an externally imposed bottleneck, because the children face an implicit bottleneck when they start speaking early in life. The model is compared with the recent development of Nicaraguan Sign Language, where it is observed that children are a driving force for inventing grammatical (or compositional) structures, possibly due to a sparseness of nput (i.e., an implicit bottleneck). The results show that in the studied model children are indeed the creative driving force for the emergence and stable evolution of compositional languages, thus suggesting that this implicit bottleneck may-in part-explain why children are so typically good at acquiring language and, moreover, why they may have been the driving force for the emergence of grammar in language.	Univ Edinburgh, Language Evolut & Computat Res Unit, Sch Philosophy Psychol & Language Sci, Edinburgh EH8 9LL, Midlothian, Scotland	Vogt, P (reprint author), Univ Edinburgh, Language Evolut & Computat Res Unit, Sch Philosophy Psychol & Language Sci, 40 George Sq, Edinburgh EH8 9LL, Midlothian, Scotland.						BELPAEME T, 2005, ADAPTIVE BEHAV; Bickerton D, 1990, LANGUAGE SPECIES; BICKERTON D, 1984, BEHAV BRAIN SCI, V7, P173; Bloom P., 2000, CHILDREN LEARN MEANI; Braine M.D.S., 1971, LEARNING LANGUAGE; Brighton H, 2002, ARTIF LIFE, V8, P25, DOI 10.1162/106454602753694756; BRISCOE EJ, 2002, LINGUISTICS EVOLUTIO; Cangelosi A., 2002, SIMULATING EVOLUTION; Cavalli-Sforza LL, 1981, CULTURAL TRANSMISSIO; CHOMSKY N, 1980, BEHAV BRAIN SCI, V3, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Darwin C., 1968, ORIGIN SPECIES; Deacon Terence W, 1997, SYMBOLIC SPECIES; DEJONG ED, 1999, P 5 EUR C ART LIF, P689; Frege G., 1892, COLLECTED PAPERS MAT, P182; Gardenfors P, 2000, CONCEPTUAL SPACES; GILBERT N, 2005, P AISB 2005 SOC INSP, P57; Goldin-Meadow S., 1982, LANG ACQUIS, P51; Jackendoff R, 1999, TRENDS COGN SCI, V3, P272, DOI 10.1016/S1364-6613(99)01333-9; KEGL J, 1989, P 4 ANN M PAC LING C; Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430; Kirby S., 2002, LINGUISTIC EVOLUTION; Lieven E, 2003, J CHILD LANG, V30, P333, DOI 10.1017/S0305000903005592; Peters A., 1983, UNITS LANGUAGE ACQUI; PINKER S, 1990, BEHAV BRAIN SCI, V13, P707; PRIGOGINE I, 1984, ORDER CHAOS; Sankoff G., 1973, KIVUNG, V6, P32; Sebba M., 1997, CONTACT LANGUAGES PI; Senghas A, 2001, PSYCHOL SCI, V12, P323, DOI 10.1111/1467-9280.00359; Senghas A, 2004, SCIENCE, V305, P1779, DOI 10.1126/science.1100199; SMITH ADM, 2005, ADAPTIVE BEHAV; Smith K, 2003, LECT NOTES ARTIF INT, V2801, P507; Smith K, 2003, ADV COMPLEX SYST, V6, P537, DOI 10.1142/S0219525903001055; STEELS L, 1996, P 2 INT C MULT SYST, P338; Steels L, 2005, BEHAV BRAIN SCI, V28, P469; Steels L., 2002, TRANSITION LANGUAGE, P252; Steels L., 1996, ANIMALS ANIMATS, P562; Steels L., 2004, P ANN M ASS COMP LIN, P9, DOI 10.3115/1218955.1218957; Tomasello M, 2000, COGNITION, V74, P209, DOI 10.1016/S0010-0277(99)00069-4; van Zaanen M., 2000, P 18 INT C COMP LING, P961; Vogt P, 2003, LECT NOTES ARTIF INT, V2801, P535; Vogt P, 2005, ARTIF INTELL, V167, P206, DOI 10.1016/j.artint.2005.04.010; VOGT P, IN PRESS P IJCAI 05; VOGT P, 2005, P EUR C COMPL SYST E; VOGT P, 2005, P AISB 2005 SOC INS; Vogt P, 2005, BEHAV BRAIN SCI, V28, P509; Wray A, 1998, LANG COMMUN, V18, P47, DOI 10.1016/S0271-5309(97)00033-5; Zipf GK, 1949, HUMAN BEHAV PRINCIPL	48	12	12	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1059-7123		ADAPT BEHAV	Adapt. Behav.		2005	13	4					325	346		10.1177/105971230501300403		22	Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary	Computer Science; Psychology; Social Sciences - Other Topics	990KC	WOS:000233740700006	
S	Divina, F; Vogt, P		Capcarrere, MS; Freitas, AA; Bentley, PJ; Johnson, CG; Timmis, J		Divina, F; Vogt, P			Perceptually grounded lexicon formation using inconsistent knowledge	ADVANCES IN ARTIFICAL LIFE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th European Conference on Artificial Life	SEP 05-09, 2005	Canterbury, ENGLAND				EVOLUTION	Typically, multi-agent models for studying the evolution of perceptually grounded lexicons assume that agents perceive the same set of objects, and that there is either joint attention, corrective feedback or cross-situational learning. In this paper we address these two assumptions, by introducing a new multi-agent model for the evolution of perceptually grounded lexicons, where agents do not perceive the same set of objects, and where agents receive a cue to focus their attention to objects, thus simulating a Theory of Mind. In addition, we vary the amount of corrective feedback provided to guide learning word-meanings. Results of simulations show that the proposed model is quite robust to the strength of these cues and the amount of feedback received.	Tilburg Univ, Computat Linguist & AI Sect, NL-5000 LE Tilburg, Netherlands; Univ Edinburgh, LEC Unit, Edinburgh EH8 9YL, Midlothian, Scotland	Divina, F (reprint author), Tilburg Univ, Computat Linguist & AI Sect, NL-5000 LE Tilburg, Netherlands.	F.Divina@uvt.nl; paulv@ling.ed.ac.uk					AKHTAR N, 1999, FIRST LANGUAGE, V19, P347, DOI DOI 10.1177/014272379901905703; Bloom P., 2000, CHILDREN LEARN MEANI; Chouinard MM, 2003, J CHILD LANG, V30, P637, DOI 10.1017/S0305000903005701; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GONG T, 2004, LIFE, V9; HURFORD JR, 1989, LINGUA, V77, P187, DOI 10.1016/0024-3841(89)90015-6; Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430; Oliphant M, 1999, ADAPT BEHAV, V7, P371, DOI 10.1177/105971239900700309; Quine W. V. O., 1960, WORD OBJECT; SMITH ADM, 2003, ARTIF LIFE, V9, P559; STEELS L, 1996, SAB96; STEELS L, 1997, P 4 EUR C ART LIF CA; STEELS L, 2002, TRANSITION LANGUAGE, P214; Steels L, 1997, EVOLUTION COMMUNICAT, V1, P1, DOI 10.1075/eoc.1.1.02ste; Tomasello M., 1999, CULTURAL ORIGINS HUM; VOGT P, 2003, J ARTIFICIAL SOC SOC, V6, P1; VOGT P, 2005, P AISB 200K SOC INSP, P80; VOGT P, 2003, THSIM V3 2 TALK HEAD, P535; VOGT P, 2005, IN PRESS BEHAV BRAIN; VOGT P, 2000, EVOLUTION COMMUNICAT, V4, P89	20	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28848-1	LECT NOTES ARTIF INT			2005	3630						644	654				11	Computer Science, Artificial Intelligence	Computer Science	BDH67	WOS:000233583100065	
S	Angiulli, F		Famili, AF; Kok, JN; Pena, JM; Siebes, A; Feelders, A		Angiulli, F			Condensed nearest neighbor data domain description	ADVANCES IN INTELLIGENT DATA ANALYSIS VI, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Symposium on Intelligent Data Analysis	SEP 08-10, 2005	Madrid, SPAIN				CONVERGENCE; RULE	A popular method to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors distances in a reference data set lie within a certain threshold. In this work we investigate the possibility of using as reference set a subset of the original data set. We discuss relationship between reference set size and generalization, and show that finding the minimum cardinality reference consistent subset is intractable. Then, we describe an algorithm that computes a reference consistent subset with only two reference set passes. Experimental results confirm the effectiveness of the approach.	CNR, ICAR, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), CNR, ICAR, Via Pietro Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.	angiulli@icar.cnr.it					Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Breunig M., 2000, P ACM INT C MAN DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L, 1996, PROBABILISTIC THEORY; Eskin E., 2002, APPL DATA MINING COM; FIX E, 1951, 5 USAF SCH AV MED; Garey M. R., 1979, COMPUTER INTRACTABIL; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Ramaswamy S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Scholkopf B., 1995, P INT C KNOWL DISC D, P251; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; Tax D. M. J., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.906164; Tax D, 1999, P EUR S ART NEUR NET, P251; TOUSSAINT M, 2002, SOCS025 MCGILL U; Vapnik V.N., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; YPMA A, 1998, P ICANN	20	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28795-7	LECT NOTES COMPUT SC			2005	3646						12	23				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDA54	WOS:000232273600002	
S	Wang, JG; Neskovic, P; Cooper, LN		Wang, L; Chen, K; Ong, YS		Wang, JG; Neskovic, P; Cooper, LN			Locally determining the number of neighbors in the k-nearest neighbor rule based on statistical confidence	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			CLASSIFICATION; REGRESSION	The k-nearest neighbor rule is one of the most attractive pattern classification algorithms. In practice, the value of k is usually determined by the cross-validation method. In this work, we propose a new method that locally determines the number of nearest neighbors based on the concept of statistical confidence. We define the confidence associated with decisions that are made by the majority rule from a finite number of observations and use it as a criterion to determine the number of nearest neighbors needed. The new algorithm is tested on several realworld datasets and yields results comparable to those obtained by the knearest neighbor rule. In contrast to the k-nearest neighbor rule that uses a fixed number of nearest neighbors throughout the feature space, our method locally adjusts the number of neighbors until a satisfactory level of confidence is reached. In addition, the statistical confidence provides a natural way to balance the trade-off between the reject rate and the error rate by excluding patterns that have low confidence levels.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.	jigang@brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R.O., 2000, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED; Friedman J ., 1994, 113 STANF U STAT DEP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						71	80				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400009	
S	Li, YG; Hu, ZH; Cai, YZ; Zhang, WD		Wang, L; Chen, K; Ong, YS		Li, YG; Hu, ZH; Cai, YZ; Zhang, WD			Support vector based prototype selection method for nearest neighbor rules	ADVANCES IN NATURAL COMPUTATION, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			LEARNING ALGORITHMS; CLASSIFICATION	The Support vector machines derive the class decision hyper planes from a few, selected prototypes, the support vectors (SVs) according to the principle of structure risk minimization, so they have good generalization ability. We proposed a new prototype selection method based on support vectors for nearest neighbor rules. It selects prototypes only from support vectors. During classification, for unknown example, it can be classified into the same class as the nearest neighbor in feature space among all the prototypes. Computational results show that our method can obtain higher reduction rate and accuracy than popular condensing or editing instance reduction method.	Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200030, Peoples R China	Li, YG (reprint author), Shanghai Jiao Tong Univ, Dept Automat, 1954 Huashan Rd, Shanghai 200030, Peoples R China.	li_yuangui@sjtu.edu.cn.edu; huhzh@sjtu.edu.cn.edu; yzcai@sjtu.edu.cn.edu; wdzhang@sjtu.edu.cn.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; BURGES CJC, 1997, NEURAL INF PROCESSIN, V9; Burges C.J.C., 1996, 13 INT C MACH LEARN, P71; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Kecman V., 2001, LEARNING SOFT COMPUT; KEERTHI SS, 2001, NEURAL COMPUT, V13, P37; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; LeCun Y. A., 1995, P INT C ART NEUR NET, P53; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; Vapnik V, 1974, THEORY PATTERN RECOG; Vapnik V., 1982, ESTIMATION DEPENDENC; Vapnik V.N., 1995, NATURE STAT LEARNING; VISHWANATHAN SVN, 2001, HYBRID INF SYSTEMS, P19; Wang L, 2005, SUPPORT VECTOR MACHI; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28323-4	LECT NOTES COMPUT SC			2005	3610						528	535				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA22	WOS:000232222400068	
S	Wang, C; Chen, YQ		Wang, L; Chen, K; Ong, YS		Wang, C; Chen, YQ			Improving Nearest Neighbor classification with simulated gravitational collapse	ADVANCES IN NATURAL COMPUTATION, PT 3, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat			PROTOTYPES; RULE	The performance of the Nearest Neighbor classifier drops significantly with the increase of the overlapping of the distribution of different classes. To overcome this drawback, we propose to simulate the physical process of gravitational collapse to trim the boundaries of the distribution of each class to reduce overlapping. The proposed simulated gravitational collapse(SGC) algorithm is tested on 7 real-world data sets. Experimental results show that the nearest prototype classifier based on SGC outperforms conventional NN and k-NN classifiers.	Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Chen, YQ (reprint author), Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	chenyq@fudan.edu.cn					BEZDEK JC, 2000, INT J INTELL SYST, V16, P1445; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HITTER GL, 1976, IEEE T INFORMATION T, V21, P665; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LAVIGNA A, 1990, THESIS U MARYLAND; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Murphy P., 1994, UCI REPOSITORY MACHI; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P403	15	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28320-X	LECT NOTES COMPUT SC			2005	3612						845	854				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA32	WOS:000232246700104	
S	Lu, CD; Zhang, TY; Zhang, W; Yang, G		Wang, J; Liao, X; Wang, J		Lu, CD; Zhang, TY; Zhang, W; Yang, G			An experimental evaluation of linear and kernel-based classifiers for face recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2005, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd International Symposium on Neural Networks	MAY 30-JUN 01, 2005	Chongqing, PEOPLES R CHINA	Chongqing Univ, SW Normal Univ, Chongqing Univ, Posts& Telecommun, SW Agr Univ, Chongqing Educ Coll, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Natl Nat Sci Fdn China, K C Wong Educ Fdn Hong Kong				This paper presents the results of a comparative study of linear and kernel-based methods for face recognition. We focus mainly on the experimental comparison of classification methods, i.e. Nearest Neighbor, Linear Support Vector Machine, Kernel based Nearest Neighbor and Nonlinear Support Vector Machine. Some interesting conclusions can be obtained after all of these methods are performed on two well-known database, i.e. ORL, YALE Face Database, respectively.	Xian Jiaotong Univ, Dept Informat & Commun Engn, Xian 710059, Shaanxi, Peoples R China; Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA; Xian Inst Post & Telecommun, Dept Commun, Xian 710059, Shaanxi, Peoples R China	Lu, CD (reprint author), Xian Jiaotong Univ, Dept Informat & Commun Engn, Xian 710059, Shaanxi, Peoples R China.	congdelu@mailst.xjtu.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Gupta H., 2002, Proceedings Sixth IEEE Workshop on Applications of Computer Vision (WACV 2002), DOI 10.1109/ACV.2002.1182137; LI J, 2003, P 2003 IEEE INT C AC, V3, P121; LIU Q, 2002, P 5 IEEE INT C AUT F, P187; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik VN, 2000, NATURE STAT LEARNING; Yu K, 2002, NEURAL PROCESS LETT, V15, P147, DOI 10.1023/A:1015244902967	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-25913-9	LECT NOTES COMPUT SC			2005	3497						124	130				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCN40	WOS:000230167200021	
S	Mulligan, JB		Bebis, G; Boyle, R; Koracin, D; Parvin, B		Mulligan, JB			A tree-structured model of visual appearance applied to gaze tracking	ADVANCES IN VISUAL COMPUTING, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st International Symposium on Visual Computing	DEC 05-07, 2005	Lake Tahoe, NV	UNR, DRI, LBNL, NASA Ames, intel, Digital Persona, Equinox				In some computer vision applications, we may need to analyze large numbers of similar frames depicting various aspects of an event. In this situation, the appearance may change significantly within the sequence, hampering efforts to track particular features. Active shape models [1] offer one approach to this problem, by "learning" the relationship between appearance and world-state from a small set of hand-labeled training examples. In this paper we propose a method for partitioning the input image set which addresses two problems: first, it provides an automatic method for selecting a set of training images for hand-labeling; second, it results in a partitioning of the image space into regions suitable for local model adaptation. Repeated application of the partitioning procedure results in a tree-structured representation of the image space. The resulting structure can be used to define corresponding neighborhoods in the shape model parameter space; a new image may be processed efficiently by first inserting it into the tree, and then solving for model parameters within the corresponding restricted domain. The ideas are illustrated with examples from an outdoor gaze-tracking application.	NASA, Ames Res Ctr, Moffett Field, CA 94035 USA	Mulligan, JB (reprint author), NASA, Ames Res Ctr, Moffett Field, CA 94035 USA.						Carpenter R. H. S., 1977, MOVEMENTS EYES; Christoudias CM, 2005, PROC CVPR IEEE, P1067; COOTES TF, 2001, P SOC PHOTO-OPT INS, V4322, P236, DOI 10.1117/12.431093; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Gersho A., 1992, VECTOR QUANTIZATION; KOWLER E, 1990, EYE MOVEMENTS THEIR; Ohno T., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30750-8	LECT NOTES COMPUT SC			2005	3804						303	312				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BDP92	WOS:000234830800037	
J	Gibert, K; Sanchez-Marre, M; Flores, X				Gibert, K; Sanchez-Marre, M; Flores, X			Cluster discovery in environmental databases using GESCONDA: The added value of comparisons	AI COMMUNICATIONS			English	Article; Proceedings Paper	4th Workshop on Binding Environmental Sciences and Artificial Intelligence	AUG 22-23, 2004	Valencia, SPAIN			knowledge acquisition and management; clustering; cluster validation; data mining; machine learning; environmental databases; statistical modelling; wastewater treatment plant	KNOWLEDGE DISCOVERY	Clustering techniques have a great importance in knowledge discovery because they can find out new groups or clusters of objects within databases. Thus, they are unsupervised learning methods, very useful when facing unknown, unlabelled and ill-structured databases, as environmental databases are. In this paper, different clustering algorithms are analyzed and compared. They are used on a real environmental data set in order to study their impact in characterizing states in this kind of domains. The comparison of the methods is undertaken using the system GESCONDA, which is a prototype of a data mining tool. Environmental data used in this paper are from a Catalan wastewater treatment plant and refers to different variables of the plant at different spatial points along 149 days.	Tech Univ Catalonia, Dept Stat & Operat Res, Barcelona, Spain; Tech Univ Catalonia, Knowledge Engn & Machine Learning Grp, Barcelona, Spain; Univ Girona, Lab Engn Quim & Ambiental, Girona, Spain	Gibert, K (reprint author), Tech Univ Catalonia, Dept Stat & Operat Res, Barcelona, Spain.	karina.gibert@upc.edu	Sanchez-Marre, Miquel/A-8569-2011				ADRIANS P, 1998, DATA MINING; Ball G. H., 1965, ISODATA NOVEL METHOD; BRATKO I, 2000, ANAL ENV DATA MACHIN; Comas J, 2001, AI COMMUN, V14, P45; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMYANOV V, 2000, 2 ICSC S NEUR COMP N, P647; DUBES R, 1980, ADV COMPUTERS, V19; Gibert K, 1998, LECT NOTES ARTIF INT, V1510, P83; GIBERT K, 2004, T 2 BIENN M INT ENV, V1, P51; GIBERT K, 2003, LNCS, P2905; Gibert K., 1997, MATHWARE SOFT COMPUT, V4, P251; Gibert K, 1998, COMPUTACION SISTEMAS, V1, P213; GIMENO JM, PRACTICAL APPL DATA; Kanevski M, 2004, ENVIRON MODELL SOFTW, V19, P845, DOI 10.1016/j.envsoft.2003.03.004; MORABITO FC, 2001, NATO ADV RES WORKSH; NAKHAEIZADEH G, 1996, IFCS, V1, P17; ROUX M, 1985, ALGORITHMS CLASSIFIC; SANCHEZMARRE M, 2002, 1 INT C INT EMS SOC, P420; Sokal R. R., 1963, PRINCIPLES NUMERICAL; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Witten I.H., 1999, DATA MINING PRACTICA	21	3	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126		AI COMMUN	AI Commun.		2005	18	4					319	331				13	Computer Science, Artificial Intelligence	Computer Science	986HE	WOS:000233439900008	
S	Waagen, D; Shah, N; Ordaz, M; Cassabaum, M		Zeinio, EG; Garber, FD		Waagen, D; Shah, N; Ordaz, M; Cassabaum, M			Random subspaces and SAR classification efficacy	Algorithms for Synthetic Aperture Radar Imagery XII	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Algorithms for Symthetic Aperture Radar Imagery XII	MAR 28-31, 2005	Orlando, FL			random projections; dimensionality reduction; distance preserving projections; synthetic aperture radar; classification	SET	The 'curse of dimensionality' has limited the application of statistical modeling techniques to low-dimensional spaces, but typical data usually resides in high-dimensional spaces (at least initially, for instance images represented as arrays of pixel values). Indeed, approaches such as Principal Component Analysis and Independent Component Analysis attempt to extract a set of meaningful linear projections while minimizing interpoint distance distortions. The counterintuitive yet effective random projections approach of Johnson and Lindenstrauss defines a sample-based dimensionality reduction technique with probabilistically provable distortion bounds. We investigate and report on the relative efficacy of two random projection techniques for Synthetic Aperture Radar images in a classification setting.								Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI 10.1145/502512.502546; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA S, 1999, TR99066; DASGUPTA S, 2000, P UNCERTAINTY ARTIFI; DEYROYE L, 1996, PROBABILISITIC THEOR; DUDA RO, 2001, PATTERN CALSSIFICATI; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FRIEDMAN J, 1979, ANAL STAT, V7; Fukunaga K., 1990, INTRO STAT PATTERN R; Han P, 2003, P IEEE ICASSP, VII, P429; Hastie T, 2001, ELEMENTS STAT LEARNI; HERO AO, 2002, IEEE SIGNAL PROC SEP, P85; Johnson W. B., 1984, CONT MATH, V26, P189; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757; Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859; Scott D. W., 1992, MULTIVARIATE DENSITY; SILVERMAN BW, 1986, DENISTY ESTIMATION; Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475	20	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5793-0	P SOC PHOTO-OPT INS			2005	5808						257	268		10.1117/12.602523		12	Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BCU80	WOS:000231335900026	
S	Woon, FL; Knight, B; Petridis, M; Patel, M		MunozAvila, H; Ricci, F		Woon, FL; Knight, B; Petridis, M; Patel, M			CBE-conveyor: A case-based reasoning system to assist engineers in designing conveyor systems	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	6th International Conference on Case-Based Reasoning	AUG 23-26, 2005	Chicago, IL	Kaidara Software, Empolis, Naval Res Lab, PricewaterhouseCooper, AAAI			PREDICTION	In this paper, we address the use of CBR in collaboration with numerical engineering models. This collaborative combination has a particular application in engineering domains where numerical models are used. We term this domain "Case Based Engineering" (CBE), and present the general architecture of a CBE system. We define and discuss the general characteristics of CBE and the special problems which arise. These are: the handling of engineering constraints of both continuous and nominal kind; interpolation over both continuous and nominal variables, and conformability for interpolation. In order to illustrate the utility of the method proposed, and to provide practical examples of the general theory, the paper describes a practical application of the CBE architecture, known as CBE-CONVEYOR, which has been implemented by the authors. Pneumatic conveying is an important transportation technology in the solid bulks conveying industry. One of the major industry concerns is the attrition of powders and granules during pneumatic conveying. To minimize the fraction of particles during pneumatic conveying, engineers want to know what design parameters they should use in building a conveyor system. To do this, engineers often run simulations in a repetitive manner to find appropriate input parameters. CBE-Conveyor is shown to speed up conventional methods for searching for solutions, and to solve problems directly that would otherwise require considerable intervention from the engineer.	Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England	Woon, FL (reprint author), Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England.	f.woon@gre.ac.uk; b.knight@gre.ac.uk; m.petridis@gre.ac.uk; m.patel@gre.ac.uk					BERGMANN R, 2001, P 9 GERM WORKSH CAS; Chapelle P, 2004, ADV POWDER TECHNOL, V15, P31, DOI 10.1163/15685520460740052; CHATTERJEE N, 1994, LECT NOTES ARTIF INT, V837, P221; CHEETHAM W, 1997, P 2 INT C CAS BAS RE, P1; CHEETHAM W, 2001, P INT C CAS BAS REAS, P589; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kalapanidas E, 2001, ENVIRON MODELL SOFTW, V16, P263, DOI 10.1016/S1364-8152(00)00072-4; Kalman H, 2000, POWDER TECHNOL, V112, P244, DOI 10.1016/S0032-5910(00)00298-9; KNIGHT B, 2003, P 18 INT JOINT C ART, P1347; KNIGHT B, 2004, P 24 SPEC GROUP ART, P73; Kolodner J., 1993, CASE BASED REASONING; Schwabacher M, 1998, AI EDAM, V12, P173; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; WEINBERGER CB, 1986, POWDER TECHNOL, V48, P19, DOI 10.1016/0032-5910(86)80060-2; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOON F, 2003, P 5 INT C CAS BAS RE, P652	16	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28174-6	LECT NOTES ARTIF INT			2005	3620						640	651				12	Computer Science, Artificial Intelligence	Computer Science	BDF64	WOS:000233274900048	
S	Hsu, CC; Yang, CY; Yang, JS				Hsu, CC; Yang, CY; Yang, JS			Associating kNN and SVM for higher classification accuracy	COMPUTATIONAL INTELLIGENCE AND SECURITY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Conference on Computational Intelligence and Security	DEC 15-19, 2005	Xi'an, PEOPLES R CHINA	IEEE Computat Intelligence, Hong Kong Chapter, Xidian Univ, Hong Kong Baptist Univ, Natl Nat Sci Fdn China, Guangdong Univ Technol				The paper proposed a hybrid two-stage method of support vector machines (SVM) to increase its performance in classification accuracy. In this model, a filtering stage of the k nearest neighbor (kNN) rule was employed to collect information from training observations and re-evaluate balance weights for the observations based on their influences. The balance weights changed the policy of the discrete class label. A novel idea of real-valued class labels for transferring the balance weights was therefore proposed. Embedded in the class label, the weights given as the penalties of the uncertain outliers in the classification were considered in the quadratic programming of SVM, and produced a different hyperplane with higher accuracy. The adoption of kNN rule in the filtering stage has the advantage to distinguish the uncertain outliers in an independent way. The results showed that the classification accuracy of the hybrid model was higher than that of the classical SVM.	No Taiwan Inst Sci & Technol, Dept Mech Engn, Taipei, Taiwan; Tamkang Univ, Dept Mech & Electromech Engn, Taipei, Taiwan	Hsu, CC (reprint author), No Taiwan Inst Sci & Technol, Dept Mech Engn, 2 Xue Yuan Rd, Taipei, Taiwan.	692342792@s92.tku.edu.tw; cy.yang@ntist.edu.tw; 096034@mail.tku.edu.tw					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; HETTICH S, 1999, UCI KD ARCH; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang CY, 2004, LECT NOTES COMPUT SC, V3173, P506	7	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30818-0	LECT NOTES ARTIF INT			2005	3801						550	555				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDQ19	WOS:000234873700080	
S	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Wang, ZH; Qu, YL				Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Wang, ZH; Qu, YL			An improved kNN algorithm - Fuzzy kNN	COMPUTATIONAL INTELLIGENCE AND SECURITY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	International Conference on Computational Intelligence and Security	DEC 15-19, 2005	Xi'an, PEOPLES R CHINA	IEEE Computat Intelligence, Hong Kong Chapter, Xidian Univ, Hong Kong Baptist Univ, Natl Nat Sci Fdn China, Guangdong Univ Technol				As a simple, effective and nonparametric classification method, kNN algorithm is widely used in text classification. However, there is an obvious problem: when the density of training data is uneven it may decrease the precision of classification if we only consider the sequence of first k nearest neighbors but do not consider the differences of distances. To solve this problem, we adopt the theory of fuzzy sets, constructing a new membership function based on document similarities. A comparison between the proposed method and other existing kNN methods is made by experiments. The experimental results show that the algorithm based on the theory of fuzzy sets (fkNN) can promote the precision and recall of text categorization to a certain degree.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; Nipissing Univ, Dept Comp Sci, North Bay, ON P1B 8L7, Canada	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	shangwenqian@hotmail.com; haibinz@npissingu.ca					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gao Xin-Bo, 2000, Acta Electronica Sinica, V28; HEVISEOK L, 2002, P 9 INT C NEUR INF P, P732; IWAYAMA M, 1995, 18 ANN INT ACM SIGIR, P273; MASAND B, 1992, 15 ANN INT ACM SIGIR; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; van Rijsbergen CJ, 1979, INFORM RETRIEVAL; WANG J, 2000, J COMPUTER RES DEV B, V37, P518; YANG Y, 1999, 22 ANN INT ACM SIGIR; YU J, 2003, CHINESE J COMPUTERS, V26, P969; ZHAO S, 1987, METHOD FUZZY MATH PA	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-30818-0	LECT NOTES ARTIF INT			2005	3801						741	746				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDQ19	WOS:000234873700109	
S	Zachery, KN; Schultz, GM; Collins, LM		Harmon, RS; Broach, JT; Holloway, JH		Zachery, KN; Schultz, GM; Collins, LM			Force Protection Demining System (FPDS) detection subsystem	Detection and Remediation Technologies for Mines and Minelike Targets X, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Detection and Remediation Technologies for Mines and Minelike Targets X	MAR 28-APR 01, 2005	Orlando, FL	SPIE		landmine detection; GPSAR; EMI; sensor fusion	FEATURE-SELECTION; CLASSIFICATION; ASSIGNMENT; ALGORITHM; NETWORK	This study describes the U.S. Army Force Protection Demining System (FPDS); a remotely-operated, multisensor platform developed for reliable detection and neutralization of both anti-tank and anti-personnel landmines. The ongoing development of the prototype multisensor detection subsystem is presented, which integrates an advanced electromagnetic pulsed-induction array and ground penetrating synthetic aperture radar array on a single standoff platform. The FPDS detection subsystem is mounted on a robotic rubber-tracked vehicle and incorporates an accurate and precise navigation/positioning module making it well suited for operation in varied and irregular terrains. Detection sensors are optimally configured to minimize interference without loss in sensitivity or performance. Mine lane test data acquired from the prototype sensors are processed to extract signal- and image-based features for automatic target recognition. Preliminary results using optimal feature and classifier selection indicate the potential of the system to achieve high probabilities of detection while minimizing false alarms. The FPDS detection software system also exploits modern multi-sensor data fusion algorithms to provide real-time detection and discrimination information to the user.	Appl Res Associates Inc, Raleigh, NC USA	Zachery, KN (reprint author), Appl Res Associates Inc, Raleigh, NC USA.						ANDREWS A, 1999, E2416 IDA, P103; BAERTLEIN B, 2001, P UXO COUNT FOR ORL; BERTSEKAS DP, 1990, INTERFACES, V20, P133, DOI 10.1287/inte.20.4.133; BINS J, 2001, INT C COMP VIS VANC, V2, P159; BUFGES C, 1998, DATA MIN KNOWL DISC, V2, P121; CANDY BH, 1990, Patent No. 4894618; CANDY BH, 1996, Patent No. 5576624; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAS Y, 2001, 19719E EUR COMM JOIN, P128; DAS Y, 1990, IEEE T GEOSCI REMOTE, V28, P278, DOI 10.1109/36.54354; DUIN RPW, PRTOOLS4 MATLAB TOOL; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gader P, 2004, IEEE T GEOSCI REMOTE, V42, P2522, DOI 10.1109/TGRS.2004.837333; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI 10.1016/S0146-664X(75)80008-6; GOLUB G, 1990, MATRIX COMPUTATIONS, P581; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KRISHNAPURAM B, 2003, P 7 ANN INT C COMP M; Laws K. I., 1980, SPIE IMAGE PROCESSIN, V238, P376; LI Q, 2003, IEEE INT C DAT MIN, P163; MACDONALD J, 2003, WEAVER ALTERNATIVES, P335; Molina L.C., 2002, IEEE INT C DAT MIN M, P306; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raghu PP, 1998, IEEE T NEURAL NETWOR, V9, P516, DOI 10.1109/72.668893; SAMADZADEGAN F, FUSION TECNIQUES REM; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tourassi GD, 2001, MED PHYS, V28, P2394, DOI 10.1118/1.1418724; UNAY D, STEM END CALYX DETEC; VANDERHEIJDEN F, 2004, CLASSIFICATION PARAM, P423; XU X, 2002, IEEE ICIP; ZACHERY R, 2000, COMMUNICATION; Zhang Y, 2003, IEEE T GEOSCI REMOTE, V41, P1005, DOI 10.1109/TGRS.2003.810922; *BRTRC, COUNT TEST MAN SYST; *US DOD, 2000, LANDM CAS REP DEM IN, P138; *US GAO, 1996, GAONSIAD95197	39	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5779-5	P SOC PHOTO-OPT INS			2005	5794		1-2				1018	1029		10.1117/12.603021		12	Engineering, Multidisciplinary; Physics, Applied	Engineering; Physics	BCR67	WOS:000230951400101	
S	Pekalska, E; Duin, RPW				Pekalska, E; Duin, RPW			Dissimilarity Representation for Pattern Recognition: Foundations and Applications	DISSIMILARITY REPRESENTATION FOR PATTERN RECOGNITION: FOUNDATIONS AND APPLICATIONS	Series in Machine Perception and Artificial Intelligence		English	Book							RADIAL BASIS FUNCTIONS; HIGH-DIMENSIONAL DATA; NEAREST-NEIGHBOR CLASSIFICATION; CURVILINEAR COMPONENT ANALYSIS; ONE-CLASS CLASSIFIERS; ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; NATIVE HILBERT-SPACES; FINITE METRIC-SPACES; PROXIMITY DATA									Agarwala R, 1999, SIAM J COMPUT, V28, P1073; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ahsanullah M., 2000, APPL STAT SCI, VIV, P29; Akaike H, 1973, INT S INF THEOR, P267, DOI DOI 10.2307/2334537; Alpay D., 1997, SCHUR FUNCTIONS OPER; Anderberg M. R., 1973, CLUSTER ANAL APPL; ANDERSON TW, 1962, ANN MATH STAT, V33, P420, DOI 10.1214/aoms/1177704568; Arkadiev A., 1964, TEACHING COMPUTER PA; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Avesani P., 1999, INT WORKSH DAT EXP S, P223; Ayad H, 2004, LECT NOTES COMPUT SC, V3077, P144; BALL K, 1990, EUR J COMBIN, V11, P305; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; BARNETT V., 1994, OUTLIERS STAT DATA; Barthelemy J-P, 1991, TREES PROXIMITY REPR; Bartkowiak A, 2001, BIOMETRICAL LETT, V38, P11; Bartkowiak A, 2000, COMPUTATION STAT, V15, P3, DOI 10.1007/s001800050031; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Basri R, 1997, COMPUT VIS IMAGE UND, V65, P447, DOI 10.1006/cviu.1996.0497; Basri R, 1996, IEEE T PATTERN ANAL, V18, P465, DOI 10.1109/34.491630; Baulieu F, 1989, ALGEBR UNIV, V20, P351; Baulieu FB, 1997, J CLASSIF, V14, P159, DOI 10.1007/s003579900009; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M, 2002, ADV NEUR IN, V14, P585; Bellman R., 1957, DYNAMIC PROGRAMMING; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Belongie S, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P20; Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bennett KP, 1999, ADVANCES IN KERNEL METHODS, P307; Berchtold S., 1998, INT C DAT ENG ORL FL; Berg C., 1984, HARMONIC ANAL SEMIGR; Bertsekas DP, 1995, NONLINEAR PROGRAMMIN; Bezdek J.C, 1999, FUZZY MODELS ALGORIT; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; Bezdek JC, 2002, IEEE IJCNN, P2225, DOI 10.1109/IJCNN.2002.1007487; Bialynicki-Birula A, 1976, ALGEBRA LINIOWA GEOM; Billingsley P., 1995, PROBABILITY MEASURE; Bilmes J, 1997, ICSITR97021 U WASH; Birkholc A, 1986, ANALIZA MATEMATYCZNA; Bishop, 1995, NEURAL NETWORKS PATT; Bishop C., 1996, INT C P ART NEUR NET, P165; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; Blumenthal L, 1936, ERGEBNISSE EINES MAT, V7, P8; BLUMENTHAL L. M., 1953, THEORY APPL DISTANCE; Bnhmann J., 1994, INT C PATT REC JER I, VII, P207; BOGNAR J, 1974, INDEFINITE INNER PRO; Bonsangue MM, 1998, THEOR COMPUT SCI, V193, P1, DOI 10.1016/S0304-3975(97)00042-X; Bookstein A., 2001, LNCS, V2089, P86; Borg I., 1997, MODERN MULTIDIMENSIO; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078; Boyd S., 2003, CONVEX OPTIMIZATION; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Bradley P. S., 1998, INFORMS Journal on Computing, V10, DOI 10.1287/ijoc.10.2.209; Breiman L., 1996, 460 U CAL STAT DEP; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRETAGNO.J, 1966, ANN I H POINCARE B, V2, P231; Bruske J., 1997, LECT NOTES COMPUT SC, V1327, P595; Buhmann J., 1995, INT C ART NEUR NETW, P197; Bunke H, 2002, PATTERN ANAL APPL, V5, P23, DOI 10.1007/s100440200003; Bunke H., 2001, LECT NOTES COMPUT SC, V2013, P1; Bunke H., 1990, SYNTACTIC STRUCTURAL; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3; Caelli T., 2002, LNCS, V2396; Campbell C., 2000, ADV NEURAL INFORM PR, P395; Cayley A., 1841, CAMBRIDGE MATH J, Vii, P267; Cech E, 1966, TOPOLOGICAL SPACES; Cha S., 2000, INT C PATT REC, V2, P21; CHABRILLAC Y, 1984, LINEAR ALGEBRA APPL, V63, P283, DOI 10.1016/0024-3795(84)90150-2; CHAN TYT, 1992, PATTERN RECOGN, V25, P883, DOI 10.1016/0031-3203(92)90041-G; Chang C-C., 2001, LIBSVM LIB SUPPORT V; Chaudhuri BB, 1999, INFORM SCIENCES, V118, P159, DOI 10.1016/S0020-0255(99)00037-7; Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P1157, DOI 10.1016/0167-8655(96)00077-3; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790; Chepoi V, 2000, J MATH PSYCHOL, V44, P600, DOI 10.1006/jmps.1999.1270; Cherkassky V, 1998, LEARNING DATA CONCEP; Cho D., 2002, LOW COMPLEXITY MULTI; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Chung K.L., 2001, COURSE PROBABILITY T; Cilibrasi R, 2004, COMPUT MUSIC J, V28, P49, DOI 10.1162/0148926042728449; Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059; Cilibrasi R, 2004, AUTOMATIC MEANING DI; Cohen J., 1997, J COMPUTATIONAL BIOL, V4; Constantinescu T, 2001, COMMUN MATH PHYS, V216, P409, DOI 10.1007/s002200000336; Conway B, 1990, UNDERGRADUATE TEXTS; Corpet F, 2000, NUCLEIC ACIDS RES, V28, P267, DOI 10.1093/nar/28.1.267; Costa L. da F., 2001, SHAPE ANAL CLASSIFIC; Courrieu P, 2002, NEURAL NETWORKS, V15, P1185, DOI 10.1016/S0893-6080(02)00091-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox T., 1995, MULTIDIMENSIONAL SCA; Cox TF, 2000, J CLASSIF, V17, P101, DOI 10.1007/s003570000006; COXETER H. S. M., 1998, NONEUCLIDEAN GEOMETR; Cristianini N., 2000, SUPPORT VECTOR MACHI; Critchley F, 1997, LINEAR ALGEBRA APPL, V251, P145, DOI 10.1016/0024-3795(95)00558-7; CROUZEIX JP, 1982, MATH PROGRAM, V23, P193, DOI 10.1007/BF01583788; Csiszar I., 1967, STUD SCI MATH HUNG, V2, P299; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarthy B., 1991, NEAREST NEIGHBOR NN; Day M, 1944, DUKE MATH J, V11, P181, DOI 10.1215/S0012-7094-44-01118-X; de Carvalho F., 1998, DATA SCI CLASSIFICAT, P370; De Carvalho F.A.T., 1994, NEW APPROACHES CLASS, P387; de Ridder D., 2002, INT C PATT REC QUEB, V3, P244; de Ridder D., 1997, PATTERN RECOGNITION, V18; de Soete G., 1996, CLUSTERING CLASSIFIC, P157; de Veld D., 2003, LASER SURG MED, V23, P367; Debnath L., 1990, INTRO HILBERT SPACES; de Diego IM, 2004, LECT NOTES COMPUT SC, V3077, P102; DELVE, DELVE DAT EV LEARN V; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Denaeux T., BELIEF FUNCTIONS PAT; Denoeux T, 2004, IEEE T SYST MAN CY B, V34, P95, DOI 10.1109/TSMCB.2002.806496; de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333; De Ridder D, 2003, ADV IMAG ELECT PHYS, V126, P351, DOI 10.1016/S1076-5670(03)80019-8; DESOETE G, 1984, J CLASSIF, V1, P235; DESOETE G, 1984, QUAL QUANT, V18, P387; DESOETE G, 1984, PATTERN RECOGN LETT, V2, P133, DOI 10.1016/0167-8655(84)90036-9; Devijver P. A., 1982, PATTERN RECOGNITION; Devroye L, 1996, PROBABILISTIC THEORY; DEZA M, 1994, J COMPUT APPL MATH, V55, P217, DOI 10.1016/0377-0427(94)90021-3; Deza M. M., 1997, GEOMETRY CUTS METRIC; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Domingos P., 2000, INT C MACH LEARN, P231; Domingos P., 2000, INT C ART INT, P564; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Dritschel M., 1996, LECT OPERATOR THEORY, P141; Dubuisson M. P., 1994, P 12 INT C PATT REC, V1, P566, DOI DOI 10.1109/ICPR.1994.576361; Duch W, 2000, CONTROL CYBERN, V29, P937; Duch W., 1998, POL C THEOR APPL ART, P33; Duch W., 2000, APPL MATH COMPUTER S, V10, P101; Duda R. O., 2001, PATTERN CLASSIFICATI; Duin R., 2002, PATTERN RECOGNITION; Duin R., 1998, LECT NOTES COMPUTER, V1451, P611; Duin R., 2005, DATA COMPLE IN PRESS; Duin R., 2004, PATTERN REPRESENTATI, P43; Duin R. P. W., 1999, International Symposium on Pattern Recognition `In Memoriam Pierre Devijver'; Duin R. ., 2001, SCAND C IM AN BERG N; Duin RPW, 1998, KYBERNETIKA, V34, P399; Duin RPW, 1997, PATTERN RECOGN LETT, V18, P1159, DOI 10.1016/S0167-8655(97)00138-4; DUIN RPW, 2002, P 16 INT C PATT REC, V2, P765; Duin RPW, 1999, PATTERN RECOGN LETT, V20, P1175, DOI 10.1016/S0167-8655(99)00085-9; Duin RPW, 2002, PATTERN RECOGN LETT, V23, P493, DOI 10.1016/S0167-8655(01)00181-7; Dunford N, 1958, LINEAR OPERATORS 1; Edelman S, 1998, BEHAV BRAIN SCI, V21, P449; Edelman S., 1996, COGN SCI C; Edelman S, 1997, NEURAL COMPUT, V9, P701, DOI 10.1162/neco.1997.9.4.701; EDELMAN Shimon, 1999, REPRESENTATION RECOG; Effros E.G., 2000, OPERATOR SPACES; Eiben A. E., 2003, INTRO EVOLUTIONARY C; Esposito F., 2000, ANAL SYMBOLIC DATA; Everitt B.S., 2001, CLUSTER ANAL; Evgeniou T, 2000, ADV COMPUT MATH, V13, P1, DOI 10.1023/A:1018946025316; Faloutsos C, 1995, ACM SIGMOD, P163; FARACH M, 1995, ALGORITHMICA, V13, P155, DOI 10.1007/BF01188585; Feller W., 1968, INTRO PROBABILITY TH, V1; Feller W., 1971, INTRO PROBABILITY TH, V2; Fichtenholz G., 1997, RACHUNEK ROZNICZKOWY; Fiedler M., 1998, J LINEAR ALGEBRA, V3, P23; Fischer B., 2001, INT WORKSH EN MIN ME, P235; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Fred A., 2002, IEEE COMP SOC C COMP, P442; Fred A., 2003, LNCS, VII, P128; Fred ALN, 2002, INT C PATT RECOG, P276; Fred ALN, 2003, IEEE T PATTERN ANAL, V25, P944, DOI 10.1109/TPAMI.2003.1217600; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; Frelicot C., 1998, LECT NOTES COMPUTER, V1451, P707; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Friedman J ., 1994, 113 STANF U STAT DEP; Fu K. S., 1982, SYNTACTIC PATTERN RE; Fujie T, 1997, J GLOBAL OPTIM, V10, P367, DOI 10.1023/A:1008282830093; Fukunaga K., 1990, INTRO STAT PATTERN R; Gaal S. A., 1964, POINT SET TOPOLOGY; Garrett P., 2003, NOTES FUNCTIONAL ANA; Gascuel O, 2000, J CLASSIF, V17, P67, DOI 10.1007/s003570000005; Gascuel O, 1997, MOL BIOL EVOL, V14, P685; Gastl G., 1967, C CONV 1965, P104; Gavrila D., 2000, EUR C COMP VIS DUBL; Gavrila D. M., 1999, IEEE INT C COMP VIS; Gdalyahu Y., 1999, IEEE T PATTERN ANAL, V21, P1312; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Ghahramani S., 2000, FUNDMENTALS PROBABIL; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Gnilka S., 1995, COMMENT MATH HELV, V35, P147; Gnilka S., 1997, ANN SOC MATH POL 1, V37, P99; Gnilka S., 1994, COMMENT MATH HELV, V34, P81; Goldberg D. E, 1989, GENETIC ALGORITHMS S; GOLDFARB L, 1984, PATTERN RECOGN, V17, P575, DOI 10.1016/0031-3203(84)90056-6; Goldfarb L., 1985, PROGR PATTERN RECOGN, V2, P241; Goldfarb L., 2000, TR00137 U NEW BRUNSW; GOLDFARB L, 1992, PATTERN RECOGN, V25, P431, DOI 10.1016/0031-3203(92)90091-V; Goldfarb L., 2004, TR04165 U NEW BRUNS; Goldfarb L., 2000, TR00138 U NEW BRUNSW; Goldfarb L., 1992, INT C PATT REC NETH, VII, P660; Goldfarb L., 2001, TR01147 U NEW BRUNSW; GOLDFARB L, 1995, PATTERN RECOGN LETT, V16, P719, DOI 10.1016/0167-8655(95)00024-B; Goldfarb L., 1997, SYSTEMS MAN CYBERNET, V5, P4139; GOLDFARB L, 1990, PATTERN RECOGN, V23, P595, DOI 10.1016/0031-3203(90)90037-L; Goldstone R., 1998, LOCALIST CONNECTIONI, P283; Goldstone R., 1999, MIT ENCY COGNITIVE S, P763; GOLDSTONE RL, 1994, J EXP PSYCHOL LEARN, V20, P3, DOI 10.1037/0278-7393.20.1.3; Gordon A.D., 1996, CLUSTERING CLASSIFIC; Gould NIM, 2002, APPL OPTIM, V72, P149; GOWDA KC, 1991, PATTERN RECOGN LETT, V12, P259; Gower J., 1971, BIOMETRICS, V27, P25; Gower J., 1982, MATH SCI, P1; GOWER JC, 1969, ROY STAT SOC C-APP, V18, P54; GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809; Graepel T, 1999, ADV NEUR IN, V11, P438; Graepel T, 1999, IEE CONF PUBL, P304, DOI 10.1049/cp:19991126; Grenander U., 1978, LECT PATTERN THEORY, V2; GRENANDER U., 1976, LECT PATTERN THEORY, VI-III; Grenander U., 1981, LECT PATTERN THEORY, V3; Greub W., 1975, LINEAR ALGEBRA; Griffiths A., 1997, WORKSH CAS BAS REAS; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; Grunwald P. D., 2005, ADV MINIMUM DESCRIPT; Guerin-Dugue A, 1999, LECT NOTES COMPUT SC, V1607, P635; Guo P, 2002, IEEE T NEURAL NETWOR, V13, P757, DOI 10.1109/TNN.2002.1000144; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Hadlock F., 1978, UTILITAS MATHEMATICA, V13, P55; Hagedoorn M, 1999, INT J PATTERN RECOGN, V13, P1151, DOI 10.1142/S0218001499000653; Hagedoorn M., 1999, INT J COMPUT VISION, V31, P103; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Halmos P., 1974, MEASURE THEORY; Hampel F, 1986, ROBUST STAT APPROACH; Hand D., 1997, CONSTRUCTION ASSESME; Hansen J., 2000, INT C PATT REC BARC, VII, P207; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hartigan J., 1975, CLUSTERING ALGORITHM; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hastie T, 2001, ELEMENTS STAT LEARNI; Hathaway RJ, 2003, PATTERN RECOGN LETT, V24, P1563, DOI 10.1016/S0167-8655(02)00395-1; HEISER WJ, 1991, PSYCHOMETRIKA, V56, P7, DOI 10.1007/BF02294582; Herault J, 1999, LECT NOTES COMPUT SC, V1607, P625; Heskes T, 1998, NEURAL COMPUT, V10, P1425, DOI 10.1162/089976698300017232; Hettich S., 1998, UCI REPOSITORY MACHI; Hjorth P, 1998, LINEAR ALGEBRA APPL, V270, P255, DOI 10.1016/S0024-3795(98)80021-9; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Hofstadter DR, 1979, GODEL ESCHER BACH ET; Hoppner F., 1999, FUZZY CLUSTER ANAL; Horn R A, 1991, TOPICS MATRIX ANAL; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hoyle D., 2003, NEUR INF PROC SYST C; Hoyle D., 2004, PHYS REV E, VE; Hoyle DC, 2003, EUROPHYS LETT, V62, P117, DOI 10.1209/epl/i2003-00370-1; Hoyle DC, 2004, LECT NOTES COMPUT SC, V3120, P579, DOI 10.1007/978-3-540-27819-1_40; Huber P. J., 1981, ROBUST STAT; Hughes B, 2004, ADV MATH, V189, P148, DOI 10.1016/j.aim.2003.11.008; Hughes N., 2003, ADV NEURAL INFORM PR; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391; Indyk P, 2001, ANN IEEE SYMP FOUND, P10; Iohvidov I.S., 1982, INTRO SPECTRAL THEOR; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain A., 1988, ALGORITHMS CLUSTERIN; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Japkowicz N, 1995, INT JOINT CONF ARTIF, P518; Jardine N., 1971, MATH TAXONOMY; Jensen FV, 1996, INTRO BAYESIAN NETWO; Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8; Johnson W., 1987, LECT NOTES, V1267; Juszczak P., 2003, ICML WORKSH LEARN IM, P81; KARZANOV AV, 1985, MATH PROGRAM, V32, P183, DOI 10.1007/BF01586090; KASHYAP RL, 1982, IEEE T PATTERN ANAL, V4, P99; Kegl B, 2002, NEURAL INFORM PROCES; Kelley J., 1975, GEN TOPOLOGY; Kelly J., 1970, LECT NOTES MATH, V490, P17; KHALIMSKY E, 1990, TOPOL APPL, V36, P1, DOI 10.1016/0166-8641(90)90031-V; Khalimsky E., 1987, J APPL MATH SIMULATI, V1, P25, DOI 10.1155/S1048953388000036; Kim J., 1999, INTELLIGENT SYSTEMS; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Klein E., 1984, THEORY CORRES; Kohonen T., 2000, SELF ORG MAPS; Kong T., 1992, TOPOLOGY ITS APPL, V46; KONG TY, 1991, AM MATH MON, V98, P901, DOI 10.2307/2324147; Koppel M., 2004, INT C MACH LEARN; Korkin D., 2002, BIOINFORMATICS, V18, P303; Kothe G., 1969, TOPOLOGICAL VECTOR S, VI, p[456, xv]; Krauthgamer R, 2004, DISCRETE COMPUT GEOM, V31, P339, DOI 10.1007/s00454-003-2872-2; Kreyszig E., 1978, INTRO FUNCTIONAL ANA; Kreyszig E., 1991, DIFFERENTIAL GEOMETR; Kruskal J.B., 1977, STAT METHODS DIGITAL, P296; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Krysicki W., 1995, RACHUNEK PRAWDOPOD 2; Krysicki W., 1995, RACHUNEK PRAWDOPOD 1; Kuncheva L. I., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00093-3; Kuncheva L., 2004, COMBINING PATTERN CL; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Kuncheva LI, 2002, LECT NOTES COMPUT SC, V2364, P81; Kurcyusz S., 1982, MATEMATYCZNE PODSTAW; Lai C, 2004, INT J PATTERN RECOGN, V18, P867, DOI 10.1142/S0218001404003459; Lai C, 2002, LECT NOTES COMPUT SC, V2364, P212; Lam L., 2000, LECT NOTES COMPUTER, V1857, P78; LANCE GN, 1967, COMPUT J, V9, P373; Landgrebe D.A., 2003, SIGNAL THEORY METHOD; Lang S., 2004, LINEAR ALGEBRA; Laub J, 2004, J MACH LEARN RES, V5, P801; Lebourgeois F., 1996, INT C PATT REC, P256; Lee J., 2002, EUR S ART NEUR NETW; Lee J.A., 2000, ESANN 2000, P13; Lee M, SIMILARITY JUDGEMENT; Lemin A.J., 1985, SOV MATH DOKL, V32, P740; Leon S, 1998, LINEAR ALGEBRA APPL; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; Levina E., 2001, INT C COMP VIS VANC; Li M., 2003, ACM SIAM S DISCR ALG; Li Ming, 1997, INTRO KOLMOGOROV COM; Ligteringen R., 1997, ANN C ADV SCH COMP I; Lin D., 1998, ICML 98, P296; Linial N, 2002, INT C MATH BEIJ CHIN; Liu T.-L., 1999, ICCV; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; MacKay D., 2003, INFORM THEORY INFERE; MacQueen J., 1967, 5 BERK S MATH STAT P, P281; Malerba D., 2001, JOINT C NEW TECHN TE; Malone S., 2000, 0006 RIC U DEP COMP; Malone SW, 2002, COMPUT STAT DATA AN, V41, P143, DOI 10.1016/S0167-9473(02)00145-7; Mangasarian OL, 1999, OPER RES LETT, V24, P15, DOI 10.1016/S0167-6377(98)00049-2; Manly B. F. J., 1994, MULTIVARIATE STAT ME; Eiter T, 1997, ACTA INFORM, V34, P109, DOI 10.1007/s002360050075; Manning C, 1999, FDN STAT NATURAL LAN; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296; MARTINEZ T, 1994, J NEURAL NETWORKS, V7, P507; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MATOUSEK J, 1990, COMMENTATIONES MATH, V31, P589; Matousek J., 2002, LECT DISCRETE GEOMET; McLachlan G. J., 1988, MIXTURE MODELS INFER; Menger K, 1931, AM J MATH, V53, P721, DOI 10.2307/2371222; METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232; MFEAT, MULT FEAT DAT UCI RE; Michalewicz Z., 1999, GENETIC ALGORITHMS D; Mico L, 1998, PATTERN RECOGN LETT, V19, P351, DOI 10.1016/S0167-8655(98)00007-5; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996; Moler M. F., 1993, NEURAL NETWORKS, V6, P525; Moreno-Seco F, 2003, PATTERN RECOGN LETT, V24, P47, DOI 10.1016/S0167-8655(02)00187-3; MORI G, 2001, P IEEE C COMP VIS PA, V1, P723; Mottl V. V., 2001, Pattern Recognition and Image Analysis, V11; Mottl V., 2001, INT WORKSH MACH LEAR; MOYA MM, 1993, WCNN'93 - PORTLAND, WORLD CONGRESS ON NEURAL NETWORKS, VOL III, P797; Munkres J., 2000, TOPOLOGY; Munoz A., 2003, INT C ART NEUR NETW, P217; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; Nadler M, 1993, PATTERN RECOGNITION; Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365; Ng A.Y., 2002, ADV NEURAL INFORM PR, V14; Noble B., 1988, APPL LINEAR ALGEBRA; olkopf B. Sch, 1999, IEEE T NEURAL NETWOR; Ong C., 2004, INT C MACH LEARN BRI; Paclik P, 2003, REAL-TIME IMAGING, V9, P237, DOI 10.1016/j.rti.2003.09.002; Paclik P., 2003, SPECTR IM WORKSH GRA; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; Parra L, 1996, NEURAL COMPUT, V8, P260, DOI 10.1162/neco.1996.8.2.260; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Paulsen V., 2002, CAMBRIDGE STUDIES AD, V78; Pekalska E., 2003, ADV NEURAL INFORM PR, V15; Pekalska E, 2002, DEALING DATA FLOOD M; Pekalska E., 1998, TN970362 DELFT U TEC; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E., 1999, C ADV SCH COMP IM HE; Pekalska E., 2002, INT C PATT REC QUEB, V3; PEKALSKA E, 2001, LECT NOTES COMPUTER, V2096, P359; Pekalska E, 2001, ELECTRON LETT, V37, P159, DOI 10.1049/el:20010121; Pekalska E, 2004, LECT NOTES COMPUT SC, V3138, P1145; Pekalska E, 2002, LECT NOTES COMPUT SC, V2364, P137; Pekalska E., 1998, TN970363 DELFT U TEC; Pekalska E., 1998, TN970361 DELFT U TEC; Pekalska E, 2002, J MACH LEARN RES, V2, P175, DOI 10.1162/15324430260185592; Pekalska E, 2004, LECT NOTES COMPUT SC, V3077, P122; Pekalska E., 2005, INT C COMP REC SYST; Pekalska E., 2005, PATTERN REC IN PRESS; Pekalska E., 2000, ICPR15 P 15 INT C PA, V2; Persoon E., 1974, 2ND P INT JOINT C PA; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25; Pisier G, 2003, LONDON MATH SOC LECT, V294; Press W. H., 1992, NUMERICAL RECIPES C; Pryce J, 1973, BASIC METHODS LINEAR; Puzicha J., 1997, IEEE INT C COMP VIS; Puzicha J, 1999, PATTERN RECOGN, V33, P617; Puzicha J., 1999, INT C COMP VIS KORF; Pyatkov S., 2002, OPERATOR THEORY NONC; Rabe-Hesketh S, 1997, ANAL PROXIMITY DATA; Raftery A., BAYESIAN MODEL SELEC; Ramasubramanian V, 2000, PATTERN RECOGN, V33, P1497, DOI 10.1016/S0031-3203(99)00134-X; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Ripley B. D., 1996, PATTERN RECOGNITION; Rish I, 2001, WORKSH EMP METH AI A; Robert C. P., 2001, BAYESIAN CHOICE; Rodrigues M, 2001, SERIES MACHINE PERCE, V42; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269; Roth V., 2003, ADV NEURAL INFORM PR, P841; Rousseeuw P., 1990, J AM STAT ASSOC, V85; ROUSSEEUW P. J., 1987, ROBUST REGRESSION OU; Rovnyak J, 1999, METHODS KREIN SPACE; Roweis S., 2002, ADV NEURAL INFORM PR, V14; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rubinstein Y., 1997, KDD, P49; Rubner Y., 1998, IEEE INT C COMP VIS, P59; Rubner Y., 1998, STANCSTN9886 STANF U; Rubner Y., 1999, THESIS STANFORD U; Rudin W, 1991, FUNCTIONAL ANAL; Rudin W, 1986, REAL COMPLEX ANAL; Sadovnichij V., 1991, THEORY OPERATORS; SAITOU N, 1987, MOL BIOL EVOL, V4, P406; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Santini S., 1996, INT C PATT REC VIENN; Santini S., 1997, INT C IM AN PROC FLO; SAUL LK, 2003, MACHINE LEARNING RES, V4, P119; SCANNELL JW, 1995, J NEUROSCI, V15, P1463; Schaback R, 2000, J COMPUT APPL MATH, V121, P165, DOI 10.1016/S0377-0427(00)00345-9; Schaback R, 1999, INT S NUM M, V132, P255; Schaback R., 2001, ADV PROBLEMS CONSTRU, V142; Schenker A, 2003, LECT NOTES COMPUT SC, V2726, P202; Schoenberg IJ, 1935, ANN MATH, V36, P724, DOI 10.2307/1968654; Schoenberg IJ, 1938, ANN MATH, V39, P811, DOI 10.2307/1968466; Schoenberg IJ, 1937, ANN MATH, V38, P787, DOI 10.2307/1968835; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; Scholkopf B., 1997, INT C ART NEUR NETW; Scholkopf B., 1997, IEEE T SIGNAL PROCES; Scholkopf B., 1998, NEURAL COMPUTATION, V10; Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Scholkopf B., 2000, ADV NEURAL INFORM PR; Scholkopf B., 1997, THESIS VERLAG MUNICH; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Scott D, 2004, COMPUTATIONAL STAT; Sebastian T., 2001, INT C IM PROC THESS; Sebastian T., 2003, SIGNAL PROC IN PRESS; Sebastian T. B., 2001, IEEE INT C COMP VIS, P755; Sebastian T.B., 2002, EUR C COMP VIS, V3, P731; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shewchuk J. R., 1994, INTRO CONJUGATE GRAD; Sierpinski W, 1952, GEN TOPOLOGY; SIMARD P, 1993, ADV NEURAL INFORMATI, V5, P50; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; Skurichina M., 2003, ARTIFICIAL NEURAL NE; Skurichina M., 2001, THESIS DELFT U TECHN; Smola AJ, 1999, ADV NEUR IN, V11, P585; Sokal RR, 1973, NUMERICAL TAXONOMY; Stadler B., 2001, ANN SOC MATH 1 UNPUB; Stadler B., 2001, BASIC PROPERTIES FIL; Stadler BMR, 2002, Z PHYS CHEM, V216, P217, DOI 10.1524/zpch.2002.216.2.217; Stadler BMR, 2001, J THEOR BIOL, V213, P241, DOI 10.1006/jtbi.2001.2423; Stadler P., 2002, BASIC PROPERTIES CLO; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Stephen G, 1998, STRING SEARCHING ALG; STREHL, 2002, J MACHINE LEARNING R, V3, P583; Strehl A., 2002, C ART INT AAAI 2002; Strehl A., 2000, NAT C ART INT WORKSH; Strehl A, 2002, THESIS U TEXAS AUSTI; Struik D. J., 1988, LECT CLASSICAL DIFFE; Surges Christopher J. C, 1998, ADV KERNEL METHODS S; Taneja I. J., GEN INFORM MEASURES; TANEJA IJ, 1995, ADV IMAG ELECT PHYS, V91, P37, DOI 10.1016/S1076-5670(08)70106-X; TANEJA IJ, 1989, ADV ELEC ELECT PHYS, V76, P327; Tarassenko L., 1995, IEE C PUBLICATION, V409; Tax D., 2001, THESIS DELFT U TECHN; Tax D., 2001, LNCS, V2096, P299; Tax D., 2004, INT C PATT REC CAMBR, V2; Tax D, 2003, DD TOOLS MATLAB TOOL; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Teh Y., 2003, ADV NEURAL INFORM PR, V15; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Terra E, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P244; Thayananthan A., 2003, IEEE C COMP VIS PATT; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Tipping M. E., 2000, ADV NEURAL INFORM PR; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Topchy A., 2004, INT C PATT REC CAMBR; Torgerson W.S., 1967, THEORY METHODS SCALI; Torsello A, 2003, PATTERN RECOGN LETT, V24, P1089, DOI 10.1016/S0167-8655(02)00255-6; Trosset M., 2000, STAT COMPUTING SECTI; Tukey J. W., 1960, CONTRIBUTIONS PROBAB, P448; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037//0033-295X.84.4.327; van der Heiden F., 2004, CLASSIFICATION PARAM; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Vasconcelos N., 2000, INT C PATT REC BARC; Vasconcelos N., 2000, INT C IM PROC THESS; Veltkamp R., 1999, UUCS199927; Veltkamp R., 2001, UUCS200103; Verma R., 1991, THESIS U TORONTO; VERVEER PJ, 1995, IEEE T PATTERN ANAL, V17, P81, DOI 10.1109/34.368147; VIDAL E, 1995, IEEE T PATTERN ANAL, V17, P899, DOI 10.1109/34.406656; Vitanyi P., 2005, IEEE ITSOC INF THEOR; von Luxburg U., 2003, ANN C COMP LEARN THE, P314; von Luxburg U, 2004, J MACH LEARN RES, V5, P669; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Watanabe S., 1974, PATTERN RECOGNITION; WEBB AR, 1995, PATTERN RECOGN, V28, P753, DOI 10.1016/0031-3203(94)00135-9; Webb AR, 1997, J CLASSIF, V14, P249, DOI 10.1007/s003579900012; Wells J. H., 1975, EMBEDDINGS EXTENSION; Werman M., 1995, IEEE T PATTERN ANAL, V17; Wharton C., 1992, ANN C COGN SCI SOC B, P588; Wilks S.S., 1962, MATH STAT; Willard S., 1970, GEN TOPOLOGY; Wilson C., 1992, HANDPRINTED CHARACTE; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wilson R., 2000, MACH LEARN, V38, P257; Wish M., 1978, MULTIDIMENSIONAL SCA; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0; Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; Young G, 1938, PSYCHOMETRIKA, V3, P19, DOI 10.1007/BF02287916; Ypma A., 1997, BRIT S APPL TIM FREQ, P69; Ypma A., 1998, ICANN 98. Proceedings of the 8th International Conference on Artificial Neural Networks; Zavrel J., 1997, BELG DUTCH C MACH LE, P139; Zha H., 2003, INT C MACH LEARN WAS; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [Anonymous], 2002, LNCS; [Anonymous], 2000, LNCS	533	122	122	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE	1793-0839	978-9-81270-317-0	SER MACH PERCEPT ART			2005	64						1	607		10.1142/9789812703170		607	Computer Science, Artificial Intelligence	Computer Science	BYZ15	WOS:000300784300019	
B	Jaeger, S; Ma, HF; Doermann, D			IEEE Computer Society	Jaeger, S; Ma, HF; Doermann, D			Identifying script on word-level with informational confidence	EIGHTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS 1 AND 2, PROCEEDINGS			English	Proceedings Paper	8th International Conference on Document Analysis and Recognition (ICDAR 2005)	AUG 29-SEP 01, 2005	Seoul, SOUTH KOREA	ABBYY Software House, BK 21 Sch Informat Technol KAIST, Elect & Telecommun Res Inst, Hitachi Cent Res Lab, IBM Corp, Int Assoc Pattern Recognit, Korea Adv Inst Sci & Technol, Korea Informat Sci Soc, Korea Sci & Engn Fdn, Minist Informat & Commun, Inst Informat Assessment, Microsoft			DOCUMENT IMAGES; CLASSIFICATION; RECOGNITION	In this paper we present a multiple classifier system for script identification. Applying a Gabor filter analysis of textures on word-level, our system identifies Latin and non-Latin words in bilingual printed documents. The classfier system comprises four different architectures based on nearest neighbors, weighted Euclidean distances, Gaussian mixture models, and support vector machines. We report results for Arabic, Chinese, Hindi, and Korean script. Moreover we show that combining informational confidence values using sum-rule can consistently outperform the best single recognition rate.	Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	Jaeger, S (reprint author), Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.	jaeger@umiacs.umd.edu; hfma@umiacs.umd.edu; doermann@umiacs.umd.edu					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; Jaeger S., 2004, Proceedings. Ninth International Workshop on Frontiers in Handwriting Recognition; Jaeger S, 2004, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2004.1334062; Joachims T., 1999, ADV KERNEL METHODS S, P41; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; MA H, 2004, P INT C DOC REC RETR, P178; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; SHANNON CE, 1948, AT&T TECH J, V27, P379; SIBUN P, 1994, P 4 C APPL NAT LANG, P115; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; TAN C, 1999, INT S INT MULT DIST, P59; Waked B, 1998, IEEE SYS MAN CYBERN, P4470; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192	16	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2420-6				2005							416	420		10.1109/ICDAR.2005.134		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BCZ12	WOS:000232022600082	
B	Yin, TK; Chiu, NT		Krishnapuram, R; Pal, N		Yin, TK; Chiu, NT			Fuzzy patterns and classification of functional brain images for the diagnosis of Alzheimer's disease	FUZZ-IEEE 2005: Proceedings of the IEEE International Conference on Fuzzy Systems: BIGGEST LITTLE CONFERENCE IN THE WORLD	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	IEEE International Conference on Fuzzy Systems	MAY 22-25, 2005	Reno, NV	IEEE, IEEE Neural Networks Soc			COMPUTER-AIDED DIAGNOSIS; CEREBRAL BLOOD-FLOW; MINIMIZATION APPROACH; NEURAL-NETWORK; C-MEANS; SYSTEM; SEGMENTATION; ALGORITHM; SPECT	Alzheimer's disease is a chronic degenerative disease of the central nervous system. Most common regional abnormalities for Alzheimer's disease are symmetric or asymmetric bilateral temporal or parietal hypoperfusion. Single-photon emission computed tomography (SPECT) is a useful tool in analyzing hypoperfusion in patients with Alzheimer's disease. The aim of this research is to provide a quantitatively automatic analysis of the SPECT scans for the diagnosis of Alzheimer's disease. A characteristic-point-based fuzzy inference classifier (CPFIC) is proposed to perform two-class classification. The closeness matrix is defined to determine the closeness between training samples, and constrained minimizations are used to systematically train the CPFIC. For comparison, experiments on nearest neighbor method and support vector machine (SVM) were also performed. In error rates, the proposed CPFIC is better than nearest neighbor method, but worse than SVM method. Although the CPFIC did not perform better than SVM in error rates, the summarizing information embedded in the patterns on characteristic points can complement SVM to provide more information to radiologists.	Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan	Yin, TK (reprint author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.						Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHANG CC, 2001, LIBSVM LIBR SUPPORT; Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chuang KH, 1999, IEEE T MED IMAGING, V18, P1117; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devous MD, 2002, EUR J NUCL MED MOL I, V29, P1685, DOI 10.1007/s000259-002-0967-2; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friston K J, 1995, HUMAN BRAIN MAPPING, V2, P165, DOI 10.1002/hbm.460030303; Friston KJ, 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Friston K.J., 1994, HUMAN BRAIN MAPPING, V1, P214; Haykin S., 1994, NEURAL NETWORKS COMP; IIDA H, 1994, J NUCL MED, V35, P2019; KUHL DE, 1982, J NUCL MED, V23, P196; Lee EW, 1998, IEEE T PATTERN ANAL, V20, P562; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; LUENBERGER D. G., 1989, LINEAR NONLINEAR PRO; OHNISHI T, 1995, J NUCL MED, V36, P1163; Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752; Sato K, 1996, IEEE T NUCL SCI, V43, P3230, DOI 10.1109/23.552723; SOKOLOFF L, 1981, FED PROC, V40, P2311; STONE M, 1974, J R STAT SOC B, V36, P111; Suykens JAK, 2002, NEUROCOMPUTING, V48, P85, DOI 10.1016/S0925-2312(01)00644-0; TERRY RD, 1994, ALZHEIMER DIS; Tolias YA, 1998, IEEE T MED IMAGING, V17, P263, DOI 10.1109/42.700738; Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389; WANG GJ, 1994, J NUCL MED, V35, P1457; Yin TK, 2004, IEEE T BIO-MED ENG, V51, P1286, DOI 10.1109/TBME.2004.827954; Yin TK, 2004, IEEE T FUZZY SYST, V12, P250, DOI 10.1109/TFUZZ.2004.825088; Yin TK, 2004, IEEE T MED IMAGING, V23, P639, DOI 10.1109/TMI.2004.826355	32	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-9158-6	IEEE INT CONF FUZZY			2005							161	166				6	Computer Science, Artificial Intelligence	Computer Science	BCR92	WOS:000230981000028	
S	Zhang, JP; Li, SZ; Wang, J		Wang, L; Jin, Y		Zhang, JP; Li, SZ; Wang, J			Geometrical probability covering algorithm	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat			CLASSIFICATION	In this paper, we propose a novel classification algorithm, called geometrical probability covering (GPC) algorithm, to improve classification ability. On the basis of geometrical properties of data, the proposed algorithm first forms extended prototypes through computing means of any two prototypes in the same class. Then Gaussian kernel is employed for covering the geometrical structure of data and used as a local probability measurement. By computing the sum of the probabilities that a new sample to be classified to the set of prototypes and extended prototypes, the classified criterion based on the global probability measurement is achieved. The proposed GPC algorithm is simple but powerful, especially, when training samples are sparse and small size. Experiments on several databases show that the proposed algorithm is promising. Also, we explore other potential applications such as outlier removal with the proposed GPC algorithm.	Fudan Univ, Dept Comp Sci & Engn, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China; Chinese Acad Sci, Inst Automat, Key Lab Complex Syst & Intelligence Sci, Beijing 100080, Peoples R China; Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China; Chinese Acad Sci, Inst Automat, Ctr Biometr & Secur Res, Beijing 100080, Peoples R China	Zhang, JP (reprint author), Fudan Univ, Dept Comp Sci & Engn, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200433, Peoples R China.	jpzhang@fudan.edu.cn; szli@nlpr.ia.ac.cn; junping.zhang@mail.ia.ac.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANIEL L, 1996, IEEE T PATTERN ANAL, V18, P831; DASARATHY BV, 1991, NN PATTERN CLASSIFIC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R. O., 2001, PATTERN CLASSIFICATI; Fraley C., 2000, 380 U WASH; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; MICHAEL JL, 1999, IEEE T PATTERN ANAL, V21, P1357; Murphy P., 1994, UCI REPOSITORY MACHI; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Samaria F., 1994, THESIS U CAMBRIDGE; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wechsler H., 1998, NATO ASI SERIES F, V163, P446; Zhang J., 2004, LNCS, V3338, P209; Zhang J., 2004, INTELLIGENT MULTIMED; ZHANG J, 2004, 6 IEEE INT C AUT FAC	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28312-9	LECT NOTES ARTIF INT			2005	3613						223	231				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA15	WOS:000232217900029	
S	Du, H; Chen, YQ		Wang, L; Jin, Y		Du, H; Chen, YQ			Pattern classification using rectified nearest feature line segment	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat			FACE RECOGNITION; CLASSIFIERS; RETRIEVAL	This paper proposes a new classification method termed Rectified Nearest Feature Line Segment (RNFLS). It overcomes the drawbacks of the original Nearest Feature Line (NFL) classifier and possesses a novel property that centralizes the probability density of the initial sample distribution, which significantly enhances the classification ability. Another remarkable merit is that RNFLS is applicable to complex problems such as two-spirals, which the original NFL cannot deal with properly. Experimental comparisons with NFL, NN(Nearest Neighbor), k-NN and NNL (Nearest Neighbor Line) using artificial and real-world datasets demonstrate that RNFLS offers the best performance.	Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China	Chen, YQ (reprint author), Fudan Univ, Sch Informat Sci & Engn, Dept Comp Sci & Engn, Shanghai 200433, Peoples R China.	chenyq@fudan.edu.cn					Blake CL, 1998, UCI REPOSITORY MACHI; Chen JH, 2004, PATTERN RECOGN, V37, P1913, DOI 10.1016/j.patcog.2003.12.003; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	9	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28331-5	LECT NOTES ARTIF INT			2005	3614		2				81	90				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA17	WOS:000232218400011	
S	Zheng, WM; Zou, CR; Zhao, L		Wang, L; Jin, Y		Zheng, WM; Zou, CR; Zhao, L			Generalized locally nearest neighbor classifiers for object classification	FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, PT 2, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	2nd International Conference on Fuzzy Systems and Knowledge Discovery	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtan Univ, IEEE Circuits & Syst Soc, IEEE Computat IntelligenceSoc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artifiical Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia-Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc Chine, Hunan Comp Federat			PATTERN-CLASSIFICATION	In this paper, we extend the locally nearest neighbor classifiers to tackle the nonlinear classification problems via the kernel trick. The better performance is confirmed by the handwritten zip code digits classification experiments on the US Postal Service (USPS) database.	Southeast Univ, Res Ctr Sci & Learning, Nanjing 210096, Jiangsu, Peoples R China; Southeast Univ, Engn Res Ctr Informat Proc & Applicat, Nanjing 210096, Jiangsu, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Res Ctr Sci & Learning, Nanjing 210096, Jiangsu, Peoples R China.	wenming_zheng@seu.edu.cn; cairong@seu.edu.cn; zhaoli@seu.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LeCun Y., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.4.541; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHOLKOPF B, P 1 INT C KNOWL DISC; Vapnik V.N., 1995, NATURE STAT LEARNING; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	7	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28331-5	LECT NOTES ARTIF INT			2005	3614		2				95	99				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDA17	WOS:000232218400013	
J	Li, LB; Jiang, W; Li, X; Moser, KL; Guo, Z; Du, L; Wang, QJ; Topol, EJ; Wang, Q; Rao, S				Li, LB; Jiang, W; Li, X; Moser, KL; Guo, Z; Du, L; Wang, QJ; Topol, EJ; Wang, Q; Rao, S			A robust hybrid between genetic algorithm and support vector machine for extracting an optimal feature gene subset	GENOMICS			English	Article						feature gene selection; genetic algorithm; support vector machine; microarray	EXPRESSION DATA; SAMPLE CLASSIFICATION; MICROARRAY DATA; SELECTION; PATTERNS; PREDICTION; CANCER	Development of a robust and efficient approach for extracting useful information from microarray data continues to be a significant and challenging task. Microarray data are characterized by a high dimension, high signal-to-noise ratio, and high correlations between genes, but with a relatively small sample size. Current methods for dimensional reduction can further be improved for the scenario of the presence of a single (or a few) high influential gene(s) in which its effect in the feature subset would prohibit inclusion of other important genes. We have formalized a robust gene selection approach based on a hybrid between genetic algorithm and support vector machine. The major goal of this hybridization was to exploit fully their respective merits (e.g., robustness to the size of solution space and capability of handling a very large dimension of feature genes) for identification of key feature genes (or molecular signatures) for a complex biological phenotype. We have applied the approach to the microarray data of diffuse large B cell lymphoma to demonstrate its behaviors and properties for mining the high-dimension data of genome-wide gene expression profiles. The resulting classifier(s) (the optimal gene subset(s)) has achieved the highest accuracy (99%) for prediction of independent microarray samples in comparisons with marginal filters and a hybrid between genetic algorithm and K nearest neighbors. (C) 2004 Elsevier Inc. All rights reserved.	Cleveland Clin Fdn, Dept Cardiovasc Med, Cleveland, OH 44195 USA; Cleveland Clin Fdn, Dept Mol Cardiol, Cleveland, OH 44195 USA; Harbin Med Coll, Dept Bioinformat, Harbin 150086, Peoples R China; Tongji Univ, Coll Biol Sci & Technol, Shanghai 200092, Peoples R China; Harbin Inst Technol, Dept Comp Sci, Harbin 150080, Peoples R China; Univ Minnesota, Inst Human Genet, Dept Med, Minneapolis, MN 55455 USA; Chinese Peoples Liberat Army Gen Hosp, Inst Otolaryngol, Dept Otorhinolaryngol Head & Neck Surg, Beijing 100853, Peoples R China	Li, X (reprint author), Cleveland Clin Fdn, Dept Cardiovasc Med, 9500 Euclid Ave, Cleveland, OH 44195 USA.	Lixia@ems.hrbmu.edu.cn; raos@ccf.org					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ashburner M, 2000, NAT GENET, V25, P25; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Brusco MJ, 2003, BRIT J MATH STAT PSY, V56, P83, DOI 10.1348/000711003321645359; Burke HB, 2000, MOL DIAGN, V5, P349, DOI 10.1054/modi.2000.19562; Cai CZ, 2003, MATH BIOSCI, V185, P111, DOI 10.1016/S0025-5564(03)00096-8; Chen XW, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P504; Chilingaryan A, 2002, MATH BIOSCI, V176, P59, DOI 10.1016/S0025-5564(01)00105-5; Cho SJ, 2002, J CHEM INF COMP SCI, V42, P927, DOI 10.1021/ci010247v; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Davis RE, 2001, J EXP MED, V194, P1861, DOI 10.1084/jem.194.12.1861; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; GILBERT ES, 1969, BIOMETRICS, V25, P505, DOI 10.2307/2528902; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; GUO Z, 2001, ANAL MED DATA INTRO; Hall M.A., 1998, CORRELATION BASED FE; HOLTE RC, 2001, P 14 BIENN C CAN SOC, P57; Houck CR, 1997, EVOL COMPUT, V5, P31, DOI 10.1162/evco.1997.5.1.31; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Ji XL, 2003, FEBS LETT, V542, P125, DOI 10.1016/S0014-5793(03)00363-6; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LI L, 2003, LIFE SCI RES, V7, P372; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Li X, 2004, NUCLEIC ACIDS RES, V32, P2685, DOI 10.1093/nar/gkh563; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; Park P J, 2001, Pac Symp Biocomput, P52; SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467; Schliep A, 2003, BIOINFORMATICS, V19, P255; Stefanini FM, 2000, BIOINFORMATICS, V16, P923, DOI 10.1093/bioinformatics/16.10.923; Szabo A, 2003, BIOSTATISTICS, V4, P555, DOI 10.1093/biostatistics/4.4.555; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Tsamardinos I., 2003, 9 INT WORKSH ART INT; XING EP, 2001, P 18 INT C SAN FRANC	37	45	50	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0888-7543		GENOMICS	Genomics	JAN	2005	85	1					16	23		10.1016/j.ygeno.2004.09.007		8	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	886XA	WOS:000226265100002	
B	Babu, TR; Murty, MN; Agrawal, VK		Ishikawa, M; Hashimoto, S; Paprzycki, M; Barakova, E; Yoshida, K; Koppen, M; Corne, DW; Abraham, A		Babu, TR; Murty, MN; Agrawal, VK			Adaptive boosting with leader based learners for classification of large handwritten data	HIS'04: Fourth International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	4th International Conference on Hybrid Intelligent Systems (HIS 04)	DEC 05-08, 2004	Kitakyushu, JAPAN	IEEE Comp Soc, Computat Intelligence Soc, IEEE, Syst Man, & Cybernet Soc, BMFSA, SOFT, Int Fuzzy Syst Assoc, City Kitakyushu, World Federat Soft Comp				Boosting is a general method for improving the accuracy of a learning algorithm. AdaBoost, short form for Adaptive Boosting method, consists of repeated use of a weak or a base learning algorithm to find corresponding weak hypothesis by adapting to the error rates of the individual weak hypotheses. A large, complex handwritten data is under study. A repeated use of weak learner on the huge data results in large. amount of processing time. In view of this, instead of using the entire training data for learning, we propose to use only prototypes. Further in the current work, the base learner consists of a nearest neighbour classifier that employs prototypes generated using "leader" clustering algorithm. The leader algorithm is a single pass algorithm and is linear in terms of time as well as computation complexity. The prototype set alone is used as training data. In the process of developing an algorithm, domain knowledge of the Handwritten data, which is under study, is made use of With the fusion of clustering, prototype selection, AdaBoost and Nearest Neighbour classifier a very high classification accuracy, which is better than reported earlier on the considered data, is obtained in less number of iterations. The procedure integrates clustering outcome in terms of prototypes with boosting.	Indian Inst Sci, Dept CSA, Bangalore 560012, Karnataka, India	Babu, TR (reprint author), Indian Inst Sci, Dept CSA, Bangalore 560012, Karnataka, India.						Babu T. R., 2001, PATTERN RECOGN, V34, P523, DOI 10.1016/S0031-3203(00)00094-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBOUR CL; Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAIN A, 1999, ACM COMPUTING SURVEY, V32; JAIN A, 2000, IEEE T PAMI, V22, P40; Kaufman L., 1989, FINDING GROUPS DATA; KEARNS M, 1994, J ACM, V41, P67, DOI 10.1145/174644.174647; Murphy P., 1994, UCI REPOSITORY MACHI; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Schapire R E, 1999, P ALGORITHMIC LEARNI; SCHAPIRE RE, 2002, MSRI WORKSH NONLINEA; Spath H, 1980, CLUSTER ANAL ALGORIT; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Valiant L.G, 1988, TR1488 HARV U AIK CO; Viaene S, 2004, IEEE T KNOWL DATA EN, V16, P612, DOI 10.1109/TKDE.2004.1277822; VISWANATH P, 2004, IN PRESS PUBLICATION	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2291-2				2005							326	331				6	Computer Science, Artificial Intelligence	Computer Science	BBW91	WOS:000228181100053	
B	Jankowski, N; Grabczewski, K		Nedjah, N; Mourelle, LM; Vellasco, MMB; Abraham, A; Koppen, M		Jankowski, N; Grabczewski, K			Heterogenous committees with competence analysis	HIS 2005: 5th International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	5th International Conference on Hybrid Intelligent Systems	NOV 06-09, 2005	Rio de Janeiro, BRAZIL	Operador Nacl Sistema Eletr, Coordenac Aperfeicoament Pessoal Nivel Super, Brazilian Comp Soc, Brazilian Soc Automat, IEEE Syst Man & Cygernet Soc, Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Federat Soft Comp, Pontific Univ Catol Rio deJaneiro				We explore some new types of committees in search of hybrid models successful in many different classification benchmarks. To provide a reliable comparison of the ensembles we restrict the task to some constant configuration of committee members for each benchmark. We were looking for new types of committees which, in such configuration, would be as much accurate and stable as possible. The paper focuses on some ideas of heterogenous committees with different ways of their members competence estimation. Heterogenous committee members adapt in different ways and are able to solve different problems. Measuring the competence of committee members helps in making competent and accurate decisions.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Grudziadzka 5, PL-87100 Torun, Poland.						Bishop C. M., 1995, NEURAL NETWORKS PATT; Boser B. E., 1992, P 5 ANN ACM WORKSH C; Breiman L., 1998, Neural Networks and Machine Learning. Proceedings; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1984, CLASSIFICATION REGRE; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUCH W, 2002, ADV SOFT COMPUTING, P412; Duda R.O., 1997, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J., 2001, ELEMENTS STAT LEARNI; GRABCZEWSKI K, 2004, FEATURE EXTRACTION F; Grabczewski K., 1999, P 4 C NEUR NETW THEI, P203; Grabczewski K., 2000, P 5 C NEUR NETW THEI, P201; JACOBS RA, 1991, NEURAL COMPUTATION, V79; Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493; Kuncheva L.I., 2003, MACHINE LEARNING, V51; MACLIN R, 1998, P AAAI; Merz C.J., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; SEEWALD AK, 2001, ADV INTELLIGENT DATA; TING KM, 1997, P 15 INT JOIN C ART; Vapnik V.N., 1995, NATURE STAT LEARNING; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zenko B., 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989601	26	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2457-5				2005							417	422				6	Computer Science, Artificial Intelligence	Computer Science	BDN06	WOS:000234402500069	
B	Acharya, T; Ray, AK	Acharya, T; Ray, AK			Acharya, Tinku; Ray, Ajoy K.	Acharya, T; Ray, AK		Recognition of Image Patterns	IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS			English	Article; Book Chapter							COUNTERPROPAGATION NETWORKS; CLASSIFICATION		[Acharya, Tinku; Ray, Ajoy K.] Avisere Inc, Tucson, AZ USA; [Acharya, Tinku] Arizona State Univ, Dept Elect Engn, Tempe, AZ 85287 USA; [Ray, Ajoy K.] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India	Acharya, T (reprint author), Avisere Inc, Tucson, AZ USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; Fu K. S., 1982, SYNTACTIC PATTERN RE; Gonzalez R. C., 1978, SYNTANTIC PATTERN RE; Haykim S., 1999, NEURAL NETWORKS COMP; Hebb D O, 1949, ORG BEHAV; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; HECHTNIELSEN R, 1988, NEURAL NETWORKS, V1, P131, DOI 10.1016/0893-6080(88)90015-9; Jungert E., 1988, PATTERN RECOGNITION; Kohonen T., 1989, SELF ORG ASS MEMORY; Majumdar A. K., 2001, PATTERN RECOGN, P185, DOI 10.1142/9789812386533_0007; Mannan B, 2003, INT J REMOTE SENS, V24, P3491, DOI 10.1080/0143116021000053805; Minsky M., 1969, PERCEPTRONS INTRO CO; Mitra S., 2003, DATA MINING MULTIMED; Pavlidis T., 1977, STRUCTURAL PATTERN R; Perner P., 1996, ADV STRUCTURAL SYNTA; Perner P., 1999, MACHINE LEARNING DAT; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; RAY AK, 1991, INFORM SCIENCES, V55, P189, DOI 10.1016/0020-0255(91)90013-K; Ripley B. D., 1996, PATTERN RECOGNITION; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Schuermann J., 1996, PATTERN CLASSIFICATI	24	0	0	BLACKWELL SCIENCE PUBL	OXFORD	OSNEY MEAD, OXFORD OX2 0EL, ENGLAND		978-0-471-74579-2				2005							157	180			10.1002/0471745790	24	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BYA62	WOS:000297761900009	
S	Robinson, S; Polak, JW			TRB	Robinson, S; Polak, JW			Modeling urban link travel time with inductive loop detector data by using the k-NN method	INFORMATION SYSTEMS AND TECHNOLOGY	TRANSPORTATION RESEARCH RECORD		English	Article; Proceedings Paper	84th Annual Meeting of the Transportation-Research-Board	JAN 09-13, 2005	Washington, DC	US Dept Transportat, US Fed Aviat Adm, US Fed Highway Adm, US Fed Motor Carrier Safety Adm, US Fed Railroad Adm, US Fed Transit Adm, US Natl Highway Traff Safety Adm, US Res & Innovat Technol Adm, NASA, USA Corps Engineers, US Coast Guard, US DOE, US EPA, Transportat Res Board, Transportat Dept 50 States, Puerto Rico & District Columbia			NONPARAMETRIC REGRESSION; SPEED	The need to measure urban link travel time (ULTT) is becoming increasingly important for network management and traveler information provision. This paper proposes the use of the k nearest neighbors (k-NN) technique to estimate ULTT with the use of single loop inductive loop detector (ILD) data. Real-world data from London is used. This paper explores the sensitivity of travel time estimates to various k-NN design parameters. It rinds that the k-NN method is not particularly sensitive to the distance metric, although care must be taken in selecting the right combination of local estimation method (LEM) and value of k. A robust LEM should be used. The optimized k-NN model is found to provide more accurate estimates than other ULTT methods. To obtain a more accurate estimate of ULTT, a potential application of this approach could be to aggregate GPS probe vehicle ULTT records from different times but the same underlying travel time distribution.	Univ London Imperial Coll Sci Technol & Med, Dept Civil & Environm Engn, Ctr Transport Studies, London SW7 2AZ, England	Robinson, S (reprint author), Univ London Imperial Coll Sci Technol & Med, Dept Civil & Environm Engn, Ctr Transport Studies, Exhibit Rd, London SW7 2AZ, England.						ANDERSON J, 1997, IEEE C INT TRANSP SY; BAJWA SI, 2003, 10 WORLD C INT TRANS; BAJWA SI, 2003, 21 AUSTR ROAD RES BO; Barbosa HM, 2000, TRANSPORT RES A-POL, V34, P103, DOI 10.1016/S0965-8564(98)00067-6; BEGON C, 2004, THESIS IMPERIAL COLL; Chen C., 2003, TRANSPORT RES REC, V1855, P160, DOI 10.3141/1855-20; Cherrett T, 2001, P I CIVIL ENG-TRANSP, V147, P23; Clark S, 2003, J TRANSP ENG-ASCE, V129, P161, DOI 10.1061/(ASCE)0733-947X(2003)129:2(161); Coifman B, 2001, TRANSPORT RES A-POL, V35, P863, DOI 10.1016/S0965-8564(00)00028-8; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAILEY DJ, 1993, TRANSPORT RES B-METH, V27, P97, DOI 10.1016/0191-2615(93)90002-R; Dailey DJ, 1999, TRANSPORT RES B-METH, V33, P313, DOI 10.1016/S0191-2615(98)00037-X; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DAVIS GA, 1991, J TRANSP ENG-ASCE, V117, P178, DOI 10.1061/(ASCE)0733-947X(1991)117:2(178); Devijver P. A., 1982, PATTERN RECOGNITION; FIX E, 1952, 11 USAF SCH AV MED, P280; Fix E., 1951, 4 USAF SCH AV MED, P261; Fukunaga K., 1990, INTRO STAT PATTERN R; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Gault H. E., 1981, 37 U NEWC TRANSP OP; Guhnemann A., 2004, 10 WORLD C TRANSP RE; Handley S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Hardle W, 1990, APPL NONPARAMETRIC R; ISHIMARU JM, 1999, FLOW EVALUATION DESI; Kittler J., 1978, Pattern Recognition and Signal Processing; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Liu H., 1998, FEATURE SELECTION KN; OSWALD K, 2000, UVACEITS014 G MAS U; PALACHARLA P, 1995, P 2 WORLD C INT TRAN, V1, P112; PAPAGIANNI S, 2003, THESIS IMPERIAL COLL; Park D, 1999, J TRANSP ENG-ASCE, V125, P515, DOI 10.1061/(ASCE)0733-947X(1999)125:6(515); Petty KF, 1998, TRANSPORT RES A-POL, V32, P1, DOI 10.1016/S0965-8564(97)00015-3; QI Y, 2004, TRANSPORT RES REC, V1879, P89, DOI 10.3141/1879-11; ROBINSON S, IN PRESS J TRANSPORT; ROBINSON S, 2004, 36 ANN C U TRANSP ST; ROBINSON SJP, 2004, 10 WORLD C TRANSP RE; Simonoff J. S., 1996, SMOOTHING METHODS ST; Sisiopiku V., 1994, TRAVEL TIME ESTIMATI; Smith BL, 1997, J TRANSP ENG-ASCE, V123, P261, DOI 10.1061/(ASCE)0733-947X(1997)123:4(261); Smith BL, 2002, TRANSPORT RES C-EMER, V10, P303, DOI 10.1016/S0968-090X(02)00009-8; Srinivasan K, 1996, TRANSPORT RES REC, V1537, P15, DOI DOI 10.3141/1537-03; Turner S., 1998, FHWAPL98035; Van der Zijpp N.J, 1997, TRANSPORT RES REC, V1607, P87, DOI 10.3141/1607-13; VANLINT H, 2004, RELIABLE TRAVEL TIME; Wardrop J. G., 1968, TRAFFIC ENG CONTROL, V9, P528; WIGGINS AE, 1999, HELSINKI JOURNEY TIM; Xie C., 2004, 83 ANN M TRANSP RES; You J, 2000, TRANSPORT RES C-EMER, V8, P231, DOI 10.1016/S0968-090X(00)00012-7; ZHANG M, 1998, ESTIMATING ARTERIAL; *MATHSW LTD, 2000, MATLAB REL 12 US DOC	51	7	7	TRANSPORTATION RESEARCH BOARD NATL RESEARCH COUNCIL	WASHINGTON	500 FIFTH ST, NW, WASHINGTON, DC 20001 USA	0361-1981	0-309-09409-7	TRANSPORT RES REC			2005		1935					47	56				10	Computer Science, Interdisciplinary Applications; Engineering, Civil; Transportation Science & Technology	Computer Science; Engineering; Transportation	BEG15	WOS:000237194200006	
S	Bao, YG; Tsuchiya, E; Ishii, N; Du, XY		Gallagher, M; Hogan, J; Maire, F		Bao, YG; Tsuchiya, E; Ishii, N; Du, XY			Classification by instance-based learning algorithm	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING IDEAL 2005, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	6th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2005)	JUL 06-08, 2005	Brisbane, AUSTRALIA	Univ Queensland				The basic k-nearest-neighbor classification algorithm works well in many domains but has several shortcomings. This paper proposes a tolerant instance-based learning algorithm TIBL and it ' s combining method by simple voting of TIBL, which is an integration of genetic algorithm, tolerant rough sets and k-nearest neighbor classification algorithm. The proposed algorithms seek to reduce storage requirement and increase generalization accuracy when compared to the basic k-nearest neighbor algorithm and. other learning models. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that TIBL algorithm and it ' s combining method, improve the performance of the k-nearest neighbor classification, and also achieves higher generalization accuracy than other popular machine learning algorithms.	Renmin Univ China, Sch Informat, Beijing, Peoples R China		baoyg@yahoo.com.cn; eisuke@hm.aitai.ne.jp; ishii@in.aitech.ac.jp; duyong@mail.ruc.edu.cn	ruc, comp_xinxi/E-4212-2012				AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Guvenir H.A, 1997, P 12 INT S COMP INF, P44; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; Merz C.J., UCI REPOSITORY MACHI; Pawlak Z., 1991, ROUGH SETS THEORETIC; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103	8	9	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26972-X	LECT NOTES COMPUT SC			2005	3578						133	140				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BCR09	WOS:000230878800018	
S	Shi, ZZ; Luo, P; Hao, YL; Li, GH; Stumptner, M; He, Q; Quirchmayr, G		Shi, Z; He, Q		Shi, ZZ; Luo, P; Hao, YL; Li, GH; Stumptner, M; He, Q; Quirchmayr, G			Intelligent technology for well logging analysis	INTELLIGENT INFORMATION PROCESSING II	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	2nd International Conference on Intelligent Information Processing	OCT 21-23, 2004	Beijing, PEOPLES R CHINA	IFIP TC12, WG12 3		intelligent technology; well log analysis; data mining; MOUCLAS algorithm		Well logging analysis plays an essential role in petroleum exploration and exploitation. It is used to identify the pay zones of gas or oil in the reservoir formations. This paper applies intelligent technology for well logging analysis, particular combining data mining and expert system together, and proposes an intelligent system for well log analysis called IntWeL Analyzer in terms of data mining platform MSMiner and expert system tool OKPS. The architecture of IntWeL Analyzer and data mining algorithms, including Ripper algorithm and MOUCLAS algorithm are also presented. MOUCLAS is based on the concept of the fuzzy set membership function that gives the new approach a solid mathematical foundation and compact mathematical description of classifiers. The aim of the study is the use of intelligent technology to interpret the pay zones from well logging data for the purpose of reservoir characterization. This approach is better than conventional techniques for well logging interpretation that cannot discover the correct relation between the well logging data and the underlying property of interest.	Chinese Acad Sci, Comp Technol Inst, Beijing 100080, Peoples R China	Shi, ZZ (reprint author), Chinese Acad Sci, Comp Technol Inst, Beijing 100080, Peoples R China.		Stumptner, Markus/B-5558-2009				AMINZADEH F, 1996, FUTURE GEOSCIENCE TE, P1; CLIFFORD A, 1991, P 8 INT WORKSH MACH, P389; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1999, P 5 ACM SIGKDD; LENT B, 1997, ICDE, P220; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; SHI ZZ, 2004, OKPS EXPERT SYSTEM D; SHI ZZ, 2002, MSMINER DATA MINING; WILLIAM W, 1995, P 12 INT C LAK TAH C	11	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736	0-387-23151-X	INT FED INFO PROC			2005	163						373	382		10.1007/0-387-23152-8_48		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BBJ45	WOS:000225784400048	
S	Kawatsure, T; Zhao, QF			IEEE	Kawatsure, T; Zhao, QF			Inducing multivariate decision trees with the R(4)-rule	INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOL 1-4, PROCEEDINGS	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-12, 2005	Waikoloa, HI	IEEE Syst, Man & Cybernet Soc		machine learning; pattern recognition; multivariate decision trees; nearest neighbor classifier; the R(4)-rule	NEIGHBOR PATTERN-CLASSIFICATION; MLP	Decision tree (DT) is often considered as a comprehensible learning model. If the data set is large, however the induced DT may be too large to understand. Currently, we have proposed a non-genetic evolutionary algorithm called R(4)-rule for producing the smallest nearest neighbor classifiers (NNCs). In this paper we propose two new approaches for inducing DTs with the R(4)-rule. The DTs considered here are multivariate, and there is an NNC with two or more prototypes in each non-terminal node. In the first method, the prototypes are found directly from the training set. In the second method, the prototypes are found from the data assigned to each non-terminal node. Using these methods, we can induce more compact and more comprehensible DTs. The efficiency and efficacy of the methods are verified through experiments with several public databases.	Univ Aizu, Aizu Wakamatsu, Japan	Kawatsure, T (reprint author), Univ Aizu, Aizu Wakamatsu, Japan.	m5081132@u-aizu.ac.jp; qf-zhao@u-aizu.ac.jp					Brieman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Endou T., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004417; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; KAWATSURE T, 2003, 2003129 IEICE PRMU; Oates T., 1997, P 14 INT C MACH LEAR, P254; Oka S., 2000, P 4 JAP AUSTR JOINT, P128; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SHIRASAKA M, 1998, P 2 AS PAC C SIM EV; Tanigawa T., 2000, P GEN EV COMP C GECC, P1047; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240	13	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	0-7803-9298-1	IEEE SYS MAN CYBERN			2005							3593	3598				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BDT16	WOS:000235210803100	
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Using functional domain composition to predict enzyme family classes	JOURNAL OF PROTEOME RESEARCH			English	Article						classification of enzyme commission; enzymatic attribute; functional domain composition; 20% threshold cutoff; nearest neighbor predictor; bioinformatics; proteomics	PROTEIN STRUCTURAL CLASS; AMINO-ACID-COMPOSITION; SECONDARY STRUCTURE PREDICTION; SUBCELLULAR LOCATION; NEURAL-NETWORKS; FOLDING TYPES; CLASSIFICATION; ALGORITHM; SEQUENCE; DATABASE	According to their main EC (Enzyme Commission) numbers, enzymes are classified into the following 6 main classes: oxidoreductases, transferases, hydrolases, lyases, isomerases, and ligases. A new method has been developed to predict the enzymatic attribute of proteins by introducing the functional domain composition to formulate a given protein sequence. The advantage by doing so is that both the sequence-order-related features and the function-related features are naturally incorporated in the predictor. As a demonstration, the jackknife cross-validation test was performed on a dataset that consists of proteins with only less than 20% sequence identity to each other in order to get rid of any homologous bias. The overall success rate thus obtained was 85% in identifying the enzyme family classes (including the identification of nonenzyme protein sequences as well). The success rate is significantly higher than those obtained by the other methods on such a stringent dataset. This indicates that using the functional domain composition to represent protein samples for statistical prediction is indeed very promising, and will become a powerful tool in bioinformatics and proteomics.	Univ Manchester, Inst Sci & Technol, Biomol Sci Dept, Manchester M60 1QD, Lancs, England; Gordon Life Sci Inst, San Diego, CA 92130 USA; TIBDD, Tianjin, Peoples R China	Cai, YD (reprint author), Univ Manchester, Inst Sci & Technol, Biomol Sci Dept, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; KNELLER DG, 1990, J MOL BIOL, V214, P171, DOI 10.1016/0022-2836(90)90154-E; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Webb EC, 1992, ENZYME NOMENCLATURE; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	29	31	33	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1535-3893		J PROTEOME RES	J. Proteome Res.	JAN-FEB	2005	4	1					109	111		10.1021/pr049835p		3	Biochemical Research Methods	Biochemistry & Molecular Biology	901MQ	WOS:000227287000013	
J	Hall, P; Samworth, RJ				Hall, P; Samworth, RJ			Properties of bagged nearest neighbour classifiers	JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY			English	Article						Bayes risk; bootstrap; classification error; cross-validation; density; discrimination; error rate; marked point process; Poisson process; prediction; regret; statistical learning; without-replacement sampling; with-replacement sampling	CROSS-VALIDATION; DENSITY-ESTIMATION; SAMPLE-SIZE; CLASSIFICATION; ERROR; DISCRIMINATION; REGRESSION; RULE	It is shown that bagging, a computationally intensive method, asymptotically improves the performance of nearest neighbour classifiers provided that the resample size is less than 69% of the actual sample size, in the case of with-replacement bagging, or less than 50% of the sample size, for without-replacement bagging. However, for larger sampling fractions there is no asymptotic difference between the risk of the regular nearest neighbour classifier and its bagged version. In particular, neither achieves the large sample performance of the Bayes classifier. In contrast, when the sampling fractions converge to 0, but the resample sizes diverge to infinity, the bagged classifier converges to the optimal Bayes rule and its risk converges to the risk of the latter. These results are most readily seen when the two populations have well-defined densities, but they may also be derived in other cases, where densities exist in only a relative sense. Cross-validation can be used effectively to choose the sampling fraction. Numerical calculation is used to illustrate these theoretical properties.	Univ Cambridge, Ctr Math Sci, Stat Lab, Cambridge CB3 0WB, England; Australian Natl Univ, Canberra, ACT, Australia	Samworth, RJ (reprint author), Univ Cambridge, Ctr Math Sci, Stat Lab, Wilberforce Rd, Cambridge CB3 0WB, England.	r.j.samworth@statslab.cam.ac.uk					Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Bickel PJ, 1997, STAT SINICA, V7, P1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; BREIMAN L, 1999, 547 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buhlmann P, 2002, ANN STAT, V30, P927; BUJA A, 2000, UNPUB SMOOTHING EFFE; BUJA A, 2000, UNPUB EFFECT BAGGING; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daley D.J., 1988, INTRO THEORY POINT P; Devroye L, 1996, PROBABILISTIC THEORY; DEVROYE L, 1982, IEEE T PATTERN ANAL, V4, P154; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Fix E, 1951, 4 US AIR FORC SCH AV; FRANCOIS J, 2001, INFORMATION PROCESSI, V1, P111; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 2000, UNPUB BAGGING NONLIN; GUERRASALCEDO C, 1999, P GEN EV COMP C, V1, P236; HALL P, 1989, STAT PROBABIL LETT, V8, P109, DOI 10.1016/0167-7152(89)90002-3; Hand D. J., 1981, DISCRIMINATION CLASS; HO TK, 1998, P 14 INT C PATT REC, P545; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Jiang WX, 2002, ANN STAT, V30, P51, DOI 10.1214/aos/1015362184; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; Kim H, 2001, J AM STAT ASSOC, V96, P589, DOI 10.1198/016214501753168271; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; KUNCHEVA LI, 2002, INFORM FUSION, P245; Larkey L. S., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Lugosi G, 1996, ANN STAT, V24, P687; Mammen E., 1992, LECT NOTES STAT, V77; MARRON JS, 1983, ANN STAT, V11, P1142; MIELNICZUK J, 1989, J STAT PLAN INFER, V23, P53, DOI 10.1016/0378-3758(89)90039-6; MOLLINEDA RA, 2000, P 4 WRLD MULT SYST C, V7, P640; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Schapire RE, 1998, ANN STAT, V26, P1651; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Skurichina M, 2002, LECT NOTES COMPUT SC, V2364, P62; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; STOLLER DS, 1954, J AM STAT ASSOC, V49, P770, DOI 10.2307/2281538; Yang JH, 1999, ORG LETT, V1, P11, DOI 10.1021/ol9900010; ZEMKE S, 1997, P ART NEUR NETW ENG, P1067	46	12	12	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	1369-7412		J ROY STAT SOC B	J. R. Stat. Soc. Ser. B-Stat. Methodol.		2005	67		3				363	379		10.1111/j.1467-9868.2005.00506.x		17	Statistics & Probability	Mathematics	937CQ	WOS:000229902600003	
S	Ferrandiz, S; Boulle, M		Perner, P; Imilya, A		Ferrandiz, S; Boulle, M			Supervised evaluation of dataset partitions: Advantages and practice	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINDS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Minining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY					In the context of large databases, data preparation takes a greater importance : instances and explanatory attributes have to be carefully selected. In supervised learning, instances partitioning techniques have been developped for univariate representations, leading to precise and comprehensible evaluations of the amount of information contained in an attribute, with respect to the target attribute. Still, the multivariate case remains unstated. In this paper, we describe the partitioning intrinsic convenience for data preparation and we settle a framework for supervised partitioning. A new evaluation criterion of labelled objects partitions, which is based on Minimum Description Length principle, is then set and tested on real and synthetic data sets.	France Telecom R&D, F-22307 Lannion, France; Univ Caen, GREYC, F-14032 Caen, France	Ferrandiz, S (reprint author), France Telecom R&D, 2 Ave Pierre Marzin, F-22307 Lannion, France.	sylvain.ferrandiz@francetelecom.com; marc.boulle@francetelecom.com					BOULLE M, 2004, DATA MINING, V5, P199; Breiman L, 1984, CLASSIFICATION REGRE; CHAPMAN P, 2000, CRISP DM 1 0 STEP BY; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; Kass G., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; KERBER R, 1991, 10 INT C ART INT, P123; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; McQueen J, 2007, 5TH BERK S MATH STAT, V1, P281; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; ZIGHED DA, 2001, 8 RENC SFC, P356	14	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						600	609				10	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100059	
S	Ferrandiz, S; Boulle, M		Perner, P; Imilya, A		Ferrandiz, S; Boulle, M			Multivariate discretization by recursive supervised bipartition of graph	MACHINE LEARNING AND DATA MINING IN PATTERN RECOGNITION, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	4th International Conference on Machine Learning and Data Mining in Pattern Recognition	JUL 09-11, 2005	Leipzig, GERMANY					In supervised learning, discretization of the continuous explanatory attributes enhances the accuracy of decision tree induction algorithms and naive Bayes classifier. Many discretization methods have been developped, leading to precise and comprehensible evaluations of the amount of information contained in one single attribute with respect to the target one. In this paper, we discuss the multivariate notion of neighborhood, extending the univariate notion of interval. We propose an evaluation criterion of bipartitions, which is based on the Minimum Description Length (MDL) principle [1], and apply it recursively. The resulting discretization method is thus able to exploit correlations between continuous attributes. Its accuracy and robustness are evaluated on real and synthetic data sets.	France Telecom R&D, F-22307 Lannion, France; Univ Caen, GREYC, F-14032 Caen, France	Ferrandiz, S (reprint author), France Telecom R&D, 2,Ave Pierre Marzin, F-22307 Lannion, France.	sylvain.ferrandiz@francetelecom.com; marc.boulle@francetelecom.com					Bay S. D., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347159; Blake C.L., UCI REPOSITORY MACHI; BOULLE M, 2004, BAYESIAN APPROACH SU, P199; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; KERBER R, 1991, 10 INT C ART INT, P123; Kwedlo W, 1999, LECT NOTES ARTIF INT, V1704, P392; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5	11	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26923-1	LECT NOTES ARTIF INT			2005	3587						253	264				12	Computer Science, Artificial Intelligence	Computer Science	BCR27	WOS:000230895100025	
S	Hendrickx, I; van den Bosch, A		Gama, J; Camacho, R; Brazdil, P; Jorge, A; Torgo, L		Hendrickx, I; van den Bosch, A			Hybrid algorithms with instance-based classification	MACHINE LEARNING: ECML 2005, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	16th European Conference on Machine Learning (ECML)/9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	OCT 03-07, 2005	Oporto, PORTUGAL	FCT, LIACC NIAAD			LEARNING ALGORITHMS	In this paper we aim to show that instance-based classification can replace the classifier component of a rule learner and of maximum-entropy modeling, thereby improving the generalization accuracy of both algorithms. We describe hybrid algorithms that combine rule learning models and maximum-entropy modeling with instance-based classification. Experimental results show that both hybrids are able to outperform the parent algorithm. We analyze and compare the overlap in errors and the statistical bias and variance of the hybrids, their parent algorithms, and a plain instance-based learner. We observe that the successful hybrid algorithms have a lower statistical bias component in the error than their parent algorithms; the fewer errors they make are also less systematic.	Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands	Hendrickx, I (reprint author), Tilburg Univ, ILK Computat Linguist & AI, POB 90153, NL-5000 LE Tilburg, Netherlands.	i.h.e.hendrickx@uvt.nl; antalb@uvt.nl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; BRILL E, 1998, P COLING ACL 98, P191; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2004, ILK0402 TILB U; Domingos P, 1996, MACH LEARN, V24, P141; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; GUIASU S, 1985, MATH INTELLIGENCER, V7; Hendy I.L., 2004, P 1L BELG DUTCH C AR, P19; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R, 1996, P 13 INT C MACH LEAR, P275; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193; Sebag M., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Ting K. M., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future; van der Veen A-J, 2004, P WORKSH ADV IND RUL, P1, DOI 10.1109/SAM.2004.1502901; VANDENBOSCH A, 2004, P 16 BELG DUTCH C AR, P219; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	19	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29243-8	LECT NOTES ARTIF INT			2005	3720						158	169				12	Computer Science, Artificial Intelligence	Computer Science	BDF41	WOS:000233235200019	
B	Levinson, SE				Levinson, SE			Mathematical Models for Speech Technology	MATHEMATICAL MODELS FOR SPEECH TECHNOLOGY			English	Book							CONNECTED WORD RECOGNITION; HIDDEN MARKOV-MODELS; SPEAKER-INDEPENDENT RECOGNITION; SPOKEN LANGUAGE COMPREHENSION; DYNAMIC-PROGRAMMING ALGORITHM; MAXIMUM-LIKELIHOOD-ESTIMATION; VOCAL-TRACT; PROBABILISTIC FUNCTIONS; CLUSTERING TECHNIQUES; UNDERSTANDING SYSTEM									Abromovitz M., 1965, HDB MATH FUNCTIONS; Aho A. V., 1980, P 14 ANN C INF SCI S; ALDEFELD B, 1980, AT&T TECH J, V59, P1343; ALLEN JB, 1977, J ACOUST SOC AM, V62, P930, DOI 10.1121/1.381586; ALTER R, 1968, IEEE T ACOUST SPEECH, VAU16, P6, DOI 10.1109/TAU.1968.1161943; Aronowitz Stanley, 1988, SCI POWER DISCOURSE; Atal B. S., 1981, COMMUNICATION; ATAL BS, 1978, J ACOUST SOC AM, V63, P1535, DOI 10.1121/1.381848; ATAL BS, 1979, IEEE T ACOUST SPEECH, V27, P247, DOI 10.1109/TASSP.1979.1163237; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179; Bahl L. R., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing; Bahl L. R., 1976, P IEEE INT C AC SPEE, P425; Bahl L. R., 1979, P 1979 IEEE INT C AC, P249; Bahl L. R., 1979, P IEEE INT C AC SPEE, P442; Bahl L. R., 1979, P IEEE INT C AC SPEE, P418; Bahl L.R., 1980, P 1980 IEEE INT C AC, P872; BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; Baker J, 1979, 97 M AC SOC AM, P547; Baker J. K., 1975, IEEE T ACOUST SPEECH, VASSP-23; Baker JK, 1975, SPEECH RECOGNITION, P521; Ball G. H., 1965, P IFIPS C; Barinaga M, 1996, SCIENCE, V272, P482, DOI 10.1126/science.272.5261.482; Bates S. L., 1976, THESIS; Baum L. E., 1972, INEQUALITIES, V3, P1; Baum L. E., 1966, ANN MATH STAT, V37, P1559; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; BAUM LE, 1968, PAC J MATH, V27, P211; Bekesy G., 1960, EXPT HEARING; Bellman R., 1957, DYNAMIC PROGRAMMING; Beyer W. H., 1968, HDB TABLES PROBABILI; Billi R., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; BOOTH TL, 1973, IEEE T COMPUT, VC 22, P442, DOI 10.1109/T-C.1973.223746; Bourland H., 1984, P INT C AC SPEECH SI, P26101; Braun M., 1975, DIFFERENTIAL EQUATIO; Bridle J. S., 1979, P I AC AUT C, P25; Brooks R., 1998, COMPUTATION METAPHOR; Brouer L. E. J., 1913, AM MATH SOC B, V20, P81; Bruner J. S., 1956, STUDY THINKING; Bunge Mario, TREATISE BASIC PHILO; Cantor G., 1980, TRANSFINITE ARITHMET; Cave R. L., 1980, P S APPL HIDD MARK M, P16; CHAN DSK, 1973, AT&T TECH J, V52, P347; Chomsky N., 1959, INFORM CONTR, V2, P137, DOI 10.1016/S0019-9958(59)90362-6; Chomsky N., 1957, SYNTACTIC STRUCTURES; CHOMSKY NOAM, 1968, SOUND PATTERNS ENGLI; Church A., 1951, ANN MATH STUD, V6; Cohen P. S., 1975, SPEECH RECOGNITION, P275; COHEN P, 1963, P NATL ACAD SCI USA, V50, P1143, DOI 10.1073/pnas.50.6.1143; COKER CH, 1976, P IEEE, V64, P452, DOI 10.1109/PROC.1976.10154; COKER CH, 1973, IEEE T ACOUST SPEECH, VAU21, P293, DOI 10.1109/TAU.1973.1162458; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROCHIERE RE, 1975, P IEEE, V63, P581, DOI 10.1109/PROC.1975.9793; Cummiskey P., 1973, Bell System Technical Journal, V52; Damasio Antonio, 2001, UNITY KNOWLEDGE CONV; Damasio A.R., 1999, FEELING WHAT HAPPENS; DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; DEMORI R, 1973, IEEE T ACOUST SPEECH, VAU21, P89, DOI 10.1109/TAU.1973.1162442; DEMORI R, 1985, IEEE T PATTERN ANAL, V7, P56; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DENES P, 1960, J ACOUST SOC AM, V32, P1450, DOI 10.1121/1.1907936; Dennett D., 1991, CONSCIOUSNESS EXPLAI; Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; Dirac A. M., P ROY SOC EDINBURGH, V59, p[122, 193]; Dreyfus H. L, 1972, WHAT COMPUTERS CANT; Duda R., 1973, PATTERN CLASSIFICATI; DUDLEY H, 1958, J ACOUST SOC AM, V30, P721, DOI 10.1121/1.1909742; Dudley H., 1930, J ACOUST SOC AM; Dunn H. K., 1962, J ACOUST SOC AM, V34; EBERHARD KM, 1995, J PSYCHOLINGUIST RES, V24, P409, DOI 10.1007/BF02143160; Edelman G. M., 2000, UNIVERSE CONSCIOUSNE; Einstein A., 1933, METHOD THEORETICAL P; Einstein A., 1929, COMMUNICATION   0425; Einstein A., 1921, MEANING RELATIVITY; Einstein A., 1926, COMMUNICATION   1204; REDDY DR, 1976, IEEE T COMPUT, V25, P422; FALLSIDE F, 1972, P I ELECTR ENG, V119, P247; Fan K., 1950, FONCTIONS DEFINIES P; Fano R., 1961, TRANSMISSION INFORM; Fant G., 1970, ACOUSTIC THEORY SPEE; Ferguson J., 1980, P S APPL HIDD MARK M, P143; Fitch H. L., 1983, J ACOUST SOC AM S1, V74, P816; Flanagan J, 1972, SPEECH ANAL SYNTHESI; Flanagan J. L., 1975, BELL SYST TECH J, V544, P485; FLANAGAN JL, 1976, P IEEE, V64, P405, DOI 10.1109/PROC.1976.10150; Fletcher H., 1953, SPEECH HEARING COMMU; FLETCHER R, 1963, COMPUT J, V6, P163; Fodor J., 2000, MIND DOESNT WORK THA; Fodor J. A., 1975, LANGUAGE THOUGHT, p103ff; Fu K, 1968, SEQUENTIAL METHODS P; Fu K. S., 1982, SYNTACTIC PATTERN RE; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P95; Fu K. S., 1974, SYNTACTIC PATTERN RE; Fu K. S., 1974, SYNTACTIC METHODS PA; FU KS, 1975, IEEE T SYST MAN CYB, VSMC5, P409, DOI 10.1109/TSMC.1975.5408432; Fu K.S., 1976, DIGITAL PATTERN RECO; FUJIMURA O, 1973, Computers in Biology and Medicine, V3, P371, DOI 10.1016/0010-4825(73)90003-6; Fujisaki T., 1984, P 10 INT C COMP LING, P16; FUNG LW, 1975, IEEE T COMPUT, VC 24, P662; Garey M.R., 1979, COMPUTERS INTRACTABI; Gillman R. A., 1975, J ACOUST SOC AM, V58, P562; Godel K., 1931, MONATSHEFTE MATH PHY, V38, P173, DOI DOI 10.1007/BF01700692; GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5; Goldberg A. E., 1995, CONSTRUCTIONS CONSTR; Goldstine Herman H., 1972, COMPUTER PASCAL VONN; Goodman R. G., 1976, ANAL LANGUAGES MAN M; Gradshteyn I. S., 1980, TABLES INTEGRALS SER; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P459, DOI 10.1109/TASSP.1976.1162857; Greibach S., 1979, P 20 ANN S FDN COMP, P66; Grossberg S, 1987, ADAPTIVE BRAIN; Hadamard J., 1960, SCI CREATIVITY; Hafer E. H., 1974, THESIS NW U; HALL JL, 1977, J ACOUST SOC AM, V61, P802, DOI 10.1121/1.381369; HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686; Hamming R. W., 1980, HIST COMPUTING 20 CE; Harris Z., 1982, GRAMMAR ENGLISH MATH; Harrison M. A., 1979, INTRO FORMAL LANGUAG; Hartigan J., 1975, CLUSTERING ALGORITHM; Haton J. P., 1980, P INT C AC SPEECH SI, P892; Hebb D O, 1949, ORG BEHAV; Henis E. A., 1995, P AAAI S CAMBR MA NO; Hestenes M.R., 1975, OPTIMIZATION THEORY; Hironymous J., 1995, AUTOMATIC LANGUAGE I; Ho Y. C., 1968, P IEEE, V56; Hodges A., 1983, A TURING ENIGMA; HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500; Hofstadter DR, 1979, GODEL ESCHER BACH ET; Hohenberg P., 1964, PHYS REV B, V136, P864; Holton G., 1995, EINSTEIN HIST OTHER; Hopcroft J. E., 1969, FORMAL LANGUAGES THE; Hopfield J. J., 2002, PHYS TODAY       NOV, P10; Hopper M. J., 1979, HARWELL SUBROUTINE L, V55; Huang J., 2001, THESIS U ILLINOIS UR; Hunt E., 1975, ARTIFICIAL INTELLIGE; Hunt M. J., 1980, P INT C AC SPEECH SI, P880; ISHIZAKA K, 1975, IEEE T ACOUST SPEECH, V23, P370, DOI 10.1109/TASSP.1975.1162701; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; JACKENDOFF R, 1991, COGNITION, V41, P9, DOI 10.1016/0010-0277(91)90031-X; Jackendoff R., 1996, LANGUAGE SPACE, P1; Jakobson R., 1939, P 3 INT C PHON SCI, P34; James W., 1899, TALKS TEACHERS PSYCH; Jaynes J., 1975, ORIGINS CONSCIOUSNES; Jelinek F., 1982, HDB STAT, V2; JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384; Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; Johnson M., 1987, BODY MIND BODILY BAS; JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307; Kempelen W. V., 1791, MECH SPEECH FOLLOWS; Kittler J., 1982, PATTERN RECOGNITION; KLATT DH, 1977, J ACOUST SOC AM, V62, P1345, DOI 10.1121/1.381666; KLATT DH, 1973, IEEE T ACOUST SPEECH, VAU21, P210, DOI 10.1109/TAU.1973.1162453; Kleene S. C., 1952, INTRO MATH; Kleffner M., THESIS U ILLINOIS UR; Knuth D., 1968, ART COMPUTER PROGRAM, V<IT>1</IT>; Knuth D. E., 1973, ART COMPUTER PROGRAM, V3; Kohonen T., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Kohonen T., 1988, SELF ORG ASS MEMORY; Kuhn T. S., 1970, STRUCTURE SCI REVOLU; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lakoff G., 2000, MATH COMES EMBODIED; Lakoff G., 1996, MORAL POLITICS; Lakoff G., 1987, WOMEN FIRE DANGEROUS; Lakoff G., 1980, METAPHORS WE LIVE BY; Lakoff George, 1999, PHILOS FLESH EMBODIE; LANDAU B, 1993, BEHAV BRAIN SCI, V16, P217; Langacker R. W., 1986, FDN COGNITIVE GRAMMA; LaPlace P.S., 1951, PHILOS ESSAY PROBABI; Latour B., 1988, PASTEURIZATION FRANC; Lawler E, 1976, COMBINATORIAL OPTIMI; Lea W. A., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing; LEA WA, 1975, IEEE T ACOUST SPEECH, VAS23, P30; LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745; LESSER VR, 1975, IEEE T ACOUST SPEECH, VAS23, P11, DOI 10.1109/TASSP.1975.1162648; Levinson S. E., 2000, P INT C DEV LEARN AP; Levinson S. E., 1977, P IEEE INT C AC SPEE; Levinson S. E., 1976, P IEEE ICISS PATR GR, P501; Levinson S. E., 1979, P IEEE ICASSP 79, P239; Levinson S. E., 1989, SPEECH TECHNOLOGY, P26; Levinson S. E., 1987, P AAAI S STANF CA MA, P36; Levinson S. E., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing; Levinson S. E., 1977, BELL SYST TECH J, V57, P1627; Levinson S. E., 1973, P IEEE C SYST MAN CY, P344; Levinson S. E., 1975, P 4 INT C ART INT TB, P499; Levinson S. E., 1996, P C MACH LEARN SNOWB; RABINER LR, 1985, AT&T TECH J, V64, P1211; LEVINSON SE, 1994, VOICE COMMUNICATION BETWEEN HUMANS AND MACHINES, P159; LEVINSON SE, 1979, IEEE T ACOUST SPEECH, V27, P134, DOI 10.1109/TASSP.1979.1163222; LEVINSON SE, 1983, AT&T TECH J, V62, P1035; LEVINSON SE, 1980, AT&T TECH J, V59, P119; Li D., 2003, P IEEE INT C AC SPEE; Li D., 2003, THESIS U ILLINOIS UR; Li K. P., 1980, ICASSP 80 Proceedings. IEEE International Conference on Acoustics, Speech and Signal Processing; Lin R.- S., 2002, THESIS U ILLINOIS UR; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LIPORACE LA, 1975, J ACOUST SOC AM, V58, P1288, DOI 10.1121/1.380811; LIPORACE LA, 1982, IEEE T INFORM THEORY, V28, P729, DOI 10.1109/TIT.1982.1056544; Lipton R. J., 1974, 37 YAL U DEP COMP SC; Liu Q., 2001, THESIS U ILLINOIS UR; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Lorentz G. G., 1976, MATH DEV ARISING HIL; Lowerre B. T., 1976, THESIS CARNEGIE MELL; MacQueen J. B., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792; Marcus M., 1980, THEORY SYNTACTIC REC; Margenau H., 1958, NATURE PHYS REALITY; Markel J.D., 1976, LINEAR PREDICTION SP; Markov A. A., 1913, P ACAD SCI ST PETERS, V7, P153; MARSHALL JC, 1977, SOC STUD SCI, V7, P475, DOI 10.1177/030631277700700412; McCalla T. R., 1967, INTRO NUMERICAL METH; McGinn C., 1999, MYSTERIOUS FLAME; Meisel W, 1972, COMPUTER ORIENTED AP; Merchant Carolyn, 1980, DEATH NATURE WOMEN E; Mercier G., SPOKEN LANGUAGE GENE, P525; MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491; Minsky M., 1969, PERCEPTRONS INTRO CO; Minsky M., 1968, SEMANTIC INFORM PROC, P425; Morse P. H., 1968, THEORETICAL ACOUSTIC; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P351, DOI 10.1109/TASSP.1981.1163586; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P284, DOI 10.1109/TASSP.1981.1163527; MYERS CS, 1982, IEEE T ACOUST SPEECH, V30, P561, DOI 10.1109/TASSP.1982.1163932; NADAS A, 1984, IEEE T ACOUST SPEECH, V32, P859, DOI 10.1109/TASSP.1984.1164378; NADAS A, 1983, IEEE T ACOUST SPEECH, V31, P504, DOI 10.1109/TASSP.1983.1164070; Nagel E., 1958, GODELS PROOF; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; Nakatsu R., 1978, REV ECL, V26, P1505; NELSON WL, 1983, BIOL CYBERN, V46, P135, DOI 10.1007/BF00339982; Newell A., 1973, SPEECH UNDERSTANDING; NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320; Nilsson N.J., 1971, PROBLEM SOLVING METH; Olive J. P., 1981, J ACOUST SOC AM, V66, P663; Olive J. P., 1977, P INT C ACOUST SPEEC, P568; OSHIKA BT, 1975, IEEE T ACOUST SPEECH, VAS23, P104, DOI 10.1109/TASSP.1975.1162639; Oshika B. T., 1976, P IEEE INT C AC SPEE, P577; Pant G., 1973, SPEECH SOUNDS FEATUR; PASSMAN DS, 1973, PAC J MATH, V44, P281; Patrick E. A., 1972, FUNDAMENTALS PATTERN; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Paz A., 1971, INTRO PROBABILISTIC; Peirce C. S., 1935, COLLECTED PAPERS C S; Penrose R., 1990, EMPORORS NEW MIND; Perennou G., 1982, Automatic Speech Analysis and Recognition. Proceedings of the NATO Advanced Study Institute; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Plato, 1955, REPUBLIC; Poincare H., 1960, DISCOVERY MATH PHYS; Poritz A. B., 1980, P S APPL HIDD MARK M, P88; Poritz A. B., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; Portnoff M. R., 1973, THESIS MIT; Potter R. K., 1968, VISIBLE SPEECH; QUILLIAN R., 1968, SEMANTIC INFORM PROC; Rabiner L., 1978, DIGITAL PROCESSING S; RABINER LR, 1984, AT&T TECH J, V63, P627; Rabiner L., 1993, FUNDAMENTALS SPEECH; RABINER LR, 1981, IEEE T COMMUN, V29, P621, DOI 10.1109/TCOM.1981.1095031; RABINER LR, 1983, AT&T TECH J, V62, P1075; Rabiner L. R., 1980, IEEE T ACOUST SPEECH, VASSP-28, P337; RABINER LR, 1985, IEEE T ACOUST SPEECH, V33, P561, DOI 10.1109/TASSP.1985.1164586; Rabiner L. R., 1979, BELL SYST TECH J, V5, P2217; RABINER LR, 1979, J ACOUST SOC AM, V66, P663, DOI 10.1121/1.383693; RABINER LR, 1979, IEEE T ACOUST SPEECH, V27, P336, DOI 10.1109/TASSP.1979.1163259; RABINER LR, 1981, AT&T TECH J, V60, P893; RABINER LR, 1984, AT&T TECH J, V63, P721; RABINER LR, 1978, IEEE T ACOUST SPEECH, V26, P575, DOI 10.1109/TASSP.1978.1163164; RABINER LR, 1982, AT&T TECH J, V61, P981; RABINER LR, 1978, IEEE T ACOUST SPEECH, V26, P34, DOI 10.1109/TASSP.1978.1163037; RABINER LR, 1980, J ACOUST SOC AM, V68, P1271, DOI 10.1121/1.385120; REDDY DR, 1967, J ACOUST SOC AM, V42, P329, DOI 10.1121/1.1910582; Reid Constance, 1970, HILBERT; Riley M. D., 1989, SPEECH TIME FREQUENC; Robins A, 1999, NEURAL NETWORKS, V12, P1191, DOI 10.1016/S0893-6080(99)00056-8; Roe D. B., 1993, P ICASSP 93 MAY; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; Rosenberg A. E., 1976, J ACOUST SOC AM   S1, V60, P512; ROSENBERG AE, 1983, IEEE T ACOUST SPEECH, V31, P713, DOI 10.1109/TASSP.1983.1164132; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; ROSENTHA.LH, 1974, IEEE T ACOUST SPEECH, VAS22, P339, DOI 10.1109/TASSP.1974.1162597; Rumelhart DE, 1986, PARALLEL DISTRIBUTED; Ruske G., 1982, Automatic Speech Analysis and Recognition. Proceedings of the NATO Advanced Study Institute; Russell B., 1962, PRINCIPIA MATH; Russell M. J., 1985, P IEEE INT C AC SPEE, P5; Russell M. J., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing; SAKOE H, 1979, IEEE T ACOUST SPEECH, V27, P588, DOI 10.1109/TASSP.1979.1163310; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Sakoe H., 1971, P 7 INT C AC, V3, P65; SCAGLIOLA C, 1983, SPEECH COMMUN, V2, P199, DOI 10.1016/0167-6393(83)90028-6; Schorske Carl E., 1979, FIN DE SIECLE VIENNA; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417; Sebestyen G. S., 1962, DECISION MAKING PROC; SHANNON CE, 1948, AT&T TECH J, V27, P379; Shapiro J.F., 1979, MATH PROGRAMMING STR; Shikano K., 1978, Transactions of the Institute of Electronics and Communication Engineers of Japan, Section E (English), VE61; Shipman D. W., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; Silverman H. F., 1974, IEEE T ACOUST SPEECH, VASSP-23, P369; Simon J. C., 1986, PATTERNS OPERATORS; Sokal AD, 1996, SOCIAL TEXT, V46/47, P217; Sondhi M. M., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing; SONDHI MM, 1974, J ACOUST SOC AM, V55, P1070, DOI 10.1121/1.1914649; SONDHI MM, 1979, IEEE T ACOUST SPEECH, V27, P268, DOI 10.1109/TASSP.1979.1163240; SORENSON HW, 1971, AUTOMATICA, V7, P465, DOI 10.1016/0005-1098(71)90097-5; STEBE PF, 1972, PAC J MATH, V43, P765; STEVENS KN, 1980, J ACOUST SOC AM, V68, P836, DOI 10.1121/1.384823; Tan I., 2002, THESIS U ILLINOIS UR; TANAKA E, 1978, IEEE T COMPUT, V27, P605; Tanenhaus M.K., 1996, ATTENTION PERFORM, P457; TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863; TAPPERT CC, 1977, INT J MAN MACH STUD, V9, P363, DOI 10.1016/S0020-7373(77)80032-1; Tohkura Y., 1983, P IEEE INT C AC SPEE; Tomasello M., 1999, CULTURAL ORIGINS HUM; Tomita M, 1985, EFFICIENT PARSING NA; Tou J.T., 1974, PATTERN RECOGNITION; TRIBOLET JM, 1979, IEEE T ACOUST SPEECH, V27, P550, DOI 10.1109/TASSP.1979.1163288; Turing A.M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433; Turing AM, 1937, P LOND MATH SOC, V42, P230; Velichko V. M., 1969, INT J MAN MACH STUD, V2, P223; Vintsyuk T. K., 1968, KIBERNETIKA, V81; Viterbi A., 1967, IEEE T INFORM THEORY, V13; Von Neumann J., 1950, THEORY GAMES; WAKITA H, 1973, IEEE T ACOUST SPEECH, VAU21, P417, DOI 10.1109/TAU.1973.1162506; WALKER DE, 1975, IEEE T ACOUST SPEECH, V23, P397, DOI 10.1109/TASSP.1975.1162726; Webster AG, 1919, P NATL ACAD SCI USA, V5, P275, DOI 10.1073/pnas.5.7.275; Weinstock R., 1974, CALCULUS VARIATIONS; Wiener N, 1948, CYBERNETICS CONTROL; WIGNER EP, 1960, COMMUN PUR APPL MATH, V13, P1, DOI 10.1002/cpa.3160130102; Wilson E. O., 1998, CONSILIENCE UNITY KN; Wolf J. J., 1977, IEEE INT C AC SPEECH, P784; WOODS WA, 1975, IEEE T ACOUST SPEECH, VAS23, P2, DOI 10.1109/TASSP.1975.1162647; Woods W. A., 1974, 2976 BOLT BER NEWM; Woods W. A., 1975, SPEECH RECOGNITION; WOODS WA, 1982, ARTIF INTELL, V18, P295, DOI 10.1016/0004-3702(82)90025-X; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773; Younger D. M., 1967, INFORM CONTROL, V10; Zador P. L., 1966, TOPICS ASYMPTOTIC QU; ZADOR PL, 1982, IEEE T INFORM THEORY, V28, P139, DOI 10.1109/TIT.1982.1056490; Zhu W., 2002, P 7 INT C INT AUT SY, P404; Zhu WY, 2001, PROC CVPR IEEE, P240; Zhu W., 2000, P 15 INT C PATT REC, V1, P936; ZUE VW, 1983, SPEECH COMMUN, V2, P181, DOI 10.1016/0167-6393(83)90023-7; [Anonymous], 2000, P INT C DEV LEARN	343	13	13	BLACKWELL SCIENCE PUBL	OXFORD	OSNEY MEAD, OXFORD OX2 0EL, ENGLAND		978-0-470-02091-3				2005							1	261				261	Acoustics; Mathematics, Applied	Acoustics; Mathematics	BYD55	WOS:000298105200012	
B	Koukal, T; Schneider, W; Suppan, F		Oluic, M		Koukal, T; Schneider, W; Suppan, F			Radiometric-topographic normalization in mountainous terrain for Landsat-TM-based forest parameter assessment by the kNN method	NEW STRATEGIES FOR EUROPEAN REMOTE SENSING			English	Proceedings Paper	24th Symposium of the European-Association-of-Remote-Sensing-Laboratories (EARSeL)	MAY 25-27, 2004	Dubrovnik, CROATIA	European Assoc Remote Sensing Labs		forest inventory; radiornetric-topographic normalization; kNN		The kNN method of combining a terrestrial forest inventory with remote sensing image analysis is applied in mountainous terrain. This poses problems of radiometric-topographic normalization, which are addressed in this paper. The SCS (sun-canopy-sensor) method, extended for including diffuse sky radiation, is found to be particularly suited for this. Estimating parameters of radiometric-topographic correction algorithms (such as the ratio of direct sun radiation and diffuse sky radiation in case of the extended SCS method) from the image itself by regression of forest pixels arbitrarily selected at different topographic conditions relies on the assumption that the forest pixels selected at different irradiation conditions represent (in the statistical average) identical forest conditions. This assumption can hardly be proved to be valid. The estimation of this ratio by tuning within the kNN cross-validation procedure, on the other hand, represents a sound method, making use of the large amount of forest information available from terrestrial forest inventories. The practicability of this method depends on the number and thematic distribution of field plots on one single scene, for which homogenous atmospheric conditions can be assumed.	BOKU Univ Natl Resources & Appl Life Sci, Dept Landscape Spatial Sci & Infrastruct, Inst Surveying Remote Sensing & Land Informat, Vienna, Austria	Koukal, T (reprint author), BOKU Univ Natl Resources & Appl Life Sci, Dept Landscape Spatial Sci & Infrastruct, Inst Surveying Remote Sensing & Land Informat, Vienna, Austria.						COLBY JD, 1991, PHOTOGRAMM ENG REM S, V57, P531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Efron B., 1993, MONOGRAPHS STAT APPL, V57; Gu D, 1998, REMOTE SENS ENVIRON, V64, P166, DOI 10.1016/S0034-4257(97)00177-6; ITTEN KL, 1992, REMOTE SENSING SERIE, P18; KILKKI P, 1987, REMOTE SENSING AIDED, P209; SMITH JA, 1980, PHOTOGRAMM ENG REM S, V46, P1183; Teillet P. M., 1982, Canadian Journal of Remote Sensing, V8; TOMPPO E, 1993, ILV S NAT FOR INV IU	9	0	0	MILLPRESS SCIENCE PUBLISHERS	ROTTERDAM	PO BOX 84118, 3009 CC ROTTERDAM, NETHERLANDS		90-5966-003-X				2005							239	246				8	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	BCD88	WOS:000228786900029	
J	Yang, Y; Zheng, CX; Lin, P				Yang, Y; Zheng, CX; Lin, P			Fuzzy clustering with spatial constraints for image thresholding	OPTICA APPLICATA			English	Article						image thresholding; fuzzy c-means; k-nearest neighbor; fuzzy thresholding	ENTROPY; PARTITION; HISTOGRAM	Image thresholding plays an important role in image segmentation. This paper presents a novel fuzzy clustering based image thresholding technique, which incorporates the spatial neighborhood information into the standard fuzzy c-means (FCM) clustering algorithm. The prior spatial constraint, which is defined as weight in this paper, is inspired-by the k-nearest neighbor (k-NN) algorithm and is modified from two aspects in order to improve the performance of image thresholding. The algorithm is. initialized by a fast FCM algorithm,. in which the iteration is carried out with the statistical gray level histogram of image instead of the conventional whole data of image; therefore its convergence is fast. Extensive experiment results and both qualitative and quantitative comparative studies with several existing methods on the thresholding of some synthetic and real images illustrate the effectiveness and robustness of the proposed algorithm.	Xian Jiaotong Univ, Inst Biomed Engn, Educ Minist, Key Lab Biomed Informat Engn, Xian 710049, Peoples R China	Yang, Y (reprint author), Xian Jiaotong Univ, Inst Biomed Engn, Educ Minist, Key Lab Biomed Informat Engn, Xian 710049, Peoples R China.	greatyyy765@sohu.com					ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; Bezdek J., 1981, PATTERN RECOGNITION; BRINK AD, 1992, PATTERN RECOGN, V25, P803, DOI 10.1016/0031-3203(92)90034-G; CHEN WT, 1994, PATTERN RECOGN, V27, P885, DOI 10.1016/0031-3203(94)90154-6; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; Chi Z., 1996, FUZZY ALGORITHMS APP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELSTEIN WA, 1984, MED PHYS, V11, P180, DOI 10.1118/1.595484; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; Gong JA, 1998, PATTERN RECOGN, V31, P295, DOI 10.1016/S0031-3203(97)00043-5; Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6; JULIUS TT, 1974, PATTERN RECOGNITION; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI [10.1117/1.1631315, 10.1117/1.16313161]; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743	19	0	0	TECHNICAL UNIV WROCLAW	WROCLAW	WYBRZEZE WYSPIANSKIEGO 27, EXPORT-IMPORT DIVISION, 50-370 WROCLAW, POLAND	0078-5466		OPT APPL	Opt. Appl.		2005	35	4					943	954				12	Optics	Optics	045VO	WOS:000237771000034	
S	Sheridan, C; O'Farrell, M; Lewis, E; Lyons, WB; Flanagan, C; Jackman, N		Byrne, HJ; Lewis, E; MacCraith, BD; McGlynn, E; McLaughlin, JA; OSullivan, GD; Ryder, AG; Walsh, JE		Sheridan, C; O'Farrell, M; Lewis, E; Lyons, WB; Flanagan, C; Jackman, N			Comparison of k-NN, backpropagation and self-organising map classification methods using an optical fibre based sensor system utilised in an industrial large scale oven	Opto-Ireland 2005: Optical Sensing and Spectroscopy	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Opto-Ireland 2005 Conference	APR 05-06, 2005	Dublin, IRELAND	SPIE Europe, Enterprise Ireland, Sci Fdn Ireland, Failte Ireland		optical fibre sensor; self-organising map; k-NN; Artificial Neural Network		This paper reports on three methods of classifying the spectral data from an optical fibre based sensor system as used in the food industry. The first method uses a feed-forward back-propagation Artificial Neural Network; the second method involves using Kohonen Self-Organising Maps while the third method is k-Nearest Neighbour analysis. The sensor monitors the food colour online as the food cooks by examining the reflected light from both the surface and the core of the product. The combination of using Principal Component Analysis and Backpropagation Neural Networks has been successfully investigated previously. In this paper, results obtained using all three classifiers are presented and compared. The Principal Components used to train each classifier are evaluated from data that generate a "colourscale" comprising six colour classifications. This scale has been developed to allow several products of similar colour to be tested using a single network that had been trained using the colourscale. The results presented show that both the neural network and the Self-Organising Map approach perform comparably, while the k-NN method tested under-performs the other two.	Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland	Sheridan, C (reprint author), Univ Limerick, Dept Elect & Comp Engn, Limerick, Ireland.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HAYKIN S, 1999, NEURAL NETWORKS COMP; Kohenen T, 2001, SELF ORG MAPS; Kohenen T., 1990, P IEEE, V78, P1464; OFARRELL M, 2003, P IEEE, V1, P368, DOI 10.1109/ICSENS.2003.1278960; Schalkoff R, 1992, PATTERN RECOGNITION; SHERIDAN C, 2004, P 14 ART NEUR NETW E, V14, P879	7	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5811-2	P SOC PHOTO-OPT INS			2005	5826						706	713		10.1117/12.619555		8	Instruments & Instrumentation; Optics; Spectroscopy	Instruments & Instrumentation; Optics; Spectroscopy	BCT93	WOS:000231202200075	
S	Pham, TD		Singh, S; Singh, M; Apte, C; Perner, P		Pham, TD			An optimally weighted fuzzy k-NN algorithm	PATTERN RECOGNITION AND DATA MINING, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	3rd International Conference on Advances in Pattern Recognition	AUG 22-25, 2005	Bath, ENGLAND				GENE-EXPRESSION DATA; CLASSIFICATION; CANCER	The nearest neighbor rule is a non-parametric approach and has been widely used for pattern classification. The k-nearest neighbor (k-NN) rule assigns crisp memberships of samples to class labels; whereas the fuzzy k-NN neighbor rule replaces crisp memberships with fuzzy memberships. The membership assignment by the conventional fuzzy k-NN algorithm has a disadvantage in that it depends on the choice of some distance function, which is not based on any principle of optimality. To overcome this problem, we introduce in this paper a computational scheme for determining optimal weights to be combined with different fuzzy membership grades for classification by the fuzzy k-NN approach. We show how this optimally weighted fuzzy k-NN algorithm can be effectively applied for the classification of microarray-based cancer data.	James Cook Univ N Queensland, Bioinformat Appl Res Ctr, Sch Informat Technol, Townsville, Qld 4811, Australia	Pham, TD (reprint author), James Cook Univ N Queensland, Bioinformat Appl Res Ctr, Sch Informat Technol, Townsville, Qld 4811, Australia.	tuan.pham@jcu.edu.au					ABLAVSKY V, 2003, P 7 INT C DOC AN REC, V2, P750; Baoli L., 2004, ACM T ASIAN LANGUAGE, V3, P215, DOI 10.1145/1039621.1039623; Bezdek J., 1981, PATTERN RECOGNITION; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; GINNEKEN BV, 2004, P 17 INT C PATT REC, V3, P718; Guo GD, 2004, LECT NOTES COMPUT SC, V2945, P559; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Isaaks E, 1989, INTRO APPL GEOSTATIS; Journel A., 1978, MINING GEOSTATISTICS; JOURNEL AG, 1996, DERIVING CONDITIONAL; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39; PALIWAL KK, 1983, IEEE T PATTERN ANAL, V5, P229; Tokola T, 1996, INT J REMOTE SENS, V17, P2333; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Zhou XB, 2004, J BIOMED INFORM, V37, P249, DOI 10.1016/j.jbi.2004.07.009	18	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-28757-4	LECT NOTES COMPUT SC			2005	3686						239	247				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDA34	WOS:000232247900026	
S	Mollineda, RA; Sanchez, JS; Sotoca, JM		Marques, JS; PerezdelaBlanca, N; Pina, P		Mollineda, RA; Sanchez, JS; Sotoca, JM			Data characterization for effective prototype selection	PATTERN RECOGNITION AND IMAGE ANALYSIS, PT 2, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	2nd Iberian Conference on Pattern Recongnition and Image Analysis	JUN 07-09, 2005	Estoril, PORTUGAL	Fund Oriente, Fund Cienc Tecnol, HP Portugal, Inst Syst & Robotics, Int Assoc Pattern Recognit			NEAREST-NEIGHBOR RULE; CLASSIFICATION; ALGORITHMS	The Nearest Neighbor classifier is one of the most popular supervised classification methods. It is very simple, intuitive and accurate in a great variety of real-world applications. Despite its simplicity and effectiveness, practical use of this rule has been historically limited due to its high storage requirements and the computational costs involved, as well as the presence of outliers. In order to overcome these drawbacks, it is possible to employ a suitable prototype selection scheme, as a way of storage and computing time reduction and it usually provides some increase in classification accuracy. Nevertheless, in some practical cases prototype selection may even produce a degradation of the classifier effectiveness. From an empirical point of view, it is still difficult to know a priori when this method will provide an appropriate behavior. The present paper tries to predict how appropriate a prototype selection algorithm will result when applied to a particular problem, by characterizing data with a set of complexity measures.	Univ Jaume 1, Dept Llenguatges & Sistemes Informat, E-12071 Castellon de La Plana, Spain	Mollineda, RA (reprint author), Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Av Sos Baynat S-N, E-12071 Castellon de La Plana, Spain.	mollined@uji.es; sanchez@uji.es; sotoca@uji.es					BERNADOMANSILLA E, 2004, P 17 INT C PATT REC, V1, P136; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Devijver P. A., 1982, PATTERN RECOGNITION; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	15	19	19	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-26154-0	LECT NOTES COMPUT SC			2005	3523						27	34				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BCM80	WOS:000230027000004	
B	Dai, JY; Lee, J; Wang, MC		Arabnia, HR		Dai, JY; Lee, J; Wang, MC			Analytical modeling of data mining process based on distributed tuple space	PDPTA '05: Proceedings of the 2005 International Conference on Parallel and Distributed Processing Techniques and Applications, Vols 1-3			English	Proceedings Paper	International Conference on Parallel and Distributed Processing Techniques and Applications	JUN 27-30, 2005	Las Vegas, NV			data mining; tuple space; parallel processing; analytical modeling		The explosive growth in data volume imposes a big challenge to traditional data mining process in that data mining algorithms tend to be computationally intensive. Parallel and distributed data mining provides an attractive solution to the large scale data mining process. Message passing based parallel computing has been widely used in diverse applications such as scientific computing, ray tracing, simulation, and recently data mining. In this paper, we will present an alternative approach based on distributed tuple space that we contend provides more convenient and efficient parallel data mining framework. Then, we describe the associated analytical performance models to investigate the scalability of the proposed architecture over the cluster computing environment. We also present the experimental results for an exemplary data mining algorithm, k nearest neighbor.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	Dai, JY (reprint author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.						ARAUJO DLA, 2000, P 2000 GEN EV COMP W, P89; CHEUNG DW, 1999, HIGH PERFORMANCE DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI JY, 2005, 13 HIGH PERF COMP S; DHILLON IS, 1999, WORKSH LARG SCAL PAR, P245; Freeman E., 1999, JAVASPACES PRINCIPLE; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; GELERNTER D, 1985, ACM T PROGR LANG SYS, V7, P80, DOI 10.1145/2363.2433; Gropp W., 1995, USING MPI PORTABLE P; GUPTA A, 1993, J PARALLEL DISTR COM, V19, P234, DOI 10.1006/jpdc.1993.1107; LEE JH, 2004, INT C PAR DISTR COMP; MEIRA W, 1995, 589 U ROCH COMP SCI; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; WYCKOFF P, 1998, IBM SYSTEM J, V37; ZAKI MJ, 1999, 15 INT C DAT ENG SYD; 2004, KDDCUP; 1992, J PARALLEL DISTRIBUT, V14, P260; MPICH PORTABLE IMPLE; 1994, IEEE WORLD C COMPUTA, V4, P2052; 1999, KDDCUP; NIH GENETIC SEQUENCE	21	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA		1-932415-61-0				2005							1135	1141				7	Computer Science, Theory & Methods	Computer Science	BDY80	WOS:000236257900167	
B	Dai, JY; Lee, J; Wang, MC		Arabnia, HR		Dai, JY; Lee, J; Wang, MC			Efficient parallel data mining for massive datasets: Parallel random forests classifier	PDPTA '05: Proceedings of the 2005 International Conference on Parallel and Distributed Processing Techniques and Applications, Vols 1-3			English	Proceedings Paper	International Conference on Parallel and Distributed Processing Techniques and Applications	JUN 27-30, 2005	Las Vegas, NV			data mining; parallel processing; random forests; cluster computing		Data mining refers to the process of finding hidden patterns inside a large dataset. While improving the accuracy of those algorithms has been the main focus of past research, massive dataset size imposes another challenge. Parallel and distributed processing techniques have been applied to data mining algorithms to make them scalable. In this paper, we discuss a new emerging data mining algorithm, random forests, and its parallelization based on VCluster, a portable parallel runtime system we have developed for a cluster of multiprocessors. Random forests is an ensemble of many decision trees and the classification is performed by majority voting by those decision trees. We also present the experimental results on the performance of parallel random forests approach.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA	Dai, JY (reprint author), Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.						ARAUJO DLA, 2000, P 2000 GEN EV COMP W, P89; Barbara D., 1997, B TECHNICAL COMMITTE, V20, P3; BAUER E, 1999, MACHINE LEARNING; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CHEUNG DW, 1999, HIGH PERFORMANCE DAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhillon I.S., 1999, LARGE SCALE PARALLEL, P245; EUILHON H, 1999, DATA MIN KNOWL DISC, V3, P237; Freitas A. A., 1998, PADD98. Proceedings of the Second International Conference on the Practical Application of Knowledge Discovery and Data Mining; HAN JW, 2000, DATA MINING CONCEPTS, P5; Kass G., 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; LEE JH, 2004, INT C PAR DISTR COMP; LEE JH, 2005, 19 EUR SIM MULT PERF; LEE JH, 2005, INT C PAR DISTR PROC; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; ZAKI MJ, 1999, 15 INT C DAT ENG SYD; 1994, IEEE WORLD C COMP IN, V4, P2052	22	0	0	C S R E A PRESS	ATHENS	115 AVALON DR, ATHENS, GA 30606 USA		1-932415-61-0				2005							1142	1148				7	Computer Science, Theory & Methods	Computer Science	BDY80	WOS:000236257900168	
B	Wang, JG; Neskovic, P; Cooper, LN			IEEE	Wang, JG; Neskovic, P; Cooper, LN			An adaptive nearest neighbor algorithm for classification	Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9			English	Proceedings Paper	4th International Conference on Machine Learning and Cybernetics	AUG 18-21, 2005	Canton, PEOPLES R CHINA	IEEE Systems, Man & Cybernet TCC, Hong Kong Polytechn Univ, Hebei Univ, S China Univ Technol, Chongqing Univ, Sun Yatsen Univ, Harbin Inst Technol, Int Univ Germany		classification; nearest neighbor rule; curse of dimensionality; statistical confidence	REGRESSION	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. It can be interpreted as an empirical Bayes classifier based on the estimated a posteriori probabilities from the k nearest neighbors. The performance of the k-nearest neighbor rule relies on the locally constant a posteriori probability assumption. This assumption, however, becomes problematic in high dimensional spaces due to the curse of dimensionality. In this paper we introduce a locally adaptive nearest neighbor rule. Instead of using the Euclidean distance to locate the nearest neighbors, the proposed method takes into account the effective influence size of each training example and the statistical confidence with which the label of each training example can be trusted. We test the new method on real-world benchmark datasets and compare it with the standard k-nearest neighbor rule and the support vector machines. The experimental results confirm the effectiveness of the propose method.	Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Dept Phys, Inst Brain & Neural Syst, Providence, RI 02912 USA.						Blake C.L., UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1951, 4 USAF SCH AV MED RA; FRIEDMAN J, 1994, 113 U STAT DEP; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886	10	1	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-9091-1				2005							3069	3074				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BDT94	WOS:000235325604089	
B	Marchiori, E; Heegaard, NHH; West-Nielsen, M; Jimenez, CR			IEEE	Marchiori, E; Heegaard, NHH; West-Nielsen, M; Jimenez, CR			Feature selection for classification with proteomic data of mixed quality	Proceedings of the 2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology			English	Proceedings Paper	2nd IEEE Symposium on Computational Intelligence in Bioformatics and Computational Biology	NOV 14-15, 2005	La Jolla, CA	IEEE Computat Intelligence Soc			PROSTATE-CANCER; OVARIAN-CANCER; SERUM; PATTERNS; ALGORITHMS	In this paper we assess experimentally the performance of two state-of-the-art feature selection methods, called RFE and RELIEF, when used for classifying pattern proteomic samples of mixed quality. The data are generated by spiking human sera to artificially create differentiable sample groups, and by handling samples at different storage temperature. We consider two type of classifiers: support vector machines (SVM) and k-nearest neighbour (kNN). Results of leave-one-out cross validation (LOOCV) experiments indicate that RELIEF selects more stable feature subsets than RFE over the runs, where the selected features are mainly spiked ones. However, RFE outperforms RELIEF in terms of (average LOOCV) accuracy, both when combined with SVM and kNN. Perfect LOOCV accuracy is obtained by RFE combined with INN. Almost all the samples that are wrongly classified by the algorithms have high storage temperature. The results of experiments on this data indicate that when samples of mixed quality are analyzed computationally, feature selection of only relevant (spiked) features does not necessarily correspond to highest accuracy of classification.	Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands	Marchiori, E (reprint author), Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands.						Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI; Diamandis EP, 2004, J NATL CANCER I, V96, P353, DOI 10.1093/jnci/djh056; Evgeniou T, 2004, MACH LEARN, V55, P71, DOI 10.1023/B:MACH.0000019805.88351.60; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Issaq HJ, 2003, ANAL CHEM, V75, p148A, DOI 10.1021/ac031249c; John G.H., 1994, INT C MACH LEARN, P121; JONG K, 2004, IEEE S COMP INT BIOI; KIRA K, 1992, 10 NAT C ART INT, P129; Li JN, 2002, CLIN CHEM, V48, P1296; LIE H, 1998, INT SERIES ENG COMPU; Liu Huiqing, 2002, Genome Inform, V13, P51; Marshall E, 2004, SCIENCE, V306, P630, DOI 10.1126/science.306.5696.630; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; OH IS, 2002, 16 INT C PATT REC IC; Petricoin EF, 2002, J NATL CANCER I, V94, P1576; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Qu YS, 2002, CLIN CHEM, V48, P1835; Ransohoff DF, 2005, J NATL CANCER I, V97, P315, DOI 10.1093/jnci/dji054; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; RENDELL LA, 1992, INT C MACH LEARN, P249; Vapnik V.N., 1998, STAT LEARNING THEORY; WESTNIELSEN M, 2005, ANAL CHEM; XING E, 2003, PRACTICAL APPROACH M; Yu L., 2003, ICML, P856; 2003, PNAS, V100, P14666	29	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-9387-2				2005							385	391				7	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Biochemistry & Molecular Biology; Computer Science	BDU91	WOS:000235518600054	
B	Thulasiram, RK; Bamgbade, AY		Blair, S; Chakraborty, U; Chen, SH; Cheng, HD; Chiu, DKY; Das, S; Denker, G; Duro, R; Romay, MG; Hung, D; Kerre, EE; VaLeong, H; Lu, CT; Lu, J; Maguire, L; Ngo, CW; Sarfraz, M; Tseng, C; Tsumoto, S; Ventura, D; Wang, PP; Yao, X; Zhang, CN; Zhang, K		Thulasiram, RK; Bamgbade, AY			Application of an instance based learning algorithm for predicting stock market index	Proceedings of the 8th Joint Conference on Information Sciences, Vols 1-3			English	Proceedings Paper	8th Joint Conference on Information Sciences (JCIS 2005)	JUL 21-26, 2005	Salt Lake City, UT	Duke Univ, Utah State Univ, San Jose State Univ, Harbin Inst Technol				This paper presents application of an instance based learning (IBL) algorithm for predicting stock index price changes. The objective is to determine the feasibility of stockprice prediction using the IB3 variant of the IBL algorithms. Various testing proportions and normalization methods were experimented to obtain good predictions. The results obtained are promising.	Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada	Thulasiram, RK (reprint author), Univ Manitoba, Dept Comp Sci, Winnipeg, MB, Canada.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; APOSTOLOS PR, 1995, NEURAL NETWORKS CAPI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hogg RV, 2001, PROBABILITY STAT INF; Kovalerchuk B., 2000, DATA MINING FINANCE; OLIKER S, 1997, NONLINEAR FINANCIAL, P183; WEIGEND AS, 1997, DECISION TECHNOLOGIE; *B GOV FED RES SYS, FED RES STAT REL	8	0	0	JOINT CONFERENCE INFORMATION SCIENCES	DURHAM	2709 MONTGOMERY ST, DURHAM, NC 27705 USA						2005							1110	1113				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BDI96	WOS:000233670801134	
B	Alizon, F; Shooter, S; Simpson, T			ASME	Alizon, Fabrice; Shooter, Steve; Simpson, Timothy			Introduction of the reuse method: Retrieving knowledge from existing product designs	Proceedings of the ASME Design Engineering Division 2005, Pts A and B			English	Proceedings Paper	ASME International Mechanical Engineering Congress and Exposition	NOV 05-11, 2005	Orlando, FL	ASME, Proc Ind Div, ASME, Rail Transportat Div, ASME, Noise Control & Acoust Div, ASME, Triol Div, ASME, Pressure Vessels & Piping Div, ASME, Bioengn Div, ASME, Mat Div, ASME, Appl Mech Div, ASME, Fluids Engn Div, ASME, Micro Elect Mech Syst Div, ASME, Heat Transfer Div, ASME, Nucl Engn Div, ASME, Power Div, ASME, Solar Energy Div, ASME, Safety Engn & Risk Anal Div, ASME, Technol & Soc Div, ASME, Adv Energy Syst Div, ASME, Aerosp Div, ASME, Comp & Informat Engn Div			CLASSIFICATION; INFORMATION	In today's marketplace, most products must better satisfy customers' needs in the shortest time and be competitively priced. In this context, the reuse of knowledge about the targeted product is critical for developing potential product platforms. One can facilitate the reuse of existing knowledge to achieve a desired design by establishing a method that considers the layout of modules (or components) with identified flow interfaces, volume and the fundamental functional description. The problem grows with the number of candidate modules and with information-rich descriptions. The proposed REUSE (Reuse Existing Unit for Shape and Efficiency) Method greatly facilitates this search by filtering candidates based on their similarity to desired characteristics and their performance efficiency. By reusing existing information from components and modules, this approach allows the detailed specification of cost (e.g., investment and production cost for a module) along with other desired characteristics. This method applies to the complete product realization enterprise from conception through product launch. It also enables traceability of design decisions to help capture rationale and justification. A case study involving a family of cameras illustrates the proposed method.	Bucknell Univ, Dept Mech Engn, Lewisburg, PA 17837 USA	Alizon, F (reprint author), Bucknell Univ, Dept Mech Engn, Lewisburg, PA 17837 USA.						Akoumianakis D, 1997, EXPERT SYST APPL, V12, P225, DOI 10.1016/S0957-4174(96)00097-8; ALIZON F, 2002, P FAIM; BRADLEY SR, 1993, ASME C DES THEOR MET, V53, P139; Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROFT WB, 1979, J DOC, V35, P285, DOI 10.1108/eb026683; CULLEY SJ, 1992, P I MECH ENG B-J ENG, V206, P253, DOI 10.1243/PIME_PROC_1992_206_082_02; Culley SJ, 1999, P I MECH ENG B-J ENG, V213, P203, DOI 10.1243/0954405991517371; Deutschman A. D., 1975, MACHINE DESIGN; DIPILLO PJ, 1976, COMMUN STAT A-THEOR, V5, P843; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; French MJ, 1993, J ENG DESIGN, V4, P267, DOI 10.1080/09544829308914786; JAYNES ET, 1967, CONFIDENCE INTERVALS, V2, P175; NANDA J, IN PRESS J COMPUTING; Pahl G., 1984, ENG DESIGN; ROY B, 1991, THEOR DECIS, V31, P49, DOI 10.1007/BF00134132; Roy B, 1993, ECONOMICA PARIS; Roy B., 1996, MULTICRITERIA METHOD; Shooter SB, 2000, ENG COMPUT-GERMANY, V16, P178, DOI 10.1007/s003660070004; SHOOTER SB, 2004, P ASME DETC; Sivaloganathan S, 1999, P I MECH ENG B-J ENG, V213, P641, DOI 10.1243/0954405991517092; Stone RB, 2000, J MECH DESIGN, V122, P359, DOI 10.1115/1.1289637; Szykman S, 2001, COMPUT AIDED DESIGN, V33, P545, DOI 10.1016/S0010-4485(01)00053-7; THEVENOT HJ, IN PRESS J ENG DESIG; TROUSSE B, 1993, ADVANCED TECHNOLOGIES, P451; VOGWELL J, 1991, P I MECH ENG B-J ENG, V205, P11, DOI 10.1243/PIME_PROC_1991_205_045_02; WEBBER SJ, 1994, THESIS U BATH; WOOD TJ, 1994, THESIS U BATH; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	29	0	0	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA		0-7918-4215-0				2005							335	343				9	Engineering, Mechanical	Engineering	BFI29	WOS:000241987200038	
B	Owotoki, P; Mayer-Lindenberg, F		Turau, V; Weyer, C		Owotoki, P; Mayer-Lindenberg, F			Comprehensible hierarchical intelligent (CHI) framework for monitoring and preventive maintenance of aircraft systems	Proceedings of the Third International Workshop on Intelligent Solutions in Embedded Systems			English	Proceedings Paper	3rd International Workshop on Intelligent Solutions in Embedded Systems (WISES 05)	MAY   20, 2005	Hamburg, GERMANY		Hamburg Univ Technol		ORGANIZATION	The peculiarities of the aircraft monitoring and maintenance domain are described and shortcomings of the current monitoring methodology are revealed. It is also shown why a new approach using computational intelligence models, as a replacement for the current BITE models, is paramount. In section 2 a brief review of developments in computational intelligence research is given. After which we present the comprehensible hierarchical intelligent framework, as a conceptual non monolithic intelligent approach utilizing distributed CI models for monitoring. Finally we conclude with discussions on the implementation and justification for our approach and direction for future work.	Tech Univ Hamburg, Dept Distributed Syst, D-2100 Hamburg, Germany	Owotoki, P (reprint author), Tech Univ Hamburg, Dept Distributed Syst, D-2100 Hamburg, Germany.						AAMODT A, 1994, AI COMMUN, V7, P39; AHA DW, 1989, P 4 INT WORKSH MACH, P27; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Breiman L., 1984, CART CLASSIFICATION; BROOKS RA, 1998, P 15 NAT C ART INT A; Buchanan B.G, 1984, RULE BASED EXPERT SY; BUNTINE W, 1989, P 6 INT WORKSH MACH, P94; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Chan P. K., 1993, Proceedings of the Second International Workshop on Multistrategy Learning (MSL-93); CHEN HC, 1992, IEEE T SYST MAN CYB, V22, P885, DOI 10.1109/21.179830; Cios K, 2002, KNOWLEDGE DISCOVERY; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAENEN BC, 2002, COMPUTATIONAL INTELL; Domingos P, 1996, MACH LEARN, V24, P141; Feigenbaum E. A, 1977, INT JOINT C ART INT, P1014; Grossberg S., 1982, STUDIES MIND BRAIN; Hayes-Roth F., 1983, BUILDING EXPERT SYST; HOLLAND JH, 1975, ADAPTATION NATURAL A; HOLSHEIMER M, 1994, CSR9406 CWI; HONG J, 1986, UIUCDCSF86949; Koza J. R., 1992, GENETIC PROGRAMMING; KUBAT M, 1997, MACHINE LEARNING DAT, P3; MITCHELL TM, 1980, TR117 RUTG U COMP SC; NEWELL A, 1956, IRE T INFORM THEOR, V2, P61, DOI 10.1109/TIT.1956.1056797; NEWELL A., 1960, P INT C INF PROC, P256; PARSAYE K, 1989, INTELLIGENT DATABASE; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, MACHINE LEARNING, V1, P1086; QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salzberg S.L., 1990, LEARNING NESTED GEN; SANTOS E, 1996, AFITENTR9601; SCHAFFER C, 1995, P 11 INT C MACH LEAR, P259; SHAPIRO GP, 1989, WORKSH KNOWL DISC RE; Smyth P, 1996, P 2 INT C KNOWL DISC, P82; TSAKONAS A, 2002, INT C SETN02 THESS G; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Welbank M., 1983, REV KNOWLEDGE ACQUIS; Willis W. D., 2004, SENSORY MECH SPINAL, V1; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Zadeh L.A., 1965, FUZZY SETS INFORM CO, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; ZIMMERMANN HJ, 2002, ADV COMP INTELLIG LE	46	0	0	HAMBURG UNIV TECHNOLOGY	HAMBURG	HAMBURG UNIV, HAMBURG, D-21073, GERMANY		3-902463-03-1				2005							175	184				10	Computer Science, Artificial Intelligence	Computer Science	BCP46	WOS:000230544200017	
S	Temel, T; Hallam, J		Ardil, C		Temel, Turgay; Hallam, John			An Evaluation of Algorithms for Single-Echo Biosonar Target Classification	PROCEEDINGS OF WORLD ACADEMY OF SCIENCE, ENGINEERING AND TECHNOLOGY, VOL 1	Proceedings of World Academy of Science Engineering and Technology		English	Proceedings Paper	Conference of the World-Academy-of-Science-Engineering-and-Technology	JAN 12-14, 2005	London, ENGLAND	World Acad Sci Engn & Technol		Classification; neuro-spike coding; non-parametric model; parametric model; Gaussian mixture; EM algorithm		A recent neuro-spiking coding scheme for feature extraction from biosonar echoes of various plants is examined with a variety of stochastic classifiers. Feature vectors derived are employed in well-known stochastic classifiers, including nearest-neighborhood, single Gaussian and a Gaussian mixture with EM optimization. Classifiers' performances are evaluated by using cross-validation and bootstrapping techniques. It is shown that the various classifers perform equivalently and that the modified preprocessing configuration yields considerably improved results.	[Temel, Turgay] Univ Edinburgh, IPAB, Sch Informat, Edinburgh EH9 3JZ, Midlothian, Scotland	Temel, T (reprint author), Univ Edinburgh, IPAB, Sch Informat, Kings Bldg, Edinburgh EH9 3JZ, Midlothian, Scotland.						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demspter A. P., 1977, J ROYAL STAT SOC B, V39, P1; Kuc R, 2001, J ACOUST SOC AM, V110, P2198, DOI 10.1121/1.1401741; Kuc R, 1997, IEEE J OCEANIC ENG, V22, P616, DOI 10.1109/48.650828; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; McKerrow P, 2001, IEEE SENS J, V1, P245, DOI 10.1109/7361.983464; MULLER R, 2000, P ICSC S INT SYST AP, P915; Muller R, 2003, NETWORK-COMP NEURAL, V14, P595, DOI 10.1088/0954-898X/14/3/311; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Therrien Charles W., 1989, DECISION ESTIMATION	12	0	0	WORLD ACAD SCI, ENG & TECH-WASET	CANAKKALE	PO BOX 125, CANAKKALE, 17100, TURKEY	1307-6884		PROC WRLD ACAD SCI E			2005	1						140	143				4	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BII11	WOS:000259631100034	
B	Knight, B; Woon, FL		Bramer, M; Coenen, F; Allen, T		Knight, B; Woon, FL			Case based adaptation using interpolation over nominal values	RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XXI	BCS CONFERENCE SERIES		English	Proceedings Paper	24th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence (AI-2004)	DEC 12-15, 2004	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence			SCATTERED DATA; SETS	In this paper we propose a method for interpolation over a set of retrieved cases in the adaptation phase of the case-based reasoning cycle. The method has two advantages over traditional systems: the first is that it can predict "new" instances, not yet present in the case base; the second is that it can predict solutions not present in the retrieval set. The method is a generalisation of Shepard's Interpolation method, formulated as the minimisation of an error function defined in terms of distance metrics in the solution and problem spaces. We term the retrieval algorithm the Generalised Shepard Nearest Neighbour (GSNN) method. A novel aspect of GSNN is that it provides a general method for interpolation over nominal solution domains. The method is illustrated in the paper with reference to the Irises classification problem. It is evaluated with reference to a simulated nominal value test problem, and to a benchmark case base from the travel domain. The algorithm is shown to out-perform conventional nearest neighbour methods on these problems. Finally, GSNN is shown to improve in efficiency when used in conjunction with a diverse retrieval algorithm.	Univ Greenwich, CMS, London SE18 6PF, England	Knight, B (reprint author), Univ Greenwich, CMS, London SE18 6PF, England.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; FRANKE R, 1980, INT J NUMER METH ENG, V15, P1691, DOI 10.1002/nme.1620151110; KNIGHT B, 2003, P 18 INT JOINT C ART, P1347; Lazzaro D, 2002, J COMPUT APPL MATH, V140, P521, DOI 10.1016/S0377-0427(01)00485-X; LENZ M, 1996, P 3 EUR WORKSH CAS B, P219; Mitchell T, 1997, SERIES COMPUTER SCI; RAMOS GA, 2001, P IASTED INT C VISUA, P219; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; SMYTH B, 2003, P 18 INT JOINT C ART, P127; SMYTH B, 1998, P 4 EUR WORKSH CAS B, P208; Smyth B., 2001, P 4 INT C CAS BAS RE, P347; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	14	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES		1-85233-907-1	BCS CONFERENCE S			2005							73	86		10.1007/1-84628-102-4_6		14	Computer Science, Artificial Intelligence	Computer Science	BBP52	WOS:000226889800006	
S	Milner, GM		Carapezza, EM		Milner, GM			Detection/classification/quantification of chemical agents using an array of surface acoustic wave (SAW) devices	Sensors, and Command, Control, Communications, and Intelligence (C31) Technologies for Homeland Security and Homeland Defense IV, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Sensors, and Command, Control, Communications, and Intelligence (C31) Technologies for Homeland Security and Homeland Defense IV	MAR 28-APR 01, 2005	Orlando, FL			chemical warfare agent (CWA) detection / classification / quantification; toxic industrial chemicals (TICS); surface acoustic wave (SAW) arrays; signal processing		ChemSentry (TM) is a portable system used to detect, identify, and quantify chemical warfare (CW) agents. Electro chemical (EC) cell sensor technology is used for blood agents and an array of surface acoustic wave (SAW) sensors is used for nerve and blister agents. The combination of the EC cell and the SAW array provides sufficient sensor information to detect, classify and quantify all CW agents of concern using smaller, lighter, lower cost units. Initial development of the SAW array and processing was a key challenge for ChemSentry (TM) requiring several years of fundamental testing of polymers and coating methods to finalize the sensor array design in 2001. Following the finalization of the SAW array, nearly three (3) years of intensive testing in both laboratory and field environments were required in order to gather sufficient data to fully understand the response characteristics. Virtually unbounded permutations of agent characteristics and environmental characteristics must be considered in order to operate against all agents and all environments of interest to the U.S. military and other potential users of ChemSentry (TM). The resulting signal processing design matched to this extensive body of measured data (over 8,000 agent challenges and 10,000 hours of ambient data) is considered to be a significant advance in state-of-the-art for CW agent detection.	BAE Syst, Integrated Def Solut, Austin, TX 78725 USA	Milner, GM (reprint author), BAE Syst, Integrated Def Solut, 6500 Tracor Ln, Austin, TX 78725 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Farley J. U., 1975, J ECONOMETRICS, V3, P297, DOI 10.1016/0304-4076(75)90037-8	2	4	4	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5763-9	P SOC PHOTO-OPT INS			2005	5778		1-2				305	316		10.1117/12.611372		12	Engineering, Multidisciplinary	Engineering	BCR48	WOS:000230925700032	
S	Wojna, A		Peters, JF; Skowron, A		Wojna, A			Analogy-based reasoning in classifier construction	TRANSACTIONS ON ROUGH SETS IV	Lecture Notes in Computer Science		English	Article						analogy-based reasoning; case-based reasoning; k nearest neighbors; similarity measure; distance based indexing; hybrid decision system; local metric induction	NEAREST-NEIGHBOR CLASSIFICATION; COMBINING RULE INDUCTION; LEARNING ALGORITHMS; SCIENCE; SYSTEM; RIONA; TREES	Analogy-based reasoning methods in machine learning make it possible to reason about properties of objects on the basis of similarities between objects. A specific similarity based method is the k nearest neighbors (k-nn) classification algorithm. In the k-nn algorithm, a decision about a new object x is inferred on the basis of a fixed number k of the objects most similar to x in a given set of examples. The primary contribution of the dissertation is the introduction of two new classification models based on the k-nn algorithm. The first model is a hybrid combination of the k-nn algorithm with rule induction. The proposed combination uses minimal consistent rules defined by local reducts of a set of examples. To make this combination possible the model of minimal consistent rules is generalized to a metric-dependent form. An effective polynomial algorithm implementing the classification model based on minimal consistent rules has been proposed by Bazan. We modify this algorithm in such a way that after addition of the modified algorithm to the k-nn algorithm the increase of the computation time is inconsiderable. For some tested classification problems the combined model was significantly more accurate than the classical k-nn classification algorithm. For many real-life problems it is impossible to induce relevant global mathematical models from available sets of examples. The second model proposed in the dissertation is a method for dealing with such sets based on locally induced metrics. This method adapts the notion of similarity to the properties of a given test object. It makes it possible to select the correct decision in specific fragments of the space of objects. The method with local metrics improved significantly the classification accuracy of methods with global models in the hardest tested problems. The important issues of quality and efficiency of the k-nn based methods are a similarity measure and the performance time in searching for the most similar objects in a given set of examples, respectively. In this dissertation both issues are studied in detail and some significant improvements are proposed for the similarity measures and for the search methods found in the literature.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Wojna, A (reprint author), Warsaw Univ, Inst Informat, Banacha 2, PL-02097 Warsaw, Poland.	wojna@mimuw.edu.pl					Aggarwal C.C., 2001, P 8 INT C DAT THEOR, P420; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ajdukiewicz K., 1974, LOGIKA PRAGMATYCZNA; BAZAN JG, 1998, LNCS, V1424, P521; Bazan JG, 2004, LECT NOTES ARTIF INT, V3066, P592; Bazan J.G., 2001, LECT NOTES ARTIF INT, V2005, P106; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; Bellman R., 1957, DYNAMIC PROGRAMMING; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; BISHOP CM, 1996, NEURAL NETWORKSH PAT; Blake CL, 1998, UCI REPOSITORY MACHI; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; BRIN S., 1995, P 21 INT C VER LARG, P574; Burr Ridge I, 1997, MACHINE LEARNING; CHAVEZ E, TRDCC993 U CHILE; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2002, P 2 SIAM INT C DAT M; Domingos P, 1996, MACH LEARN, V24, P141; Duda R., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; Finkel R. A., 1974, Acta Informatica, V4, DOI 10.1007/BF00288933; FISHER RA, 1925, METRON, V5, P3; Fix E., 1951, 4 USAF SCH AV MED RA; FRIEDMAN J, 1997, 113 STANF U DEP STAT; Friedman J., 2001, ELEMENTS STAT LEARNI; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; Golding AR, 1996, ARTIF INTELL, V87, P215, DOI 10.1016/0004-3702(95)00120-4; Gora G, 2002, LECT NOTES ARTIF INT, V2475, P405; Gora G, 2002, FUND INFORM, V51, P369; Gora G, 2002, LECT NOTES ARTIF INT, V2430, P111; Gosset W.S., 1908, BIOMETRIKA, V6, P1; Grzymala-Busse J. W., 1992, HDB APPL ADV ROUGH S, P3; Guttman A., 1984, P ACM SIGMOD INT C M, P47; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Jensen FV, 1996, INTRO BAYESIAN NETWO; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; Kataymaand N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Kira K., 1992, P 9 INT C MACH LEARN; Kleinberg J, 2004, J ACM, V51, P263, DOI 10.1145/972639.972644; Klosgen W., 2002, HDB DATA MINING KNOW; Kononenko I., 1994, LECT NOTES ARTIF INT, V784, P171; Leake D.B., 1996, CASE BASED REASONING; LI J, 2003, IN PRESS MACHINE LEA; LI J, 2001, P 5 PAC AS C KNOWL D, P455; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Luce Duncan, 1957, GAMES DECISIONS; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; MICHALSKI RS, 1983, ARTIF INTELL, V20, P111, DOI 10.1016/0004-3702(83)90016-4; Morgenstern O., 1944, THEORY GAMES EC BEHA; NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Pawlak Z., 1991, ROUGH SETS THEORETIC; POLKOWSKI L, 1997, ROUGH SETS DATA MINI, P259; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Robinson John T., 1981, P ACM SIGMOD INT C M, P10; Rosenblueth Arturo, 1943, PHILOS SCI, V10, P18, DOI DOI 10.1086/286788; RUSSELL SJ, 1989, USE KNOWLEDGE ANALOG; SALZBERG S, 1991, MACH LEARN, V2, P229; Savaresi S., 2001, P 1 SIAM INT C DAT M, P1; SELLIS T, 1987, P 13 INT C VER LARG, P574; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Skowron A, 2004, LECT NOTES ARTIF INT, V3066, P229; Skowron A., 1992, INTELLIGENT DECISION, P331; Skowron A., 2003, ROUGH NEURAL COMPUTI, P43; Skowron A., ROUGH SET EXPLORATIO; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Vapnik V.N., 1998, STAT LEARNING THEORY; VELOSO M, 1994, PLANNING LEARNING AN; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1994, THESIS OREGON STATE; White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202; Wiener N., 1948, CYBERNETICS; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wojna A, 2003, FUND INFORM, V56, P285; WOJNA AG, 2003, P 3 IEEE INT C DAT M, P681; WOJNA AG, 2000, THESIS WARSAW U; WOLPERT D, 1989, NEURAL NETWORKS, V3, P445; Wroblewski J., 1998, LECT NOTES ARTIF INT, V1424, P402; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; ZAVREL J, 1997, P 7 BELG DUTCH C MAC, P139	96	19	19	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-29830-4	LECT NOTES COMPUT SC			2005	3700						277	374				98	Computer Science, Theory & Methods	Computer Science	BDN26	WOS:000234424800011	
S	Mignani, AG; Ciaccheri, L; Smith, PR; Cimato, A; Attilio, C; Huertas, R; Latorre, MM; Bertho, AC; O'Rourke, B; McMillan, ND		Voet, M; Willsch, R; Ecke, W; Jones, J; Culshaw, B		Mignani, AG; Ciaccheri, L; Smith, PR; Cimato, A; Attilio, C; Huertas, R; Latorre, MM; Bertho, AC; O'Rourke, B; McMillan, ND			Scattered colorimetry and multivariate data processing as an objective tool for liquid mapping	17th International Conference on Optical Fibre Sensors, Pts 1 and 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	17th International Conference on Optical Fibre Sensors	MAY 23-27, 2005	Brugge, BELGIUM	I D FOS Res, Fibre Opt Sensors & Sensing Syst, European Off Aerosp Res & Dev, USAF Res Lab, Network Excellence Micro Opt, SCK CEN, Belgian Nucl Res Ctr, FWO, FNRS, Export Flanders, Flanders Foreign Investment Off, ESF, European Opt Soc, Inst Phys, IEEE, SPIE, Inst Measurement & Control UK, IEEE LEOS, Opt Soc Amer, AMA German Sensor Technol Assoc, DGaO German Soc Appl Opt, OptecNet German Network Competence Opt Photon Technologies, Sensors Web Portal		liquid mapping; colorimetry; scattering; turbidity		Scattered colorimetry, i.e., multi-angle and multi-wavelength absorption spectroscopy performed in the visible spectral range, was used to map three kinds of liquids: extra virgin olive oils, frying oils, and detergents in water. By multivariate processing of the spectral data, the liquids could be classified according to their intrinisic characteristics: geographic area of extra virgin olive oils, degradation of frying oils, and surfactant types and mixtures in water.	CNR, IFAC, Dept Optoelect & Photon, I-50127 Florence, Italy	Mignani, AG (reprint author), CNR, IFAC, Dept Optoelect & Photon, Via Panciatichi 64, I-50127 Florence, Italy.						ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA	4	4	4	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5855-4	P SOC PHOTO-OPT INS			2005	5855		1-2				38	41		10.1117/12.623388		4	Instruments & Instrumentation; Optics	Instruments & Instrumentation; Optics	BCV71	WOS:000231443000009	
B	Madani, K; Chebira, A; Rybnik, M; Bouyoucef, EK			IEEE	Madani, Kurosh; Chebira, Abdennasser; Rybnik, Mariusz; Bouyoucef, El-Khier			Tree-like multiple neural network models generator with a complexity estimation based decomposer	2005 IEEE INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS	IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems-Technology and Applications-IDAACS		English	Proceedings Paper	3rd IEEE Intelligent Data Acquisition and Advanced Computing Systems	SEP 05-07, 2005	Sofia, BULGARIA	IEEE, Inst Comp Informat Technol, Ternopil Acad Natl Econ, Tech Univ Sofia, Fac Comp Syst & Control, Univ Sofia, Ternopil Acad Natl Econ, IEEE Instrumentat & Measurement Soc, Sci & Technol Ctr, IEEE Bulgaria Sect, IEEE Comp Chapter Bulgaria Sect		Artificial Neural Networks; complexity estimation; self-organization; intelligent decomposer; universal information processing	PATTERN-CLASSIFICATION; INFORMATION	In this article we present a self organizing hybrid modular approach that is aimed at reduction of processing task complexity by decomposition of an initially complex problem into a set of simpler sub-problems. This approach hybridizes Artificial Neural Networks based artificial intelligence and complexity estimation loops in order to reach a higher level intelligent processing capabilities. In consequence, our approach mixtures learning, complexity estimation and specialized data processing modules in order to achieve a higher level self-organizing modular intelligent information processing system. Experimental results validating the presented approach are reported and discussed.	Univ Paris 12, Senart Inst Technol, Signal & Intelligent Syst Lab, Intelligence Instrumentat & Syst Div I2S, F-77127 Lieusaint, France	Madani, K (reprint author), Univ Paris 12, Senart Inst Technol, Signal & Intelligent Syst Lab, Intelligence Instrumentat & Syst Div I2S, Av Pierre Point, F-77127 Lieusaint, France.	madani@univ-paris12.fr; chebira@univ-paris12.fr					Arbib M.A., 2003, HDB BRAIN THEORY NEU; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BRUSKE J, 1995, ADV NEURAL INFORMATI, V7, P497; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FISHER A, 2000, MATH THEORY PROBABIL; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Fukunaga K., 1990, INTRO STAT PATTERN R; GOONATILAKE S, INTELLIGENT HYBRID S, P1; HO TK, 2000, LECT NOTES COMPUTER; Ho TK, 1998, COMPUT VIS IMAGE UND, V70, P101, DOI 10.1006/cviu.1998.0624; JOLLIFEE IT, 1986, PRINCIPLE COMPONENT; Jordan MI, 1995, NEURAL NETWORKS, V8, P1409, DOI 10.1016/0893-6080(95)00014-3; Kohn AF, 1996, PATTERN RECOGN, V29, P873, DOI 10.1016/0031-3203(95)00122-0; Kohonen T., 1988, SELF ORG ASS MEMORY; Krogh A, 1995, ADV NEURAL INFORMATI, V7, P231; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; MADANI K, 2003, LNCS SERIES, P382; MADANI K, 2000, PKDD 2000; MADDOX J, 1990, NATURE, V344, P705; MATUSITA K, 1967, ANN I STAT MATH, V19, P181, DOI 10.1007/BF02911675; Murray-Smith R., 1997, MULTIPLE MODEL APPRO; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pierson W., 1998, THESIS OHIO STATE U; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; SANG KK, NEURAL INFORM PROCES, V7, P497; SINGH S, 2003, IEEE T PATTERN ANAL; Sridhar DV, 1999, NEURAL NETWORKS, V12, P915, DOI 10.1016/S0893-6080(99)00030-1; TAKESHITA T, 1987, T IEICE, P567	30	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		978-0-7803-9445-2	INT WORKSH INT DATA			2005							60	65		10.1109/IDAACS.2005.282942		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Instruments & Instrumentation	Computer Science; Instruments & Instrumentation	BFW78	WOS:000245169600013	
B	Li, YG; Huang, JJ; Zhang, WD; Zhang, XL			IEEE	Li, Yuangui; Huang, Jinjie; Zhang, Weidong; Zhang, Xiaolei			New prototype selection rule integrated condensing with editing process for the nearest neighbor rules	2005 IEEE International Conference on Industrial Technology - (ICIT), Vols 1 and 2			English	Proceedings Paper	IEEE International Conference on Industrial Technology (ICIT)	DEC 14-17, 2005	Hong Kong, PEOPLES R CHINA	IEEE			LEARNING ALGORITHMS; CLASSIFICATION; DESIGN	A new prototype selection method was proposed to reduce the training set for the nearest neighbor rule. The method aimed to integrate the advantage of editing and condensing method, and it only selects the points in class boundary into prototype set. It used information contained in internal points to 'clean' or edit overlapping and noise of training set, then condensing process which only keeps border points was used to obtain prototype set. Computational results show that it can obtain satisfactory performance and higher condensing rate than popular instance reduction algorithm.	Shanghai Jiao Tong Univ, Automat Dept, Shanghai 200030, Peoples R China	Li, YG (reprint author), Shanghai Jiao Tong Univ, Automat Dept, Shanghai 200030, Peoples R China.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Blake C.L., UCI REPOSITORY MACHI; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Dasarathy BV, 2000, PATTERN ANAL APPL, V3, P19, DOI 10.1007/s100440050003; Devijver P. A., 1982, PATTERN RECOGNITION; Domeniconi C., 2001, ADV NEURAL INFORM PR, V14, P665; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Nadler M, 1993, PATTERN RECOGNITION; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-9483-6				2005							1014	1018				5	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Engineering, Mechanical	Computer Science; Engineering	BEO65	WOS:000238482500177	
B	Zhang, Z; Xu, X; Huang, T			IEEE	Zhang, Z; Xu, X; Huang, T			Indecisive classifier	2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2			English	Proceedings Paper	IEEE International Conference on Multimedia and Expo (ICME)	JUL 06-08, 2005	Amsterdam, NETHERLANDS	IEEE				Nearest neighbor classification expects the class conditional probabilities to be locally constant. The assumption becomes invalid in high dimension due to the curse-of-dimensionality. Severe bias can be introduced under this condition when using nearest neighbor rule. We propose an adaptive nearest neighbor classification method "indecisive classifier" to minimize bias and variance by avoiding decision making in some hard-decision region. As a result, better classification performance can be expected in some scenario such as video based face recognition.	Univ Illinois, Urbana, IL 61801 USA	Zhang, Z (reprint author), Univ Illinois, Urbana, IL 61801 USA.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DJOUADI A, 1998, PAMI, V20; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1952, 11 USAF SCH AV MED; FUKUNAGA K, 1973, INFORM THEORY, V19; HASTIE T, 1996, PAMI, V18; HASTIE T, 2001, ELEMENTS STAT LEARNI, P427; PENG J, 2004, PAMI, V26; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-9331-7				2005							570	573				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BDO93	WOS:000234623800143	
B	Markowska-Kaczmar, U; Kubacki, P		Kwasnicka, H; Paprzycki, M		Markowska-Kaczmar, U; Kubacki, P			Support vector machines in handwritten digits classification	5th International Conference on Intelligent Systems Design and Applications, Proceedings			English	Proceedings Paper	5th International Conference on Intelligent Systems Design and Applications (ISDA 2005)	SEP 08-10, 2005	Wroclaw, POLAND	World Federat Soft Comp, European Soc Fuzzy Log & Technol, European Neural Network Soc, Warsaw Sch Social Psychol, Polish Minist Sci Res & Informat Technol				In the paper our approach to classify handwritten digits by using Support Vector Machines is described. Because of the unsatisfying, long time of training of SVM we propose to apply k-nearest neighbours algorithm with Manhattan distance to obtain reduced size of training set having a hope that this hybrid method does not make the significantly worse results of recognition, The aim of presented further experiments was to verify this assumption.	Wroclaw Tech Univ, Inst Appl Informat, PL-50370 Wroclaw, Poland	Markowska-Kaczmar, U (reprint author), Wroclaw Tech Univ, Inst Appl Informat, Wyb Wyspinanskiego 27, PL-50370 Wroclaw, Poland.						ABOUMOUSTAFA KT, 1967, PATTERN RECOGN, V5, P923; Cheong S., 2004, NEURAL INFORM PROCES, V2, P47; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESTEFANO C, 1994, P IEEE C MAN SYST CY, P759; LINLIN H, 2004, NEUROCOMPUTING, V5, P197; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3206(03)00085-2; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; RABINER L. R., 1990, READINGS SPEECH RECO, P267	8	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2286-6				2005							406	411		10.1109/ISDA.2005.87		6	Computer Science, Artificial Intelligence	Computer Science	BDE37	WOS:000233058700069	
B	Zhao, QF		Shih, TK; Shibata, Y		Zhao, QF			Design smart NNTrees based on the R-4-rule	AINA 2005: 19th International Conference on Advanced Information Networking and Applications, Vol 2			English	Proceedings Paper	19th International Conference on Advanced Information Networking and Applications	MAR 28-30, 2005	Taipei, TAIWAN	IEEE Comp Soc Tech Comm Distributed Proc, Tamkang Univ, Asian Off Aerosp Res & Dev, USA Asian Res Off			NEIGHBOR PATTERN-CLASSIFICATION; DECISION TREES; ALGORITHM; MLP	Neural network tree (NNTree) is a hybrid learning model with the overall structure being a decision tree (DT), and each non-terminal node containing an expert neural network (ENN). Generally speaking, NNTrees outperform conventional DTs because more complex and possibly better features can be extracted by the ENNs. So far we have studied several genetic algorithms (GAs) for designing the NNTrees. These algorithms are computationally expensive, and the NNTrees obtained are often very large. In this paper, we propose a new approach based on the R-4-rule, which is a non-genetic evolutionary algorithm proposed by the author several years ago. The key point is to propose a heuristic method for defining the teacher signals for the examples assigned to a non-terminal node. Once the teacher signals are defined, the ENNs can be trained quickly using the R-4-rule. Experiments with several public databases show that the new approach can produce smart NNTrees quickly and effectively.	Univ Aizu, Aizu Wakamatsu 9658580, Japan	Zhao, QF (reprint author), Univ Aizu, Aizu Wakamatsu 9658580, Japan.						Brieman L, 1984, CLASSIFICATION REGRE; Carpenter G. A., 1988, IEEE COMPUT, V21, P77; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P163, DOI 10.1109/34.67645; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; GUO H, 1992, IEEE T NEURAL NETWOR, V3, P923, DOI 10.1109/72.165594; HENRICHO.EG, 1969, IEEE T COMPUT, VC 18, P614, DOI 10.1109/T-C.1969.222728; Hyafil L., 1976, Information Processing Letters, V5, DOI 10.1016/0020-0190(76)90095-8; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Lu C, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P518; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MIZUNO S, 2002, P 4 AS PAC C SIM EV, P573; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; SETHI IK, 1990, P IEEE, V78, P1605, DOI 10.1109/5.58346; TAKEDA T, 2003, P INNS IEEE INT JOIN; TAKEDA T, 2003, INT C HYBR INT SYST; Zhao QF, 1997, IEEE T NEURAL NETWOR, V8, P1371, DOI 10.1109/72.641460; ZHAO QF, 2000, NC200057 IEICE; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762; Zhao QF, 2001, IEEE C EVOL COMPUTAT, P240; ZHAO QF, 2004, P IEEE INT C SYST MA	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2249-1				2005							547	551				5	Computer Science, Information Systems; Telecommunications	Computer Science; Telecommunications	BCH23	WOS:000229285400119	
B	de Castro, PAD; Santoro, DM; Camargo, HA; Nicoletti, MC		Ishikawa, M; Hashimoto, S; Paprzycki, M; Barakova, E; Yoshida, K; Koppen, M; Corne, DW; Abraham, A		de Castro, PAD; Santoro, DM; Camargo, HA; Nicoletti, MC			Improving a Pittsburgh learnt fuzzy rule base using feature subset selection	HIS'04: Fourth International Conference on Hybrid Intelligent Systems, Proceedings			English	Proceedings Paper	4th International Conference on Hybrid Intelligent Systems (HIS 04)	DEC 05-08, 2004	Kitakyushu, JAPAN	IEEE Comp Soc, Computat Intelligence Soc, IEEE, Syst Man, & Cybernet Soc, BMFSA, SOFT, Int Fuzzy Syst Assoc, City Kitakyushu, World Federat Soft Comp		feature subset selection; Pittsburgh approach; fuzzy rule bases; C-Focus; Relief-E; wrapper methods; hybrid systems	CLASSIFICATION	This paper investigates the problem of feature subset selection as a pre-processing step to a method which learns fuzzy rule bases using genetic algorithm (GA) implementing the Pittsburgh approach. Four feature subset selection methods are investigated in the context of learning fuzzy rule bases. Two of them are filter methods namely, the Relief-E and the C-Focus. The other two are wrapper methods using GA as their search process; one implements the instance-based method 1-NN and the other, the constructive neural network algorithm DistAl. Results of the experiments conducted in three domains are presented and discussed; they show that methods which learn fuzzy rule bases can benefit from feature subset selection methods.	DC UFSCar, BR-13565905 Sao Carlos, SP, Brazil	de Castro, PAD (reprint author), DC UFSCar, BR-13565905 Sao Carlos, SP, Brazil.						ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ARAUZO A, 2003, P 7 ONL WORLD C SOFT, P225; Bezdek J., 1981, PATTERN RECOGNITION; BLUM A, 1997, ARTIF INTELL, V10, P245; Cordon O., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.943725; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M., 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kira K., 1992, P 10 NAT C ART INT, P129; Kononenko I, 1994, P EUR C MACH LEARN, P171; Langley P., 1994, P AAAI FALL S REL NE; Merz C.J., 1998, UCI REPOSITORY MACHI; Smith S. F., 1980, THESIS U PITTSBURGH; Yang J., 1999, INTELLIGENT DATA ANA, V3, P53; YANG J, 1998, FEATURE EXTRACTION C, pCH8; Yuan YF, 1996, FUZZY SET SYST, V84, P1, DOI 10.1016/0165-0114(95)00302-9	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2291-2				2005							180	185				6	Computer Science, Artificial Intelligence	Computer Science	BBW91	WOS:000228181100029	
B	Ishii, N; Tsuchiya, E; Bao, YG; Yamaguchi, N		Lee, R; Lee, KW; Malloy, B		Ishii, N; Tsuchiya, E; Bao, YG; Yamaguchi, N			Combining classification improvements by ensemble processing	Third ACIS International Conference on Software Engineering Research, Managment and Applications, Proceedings			English	Proceedings Paper	3rd International Conference on Software Engineering Research, Management and Applications	AUG 11-13, 2005	Mt Pleasant, MI		Cent Michigan Univ	data mining; artificial intelligence; knowledge discovery		The k-nearest neighbor (KNN) classification is a simple and effective classification approach. However improving performance of the classifier is still attractive. Combining multiple classifiers is an effective technique for improving accuracy. There are many general combining algorithms, such as Bagging, Boosting, or Error Correcting Output Coding that significantly improve the classifier such as decision trees, rule learners, or neural networks. Unfortunately, these combining methods developed do not improve the nearest neighbor classifiers. In this paper first, we present a new approach to combine multiple KNN classifiers based on different distance functions, in which we apply multiple distance functions to improve the performance of the k-nearest neighbor classifier Second, we develop a combining method, in which the weights of the distance function, are learnt by genetic algorithm. Finally, combining classifiers in error correcting output coding, are discussed The proposed algorithms seek to increase generalization accuracy when compared to the basic k-nearest neighbor algorithm. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that the proposed algorithms improve the performance of the k-nearest neighbor classification.								BAO Y, 2002, P 5 INT C DISC SCI, P361; Bao YG, 2002, LECT NOTES COMPUT SC, V2412, P461; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ITQON S, 2000, J IECI, V2, P23; Merz C.J., 1998, UCI REPOSITORY MACHI; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tapia R. A., 1978, NONPARAMETRIC PROBAB; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YAMAGUCHI Y, 2004, SYSTEMS COMPUTERS JA, V35, P9	12	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2297-1				2005							240	246				7	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BCX73	WOS:000231789000031	
B	Mujica-V, VE; Sisalem, D; Popescu-Zeletin, R		Skowron, A; Barthes, JP; Jain, L; Sun, R; MorizetMahoundeaux, P; Liu, J; Zhong, N		Mujica-V, VE; Sisalem, D; Popescu-Zeletin, R			Evolving biosciences in multi-agent systems	2005 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, Proceedings			English	Proceedings Paper	International Conference on Intelligent Agent Technology	SEP 19-22, 2005	Compiegne, FRANCE	IEEE Comp Soc, Web Intelligence Consortium, Assoc Comp Machinery	Compiegne Univ Technol		AD HOC NETWORKS	This paper proposes a strong research interest in afield related to bioinformatics and computational biology in a Multi-Agent System (MAS). We promote the use of evolutionary computation within intelligent Multi-Agent Systems taking particularly the enhancement of the NEUron Routing ALgorithm (NEURAL) in Mobile Ad Hoc Network (AMNET). More precisely, we develop an intelligent mobile agent called the NEURAL Agent which significantly improves the performance of NEURAL. Results demonstrated that the NEURAL Agent leads to significant benefits in the average end-to-end delay and the packet delivery ratio of the routing protocol.	Fraunhofer FOKUS Inst, Berlin, Germany	Mujica-V, VE (reprint author), Fraunhofer FOKUS Inst, Berlin, Germany.						BERKELEY U, 1998, NETWORK SIMULATOR; BROCH J, 1998, 4 ANN ACM IEEE INT C, P85; Costa-Requena J, 2004, WIREL NETW, V10, P367, DOI 10.1023/B:WINE.0000028541.95473.79; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hass Z. J., 2001, IEEE ACM T NETWORK, V9, P427; Kohonen T, 2001, SELF ORG MAPS; MUJICA VVE, 2005, P 3 INT S MOD OPT MO; Perkins CE, 2001, IEEE PERS COMMUN, V8, P16, DOI 10.1109/98.904895; REHABI Y, 2005, P 10 IEEE S COMP COM; Sycara KP, 1998, AI MAG, V19, P79	10	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2416-8				2005							148	151				4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BDI55	WOS:000233623100026	
J	Wang, H; Bell, D				Wang, H; Bell, D			Extended k-nearest neighbours based on evidence theory	COMPUTER JOURNAL			English	Article							TRANSFERABLE BELIEF MODEL; DEMPSTER-SHAFER THEORY; CLASSIFICATION RULE; PATTERN-RECOGNITION; APPROXIMATION; CLASSIFIERS; COMBINATION	An evidence theoretic classification method is proposed in this paper. In order to classify a pattern we consider its neighbours, which are taken as parts of a single source of evidence to support the class membership of the pattern. A single mass function or basic belief assignment is then derived, and the belief function and the pignistic ('betting rates') probability function can be calculated. Then the (posterior) conditional pignistic probability function is calculated and used to decide the class label for the pattern. It is shown that such a classifier extends the standard majority voting based k-nearest neighbour classifier, and it is an approximation to the optimal Bayes classifier. In experiments this classifier performed as well as or better than the voting and distance weighted k-nearest neighbours classifiers with best k, and its performance became stable when the number of neighbours considered was >4.	Univ Ulster, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland; Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Wang, H (reprint author), Univ Ulster, Sch Comp & Math, Coleraine BT52 1SA, Londonderry, North Ireland.	h.wang@ulster.ac.uk; da.bell@qub.ac.uk					BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bauer M, 1997, INT J APPROX REASON, V17, P217, DOI 10.1016/S0888-613X(97)00013-3; BENNETT P, 2003, IN PRESS INFORMATION; Bennett P. N., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Buxton BF, 2001, MEAS CONTROL-UK, V34, P229; Chang C., 2004, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; Denoeux T, 2001, INT J UNCERTAIN FUZZ, V9, P437, DOI 10.1016/S0218-4885(01)00088-0; Denoeux T, 2002, INT J APPROX REASON, V31, P77, DOI 10.1016/S0888-613X(02)00073-7; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1951, DISCRIMINARY ANAL NO; Hand D.J., 2001, PRINCIPLES DATA MINI; HARMANEC D, 1999, UNCERTAINTY ARTIFICI, V15, P271; Hull D.A., 1996, P 19 ANN INT ACM SIG, P279, DOI 10.1145/243199.243275; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KITTLER J, 2000, LNCS, V1857; KITTLER J, 2001, LNCS, V2096; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; LAM W, 2001, P 24 ANN INT ACM SIG, P303, DOI 10.1145/383952.384011; Larkey L. S., 1996, P SIGIR 96 19 ACM IN, P289, DOI 10.1145/243199.243276; Li YH, 1998, COMPUT J, V41, P537, DOI 10.1093/comjnl/41.8.537; LOWRANCE JD, 1986, P AAAI 86 PHIL AUG, V2, P896; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; PIATETSKYSHAPIR.G, 2003, POLL WHAT DATA MININ; Shafer G., 1976, MATH THEORY EVIDENCE; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Smets P., 1998, HDB DEFEASIBLE REASO, V1, P267; SMETS P, 1990, IEEE T PATTERN ANAL, V12, P447, DOI 10.1109/34.55104; TESSEM B, 1993, ARTIF INTELL, V61, P315, DOI 10.1016/0004-3702(93)90072-J; Wilson N, 2000, HANDBOOK OF DEFEASIBLE REASONING AND UNCERTAINTY MANAGEMENT SYSTEMS, VOL 5, P421; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yang Y., 2000, P 17 INT C MACH LEAR, P1167; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	36	3	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0010-4620		COMPUT J	Comput. J.	NOV	2004	47	6					662	672		10.1093/comjnl/47.6.662		11	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	865LE	WOS:000224703800004	
J	Hansen, ME; Carstensen, JM				Hansen, ME; Carstensen, JM			Density-based retrieval from high-similarity image databases	PATTERN RECOGNITION			English	Article						density based; identification; density estimation; image retrieval	COLOR	Many image classification problems can fruitfully be thought of as image retrieval in a "high similarity image database" (HSID) characterized by being tuned towards a specific application and having a high degree of visual similarity between entries that should be distinguished. We introduce a method for HSID retrieval using a similarity measure based on a linear combination of Jeffreys-Matusita distances between distributions of local (pixelwise) features estimated from a set of automatically and consistently defined image regions. The weight coefficients are estimated based on optimal retrieval performance. Experimental results on the difficult task of visually identifying clones of fungal colonies grown in a petri dish and categorization of pelts show a high retrieval accuracy of the method when combined with standardized sample preparation and image acquisition. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Tech Univ Denmark, DK-2800 Lyngby, Denmark	Hansen, ME (reprint author), Tech Univ Denmark, Bldg 321, DK-2800 Lyngby, Denmark.	meh@imm.dtu.dk	Hansen, Michael/C-9028-2011	Hansen, Michael/0000-0001-7879-2106			ANDROUTSOS D, 1998, DISTANCE MEASURES CO; Bishop C. M., 1995, NEURAL NETWORKS PATT; CARSON C, 1997, CVPR97 WORKSH CONT B; CINQUE L, 1999, COLOR BASED IMAGE RE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450; Dorge T, 2000, J MICROBIOL METH, V41, P121, DOI 10.1016/S0167-7012(00)00142-1; FUKANAGA K, 1990, INTRO PATTERN RECOGN; Hastie T., 2002, ELEMENTS STAT LEARNI; IZENMAN AJ, 1991, J AM STAT ASSOC, V86, P205, DOI 10.2307/2289732; Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3; Kankanhalli MS, 1999, PATTERN RECOGN LETT, V20, P109, DOI 10.1016/S0167-8655(98)00100-7; Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753; Pitt J.I., 1979, GENUS PENICILLIUM IT; Raper K.B., 1949, MANUAL PENICILLIA; Ripley B. D., 1996, PATTERN RECOGNITION; Roussopoulos N, 1995, P ACM SIGMOD INT C M, P71, DOI DOI 10.1145/223784.223794; Sonka M., 1994, IMAGE PROCESSING ANA	18	10	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	NOV	2004	37	11					2155	2164		10.1016/j.patcog.2004.02.018		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	848XI	WOS:000223501000005	
J	Linnell, TA; Deravi, F				Linnell, TA; Deravi, F			Mapping vector accumulator: fractal domain feature for character recognition	ELECTRONICS LETTERS			English	Article								A new feature is presented which is calculated directly from the fractal-compressed form of images. The performance of this feature is analysed by using it in the training of standard classifiers for a character recognition problem. The feature is shown to be translation invariant, giving it an advantage over methods that use pixels or compressed data directly.	Univ Kent, Dept Elect, Canterbury, Kent, England	Linnell, TA (reprint author), Univ Kent, Dept Elect, Canterbury, Kent, England.	tristan.linnell@iee.org	Deravi, Farzin/E-7190-2013	Deravi, Farzin/0000-0003-0885-437X			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher Y, 1994, FRACTAL IMAGE COMPRE; Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028; Parzen E., 1962, ANN MATH STAT, V33, P1064	4	4	4	IEE-INST ELEC ENG	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	0013-5194		ELECTRON LETT	Electron. Lett.	OCT 28	2004	40	22					1406	1407		10.1049/el:20046478		2	Engineering, Electrical & Electronic	Engineering	871CL	WOS:000225106800014	
J	Liu, D				Liu, D			A strong lower bound for approximate nearest neighbor searching	INFORMATION PROCESSING LETTERS			English	Article						computational geometry; approximate nearest neighbor searching; lower bound	HIGH-DIMENSIONAL SPACES; ALGORITHM	We prove a lower bound of d(1-o(1)) on the query time for any deterministic algorithms that solve approximate nearest neighbor searching in Yao's cell probe model. Our result greatly improves the best previous lower bound for this problem, which is Omega (loglogd/logloglogd) [A. Chakrabarti et al., in: Proc. 31 st Ann. ACM S ymp. Theory of Computing, 1999, pp. 305-311]. Our proof is also much simpler than the proof of A. Chakrabarti et al. (C) 2004 Elsevier B.V All rights reserved.	Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA	Liu, D (reprint author), Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA.	dingliu@cs.princeton.edu					Agarwal P. K., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/129712.129763; ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Barkol O., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335350; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Chakrabarti A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301325; CHAKRABARTI A, 2002, THESIS PRINCETON U; Chan T. M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, DOI 10.1145/262839.263001; Chazelle B., 2000, DISCREPANCY METHOD R; Clarkson K. L., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, DOI 10.1145/177424.177609; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1982, HDB STAT, V2; Dobkin D., 1976, SIAM Journal on Computing, V5, DOI 10.1137/0205015; Edelsbrunner H., 1987, ALGORITHMS COMBINATO; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; Flickner M., 1995, IEEE COMPUT, V28, P23; Harper L.H., 1966, J COMBINATORIAL THEO, V1, P385, DOI 10.1016/S0021-9800(66)80059-5; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Miltersen PB, 1998, J COMPUT SYST SCI, V57, P37, DOI 10.1006/jcss.1998.1577; Yao A.C., 1985, P 17 ANN ACM S THEOR, P163, DOI 10.1145/22145.22163; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274	27	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0020-0190		INFORM PROCESS LETT	Inf. Process. Lett.	OCT 16	2004	92	1					23	29		10.1016/j.ipl.2004.06.001		7	Computer Science, Information Systems	Computer Science	853PH	WOS:000223839000004	
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Predicting 22 protein localizations in budding yeast	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						gene ontology; functional domain composition; pseudo-amino acid composition; GO-FunD-PseAA predictor; InterPro database; hybrid space; nearest neighbor algorithm	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; GENE ONTOLOGY; SITES; CLASSIFICATION; SEQUENCE	According to the recent experiments, proteins in budding yeast can be distinctly classified into 22 subcellular locations. Of these proteins, some bear the multi-locational feature, i.e., occur in more than one location. However, so far all the existing methods in predicting protein subcellular location were developed to deal with only the mono-locational case where a query protein is assumed to belong to one, and only one, subcellular location. To stimulate the development of subcellular location prediction, an augmentation procedure is formulated that will enable the existing methods to tackle the multi-locational problem as well. It has been observed thru a jackknife cross-validation test that the success rate obtained by the augmented GO-FnD-PseAA algorithm [BBRC 320 (2004) 1236] is overwhelmingly higher than those by the other augmented methods. It is anticipated that the augmented GO-FunD-PseAA predictor will become a very useful tool in predicting protein subcellular localization for both basic research and practical application. (C) 2004 Elsevier Inc. All rights reserved.	Univ Manchester, Dept Biomol Sci, Manchester M60 1QD, Lancs, England; Gordon Life Sci Inst, San Diego, CA 92130 USA; TIBDD, Tianjin, Peoples R China	Cai, YD (reprint author), Univ Manchester, Dept Biomol Sci, POB 88, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072.abs; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2004, J CELL BIOCHEM, V91, P1085, DOI 10.1002/jcb.20083; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou P. Y., 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huh WK, 2003, NATURE, V425, P686, DOI 10.1038/nature02026; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	31	39	42	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X		BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	OCT 15	2004	323	2					425	428		10.1016/j.bbrc.2004.08.113		4	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	856WS	WOS:000224076900010	
J	Shi, HL; Paolucci, U; Vigneau-Callahan, KE; Milbury, PE; Matson, WR; Kristal, BS				Shi, HL; Paolucci, U; Vigneau-Callahan, KE; Milbury, PE; Matson, WR; Kristal, BS			Development of biomarkers based on diet-dependent metabolic serotypes: Practical issues in development of expert system-based classification models in metabolomic studies	OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY			English	Article							FEMALE; RATS	Dietary restriction (DR)-induced changes in the serum metabolome may be biomarkers for physiological status (e.g., relative risk of developing age-related diseases such as cancer). Megavariate analysis (unsupervised hierarchical cluster analysis [HCA]; principal components analysis [PCA]) of serum metabolites reproducibly distinguish DR from ad libitum fed rats. Component-based approaches (i.e., PCA) consistently perform as well as or better than distance-based metrics (i.e., HCA). We therefore tested the following: (A) Do identified subsets of serum metabolites contain sufficient information to construct mathematical models of class membership (i.e., expert systems)? (B) Do component-based metrics out-perform distance-based metrics? Testing was conducted using KNN (k-nearest neighbors, supervised HCA) and SIMCA (soft independent modeling of class analogy, supervised PCA). Models were built with single cohorts, combined cohorts or mixed samples from previously studied cohorts as training sets. Both algorithms over-fit models based on single cohort training sets. KNN models had >85% accuracy within training/test sets, but were unstable (i.e., values of k could not be accurately set in advance). SIMCA models had 100% accuracy within all training sets, 89% accuracy in test sets, did not appear to over-fit mixed cohort training sets, and did not require post-hoc modeling adjustments. These data indicate that (i) previously defined metabolites are robust enough to construct classification models (expert systems) with SIMCA that can predict unknowns by dietary category; (ii) component-based analyses outperformed distance-based metrics; (iii) use of over-fitting controls is essential; and (iv) subtle inter-cohort variability may be a critical issue for high data density biomarker studies that lack state markers.	Cornell Univ, Coll Med, Burke Med Res Inst, Dementia Res Serv, White Plains, NY 10605 USA; ESA Inc, Chelmsford, MA USA; Tufts Univ, USDA, Human Nutr Res Ctr Aging, Antioxidants Res Lab, Boston, MA 02111 USA; Cornell Univ, Coll Med, Dept Biochem & Neurosci, White Plains, NY 10605 USA	Kristal, BS (reprint author), Cornell Univ, Coll Med, Burke Med Res Inst, Dementia Res Serv, 785 Mamaroneck Ave, White Plains, NY 10605 USA.	Bkristal@burke.org					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kristal BS, 1994, MODULATION AGING PRO, P1; MATSON WR, 1984, CLIN CHEM, V30, P1477; McCay CM, 1935, J NUTR, V10, P63; MILBURY PE, 1997, COULOMETRIC ARRAY DE, P125; Paolucci U, 2004, OMICS, V8, P209, DOI 10.1089/omi.2004.8.209; Paolucci U, 2004, OMICS, V8, P221, DOI 10.1089/omi.2004.8.221; Shi HL, 2002, J NUTR, V132, P1039; Shi HL, 2002, J NUTR, V132, P1031; VIGNEAUCALLAHAN KE, 2001, J NUTR, pS924; WEINDRUCH R, 1988, RETARDATION AGING DI; Willett WC, 1999, NEW ENGL J MED, V341, P427, DOI 10.1056/NEJM199908053410607; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5	13	18	22	MARY ANN LIEBERT INC	LARCHMONT	2 MADISON AVENUE, LARCHMONT, NY 10538 USA	1536-2310		OMICS	OMICS	FAL	2004	8	3					197	208		10.1089/omi.2004.8.197		12	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	867IQ	WOS:000224836700003	
J	Pan, F; Wang, BY; Hu, X; Perrizo, W				Pan, F; Wang, BY; Hu, X; Perrizo, W			Comprehensive vertical sample-based KNN/LSVM classification for gene expression analysis	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						data mining; k-nearest neighbor; support vector machine; feature selection; P-tree; gene expression; machine learning	CONSISTENCY; PREDICTION; ALGORITHMS; CANCER	Classification analysis of microarray gene expression data has been widely used to uncover biological features and to distinguish closely related cell types that often appear in the diagnosis of cancer. However, the number of dimensions of gene expression data is often very high, e.g., in the hundreds or thousands. Accurate and efficient classification of such high-dimensional data remains a contemporary challenge. In this paper, we propose a comprehensive vertical sample-based KNN/LSVM classification approach with weights optimized by genetic algorithms for high-dimensional data. Experiments on common gene expression datasets demonstrated that our approach can achieve high accuracy and efficiency at the same time. The improvement of speed is mainly related to the vertical data representation, P-tree,(1) and its optimized logical algebra. The high accuracy is due to the combination of a KNN majority voting approach and a local support vector machine approach that makes optimal decisions at the local level. As a result, our approach could be a powerful tool for high-dimensional gene expression data analysis. (C) 2004 Elsevier Inc. All rights reserved.	N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA; Rockefeller Univ, Lab Struct Microbiol, New York, NY 10021 USA	Pan, F (reprint author), N Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA.	fei.pan@ndsu.nodak.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burr Ridge I, 1997, MACHINE LEARNING; Cover T.M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; DING Q, 2002, ACM S APPL COMPUT, P11; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EISEN MB, 1995, P NATL ACAD SCI USA, P14863; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Goldberg D. E., 1991, FDN GENETIC ALGORITH, P69; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; MANGASARIAN OL, 1999, 9903 U WISC COMP SCI; MOORE DS, 1977, ANN STAT, V5, P143, DOI 10.1214/aos/1176343747; Ooi CH, 2003, BIOINFORMATICS, V19, P37, DOI 10.1093/bioinformatics/19.1.37; PERERA A, 2003, SIGKDD EXPLOR, V4, P108; PERRIZO W, 2001, NDSUCSORTR011; Vapnik V.N., 1995, NATURE STAT LEARNING; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698; Yang YH, 2002, NUCLEIC ACIDS RES, V30, DOI 10.1093/nar/30.4.e15	22	10	10	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464		J BIOMED INFORM	J. Biomed. Inform.	AUG	2004	37	4					240	248		10.1016/j.jbi.2004.07.003		9	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	863VZ	WOS:000224592800003	
J	Li, JY; Ong, HL				Li, JY; Ong, HL			Feature space transformation for better understanding biological and medical classifications	JOURNAL OF RESEARCH AND PRACTICE IN INFORMATION TECHNOLOGY			English	Article							ACUTE LYMPHOBLASTIC-LEUKEMIA; GENE-EXPRESSION PROFILES; PATTERNS; CANCER	Recently published gene expression profiles and proteomic mass/charge ratios are extremely high-dimensional data. Though support vector machines can well learn the inner relationship of the data for classification, the non-linear kernel functions pose an obstacle to explain the prediction reasons to non-specialists. In this paper, we study the problem of feature space transformation for easy interpretability of classification results. Each new feature is a combination of multiple original features provided that the new feature captures a large percentage of one class of data, but sharply discriminates the data in the other class. Under the description of new features, training or test data are clearly class-separable. We also discuss a more sophisticated rule-based method, called PCL, for classification. PCL provides easily explainable classification scores for us to better understand the predictions and the test data themselves. Visualization is also used to enhance the understanding of the classifier output. We use rich examples to demonstrate our main points.	Inst Infocomm Res, Singapore 119613, Singapore	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; hweeleng@i2r.a-star.edu.sg					Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1999, P 5 ACM SIGKDD INT C, P3; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Li J, 2002, SER INF MANAGE SCI, V1, P325; LI J, 2000, P 17 INT C MACH LEAR, P551; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	12	0	0	AUSTRALIAN COMPUTER SOC INC	SYDNEY	PO BOX Q534, QVB POST OFFICE, SYDNEY, NSW 1230, AUSTRALIA	1443-458X		J RES PRACT INF TECH	J. Res. Pract. Inf. Technol.	AUG	2004	36	3					131	144				14	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	849UB	WOS:000223565300002	
J	Mountrakis, G; Stefanidis, A; Schlaisich, I; Agouris, P				Mountrakis, G; Stefanidis, A; Schlaisich, I; Agouris, P			Supporting quality-based image retrieval through user preference learning	PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING			English	Article							UNCERTAINTY; SIMILARITY; ALGORITHM; ERROR	It is common for modem geospotial libraries to contain multiple datasets that cover the same area but differ only in some specific quality attributes (e.g., resolution and precision). This is affecting the concept of content-based geospatial queries, as simple coverage-based query mechanisms (e.g., declaring a specific area of interest) as well as theme-based query mechanisms (e.g., requesting a black and white aerial photo or multispectral satellite imagery) are rendered inadequate to identify and access specific datasets in such collections. In this paper we introduce a novel approach to handle data quality attributes in geospatial queries. Our approach is characterized by the ability to model and learn user preferences, thus establishing user profiles that allow us to customize image queries for improving their functionality in a constantly diversifying geospatial user community.	Univ Maine, Dept Spatial Informat Sci & Engn, Orono, ME 04469 USA; Univ Maine, Natl Ctr Geog Informat & Anal, Orono, ME 04469 USA	Mountrakis, G (reprint author), Univ Maine, Dept Spatial Informat Sci & Engn, 348 Boardman Hall, Orono, ME 04469 USA.	giorgos@spatial.maine.edu; tony@spatial.maine.edu; isolde@spatial.maine.edu; peggy@spatial.maine.edu					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bastin L, 2002, COMPUT GEOSCI-UK, V28, P337, DOI 10.1016/S0098-3004(01)00051-6; BEARD MK, 1997, GEOGRAPHIC INFORMATI, P280; BENNETT DA, 1996, CARTOGR GEOGR INF SC, V23, P3, DOI 10.1559/152304096782512177; Buttenfield B., 1993, CARTOGRAPHICA, V30, P1, DOI 10.3138/232H-6766-3723-5114; BUTTENFIELD BP, 1991, AUT 10 AM C SURV MAP, P423; BUTTENFIELD B, 1994, VISUALIZATION IN GEOGRAPHICAL INFORMATION SYSTEMS, P150; CAMPBELL G, 1994, FIG C MELB AUSTR, V20; Carkacioglu A, 2002, IEEE IMAGE PROC, P405; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis TJ, 1997, COMPUT GEOSCI, V23, P397, DOI 10.1016/S0098-3004(97)00012-5; Doucette P, 2001, ISPRS J PHOTOGRAMM, V55, P347, DOI 10.1016/S0924-2716(01)00027-2; Duckham M., 2000, Spatial Cognition and Computation, V2, DOI 10.1023/A:1015527221658; Evans BJ, 1997, COMPUT GEOSCI, V23, P409, DOI 10.1016/S0098-3004(97)00011-3; FEGEAS RG, 1992, CARTOGR GEOGR INFORM, V19, P278, DOI 10.1559/152304092783762209; Fisher P. F., 1999, GEOGRAPHICAL INFORMA, V1, P191; GOODCHILD MF, 1999, INT S SPAT DAT QUAL, P1; HUNTER GJ, 1995, PHOTOGRAMM ENG REM S, V61, P529; Lim JH, 2001, IEEE T KNOWL DATA EN, V13, P846; Ma WY, 1998, J AM SOC INFORM SCI, V49, P633, DOI 10.1002/(SICI)1097-4571(1998)49:7<633::AID-ASI5>3.3.CO;2-R; MacEachren A., 1992, CARTOGRAPHIC PERSPEC, V13, P10; Mandl T, 2000, NEURAL COMPUT APPL, V9, P280, DOI 10.1007/s005210070005; MCGRANAGHAN M, 1993, CARTOGRAPHICA, V30, P8, DOI 10.3138/310V-0067-7570-6566; MITAIM S, 1997, 4 INT FOR RES TECHN, P25; Mountrakis G, 2003, LECT NOTES COMPUT SC, V2750, P412; Muller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5; Paradis J., 1994, URISA Journal, V6; Unwin DJ, 1995, PROG HUM GEOG, V19, P549, DOI 10.1177/030913259501900408; Veregin H., 1999, GEOGRAPHICAL INFORMA, V1, P177; Walker P. A., 1988, International Journal of Geographical Information Systems, V2, DOI 10.1080/02693798808927909; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; *NIST, 1992, FED INF PROC STAND	33	0	0	AMER SOC PHOTOGRAMMETRY	BETHESDA	5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA	0099-1112		PHOTOGRAMM ENG REM S	Photogramm. Eng. Remote Sens.	AUG	2004	70	8					973	981				9	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	843JH	WOS:000223074300011	
J	Sboner, A; Bauer, P; Zumiani, G; Eccher, C; Blanzieri, E; Forti, S; Cristofolini, M				Sboner, A; Bauer, P; Zumiani, G; Eccher, C; Blanzieri, E; Forti, S; Cristofolini, M			Clinical validation of an automated system for supporting the early diagnosis of melanoma	SKIN RESEARCH AND TECHNOLOGY			English	Article						computer-aided diagnosis; decision support system; digital dermoscopy	PIGMENTED SKIN-LESIONS; ARTIFICIAL NEURAL-NETWORK; EPILUMINESCENCE MICROSCOPY; IMAGE-ANALYSIS; CUTANEOUS MELANOMA; PATTERN-ANALYSIS; CLASSIFICATION	Background: Early diagnosis and surgical excision is the most effective treatment of melanoma. Well-trained dermatologists reach a high level of diagnostic accuracy with good sensitivity and specificity. Their performances increase using some technical aids as digital epiluminescence microscopy. Several studies describe the development of computerized systems whose aim is supporting dermatologists in the early diagnosis of melanoma. In many cases, the performances of those systems were comparable to those of dermatologists. However, this cannot tell us whether a system is able to support dermatologists. Actually, the computerized system might correctly recognize the same lesions that the dermatologist does, without providing them any useful advice and therefore being useless in recognizing early malignant lesions. Purpose: We present a novel approach to enhance dermatologists' performances in the diagnosis of early melanoma. We provide results of our evaluation of a computerized system combined with dermatologists. Methods: A Multiple-Classifier system was developed on a set of 152 cases and combined to a group of eight dermatologists to support them by improving their sensitivity. Results: The eight dermatologists have average sensitivity and specificity values of 0.83 and 0.66, respectively. The Multiple-Classifier system performs as well as the eight dermatologists (sensitivity range: 0.75-0.86; specificity range: 0.64-0.89). The combination with the dermatologists shows an average improvement of 11% (P=0.022) of dermatologists' sensitivity. Conclusion: Our results suggest that an automated system can be effective in supporting dermatologists because it recognizes different malignant melanomas with respect to the dermatologists.	IRST, ITC, Ctr Sci & Technol Res, I-38050 Trent, Italy; Santa Chiara Hosp, Dept Dermatol, Trent, Italy; Lega Italiana Lotta Contro & Tumori, Sez Trentina, Trent, Italy	Sboner, A (reprint author), IRST, ITC, Ctr Sci & Technol Res, Via Somma 18, I-38050 Trent, Italy.	sboner@itc.it	Sboner, Andrea/C-6487-2008	Sboner, Andrea/0000-0001-6915-3070			BAUER P, 2000, MELANOMA RES, V10, P1; Binder M, 1998, MELANOMA RES, V8, P261, DOI 10.1097/00008390-199806000-00009; BINDER M, 1994, BRIT J DERMATOL, V130, P460, DOI 10.1111/j.1365-2133.1994.tb03378.x; Binder M, 2000, MELANOMA RES, V10, P556, DOI 10.1097/00008390-200012000-00007; BISHOF L, 1999, NEW APPROACHES MED I, V3474, P130; Breiman L, 1984, CLASSIFICATION REGRE; BRESLOW A, 1970, ANN SURG, V172, P902, DOI 10.1097/00000658-197011000-00017; CASCINELLI N, 1992, MELANOMA RES, V2, P167; CHAN PK, 1999, MACHINE LEARNING, V36; CLEMENTE CG, 1998, MELANOMA NEVI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristofolini M, 1997, SKIN RES TECHNOL, V3, P23, DOI 10.1111/j.1600-0846.1997.tb00155.x; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; Duda R.O., 2000, PATTERN CLASSIFICATI; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; Gonzales R. C., 2002, DIGITAL IMAGE PROCES; GREEN A, 1994, J AM ACAD DERMATOL, V31, P958; KOH HK, 1991, NEW ENGL J MED, V325, P171, DOI 10.1056/NEJM199107183250306; Lavrac N, 1999, ARTIF INTELL MED, V16, P3, DOI 10.1016/S0933-3657(98)00062-1; NACHBAR F, 1994, J AM ACAD DERMATOL, V30, P551; PEHAMBERGER H, 1987, J AM ACAD DERMATOL, V17, P571, DOI 10.1016/S0190-9622(87)70239-4; Pehamberger H, 1993, J INVEST DERMATOL, V100, P356; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rubegni P, 2002, SKIN RES TECHNOL, V8, P276, DOI 10.1034/j.1600-0846.2001.00350.x; SBONER A, 2001, TECHNOL HEALTHCARE, V9, P354; Sboner A, 2003, ARTIF INTELL MED, V27, P29, DOI 10.1016/S0933-3657(02)00087-8; Seidenari S, 1999, MELANOMA RES, V9, P163, DOI 10.1097/00008390-199904000-00009; SHINDENWOLF T, 1993, INT ACAD CYTOL ANAL, V15, P1; Stolz W, 1994, COLOR ATLAS DERMATOS; TAKIWAKI H, 1995, J AM ACAD DERMATOL, V32, P600, DOI 10.1016/0190-9622(95)90344-5; ZSOLT BA, 1997, DERMATOL CLIN, V15, P79	31	10	10	BLACKWELL MUNKSGAARD	COPENHAGEN	35 NORRE SOGADE, PO BOX 2148, DK-1016 COPENHAGEN, DENMARK	0909-752X		SKIN RES TECHNOL	Skin Res. Technol.	AUG	2004	10	3					184	192		10.1111/j.1600-0846.2004.00066.x		9	Dermatology	Dermatology	832RV	WOS:000222285600008	
J	Yin, TK; Chiu, NT				Yin, TK; Chiu, NT			A computer-aided diagnosis for distinguishing Tourette's syndrome from chronic tic disorder in children by a fuzzy system with a two-step minimization approach	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Article						AI approaches; biosignal interpretation and diagnostic systems; fuzzy systems; signal and image processing	PERFUSION; TECHNETIUM-99M-HMPAO; CHILDHOOD; SPECT	Tourette's syndrome, no longer considered as a rare and unusual disease, is the most severe tic disorder in children. Early differential diagnosis between Tourette's syndrome and chronic tic disorder is difficult but important because proper and early medical therapy can improve the child's condition. Brain single-photon emission computed tomography (SPECT) perfusion imaging with technetium-99m hexamethylpropylene amine oxime is a method to distinguish these two diseases. In this paper, a fuzzy system called characteristic-point-based fuzzy inference system (CPFIS) is proposed to help radiologists perform computer-aided diagnosis (CAD). The CPFIS consists of SPECT-volume processing, input-variables selection, characteristic-points (CPs) derivation, and parameter tuning of the fuzzy system. Experimental results showed that the major fuzzy rules from the obtained CPs match the major patterns of Tourette's syndrome and chronic tic disorder in perfusion imaging. If any case that was diagnosed as chronic tic by the radiologist but as Tourette's syndrome by the CPFIS was taken as Tourette's syndrome, then the accuracy of the radiologist was increased from 87.5% (21 of 24) without the CPFIS to 91.7% (22 of 24) With the CPFIS. All 17 cases of Tourette's syndrome, which is more severe than chronic tic disorder, were correctly classified. Although the construction and application process of the proposed method is complete, more samples should be used and tested in order to design a universally effective CAD without small sample-size concerns in this research.	Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan; Natl Cheng Kung Univ, Coll Med, Dept Nucl Med, Tainan, Taiwan	Yin, TK (reprint author), Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan.	qtkyin@mail.chna.edu.tw					Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chiu NT, 2001, EUR J NUCL MED, V28, P183, DOI 10.1007/s002590000402; CLEMENTZ GL, 1988, AM FAM PHYSICIAN, V38, P163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EAPEN V, 1994, BRIT J PSYCHIAT, V164, P708; Fukunaga K., 1990, INTRO STAT PATTERN R; Gordon I, 1996, NUCL MED COMMUN, V17, P1021, DOI 10.1097/00006231-199612000-00004; Haykin S., 1994, NEURAL NETWORKS COMP; Klieger PS, 1997, J NUCL MED, V38, P188; Kompoliti K, 1998, MOVEMENT DISORD, V13, P477, DOI 10.1002/mds.870130317; LACEY DJ, 1986, CLIN PEDIATR, V25, P433, DOI 10.1177/000992288602500901; Lampreave JL, 1998, J NUCL MED, V39, P624; Lin FJ, 2001, ZOOL STUD, V40, P199; LUENBERGER D. G., 1989, LINEAR NONLINEAR PRO; METZ CE, 1986, INVEST RADIOL, V21, P720; Moriarty J, 1997, PSYCHOL MED, V27, P737, DOI 10.1017/S0033291796004072; MORIARTY J, 1995, BRIT J PSYCHIAT, V167, P249, DOI 10.1192/bjp.167.2.249; Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620; PHILLIPS DS, 1978, BASIC STAT HLTH SCI; SIEG KG, 1993, CLIN NUCL MED, V18, P255, DOI 10.1097/00003072-199303000-00022; Tailairach J, 1988, COPLANAR STEREOTAXIC; YIN TK, 2001, P 6 C ART INT APPL K, P652; Yu SY, 2000, IEEE T MED IMAGING, V19, P115	23	7	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	JUL	2004	51	7					1286	1295		10.1109/TBME.2004.827954		10	Engineering, Biomedical	Engineering	830ON	WOS:000222132200024	
J	Martinoia, S; Massobrio, P; Bove, M; Massobrio, G				Martinoia, S; Massobrio, P; Bove, M; Massobrio, G			Effect of skull resistivity on the spatial resolutions of EEG and MEG (vol 51, pg 859, 2004)	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING			English	Correction							LA-TOURETTES-SYNDROME; PERFUSION; TECHNETIUM-99M-HMPAO; DIAGNOSIS; DISORDERS; CHILDHOOD; SYSTEM; SPECT		Univ Genoa, Dept Biophys & Elect Engn, Neuroengn & Bionanotechnol Grp, I-16145 Genoa, Italy; Univ Genoa, Sect Human Physiol, Dept Expt Med, Genoa, Italy	Martinoia, S (reprint author), Univ Genoa, Dept Biophys & Elect Engn, Neuroengn & Bionanotechnol Grp, Via Opera Pia 11A, I-16145 Genoa, Italy.	giaser@dibe.unige.it; Paolo.Massobrio@ingegneria.studenti.unige.it; bove@dibe.unige.it; biofet@dibe.unige.it	Martinoia, Sergio/H-1863-2011				Cheng HD, 1998, IEEE T MED IMAGING, V17, P442; Chiu NT, 2001, EUR J NUCL MED, V28, P183, DOI 10.1007/s002590000402; CLEMENTZ GL, 1988, AM FAM PHYSICIAN, V38, P163; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EAPEN V, 1994, BRIT J PSYCHIAT, V164, P708; Fukunaga K., 1990, INTRO STAT PATTERN R; Gordon I, 1996, NUCL MED COMMUN, V17, P1021, DOI 10.1097/00006231-199612000-00004; Haykin S., 1994, NEURAL NETWORKS COMP; Klieger PS, 1997, J NUCL MED, V38, P188; Kompoliti K, 1998, MOVEMENT DISORD, V13, P477, DOI 10.1002/mds.870130317; LACEY DJ, 1986, CLIN PEDIATR, V25, P433, DOI 10.1177/000992288602500901; Lampreave JL, 1998, J NUCL MED, V39, P624; LIN CT, 1991, IEEE T COMPUT, V40, P1320, DOI 10.1109/12.106218; LUENBERGER D. G., 1989, LINEAR NONLINEAR PRO; Martinoia S, 2004, IEEE T BIO-MED ENG, V51, P859, DOI 10.1109/TBME.2004.826607; METZ CE, 1986, INVEST RADIOL, V21, P720; Moriarty J, 1997, PSYCHOL MED, V27, P737, DOI 10.1017/S0033291796004072; MORIARTY J, 1995, BRIT J PSYCHIAT, V167, P249, DOI 10.1192/bjp.167.2.249; Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620; PHILLIPS DS, 1978, BASIC STAT HLTH SCI; SIEG KG, 1993, CLIN NUCL MED, V18, P255, DOI 10.1097/00003072-199303000-00022; Tailairach J, 1988, COPLANAR STEREOTAXIC; YIN TK, 2001, P 6 C ART INT APPL K, P652; Yu SY, 2000, IEEE T MED IMAGING, V19, P115	24	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9294		IEEE T BIO-MED ENG	IEEE Trans. Biomed. Eng.	JUL	2004	51	7					1295	1295		10.1109/TBME.2004.832417		1	Engineering, Biomedical	Engineering	830ON	WOS:000222132200025	
J	Levendovszky, J; Fancsali, A				Levendovszky, J; Fancsali, A			Real-time call admission control for packet-switched networking by cellular neural networks	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS			English	Article						call admission control (CAC); cellular neural network (CNN); set separation	CNN; UNIVERSAL; MACHINE	In this paper, novel call admission control (CAC) algorithms are developed based on cellular neural networks. These algorithms can achieve high network utilization by performing CAC in real-time, which is imperative in supporting quality of service (QoS) communication over packet-switched networks. The proposed solutions are of basic significance in access technology where a subscriber population (connected to the Internet via an access module) needs to receive services. In this case, QoS can only be preserved by admitting those user configurations which will not overload the access module. The paper treats CAC as a set separation problem where the separation surface is approximated based on a training set. This casts CAC as an image processing task in which a complex admission pattern is to be recognized from a couple of initial points belonging to the training set. Since CNNs can implement any propagation models to explore complex patterns, CAC can then be carried out by a CNN. The major challenge is to find the proper template matrix which yields high network utilization. On the other hand, the proposed method is also capable of handling three-dimensional separation surfaces, as in a typical access scenario there are three traffic classes (e.g., two type of Internet access and one voice over asymmetric digital subscriber line.	Budapest Univ Technol & Econ, Dept Telecommun, H-1117 Budapest, Hungary	Levendovszky, J (reprint author), Budapest Univ Technol & Econ, Dept Telecommun, H-1117 Budapest, Hungary.	levendov@hit.bme.hu	Levendovszky, Janos/F-5062-2013				BAKAMDIS SG, 1993, P IEEE INT C AC SPEE, V5, P658; CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P289, DOI 10.1109/81.224308; CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P147, DOI 10.1109/81.222795; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FANCSALI A, 2001, P POL CZECH HUNG WOR; Fantacci R, 1999, IEEE T CIRCUITS-I, V46, P1457, DOI 10.1109/81.809547; HIRAMATSU A, 1994, NEURAL NETWORKS TELE; HUI JY, 1988, IEEE J SEL AREA COMM, V6, P1598, DOI 10.1109/49.12887; LEVENDOVSZKY J, 1995, J COMMUN DED ATM NET, V47, P19; LEVENDOVSZKY J, 1999, P 2 INT C ATM JUN 21, P195; LEVENDOVSZKY J, 1995, C579 COPERNICUS; Linan G, 1999, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON MICROELECTRONICS FOR NEURAL, FUZZY AND BIO-INSPIRED SYSTEMS, MICORNEURO'99, P61, DOI 10.1109/MN.1999.758847; Petras I, 2000, PROCEEDINGS OF THE 2000 6TH IEEE INTERNATIONAL WORKSHOP ON CELLULAR NEURAL NETWORKS AND THEIR APPLICATIONS (CNNA 2000), P3, DOI 10.1109/CNNA.2000.876810; Rekeczky C, 1999, J VLSI SIG PROCESS S, V23, P373, DOI 10.1023/A:1008153320440; ROSKA T, 1993, IEEE T CIRCUITS-II, V40, P163, DOI 10.1109/82.222815; WISMER DA, 1978, SYSTEM SCI ENG	16	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1057-7122		IEEE T CIRCUITS-I	IEEE Trans. Circuits Syst. I-Regul. Pap.	JUN	2004	51	6					1172	1183		10.1109/TCSI.2004.826207		12	Engineering, Electrical & Electronic	Engineering	828YY	WOS:000222010900013	
J	Zheng, WM; Zhao, L; Zou, CR				Zheng, WM; Zhao, L; Zou, CR			Locally nearest neighbor classifiers for pattern classification	PATTERN RECOGNITION			English	Article						pattern classification; nearest feature line; nearest neighbor line	FACE RECOGNITION	In this paper, two novel classifiers based on locally nearest neighborhood rule, called nearest neighbor line and nearest neighbor plane, are presented for pattern classification. Comparison to nearest feature line and nearest feature plane, the proposed methods take much lower computation cost and achieve competitive performance. (C) 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Southeast Univ, Dept Radio Engn, Engn Res Ctr Informat Proc & Applicat, Nanjing 210096, Jiangsu, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Dept Radio Engn, Engn Res Ctr Informat Proc & Applicat, Nanjing 210096, Jiangsu, Peoples R China.	wenming_zheng@seu.edu.cn					Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323	4	48	51	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JUN	2004	37	6					1307	1309		10.1016/j.patcog.2003.11.004		3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	822PW	WOS:000221553100018	
J	Cai, YD; Doig, AJ				Cai, YD; Doig, AJ			Prediction of Saccharomyces cerevisiae protein functional class from functional domain composition	BIOINFORMATICS			English	Article							MULTIPLE SEQUENCE ALIGNMENT; YEAST GENOME; DATABASE; FAMILIES; CLASSIFICATION; IDENTIFICATION; ALGORITHM; PATTERNS; RESOURCE; FEATURES	Motivation: A key goal of genomics is to assign function to genes, especially for orphan sequences. Results: We compared the clustered functional domains in the SBASE database to each protein sequence using BLASTP. This representation for a protein is a vector, where each of the non-zero entries in the vector indicates a significant match between the sequence of interest and the SBASE domain. The machine learning methods nearest neighbour algorithm (NNA) and support vector machines are used for predicting protein functional classes from this information. We find that the best results are found using the SBASE-A database and the NNA, namely 72% accuracy for 79% coverage. We tested an assigning function based on searching for InterPro sequence motifs and by taking the most significant BLAST match within the dataset. We applied the functional domain composition method to predict the functional class of 2018 currently unclassified yeast open reading frames.	UMIST, Dept Biomol Sci, Manchester M60 1QD, Lancs, England	Doig, AJ (reprint author), UMIST, Dept Biomol Sci, POB 88, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk; Andrew.Doig@umist.ac.uk					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2000, BIOINFORMATICS, V16, P1145, DOI 10.1093/bioinformatics/16.12.1145; Attwood TK, 2000, NUCLEIC ACIDS RES, V28, P225, DOI 10.1093/nar/28.1.225; Bachinsky AG, 2000, BIOINFORMATICS, V16, P358, DOI 10.1093/bioinformatics/16.4.358; Bateman A, 2000, NUCLEIC ACIDS RES, V28, P263, DOI 10.1093/nar/28.1.263; BURBIDGE R, 2000, P AISB 00 S ART INT, P1; Corpet F, 1999, NUCLEIC ACIDS RES, V27, P263, DOI 10.1093/nar/27.1.263; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dandekar T, 1998, TRENDS BIOCHEM SCI, V23, P324, DOI 10.1016/S0968-0004(98)01274-2; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Dujon B, 1998, ELECTROPHORESIS, V19, P617, DOI 10.1002/elps.1150190427; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Goffeau A, 1996, SCIENCE, V274, P546, DOI 10.1126/science.274.5287.546; Goffeau A., 1996, SCIENCE, V274, P563; Gracy J, 1998, BIOINFORMATICS, V14, P164, DOI 10.1093/bioinformatics/14.2.164; Hegyi H, 1999, J MOL BIOL, V288, P147, DOI 10.1006/jmbi.1999.2661; Henikoff S, 1999, BIOINFORMATICS, V15, P471, DOI 10.1093/bioinformatics/15.6.471; Hofmann K, 1999, NUCLEIC ACIDS RES, V27, P215, DOI 10.1093/nar/27.1.215; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; JOACHIMS T, 1999, INT C MACH LEARN ICM, P700; Joachims T, 1998, P 10 EUR C MACH LEAR, P137; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Kasuya A, 1999, J MOL BIOL, V286, P1673, DOI 10.1006/jmbi.1999.2581; King RD, 2001, BIOINFORMATICS, V17, P445, DOI 10.1093/bioinformatics/17.5.445; King RD, 2000, YEAST, V17, P283, DOI 10.1002/1097-0061(200012)17:4<283::AID-YEA52>3.0.CO;2-F; Marcotte EM, 1999, NATURE, V402, P83; Marcotte EM, 2000, CURR OPIN STRUC BIOL, V10, P359, DOI 10.1016/S0959-440X(00)00097-X; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Mewes HW, 1997, NATURE, V387, P7; Mewes HW, 1999, NUCLEIC ACIDS RES, V27, P44, DOI 10.1093/nar/27.1.44; MORRISON R, 2003, UNPUB; Mulder NJ, 2003, NUCLEIC ACIDS RES, V31, P315, DOI 10.1093/nar/gkg046; Nevill-Manning CG, 1998, P NATL ACAD SCI USA, V95, P5865, DOI 10.1073/pnas.95.11.5865; OLIVER SG, 1997, GENOME DIGEST, V4, P4; Overbeek R, 1999, P NATL ACAD SCI USA, V96, P2896, DOI 10.1073/pnas.96.6.2896; Pearson WR, 1996, METHOD ENZYMOL, V266, P227; Pellegrini M, 2001, CURR OPIN CHEM BIOL, V5, P46, DOI 10.1016/S1367-5931(00)00165-4; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Perez AJ, 2002, COMP FUNCT GENOM, V3, P423, DOI 10.1002/cfg.208; Ponting CP, 1999, NUCLEIC ACIDS RES, V27, P229, DOI 10.1093/nar/27.1.229; Skolnick J, 2000, TRENDS BIOTECHNOL, V18, P34, DOI 10.1016/S0167-7799(99)01398-0; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Vapnik V.N., 1998, STAT LEARNING THEORY; Vapnik V.N., 1995, NATURE STAT LEARNING; Vlahovicek K, 2002, NUCLEIC ACIDS RES, V30, P273, DOI 10.1093/nar/30.1.273; Zagulski M, 1998, ACTA BIOCHIM POL, V45, P627	48	27	29	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 22	2004	20	8					1292	1300		10.1093/bioinformatics/bth085		9	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	822QY	WOS:000221556100011	
J	Huang, CC; Lee, HM				Huang, CC; Lee, HM			A grey-based nearest neighbor approach for missing attribute value prediction	APPLIED INTELLIGENCE			English	Article						missing attribute values; grey-based nearest neighbor approach; grey relational analysis; the nearest neighbor concept	CLASSIFICATION; ALGORITHM	This paper proposes a grey-based nearest neighbor approach to predict accurately missing attribute values. First, grey relational analysis is employed to determine the nearest neighbors of an instance with missing attribute values. Accordingly, the known attribute values derived from these nearest neighbors are used to infer those missing values. Two datasets were used to demonstrate the performance of the proposed method. Experimental results show that our method outperforms both multiple imputation and mean substitution. Moreover, the proposed method was evaluated using five classification problems with incomplete data. Experimental results indicate that the accuracy of classification is maintained or even increased when the proposed method is applied for missing attribute value prediction.	Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Huang, CC (reprint author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bertino E, 1998, MULTIMEDIA SYST, V6, P2, DOI 10.1007/s005300050072; Blake CL, 1998, UCI REPOSITORY MACHI; Buntine W. L., 1991, Complex Systems, V5; Cestnik B, 1987, PROGR MACHINE LEARNI, P31; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Deng Julong, 1989, Journal of Grey Systems, V1; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090; Fisher RA, 1936, ANN EUGENIC, V7, P179; FIX E, 1951, 2149004 USAF SCH AV; Freund Y., 1999, P 16 INT C MACH LEAR, P124; Freund Y., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279985; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Huang C.C., 2002, P UK WORKSH COMP INT; John G., 1995, P 11 C UNC ART INT, P338; John G.C., 1995, P 12 INT C MACH LEAR, P108; King G, 2001, AM POLIT SCI REV, V95, P49; KOHAVI R, 1995, EUR C MACH LEARN; LIN CT, 1999, J GREY SYSTEM, V4, P359; MICHALSKI RS, 1980, INT J POLICY ANAL IN, V4; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; REICH Y, 1990, P 1 INT WORKSH FORM, P330; Rubin DB, 1987, MULTIPLE IMPUTATION; SALZBERG S, 1988, TR1088 HARV U CTR RE; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; WATSON CP, 1993, STAT MANAGEMENT EC; Witten I. H., 2000, DATA MINING PRACTICA; WU JH, 1999, J GREY SYST, V3, P287	35	10	14	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X		APPL INTELL	Appl. Intell.	MAY-JUN	2004	20	3					239	252		10.1023/B:APIN.0000021416.41043.0f		14	Computer Science, Artificial Intelligence	Computer Science	806CG	WOS:000220411400004	
J	Wyns, B; Sette, S; Boullart, L; Baeten, D; Hoffman, IEA; De Keyser, F				Wyns, B; Sette, S; Boullart, L; Baeten, D; Hoffman, IEA; De Keyser, F			Prediction of diagnosis in patients with early arthritis using a combined Kohonen mapping and instance-based evaluation criterion	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						Kohonen neural networks; case-based reasoning; prediction system; decision support systems; chronic autoimmune arthritis	SELF-ORGANIZING MAP; RHEUMATOID-ARTHRITIS; CLASSIFICATION; SPONDYLOARTHROPATHY; SYNOVIUM	Rheumatoid arthritis (RA) and spondyloarthropathy (SpA) are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. This paper introduces a self-organizing artificial neural network combined with a case-based reasoning evaluation criterion to predict diagnosis in patients with early arthritis. Results show that 47.2% of the sample space can be predicted with an accuracy of 84.0% and attaining a high confidence level. 37.7% of the sample space is classified with an overall accuracy of 65.0%. The remaining group was labeled as "undetermined". A general prediction accuracy of 75.6% is reached, exceeding the performance of other approaches such as a backpropagation neural network and the Quest decision tree program. Furthermore, by using this new method, more specifically case-based reasoning, as a helpful tool to classify patients with early arthritis, the possibility of a confidence measure is given, indicating a degree of "belief" of the system in its results. This is often an important feature when dealing with diagnosis in human patients. (C) 2004 Elsevier B.V. All rights reserved.	Ghent Univ, Fac Sci Appl, Dept Elect Energy Syst & Automat, B-9000 Ghent, Belgium; Ghent Univ, Fac Sci Appl, Dept Text, B-9000 Ghent, Belgium; Ghent Univ Hosp, Fac Med, Dept Rheumatol, B-9000 Ghent, Belgium	Wyns, B (reprint author), Ghent Univ, Fac Sci Appl, Dept Elect Energy Syst & Automat, Technol Pk 913, B-9000 Ghent, Belgium.	bart.wyns@ugent.be					Anderson J. A., 1989, NEUROCOMPUTING FDN R; Arnett FC, 1987, ARTHRITIS RHEUM, V31, P315; Baeten D, 2000, ANN RHEUM DIS, V59, P945, DOI 10.1136/ard.59.12.945; BAETEN D, 2002, CLIN RHEUMATOL, V21, P447; Baeten D, 2001, ARTHRITIS RHEUM, V44, P2255, DOI 10.1002/1529-0131(200110)44:10<2255::AID-ART388>3.0.CO;2-#; Baeten D, 2000, ARTHRITIS RHEUM, V43, P1233, DOI 10.1002/1529-0131(200006)43:6<1233::AID-ANR6>3.0.CO;2-9; Baeten D, 1999, CLIN RHEUMATOL, V18, P434, DOI 10.1007/s100670050134; Baeten D, 2002, J PATHOL, V196, P343, DOI 10.1002/path.1044; BOULLAR L, 2003, P IFAC INT C INT CON, P55; Burr Ridge I, 1997, MACHINE LEARNING; Chen DR, 2000, ULTRASOUND MED BIOL, V26, P405, DOI 10.1016/S0301-5629(99)00156-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOUGADOS M, 1991, ARTHRITIS RHEUM, V34, P1218, DOI 10.1002/art.1780341003; HECTHNIELSEN R, 1989, NEUROCOMPUTING; Henson S, 1999, FOOD CONTROL, V10, P99, DOI 10.1016/S0956-7135(98)00162-5; HOKELA T, 1999, SPECIAL ISSUE IJCAI; Kohonen T., 1989, SELF ORG ASS MEMORY; Leake D.B., 1996, CASE BASED REASONING; Lippmann R. P., 1987, IEEE ASSP Magazine, V4, DOI 10.1109/MASSP.1987.1165576; Loh WY, 1997, STAT SINICA, V7, P815; MANICKAM S, 2000, IEEE TENCON 2000, P24; Markey MK, 2003, ARTIF INTELL MED, V27, P113, DOI 10.1016/S0933-3657(03)00003-4; OTTE G, 1990, MUSCLE NERVE, V10, P982; Patterson D., 1996, ARTIFICIAL NEURAL NE; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SETTE S, 1995, TEXT RES J, V65, P196, DOI 10.1177/004051759506500402; SIEBEN G, 1994, ACTA NEUROCHIR, V129, P193, DOI 10.1007/BF01406504; VANDENBOSCH F, 2001, J RHEUMATOL, V28, P2	28	11	11	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657		ARTIF INTELL MED	Artif. Intell. Med.	MAY	2004	31	1					45	55		10.1016/j.artmed.2004.01.002		11	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	832GS	WOS:000222256000003	
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Predicting subcellular localization of proteins in a hybridization space	BIOINFORMATICS			English	Article							AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; SUPPORT VECTOR MACHINES; LOCATION PREDICTION; SORTING SIGNALS; SEQUENCE; RESOURCE; SITES	Motivation: The localization of a protein in a cell is closely correlated with its biological function. With the number of sequences entering into databanks rapidly increasing, the importance of developing a powerful high-throughput tool to determine protein subcellular location has become self-evident. In view of this, the Nearest Neighbour Algorithm was developed for predicting the protein subcellular location using the strategy of hybridizing the information derived from the recent development in gene ontology with that from the functional domain composition as well as the pseudo amino acid composition. Results: As a showcase, the same plant and non-plant protein datasets as investigated by the previous investigators were used for demonstration. The overall success rate of the jackknife test for the plant protein dataset was 86%, and that for the non-plant protein dataset 91.2%. These are the highest success rates achieved so far for the two datasets by following a rigorous cross-validation test procedure, suggesting that such a hybrid approach (particularly by incorporating the knowledge of gene ontology) may become a very useful high-throughput tool in the area of bioinformatics, proteomics, as well as molecular cell biology.	UMIST, Biomol Sci Dept, Manchester M60 1QD, Lancs, England; Gordon Life Sci Inst, San Diego, CA 92130 USA; TRIBD, Tianjin, Peoples R China	Cai, YD (reprint author), UMIST, Biomol Sci Dept, POB 88, Manchester M60 1QD, Lancs, England.	y.cai@umist.ac.uk	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; BLOBEL G, 1976, BIOCHEM BIOPH RES CO, V68, P1, DOI 10.1016/0006-291X(76)90001-2; Cai Yu-Dong, 2000, Molecular Cell Biology Research Communications, V4, P172, DOI 10.1006/mcbr.2001.0269; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou JJ, 1999, CELL, V96, P615, DOI 10.1016/S0092-8674(00)80572-3; Chou JJ, 1998, CELL, V94, P171, DOI 10.1016/S0092-8674(00)81417-8; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou K.C., 2002, GENE CLONING EXPRESS, P57; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Claros MG, 1997, CURR OPIN STRUC BIOL, V7, P394, DOI 10.1016/S0959-440X(97)80057-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Jensen LJ, 2002, J MOL BIOL, V319, P1257, DOI 10.1016/S0022-2836(02)00379-0; Letunic I, 2002, NUCLEIC ACIDS RES, V30, P242, DOI 10.1093/nar/30.1.242; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Vlahovicek K, 2002, NUCLEIC ACIDS RES, V30, P273, DOI 10.1093/nar/30.1.273; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365	37	48	52	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	MAY 1	2004	20	7					1151	1156		10.1093/bioinformatics/bth054		6	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	816WJ	WOS:000221139700018	
J	Lee, C; Lee, J; Lee, C				Lee, C; Lee, J; Lee, C			Korean adult male voxel model KORMAN segmented from magnetic resonance images	MEDICAL PHYSICS			English	Article						voxel; human model; construction; dosimetry; magnetic resonance	MONTE-CARLO CALCULATIONS; PHANTOM; SYSTEM	A voxel model of Korean adult male, KORMAN, was developed by processing whole-body magnetic resonance (MR) images of a healthy volunteer who represents an approximately average Korean in height and weight. Layer by layer the MR images were semi-automatically segmented and indexed using a graphic software and digitizer to construct data arrays consisting of 250 X 120 X 170 voxels of a size of 2 X 2 X 10 mm(3). To assess the utility of the model, some illustrative dosimetric calculations were made to obtain organ absorbed doses and effective doses to the KORMAN placed in broad parallel photon fields with energies ranging from 0.05 to 10 MeV. The results were compared with those based on the medical internal radiation dose (MIRD)-type models given in ICRP74. The effective doses of ICRP74 were higher than those of KORMAN with percent differences ranging from 6% (LLAT, 10 MeV) to 30% (PA, 0.05 MeV). Significant differences of more than 40% were observed in organ absorbed doses for some organs including bone surface (AP), stomach (PA), and testes (LAT) for low photon energy. These are mainly caused by difference in trunk thickness between MIRD-type model and KORMAN, and differences in organ positions in the body. (C) 2004 American Association of Physicists in Medicine.	Hanyang Univ, Innovat Technol Ctr Radiat Safety, Seoul 133791, South Korea; Univ Florida, Dept Radiol & Nucl Med, Gainesville, FL 32611 USA	Lee, C (reprint author), Hanyang Univ, Innovat Technol Ctr Radiat Safety, HIT Bldg,17 Haengdang, Seoul 133791, South Korea.	cslee@itrs.hanyang.ac.kr; cslee@itrs.hanyang.ac.kr					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristy M., 1980, ORNLNUREGTM367; Cristy M., 1987, ORNLTM8381VI; Dimbylow P.J., 1995, P INT WORKSH VOX PHA, P1; GIBBS SJ, 1984, ORAL SURG ORAL MED O, V58, P347, DOI 10.1016/0030-4220(84)90066-5; HWANG JML, 1975, ORNL5046; ICRP, 1975, ICRP PUBL, V23; ICRP, 1991, ICRP PUBL, V60; ICRP, 2003, ICRP PUBL, V89; ICRP, 1993, ICRP PUBL, V67; ICRU (International Commission on Radiological Units and Measurements and International Commission on Radiation Units and Measurements), 1984, 44 ICRU; International Commission on Radiological Protection (ICRP), 1996, ICRP PUBL, V74; Kramer R, 2003, PHYS MED BIOL, V48, P1239, DOI 10.1088/0031-9155/48/10/301; KRAMER R, 1982, S885 GSF; LAURIE SW, 2002, LACP02408 LOS AL NAT; LEE J, 2002, P 1 AS OC C RAD PROT, P122; LIGIER Y, 1994, M D COMPUT, V11, P212; Nipper JC, 2002, PHYS MED BIOL, V47, P3143, DOI 10.1088/0031-9155/47/17/307; Saito K, 2001, RADIAT ENVIRON BIOPH, V40, P69, DOI 10.1007/s004110000082; SNYDER WS, 1969, J NUCL MED, V10; TANAKA G-I, 1989, Nippon Acta Radiologica, V49, P344; WILLIAMS G, 1986, PHYS MED BIOL, V31, P449, DOI 10.1088/0031-9155/31/4/010; Xu XG, 2000, HEALTH PHYS, V78, P476, DOI 10.1097/00004032-200005000-00003; Yoriyaz H, 2000, MED PHYS, V27, P1555, DOI 10.1118/1.599021; Zankl M, 2001, RADIAT ENVIRON BIOPH, V40, P153, DOI 10.1007/s004110100094; Zankl M, 2002, PHYS MED BIOL, V47, P2367, DOI 10.1088/0031-9155/47/14/301; ZANKL M, 1988, RADIAT ENVIRON BIOPH, V27, P154; ZANKL M, 1995, RADIAT PROT DOSIM, V57, P393; ZUBAL IG, 1994, MED PHYS, V21, P299	29	16	18	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405		MED PHYS	Med. Phys.	MAY	2004	31	5					1017	1022		10.1118/1.1689013		6	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	821EX	WOS:000221444300010	
J	Mechanda, SM; Baum, BR; Johnson, DA; Arnason, JT				Mechanda, SM; Baum, BR; Johnson, DA; Arnason, JT			Analysis of diversity of natural populations and commercial lines of Echinacea using AFLP	CANADIAN JOURNAL OF BOTANY-REVUE CANADIENNE DE BOTANIQUE			English	Article						Echinacea; population genetic analysis; multivariate analysis; AFLP band homologies	FRAGMENT LENGTH POLYMORPHISM; BUFFALOGRASS BUCHLOE-DACTYLOIDES; GENETIC-RELATIONSHIPS; RAPD VARIATION; MARKERS; ASTERACEAE; CULTIVARS; LACTUCA; CLASSIFICATION; DISCRIMINATION	An analysis of diversity of Echinacea native to North America, using amplified fragment length polymorphism (AFLP(R)), was carried out to complement a previously undertaken taxonomic revision of Echinacea that employed multivariate morphometrics. A total of 53 940 AFLP fragments, of which 40 455 were polymorphic, were scored on 435 individual plants from 58 populations consisting of 10 individuals per population. The resulting polymorphism was sufficient to distinguish each plant. A monomorphic AFLP band and a polymorphic AFLP band that migrated a the same position, taken from samples of four species and eight varieties, were cloned, and multiple clones were sequenced. The polymorphic band at the same position across fragments was not identical, with identity as low as 23% compared with 50% identity of the monomorphic band, both of which were at the 100% threshold of sequence similarity. Thus, the AFLP banding profiles, irrespective of their sequence identity, were treated as phenotypes for population genetic, discriminant, and phylogenetic analyses. Variance components within populations and among populations within species were of equal magnitude, but the partitioned variation was slightly higher among varieties than among populations within varieties. Since no species-specific or variety-specific AFLP fingerprints were found, canonical discriminant analysis was conducted, resulting in support for four species but not for the varieties. Similar results were obtained with cluster and principal coordinate analyses, based on genetic distances. To achieve identification using AFLP fingerprints, various classificatory analyses were performed, followed by bootstrapping for validation. An example to identify an unknown plant at the species level with a minimum of 10 AFLP fragments, with greater than 82% overall correct classification, is provided. Phylogenetic analysis of all 435 individuals supported only Echinacea purpurea (L.) Moench and Echinacea laevigata (C.L. Boynton & Beadle) as separate entities, and only the three Echinacea atrorubens varieties and Echinacea pallida var. tennesseensis (Beadle) Binns, B.R. Baum Arnason.	Agr & Agri Food Canada, Ottawa, ON K1A 0C6, Canada; Univ Ottawa, Dept Biol, Ottawa, ON K1N 6N5, Canada	Baum, BR (reprint author), Agr & Agri Food Canada, Neatby Bldg,960 Carling Ave, Ottawa, ON K1A 0C6, Canada.	baumbr@agr.gc.ca					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Anderson T., 1984, INTRO MULTIVARIATE S; Backeljau T, 1995, CLADISTICS, V11, P119; Badr A, 2002, CAN J BOT, V80, P962, DOI [10.1139/B02-084, 10.1139/b02-084]; Baum BR, 2001, PHYTOCHEMISTRY, V56, P543, DOI 10.1016/S0031-9422(00)00425-8; Binns SE, 2002, SYST BOT, V27, P610; BLUMENTHAL M, 1992, WHOLE FOODS      JUN, P20; Bonnema G, 2002, GENOME, V45, P217, DOI 10.1139/G01-145; Borchers AT, 2000, AM J CLIN NUTR, V72, P339; Brevoort P, 1996, HERBALGRAM, V36, P49; Breyne P, 1999, MOL GEN GENET, V261, P627; Buntjer JB, 2002, HEREDITY, V88, P46, DOI 10.1038/sj/hyd/6800007; CLARK AG, 1993, MOL BIOL EVOL, V10, P1096; COART E, 2002, THEOR APPL GENET, V1108, P1; COCHRAN WG, 1961, BIOMETRICS, V17, P10, DOI 10.2307/2527493; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Doyle J. J., 1987, PHYTOCHEMISTRY B, V19, P11; DROOGENBROECK BV, 2002, THEOR APPL GENET, V105, P1; El Rabey H, 2002, PLANT BIOLOGY, V4, P1; EXCOFFIER L, 1992, GENETICS, V131, P479; Foster S., 1991, ECHINACEA NATURES IM; Ganter PF, 2000, CAN J MICROBIOL, V46, P967, DOI 10.1139/cjm-46-11-967; Giannasi N, 2001, MOL ECOL, V10, P419, DOI 10.1046/j.1365-294x.2001.01220.x; GILBERT ES, 1968, J AM STAT ASSOC, V63, P1399, DOI 10.2307/2285893; Gobert V, 2002, AM J BOT, V89, P2017, DOI 10.3732/ajb.89.12.2017; Guan Shukui, 2002, Applied and Environmental Microbiology, V68, P2690, DOI 10.1128/AEM.68.6.2690-2698.2002; Hedren M, 2001, AM J BOT, V88, P1868, DOI 10.2307/3558363; Hill M, 1996, THEOR APPL GENET, V93, P1202; HOBBS C, 1994, HERBALGRAM, V30, P33; Hodkinson TR, 2002, ANN BOT-LONDON, V89, P627, DOI 10.1093/aob/mcf091; HUFF DR, 1993, THEOR APPL GENET, V86, P927, DOI 10.1007/BF00211043; IPEK M, 2003, PLANT ANIMAL GENOME, V11; Kapteyn J, 2002, THEOR APPL GENET, V105, P369, DOI 10.1007/s00122-002-0960-y; Kardolus JP, 1998, PLANT SYST EVOL, V210, P87, DOI 10.1007/BF00984729; Keim P, 1997, J BACTERIOL, V179, P818; KIM DH, 2003, PLANT ANIMAL GENOME, V11; Koopman WJM, 1996, ACTA BOT NEERL, V45, P211; Koopman WJM, 2000, EUPHYTICA, V116, P151, DOI 10.1023/A:1004086503349; Koopman WJM, 2001, AM J BOT, V88, P1881, DOI 10.2307/3558364; KRZANOWSKI WJ, 1975, J AM STAT ASSOC, V70, P782, DOI 10.2307/2285437; Kshirsagar A. M., 1972, MULTIVARIATE ANAL; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Lombard V, 2000, CROP SCI, V40, P1417; MACE ES, 1999, THEOR APPL GENET, V99, P534; Mace ES, 1999, THEOR APPL GENET, V99, P626, DOI 10.1007/s001220051277; MANTEL N, 1967, CANCER RES, V27, P209; MCGREGOR R L, 1968, University of Kansas Science Bulletin, V48, P113; Mechanda SM, 2004, GENOME, V47, P15, DOI 10.1139/G03-094; Mengistu LW, 2000, THEOR APPL GENET, V101, P70, DOI 10.1007/s001220051451; SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409; Miller MP, 1997, TOOLS POPULATION GEN; Mueller UG, 1999, TRENDS ECOL EVOL, V14, P389, DOI 10.1016/S0169-5347(99)01659-6; NEI M, 1973, P NATL ACAD SCI USA, V70, P3321, DOI 10.1073/pnas.70.12.3321; NEI M, 1972, AM NAT, V106, P283, DOI 10.1086/282771; Nicholas KB, 1997, GENEDOC TOOL EDITING; Nilsson NO, 1999, PLANT BREEDING, V118, P327, DOI 10.1046/j.1439-0523.1999.00390.x; Ogden R, 2002, MOL ECOL, V11, P437, DOI 10.1046/j.0962-1083.2001.01442.x; PEAKALL R, 1995, MOL ECOL, V4, P135, DOI 10.1111/j.1365-294X.1995.tb00203.x; Pimentel RA, 1979, MORPHOMETRICS MULTIV; Powell W, 1996, MOL BREEDING, V2, P225, DOI 10.1007/BF00564200; Quagliaro J, 2001, J HERED, V92, P38; RAAMSDONK LWD, 2000, THEOR APPL GENET, V100, P1000; RAO C.R., 1952, ADV STAT METHODS BIO; Reamon-Buttner SM, 1999, CHROMOSOME RES, V7, P297, DOI 10.1023/A:1009231031667; ROHLF FJ, 2000, NTSYSPC NUMERICAL AX; Roldan-Ruiz I, 2001, THEOR APPL GENET, V103, P1138, DOI 10.1007/s001220100571; Sambrook J., 1988, MOL CLONING LAB MANU; SAS Institute Inc, 2002, SAS STAT US GUID VER; SCHNEITER R, 2001, RRD MOLEC CELL BIO 1, V2, P1; Semagn K, 2000, THEOR APPL GENET, V101, P1145, DOI 10.1007/s001220051591; SNOW R, 1963, STAIN TECHNOL, V38, P9; Soleimani VD, 2002, CAN J PLANT SCI, V82, P35; Steiger DL, 2002, THEOR APPL GENET, V105, P209, DOI 10.1007/s00122-002-0939-8; SWOFFORD DL, 1999, PAUP PHYLOGENETIC AN; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Tomkins JP, 2001, THEOR APPL GENET, V102, P489, DOI 10.1007/s001220051672; TYLER VE, 1993, ACS SYM SER, V534, P25; Urbatsch LE, 2000, SYST BOT, V25, P539, DOI 10.2307/2666695; URBATSCH LE, 1995, SYST BOT, V20, P28, DOI 10.2307/2419630; Jones CJ, 1997, MOL BREEDING, V3, P381, DOI 10.1023/A:1009612517139; van den Berg RG, 2002, THEOR APPL GENET, V105, P1109, DOI 10.1007/s00122-002-1054-6; VOS P, 1995, NUCLEIC ACIDS RES, V23, P4407, DOI 10.1093/nar/23.21.4407; Wong A, 2001, GENOME, V44, P677, DOI 10.1139/gen-44-4-677; Yeh Francis C., 1997, Belgian Journal of Botany, V129, P157; ZANDE L, 1995, J EVOLUTION BIOL, V8, P645	86	9	9	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA, ONTARIO K1A 0R6, CANADA	0008-4026		CAN J BOT	Can. J. Bot.-Rev. Can. Bot.	APR	2004	82	4					461	484		10.1139/B04-006		24	Plant Sciences	Plant Sciences	829GL	WOS:000222035300006	
J	Roncaglia, A; Elmi, I; Dori, L; Rudan, M				Roncaglia, A; Elmi, I; Dori, L; Rudan, M			Adaptive K-NN for the detection of air pollutants with a sensor array	IEEE SENSORS JOURNAL			English	Article						benzene, toluene and xylene (BTX); CO; gas mixtures; K-nn classification; NO2; quantitative analysis; SnO2 sensors	ARTIFICIAL NEURAL-NETWORK; GAS SENSORS; PATTERN CLASSIFICATION; POLLUTION; SYSTEM	The field of air-quality monitoring is gaining increasing interest, with regard to both indoor environment and air-pollution control in open space. This work introduces a pattern recognition technique based on adaptive K-nn applied to a multisensor system, optimized for the recognition of some relevant tracers for air pollution in outdoor environment, namely benzene, toluene, and xylene (BTX), NO2, and CO. The pattern-recognition technique employed aims at recognizing the target gases within an air sample of unknown composition and at estimating their concentrations. It is based on PCA and K-nn classification with an adaptive vote technique based on the gas concentrations of the training samples associated to the K-neighbors. The system is tested in a controlled environment composed of synthetic air with a fixed humidity rate (30%) at concentrations in the ppm range for BTX and NO2, in the range of 10 ppm for CO. The pattern recognition technique is experimented on a knowledge base composed of a limited number of samples (130), with the adoption of a leave-one-out procedure in order to estimate the classification probability. In these conditions, the system demonstrates the capability to recognize the presence of the target gases in controlled conditions with a high hit-rate. Moreover, the concentrations of the individual components of the test samples are successfully estimated for BTX and NO2 in more than 80% of the considered cases, while a lower hit-rate (69%) is reached for CO.	Italian Natl Res Council, IMM, CNR, I-40129 Bologna, Italy; Univ Bologna, DEIS, I-40136 Bologna, Italy; ARCES, I-40136 Bologna, Italy	Roncaglia, A (reprint author), Italian Natl Res Council, IMM, CNR, I-40129 Bologna, Italy.	alberto.roncaglia@imm.cnr.it					ALVES JSG, 1999, SENSOR ACTUAT B-CHEM, V59, P69; BRASINI F, 1989, SENSOR ACTUAT B-CHEM, V69, P219; Brunet J, 2001, THIN SOLID FILMS, V391, P308, DOI 10.1016/S0040-6090(01)01001-X; COCHEO V, 1999, AIR QUALITY EUROPE C, P172; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DORI L, 1997, P EUROSENSORS 11 C W, P21; Dori L, 2000, SENSOR MATER, V12, P163; ELMI I, 2000, P 13 EUR C SOL STAT, V14; Fukunaga K., 1990, INTRO STAT PATTERN R; Hong HK, 2000, SENSOR ACTUAT B-CHEM, V66, P49, DOI 10.1016/S0925-4005(99)00460-8; HORNER G, 1990, SENSOR ACTUAT B-CHEM, V2, P173, DOI 10.1016/0925-4005(90)85002-G; KANAL L, 1971, PATTERN RECOGN, V3, P225, DOI 10.1016/0031-3203(71)90013-6; LACHENBRUCH P, 1968, TECHNOMETR, V13, P1; Lu Y, 2000, ANAL CHIM ACTA, V417, P101, DOI 10.1016/S0003-2670(00)00922-3; Martin MA, 2001, SENSOR ACTUAT B-CHEM, V77, P468, DOI 10.1016/S0925-4005(01)00736-5; Mayer H, 1999, ATMOS ENVIRON, V33, P4029, DOI 10.1016/S1352-2310(99)00144-2; Mitrovics J, 1998, ACCOUNTS CHEM RES, V31, P307, DOI 10.1021/ar970064n; Becker T, 2000, SENSOR ACTUAT B-CHEM, V69, P108, DOI 10.1016/S0925-4005(00)00516-5; Negri RM, 2001, SENSOR ACTUAT B-CHEM, V75, P172, DOI 10.1016/S0925-4005(01)00543-3; Oyabu T, 1997, SENSOR MATER, V9, P177; Platt U., 1994, AIR MONITORING SPECT, P27; RONCAGLIA A, 2001, P ISOEN WASH DC MAR, P170; ROVATTI R, 1995, NEURAL COMPUT, V7, P594, DOI 10.1162/neco.1995.7.3.594; SBERVEGLIERI G, 1992, SENSOR ACTUAT B-CHEM, V6, P239, DOI 10.1016/0925-4005(92)80062-3	24	1	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1530-437X		IEEE SENS J	IEEE Sens. J.	APR	2004	4	2					248	256		10.1109/JSEN.2004.823653		9	Engineering, Electrical & Electronic; Instruments & Instrumentation; Physics, Applied	Engineering; Instruments & Instrumentation; Physics	802IS	WOS:000220157800012	
J	Zhang, B; Srihari, SN				Zhang, B; Srihari, SN			Fast k-nearest neighbor classification using cluster-based trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor classification; nonmetrics; metrics; cluster tree	ALGORITHM; SEARCH; RECOGNITION; REPRESENTATION; RULE	Most fast k-nearest neighbor (k-NN) algorithms exploit metric properties of distance measures for reducing computation cost and a few can work effectively on both metric and nonmetric measures. We propose a cluster-based tree algorithm to accelerate k-NN classification without any presuppositions about the metric form and properties of a dissimilarity measure. A mechanism of early decision making and minimal side-operations for choosing searching paths largely contribute to the efficiency of the algorithm. The algorithm is evaluated through extensive experiments over standard NIST and MNIST databases.	Univ Calif Los Angeles, Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Sch Med, Dept Biostat, Los Angeles, CA 90095 USA; SUNY Buffalo, CEDAR, Dept Comp Sci & Engn, Amherst, NY 14228 USA	Zhang, B (reprint author), Univ Calif Los Angeles, Sch Med, Dept Human Genet, Los Angeles, CA 90095 USA.	binzhang@mednet.ucla.edu; srihari@cedar.buffalo.edu					BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BRODER AJ, 1990, PATTERN RECOGN, V23, P171, DOI 10.1016/0031-3203(90)90057-R; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HUNTTENLOCHER D, 1997, IEEE T PATTERN ANAL, V19, P1; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Puzicha J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790412; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; ZHANG B, 2003, P JCIS INT C COMP VI	23	38	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					525	528				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	801NO	WOS:000220102800009	
J	Kamp, JF; Poirier, F; Doignon, P				Kamp, JF; Poirier, F; Doignon, P			Interaction with in-vehicle electronic systems: A complete description of a neural network approach	NEURAL PROCESSING LETTERS			English	Article						dynamic vector quantization; handwritten character recognition; in-vehicle system; industrial application; k-nearest neighbour classifier; man-machine interaction; touchpad; winner takes all NN		Interaction with in-vehicle systems (car phones, traffic information, route guidance, etc) becomes a very difficult task since the control devices are often reduced to small switches and push-buttons. To solve the problem, a new input interface is proposed, based on character recognition. The paper describes in detail how a simple neural network can be applied down to the level of an industrial realization to provide a reliable user-machine interface. The industrial application is that of character recognition where characters are drawn with the finger on a small touchpad. Compared with the nearest neighbour method, the neural network solution has slightly better recognition rate, is faster and requires less memory space. The design of the recognition system is given and results of an experiment made on a driving simulator are presented.	Univ Bretagne Sud, Lab VALORIA, Ctr Rech Y Coppens, F-56000 Vannes, France; Renault, Technoctr, F-78288 Guyancourt, France	Kamp, JF (reprint author), Univ Bretagne Sud, Lab VALORIA, Ctr Rech Y Coppens, Campus Tohann, F-56000 Vannes, France.	jean-francois.kamp@univ-ubs.fr; franck.poirier@univ-ubs.fr; philippe.doignon@renault.fr					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; GARCIASALICETTI S, 1996, ACT 4 C NAT ECR DOC, P15; Greenstein J. S., 1988, HDB HUMAN COMPUTER I; GUYON I, 1991, PATTERN RECOGN, V24, P105, DOI 10.1016/0031-3203(91)90081-F; Harel D., 1987, SCI COMPUTER PROGRAM, V8; Holmstrom L, 1997, IEEE T NEURAL NETWOR, V8, P5, DOI 10.1109/72.554187; Kohonen T, 1990, P INT JOINT C NEUR N, P545; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOHONEN T, 1988, NEURAL NETWORKS, V1, P303; Paelke G. M., 1993, Proceedings of the Human Factors and Ergonomics Society 37th Annual Meeting. Designing for Diversity; POIRIER F, 1991, ARTIFICIAL NEURAL NE, V2, P1333; POIRIER F, 1991, P 2 EUR C SPEECH COM, V2, P1003; TADJ C, 1993, P 3 EUR C SPEECH COM, V2, P1009; WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7; YAMAMOTO T, 1999, P 6 ANN WORLD C INT	17	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621		NEURAL PROCESS LETT	Neural Process. Lett.	APR	2004	19	2					109	129		10.1023/B:NEPL.0000023422.16224.cf		21	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	811HM	WOS:000220763000002	
J	Burroni, M; Corona, R; Dell'Eva, G; Sera, F; Bono, R; Puddu, P; Perotti, R; Nobile, F; Andreassi, L; Rubegni, P				Burroni, M; Corona, R; Dell'Eva, G; Sera, F; Bono, R; Puddu, P; Perotti, R; Nobile, F; Andreassi, L; Rubegni, P			Melanoma computer-aided diagnosis: Reliability and feasibility study	CLINICAL CANCER RESEARCH			English	Article							PIGMENTED SKIN-LESIONS; ARTIFICIAL NEURAL-NETWORK; DIGITAL EPILUMINESCENCE MICROSCOPY; FINITE-SAMPLE SIZE; MALIGNANT-MELANOMA; 7-POINT CHECKLIST; IMAGE-ANALYSIS; ABCD RULE; DERMOSCOPY ANALYSIS; PATTERN-ANALYSIS	Background Differential diagnosis of melanoma from melanocytic nevi is often not straightforward. Thus, a growing interest has developed in the last decade in the automated analysis of digitized images obtained by epiluminescence microscopy techniques to assist clinicians in differentiating early melanoma from benign skin lesions. Purpose: The aim of this study was to evaluate diagnostic accuracy provided by different statistical classifiers on a large set of pigmented skin lesions grabbed by four digital analyzers located in two different dermatological units. Experimental Design: Images of 391melanomas and 449 melanocytic nevi were included in the study. A linear classifier was built by using the method of receiver operating characteristic curves to identify a threshold value for a fixed sensitivity of 95%. A K-nearest-neighbor classifier, a non-parametric method of pattern recognition, was constructed using all available image features and trained for a sensitivity of 98% on a large exemplar set of lesions. Results: On independent test sets of lesions, the linear classifier and the K-nearest-neighbor classifier produced a mean sensitivity of 95% and 98% and a mean specificity of 78% and of 79%, respectively. Conclusions: In conclusion, our study suggests that computer-aided differentiation of melanoma from benign pigmented lesions obtained with DB-Mips is feasible and, above all, reliable. In fact, the same instrumentations used in different units provided similar diagnostic accuracy. Whether this would improve early diagnosis of melanoma and/or reducing unnecessary surgery needs to be demonstrated by a randomized clinical trial.	Univ Siena, Policlin Le Scotte, Ist Sci Dermatol, Dept Dermatol, I-53100 Siena, Italy; Italian Canc League, Siena, Italy; Ist Dermopat Immacolata, Rome, Italy	Rubegni, P (reprint author), Univ Siena, Policlin Le Scotte, Ist Sci Dermatol, Dept Dermatol, Via Laterina 8, I-53100 Siena, Italy.	rubegni@unisi.it	Sera, Francesco/C-8176-2011				Andreassi L, 1999, ARCH DERMATOL, V135, P1459, DOI 10.1001/archderm.135.12.1459; Argenziano G, 1998, ARCH DERMATOL, V134, P1563, DOI 10.1001/archderm.134.12.1563; ASCIERTO PA, 2003, INT J ONCOL, V2, P1209; Bafounta ML, 2001, ARCH DERMATOL, V137, P1343; Bauer P, 2000, MELANOMA RES, V10, P345, DOI 10.1097/00008390-200008000-00005; Bellman R., 1961, ADAPTIVE CONTROL PRO; Binder M, 1998, MELANOMA RES, V8, P261, DOI 10.1097/00008390-199806000-00009; BINDER M, 1994, BRIT J DERMATOL, V130, P460, DOI 10.1111/j.1365-2133.1994.tb03378.x; BINDER M, 1995, ARCH DERMATOL, V131, P286, DOI 10.1001/archderm.131.3.286; Binder M, 2000, MELANOMA RES, V10, P556, DOI 10.1097/00008390-200012000-00007; Carli P, 1998, EUR J CANCER PREV, V7, P397, DOI 10.1097/00008469-199810000-00005; Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURLEY RK, 1989, BRIT MED J, V299, P16; DECOSTE SD, 1993, ARCH DERMATOL, V129, P57, DOI 10.1001/archderm.129.1.57; Dreiseitl S, 2001, J BIOMED INFORM, V34, P28, DOI 10.1006/jbin.2001.10004; DUVIVIER AWP, 1991, CLIN EXP DERMATOL, V16, P344, DOI 10.1111/j.1365-2230.1991.tb00397.x; ERCAL F, 1994, IEEE T BIO-MED ENG, V41, P837, DOI 10.1109/10.312091; FRIEDMAN RJ, 1985, CA-CANCER J CLIN, V35, P130, DOI 10.3322/canjclin.35.3.130; GREEN A, 1994, J AM ACAD DERMATOL, V31, P958; GRIN CM, 1990, ARCH DERMATOL, V126, P763, DOI 10.1001/archderm.126.6.763; Gutkowicz-Krusin D, 1997, SKIN RES TECHNOL, V3, P15, DOI 10.1111/j.1600-0846.1997.tb00154.x; HALL PN, 1995, BRIT J DERMATOL, V132, P325, DOI 10.1111/j.1365-2133.1995.tb08664.x; HEALSMITH MF, 1994, BRIT J DERMATOL, V130, P48, DOI 10.1111/j.1365-2133.1994.tb06881.x; KOH HK, 1990, CANCER, V65, P375, DOI 10.1002/1097-0142(19900115)65:2<375::AID-CNCR2820650233>3.0.CO;2-Z; MACKIE RM, 1990, BRIT MED J, V301, P1005; Mardia K. V., 1979, MULTIVARIATE ANAL, P521; MCGOVERN TW, 1992, J DERMATOL SURG ONC, V18, P22; Menzies SW, 1996, ARCH DERMATOL, V132, P1178, DOI 10.1001/archderm.132.10.1178; NACHBAR F, 1994, J AM ACAD DERMATOL, V30, P551; PEHAMBERGER H, 1993, J INVEST DERMATOL, V100, pS356, DOI 10.1038/jid.1993.63; Pizzichetta MA, 2001, ARCH DERMATOL, V137, P1376; Rigel DS, 2000, CA-CANCER J CLIN, V50, P215, DOI 10.3322/canjclin.50.4.215; Rubegni P, 2002, J INVEST DERMATOL, V119, P471, DOI 10.1046/j.1523-1747.2002.01835.x; Rubegni P, 2002, INT J CANCER, V101, P576, DOI 10.1002/ijc.10620; Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017; SCHINDEWOLF T, 1993, ANAL QUANT CYTOL, V15, P1; SEIDENARI S, 1999, MELANOMA RES, V9, P63; Seidenari S, 1999, MELANOMA RES, V9, P163, DOI 10.1097/00008390-199904000-00009; Sober Arthur J., 1994, Journal of Dermatology (Tokyo), V21, P885; SOYER H, 2001, ATLAS BASED CONSENSU; STANGANELLI I, 1995, J AM ACAD DERMATOL, V33, P584, DOI 10.1016/0190-9622(95)91275-4; STEINER A, 1987, ANTICANCER RES, V7, P433; STEINER A, 1987, J AM ACAD DERMATOL, V17, P584, DOI 10.1016/S0190-9622(87)70240-0; SWETS JA, 1992, EVALUATION DIAGNOSTI; Whited JD, 1998, JAMA-J AM MED ASSOC, V279, P696, DOI 10.1001/jama.279.9.696; HALL WH, 1992, JAMA-J AM MED ASSOC, V268, P1314	47	38	38	AMER ASSOC CANCER RESEARCH	PHILADELPHIA	615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA	1078-0432		CLIN CANCER RES	Clin. Cancer Res.	MAR 15	2004	10	6					1881	1886		10.1158/1078-0432.CCR-03-0039		6	Oncology	Oncology	804ZW	WOS:000220337600003	
J	Wyns, B; Boullart, L; Sette, S; Baeten, D; Hoffman, I; De Keyser, F				Wyns, B; Boullart, L; Sette, S; Baeten, D; Hoffman, I; De Keyser, F			Prediction of arthritis using a modified Kohonen mapping and case based reasoning	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						classification; neural network models; case based reasoning; threshold; self-organizing systems; medical applications	SELF-ORGANIZING MAP; RHEUMATOID-ARTHRITIS; DIAGNOSIS	Rheumatoid arthritis and spondyloarthropathy are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. In this paper we apply a topological mapping combined with a case based reasoning evaluation criterion to predict early arthritis. The first part presents a brief introduction to the problem and self-learning neural networks while the second part of this paper will apply this technique together with a case based reasoning evaluation criterion to diagnostic classification. Finally the paper shows that the Kohonen neural network achieves good performance that exceeds the results of other neural network approaches and decision trees. (C) 2004 Elsevier Ltd. All rights reserved.	State Univ Ghent, Dept Elect Energy Syst & Automat, B-9052 Zwijnaarde, Belgium; Hogesch W Vlaanderen, ICT, B-8500 Kortrijk, Belgium; State Univ Ghent Hosp, Dept Rheumatol, B-9000 Ghent, Belgium	Wyns, B (reprint author), State Univ Ghent, Dept Elect Energy Syst & Automat, Technol Pk 913, B-9052 Zwijnaarde, Belgium.	bart.wyns@ugent.be					Baeten D, 2000, ANN RHEUM DIS, V59, P945, DOI 10.1136/ard.59.12.945; Baeten D, 2001, ARTHRITIS RHEUM, V44, P2255, DOI 10.1002/1529-0131(200110)44:10<2255::AID-ART388>3.0.CO;2-#; Baeten D, 1999, CLIN RHEUMATOL, V18, P434, DOI 10.1007/s100670050134; Chen DR, 2000, ULTRASOUND MED BIOL, V26, P405, DOI 10.1016/S0301-5629(99)00156-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Henson DB, 1997, ARTIF INTELL MED, V10, P99, DOI 10.1016/S0933-3657(97)00388-6; Hrycej T., 1997, NEUROCONTROL IND CON; Kohonen T., 1989, SELF ORG ASS MEMORY; LOH WY, 2002, QUICK UNBIASED EFFIC; LOH WY, 1997, STAT SINICA, V10, P15; Markey MK, 2003, ARTIF INTELL MED, V27, P113, DOI 10.1016/S0933-3657(03)00003-4; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SETTE S, 1995, TEXT RES J, V65, P196, DOI 10.1177/004051759506500402; SIEBEN G, 1994, ACTA NEUROCHIR, V129, P193, DOI 10.1007/BF01406504; TROFESTAS SG, 1997, METHODS APPL INTELLI; VERCAUTEREN L, 1990, P INT NEUR NETW C PA, P387; ZILOUCHIAN A, 2000, INTELLIGENT CONTROL	17	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	MAR	2004	17	2					205	211		10.1016/j.engappai.2004.02.007		7	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	821BL	WOS:000221434400008	
J	Garcia-Gomez, JM; Vidal, U; Marti-Bonmati, L; Galant, J; Sans, N; Robles, M; Casacuberta, F				Garcia-Gomez, JM; Vidal, U; Marti-Bonmati, L; Galant, J; Sans, N; Robles, M; Casacuberta, F			Benign/malignant classifier of soft tissue tumors using MR imaging	MAGNETIC RESONANCE MATERIALS IN PHYSICS BIOLOGY AND MEDICINE			English	Article						magnetic resonance imaging; soft tissue tumor; pattern recognition; clinical decision support systems; artificial neural networks; support vector machine; K-Nearest neighbor	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORK; BREAST-CANCER; PREDICTION; MALIGNANCY; MICROCALCIFICATIONS	This article presents a pattern-recognition approach to the soft tissue tumors (STT) benign/ malignant character diagnosis using magnetic resonance (MR) imaging applied to a large multicenter database. Objective: To develop and test an automatic classifier of STT into benign or malignant by using classical MR imaging findings and epidemiological information. Materials and methods: A database of 430 patients (62% benign and 38% malignant) from several European multicenter registers. There were 61 different histologies (36 with benign and 25 with malignant nature). Three pattern-recognition methods (artificial neural networks, support vector machine, k-nearest neighbor) were applied to learn the discrimination between benignity and malignancy based on a defined MR imaging findings protocol. After the systems had learned by using training samples (with 302 cases), the clinical decision support system was tested in the diagnosis of 128 new STT cases. Results: An 88-92% efficacy was obtained in a not-viewed set of tumors using the pattern-recognition techniques. The best results were obtained with a back-propagation artificial neural network. Conclusion: Benign vs. malignant STT discrimination is accurate by using pattern-recognition methods based on classical MR image findings. This objective tool will assist radiologists in STT grading.	Hosp Univ Dr Peset, Serv Radiol, Valencia 46017, Spain; Univ Politecn Valencia, BET, E-46071 Valencia, Spain; Hosp San Juan Alicante, Serv Radiol, Alicante, Spain; CHU Purpan, Dept Radiol, Toulouse, France; Univ Politecn Valencia, DSIC, ITI, E-46071 Valencia, Spain	Garcia-Gomez, JM (reprint author), Hosp Univ Dr Peset, Serv Radiol, Avda Gaspar Aguilar 90, Valencia 46017, Spain.	Luis.Marti@uv.es					Abdolmaleki P, 1997, Radiat Med, V15, P283; Abdolmaleki P, 2001, CANCER LETT, V171, P183, DOI 10.1016/S0304-3835(01)00508-0; Baker JA, 1996, RADIOLOGY, V198, P131; Bazzani A, 2001, PHYS MED BIOL, V46, P1651, DOI 10.1088/0031-9155/46/6/305; Bishop C. M., 1995, NEURAL NETWORKS PATT; CHANG RF, 2003, ULTRASOUN MED BIOL, V10, P189; Chang RF, 2003, ULTRASOUND MED BIOL, V29, P679, DOI 10.1016/S0301-5629(02)00788-3; Chen DR, 2002, ULTRASOUND MED BIOL, V28, P1301, DOI 10.1016/S0301-5629(02)00620-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; De Schepper AM, 2000, EUR RADIOL, V10, P213, DOI 10.1007/s003300050037; Dhawan AP, 1996, IEEE T MED IMAGING, V15, P246, DOI 10.1109/42.500063; Duda R. O., 2001, PATTERN CLASSIFICATI; FLOYD CE, 1994, CANCER, V74, P2944, DOI 10.1002/1097-0142(19941201)74:11<2944::AID-CNCR2820741109>3.0.CO;2-F; Galant J, 2003, EUR RADIOL, V13, P337, DOI 10.1007/s0030-002-1463-6; GALANT J, 1998, THESIS U MH DEALICAN; GARCIAGOMEZ JM, 2002, P 19 ANN M EUR SOC M, P274; GURNEY JW, 1995, RADIOLOGY, V196, P823; JOACHIMS T, 2002, SVM LIGHT V4 00 SUPP; Lisboa PJG, 2002, NEURAL NETWORKS, V15, P11, DOI 10.1016/S0893-6080(01)00111-3; Liu HX, 2003, J CHEM INF COMP SCI, V43, P900, DOI 10.1021/ci0256438; Lu C, 2003, ARTIF INTELL MED, V28, P281, DOI 10.1016/S0933-3657(03)00051-4; MALDONADO JA, 2001, P 23 ANN ITN C IEEE; May DA, 1997, SKELETAL RADIOL, V26, P2; MOULTON JS, 1995, AM J ROENTGENOL, V164, P1191; Bosanquet N, 1999, LANCET, V353, P1381; Sahiner B, 1996, IEEE T MED IMAGING, V15, P598, DOI 10.1109/42.538937; Sboner A, 2003, ARTIF INTELL MED, V27, P29, DOI 10.1016/S0933-3657(02)00087-8; Segal NH, 2003, AM J PATHOL, V163, P691, DOI 10.1016/S0002-9440(10)63696-6; SHORTLIFFE E, 2000, MED INFORMATICS COMP; Underwood J, 2001, ST HEAL T, V84, P561; VANBEMMEL JH, 1997, HDB MED INFORMATICS, P239; VANDERLEI J, 1997, HDB MED INFORMATICS, P261; VIDAL C, 2002, P 9 C SOC ESP INF SA, P207; Weatherall P T, 1995, Magn Reson Imaging Clin N Am, V3, P669; Zell A., 1995, STUTTGART NEURAL NET	36	3	3	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0968-5243		MAGN RESON MATER PHY	Magn. Reson. Mat. Phys. Biol. Med.	MAR	2004	16	4					194	201		10.1007/s10334-003-0023-7		8	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	818BF	WOS:000221219900006	
J	Yager, RR				Yager, RR			Choquet aggregation using order inducing variables	INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS			English	Article						ordered aggregation; OWA operators; fusion; fuzzy sets; nearest neighbor methods	FUZZY MEASURES; OWA OPERATORS	We discuss the OWA and Choquet integral aggregation operators and point out the central role the ordering operation plays in these operators. We extend the capabilities of the Choquet integral aggregation by allowing the ordering to be induced by some values other then those being aggregated. This allows us to consider an induced Choquet Choquet integral aggregation operator. We look at the properties of this operator. We then look at its applications Among the applications considered are aggregations guided by linguistic and other ordinal structures. We look at the use of induced aggregation in nearest neighbor methods. We also consider the Choquet aggregation of complex objects such as matrices and vectors.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.	yager@panix.com	Yager, Ronald/A-2960-2013				Choquet G., 1953, ANN I FOURIER GRENOB, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NORMS NN PATTERN CLA; Denneberg D., 1994, NONADDITIVE MEASURE; Grabisch M., 1999, FUZZY MEASURES INTEG; Grabisch M, 1997, ORDERED WEIGHTED AVERAGING OPERATORS, P73; Mitchell HB, 2000, INT J INTELL SYST, V15, P317, DOI 10.1002/(SICI)1098-111X(200004)15:4<317::AID-INT4>3.0.CO;2-J; MUROFUSHI T, 1999, FUZZY MEASURES INTEG, P3; MUROFUSHI T, 1989, FUZZY SET SYST, V29, P201, DOI 10.1016/0165-0114(89)90194-2; Schaefer PA, 1999, INT J INTELL SYST, V14, P123, DOI 10.1002/(SICI)1098-111X(199902)14:2<123::AID-INT1>3.3.CO;2-5; SIGENO M, 1977, FUZZY AUTOMATA DECIS, P89; Yager R. R., 1997, ORDERED WEIGHTED AVE; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; Yager R.R., 1998, P FUZZ IEEE WORLD C, P123; YAGER RR, 2001, P ATL S COMP BIOL GE, P92; YAGER RR, 1997, INCULSION IMPORTANCE, P41; Yager RR, 1998, PROCEEDINGS OF THE IEEE/IAFE/INFORMS 1998 CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR FINANCIAL ENGINEERING (CIFER), P220, DOI 10.1109/CIFER.1998.690125; Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; YAGER RR, 1992, INT J MAN MACH STUD, V37, P103, DOI 10.1016/0020-7373(92)90093-Z; Yager RR, 2002, IEEE T SYST MAN CY B, V32, P512, DOI 10.1109/TSMCB.2002.1018770; Yager RR, 2000, IEEE T FUZZY SYST, V8, P453, DOI 10.1109/91.868951; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904; ZADEH LA, 1999, P EUROFUSE SIC C 199, P1	25	33	34	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-4885		INT J UNCERTAIN FUZZ	Int. J. Uncertainty Fuzziness Knowl.-Based Syst.	FEB	2004	12	1					69	88		10.1142/S0218488504002667		20	Computer Science, Artificial Intelligence	Computer Science	811YL	WOS:000220807100007	
J	Lee, Y; Wahba, G; Ackerman, SA				Lee, Y; Wahba, G; Ackerman, SA			Cloud classification of satellite radiance data by multicategory support vector machines	JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY			English	Article							MODIS	Two-category support vector machines (SVMs) have become very popular in the machine learning community for classification problems and have recently been shown to have good optimality properties for classification purposes. Treating multicategory problems as a series of binary problems is common in the SVM paradigm. However, this approach may fail under a variety of circumstances. The multicategory support vector machine (MSVM), which extends the binary SVM to the multicategory case in a symmetric way, and has good theoretical properties, has recently been proposed. The proposed MSVM in addition provides a unifying framework when there are either equal or unequal misclassification costs, and when there is a possibly nonrepresentative training set. Illustrated herein is the potential of the MSVM as an efficient cloud detection and classification algorithm for use in Earth Observing System models, which require knowledge of whether or not a radiance profile is cloud free. If the profile is not cloud free, it is valuable to have information concerning the type of cloud, for example, ice or water. The MSVM has been applied to simulated MODIS channel data to classify the radiance profiles as coming from clear sky, water clouds, or ice clouds, and the results are promising. It can be seen in simple examples, and application to Moderate Resolution Imaging Spectroradiometer (MODIS) observations, that the method is an improvement over channel-by-channel partitioning. It is believed that the MSVM will be a very useful tool for classification problems in atmospheric sciences.	Univ Wisconsin, Dept Stat, Madison, WI 53706 USA; Ohio State Univ, Dept Stat, Columbus, OH 43210 USA; Univ Wisconsin, Dept Atmospher & Ocean Sci, Madison, WI USA	Wahba, G (reprint author), Univ Wisconsin, Dept Stat, 1210 W Dayton St, Madison, WI 53706 USA.	wahba@stat.wisc.edu					Ackerman SA, 1998, J GEOPHYS RES-ATMOS, V103, P32141, DOI 10.1029/1998JD200032; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Ferris MC, 1999, COMPUT OPTIM APPL, V12, P207, DOI 10.1023/A:1008636318275; Heidinger AK, 2002, J ATMOS OCEAN TECH, V19, P586, DOI 10.1175/1520-0426(2002)019<0586:UMTECC>2.0.CO;2; Key JR, 1998, COMPUT GEOSCI, V24, P443, DOI 10.1016/S0098-3004(97)00130-1; KIMELDOR.G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Lee Y, 2001, COMPUTING SCI STAT, V33, P498; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; LEE Y, 2002, 1062 U WISC DEP STAT; LEE Y, 2002, 1064 U WISC DEP STAT; Lin Y., 1999, 1014 U WISC DEP STAT; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Lin Y, 2002, DATA MIN KNOWL DISC, V6, P259, DOI 10.1023/A:1015469627679; Mangasarian O.L., 1994, CLASSICS APPL MATH, V10; OSULLIVAN F, 1986, J AM STAT ASSOC, V81, P96, DOI 10.2307/2287973; Platnick S, 2003, IEEE T GEOSCI REMOTE, V41, P459, DOI 10.1109/TGRS.2002.808301; Scholkopf B, 2002, LEARNING KERNELS SUP; Scholkopf B., 1999, ADV KERNEL METHODS S; STRABALA KI, 1994, J APPL METEOROL, V33, P212, DOI 10.1175/1520-0450(1994)033<0212:CPIFD>2.0.CO;2; Vapnik V.N., 1998, STAT LEARNING THEORY; WAHBA G, 1994, ADV NEURAL INFORMATI, V6, P415; Wahba G, 1995, ANN STAT, V23, P1865; Wahba G, 2002, P NATL ACAD SCI USA, V99, P16524, DOI 10.1073/pnas.242574899; Wahba G., 1990, CBMS NSF REGIONAL C, V59; Wahba G, 1999, ADVANCES IN KERNEL METHODS, P69; Wahba G, 2000, ADV NEUR IN, P297	27	20	21	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	0739-0572		J ATMOS OCEAN TECH	J. Atmos. Ocean. Technol.	FEB	2004	21	2					159	169		10.1175/1520-0426(2004)021<0159:CCOSRD>2.0.CO;2		11	Engineering, Ocean; Meteorology & Atmospheric Sciences	Engineering; Meteorology & Atmospheric Sciences	780PT	WOS:000189391100002	
J	Teoh, A; Samad, SA; Hussain, A				Teoh, A; Samad, SA; Hussain, A			Nearest neighbourhood classifiers in a bimodal biometric verification system fusion decision scheme	JOURNAL OF RESEARCH AND PRACTICE IN INFORMATION TECHNOLOGY			English	Article						biometrics; face verification; speaker verification; k-NN classifiers	SPEAKER RECOGNITION; IDENTIFICATION; FACE; AUTHENTICATION; CLASSIFICATION; ALGORITHM	Identity verification systems that use a mono modal biometrics always have to contend with sensor noise and limitations of feature extractor and matching. However combining information from different biometrics modalities may well provide higher and more consistent performance levels. A robust yet simple scheme can fuse the decisions produced by the individual biometric experts. In this paper, k-Nearest Neighbourhood (k-NN) based classifiers are adopted in the decision fusion module for the face and speech experts. k-NN rule owes much of its popularity in pattern recognition community to its simplicity and good performance in practical application. Besides that, k-NN may also provide a ternary decision scheme which is rarely found in other classifiers. The fusion decision schemes considered are voting-, modified- and theoretic evidence of k-NN classifiers based on Dempster-Shafer theory. The performances of these k-NN classifiers are evaluated in both balanced and unbalanced conditions and compared with other classification approaches such as sum rule, voting techniques and Multilayer Perceptron on a bimodal database.	Multimedia Univ, FIST, Melaka 75450, Malaysia; Univ Kebangsaan Malaysia, Fac Engn, Elect Elect & Syst Engn Dept, Bangi, Malaysia	Teoh, A (reprint author), Multimedia Univ, FIST, Melaka 75450, Malaysia.	bjteoh@mmu.edu.my; salina@eng.ukm.my; aini@eng.ukm.my	Teoh, Andrew Beng Jin/F-4422-2010; Hussain, Aini/G-4074-2011				BIGUN ES, 1997, P 1 INT C AUD VID BA, P327; BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560; Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714; CHOUDHURY T, 1999, 2 INT C AUD BIOM PER, P176; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dieckmann U, 1997, PATTERN RECOGN LETT, V18, P827, DOI 10.1016/S0167-8655(97)00063-9; Duc B, 1997, LECT NOTES COMPUT SC, V1206, P311; Duda R., 1973, PATTERN CLASSIFICATI; HELLMAN MF, 1970, IEEE T SYST MAN CYB, V6, P155; Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Martin Rainer, 1994, P 7 EUR SIGN PROC C, P1182; MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786; Pigeon S, 1998, P SOC PHOTO-OPT INS, V3314, P166, DOI 10.1117/12.304683; Rabiner L., 1993, FUNDAMENTALS SPEECH; ROLI F, 2002, P 3 INT WORKSH MCS 2; Ross A., 2001, P 3 INT C AUD VID BA, P354; SAKOE H, 1971, P 7 INT C AC, V20, pC13; Samad S. A., 2001, Proceedings of the Sixth International Symposium on Signal Processing and its Applications (Cat.No.01EX467), DOI 10.1109/ISSPA.2001.950224; SAMAD SA, 2001, P INT C INF TECHN MU; SANDERSON C, 2001, DIGIT DATABASE 1 0 M; Shafer G., 1976, MATH THEORY EVIDENCE; Turk L, 1999, AEROSP SCI TECHNOL, V3, P71, DOI 10.1016/S1270-9638(99)80031-5; VERLINDE P, 1999, 2 INT C AUD VID BAS; Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805; WILPON JG, 1985, IEEE T ACOUST SPEECH, V33, P587, DOI 10.1109/TASSP.1985.1164581; YACOUB SB, 1999, P 2 INT C AUD VID BA, P25; Zilovic MS, 1997, IEEE T SPEECH AUDI P, V5, P84, DOI 10.1109/89.554274; *OL RES LAB, 2000, DAT FAC; *OTAGO, 2000, OT SPEECH CORP	31	6	6	AUSTRALIAN COMPUTER SOC INC	SYDNEY	PO BOX Q534, QVB POST OFFICE, SYDNEY, NSW 1230, AUSTRALIA	1443-458X		J RES PRACT INF TECH	J. Res. Pract. Inf. Technol.	FEB	2004	36	1					47	62				16	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	806VE	WOS:000220460600005	
J	Li, JY; Dong, GZ; Ramamohanarao, K; Wong, LS				Li, JY; Dong, GZ; Ramamohanarao, K; Wong, LS			DeEPs: A new instance-based lazy discovery and classification system	MACHINE LEARNING			English	Article						instance-based; emerging patterns; borders; lazy learning; classification	LEARNING ALGORITHMS; NEAREST-NEIGHBOR; PATTERNS	Distance is widely used in most lazy classification systems. Rather than using distance, we make use of the frequency of an instance's subsets of features and the frequency-change rate of the subsets among training classes to perform both knowledge discovery and classification. We name the system DeEPs. Whenever an instance is considered, DeEPs can efficiently discover those patterns contained in the instance which sharply differentiate the training classes from one to another. DeEPs can also predict a class label for the instance by compactly summarizing the frequencies of the discovered patterns based on a view to collectively maximize the discriminating power of the patterns. Many experimental results are used to evaluate the system, showing that the patterns are comprehensible and that DeEPs is accurate and scalable.	Inst Infocomm Res, Singapore 119613, Singapore; Wright State Univ, Dept CSE, Dayton, OH 45435 USA; Univ Melbourne, Dept CSSE, Parkville, Vic 3052, Australia	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; gdong@cs.wright.edu; rao@cs.mu.oz.au; limsoon@i2r.a-star.edu.sg	Wong, Limsoon/E-5033-2010				Aha D.W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bayardo Jr R., 1999, P 5 ACM SIGKDD INT C, P145, DOI 10.1145/312129.312219; Blake C.L., 1998, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B., 1991, NEAREST NEIGHBOR PAT; Datta P., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; DATTA P, 1997, MACH LEARN, P75; Devroye L, 1996, PROBABILISTIC THEORY; Domingos P, 1996, MACH LEARN, V24, P141; Dong G., 1998, P 2 PAC AS C KNOWL D, P72; Dong G., 1999, P 2 INT C DISC SCI, P30; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; HILDERMAN RJ, 2001, P 5 PAC AS C KNOWL D, P247; HIRSH H, 1994, MACH LEARN, V17, P5, DOI 10.1007/BF00993863; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; Iba W., 1992, P 10 NAT C ART INT, P223; KEUNG CK, 2000, P 4 PAC AS C KNOWL D, P142; Klemettinen M., 1994, P 3 INT C INF KNOWL, P401, DOI 10.1145/191246.191314; KOHAVI R, 1994, TOOLS ARTIFICIAL INT, P740; KUBAT M, 2000, MACH LEARN, P503; Langley P., 1993, P 13 INT JOINT C ART, P889; LI J, 2001, THESIS U MELBOURNE; LI J, 2001, 5 PAC AS C KNOWL DIS, P455; Li J, 2000, P 4 EUR C PRINC PRAC, P191; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Liu B, 1998, P 4 INT C KNOWL DISC, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Mitchell T. M., 1977, P 5 INT JOINT C ART, P305; MITCHELL TM, 1982, ARTIF INTELL, V18, P203, DOI 10.1016/0004-3702(82)90040-6; Padmanabhan B., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Sahar S, 1999, P 5 ACM SIGKDD INT C, P332, DOI 10.1145/312129.312272; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; Sebag M., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96); Silberschatz A, 1996, IEEE T KNOWL DATA EN, V8, P970, DOI 10.1109/69.553165; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WILSON DR, 1997, MACH LEARN, P403; ZHANG JP, 1992, MACHINE LEARNING /, P470	48	39	42	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB	2004	54	2					99	124		10.1023/B:MACH.0000011804.08528.7d		26	Computer Science, Artificial Intelligence	Computer Science	762XB	WOS:000188006900001	
J	Lindenbaum, M; Markovitch, S; Rusakov, D				Lindenbaum, M; Markovitch, S; Rusakov, D			Selective sampling for nearest neighbor classifiers	MACHINE LEARNING			English	Article						active learning; selective sampling; nearest neighbor; random field	LEARNING ALGORITHMS; CLASSIFICATION	Most existing inductive learning algorithms work under the assumption that their training examples are already tagged. There are domains, however, where the tagging procedure requires significant computation resources or manual labor. In such cases, it may be beneficial for the learner to be active, intelligently selecting the examples for labeling with the goal of reducing the labeling cost. In this paper we present LSS-a lookahead algorithm for selective sampling of examples for nearest neighbor classifiers. The algorithm is looking for the example with the highest utility, taking its effect on the resulting classifier into account. Computing the expected utility of an example requires estimating the probability of its possible labels. We propose to use the random field model for this estimation. The LSS algorithm was evaluated empirically on seven real and artificial data sets, and its performance was compared to other selective sampling algorithms. The experiments show that the proposed algorithm outperforms other methods in terms of average error rate and stability.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Lindenbaum, M (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	mic@cs.technion.ac.il; shaulm@cs.technion.ac.il; rusakov@cs.technion.ac.il					Adler R, 1981, GEOMETRY RANDOM FIEL; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116828; Blake CL, 1998, UCI REPOSITORY MACHI; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COHN DA, 1995, ADV NEURAL INFORM PR, V7, P705; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagan I, 1995, P 12 INT C MACH LEAR, P150; DAVIS DT, 1992, P IJCNN, V1, P676, DOI 10.1109/IJCNN.1992.287109; DeGroot MH, 1986, PROBABILITY STAT; Duda R., 1973, PATTERN CLASSIFICATI; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Fedorov V.V., 1972, THEORY OPTIMAL EXPT; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; HASENJAGER M, 1996, LECT NOTES COMPUTER, V1112, P501; Hasenjager M, 1998, NEURAL PROCESS LETT, V7, P107, DOI 10.1023/A:1009688513124; Lang K.J., 1988, P 1988 CONN MOD SUMM, P52; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Lindenbaum M., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); MacKay D., 1998, NATO ASI SERIES F, V168, P133; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; MOORE A, 1998, P 15 INT C MACH LEAR, P386; Papoulis A., 1991, PROBABILITY RANDOM V; RAYCHAUDHURI T, 1995, IEEE ICNN, V3, P1338; Russell SJ, 1995, ARTIFICIAL INTELLIGE; SALZBERG S., 1995, P 14 INT JOINT C ART, P1025; SEUNG HS, 1992, P 5 ANN ACM WORKSH C; Smyth B, 1999, LECT NOTES ARTIF INT, V1650, P329; TAN M, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P854; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wong E., 1985, STOCHASTIC PROCESSES; Zhang JP, 1997, ARTIF INTELL REV, V11, P175, DOI 10.1023/A:1006500703083	34	48	51	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	FEB	2004	54	2					125	152		10.1023/B:MACH.0000011805.60520.fe		28	Computer Science, Artificial Intelligence	Computer Science	762XB	WOS:000188006900002	
J	Podsiadlo, P; Stachowiak, GW				Podsiadlo, P; Stachowiak, GW			Classification of tribological surfaces without surface parameters	TRIBOLOGY LETTERS			English	Article						classification; dissimilarity measure; tribological surfaces	SUPPORT VECTOR MACHINES; PATTERN-CLASSIFICATION; DISTANCE; RECOGNITION; ROUGHNESS; NETWORKS; WEAR	Quantitative measures are obtained from images of tribological surfaces. Based on these data, decisions are made regarding manufacturing and maintenance processes, machine-condition monitoring and failure analysis of engineering components. These decisions are often guided by an automated pattern recognition system. Components of this system are: surface topography data acquisition, surface characterization, surface classification and performance evaluation. The characterization and classification of tribological surfaces are major challenges that make the development of a reliable pattern-recognition system difficult. The reasons are that: (i) tribological surfaces often exhibit a non-stationary and multiscale nature, while most surface characterization methods currently used work well with surface data exhibiting a stationary random process, (ii) changes in topography that might occur between the interacting surfaces usually need to be known in advance, and (iii) the selection of surface parameters that separate different classes of surfaces is usually time-consuming and cumbersome. Because of these difficulties, characterization and classification methods which do not use surface parameters have been developed. In the classification methods, a measure of dissimilarity (e.g., Euclidean distance) calculated between a surface to be classified and already classified surfaces was used, instead of surface parameters. The unclassified surface was assigned to the class ( of classified surfaces) with the lowest value of dissimilarity measure. The suitability of different classifiers; such as k-nearest neighbour classifier, linear-discriminant-analysis based classifiers and different dissimilarity measures; for the classification of tribological surface topographies ( without the need for surface parameters) is investigated in this paper. Recent developments in this area, i. e., a fractal measure and a hybrid fractal-wavelet measure, are also discussed. The most suitable method for the classification of tribological surfaces has been selected.	Univ Western Australia, Sch Mech & Mat Engn, Tribol Lab, Crawley, WA 6009, Australia	Stachowiak, GW (reprint author), Univ Western Australia, Sch Mech & Mat Engn, Tribol Lab, Crawley, WA 6009, Australia.						ARKADEV AG, 1996, COMPUTERS PATTERN RE; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COCHET W, 1997, OPER RES, V45, P213; Coquin D, 2001, PATTERN RECOGN LETT, V22, P1483, DOI 10.1016/S0167-8655(01)00104-0; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Di Gesu V, 1999, PATTERN RECOGN LETT, V20, P207, DOI 10.1016/S0167-8655(98)00115-9; DONG WP, 2000, DEV METHODS CHARACTE; Duin RPW, 1998, KYBERNETIKA, V34, P399; Duin RPW, 1999, PATTERN RECOGN LETT, V20, P1175, DOI 10.1016/S0167-8655(99)00085-9; Fisher Y., 1995, FRACTAL IMAGE COMPRE; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028; Niu YM, 1998, J MANUF SCI E-T ASME, V120, P807, DOI 10.1115/1.2830224; Pekalksa E., 2001, J MACHINE LEARNING R, V2, P175; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Podsiadlo P, 2002, TRIBOL LETT, V13, P241, DOI 10.1023/A:1021059108478; PODSIADLO P, 2000, TRIBOLOGY SERIES, V38, P546; PODSIADLO P, 2001, TRIBOLOGY SERIES, V39, P697; PODSIADLO P, 2003, IN PRESS WEAR; RAMAMOORTHY B, 1993, WEAR, V167, P155, DOI 10.1016/0043-1648(93)90320-L; Rosenfeld A, 2000, INT J IMAG SYST TECH, V11, P101, DOI 10.1002/1098-1098(2000)11:2<101::AID-IMA1>3.0.CO;2-J; Stachowiak GB, 2001, WEAR, V249, P201, DOI 10.1016/S0043-1648(01)00557-9; Stachowiak GW, 2001, WEAR, V249, P194, DOI 10.1016/S0043-1648(01)00562-2; Subrahmanyam M, 1997, TRIBOL INT, V30, P739, DOI 10.1016/S0301-679X(97)00056-X; Tan T, 2002, PATTERN RECOGN, V35, P1371, DOI 10.1016/S0031-3203(01)00125-X; Thomas TR, 1998, INT J MACH TOOL MANU, V38, P405, DOI 10.1016/S0890-6955(97)00084-9; Tsai DM, 1999, PATTERN RECOGN, V32, P389, DOI 10.1016/S0031-3203(98)00077-6; Webb A.R., 1999, STAT PATTERN RECOGNI; Wu YQ, 2002, PATTERN RECOGN, V35, P2311, DOI 10.1016/S0031-3203(01)00132-7	30	6	6	KLUWER ACADEMIC/PLENUM PUBL	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1023-8883		TRIBOL LETT	Tribol. Lett.	FEB	2004	16	1-2					163	171		10.1023/B:TRIL.0000009726.17576.b5		9	Engineering, Chemical; Engineering, Mechanical	Engineering	756ZU	WOS:000187516300019	
J	Liu, WX; Zheng, NN				Liu, WX; Zheng, NN			Learning sparse features for classification by mixture models	PATTERN RECOGNITION LETTERS			English	Article						non-negative matrix factorization; classification; mixture models; sparse features; Lp norm	MATRIX FACTORIZATION; RECOGNITION	Non-negative matrix factorization (NMF) can discover sparse features for classification via mixture models and the sparseness of features controls the learning rate of the basis function parameters. But the original NMF in which the basis vectors are unit ones in L-1 norm, does not increase the sparseness of learned features. This paper generalizes NMF to L-p-NMF where the basis vectors are unit ones in L-p norm. Experiments demonstrate how p affects the sparseness of learned features and the final classification accuracy. And the results show that L-2-NMF is superior one for practical implementation. (C) 2003 Elsevier B.V. All rights reserved.	Xian Jiaotong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China	Liu, WX (reprint author), Xian Jiaotong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; LEE DD, 2001, ADV NEURAL INFORAMAT, V13; Lee DD, 1999, NATURE, V401, P788; LI SZ, 2001, P IEEE INT C COMP VI; LIU WG, 2002, EXISTING NEW ALGORIT; McLachlan G. J., 1988, MIXTURE MODELS INFER; McLachlan GJ, 2000, FINITE MIXTURE MODEL; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; SAUL LK, 2002, ADV NEURAL INFORMATI, V14; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; *MIT CTR BIOL COMP, CBCL FAC DAT	13	12	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 19	2004	25	2					155	161		10.1016/j.patrec.2003.09.007		7	Computer Science, Artificial Intelligence	Computer Science	759CD	WOS:000187720000002	
J	Belacel, N; Boulassel, MR				Belacel, N; Boulassel, MR			Multicriteria fuzzy classification procedure PROCFTN: methodology and medical application	FUZZY SETS AND SYSTEMS			English	Article						multicriteria decision aid; classification; fuzzy sets; fuzzy binary relations; scoring function; astrocytic tumour; medical diagnosis	ASSIGNMENT METHOD; DIAGNOSIS; CRITERIA	In this paper, we introduce a new classification procedure for assigning objects to predefined classes, named PROCFTN. This procedure is based on a fuzzy scoring function for choosing a subset of prototypes, which represent the closest resemblance with an object to be assigned. It then applies the majority-voting rule to assign an object to a class. We also present a medical application of this procedure as an aid to assist the diagnosis of central nervous system tumours. The results are compared with those obtained by other classification methods, reported on the same data set, including decision tree, production rules, neural network, k nearest neighbor, multilayer perceptron and logistic regression. Our results are very encouraging and show that the multicriteria decision analysis approach can be successfully used to help medical diagnosis. Crown Copyright (C) 2003 Published by Elsevier B.V. All rights reserved.	Natl Res Council Canada, Inst Informat Technol E Business, E Hlth Grp, St John, NB E2L 2Z6, Canada; McGill Univ, Montreal Chest Inst, Immunodeficiency Serv, Montreal, PQ H3A 2T5, Canada	Belacel, N (reprint author), Natl Res Council Canada, Inst Informat Technol E Business, E Hlth Grp, POB 69000,127 Carleton St, St John, NB E2L 2Z6, Canada.	nabil.belacel@nrc-cnrc.gc.ca; rachid.boulasse@muhc.mcgill.ca					BANERJEE A, 1993, FUZZY SETS SYSTEMS, V53, P295; BARRETT CR, 1990, FUZZY SET SYST, V34, P197, DOI 10.1016/0165-0114(90)90159-4; BARTELS PH, 1989, ANAL QUANT CYTOL, V11, P1; BELACEL N, 1999, INNOV TECH BIOL MED, V20, P239; Belacel N, 2000, EUR J OPER RES, V125, P175, DOI 10.1016/S0377-2217(99)00192-7; Belacel N, 2001, COMPUT METH PROG BIO, V64, P145, DOI 10.1016/S0169-2607(00)00100-0; BELACEL N, 1999, THESIS FREE U BRUSSE; Belacel N, 2001, ARTIF INTELL MED, V21, P201, DOI 10.1016/S0933-3657(00)00086-5; BLACK PM, 1991, NEW ENGL J MED, V324, P1555, DOI 10.1056/NEJM199105303242205; BOUYSSOU D, 1991, P INT WORKSH MULT DE, P16; BOUYSSOU D, 1992, MULTIPLE CRITERIA DE, P93; BRANS JP, 1985, MANAGE SCI, V31, P647, DOI 10.1287/mnsc.31.6.647; BURGER PC, 1985, CANCER, V56, P1106, DOI 10.1002/1097-0142(19850901)56:5<1106::AID-CNCR2820560525>3.0.CO;2-2; CHING JY, 1995, IEEE T PATTERN ANAL, V17, P641, DOI 10.1109/34.391407; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1991, NEAREST NEIGHBOUR NN; DECAESTECKER C, 1997, THESIS FREE U BRUSSE; DECAESTECKER C, 1995, J NEUROPATH EXP NEUR, V54, P371, DOI 10.1097/00005072-199505000-00010; FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007; FODOR J, 1998, USE FUZZY PREFERENCE, P69; Fodor J., 1994, FUZZY PREFERENCE MOD; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; GRECO S, 1999, ADV MULTIPLE CRITERI; JELONEK J, 1994, P 1 NAT C NEUR NETW, P268; Kandel E. R., 1991, PRINCIPLES NEURAL SC; Kleihues P, 1993, HISTOLOGICAL TYPING; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Orlovsky S. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90001-5; PERNY P, 1992, FUZZY SET SYST, V49, P33, DOI 10.1016/0165-0114(92)90108-G; PERNY P, 1992, THESIS PARIS DAUPHIN; Perny P, 1998, ANN OPER RES, V80, P137, DOI 10.1023/A:1018907729570; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROUBENS M, 1989, EUR J OPER RES, V40, P309, DOI 10.1016/0377-2217(89)90423-2; Roy B., 1996, MULTICRITERIA METHOD; VINCKE P., 1992, MULTICRITERIA DECISI; WEI Y, 1992, THESIS PARIS DAUPHIN; WEISS SM, 1991, COMPUTER SYSTEMS THA	37	15	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JAN 16	2004	141	2					203	217		10.1016/S0165-0114(03)00022-8		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	761NJ	WOS:000187914600003	
J	Devillez, A				Devillez, A			Four fuzzy supervised classification methods for discriminating classes of non-convex shape	FUZZY SETS AND SYSTEMS			English	Article						classes of non-convex shape; fuzzy classification; fuzzy logic; possibility theory; supervised classification	PATTERN-CLASSIFICATION; RECOGNITION; ALGORITHM; RULES	Our work deals with modelling and optimising industrial processes such as metal cutting with high-speed machining. In this field we have chosen to use fuzzy supervised classification methods in order to design a diagnosis system or a process-monitoring module. The problem, we currently meet, concerns the shape of the classes, we generally obtain. These shapes are often non-convex and non-separable by a hyperplane. For these reasons, we focus on fuzzy supervised classification methods in order to discriminate these classes. The choice of a method is not obvious and we perform a comparative study. The two classical methods tested were the fuzzy K-nearest-neighbours method and a method based on distributed fuzzy rules. Furthermore, we propose two adaptations of the fuzzy pattern matching algorithm called fuzzy pattern matching with exponential function and fuzzy pattern matching multidensity. After some refresher on supervised classification, the four tested methods are detailed and compared according to the following criteria: quality of the discrimination, computation time and ability to decide. The response of each classifier is illustrated by membership level curves and the quality of diagnosis is studied by the introduction of membership and ambiguity rejects. (C) 2003 Elsevier B.V. All rights reserved.	Univ Metz, LPMM, CNRS,UMR 7554, Inst Super Genie Mecan & Prod, F-57045 Metz 1, France	Devillez, A (reprint author), Univ Metz, LPMM, CNRS,UMR 7554, Inst Super Genie Mecan & Prod, Ile Saulcy, F-57045 Metz 1, France.	deviliez@lpmm.univ-metz.fr					Baldwin JF, 1997, INT J INTELL SYST, V12, P523, DOI 10.1002/(SICI)1098-111X(199707)12:7<523::AID-INT3>3.0.CO;2-N; Baldwin JF, 1999, INT J APPROX REASON, V22, P109, DOI 10.1016/S0888-613X(99)00016-X; BELLOIR F, 1999, THESIS U REIMS CHAMP; Bezdek J., 1981, PATTERN RECOGNITION; Bezdek JC, 1991, FUZZY MODELS PATTERN; Billaudel P, 1999, INT J APPROX REASON, V20, P1; BREHELIN L, 1995, ETUDE TAUX ERREUR BA; BREIMAN L, 1984, CLASSIFICATION REGRE, P43; Broomhead D. S., 1988, Complex Systems, V2; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVILLEZ A, 2002, WSEAS T CIRCUITS, V1, P94; DEVILLEZ A, 1999, THESIS U REIMS CHAMP; DEVILLEZ A, 1998, CESA 98 IEEE SYSTEMS, V4, P902; DEVILLEZ A, 1999, MATH INFORM SCI HUM, V147, P71; DUBOIS D, 1988, FUZZY SET SYST, V28, P313, DOI 10.1016/0165-0114(88)90038-3; Dubois D., 1987, THEORIE POSSIBILITES; Dubuisson B, 1990, DIAGNOSTIC RECONNAIS; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; FRELICOT C, 1995, P EUFIT 95 AACH GERM; FRELICOT C, 1993, 12 WORLD C INT FED A; Gascuel O, 1998, INT J PATTERN RECOGN, V12, P517, DOI 10.1142/S0218001498000336; GRABISCH M, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P47, DOI 10.1109/FUZZY.1992.258678; Grabisch M, 1996, EUR J OPER RES, V89, P445, DOI 10.1016/0377-2217(95)00176-X; GRABISCH M, 1995, INT JOINT C 4 IEEE I, P145; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; ISHIBUCHI H, 1993, FUZZY SET SYST, V59, P295, DOI 10.1016/0165-0114(93)90474-V; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; Janikow CZ, 1996, INFORM SCIENCES, V89, P275, DOI 10.1016/0020-0255(95)00239-1; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN F, 1998, THESIS U REIMS CHAMP; Masson M.-H., 1996, RAIRO-APII-JESA Journal Europeen des Systemes Automatises, V30; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; SHANAHAN JG, 2000, SOFT COMPUTING KNOWL; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; Zadeh L.A., 1965, FUZZY SETS INFORM CO, P338, DOI DOI 10.1016/S0019-9958(65)90241-X	37	5	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JAN 16	2004	141	2					219	240		10.1016/S0165-0114(03)00265-3		22	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	761NJ	WOS:000187914600004	
J	Karacali, B; Ramanath, R; Snyder, WE				Karacali, B; Ramanath, R; Snyder, WE			A comparative analysis of structural risk minimization by support vector machines and nearest neighbor rule	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbor; structural risk minimization; support vector machines; kernel operator; prototype selection	CLASSIFICATION; ALGORITHMS; SEARCH	Support vector machines (SVMs) are by far the most sophisticated and powerful classifiers available today. However, this robustness and novelty in approach come at a large computational cost. On the other hand, nearest neighbor (NN) classifiers provide a simple yet robust approach that is guaranteed to converge to a result. In this paper, we present a technique that combines these two classifiers by adopting a NN rule-based structural risk minimization classifier. Using synthetic and real data, the classification technique is shown to be more robust to kernel conditions with a significantly lower computational cost than conventional SVMs. Consequently, the proposed method provides a powerful alternative to SVMs in applications where computation time and accuracy are of prime importance. Experimental results indicate that the NNSRM formulation is not only computationally less expensive, but also much more robust to varying data representations than SVMs. (C) 2003 Elsevier B.V. All rights reserved.	N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA; Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA	Ramanath, R (reprint author), N Carolina State Univ, Dept Elect & Comp Engn, Box 7911, Raleigh, NC 27695 USA.						BHATTACKARYA B, 1998, P IEEE INT C PATT RE, V1, P238, DOI 10.1109/ICPR.1998.711125; Blake CL, 1998, UCI REPOSITORY MACHI; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; CHIDANANDAGOWDA K, 1979, IEEE T INFORM THEORY, V25, P488; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Devijver P. A., 1982, PATTERN RECOGNITION; FARACHCOLTON M, 1999, 40 ANN S FDN COMP SC; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Joachims T., 1999, ADV KERNEL METHODS S; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Osuna E., 1997, P COMP VIS PATT REC; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Scholkopf B., 2000, ADV NEURAL INFORM PR, V13, P301; Scholkopf B., 1999, ADV KERNEL METHODS S; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VAPNIK V, 1997, ADV NEURAL INFORMATI, V9; Vapnik V., 1998, ADAPTIVE LEARNING SY; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yu K, 2002, NEURAL PROCESS LETT, V15, P147, DOI 10.1023/A:1015244902967	23	8	9	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 5	2004	25	1					63	71		10.1016/j.patrec.2003.09.002		9	Computer Science, Artificial Intelligence	Computer Science	757GN	WOS:000187554800006	
S	Quang, LS; Bao, HT		Dai, H; Srikant, R; Zhang, C		Quang, LS; Bao, HT			A conditional probability distribution-based dissimilarity measure for categorial data	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific/Asia Conference on Advances in Knowledge Discovery and Data Mining	MAY 26-28, 2004	Sydney, AUSTRALIA	NICIA, SAS, Univ Technol Sydney, Deakin Univ		dissimilarity measures; categorical data; conditional probability; hypothesis testing		Measuring the similarity between objects described by categorical attributes is a difficult task because no relations between categorical values can be mathematically specified or easily established. In the literature, most similarity (dissimilarity) measures for categorical data consider the similarity of value pairs by considering whether or not these two values are identical. In these methods, the similarity (dissimilarity) of a non-identical value pair is simply considered 0 (1). In this paper, we introduce a dissimilarity measure for categorical data by imposing association relations between non-identical value pairs of an attribute based on their relations with other attributes. The key idea is to measure the similarity between two values of a categorical attribute by the similarities of the conditional probability distributions of other attributes conditioned on these two values. Experiments with a nearest neighbor algorithm demonstrate the merits of our proposal in real-life data sets.	Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan	Quang, LS (reprint author), Japan Adv Inst Sci & Technol, Sch Knowledge Sci, Tatsunokuchi, Ishikawa 9231292, Japan.	quag@jaist.ac.jp; bao@jaist.ac.jp					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALBERT ML, 1983, QUANTITATIVE APPL SO, V32; BATAGELJ V, 1995, J CLASSIFICATION, V12; BAULIEU FB, 1989, J CLASSIF, P233; BLAKE CL, 1998, REPOSITORY MACHNINE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; GOWER JC, 1986, J CLASSIF, P5; HUANG Z, 1988, DATA MIN KNOWL DISC, V2, P283; HUBALEK Z, 1982, BIOL REV, V57, P669, DOI 10.1111/j.1469-185X.1982.tb00376.x; KAUFMANN L, 1987, STAT DATA ANAL BASED, V405, P87; KULLBACK S, 1959, INFORMATION THEORY S; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; MacQueen JB, 1967, P 5 BERK S MATH STAT, P281; NENE SA, 1997, IEEETPAMI IEEE T PAT, V19	16	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22064-X	LECT NOTES ARTIF INT			2004	3056						580	589				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAF29	WOS:000221955100067	
S	Li, JY; Ramamohanarao, K		Dai, H; Srikant, R; Zhang, C		Li, JY; Ramamohanarao, K			A tree-based approach to the discovery of diagnostic biomarkers for ovarian cancer	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific/Asia Conference on Advances in Knowledge Discovery and Data Mining	MAY 26-28, 2004	Sydney, AUSTRALIA	NICIA, SAS, Univ Technol Sydney, Deakin Univ		decision trees; committee method; ovarian cancer; biomarkers; classification	CLASSIFICATION; PREDICTION	Computational diagnosis of cancer is a classification problem, and it has two special requirements on a learning algorithm: perfect accuracy and small number of features used in the classifier. This paper presents our results on an ovarian cancer data set. This data set is described by 15154 features, and consists of 253 samples. Each sample is referred to a woman who suffers from ovarian cancer or who does not have. In fact, the raw data is generated by the so-called mass spectrosmetry technology measuring the intensities of 15154 protein or peptide-features in a blood sample for every woman. The purpose is to identify a small subset of the features that can be used as biomarkers to separate the two classes of samples with high accuracy. Therefore, the identified features can be potentially used in routine clinical diagnosis for replacing labour-intensive and expensive conventional diagnosis methods. Our new tree-based method can achieve the perfect 100% accuracy in 10-fold cross validation on this data set. Meanwhile, this method also directly outputs a small set of biomarkers. Then we explain why support vector machines, naive bayes, and k-nearest neighbour cannot fulfill the purpose. This study is also aimed to elucidate the communication between contemporary cancer research and data mining techniques.	Inst Infocomm Res, Singapore 119613, Singapore; Univ Melbourne, Dept CSSE, Melbourne, Vic 3010, Australia	Li, JY (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@i2r.a-star.edu.sg; rao@cs.mu.oz.au					Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Freund Y., 1996, INT C MACH LEARN, P148; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; JINYAN L, 2003, P ICDM, P585; JULIA D, 2001, NATURE REV CANC, V3, P267; Langley P., 1994, P 10 C UNC ART INT, P399; LI JY, 2003, BIOINFORMATICS, V19, P1193; LIU HQ, 2002, GENOME INFORMATICS, P51; Petricoin EF, 2002, LANCET, V359, P572, DOI 10.1016/S0140-6736(02)07746-2; Quinlan J. R., 1993, C45 PROGRAMS MACHINE; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	18	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22064-X	LECT NOTES ARTIF INT			2004	3056						682	691				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAF29	WOS:000221955100078	
S	Sierra, B; Lazkano, E; Martinez-Otzeta, JM; Astigarraga, A		Webb, GI; Yu, X		Sierra, B; Lazkano, E; Martinez-Otzeta, JM; Astigarraga, A			Combining Bayesian networks, k nearest neighbours algorithm and attribute selection for gene expression data analysis	AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004	Cairns, AUSTRALIA		Cent Queensland Univ		FEATURE SUBSET-SELECTION; CLASSIFICATION; DISCOVERY; CANCER	In the last years, there has been a large growth in gene expression profiling technologies, which are expected to provide insight into cancer related cellular processes. Machine Learning algorithms, which are extensively applied in many areas of the real world, are not still popular in the Bioinformatics community. We report on the successful application of the combination of two supervised Machine Learning methods, Bayesian Networks and k Nearest Neighbours algorithms, to cancer class prediction problems in three DNA microarray datasets of huge dimensionality (Colon, Leukemia and NCI-60). The essential gene selection process in microarray domains is performed by a sequential search engine and after used for the Bayesian Network model learning. Once the genes are selected for the Bayesian Network paradigm, we combine this paradigm with the well known K NN algorithm in order to improve the classification accuracy.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, E-20080 San Sebastian, Spain	Sierra, B (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, POB 649, E-20080 San Sebastian, Spain.	ccpsiarb@si.ehu.es					Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; BLANCO R, 2004, INT J PATTERN RECOGN; Burr Ridge I, 1997, MACHINE LEARNING; Chickering D. M, 2002, J MACHINE LEARNING R, V3, p[507, 524]; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Doak J., 1992, CSE9218 U CAL DAV; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N., 1996, AAAI IAAI, V2, P1277; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; INZA I, 2002, IN PRESS J INTELLIGE; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; JENSEN F, 2001, BAYESIAN NETWORKS DE; Kittler J., 1978, Pattern Recognition and Signal Processing; KOHAVI R, 1995, P INT JOINT C ART IN; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, DOI 10.1142/S021821309700027X; Lazkano E, 2003, LECT NOTES ARTIF INT, V2902, P171; LI L, 2000, P 1 C CRIT ASS MICR, pA6061; LI W, 2000, P 1 C CRIT ASS MICR; Liu H., 1998, FEATURE SELECTION KN; PEARL J, 1987, ARTIF INTELL, V32, P247; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; ROMERO D, 2004, INT J PATTERN RECOGN, V18, P45; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHANNON CE, 1948, AT&T TECH J, V27, P379; Sierra B, 2001, ARTIF INTELL MED, V22, P233, DOI 10.1016/S0933-3657(00)00111-1; Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4; Xing E. P., 2001, P 18 INT C MACH LEAR, P601	30	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-24059-4	LECT NOTES ARTIF INT			2004	3339						86	97				12	Computer Science, Artificial Intelligence	Computer Science	BBM32	WOS:000226133600008	
S	Sucahyo, YG; Gopalan, RP		Webb, GI; Yu, X		Sucahyo, YG; Gopalan, RP			Building a more accurate classifier based on strong frequent patterns	AI 2004: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	17th Annual Australian Conference on Artificial Intelligence	DEC 04-06, 2004	Cairns, AUSTRALIA		Cent Queensland Univ			The classification problem in data mining is to discover models from training data for classifying unknown instances. Associative classification builds the classifier rules using association rules and it is more accurate compared to previous methods. In this paper, a new method named CSFP that builds a classifier from strong frequent patterns without the need to generate association rules is presented. We address the rare item problem by using a partitioning method. Rules generated are stored using a compact data structure named CP-Tree and a series of pruning methods are employed to discard weak frequent patterns. Experimental results show that our classifier is more accurate than previous associative classification methods as well as other state-of-the-art non-associative classifiers.	Curtin Univ Technol, Dept Comp, Bentley, WA 6102, Australia	Sucahyo, YG (reprint author), Curtin Univ Technol, Dept Comp, Kent St, Bentley, WA 6102, Australia.	sucahyoy@cs.curtin.edu.au; raj@cs.curtin.edu.au					AGRAWAL R, 1993, P ACM SIGMOD WASH; COHEN W, 1995, P ICML TAH CITY CA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG G, 1999, P 2 INT C DISC SCI T; Duda R. O., 2001, PATTERN CLASSIFICATI; Fayyad U., 1993, P IJCAI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GOPALAN RP, 2004, P SIAM INT WORKSH HP; KOHAVI R, 1994, MLC MACHINE LEARNING, P740; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; LI W, 2001, P IEEE ICDM SAN JOS; LIU B, 2000, P PKDD 2000 LYON FRA; LIU B, 1998, P ACM SIGKDD NEW YOR; MERETAKIS D, 1999, P ACM SIGKDD SAN DIE; QUINTANA JR, 1992, REV IBEROAMERICANA P, V1, P5; Yin X., 2003, P SIAM INT C DAT MIN; ZHANG X, P IDEAL HONG KONG	17	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-24059-4	LECT NOTES ARTIF INT			2004	3339						1036	1042				7	Computer Science, Artificial Intelligence	Computer Science	BBM32	WOS:000226133600098	
J	Kos, G; Krska, R; Lohninger, H; Griffiths, PR				Kos, G; Krska, R; Lohninger, H; Griffiths, PR			A comparative study of mid-infrared diffuse reflection (DR) and attenuated total reflection (ATR) spectroscopy for the detection of fungal infection on RWA2-corn	ANALYTICAL AND BIOANALYTICAL CHEMISTRY			English	Article						attenuated total reflection; diffuse reflection; mid-infrared spectroscopy; comparison study; cereals; mycotoxins	PARTICLE-SIZE MORPHOLOGY; CARBOHYDRATE SYSTEMS; SAMPLE DILUTION; MYCOTOXINS; CEREALS; SPECTRA; WHEAT; CORN; CHROMATOGRAPHY; TRICHOTHECENES	An investigation into the rapid detection of mycotoxin-producing fungi on corn by two mid-infrared spectroscopic techniques was undertaken. Corn samples from a single genotype (RWA2, blanks, and contaminated with Fusarium graminearum) were ground, sieved and, after appropriate sample preparation, subjected to mid-infrared spectroscopy using two different accessories (diffuse reflection and attenuated total reflection). The measured spectra were evaluated with principal component analysis (PCA) and the blank and contaminated samples were classified by cluster analysis. Reference data for fungal metabolites were obtained with conventional methods. After extraction and clean-up, each sample was analyzed for the toxin deoxynivalenol (DON) by gas chromatography with electron capture detection (GC-ECD) and ergosterol (a parameter for the total fungal biomass) by high-performance liquid chromatography with diode array detection (HPLC-DAD). The concentration ranges for contaminated samples were 880-3600 mug/kg for ergosterol and 300-2600 mug/kg for DON. Classification efficiency was 100% for ATR spectra. DR spectra did not show as obvious a clustering of contaminated and blank samples. Results and trends were also observed in single spectra plots. Quantification using a PLS1 regression algorithm showed good correlation with DON reference data, but a rather high standard error of prediction (SEP) with 600 mug/kg (DR) and 490 mug/kg (ATR), respectively, for ergosterol. Comparing measurement procedures and results showed advantages for the ATR technique, mainly owing to its ease of use and the easier interpretation of results that were better with respect to classification and quantification.	IFA Tulln, Inst Agrobiotechnol, Ctr Analyt Chem, A-3430 Tulln, Austria; Vienna Univ Technol, Div Analyt Chem, Inst Chem Technol & Analyt, A-1060 Vienna, Austria; Univ Idaho, Dept Chem, Moscow, ID 83844 USA	Krska, R (reprint author), IFA Tulln, Inst Agrobiotechnol, Ctr Analyt Chem, Konrad Lorenz Str 20, A-3430 Tulln, Austria.		Krska, Rudolf/A-6385-2012				BECHTEL DB, 1985, CEREAL CHEM, V62, P191; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; D'Mello JPF, 1999, ANIM FEED SCI TECH, V80, P183, DOI 10.1016/S0377-8401(99)00059-0; European Commission, 2000, SANCO192500REV1 DGSA, P1; GORDON SH, 1993, BIOTECHNOL ADV, V11, P665, DOI 10.1016/0734-9750(93)90035-L; Gordon SH, 1997, INT J FOOD MICROBIOL, V35, P179, DOI 10.1016/S0168-1605(96)01217-2; GREENE RV, 1992, J AGR FOOD CHEM, V40, P1144, DOI 10.1021/jf00019a011; HOCHSTEINER W, 2001, TIERARZTL MONATSSCHR, P342; Kos G, 2003, ANAL CHEM, V75, P1211, DOI 10.1021/ac0260903; Krska R, 2001, FRESEN J ANAL CHEM, V371, P285, DOI 10.1007/s002160100992; Langseth W, 1998, J CHROMATOGR A, V815, P103, DOI 10.1016/S0021-9673(98)00388-4; LOHNINGER H, 1999, TEACHME DATA ANAL; LOHNINGER H, 2000, DATALAB PROGRAM STAT; Marquardt RR, 1996, ANIM FEED SCI TECH, V58, P77, DOI 10.1016/0377-8401(95)00875-6; Miller J.D., 1994, MYCOTOXINS GRAIN COM; MIRAGLIA M, 1998, MYCOTOXINS PHYCOTOXI; Naes T, 2002, USER FRIENDLY GUIDE; OLINGER JM, 1993, APPL SPECTROSC, V47, P687, DOI 10.1366/0003702934066965; OLINGER JM, 1993, APPL SPECTROSC, V47, P695, DOI 10.1366/0003702934067054; OTTO M, 1997, CHEMOMETRIE; PARK DL, 1989, J ASSOC OFF ANA CHEM, V72, P399; Pittet A, 1998, REV MED VET-TOULOUSE, V149, P479; SCHWADORF K, 1989, J ASSOC OFF ANA CHEM, V72, P457; SEITZ LM, 1977, CEREAL CHEM, V54, P1201; SMITH JE, 1991, MYCOTOXINS ANIMAL FO; Stuchebryukov SD, 1997, OPT COMMUN, V140, P36, DOI 10.1016/S0030-4018(97)00143-0; TRUCKSESS MW, 1995, J AOAC INT, V78, P135; Weingaertner J, 1997, FRESEN J ANAL CHEM, V357, P1206, DOI 10.1007/s002160050332; WHEELER BC, 1993, P 15 INT C I EL EL E, P7037; Wilson RH, 1999, TRAC-TREND ANAL CHEM, V18, P85, DOI 10.1016/S0165-9936(98)00107-1; *AFNOR, 1991, V18112 AFNOR NF, P1; *GIPSA, 2002, GRAIN FUNG DIS MYC R; *ISO, 1994, ISOTC34SC10N508	33	20	20	SPRINGER-VERLAG HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1618-2642		ANAL BIOANAL CHEM	Anal. Bioanal. Chem.	JAN	2004	378	1					159	166		10.1007/s00216-003-2245-y		8	Biochemical Research Methods; Chemistry, Analytical	Biochemistry & Molecular Biology; Chemistry	752DW	WOS:000187132600033	
S	Jankowski, N; Grochowski, M		Rutkowski, L; Siekmann, J; Tadeusiewicz, R; Zadeh, LA		Jankowski, N; Grochowski, M			Comparison of instances seletion algorithms I. Algorithms survey	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2004	Lecture Notes in Artificial Intelligence		English	Article; Proceedings Paper	7th International Conference on Artificial Intelligence and Soft Computing	JUN 07-11, 2004	Zakopane, POLAND	Polish Neural Network Soc, Czestochowa Univ Technol, Dept Comp Engn			NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	Several methods were proposed to reduce the number of instances (vectors) in the learning set. Some of them extract only bad vectors while others try to remove as many instances as possible without significant degradation of the reduced dataset for learning. Several strategies to shrink training sets axe compared here using different neural and machine learning classification algorithms. In part H (the accompanying paper) results on benchmarks databases have been presented.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Ul Grudziadzka 5, PL-87100 Torun, Poland.	norbert@phys.uni.torun.pl; grochu@phys.uni.torun.pl					ADAMCZAK R, 1997, 3 C NEUR NETW THEIR, P65; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bhattacharya B., 1981, INT S INF THEOR SANT; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1997, PATTER CLASSIFICATIO, V2; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GRABCZEWSKI K, 1999, 4 C NEUR NETW THEIR, P203; Grochowski M., 2003, THESIS N COPERNICUS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jankowski N., 2000, NEURAL NETWORKS SOFT, P209; JANKOWSKI N, 1997, 7 INT C ART NEUR NET, P385; Kohonen T, 1986, TKKFA601 HELS U TECH; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SCHOLKOPF B, 2002, LEARNNG KERNELS; Skalak D.B., 1994, INT C MACH LEARN, P293; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	20	27	27	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22123-9	LECT NOTES ARTIF INT			2004	3070						598	603				6	Computer Science, Artificial Intelligence	Computer Science	BAH85	WOS:000222325200090	
B	Vogt, P		Pollack, J; Bedau, M; Husbands, P; Ikegami, T; Watson, RA		Vogt, P			Minimum cost and the emergence of the Zipf-Mandelbrot law	Artificial Life IX			English	Proceedings Paper	9th International Conference on the Simulation and Synthesis of Artificial Life (ALIFE9)	SEP 12-15, 2004	Boston, MA	Int Soc Artificial Life, Brandeis Univ				This paper illustrates how the Zipf-Mandelbrot law can emerge in language as a result of minimising the cost of categorising sensory images. The categorisation is based on the discrimination game in which sensory stimuli are categorised at different hierarchical layers of increasing density. The discrimination game is embedded in a variant of the language game model, called the selfish game, which in turn is embedded in the framework of iterated learning. The results indicate that a tendency to communicate in general terms, which is less costly, can contribute to the emergence of the Zipf-Mandelbrot law.	Univ Edinburgh, Language Evolut & Computat Res Unit, Edinburgh, Midlothian, Scotland	Vogt, P (reprint author), Univ Edinburgh, Language Evolut & Computat Res Unit, Edinburgh, Midlothian, Scotland.						Cancho RFI, 2003, P NATL ACAD SCI USA, V100, P788, DOI 10.1073/pnas.0335980100; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gardenfors P, 2000, CONCEPTUAL SPACES; Gunther R, 1996, INT J THEOR PHYS, V35, P395, DOI 10.1007/BF02083823; Kirby S., 2002, LINGUISTIC EVOLUTION; LI WT, 1992, IEEE T INFORM THEORY, V38, P1842, DOI 10.1109/18.165464; Lloyd B., 1978, COGNITION CATEGORIZA; Mandelbrot BB, 1953, COMMUN THEORY, P503; MILLER GA, 1957, AM J PSYCHOL, V70, P311, DOI 10.2307/1419346; Siskind JM, 1996, COGNITION, V61, P39, DOI 10.1016/S0010-0277(96)00728-7; SMITH ADM, 2003, ARTIF LIFE, V9, P559; SMITH K, IN PRESS J THEORETIC; STEELS L, 1996, P INT C MUTL AG SYST; Steels L., 2002, TRANSITION LANGUAGE; TULLO C, 2003, LANGUAGE EVOLUTION C; VOGT P, 2004, P BEN 2004; VOGT P, 2004, P EV, V5; VOGT P, 2003, ADV ARTIFICIAL LIFE; VOGT P, 2000, EVOLUTION COMMUNICAT, V4, P89; Zipf GK, 1949, HUMAN BEHAV PRINCIPL	20	1	1	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA		0-262-66183-7				2004							214	219				6	Biology; Computer Science, Artificial Intelligence	Life Sciences & Biomedicine - Other Topics; Computer Science	BCV06	WOS:000231382900035	
S	Kosar, K; Lhotska, L; Krajca, V		Barreiro, JM; MartinSanchez, F; Maojo, V; Sanz, F		Kosar, K; Lhotska, L; Krajca, V			Classification of long-term EEG recordings	BIOLOGICAL AND MEDICAL DATA ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Symposium on Biological and Medical Data Analysis (ISBMDA)	NOV   18, 2004	Barcelona, SPAIN				ADAPTIVE SEGMENTATION; SEIZURE DETECTION	Computer assisted processing of long-term EEG recordings is gaining a growing importance. To simplify the work of a physician, that must visually evaluate long recordings, we present a method for automatic processing of EEG based on learning classifier. This method supports the automatic search of long-term EEG recording and detection of graphoelements - signal parts with characteristic shape and defined diagnostic value. Traditional methods of detection show great percent of error caused by the great variety of non-stationary EEG. The idea of this method is to break down the signal into stationary sections called segments using adaptive segmentation and create a set of normalized discriminative features representing segments. The groups of similar patterns of graphoelements form classes used for the learning of a classifier. Weighted features are used for classification performed by modified learning classifier fuzzy k-Nearest Neighbours. Results of classification describe classes of unknown segments. The implementation of this method was experimentally verified on a real EEG with the diagnosis of epilepsy.	Czech Tech Univ, Gerstner Lab, Prague 16627 6, Czech Republic; Univ Hosp Bulovka, Prague 18081 8, Czech Republic	Kosar, K (reprint author), Czech Tech Univ, Gerstner Lab, Technicka 2, Prague 16627 6, Czech Republic.	1hotska@fel.cvut.cz; krajca@fnb.cz					Agarwal R, 1998, ELECTROEN CLIN NEURO, V107, P44, DOI 10.1016/S0013-4694(98)00009-1; BODENSTEIN G, 1977, P IEEE, V65, P642, DOI 10.1109/PROC.1977.10543; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVEY BLK, 1989, MED BIOL ENG COMPUT, V27, P365, DOI 10.1007/BF02441427; GUTMAN J, 1982, ELECTROENCEPHALOGR C, V83, P271; HORNERO R, 1999, IEEE ENG MED BIOL, P73; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KRAJCA V, 1992, LEKAR TECHNIKA, V2, P28; KRAJCA V, 1991, INT J BIOMED COMPUT, V28, P71, DOI 10.1016/0020-7101(91)90028-D; Mayer-Kress Gottfried, 1994, Integrative Physiological and Behavioral Science, V29, P205, DOI 10.1007/BF02691325; PETROSIAN A, 1995, P SOC PHOTO-OPT INS, V2569, P189, DOI 10.1117/12.217574; PLOTKIN EI, P CCECE 21 SEPT 1992; QU H, 1993, ELECTROEN CLIN NEURO, V86, P79, DOI 10.1016/0013-4694(93)90079-B; Smith S.W., 1997, DIGITAL SIGNAL PROCE; VARRI A, 1988, DIGITAL PROCESSING E; Weng W, 1996, NEURAL NETWORKS, V9, P1223, DOI 10.1016/0893-6080(96)00032-9	16	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-23964-2	LECT NOTES COMPUT SC			2004	3337						322	332				11	Biochemistry & Molecular Biology; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Medical Informatics	Biochemistry & Molecular Biology; Computer Science; Medical Informatics	BBM23	WOS:000226129700033	
S	Park, SB; Chang, JH; Zhang, BT		Gelbukh, A		Park, SB; Chang, JH; Zhang, BT			Korean compound noun decomposition using syllabic information only	COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Text Processing and Computational Linguistics	FEB 15-21, 2004	Seoul, SOUTH KOREA	Assoc Computat Linguist				The compound nouns are freely composed in Korean, since it is possible to concatenate independent nouns without a postposition. Therefore, the systems that handle compound nouns such as machine translation and information retrieval have to decompose them into single nouns for the further correct analysis of texts. This paper proposes the GECORAM (GEneralized COmbination of Rule-based learning And Memory-based learning) algorithm for Korean compound noun decomposition using only syllabic information. The merit of rule-based learning algorithms is high comprehensibility, but they shows low performance in many application tasks. To tackle this problem, GECORAM combines the rule-based learning and memory-based learning. According to the experimental results, GECORAM shows higher accuracy than rule-based learning or memory-based learning alone.	Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151744, South Korea	Park, SB (reprint author), Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151744, South Korea.	sbpark@bi.snu.ac.kr; jhchang@bi.snu.ac.kr; btzhang@bi.snu.ac.kr					Abney S., 1999, P 1999 JOINT SIGDAT, P38; Brill E, 1995, COMPUT LINGUIST, V21, P543; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cohen W. W., 1995, P 12 INT C MACH LEAR, P115; Cohen W. W., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS W, 2001, TIMBL TILBURG MEMORY; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Furnkranz J., 1994, P 11 INT C MACH LEAR, P70; KANG SS, 1998, J KISS, V25, P172; LEE JW, 1999, P MT SUMM 7, P427; PARK SB, 2003, P 41 ANN M ASS COMP, P497; Quinlan R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN R, 1995, P 12 INT C MACH LEAR, P464; SHIM KS, 1999, P 3 CHIN KOR JOINT S, P106; YOON BH, 1997, KISS J, V24, P900	16	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-21006-7	LECT NOTES COMPUT SC			2004	2945						146	157				12	Computer Science, Information Systems; Computer Science, Theory & Methods; Language & Linguistics	Computer Science; Linguistics	BY59Y	WOS:000189417900018	
S	Moon, J; Shon, T; Seo, J; Kim, J; Seo, J		Aykanat, C; Dayar, T; Korpeoglu, I		Moon, J; Shon, T; Seo, J; Kim, J; Seo, J			An approach for spam E-mail detection with support vector machine and n-gram indexing	COMPUTER AND INFORMATION SCIENCES - ISCIS 2004, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	19th International Symposium on Computer and Information Sciences (ISCIS 2004)	OCT 27-29, 2004	Kemer Antalya, TURKEY	Bilkent Univ, Dept Comp Engn, Inst Elect & Elect Engineers Turkey Sect, Working Grp, Int Federat Informat Proc, Sci & Tech Res Council Turkey				Many solutions have been deployed to prevent harmful effects from spam mail. Typical methods are either pattern matching using the keyword or method using the probability such as naive Bayesian method. In this paper, we proposed a classification method of spam mail from normal mail using support vector machine, which has excellent performance in binary pattern classification problems. Especially, the proposed method efficiently practices a learning procedure with a word dictionary by the n-gram. In the conclusion, we showed our proposed method being superior to others in the aspect of comparing performance.	Korea Univ, Ctr Informat Secur Technol, Seoul 136701, South Korea; ETRI, Natl Secur Res Inst, Taejon, South Korea; Samsung Elect Co, Suwon, South Korea	Moon, J (reprint author), Korea Univ, Ctr Informat Secur Technol, Seoul 136701, South Korea.	jsmoon@korea.ac.kr; 743zh2k@korea.ac.kr; seojt@etri.re.kr; sky45k@korea.ac.kr; korea002@korea.ac.kr					Androutsopoulos I., 2000, 23 ACM INT C RES DEV, P160; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAMPBELL C, 1998, SIMPLE LEARNING ALGO; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; CRISTIANINI N, 2000, SUPPORT VECTOR MACHI, P33; ION A, 2000, PKDD 2000, P1; JOACHIMS T, MYSVM SUPPORTS VECTO; Joachims T, 1998, EUR C MACH LEARN ECM, P137; JOONHO L, 1996, KOREAN SOC INFORMATI, V7, P47; MEHRAN S, 1998, AAA198 WORKSH LEARN; PONTIL M, 1997, 152 CBCL; Ruping S., 2000, MYSVM MANUAL; Vapnik V.N., 1995, NATURE STAT LEARNING	15	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-23526-4	LECT NOTES COMPUT SC			2004	3280						351	362				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BBE06	WOS:000225096700036	
S	Ma, HF; Doermann, D		Smith, EHB; Hu, J; Allan, J		Ma, HF; Doermann, D			Word level script identification for scanned document images	DOCUMENT REGOGNITION AND RETRIEVAL XI	Proceedings of SPIE		English	Proceedings Paper	Conference on Document Recognition and Retrieval XI	JAN 21-22, 2004	San Jose, CA	Soc Imaging Sci & Technol, SPIE		script identification; support vector machines (SVM); Gaussian mixture model (GMM); k-nearest; neighbor (k-NN); gabor filter	CLASSIFICATION; RECOGNITION; NETWORKS	In this paper, we compare the performance of three classifiers used to identify the script of words in scanned document images. In both training and testing, a Gabor filter is applied and 16 channels of features are extracted. Three classifiers (Support Vector Machines (SVM), Gaussian Mixture Model (GMM) and k-Nearest-Neighbor (k-NN)) are used to identify different scripts at the word level (glyphs separated by white space). These three classifiers are applied to a variety of bilingual dictionaries and their performance is compared. Experimental results show the capability of Gabor filter to capture script features and the effectiveness of these three classifiers for script identification at the word level.	Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA	Ma, HF (reprint author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	hfma@umiacs.umd.edu; doermann@umiacs.umd.edu					BLANZ V, 1996, ICANN, P251; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DOERMANN D, 2002, SPIE C DOC REC RETR, P37; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; ITTNER DJ, 1993, ICDAR 93, P336; Joachims T., 1999, ADV KERNEL METHODS S, P41; MA H, 2003, SPIE C DOC REC RETR, P179; Ma HF, 2003, SEVENTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, VOLS I AND II, PROCEEDINGS, P968; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; SCHMIDT M, 1996, INTERFACE 96 P SYDN; SIBUN P, 1994, P 4 C APPL NAT LANG, P115; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; Waked B, 1998, IEEE SYS MAN CYBERN, P4470; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192	19	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	0-8194-5199-1	PROC SPIE			2004	5296						124	135				12	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BY62S	WOS:000189424500016	
B	Yang, Y; Zheng, CX; Lin, P		Wei, D; Wang, H; Peng, ZY; Kara, A		Yang, Y; Zheng, CX; Lin, P			Image thresholding based on spatially weighted fuzzy C-means clustering	FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Computer and Information Technology	SEP 14-16, 2004	Wuhan, PEOPLES R CHINA	Wuhan Univ, Univ Aizu, Natl Nat Sci Fdn China, IEEE Engn Med & Biol Soc			ENTROPY; HISTOGRAM; PARTITION	In this paper, a novel spatially weighted fuzzy c-means (SWFCM) clustering algorithm for image thresholding is presented. The algorithm is formulated by incorporating the spatial neighborhood information into the standard FCM clustering algorithm. Two improved implementations of the k-nearest neighbor (k-NN) algorithm are developed for calculating the weight in the SWFCM algorithm so as to improve the performance of image thresholding. To speed up the FCM algorithm, the iteration is carried out with the statistical gray level histogram of image instead of the conventional whole data of image. Some comparisons with classical thresholding algorithm and fuzzy thresholding algorithm are also given in this paper. Experimental results on both synthetic and real images are given to demonstrate the effectiveness of the proposed algorithm. In addition, due to the neighborhood model, the proposed method is more tolerant to noise.	Xian Jiaotong Univ, Educ Minist, Key Lab Biomed Informat Engn, Inst Biomed Engn, Xian 710049, Peoples R China	Yang, Y (reprint author), Xian Jiaotong Univ, Educ Minist, Key Lab Biomed Informat Engn, Inst Biomed Engn, Xian 710049, Peoples R China.						ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; Bezdek J., 1981, PATTERN RECOGNITION; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELSTEIN WA, 1984, MED PHYS, V11, P180, DOI 10.1118/1.595484; Fu S. K., 1981, PATTERN RECOGN, V13, P3; Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6; JULIUS TT, 1974, PATTERN RECOGNITION; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; Otsu N., 1978, IEEE T SYST MAN CYB, V8, P62; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743	14	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2216-5				2004							184	189				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BBB01	WOS:000224461900029	
S	Zhou, Y; Goldman, S		Khoshgoftaar, TM		Zhou, Y; Goldman, S			Democratic co-learning	ICTAI 2004: 16TH IEEE INTERNATIONALCONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	16th IEEE International Conference on Tools with Artificial Intelligence	NOV 15-17, 2004	Boca Raton, FL	IEEE Comp Soc, Informat Technol Res Inst, Wright State Univ, Florida Atlantic Univ			CLASSIFICATION; ALGORITHM; EM	For many machine learning applications it is important to develop algorithms that use both labeled and unlabeled data. We present democratic co-learning in which multiple algorithms instead of multiple views enable learners to label data for each other Our technique leverages off the fact that different learning algorithms have different inductive biases and that better predictions can be made by the voted majority. We also present democratic priority sampling, a new example selection method for active learning.	Univ S Alabama, Sch Comp & Informat Sci, Mobile, AL 36688 USA	Zhou, Y (reprint author), Univ S Alabama, Sch Comp & Informat Sci, Mobile, AL 36688 USA.						Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagan I, 1995, P 12 INT C MACH LEAR, P150; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Goldman S., 2000, P 17 INT C MACH LEAR, P327; Lewis DD, 1994, P 17 ANN INT ACM SIG, P3; MUSLEA I, 2001, IJCAI 01 WORKSH TEXT; Muslea I., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Nigam K., 2000, 9 INT C INF KNOWL MA, P86; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; PHILIP KC, 1996, P 9 FLOR AL RES S, P151; PHILIP KC, 1998, J INTELLIGENT INTEGR, V8, P5; Quinlan R., 1986, MACH LEARN, V1, P81; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130417; ZHOU ZH, 2004, P 15 EUR C MACH LEAR	19	25	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409	0-7695-2236-X	PROC INT C TOOLS ART			2004							594	602				9	Computer Science, Artificial Intelligence	Computer Science	BBI06	WOS:000225597000078	
S	Xie, ZP; Hsu, W; Lee, ML		Khoshgoftaar, TM		Xie, ZP; Hsu, W; Lee, ML			Mode committee: A novel ensemble method by clustering and local learning	ICTAI 2004: 16TH IEEE INTERNATIONALCONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, PROCEEDINGS	PROCEEDINGS - INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	16th IEEE International Conference on Tools with Artificial Intelligence	NOV 15-17, 2004	Boca Raton, FL	IEEE Comp Soc, Informat Technol Res Inst, Wright State Univ, Florida Atlantic Univ			CLASSIFICATION	Ensemble methods have proved effective to achieve higher accuracy. Some simple ensemble methods, such as Bagging, work well with unstable base algorithms, but fail with stable ones. The reason is that such methods achieve higher accuracy by reducing only the variance of the base algorithms. It does not touch the bias. Here, we propose a novel ensemble method, Mode Committee, intended to work for both stable and unstable base algorithms. It first derive a new algorithm, called mode competitor, from given base algorithm, with the help of k-modes clustering method and the local learning strategy. Randomness is injected into each mode competitor by the process of random seeding. The aim of deriving mode competitor is to reduce the bias with the possible increasing variance. Then, multiple mode competitors form a committee and vote on the decision of new example, with the aim to reduce the variance of mode competitors. Such an arithmetic framework has been materialized by two base algorithms, the unstable C4.5 and the stable naive Bayes. Extensive empirical results demonstrate this method's superiority, and further analysis by bias-variance decomposition reveals that it is due to the low-bias of mode competitors.	Fudan Univ, Dept CIT, Shanghai 200433, Peoples R China	Xie, ZP (reprint author), Fudan Univ, Dept CIT, Shanghai 200433, Peoples R China.						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Blake CL, 1998, UCI REPOSITORY MACHI; Breiman L, 1996, 460 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; KOHAVI R, 1996, P 13 INT C MACH LEAR, P313; Maclin R., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Xie ZP, 2003, PROC INT C TOOLS ART, P522; Zheng Z., 1998, P 10 EUR C MACH LEAR, P196; Zhou ZH, 2002, KNOWL-BASED SYST, V15, P515, DOI 10.1016/S0950-7051(02)00038-2	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409	0-7695-2236-X	PROC INT C TOOLS ART			2004							628	633				6	Computer Science, Artificial Intelligence	Computer Science	BBI06	WOS:000225597000082	
S	Bao, YG; Ishii, N; Du, XY		Yang, ZR; Everson, R; Yin, H		Bao, YG; Ishii, N; Du, XY			Combining multiple k-nearest neighbor classifiers using different distance functions	INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter, ENGLAND	Execter Univ, Comp Sci Dept, IEEE Neural Networks Soc, Springer Verlag				The k-nearest neighbor (KNN) classification is a simple and effective classification approach. However, improving performance of the classifier is still attractive. Combining multiple classifiers is an effective technique for improving accuracy. There are many general combining algorithms, such as Bagging, Boosting, or Error Correcting Output Coding that significantly improve the classifier such as decision trees, rule learners, or neural networks. Unfortunately, these combining methods do not improve the nearest neighbor classifiers. In this paper we present a new approach to combine multiple KNN classifiers based on different distance funtions, in which we apply multiple distance functions to improve the performance of the k-nearest neighbor classifier. The proposed algorithm seeks to increase generalization accuracy when compared to the basic k-nearest neighbor algorithm. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository. The results show that the proposed algorithm improves the performance of the k-nearest neighbor classification.	Aichi Informat Syst, Aichi, Japan; Aichi Inst Technol, Aichi, Japan; Renmin Univ China, Beijing, Peoples R China	Bao, YG (reprint author), Aichi Informat Syst, Aichi, Japan.	baoyg@yahoo.com.cn; ishii@aitech.ac.ip; Duyong@mail.ruc.edu.cn					BAO Y, 2002, P 3 INT C INT DAT EN, P461; BAO Y, 2002, P 5 INT C DISC SCI, P361; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ITQON S, 2000, J IECI, V2, P23; Merz C.J., 1998, UCI REPOSITORY MACHI; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tapia R. A., 1978, NONPARAMETRIC PROBAB; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	11	6	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22881-0	LECT NOTES COMPUT SC			2004	3177						634	641				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAV07	WOS:000223701300093	
S	Everson, RM; Fieldsend, JE		Yang, ZR; Everson, R; Yin, H		Everson, RM; Fieldsend, JE			A variable metric probabilistic k-nearest-neighbours classifier	INTELLIGENT DAA ENGINEERING AND AUTOMATED LEARNING IDEAL 2004, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2004)	AUG 25-27, 2004	Execter, ENGLAND	Execter Univ, Comp Sci Dept, IEEE Neural Networks Soc, Springer Verlag				k-nearest neighbour (k-nn) model is a simple, popular classifier. Probabilistic k-nn is a more powerful variant in which the model is cast in a Bayesian framework using (reversible jump) Markov chain Monte Carlo methods to average out the uncertainy over the model parameters. The k-nn classifier depends crucially on the metric used to determine distances between data points. However, scalings between features, and indeed whether some subset of features is redundant, are seldom known a priori. Here we introduce a variable metric extension to the probabilistic k-nn classifier, which permits averaging over all rotations and scalings of the data. In addition, the method permits automatic rejection of irrelevant features. Examples are provided on synthetic data, illustrating how the method can deform feature space and select salient features, and also on real-world data.	Univ Exeter, Dept Comp Sci, Exeter, Devon, England	Everson, RM (reprint author), Univ Exeter, Dept Comp Sci, Exeter, Devon, England.						Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denison D., 2002, BAYESIAN METHODS NON; Fan J., 1996, LOCAL POLYNOMIAL MOD; Green P.J., 1995, BIOMETRIKA, V82; HOLMES CC, 2002, J ROYAL STAT SOC B, V64, P1; Larget B, 1999, MOL BIOL EVOL, V16, P750; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Sykacek P, 2000, ADV NEUR IN, V12, P638	9	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22881-0	LECT NOTES COMPUT SC			2004	3177						654	659				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BAV07	WOS:000223701300096	
B	Figueira, LB; Nicoletti, MD		Srimani, PK		Figueira, LB; Nicoletti, MD			Choosing the initial set of exemplars when learning with an NGE-based system	ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS			English	Proceedings Paper	International Conference on Information Technology - Coding and Computing	APR 05-07, 2004	Las Vegas, NV	IEEE Comp Soc				In the original proposal of the NGE (Nested Generalized Exemplar) system, the induction of a concept is based on an initial set of training examples (named seeds) that are randomly chosen. The number of examples in this set is arbitrary, generally determined by the user of the system. It can be seen empirically, that the final results are influenced by the initial choice of the seeds. The work described in this paper proposes and investigates other alternative methods for choosing seeds and empirically evaluates their impact on the learning results in seven knowledge domains, as far as accuracy and number of expressions describing the concepts are concerned. In spite of the additional time investment associated with using a clustering method and, assuming that accuracy of the induced concept is of major importance, experiments have shown that choosing the initial set of seeds as the center of clusters can be the best option.	UFSCar, Dept Comp Sci, Sao Carlos, SP, Brazil	Figueira, LB (reprint author), UFSCar, Dept Comp Sci, Sao Carlos, SP, Brazil.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; BLAKE EKC, 1998, UCI REPOSITORY; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; NETO LGP, 2003, ICMLA 03, P193; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670	6	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2108-8				2004							193	197		10.1109/ITCC.2004.1286630		5	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAA56	WOS:000221353100044	
J	Muhlenbach, F; Lallich, S; Zighed, DA				Muhlenbach, F; Lallich, S; Zighed, DA			Identifying and handling mislabelled instances	JOURNAL OF INTELLIGENT INFORMATION SYSTEMS			English	Article; Proceedings Paper	13th International Symposium on Methodologies for Intelligent Systems (ISMIS 2002)	JUN 27-29, 2002	LYON, FRANCE	Univ Claude Bernard Lyon 1, Univ Lumiere Lyon 2, Inst Natl Sci Appl Lyon		supervised learning; mislabelled data; geometrical neighbourhood; filtering; removing instances; relabelling instances	LEARNING ALGORITHMS; CLASSIFICATION; OUTLIERS	Data mining and knowledge discovery aim at producing useful and reliable models from the data. Unfortunately some databases contain noisy data which perturb the generalization of the models. An important source of noise consists of mislabelled training instances. We offer a new approach which deals with improving classification accuracies by using a preliminary filtering procedure. An example is suspect when in its neighbourhood defined by a geometrical graph the proportion of examples of the same class is not significantly greater than in the database itself. Such suspect examples in the training data can be removed or relabelled. The filtered training set is then provided as input to learning algorithms. Our experiments on ten benchmarks of UCI Machine Learning Repository using 1-NN as the final algorithm show that removal gives better results than relabelling. Removing allows maintaining the generalization error rate when we introduce from 0 to 20% of noise on the class, especially when classes are well separable. The filtering method proposed is finally compared to the relaxation relabelling schema.	Univ Lyon 2, ERIC Lab, F-69676 Bron, France	Muhlenbach, F (reprint author), Univ Lyon 2, ERIC Lab, Batiment L,5 Ave Pierre Mendes France, F-69676 Bron, France.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Barnett V., 1984, OUTLIERS STAT DATA; BECKMAN RJ, 1983, TECHNOMETRICS, V25, P119, DOI 10.2307/1268541; Blake CL, 1998, UCI REPOSITORY MACHI; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; Brodley CE, 1999, J ARTIF INTELL RES, V11, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ELFVING T, 1982, COMPUT VISION GRAPH, V20, P158, DOI 10.1016/0146-664X(82)90042-9; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267; Jain A., 1988, ALGORITHMS CLUSTERIN; John G. H., 1995, P 1 INT C KNOWL DISC, P174; KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; LALLICH S, 2003, RSTI RIA ECA, V17, P399; Lallich S, 2002, LECT NOTES ARTIF INT, V2366, P5; LARGERON C, 1991, THESIS U LYON 1; MILLIGAN GW, 1988, J CLASSIF, V5, P181, DOI 10.1007/BF01897163; Mood AM, 1940, ANN MATH STAT, V11, P367, DOI 10.1214/aoms/1177731825; MORAN PAP, 1948, J ROY STAT SOC B MET, P246; MUHLENBACH F, 2002, ECA, V1, P155; Ord JK, 1981, SPATIAL PROCESSES MO; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Wald A, 1940, ANN MATH STAT, V11, P147, DOI 10.1214/aoms/1177731909; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZIGHED DA, 2001, ACT 8 C SOC FRANC CL, P356; ZIGHED DA, 1990, TRAITEMENT SIGNAL, V2, P213; Zighed D. A., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); ZIGHED DA, 1999, APPRENTISSAGE AUTOMA, P85	32	24	25	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0925-9902		J INTELL INF SYST	J. Intell. Inf. Syst.	JAN	2004	22	1					89	109		10.1023/A:1025832930864		21	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	725ZC	WOS:000185571500006	
S	Mitani, Y; Fujita, Y; Matsunaga, N; Hamarnoto, Y		Negoita, MG; Howlett, RJ; Jain, LC		Mitani, Y; Fujita, Y; Matsunaga, N; Hamarnoto, Y			A study on nonparametric classifiers for a CAD system of diffuse lung opacities in thin-section computed tomography images	KNOWLEDGE-BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Conference on Knowledge-Based Intelligent Information and Engineering Systems	SEP, 2004	Wellington, NEW ZEALAND	Royal Soc New Zealand, IPENZ, New Zealand Trade & Enterprise, Telecom, Allied Telesyn, Positively Wellington Business	Wellington Inst Technol			The classification of diffuse lung opacities in thin-section computed tomography (HRCT) images is an important step for developing a computer-aided diagnosis(CAD) system. In practical situations such that the ratio of the dimensionality to the training sample size per a class is small, the design of a CAD system for classifying diffuse lung opacities is considered to be one of difficult tasks. In this paper, we examine the classification performance of nonparametric classifiers for a CAD system of diffuse lung opacities in practical situations.	Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan; Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan; Yamaguchi Univ, Sch Med, Ube, Yamaguchi 7558505, Japan	Mitani, Y (reprint author), Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Fukunaga K., 1990, INTRO STAT PATTERN R; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; MITANI Y, 2000, P 4 INT C KNOWL BAS, V2, P780; MITANI Y, 2002, KNOWLEDGE BASED IN 1, V82, P121; MITANI Y, 2003, IEEE EMBS AS PAC C B; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rumelhart D E, 1986, PARALLEL DISTRIBUTED	11	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-23318-0	LECT NOTES COMPUT SC			2004	3213						608	613				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Computer Science	BBB75	WOS:000224585300084	
B	Figueira, LB; Lisboa, FOSS; Nicoletti, MD		Dick, S; Kurgan, L; Musilek, P; Pedrycz, W		Figueira, LB; Lisboa, FOSS; Nicoletti, MD			Learning fuzzy hyper-rectangles with instance and neural based methods	NAFIPS 2004: ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, VOLS 1AND 2: FUZZY SETS IN THE HEART OF THE CANADIAN ROCKIES			English	Proceedings Paper	Annual Meeting of the North-American-Fuzzy-Information-Processing-Society	JUN 27-30, 2004	Banff, CANADA	Amer Fuzzy Informat Proc Soc				The NGE model is an instance-based inductive learning method that generalizes a given training set into hypotheses represented as a set of hyper-rectangles in a n-dimensional Euclidean space. The RuleNet model does exactly the same thing, but using a neural network algorithm. This paper focuses on a fuzzy version of both algorithms aiming at comparing their performances.	UFSCar, Dept Comp Sci, BR-13565905 Sao Carlos, SP, Brazil	Figueira, LB (reprint author), UFSCar, Dept Comp Sci, BR-13565905 Sao Carlos, SP, Brazil.		Lisboa, Flavia/I-6767-2012				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Klir G.J., 1995, FUZZY SETS FUZZY LOG; Merz C.J., 1998, UCI REPOSITORY MACHI; NAUCK D, 1997, FDN NEURO FUZZY SYST; Nicoletti MD, 1998, LECT NOTES ARTIF INT, V1532, P427; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALISBOA FOS, 2003, 12 IEEE INT C FUZZ S, V1, P90; SALZBERG S, 1991, MACH LEARN, V6, P252; SALZBERG SL, 1989, THESIS HARVARD U CAM; TSCHICHOLDGURMA, 1995, THESIS ETH ZURICH; TschicholdGurman N, 1997, FUZZY SET SYST, V85, P287, DOI 10.1016/0165-0114(95)00351-7	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-8376-1				2004							462	467				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BAR86	WOS:000223305100088	
B	Kobayashi, T; Nakagawa, M			IEEE Comp Soc	Kobayashi, T; Nakagawa, M			Pattern recognition by distributed coding: Test and analysis of the power space similarity method	NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS			English	Proceedings Paper	9th International Workshop on Frontiers in Handwriting Recognition (IWFHR-9 2004)	OCT 26-29, 2004	Tokyo, JAPAN	Hitachi, IBM, Fujitsu Lab, NEC, Toshiba, Microsoft, Int Assoc Pattern Recognit				This paper considers pattern recognition methods using distributed coding. These methods permit rapid learning from a large number of training samples; their recognition speed is high regardless of the size of the learning samples. This paper presents both basic algorithm and extended algorithms. Experiments with a large database of off-line handwritten numeric patterns are then described using the power space similarity method, being a type of distributed coding. Finally the effectiveness of the technique is considered.	Tokyo Univ Agr & Technol, Grad Sch Technol, Tokyo 1848588, Japan	Kobayashi, T (reprint author), Tokyo Univ Agr & Technol, Grad Sch Technol, 2-24-16 Nakacho, Tokyo 1848588, Japan.						Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Kanerva P, 1988, SPARSE DISTRIBUTED M; KOBAYASHI T, 1997, Patent No. 5689584; MURATA N, 2002, PRMU200297 IEICE, P37; SHIBATA T, 2003, TECHNICAL REPORT IEI, V103, P85	7	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2187-8				2004							389	394		10.1109/IWFHR.2004.83		6	Computer Science, Artificial Intelligence	Computer Science	BBG81	WOS:000225462900065	
S	Okazaki, N; Matsuo, Y; Ishizuka, M		Zhang, C; Guesgen, HW; Yeap, WK		Okazaki, N; Matsuo, Y; Ishizuka, M			Coherent arrangement of sentences extracted from multiple newspaper articles	PRICAI 2004: TRENDS IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	8th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2004)	AUG 09-13, 2004	Auckland, NEW ZEALAND	Univ Auckland, Inst Informat Technol Res, USAF Off Sci Res, Asian Off Aerosp Res & Dev, Auckland Univ Technol, Franz Inc				Multi-document summarization is a challenge to information overload problem to provide a condensed text for a number of documents. Most multi-document summarization systems make use of extraction techniques (e.g., important sentence extraction) and compile a summary from the selected information. However, sentences gathered from multiple sources are not organized as a comprehensible text. Therefore, it is important to consider sentence ordering of extracted sentences in order to reconstruct discourse structure in a summary. We propose a novel method to plan a coherent arrangement of sentences extracted from multiple newspaper articles. Results of our experiment show that sentence reordering has a discernible effect on summary readability. The results also shows significant improvement on sentence arrangement compared to former methods.	Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo 1138656, Japan; AIST Tokyo Waterfront, Cyber Assist Res Ctr, Koto Ku, Tokyo 1350064, Japan	Okazaki, N (reprint author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.	okazaki@miv.t.u-tokyo.ac.jp					Barzilay R, 2002, J ARTIF INTELL RES, V17, P35; Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/290941.291025; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HIRAO T, 2004, IN PRESS 4 NTCIR WOR; Hobbs J. R., 1990, CSLI LECT NOTES; Hume D., 1748, PHILOS ESSAYS HUMAN; Lapata M., 2003, P 41 M ASS COMP LING, P545; MANI I, 2003, P HLT NAACL03; Mani I, 2000, P 38 ANN M ASS COMP, P69, DOI 10.3115/1075218.1075228; MANN William C., 1988, TEXT, V8, P243, DOI 10.1515/text.1.1988.8.3.243; OKAZAKI N, 2004, IN PRESS 4 NTCIR WOR	11	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22817-9	LECT NOTES ARTIF INT			2004	3157						882	891				10	Computer Science, Artificial Intelligence	Computer Science	BAU59	WOS:000223633300093	
S	Vijay, PA; Murty, MN; Subramanian, DK		Kittler, J; Petrou, M; Nixon, M		Vijay, PA; Murty, MN; Subramanian, DK			An efficient technique for protein sequence clustering and classification	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 2	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			In this paper, a technique to reduce time and space during protein se quene clustering and classification is presente d. During training and testing phase, the similarity score value between a pair of sequences is determined by sele cting a portion of the sequence inste ad of the entire sequence. It is like sele cting a subset of featur es for sequence data sets. The experimental results of the proposed method shows that the classification accuracy (CA) using the prototyp es generate d/used do not degrade much but the tr aining and testing time are reduc ed significantly. Thus the experimental results indicate that the similarity score need not b e calculated by considering the entire length of the sequence for achieving a good CA. Even sp ace requir ement is reduc ed during execution phase. We have tested this using K-medians, Supervised K-medians and Nearest Neighbour Classifier (NNC) techniques.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Vijay, PA (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JASON TL, 1994, NUCLEIC ACIDS RES, V6, P559; KRIVENTSEVA EV, 2001, NUCLEIC ACIDS RES, P29; MARTINEZ HCD, 2003, PATTERN RECOGN, V3, P173; MOUNT DW, 2002, BIOINFORMATICS SEQUE; PETER C, 2000, COMPUTATIONAL MOL BI; SHARAN R, 2000, P 8 ISMB; SOMERVUO P, 2000, P 3 INT C DISC SCI, P76; VIJAYA PA, 2003, P 5 ICAPR, P129; VIJAYA PA, 2003, P IEEE TENCON AS PAC, P409; XIAOQUIN H, 1991, ADV APPL MATH, V12, P337; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; YONA G, 2000, NUCLEIC ACIDS RES, P28	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2128-2	INT C PATT RECOG			2004							447	450		10.1109/ICPR.2004.1334254		4	Computer Science, Artificial Intelligence	Computer Science	BAW22	WOS:000223877400109	
S	Paredes, R; Vidal, E		Kittler, J; Petrou, M; Nixon, M		Paredes, R; Vidal, E			Learning prototypes and distances (LPD). A prototype reduction technique based on nearest neighbor error minimization	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 3	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc	nearest neighbor condensing; weighted dissimilarity distances	FACE DETECTION; CLASSIFICATION; RECOGNITION	A prototype reduction algorithm is proposed which simultaneous train both a reduced set of prototypes and a suitable local metric for these prototypes. Starting with an initial selection of a small number of prototypes, it iteratively adjusts both the position (features) of these prototypes and the corresponding local-metric weights. The resulting prototypes/metric combination minimizes a suitable estimation of the classification error probability. Good performance of this algorithm is assessed through experiments with a number of benchmark data sets and through a real two-class classification task which consists of detecting human faces in unrestricted-background pictures.	Univ Politecn Valencia, Dept Sistemas Informat & Computac, Valencia, Spain	Paredes, R (reprint author), Univ Politecn Valencia, Dept Sistemas Informat & Computac, Valencia, Spain.						Blake C.L., UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PAREDES R, 2000, 15 INT C PATT REC 15; PAREDES R, 2003, THESIS DSIC UPV; Peng J, 2002, P IEEE INT C PATT RE; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Short R. D., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Titsias MK, 2003, IEEE T PATTERN ANAL, V25, P924, DOI 10.1109/TPAMI.2003.1206521	13	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2128-2	INT C PATT RECOG			2004							442	445		10.1109/ICPR.2004.1334561		4	Computer Science, Artificial Intelligence	Computer Science	BAW25	WOS:000223879500108	
S	Kato, T; Wada, T		Kittler, J; Petrou, M; Nixon, M		Kato, T; Wada, T			Direct condensing: An efficient Voronoi condensing algorithm for nearest neighbor classifiers	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 3	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			Voronoi condensing reduces training patterns of nearest neighbor classifiers without changing the classification boundaries. This method plays important roles not only in the nearest neighbor classifiers but also in the other classifiers such as the support vector machines, because the resulting prototype patterns involve support vectors in many cases. However, previous algorithms for Voronoi condensing were computationally inefficient in general Pattern Recognition tasks. This is because they use proximity graphs for entire training patters, which require computational time exponentially for the dimension of pattern space. For solving this problem, we proposed an efficient algorithm for Voronoi condensing named direct condensing that does not require the entire proximity graphs of training patterns. We confirmed that direct condensing efficiently calculates Voronoi condensed prototypes in high dimension (from 2 to 20 dimensions).	Wakayama Univ, Dept Comp & Commun Sci, Wakayama 6408510, Japan	Kato, T (reprint author), Wakayama Univ, Dept Comp & Commun Sci, 930 Sakaedani, Wakayama 6408510, Japan.						AHA DW, 1991, CASE BASED REASONING, P147; BARDFORD C, 1996, ACM T MATH SOFTWARE, V22, P469; BHATTACHARYA, 1981, INT S INF THEOR SANT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Shibata T, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P641; Vapnik V.N., 1998, STAT LEARNING THEORY	9	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2128-2	INT C PATT RECOG			2004							474	477		10.1109/ICPR.2004.1334569		4	Computer Science, Artificial Intelligence	Computer Science	BAW25	WOS:000223879500116	
S	Viswanath, P; Murty, MN; Bhatnagar, S		Kittler, J; Petrou, M; Nixon, M		Viswanath, P; Murty, MN; Bhatnagar, S			A pattern synthesis technique with an efficient nearest neighbor classifier for binary pattern recognition	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			Important factors affecting the efficiency and performance of the nearest neighbor classifier (NNC) are space, classification time requirements and for high dimensional data, due to the curse of dimensionality, the training set size should be large. In this paper we propose novel techniques to improve the performance of NNC and at the same time to reduce its computational burden. A compact representation of the training set along with an efficient NNC which does implicit pattern synthesis is presented. A comparison of empirical results is made with relevant methods.	Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India	Viswanath, P (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI; Efron B., 1979, ANN STAT, V1, P1; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814	4	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2128-2	INT C PATT RECOG			2004							416	419				4	Computer Science, Artificial Intelligence	Computer Science	BAW23	WOS:000223878400101	
S	Franco, A; Maltoni, D; Nanni, L		Kittler, J; Petrou, M; Nixon, M		Franco, A; Maltoni, D; Nanni, L			Reward-punishment editing	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc		NEAREST NEIGHBOR RULES	In this work a novel editing technique is proposed. The basic idea of the algorithm is to reward patterns that contribute to a correct classification and to punish those that provide a wrong one. Reward-punishment is performed according to two criteria: the former operates at very local level while the latter analyses the training set at coarser scales in a multi-resolution fashion. A score is calculated for each pattern according to the two criteria and patterns whose score is lower than a predefined threshold are edited out. Experiments carried out on two difficult classification problems show the superiority of this method with respect to other well known approaches.	Univ Bologna, DEIS, IEIIT, CNR, I-40136 Bologna, Italy	Franco, A (reprint author), Univ Bologna, DEIS, IEIIT, CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.						BARANDELA R, 2000, JOINT IAPR INT WORKS, P621; Bezdek J., 1981, PATTERN RECOGNITION; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; PARADES R, 2000, P INT C PATT REC ICP, V2, P25; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; Watson C.I., 1992, NIST SPECIAL DATABAS; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	10	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2128-2	INT C PATT RECOG			2004							424	427		10.1109/ICPR.2004.1333793		4	Computer Science, Artificial Intelligence	Computer Science	BAW23	WOS:000223878400103	
S	Liu, W; Wang, YH; Li, SZ; Tan, TN		Kittler, J; Petrou, M; Nixon, M		Liu, W; Wang, YH; Li, SZ; Tan, TN			Nearest intra-class space classifier for face recognition	PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOL 4	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	17th International Conference on Pattern Recognition (ICPR)	AUG 23-26, 2004	Cambridge, ENGLAND	Int Assoc Pattern Recognit, Univ Surrey, UniS, IEEE Comp Soc, HP Res Labs Bristol	British Machine Vis Assoc			In this paper we propose a novel classification method, called nearest intra-class space (NICS), for face recognition. In our method, the distribution of face patterns of each person is represented by the intra-class space to capture all intra-class variations. Then, a regular principal subspace is derived from each intra-class space using principal component analysis. The classification is based on the nearest weighted distance, combining distance-from-subspace and distance-in-subspace, between the query face and each intra-class subspace. Experimental results show that the NICS classifier outperforms other classifiers in terms of recognition performance.	Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China	Liu, W (reprint author), Chinese Acad Sci, Inst Automat, NLPR, POB 2728, Beijing, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; MOGHADDAM B, 1998, ADV NEURAL INFORMATI, V11, P910; Oja E., 1983, SUBSPACE METHODS PAT; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG XG, 2000, P INT C COMP VIS, V1, P679	7	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1051-4651	0-7695-2128-2	INT C PATT RECOG			2004							495	498				4	Computer Science, Artificial Intelligence	Computer Science	BAW23	WOS:000223878400119	
B	Poyhonen, S; Conti, M; Cavallini, A; Montanari, GC; Filippetti, F			IEEE	Poyhonen, S; Conti, M; Cavallini, A; Montanari, GC; Filippetti, F			Insulation defect localization through partial discharge measurements and numerical classification	Proceedings of the IEEE-ISIE 2004, Vols 1 and 2			English	Proceedings Paper	IEEE International Symposium on Industrial Electronics	MAY 04-07, 2004	Ajaccio, FRANCE	IEEE		partial discharges; insulation systems; defect localization; support vector machine	PATTERN-CLASSIFICATION	Partial discharge (PD) analysis is a fundamental tool to guide decision making in electrical insulation diagnosis for condition based maintenance. In this paper, PD signals are analyzed to localize defects in insulation systems. The task of automatic defect localization with respect to electrodes has a wide range of industrial applications. In fact, depending on the apparatus type., risk assessment is remarkably affected by defect location with respect to the electrodes. In this study.. various parameters are first extracted from PD distributions., and statistical analysis is performed to select the most significant parameters concerning localization. Then, the localization process is carried out through numerical classification. Three different classification methods are compared to find the best approach for this application. Comparing a k-nearest neighbor classifier, a probabilistic neural network and a support vector machine (SVM) based classifier, the best results are gained with SVM. although the former two are simpler to implement and easier to tune. SVM based classification has not been applied in PD analysis before this research.	Helsinki Univ Technol, Control Engn Lab, Helsinki, Finland	Poyhonen, S (reprint author), Helsinki Univ Technol, Control Engn Lab, Helsinki, Finland.						Rahman MKA, 2000, IEE P-SCI MEAS TECH, V147, P7, DOI 10.1049/ip-smt:20000074; CAVALLINI A, 2002, P IEEE C EL INS DIEL, P698; Cavallini A, 2003, IEEE T DIELECT EL IN, V10, P216, DOI 10.1109/TDEI.2003.1194102; Contin A, 2002, IEEE T DIELECT EL IN, V9, P335, DOI 10.1109/TDEI.2002.1007695; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI; Danikas MG, 2003, ELECTR ENG, V85, P87, DOI 10.1007/s00202-002-0151-5; Filippetti F, 2000, IEEE T IND ELECTRON, V47, P994, DOI 10.1109/41.873207; Krzanowski W. J., 1988, PRINCIPLES MULTIVARI; Salama MMA, 2000, IEEE T DIELECT EL IN, V7, P118, DOI 10.1109/94.839349; SATISH L, 1995, IEEE T DIELECT EL IN, V2, P352, DOI 10.1109/94.395421; Specht D.F., 1988, P IEEE INT C NEURAL, V1, P525; WENZEL D, 1994, P IEEE INT S EL INS, P233, DOI 10.1109/ELINSL.1994.401523; *IEC, 2001, PART DISCH MEAS	14	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-8304-4				2004							417	422				6	Automation & Control Systems; Engineering, Industrial; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BDG38	WOS:000233365800074	
B	Long, JD; Stoecklin, S; Schwartz, DG; Patel, MK		Hamza, MH		Long, JD; Stoecklin, S; Schwartz, DG; Patel, MK			Adaptive similarity metrics in case-based reasoning	Proceedings of the Sixth IASTED International Conference on Intelligent Systems and Control			English	Proceedings Paper	6th IASTED International Conference on Intelligent Systems and Control	AUG 23-25, 2004	Honolulu, HI	Int Assoc Sci & Technol Dev, Tech Comm Control, Tech Comm Intelligent Syst & Control		case-based reasoning; metadata architecture; similarity measures		A similarity measure is a critical component in any case-based reasoning (CBR) system. It compares two cases with respect to their "features," with each feature using a separate "comparator." The results of the comparators are combined according to some rule to give an overall measure of the similarity between the given cases. Previous works have described a CBR framework that can easily be instantiated to provide a case-based reasoner for virtually any problem domain. This uses an "adaptive," or "reflective'' software architecture wherein case features are associated with their comparators dynamically via run-time references to metadata. New instances of the framework are created simply by changing the metadata. No reprogramming is required. In this paper, we extend this concept to allow for dynamic selection also of feature-comparator combination rules. This makes the framework more adaptive by eliminating, the need to reprogram it for each such new rule. The overall effect is that the entire similarity measure is described by metata. The approach is illustrated via an example.	Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA	Long, JD (reprint author), Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA.						AAMODT A, 1994, AI COMMUN, V7, P39; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GAO L, P 2002 ACM INT C MAN; Han J. W., 2000, DATA MINING CONCEPTS; Kaufman L., 1990, FINDING GROUPS DATA; LOUIS SJ, 1999, P GEN EV COMP C ORL; SCHWARTZ DG, 2002, 5 INT C INF FUS IF 0; SISTLA AP, 1997, IEEE INT C DAT ENG A; Snort Open Source Network Intrusion Prevention and Detection System (IDS/IPS), SNORT OPEN SOURCE NE; YODER J, 2001, ACM SIGPLAN NOTICES; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	11	0	1	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA		0-88986-436-5				2004							260	265				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Operations Research & Management Science	Automation & Control Systems; Computer Science; Operations Research & Management Science	BCC26	WOS:000228556100046	
S	Yang, Y; Zheng, CX; Lin, P		Sanfeliu, A; Trinidad, JFM; Ochoa, JAC		Yang, Y; Zheng, CX; Lin, P			Image thresholding via a modified fuzzy c-means algorithm	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th Iberoamerican Congress on Pattern Recognition	OCT 16-29, 2004	Puebla, MEXICO	Inst Cybernet, Math & Phys Cuba, Ctr Applicat Adv Technol Cuba, Univ La Salle, Mexico, Autonomous Univ Puebla, Int Assoc Patern Recognit, Cuban Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, Spanish Assoc Pattern Recognit & Image Anal, SIGPR SBC, Mexican Assoc Comp Vis, Neurocomp & Robit			ENTROPY; HISTOGRAM; PARTITION	In this paper, a modified fuzzy c-means (FCM) algorithm named weighted fuzzy c-means (WFCM) algorithm for image thresholding is presented. The algorithm is developed by incorporating the spatial neighborhood information into the standard FCM clustering algorithm. The weight indicates the spatial influence of the neighboring pixels on the centre pixel, which is derived from the k-nearest neighbor (k-NN) algorithm and is modified in two aspects so as to improve its property in the WFCM algorithm. To speed up the algorithm, the iteration in FCM algorithm is carried out with the statistical gray level histogram of image instead of the conventional whole data of image. The performance of the algorithm is compared with those of an existing fuzzy thresholding algorithm and widely applied between variance and entropy methods. Experimental results on both synthetic and real images are given to demonstrate the proposed algorithm is effective and efficient. In addition, due to the neighborhood model, our method is more tolerant to noise.	Xian Jiaotong Univ, Key Lab Biomed Informat Engn, Educ Minist, Inst Biomed Engn, Xian 710049, Peoples R China	Yang, Y (reprint author), Xian Jiaotong Univ, Key Lab Biomed Informat Engn, Educ Minist, Inst Biomed Engn, Xian 710049, Peoples R China.	greatyyy765@sohu.com					Bezdek J., 1981, PATTERN RECOGNITION; Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDELSTEIN WA, 1984, MED PHYS, V11, P180, DOI 10.1118/1.595484; Fu S. K., 1981, PATTERN RECOGN, V13, P3; Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6; JULIUS TT, 1974, PATTERN RECOGNITION; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Zhao MS, 2001, IEEE T FUZZY SYST, V9, P469, DOI 10.1109/91.928743	13	3	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-23527-2	LECT NOTES COMPUT SC			2004	3287						589	596				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BBE01	WOS:000225085900074	
B	Cheng, MY; Cheung, SC; Tse, TH		Ehrich, HD; Schewe, KD		Cheng, MY; Cheung, SC; Tse, TH			Towards the application of classification techniques to test and identify faults in multimedia systems	QSIC 2004: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON QUALITY SOFTWARE			English	Proceedings Paper	4th International Conference on Quality Software	SEP 08-09, 2004	Braunschweig, GERMANY	Tech Univ Braunschweig, Inst Informat Syst, Univ Hong Kong, Software Engn Grp, Swinburne Univ Technol, Ctr Software Engn		software testing; multimedia; classification; Bayesian networks; k-nearest neighbor; neural networks	SYNCHRONIZATION	The advances in computer and graphic technologies have led to the popular use of multimedia for information exchange. However multimedia systems are difficult to test. A major reason is that these systems generally exhibit fuzziness in their temporal behaviors. The fuzziness is caused by the existence of non-deterministic factors in their runtime environments, such as system load and network traffic. It complicates the analysis of test results. The problem is aggravated when a test involves the synchronization of different multimedia streams as well as variations in system loading. In this paper, we conduct an empirical study on the testing and fault-identification of multimedia systems by treating the issue as a classification problem. Typical classification techniques, including Bayesian networks, k-nearest neighbor and neural networks, are experimented with the use of X-Smiles, an open source multimedia authoring tool supporting the Synchronized Multimedia Integration Language (SMIL). The encouraging result of our study, which is based only on five attributes, shows that our proposal can achieve an accuracy of 57.6 to 79.2% in identifying the types of fault in environments where common cause variations are present. A further improvement Of 7.6% is obtained via normalization.	Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Tse, TH (reprint author), Univ Hong Kong, Dept Comp Sci, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.		Tse, T.H./C-6590-2008				ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; ARBACH L, 2003, P IEEE CAN C EL COMP, V3, P1441; Baek S, 2000, ELECTRON LETT, V36, P1821, DOI 10.1049/el:20001249; Beizer B., 1990, SOFTWARE TESTING TEC; Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691; BUJA A, IN PRESS J COMPUTATI; Burr Ridge I, 1997, MACHINE LEARNING; Chen TY, 2003, INFORM SOFTWARE TECH, V45, P1, DOI 10.1016/S0950-5849(02)00129-5; CHEUNG SC, 2001, P 12 INT S SOFTW REL, P210; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fix E., 1952, 11 USAF SCH AV MED; Groenen P. J. F., 1993, MAJORIZATION APPROAC; Guojun Lu, 1996, COMMUNICATION COMPUT; LEE J, 1990, IEEE T GEOSCI REMOTE, V28, P846, DOI 10.1109/36.58972; LITTLE TDC, 1990, IEEE J SEL AREA COMM, V8, P413, DOI 10.1109/49.53017; Liu J.N.K., 1999, P IEEE INT C SYST MA, V3, P429; Padberg F, 2004, IEEE T SOFTWARE ENG, V30, P17, DOI 10.1109/TSE.2004.1265733; Russell E. L., 2000, DATA DRIVEN TECHNIQU; SU JL, 2001, P 23 ANN INT C IEEE, V4, P3824; ZIV H, 1997, BAYESIAN NETWORK CON; Ziv H., 1997, Proceedings International Conference on Software Maintenance (Cat. No.97CB36119), DOI 10.1109/ICSM.1997.624236	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2207-6				2004							32	40				9	Computer Science, Software Engineering	Computer Science	BBA88	WOS:000224457200005	
S	Skowron, A; Wojna, A		Tsumoto, S; Slowinski, R; Komorowski, J; GrzymalaBusse, JW		Skowron, A; Wojna, A			K nearest neighbor classification with local induction of the simple value difference metric	ROUGH SETS AND CURRENT TRENDS IN COMPUTING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	4th International Conference on Routh Sets and Current Trends in Computing	JUN 01-05, 2004	Uppsala, SWEDEN		Uppsala Univ			The classical k nearest neighbor (k-nn) classification assumes that a fixed global metric is defined and searching for nearest neighbors is always based on this global metric. In the paper we present a model with local induction of a metric. Any test object induces a local metric from the neighborhood of this object and selects k nearest neighbors according to this locally induced metric. To induce both the global and the local metric we use the weighted Simple Value Difference Metric (SVDM). The experimental results show that the proposed classification model with local induction of a metric reduces classification error up to several times in comparison to the classical k-nn method.	Warsaw Univ, Fac Math Informat & Mech, PL-02097 Warsaw, Poland	Skowron, A (reprint author), Warsaw Univ, Fac Math Informat & Mech, Ul Banacha 2, PL-02097 Warsaw, Poland.	skowron@mimuw.edu.pl; wojna@mimuw.edu.pl					Blake CL, 1998, UCI REPOSITORY MACHI; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Burr Ridge I, 1997, MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2002, P 2 SIAM INT C DAT M; Domingos P, 1996, MACH LEARN, V24, P141; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN J, 1994, 113 DEP STAT STANF U; Gora G, 2002, FUND INFORM, V51, P369; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; PAWLAK Z, 1991, ROUGH SETS THEOERETI; Skowron A., 2003, ROUGH NEURAL COMPUTI, P43; Vapnik V.N., 1998, STAT LEARNING THEORY; Wojna A, 2003, FUND INFORM, V56, P285	14	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22117-4	LECT NOTES ARTIF INT			2004	3066						229	234				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAH82	WOS:000222323600027	
B	Hao, YL; Quirchmayr, G; Stumptner, M		Chen, J		Hao, YL; Quirchmayr, G; Stumptner, M			MOUCLAS mining on well logging data	SERVICE SYSTEMS AND SERVICE MANAGEMENT - PROCEEDINGS OF ICSSSM '04, VOLS 1 AND 2			English	Proceedings Paper	International Conference on Service Systems and Service Management	JUL 19-21, 2004	Beijing, PEOPLES R CHINA	IEEE Syst, Man & Cybernet Soc, Tsinghua Univ, Sch Econ & Management		data mining; MOUCLAS pattern; oil/gas formation identification		Oil/gas formation identification is one of the most costly and challenging tasks of the service IT community in petroleum industry, where the petroleum database contains such records (or attributes) as various types of well logging data whose values are all quantitative. This paper proposes a novel data mining algorithm for the classification over quantitative data, based on a new pattern called MOUCLAS (MOUntain function based CLASsification) Patterns. The aim of the study is to apply MOUCLAS mining on the well logging data for purpose of oil/gas formation identification. From data mining point of view, the motivation of the study is to develop an association rule based classifier, which can has any number of predicates in the antecedent and overcome the limitation caused by the discretization method, for quantitative attributes by the concepts of clustering. An illustration of using well logging data for oil/gas formation identification is presented in the paper. MOUCLAS is ideally suitable to derive the implicit relationship between measured values (well logging data) and properties to be predicted (oil/gas formation or not). As a hybrid of classification and clustering and association rules mining, our approach have several advantages which are (1) it has a solid mathematical foundation and compact mathematical description of classifiers, (2) it does not require discretization, (3) it is robust when handling noisy or incomplete data in high dimensional data space, (4) it is not sensitive to the order of input items and it scales linearly with the size of input.				Stumptner, Markus/B-5558-2009				AMINZADEH F, 1996, GCSEPFM, P1; Balan B., 1995, 30978 SPE; Chiu S.L., 1994, J INTELLIGENT FUZZY, V2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOUGHERTY J, 1995, P 12 INT C MACH LEAR, P94; Ellis D. V., 1987, WELL LOGGING EARTH S; FAYYAD U., 1996, ADV KNOWLEDGE DISCOV, P1; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Han J. W., 2000, DATA MINING CONCEPTS; Hinneburg A., 1998, KNOWLEDGE DISCOVERY, P58; LENT B, 1997, ICDE, P220; Li J., 2001, KNOWL INF SYST, V3, P131, DOI 10.1007/PL00011662; Liu B., 1998, KNOWLEDGE DISCOVERY, P80; Meretakis D., 1999, P 5 ACM SIGKDD INT C, P165, DOI 10.1145/312129.312222; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rider M., 1996, GEOLOGICAL INTERPRET; SKIKANT R, 1996, SIG MOD 96, P1; Yager RR, 1994, J INTELL FUZZY SYST, V2, P209	18	0	0	INTERNATIONAL ACADEMIC PUBLISHERS LTD	HONG KONG	UNIT 1205, 12 FLOOR, SINO PLAZA, 255 GLOUCESTER ROAD, HONG KONG 00000, CAUSEWAY BAY, PEOPLES R CHINA		7-5062-6821-3				2004							475	479				5	Computer Science, Artificial Intelligence; Management; Operations Research & Management Science	Computer Science; Business & Economics; Operations Research & Management Science	BAV84	WOS:000223847800095	
S	Naude, JJ; van Wyk, MA; van Wyk, BJ		Fred, A; Caelli, T; Duin, RPW; Campilho, A; DeRidder, D		Naude, JJ; van Wyk, MA; van Wyk, BJ			Geneneralized variable-kernel similarity metric learning	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th International Workshop on Structural and Syntactic Pattern Recognition/5th International Conference on Statistical Techniques in Pattern Recognition	AUG 18-20, 2004	Lisbon, PORTUGAL	Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento				Proximity-based classifiers such as RBF-networks and nearest-neighbour classifiers are notoriously sensitive to the metric used to determine distance between samples. In this paper a method for learning such a metric from training data is presented. This algorithm is a generalization of the so called Variable-Kernel Similarity Metric (VSM) Learning, originally proposed by Lowe and is therefore known as Generalized Variable-Kernel Similarity Metric (GVSM) learning. Experimental results show GVSM to be superior to VSM for extremely noisy or cross-correlated data.	Rand Afrikaans Univ, Johannesburg, South Africa; Kentron Dynam, Centurion, South Africa; Tshwane Univ Technol, French S African Tech Inst Elect, Pretoria, South Africa	Naude, JJ (reprint author), Rand Afrikaans Univ, Auckland Pk, Johannesburg, South Africa.	hannes.naude@kentron.co.za; mavw@fsatie.ac.za; ben.van.wyk@fsatie.ac.za					BEIS J, 1997, C COMP VIS PATT REC, P1000; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R., 1973, PATTERN CLASSIFICATI; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061	6	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22570-6	LECT NOTES COMPUT SC			2004	3138						788	796				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAS89	WOS:000223398900086	
S	Kudo, M; Imai, H; Tanaka, A; Murai, T		Fred, A; Caelli, T; Duin, RPW; Campilho, A; DeRidder, D		Kudo, M; Imai, H; Tanaka, A; Murai, T			A nearest neighbor method using bisectors	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	10th International Workshop on Structural and Syntactic Pattern Recognition/5th International Conference on Statistical Techniques in Pattern Recognition	AUG 18-20, 2004	Lisbon, PORTUGAL	Inst Telecommun, Inst Super Tecn, Int Assoc Pattern Recognit, Fund Luso-Amer Desenvolvimento			ALGORITHM; RULE	A novel algorithm for finding the nearest neighbor was proposed. According to the development of modern technology, the demand is increasing in large-scale datasets with a large number of samples and a large number of features. However, almost all sophisticated algorithms proposed so far are effective only in a small number of features, say, up to 10. This is because in a high-dimensional space many pairs of samples share a same distance. Then the naive algorithm outperforms the others. In this study, we considered to utilize a sequential information of distances obtained by the examined training samples. Indeed, a combinatorial information of examined samples was used as bisectors between possible pairs of them. With this algorithm, a query is processed in O(alphabetand) for n samples in a d-dimensional space and for alpha,beta < 1, in expense of a preprocessing time and space in O(n(2)). We examined the performance of the algorithm.	Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Sapporo, Hokkaido 0608628, Japan	Kudo, M (reprint author), Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Kita 13,Nishi 8, Sapporo, Hokkaido 0608628, Japan.	mine@main.eng.hokudai.ac.jp; imai@main.eng.hokudai.ac.jp; takira@main.eng.hokudai.ac.jp; murahiko@main.eng.hokudai.ac.jp	Kudo, Mineichi/B-9973-2011				Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; CHANG CC, 1993, PATTERN RECOGN LETT, V14, P625, DOI 10.1016/0167-8655(93)90047-H; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P268; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KLINBERG J, 1997, P 29 ACM S THEOR COM, P599; KUDO M, 2003, PATTERN RECOGN, V24, P1213; MANEEWONGVATANA S, 2001, P 7 WORKSH ALG DAT S, P276; MURPHY PM, 1991, UCI REPOSITORY MACHI	12	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-22570-6	LECT NOTES COMPUT SC			2004	3138						885	893				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BAS89	WOS:000223398900097	
J	Nguyen, SH; Bazan, J; Skowron, A; Nguyen, HS				Nguyen, SH; Bazan, J; Skowron, A; Nguyen, HS			Layered learning for concept synthesis	TRANSACTIONS ON ROUGH SETS I	LECTURE NOTES IN COMPUTER SCIENCE		English	Article						concept synthesis; hierarchical schema; layered learning; rough sets	GRANULES; WORDS	We present a hierarchical scheme for synthesis of concept approximations based on given data and domain knowledge. We also propose a solution, founded on rough set theory, to the problem of constructing the approximation of higher level concepts by composing the approximation of lower level concepts. We examine the effectiveness of the layered learning approach by comparing it with the standard learning approach. Experiments are carried out on artificial data sets generated by a road traffic simulator.	Polish Japanese Inst Informat Technol, PL-02008 Warsaw, Poland; Univ Rzeszow, Inst Math, PL-35959 Rzeszow, Poland; Warsaw Univ, Inst Math, PL-02097 Warsaw, Poland	Nguyen, SH (reprint author), Polish Japanese Inst Informat Technol, Koszykowa 86, PL-02008 Warsaw, Poland.	hoa@mimuw.edu.pl; bazan@mimuw.edu.pl; skowron@mimuw.edu.pl; son@mimuw.edu.pl	Nguyen, Hung Son /I-7452-2012; Nguyen, Sinh Hoa/G-8901-2013				Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; BARWISE J, 1997, TRACTS THEORETICAL C, V44; Bazan J., 1998, ROUGH SETS KNOWLEDGE, V1, P321; Bazan J, 2003, LECT NOTES ARTIF INT, V2639, P181; Bazan J.G., 2001, LECT NOTES ARTIF INT, V2005, P106; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIREDMAN J, 2001, ELEMENTS STAT LEARNI; Grzymala-Busse J. W., 1997, Fundamenta Informaticae, V31; KLOESGEN W, 2002, HDB KNOWLEDGE DISCOV; Komorowski J., 1999, ROUGH FUZZY HYBRIDIZ, P3; Mitchell TM, 1998, MACHINE LEARNING; Pal S. K., 2003, ROUGH NEURAL COMPUTI; Pawlak Z., 1991, SYSTEM THEORY KNOWLE, V9; Poggio T., 2003, NOTICES AMS, V50, P537; Polkowski L, 2001, COMPUT INTELL, V17, P472, DOI 10.1111/0824-7935.00159; Polkowski L., 1999, COMPUTING WORDS INFO, P201; Polkowski L, 1996, INT J APPROX REASON, V15, P333, DOI 10.1016/S0888-613X(96)00072-2; SKOWRON A, 2001, P 2 AS PAC C INT AG, P28; Skowron A, 2003, STUD FUZZ SOFT COMP, V125, P13; SKOWRON A, INFORMATION GRANULES, P43; Skowron A., 1992, HDB APPL ADV ROUGH S, V11, P331; Skowron A, 2002, ADV SOFT COMP, P338; Skowron A, 2001, FUND INFORM, V47, P337; Skowron A, 2001, INT J INTELL SYST, V16, P57, DOI 10.1002/1098-111X(200101)16:1<57::AID-INT6>3.0.CO;2-Y; Stone P., 2000, LAYERED LEARNING MUL; Wroblewski J., 1998, LECT NOTES ARTIF INT, V1424, P402; Zadeh LA, 2001, AI MAG, V22, P73; Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904	28	47	47	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		LECT NOTES COMPUT SC			2004	3100						187	208				22	Computer Science, Theory & Methods	Computer Science	BAR28	WOS:000223234300009	
J	Takagi, N; Kikuchi, H; Mukaidono, M				Takagi, N; Kikuchi, H; Mukaidono, M			Applications of fuzzy logic functions to knowledge discovery in databases	TRANSACTIONS ON ROUGH SETS II	LECTURE NOTES IN COMPUTER SCIENCE		English	Article							CLASSIFICATION	This chapter is a summary of knowledge discovery algorithms that take an input of training examples of target knowledge, and output a fuzzy logic formula that best fits the training examples. The execution is done in three steps; first, the given mapping is divided into some Q-equivalent classes; second, the distances between the mapping and each local fuzzy logic function are calculated by a simplified logic formula; and last, the shortest distance is obtained by a modified graph-theoretic algorithm. After a fundamental algorithm for fitting is provided, fuzzy logic functions are applied to a more practical example of classification problem, in which expressiveness of fuzzy logic functions is examined for a well-known machine learning database.	Toyama Prefectural Univ, Dept Elect & Informat, Toyama 9390398, Japan; Tokai Univ, Dept Informat Media Technol, Hiratsuka, Kanagawa 2591292, Japan; Meiji Univ, Dept Comp Sci, Tama Ku, Kawasaki, Kanagawa 2148571, Japan	Takagi, N (reprint author), Toyama Prefectural Univ, Dept Elect & Informat, Toyama 9390398, Japan.						Bezdek J., 1981, PATTERN RECOGNITION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fayyad U. M., 1996, ADV KNOWLEDGE DISCOV; Grabisch M, 1992, P 2 INT C FUZZ LOG N, P659; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; KANDEL A, 1973, IEEE T COMPUT, VC 22, P826; KANDEL A, 1980, IEEE T COMPUT, V29, P986; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIKUCHI H, 1991, P INT FUZZ ENG S, V1, P91; LEE RCT, 1971, INFORM CONTROL, V19, P417, DOI 10.1016/S0019-9958(71)90684-X; LIU CH, 1985, P IEEE 15 INT S MULT, P182; MUKAIDONO M, 1975, IECE T D, V58, P150; Mukaidono M., 1979, Proceedings of the Ninth International Symposium on Multiple-Valued Logic; MUKAIDONO M, 1987, ANAL FUZZY INFORM, P213; MUKAIDONO M, 1975, IECE T D, V58, P748; ROSS KA, 1988, DISCRETE MATH; RUMELHART DE, 1989, PARALLEL DISTRIBUTED; UMANO M, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P2113, DOI 10.1109/FUZZY.1994.343539; WEISS SM, 1991, COMPUTER SYSTEMS LEA, P51	19	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		LECT NOTES COMPUT SC			2004	3135						107	128				22	Computer Science, Theory & Methods	Computer Science	BBV25	WOS:000228008900007	
J	Tsiriga, V; Virvou, M				Tsiriga, V; Virvou, M			A framework for the initialization of student models in Web-based intelligent tutoring systems	USER MODELING AND USER-ADAPTED INTERACTION			English	Article						initialization; machine learning for user modeling; stereotypes; student modeling; Web-based intelligent tutoring systems	ADAPTIVE HYPERMEDIA; USER MODELS; CLASSIFICATION; TOOL	Initializing a student model for individualized tutoring in educational applications is a difficult task, since very little is known about a new student. On the other hand, fast and efficient initialization of the student model is necessary. Otherwise the tutoring system may lose its credibility in the first interactions with the student. In this paper we describe a framework for the initialization of student models in Web-based educational applications. The framework is called ISM. The basic idea of ISM is to set initial values for all aspects of student models using an innovative combination of stereotypes and the distance weighted k-nearest neighbor algorithm. In particular, a student is first assigned to a stereotype category concerning her/ his knowledge level of the domain being taught. Then, the model of the new student is initialized by applying the distance weighted k-nearest neighbor algorithm among the students that belong to the same stereotype category with the new student. ISM has been applied in a language learning system, which has been used as a test-bed. The quality of the student models created using ISM has been evaluated in an experiment involving classroom students and their teachers. The results from this experiment showed that the initialization of student models was improved using the ISM framework.	Univ Piraeus, Dept Informat, Piraeus 18534, Greece	Tsiriga, V (reprint author), Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.	vtsir@unipi.gr; mvirvou@unipi.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; AIMEUR E, 2001, P INT C COMP AID LEA, P51; Aimeur E, 2002, LECT NOTES COMPUT SC, V2363, P718; Albrecht F., 2000, Journal of Interactive Learning Research, V11; Alpert S.R., 1999, INT J ARTIFICIAL INT, V10, P183; Baffes P., 1996, Journal of Artificial Intelligence in Education, V7; Beck JE, 2000, LECT NOTES COMPUT SC, V1839, P584; BEESON MJ, 1989, P 4 INT C AI ED IOS, P9; BONTCHEVA K, 2002, LECT NOTES COMPUTER, V2347, P69; Brusilovsky P., 1998, Journal of Computing and Information Technology - CIT, V6; Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964; Burr Ridge I, 1997, MACHINE LEARNING; Burton R. B., 1982, INTELLIGENT TUTORING, P157; Chin DN, 2001, USER MODEL USER-ADAP, V11, P181, DOI 10.1023/A:1011127315884; Chiu BC, 1998, USER MODEL USER-ADAP, V8, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DASILVA P, 1997, P WEBNET 97 WORLD C, P959; DASILVA P, 1998, P 2 WORKSH AD HYP HY, P35; De Bra P, 2000, CYBERPSYCHOL BEHAV, V3, P71; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Emde W., 1996, P 13 INT C MACH LEAR, P122; GAROFALAKIS J, 2002, P IEEE INT C ADV LEA, P28; GURER DW, 1995, P AAAI SPR S REPR ME, P51; Guzman E, 2002, LECT NOTES COMPUT SC, V2363, P739; HEIFT T, 2001, INT J ARTIFICIAL INT, V12, P310; Heift T, 2000, LECT NOTES COMPUT SC, V1839, P354; Henze N., 2001, INT J ARTIFICIAL INT, V12, P325; Hoppe H. U., 1994, Journal of Artificial Intelligence in Education, V5; HOTHI J, 1998, P 2 WORKSH AD HYP HY, P45; Kay J, 2000, LECT NOTES COMPUT SC, V1839, P19; Kobsa A, 2001, KNOWL ENG REV, V16, P111, DOI 10.1017/S0269888901000108; KURHILA J, 2001, P 10 INT PEG2001 C, P194; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; MORIARTY C, 2001, P 2 DELOS NETW EXC W; MURPHY M, 1997, P 6 INT C US MOD, P301; Nwana H. S., 1991, User Modeling and User-Adapted Interaction, V1, DOI 10.1007/BF00158950; Ogata H, 2001, COMPUT EDUC, V37, P225, DOI 10.1016/S0360-1315(01)00048-3; Okazaki Y., 1996, ED TECHNOLOGY RES, V19, P35; PALIOURAS G, 1909, P 7 INT C US MOD CIS, P169; RICH E, 1983, INT J MAN MACH STUD, V18, P199, DOI 10.1016/S0020-7373(83)80007-8; Rich E., 1979, COGNITIVE SCI, V3, P329, DOI DOI 10.1207/515516709C0G0304_3; SCHWAB I, 2002, KUNSTLICHE INTELLIGE, V3, P5; Sison R, 1998, USER MODEL USER-ADAP, V8, P103, DOI 10.1023/A:1008225015395; SISON R, 1998, J ARTIFICIAL INTELLI, V9, P128; Sison RC, 2000, MACH LEARN, V38, P157, DOI 10.1023/A:1007690108308; SLEEMAN D, 1987, ARTIFICIAL INTELLIGE; Tchetagni JMP, 2002, LECT NOTES COMPUT SC, V2363, P708; TSIRIGA V, P 2002 IEEE INT C SY; TSIRIGA V, 2002, P 2002 1 INT IEEE S, V1, P138, DOI 10.1109/IS.2002.1044243; Vassileva J, 1997, FR ART INT, V39, P498; Virvou M, 1999, USER MODEL USER-ADAP, V9, P321, DOI 10.1023/A:1008385523066; Virvou M, 2001, LECT NOTES ARTIF INT, V2109, P158; Virvou M., 2001, Proceedings IEEE International Conference on Advanced Learning Technologies, DOI 10.1109/ICALT.2001.943878; Weber G., 1997, P 6 INT C US MOD, P289; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	56	17	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-1868		USER MODEL USER-ADAP	User Model. User-Adapt. Interact.		2004	14	4					289	316		10.1023/B:USER.0000043396.14788.cc		28	Computer Science, Cybernetics	Computer Science	857ZE	WOS:000224158800001	
B	Li, J; Liang, QL; Manry, MT			ieee	Li, J; Liang, QL; Manry, MT			Co-channel interference suppression with model simplification in TDMA systems	2004 IEEE 15TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-4, PROCEEDINGS			English	Proceedings Paper	15th IEEE International Symposium on Personal, Indoor, Mobile, Radio Communications (PIMRC 2004)	SEP 05-08, 2004	Barcelona, SPAIN	IEEE		mobile communication; co-channel interference; TDMA; learning vector quantization	EQUALIZER	This paper studies the co-channel interference (CCI) problem for time-division-multiple-access (TDMA) cellular mobile communication systems with burst transmission. We present a method using Learn Vector Quantization (LVQ) to cancel CCI for such systems. The model of the overall CCo is significantly simplified based on that of the individual CCI. The LVQ is realized as a classification equalizer with a decision feedback adaptive filter. An extremely small number of unique words (UWs) is utilized to initialize the LVQ equalizer. Simulation results show that the bit error rate (BER) of our proposed method is much better than that of the recently proposed nearest neighbor classification (NNC) equalizer.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.						Anderson B. D. O., 1979, OPTIMAL FILTERING; BENELLI G, 1991, P INT C GLOBECOM 91, P1469; Chen S, 1996, IEE P-COMMUN, V143, P219, DOI 10.1049/ip-com:19960612; CHEN S, 1992, SIGNAL PROCESS, V28, P91, DOI 10.1016/0165-1684(92)90067-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVELLA R, 1989, IEEE J SEL AREA COMM, V7, P122, DOI 10.1109/49.16853; FORNEY GD, 1972, IEEE T INFORM THEORY, V18, P363, DOI 10.1109/TIT.1972.1054829; GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457; Jakes W.C., 1993, MICROWAVE MOBILE COM; Kohonen T, 1990, P INT JOINT C NEUR N, P545; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LI J, 2004, IN PRESS P ICASSP 20; Liang QL, 2000, IEEE T CIRCUITS-II, V47, P1419, DOI 10.1109/82.899635; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Rappaport T.S., 1996, WIRELESS COMMUNICATI; SAVAZZI P, 2000, IEEE J SEL AREA COMM, V16, P418; SKLLAR B, 1997, IEEE COMMUN MAG, V35, P148	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-8523-3				2004							1302	1306				5	Telecommunications	Telecommunications	BBH14	WOS:000225483300253	
B	Wang, YJ; Guan, L			IEEE	Wang, YJ; Guan, L			An investigation of speech-based human emotion recognition	2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING			English	Proceedings Paper	6th IEEE Workshop on Multimedia Signal Processing	SEP 29-OCT 01, 2004	Siena, ITALY	IEEE Signal Proc Soc, Multimedia Signal Proc Tech Comm, Univ Degli Studi di Siena, Monte dei Paschi de Siena				This paper presents our recent work on recognizing human emotion from speech signal. The proposed recognition system was tested over a language, speaker, and context independent emotional speech database. Prosodic, Mel-Frequency Cepstral Coefficient (MFCC),. features are extracted from the and formant frequency speech utterances. We perform feature selection by using stepwise method based on Mahalanobis distance. The selected features are used to classify the speeches into their corresponding emotional classes. Different classification algorithms including Maximum Likelihood Classifier (MLC), Gaussian Mixture Model (GMM), Neural Network (NN), K-nearest Neighbors (K-NN), and Fisher's Linear Discriminant Analysis (FLDA) are compared in this study. The recognition results show that FLDA gives the best recognition accuracy by using the selected features.	Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON M5B 2K3, Canada	Wang, YJ (reprint author), Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON M5B 2K3, Canada.						BHATTI MW, 2004, IEEE ISCAS VANC 0523; BILMES J.A., 1998, ICSITR97021; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HIRST D, 1992, TALKING MACHINE THEO; KWON O, 2003, EMOTION RECOGNITION; LEE CM, 2002, P INT C MULT EXP	6	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-8578-0				2004							15	18				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BBC43	WOS:000224752800004	
B	Li, HF; Zhang, KS; Jiang, T			IEEE Comp Soc	Li, HF; Zhang, KS; Jiang, T			Minimum entropy clustering and applications to gene expression analysis	2004 IEEE COMPUTATIONAL SYSTEMS BIOINFORMATICS CONFERENCE, PROCEEDINGS			English	Proceedings Paper	IEEE Computational Systems Bioinformatics Conference (CSB 2004)	AUG 16-19, 2004	Stanford, CA	IEEE Comp Soc, Hewlett-Packard Co, Coop Platinum, BioMed Cent, Off Sci, US DOE			DENSITY-FUNCTION; PATTERNS; CRITERIA; NETWORK	Clustering is a common methodology for analyzing the gene expression data. In this paper, we present a new clustering algorithm from an information-theoretic point of view. First, we propose the minimum entropy (measured on a posteriori probabilities) criterion, which is the conditional entropy of clusters given the observations. Fano's inequality indicates that it could be a good criterion for clustering. We generalize the criterion by replacing Shannon's entropy with Havrda-Charvat's structural a-entropy. Interestingly, the minimum entropy criterion based on structural a-entropy is equal to the probability error of the nearest neighbor method when alpha = 2. This is another evidence that the proposed criterion is good for clustering. With a nonparametric approach for estimating a posteriori probabilities, an efficient iterative algorithm is then established to minimize the entropy. The experimental results show that the clustering algorithm performs significantly better than k-means/medians, hierarrhical clustering, SOM, and EM in terms of adjusted Rand index. Particularly, our algorithm performs very well even when the correct number of clusters is unknown. In addition, most clustering algorithms produce poor partitions in presence of outliers while our method can correctly reveal the structure of data and effectively identify outliers simultaneously.	Univ Calif Riverside, Riverside, CA 92521 USA	Li, HF (reprint author), Univ Calif Riverside, Riverside, CA 92521 USA.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Cho RJ, 1998, MOL CELL, V2, P65, DOI 10.1016/S1097-2765(00)80114-8; Cover T. M., 1991, ELEMENTS INFORMATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Duda R., 1973, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Everitt B.S., 2001, CLUSTER ANAL; FRALEY C, 2002, 415R U WASH DEP STAT; Fukunaga K., 1990, INTRO STAT PATTERN R; Han J. W., 2000, DATA MINING CONCEPTS; Havrda J., 1967, KYBERNETIKA, V3, p[1, 30]; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Hughes TR, 2000, CELL, V102, P109, DOI 10.1016/S0092-8674(00)00015-5; Ideker T, 2001, SCIENCE, V292, P929, DOI 10.1126/science.292.5518.929; Jain A., 1988, ALGORITHMS CLUSTERIN; KAPUR J, 1994, MEASURES INFORMATION; Kapur J.N., 1967, MATH SEMINAR, V4, P78; Kohonen T., 2001, SELF ORGANIZING MAPS; Li Ming, 1997, INTRO KOLMOGOROV COM; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MILLIGAN GW, 1986, MULTIVAR BEHAV RES, V21, P441, DOI 10.1207/s15327906mbr2104_5; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Renyi A., 1961, 4TH P BERK S MATH ST, V1, P547; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Shannon E., 1948, BELL SYST TECH J, V27, P623; Tavazoie S, 1999, NAT GENET, V22, P281; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; Yeung KY, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-5-r34	30	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2194-0				2004							142	151				10	Biotechnology & Applied Microbiology; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Genetics & Heredity	Biotechnology & Applied Microbiology; Computer Science; Genetics & Heredity	BAX76	WOS:000224127800015	
B	Zheng, WM; Zou, CR; Zhao, L			IEEE	Zheng, WM; Zou, CR; Zhao, L			Face recognition using two novel nearest neighbor classifiers	2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS: DESIGN AND IMPLEMENTATION OF SIGNAL PROCESSING SYSTEMS INDUSTRY TECHNOLOGY TRACKS MACHINE LEARNING FOR SIGNAL PROCESSING MULTIMEDIA SIGNAL PROCESSING SIGNAL PROCESSING FOR EDUCATION			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing	MAY 17-21, 2004	Montreal, CANADA	IEEE Signal Proc Soc, IEEE			FEATURE LINE METHOD; CLASSIFICATION; RETRIEVAL	In this paper, two novel classifiers based on locally nearest neighborhood rule, called nearest neighbor line (NNL) and nearest neighbor plane (NNP), are presented for face recognition. The underlying idea of both classifiers is the local linear combination technique that has been previously used in locally linear embedding (LLE) for nonlinear dimension reduction. Comparison to other linear combination based classifiers such as the nearest feature line (NFL) and the nearest feature plane (NFP), the proposed method takes much lower computation cost. Furthermore, the experimental results on the ORL face database have shown that the performance of both proposed methods are competitive to the NFL and NFP in face classification.	Southeast Univ, Res Ctr Learning Sci, Nanjing 210096, Jiangsu, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Res Ctr Learning Sci, Nanjing 210096, Jiangsu, Peoples R China.						BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/cviu.1994.1019; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; SAUL LK, INTRO LOCALLY LINEAR; ULHMAN S, 1991, IEEE T PAMI, V13, P992	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA						2004							725	728				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Telecommunications	Computer Science; Engineering; Imaging Science & Photographic Technology; Telecommunications	BAH10	WOS:000222179700182	
B	Fuentealba, C; Simon, C; Choffel, D; Charpentier, P; Masson, D			IEEE	Fuentealba, C; Simon, C; Choffel, D; Charpentier, P; Masson, D			Wood products identification by internal characteristics readings	2004 IEEE International Conference on Industrial Technology (ICIT), Vols. 1- 3			English	Proceedings Paper	IEEE International Conference on Industrial Technology (ICIT)	DEC 08-10, 2004	Hammamet, TUNISIA	IEEE		wood product; automatic identification; traceability; k-nearest neighbors		The traceability of products is an ever growing demand of quality for many areas. In the manufacturing process, traceability is required to follow-up all the production cycle of the product. Consequently, product traceability can result in a great control of the production process, thus allows improving control of production tools and reacting to their deficiencies. For wood industries, implementation of current identification techniques is not easy, due to the extremely variable nature of the wood and the particular features of the manufacturing process. In this article, we implement a traceability tool within a manufacturing process using the intrinsic characteristics of the wood product. The goal is to achieve an individual identification of products. We use a microwave sensor to obtain a unique signature of the product and then we develop its identification. Thus, the identification process on the basis of a numerical product signature can be considered as a discrimination problem as for the nearest neighbor method. We evaluate the error rate of identification by a Monte Carlo simulation of the process. This work shows the high potential of developing an identification system based on the use of the intrinsic characteristics of product.	CRAN, Fac Sci, F-54506 Vandoeuvre Les Nancy, France	Fuentealba, C (reprint author), CRAN, Fac Sci, BP 239, F-54506 Vandoeuvre Les Nancy, France.						CHARPENTIER P, 2003, FOREST PRODUCTS J, V53; CHAXEL F, 2002, P IEEE INT C SYST MA, V4; Chiorescu S, 2003, FOREST PROD J, V53, P78; CHOFFEL D, 2001, P 10 IFAC S INF CONT; CHOFFEL D, 1992, P 1 SEM SCANN TECHN; CHOFFEL D, 1999, P SPIE MACH VIS SYST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GUZENDA R, 2000, 12 INT S NOND TEST W; JAIN A, 2000, COMMUNICATIONS ACM, V43; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Menard M, 2001, FUZZY SET SYST, V122, P363, DOI 10.1016/S0165-0114(00)00052-X; PARKER JR, 2002, P VIS INT 2002 CALG, P27; SASAKI Y, 2000, 12 INT S NOND TEST W; SIMON C, 1997, P BRAZ S DOC IM AN, P261; TANAKA T, 2000, 12 INT S NOND TEST W; TORGONIKOV GI, 1992, DIELECTRIC PROPERTIE; WALKER JCF, 1992, PRIMARY WOOD PROCESS	18	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-8662-0				2004							763	768				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BCW39	WOS:000231537500136	
S	Figueira, LB; Nicoletti, MD			IEEE	Figueira, LB; Nicoletti, MD			Evaluating the effects of distance metrics on a NGE-based system	2004 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN & CYBERNETICS, VOLS 1-7	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2004	The Hague, NETHERLANDS	IEEE		NGE learning; distance metrics; HVDM; IVDM; WVDM	LEARNING ALGORITHMS; NEAREST-NEIGHBOR; CLASSIFICATION	The Nested Generalized Exemplar (NGE) model (implemented by EACH algorithm) is an incremental form of inductive learning from examples that generalizes a given training set into hypotheses represented as a set of hyper-rectangles in an n-dimensional Euclidean space. NGE depends heavily on the distance Metric used in both processes, learning and classification. This work investigates the impact on the predictive accuracy of the learnt concepts by NGE as a consequence of using three new heterogeneous distance functions namely HVDM, IVDM and WVDM, instead of the Euclidean distance metric originally proposed. The paper presents and analyses the results of experiments in various domains using the Euclidean and the three heterogeneous distance functions.	Unif Fed San Carlos, Dept Comp Sci, Sao Carlos, SP, Brazil	Figueira, LB (reprint author), Unif Fed San Carlos, Dept Comp Sci, Sao Carlos, SP, Brazil.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Merz C.J., 1998, UCI REPOSITORY MACHI; SALZBERG S, 1991, MACH LEARN, V6, P252; SALZBERG SL, 1989, THESIS HARVARD U CAM; Schaffer C., 1994, P 11 INT C MACH LEAR, P259; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOLPERT DH, 92035001 SFI TR NM	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	0-7803-8566-7	IEEE SYS MAN CYBERN			2004							3395	3401		10.1109/ICSMC.2004.1400867		7	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Robotics	Automation & Control Systems; Computer Science; Robotics	BBP32	WOS:000226863300572	
S	Snchez, JS; Sotoca, JM; Pla, F			IEEE	Snchez, JS; Sotoca, JM; Pla, F			Efficient nearest neighbor classification with data reduction and fast search algorithms	2004 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN & CYBERNETICS, VOLS 1-7	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2004	The Hague, NETHERLANDS	IEEE		classification; nearest neighbor; data reduction; fast search algorithm	PATTERN-CLASSIFICATION; RULE	The Nearest Neighbor classfier is one of the most popular non-parametric classification methods. It is very simple, intuitive and accurate in a great variety of real-world applications. Despite its simplicity and effectiveness, practical use of this decision rule has been historically limited due to its high storage requirements and the computational costs involved. In order to overcome these drawbacks, it is possible either to employ fast search algorithms or to use a training set size reduction scheme. The present paper provides a comparative analysis of fast search algorithms and data reduction techniques to assess their pros and cons from both theoretical and practical viewpoints.	Univ Jaume 1, Dept Llenguatges & Sist Informt, E-12071 Castellon de La Plana, Spain	Snchez, JS (reprint author), Univ Jaume 1, Dept Llenguatges & Sist Informt, Av Sos Baynat S-N, E-12071 Castellon de La Plana, Spain.						ALINAT P, 1993, 5516 ROARS ESPRIT; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Devijver P. A., 1982, PATTERN RECOGNITION; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Merz C.J., 1998, UCI REPOSITORY MACHI; MIC L, 1996, PATTERN RECOGN, V17, P731; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311	26	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X	0-7803-8566-7	IEEE SYS MAN CYBERN			2004							4757	4762				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Robotics	Automation & Control Systems; Computer Science; Robotics	BBP32	WOS:000226863300801	
S	Zeng, XC; Martinez, TR			ieee	Zeng, XC; Martinez, TR			Feature weighting using neural networks	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council			LEARNING ALGORITHMS	In this work we propose a feature weighting method for classification tasks by extracting relevant information from a trained neural network. This method weights an attribute based on strengths (weights) of related links in the neural network, in which an important feature is typically connected to strong links and has more impact on the outputs. This method is applied to feature weighting for the nearest neighbor classifier and is tested on 15 real-world classification tasks. The results show that it can improve the nearest neighbor classifier on 14 of the 15 tested tasks, and also outperforms the neural network on 9 tasks.	Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Zeng, XC (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; Breiman L, 1984, CLASSIFICATION REGRE; Cardie C., 1993, P 10 INT C MACH LEAR, P25; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; John G. H., 1994, P 11 INT C MACH LEAR, P121; Ling CX, 1997, INT J PATTERN RECOGN, V11, P405, DOI 10.1142/S0218001497000184; Merz C. J., 1996, UCI REPOSITORY MACHI; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	9	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	0-7803-8359-1	IEEE IJCNN			2004							1327	1330				4	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900230	
S	Anguita, D; Ridella, S; Rivieccio, F; Zunino, R; Amerio, S; Lazzizzera, I			ieee	Anguita, D; Ridella, S; Rivieccio, F; Zunino, R; Amerio, S; Lazzizzera, I			Model selection in top quark tagging with a support vector classifier	2004 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, PROCEEDINGS	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	IEEE International Joint Conference on Neural Networks (IJCNN)	JUL 25-29, 2004	Budapest, HUNGARY	IEEE, IEEE Neural Networks Soc, Hungarian Acad Sci, Comp & Automat Res Inst, Katholieke Univ Leuven, Republic Hungary, Natl Commun & Informat Council				The problem of tagging a Top Quark generation event in data coming from the Collider Detector at Fermilab is here considered and tackled through the use of a Support Vector Machine Classifier. In order to select a fitting model, a twofold procedure has been adopted. The SVC hyperparameters have been selected through the bootstrap technique and then an additional tuning of the bias value and the error relevance has been performed by means both of a Purity Vs. Efficiency curve and of the AUC value. The generalization capability of the model has been evaluated using the Maximal Discrepancy criterion.	Univ Genoa, Dept Biophys & Elect Engn, DIBE, I-16145 Genoa, Italy	Anguita, D (reprint author), Univ Genoa, Dept Biophys & Elect Engn, DIBE, Via Opera Pia 11A, I-16145 Genoa, Italy.						ABACHI S, 1997, UNPUB PHYS REV LETT; Abe F, 1997, PHYS REV LETT, V79, P1992, DOI 10.1103/PhysRevLett.79.1992; Anguita D, 2000, NEURAL PROCESS LETT, V11, P51, DOI 10.1023/A:1009636300083; Anguita D, 2003, NEUROCOMPUTING, V55, P109, DOI 10.1016/S0925-2312(03)00430-2; Bartlett PL, 2002, MACH LEARN, V48, P85, DOI 10.1023/A:1013999503812; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CORTES C, 2004, ADV NEURAL INFORMATI, V16; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Efron B, 1993, MONOGRAPHS STAT APPL; EGAN JP, 1975, SIGNAL DETECTION THE; Fisher RA, 1936, ANN EUGENIC, V7, P179; GUYON I, ONLINE SVM APPL LIST; LAENEN E, 1994, PHYS LETT B, V321, P254, DOI 10.1016/0370-2693(94)90473-1; PARISI G, 1978, PHYS LETT B, V74, P65, DOI 10.1016/0370-2693(78)90061-8; SIDOTI A, 1999, THESIS U TRENTO; SJOSTRAND T, 1986, COMPUT PHYS COMMUN, V39, P347, DOI 10.1016/0010-4655(86)90096-2; VANNEREM P, 1999, P AIHENP 99; Vapnik V.N., 1998, STAT LEARNING THEORY	19	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576	0-7803-8359-1	IEEE IJCNN			2004							2059	2064				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BBC97	WOS:000224941900356	
S	Chakrabarti, A; Regev, O			ieee computer society	Chakrabarti, A; Regev, O			An optimal randomised cell probe lower bound for approximate nearest neighbour searching	45TH ANNUAL IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE, PROCEEDINGS	ANNUAL IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTER SCIENCE		English	Proceedings Paper	45th Annual IEEE Symposium on Foundations of Computer Science	OCT 17-19, 2004	Rome, ITALY	IEEE Comp Soc, Tech Soc Fdn Comp			PROTEIN SECONDARY STRUCTURE; PREDICTION	We consider the approximate nearest neighbour search problem on the Hamming Cube {0, 1}(d). We show that a randomised cell probe algorithm that uses polynomial storage and word size d(O(1)) requires a worst case query time of Omega (log log d/log log log d). The approximation factor may be as loose as 2(log1-eta) (d) for any fixed eta > 0. This generalises an earlier result [5] on the deterministic complexity of the same problem and, more importantly, fills a major gap in the study of this problem since all earlier lower bounds either did not allow randomisation [5, 18] or did not allow approximation [4, 2, 15]. We also give a cell probe algorithm which proves that our lower bound is optimal. Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the Richness Technique [20] used in a lot of recent research around this problem would not have helped here. Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [6, 1, 23, 14]. In particular we make heavy use of the round elimination and message compression ideas in the recent work of Sen [23] and Jain, Radhakrishnan, and Sen [14], and also introduce a new technique which we call message switching.	Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA	Chakrabarti, A (reprint author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.						Barkol O., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335350; Bar-Yossef Z., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181944; BEAME P, 2003, COMMUNICATION; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Chakrabarti A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301325; Chakrabarti A., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959901; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Berg M, 2000, COMPUTATIONAL GEOMET; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R., 1973, PATTERN CLASSIFICATI; FREDMAN ML, 1984, J ACM, V31, P538, DOI 10.1145/828.1884; Har-Peled S., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959884; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jain R., 2003, P 30 INT C AUT LANG, P300; JAYRAM TS, 2003, P 35 ANN ACM S THEOR, P667; Klauck Hartmut, 2001, P 33 ANN ACM S THEOR, P124, DOI 10.1145/380752.380786; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; LIU D, 2003, UNPUB STRONG LOWER B; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; Miltersen PB, 1998, J COMPUT SYST SCI, V57, P37, DOI 10.1006/jcss.1998.1577; Miltersen P. B., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, DOI 10.1145/225058.225093; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; SALTON G, 1983, INTRO MODERN INFORMA; Sen P., 2003, Proceedings 18th IEEE Annual Conference on Computational Complexity; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274; Yao AC-C, 1977, P 18 ANN IEEE S FDN, P222, DOI DOI 10.1109/SFCS.1977.24; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464	28	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0272-5428	0-7695-2228-9	ANN IEEE SYMP FOUND			2004							473	482		10.1109/FOCS.2004.12		10	Computer Science, Theory & Methods	Computer Science	BBF37	WOS:000225221700049	
B	Yin, TK; Chiu, NT			IEEE Comp Soc	Yin, TK; Chiu, NT			Discrimination between alzheimer's dementia and controls by automated analysis of statistical parametric maps of Tc-99m-HMPAO-SPECT volumes	BIBE 2004: FOURTH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS			English	Proceedings Paper	4TH IEEE Symposium on Bioinformatics and Bioengineering (BIBE 2004)	MAY 19-21, 2004	Tai Chung, TAIWAN	IEEE Comp Soc, IEEE Neural Networks Soc, Taichung Healthcare & Management Univ, Minist Educ, Natl Sci Council, Inst Informat Ind			CEREBRAL BLOOD-FLOW; PHOTON-EMISSION-TOMOGRAPHY; REFERENCE REGION; DISEASE; SPECT; BRAIN; QUANTIFICATION; DIAGNOSIS; PERFUSION; CHOICE	Alzheimer's disease is a chronic degenerative disease of the central nervous system. Clinically early detection of Alzheimer's disease is helpful in taking care of the patients. The nuclear imaging method, single-photon emission computed tomography (SPECT), is a useful tool in analyzing the cerebral blood flow. Most common regional abnormalities for Alzheimer's disease are symmetric or asymmetric bilateral temporal or parietal hypoperfusion, or frontal hypoperfusion. Statistical Parametric Mapping (SPM) is employed to do pre-processing of SPECT volumes. Due to its effectiveness, easiness and fastness, SPM has been widely applied to the diagnosis and function research of brain diseases. The proposed system can provide a quantitatively automatic analysis of the SPECT volumes. The selection of three variables based on the statistical parametric t maps between Alzheimer's and normal volumes are proposed Then an optimal linear classifier is applied to discriminate between these two group of volumes. In statistical pattern recognition, the Bayes error the overlap among different class densities, is the smallest possible error in the current measurement space. Due to the effectiveness of the variable selection, the simple optimal linear classifier achieves a near-Bayes error ratio. The sensitivity and specificity of the proposed method are 88% and 90%, respectively. With the high sensitivity and specificity performance, the proposed automatic analysis of brain SPECT volumes can assist in the clinical practice of radiologists.	Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan	Yin, TK (reprint author), Chia Nan Univ Pharm & Sci, Dept Management Informat Sci, Tainan, Taiwan.						BRUN A, 1981, HISTOPATHOLOGY, V5, P549, DOI 10.1111/j.1365-2559.1981.tb01818.x; Claus JJ, 1999, EUR J NUCL MED, V26, P265, DOI 10.1007/s002590050387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devous MD, 2002, EUR J NUCL MED MOL I, V29, P1685, DOI 10.1007/s000259-002-0967-2; Elgh E, 2002, EUR J NUCL MED MOL I, V29, P1140, DOI 10.1007/s00259-002-0829-y; FRISTON KJ, 1991, J CEREBR BLOOD F MET, V11, P690; Friston K J, 1995, HUMAN BRAIN MAPPING, V2, P165, DOI 10.1002/hbm.460030303; Friston KJ, 1995, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402; Friston K.J., 1994, HUMAN BRAIN MAPPING, V1, P214; Fukunaga K., 1990, STAT PATTERN RECOGNI; Goethals I, 2002, EUR J NUCL MED MOL I, V29, P975, DOI 10.1007/s00259-002-0872-8; Haykin S., 1994, NEURAL NETWORKS COMP; Holmes AP, 1996, J CEREBR BLOOD F MET, V16, P7; IIDA H, 1994, J NUCL MED, V35, P2019; KUHL DE, 1982, J NUCL MED, V23, P196; METZ CE, 1986, INVEST RADIOL, V21, P720; OHNISHI T, 1995, J NUCL MED, V36, P1163; Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620; PETERSON DW, 1966, IEEE T INFORM THEORY, V12, P380, DOI 10.1109/TIT.1966.1053913; Pickut BA, 1999, PSYCHIAT RES-NEUROIM, V90, P103, DOI 10.1016/S0925-4927(99)00004-9; POLINE JB, 1993, J CEREBR BLOOD F MET, V13, P425; Rajapakse JC, 2001, IEEE T BIO-MED ENG, V48, P1186, DOI 10.1109/10.951522; Salmon E, 2000, HUM BRAIN MAPP, V10, P39, DOI 10.1002/(SICI)1097-0193(200005)10:1<39::AID-HBM50>3.0.CO;2-B; Signorini M, 1999, NEUROIMAGE, V9, P63, DOI 10.1006/nimg.1998.0381; Sjobeck M, 2001, DEMENT GERIATR COGN, V12, P211, DOI 10.1159/000051260; SOKOLOFF L, 1981, FED PROC, V40, P2311; Soonawala D, 2002, NEUROIMAGE, V17, P1193, DOI 10.1006/nimg.2002.1259; STONE M, 1974, J R STAT SOC B, V36, P111; STROTHER SC, 1995, J CEREBR BLOOD F MET, V15, P738; SYED GMS, 1992, NUCL MED COMMUN, V13, P811, DOI 10.1097/00006231-199211000-00007; Talairach J., 1988, CO PLANAR STEREOTAXI; TALBOT PR, 1994, EUR J NUCL MED, V21, P503; TERRY RD, 1994, ALZHEIMER DIS; WANG GJ, 1994, J NUCL MED, V35, P1457; WORSLEY KJ, 1992, J CEREBR BLOOD F MET, V12, P900	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA		0-7695-2173-8				2004							183	190				8	Biochemistry & Molecular Biology; Computer Science, Interdisciplinary Applications; Medicine, Research & Experimental	Biochemistry & Molecular Biology; Computer Science; Research & Experimental Medicine	BAH58	WOS:000222238200025	
B	Goldschmidt, RR; Passos, EL; Godoy, RA; Schettini, F; Paolino, A		Chu, HW; Savoie, M; Sanchez, B		Goldschmidt, RR; Passos, EL; Godoy, RA; Schettini, F; Paolino, A			Assistance in selecting KDD algorithms	International Conference on Computing, Communications and Control Technologies, Vol 1, Proceedings			English	Proceedings Paper	International Conference on Computing, Communications and Control Technologies (CCCT 2004)	AUG 14-17, 2004	Austin, TX	Univ Texas Austin, Int Inst Informat & System, IEEE Comp Soc, Venezuela Chapter, Inter Amer Org Higher Educ		knowledge discovery in databases; knowledge discovery assistance; ranking data mining algorithms		Knowledge Discovery in Databases, or KDD for short, is a non-trivial process of identifying useful patterns in huge databases. It is an interactive and iterative process that involves several steps with many decisions being made by users. A new and fertile research area, referenced in the present work as KDD Assistance, is concerned about the development of computational mechanisms that help men in making decisions in KDD processes. An important step in KDD process concerns the choice of which data mining algorithm(s) should be used in new databases. The present work aims at evaluating a ranking algorithm based approach. Given a new database, such approach takes algorithms' past performance in similar databases into consideration in order to indicate which algorithms should be tried on first. A computational tool to implement this approach was developed and is described in detail. Experiments with six classification algorithms and several databases are reported.	PUC Rio NUPAC, Ctr Cidade, Escola Ciencias Exatas & Tecnol, ICA Computat Intelligence Lab, Rio De Janeiro, Brazil	Goldschmidt, RR (reprint author), PUC Rio NUPAC, Ctr Cidade, Escola Ciencias Exatas & Tecnol, ICA Computat Intelligence Lab, Rio De Janeiro, Brazil.						BRAZDIL P, 2003, MACHINE LEARNING, V50; BRODLEY C, 1993, P 10 INT C MACH LEAR; CID D, 2001, P 2 C LOG ART INT RO, V2, P81; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ENGELS P, 1998, P 13 EUR C ART INT; FAYYAD UM, 1996, COMMUN ACM, P27; GOLDSCHMIDT R, 2002, IC AI 02 INT C AI LA; GOLDSCHMIDT R, 2003, THESIS PONTIFICIA U; GOLDSCHMIDT R, 2003, CLEI 03 C LAT INF LA; GONCALVES LB, 2001, THESIS PONTIFICIA U; HAYKIN S, 1999, NEURAL NETWORKS COMP; Michie D, 1994, MACHINE LEARNING NEU; NEAVE H, 1992, DISTRIBUTIONS FREE T; Quinlan J. R., 1993, PROGRAMS MACHINE LEA; Weiss S. M., 1998, PREDICTIVE DATA MINI; Wolpert D. H., 1996, SFITR9502010	16	0	0	INT INST INFORMATICS & SYSTEMICS	ORLANDO	14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA		980-6560-17-5				2004							12	17				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BBV04	WOS:000227981900003	
B	Du, WW; Zhao, QF		DelPobil, AP		Du, WW; Zhao, QF			An improved R-4-rule for evolutionary learning of NN-NILP	Proceedings of the Eighth IASTED International Conference on Artificial Intelligence and Soft Computing			English	Proceedings Paper	8th IASTED International Conference on Artificial Intelligence and Soft Computing	SEP 01-03, 2004	Marbella, SPAIN	Int Assoc Sci & Technol Dev, TC Artificial Intelligence & Expert, IASTED, TC Soft Comp, World Modelling & Simulat Forum		the R-4-rule; nearest neighbor based multilayer perceptron (NN-MLP); pattern recognition; learning vector quantization; and neural networks	NEIGHBOR PATTERN-CLASSIFICATION; RULE	To design the nearest-neighbor-based multilayer perceptron (NN-MLP) efficiently, we have proposed a non-genetic evolutionary algorithm called the W-rule. Experimental results obtained so far show that the W-rule can produce the smallest or nearly smallest networks with high generalization ability by iteratively performing four basic operations: recognition, remembrance, (r) under bar eduction, and review. To use this algorithm, however, we must specify several parameters properly, and this is often not easy. In this paper, we try to improve the usability of the R-4-rule by reducing the number of parameters. The efficiency of the improved algorithm is verified through experiments with several public databases.	Univ Aizu, Aizu Wakamatsu 9658580, Japan	Du, WW (reprint author), Univ Aizu, Aizu Wakamatsu 9658580, Japan.						CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CHANG EI, 1991, ADV NEURAL INFORMATI, V3, P797; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Mitchell T., MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1988, IEEE COMPUT, V21, P77; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; ZHAO QF, 1994, P IEICE KAUR WORKSH, P121; Zhao QF, 1996, IEEE T NEURAL NETWOR, V7, P762	14	0	0	ACTA PRESS	CALGARY	B6, STE 101, 2509 DIEPPE AVE SW, CALGARY, ALBERTA T3E 7J9, CANADA		0-88986-452-7				2004							238	242				5	Computer Science, Artificial Intelligence	Computer Science	BCB30	WOS:000228486200042	
J	Dzeroski, S; Drumm, D				Dzeroski, S; Drumm, D			Using regression trees to identify the habitat preference of the sea cucumber (Holothuria leucospilota) on Rarotonga, Cook Islands	ECOLOGICAL MODELLING			English	Article; Proceedings Paper	3rd European Ecological Modelling Conference	SEP 10-15, 2001	DUBROVNIK, CROATIA			machine learning; tropical marine ecology; habitat preference; sea cucumber		In the Pacific Islands, invertebrates including sea cucumbers are among the most valuable and vulnerable inshore fisheries resources. As human activities continue to force substantial impacts on coral reef ecosystems, the management of inshore fisheries has become an increasingly important priority. Knowledge of the distribution, biology and habitat requirements of a species can significantly enhance conservation efforts. The sea cucumber (Holothuria leucospilota) forms an important part of the traditional subsistence fishery on Rarotonga, Cook Islands, yet little is known of this species' present spatial distribution and abundance around the island. We apply two machine learning approaches and a classical statistical approach to predict the number of sea cucumber individuals from site characteristics. The machine learning methods used are induction of regression trees and instance-based learning. These are compared to the classical statistical approach of linear regression. The most accurate predictions are obtained using instance-based learning, while the most understandable descriptions are obtained using regression tree induction. (C) 2003 Elsevier B.V. All rights reserved.	Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia; Univ Otago, Dept Marine Sci, Dunedin, New Zealand	Dzeroski, S (reprint author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova 39, Ljubljana 1000, Slovenia.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Breiman L, 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalzell P, 1996, OCEANOGR MAR BIOL, V34, P395; DASARATHY BV, 1990, NORMS NN PATTERN CLA; FIELDING A, 1999, MACHING LEARNING MET; LEK S, 1999, ECOL MODEL, V120; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Recknagel F, 2001, ECOL MODEL, V146, P1, DOI 10.1016/S0304-3800(01)00291-5; Sperduto MB, 1996, PHOTOGRAMM ENG REM S, V62, P1269; WANG Y, 1997, P POST PAP EUR C MAC; Witten I.H., 1999, DATA MINING PRACTICA; ZHOU Q, 2000, BOOK ABSTRACTS	13	27	28	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3800		ECOL MODEL	Ecol. Model.	DEC 15	2003	170	2-3					219	226		10.1016/S0304-3800(03)00229-1		8	Ecology	Environmental Sciences & Ecology	756JB	WOS:000187461000011	
J	Singh, S				Singh, S			Multiresolution estimates of classification complexity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; classification complexity; feature space partitioning	PATTERN-CLASSIFICATION; PROBABILITY; RECOGNITION; INFORMATION; ERROR	In this paper, we study two measures of classification complexity based on feature space partitioning: "purity" and "neighborhood separability." The new measures of complexity are compared with probabilistic distance measures and a number of other nonparametric estimates of classification complexity on a total of 10 databases from the University of Calfornia, Irvine, (UCl) repository.	Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England	Singh, S (reprint author), Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England.	s.singh@ex.ac.uk					BENBESSAT M, 1982, HDB STAT, P773; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BOHM C, 2001, ACM SURVEYS; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; Fisher A., 1923, MATH THEORY PROBABIL; FIX E, 1949, 2149004 US AIR FORC; FOLEY JD, 1987, COMPUTER GRAPHICS PR; FRIEDMAN JH, 1979, ANN STAT, V7, P697, DOI 10.1214/aos/1176344722; Fu K, 1986, HDB PATTERN RECOGNIT; Fukunaga K., 1990, INTRO STAT PATTERN R; GLICK N, 1973, ANN I STAT MATH, V25, P373, DOI 10.1007/BF02479383; Ho T. K., 2000, P 15 INT C PATT REC, P43; Ho TK, 2000, LECT NOTES COMPUT SC, V1857, P97; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Ho TK, 1998, COMPUT VIS IMAGE UND, V70, P101, DOI 10.1006/cviu.1998.0624; HO TK, 1994, INT C PATT RECOG, P178; HO TK, 2001, P 2 INT WORKSH MULT, P53; Hunter G.M., 1978; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Kishore JK, 2001, INFORM SCIENCES, V131, P65, DOI 10.1016/S0020-0255(00)00081-5; Kohn AF, 1996, PATTERN RECOGN, V29, P873, DOI 10.1016/0031-3203(95)00122-0; Loftsgaardne D., 1965, ANN MATH STAT, P1049; MADDOX J, 1990, NATURE, V344, P705; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Perlin K., 1989, Computer Graphics, V23; PIERSON WE, UNPUB USE BOUNDARY M; PIERSON WE, 1998, THESIS OHIO STAT U; PIERSON WE, 1998, P SPIE C AUT TARG RE, V7; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; SANCHO JL, 1996, SIGNAL PROCESSING CO; SANCHO JL, 1996, P IEE C MATHS SIGN P; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SINGH S, 2003, PATTERN ANAL APPL, V6; SINGH S, 2002, P 15 INT C PATTERN R, V2, P144; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; Therrien Charles W., 1989, DECISION ESTIMATION; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; VAPNIK VN, 1998, STAT LEARNING THEOER; WALLACE CS, 1968, COMPUT J, V11, P185; WILLIAMS AC, 1997, P SPIE ITN S OPT ENG; XIE Q, 1993, IEEE T PATTERN ANAL, P1326	47	27	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1534	1539		10.1109/TPAMI.2003.1251146		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	746UA	WOS:000186765000003	
J	Nock, R; Sebban, M; Bernard, D				Nock, R; Sebban, M; Bernard, D			A simple locally adaptive nearest neighbor rule with application to pollution forecasting	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						machine learning; case-based reasoning; neighborhood; pollution forecasting	CLASSIFICATION	In this paper, we propose a thorough investigation of a nearest neighbor rule which we call the "Symmetric Nearest Neighbor (sNN) rule". Basically, it symmetrises the classical nearest neighbor relationship from which are computed the points voting for some instances. Experiments on 29 datasets, most of which are readily available, show that the method significantly outperforms the traditional Nearest Neighbors methods. Experiments on a domain of interest related to tropical pollution normalization also show the greater potential of this method. We finally discuss the reasons for the rule's efficiency, provide methods for speeding-up the classification time, and derive from the sNN rule a reliable and fast algorithm to fix the parameter k in the k-NN rule, a longstanding problem in this field.	Univ Antilles Guyane, Grimaag Dept Sci Interfac, F-97275 Schoelcher, France; Univ St Etienne, Eurise Dept Informat, F-42023 St Etienne 2, France	Nock, R (reprint author), Univ Antilles Guyane, Grimaag Dept Sci Interfac, Campus Schoelcher,BP 7209, F-97275 Schoelcher, France.	rnock@martinique.univ-ag.fr; Marc.Sebban@univ-st-etienne.fr; dbernard@univ-ag.fr					BERNARD D, 1995, MAR POLLUT BULL, V30, P619, DOI 10.1016/0025-326X(95)00085-2; Blake CL, 1998, UCI REPOSITORY MACHI; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1007/BF00994006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRAKOPOULOS JA, 1995, P 12 INT C MACH LEAR, P203; FIX E, 1951, TR2149004 USAF SCH A; FREIDMAN JH, 1997, ACM T MATH SOFTWARE, V3, P209; FRIEDMAN J. H., 1994, FLEXIBLE METRIC NEAR; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HARWOOD D, 1987, PATTERN RECOGN LETT, V6, P155, DOI 10.1016/0167-8655(87)90002-X; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Keogh E., 1997, P 14 INT C MACH LEAR, P406; KNAPP RR, 1998, UVMCS19980101 U VERM; Nock R, 2001, PATTERN RECOGN LETT, V22, P413, DOI 10.1016/S0167-8655(00)00137-9; OKAMOTO S, 1996, P 13 INT C MACH LEAR, P355; PALAU AM, 1998, P 14 INT C PATT REC, V1; Venkatesh S. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130396; YANILOS PN, 1993, P 4 ANN ACM SIGACT S, P311	20	3	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	JOURNAL DEPT PO BOX 128 FARRER ROAD, SINGAPORE 912805, SINGAPORE	0218-0014		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2003	17	8					1369	1382		10.1142/S0218001403002952		14	Computer Science, Artificial Intelligence	Computer Science	766KR	WOS:000188376000005	
J	Markou, M; Singh, S				Markou, M; Singh, S			Novelty detection: a review - part 1: statistical approaches	SIGNAL PROCESSING			English	Review						novelty detection review; statistical approaches; Gaussian mixture models; hidden Markov models; KNN; Parzen density estimation; string matching; clustering	REJECT OPTION; CLASSIFICATION; OUTLIERS; NETWORK; SYSTEM	Novelty detection is the identification of new or unknown data or signal that a machine learning system is not aware of during training. Novelty detection is one of the fundamental requirements of a good classification or identification system since sometimes the test data contains information about objects that were not known at the time of training the model. In this paper we provide state-of-the-art review in the area of novelty detection based on statistical approaches. The second part paper details novelty detection using neural networks. As discussed, there are a multitude of applications where novelty detection is extremely important including signal processing, computer vision, pattern recognition, data mining, and robotics. (C) 2003 Elsevier B.V. All rights reserved.	Univ Exeter, PANN Res, Dept Comp Sci, Exeter EX4 4PT, Devon, England	Markou, M (reprint author), Univ Exeter, PANN Res, Dept Comp Sci, Exeter EX4 4PT, Devon, England.						BAKER LD, 1999, HIERARCHICAL PROBABI; BARNETT V., 1994, OUTLIERS STAT DATA; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; BISHOP C, 1994, P IEE C VIS IM SIGN, P217; BROTHERTON T, 1998, P IJCNN C ANCH MAY; CAMPBELL C, 2001, ADV NIPS, V14; CARPENTER GA, 1997, P INT C NEUR NETW, V3, P1459, DOI 10.1109/ICNN.1997.614010; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASGUPTA D, 1996, P INT C INT SYST REN; Dasgupta D., 2000, P IEEE INT C SYST MA, V1, P125; Dasgupta D., 2002, Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), DOI 10.1109/CEC.2002.1004386; DASGUPTA D, 2001, CS01001 U MEMPH DIV; Desforges MJ, 1998, P I MECH ENG C-J MEC, V212, P687, DOI 10.1243/0954406981521448; Duda R. O., 2001, PATTERN CLASSIFICATI; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; Fisher RA, 1928, P CAMB PHILOS SOC, V24, P180; Foggia P, 1999, PATTERN RECOGN, V32, P1435, DOI 10.1016/S0031-3203(98)00169-1; Forrest S., 1994, Proceedings of 1994 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.94CH3444-7), DOI 10.1109/RISP.1994.296580; Fumera G, 2000, PATTERN RECOGN, V33, P2099, DOI 10.1016/S0031-3203(00)00059-5; Guh RS, 1999, ARTIF INTELL ENG, V13, P413, DOI 10.1016/S0954-1810(99)00022-9; Guttormsson S E, 1999, IEEE T ENERGY CONVER, V14; Hansen L. K., 1997, Open Systems & Information Dynamics, V4, DOI 10.1023/A:1009643503022; HANSEN LK, 2000, P IEEE ICASSP 2000, V6, P3494; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HICKINBOTHAM SJ, 2000, P IEEE IJCNN COM IT; Japkowicz N., 1995, P 14 JOINT C ART INT, P518; Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8; KING SP, 2002, P 2002 INT C CONTR A, V1, P221, DOI 10.1109/CCA.2002.1040189; Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006; Lauer M., 2001, P 12 EUR C MACH LEAR, P300; LAURIKKALA J, 2000, INTELLIGENT DATA ANA; MANIKOPOULOS C, 2002, IEEE COMM MAG    OCT, V40; Manson G., 2002, P IES C SWANS UK; MANSON G, 2000, P 7 INT S SMART STRU; MANSON G, 2001, P 4 INT C DAM ASS ST; Nairac A, 1999, INTEGR COMPUT-AID E, V6, P53; NAIRAC A, 1997, P 5 IEE INT C ART NE, P227; ODIN T, 2000, P COMADEN C HOUST TX; Parra L, 1996, NEURAL COMPUT, V8, P260, DOI 10.1162/neco.1996.8.2.260; Pizzi NJ, 2001, ARTIF INTELL MED, V21, P263, DOI 10.1016/S0933-3657(00)00095-6; ROBERTS S, 1994, NEURAL COMPUT, V6, P270, DOI 10.1162/neco.1994.6.2.270; ROBERTS SJ, 2002, P 1 INT C ADV MED SI, P166; Roberts SJ, 1999, IEE P-VIS IMAGE SIGN, V146, P124, DOI 10.1049/ip-vis:19990428; RUOTOLO R, 1997, P 5 PAN AM C APPL ME; SAUNDERS R, 2000, P ARTIFICIAL INTELLI; SCARTH GB, 1995, P INT SOC MAGN RES M, P238; SINGH S, 2003, IN PRESS IEEE T KNOW; Spence C, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P3; Stefano C., 2000, IEEE T SYST MAN CYB, V1, P84; TARAKANOV A, 2002, P C EV COMP CEC 02, V1, P938, DOI 10.1109/CEC.2002.1007051; Tarassenko L., 1995, P 4 IEE INT C ART NE, V4, P442; Tarassenko L., 1999, IEE Colloquium on Condition Monitoring Machinery, External Structures and Health (Ref. No. 1999/034); Tax D M J, 2000, INT C PATT REC, V2; Tax D. M. J., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings; Webb A.R., 1999, STAT PATTERN RECOGNI; Wei Fan, 2001, Proceedings 2001 IEEE International Conference on Data Mining, DOI 10.1109/ICDM.2001.989509; Yamanishi K., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347160; Yang Y, 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953; Yang Y., 2002, INT C KNOWL DISC DAT; Yang Y.M, 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; YEUNG DY, 2002, PATTERN RECOGN, V36, P229; YEUNG DY, 2002, P INT C PATT REC QUE	64	292	309	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-1684		SIGNAL PROCESS	Signal Process.	DEC	2003	83	12					2481	2497		10.1016/j.sigpro.2003.018		17	Engineering, Electrical & Electronic	Engineering	739KY	WOS:000186346000001	
J	Luaces, O; Bahamonde, A				Luaces, O; Bahamonde, A			Inflating examples to obtain rules	INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS			English	Article							NEAREST-NEIGHBOR; LEARNING ALGORITHMS; CLASSIFICATION	A new machine learning system is presented in this article. It is called INNER and induces classification rules from a set of training examples. The process followed by this system starts with the random selection of a subset of examples that are iteratively inflated in order to cover the surroundings provided that they are inhabited by examples of the same class, thus becoming rules that will be applied by means of a partial matching mechanism. The rules so obtained can be seen as clusters of examples and represent clear evidence to support explanations about their future classifications and may be used to build intelligent advisors. The whole algorithm can be seen as a set of elastic transformations of examples and rules and produces concise, accurate rule sets, as is experimentally demonstrated in the final section of the article. (C) 2003 Wiley Periodicals, Inc.	Univ Oviedo, Artificial Intelligence Ctr, Gijon 33271, Spain	Luaces, O (reprint author), Univ Oviedo, Artificial Intelligence Ctr, Campus Viesques, Gijon 33271, Spain.						Aha D.W., 1990, THESIS U CALIFORNIA; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAHAMONDE A, 1994, INT J COMPUT MATH, V54, P127, DOI 10.1080/00207169408804346; Bahamonde A, 1997, LECT NOTES COMPUT SC, V1240, P536; Blake CL, 1998, UCI REPOSITORY MACHI; BOTANA F, 1995, INT J HUM-COMPUT ST, V42, P137, DOI 10.1006/ijhc.1995.1006; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Clark P., 1991, P 5 EUR WORK SESS LE, P151; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; del Coz JJ, 1999, LECT NOTES COMPUT SC, V1606, P527; Domingos P, 1996, MACH LEARN, V24, P141; Furnkranz J, 1999, ARTIF INTELL REV, V13, P3, DOI 10.1023/A:1006524209794; Holte RC, 1989, P 11 INT JOINT C ART, P813; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KOHAVI R, 1994, PROC INT C TOOLS ART, P740, DOI 10.1109/TAI.1994.346412; Kohonen T., 1995, SPRINGER SERIES INFO; Luaces O, 1999, LECT NOTES COMPUT SC, V1606, P497; LUACES O, 1998, LECT NOTES ARTIF INT, V1416, P448; LUACES O, 2000, REV IBEROAMERICANA I, V9, P38; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RANILLA J, 1998, REV IBEROAMERICANA I, V4, P4; Ranilla J, 2002, INT J HUM-COMPUT ST, V56, P445, DOI 10.1006/ijhc.1002; Salzberg S.L., 1990, LEARNING NESTED GEN; SPIEGEL MR, 1970, ESTADISTICA; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Thrun S.B., 1991, CSCMU91197; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WNEK J, 1990, COMP LEARNING PARADI	32	8	8	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0884-8173		INT J INTELL SYST	Int. J. Intell. Syst.	NOV	2003	18	11					1113	1143		10.1002/int.10132		31	Computer Science, Artificial Intelligence	Computer Science	731UU	WOS:000185905500002	
J	Bressan, M; Vitria, J				Bressan, M; Vitria, J			Nonparametric discriminant analysis and nearest neighbor classification	PATTERN RECOGNITION LETTERS			English	Article						nearest neighbors classifier; nonparametric discriminant analysis; face recognition	RECOGNITION	Nonparametric discriminant analysis (NDA), opposite to other nonparametric techniques, has received little or no attention within the pattern recognition community. Nearest neighbor classification (NN) instead, has a well established position among other classification techniques due to its practical and theoretical properties. In this paper, we observe that when we seek a linear representation adapted to improve NN performance, what we obtain not surprisingly is quite close to NDA. Since a hierarchy is provided on the extracted features it also serves as a dimensionality reduction technique that preserves NN performance. Experiments evaluate and compare NN classification using our proposed representation against more classical feature extraction techniques. (C) 2003 Elsevier B.V. All rights reserved.	Univ Autonoma Barcelona, CVC, Bellaterra 08193, Barcelona, Spain; Univ Autonoma Barcelona, Dept Informat, Bellaterra 08193, Barcelona, Spain	Bressan, M (reprint author), Univ Autonoma Barcelona, CVC, Bellaterra 08193, Barcelona, Spain.		Vitria, Jordi/C-7072-2008				Blake CL, 1998, UCI REPOSITORY MACHI; Bressan M, 2003, PATTERN RECOGN, V36, P691, DOI 10.1016/S0031-3203(02)00104-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1990, NN PATTERN CLASSIFIC; Devijver P. A., 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E, 1951, DISCRIMINATORY ANAL; FOGARTY TC, 1992, MACH LEARN, V9, P387, DOI 10.1007/BF00994113; FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671; Fukunaga K., 1990, INTRO STAT PATTERN R; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Martinez A., 1998, 24 COMP VIS CTR; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244	14	56	62	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	NOV	2003	24	15					2743	2749		10.1016/S0167-8655(03)00117-X		7	Computer Science, Artificial Intelligence	Computer Science	713LN	WOS:000184859600022	
J	Ross, ME; Zhou, XD; Song, GC; Shurtleff, SA; Girtman, K; Williams, WK; Liu, HC; Mahfouz, R; Raimondi, SC; Lenny, N; Patel, A; Downing, JR				Ross, ME; Zhou, XD; Song, GC; Shurtleff, SA; Girtman, K; Williams, WK; Liu, HC; Mahfouz, R; Raimondi, SC; Lenny, N; Patel, A; Downing, JR			Classification of pediatric acute lymphoblastic leukemia by gene expression profiling	BLOOD			English	Article							MLL TRANSLOCATIONS; PCR ANALYSIS; PRE-B; CANCER; REARRANGEMENTS; PREDICTION; DISCOVERY; E2A-PBX1; CHILDREN; SURVIVAL	Contemporary treatment of pediatric acute lymphoblastic leukemia (ALL) requires the assignment of patients to specific risk groups. We have recently demonstrated that expression profiling of leukemic blasts can accurately identify the known prognostic subtypes of ALL, including T-cell lineage ALL (T-ALL), E2A-PBX1, TEL-AML1, MLL rearrangements, BCR-ABL, and hyperdiploid karyotypes with more than 50 chromosomes. As the next step toward developing this methodology into a frontline diagnostic tool, we have now analyzed leukemic blasts from 132 diagnostic samples using higher density oligonucleotide arrays that allow the interrogation of most of the identified genes in the human genome. Nearly 60% of the newly identified subtype discriminating genes are novel markers not identified in our previous study, and thus should provide new insights into the altered biology underlying these leukemias. Moreover, a proportion of the newly selected genes are highly ranked as class discriminators, and when incorporated into class-predicting algorithms resulted in an overall diagnostic accuracy of 97%. The performance of an array containing the identified discriminating genes should now be assessed in frontline clinical trials in order to determine the accuracy, practicality, and cost effectiveness of this methodology in the clinical setting. (Blood. 2003; 102:2951-2959) (C) 2003 by The American Society of Hematology.	St Jude Childrens Res Hosp, Dept Pathol, Dept Hematol Oncol, Memphis, TN 38105 USA; St Jude Childrens Res Hosp, Hartwell Ctr Bioinformat & Biotechnol, Memphis, TN 38105 USA	Downing, JR (reprint author), St Jude Childrens Res Hosp, Dept Pathol, Dept Hematol Oncol, 332 N Lauderdale St, Memphis, TN 38105 USA.	jim.downing@stjude.org					Advani AS, 2002, LEUKEMIA RES, V26, P713, DOI 10.1016/S0145-2126(01)00197-7; Andersson A, 2001, LEUKEMIA, V15, P1293, DOI 10.1038/sj.leu.2402189; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cuthbert G, 2000, GENE CHROMOSOME CANC, V29, P180, DOI 10.1002/1098-2264(2000)9999:9999<::AID-GCC1016>3.0.CO;2-K; Downing JR, 2002, CANCER CELL, V2, P437, DOI 10.1016/S1535-6108(02)00211-8; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ferrando AA, 2000, SEMIN HEMATOL, V37, P381, DOI 10.1016/S0037-1963(00)90018-0; Friedmann A M, 2000, Oncologist, V5, P321, DOI 10.1634/theoncologist.5-4-321; Fu XY, 1999, ONCOGENE, V18, P4920, DOI 10.1038/sj.onc.1202874; Fullwood Y, 1999, J BIOL CHEM, V274, P31553, DOI 10.1074/jbc.274.44.31553; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Harrison CJ, 2001, BRIT J HAEMATOL, V113, P3, DOI 10.1046/j.1365-2141.2001.02643.x; Horvat S, 2001, GENOMICS, V72, P209, DOI 10.1006/geno.2000.6441; Irminger-Finger I, 2002, INT J BIOCHEM CELL B, V34, P582, DOI 10.1016/S1357-2725(01)00161-3; Kasof GM, 2001, J BIOL CHEM, V276, P3238, DOI 10.1074/jbc.M003670200; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Maloney KW, 2000, LEUKEMIA, V14, P2276, DOI 10.1038/sj.leu.2401965; MARTINEZCLIMENT JA, 1995, LEUKEMIA, V9, P1299; McWhirter JR, 1999, P NATL ACAD SCI USA, V96, P11464, DOI 10.1073/pnas.96.20.11464; Moos PJ, 2002, CLIN CANCER RES, V8, P3118; Rosenwald A, 2002, NEW ENGL J MED, V346, P1937, DOI 10.1056/NEJMoa012914; PLATT J, 1999, ADV KEMEL METHODS SU, P105; Pui CH, 1998, NEW ENGL J MED, V339, P605; Pui CH, 2000, LEUKEMIA, V14, P2286, DOI 10.1038/sj.leu.2401938; Pui CH, 2001, LANCET ONCOL, V2, P597, DOI 10.1016/S1470-2045(01)00516-2; RAIMONDI SC, 1993, BLOOD, V81, P2237; SALLAN SE, 1980, BLOOD, V55, P395; SATHER HN, 1986, MED PEDIATR ONCOL, V14, P166, DOI 10.1002/mpo.2950140311; Schoch C, 2002, P NATL ACAD SCI USA, V99, P10008, DOI 10.1073/pnas.142103599; Schrappe M, 2000, BLOOD, V95, P3310; Silverman LB, 2001, BLOOD, V97, P1211, DOI 10.1182/blood.V97.5.1211; Smith M, 1996, J CLIN ONCOL, V14, P18; van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967; van Dongen JJM, 1999, LEUKEMIA, V13, P1901, DOI 10.1038/sj.leu.2401592; Whittock NV, 2000, BIOCHEM BIOPH RES CO, V276, P454, DOI 10.1006/bbrc.2000.3500; Witten H., 2000, DATA MINING PRACTICA; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	38	309	319	AMER SOC HEMATOLOGY	WASHINGTON	1900 M STREET. NW SUITE 200, WASHINGTON, DC 20036 USA	0006-4971		BLOOD	Blood	OCT 15	2003	102	8					2951	2959		10.1182/blood-2003-01-0338		9	Hematology	Hematology	731HB	WOS:000185877300045	
J	Preston, JM; Kirlin, RL				Preston, JM; Kirlin, RL			Comment on "Acoustic seabed classification: improved statistical method"	CANADIAN JOURNAL OF FISHERIES AND AQUATIC SCIENCES			English	Editorial Material							HABITATS; SYSTEM		Quester Tangent Corp, Sidney, BC V8L 5Y8, Canada; Univ Victoria, Dept Elect & Comp Engn, Victoria, BC V8W 3P6, Canada	Preston, JM (reprint author), Quester Tangent Corp, 201 9865 W Saanich Rd, Sidney, BC V8L 5Y8, Canada.						ANDERSON JT, 2001, SPATIAL PROCESSES MA; Anderson JT, 2002, ICES J MAR SCI, V59, P156, DOI 10.1006/jmsc.2001.1126; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Legendre P, 2002, CAN J FISH AQUAT SCI, V59, P1085, DOI 10.1139/F02-096; Ellingsen KE, 2002, ICES J MAR SCI, V59, P825, DOI 10.1006/jmsc.2002.1198; Morrison MA, 2001, J SEA RES, V46, P233, DOI 10.1016/S1385-1101(01)00089-2; PRESTON JM, 2001, P MTS IEEE OC 2001 O	8	13	14	NATL RESEARCH COUNCIL CANADA	OTTAWA	RESEARCH JOURNALS, MONTREAL RD, OTTAWA, ONTARIO K1A 0R6, CANADA	0706-652X		CAN J FISH AQUAT SCI	Can. J. Fish. Aquat. Sci.	OCT	2003	60	10					1299	1300		10.1139/F03-131		2	Fisheries; Marine & Freshwater Biology	Fisheries; Marine & Freshwater Biology	743LN	WOS:000186573400011	
J	Kleinberg, J				Kleinberg, J			Bursty and hierarchical structure in streams	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Proceedings Paper	8th ACM/SIGKDD International Conference on Knowledge Discovery and Data Mining	JUL, 2002	EDMONTON, CANADA	ACM, SIGKDD		data stream algorithms; text mining; Markov source models		A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise-that the appearance of a topic in a document stream is signaled by a "burst of activity," with certain features rising sharply in frequency as the topic emerges. The goal of the present work is to develop a formal approach for modeling such " bursts," in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content. The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitions; it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream. Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Kleinberg, J (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Agrawal R., 1995, P INT C DAT ENG; AIGRAIN P, 1996, MULTIMEDIA TOOLS APP, V3; Allan J., 1998, P DARPA BROADC NEWS; ALLAN J, 1998, P SIGIR INT C INF RE; ANICK D, 1982, BELL SYST TECH J, V61; BECKER K, 2000, P 15 BRAZ S DAT; Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214; Berghel H, 1997, COMMUN ACM, V40, P11, DOI 10.1145/256175.256176; BIRRELL A, 1997, PACHYDERM E MAIL SYS; BLANTON T, 1995, WHITE HOUSE E MAIL; BOONE G, 1998, P 2 INT C AUT AG; CHARIKAR M, 2002, P 29 INT C AUT LANG; Chatfield C., 1996, ANAL TIME SERIES INT; Chatman S., 1978, STORY DISCOURSE NARR; CHUDOVA D, 2001, KDD WORKSH TEMP DAT; COHEN WW, 1996, P AAAI SPRING S MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EHRICH R, 1976, IEEE T COMPUT, V25, P7; ELWALID A, 1993, IEEE ACM T NETWORKIN, V1; FINE S, 1998, MACHINE LEARNING, V32; Forster E. M., 1927, ASPECTS NOVEL; GAROFALAKIS M, 2002, ACM SIGMOD INT C MAN; GAY G, 2001, ED TECHNOLOGY SOC, V4; Genette Gerard, 1980, NARRATIVE DISCOURSE; Genette Gerard, 1988, NARRATIVE DISCOURSE; GROSZ BJ, 1986, COMPUTATIONAL LINGUI, V12; GRUBER T, HYPERMAIL; GURALNIK V, 1999, INT C KNOWL DISC DAT; HAN J, 1998, P INT C KNOWL DISC D; Hand D.J., 2001, PRINCIPLES DATA MINI; HAVRE S, 2000, P IEEE S INF VIS; HAWKINS D, 1976, APPL STAT, V25; HECKEL B, 1997, P WORKSH NEW PAR INF; HELFMAN J, 1995, ISHMAIL IMMEDIATE ID; Horvitz E., 1999, P ACM C HUM FACT COM; HUDSON DJ, 1966, J AM STAT ASSOC, V61, P1097, DOI 10.2307/2283203; Kelly F., 1996, STOCHASTIC NETWORKS; KEOGH E, 1997, P INT C KNOWL DISC D; LAST M, 2001, IEEE T SYSTEMS MAN B, V31; LAVRENKO V, 2000, KDD 2000 WORKSH TEXT; LEWIS DD, 1997, INF P MANAGEMENT, V33; LUKESH SS, 1999, 1 MONDAY, V4; Maes P., 1994, Communications of the ACM, V37, DOI 10.1145/176789.176792; MANNILA H, 2001, P INT C KNOWL DISC D; MARKUS ML, 1994, ACM T INFORM SYST, V12, P119, DOI 10.1145/196734.196738; MARTIN R, 2001, KDD WKSHP TEMP DAT M; MILLER N, 1998, P IEEE VISUALIZATION; Moore R. W., 2000, D LIB MAGAZINE, V6; MURPHY K, 2001, ADV NEURAL INFORMATI, V14; OLSEN F, 1999, CHRONICLE HIGHE 0824; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; POLLOCK S, 1988, ACM T INFORM SYST, V6, P232, DOI 10.1145/45945.214327; Rabiner L. A., 1989, P IEEE, V77; REDMOND M, 1998, P AAAI WORKSH CAS BA; RENNIE J, 2000, P KDD WORKSH TEXT MI; Sahami M., 1998, P AAAI WORKSH LEARN; Schneier B, 1996, APPL CRYPTOGRAPHY; SCOTT S, 1998, THESIS HARVARD U; SCOTT SL, 2002, MARKOV MODULATED POI; SEGAL R, 1999, P INT C AUT AG; SEGAL R, 2000, P INT C MACH LEARN; SHAW S, 1990, IEEE T ACOUSTICS SPE, V38, P2; SWAN R, 2000, P SIGIR INT C INF RE; SWAN R, 2000, KDD 2000 WORKSH TEXT; SWAN R, 1999, P 8 INT C INF KNOWL; WHITTAKER S, 1996, P ACM SIGCHI C HUM F; WONG P, 2000, P IEEE INFORMATION V; YANG Y, 2000, P SIGIR INT C INF RE; YANG Y, 1998, P SIGIR INT C INF RE; GOGGLE ZEITGEIST SEA	70	55	58	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	OCT	2003	7	4					373	397		10.1023/A:1024940629314		25	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	704UM	WOS:000184358900003	
J	Raymer, ML; Doom, TE; Kuhn, LA; Punch, WF				Raymer, ML; Doom, TE; Kuhn, LA; Punch, WF			Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article; Proceedings Paper	IEEE International Symposium on Bio-Informatic and Biomedcial Engineering	NOV 08-10, 2000	WASHINGTON, D.C.	IEEE		bioinformatics; evolutionary computing; genetic algorithms; pattern recognition	K-NEAREST-NEIGHBORS; GENETIC ALGORITHMS; FEATURE-SELECTION; LIGAND INTERACTIONS; WATER-MOLECULES; BOUND ALGORITHM; HYDROGEN-BONDS; DRUG DESIGN; PROTEINS; CLASSIFICATION	A key element of bioinformatics research is the extraction of meaningful information from large experimental data-sets. Various approaches, including statistical and graph theoretical methods, data mining, and computational pattern recognition, have been applied to this task with varying degrees of success. Using a novel classifier based on the Bayes discriminant function, we present a hybrid algorithm that employs feature selection and extraction to isolate salient features from large medical and other biological data sets. We have previously shown that a genetic algorithm coupled with a k-nearest-neighbors classifier performs well in extracting information about protein-water binding from X-ray crystallographic protein structure data. The effectiveness of the hybrid EC-Bayes classifier is demonstrated to distinguish the features of this data set that are the most statistically relevant and to weight these features appropriately to aid in the prediction of solvation sites.	Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA; Michigan State Univ, Dept Biochem, E Lansing, MI 48824 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Raymer, ML (reprint author), Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.		Raymer, Michael/G-3398-2013	Raymer, Michael/0000-0003-2649-0792			ABOLA EE, 1987, PROTEIN DATA BANK CR, P107; AEBERHARD S, 1992, 9201 J COOK U N QUEE; Aeberhard S, 1992, 9202 J COOK U N QUEE; BAKER EN, 1984, PROG BIOPHYS MOL BIO, V44, P97, DOI 10.1016/0079-6107(84)90007-5; BAYES T, 1763, PHIL T ROY SOC, V53; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Blake CL, 1998, UCI REPOSITORY MACHI; Cestnik G., 1987, PROGR MACHINE LEARNI, P31; CONNOLLY ML, 1983, SCIENCE, V221, P709, DOI 10.1126/science.6879170; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Diaconis P., 1983, SCI AM, V248; Domingos P., 1996, P 13 INT C MACH LEAR, P105; Duda R., 1973, PATTERN CLASSIFICATI; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HOBOHM U, 1992, PROTEIN SCI, V1, P409; ISHIBUCHI H, 1995, IEEE T FUZZY SYST, V3, P260, DOI 10.1109/91.413232; Jain A., 1982, HDB STATISTICS, V2, P835, DOI 10.1016/S0169-7161(82)02042-2; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JAYNES ET, 1968, IEEE T SYST SCI CYB, VSSC4, P227, DOI 10.1109/TSSC.1968.300117; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; Kuhn LA, 1995, PROTEINS, V23, P536, DOI 10.1002/prot.340230408; KUHN LA, 1992, J MOL BIOL, V228, P13, DOI 10.1016/0022-2836(92)90487-5; MAO J, 1994, P 12 INT C PATT REC, P622; MARCHAND A, 1983, AM J CLIN PATHOL, V80, P369; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; PITT WR, 1993, J COMPUT CHEM, V14, P1007, DOI 10.1002/jcc.540140902; Poornima CS, 1995, J COMPUT AID MOL DES, V9, P513, DOI 10.1007/BF00124322; Poornima CS, 1995, J COMPUT AID MOL DES, V9, P500, DOI 10.1007/BF00124321; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1986, P 2 AUSTR C APPL EXP; QUINLAN JR, 1986, MACHINE LEARNING ART, P149; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; RAYMER ML, 1997, P 7 INT C GEN ALG IC, P561; RAYMER ML, 2001, UNPUB PROTEIN ENG; Raymer ML, 1997, J MOL BIOL, V265, P445, DOI 10.1006/jmbi.1996.0746; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1); Sridharan NS, 1989, P 11 INT JOINT C ART, P781; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306; VAFAIE H, 1998, FEATURE EXTRACTION C, P307; VEDANI A, 1991, J AM CHEM SOC, V113, P5860, DOI 10.1021/ja00015a049; WADE RC, 1993, J MED CHEM, V36, P140, DOI 10.1021/jm00053a018; WEISS S, 1990, EMPIRICAL COMP PATTE; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; YANG J, 1998, P INT JOINT C NEUR N; YANG J, 1998, FEATURE EXTRACTION C, P117	52	19	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1083-4419		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2003	33	5					802	813		10.1109/TSMCB.2003.816922		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	724PN	WOS:000185496100009	
J	Podsiadlo, P; Stachowiak, GW				Podsiadlo, P; Stachowiak, GW			Fractal-wavelet based classification of tribological surfaces	WEAR			English	Article; Proceedings Paper	10th Nordic Symposium on Tribology (NORDTRIB 2002)	JUN 09-12, 2002	STOCKHOLM, SWEDEN			fractal-wavelet analysis; surface classification; tribological surfaces	TEXTURE CLASSIFICATION; WEAR; MORPHOLOGY; INSPECTION; DISTANCE; FILTERS	Classification of the topography of freshly machined, worn and damaged surfaces (e.g. damaged by adhesion, scoring, abrasion, pitting) is still a problem in machine failure analysis. Tribological surfaces often exhibit both a multiscale nature (i.e. different length scales of surface features) and a non-stationary nature (i.e. features which are superimposed on each other and located at different positions on a surface). The most widely used approaches to surface classification are based on the Fourier transform or statistical functions and parameters. Often these approaches are inadequate and provide incorrect classification of the tribological surfaces. The main reason is that these techniques fail to simultaneously capture the multiscale nature and the non-stationary nature of the surface data. A new method, called a hybrid fractal-wavelet method, has recently been developed for the characterization of tribological surfaces in a multiscale and non-stationary manner. In contrast to other methods, this method combines both the wavelets' inherent ability to characterize surfaces at each individual scale and the fractals' inherent ability to characterize surfaces in a scale-invariant manner. The application of this method to the classification of artificially generated fractal and tribological surfaces (e.g. worn surfaces) is presented in this paper. The newly developed method has been further modified to better suit tribological surface data, including a new measure of differences between initial and decoded images. The accuracy of this method in the classification of surfaces was assessed. (C) 2003 Elsevier Science B.V All rights reserved.	Univ Western Australia, Sch Mech Engn, Tribol Lab, Crawley, WA 6009, Australia	Podsiadlo, P (reprint author), Univ Western Australia, Sch Mech Engn, Tribol Lab, Crawley, WA 6009, Australia.						Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796; Baddeley A.J, 1992, ROBUST COMPUTER VISI, P59; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; Brislawn CM, 1996, APPL COMPUT HARMON A, V3, P337, DOI 10.1006/acha.1996.0026; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; Cho U, 2000, TRIBOL INT, V33, P461, DOI 10.1016/S0301-679X(00)00074-8; Coquin D, 2001, PATTERN RECOGN LETT, V22, P1483, DOI 10.1016/S0167-8655(01)00104-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HUANG Z, 2000, P INT C PATT REC, V3, P913; Kun Xu, 1997, Engineering Applications of Artificial Intelligence, V10; MALLAT S, 1999, TOUR SIGNAL PROCESSI; Myshkin NK, 1997, WEAR, V203, P658, DOI 10.1016/S0043-1648(96)07432-7; Podsiadlo P, 2000, WEAR, V242, P160, DOI 10.1016/S0043-1648(00)00416-6; Podsiadlo P, 2002, TRIBOL LETT, V13, P241, DOI 10.1023/A:1021059108478; PODSIADLO P, 2000, TRIBOLOGY SERIES, V38, P546; PODSIADLO P, 2001, TRIBOLOGY SERIES, V39, P697; RAMAMOORTHY B, 1993, WEAR, V167, P155, DOI 10.1016/0043-1648(93)90320-L; ROYLANCE BJ, 1992, LUBR ENG, V48, P940; Russ J.C., 1994, FRACTAL SURFACES; Singh S, 2001, PATTERN RECOGN, V34, P1601, DOI 10.1016/S0031-3203(00)00099-6; Stachowiak GB, 2001, WEAR, V249, P201, DOI 10.1016/S0043-1648(01)00557-9; Stachowiak GW, 2001, WEAR, V249, P194, DOI 10.1016/S0043-1648(01)00562-2; Thomas TR, 1999, WEAR, V232, P41, DOI 10.1016/S0043-1648(99)00128-3; Tsai DM, 1999, PATTERN RECOGN, V32, P389, DOI 10.1016/S0031-3203(98)00077-6; Tsai DM, 2000, INT J ADV MANUF TECH, V16, P474; Wiltschi K, 2000, MACH VISION APPL, V12, P113, DOI 10.1007/s001380050130	26	14	15	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0043-1648		WEAR	Wear	OCT	2003	254	11					1189	1198		10.1016/S0043-1648(03)00333-8		10	Engineering, Mechanical; Materials Science, Multidisciplinary	Engineering; Materials Science	723UA	WOS:000185448900019	
J	Steele, BM; Patterson, DA; Redmond, RL				Steele, BM; Patterson, DA; Redmond, RL			Toward estimation of map accuracy without a probability test sample	ENVIRONMENTAL AND ECOLOGICAL STATISTICS			English	Article						classification; discriminant analysis; posterior probabilities; spatial data	REMOTELY-SENSED DATA; ERROR RATE ESTIMATION; THEMATIC CLASSIFICATION ACCURACY; LAND-COVER; CROSS-VALIDATION; INFORMATION; CLASSIFIERS; MISCLASSIFICATION; VEGETATION; DESIGN	The time and effort required of probability sampling for accuracy assessment of large-scale land cover maps often means that probability test samples are not collected. Yet, map usefulness is substantially reduced without reliable accuracy estimates. In this article, we introduce a method of estimating the accuracy of a classified map that does not utilize a test sample in the usual sense, but instead estimates the probability of correct classification for each map unit using only the classification rule and the map unit covariates. We argue that the method is an improvement over conventional estimators, though it does not eliminate the need for probability sampling. The method also provides a new and simple method of constructing accuracy maps. We illustrate some of problems associated with accuracy assessment of broad-scale land cover maps, and our method, with a set of nine Landsat Thematic Mapper satellite image-based land cover maps from Montana and Wyoming, USA.	Univ Montana, Dept Math Sci, Missoula, MT 59812 USA; Univ Montana, Wildlife Spatial Anal Lab, Montana Cooperat Wildlife Res Unit, Missoula, MT 59812 USA	Steele, BM (reprint author), Univ Montana, Dept Math Sci, Missoula, MT 59812 USA.						ARNO SF, 1979, INT218 USDA FOR SERV; BASFORD KE, 1985, J AM STAT ASSOC, V80, P286, DOI 10.2307/2287884; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CAMPBELL JB, 1981, PHOTOGRAMM ENG REM S, V47, P355; Carpenter GA, 1999, REMOTE SENS ENVIRON, V70, P326, DOI 10.1016/S0034-4257(99)00051-6; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; CONGALTON RG, 1988, PHOTOGRAMM ENG REM S, V54, P587; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX DR, 1958, BIOMETRIKA, V45, P562, DOI 10.2307/2333203; Cressie N. A. C., 1993, STAT SPATIAL DATA; DAWID AP, 1982, J AM STAT ASSOC, V77, P605, DOI 10.2307/2287720; Efron B., 1993, INTRO BOOTSTRAP; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; FISHER PF, 1994, PHOTOGRAMM ENG REM S, V60, P905; Fix E, 1951, 4 US AIR FORC SCH AV; Foody GM, 1996, INT J REMOTE SENS, V17, P1317; GANESALINGAM S, 1980, PATTERN RECOGN, V12, P405, DOI 10.1016/0031-3203(80)90016-3; GLICK N, 1978, PATTERN RECOGN, V10, P211, DOI 10.1016/0031-3203(78)90029-8; GOPAL S, 1994, PHOTOGRAMM ENG REM S, V60, P181; GRIFFITH DA, 1999, SPATIAL ACCURACY ASS; Hammond TO, 1996, INT J REMOTE SENS, V17, P1261; Hand DJ, 1997, CONSTRUCTION ASSESSM; HAND DJ, 1986, PATTERN RECOGN LETT, V4, P335, DOI 10.1016/0167-8655(86)90054-1; Hastie T, 2001, ELEMENTS STAT LEARNI; KARTIKEYAN B, 1994, INT J REMOTE SENS, V15, P1037; KRZANOWSKI WJ, 2001, J APPL STAT, V5, P585; Kyriakidis PC, 2001, ENVIRON ECOL STAT, V8, P311, DOI 10.1023/A:1012778302005; Lee TCM, 2000, J AM STAT ASSOC, V95, P259, DOI 10.2307/2669543; Ma ZK, 2001, PHOTOGRAMM ENG REM S, V67, P295; McIver DK, 2002, REMOTE SENS ENVIRON, V81, P253, DOI 10.1016/S0034-4257(02)00003-2; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; NEMANI R, 1993, INT J REMOTE SENS, V14, P2519; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169; Ripley B. D., 1996, PATTERN RECOGNITION; SCHAVIO RA, 2000, INT STAT REV, V68, P295; Steele BM, 2001, INT J REMOTE SENS, V22, P3143, DOI 10.1080/01431160152558297; Steele BM, 1998, REMOTE SENS ENVIRON, V66, P192, DOI 10.1016/S0034-4257(98)00061-3; STEELE BM, IN PRESS P 33 S INT; Steele BM, 2000, REMOTE SENS ENVIRON, V74, P545, DOI 10.1016/S0034-4257(00)00145-0; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7; Stehman SV, 1998, REMOTE SENS ENVIRON, V64, P331, DOI 10.1016/S0034-4257(98)00010-8; Stehman SV, 2000, REMOTE SENS ENVIRON, V72, P35, DOI 10.1016/S0034-4257(99)00090-5; STEHMAN SV, 1995, INT J REMOTE SENS, V16, P589; Stuckens J, 2000, REMOTE SENS ENVIRON, V71, P282, DOI 10.1016/S0034-4257(99)00083-8; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; Vogelmann JE, 1998, ENVIRON MONIT ASSESS, V51, P415, DOI 10.1023/A:1005996900217; WATSON DF, 1985, GEO-PROCESSING, V2, P315; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; ZHU Z, 1999, SPATIAL ACCURACY ASS	50	12	12	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1352-8505		ENVIRON ECOL STAT	Environ. Ecol. Stat.	SEP	2003	10	3					333	356		10.1023/A:1025111108050		24	Environmental Sciences; Mathematics, Interdisciplinary Applications; Statistics & Probability	Environmental Sciences & Ecology; Mathematics	711AQ	WOS:000184715300003	
J	Okazaki, N; Matsuo, Y; Matsumura, N; Ishizuka, M				Okazaki, N; Matsuo, Y; Matsumura, N; Ishizuka, M			Sentence extraction by spreading activation through sentence similarity	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						summarization; extraction; sentence similarity; spreading activation		Although there has been a great deal of research on automatic summarization, most methods rely on statistical methods, disregarding relationships between extracted textual segments. We propose a novel method to extract a set of comprehensible sentences which centers on several key points to ensure sentence connectivity. It features a similarity network from documents with a lexical dictionary, and spreading activation to rank sentences. We show evaluation results of a multi-document summarization system based on the method participating in a competition of summarization, TSC (Text Summarization Challenge) task, organized by the third NTCIR project.	Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan; AIST Tokyo Waterfront, Cyber Assist Res Ctr, Tokyo 1350064, Japan	Okazaki, N (reprint author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan.						Barzilay R., 1997, P ACL WORKSH INT SCA, P10; Barzilay R, 2002, J ARTIF INTELL RES, V17, P35; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; FUKUMOTO J, 1997, PACLING 97; FUKUSHIMA T, 2002, 3 NTCIR WORKSH M 1, P87; KANDPAL HC, 2001, J OPT A-PURE APPL OP, V3, P1; LUHN HP, 1958, IBM J RES DEV, V2, P159; Mani I., 1999, Information Retrieval, V1, DOI 10.1023/A:1009930203452; Mani I, 2001, AUTOMATIC SUMMARIZAT; Mitra M., 1997, INFORMATION PROCESSI, V32, P53; Morris J., 1991, Computational Linguistics, V17; NAGAO K, 1998, P 17 INT C COMP LING; OKAZAKI N, 2002, 3 NTCIR WORKSH M 5, P39; OKUMURA M, 1994, P COLING 94, V2, P75; Salton G., 1989, AUTOMATIC TEXT PROCE; Stein GC, 2000, COMPUT INTELL, V16, P606, DOI 10.1111/0824-7935.00131	19	5	5	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532		IEICE T INF SYST	IEICE Trans. Inf. Syst.	SEP	2003	E86D	9					1686	1694				9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	720TL	WOS:000185276000027	
J	Hullermeier, E				Hullermeier, E			Possibilistic instance-based learning	ARTIFICIAL INTELLIGENCE			English	Article						possibility theory; fuzzy set theory; machine learning; instance-based learning; nearest neighbor classification; probability	NEIGHBOR CLASSIFICATION RULE; NEAREST NEIGHBORS; DENSITY-FUNCTION; NATURAL LANGUAGES; ALGORITHMS; RECOGNITION; KNOWLEDGE	A method of instance-based learning is introduced which makes use of possibility theory and fuzzy sets. Particularly, a possibilistic version of the similarity-guided extrapolation principle underlying the instance-based learning paradigm is proposed. This version is compared to the commonly used probabilistic approach from a methodological point of view. Moreover, aspects of knowledge representation such as the modeling of uncertainty are discussed. Taking the possibilistic extrapolation principle as a point of departure, an instance-based learning procedure is outlined which includes the handling of incomplete information, methods for reducing storage requirements and the adaptation of the influence of stored cases according to their typicality. First theoretical and experimental results showing the efficiency of possibilistic instance-based learning are presented as well. (C) 2003 Elsevier B.V. All rights reserved.	Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany	Hullermeier, E (reprint author), Univ Marburg, Dept Math & Comp Sci, D-35032 Marburg, Germany.						Aha D. W., 1989, P 6 INT WORKSH MACH, P387; Aha D.W., 1997, LAZY LEARNING; AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; BEREAU M, 1991, FUZZY SET SYST, V44, P17, DOI 10.1016/0165-0114(91)90029-P; Bezdek J., 1981, PATTERN RECOGNITION; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bradley Raymond, 1979, POSSIBLE WORLDS; Brodley C. E., 1993, P 10 INT C MACH LEAR, P17; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Cohen L.J., 1989, INTRO PHILOS INDUCTI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NN; DASARATHY BV, 1980, IEEE T PATTERN ANAL, V2, P67; DAVIES LJ, 1988, SYSTEMS PRACTICE, V1, P11, DOI 10.1007/BF01059886; de Mantaras RL, 1998, DATA KNOWL ENG, V25, P99; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DIXON JK, 1979, IEEE T SYST MAN CYB, V9, P617, DOI 10.1109/TSMC.1979.4310090; DOMINGOS P, 1995, P 14 INT JOINT C ART, P1226; Domingos P, 1996, MACH LEARN, V24, P141; Dubois D., 1992, P FUZZ IEEE SAN DIEG, P821; DUBOIS D, 1986, EUR J OPER RES, V25, P345, DOI 10.1016/0377-2217(86)90266-3; DUBOIS D, 2000, SOFT COMPUTING CASE, P47; DUBOIS D, 2002, LECT NOTES ARTIF INT, V2275, P1; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; Dubois D, 1998, INT J INTELL SYST, V13, P345, DOI 10.1002/(SICI)1098-111X(199804)13:4<345::AID-INT3>3.3.CO;2-I; Dubois D., 2001, LECT NOTES ARTIF INT, V2143, P522; DUBOIS D, 1992, FUZZY SET SYST, V49, P65, DOI 10.1016/0165-0114(92)90110-P; Dubois D., 1988, POSSIBILITY THEORY; Dubois D., 2000, Advances in Case-Based Reasoning. 5th European Workshop, EWCBR 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1898); Dubois D, 2002, IEEE T FUZZY SYST, V10, P322, DOI 10.1109/TFUZZ.2002.1006435; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; Dubois D., 2000, Journal of Logic, Language and Information, V9, DOI 10.1023/A:1008370109997; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1991, NEAREST NEIGHBOR NN; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; HULLERMEIER E, 1999, P IJCAI 99, P248; HULLERMEIER E, 2002, P ECAI 2002 15 EUR C, P360; Hume David, 1999, ENQUIRY CONCERNING H; Jozwik A., 1983, Pattern Recognition Letters, V1, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kibler D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00315.x; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; Kolodner J., 1993, CASE BASED REASONING; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, DOI 10.1109/91.227387; LEWIS DK, 1973, J PHILOS LOGIC, P2; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; McKenna E., 2000, P 14 EUR C ART INT, P60; Mitchell TM, 1980, CBMTR117 RUTG U; Niiniluoto I., 1988, ANALOGICAL REASONING, P271; PARTHASARATHY G, 1990, IEEE T SYST MAN CYB, V20, P715, DOI 10.1109/21.57285; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATRICK EA, 1970, INFORM CONTROL, V16, P128, DOI 10.1016/S0019-9958(70)90081-1; Quinlan J. R., 1989, P 6 INT WORKSH MACH, P164; Quinlan R., 1993, P 10 INT C MACH LEAR, P236; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1023/A:1022661727670; SANCHEZ E, 1978, INFORM SCIENCES, V15, P45, DOI 10.1016/0020-0255(78)90021-X; Shafer G., 1976, MATH THEORY EVIDENCE; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Silverman B.W., 1986, DENSITY ESTIMATION S; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P121; VAPNIK VN, 1998, STATLEARNING THEORY; Wand M. P., 1995, KERNEL SMOOTHING; Weisbrod J., 1998, Soft Computing, V2, DOI 10.1007/s005000050037; Wess S., 1994, Topics in Case-Based Reasoning. First European Workshop, EWCBR-93. Selected Papers; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; WILSON DR, 1997, THESIS B YOUNG U PRO; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418; ZADEH LA, 1978, INT J MAN MACH STUD, V10, P395, DOI 10.1016/S0020-7373(78)80003-0; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; Zhang J., 1992, P 9 INT MACH LEARN C, P470; Zhang JP, 1997, ARTIF INTELL REV, V11, P175, DOI 10.1023/A:1006500703083	85	10	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0004-3702		ARTIF INTELL	Artif. Intell.	AUG	2003	148	1-2					335	383		10.1016/S0004-3702(03)00019-5		49	Computer Science, Artificial Intelligence	Computer Science	713LY	WOS:000184860500011	
J	Wojna, A				Wojna, A			Center-based indexing in vector and metric spaces	FUNDAMENTA INFORMATICAE			English	Article							COMBINING RULE INDUCTION; ALGORITHM; CLASSIFICATION; RIONA; TREES	The paper addresses the problem of indexing data for k nearest neighbors (k-nn) search. Given a collection of data objects and a similarity measure the searching goal is to find quickly the k most similar objects to a given query object. We present a top-down indexing method that employs a widely used scheme of indexing algorithms. It starts with the whole set of objects at the root of an indexing tree and iteratively splits data at each level of indexing hierarchy. In the paper two different data models are considered. In the first, objects are represented by vectors from a multi-dimensional vector space. The second, more general, is based on an assumption that objects satisfy only the axioms of a metric space. We propose an iterative k-means algorithm for tree node splitting in case of a vector space and an iterative k-approximate-centers algorithm in case when only a metric space is provided. The experiments show that the iterative k-means splitting procedure accelerates significantly k-nn searching over the one-step procedure used in other indexing structures such as GNAT, SS-tree and M-tree and that the relevant representation of a tree node is an important issue for the performance of the search process. We also combine different search pruning criteria used in BST, GHT nad GNAT structures into one and show that such a combination outperforms significantly each single pruning criterion. The experiments are performed for benchmark data sets of the size up to several hundreds of thousands of objects. The indexing tree with the k-means splitting procedure and the combined search criteria is particularly effective for the largest tested data sets for which this tree accelerates searching up to several thousands times.	Warsaw Univ, Inst Informat, PL-02097 Warsaw, Poland	Wojna, A (reprint author), Warsaw Univ, Inst Informat, Ul Banacha 2, PL-02097 Warsaw, Poland.	wojna@mimuw.edu.pl					Aggarwal C.C., 2001, P 8 INT C DAT THEOR, P420; Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93597.98741; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BIBERMAN Y, 1994, P 9 EUR C MACH LEARN, P49; Blake CL, 1998, UCI REPOSITORY MACHI; BRIN S., 1995, P 21 INT C VER LARG, P574; Burr Ridge I, 1997, MACHINE LEARNING; CHAVEZ E, 1999, TRDCC993 U CHIL DEP; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1996, MACH LEARN, V24, P141; Duda R., 1973, PATTERN CLASSIFICATI; Finkel R. A., 1974, Acta Informatica, V4, DOI 10.1007/BF00288933; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Gora G, 2002, FUND INFORM, V51, P369; Gora G, 2002, LECT NOTES ARTIF INT, V2430, P111; Guttman A., 1984, P ACM SIGMOD INT C M, P47; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; Kataymaand N., 1997, P ACM SIGMOD INT C M, P369, DOI 10.1145/253260.253347; Lin K.-I., 1994, VLDB J, V3, P517, DOI 10.1007/BF01231606; NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Robinson John T., 1981, P ACM SIGMOD INT C M, P10; SALZBERG S, 1991, MACH LEARN, V2, P229; Savaresi S., 2001, P 1 SIAM INT C DAT M, P1; SELLIS T, 1987, P 13 INT C VER LARG, P574; SKOWRON A, 2003, ROUGH SET EXPLORATIO; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VELOSO M, 1994, PLANNING LEARNING AN; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WETTSCHERECK D, 1994, THESIS OREGON STATE; White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202; WOJNA A, 2003, P 3 IEEE INT C DAT M; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311	40	6	7	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968		FUND INFORM	Fundam. Inform.	AUG	2003	56	3					285	310				26	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	752PU	WOS:000187177000005	
J	Yager, RR				Yager, RR			Induced aggregation operators	FUZZY SETS AND SYSTEMS			English	Article; Proceedings Paper	EUROFUSE Workshop on Preference Modelling and Applications	APR 25-27, 2001	GRANADA, SPAIN			IOWA operator; OWA aggregation operators; best yesterday models		We introduce the induced ordered weighted averaging (IOWA) operator. In these operators the argument ordering process is guided by a variable called the order inducing value. A procedure for learning the weights from data is described. We suggest a number of applications of these induced OWA aggregation operators. First we show its possibilities in modeling nearest-neighbor rules. Next it is applied to the aggregation of complex objects such as matrices. It is also used to establish a new class of information fusion models called "best yesterday models". Finally, we extend the idea of order induced aggregation to the Choquet aggregation resulting in what we call the induced Choquet ordered averaging (I-COA) operator. (C) 2002 Elsevier Science B.V. All rights reserved.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, 715 N Ave, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denneberg D., 1994, NONADDITIVE MEASURE; Filev D, 1998, FUZZY SET SYST, V94, P157, DOI 10.1016/S0165-0114(96)00254-0; Grabisch M., 1999, FUZZY MEASURES INTEG; SUGENO M, 1987, P 2 IFSA C TOK, P408; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89; Yager R. R., 1997, ORDERED WEIGHTED AVE; Yager R.R., 1998, P FUZZ IEEE WORLD C, P123; YAGER RR, 2001, P ATL S COMP BIOL GE, P92; Yager RR, 1998, PROCEEDINGS OF THE IEEE/IAFE/INFORMS 1998 CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR FINANCIAL ENGINEERING (CIFER), P220, DOI 10.1109/CIFER.1998.690125; Yager RR, 1999, IEEE T SYST MAN CY B, V29, P141, DOI 10.1109/3477.752789; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; Yager RR, 2002, IEEE T SYST MAN CY B, V32, P512, DOI 10.1109/TSMCB.2002.1018770	13	104	121	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114		FUZZY SET SYST	Fuzzy Sets Syst.	JUL 1	2003	137	1					59	69		10.1016/S0165-0114(02)00432-3		11	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	693YQ	WOS:000183746300006	
J	Singh, S				Singh, S			PRISM - A novel framework for pattern recognition	PATTERN ANALYSIS AND APPLICATIONS			English	Article						cells; classification complexity; data compactness; feature selection; hypercuboids; PRISM	CLASSIFICATION; COMPLEXITY; INFORMATION; PROBABILITY; SELECTION; ERROR	In this paper, we introduce a new model of solving pattern recognition tasks called PRISM (Pattern Recognition using Information Slicing Method). The main concept behind PRISM is the slicing of information through multiple planes across different feature axes to generate a number of cells. The number of cells created and their volume depends upon the number partitions per axes. In this context we define resolution as the number of partitions per axes. In this paper, we make the following contributions. First, we provide a brief survey of the class separability measures and feature partitioning schemes used for pattern recognition. Secondly, we define the PRISM framework and the algorithm for data assignment to cells. Thirdly, we detail four important concepts in PRISM: purity, neighbourhood separability, collective entropy, and data compactness. The first two measures define the data complexity, the next measure relates to uncertainty, and the last measure defines the alternative to statistical data variance in the PRISM framework. Fourthly, we investigate the variability in the estimates of these measures depending on the placement of partitions on each feature axis. Finally, we give an overview of experimental successes achieved with PRISM in the areas of classification complexity estimation and feature selection.	Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England	Singh, S (reprint author), Univ Exeter, Dept Comp Sci, Exeter EX4 4PT, Devon, England.						Ben-Bassat M., 1982, HDB STATISTICS, V2, P773, DOI 10.1016/S0169-7161(82)02038-0; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; BOHM C, 2001, ACM COMPUT SURV; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHERNOFF A, 1966, ANN I STAT MATH, V18, P179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; Feldman DP, 1998, PHYS LETT A, V238, P244, DOI 10.1016/S0375-9601(97)00855-4; Fisher A., 1923, MATH THEORY PROBABIL; FIX E, 1949, 2149004 USAF SCH AV; FOLEY JD, 1987, COMPUTER GRAPHICS PR; Fu K, 1986, HDB PATTERN RECOGNIT; Fukunaga K., 1990, INTRO STAT PATTERN R; GLICK N, 1973, ANN I STAT MATH, V25, P373, DOI 10.1007/BF02479383; Ho TK, 2000, LECT NOTES COMPUT SC, V1857, P97; HUNTER GM, 1978, THESIS PRINCETON U P; ITTNER A, 1997, P 7 INT FUZZ SYST AS; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Kishore JK, 2001, INFORM SCIENCES, V131, P65, DOI 10.1016/S0020-0255(00)00081-5; KOHN A, 1976, PATTERN RECOGN, V29, P873; Kon MA, 2000, NEURAL NETWORKS, V13, P365, DOI 10.1016/S0893-6080(00)00015-0; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; Loftsgaardne D., 1965, ANN MATH STAT, P1049; MADDOX J, 1990, NATURE, V344, P705; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Perlin K., 1989, Computer Graphics, V23; Pierson W., 1998, THESIS OHIO STATE U; PIERSON WE, 1998, P SPIE C AUT TARG RE; PIERSON WE, 2002, UNPUB IEEE T PATT AN; RAHMAN AFR, 1998, P INT C IM AN PROC, P893; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; SANCHO JL, 1996, P IEE C MATH SIGN PR; SANCHO JL, 1996, INTELLIGENT METHODS; SINGH S, 2003, IN PRESS IEEE T PATT; SINGH S, 2003, IN PRESS IEEE T SYST; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; Therrien Charles W., 1989, DECISION ESTIMATION; TOUSSAIN.GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260; Vapnik V.N., 1998, STAT LEARNING THEORY; WALLACE CS, 1968, COMPUT J, V11, P185; WILLIAMS AC, 1997, SPIE INT S OPT ENG; WU Y, 2001, LNCS, V2013, P222; XIE Q, 1993, IEEE T PATTERN ANAL, P1326; ZHAO M, 1999, P INT JOINT C NEUR N, V3, P1631	46	8	8	SPRINGER-VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	1433-7541		PATTERN ANAL APPL	Pattern Anal. Appl.	JUL	2003	6	2					134	149		10.1007/s10044-002-0186-2		16	Computer Science, Artificial Intelligence	Computer Science	711TU	WOS:000184757800004	
J	Kudo, M; Masuyama, N; Toyama, J; Shimbo, M				Kudo, M; Masuyama, N; Toyama, J; Shimbo, M			Simple termination conditions for k-nearest neighbor method	PATTERN RECOGNITION LETTERS			English	Article						pattern recognition; the k-nearest neighbor method; branch-and-bound algorithm; termination condition	ALGORITHM; SEARCH	The main problem with k-nearest neighbor (k-NN) method is that the computational cost in the search process is proportional to the size of the training samples. Many search algorithms have been proposed to cope with this problem. In this study, we consider some conditions for terminating the search procedure when the true k-NNs have been found in the middle of the search, and we present, as an example, a procedure in the branch-and-bound algorithm. These conditions do not always work for a certain sample, but they reduce the computational cost on average. (C) 2002 Elsevier Science B.V. All rights reserved.	Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Sapporo, Hokkaido 0608628, Japan; Hokkaido Informat Univ, Fac Informat Media, Ebetsu, Hokkaido 0698585, Japan	Kudo, M (reprint author), Hokkaido Univ, Grad Sch Engn, Div Syst & Informat Engn, Kita Ku, Kita 13,Nishi 8, Sapporo, Hokkaido 0608628, Japan.		Kudo, Mineichi/B-9973-2011				BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; BERCHTOLD S, 1998, P 14 IEEE C DAT ENG, P23; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Califano A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139656; CHANG CC, 1993, PATTERN RECOGN LETT, V14, P625, DOI 10.1016/0167-8655(93)90047-H; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P268; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Guttman A., 1984, ACM SIGMOD, P47; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kleinberg J. M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; MURPHY PM, 1991, UCI REPOSITORY MACHI; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Wolfson H.J., 1990, P 1 EUR C COMP VIS, P526	21	3	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655		PATTERN RECOGN LETT	Pattern Recognit. Lett.	JUN	2003	24	9-10					1203	1213		10.1016/S0167-8655(02)00302-1		11	Computer Science, Artificial Intelligence	Computer Science	652FJ	WOS:000181368900009	
J	Vogt, P				Vogt, P			Anchoring of semiotic symbols	ROBOTICS AND AUTONOMOUS SYSTEMS			English	Article						anchoring problem; symbol grounding problem; physical grounding; adaptive language games; semiotics		This paper presents arguments for approaching the anchoring problem using semiotic symbols. Semiotic symbols are defined by a triadic relation between forms, meanings and referents, thus having an implicit relation to the real world. Anchors are formed between these three elements rather than between 'traditional' symbols and sensory images. This allows an optimization between the form (i.e. the 'traditional' symbol) and the referent. A robotic experiment based on adaptive language games illustrates how the anchoring of semiotic symbols can be achieved in a bottom-up fashion. The paper concludes that applying semiotic symbols is a potentially valuable approach toward anchoring. (C) 2003 Elsevier Science B.V. All rights reserved.	Univ Maastricht, Inst Knowledge & Agent Technol, NL-6200 MD Maastricht, Netherlands	Vogt, P (reprint author), Univ Maastricht, Inst Knowledge & Agent Technol, POB 616, NL-6200 MD Maastricht, Netherlands.						Belpaeme T, 2002, THESIS VRIJE U BRUSS; BILLARD A, 2001, IMITATION ANIMALS AR; Bowerman M., 2001, LANGUAGE ACQUISITION; Brooks R. A., 1990, Robotics and Autonomous Systems, V6, DOI 10.1016/S0921-8890(05)80025-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deacon Terence W, 1997, SYMBOLIC SPECIES; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Jung D, 2000, AUTON ROBOT, V8, P269, DOI 10.1023/A:1008929609573; Ogden C. K., 1923, MEANING MEANING STUD; PEIRCE CS, 1931, COLLECTED PAPERS, V1; Roy DK, 2002, COGNITIVE SCI, V26, P113, DOI 10.1016/S0364-0213(01)00061-1; Coradeschi S., 2000, Proceedings Seventeenth National Conference on Artificial Intelligence (AAAI-2000). Twelfth Innovative Applications of Artificial Intelligence Conference (IAAI-2000); Siskind JM, 2001, J ARTIF INTELL RES, V15, P31; STEELS L, 1996, ANIMALS ANIMALS, V4; Steels L., 2000, EVOLUTION COMMUNICAT, V4, P3; STEELS L, 1996, P INT C MULT SYST; STEELS L, 1997, P 4 EUR C ART LIF; Tomasello M., 1999, CULTURAL ORIGINS HUM; VOGT P, 2002, P 14 BELG NETH ART I, P331; Vogt P., 2002, COGNITIVE SYSTEMS RE, V3, P429, DOI DOI 10.1016/S1389-0417(02)00051-7; VOGT P., 2000, THESIS VRIJE U BRUSS; VOGT P, 2000, EVOLUTION COMMUNICAT, V4, P89; Wittgenstein L., 1958, PHILOS INVESTIGATION; YANCO H, 1993, ANIMALS ANIMATS, V2, P478	24	29	29	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0921-8890		ROBOT AUTON SYST	Robot. Auton. Syst.	MAY 31	2003	43	2-3					109	120		10.1016/S0921-8890(02)00353-6		12	Automation & Control Systems; Computer Science, Artificial Intelligence; Robotics	Automation & Control Systems; Computer Science; Robotics	677WB	WOS:000182830800004	
J	Cai, YD; Chou, KC				Cai, YD; Chou, KC			Nearest neighbour algorithm for predicting protein subcellular location by combining functional domain composition and pseudo-amino acid composition	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						hybrid algorithm; proteins subcellular location; functional domain composition; pseudo-amino acid composition; bioinformatics; proteomics	SUPPORT VECTOR MACHINES; PROKARYOTIC PROTEINS; STRUCTURAL CLASSES; SITES	In this paper, based on the approach by combining the "functional domain composition" [K.C. Chou, Y.D. Cai, J. Biol. Chem. 277 (2002) 45765] and the pseudo-amino acid composition [K.C. Chou, Proteins Struct. Funct. Genet. 43 (2001) 246; Correction Proteins Struct. Funct. Genet. 2044 (2001) 2060], the Nearest Neighbour Algorithm (NNA) was developed for predicting the protein subcellular location. Very high success rates were observed, suggesting that such a hybrid approach may become a useful high-throughput tool in the area of bioinformatics and proteomics. (C) 2003 Elsevier Science (USA). All rights reserved.	Chinese Acad Sci, Shanghai Res Ctr Biotechnol, Shanghai 200233, Peoples R China; Pfizer Inc, Upjohn Labs, Kalamazoo, MI 49007 USA	Cai, YD (reprint author), UMIST, Biomol Sci Dept, POB 88, Manchester M60 1QD, Lancs, England.		Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Cai Yu-Dong, 2000, Molecular Cell Biology Research Communications, V4, P172, DOI 10.1006/mcbr.2001.0269; Cai YD, 2001, PROTEINS, V43, P336, DOI 10.1002/prot.1045; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; CHOU KC, 2002, PROTEIN PEPTIDE SCI, V3, P615; CHOU KC, 2003, IN PRESS PROTEINS ST; Chou KC, 1998, BIOCHEM BIOPH RES CO, V252, P63, DOI 10.1006/bbrc.1998.9498; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou K.C., 2002, GENE CLONING EXPRESS, P57; CHOU KC, 1994, J BIOL CHEM, V269, P22014; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Claros MG, 1997, CURR OPIN STRUC BIOL, V7, P394, DOI 10.1016/S0959-440X(97)80057-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elrod DW, 2002, PROTEIN ENG, V15, P713, DOI 10.1093/protein/15.9.713; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Mardia K. V., 1979, MULTIVARIATE ANAL, P322; Murvai J, 2001, NUCLEIC ACIDS RES, V29, P58, DOI 10.1093/nar/29.1.58; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251	35	74	79	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X		BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	MAY 30	2003	305	2					407	411		10.1016/S0006-291X(03)00775-7		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	681RH	WOS:000183048800031	
J	Sebban, M; Nock, R; Lallich, S				Sebban, M; Nock, R; Lallich, S			Stopping criterion for boosting-based data reduction techniques: From binary to multiclass problems	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article; Proceedings Paper	18th International Conference on Machine Learning	JUN 28-JUL 01, 2001	WILLIAMSTOWN, MASSACHUSETTS				NEAREST NEIGHBOR RULE; CLASSIFICATION	So far, boosting has been used to improve the quality of moderately accurate learning algorithms, by weighting and combining many of their weak hypotheses into a final classifier with theoretically high accuracy. In a recent work (Sebban, Nock and Lallich, 2001), we have attempted to adapt boosting properties to data reduction techniques. In this particular context, the objective was not only to improve the success rate, but also to reduce the time and space complexities due to the storage requirements of some costly learning algorithms, such as nearest-neighbor classifiers. In that framework, each weak hypothesis, which is usually built and weighted from the learning set, is replaced by a single learning instance. The weight given by boosting defines in that case the relevance of the instance, and a statistical test allows one to decide whether it can be discarded without damaging further classification tasks. In Sebban, Nock and Lallich (2001), we addressed problems with two classes. It is the aim of the present paper to relax the class constraint, and extend our contribution to multiclass problems. Beyond data reduction, experimental results are also provided on twenty-three datasets, showing the benefits that our boosting-derived weighting rule brings to weighted nearest neighbor classifiers.	Univ St Etienne, Fac Sci, Eurise, F-42023 St Etienne 2, France; French W Indies & Guiana Univ, Dept Sci, GRIMAAG, Schoelcher 97275, Martinique; Univ Lyon 2, Dept Econ, ERIC, F-69676 Bron, France	Sebban, M (reprint author), Univ St Etienne, Fac Sci, Eurise, F-42023 St Etienne 2, France.						Allwein E.L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Breiman L, 1984, CLASSIFICATION REGRE; Brodley CE, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P799; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1998, ANN STAT, V26, P451; John G. H., 1994, P 11 INT C MACH LEAR, P121; Koller D., 1996, P 13 INT C MACH LEAR, P284; Merz C. J., 1996, UCI REPOSITORY MACHI; Nock R, 2001, PATTERN RECOGN LETT, V22, P413, DOI 10.1016/S0167-8655(00)00137-9; NOCK R, 2000, P INT C ALG LEARN TH, P224; Nock R., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, DOI 10.1142/S0218213001000453; Schapire R. E., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279960; Schapire RE, 1998, ANN STAT, V26, P1651; Sebban M., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference; Sebban M., 2000, P 17 INT C MACH LEAR, P855; Sebban M., 2001, P 18 INT C MACH LEAR, P505; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Vapnik V., 1982, ESTIMATION DEPENDENC; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	25	2	2	M I T PRESS	CAMBRIDGE	FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA	1532-4435		J MACH LEARN RES	J. Mach. Learn. Res.	MAY 15	2003	3	4-5					863	885		10.1162/jmlr.2003.3.4-5.863		23	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	714RA	WOS:000184926200011	
J	Marcelloni, F				Marcelloni, F			Feature selection based on a modified fuzzy C-means algorithm with supervision	INFORMATION SCIENCES			English	Article						feature selection; fuzzy C-means; k-nearest neighbors; supervised learning	GENETIC ALGORITHM	In this paper we propose a new approach to feature selection based on a modified fuzzy C-means algorithm with supervision (MFCMS). MFCMS completes the unsupervised learning of classical fuzzy C-means with labeled patterns. The labeled patterns allow MFCMS to accurately model the shape of each cluster and consequently to highlight the features which result to be particularly effective to characterize a cluster. These features are distinguished by a low variance of their values for the patterns with a high membership degree to the cluster. If, with respect to these features, the distance between the prototype of the cluster and the prototypes of the other clusters is high, then these features have the property of discriminating between the cluster and the other clusters. To take these two aspects into account, for each cluster and each feature, we introduce a purposely defined index: the higher the value of the index, the higher the discrimination capability of the feature for the cluster. We execute MFCMS on the training set considering all patterns as labeled. Then, we retain the features which are associated, at least for one cluster, with an index larger than a threshold T. We applied MFCMS to several real-world pattern classification benchmarks. We used the well-known k-nearest neighbors as learning algorithm. We show that feature selection performed by MFCMS achieved an improvement in generalization on all data sets. (C) 2002 Elsevier Science Inc. All rights reserved.	Univ Pisa, Dipartimento Ingn Informaz Elettr Informat Teleco, I-56122 Pisa, Italy	Marcelloni, F (reprint author), Univ Pisa, Dipartimento Ingn Informaz Elettr Informat Teleco, Via Diotisalvi 2, I-56122 Pisa, Italy.						AHA DW, 1996, ARTIFICIAL INTELLIGE; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; ALMUALLIM H, 1992, P 9 NAT C ART INT, P547; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Bezdek J., 1981, PATTERN RECOGNITION; Bezdek J.C, 1999, FUZZY MODELS ALGORIT; Caruana R., 1994, P 11 INT C MACH LEAR, P28; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; DOAK J, 1992, EVALUATION FEATURE S; Domingos P, 1997, ARTIF INTELL REV, V11, P227; Duran B.C., 1974, CLUSTER ANAL SURVEY; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1023/A:1022852608280; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GUSTAFSON DE, 1979, ADV FUZZY SET THEORY, P605; Hall M. A., 2000, P 17 INT C MACH LEAR, P359; Hoppner F., 1999, FUZZY CLUSTER ANAL; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; John G. H., 1994, P 11 INT C MACH LEAR, P121; Kaufman L., 1990, FINDING GROUPS DATA; KELLER A, P 1999 EUSFLAT ESTYL, P497; Kira K., 1992, P 9 INT C MACH LEARN, P249; Kononenko I, 1994, P EUR C MACH LEARN, P171; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Lanzi PL, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P537, DOI 10.1109/ICEC.1997.592369; LOWE D, 1985, NEURAL COMPUT, V7, P72; Moore A. W., 1994, P 11 INT C MACH LEAR, P190; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9; PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6; Pedrycz W, 1997, IEEE T SYST MAN CY B, V27, P787, DOI 10.1109/3477.623232; Pudil P., 1994, PATTERN RECOGN, V15, P1119; Pudil P, 1998, IEEE INTELL SYST APP, V13, P66, DOI 10.1109/5254.671094; Ravi TV, 1999, PATTERN RECOGN LETT, V20, P659, DOI 10.1016/S0167-8655(99)00027-6; RHEE FCH, 1999, P 1999 IEEE FUZZ SYS, P1266; RICHELDI M, 1996, P 2 INT C KNOWL DISC, P379; Schlimmer J.C., 1993, P 10 INT C MACH LEAR, P284; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Yang J., 1998, FEATURE EXTRACTION C; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z	42	21	24	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255		INFORM SCIENCES	Inf. Sci.	MAY	2003	151						201	226		10.1016/S0020-0255(02)00402-4		26	Computer Science, Information Systems	Computer Science	666ZL	WOS:000182206300010	
J	Mattioni, BE; Kauffman, GW; Jurs, PC; Custer, LL; Durham, SK; Pearl, GM				Mattioni, BE; Kauffman, GW; Jurs, PC; Custer, LL; Durham, SK; Pearl, GM			Predicting the genotoxicity of secondary and aromatic amines using data subsetting to generate a model ensemble	JOURNAL OF CHEMICAL INFORMATION AND COMPUTER SCIENCES			English	Article							ASSISTED STRUCTURE-ACTIVITY; MOLECULAR-STRUCTURE; HETEROAROMATIC AMINES; CHEMICAL CARCINOGENS; BIOLOGICAL-ACTIVITY; GENETIC ALGORITHMS; MUTAGENIC POTENCY; ACUTE TOXICITY; QSAR TREATMENT; STATE INDEXES	Binary quantitative structure-activity relationship (QSAR) models are developed to classify a data set of 334 aromatic and secondary amine compounds as genotoxic or nongenotoxic based on information calculated solely from chemical structure. Genotoxic endpoints for each compound were determined using the SOS Chromotest in both the presence and absence of an S9 rat liver homogenate. Compounds were considered genotoxic if assay results indicated a positive genotoxicity hit for either the S9 inactivated or S9 activated assay. Each compound in the data set was encoded through the calculation of numerical descriptors that describe various aspects of chemical structure (e.g. topological, geometric, electronic, polar surface area). Furthermore, five additional descriptors that focused on the secondary and aromatic nitrogen atoms in each molecule were calculated specifically for this study. Descriptor subsets were examined using a genetic algorithm search engine interfaced with a k-Nearest Neighbor fitness evaluator to find the most information-rich subsets, which ultimately served as the final predictive models. Models were chosen for their ability to minimize the total number of misclassifications, with special attention given to those models that possessed fewer occurrences of positive toxicity hits being misclassified as nontoxic (false negatives). In addition, a subsetting procedure was used to form an ensemble of models using different combinations of compounds in the training and prediction sets. This was done to ensure that consistent results could be obtained regardless of training set composition. The procedure also allowed for each compound to be externally validated three times by different training set data with the resultant predictions being used in a "majority rules" voting scheme to produce a consensus prediction for each member of the data set. The individual models produced an average training set classification rate of 71.6% and an average prediction set classification rate of 67.7%. However, the model ensemble was able to correctly classify the genotoxicity of 72.2% of all prediction set compounds.	Penn State Univ, Dept Chem, University Pk, PA 16802 USA; Bristol Myers Squibb Co, Princeton, NJ 08453 USA	Jurs, PC (reprint author), Penn State Univ, Dept Chem, 152 Davey Lab, University Pk, PA 16802 USA.						Agrafiotis DK, 2002, J CHEM INF COMP SCI, V42, P903, DOI 10.1021/ci0203702; ASHBY J, 1982, CARCINOGENESIS, V3, P1277, DOI 10.1093/carcin/3.11.1277; ASHBY J, 1988, MUTAT RES, V204, P17, DOI 10.1016/0165-1218(88)90114-0; Bacha PA, 2002, J CHEM INF COMP SCI, V42, P1104, DOI 10.1021/ci020366q; BALABAN AT, 1982, CHEM PHYS LETT, V89, P399, DOI 10.1016/0009-2614(82)80009-2; Basak SC, 2001, J CHEM INF COMP SCI, V41, P671, DOI 10.1021/ci000126f; BENIGNI R, 1994, ENVIRON MOL MUTAGEN, V24, P208, DOI 10.1002/em.2850240310; Benigni R, 1998, ENVIRON MOL MUTAGEN, V32, P75, DOI 10.1002/(SICI)1098-2280(1998)32:1<75::AID-EM9>3.0.CO;2-A; Benigni R, 2002, MUTAT RES-REV MUTAT, V511, P191, DOI 10.1016/S1383-5742(02)00008-X; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; CARHART RE, 1985, J CHEM INF COMP SCI, V25, P64, DOI 10.1021/ci00046a002; Cash GG, 2001, MUTAT RES-GEN TOX EN, V491, P31, DOI 10.1016/S1383-5718(00)00167-4; CHIGNELL CF, 1983, STRUCTURE ACTIVITY C; CHOU JT, 1979, J MED CHEM, V22, P792, DOI 10.1021/jm00193a008; Colvin ME, 1998, MUTAT RES-FUND MOL M, V400, P479, DOI 10.1016/S0027-5107(98)00073-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cronin M T, 2000, Curr Opin Drug Discov Devel, V3, P292; DEBNATH AK, 1992, ENVIRON MOL MUTAGEN, V19, P37, DOI 10.1002/em.2850190107; DEWAR MJS, 1985, J AM CHEM SOC, V107, P3902, DOI 10.1021/ja00299a024; Durham S K, 2001, Curr Opin Drug Discov Devel, V4, P110; Eldred DV, 1999, SAR QSAR ENVIRON RES, V10, P75, DOI 10.1080/10629369908039170; Eldred DV, 1999, CHEM RES TOXICOL, V12, P670, DOI 10.1021/tx980273w; ENSLEIN K, 1994, MUTAT RES, V305, P47, DOI 10.1016/0027-5107(94)90125-2; FINK SI, 1980, FARMACO-ED SCI, V35, P965; Franke R, 2001, CARCINOGENESIS, V22, P1561, DOI 10.1093/carcin/22.9.1561; Greene N, 2002, ADV DRUG DELIVER REV, V54, P417, DOI 10.1016/S0169-409X(02)00012-1; Gupta S, 1999, J CHEM INF COMP SCI, V39, P272, DOI 10.1021/ci980073q; Hammett LP, 1937, J AM CHEM SOC, V59, P96, DOI 10.1021/ja01280a022; Hatch FT, 2001, ENVIRON MOL MUTAGEN, V38, P268, DOI 10.1002/em.10028; HIBBERT DB, 1993, CHEMOMETR INTELL LAB, V19, P277, DOI 10.1016/0169-7439(93)80028-G; HOFNUNG M, 1988, ANN NY ACAD SCI, V534, P817, DOI 10.1111/j.1749-6632.1988.tb30169.x; Johnson DE, 2000, DRUG DISCOV TODAY, V5, P445, DOI 10.1016/S1359-6446(00)01559-2; JOHNSON SR, 1997, COMPUTER ASSISTED LE; Jurs P, 1979, COMPUTER ASSISTED DR; JURS PC, 1983, FUND APPL TOXICOL, V3, P343, DOI 10.1016/S0272-0590(83)80002-5; Karelson M, 2000, MOL SIMULAT, V24, P229, DOI 10.1080/08927020008022373; Katritzky AR, 1996, J PHYS CHEM-US, V100, P10400, DOI 10.1021/jp953224q; KAUFFMAN GW, 2002, THESIS PENNSYLVANIA; Kier L.B., 1986, MOL CONNECTIVITY STR; KIER LB, 1990, PHARMACEUT RES, V7, P801, DOI 10.1023/A:1015952613760; Kier LB, 1976, MOL CONNECTIVITY CHE; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P1, DOI 10.1002/qsar.19860050102; KIER LB, 1986, QUANT STRUCT-ACT REL, V5, P7, DOI 10.1002/qsar.19860050103; KIER LB, 1985, QUANT STRUCT-ACT REL, V4, P109, DOI 10.1002/qsar.19850040303; KLOPMAN G, 1984, J AM CHEM SOC, V106, P7315, DOI 10.1021/ja00336a004; KLOPMAN G, 1985, ENVIRON HEALTH PERSP, V61, P269, DOI 10.2307/3430077; KUGLERSTEIGMEIER ME, 1989, MUTAT RES, V211, P279, DOI 10.1016/0027-5107(89)90011-0; LEWIS DFW, 1992, REV COMPUTATIONAL CH; Liu SS, 1998, J CHEM INF COMP SCI, V38, P387, DOI 10.1021/ci970109z; LUCASIUS CB, 1993, CHEMOMETR INTELL LAB, V19, P1, DOI 10.1016/0169-7439(93)80079-W; LUKE BT, 1994, J CHEM INF COMP SCI, V34, P1279, DOI 10.1021/ci00022a009; Maran U, 1999, QUANT STRUCT-ACT REL, V18, P3, DOI 10.1002/(SICI)1521-3838(199901)18:1<03::AID-QSAR3>3.0.CO;2-P; Matthews EJ, 2000, J MOL GRAPH MODEL, V18, P605; Meyer H., 1899, N-S ARCH EXP PATH PH, V42, P109; Mitchell T, 2001, Curr Opin Drug Discov Devel, V4, P314; MOSIER PD, 2003, IN PRESS CHEM RES TO; Newcomb M, 2000, ACCOUNTS CHEM RES, V33, P449, DOI 10.1021/ar960058b; Newman M.S., 1956, STERIC EFFECTS ORGAN; OVERTON E, 2001, STUDIEN NARKOSEN; Pearl Greg M., 2001, Current Topics in Medicinal Chemistry, V1, P247, DOI 10.2174/1568026013395074; PEARLMAN RS, 1980, PHYSICAL CHEM PROPER; Pimentel G. C., 1960, HYDROGEN BOND; QUILLARDET P, 1993, MUTAT RES, V297, P235, DOI 10.1016/0165-1110(93)90019-J; QUINN FR, 1981, J MED CHEM, V24, P636, DOI 10.1021/jm00137a031; Rekker R. F., 1977, HYDROPHOBIC FRAGMENT; Richard AM, 1998, MUTAT RES-FUND MOL M, V400, P493, DOI 10.1016/S0027-5107(98)00068-2; SANDERSON DM, 1991, HUM EXP TOXICOL, V10, P261; Serra JR, 2001, CHEM RES TOXICOL, V14, P1535, DOI 10.1021/tx010101q; Serra JR, 2003, CHEM RES TOXICOL, V16, P153, DOI 10.1021/tx020077w; STANTON DT, 1990, ANAL CHEM, V62, P2323, DOI 10.1021/ac00220a013; STEWART JJP, 1990, J COMPUT AID MOL DES, V4, P1, DOI 10.1007/BF00128336; STOUCH TR, 1985, ENVIRON HEALTH PERSP, V61, P329, DOI 10.2307/3430083; STUPER AJ, 1977, CHEMOMETRICS THEORY; Sutton MD, 2000, ANNU REV GENET, V34, P479, DOI 10.1146/annurev.genet.34.1.479; Tetko IV, 2001, J CHEM INF COMP SCI, V41, P1407, DOI 10.1021/ci010368v; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; Vinogradov SN, 1971, HYDROGEN BONDING; WESSEL MD, 1997, THESIS PENNSYLVANIA; WIENER H, 1947, J AM CHEM SOC, V69, P17, DOI 10.1021/ja01193a005; WOO YT, 1995, TOXICOL LETT, V79, P219, DOI 10.1016/0378-4274(95)03373-S; YUAN M, 1980, TOXICOL APPL PHARM, V52, P294, DOI 10.1016/0041-008X(80)90117-9; YUTA K, 1981, J MED CHEM, V24, P241, DOI 10.1021/jm00135a003; *IND U, MOPAC V 6 0	83	35	35	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0095-2338		J CHEM INF COMP SCI	J. Chem. Inf. Comput. Sci.	MAY-JUN	2003	43	3					949	963		10.1021/ci034013i		15	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Chemistry; Computer Science	684LR	WOS:000183209300026	
J	James, GM				James, GM			Variance and bias for general loss functions	MACHINE LEARNING			English	Article						bias; variance; prediction error; loss function	REGRESSION	When using squared error loss, bias and variance and their decomposition of prediction error are well understood and widely used concepts. However, there is no universally accepted definition for other loss functions. Numerous attempts have been made to extend these concepts beyond squared error loss. Most approaches have focused solely on 0-1 loss functions and have produced significantly different definitions. These differences stem from disagreement as to the essential characteristics that variance and bias should display. This paper suggests an explicit list of rules that we feel any "reasonable" set of definitions should satisfy. Using this framework, bias and variance definitions are produced which generalize to any symmetric loss function. We illustrate these statistics on several loss functions with particular emphasis on 0-1 loss. We conclude with a discussion of the various definitions that have been proposed in the past as well as a method for estimating these quantities on real data sets.	Univ So Calif, Marshall Sch Business, Los Angeles, CA 90089 USA	James, GM (reprint author), Univ So Calif, Marshall Sch Business, Los Angeles, CA 90089 USA.						BREIMAN L, 1996, 460 U CAL BERK STAT; Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T. G., 1995, P 12 INT C MACH LEAR, P313; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; DOMINGOS P, 2000, P 17 INT C MACH LEAR; Efron B., 1993, INTRO BOOTSTRAP; EFRON B, 1978, J AM STAT ASSOC, V73, P113, DOI 10.2307/2286531; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E, 1951, DISCRIMINATORY ANAL; Freund Y., 1996, MACHINE LEARNING; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN J, 1996, BIAS VARIANCE 0 1 LO; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Heskes T, 1998, NEURAL COMPUT, V10, P1425, DOI 10.1162/089976698300017232; KOHAVI R, 1996, MACHINE LEARNING; Schapire RE, 1998, ANN STAT, V26, P1651; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Tibshirani Robert, 1996, BIAS VARIANCE PREDIC; Wolpert DH, 1997, NEURAL COMPUT, V9, P1211, DOI 10.1162/neco.1997.9.6.1211	21	37	37	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125		MACH LEARN	Mach. Learn.	MAY	2003	51	2					115	135		10.1023/A:1022899518027		21	Computer Science, Artificial Intelligence	Computer Science	656YM	WOS:000181638700001	
J	Okamoto, S; Yugami, N				Okamoto, S; Yugami, N			Effects of domain characteristics on instance-based learning algorithms	THEORETICAL COMPUTER SCIENCE			English	Article						instance-based learning; k-nearest neighbor classifier; average-case analysis; expected accuracy; optimal value of k	AVERAGE-CASE ANALYSIS	This paper presents average-case analyses of instance-based learning algorithms. The algorithms analyzed employ a variant of k-nearest neighbor classifier (k-NN). Our analysis deals with a monotone m-of-n target concept with irrelevant attributes, and handles three types of noise: relevant attribute noise, irrelevant attribute noise, and class noise. We formally represent the expected classification accuracy of k-NN as a function of domain characteristics including the number of training instances, the number of relevant and irrelevant attributes, the threshold number in the target concept, the probability of each attribute, the noise rate for each type of noise, and k. We also explore the behavioral implications of the analyses by presenting the effects of domain characteristics on the expected accuracy of k-NN and on the optimal value of k for artificial domains. (C) 2002 Elsevier Science B.V. All rights reserved.	Fujitsu Labs, Mihama Ku, Chiba 2138588, Japan	Okamoto, S (reprint author), Fujitsu Labs, Mihama Ku, 1-9-3 Nakase, Chiba 2138588, Japan.						Aha D.W., 1989, P 11 INT JOINT C ART, P794; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALBERT MK, 1991, P 9 NAT C ART INT, P553; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREECY RH, 1992, COMMUN ACM, V35, P48, DOI 10.1145/135226.135228; DASARATHY BV, 1991, NORMS NN PATTERN CLA; Duda R., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED; GOLEA M, 1993, NEURAL COMPUT, V5, P767, DOI 10.1162/neco.1993.5.5.767; HAUSSLER D, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1101; HIRSCHBERG D, 1992, P 9 INT C MACH LEARN, P206; Iba W., 1992, P 9 INT C MACH LEARN, P233; Iba W., 1992, P 10 NAT C ART INT, P223; Kasif Simon, 1994, P 11 INT MACH LEARN, P242; Langley P., 1999, P 16 INT C MACH LEAR, P220, DOI 10.1.1.43.3472; Langley P., 1993, P 13 INT JOINT C ART, P889; Murphy P.M., 1991, P 8 INT WORKSH MACH, P183; OKAMOTO S, 1996, P 13 INT C MACH LEAR, P355; OKAMOTO S, 1997, P 15 INT JOINT C ART, P238; OKAMOTO S, 2000, P 17 INT C MACH LEAR, P695; OKAMOTO S, 1995, LECT NOTES ARTIF INT, V1013, P253; PAZZANI MJ, 1992, MACH LEARN, V9, P349, DOI 10.1007/BF00994111; PITT L, 1988, J ACM, V35, P965, DOI 10.1145/48014.63140; Reischuk R, 1999, LECT NOTES COMPUT SC, V1563, P414; SALZBERG S, 1991, P 12 INT JOINT C ART, P705; SALZBERG S, 1995, IEEE T PATTERN ANAL, V17, P599, DOI 10.1109/34.387506; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; WALTZ DL, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1117; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	33	7	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0304-3975		THEOR COMPUT SCI	Theor. Comput. Sci.	APR 4	2003	298	1					207	233		10.1016/S0304-3975(02)00424-3		27	Computer Science, Theory & Methods	Computer Science	663GH	WOS:000181997500010	
J	Riquelme, JC; Aguilar-Ruiz, JS; Toro, M				Riquelme, JC; Aguilar-Ruiz, JS; Toro, M			Finding representative patterns with ordered projections	PATTERN RECOGNITION			English	Article						data mining; preprocessing techniques; pattern analysis; axis-parallel classifiers		This paper presents a new approach to finding representative patterns for dataset editing. The algorithm patterns by ordered projections (POP), has some interesting characteristics: important reduction of the number of instances from the dataset; lower computational cost (Theta(mn log n)) with respect to other typical algorithms due to the absence of distance calculations; conservation of the decision boundaries, especially from the point of view of the application of axis-parallel classifiers. POP works well in practice with both continuous and discrete attributes. The performance of POP is analysed in two ways: percentage of reduction and classification. POP has been compared to IB2, ENN and SHRINK concerning the percentage of reduction and the computational cost. In addition, we have analysed the accuracy of k-NN and C4.5 after applying the reduction techniques. An extensive empirical study using datasets with continuous and discrete attributes from the UCI repository shows that POP is a valuable preprocessing method for the later application of any axis-parallel learning algorithm. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Univ Seville, Tech Sch Comp Sci & Engn, Dept Comp Sci, E-41012 Seville, Spain	Aguilar-Ruiz, JS (reprint author), Univ Seville, Dept Lenguajes & Sistemas Informat, Avda Reina Mercedes S-N, E-41012 Seville, Spain.		Riquelme, Jose/E-6451-2010				Aguilar J, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P771; AGUILARRUIZ JS, 2000, P 14 EUR C ART INT B, P251; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOARE CAR, 1962, COMPUT J, V5, P10, DOI 10.1093/comjnl/5.1.10; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KLEE V, 1980, ARCH MATH, V34, P75, DOI 10.1007/BF01224932; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	15	17	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	APR	2003	36	4					1009	1018		10.1016/S0031-3203(02)00119-X		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	638NR	WOS:000180577600014	
J	Chang, DH; Kothari, R; Islam, S				Chang, DH; Kothari, R; Islam, S			Classification of soil texture using remotely, sensed brightness temperature over the southern great plains	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						artificial neural network (ANN); remote sensing; soil moisture; soil texture	PHYSICAL-PROPERTIES; NEURAL-NETWORK; INFORMATION; LANDSCAPE; SCALE; WATER; MODEL	This study explores the use of artificial neural networks (ANNs) models and brightness temperature from the Southern Great Plains in the United States to classify soil into different textures. Previous studies using ANN models and brightness temperature in a single drying cycle suggested that they might contain sufficient features to classify soil into three categories. To classify soil into more than three groups and to explore the limits of classification accuracy, this paper suggests the use of multiple-drying-cycle brightness temperature data. We have performed several experiments with feed-forward neural network (FFNN) models, and the results suggest that the maximum achievable classification accuracy through the use of multiple-drying-cycle brightness temperature is about 80%. It appears that the rapidly changing space-time evolution of brightness temperature will restrict the FFNN model performance. Motivated by these observations, we have used a simple prototype-based classifier, known as the 1-NN model, and achieved 86% classification accuracy for six textural groups. A comparison of error regions predicted by both models suggests that for the given input representation maximum achievable accuracy for classification into six soil texture types is about 93%.	Chaiyang Univ Technol, Dept Environm Engn, Wufeng, Taiwan; Chaiyang Univ Technol, Grad Inst Environm Engn & Management, Wufeng, Taiwan; IBM Corp, India Res Lab, New Delhi 110016, India; Univ Cincinnati, Dept Civil & Environm Engn, Cincinnati Earth Syst Sci Program, Cincinnati, OH 45221 USA	Chang, DH (reprint author), Chaiyang Univ Technol, Dept Environm Engn, Wufeng, Taiwan.						BAND LE, 1995, HYDROL PROCESS, V9, P401, DOI 10.1002/hyp.3360090312; Bishop CM, 1996, NEURAL NETWORKS PATT; Burke EJ, 1997, WATER RESOUR RES, V33, P1689, DOI 10.1029/97WR01000; CAMILLO PJ, 1986, IEEE T GEOSCI REMOTE, V24, P930, DOI 10.1109/TGRS.1986.289708; Chang DH, 2000, REMOTE SENS ENVIRON, V74, P534, DOI 10.1016/S0034-4257(00)00144-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; Hollenbeck KJ, 1996, WATER RESOUR RES, V32, P139, DOI 10.1029/95WR02916; Jackson T. J., 1995, REMOTE SENS ENVIRON, V53, P27; Jackson TJ, 1999, IEEE T GEOSCI REMOTE, V37, P2136, DOI 10.1109/36.789610; KONDO J, 1990, J APPL METEOROL, V29, P385, DOI 10.1175/1520-0450(1990)029<0385:APOEFB>2.0.CO;2; Levenberg K., 1944, Quarterly of Applied Mathematics, V2; MARQUARDT D, 1963, SIAM J APPL MATH, V11, P231; Mattikalli NM, 1998, WATER RESOUR RES, V34, P2289, DOI 10.1029/98WR00553; Miller D. A., 1998, EARTH INTERACTIONS, V2; Mitiche A, 1996, INT J PATTERN RECOGN, V10, P393, DOI 10.1142/S0218001496000268; RODRIGUEZ-ITURBE I, 1995, GEOPHYS RES LETT, V22, P2757, DOI 10.1029/95GL02779; Zhu AX, 1997, GEODERMA, V77, P217, DOI 10.1016/S0016-7061(97)00023-2; Zhu AX, 2000, WATER RESOUR RES, V36, P663, DOI 10.1029/1999WR900315	19	7	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017-2394 USA	0196-2892		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	MAR	2003	41	3					664	674		10.1109/TGRS.2003.809935		11	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing	Geochemistry & Geophysics; Engineering; Remote Sensing	678MQ	WOS:000182871300016	
J	Emrahoglu, N; Yegingil, I; Pestemalci, V; Senkal, O; Kandirmaz, HM				Emrahoglu, N; Yegingil, I; Pestemalci, V; Senkal, O; Kandirmaz, HM			Comparison of a new algorithm with the supervised classifications	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article								In this study, a new classification algorithm in which only the selected pixels have been attempted to be classified (selected pixels classification: SPC) has been introduced and compared with the well known supervised classification methods such as maximum likelihood, minimum distance, nearest neighbour and condensed nearest neighbour. To examine the algorithm, Landsat Thematic Mapper (TM) data have been used to classify the crop cover in the selected region. It is clearly demonstrated that the SPC method has the higher accuracy with comparable CPU times.	Cukurova Univ, Dept Phys, Adana, Turkey	Emrahoglu, N (reprint author), Cukurova Univ, Dept Phys, Adana, Turkey.						BENELLI G, 1987, WORKSH REM SENS TECH; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ENGVALL JL, 1977, REMOTE SENS ENVIRON, V6, P303, DOI 10.1016/0034-4257(77)90050-5; FIX E, DISCRIMINATORY ANAL; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Hansen M, 1996, INT J REMOTE SENS, V17, P1075; HART PE, 1968, IEEE T INFORMATION T, V14, P516; HORD RM, 1982, DIGITAL IMAGE PROCES; INCE F, 1986, INT J REMOTE SENS, V8, P1829; LEE T, 1985, INT J REMOTE SENS, V6, P75; PESTEMALCI V, 1996, TURKISH J PHYS, V20, P490; RICHARDS JA, 1984, REMOTE SENS ENVIRON, V16, P35, DOI 10.1016/0034-4257(84)90025-7	13	8	8	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161		INT J REMOTE SENS	Int. J. Remote Sens.	FEB 20	2003	24	4					649	655		10.1080/01431160210145597		7	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	653EK	WOS:000181422100003	
J	Roggo, Y; Duponchel, L; Huvenne, JP				Roggo, Y; Duponchel, L; Huvenne, JP			Comparison of supervised pattern recognition methods with McNemar's statistical test - Application to qualitative analysis of sugar beet by near-infrared spectroscopy	ANALYTICA CHIMICA ACTA			English	Article						classification; supervised pattern recognition method; McNemar's test; NIRS; sugar beet	PROBABILISTIC NEURAL NETWORKS; CLASSIFICATION; SPECTRA; ALGORITHMS; REGRESSION; EXCIPIENTS; NEIGHBOR; HOLMES	The application of supervised pattern recognition methodology is becoming important within chemistry. The aim of the study is to compare classification method accuracies by the use of a McNemar's statistical test. Three qualitative parameters of sugar beet are studied: disease resistance (DR), geographical origins and crop periods. Samples are analyzed by near-infrared spectroscopy (NIRS) and by wet chemical analysis (WCA). Firstly, the performances of eight well-known classification methods on NIRS data are compared: Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN) method, Soft Independent Modeling of Class Analogy (SIMCA), Discriminant Partial Least Squares (DPLS), Procrustes Discriminant Analysis (PDA), Classification And Regression Tree (CART), Probabilistic Neural Network (PNN) and Learning Vector Quantization (LVQ) neural network are computed. Among the three data sets, SIMCA, DPLS and PDA have the highest classification accuracies. LDA and KNN are not significantly different. The non-linear neural methods give the less accurate results. The three most accurate methods are linear, non-parametric and based on modeling methods. Secondly, we want to emphasize the power of near-infrared reflectance data for sample discrimination. McNemar's tests compare classification developed with WCA or with NIRS data. For two of the three data sets, the classification results are significantly improved by the use of NIRS data. (C) 2002 Elsevier Science B.V. All rights reserved.	Univ Sci & Technol, CNRS, UMR 8516, Lab Spectrochim Infrarouge & Raman, F-59655 Villeneuve Dascq, France	Roggo, Y (reprint author), Univ Sci & Technol, CNRS, UMR 8516, Lab Spectrochim Infrarouge & Raman, Batiment C5, F-59655 Villeneuve Dascq, France.		roggo, yves/F-2214-2011				Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Armanino C, 2002, ANAL CHIM ACTA, V454, P315, DOI 10.1016/S0003-2670(01)01548-3; BARHAM D, 1972, ANALYST, V97, P142, DOI 10.1039/an9729700142; BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201; Breiman L, 1984, CLASSIFICATION REGRE; BUCCI R, 2002, J AGR FOOD CHEM, V20, P413; Burnham AJ, 1996, J CHEMOMETR, V10, P31, DOI 10.1002/(SICI)1099-128X(199601)10:1<31::AID-CEM398>3.0.CO;2-1; CANDOLFI A, 1998, J PHARM BIOMED ANAL, V16, P1229; Candolfi A, 1999, J PHARMACEUT BIOMED, V21, P115, DOI 10.1016/S0731-7085(99)00125-9; Cappelli C, 2002, COMPUT STAT DATA AN, V38, P285, DOI 10.1016/S0167-9473(01)00044-5; Chapman WW, 2001, J BIOMED INFORM, V34, P4, DOI 10.1006/jbin.2001.1000; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demuth H., 2001, NEURAL NETWORK TOOLB; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Everitt B. S., 1977, ANAL CONTINGENCY TAB; Fisher R., 1935, DESIGN EXPT; Gonzalez-Arjona D, 1999, ANAL CHIM ACTA, V381, P257, DOI 10.1016/S0003-2670(98)00764-8; Gonzalez-Arjona D, 2001, CHEMOMETR INTELL LAB, V57, P133, DOI 10.1016/S0169-7439(01)00128-9; Gonzalez-Arjona D, 1999, TALANTA, V49, P189, DOI 10.1016/S0039-9140(98)00354-3; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1989, SELF ORG ASSOCIATIVE; Kramer K, 2000, ANAL CHIM ACTA, V420, P155, DOI 10.1016/S0003-2670(00)00877-1; Martens H., 1989, MULTIVARIATE CALIBRA; MARTIN M, 1996, ANAL CHIM ACTA, V350, P191; Massart D.L., 1988, CHEMOMETRICS TXB; OSBORN BG, 1993, PRACTICAL NIR SPECTR; PALLARA A, 1992, STAT APPL, V4, P255; Pomeranz Y., 1994, FOOD ANAL THEORY PRA; Roggo Y, 2002, J NEAR INFRARED SPEC, V10, P137; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; SHARAF M, 1986, CHEMOMETRICS, P228; Simon L, 2001, BIOCHEM ENG J, V7, P41, DOI 10.1016/S1369-703X(00)00102-9; Smola N, 2000, ANAL CHIM ACTA, V410, P203, DOI 10.1016/S0003-2670(99)00891-0; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STAHLE L, 1987, Journal of Chemometrics, V1, P185, DOI 10.1002/cem.1180010306; TAN C, 2002, INFORM PROCESS MANAG, V38, P329; Tenenhaus M., 1998, REGRESSION PLS; VANDEGINSTE G, 1988, HDB CHEMOMETRICS QUA, P207; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wu W, 1997, ANAL CHIM ACTA, V349, P253, DOI 10.1016/S0003-2670(97)00285-7; *FOSS, 2001, MAN UT FOSS FRANC SU; *ICUMSA, 1994, 61 ICUMSA GS	45	48	50	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670		ANAL CHIM ACTA	Anal. Chim. Acta	FEB 3	2003	477	2					187	200		10.1016/S0003-2670(02)01422-8		14	Chemistry, Analytical	Chemistry	636CR	WOS:000180437400002	
S	Vogt, P		Banzhaf, W; Christaller, T; Dittrich, P; Kim, JT; Ziegler, J		Vogt, P			THSim v3.2: The talking heads simulation tool	ADVANCES IN ARTIFICIAL LIFE, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th European Conference on Artifical Life	SEP 14-17, 2003	DORTMUND, GERMANY	Deutsch Forsch Gemeinsch, European Network Excellence Evolut Computat, Univ Dortmund e V, Gesell Freunde, Gesell Informat e V, Univ Dortmund, Westfal Ind Museum			EVOLUTION; EMERGENCE; LANGUAGE	The field of language evolution and computation may benefit from using efficient and robust simulation tools that are based on widely exploited principles within the field. The tool presented in this paper is one that could fulfil such needs. The paper presents an overview of the tool - THSim v3.2 - and discusses some research questions that can be investigated with it.	Tilburg Univ, NL-5000 LE Tilburg, Netherlands; Univ Edinburgh, Language Evolut & Computat Res Unit, Edinburgh EH8 9YL, Midlothian, Scotland	Vogt, P (reprint author), Tilburg Univ, POB 90153, NL-5000 LE Tilburg, Netherlands.						Batali J., 1998, APPROACHES EVOLUTION; Brighton H, 2002, ARTIF LIFE, V8, P25, DOI 10.1162/106454602753694756; Cangelosi A, 1998, CONNECT SCI, V10, P83; Cangelosi A., 2002, SIMULATING EVOLUTION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; HURFORD JR, 1989, LINGUA, V77, P187, DOI 10.1016/0024-3841(89)90015-6; KAPLAN F, 2000, THESIS LAB INFORMATI; KIRBY S, 2002, ARTIFICIAL LIFE, V8; Kirby S, 2001, IEEE T EVOLUT COMPUT, V5, P102, DOI 10.1109/4235.918430; Oliphant M, 1999, ADAPT BEHAV, V7, P371, DOI 10.1177/105971239900700309; Smith ADM, 2001, LECT NOTES ARTIF INT, V2159, P381; STEELS L, 1996, ANIMALS ANIMATS, V4; Steels L., 1999, TALKING HEADS EXPT, V1; VOGT P, 2003, J ARTIFICIAL SOC SOC, V6; VOGT P, 2003, P EUR SUMM SCH LOG L; VOGT P, 2000, EVOLUTION COMMUNICAT, V4, P89	17	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-20057-6	LECT NOTES ARTIF INT			2003	2801						535	544				10	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Computer Science	BX96C	WOS:000187009400057	
S	Huang, CC; Lee, HM		Berthold, MR; Lenz, HJ; Bradley, E; Kruse, R; Borgelt, C		Huang, CC; Lee, HM			A novel partial-memory learning algorithm based on grey relational structure	ADVANCES IN INTELLIGENT DATA ANALYSIS V	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	5th International Symposium on Intelligent Data Analysis	AUG 28-30, 2003	BERLIN, GERMANY				NEAREST NEIGHBOR RULE; CLASSIFICATION	In instance-based learning, the storage of instances must increase along with the number of training instances. In addition, it usually takes too much time to classify an unseen instance because all training instances have to be considered in determining the 'nearness' between instances. This paper proposes a novel partial-memory learning method based on the grey relational structure. That is, only some of the training instances are adopted for classification. The relationships among instances are first determined according to the grey relational structure. In this relational structure, the inward edges of each training instance, indicating how many times each instance is used as the nearest neighbor or neighbors in determining the class labels of other instances, can be found. This approach excludes the training instances with no or few inward edges for learning. By using the proposed approach, new instances can be classified with a few training instances. Five datasets are used for demonstrating the performance of the proposed approach. Experimental results indicate that the classification accuracy can be maintained when most of the training instances are pruned prior to learning. Meanwhile, the number of remained training instances is comparable to that of other existing pruning techniques.	Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan; Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan	Huang, CC (reprint author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake CL, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng Julong, 1989, Journal of Grey Systems, V1; DENG J, 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Fix E., 1951, 4 USAF SCH AV MED; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HUANG CC, 2002, P 2002 UK WORKSH COM; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; LIN CT, 1999, J GREY SYSTEM, V4, P359; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE M, 1974, J R STAT SOC B, V36, P111; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	18	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40813-4	LECT NOTES COMPUT SC			2003	2810						68	75				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BX67Y	WOS:000186104900007	
S	Kim, YS; Chang, JH; Zhang, BT		Whang, KY; Jeon, J; Shim, K; Srivastava, J		Kim, YS; Chang, JH; Zhang, BT			An empirical study on dimensionality optimization in text mining for linguistic knowledge acquisition	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	7th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 30-MAY 02, 2003	SEOUL, SOUTH KOREA	Adv Informat Technol Res Ctr, KAIST, Stat Res Ctr Complex Syst, SNU, Korea Informat Sci Soc, Korean Datamining Soc, USAF, Off Sci Res, Asian Off Aerosp Res & Dev, ACM SIGKDD		knowledge acquisition; text mining; Latent Semantic Analysis; probabilistic latent semantic analysis; target word selection		In this paper, we try to find empirically the optimal dimensionality in data-driven models, Latent Semantic Analysis (LSA) model and Probabilistic Latent Semantic Analysis (PLSA) model. These models are used for building linguistic semantic knowledge which could be used in estimating contextual semantic similarity for the target word selection in English-Korean machine translation. We also facilitate k-Nearest Neighbor learning algorithm. We diversify our experiments by analyzing the covariance between the value of k in k-NN learning and accuracy of selection, in addition to that between the dimensionality and the accuracy. While we could not find regular tendency of relationship between the dimensionality and the accuracy, however, we could find the optimal dimensionality having the most sound distribution of data during experiments.	Hallym Univ, Div Informat & Telecommun Engn, Kang Won 200702, South Korea; Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea	Kim, YS (reprint author), Hallym Univ, Div Informat & Telecommun Engn, Kang Won 200702, South Korea.						BAIN L, 1987, INTRO PROBABILITY MA, P179; BERRY M, 1993, CS93194 U TENN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hofmann T., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312649; KIM Y, 2002, P 19 INT C COMP LING, P453; KIM Y, 2001, MACHINE TRANSLATION, V16, P89, DOI 10.1023/A:1014540107013; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259	7	4	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-04760-3	LECT NOTES ARTIF INT			2003	2637						111	116				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	BX23S	WOS:000184716000011	
S	Mountrakis, G; Agouris, P		Hadzilacos, T; Manolopoulos, Y; Roddick, JF; Theodoridis, Y		Mountrakis, G; Agouris, P			Learning similarity with fuzzy functions of adaptable complexity	ADVANCES IN SPATIAL AND TEMPORAL DATABASES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Symposium on Advances in Spatial and Temporal Databases	JUL 24-27, 2003	SANTORINI ISL, GREECE	Microsoft, MDS Marathon Data Syst, Comp Technol Inst, Univ Piraeus				A common approach in database queries involves the multidimensional representation of objects by a set of features. These features are compared to the query representation and then combined together to produce a total similarity metric. In this paper we introduce a novel technique for similarity learning within features (attributes) by manipulating fuzzy membership functions (FMFs) of different complexity. Our approach is based on a gradual complexity increase adaptable to problem requirements. The underlying idea is that less adaptable functions will act as approximations for more complex ones. We begin by interpolating a set of planes in the training dataset and due to linearity we get a fast first impression of the underlying complexity. We proceed to interpolate two asymmetrical sigmoidal functions whose initial approximations are calculated from the plane properties. If satisfactory accuracy is not achieved we provide advanced modeling capabilities by investigating FMFs parameters and convolving their output with additional functions.	Univ Maine, Natl Ctr Geog Informat & Anal, Dept Spatial Informat Sci & Engn, Orono, ME 04469 USA	Mountrakis, G (reprint author), Univ Maine, Natl Ctr Geog Informat & Anal, Dept Spatial Informat Sci & Engn, 348 Boardman Hall, Orono, ME 04469 USA.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BATCHELOR BG, 1978, PATTERN RECOGN, P71; BERCHTOLD S, 1997, P ACM SIGMOD INT C M, P564, DOI 10.1145/253260.253407; CARKACIOGLU A, 2002, P INT C IM PROC, P405; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; David BL., 1993, P 4 INT C FDN DAT OR, P69; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Ishii N., 1998, Proceedings. IEEE International Joint Symposia on Intelligence and Systems (Cat. No.98EX174), DOI 10.1109/IJSIS.1998.685412; Lim JH, 2001, IEEE T KNOWL DATA EN, V13, P846; Mandl T, 2000, NEURAL COMPUT APPL, V9, P280, DOI 10.1007/s005210070005; Mitaim S., 1997, Proceeding. IEEE International Forum on Research and Technology Advances in Digital Libraries. -ADL'97- (Cat. No.97TB100126), DOI 10.1109/ADL.1997.601197; Nadler M, 1993, PATTERN RECOGNITION; Papadias D, 1999, INT J GEOGR INF SCI, V13, P93, DOI 10.1080/136588199241373; PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4; Rafiei D., 1997, P ACM SIGMOD INT C M, P13, DOI 10.1145/253260.253264; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Vlachos M., 2002, Proceedings 13th International Workshop on Database and Expert Systems Applications. DEXA 2002; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103; Yi B.K., 2000, P 26 INT C VER LARG, P385	19	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40535-6	LECT NOTES COMPUT SC			2003	2750						412	429				18	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BX40Z	WOS:000185178500024	
S	Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G		Dehne, F; Sack, JR; Smid, M		Bremner, D; Demaine, E; Erickson, J; Iacono, J; Langerman, S; Morin, P; Toussaint, G			Output-sensitive algorithms for computing nearest-neighbour decision boundaries	ALGORITHMS AND DATA STRUCTURES, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	8th International Workshop on Algorithms and Data Structures (WADS 2003)	JUL 30-AUG 01, 2003	OTTAWA, CANADA		CARLETON UNIV		CONVEX-HULL ALGORITHM	Given a set R of red points and a set, B of blue points, the nearest-neighbour decision rule classifies a new point q as red (respectively, blue) if the closest point to q in R U B comes from R (respectively, B). This rule implicitly partitions space into a red set and a blue set that are separated by a red-blue decision boundary. In this paper we develop output-sensitive algorithms for computing this decision boundary for point sets on the line and in R-2. Both algorithms run in time O(n log k), where k is the number of points that contribute to the decision boundary. This running time is the best possible when parameterizing with respect to n and k.	Univ New Brunswick, Fac Comp Sci, New Brunswick, NJ USA; MIT, Cambridge, MA 02139 USA; Univ Illinois, Dept Comp Sci, Chicago, IL 60680 USA; Free Univ Brussels, Charge Rech FNRS, Brussels, Belgium; Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5B6, Canada; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2T5, Canada	Bremner, D (reprint author), Univ New Brunswick, Fac Comp Sci, New Brunswick, NJ USA.						Ben-Or M., 1983, P 15 ANN ACM S THEOR, P80, DOI 10.1145/800061.808735; Bhattacharya BK, 1997, J ALGORITHM, V25, P177, DOI 10.1006/jagm.1997.0869; Blum M., 1973, Journal of Computer and System Sciences, V7, DOI 10.1016/S0022-0000(73)80033-9; Chan TM, 1996, DISCRETE COMPUT GEOM, V16, P361, DOI 10.1007/BF02712873; Chan TM, 1997, DISCRETE COMPUT GEOM, V18, P433, DOI 10.1007/PL00009327; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1978, PATTERN RECOGN, V10, P41, DOI 10.1016/0031-3203(78)90047-X; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; DOBKIN DP, 1985, J ALGORITHM, V6, P381, DOI 10.1016/0196-6774(85)90007-0; DOBKIN DP, 1983, THEOR COMPUT SCI, V27, P241, DOI 10.1016/0304-3975(82)90120-7; HOARE C. A. R., 1961, CACM, V4, P321, DOI 10.1145/366622.366644; KIRKPATRICK D, 1983, SIAM J COMPUT, V12, P28, DOI 10.1137/0212002; KIRKPATRICK DG, 1986, SIAM J COMPUT, V15, P287, DOI 10.1137/0215021; Preparata F. P., 1985, COMPUTATIONAL GEOMET; Shamos M., 1975, P 7 ANN ACM S THEOR, P224, DOI 10.1145/800116.803772; STONE CJ, 1980, ANN STAT, V8, P1348, DOI 10.1214/aos/1176345206; TOUSSAINT GT, 1984, P COMP SCI STAT 16 S; TOUSSAINT GT, 2003, UNPUB PROXIMITY GRAP; Wenger R, 1997, ALGORITHMICA, V17, P322, DOI 10.1007/BF02523195	19	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40545-3	LECT NOTES COMPUT SC			2003	2748						451	461				11	Computer Science, Theory & Methods	Computer Science	BX52R	WOS:000185605300039	
S	Yang, JY; Yang, MQ; Ersoy, OK		Kaynak, O; Alpaydin, E; Oja, E; Xu, L		Yang, JY; Yang, MQ; Ersoy, OK			Exploring protein functional relationships using genomic information and data mining techniques	ARTIFICAIL NEURAL NETWORKS AND NEURAL INFORMATION PROCESSING - ICAN/ICONIP 2003	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	Joint International Conference on Artificial Neural Networks (ICANN)/International on Neural Information Processing (ICONIP)	JUN 26-29, 2002	ISTANBUL, TURKEY	Bogazici Univ Fdn, USAF, European Off Aerosp Res & Dev, Turkish Sci & Tech Res Council				An approach that uses both supervised and unsupervised learning methods for exploring protein functional relationships is reported; we refer to this as Maximum Contrast (MC) tree. The tree is constructed by performing a hierarchical decomposition of the feature space; this step is performed regardless of complex nature of protein functions, i.e. it performs this decomposition even without knowledge of the protein functional class labels. In order to test our algorithm, we have constructed a library of Protein Phylogenetic Profiles for the proteins in the yeast Saccharomyces Cerevisiae with 60 species. Results showed our algorithm compares favorably to other classification algorithms such as the decision tree algorithms C4.5, C5, and to support vector machines.	Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Yang, JY (reprint author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Choe W, 2000, BIOINFORMATICS, V16, P1062, DOI 10.1093/bioinformatics/16.12.1062; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ERSOY OK, 1998, ALGORITHM ARCHITECTU, P364; ERSOY OK, 1995, IEEE T NEURAL NETWOR, V6, P1037, DOI 10.1109/72.410348; Marcotte EM, 1999, NATURE, V402, P83; PAVLIDIS P, J COMPUTATIONAL BIOL, V9, P401; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; YANG J, 2002, INTELLIGENG ENG SYST, V12, P733	11	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40408-2	LECT NOTES COMPUT SC			2003	2714						1073	1080				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BX47F	WOS:000185378100128	
J	Li, JY; Liu, HQ; Downing, JR; Yeoh, AEJ; Wong, LS				Li, JY; Liu, HQ; Downing, JR; Yeoh, AEJ; Wong, LS			Simple rules underlying gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients	BIOINFORMATICS			English	Article							CLASSIFICATION; PREDICTION; DISCOVERY; PATTERNS	Motivations and Results: For classifying gene expression profiles or other types of medical data, simple rules are preferable to non-linear distance or kernel functions. This is because rules may help us understand more about the application in addition to performing an accurate classification. In this paper, we discover novel rules that describe the gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients. We also introduce a new classifier, named PCL, to make effective use of the rules. PCL is accurate and can handle multiple parallel classifications. We evaluate this method by classifying 327 heterogeneous ALL samples. Our test error rate is competitive to that of support vector machines, and it is 71% better than C4.5, 50% better than Naive Bayes, and 43% better than k-nearest neighbour. Experimental results on another independent data sets are also presented to show the strength of our method.	Labs Informat Technol, Singapore 119613, Singapore; St Jude Childrens Res Hosp, Memphis, TN 38105 USA; Natl Univ Singapore, Singapore 119074, Singapore	Li, JY (reprint author), Labs Informat Technol, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@lit.a-star.edu.sg	Wong, Limsoon/E-5033-2010				Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Iba W., 1992, P 10 NAT C ART INT, P223; LI J, 2000, P 17 INT C MACH LEAR, P551; Li J., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Liu H., 1995, P IEEE 7 INT C TOOLS, P338; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Witten H., 2000, DATA MINING PRACTICA; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	14	46	56	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803		BIOINFORMATICS	Bioinformatics	JAN	2003	19	1					71	78		10.1093/bioinformatics/19.1.71		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	636PA	WOS:000180463900011	
B	Li, J; Li, DD; Khoja, JA; Liang, QL; Manry, MT; Prabhu, VK		Heiter, G		Li, J; Li, DD; Khoja, JA; Liang, QL; Manry, MT; Prabhu, VK			Overcoming co-channel interference in TDMA systems using SOM equalizer	BOSTON 2003 RADIO & WIRELESS RAWCON CONFERENCE, PROCEEDINGS			English	Proceedings Paper	IEEE Radio and Wireless Conference (RAWCON 2003)	AUG 10-13, 2003	BOSTON, MA	IEEE Microware Theory & Tech Soc, IEEE Boston Sect, IEEE Commun Soc			CHANNEL EQUALIZATION	This paper studies the co-channel interference (CCI) problem for time-division-multiple-access (TDMA) cellular mobile communication system with burst transmission. We present a method using self-organizing-map (SOM) to overcome CCI for such a system. The SOM is realized as a classification equalizer with a decision feedback adaptive filter. An extremely small number of unique words (UWs) is utilized to initialize the SOM equalizer. Simulation results show that the bit error rate (BER) of our proposed method is much better than that of the recently proposed nearest neighbor classification equalizer.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.						Chen S, 1996, IEE P-COMMUN, V143, P219, DOI 10.1049/ip-com:19960612; CHEN S, 1992, SIGNAL PROCESS, V28, P91, DOI 10.1016/0165-1684(92)90067-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Jakes W.C., 1993, MICROWAVE MOBILE COM; KOHONEN T, 1995, SELFORGANIZING MAPS; Liang QL, 2000, IEEE T CIRCUITS-II, V47, P1419, DOI 10.1109/82.899635; Rappaport T.S., 1996, WIRELESS COMMUNICATI; Savazzi P, 1998, IEEE J SEL AREA COMM, V16, P1640, DOI 10.1109/49.737633; XIANG ZJ, 1994, IEEE T SIGNAL PROCES, V42, P2470	9	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7829-6				2003							123	126				4	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BX45A	WOS:000185329800031	
S	Woon, FL; Knight, B; Petridis, M		Ashley, KD; Bridge, DG		Woon, FL; Knight, B; Petridis, M			Case base reduction using solution-space metrics	CASE-BASED REASONING RESEARCH AND DEVELOPMENT, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	5th International Conference on Case-Bases Reasoning (ICCBR 2003)	JUN 23-26, 2003	TRONDHEIM, NORWAY	Kaidara Software, Empolis & Norwegian, Univ Sci & Technol, Dept Comp & Informat Sci			NEAREST NEIGHBOR RULE; LEARNING ALGORITHMS; BENDS	In this paper we propose a case base reduction technique which uses a metric defined on the solution space. The technique utilises the Generalised Shepard Nearest Neighbour (GSNN) algorithm to estimate nominal or real valued solutions in case bases with solution space metrics. An overview of GSNN and a generalised reduction technique, which subsumes some existing decremental methods, such as the Shrink algorithm, are presented. The reduction technique is given for case bases in terms of a measure of the importance of each case to the predictive power of the case base. A trial test is performed on two case bases of different kinds, with several metrics proposed in the solution space. The tests show that GSNN can out-perforin standard nearest neighbour methods on this set. Further test results show that a case-removal order proposed based on a GSNN error function can produce a sparse case base with good predictive power.	Tunku Abdul Rahman Coll, Sch Arts & Sci, Kuala Lumpur, Malaysia; Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England	Woon, FL (reprint author), Tunku Abdul Rahman Coll, Sch Arts & Sci, Kuala Lumpur, Malaysia.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Cameron-Jones R.M., 1995, P 8 AUSTR JOINT C AR, P99; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Hanson R, 2002, P I MECH ENG E-J PRO, V216, P143, DOI 10.1243/095440802320225284; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kalman H, 2000, POWDER TECHNOL, V112, P244, DOI 10.1016/S0032-5910(00)00298-9; Keane M. T., 1995, P 14 INT JOINT C ART, P377; Kibler D., 1987, Proceedings of the Fourth International Workshop on Machine Learning; KNIGHT B, 2003, IN PRESS P 18 INT JO; Kolodner J., 1993, CASE BASED REASONING; MITCHELL TM, 1997, MACH LEARN, P230; RICHTER M, ICCBR 2001; Salamo M, 2002, LECT NOTES ARTIF INT, V2416, P365; Shepard D, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616; Smyth B, 1998, LECT NOTES ARTIF INT, V1488, P208; Smyth B, 1999, LECT NOTES ARTIF INT, V1650, P329; Watson I., 1997, APPL CASE BASED REAS; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; WITTEN IH, 2000, PRACTICAL MACHINE LE, P125; Yang Q, 2001, COMPUT INTELL, V17, P250, DOI 10.1111/0824-7935.00143	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40433-3	LECT NOTES ARTIF INT			2003	2689						652	664				13	Computer Science, Artificial Intelligence	Computer Science	BX29X	WOS:000184854300049	
B	Gregson, DJ; Li, KF; Fu, W		Olivier, G; Pierre, S; Sood, VK		Gregson, DJ; Li, KF; Fu, W			Fault detection using phenomenological models	CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS: TOWARD A CARING AND HUMANE TECHNOLOGY			English	Proceedings Paper	15th IEEE Canadian Conference on Electrical and Computer Engineering	MAY 04-07, 2003	MONTREAL, CANADA	IEEE, IEEE Canada, IEEE Eastern Canada Council, IEEE Montreal, St Maurice & Quebec Sect, Ecole Polytech Montreal, Manitoba HVDC Res Ctr, Cooperat Etudiante Ecole Polytech, John Wiley & Sons Canada, McGraw Hill Ryerson Ltd, Cheneliere McGraw Hill, Oxford Univ Press, Presses Int Polytech		fault detection; system modeling; behavioural modeling; outlier analysis		There exist many different established approaches to detect system faults. This paper discusses the various system models and the associated fault detection techniques. Specifically, phenomenological models are presented in detail. Fault detection using principal components analysis and the cluster and classify method is illustrated with real operational data from an electrically powered vehicle.	Quester Tangent Corp, Sidney, BC, Canada	Gregson, DJ (reprint author), Quester Tangent Corp, Sidney, BC, Canada.						AGRAWAL R, 1993, P FODO C; BARNETT V., 1994, OUTLIERS STAT DATA; Bishop C. M., 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRYAN FJ, 1988, MULTIVARIATE STAT ME; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dym C. L., 1991, KNOWLEDGE BASED SYST; Fahlman S. E., 1990, CMUCS90100 SCH COMP; Goldberg D. E, 1989, GENETIC ALGORITHMS S; Han J., 2001, DATA MINING CONCEPTS; Keravnou E. T., 1986, COMPETENT EXPERT SYS; Pouliezos A. D., 1994, REAL TIME FAULT MONI; PRESTON J, 2002, OBJECTIVE MEASURES A; RINNER B, 1996, THESIS GRAZ U TECHNO; SIDDALL JN, 1990, EXPERT SYSTEMS ENG; SIMULA O, 1998, ANAL MODELING COMPLE	16	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7781-8				2003							855	859				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic; Optics; Telecommunications	Computer Science; Engineering; Optics; Telecommunications	BX59A	WOS:000185776300199	
S	Ferrer-Troyano, LJ; Aguilar-Ruiz, JS; Riquelme, JC		Sloot, PMA; Abramson, D; Bogdanov, AV; Dongarra, JJ; Zomaya, AY; Gorbachev, YE		Ferrer-Troyano, LJ; Aguilar-Ruiz, JS; Riquelme, JC			Empirical evaluation of the difficulty of finding a good value of k for the nearest neighbor	COMPUTATIONAL SCIENCE - ICCS 2003, PT II, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	International Conference on Computational Science (ICCS 2003)	JUN 02-04, 2003	MELBOURNE, AUSTRALIA	Univ Amsterdam, Hewlett Packard, Springer Verlag, Netherlands Inst St Petersburg, Russian Federat, Minist Ind, Sci & Technol, Govt St Petersburg, Comm Sci & High Educ, St Petersburg State Tech Univ, Inst High Performance Comp & Informat Syst, IBM Australia, Microsoft, Cray Inc, Dolphin Interconnect, Microway, Etnus, ceanet, NAG, Pallas GmbH		nearest neighbor; local adaptive nearest neighbor	CLASSIFICATION	As an analysis of the classification accuracy bound for the Nearest Neighbor technique, in this work we have studied if it is possible to find a good value of the parameter k for each example according to their attribute values. Or at least, if there is a pattern for the parameter k in the original search space. We have carried out different approaches based on the Nearest Neighbor technique and calculated the prediction accuracy for a group of databases from the UCI repository. Based on the experimental results of our study, we can state that, in general, it is not possible to know a priori a specific value of k to correctly classify an unseen example.	Univ Sevilla, Dept Comp Sci, Seville 41012, Spain	Ferrer-Troyano, LJ (reprint author), Univ Sevilla, Dept Comp Sci, Avenida Reina Mercedes S-N, Seville 41012, Spain.		Riquelme, Jose/E-6451-2010				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Blake CL, 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FERRER FJ, 2001, P 10 PORT C ART INT; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; STONE M, 1974, J R STAT SOC B, V36, P111; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1994, ADV NEURAL INFORMATI, P184; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	13	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40195-4	LECT NOTES COMPUT SC			2003	2658						766	773				8	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BX28K	WOS:000184831800083	
S	Cardenes, R; Warfield, SK; Macias, EM; Santana, JA; Ruiz-Alzola, J		MorenoDiaz, R; Pichler, F		Cardenes, R; Warfield, SK; Macias, EM; Santana, JA; Ruiz-Alzola, J			An efficient algorithm for multiple sclerosis lesion segmentation from brain MRI	COMPUTER AIDED SYSTEMS THEORY - EUROCAST 2003	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	9th International Workshop on Computer Aided Systems Theory	FEB 24-28, 2003	LAS PALMAS GC, SPAIN				FINDING NEAREST NEIGHBORS; ARBITRARY DIMENSIONS; CLASSIFICATION	We propose a novel method for the segmentation of Multiple Sclerosis (MS) lesions in MRI. The method is based on a three-step approach: first a conventional k-NN classifier is applied to pre-classify gray matter (CM), white matter (WM), cerebro-spinal fluid (CSF) and MS lesions from a set of prototypes selected by an expert. Second, the classification of problematic patterns is resolved computing a fast distance transformation (DT) algorithm from the set of prototypes in the Euclidean space defined by the MRI dataset. Finally, a connected component filtering algorithm is used to remove lesion voxels not connected to the real lesions. This method uses distance information together with intensity information to improve the accuracy of lesion segmentation and, thus, it is specially useful when MS lesions have similar intensity values than other tissues. It is also well suited for interactive segmentations due to its efficiency. Results are shown on real MRI data as wall as on a standard database of synthetic images.	Univ Las Palmas de Gran Canaria, Dept Ingn Telemat, Las Palmas Gran Canaria, Spain; Harvard Univ, Sch Med, Cambridge, MA 02138 USA; Brigham & Womens Hosp, Dept Radiol, Boston, MA 02115 USA; Univ Las Palmas de Gran Canaria, Med Technol Ctr, Las Palmas Gran Canaria, Spain	Cardenes, R (reprint author), Univ Las Palmas de Gran Canaria, Dept Ingn Telemat, Las Palmas Gran Canaria, Spain.	ruben@ctm.ulpgc.es; warfield@bwh.harvard.edu; elsa@dit.ulpgc.es; jaruelio@ctm.ulpgc.es; jruiz@ctm.ulpgc.es	Warfield, Simon/B-3352-2009				Aurenhammer F, 2000, HANDBOOK OF COMPUTATIONAL GEOMETRY, P201, DOI 10.1016/B978-044482537-7/50006-1; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; Cocosco Chris A., 1997, NEUROIMAGE, V5, P425; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUISENAIRE O, 2000, P 10 EUR SIGN PROC C, P1365; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Duda R., 1973, PATTERN CLASSIFICATI; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; JIANG QY, 1993, PATTERN RECOGN LETT, V14, P531, DOI 10.1016/0167-8655(93)90101-I; KAUS M, 2000, THESIS BERLIN; Okabe A., 1992, SPATIAL TESSELATIONS; RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4; VERWER BJH, 1989, IEEE T PATTERN ANAL, V11, P425, DOI 10.1109/34.19041; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; Warfield SK, 2000, MED IMAGE ANAL, V4, P43, DOI 10.1016/S1361-8415(00)00003-7	17	5	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-20221-8	LECT NOTES COMPUT SC			2003	2809						542	551				10	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Automation & Control Systems; Computer Science; Imaging Science & Photographic Technology	BY16G	WOS:000188006400049	
S	Li, JY; Ng, SK; Wong, LS		Calvanese, D; Lenzerini, M; Motwani, R		Li, JY; Ng, SK; Wong, LS			Bioinformatics adventures in database research	DATABASE THEORY ICDT 2003, PROCEEDINGS	Lecture Notes in Computer Science		English	Article; Proceedings Paper	9th International Conference on Database Theory (ICDT)	JAN 08-10, 2003	SIENA, ITALY	Univ Roma, Dipartimento Informat Sistemist			COLLECTION TYPES; QUERY LANGUAGES; HUMAN GENOME; DISCOVERY; CLASSIFICATION; PREDICTION; GENE; SYSTEM	Informatics has helped launch molecular biology into the genomic era. It appears certain that informatics will remain a major contributor to molecular biology in the post-genome era. We discuss here data integration and datamining in bioinformatics, as well as the role that database theory played in these topics. We also describe LIMS as a third key topic in bioinformatics where advances in database system and theory can be very relevant.	Labs Informat Technol, Singapore 119613, Singapore	Li, JY (reprint author), Labs Informat Technol, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	jinyan@lit.a-star.edu.sg; skng@lit.a-star.edu.sg; limsoon@lit.a-star.edu.sg	Wong, Limsoon/E-5033-2010				AGRAWAL R, VLDB 94, P487; Baker PG, 1998, CURR OPIN BIOTECH, V9, P54, DOI 10.1016/S0958-1669(98)80084-0; BAYARDO RJ, SIGMOD 98, P85; BUNEMAN P, 1995, THEOR COMPUT SCI, V149, P3, DOI 10.1016/0304-3975(95)00024-Q; Buneman P., 1994, SIGMOD Record, V23; CHEN J, IN PRESS BIOINFORMAT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAMAS L, POPL 82, P207; Davidson S. B., 1997, International Journal on Digital Libraries, V1; DONG G, KDD 99, P15; FAYYAD UM, IJCAI 93, P1022; Gerhold D, 1999, TRENDS BIOCHEM SCI, V24, P168, DOI 10.1016/S0968-0004(99)01382-1; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Haas LM, 2001, IBM SYST J, V40, P489; Hatzigeorgiou AG, 2002, BIOINFORMATICS, V18, P343, DOI 10.1093/bioinformatics/18.2.343; JAESCHKE G, PODS 82, P124; KOZAK M, 1987, NUCLEIC ACIDS RES, V15, P8125, DOI 10.1093/nar/15.20.8125; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; LANGLEY P, AAAI 92, P223; LI J, ICML 00, P551; LI J, 2002, IN PRESS BIOINFORMAT; LI J, PKDD 02, P325; Libkin L, 1997, J COMPUT SYST SCI, V55, P241, DOI 10.1006/jcss.1997.1523; Liu H., 1995, P IEEE 7 INT C TOOLS, P338; MAKINOUCHI A, VLDB 77, P447; Mannila H, 1997, DATA MIN KNOWL DISC, V1, P241, DOI 10.1023/A:1009796218281; PAPAKONSTANTINO.Y, ICDE 95, P251; PEARSON PL, 1992, NUCLEIC ACIDS RES, V20, P2201; Pedersen AG, 1997, ISMB, P226; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schuler GD, 1996, METHOD ENZYMOL, V266, P141; Searls DB, 2000, DRUG DISCOV TODAY, V5, P135, DOI 10.1016/S1359-6446(99)01457-9; Thomas S. J., 1986, ADV COMPUTING RES, V3, P269; Vapnik V.N., 1995, NATURE STAT LEARNING; Wadler Philip, 1992, MATH STRUCTURES COMP, V2, P461; Wong L, 1996, J COMPUT SYST SCI, V52, P495, DOI 10.1006/jcss.1996.0037; Wong L., 2000, J FUNCTIONAL PROGRAM, V10, P19, DOI 10.1017/S0956796899003585; WONG L, BIBE 00, P21; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; ZENG F, IN PRESS GIW 02; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; *DOE, 1993, DOE INF SUMM M REP	43	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-00323-1	LECT NOTES COMPUT SC			2003	2572						31	46				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BW31N	WOS:000181548600003	
B	van Herwijnen, O; Terken, J; van den Bosch, A; Marsi, E			ACL	van Herwijnen, O; Terken, J; van den Bosch, A; Marsi, E			Learning PP attachment for filtering prosodic phrasing	EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE			English	Proceedings Paper	10th Conference of the European Chapter of the Association-for-Computational-Linguistics (EACL 2003)	APR 12-17, 2003	Budapest, HUNGARY	Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc				We explore learning prepositional-phrase attachment in Dutch, to use it as a filter in prosodic phrasing. From a syntactic treebank of spoken Dutch we extract instances of the attachment of prepositional phrases to either a governing verb or noun. Using cross-validated parameter and feature selection, we train two learning algorithms, IB1 and RIPPER, on making this distinction, based on unigram and bigram lexical features and a cooccurrence feature derived from WWW counts. We optimize the learning on noun attachment, since in a second stage we use the attachment decision. for blocking the incorrect placement of phrase boundaries before prepositional phrases attached to the preceding noun. On noun attachment, IB1 attains an F-score of 82; RIPPER an F-score of 78. When used as a filter for prosodic phrasing, using attachment decisions from IB1 yields the best improvement on precision (by six points to 71) on phrase boundary placement.	Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands			van den Bosch, Antal/G-5072-2011	van den Bosch, Antal/0000-0003-2493-656X			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BEAR J, 1990, P 28 C ASS COMP LING, P17, DOI 10.3115/981823.981826; BRILL E, 1994, P 15 ANN C COMP LING; CHARNIAK E., 2000, P 1 C N AM CHAPT ASS, P132; Church KM, 1991, COMPUTATIONAL LINGUI, V16, P22; Cohen W. W., 1995, P 12 INT C MACH LEAR; Collins M, 1996, P 34 ANN M ASS COMP; COLLINS M, 1995, P 3 WORKSH VER LARG; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670; DAELEMANS W, 2002, ILK0210 TILB U; Dunning T., 1993, Computational Linguistics, V19; FRANZ A, 1996, LECT NOTES ARTIF INT, V1040, P188; Hindle D., 1993, Computational Linguistics, V19; MARSI E, 1997, PROGR SPEECH SYNTHES, P477; PAARDEKOOPER PC, 1977, ABN BEKNOPTE ABN SYN; RATNAPARKHI A, 1994, P ARPA WORKSH HUM LA; Ratnaparkhi A, 1997, P 2 C EMP METH NAT L, P1; SANDERMAN A, 1996, THESIS EINDHOVEN U T; Sanderman AA, 1997, LANG SPEECH, V40, P391; Selkirk Elisabeth, 1984, PHONOLOGY SYNTAX REL; VANDERWOUDEN T, 2002, P 3 INT C LANG RES E, P768; VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V1, P529; VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V2, P959; VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA; VOLK M, 2000, P KONVENS 2000, P151; ZAVREL J, 1997, P WORKSH COMP NAT LA, P136	27	0	0	ASSOCIATION COMPUTATIONAL LINGUISTICS	SOMERSET	PO BOX 6090, SOMERSET, NJ 08875 USA		1-932432-00-0				2003							139	146				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Computer Science; Linguistics	BAN69	WOS:000222995200019	
J	Gilboa, I; Schmeidler, D				Gilboa, I; Schmeidler, D			Inductive inference: An axiomatic approach	ECONOMETRICA			English	Article						case-based reasoning; case-based decision theory; prediction; maximum likelihood; kernel functions; kernel classification	DECISION-THEORY	A predictor is asked to rank eventualities according to their plausibility, based on past cases. We assume that she can form a ranking given any memory that consists of finitely many past cases. Mild consistency requirements on these rankings imply that they have a numerical representation via a matrix assigning numbers to eventuality-case pairs, as follows. Given a memory, each eventuality is ranked according to the sum of the numbers in its row, over cases in memory. The number attached to an eventuality-case pair can be interpreted as the degree of support that the past case lends to the plausibility of the eventuality. Special instances of this result may be viewed as axiomatizing kernel methods for estimation of densities and for classification problems. Interpreting the same result for rankings of theories or hypotheses, rather than of specific eventualities, it is shown that one may ascribe to the predictor subjective conditional probabilities of cases given theories, such that her rankings of theories agree with rankings by the likelihood functions.	Tel Aviv Univ, Eitan Berglas Sch Econ, IL-69978 Tel Aviv, Israel; Tel Aviv Univ, Recanati Sch Business, IL-69978 Tel Aviv, Israel; Yale Univ, Cowles Fdn, New Haven, CT 06520 USA; Tel Aviv Univ, Dept Stat, IL-69978 Tel Aviv, Israel; Ohio State Univ, Dept Econ, Columbus, OH 43210 USA	Gilboa, I (reprint author), Tel Aviv Univ, Eitan Berglas Sch Econ, IL-69978 Tel Aviv, Israel.						Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Finetti B., 1937, ANN I H POINCARE, V7, P1; Devroye L, 1996, PROBABILISTIC THEORY; Fix E., 1951, 4 USAF SCH AV MED; Fix E., 1952, 2149004 USAF SCH AV; FORSYTH R, 1986, MACHINE LEARNING APP; Gilboa I, 1997, ECON THEORY, V9, P47, DOI 10.1007/BF01213442; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; GILBOA L, 2001, THEORY CASE BASED DE; GILBOA L, 1999, 3199 FOERD I EC RES; GILBOA L, 2002, MATH OPER RES, V27, P68; Hacking Ian, 1975, EMERGENCE PROBABILIT; Hume D, 1748, ENQUIRY HUMAN UNDERS; MYERSON RB, 1995, SOC CHOICE WELFARE, V12, P59; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Ramsey Frank Plumpton, 1931, FDN MATH OTHER LOGIC; Riesbeck C., 1989, INSIDE CASE BASED RE; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Royall R., 1966, THESIS STANFORD U ST; Savage L., 1954, FDN STAT; Schank Roger C., 1986, EXPLANATION PATTERNS; Scott D. W., 1992, MULTIVARIATE DENSITY; Silverman B.W., 1986, DENSITY ESTIMATION S; STONE C, 1977, ANN STAT, V5, P689; YOUNG HP, 1975, SIAM J APPL MATH, V28, P824, DOI 10.1137/0128067	26	20	20	BLACKWELL PUBL LTD	OXFORD	108 COWLEY RD, OXFORD OX4 1JF, OXON, ENGLAND	0012-9682		ECONOMETRICA	Econometrica	JAN	2003	71	1					1	26		10.1111/1468-0262.00388		26	Economics; Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Statistics & Probability	Business & Economics; Mathematics; Mathematical Methods In Social Sciences	637ZQ	WOS:000180543900001	
J	Uchimura, S; Watanabe, M; Hamamoto, Y				Uchimura, S; Watanabe, M; Hamamoto, Y			On the optimization of a Gabor filter-based feature extractor for handwritten character recognition	ELECTRONICS AND COMMUNICATIONS IN JAPAN PART III-FUNDAMENTAL ELECTRONIC SCIENCE			English	Article						handwritten character recognition; Gabor parameter optimization; energy function method; response surface method; two-stage searches	CLASSIFICATION	In order to use the Gabor feature extraction system in the real world, the problem of optimizing the Gabor parameters must be resolved. In the conventional optimization method, several candidates are prepared, the error rate for them is found through experimentation, and the parameters which give the lowest recognition error rates are taken to be optimal values. However, in the conventional method, setting the candidate values so that they are certain to include optimal values is a common problem. In this paper, the authors evaluate from the standpoint of the optimalness of the solutions and computational burden the optimization methods (two-stage conventional method, response surface method, and energy function method) that address the problems of the conventional method. (C) 2003 Wiley Periodicals, Inc.	Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan	Uchimura, S (reprint author), Yamaguchi Univ, Fac Engn, Ube, Yamaguchi 7558611, Japan.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Funkunaga K., 1990, INTRO STAT PATTERN R; HAMAMOTO Y, 1994, J IEICE, V77, P853; Hamamoto Y., 1996, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ79D-II; Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5; HEIDEMANN G, 1996, P 13 INT C PATT REC, V4, P70; Iri M., 1985, COMMON SENSE NUMERIC; JAIN AK, 1992, PATTERN RECOGN, V25, P1459, DOI 10.1016/0031-3203(92)90120-8; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293; KONDO Y, 1967, STAT METHODS ENG; OKUNO C, 1969, METHODS PLANNING EXP; Press WH, 1993, NUMERICAL RECIPES C; SAITO Y, 1978, DENSOKENI REPORT, V42, P385; TAGUCHI G, 1977, METHODS PLANNING EXP, V2; UCHIMURA S, 1998, PRMU97225 IEICE; UCHIMURA S, 1996, PRMU9628 IEICE	17	0	0	SCRIPTA TECHNICA-JOHN WILEY & SONS	NEW YORK	605 THIRD AVE, NEW YORK, NY 10158 USA	1042-0967		ELECTRON COMM JPN 3	Electron. Commun. Jpn. Pt. III-Fundam. Electron. Sci.		2003	86	12					27	37		10.1002/ecjc.10140		11	Engineering, Electrical & Electronic	Engineering	694EM	WOS:000183760900003	
S	Ben Hamza, A; Krim, H		Rangarajan, A; Figueiredo, M; Zerubia, J		Ben Hamza, A; Krim, H			Image registration and segmentation by maximizing the Jensen-Renyi divergence	ENERGY MINIMIZATION METHODS IN COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	4th International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	JUL 07-09, 2003	LISBON, PORTUGAL	Int Assoc Pattern Recognit, Inst Superior Tecn, Inst Telecommun			CLASSIFICATION	Information theoretic measures provide quantitative entropic divergences between two probability distributions or data sets. In this paper, we analyze the theoretical properties of the Jensen-Renyi divergence which is defined between any arbitrary number of probability distributions. Using the theory of majorization, we derive its maximum value, and also some performance upper bounds in terms of the Bayes risk and the asymptotic error of the nearest neighbor classifier. To gain further insight into the robustness and the application of the Jensen-Renyi divergence measure in imaging, we provide substantial numerical experiments to show the power of this entopic measure in image registration and segmentation.	N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA	Ben Hamza, A (reprint author), N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA.		Ben Hamza, Abdessamad/G-4571-2013				ALI SM, 1966, J ROY STAT SOC B, V28, P131; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L, 1996, PROBABILISTIC THEORY; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gomez JF, 2000, NEURAL NETWORKS, V13, P1; HE Y, 2000, P SPIE, V4116; HE Y, 2003, IEEE T SIGNAL PROCES, V51; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; Jensen J. R., 1996, INTRO DIGITAL IMAGE; KATURI R, 1991, COMPUTER VISION PRIN; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Marshall AW, 1979, INEQUALITIES THEORY; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; RENYI A, 1961, MEASURES ENTROPY INF, V2, P525; Roman-Roldan R, 1998, PHYS REV LETT, V80, P1344, DOI 10.1103/PhysRevLett.80.1344; STOICA R, 1998, IEEE INT C IM PROC C; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VIOLA P, 1997, INT J COMPUT VISION, V24, P173	21	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40498-8	LECT NOTES COMPUT SC			2003	2683						147	163				17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX35F	WOS:000185041700010	
S	Behnke, S				Behnke, S			Hierarchical neural networks for image interpretation - Introduction	HIERARCHICAL NEURAL NETWORKS FOR IMAGE INTERPRETATION	Lecture Notes in Computer Science		English	Article							PRIMARY VISUAL-CORTEX; NONNEGATIVE MATRIX FACTORIZATION; LONG-TERM DEPENDENCIES; HUMAN FACE DETECTION; PATTERN-RECOGNITION; BELIEF PROPAGATION; GRADIENT DESCENT; SHAPE REPRESENTATION; LEARNING ALGORITHMS; OBJECT-RECOGNITION		Int Comp Sci Inst, Berkeley, CA 94704 USA	Behnke, S (reprint author), Int Comp Sci Inst, 1947 Ctr Str, Berkeley, CA 94704 USA.		Behnke, Sven/B-5509-2013	Behnke, Sven/0000-0002-5040-7525			ACKLEY DH, 1985, COGNITIVE SCI, V9, P147, DOI 10.1016/S0364-0213(85)80012-4; AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259; ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Arena P, 2002, INT J CIRC THEOR APP, V30, P349, DOI 10.1002/cta.203; Atiya AF, 2000, IEEE T NEURAL NETWOR, V11, P697, DOI 10.1109/72.846741; Baker S., 2002, IEEE T PATTERN ANAL, V24; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Balya D, 2002, INT J CIRC THEOR APP, V30, P363, DOI 10.1002/cta.204; Barlow H B, 1972, Perception, V1, P371, DOI 10.1068/p010371; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Barthlott W, 1997, PLANTA, V202, P1, DOI 10.1007/s004250050096; BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141; BAUMGARTE V, 2001, P INT C ENG REC SYST; Behnke S, 2000, LECT NOTES ARTIF INT, V1856, P186; BEHNKE S, 1998, P INT JOINT C NEUR N, V2, P820; BEHNKE S, 1997, P INT C NEUR NETW IC, V3, P1391, DOI 10.1109/ICNN.1997.613997; BEHNKE S, 1998, P INT C ART NEUR NET, V2, P567; BEHNKE S, 2001, LECT NOTES ARTIF INT, V2103, P125; BEHNKE S, 1998, P 3 INT WORKSH NEUR, P39; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bellman R., 1961, ADAPTIVE CONTROL PRO; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Beyer K., 1999, P 7 INT C DAT THEOR, P217; BIEHL M, 1995, J PHYS A-MATH GEN, V28, P643, DOI 10.1088/0305-4470/28/3/018; Bierling M, 1988, P SOC PHOTO-OPT INS, V1001, P942; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BOGACZ R, 1999, P 3 INT C COGN NEUR; Boynton GM, 1999, VISION RES, V39, P257, DOI 10.1016/S0042-6989(98)00113-8; Breiman L, 1984, CLASSIFICATION REGRE; Bullier J, 2001, TRENDS COGN SCI, V5, P369, DOI 10.1016/S1364-6613(00)01730-7; Burr Ridge I, 1997, MACHINE LEARNING; BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851; CAMINITI R, 1996, VISION MOVEMENT MECH; Carpenter G, 1991, PATTERN RECOGNITION; CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P147, DOI 10.1109/81.222795; CHUA LO, 2001, CELLULAR NEURAL NETW; COIFMAN RR, 1994, NATO ADV SCI INST SE, V442, P363; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N, 2000, INTRO SUPPORT VECTOR; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, DOI 10.1007/BF02551274; DAUBECHES I, 1992, CBMS NSF SERIES APPL, V61; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; De Bonet J. S., 1997, COMPUTER GRAPHICS, P361; Dell'Acqua F, 2002, IEEE T PATTERN ANAL, V24, P569, DOI 10.1109/34.993564; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; De Weerd P, 1998, VISION RES, V38, P2721, DOI 10.1016/S0042-6989(97)00432-X; Dill M, 1998, PERCEPT PSYCHOPHYS, V60, P65, DOI 10.3758/BF03211918; Doniger GM, 2000, J COGNITIVE NEUROSCI, V12, P615, DOI 10.1162/089892900562372; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.2307/2291512; Duda R. O., 1973, PATTERN RECOGNITION; ECKHORN R, 1988, BIOL CYBERN, V60, P121, DOI 10.1007/BF00202899; EDK D, 2002, LNCS, V2415, P284; Efron B., 1993, INTRO BOOTSTRAP; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893; ElHihi S, 1996, ADV NEUR IN, V8, P493; EMILE HL, 1990, SIMULATED ANNEALING; Fahlman S.E., 1988, P 1988 CONN MOD SUMM, P38; FAN Y, 2000, OPTICAL ENG, V38, P2894; FECHNER GT, 1858, ABK K GES WISSENS MP, P4; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fletcher R., 1987, PRACTICAL METHODS OP; Fletcher R., 1976, LECT NOTES MATH, V506, P73; FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346; FOLDIAK P, 2002, HDB BRAIN THEORY NEU; Foldiak P., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.2.194; Lawrence S, 2000, IEEE T KNOWL DATA EN, V12, P126, DOI 10.1109/69.842255; FRANZ C, 1889, ARCH ANATOMIE PHYS S, V2, P263; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790414; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; FREUND Y, 1992, ADV NEUR IN, V4, P912; FREY BJ, 1997, COMPUTATIONAL BIOL M; Frey BJ, 1998, ADV NEUR IN, V10, P479; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gabor D., 1946, Journal of the Institution of Electrical Engineers. III. Radio and Communication Engineering, V93; GARRIS MD, 1992, NIST SPECIAL DATABAS, V3; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GIESE MA, 1998, KLUWER INT SERIES EN, V469; Govindaraju V, 1996, INT J COMPUT VISION, V19, P129, DOI 10.1007/BF00055801; Grossberg S, 2001, CEREB CORTEX, V11, P37, DOI 10.1093/cercor/11.1.37; Grossberg S, 1999, SPATIAL VISION, V12, P163, DOI 10.1163/156856899X00102; GROTHER PJ, 1993, 5209 NISTIR NIST; Haag J, 1997, J NEUROSCI, V17, P4809; Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326; Hahnloser RLT, 1998, NEURAL NETWORKS, V11, P691, DOI 10.1016/S0893-6080(98)00012-4; Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072; Hebb D O, 1949, ORG BEHAV; HEISELE B, 2000, 1687 MIT AI LAB; Heisenberg W., 1927, Zeitschrift fur Physik, V43, DOI 10.1007/BF01397280; Henkel RD, 1998, ADV NEUR IN, V10, P808; Hertzmann A, 2001, COMP GRAPH, P327; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hjelmas E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hopfield IJ, 2000, P NATL ACAD SCI USA, V97, P13919; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Hopfield JJ, 2001, P NATL ACAD SCI USA, V98, P1282, DOI 10.1073/pnas.031567098; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Igel C, 2003, NEUROCOMPUTING, V50, P105, DOI 10.1016/S0925-2312(01)00700-7; ITO M, 1995, J NEUROPHYSIOL, V73, P218; Jaeger H, 2001, 148 GMD GERM NAT RES; Jeng SH, 1998, PATTERN RECOGN, V31, P273, DOI 10.1016/S0031-3203(97)00048-4; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; JOHNSON SP, 2000, P 12 INT C INF STUD; Johnson SP, 1996, COGNITIVE DEV, V11, P161, DOI 10.1016/S0885-2014(96)90001-5; JUALESZ B, 1984, DYNAMIC ASPECTS NEOC, P585; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Kalman R. E., 1960, T ASME, V82, P35; Kandel E. R., 2000, PRINCIPLES NEURAL SC; KANIZSA GK, 1989, ORG VISION; Kapasi UJ, 2002, PR IEEE COMP DESIGN, P282, DOI 10.1109/ICCD.2002.1106783; Kass M., 1988, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KELLMAN PJ, 1983, COGNITIVE PSYCHOL, V15, P483, DOI 10.1016/0010-0285(83)90017-8; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; KNIERIM JJ, 1992, J NEUROPHYSIOL, V67, P961; KOCH C, 1995, VISION CHIPS IMPLEME; Koffka K., 1935, PRINCIPLES GESTALT P; Kohonen T, 1984, SPRINGER SERIES INFO, V8; KOKARAM AC, 1998, P SPIE C BAYES INF I, P212; KROGH A, 1992, ADV NEUR IN, V4, P950; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LAMME VAF, 1995, J NEUROSCI, V15, P1605; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9; LECUN Y, 1990, ADV NEURAL INFORMATI, V2; LECUN Y, 1994, MNIST DATABASE HANDW; Lee CH, 1996, PATTERN RECOGN, V29, P1877, DOI 10.1016/0031-3203(96)00036-2; Lee DD, 2001, ADV NEUR IN, V13, P556; Lee DD, 1999, NATURE, V401, P788; Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1; Legenstein RA, 2001, ADV NEUR IN, V13, P259; Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9; Li ZP, 2001, NEURAL COMPUT, V13, P1749, DOI 10.1162/08997660152469332; LINAN G, 2001, P 27 EUR SOL STAT CI, P216; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; LOVELL DR, 1994, THESIS U QUEENSLAND; MAAS W, 2001, UNPUB REAL TIME COMP; Maio D, 2000, PATTERN RECOGN, V33, P1525, DOI 10.1016/S0031-3203(99)00130-2; MALLADI R, 1995, P NATL ACAD SCI USA, V92, P7046, DOI 10.1073/pnas.92.15.7046; Mallat S., 1992, IEEE T PATTERN ANAL, V14, P7; MALLAT S, 1989, IEEE T PATTERN ANAL, V2, P7; Marr D., 1982, VISION COMPUTATIONAL; Mayraz G, 2001, ADV NEUR IN, V13, P953; McEliece RJ, 1998, IEEE J SEL AREA COMM, V16, P140, DOI 10.1109/49.661103; MERON E, 1992, PHYS REP, V218, P1, DOI 10.1016/0370-1573(92)90098-K; Messer K., 1999, P 2 INT C AUD VID BA, P72; Minsky M., 1969, PERCEPTRONS INTRO CO; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Møller M, 1993, Int J Neural Syst, V4, P15, DOI 10.1142/S0129065793000031; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; NAKAYAMA K, 1990, PERCEPTION, V19, P497, DOI 10.1068/p190497; NAZIR T A, 1990, Spatial Vision, V5, P81, DOI 10.1163/156856890X00011; Neumann H, 1999, BIOL CYBERN, V81, P425, DOI 10.1007/s004220050573; NEWTON I, 1664, METHODUS FLUXIONUM S; Nyquist H., 1928, T AIEE, V47, P617; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OTOOLE A, 1995, P INT WORKSH AUT FAC, P326; PALM G, 1980, BIOL CYBERN, V36, P19, DOI 10.1007/BF00337019; Parveen S, 2002, ADV NEUR IN, V14, P1189; Pascual-Leone A, 2001, SCIENCE, V292, P510, DOI 10.1126/science.1057099; Pasemann F, 1998, NETWORK-COMP NEURAL, V9, P495, DOI 10.1088/0954-898X/9/4/006; Pasupathy A, 2001, J NEUROPHYSIOL, V86, P2505; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0; Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; RAIZADA RDS, 2001, VIS COGN, V8, P341; RAMACHER U, 2001, P EUR SOL STAT CIRC; Ramsden BM, 2001, CEREB CORTEX, V11, P648, DOI 10.1093/cercor/11.7.648; Rao RPN, 1999, VISION RES, V39, P1963, DOI 10.1016/S0042-6989(98)00279-X; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018; REICHER GM, 1969, J EXP PSYCHOL, V81, P275, DOI 10.1037/h0027768; Reynolds JH, 1999, NEURON, V24, P19, DOI 10.1016/S0896-6273(00)80819-3; Riedmiller M., 1993, P IEEE INT C NEUR NE, P586; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Rojas R., 1996, NEURAL NETWORKS SYST; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Roska B, 2001, NATURE, V410, P583, DOI 10.1038/35069068; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salomon R, 1996, NEURAL NETWORKS, V9, P589; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; SARDANA HK, 1994, PATTERN RECOGN, V27, P109, DOI 10.1016/0031-3203(94)90021-3; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Schneiderman H., 2000, P IEEE C COMP VIS PA; Scholkopf B, 2002, LEARNING KERNELS SUP; Senseman DM, 2002, J NEUROPHYSIOL, V87, P1499, DOI 10.1152/jn.00475.2001; Seung HS, 1998, ADV NEUR IN, V10, P654; Siegel M, 2000, J COMPUT NEUROSCI, V8, P161, DOI 10.1023/A:1008973215925; SIEGELMANN HT, 1995, J COMPUT SYST SCI, V50, P132, DOI 10.1006/jcss.1995.1013; SILVA FM, 1990, LECT NOTES COMPUT SC, V412, P110; Simoncelli E, 1996, P IEEE INT C IM PROC; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.neuro.18.1.555; Smith R, 1998, ANN ONCOL, V9, P6; Smolensky P., 1986, PARALLEL DISTRIBUTED, V1, P194; Somers DC, 1998, CEREB CORTEX, V8, P204, DOI 10.1093/cercor/8.3.204; STEMMLER M, 1995, SCIENCE, V269, P1877, DOI 10.1126/science.7569930; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Super H, 2001, NAT NEUROSCI, V4, P304, DOI 10.1038/85170; Sutton R. S., 1998, REINFORCEMENT LEARNI; TAYA R, 1995, PERCEPTION, V24, P685, DOI 10.1068/p240685; Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), DOI 10.1109/AFGR.2000.840612; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; THORPE SJ, 1998, TRENDS RES, P333; TOLLENAERE T, 1990, NEURAL NETWORKS, V3, P520; Treisman A, 1977, ATTENTION PERFORM, P333; Tsodyks MV, 1997, P NATL ACAD SCI USA, V94, P719, DOI 10.1073/pnas.94.2.719; TURNER MR, 1986, BIOL CYBERN, V55, P71; VanRullen R, 2001, NEUROCOMPUTING, V38, P1003, DOI 10.1016/S0925-2312(01)00445-3; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Vijayakumar S., 2001, Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180), DOI 10.1109/IROS.2001.976418; VONHUNDELSHAUSE.F, 2002, LECT NOTES ARTIF INT, V2377, P374; Weber EH, 1834, PULSU RESORPTIONE AU; WEISS SM, 1990, COMPUTERS SYSTEMS LE; Wellner J, 1998, INFORMATION PROCESSING IN CELLS AND TISSUES, P295; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270; WILSON CL, 1993, NEURAL NETWORKS SIGN, V3, P485; WISKOTT L, 2003, IN PRESS PROBLEMS SY; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Wong ROL, 1999, ANNU REV NEUROSCI, V22, P29, DOI 10.1146/annurev.neuro.22.1.29; Yedidia JS, 2001, ADV NEUR IN, V13, P689; Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6; *ASME, 1986, PITN BOW MOD M POST	243	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40722-7	LECT NOTES COMPUT SC			2003	2766						1	+				210	Computer Science, Theory & Methods	Computer Science	BX63P	WOS:000185939800001	
J	Apte, CV; Hong, SJ; Natarajan, R; Pednault, EPD; Tipu, FA; Weiss, SM				Apte, CV; Hong, SJ; Natarajan, R; Pednault, EPD; Tipu, FA; Weiss, SM			Data-intensive analytics for predicting modeling	IBM JOURNAL OF RESEARCH AND DEVELOPMENT			English	Article							INFORMATION; RULES	The Data Abstraction Research Group was formed in the early 1990s, to bring focus to the work of the Mathematical Sciences Department in the emerging area of knowledge discovery and data mining (KD & DM). Most activities in this group have been performed in the technical area of predictive modeling, roughly at the intersection of machine learning, statistical modeling, and database technology. There has been a major emphasis on using business and industrial problems to motivate the research agenda. Major accomplishments include advances in methods for feature analysis, rule-based pattern discovery, and probabilistic modeling, and novel solutions for insurance risk management, targeted marketing, and text mining. This paper presents an overview of the group's major technical accomplishments.	IBM Corp, Div Res, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA	Apte, CV (reprint author), IBM Corp, Div Res, Thomas J Watson Res Ctr, POB 218, Yorktown Hts, NY 10598 USA.						APTE C, 1995, ADV KNOWLEDGE DISCOV, P541; Apte C., 2001, P 7 ACM SIGKDD INT C, P408, DOI 10.1145/502512.502573; APTE C, 1994, ACM T INFORM SYST, V12, P233, DOI 10.1145/183422.183423; APTE C, 1996, RC20271 IBM TJ WATS; Apte C., 1994, P 17 ANN INT ACM SIG, P23; Apte C, 1999, IEEE INTELL SYST APP, V14, P49, DOI 10.1109/5254.809568; Apte CV, 2002, IBM SYST J, V41, P438; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fayyad U.M., 1995, ADV KNOWLEDGE DISCOV; Freund Y., 1996, P 13 INT C MACH LEAR, P148; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; HONG S, 1996, P ISIS 96, P10; HONG SJ, 2001, P 3 INT C DAT WAR KN, P131; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P709; Hong SJ, 1997, IEEE T KNOWL DATA EN, V9, P718; Indurkhya Nitin, 2001, P 7 ACM SIGKDD INT C, P287, DOI 10.1145/502512.502553; James M., 1985, CLASSIFICATION ALGOR; Kulikowski C., 1991, COMPUTER SYSTEMS LEA; Iyengar V. S., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347110; Michie D, 1994, MACHINE LEARNING NEU; Ripley B. D., 1996, PATTERN RECOGNITION; Scheffe H., 1959, ANAL VARIANCE; WEISS SM, 2000, P 17 INT C MACH LEAR, P1135; Weiss SM, 1999, IEEE INTELL SYST APP, V14, P63, DOI 10.1109/5254.784086; WEISS SM, 2001, RC22061 IBM TJ WATS; Weiss S.M., 2001, P 5 EUR C PRINC DAT, P484; Weiss SM, 2000, IEEE INTELL SYST APP, V15, P57, DOI 10.1109/5254.850828; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	29	5	5	IBM CORP	ARMONK	OLD ORCHARD RD, ARMONK, NY 10504 USA	0018-8646		IBM J RES DEV	IBM J. Res. Dev.	JAN	2003	47	1					17	23				7	Computer Science, Hardware & Architecture; Multidisciplinary Sciences	Computer Science; Science & Technology - Other Topics	636VW	WOS:000180478800003	
J	Sakkis, G; Androutsopoulos, I; Paliouras, G; Karkaletsis, V; Spyropoulos, CD; Stamatopoulos, P				Sakkis, G; Androutsopoulos, I; Paliouras, G; Karkaletsis, V; Spyropoulos, CD; Stamatopoulos, P			A memory-based approach to anti-spam filtering for mailing lists	INFORMATION RETRIEVAL			English	Article						text categorization; machine learning; unsolicited commercial e-mail; spam	LEARNING ALGORITHMS; TEXT CATEGORIZATION; CLASSIFICATION	This paper presents an extensive empirical evaluation of memory-based learning in the context of anti-spam filtering, a novel cost-sensitive application of text categorization that attempts to identify automatically unsolicited commercial messages that flood mailboxes. Focusing on anti-spam filtering for mailing lists, a thorough investigation of the effectiveness of a memory-based anti-spam filter is performed using a publicly available corpus. The investigation includes different attribute and distance-weighting schemes, and studies on the effect of the neighborhood size, the size of the attribute set, and the size of the training corpus. Three different cost scenarios are identified, and suitable cost-sensitive evaluation functions are employed. We conclude that memory-based anti-spam filtering for mailing lists is practically feasible, especially when combined with additional safety nets. Compared to a previously tested Naive Bayes filter, the memory-based filter performs on average better, particularly when the misclassification cost for non-spam messages is high.	Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece; Athens Univ Econ & Business, Dept Informat, GR-10434 Athens, Greece; Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece; Univ Athens, Dept Informat, GR-15771 Athens, Greece	Sakkis, G (reprint author), Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, GR-15310 Athens, Greece.	gsakis@iit.demokritos.gr; ion@aueb.gr; paliourg@iit.demokritos.gr; vangelis@iit.demokritos.gr; costass@iit.demokritos.gr; T.Stamatopoulos@di.uoa.gr					AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Andren N, 2000, J STRATEGIC STUD, V23, P167; Androutsopoulos I., 2000, P WORKSH MACH LEARN, P1; Androutsopoulos I, 2000, P WORKSH MACH LEARN, P9; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Burr Ridge I, 1997, MACHINE LEARNING; Cohen W. W., 1996, P AAAI SPRING S MACH, P18; Cohen WW, 1999, ACM T INFORM SYST, V17, P141, DOI 10.1145/306686.306688; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cranor LF, 1998, COMMUN ACM, V41, P74, DOI 10.1145/280324.280336; Cristianini N, 2000, INTRO SUPPORT VECTOR; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; DAELEMANS W, 2000, TIMBL TILBURG MEMORY; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Duda R.O., 1973, PATTERN CLASSIFICATI, P10; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; GIRAUDCARRIER C, 1995, THEO DECI L, V15, P341; Hall RJ, 1998, COMMUN ACM, V41, P88, DOI 10.1145/272287.272329; HIDALGO JMG, 2000, 4 COMP NAT LANG LEAR, P99; HULL DA, 2000, NIST SP, P35; Joachims T, 1997, P 14 INT C MACH LEAR, P143; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lang K., 1995, P 12 INT C MACH LEAR, P331; Lewis D.D., 1995, P 18 ANN INT ACM SIG, P246, DOI 10.1145/215206.215366; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; PANTEL P, 1998, AAAI WORKSH MAD WISC; Payne TR, 1997, APPL ARTIF INTELL, V11, P1, DOI 10.1080/088395197118325; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313; Sahami M., 1998, AAAI WORKSH MAD WISC, P55; Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44; SALTON G, 1983, INTRO MODERN INFORMA; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; SEBASTIANI F, 2001, IEIB4311999 CONS NAZ; WETTSCHERECK D, 1994, THESIS OREGON STATE; WETTSCHERECK D, 1995, AIC95012 NAV RES LAB; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WILSON DR, 1997, THESIS B YOUNG U; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Yang Y, 1997, P 14 INT C MACH LEAR, P412; ZAVREL J, 1997, P 7 BELG DUTCH C MAC	44	77	82	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-4564		INFORM RETRIEVAL	Inf. Retr.	JAN	2003	6	1					49	73		10.1023/A:1022948414856		25	Computer Science, Information Systems	Computer Science	660FM	WOS:000181823200003	
B	Boullart, L; Sette, S; Wyns, B; Baeten, D; Hoffman, I; De Keyser, F		Ruano, AE; Ruano, MG; Fleming, PJ		Boullart, L; Sette, S; Wyns, B; Baeten, D; Hoffman, I; De Keyser, F			Prediction of arthritis using a modified Kohonen mapping and case based learning	INTELLIGENT CONTROL SYSTEMS AND SIGNAL PROCESSING 2003	IFAC PROCEEDINGS SERIES		English	Proceedings Paper	IFAC International Conference on Intelligent Control Systems and Signal Processing	APR 08-11, 2003	FARO, PORTUGAL	Int Federat Automat Control, IEEE, Int Fuzzy Syst Assoc, Neural Networks Soc	UNIV ALGARVE	classification; neural network models; case based learning; threshold; self-organizing systems; medical applications	RHEUMATOID-ARTHRITIS	Rheumatoid arthritis (RA) and spondyloarthropathy (SpA) are the two most frequent forms of chronic autoimmune arthritis. These diseases lead to important inflammatory symptoms resulting in an important functional impairment. In this paper we apply a topological mapping combined with a case based learning evaluation criterion to predict early arthritis. The first part presents a brief introduction to the problem and self-learning neural networks while the second part of this paper will apply this technique together with a case based learning evaluation criterion to diagnostic classification. Finally the paper shows that the Kohonen neural network achieves good performance that exceeds the results of other neural network approaches and decision trees. Copyright (C) 2003 IFAC.	State Univ Ghent, Fac Sci Appl, Dept Elect Energy Syst & Automat, Ghent, Belgium	Boullart, L (reprint author), State Univ Ghent, Fac Sci Appl, Dept Elect Energy Syst & Automat, Ghent, Belgium.						ALI Z, 2000, INTELLIGENT CONTROL; Baeten D, 2000, ANN RHEUM DIS, V59, P945, DOI 10.1136/ard.59.12.945; Baeten D, 2001, ARTHRITIS RHEUM, V44, P2255, DOI 10.1002/1529-0131(200110)44:10<2255::AID-ART388>3.0.CO;2-#; Baeten D, 1999, CLIN RHEUMATOL, V18, P434, DOI 10.1007/s100670050134; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kohonen T., 1989, SELF ORG ASS MEMORY; LOH WY, 2002, QUICK UNBIASED EFFIC; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SEIBEN G, 1994, ACTA NEUROCHIRUGICA, P193; SETTE S, 1995, TEXT RES J, V65, P196, DOI 10.1177/004051759506500402; SPYROS GT, 1997, METHODS APPL INTELLI; TOMAS H, 1997, NEUROCONTROL IND CON	12	0	0	PERGAMON-ELSEVIER SCIENCE LTD	KIDLINGTON	THE BOULEVARD, LANGFORD LANE,, KIDLINGTON OX5 1GB, OXFORD, ENGLAND		0-08-044088-6	IFAC P SER			2003							43	48				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BY50Q	WOS:000189390000008	
B	Yager, RR		BouchonMeunier, B; Foulloy, L; Yager, RR		Yager, RR			Prototype based reasoning and fuzzy modeling	INTELLIGENT SYSTEMS FOR INFORMATION PROCESSING: FROM REPRESENTATION TO APPLICATIONS			English	Proceedings Paper	9th International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems	JUL 01-05, 2002	ANNECY, FRANCE			fuzzy modeling; fuzzy measures; nearest neighbor principle; information fusion		We introduce the methodology of prototype based reasoning and discuss its role as a technology for supplying missing information about some object based on known information about related objects. We show that nearest neighbor based systems and fuzzy rule based models are examples of prototype based reasoning. This perspective allows us to extend the capabilities of fuzzy modeling technology in a number of directions. One such extension discussed here is to suggest a method for fusing multiple fuzzy systems models.	Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.		Yager, Ronald/A-2960-2013				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1988, POSSIBILITY THEORY; Duda R. O., 2001, PATTERN CLASSIFICATI; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; MAMDANI EH, 1974, P I ELECTR ENG, V121, P1585; MUROFUSHI T, 1999, FUZZY MEASURES INTEG, P3; Nguyen H. T., 1998, FUZZY SYSTEMS MODELI; Sugeno M., 1974, THESIS TOKYO I TECHN; Sugeno M., 1977, FUZZY AUTOMATA DECIS, P89; YAGER RR, 1993, FUZZY SET SYST, V55, P255, DOI 10.1016/0165-0114(93)90252-D; YAGER RR, 2001, MII2111 MACH INT I I; Yager R.R., 1994, ESSENTIALS FUZZY MOD; YGER RR, 2001, P ATL S COMP BIOL GE, P92; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575	14	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS		0-444-51379-5				2003							167	178		10.1016/B978-044451379-3/50013-3		12	Computer Science, Artificial Intelligence	Computer Science	BY37T	WOS:000189131300013	
J	Grumberg, O; Livne, S; Markovitch, S				Grumberg, O; Livne, S; Markovitch, S			Learning to order BDD variables in verification	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							BINARY DECISION DIAGRAMS; FORMAL VERIFICATION; OBDDS; ALGORITHM	The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. One of the most successful methods for automated verification of finite-state systems is model checking. Most of the current model-checking systems use binary decision diagrams (BDDs) for the representation of the tested model and in the verification process of its properties. Generally, BDDs allow a canonical compact representation of a boolean function (given an order of its variables). The more compact the BDD is, the better performance one gets from the verifier. However, finding an optimal order for a BDD is an NP-complete problem. Therefore, several heuristic methods based on expert knowledge have been developed for variable ordering. We propose an alternative approach in which the variable ordering algorithm gains "ordering experience" from training models and uses the learned knowledge for finding good orders. Our methodology is based on offline learning of pair precedence classifiers from training models, that is, learning which variable pair permutation is more likely to lead to a good order. For each training model, a number of training sequences are evaluated. Every training model variable pair permutation is then tagged based on its performance on the evaluated orders. The tagged permutations are then passed through a feature extractor and are given as examples to a classifier creation algorithm. Given a model for which an order is requested, the ordering algorithm consults each precedence classifier and constructs a pair precedence table which is used to create the order. Our algorithm was integrated with SMV, which is one of the most widely used verification systems. Preliminary empirical evaluation of our methodology, using real benchmark models, shows performance that is better than random ordering and is competitive with existing algorithms that use expert knowledge. We believe that in sub-domains of models (alu, caches, etc.) our system will prove even more valuable. This is because it features the ability to learn sub-domain knowledge, something that no other ordering algorithm does.	Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Grumberg, O (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.						AKERS SB, 1978, IEEE T COMPUT, V27, P509; AZIZ A, 1994, P 31 DES AUT C, P283, DOI 10.1145/196244.196379; BEER I, 1996, P 33 DES AUT C, P655, DOI 10.1145/240518.240642; BERN J, 1995, P 32 ACM IEEE DES AU, P408, DOI 10.1145/217474.217563; Bollig B, 1996, IEEE T COMPUT, V45, P993, DOI 10.1109/12.537122; BOLLIG B, 1995, P INT WORKSH LOG SYN; Breiman L, 1984, CLASSIFICATION REGRE; Brglez F, 1989, P INT S CIRC SYST IS, P1924; BROOS P, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P651; Bryant R.E., 1986, IEEE T COMPUT; Butler K.M., 1991, P 28 ACM IEEE DES AU, P417, DOI 10.1145/127601.127705; Chamberlain R. D., 1995, P 32 IEEE ACM DES AU, P139, DOI 10.1145/217474.217520; Chung P.-Y., 1993, [Proceedings] 1993 IEEE International Symposium on Circuits and Systems, DOI 10.1109/ISCAS.1993.394067; CLARKE EM, 1986, ACM T PROGR LANG SYS, V8, P244, DOI 10.1145/5397.5399; Cohen WW, 1999, J ARTIF INTELL RES, V10, P243; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Drechsler R., 1998, Proceedings 1998 Design and Automation Conference. 35th DAC. (Cat. No.98CH36175), DOI 10.1109/DAC.1998.724466; Drechsler R, 1996, IEE P-COMPUT DIG T, V143, P364, DOI 10.1049/ip-cdt:19960789; Duda R., 1973, PATTERN CLASSIFICATI; Even G, 1998, ALGORITHMICA, V20, P151, DOI 10.1007/PL00009191; FRIEDMAN JH, 1977, IEEE T COMPUT, V26, P404; FRIEDMAN SJ, 1987, P 24 DES AUT C DAC M, P151; FUJII H, 1993, P INT C COMP AID DES, P38, DOI 10.1109/ICCAD.1993.580028; FUJITA M, 1993, IEEE T COMPUT AID D, V12, P6, DOI 10.1109/43.184839; Fujita M., 1988, P IEEE INT C COMP AI, P2; FUJITA M, 1995, P INT WORKSH LOG SYN, P596; Hunt EB, 1966, EXPT INDUCTION; ISHIURA N, 1991, P INT C COMP AID DES, P472; Iyer MA, 1996, IEEE T VLSI SYST, V4, P295, DOI 10.1109/92.502203; JAIN J, 1998, P INT C COMP AID DES, P631, DOI 10.1145/288548.289099; Karp R. M., 1972, COMPLEXITY COMPUTER, P85; Kaufmann M, 1997, PR IEEE COMP DESIGN, P25, DOI 10.1109/ICCD.1997.628845; KONUK H, 1993, P 11 IEEE VLSI TEST, P85; Lindenbaum M., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Long D. E., 1995, Proceedings 13th IEEE VLSI Test Symposium (Cat. No.95TH8068), DOI 10.1109/VTEST.1995.512610; Malik S., 1988, P INT C COMP AID DES, P6; McMillan K., 1993, SYMBOLIC MODEL CHECK; Meinel C., 1997, Proceedings 1997. Design Automation Conference, 34th DAC; MEINEL C, 1998, LECT NOTES COMPUTER, V1521, P419; Meinel C, 1997, PR IEEE COMP DESIGN, P338, DOI 10.1109/ICCD.1997.628892; MERCER MR, 1992, P 29 DES AUT C DAC; Minato S., 1990, P 27 ACM IEEE DES AU, P52; NAKAMURA K, 1998, P ICCAD 98 NOV, P392, DOI 10.1145/288548.289059; Panda S., 1995, P INT C COMP AID DES, P74, DOI 10.1109/ICCAD.1995.479994; PANDA S, 1994, P INT C COMP AID DES, P628; Parker D. B., 1985, TR47 MIT CTR COMP RE; QUEILLE JP, 1981, LNCS, V137, P337; Quinlan J. R., 1979, Expert Systems in the Micro-Electronic Age. Proceedings of the 1979 AISB Summer School; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rudell R., 1993, P INT C COMP AID DES, P42, DOI 10.1109/ICCAD.1993.580029; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; Touati H. J., 1990, P INT C COMP AID DES, P130; Utgoff P. E., 1987, Proceedings of the Fourth International Workshop on Machine Learning; UTGOFF PE, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P596; Wahba A, 1995, LECT NOTES COMPUT SC, V987, P171; Widrow B., 1960, 1960 IRE WESCON CONV, P96; ZHUANG N, 1996, P IEEE INT S CIRC SY, V3, P414	58	9	9	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757		J ARTIF INTELL RES	J. Artif. Intell. Res.		2003	18						83	116				34	Computer Science, Artificial Intelligence	Computer Science	640VG	WOS:000180708200001	
J	Priebe, CE; Marchette, DJ; DeVinney, JG; Socolinsky, DA				Priebe, CE; Marchette, DJ; DeVinney, JG; Socolinsky, DA			Classification using class cover catch digraphs	JOURNAL OF CLASSIFICATION			English	Article						classification; random graph; class cover; prototype selection		We present a semiparametric mixture methodology for classification which involves modelling the class-conditional discriminant regions via collections of balls. The number, location, and size of the balls are determined adaptively through consideration of dominating sets for class cover catch digraphs based on proximity between training observations. Performance comparisons are presented on synthetic and real examples versus k-nearest neighbors, Fisher's linear discriminant and support vector machines. We demonstrate that the proposed semiparametric classifier has performance approaching that of the optimal parametric classifier in cases for which the optimal is available for comparison.	Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA; USN, Ctr Surface Warfare, Dahlgren, VA 22448 USA; Ctr Comp Sci, Bowie, MD 20715 USA; Equinox Corp, Baltimore, MD 21202 USA	Priebe, CE (reprint author), Johns Hopkins Univ, Dept Math Sci, Baltimore, MD 21218 USA.		Priebe, Carey E./A-3305-2010				ARORA S, 1997, HARDNESS APPROXIMATI; Chvatal V., 1979, Mathematics of Operations Research, V4, DOI 10.1287/moor.4.3.233; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASRATHY BV, 2000, P 15 INT C PATT REC, V2, P692; DeVinney J, 2003, THESIS J HOPKINS U B; DEVINNEY JG, 2002, IN PRESS COMPUTING S, P24; DEVINNEY JG, 2001, UNPUB CLASS COVER CA; Devroye L, 1996, PROBABILISTIC THEORY; Duda R. O., 2001, PATTERN CLASSIFICATI; FRIEDMAN JH, 1996, UNPUB ANOTHER APPROA; Hartigan J., 1975, CLUSTERING ALGORITHM; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hastie T, 1998, ANN STAT, V26, P451; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Jain A. K., 1996, IEEE COMPUTER    MAR, P31; Joachims T., 1999, ADV KERNEL METHODS S; Karonski M, 1999, COMB PROBAB COMPUT, V8, P131, DOI 10.1017/S0963548398003459; Karp Richard, 1972, REDUCIBILITY COMBINA; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Lebourgeois F., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547426; Maa JF, 1996, ANN STAT, V24, P1069; MAEHARA H, 1984, J GRAPH THEOR, V8, P431, DOI 10.1002/jgt.3190080312; Marchette DJ, 2003, PATTERN RECOGN, V36, P45, DOI 10.1016/S0031-3203(02)00042-0; OLSON T, 2001, IN PRESS MATH PROGRA; PAREKH AK, 1991, INFORM PROCESS LETT, V39, P237, DOI 10.1016/0020-0190(91)90021-9; PRIEBE CE, 1999, CISST 99, P397; Priebe CE, 2001, STAT PROBABIL LETT, V55, P239, DOI 10.1016/S0167-7152(01)00129-8; Priebe CE, 2001, COMPUT STAT DATA AN, V35, P475, DOI 10.1016/S0167-9473(00)00017-7; SCHOLKOPF B, 2001, NEURAL COMPUT, V13, P7; Skalak D. B., 1997, THESIS U MASSACHUSET; SMITH DL, 1995, P SOC PHOTO-OPT INS, V2496, P404, DOI 10.1117/12.211337; SOCOLINSKY DA, 2003, 634 J HOPK U DEP MAT; Vapnik V.N., 1995, NATURE STAT LEARNING; WITHERSPOON NH, 1995, P SOC PHOTO-OPT INS, V2496, P500, DOI 10.1117/12.211346	34	19	20	SPRINGER-VERLAG	NEW YORK	175 FIFTH AVE, NEW YORK, NY 10010 USA	0176-4268		J CLASSIF	J. Classif.		2003	20	1					3	23		10.1007/s00357-003-0003-7		21	Mathematics, Interdisciplinary Applications; Psychology, Mathematical	Mathematics; Psychology	680KG	WOS:000182976000001	
S	Haykin, S		Ablameyko, S; Gori, M; Goras, L; Piuri, V		Haykin, S			Impact of neural networks on signal processing and communications	LIMITATIONS AND FUTURE TRENDS IN NEURAL COMPUTATION	NATO SCIENCE SERIES, SUB-SERIES III: COMPUTER AND SYSTEMS SCIENCES		English	Proceedings Paper	NATO Advanced Research Workshop on Limitations and Future Trends in Neural Computation	OCT 22-24, 2001	Siena, ITALY	NATO			PATTERN-CLASSIFICATION; SYSTEMS	Signal-processing and communication environments are characterized by two common characteristics: nonstationarity and non-Gaussianity, which make adaptive and learning systems a natural tool for dealing with these environments. In this chapter, we first discuss performance ingredients that are basic to the operation of adaptive and learning systems This discussion sets the stage for the following topics: Linear adaptive filters configured around a single computational unit. Autoregressive models for data parameterization and spectral analysis. Target tracking in an environment dominated by clutter (e.g., radar backscatter from an ocean environment) Learning the dynamics of a nonstationary environment, with particular emphasis given to recurrent multilayer perceptrons and related open research problems.	McMaster Univ, Hamilton, ON, Canada	Haykin, S (reprint author), McMaster Univ, Hamilton, ON, Canada.						ABUMOSTAFA YS, 1995, NEURAL COMPUT, V7, P639, DOI 10.1162/neco.1995.7.4.639; ALEXANDER ST, 1993, IEEE T SIGNAL PROCES, V41, P20, DOI 10.1109/TSP.1993.193124; BELLINI S, 1994, BLIND DECONVOLUTION, pCH2; Benesty J., 2001, ADV NETWORK ACOUSTIC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FELDKAMP LA, 2001, INT JOINT C NEUR NET; FELDKAMP LA, 2001, P 11 YAL WORKSH AD L, P78; Hassibi B, 2001, IEEE T AUTOMAT CONTR, V46, P309, DOI 10.1109/9.905700; Hassibi B, 1996, IEEE T SIGNAL PROCES, V44, P267, DOI 10.1109/78.485923; Haykin S, 1998, P IEEE, V86, P2325, DOI 10.1109/5.726792; HAYKIN S, UNPUB P IEEE; HAYKIN S, 1999, NEURAL NETWORKS COMP; Haykin S., 2001, ADAPTIVE FILTER THEO; Haykin S, 2001, IEEE SIGNAL PROC MAG, V18, P6, DOI 10.1109/MSP.2001.939832; Huber P. J., 1981, ROBUST STAT; JULIER SJ, 1997, 11 S AER DEF SENS SI; Kay S. M., 1988, MODERN SPECTRAL ESTI; KELLER JB, 1976, AM MATH MON, V83, P107, DOI 10.2307/2976988; KIRSCH A, 1996, INTRO MATH THEORY IN; Kohenen T., 1997, SELF ORG MAPS; Lanczos C., 1964, LINEAR DIFFERENTIAL; LO JT, 2001, ADAPTIVE VS ACCOMMOD, P1279; LUCKY RW, 1966, AT&T TECH J, V45, P255; NORGARD M, 2000, ADV DERIVATIVE FREE; PATEL G, 2001, KALMAN FILTERING NEU, pCH3; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Pristley M., 1981, SPECTRAL ANAL TIME S; PUSKORIUS GV, 1994, IEEE T NEURAL NETWOR, V5, P279, DOI 10.1109/72.279191; Schlogl A, 2000, ELECTROENCEPHALOGRAM; SONTAG ED, 1996, RECURRENT NEURAL NET; Tikhonov A. N., 1977, SOLUTIONS ILL POSED; Wan E.A., 2001, KALMAN FILTERING NEU; Widrow B., 1960, IRE WESCON CONV RE 4, P96; Williams R. J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.270	35	0	0	I O S PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1387-6694	1-58603-324-7	NATO SC S SS III C S			2003	186						95	114				20	Computer Science, Artificial Intelligence	Computer Science	BY84E	WOS:000189476100005	
S	Sebban, M; Suchier, HM		Lavrac, N; Gamberger, D; Blockeel, H; Todorovski, L		Sebban, M; Suchier, HM			On boosting improvement: Error reduction and convergence speed-up	MACHINE LEARNING: ECML 2003	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Article; Proceedings Paper	14th European Conference on Machine Learning	SEP 22-26, 2003	CAVTAT, CROATIA	Croatian Minist Sci & Technol, Slovenian Minist Educ, Sci & Sports, Knowledge Discovery Network Excellence			ALGORITHM; MAJORITY	Boosting is not only the most efficient ensemble learning method in practice, but also the one based on the most robust theoretical properties. The adaptive update of the sample distribution, which tends to increase the weight of the misclassified examples, allows to improve the performance of any learning algorithm. However, its ability to avoid overfitting has been challenged when boosting is applied to noisy data. This situation is frequent with the modern databases, built thanks to new data acquisition technologies, such as the Web. The convergence speed of boosting is also penalized on such databases, where there is a large overlap of probability density functions of the classes to learn (large Bayesian error). In this article, we propose a slight modification of the weight update rule of the algorithm ADABOOST. We show that by exploiting an adaptive measure of a local entropy, computed from a neighborhood graph built on the examples, it is possible to identify not only the outliers but also the examples located in the Bayesian error region. Taking into account this information, we correct the weight of the examples to improve the boosting performances. A broad experimental study shows the interest of our new algorithm, called iADABOOST.	Univ St Etienne, EURISE, F-42023 St Etienne 2, France	Sebban, M (reprint author), Univ St Etienne, EURISE, 23 Rue Dr Paul Michelon, F-42023 St Etienne 2, France.						Breiman L, 1984, CLASSIFICATION REGRE; Breiman L, 1996, 460 U CAL DEP STAT; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIETTERICH TG, 1999, MACH LEARN, P1; DOMINGO C, 2000, 3 ANN C COMP LEARN T, P180; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Freund Y., 1996, 13 INT C MACH LEARN, P148; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Friedman J, 1998, ADDITIVE LOGISTIC RE; KWEK S, 2002, 13 EUR C MACH LEARN, P245; MACLIN R, 1998, AAAI IAAI, P700; Merz C.J., UCI REPOSITORY MACHI; Nock R, 2001, PATTERN RECOGN LETT, V22, P413, DOI 10.1016/S0167-8655(00)00137-9; NOCK R, 2002, 13 EUR C MACH LEARN; PREPARATA F, 1985, PATTERN RECOGNITION; RATSCH G, 1998, C NIPS; Schapire R. E., 1990, MACHINE LEARNING; Schapire RE, 1998, ANN STAT, V26, P1651; SCHAPIRE RE, 1998, 11 ANN C COMP LEARN, P80; SEBBAN M, 2003, J MACHINE LEARNING R; WILSON D, 1998, MACHINE LEARNING	23	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-20121-1	LECT NOTES ARTIF INT			2003	2837						349	360				12	Computer Science, Artificial Intelligence	Computer Science	BX96X	WOS:000187061900032	
B	Mill, J; Inoue, A		Walker, EL		Mill, J; Inoue, A			An application of fuzzy support vectors	NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS			English	Proceedings Paper	22nd International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS)	JUL 24-26, 2003	CHICAGO, IL	IEEE Syst, Man & Cybernet Soc, IEEE, N Amer Fuzzy Informat Proc Soc				Support Vector Machines (SVMs) are a recently introduced Machine Learning technique. SVMs approach binary classification by attempting to find a hyperplane that separates the two categories of training vectors. This hyperplane is expressed as a function of a subset of the training vectors. These vectors are called support vectors. In this paper, we present a method of fuzzifying support vectors based off of the results of an SVM induction. We then propose a method of enhancing SVM induction using these fuzzy support vectors. We finish by presenting a computational example using the IRIS data set.	Spokane Falls Community Coll, Spokane, WA 99224 USA	Mill, J (reprint author), Spokane Falls Community Coll, Spokane, WA 99224 USA.						ABE S, 2001, UNPUB SUPPORT VECTOR; Blake CL, 1998, UCI REPOSITORY MACHI; Christianini N., 2000, INTRO SUPPORT VECTOR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Joachims T., 1999, ADV KERNEL METHODS S; Joachims T., 1998, P EUR C MACH LEARN E; JOACHIMS T, 2001, P INT C MACH LEARN; Klir G.J., 1995, FUZZY SETS FUZZY LOG; MILL J, 2002, THESIS E WASHINGTON; MILLER P, 2003, MIDW C ART INT COGN; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V.N., 1995, NATURE STAT LEARNING	12	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7918-7				2003							302	306				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX38N	WOS:000185095000055	
B	Bian, HY; Mazlack, L		Walker, EL		Bian, HY; Mazlack, L			Fuzzy-rough nearest-neighbor classification approach	NAFIPS'2003: 22ND INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS PROCEEDINGS			English	Proceedings Paper	22nd International Conference of the North-American-Fuzzy-Information-Processing-Society (NAFIPS)	JUL 24-26, 2003	CHICAGO, IL	IEEE Syst, Man & Cybernet Soc, IEEE, N Amer Fuzzy Informat Proc Soc			PREDICTION	This paper proposes a new fuzzy-rough nearest-neighbor (NN1) approach based on the fuzzy-rough sets theory. This approach is more suitable to be used under partially exposed and unbalanced data set compared with crisp NN and fuzzy NN approach. Then the new method is applied to China listed company financial distress prediction, a typical classification task under partially exposed and unbalanced learning space. Results suggest that the compared with crisp and fuzzy nearest neighbor classification methods, this method provides more accurate prediction result under this research design.	Univ Cincinnati, ECECS Dept, Appl AI Lab, Cincinnati, OH 45221 USA	Bian, HY (reprint author), Univ Cincinnati, ECECS Dept, Appl AI Lab, Cincinnati, OH 45221 USA.						Altman E.I., 1993, CORPORATE FINANCIAL; Bezdek J., 1981, PATTERN RECOGNITION; Bian H. Y, 2002, P IASTED INT S ART I, P160; BIAN HY, 2002, THESIS CITY U HONG K; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dimitras AI, 1996, EUR J OPER RES, V90, P487, DOI 10.1016/0377-2217(95)00070-4; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Duda R., 1973, PATTERN CLASSIFICATI; ESTES WK, 1994, CLASSIFICATION COGNI, V22; Keasey K., 1991, BRIT J MANAGE, V2, P89, DOI 10.1111/j.1467-8551.1991.tb00019.x; Keller J. M., 1985, IEEE T SYSTEMS MAN C, V15; Lin FY, 2001, KNOWL-BASED SYST, V14, P189, DOI 10.1016/S0950-7051(01)00096-X; Mitchell HB, 2001, INT J INTELL SYST, V16, P459, DOI 10.1002/int.1018; Murphy P. M., UCI REPOSITORY MACHI	14	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7918-7				2003							500	505				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BX38N	WOS:000185095000089	
S	Jankowski, N		Rutkowski, L; Kacprzyk, J		Jankowski, N			Discrete quasi-gradient features weighting algorithm	NEURAL NETWORKS AND SOFT COMPUTING	ADVANCES IN SOFT COMPUTING		English	Proceedings Paper	6th International Conference on Neural Networks and Soft Computing	JUN 11-15, 2002	ZAKOPANE, POLAND	Polish Neural Network Soc				A new method of feature weighting, useful also for feature extraction has been described. It is quite efficient and gives quite accurate results. Weighting algorithm may be used with any kind of learning algorithm. The weighting algorithm with k-nearest neighbors model was used to estimate the best feature base for a given distance measure. Results obtained with this algorithm clearly show its superior performance in several benchmark tests.	Nicholas Copernicus Univ, Dept Informat, PL-87100 Torun, Poland	Jankowski, N (reprint author), Nicholas Copernicus Univ, Dept Informat, Ul Grudziadska 5, PL-87100 Torun, Poland.						Almuallim H., 1992, Proceedings of the Ninth Biennial Conference of the Canadian Society for Computational Studies of Intelligence; Bishop C. M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASH M, 1997, INTELLIGENT DATA ANA, V1; Duch W., 1999, INT JOINT C NEUR NET, P742; DUCH W, 1998, NEURAL PROCESS LETT, V7, P1; DUDA RO, 1997, PATTER CLASSIFICATIO; FERNANDEZ M, 1999, 5 INT WORK C ART NAT, P477; Grabczewski K., 2000, NEURAL NETWORKS SOFT, P202; JANKOWSKI N, 1999, THESIS NICHOLAS COPE; Merz C.J., 1998, UCI REPOSITORY MACHI; Schiffmann W., 1993, P EUR S ART NEUR NET, P97; WEISS SM, 1990, READINGS MACHINE; WILSON DR, 1997, THESIS DEPT COMPUTER; WILSON DR, 1996, INT C ART INT EXP SY, P11; ZARNDT F, 1995, THESIS DEPT COMPUTER	16	0	0	PHYSICA-VERLAG GMBH & CO	HEIDELBERG	TIERGARTENSTR 17, D-69121 HEIDELBERG, GERMANY	1615-3871	3-7908-0005-8	ADV SOFT COMP			2003							194	199				6	Computer Science, Artificial Intelligence	Computer Science	BW57F	WOS:000182433900026	
J	Chater, N; Oaksford, M; Nakisa, R; Redington, M				Chater, N; Oaksford, M; Nakisa, R; Redington, M			Fast, frugal, and rational: How rational norms explain behavior	ORGANIZATIONAL BEHAVIOR AND HUMAN DECISION PROCESSES			English	Review							TRACE MEMORY MODEL; DECISION-MAKING; NONCOMPENSATORY MODELS; COGNITIVE ARCHITECTURE; INDIVIDUAL-DIFFERENCES; WORD RECOGNITION; SYMBOLIC MODEL; INFORMATION; EXPECTATIONS; LIKELIHOOD	Much research on judgment and decision making has focussed on the adequacy of classical rationality as a description of human reasoning. But more recently it has been argued that classical rationality should also be rejected even as normative standards for human reasoning. For example, Gigerenzer and Goldstein (1996) and Gigerenzer and Todd (1999a) argue that reasoning involves "fast and frugal" algorithms which are not justified by rational norms, but which succeed in the environment. They provide three lines of argument for this view, based on: (A) the importance of the environment; (B) the existence of cognitive limitations; and (C) the fact that an algorithm with no apparent rational basis, Take-the-Best, succeeds in an judgment task (judging which of two cities is the larger; based on lists of features of each city). We reconsider (A)-(C), arguing that standard patterns of explanation in psychology and the social and biological sciences, use rational norms to explain why simple cognitive algorithms can succeed. We also present new computer simulations that compare Take-the-Best with other cognitive models (which use connectionist, exemplar-based, and decision-tree algorithms). Although Take-the-Best still performs well, it does not perform noticeably better than the other models. We conclude that these results provide no strong reason to prefer Take-the-Best over alternative cognitive models. (C) 2003 Elsevier Science (USA). All rights reserved.	Univ Warwick, Dept Psychol, Coventry CV4 7AL, W Midlands, England; Cardiff Univ, Sch Psychol, Cardiff CF1 3YG, S Glam, Wales; Univ Oxford, Dept Expt Psychol, Oxford OX1 3UD, England	Chater, N (reprint author), Univ Warwick, Dept Psychol, Coventry CV4 7AL, W Midlands, England.	nick.chater@warwick.ac.uk					AKERLOF GA, 1985, AM ECON REV, V75, P708; Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; Anderson J., 1983, ARCHITECTURE COGNITI; Anderson J. R., 1990, ADAPTIVE CHARACTER T; ANDERSON JR, 1991, PSYCHOL SCI, V2, P396, DOI 10.1111/j.1467-9280.1991.tb00174.x; ANDERSON JR, 1991, BEHAV BRAIN SCI, V14, P471; ANDERSON JR, 1989, PSYCHOL REV, V96, P703, DOI 10.1037/0033-295X.96.4.703; ANDERSON NH, 1981, FDN INFORMATION INTE; ANSCOMBE FJ, 1963, ANN MATH STAT, V34, P199, DOI 10.1214/aoms/1177704255; ARROW KJ, 1996, RATIONAL FDN EC BEHA; ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021; Ayton P, 1997, CAH PSYCHOL COGN, V16, P39; Ayton P, 2000, BEHAV BRAIN SCI, V23, P666, DOI 10.1017/S0140525X00233438; Barkow J. H., 1992, ADAPTED MIND EVOLUTI; Berger J. O., 1995, STAT DECISION THEORY; BERNADO JM, 1995, BAYESIAN THEORY; BRAINE MDS, 1978, PSYCHOL REV, V85, P1, DOI 10.1037//0033-295X.85.1.1; Broder A, 2000, J EXP PSYCHOL LEARN, V26, P1332, DOI 10.1037/0278-7393.26.5.1332; Brown GDA, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P121; BRUNNER D, 1992, ANIM BEHAV, V44, P597, DOI 10.1016/S0003-3472(05)80289-1; BRUNSWICK E, 1934, WAHRNEHMUNG GEGENSTA; BULLINARIA JA, 1994, PROCEEDINGS OF THE SIXTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P84; CHATER N, 1995, CONNECTIONIST MODELS, P207; Chater N, 2000, SYNTHESE, V122, P93, DOI 10.1023/A:1005272027245; Chater N, 1996, PSYCHOL REV, V103, P566, DOI 10.1037//0033-295X.103.3.566; CHATER N, 1990, COGNITION, V34, P93, DOI 10.1016/0010-0277(90)90033-G; Cheng PW, 1997, PSYCHOL REV, V104, P367, DOI 10.1037//0033-295X.104.2.367; Cherniak C., 1986, MINIMAL RATIONALITY; Chew S., 1983, ECONOMETRICA, V51, P1065; Chomsky N., 1980, RULES REPRESENTATION; Christiansen M. H., 1999, COGNITIVE SCI, V23; Christiansen M.H., 2001, CONNECTIONIST PSYCHO; COHEN LJ, 1981, BEHAV BRAIN SCI, V4, P317; Colman A. M., 1995, GAME THEORY ITS APPL; COLTHEART M, 1993, PSYCHOL REV, V100, P589, DOI 10.1037//0033-295X.100.4.589; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAWFORD CB, 1987, SOCIOBIOLOGY PSYCHOL; CYERT RM, 1974, J POLIT ECON, V82, P521, DOI 10.1086/260210; Czerlinski J, 1999, SIMPLE HEURISTICS MA, P97; Davidson D., 1984, INQUIRIES TRUTH INTE; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; DECANIO SJ, 1979, Q J ECON, V93, P47, DOI 10.2307/1882597; DHAMI MK, 2002, THINK REASONING, V7, P5; Dhami MK, 2001, J BEHAV DECIS MAKING, V14, P141, DOI 10.1002/bdm.371; Dougherty MRP, 1999, PSYCHOL REV, V106, P180, DOI 10.1037/0033-295X.106.1.180; DUDA RO, 1973, PATTERNS CLASSIFICAT; EINHORN HJ, 1975, ORGAN BEHAV HUM PERF, V13, P171, DOI 10.1016/0030-5073(75)90044-6; EINHORN HJ, 1970, PSYCHOL BULL, V73, P221, DOI 10.1037/h0028695; EINHORN HJ, 1971, ORGAN BEHAV HUM PERF, V6, P1, DOI 10.1016/0030-5073(71)90002-X; ELLSBERG D, 1961, Q J ECON, V75, P643, DOI 10.2307/1884324; Elster Jon, 1986, RATIONAL CHOICE; Evans J. S. B. T., 1996, RATIONALITY REASONIN; Evans J. St. B. T., 1993, HUMAN REASONING; Evans JSBT, 1989, BIAS HUMAN REASONING; EVANS JST, 1997, CAHIERS PSYCHOL COGN, V16, P1; FISHBURN PC, 1983, J ECON THEORY, V31, P293, DOI 10.1016/0022-0531(83)90079-0; FLOOD MM, 1958, MANAGE SCI, V5, P5, DOI 10.1287/mnsc.5.1.5; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Frey B., 1998, GRAPHICAL MODELS MAC; Friedman M., 1953, METHODOLOGY POSITIVE; Friedman N., 1996, P 12 C UNC ART INT, P252; Gallistel C. R., 1990, ORG LEARNING; GANZACH Y, 1995, PSYCHOL BULL, V118, P422, DOI 10.1037//0033-2909.118.3.422; Garey M.R., 1979, COMPUTERS INTRACTABI; Gibson J. J., 1979, ECOLOGICAL APPROACH; Gigerenzer G, 2001, DAHL WS ENV, P1; Gigerenzer G., 2000, ADAPTIVE THINKING RA; Gigerenzer G., 1987, COGNITION INTUITIVE; GIGERENZER G, 1988, J EXP PSYCHOL HUMAN, V14, P513, DOI 10.1037/0096-1523.14.3.513; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P75; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P3; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037//0033-295X.102.4.684; Gigerenzer G, 2001, DAHL WS ENV, P37; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037//0033-295X.103.4.650; Goldstein D. G., 1999, SIMPLE HEURISTICS MA, P37; GOOD IJ, 1971, FDN STAT INFERENCE; Hahn U, 1998, COGNITION, V65, P197, DOI 10.1016/S0010-0277(97)00044-9; HAMMOND KR, 1965, PSYCHOL REV, V72, P215, DOI 10.1037/h0021798; Harsanyi John C., 1988, GEN THEORY EQUILIBRI; Hertwig R, 2000, BEHAV BRAIN SCI, V23, P678, DOI 10.1017/S0140525X00363439; HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0; HINTZMAN DL, 1984, BEHAV RES METH INS C, V16, P96; HINTZMAN DL, 1988, PSYCHOL REV, V95, P528, DOI 10.1037/0033-295X.95.4.528; HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037//0033-295X.93.4.411; Inhelder B, 1958, GROWTH LOGICAL THINK; INTRATOR N, 1993, ADV NEURAL INFORMATI, V5, P3; Jeannerod M, 1988, NEURAL BEHAV ORG GOA; JOHNSON E. J., 1990, INSIGHTS DECISION MA, P129; JUSLIN P, 2001, UNPUB PROBABILITIES; KACELNIK A, 1998, RATIONAL MODELS COGN, P54; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Kahneman D., 1982, JUDGMENT UNCERTAINTY; Kolodner J., 1993, CASE BASED REASONING; Kreps DM, 1990, COURSE MICROECONOMIC; Kripke S., 1982, WITTGENSTEIN RULES P; LEEUWENBERG E, 1988, PSYCHOL REV, V95, P485, DOI 10.1037//0033-295X.95.4.485; LIBBY R, 1976, ORGAN BEHAV HUM PERF, V16, P1, DOI 10.1016/0030-5073(76)90002-7; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; LING CX, 1993, COGNITION, V49, P235, DOI 10.1016/0010-0277(93)90006-H; LING CX, 1994, COGNITIVE SCI, V18, P595, DOI 10.1207/s15516709cog1804_3; Loewenstein G., 1992, CHOICE TIME, P3; LOOMES G, 1982, ECON J, V92, P805, DOI 10.2307/2232669; MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037//0033-295X.101.4.676; MACHINA MJ, 1982, ECONOMETRICA, V39, P277; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MACLEOD P, 1998, INTRO CONNECTIONIST; Marr D., 1982, VISION; Martignon L., 1999, SIMPLE HEURISTICS MA, P119; Martignon L., 1999, SIMPLE HEURISTICS MA, P169; Massaro D. W., 1987, SPEECH PERCEPTION EA; May KO, 1954, ECONOMETRICA, V22, P1, DOI 10.2307/1909827; Maynard Smith J., 1973, Nature London, V246, P15; McClelland J. L., 1998, RATIONAL MODELS COGN, P21; McCloskey D. N., 1985, RHETORIC EC; McDermott D., 1987, Computational Intelligence, V3, DOI 10.1111/j.1467-8640.1987.tb00183.x; McFarland D, 1981, QUANTITATIVE ETHOLOG; Meehl P. E., 1954, CLIN VERSUS STAT PRE; MESSICK DM, 1991, GAME EQUILIBRIUM MOD, V1, P304; Minsky M., 1969, PERCEPTRONS INTRO CO; Morgenstern O., 1944, THEORY GAMES EC BEHA; MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366; Movellan JR, 1996, PROCEEDINGS OF THE EIGHTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P381; MOVELLAN JR, 1995, PDPCNS954 CARN MELL; MUTH JF, 1961, ECONOMETRICA, V29, P315, DOI 10.2307/1909635; Nash JF, 1950, ECONOMETRICA, V18, P155, DOI 10.2307/1907266; NEAL RM, 1993, ADV NEURAL INFORMATI, V5, P475; Nelson RR, 1982, EVOLUTIONARY THEORY; Newell A., 1991, UNIFIED THEORIES COG; NEWELL A, 1982, ARTIF INTELL, V18, P87, DOI 10.1016/0004-3702(82)90012-1; NEWELL BR, 2001, UNPUB TAKE BEST LOOK; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A; Oaksford M., 1998, RATIONALITY UNCERTAI; Oaksford M., 1990, AI & Society, V4, DOI 10.1007/BF01889765; OAKSFORD M, 1994, PSYCHOL REV, V101, P608, DOI 10.1037//0033-295X.101.4.608; Oaksford M., 1998, RATIONAL MODELS COGN; Oaksford M., 1995, Thinking & Reasoning, V1, DOI 10.1080/13546789508251501; Oaksford M., 1993, RATIONALITY, P31; Oaksford M., 1991, Mind and Language, V6, DOI 10.1111/j.1468-0017.1991.tb00173.x; PARIS J, 1992, UNCERTAIN REASONERS; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Payne J. W., 1993, ADAPTIVE DECISION MA; PAYNE JW, 1976, ORGAN BEHAV HUM PERF, V16, P366, DOI 10.1016/0030-5073(76)90022-2; PAYNE JW, 1988, J EXP PSYCHOL LEARN, V14, P534, DOI 10.1037//0278-7393.14.3.534; Payne JW, 1996, ORGAN BEHAV HUM DEC, V66, P131, DOI 10.1006/obhd.1996.0044; Pearl J., 1988, PROBABILISTIC REASON, p[505, 506, 507, 524]; PERSSON M, 1999, UNPUB ECOLOGICAL RAT; Pinker S., 1998, MIND WORKS; Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56; POMERANTZ JR, 1987, HDB PERCEPTION HUMAN, V2; Pylyshyn Z., 1987, ROBOTS DILEMMA FRAME; Quine W. V. O., 1960, WORD OBJECT; Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN; REINER R, 1995, MIND MACH, V5, P373, DOI 10.1007/BF00974751; Rescorla R. A., 1972, CLASSICAL CONDITION, P64, DOI DOI 10.1016/J.COGPSYCH.2004.11.001; Rieskamp J., 1999, SIMPLE HEURISTICS MA, P141; Rips L. J., 1994, PSYCHOL PROOF; Roth A., 1995, HDB EXPT EC, P111; Roth AE, 1996, RATIONAL FOUNDATIONS OF ECONOMIC BEHAVIOUR, P198; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, VII; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Samuelson P. A., 1937, REV ECON STUD, V4, P155, DOI 10.2307/2967612; Savage L., 1954, FDN STAT; SAWYER J, 1966, PSYCHOL BULL, V66, P178, DOI 10.1037/h0023624; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Shanks D., 1995, PSYCHOL ASS LEARNING; SHANKS DR, 1995, Q J EXP PSYCHOL-A, V48, P257; SHEPARD RN, 1967, DECISION MAKING, P257; SIMON HA, 1959, AM ECON REV, V49, P253; Simon Herbert, 1992, EC BOUNDED RATIONALI; Stanovich K. E., 1998, THINK REASONING, V4, P193; Stanovich K. E., 1998, THINK REASONING, V4, P289, DOI 10.1080/135467898394094; Stanovich KE, 2000, BEHAV BRAIN SCI, V23, P645, DOI 10.1017/S0140525X00003435; Stanovich KE, 1998, J EXP PSYCHOL GEN, V127, P161, DOI 10.1037/0096-3445.127.2.161; STANOVICH KE, 1999, WHO RATIONAL STUDIES; Stein E., 1996, GOOD REASON RATIONAL; Stephens D., 1986, FORAGING THEORY; STICK SP, 1990, FRAGMENTATION REASON; TARABAN R, 1988, J MEM LANG, V27, P597, DOI 10.1016/0749-596X(88)90011-3; TODD IA, 1993, ANIM BEHAV, V46, P765, DOI 10.1006/anbe.1993.1254; Todd P., 1999, SIMPLE HEURISTICS MA, P357; Tversky A., 1986, J BUS, V59, P251; TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955; TVERSKY A, 1969, PSYCHOL REV, V76, P31, DOI 10.1037/h0026750; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; van Damme E., 1991, STABILITY PERFECTION; vanderHelm PA, 1996, PSYCHOL REV, V103, P429, DOI 10.1037/0033-295X.103.3.429; VANS JST, 1982, PSYCHOL DEDUCTIVE RE; von Helmholtz H., 1910, TREATISE PHYSL OPTIC, V3; WEBER EU, 1995, PSYCHOL LEARN MOTIV, V32, P33, DOI 10.1016/S0079-7421(08)60307-2	193	52	52	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0749-5978		ORGAN BEHAV HUM DEC	Organ. Behav. Hum. Decis. Process.	JAN	2003	90	1					63	86		10.1016/S0749-5978(02)00508-3		24	Psychology, Applied; Management; Psychology, Social	Psychology; Business & Economics	668UU	WOS:000182312200005	
J	Bagui, SC; Bagui, S; Pal, K; Pal, NR				Bagui, SC; Bagui, S; Pal, K; Pal, NR			Breast cancer detection using rank nearest neighbor classification rules	PATTERN RECOGNITION			English	Article						classification rules; rank nearest neighbor rules; nearest neighbor rules; breast masses; breast cancer detection; cell nucleus; mean texture; worst mean area; error rate; Bayes error rate	NUCLEAR FEATURES; DIAGNOSIS; CYTOLOGY	In this article, we propose a new generalization of the rank nearest neighbor (RNN) rule for multivariate data for diagnosis of breast cancer. We study the performance of this rule using two well known databases and compare the results with the conventional k-NN rule. We observe that this rule performed remarkably well, and the computational complexity of the proposed k-RNN is much less than the conventional k-NN rule. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	Indian Stat Inst, Elect & Commun Sci Unit, Calcutta 700035, W Bengal, India; Univ W Florida, Dept Math & Stat, Pensacola, FL 32514 USA; Univ W Florida, Dept Comp Sci, Pensacola, FL 32514 USA	Pal, NR (reprint author), Indian Stat Inst, Elect & Commun Sci Unit, 203 BT Rd, Calcutta 700035, W Bengal, India.						ANDERSON TW, 1966, P 1 INT S AN; BAGUI SC, 1995, PATTERN RECOGN LETT, V16, P601, DOI 10.1016/0167-8655(95)80006-F; BAGUI SC, 1998, STATIST, V16, P181; Bennett K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cramer H., 1946, MATH METHODS STAT; DASGUPTA S, 1980, SANKHYA A, V42, P219; DENGLER J, 1993, IEEE T MED IMAGING, V12, P634, DOI 10.1109/42.251111; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; Fix E, 1951, 4 US AIR FORC SCH AV; Johnson R.A., 1998, APPL MULTIVARIATE ST; KARSSEMEIJER N, 1998, DIGITAL MAMOGRAPHY; Mangasarian O. L., 1990, SIAM NEWS, V23; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; RANDLES RH, 1978, J AM STAT ASSOC, V73, P379, DOI 10.2307/2286669; SHEN L, 1994, IEEE T MED IMAGING, V13, P263; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Street W., 1993, IS T SPIE 1993 INT S, P861; WOLBERG WH, 1994, CANCER LETT, V77, P163, DOI 10.1016/0304-3835(94)90099-X; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; WOLBERG WH, 1995, HUM PATHOL, V26, P792, DOI 10.1016/0046-8177(95)90229-5; Zhang J., 1992, P 9 INT MACH LEARN C, P470	22	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203		PATTERN RECOGN	Pattern Recognit.	JAN	2003	36	1					25	34		10.1016/S0031-3203(02)00044-4		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	612XP	WOS:000179101000003	
S	Barandela, R; Sanchez, JS; Garcia, V; Ferri, FJ		Perales, FJ		Barandela, R; Sanchez, JS; Garcia, V; Ferri, FJ			Learning from imbalanced sets through resampling and weighting	PATTERN RECOGNITION AND IMAGE ANALYSIS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Article; Proceedings Paper	1st Iberian Conference on Pattern Recognition and Image Analysis	JUN 04-06, 2003	MALLORCA, SPAIN	MCyT, Int Assoc Pattern Recognit, European Union, Conselleria Innovacio Energia	UNIV ILLES BALEARS, DEPT CIENCIES MATH & INFORMAT			The problem of imbalanced training sets in supervised pattern recognition methods is receiving growing attention. Imbalanced training sample means that one class is represented by a large number of examples while the other is represented by only a few. It has been observed that this situation, which arises in several practical situations, may produce an important deterioration of the classification accuracy, in particular with patterns belonging to the less represented classes. In the present paper, we introduce a new approach to design an instance-based classifier in such imbalanced environments.	Inst Tecnol Toluca, Metepec 52140, Mexico; Dept Llenguatges Sistemas Informat, Castello 12071, Spain; Univ Valencia, Dept Informat, E-46100 Burjassot, Spain; Inst Geog, Havana, Cuba	Barandela, R (reprint author), Inst Tecnol Toluca, Av Tecnol SN, Metepec 52140, Mexico.						Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Barandela R., 2001, P 9 SPAN S PATT REC, P103; Chan P. K., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CHAWLA NV, 2000, J ARTIFICIAL INTELLI, V16, P321; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, NEAREST NEIGHBOR NOR; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Eavis T, 2000, LECT NOTES ARTIF INT, V1822, P280; Ezawa K J, 1996, P 13 INT C MACH LEAR, P139; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; FERRI FJ, 1998, LECT NOTES COMPUTER, V1451, P620; Gordon D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00317.x; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Lewis DD, 1994, P 11 INT C MACH LEAR, P148; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Swets J., 2000, SCI AM, P82; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Woods K. S., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, DOI 10.1142/S0218001493000698	24	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743	3-540-40217-9	LECT NOTES COMPUT SC			2003	2652						80	88				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BX28N	WOS:000184832300010	
B	Li, J; Liang, QL; Manry, MT		Gong, K; Niu, ZH		Li, J; Liang, QL; Manry, MT			Adaptive channel equalization for satellite communications with multipath based on unsupervised learning algorithm	PIMRC 2003: 14TH IEEE 2003 INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS PROCEEDINGS, VOLS 1-3 2003			English	Proceedings Paper	14th IEEE International Symposium on Personal, Indoor and Mobile Radio Communications	SEP 07-10, 2003	BEIJING, PEOPLES R CHINA	Chinese Inst Elect, King Coll London, Tsinghua Univ, IEEE Beijing Sect, EiC, IEE, IEEE Commun Soc		equalization; satillite cominmnication; NNC; unsupervised learining; TDMA	INTERFERENCE; NETWORKS	Channel equalization has been revealed to be a classification problem by some recent applications of clustering and neural network techniques. In this paper a new unsupervised learning (clustering) algorithm, adaptive nearest neighbor classifier (ANNC) is presented for channel equalization. ANNC can mine more channel characteristics than the recently proposed nearest neighbor (NNC) classifier. The proposed method is applied to a time-division-multiple-access (TDMA) satellite communication system with burst digital transmission. The improvement of the proposed algorithm over the recently reported NNC approach is clearly demonstrated.	Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA	Li, J (reprint author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.						BENELLI G, 1991, P INT C GLOBECOM 91, P1469; CHEN S, 1993, IEEE T NEURAL NETWOR, V4, P570, DOI 10.1109/72.238312; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVELLA R, 1989, IEEE J SEL AREA COMM, V7, P122, DOI 10.1109/49.16853; Duda R. O., 1999, PATTERN CLASSIFICATI; FORNEY GD, 1972, IEEE T INFORM THEORY, V18, P363, DOI 10.1109/TIT.1972.1054829; Hussain A, 1997, IEEE T COMMUN, V45, P1358, DOI 10.1109/26.649741; JADES WC, 1993, MICROWAVE MOBILE COM; KECHRIOTIS G, 1994, IEEE T NEURAL NETWOR, V5, P267, DOI 10.1109/72.279190; LIANG Q, 2002, IEEE 55 VEH TECHN C, V4, P1869; LIANG Q, 2002, P IEEE GLOB 02 TAIP; Liang QL, 2000, IEEE T FUZZY SYST, V8, P551; SAVAZZI P, 2000, IEEE J SEL AREA COMM, V16, P418; SKLLAR B, 1997, IEEE COMMUN MAG, V35, P148	14	0	0	PUBLISHING HOUSE ELECTRONICS INDUSTRY	BEIJING	PO BOX 173 WANSHOU ROAD, BEIJING 100036, PEOPLES R CHINA		7-5053-5066-8				2003							730	734				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BY28C	WOS:000188739500151	
B	Lisboa, FOSS; Nicoletti, MD; Ramer, A		Nasaoui, O; Frigui, H; Keller, JM		Lisboa, FOSS; Nicoletti, MD; Ramer, A			Experiencing fuzzy exemplar-based classifier systems	PROCEEDINGS OF THE 12TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	12th IEEE International Conference on Fuzzy Systems	MAY 25-28, 2003	ST LOUIS, MO	IEEE, IEEE Neural Networks Soc				The NGE model (implemented by EACH) is an incremental form of inductive learning from examples that generalizes a given training set into hypotheses represented as a set of hyperrectangles in an n-dimensional Euclidean space. The NGE algorithm can be considered a descendent of either NN or KNN algorithms. This paper focuses on a fuzzy version of the NGE algorithm, aiming at comparing its performance with a fuzzy version of the NN algorithm and, of the KNN algorithm.	USP, IFSC, BR-13560970 Sao Carlos, SP, Brazil	Lisboa, FOSS (reprint author), USP, IFSC, BR-13560970 Sao Carlos, SP, Brazil.		Lisboa, Flavia/I-6767-2012				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Klir G.J., 1995, FUZZY SETS FUZZY LOG; KOLODNER J, 1984, RETRIEVAL ORGANIZATI; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Merz C.J., 1998, UCI REPOSITORY MACHI; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALZBERG S, 1991, MACH LEARN, V6, P252; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5	11	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7810-5	IEEE INT CONF FUZZY			2003							90	95				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BW87V	WOS:000183448800016	
B	Auephanwiriyakul, S		Nasaoui, O; Frigui, H; Keller, JM		Auephanwiriyakul, S			A linguistic K-nearest prototype with an application to management surveys	PROCEEDINGS OF THE 12TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2	IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)		English	Proceedings Paper	12th IEEE International Conference on Fuzzy Systems	MAY 25-28, 2003	ST LOUIS, MO	IEEE, IEEE Neural Networks Soc			FUZZY	For many years, one of the, problems in pattern recognition is classification. There are many methods' that deal with this type of problem. The data sets are sometimes in the binary form (real number) and represented by vectors of binary numbers (real numbers) although there are uncertainties in the data, e.g., data collected in management questionnaires. In this paper, we developed a linguistic K-nearest prototype algorithm with vectors of fuzzy numbers as inputs. This algorithm is based on the extension principle and the decomposition theorem. We apply this algorithm to linguistic vectors derived from a set of thirty-nine subjects answering questions about students' satisfaction with communication to their university.	Chiang Mai Univ, Dept Comp Engn, Chiang Mai 50200, Thailand	Auephanwiriyakul, S (reprint author), Chiang Mai Univ, Dept Comp Engn, Chiang Mai 50200, Thailand.						ADRIAN A, 1998, P IEEE INT C SYST MA, P2144; AUEPHANWIRIYAKU.S, 2002, IEEE INT C FUZZ SYST, P1321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dong W., 1985, CIVIL ENG SYSTEMS, V2, P201, DOI 10.1080/02630258508970407; DONG WM, 1987, FUZZY SET SYST, V21, P183, DOI 10.1016/0165-0114(87)90163-1; Dubois D., 1980, FUZZY SETS SYSTEMS T; Duda R., 1973, PATTERN CLASSIFICATI; Gupta M. M., 1979, ADV FUZZY SET THEORY, P153; KALEVA O, 1984, FUZZY SET SYST, V12, P215, DOI 10.1016/0165-0114(84)90069-1; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KELLER JM, 2000, P 9 IEEE INT C FUZZ, P387; Klir G.J., 1995, FUZZY SETS FUZZY LOG; KRAMOSIL I, 1975, KYBERNETIKA, V11, P336; Mare M., 1994, COMPUTATION FUZZY QU; Moore R., 1966, INTERVAL ANAL; Yager R.R., 1978, P CDC, P1435; Zadeh L., 1973, IEEE T SYS MAN CYB, V3	17	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA		0-7803-7810-5	IEEE INT CONF FUZZY			2003							784	788				5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BW87V	WOS:000183448800136	
