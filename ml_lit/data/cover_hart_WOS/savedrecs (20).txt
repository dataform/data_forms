PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	PG	WC	SC	GA	UT	PM
J	Jung, JJ				Jung, Jason J.			Semantic co-browsing system based on contextual synchronization on peer-to-peer environment	COMPUTING AND INFORMATICS			English	Article						context-awareness; focused crawling; peer-to-peer	WEB; CLASSIFICATION; NETWORK	In this paper, we focus on a personalized information retrieval system based on multi-agent platform. Especially, they are capable of sharing information between them, for supporting collaborations between people. Personalization module has to be exploited to be aware of the corresponding user's browsing contexts (e.g., purposes, intention, and goals) at the specific moment. We want to recommend as relevant information to the estimated user context as possible, by analyzing the interaction results (e.g., clickstreams or query results). Thereby, we propose a novel approach to self-organizing agent groups based on contextual synchronization. Synchronization is an important requirement for online collaborations among them. This synchronization method exploits contextual information extracted from a set of personal agents in the same group, for real-time information sharing. Through semantically tracking of the users' information searching behaviors, we model the temporal dynamics of personal and group context. More importantly, in a certain moment, the contextual outliers can be detected, so that the groups can be automatically organized again with the same context. The cobrowsing system embedding our proposed method was shown 52.7% and 11.5% improvements of communication p, erformance, compared to single browsing system and asynchronous collaborative browsing system, respectively.	Yeungnam Univ, Dept Comp Engn, Gyeungsan, South Korea	Jung, JJ (reprint author), Yeungnam Univ, Dept Comp Engn, Gyeungsan, South Korea.	j2jung@intelligent.pe.kr	Jung, Jason J./B-9622-2012	Jung, Jason J./0000-0003-0050-7445			Androutsellis-Theotokis S, 2004, ACM COMPUT SURV, V36, P335, DOI 10.1145/1041680.1041681; BERNERSLEE T, 2001, SEMANTIC WEB SCI AM, V285, P34; BRA PD, 1994, COMPUTER NETWORKS IS, V27, P183; Chakrabarti S, 1999, COMPUT NETW, V31, P1623, DOI 10.1016/S1389-1286(99)00052-3; Chakrabarti S., 2002, P 11 INT WORLD WID W, P148; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dieng R., 1998, P 13 EUR C ART INT E, P341; Euzenat J., 2005, J DATA SEMANTICS, V3730, P146, DOI DOI 10.1007/11603412\-5; EUZENAT J, 1994, P 4 ASIS SIG CR WORK, P69; JUNG JJ, IN PRESS INFORM RETR; Jung JJ, 2005, J UNIVERS COMPUT SCI, V11, P1383; Jung JJ, 2005, J UNIVERS COMPUT SCI, V11, P213; Jung JJ, 2005, IEICE T INF SYST, VE88D, P843, DOI 10.1093/ietisy/e88-d.5.843; Kalfoglou Y, 2003, KNOWL ENG REV, V18, P1, DOI 10.1017/S0269888903000651; Kleinberg J.M., 1999, JACM, V46, P5; Levenshtein V., 1966, CYBERNETICS CONTROL, V10, P707; Madhavan J., 2001, P 27 INT C VER LARG, P48; MENCZER F, 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773; Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875; Papadimitriou S., 2005, P 31 INT C VER LARG, P697; Papadimitriou S, 2004, VLDB J, V13, P222, DOI 10.1007/s00778-004-0130-8; Puttagunta V., 2002, P 2002 INT C MACH LE, P197; Sahami M., 1998, P AAAI 98 WORKSH LEA; Srinivasan P, 2005, INFORM RETRIEVAL, V8, P417, DOI 10.1007/s10791-005-6993-5; Stumme G., 2001, P 17 INT JOINT C ART, P225; Xiao L, 2005, IEEE T PARALL DISTR, V16, P1078; Yang B, 2003, PROC INT CONF DATA, P49; ZHUGE H, 2004, SEMANTICS RESOURCE G, V21, P1; Ziegler CN, 2004, LECT NOTES COMPUT SC, V3291, P840	30	1	1	0	3	SLOVAK ACAD SCIENCES INST INFORMATICS	BRATISLAVA	DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA	1335-9150			COMPUT INFORM	Comput. Inform.		2007	26	5					469	488				20	Computer Science, Artificial Intelligence	Computer Science	238LW	WOS:000251450100002		
S	Elghazel, H; Kheddouci, H; Deslandres, V; Dussauchoy, A		Corruble, V; Takeda, M; Suzuki, E		Elghazel, Haytham; Kheddouci, Hamamache; Deslandres, Veronique; Dussauchoy, Alain			A partially dynamic clustering algorithm for data insertion and removal	Discovery Science, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	10th International Conference on Discovery Science	OCT 01-04, 2007	Sendai, JAPAN	AF Off Sci Res, Asian Off Aerosp Res & Dev, Grad Sch Informat Sci		dynamic clustering; graph b-coloring; dissimilarity; dominance		We consider the problem of dynamic clustering which has been addressed in many contexts and applications including dynamic information retrieval, Web documents classification, etc. The goal is to efficiently maintain homogenous and well-separated clusters as new data are inserted or existing data are removed. We propose a framework called dynamic b-coloring clustering based solely on pairwise dissimilarities among all pairs of data and on cluster dominance. In experiments on benchmark data sets, we show improvements in the performance of clustering solution in terms of quality and computational complexity.	Univ Lyon 1, LIESP Lab, F-69622 Villeurbanne, France	Elghazel, H (reprint author), Univ Lyon 1, LIESP Lab, 43 Bd,11 Novembre 1918, F-69622 Villeurbanne, France.						Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elghazel H, 2006, LECT NOTES ARTIF INT, V4203, P473; Irving RW, 1999, DISCRETE APPL MATH, V91, P127, DOI 10.1016/S0166-218X(98)00146-2; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Kalyani M, 2010, PATTERN RECOGN, V24, P2367	6	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-75487-9	LECT NOTES ARTIF INT			2007	4755						78	90				13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BGU93	WOS:000250717900009		
S	Andra, S; Nagy, G; Liu, CL		Lin, X; Yanikoglu, BA		Andra, Srinivas; Nagy, George; Liu, Cheng-Lin			Frequency coding: An effective method for combining dichotomizers - art. no. 650004	Document Recognition and Retrieval XIV	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	Conference on Document Recognition and Retrieval XIV	JAN 30-FEB 01, 2007	San Jose, CA	Soc Imaging Sci & Technol, SPIE		frequency coding; dichotomizers; nonparametric classification	CLASSIFICATION	Binary classifiers (dichotomizers) are combined for multi-class classification. Each rep-ion formed by the pairwise decision boundaries is assigned to the class with the highest frequency of training samples in that region. With more samples and classifiers, the frequencies converge to increasingly accurate non-parametric estimates of the posterior class probabilities in the vicinity of the decision boundaries. The method is applicable to non-parametric discrete or continuous class distributions dichotomized by either linear or non-linear classifiers (like support vector machines). We present a formal description of the method and place it in context with related methods. We present experimental results on machine-printed and handwritten digits that demonstrate the viability of frequency coding in a classification task.	Rensselaer Polytech Inst, ECSE Dept, DocLab, Troy, NY 12180 USA	Andra, S (reprint author), Rensselaer Polytech Inst, ECSE Dept, DocLab, Troy, NY 12180 USA.						Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; ANDRA S, 2006, THESIS RENSSELAER PO; ANDRA S, 2006, P 18 INT C PATT REC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136; Hastie T, 1998, ANN STAT, V26, P451; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Platt J. C., 2000, ADV LARGE MARGIN CLA; Sarkar P, 2005, IEEE T PATTERN ANAL, V27, P88, DOI 10.1109/TPAMI.2005.18; SAVICKY P, 2003, P 5 INT S INT DAT AN, P219; Vapnik V., 1998, STAT LEARNING THEORY; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wu TF, 2004, J MACH LEARN RES, V5, P975; ZASLAVSKY T, 1975, MEM AM MATH SOC, V1, P154; ZHANG X, 2006, P SPIE, V6067	17	0	0	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-6613-6	P SOC PHOTO-OPT INS			2007	6500						50004	50004	650004	10.1117/12.708803		8	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BGG59	WOS:000246686900003		
S	Angiulli, F; Folino, G		Kermarrec, AM; Bouge, L; Priol, T		Angiulli, Fabrizio; Folino, Gianluigi			Efficient distributed data condensation for nearest neighbor classification	Euro-Par 2007 Parallel Processing, Proceedings	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	13th International Euro-Par Conference on Parallel Processing	AUG 28-31, 2007	Rennes, FRANCE	Int Federat Informat Proc, ACM				In this work, PFCNN, a distributed method for computing a consistent subset of very large data sets for the nearest neighbor decision rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. Experimental results, performed on a class of synthetic datasets revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale-up well and are efficient in memory consumption and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule.	Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.						Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Foster I., 2003, GRID2 BLUEPRINT NEW; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KARACALI B, 2002, IEEE T NEURAL NETWOR, V14, P127; STONE C, 1977, ANN STAT, V8, P1348	8	1	1	0	7	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74465-8	LECT NOTES COMPUT SC			2007	4641						338	347				10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BGS81	WOS:000250368200036		
B	Hu, JN; Deng, WH; Guo, J; Xu, WR		Lei, JS; Yu, J; Zhou, SG		Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran			Learning locality discriminating indexing for text categorization	FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Fuzzy Systems and Knowledge Discovery	AUG 24-27, 2007	Haikou, PEOPLES R CHINA	Hainan Univ, IEEE Reliabil Soc, Asia Pacific Neural Network Assembly				This paper introduces a locality discriminating indexing (LDI) algorithm for text categorization. The LDI algorithm offers a manifold way of discriminant analysis. Based on the hypothesis that samples from different classes reside in class-specific manifold structures, the algorithm depicts the manifold structures by a nearest-native graph and a invader graphs. And a new locality discriminant criterion is proposed, which best preserves the within-class local structures while suppresses the between-class overlap. Using the notion of the Laplacian of the graphs, the LDI algorithm finds the optimal linear transformation by solving the generalized eigenvalue problem. The feasibility of the LDI algorithm has been successfully tested in text categorization using 20NG and Reuters-21578 databases. Experiment results show LDI is an effective technique for document modeling and representations for classification.	[Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China	Hu, JN (reprint author), Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.						Chung F. R. K., 1997, AM MATH SOC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; HE X, 2000, P ACM SIGIR; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283	6	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA							2007							239	242		10.1109/FSKD.2007.383		4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHE44	WOS:000252460600047		
B	Wedge, DC; Kell, DB; Gaskell, SJ; Lau, KW; Hubbard, SJ; Eyers, C			ACM	Wedge, David C.; Kell, Douglas B.; Gaskell, Simon J.; Lau, King Wai; Hubbard, Simon J.; Eyers, Claire			Peptide Detectability following ESI Mass Spectrometry: Prediction using Genetic Programming	GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2			English	Proceedings Paper	Annual Conference of Genetic and Evolutionary Computation Conference	JUL 07-11, 2007	London, ENGLAND	ACM		Genetic Programming; input selection; classification; AUROC; proteomics; mass spectrometry	MULTIPLEXED ABSOLUTE QUANTIFICATION; CONCATENATED SIGNATURE PEPTIDES; PROTEOMICS; PROTEINS	The accurate quantification of proteins is important in several areas of cell biology, biotechnology and medicine. Both relative and absolute quantification of proteins is often determined following mass spectrometric analysis of one or more of their constituent peptides. However, in order for quantification to be successful, it is important that the experimenter knows which peptides are readily detectable under the mass spectrometric conditions used for analysis. In this paper, genetic programming is used to develop a function which predicts the delectability of peptides from their calculated physico-chemical properties. Classification is carried out in two stages: the selection of a good classifier using the AUROC objective function and the setting of an appropriate threshold. This allows the user to select the balance point between conflicting priorities in an intuitive way. The success of this method is found to be highly dependent on the initial selection of input parameters. The use of brood recombination and a modified version of the multi-objective FOCUS method are also investigated. While neither has a significant effect on predictive accuracy, the use of the FOCUS method leads to considerably more compact Solutions.	[Wedge, David C.; Kell, Douglas B.; Gaskell, Simon J.] Univ Manchester, Manchester Interdisciplinary Bioctr, Sch Chem, Manchester M1 7DN, Lancs, England	Wedge, DC (reprint author), Univ Manchester, Manchester Interdisciplinary Bioctr, Sch Chem, 131 Princess St, Manchester M1 7DN, Lancs, England.	david.wedge@manchester.ac.uk; dbk@manchester.ac.uk; Simon.Gaskell@manchester.ac.uk; k.lau@manchester.ac.uk; Simon.Hubbard@manchester.ac.uk; Claire.Eyers@manchester.ac.uk	Hubbard, Simon/B-9006-2009; Kell, Douglas/E-8318-2011; Eyers, Claire/C-6291-2013	Kell, Douglas/0000-0001-5838-7963; Eyers, Claire/0000-0002-3223-5926			Aebersold R, 2003, NATURE, V422, P198, DOI 10.1038/nature01511; Altenberg L, 1994, ADV GENETIC PROGRAMM, P47; Banzhaf W., 1998, GENETIC PROGRAMMING; Beynon RJ, 2005, NAT METHODS, V2, P587, DOI 10.1038/NMETH774; Breiman L., 1984, CLASSIFICATION REGRE; Broadhurst DI, 2006, METABOLOMICS, V2, P171, DOI 10.1007/s11306-006-0037-z; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Jong ED, 2001, P GEN EV COMP C GECC, P11; Eriksson J, 2000, ANAL CHEM, V72, P999, DOI 10.1021/ac990792j; FENN JB, 1989, SCIENCE, V246, P64, DOI 10.1126/science.2675315; Gay S, 2002, PROTEOMICS, V2, P1374, DOI 10.1002/1615-9861(200210)2:10<1374::AID-PROT1374>3.0.CO;2-D; Gerber SA, 2003, P NATL ACAD SCI USA, V100, P6940, DOI 10.1073/pnas.0832254100; Gianazza E, 2003, J NUTR, V133, P9; Langdon W. B., 1998, GENETIC PROGRAMMING; Pratt JM, 2006, NAT PROTOC, V1, P1029, DOI 10.1038/nprot.2006.129; Rifai N, 2006, NAT BIOTECHNOL, V24, P971, DOI 10.1038/nbt1235; Tackett W. A., 1994, THESIS U SO CALIFORN; Tang HX, 2006, BIOINFORMATICS, V22, pE481, DOI 10.1093/bioinformatics/btl237; Vaidyanathan S, 2003, ANAL CHEM, V75, P6679, DOI 10.1021/ac034669a; WESTIN LK, 2001, UNINF0118 UM U	20	6	6	0	1	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-59593-697-4				2007							2219	2225				7	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Computer Science	BKI74	WOS:000268226900397		
S	Aparicio, G; Blanquer, I; Hernandez, V		Dayde, M; Palma, MLM; Coutinho, LGA; Pacitti, E; Lopes, JC		Aparicio, G.; Blanquer, I.; Hernandez, V.			A parallel implementation of the K nearest neighbours classifier in three levels: Threads, MPI processes and the Grid	High Performance Computing for Computational Science - VECPAR 2006	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on High Performance Computing for Computational Science	JUN 10-13, 2006	Rio de Janeiro, BRAZIL	Fac Engn Porto, Petrobras, IBM Brazil, FABMEC, CNPq, FAPERJ, Univ Porto, Fac Engn, Inst Natl Rech Informat, Sillicon Graph, Univ Porto		grid; parallel computing; threads and data mining		The work described in this paper tackles the problem of data mining and classification of large amounts of data using the K nearest neighbours classifier (KNN) [1]. The large computing demand of this process is solved with a parallel computing implementation specially designed to work in Grid environments of multiprocessor computer farms. The different parallel computing approaches (intra-node, inter-node and inter-organisations) are not sufficient by themselves to face the computing demand of such a big problem. Instead of using parallel techniques separately, we propose to combine the three of them considering the parallelism grain of the different parts of the problem. The main purpose is to complete a 1 month-CPU job in a few hours. The technologies that are being used are the EGEE Grid Computing Infrastructure running the Large Hadron Collider Computing Grid (LCG 2.6) middleware [3], MPI [4] [5] and POSIX [6] threads. Finally, we compare the results obtained with the most popular and used tools to understand the importance of this strategy.	Univ Politecn Valencia, Inst Aplicac Tecnol Informac & Comun Avanzadas, Valencia 46022, Spain	Aparicio, G (reprint author), Univ Politecn Valencia, Inst Aplicac Tecnol Informac & Comun Avanzadas, Camino Vera S-N, Valencia 46022, Spain.		Blanquer, Ignacio/K-8675-2014	Blanquer, Ignacio/0000-0003-1692-8922			Cover TM, 1967, IEEE T INFORM THEORY, V13, P2127, DOI 10.1109/TIT.1967.1053964; Drepper U., 2003, NATIVE POSIX THREAD; Foster I., 2001, INT J SUPERCOMPUTER, V15; FRANK E, 2005, WEKA 3 DATA MINING S; Gropp W., 1998, MPI COMPLETE REFEREN; *LCG, WORLD WID WEB COMP G; 2003, MESSAGE PASSING INTE	7	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-71350-0	LECT NOTES COMPUT SC			2007	4395						225	235				11	Computer Science, Theory & Methods	Computer Science	BGD04	WOS:000246102900018		
B	Verron, S; Tiplica, T; Kobi, A		Zaytoon, J; Ferrier, JL; Cetto, JA; Filipe, J		Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessarnad			Multivariate control charts with a bayesian network	ICINCO 2007: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL ICSO: INTELLIGENT CONTROL SYSTEMS AND OPTIMIZATION			English	Proceedings Paper	4th International Conference on Informatics in Control, Automation and Robotics	MAY 09-12, 2007	Angers, FRANCE	Inst Syst & Technol Informat, Control & Commun, Univ Angers, Int Federat Automat Control, GDR MACS, CNRS, EEA, Assoc Advancement Artificial Intelligence		SPC; bayesian network; multivariate control charts; T-2; MEWMA	CLASSIFICATION	The purpose of this article is to present an approach allowing the fault detection of a multivariate process with a bayesian network. As a discriminant analysis is easily modeled with a bayesian network, we will show that we we can consider the multivariate T-2 and MEWMA control charts as particular cases of the discriminant analysis. So, we give the structure of the bayesian network as well as the parameters of the network in order to detect faults in the multivariate space in the same manners as if we used multivariate control charts. The resulting bayesian network, with a computed threshold, is similar to the multivariate control charts.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessarnad] LASQUO ISTIA, F-49000 Angers, France	Verron, S (reprint author), LASQUO ISTIA, 62 Ave Notre Dame du Lac, F-49000 Angers, France.						Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; Bodden KM, 1999, J QUAL TECHNOL, V31, P120; Chiang L. H., 2001, FAULT DETECTION DIAG; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Hotelling H., 1947, TECHNIQUES STAT ANAL, P111; JACKSON JE, 1985, COMMUN STAT-THEOR M, V14, P2657, DOI 10.1080/03610928508829069; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; KONONENKO I, 1991, EUR WORK SESS LEARN, P206; Kourti T, 1996, J QUAL TECHNOL, V28, P409; Langley P., 1992, NAT C ART INT; LOWRY CA, 1992, TECHNOMETRICS, V34, P46, DOI 10.2307/1269551; MACGREGOR H, 1995, CHROMOSOME RES, V3, P3, DOI 10.1007/BF00711155; Montgomery Douglas C, 1997, INTRO STAT QUALITY C; Pearl J, 1988, PROBABILISTIC REASON; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; PIGNATIELLO JJ, 1990, J QUAL TECHNOL, V22, P173; Shewhart WA, 1931, EC CONTROL QUALITY M; Vapnik V.N., 1995, NATURE STAT LEARING	21	1	1	1	1	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL			978-972-8865-82-5				2007							228	233				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems	Automation & Control Systems; Computer Science	BHF14	WOS:000252639500032		
B	Han, DW; Zhang, J		Wani, MA; Kantardzic, MM; Li, T; Liu, Y; Kurgan, L; Ye, J; Ogihara, M; Sagiroglu, S; Chen, XW; Peterson, L; Hafeez, K		Han, Dianwei; Zhang, Jun			A comparison of two algorithms for predicting the condition number	ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	6th International Conference on Machine Learning and Applications	DEC 13-15, 2007	Cincinnati, OH	Assoc Machine Learning & Applicat, IEEE				We present experimental results of comparing the Modified K-Nearest Neighbor (MkNN) algorithm with Support Vector Machine (SVM) in the prediction of condition numbers of sparse matrices. Condition number of a matrix is an important measure in numerical analysis and linear algebra. However the direct computation of the condition number of a matrix is very expensive in terms of CPU and memory cost, and becomes prohibitive for large size matrices. We use data mining techniques to estimate the condition number of a given sparse matrix. In our previous work, we used Support Vector Machine (SVM) to predict the condition numbers. While SVM is considered a state-of-the-art classification/regression algorithm, kNN is usually used for collaborative filtering tasks. Since prediction can also be interpreted as a classsfication/regression task, virtually any supervised learning algorithm (such as kNN) can also be applied. Experiments are performed on a publicly available dataset. We conclude that Modified kNN (MkNN) performs much better than SVM on this particular dataset.	[Han, Dianwei; Zhang, Jun] Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA	Han, DW (reprint author), Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.						BAI Z, 1993, ACM T MATH SOFTWARE, V19, P202, DOI 10.1145/152613.152617; Bennett K., 2000, SIGKDD EXPLORATIONS, V2, P1; BISCHOF C, 1990, SIAM J MATRIX ANAL A, V11, P31; BISCHOF C. H., 1992, J NUMER LINEAR ALG A, V1, P149; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fix E., 1951, 2149004 USAF SCH AV; Golub G.H., 1996, MATRIX COMPUTATION, V3rd; HIGHAM NJ, 1988, ACM T MATH SOFTWARE, V14, P381, DOI 10.1145/50063.214386; Joachims T., 1999, MAKING LARGE SCALE S; Ma JS, 2003, NEURAL COMPUT, V15, P2683, DOI 10.1162/089976603322385117; Smola A. J., 1998, TECHNICAL REPORT SER, VNC2-TR-1998-030; THEODORE B, 2000, INT JOINT C NEUR NET, V6, P6348; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; XU S, 2004, COMMUNICATIONS INFOR, V4, P325; XU S, 2005, P 8 WORKSH MIN SCI E, P49; YANG H, 2002, P 3 INT C INT DAT EN	17	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3069-7				2007							223	228				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHF84	WOS:000252793400037		
J	Lee, H; Kim, E; Park, M				Lee, Heesung; Kim, Euntai; Park, Mignon			A genetic feature weighting scheme for pattern recognition	INTEGRATED COMPUTER-AIDED ENGINEERING			English	Article							SCALE FEATURE-SELECTION; CLASSIFICATION; ALGORITHMS	This paper proposes a new pattern recognition scheme, combining a new adaptive feature weighting and modified k-Nearest Neighbor (k-NN) rule. The proposed feature weighting method named adaptive-3FW. It uses three non-uniform weight levels (zero weight, middle weight and full weight) to weight each feature. The middle weight value is determined using genetic algorithms (GAs). The proposed adaptive-3FW overcomes overfitting issues and achieves high recognition performance. Novel GA operators tailored for this formulation are introduced to implement the proposed scheme. Further, a modified k-NN is proposed which uses a class-dependent feature weighting strategy. Whilst the conventional pattern recognition systems use the same set of feature weights for all classes, the proposed algorithm uses different sets of feature weights for different classes. Experiments were performed with the UCI repository for machine learning databases and the unconstrained handwritten numeral database of Concordia University in Canada to show the performance of the proposed method.	Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea	Kim, E (reprint author), Yonsei Univ, Sch Elect & Elect Engn, C613,134 Shinchon Dong, Seoul 120749, South Korea.	etkim@yonsei.ac.kr					Coley D. A., 1999, INTRO GENETIC ALGORI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L. D., 1991, HDB GENETIC ALGORITH; DUDA RO, 2001, PATTERN CLASSIFICAT; GOSE E, 1996, PATTEN RECOGNITION I; Hong JH, 2006, PATTERN RECOGN LETT, V27, P143, DOI 10.1016/j.patrec.2005.07.009; Hussein F, 2001, SIXTH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, PROCEEDINGS, P1240; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kelly J. D. J., 1991, P 4 INT C GEN ALG TH, P377; KOHAVI R, 1997, EUR C MACH LEARN ECM; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P648; Liu YX, 1998, PROC CVPR IEEE, P800; Murphy P. M., 1994, UCI REPOSITORY MACHI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Oliveira LS, 2003, INT J PATTERN RECOGN, V17, P903, DOI 10.1142/S021800140300271X; Piramuthu S, 1998, P ANN HICSS, P294, DOI 10.1109/HICSS.1998.648324; Pratt W. K., 1978, DIGITAL IMAGE PROCES; PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Suen C., 1990, P INT WORKSH FRONT H, P131	20	25	25	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1069-2509			INTEGR COMPUT-AID E	Integr. Comput.-Aided Eng.		2007	14	2					161	171				11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Computer Science; Engineering	161VF	WOS:000246043800004		
S	Khosla, D; Moore, CK; Chelian, S		Priddy, KL; Ertin, E		Khosla, Deepak; Moore, Christopher K.; Chelian, Suhas			A bio-inspired system for spatio-temporal recognition in static and video imagery	INTELLIGENT COMPUTING: THEORY AND APPLICATIONS V	Proceedings of SPIE		English	Proceedings Paper	Conference on Intelligent Computing - Theory and Applications V	APR 09-10, 2007	Orlando, FL	SPIE		event recognition; scene classification; bio-inspired; interactive learning	VISUAL-ATTENTION; NETWORKS	This paper presents a bio-inspired method for spatio-temporal recognition in static and video imagery. It builds upon and extends our previous work on a bio-inspired Visual Attention and object Recognition System (VARS). The VARS approach locates and recognizes objects in a single frame. This work presents two extensions of VARS. The first extension is a Scene Recognition Engine (SCE) that learns to recognize spatial relationships between objects that compose a particular scene category in static imagery. This could be used for recognizing the category of a scene, e.g., office vs. kitchen scene. The second extension is the Event Recognition Engine (ERE) that recognizes spatio-temporal sequences or events in sequences. This extension uses a working memory model to recognize events and behaviors in video imagery by maintaining and recognizing ordered spatio-ternporal sequences. The working memory model is based on an ARTSTORE(1) neural network that combines an ART-based neural network with a cascade of sustained temporal order recurrent (STORE)(1) neural networks. A series of Default ARTMAP classifiers ascribes event labels to these sequences. Our preliminary studies have shown that this extension is robust to variations in an object's motion profile. We evaluated the performance of the SCE and ERE on real datasets. The SCE module was tested on a visual scene classification task using the LabelMe(2) dataset. The ERE was tested on real world video footage of vehicles and pedestrians in a street scene. Our system is able to recognize the events in this footage involving vehicles and pedestrians.	HRL Labs LLC, Malibu, CA USA	Khosla, D (reprint author), HRL Labs LLC, Malibu, CA USA.						Barnard M, 2005, ICME, P1150; Bosch A., 2006, P ECCV; BRADSKI G, 1994, BIOL CYBERN, V71, P469, DOI 10.1007/BF00198465; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Carpenter GA, 2003, IEEE IJCNN, P1396; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; Clover T., 1967, IEEE T INFORM THEORY, V13, P21; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Epstein R, 1999, NEURON, V23, P115, DOI 10.1016/S0896-6273(00)80758-8; HU W, 2004, IEEEE T SYSTEMS MA B, P1618; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Khosla D., 2007, P SPIE; Lazebnik S., 2006, P IEEE C COMP VIS PA; Lowe D., 1999, INT C COMP VIS CORF, P1150; Lv F., 2006, P 9 IEEE INT WORKSH, P83; Murphy K.P., 2002, DYNAMIC BAYESIAN NET; Park S., 2003, IWVS 03 1 ACM SIGMM, P65; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; RUSSELL BC, 2005, AIM2005025; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; VOGEL J, 2004, NATURAL SCENE RETRIE	21	1	1	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-6682-2	PROC SPIE			2007	6560								656002	10.1117/12.719975		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Computer Science; Engineering; Optics; Imaging Science & Photographic Technology	BGL73	WOS:000248227000001		
S	Khosla, D; Moore, CK; Huber, D; Chelian, S		Priddy, KL; Ertin, E		Khosla, Deepak; Moore, Christopher K.; Huber, David; Chelian, Suhas			Bio-inspired Visual Attention and Object Recognition	INTELLIGENT COMPUTING: THEORY AND APPLICATIONS V	Proceedings of SPIE		English	Proceedings Paper	Conference on Intelligent Computing - Theory and Applications V	APR 09-10, 2007	Orlando, FL	SPIE		object recognition; attention; bio-inspired; invariant transformation; COIL-100; Caltech-101; bio-inspired vision	CORTEX	This paper describes a bio-inspired Visual Attention and Object Recognition System (VARS) that can (1) learn representations of objects that are invariant to scale, position and orientation; and (2) recognize and locate these objects in static and video imagery. The system uses modularized bio-inspired algorithms/techniques that can be applied towards finding salient objects in a scene, recognizing those objects, and prompting the user for additional information to facilitate interactive learning. These algorithms are based on models of human visual attention, search, recognition and learning. The implementation is highly modular, and the modules can be used as a complete system or independently. The underlying technologies were carefully researched in order to ensure they were robust, fast, and could be integrated into an interactive system. We evaluated our system's capabilities on the Caltech-101 and COIL-100 datasets, which are commonly used in machine vision, as well as on simulated scenes. Preliminary results are quite promising in that our system is able to process these datasets with good accuracy and low computational times.	HRL Labs LLC, Malibu, CA USA	Khosla, D (reprint author), HRL Labs LLC, Malibu, CA USA.						Andoni A, 2006, P S FDN COMP SCI; BERG A, 2005, SHAPE MATCHING OBJEC; BOUSSAOUD D, 1991, J COMP NEUROL, V306, P554, DOI 10.1002/cne.903060403; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Carpenter GA, 2003, IEEE IJCNN, P1396; Carpenter GA, 1998, COMPUT VIS IMAGE UND, V69, P1, DOI 10.1006/cviu.1997.0561; Clover T., 1967, IEEE T INFORM THEORY, V13, P21; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DRAPER B, 2003, EVALUATION SELECTIVE; Fei-fei L., 2004, CVPR; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Grill-Spector K, 2005, PSYCHOL SCI, V16, P152, DOI 10.1111/j.0956-7976.2005.00796.x; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Kandel E. R., 2000, PRINCIPLES NEURAL SC; Lazebnik S., 2006, P IEEE C COMP VIS PA; Lowe D., 1999, INT C COMP VIS CORF, P1150; Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NAVALPAKKAM V, 2006, P IEEE COMP VIS PA R; Navalpakkam V., 2003, P INT WORKSH ATT PER; Nene S., 1996, CUCS00696 DEP COMP S; ORABONA F, 2005, CVPR 2005; Palmeri T., 2004, NATURE REV NEUROSCIE, V5; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019; Roobaert D., 1999, NNSP99; Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; SERRE T, 2005, P IEEE C COMP VIS P; Wolf L., 2006, CVPR; Zhang H., 2006, CVPR	31	1	1	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-6682-2	PROC SPIE			2007	6560								656003	10.1117/12.719981		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Computer Science; Engineering; Optics; Imaging Science & Photographic Technology	BGL73	WOS:000248227000002		
S	Smith, JE; Tahir, MA		Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Smith, J. E.; Tahir, M. A.			Stop wasting time: On predicting the success or failure of learning for industrial applications	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND				VARIANCE; BIAS	The successful application of machine learning techniques to industrial problems places various demands on the collaborators. The system designers must possess appropriate analytical skills and technical expertise, and the management of the industrial or commercial partner must be sufficiently convinced of the potential benefits that they are prepared to invest in money and equipment. Vitally, the collaboration also requires a significant investment in time from the end-users in order to provide training data from which the system can (hopefully) learn. This poses a problem if the developed Machine Learning system is not sufficiently accurate, as the users and management; may view their input as wasted effort, and lose faith with the process. In this paper we investigate techniques for making early predictions of the error rate achievable after further interactions. In particular we show how decomposing the error in different components can lead to useful predictors of achievable accuracy, but; that this is dependent on the choice of an appropriate sampling methodology.	[Smith, J. E.; Tahir, M. A.] Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England	Smith, JE (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.						BREIMAN L, 460 U CAL STAT DEP; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; BRIAN D, 1999, P 4 AUSTR KNOWL ACQ, P117; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 2000, P 17 INT C MACH LEAR, P231; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Geman S., 1995, NEURAL COMPUT, V4, P1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Kohavi R., 1996, P 13 INT C MACH LEAR; KOHAVI R, 1995, P 8 EUR C MACH LEARN; KONG BE, 1995, P 12 INT C MACH LEAR, P313; Platt J., 1998, ADV KERNEL METHODS S; Putten P.V.D., 2004, MACH LEARN, V57, P177; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rodriguez JJ, 2005, LECT NOTES COMPUT SC, V3512, P779; WEBB GI, 2003, ESTIMATING BIAS VARI; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849	22	3	3	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-77225-5	LECT NOTES COMPUT SC			2007	4881						673	683				11	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHE04	WOS:000252394900068		
S	Bosin, A; Dessi, N; Pes, B		Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara			Capturing heuristics and intelligent methods for improving micro-array data classification	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND				CLASSIFIERS; CANCER	Classification of micro-array data has been studied extensively but only a small amount of research work has been done on classification of micro-array data involving more than two classes. This paper proposes a learning strategy that deals with building a multi-target classifier and takes advantage from well known data mining techniques. To address the intrinsic difficulty of selecting features in order to promote the classification accuracy, the paper considers the use of a set of binary classifiers each of ones is devoted to predict a single class of the multi-classification problem. These classifiers are similar to local experts whose knowledge (about the features that are most correlated to each class value) is taken into account by the learning strategy for selecting an optimal set of features. Results of the experiments performed on a publicly available dataset demonstrate the feasibility of the proposed approach.	[Bosin, Andrea; Dessi, Nicoletta; Pes, Barbara] Univ Cagliari, Dipartimento Matemat & Informat, I-09124 Cagliari, Italy	Bosin, A (reprint author), Univ Cagliari, Dipartimento Matemat & Informat, Via Osped 72, I-09124 Cagliari, Italy.						Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; BOSIN A, 2007, P WILF 2007; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DRUMMOND C, 2006, MACHINE LEARNING J, V65; Drummond C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347126; Everitt B. S., 1977, ANAL CONTINGENCY TAB; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Frank E., 2005, DATA MINING PRACTICA; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Liu Huiqing, 2002, Genome Inform, V13, P51; MUKHERJEE S, 2003, CLASSIFYING MICROARR; PIATETSKYSHAPIR.G, 2003, SIGKDD 2003; Simon R, 2003, SIGKDD EXPLORATIONS, V5, P31; SOMORJAI R, 2003, BIOINFORMATICS, V19; STATNIKOV A, 2005, BIOINFORMATICS, V21; TAO L, 2004, BIOINFORMATICS, V20; Vapnik V., 1998, STAT LEARNING THEORY	21	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-77225-5	LECT NOTES COMPUT SC			2007	4881						790	799				10	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHE04	WOS:000252394900079		
S	Angiulli, F; Fionda, V; Rombo, SE		Yin, H; Tino, P; Corchado, E; Byrne, W; Yao, X		Angiulli, Fabrizio; Fionda, Valeria; Rombo, Simona E.			Protein data condensation for effective quaternary structure classification	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2007	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND				FUNCTIONAL DOMAIN COMPOSITION; PREDICTION; SECONDARY	Many proteins are composed of two or more subunits, each associated with different polypeptide chains. The number and the arrangement of subunits forming a protein are referred to as quaternary structure. The quaternary structure of a protein is important, since it characterizes the biological function of the protein when it is involved in specific biological processes. Unfortunately, quaternary structures are not trivially deducible from protein amino acid sequences. In this work, we propose a protein quaternary structure classification method exploiting the functional domain composition of proteins. It is based on a nearest neighbor condensation technique in order to reduce both the portion of dataset to be stored and the number of comparisons to carry out. Our approach seems to be promising, in that it guarantees an high classification accuracy, even though it does not require the entire dataset to be analyzed. Indeed, experimental evaluations show that the method here proposed selects a small dataset portion for the classification (of the order of the 6.43%) and that it is very accurate (97.74%).	[Angiulli, Fabrizio; Rombo, Simona E.] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.						Bairoch A, 1996, NUCLEIC ACIDS RES, V24, P21, DOI 10.1093/nar/24.1.21; Angiulli Fabrizio, 2005, P 22 INT C MACH LEAR; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Kim Wan Kyu, 2002, Genome Inform, V13, P42; KLOTZ IM, 1970, ANNU REV BIOCHEM, V39, P25, DOI 10.1146/annurev.bi.39.070170.000325; Lesk A.M, 2001, INTRO PROTEIN ARCHIT; Meiler J, 2003, P NATL ACAD SCI USA, V100, P12105, DOI 10.1073/pnas.1831973100; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Song R, 2004, J CHEM INF COMP SCI, V44, P1324, DOI 10.1021/ci034288y; SUND H, 1966, ANGEW CHEM INT EDIT, V5, P231, DOI 10.1002/anie.196602311; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wojcik J., 2001, BIOINFORMATICS S1, V17, P296; YU X, 2006, BMC BIOINFORMATICS, V7; Yu XJ, 2004, CHINESE SCI BULL, V49, P2379, DOI 10.1360/982004-142; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331	22	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-77225-5	LECT NOTES COMPUT SC			2007	4881						810	820				11	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BHE04	WOS:000252394900081		
S	Mignani, AG; Ciaccheri, L; Cucci, C; Mencaglia, AA; Cimato, A; Attilio, C; Thienpont, H; Ottevaere, H; Paolesse, R; Mastroianni, M; Monti, D; Buonocore, G; Del Nobile, A; Mentana, A; Grimaldi, MF; Dall'Asta, C; Faccini, A; Galaverna, G; Dossena, A		Matvienko, GG; Ivanov, AP; Nikitin, PI; Voropay, ES; Khodasevich, MA; Panchenko, VY; Golubev, VS		Mignani, A. G.; Ciaccheri, L.; Cucci, C.; Mencaglia, A. A.; Cimato, A.; Attilio, C.; Thienpont, H.; Ottevaere, H.; Paolesse, R.; Mastroianni, M.; Monti, D.; Buonocore, G.; Del Nobile, A.; Mentana, A.; Grimaldi, M. F.; Dall'Asta, C.; Faccini, A.; Galaverna, G.; Dossena, A.			EAT-by-LIGHT fiber-optic and micro-optic devices for food quality and safety assessment	INTERNATIONAL CONFERENCE ON LASERS, APPLICATIONS, AND TECHNOLOGIES 2007: ENVIRONMENTAL MONITORING AND ECOLOGICAL APPLICATIONS; OPTICAL SENSORS IN BIOLOGICAL, CHEMICAL, AND ENGINEERING TECHNOLOGIES; AND FEMTOSECOND LASER PULSE FILAMENTATION	Proceedings of SPIE		English	Proceedings Paper	International Conference on Lasers, Applications, and Technologies	MAY 28-JUN 01, 2007	Minsk, BYELARUS	Natl Acad Sci, Russian Acad Sci, Moscow State Univ, M V Lomonosov, BI Stepanov Inst Phys, Int Sci & Technol Ctr, Belarus Fdn Basic Res, Belarus Phys Soc, Russian Phys Soc, SPIE Russian Chapter		food authentication; scattered colorimetry; absorption spectroscopy; fluorescence spectroscopy; olive oil; beer; aflatoxins; milk	OLIVE OIL; CLASSIFICATION	A selection is presented of fiber-optic and micro-optic devices that have been designed and tested for guaranteeing the quality and safety of typical foods, such as extra virgin olive oil, beer, and milk. Scattered colorimetry is used to authenticate various types of extra virgin olive oil and beer, while a fiber-optic-based device for UV-VIS-NIR absorption spectroscopy is exploited in order to obtain the hyperspectral optical signature of olive oil. This is done not only for authentication purposes, but also so as to correlate the spectral data with the content of fatty acids, which are important nutritional factors. A micro-optic sensor for the detection of olive oil aroma that is capable of distinguishing different ageing levels of extra virgin olive oil is also presented. It shows effective potential for acting as a smart cap of bottled olive oil in order to achieve a non-destructive olfactory perception of oil ageing. Lastly, compact portable fluorometer for the rapid monitoring of the carcinogenic M1 aflatoxin in milk, is experimented.	[Mignani, A. G.; Ciaccheri, L.; Cucci, C.; Mencaglia, A. A.] CNR IFAC, Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR IFAC, Sesto Fiorentino, FI, Italy.	a.g.mignani@ifac.cnr.it	Ottevaere, Heidi/A-9294-2010; Dall'Asta, Chiara/C-3173-2008; Mencaglia, Andrea/C-1692-2015; 	Dall'Asta, Chiara/0000-0003-0716-8394; Galaverna, Gianni/0000-0001-9042-2378			ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; Buratti S, 2005, ITAL J FOOD SCI, V17, P203; CHIAVARO E, 2001, J CHROMATOGR A, V937, P257; Christy A. A., 2007, NEAR INFRARED SPECTR; Connolly C., 2005, Sensor Review, V25, DOI 10.1108/02602280510606453; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUCCI C, 2007, IN PRESS SENSORS A B; Di Natale C, 2007, SENSOR ACTUAT B-CHEM, V121, P238, DOI 10.1016/j.snb.2006.09.038; DOLPHIN D, 1978, PORYPHYRINS, V3; Franco CM, 1998, J CHROMATOGR A, V815, P21, DOI 10.1016/S0021-9673(98)00509-3; Harwood JL, 1999, HDB OLIVE OIL; HESTER RE, 2001, FOOD SAFETY FOOD QUA; IARC, 1993, IARC MONOGR EVAL CAR, V56, P1; JACKSON M, 2001, GREAT BEERS BELGUIM; JAE M, 2002, OILS FATS AUTHENTICA; KELLER JJ, 2000, COMPLIANCE MANUAL FO; Lees M., 2003, FOOD AUTHENTICITY TR; Mencaglia AA, 2003, P SOC PHOTO-OPT INS, V4763, P248, DOI 10.1117/12.508795; MIGNANI AG, 2007, IN PRESS P SPIE, V6585; MIGNANI AG, 2006, P SPIE, V6189; Mignani AG, 2005, SENSOR ACTUAT B-CHEM, V111, P363, DOI 10.1016/j.snb.2005.03.023; Mignani AG, 2005, P SOC PHOTO-OPT INS, V5855, P38, DOI 10.1117/12.623388; PAOLESSE R, 2003, P 16 INT C OPT FIB S, P742; Rakow NA, 2000, NATURE, V406, P710, DOI 10.1038/35021028; SERVILI M, 1995, J SCI FOOD AGR, V67, P61, DOI 10.1002/jsfa.2740670111; Siesler HW, 2002, NEAR INFRARED SPECTR; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; VANEGMOND HP, 1998, INTRO MYCOTOXINS DAI; WEBB T, 2005, GOOD BEER GUIDE BELG	30	1	1	1	5	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-6891-8	PROC SPIE			2007	6733								67331K	10.1117/12.753315		13	Biochemistry & Molecular Biology; Remote Sensing; Optics	Biochemistry & Molecular Biology; Remote Sensing; Optics	BGZ41	WOS:000251495000018		
J	Lisboa, FOSD; Nicoletti, MD; Ramere, A				Santos de Sa Lisboa, Flavia O.; Nicoletti, Maria do Carmo; Ramere, Arthur			A version of the NGE model suitable for fuzzy domains	JOURNAL OF INTELLIGENT & FUZZY SYSTEMS			English	Article						NGE; NN; KNN; fuzzy NGE	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; CLASSIFICATION	The Nested Generalized Exemplar (NGE) model is an incremental form of inductive learning that generalizes a given training set into hypotheses represented as a set of hyperrectangles in an n-dimensional Euclidean space. The NGE algorithm can be considered a descendent of either Nearest Neighbor (NN) or K-Nearest Neighbor (KNN) algorithms. NGE based systems classify new instances by calculating their similarity to the nearest generalized exemplar (i.e. hyperrectangle). Similarity in an NGE model is implemented by a distance metric namely the Euclidean distance. This paper describes a version of the NGE model suitable for fuzzy domains called Fuzzy NGE (F-NGE). F-NGE learns fuzzy rules for classifying instances into crisp classes. An implementation of F-NGE has been tested in several different knowledge domains for which results are presented and discussed. Results of fuzzy versions of NN and KNN using the same domains are also presented, for comparison.	Univ Fed Sao Carlos, Dept Computat, Sao Carlos, SP, Brazil; Univ Sao Paulo, Inst Fis Sao Carlos, Sao Carlos, SP, Brazil; Univ New S Wales, Sch Engn & Comp Sci, Sydney, NSW, Australia	Nicoletti, MD (reprint author), Univ Fed Sao Carlos, Dept Computat, Sao Carlos, SP, Brazil.	carmo@dc.ufscar.br	Lisboa, Flavia/I-6767-2012				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIGUEIRA LB, 2004, P 2004 IEEE SMC OCT, P3395; FIGUEIRA LB, 2004, P ITCC 2004 5 7 APR, V2, P193; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Heath D, 1996, J EXP THEOR ARTIF IN, V8, P129, DOI 10.1080/095281396147429; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Klir G. J., 1995, FUZZY SETS FUZZY LOG; KOLODNER JL, 1984, RETRIEVAL ORG STATEG; LISBOA FOS, 2003, 12 IEEE INT C FUZZ S, P90; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Merz C, 1998, UCI REPOSITORY MACHI; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rondall Wilson D., 1996, P INT C NEUR NETW IC, P1263; Sadegh-Zadeh K, 1999, ARTIF INTELL MED, V15, P309, DOI 10.1016/S0933-3657(98)00060-8; SALZBERG S, 1991, MACH LEARN, V6, P252; SPECHT DF, 1992, P IEEE INT JOINT C N, P761; TschicholdGurman N, 1997, FUZZY SET SYST, V85, P287, DOI 10.1016/0165-0114(95)00351-7; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; WETTSCHERECK D, 1994, P 7 EUR C MACH LEARN, P323; Wilson D.R., 1997, P 14 INT C MACH LEAR, P404; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, P INT C ART NEUR NET, P514; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5	26	3	3	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1064-1246			J INTELL FUZZY SYST	J. Intell. Fuzzy Syst.		2007	18	1					1	17				17	Computer Science, Artificial Intelligence	Computer Science	187PO	WOS:000247860500001		
J	Wang, CY; Sun, YF; Liang, YC				Wang, Chaoyong; Sun, Yanfeng; Liang, Yanchun			An improved SVM based on similarity metric	JOURNAL OF UNIVERSAL COMPUTER SCIENCE			English	Article						support vector machine; Riemannian metric; similarity metric		A novel support vector machine method for classification is presented in this paper. A modified kernel function based on the similarity metric and Riemannian metric is applied to the support vector machine. In general, it is believed that the similarity of homogeneous samples is higher than that of inhomogeneous samples. Therefore, in Riemannian geometry, Riemannian metric can be used to reflect local property of a curve. In order to enlarge the similarity metric of the homogeneous samples or reduce that of the inhomogeneous samples in the feature space, Riemannian metric is used in the kernel function of the SVM. Simulated experiments are performed using the databases including an artificial and the UCI real data. Simulation results show the effectiveness of the proposed algorithm through the comparison with four typical kernel functions without similarity metric.	[Wang, Chaoyong] Jilin Teachers Inst Engn & Technol, Dept Fundamental Sci, Changchun 130021, Peoples R China; [Wang, Chaoyong; Sun, Yanfeng; Liang, Yanchun] Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China	Wang, CY (reprint author), Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.	dynasty1188@126.com; sunyf@jlu.edu.cn; ycliang@jlu.edu.cn					Cherkassy V., 1998, LEARNING DATA CONCEP; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Palais R.S., 1988, LECT NOTES MATH, V1353; SCHOLKOPF B, 1999, ADV KERNEL METHODS C; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Steinwart I., 2001, J MACHINE LEARNING R, V2, P67, DOI 10.1162/153244302760185252; Vapnik V. N., 1995, NATURE STAT LEARNING; Wu S, 2002, NEURAL PROCESS LETT, V15, P59, DOI 10.1023/A:1013848912046	10	0	0	0	10	GRAZ UNIV TECHNOLGOY, INST INFORMATION SYSTEMS COMPUTER MEDIA-IICM	GRAZ	INFFELDGASSE 16C, GRAZ, A-8010, AUSTRIA	0948-695X			J UNIVERS COMPUT SCI	J. Univers. Comput. Sci.		2007	13	10					1462	1470				9	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	268YL	WOS:000253616300006		
S	Song, Y; Huang, J; Zhou, D; Zha, H; Giles, CL		Kok, JN; Koronacki, J; DeMantaras, RL; Matwin, S; Mladenic, D; Skowron, A		Song, Yan; Huang, Jian; Zhou, Ding; Zha, Hongyuan; Giles, C. Lee			IKNN: Informative K-nearest neighbor pattern classification	Knowledge Discovery in Databases: PKDD 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	18th European Conference on Machine Learning (ECML 2007)/11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2007)	SEP 17-21, 2007	Warsaw, POLAND	Warsaw Univ, Fac Math, Informat & Mech, Polish Acad Sci, Inst Comp Sci, European Off Aerosp Res & Dev, Air Force Off Sci Res, USAF Res Lab	Warsaw Univ			The K-nearest neighbor (KNN) decision rule has been a ubiquitous classification tool with good scalability. Past experience has shown that the optimal choice of K depends upon the data, making it laborious to tune the parameter for different applications. We introduce a new metric that measures the informativeness of objects to be classified. When applied as a query-based distance metric to measure the closeness between objects, two novel KNN procedures, Locally Informative-KNN (LI-KNN) and Globally Informative-KNN (GI-KNN), are proposed. By selecting a subset of most informative objects from neighborhoods, our methods exhibit stability to the change of input parameters, number of neighbors(K) and informative points (I). Experiments on UCI benchmark data and diverse real-world data sets indicate that our approaches are application-independent and can generally outperform several popular KNN extensions, as well as SVM and Boosting methods.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Song, Y (reprint author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.						ATHITSOS V, 2005, CVPR 05 WASH DC US; ATHITSOS V, 2005, CVPR 05 WASH DC US, P486; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Friedman J., 1994, 113 STANF U STAT DEP; Han Eui-Hong Sam, 2001, 5 PAC AS C KNOWL DIS, P53; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; LATOURRETTE M, 2000, ECML 00 P 11 EUR C M, P238; Peng J, 2001, CVPR 01, P58; SCHAPIRE RE, 1998, COLT 98; Weinberger K. Q., 2005, NIPS; Zhang H., 2006, CVPR, P2126	14	21	21	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74975-2	LECT NOTES ARTIF INT			2007	4702						248	264				17	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BGQ47	WOS:000249743700021		
S	Suri, NR; Srinivas, VS; Murty, MN		Kok, JN; Koronacki, J; DeMantaras, RL; Matwin, S; Mladenic, D; Skowron, A		Suri, N. Rama; Srinivas, V. S.; Murty, M. Narasimha			A cooperative game theoretic approach to prototype selection	Knowledge Discovery in Databases: PKDD 2007, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	18th European Conference on Machine Learning (ECML 2007)/11th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD 2007)	SEP 17-21, 2007	Warsaw, POLAND	Warsaw Univ, Fac Math, Informat & Mech, Polish Acad Sci, Inst Comp Sci, European Off Aerosp Res & Dev, Air Force Off Sci Res, USAF Res Lab	Warsaw Univ			In this paper we consider the task of prototype selection whose primary goal is to reduce the storage and computational requirements of the Nearest Neighbor classifier while achieving better classification accuracies. We propose a solution to the prototype selection problem using techniques from cooperative game theory and show its efficacy experimentally.	Indian Inst Sci, Dept Comp Sci & Automat, Elect Commerce Lab, Bangalore 560012, Karnataka, India	Suri, NR (reprint author), Indian Inst Sci, Dept Comp Sci & Automat, Elect Commerce Lab, Bangalore 560012, Karnataka, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; INARRA E, 1993, INT J GAME THEORY, V22, P13, DOI 10.1007/BF01245567; Keinan A, 2004, NEURAL COMPUT, V16, P1887, DOI 10.1162/0899766041336387; LI Y, 2005, ADV NATURA COMPOSITE; Murphy P. M., 1994, UCI REPOSITORY MACHI; Myerson R., 1997, GAME THEORY ANAL CON; SANCHEZ JS, 2001, P 14 BRAZ S COMP GRA; Shapley L. S., 1971, International Journal of Game Theory, V1, DOI 10.1007/BF01753431; STRAFFIN PD, 1993, GAME THEORY; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	10	1	1	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-74975-2	LECT NOTES ARTIF INT			2007	4702						556	564				9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BGQ47	WOS:000249743700054		
S	Vanderlooy, S; van der Maaten, L; Sprinkhuizen-Kuyper, I		Perner, P		Vanderlooy, Stijn; van der Maaten, Laurens; Sprinkhuizen-Kuyper, Ida			Off-line learning with transductive confidence machines: An empirical evaluation	Machine Learning and Data Mining in Pattern Recognition, Proceedings	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	5th International Conference on Machine Learning and Data Mining in Pattern Recognition	JUL 18-20, 2007	Leipzig, GERMANY				CLASSIFICATION; ALGORITHMS	The recently introduced transductive confidence machines (TCMs) framework allows to extend classifiers such that they satisfy the calibration property. This means that the error rate can be set by the user prior to classification. An analytical proof of the calibration property was given for TCMs applied in the on-line learning setting. However, the nature of this learning setting restricts the applicability of TCMs. In this paper we provide strong empirical evidence that the calibration property also holds in the off-line learning setting. Our results extend the range of applications in which TCMs can be applied. We may conclude that TCMs are appropriate in virtually any application domain.	Univ Limburg, MICC IKAT, NL-6200 MD Maastricht, Netherlands	Vanderlooy, S (reprint author), Univ Limburg, MICC IKAT, POB 616, NL-6200 MD Maastricht, Netherlands.						BELLOTTI T, 2006, THESIS ROYAL HOLLOWA; Blanzieri E, 1999, LECT NOTES ARTIF INT, V1650, P14; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Fisher RA, 1936, ANN EUGEN, V7, P178; Gammerman A., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998); Gammerman A, 2002, THEOR COMPUT SCI, V287, P209, DOI 10.1016/S0304-3975(02)00100-7; Khardon R, 2005, J ARTIF INTELL RES, V24, P341; Melluish T., 2001, LECT NOTES ARTIF INT, V2167, P360; Newman D., 1998, UCI REPOSITORY MACHI; PROEDROU K, 2001, 0102 ROYAL HOLL U LO; SAUNDERS C, 2000, ICALT 2000, P325; Saunders C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P722; Shawe- Taylor J., 2004, KERNEL METHODS PATTE; VANDERLOOY S, 2007, 0703 MICCIKAT U MAAS; VOVK V, 2005, ALGORITHMIC LEANING	16	10	10	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-73498-7	LECT NOTES ARTIF INT			2007	4571						310	323				14	Computer Science, Artificial Intelligence	Computer Science	BGM77	WOS:000248523200023		
S	Gomez, O; Morales, EF; Gonzalez, JA		Gelbukh, A; Morales, AFK		Gomez, Octavio; Morales, Eduardo F.; Gonzalez, Jesus A.			Weighted instance-based learning using representative intervals	MICAI 2007: ADVANCES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th Mexican International Conference on Artificial Intelligence (MICAI 2007)	NOV 04-10, 2007	Aguascalientes, MEXICO	Mexican Soc Artificial Intelligence		feature weighting; instance-based learning; K-NN	ALGORITHMS	Instance-based learning algorithms are widely used due to their capacity to approximate complex target functions; however; the performance of this kind of algorithms degrades significantly in the presence of irrelevant features. This paper introduces a new noise tolerant instance-based learning algorithm, called WIB-K, that uses one or more weights, per feature per class, to classify integer-valued databases. A set of intervals that represent the rank of values of all the features is automatically created for each class, and the nonrepresentative intervals are discarded. The remaining intervals (representative intervals) of each feature are compared against the representative intervals of the same feature in the other classes to assign a weight. The weight represents the discriminative power of the interval, and is used in the similarity function to improve the classification accuracy. The algorithm was tested on several datasets, and compared against other representative machine learning algorithms showing very competitive results.	Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Tonantzintla 72840, Mexico	Gomez, O (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1, Tonantzintla 72840, Mexico.	gomezo@ccc.inaoep.mx; emorales@ccc.inaoep.mx; jagonzalez@ccc.inaoep.mx		Gonzalez, Jesus/0000-0002-5232-4109			AHA DW, 1998, FEATURE EXTRACTION C, V1; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BLANSCHE A, 2006, PATTERN RECOGNITION, V27; Cleary J. G., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de la Torre A, 2002, SPEECH COMMUN, V38, P267, DOI 10.1016/S0167-6393(01)00068-1; Dougherty J., 1995, MACHINE LEARNING; Frank E., 2005, DATA MINING PRACTICA; GARTNER T, 2001, MACHINE LEARNING; GEORGE H, 1995, P 11 C UNC ART INT M, V11, P338; KIRA K, 1992, AAAI 1992; Kononenko I., 1994, LNCS, V784; Newman D., 1998, UCI REPOSITORY MACHI; PLAT JC, 1998, ADV KERNEL METHODS S; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SMITH EE, 1981, CATEGORIES CONCETPS; TAHIR TA, 2007, PATTERN RECOGN, V28, P438; WEISSTEIN EW, 2002, ANOVA TEST MATHWORLD; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WITTEN IH, 1998, MACHINE LEARNING	21	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-76630-8	LECT NOTES ARTIF INT			2007	4827						420	430				11	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BGW96	WOS:000251037900040		
S	Liu, CP; Yuan, XH; Wang, ZH; Cui, ZM		Zhang, TX; Nardell, C; Smith, D; Lu, HQ		Liu, Chunping; Yuan, Xiaohua; Wang, Zhaohui; Cui, Zhiming			Novel color image segmentation using self-generating prototypes - art. no. 67864A	MIPPR 2007: AUTOMATIC TARGET RECOGNITION AND IMAGE ANALYSIS; AND MULTISPECTRAL IMAGE ACQUISITION, PTS 1 AND 2	PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS (SPIE)		English	Proceedings Paper	5th International Symposium on Multispectral Image Processing and Pattern Recognition	NOV 15-17, 2007	Wuhan, PEOPLES R CHINA	SPIE, State Key Lab Multi Spectral Informat Proc Technol, Chinese Educ Minist Key Lab Image Proc & Intelligence Control, Huazhong Univ Sci & Technol	Wuhan Univ	competitive learning; color image segmentation; K-nearest neighbor algorithm; Learning vector quantization; hierarchical clustering; self-generating prototype		A new self-generating prototypes method based on SGNT is presented. This method uses reference patterns as initial prototype. This procedure can be implemented in a SGNT with specific architecture consisting of one root and the initial class number of reference patterns. The leaf in SGNT is defined with prototype vector, learning vector, center property vector and distant property vector. After training, prototype set are outputted. The main advantage of this method is that both the number of prototypes and their locations are learned from the training set without much human intervention. Experiments with synthesis and real color image the excellent performance of this classification scheme as compared to existing K-nearest neighbor (K-NN) and Learning vector quantization (LVQ) algorithm.	[Liu, Chunping; Wang, Zhaohui; Cui, Zhiming] Suzhou Univ, Sch Comp Sci & Technol, Suzhou 215006, Jiangsu, Peoples R China	Liu, CP (reprint author), Suzhou Univ, Sch Comp Sci & Technol, Suzhou 215006, Jiangsu, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; FANG L, 1991, P INT JOINT C NEUR N; HASTIE T, 2001, SPRINGER SERIES STAT, P1481; Inoue H., 2002, THESIS OKAYAMA U SCI; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; Kohonen T., 1995, SELF ORGANIZING MAPS; Wen W. X., 1992, INT JOINT C NEUR NET, V2, P751; WEN WX, 1992, P INT JOINT C NEUR N, V4, P850, DOI 10.1109/IJCNN.1992.227211	9	0	0	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-6950-2	P SOC PHOTO-OPT INS			2007	6786		1-2				A7864	A7864		10.1117/12.751169		8	Remote Sensing; Optics; Imaging Science & Photographic Technology	Remote Sensing; Optics; Imaging Science & Photographic Technology	BHK04	WOS:000253700100153		
J	Gao, QB; Wang, ZZ				Gao, Qing-Bin; Wang, Zheng-Zhi			Center-based nearest neighbor classifier	PATTERN RECOGNITION			English	Article						pattern classification; nearest neighbor; nearest feature line; centered-based nearest neighbor; computational biology	PATTERN-CLASSIFICATION; FEATURE LINE; PREDICTION	In this paper, a novel center-based nearest neighbor (CNN) classifier is proposed to deal with the pattern classification problems. Unlike nearest feature line (NFL) method, CNN considers the line passing through a sample point with known label and the center of the sample class. This line is called the center-based line (CL). These lines seem to have more capacity of representation for sample classes than the original samples and thus can capture more information. Similar to NFL, CNN is based on the nearest distance from an unknown sample point to a certain CL for classification. As a result, the computation time of CNN can be shortened dramatically with less accuracy decrease when compared with NFL. The performance of CNN is demonstrated in one simulation experiment from computational biology and high classification accuracy has been achieved in the leave-one-out test. The comparisons with nearest neighbor (NN) classifier and NFL classifier indicate that this novel classifier achieves competitive performance. (c) 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China	Gao, QB (reprint author), Natl Univ Def Technol, Inst Automat, Changsha 410073, Peoples R China.	qbgao@nudt.edu.cn	Gao, Qing-Bin/G-9825-2011				COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gao QB, 2005, COMPUT BIOL CHEM, V29, P388, DOI 10.1016/j.compbiolchem.2005.08.002; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204	9	42	47	1	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	JAN	2007	40	1					346	349		10.1016/j.patcog.2006.06.033		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	102TX	WOS:000241837300031		
S	Babu, VS; Viswanath, P		Ghosh, A; De, RK; Pal, SK		Babu, V. Suresh; Viswanath, P.			Weighted k-nearest leader classifier for large data sets	PATTERN RECOGNITION AND MACHINE INTELLIGENCE, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	2nd International Conference on Pattern Recognition and Machine Intelligence	DEC 18-22, 2007	Calcutta, INDIA	Indian Stat Inst, Machine Intelligence Univ, ISI Ctr Soft Comp Res, Int Assoc Pattern Recognit, Int Ctr Pure & Appl Math, Web Intelligence Consortium, Yahoo India Res & Dev, Philips Res Asia		weighted leaders method; k-NNC; noise elimination; prototypes		Leaders clustering method is a fast one and can be used to derive prototypes called leaders from a large training set which can be used in designing a classifier. Recently nearest leader based classifier is shown to be a faster version of the nearest neighbor classifier, but its performance can be a degraded one since the density information present in the training set is lost while deriving the prototypes. In this paper we present a generalized weighted k-nearest leader based classifier which is a faster one and also an on-par classifier with the k-nearest neighbor classifier. The method is to find the relative importance of each prototype which is called its weight and to use them in the classification. The design phase is extended to eliminate some of the noisy prototypes to enhance the performance of the classifier. The method is empirically verified using some standard data sets and a comparison is drawn with some of the earlier related methods.	[Babu, V. Suresh; Viswanath, P.] Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India	Babu, VS (reprint author), Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Ester M., 1996, P 2 INT C KNOWL DISC, P226; HART PE, 1968, IEEE T INFORMATI MAY, P515; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Spath H., 1980, CLUSTER ANAL ALGORIT; Vijaya PA, 2004, PATTERN RECOGN LETT, V25, P505, DOI 10.1016/j.patrec.2003.12.013; Viswanath P, 2006, P 18 INT C PATT REC, V1, P912	9	3	3	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-77045-9	LECT NOTES COMPUT SC			2007	4815						17	24				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHC02	WOS:000252140200003		
S	Dehzangi, O; Jahromi, MZ; Taheri, S		Rajapakse, JC; Schmidt, B; Volkert, G		Dehzangi, Omid; Jahromi, Mansoor Zolghadri; Taheri, Shahram			High performance classification of two imagery tasks in the cue-based brain computer interface	PATTERN RECOGNITION IN BIOINFORMATICS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	2nd International Workshop on Pattern Recognition in Bioinformatics	OCT 01-02, 2007	Singapore, SINGAPORE	IAPR		nearest neighbor; weighted distance; brain-computer interface; EEG	NEAREST-NEIGHBOR RULE; EEG CLASSIFICATION	Translation of human intentions into control signals for a computer, so called Brain-Computer Interface (BCI), has been a growing research field during the last years. In this way, classification of mental tasks is under investigation in the BCI society as a basic research. In this paper, a Weighted Distance Nearest Neighbor (WDNN) classifier is presented to improve the classification rate between the left and right imagery tasks in which a weight is assigned to each stored instance. The specified weight of each instance is then used for calculating the distance of a test pattern to that instance. We propose an iterative learning algorithm to specify the weights of training instances such that the error rate of the classifier on training data is minimized. ElectroEncephaloGram (EEG) signals are caught from four familiar subjects with the cue-based BCI. The proposed WDNN classifier is applied to the band power and fractal dimension features, which are extracted from EEG signals to classify mental tasks. Results show that our proposed method performs better in some subjects in comparison with the LDA and SVM, as well-known classifiers in the BCI field.	[Dehzangi, Omid; Jahromi, Mansoor Zolghadri; Taheri, Shahram] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore	Dehzangi, O (reprint author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore, Singapore.			Zolghadri Jahromi, Mansoor/0000-0003-3815-1528			BOOSTANI R, 2004, J NEURAL ENG, V1, P4; BOOSTANI R, 2007, J MED BIO ENG COMP, V6; BOZORGZADEH Z, 2000, IEEE INT C AC SPEECH, V6, P2385; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DERICHE M, 2001, IEEE INT C AC SPEECH, V2, P1057; Esteller R, 2000, THESIS GEORGIA I TEC; Fawcett T., 2003, HPL20034; FLOTZINGER D, 1994, IEEE INT C COMP INT, V6, P3448; FUKUNAGA K, 1999, INTRO STAT PATTERN C; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Graimann B, 2004, IEEE T BIO-MED ENG, V51, P954, DOI 10.1109/TBME.2004.826671; Haselsteiner E, 2000, IEEE T REHABIL ENG, V8, P457, DOI 10.1109/86.895948; HIGUCHI T, 1988, PHYSICA D, V31, P277, DOI 10.1016/0167-2789(88)90081-4; KALCHER J, 1992, P ANN INT C IEEE, V4, P1658; LACHICHE N, 2003, 20 INT C MACH LEARN, P416; Pfurtscheller G, 1998, IEEE Trans Rehabil Eng, V6, P316, DOI 10.1109/86.712230; PFURTSCHELLER G, 1999, HDB ELECTROENCEPH CL, V6; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; Schlogl A, 1997, BIOMED TECH, V42, P162, DOI 10.1515/bmte.1997.42.6.162; Vapnic V.N., 1998, STAT LEARNING THEORY; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER K, 2005, ADV NEURAL INFORM PR, P18; XIAOYUAN J, 2004, IEEE T SYS MAN CYBER, V34, P5	25	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-75285-1	LECT NOTES COMPUT SC			2007	4774						378	390				13	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BGY27	WOS:000251314800036		
B	Dehzangi, O; Jahromi, MZ		DelPobil, AP		Dehzangi, O.; Jahromi, M. Zolghadri			A proposed method of local feature-weighting to improve predictions of basic nearest neighbor rule	PROCEDINGS OF THE 11TH IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING			English	Proceedings Paper	11th IASTED International Conference on Artificial Intelligence and Soft Computing	AUG 29-31, 2007	Palma de Mallorca, SPAIN	Int Assoc Sci & Technol Dev, IASTED, TC Artificial Intelligence & Expert Syst, IASTED, TC Comm Soft Comp, Catalan Assoc Artificial Intelligence, Spanish Assoc Artificial Intelligence		pattern classification; nearest neighbor; local feature weighting; adaptive distance measure	CLASSIFICATION	predict the class of a query pattern. Several studies have shown that irrelevant, interacting, or noisy features have as much effect on distance computation as other features. Various global and local feature-weighting algorithms have been proposed to deal with this problem. In this paper, we use a local weighting scheme that allows feature weights to vary for each training instance. We propose a novel learning algorithm to learn the weight of each feature for every training instance. By associating a cost to each training instance, the proposed learning algorithm attempts to minimize the sum of costs for misclassified training instances. Using a number of data sets from the UCI-ML repository, we show that the proposed feature-weighting scheme is quite effective in improving the generalization ability of the NN classifier.	Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran	Dehzangi, O (reprint author), Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.			Zolghadri Jahromi, Mansoor/0000-0003-3815-1528			Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bang SL, 2006, INFORM PROCESS MANAG, V42, P387, DOI 10.1016/j.ipm.2005.04.003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R O, 2001, PATTERN CLASSIFICATI; MORRING BD, 2003, INTELL DATA ANAL, V7, P61; RAZA M, 2005, INFORM TECHNOLOGY AP, V4, P475; Tsang E. C. C., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.943700; WANG J, 2006, PATTERN RECOGN, V31, P417; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER K, ADV NEURAL INFORM PR, V18; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Zhang J., 1992, P 9 INT MACH LEARN C, P470	13	0	0	0	1	ACTA PRESS ANAHEIM	ANAHEIM	PO BOX 5124, ANAHEIM, CA 92814-5124 USA			978-0-88986-693-5				2007							175	178				4	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	BGW63	WOS:000250957100029		
B	Chen, TS; Chiu, YH; Lin, CC				Chen, Tung-Shou; Chiu, Yung-Hsing; Lin, Chih-Chiang			Fast Nearest Neighbor classification using class-based clustering	PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	6th International Conference on Machine Learning and Cybernetics	AUG 19-22, 2007	Hong Kong, PEOPLES R CHINA	Machine Learning & Cybernet Res Inst, Hebei Univ, IEEE Syst Man & Cybernet Soc, Harbin Inst Technol Shenzhen Grad Sch, Chinese Univ Hong Kong, City Univ Hong Kong, Hong Kong Baptist Univ, Hong Kong Univ Sci & Technol, Int Fuzzy Syst Assoc, Hebei Univ Sci & Technol		classification; Nearest Neighbor; parameter-free; accelerating; clustering	TREES; RULE	Nearest Neighbor Rule (NNR) is a parameter-free classifier which is easy to implement, simple to operate and with high accuracy. However, it is time and memory consuming for large datasets. This study proposed a parameter-free method to accelerate NNR. This method employs a class-based clustering algorithm to divide the training data to several clusters with respective members belonging to the same class. Cluster representations are extracted clustering border data based on the nearest neighbors between the different class clusters. Since the cluster representations are the clustering border data rather than the clustering centers, the predicting accuracy will not be affected by removing a cluster's internal data. In the predicting phase, the nearest neighbor search area is narrowed down by referring to a distance between a testing data and its nearest cluster. Thus the predicting process Is speeded up. In this paper, the performance of the proposed method was evaluated and compared with NNR, K-NNR, and LIBSVM by using 5 benchmark datasets. Experimental results show that the proposed parameter-free classification algorithm is very easy to operate and gives consideration to speed and accuracy.	[Chen, Tung-Shou; Chiu, Yung-Hsing] Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung 404, Taiwan	Chen, TS (reprint author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung 404, Taiwan.						BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; Chang C.-C., LIBSVM LIB SUPPORT V; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen RC, 2006, INT J PATTERN RECOGN, V20, P227, DOI 10.1142/S0218001406004624; Chen TS, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P485; CHEN TS, 2005, P 5 INT C EL BUS HON, P214; Chen TS, 2006, LECT NOTES ARTIF INT, V4114, P278; CHOU CH, 2006, P 18 INT C PATT REC, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dunham M. H., 2003, DATA MINING INTRO AD; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; NEWMAN DJ, UCI RESP MACHINE LEA; Roiger R., 2003, DATA MINING TUTORIAL; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Vapnik V. N., 1995, NATURE STAT LEARNING; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525	18	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0972-3				2007							1894	1898				5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	BGZ09	WOS:000251433403014		
B	Ahanathapillai, V; Soraghan, JJ; Hamilton, DJ; Morison, G		Sanei, S; Chambers, JA; McWhirter, J; Hicks, Y; Constantinides, AG		Ahanathapillai, V.; Soraghan, J. J.; Hamilton, D. J.; Morison, G.			Echocardiographical sequence analysis for the diagnosis of heart wall damage	Proceedings of the 2007 15th International Conference on Digital Signal Processing			English	Proceedings Paper	15th International Conference on Digital Signal Processing	JUL 01-04, 2007	Cardiff, WALES	IEEE UK & Republic Ireland Sect	Cardiff Univ	Principal component analysis (PCA); Independent Component Analysis (ICA); heart disease; echocardiography; wall motion abnormality	INDEPENDENT COMPONENT ANALYSIS; CLASSIFICATION; RECOGNITION	Abnormality in the heart wall motion, caused by common cardiac problems (such as cardiomyopathy, coronary artery diseases, and myocardial ischemia) could eventually lead to complications such as heart failure or heart attack. Various cardiac images can be used to identify such wall motion abnormality and help diagnose the possible presence of damaged tissue in the heart wall. In this paper, an Independent Component Analysis (ICA) technique based system is proposed to diagnose the abnormality in the heart wall. Results clearly indicate that such feature extraction technique could be used effectively to diagnose cardiac problems at an early stage.	Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland	Ahanathapillai, V (reprint author), Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland.						AHANATHAPILLAI V, 2006, P MEDSIP 06 C; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bosch JG, 2005, ACAD RADIOL, V12, P358, DOI 10.1016/j.acra.2004.11.025; Cerqueira MD, 2002, CIRCULATION, V105, P539, DOI 10.1161/hc0402.102975; COOTES T, 1994, IMAGING VISION COMPU, V12, P335; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Kaddoura S., 2002, ECHO MADE EASY; MANIAM J, 2005, SUNWAY ACAD J, V2, P77; Serpen G, 2003, COMPUT BIOL MED, V33, P119, DOI 10.1016/S0010-4825(02)00063-X; Smith L. I., TUTORIAL PRINCIPAL C; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758	14	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-0881-8				2007							155	158				4	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BGQ10	WOS:000249666900040		
S	Chen, TS; Lin, CC; Chiu, YH		Xu, AP; Zhu, H; Chen, SY; Yan, B; Meng, QG; Miao, D; Fang, Y		Chen, Tung-Shou; Lin, Chih-Chiang; Chiu, Yung-Hsing			A new parameter-free classification algorithm based on nearest neighbor rule and K-means for mobile devices	Proceedings of the 6th WSEAS International Conference on Applied Computer Science	ELECTRICAL AND COMPUTER ENGINEERING		English	Proceedings Paper	6th WSEAS International Conference on Applied Computer Science (ACOS 07)	APR 15-17, 2007	Hangzhou, PEOPLES R CHINA	WSEAS		classification; parameter-free; K-means; nearest neighbor rule (NNR); support vector machine (SVM); mobile devices	SYSTEM	This paper proposes a parameter-free classifier which combines K-means with Nearest Neighbor Rule (NNR) - called Incremental Cluster-based Classification (ICC). The classifier is used in low power and capacity devices such as Personal Digital Assistant (PDA) and Smartphone. In the training phase, ICC employs K-means to group instances into several clusters, and then incrementally separates the cluster into two clusters until the cluster members belong to the same type within each cluster. Thus instances have uniform class label within each cluster. In the predicting phase, ICC adopts NNR to find a centroid which is the nearest neighbor of the unlabeled instance. Since the training data are substituted by the cluster centroids; memory and computation requirements are decreased. K-means and NNR are both simple and efficient methods. ICC is easy to redo and have efficient performance and is, hence, suitable for low capacity hardware. In this paper, the prediction accuracy of ICC is evaluated and compared with those of NNR and Support Vector Machine (SVM). Our experimental results show that the prediction accuracy of ICC is comparable to NNR. Although NNR is the easiest to use and redo, it is sensitive to noises and consumes time and memory for a large dataset. Despite the higher accuracy of LIBSVM, it is time-consuming to select an appropriate kernel function and related parameters. ICC is parameter-free, simple to operate and easy to implement. Mobile users can complete their work more conveniently and accurately.	Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung 404, Taiwan	Chen, TS (reprint author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, 129 Sec 3 Sanmin Rd, Taichung 404, Taiwan.						Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chen RC, 2005, LECT NOTES COMPUT SC, V3497, P916; Chen RC, 2005, LECT NOTES COMPUT SC, V3498, P409; Chen T.-S., 2005, P 2005 INT S INT SIG, P405; CHEN TS, 2003, P INT C INF CYB SYST, P1519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNHAM MH, 2003, DATA MINING INTRODUC; Han J., 2000, DATA MINING CONCEPTS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; McQueen J., 1967, 5TH BERK S MATH STAT, V1, P281; NEWMAN DJ, 1998, UCI REPOSITORY MACH; ROIGER RJ, 2003, DATTA MINING TUTORIA; Vapnik V. N., 1995, NATURE STAT LEARNING; Zhao XM, 2004, LECT NOTES COMPUT SC, V3177, P11	14	1	1	2	2	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE	1790-5117		978-960-8457-66-9	ELE COM ENG			2007							152	155				4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BGQ67	WOS:000249798700028		
B	Fayyaz, M; Mujahid, A; Khan, A; Choi, TS; Qbal, N	Yang, JY	Yang, MQ; Zhu, MM; Zhang, Y; Arabnia, HR; Deng, Y; Bourbakis, N		Fayyaz, Mudassir; Mujahid, Adnan; Khan, Asifullah; Choi, Tae-Sun; Qbal, Nadeem.	Yang, JY		G-protein coupled receptor subfamilies prediction based on nearest neighbor approach	PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II			English	Proceedings Paper	7th IEEE International Conference on Bioinformatics and Bioengineering	OCT 14-17, 2007	Boston, MA	IEEE, IEEE Comp Soc, IEEE Engn Med Biol, NSF, Int Soc Intelligent Biol Med, Syst, Man, Cybermet Soc		Fast Fourier Transform; G-Proteins Coupled Receptors; multilevel classification; Nearest Neighbor Classifier	FAST FOURIER-TRANSFORM; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; HIDDEN MARKOV-MODELS; FAMILY CLASSIFICATION; GPCR RECOGNITION; SEQUENCE; DATABASE; PFAM	Hydrophobicity has been considered as the potential measurement for the prediction of G-Proteins coupled receptor subfamilies. In the present work, using Hydrophobicity measure, we make use of Fast Fourier Transform to better analyze the sequence information. In our experiments, we have observed that sequence pattern based information could easily be exploited in the frequency domain using proximity rather than increasing margin of separation between the classes. Based on this information, a simple Nearest Neighbor (NN) method is then used to classify the 17 subfamilies. The proposed proximity based approach has outperformed the one against all implementation of Support Vector Machine (SVM) [Y. Z. Guo, et al, Acta Biochimica et Biophysica Sinica, 37(2005) 759]. Our simple proximity based approach has superior performance in terms of all three measures on both Jackknife and independent data set. For B, C, D and F subfamilies, the Mathew's correlation coefficient and overall accuracy using jackknife test are 0.96 and 96.03 %, while, using independent data set are 0.91 and 91.6 % respectively. The results validate the idea of exploiting sequence pattern based information in the frequency domain using proximity in terms of Euclidian distance. Another side advantage is that instead of training and saving 17 SVM models, we need a single NN classifier.	[Fayyaz, Mudassir; Mujahid, Adnan] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Swabi, Pakistan	Fayyaz, M (reprint author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Swabi, Pakistan.						Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Bateman A, 2004, NUCLEIC ACIDS RES, V32, pD138, DOI 10.1093/nar/gkh121; Bhasin M, 2004, NUCLEIC ACIDS RES, V32, pW383, DOI 10.1093/nar/gkh416; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; COSIC I, 1994, IEEE T BIO-MED ENG, V41, P1101, DOI 10.1109/10.335859; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Eisenhaber F, 1998, TRENDS CELL BIOL, V8, P69; FAUCHERE JL, 1983, EUR J MED CHEM, V18, P369; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; GRANTHAM R, 1974, SCIENCE, V185, P862, DOI 10.1126/science.185.4154.862; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Guo YZ, 2005, ACTA BIOCH BIOPH SIN, V37, P759, DOI 10.1111/j.1745-7270.2005.00110.x; Hiramoto T, 2002, J PROTEIN CHEM, V21, P537, DOI 10.1023/A:1022429722651; Horn F, 2001, NUCLEIC ACIDS RES, V29, P346, DOI 10.1093/nar/29.1.346; ILMAN AG, GOODMAN GILMANS PHAR; Karchin R, 2002, BIOINFORMATICS, V18, P147, DOI 10.1093/bioinformatics/18.1.147; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; Katoh K, 2002, NUCLEIC ACIDS RES, V30, P3059, DOI 10.1093/nar/gkf436; Khan A., 2005, International Journal of Knowledge-Based and Intelligent Engineering Systems, V9; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; Lapinsh M, 2002, PROTEIN SCI, V11, P795, DOI 10.1110/ps.2500102; LUDMILA I, 2004, COMBINING PATTERN CL; Majid A., 2006, INT J HYBRID INTELLI, V3, P109; Mandell AJ, 1997, PHYSICA A, V244, P254, DOI 10.1016/S0378-4371(97)00294-X; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; NOVIC M, 1995, J CHEM INF COMP SCI, V35, P454, DOI 10.1021/ci00025a013; Papasaikas PK, 2004, NUCLEIC ACIDS RES, V32, pW380, DOI 10.1093/nar/gkh431; Papasaikas PK, 2003, SAR QSAR ENVIRON RES, V14, P413, DOI 10.1080/10629360310001623999; Shepherd AJ, 2003, PROTEINS, V50, P290, DOI 10.1002/prot.10290; Sonnhammer ELL, 1998, NUCLEIC ACIDS RES, V26, P320, DOI 10.1093/nar/26.1.320; TRAMANTANO A, 2005, 10 MOST WANTED SOLUT; XU JH, 2005, GENOMICS PROTEOMICS	38	0	0	0	14	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1509-0				2007							1348	1354				7	Engineering, Biomedical; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BHG41	WOS:000252958200217		
B	Mhamdi, F; Elloumi, M		Rolland, C; Collard, M; Pastor, O; Flory, A; Cavarero, JL		Mhamdi, Faouzi; Elloumi, Mourad			A New Survey On knowledge Discovery And Data Mining	PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON RESEARCH CHALLENGES IN INFORMATION SCIENCE: RCIS 2008			English	Proceedings Paper	2nd International Conference on Research Challenges in Information Science	JUN 03-06, 2008	Marrakech, MOROCCO			Data Mining; Knowledge Discovery	PATTERN-CLASSIFICATION; EFFICIENT ALGORITHM; APPROXIMATION; SEQUENCES; NETWORKS; SYSTEM; MODEL	Knowledge discovery is an emerging field where we combine techniques from algorithmics, artificial intelligence, mathematics and statistics to deal with the theoretical and practical issues of extracting knowledge, i.e., new concepts or concept relationships hidden in volumes of raw data. Knowledge discovery offers the capacity to automate complex search and data analysis tasks. Data mining is the main phase in the knowledge discovery process. It consists in extracting nuggets of knowledge, i.e., pertinent patterns, pattern correlations, estimation or rules, hidden in bodies of data. The extracted nuggets of knowledge will be used in the verification of hypothesis or the prediction and explanation of knowledge. In this paper, we present a new survey on Knowledge Discovery and Data Mining (KDD).	[Mhamdi, Faouzi; Elloumi, Mourad] Higher Sch Sci & Technol Tunis, Res Unit Technol Informat & Commun, Tunis 1008, Tunisia	Mhamdi, F (reprint author), Higher Sch Sci & Technol Tunis, Res Unit Technol Informat & Commun, 5 Ave Taha Hussein, Tunis 1008, Tunisia.	Faouzi.Mhamdi@ensi.rnu.tn; Mourad.Elloumi@fsegt.rnu.tn					AARNODT A, 1994, AI COMMUN, V7, P39; Agrawal R, 1994, P 20 INT C VER LARG, P487; Ankerst M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347124; Attardi G., 1999, P THAI 99 EUR S TEL, P105; BANDYOPADHYAY S, 1995, PATTERN RECOGN LETT, V16, P801, DOI 10.1016/0167-8655(95)00052-I; BECKMANN N, 1990, P INT C GEOGR INF SY; Berkhin P., 2002, SURVEY CLUSTERING DA; BERRY MJA, 1997, DATA MINING MARKETIN; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOUDJELOUD L, 2005, PAC AS C KNOWL DISC; BOUGUETTAYA A, 1996, IEEE T KNOWLEDGE DAT, V8; BOUROCHE J, 2002, ANAL DONNEES; Brachman RJ, 1996, ADV KNOWLEDGE DISCOV; Breiman L., 1984, CLASSIFICATION REGRE; BRUHA I, 2000, P WORKSH POST PROC M, P20; Brusic V, 1999, KNOWL ENG REV, V14, P257, DOI 10.1017/S0269888999003069; CAILIEZ F, 1976, INTRO ANAL DONNEES; CARLIN BP, 1995, J ROY STAT SOC B MET, V57, P473; Celeux G., 1989, CLASSIFICATION AUTOM; CHEESSEMAN P, 1996, ADV KNOWLEDGE DISCOV; Chen M.-H., 2000, MONTE CARLO METHODS; Cole R.M., 1998, THESIS U W AUSTR AUS; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2000, INTOR SUPPORT VECTOR; CUSTSEM BV, 1994, CLASSIFICATION DISSI; DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364; Devroye L., 1996, PROBABILISTIC THEORY; Draper NR, 1998, WILEY SERIES PROBABI; DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115; EICK SG, 1997, DATA MINING KNOWLEDG, V1; ELLOUMI M, 2002, KNOWLEDGE BASED SYST, V15; Engels R., 1998, P 13 EUR C ART INT, P430; ERRAY W, 2006, P EGC 06 LILL FRANC; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Ester M., 1995, P 1 INT C KNOWL DISC, P94; Estivill-Castro V., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886); Falkenauer E., 1998, GENETIC ALGORITHMS G; FAMILI A, 1997, INTELL DATA ANAL, V1, P23; Fayyad U., 1996, DATA MINING KNOWLEDG; FAYYAD U, 2004, P PACIFIC KNOWL DISC, V2; Fayyad U. M., 2001, INFORM VISUALIZATION; FELDMAN R, 2002, LINK ANAL CURRENT ST; Fox J., 1997, APPL REGRESSION ANAL; FRALEY C, 1999, MCLUST SQFTWARE MODE; Frawley W., 1992, AI MAGAZINE      FAL, P213; Freitas AA, 2002, ADV EVOLUTIONARY COM; FRITZKE B, 1994, NEURAL NETWORKS J, V7; Gascuel O, 1999, ST CLASS DAT ANAL, P58; Goebel M., 1999, ACM SIGKDD EXPLORATI, V1, P20, DOI 10.1145/846170.846172; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Guha S., 1998, P ACM SIGMOD INT C M, P73, DOI 10.1145/276304.276312; Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967; GUYON O, 1996, ADV KNOWLEDGE DISCOV, P181; Han EH, 1999, THESIS U MINNESOTA; Han J., 2006, DATA MINING CONCEPTS; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Haykim S, 1994, NEURAL NETWORKS COMP; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; HILBORN R, 1997, ECOLOGIST DETECTIVE; HOLLAND JH, 1975, ADAPTATION NATURAL A; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Jain AK, 1988, ALGORITHMS CLUSTERIN, P55; Jensen D., 1998, AAAI FALL S AI LINK; Jong KAD, 1993, MACH LEARN, V13, P161; JOURDAN L, 2003, THESIS U SCI TECHNOL; Kantardzic M., 2002, DATA MINING CONCEPTS; Karypis G., 1999, CHAMELEON HIERARCHIC, P68; Kaufman L., 1990, FINDING GROUPS DATA; Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847; Kelly JD, 1991, P 12 INT JOINT C ART, P645; KHOSHGOFTAAR TM, 1999, RECENT ADV RELIABILI; KODRATOFF Y, 1998, SIGNAUX J, P38; Kolatch E., 2001, CLUSTERING ALGORITHM; Kolodner J. L., 1993, CASE BASED REASONING; KOLODNER JL, 1992, ARTIF INTELL REV, V6, P3, DOI 10.1007/BF00155578; KRIEGEL HP, 1990, P INT C GEOGR INF SY; KWOK TY, 1998, P 14 INT C PATT REC; Larose D T., 2004, DISCOVERING KNOWLEDG; LEHN R, 2004, MESURES QUALITE FOUI, P141; LENCA P, 2004, MESURES QUALITE FOUI, P219; Leng B, 1994, J Comput Biol, V1, P25; Lent B, 1997, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.1997.581756; LI W, 2001, CAYAR ACCURATE EFFIC; LIEBER J, 2002, P EUR C ART INT; Liu B., 1998, INTEGRATING CLASSIFI; LIU H, 1998, SERIES SPRINGER INT; Mandic D. P., 2001, RECURRENT NEURAL NET; Mitchelle T. M., 1997, DECISION TREE LEARNI, P52; Ng R., 1994, P 20 INT C VER LARG, P144; OVERTON CG, 1998, COMPUTATIONAL METHOD, P65; PIATETSKYSHAPIR.G, 2006, WHAT ARE GRAND CHALL, V8; POULET F, 2002, INT J IMAGE GRAPHICS, V2, P127, DOI 10.1142/S0219467802000524; POULET F, 2005, RNTIE4; Press W. H., 1988, NUMERICAL RECIPES C; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RAKOTOMALALA R, 2005, SPRINGER LECT NOTES; Ripley BD, 1996, PATTERN RECOGNITION; Robert C. P., 2004, MONTE CARLO STAT MET; ROBERT CP, 2001, BAASIAN CHOICE; Ryden T., 2004, HIDDEN MARKOV MODELS; SAVARESI S, 2001, P SIAM ICDM 01 CHIC; Savaresi SM, 2002, SIAM PROC S, P299; SCOTT DW, 1992, MULFIVARIATE DENSITY; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; SKALAK DB, 1994, P AAAI 93 CAS BAS RE, P64; Smola A. J., 1996, REGRESSION ESTIMATIO; SOIBELMAN L, 2002, J COMPUTING CIVIL EN; Spence R., 2001, INFORM VISUALIZATION; Steinbach M., 2000, COMPARISON DOCUMENT; Tan P.-N., 2005, INTRO DATA MINING PE; Thelwall M., 2004, LINK ANAL INFORM SCI; THORNE JL, 1998, MOL BIOL EVOL, V15, P647; TOIVONEN H, 1995, ECML 99 WORKSH STAT; TSATSOULIS C, INT J QUALITY SAFETY, V12, P24; UTANS J, 1999, P AI APPL WALL STREE, P35; Vapnik V, 1997, ADV NEUR IN, V9, P281; VOORHEES EM, 1986, INFORM PROCESS MANAG, V22, P465, DOI 10.1016/0306-4573(86)90097-X; Wallace C. S., 1994, Proceedings of the 7th Australian Joint Conference on Artificial Intelligence. Artificial Intelligence. AI'94. Sowing the Seeds for the Future; WANG J, 2005, HARMONY EFFICIENTLY; Wang J T L, 2005, DATA MINING BIOINFOR; Wang JTL, 1999, J COMPUT BIOL, V6, P209, DOI 10.1089/cmb.1999.6.209; Wang J. T. L., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347157; WANG JTL, 1994, NUCLEIC ACIDS RES, V22, P2769, DOI 10.1093/nar/22.14.2769; WILLET P, 1990, PARALLEL DATABASE PR; WINSTON PH, 1992, ARTIF INTELL, P423; WITTEN I, 2006, DATAMINING PRACTICAL; Ye Nong, 2001, P 2 IEEE SMC INF ASS, P1; Yin MM, 2004, INFORM SCIENCES, V163, P201, DOI 10.1016/j.ins.2003.03.016; Yin X, 2003, CPAR CLASSIFICATION; YU LTH, 2003, EUR WORKSH DAT MIN T; YUAN Y, 1995, FUZZY SETS SYSTEMS J, V25, P139; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R; ZIGHED D, 2002, DATA MINING	136	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1677-6				2007							427	432				6	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BJC11	WOS:000264665900048		
B	Cheng, HB; Tan, PN; Jin, R		Apte, C; Liu, B; Parthasarathy, S; Skillicorn, D		Cheng, Haibin; Tan, Pang-Ning; Jin, Rong			Localized Support Vector Machine and Its Efficient Algorithm	PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING			English	Proceedings Paper	7th SIAM International Conference on Data Mining	APR 26-28, 2007	Minneapolis, MN	Amer Stat Assoc			CLASSIFICATION	Nonlinear Support Vector Machines employ sophisticated kernel functions to classify data sets with complex decision surfaces. Determining the right parameters of such functions is not only computationally expensive, the resulting models are also susceptible to overfitting due to their large VC dimensions. Instead of fitting a nonlinear model, this paper presents a framework called Localized Support Vector Machine (LSVM), which builds multiple linear SVM models from the training data. Since each model is designed to classify a particular test example, it has high computational cost. To overcome this limitation, we propose an efficient implementation of LSVM, termed Profile SVM (PSVM). PSVM partitions the training examples into clusters and builds a separate linear SVM model for each cluster. Our empirical results show that (1) Both LSVM and PSVM outperform nonlinear SVM on the majority of the evaluated data sets; and (2) PSVM achieves comparable accuracy as LSVM but with significant computational savings.								Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Burges C. J. C., 1998, KNOWLEDGE DISCOVERY, V2; Chang C.C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gunn SR, 1997, SUPPORT VECTOR MACHI; HECHENBICHLER K, 2006, SFB, V386; JOACHIMS T, 1999, INT C MACH LEARN SAN; Newman D., 1998, UCI REPOSITORY MACHI; Platt JC, 2000, ADV NEUR IN, V12, P547; Zhang H, 2006, IEEE C COMP VIS PATT	10	1	2	0	0	SIAM	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA			978-0-898716-30-6				2007							461	466				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematics, Applied	Computer Science; Mathematics	BUG50	WOS:000289220200045		
B	Ghosh, AK		Pal, P		Ghosh, Anil K.			Adaptive nearest neighbor classifier	Proceedings of the Sixth International Conference on Advances in Pattern Recognition			English	Proceedings Paper	6th International Conference on Advances in Pattern Recognition	JAN 02-04, 2007	Calcutta, INDIA	Adobe, GM R&D, India Sci Lab, Reserve Bank India	Indian Stat Inst	Bayesian strength function; cross-validation; posterior probability; prior distribution; sequential technique		In nearest neighbor classification, one normally uses cross-validation type methods to estimate the optimum value of k, and that estimated value is used for classifying all observations. However, in classification problems, in addition to depending on the training sample, a good choice of k depends on the specific observation to be classified. In this article we propose an adaptive nearest neighbor classification technique, where the value of k is selected depending on the distribution of competing classes in the vicinity of the observation to be classified. Results on some simulated and benchmark examples are presented to show the utility of the proposed method.	Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India	Ghosh, AK (reprint author), Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India.						Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J., 1994, 113 STANF U STAT DEP; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hodges J., 1951, 4 USAF SCH AV MED, P261; Hopcroft J. E., 1974, DESIGN ANAL COMPUTER, V1st; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Schapire RE, 1998, ANN STAT, V26, P1651; Silverman BW, 1986, DENSITY ESTIMATION S; Tibshirani R, 1993, INTRO BOOTSTRAP	18	0	0	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			978-981-270-553-2				2007							281	284				4	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BFY86	WOS:000245470300046		
S	Temel, T; Hallam, J		Ardil, C		Temel, Turgay; Hallam, John			An Evaluation of Algorithms for Single-Echo Biosonar Target Classification	PROCEEDINGS OF WORLD ACADEMY OF SCIENCE, ENGINEERING AND TECHNOLOGY, VOL 1	Proceedings of World Academy of Science Engineering and Technology		English	Proceedings Paper	Conference of the World-Academy-of-Science-Engineering-and-Technology	JAN 12-14, 2005	London, ENGLAND	World Acad Sci Engn & Technol		Classification; neuro-spike coding; non-parametric model; parametric model; Gaussian mixture; EM algorithm		A recent neuro-spiking coding scheme for feature extraction from biosonar echoes of various plants is examined with a variety of stochastic classifiers. Feature vectors derived are employed in well-known stochastic classifiers, including nearest-neighborhood, single Gaussian and a Gaussian mixture with EM optimization. Classifiers' performances are evaluated by using cross-validation and bootstrapping techniques. It is shown that the various classifers perform equivalently and that the modified preprocessing configuration yields considerably improved results.	[Temel, Turgay] Univ Edinburgh, IPAB, Sch Informat, Edinburgh EH9 3JZ, Midlothian, Scotland	Temel, T (reprint author), Univ Edinburgh, IPAB, Sch Informat, Kings Bldg, Edinburgh EH9 3JZ, Midlothian, Scotland.	ttemel@inf.ed.ac.uk; john@mip.sdu.dk					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bishop C.M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demster A. P., 1977, J ROYAL STAT SOC B, V39, P1; Kuc R, 2001, J ACOUST SOC AM, V110, P2198, DOI 10.1121/1.1401741; Kuc R, 1997, IEEE J OCEANIC ENG, V22, P616, DOI 10.1109/48.650828; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; McKerrow P, 2001, IEEE SENS J, V1, P245, DOI 10.1109/7361.983464; MULLER R, 2000, P ICSC S INT SYST AP, P915; Muller R, 2003, NETWORK-COMP NEURAL, V14, P595, DOI 10.1088/0954-898X/14/3/311; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Therrien C.W, 1989, DECISION ESTIMATION	12	0	0	0	0	WORLD ACAD SCI, ENG & TECH-WASET	CANAKKALE	PO BOX 125, CANAKKALE, 17100, TURKEY	1307-6884			PROC WRLD ACAD SCI E			2007	1						140	143				4	Computer Science, Artificial Intelligence; Mathematics, Applied	Computer Science; Mathematics	BII11	WOS:000259631100034		
B	Su, GS; Lei, WJ; Zhang, XF		Jing, G; Gao, J; Zhou, A; Gou, P		Su Guoshao; Lei Wenjie; Zhang Xiaofei			Rockburst prediction method based on K-nearest neighbor pattern recognition	Progress in Mining Science and Safety Technology, Pts A and B			English	Proceedings Paper	International Symposium on Mining Science and Safety Technology	APR 16-19, 2007	Jiaozuo, PEOPLES R CHINA	Henan Polytech Univ, China Occupat Safety & Hlth Assoc, China Coal Assoc, Japan Muroran Inst Technol, Japan Kyushu Univ, Poland Slaska Univ, Mining Fac Penn Univ, France Lille Univ, TAFE, Australia Cent Gippsland Inst, Polland Res Inst Labor Protect, Int Journal Occupat Safety & Ergon		rockburst; mining; k-Nearest Neighbor method; pattern recognition		Rockburst is a geological disaster induced by mining at great depth. How to predict rockburst effectively for safety during mining has become an unresolved key problem. Because of poor understanding of the mechanism and influence factors of rockbust, it is very difficult to give accurate prediction using conventional methods. A new method based on k-Nearest Neighbor pattern recognition tech, which is one of the simplest and most effective tools in the field of pattern recognition, is proposed. First, the historical instances with influence factors induced rockbust are collected into database. Then, k historical instances whose influence factors similar to that of new instance are selected through scanning the database based on the neighbor similarity function. Finally, roburst risk of the new instance can be recognized by majority vote among the k nearest historical instances. The method gives accurate rockburst predictions under novel conditions when mining at great depth. The results of case studies at deep gold mines in South African show that this method is scientific, feasible, and promising.	Guangxi Univ, Dept Civil & Architecture Engn, Nanning 530004, Peoples R China	Su, GS (reprint author), Guangxi Univ, Dept Civil & Architecture Engn, Nanning 530004, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Feng X.T., 1994, T NONFERR METAL SOC, V4, P9; [冯夏庭 Feng Xiating], 2002, [东北大学学报. 自然科学版, Journal of Northeastern University], V23, P57; FENG XT, 2000, INTRO INTELLIGENT RO, P294; Fujii Y, 1997, INT J ROCK MECH MIN, V34, P85, DOI 10.1016/S0148-9062(96)00030-7; Gu Shun-de, 2000, Journal of Shanghai Medical University, V27, P108; He J., 2000, P PRICAI 2000 INT WO, P24; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Linkov AM, 1996, INT J ROCK MECH MIN, V33, P727, DOI 10.1016/0148-9062(96)00021-6; Mansurov VA, 2001, INT J ROCK MECH MIN, V38, P893, DOI 10.1016/S1365-1609(01)00055-7; SHASHA K, 2005, J HENAN NORMAL U, V33, P134; SIMIVASAN C, 1997, J ROCK MECH MINING S, V34, P1001; Wang YG, 1998, J MATER SCI LETT, V17, P493, DOI 10.1023/A:1006536612619; Yang KY, 2007, INFORM COMPUT, V205, P65, DOI 10.1016/j.ic.2006.08.004; ZHANG BY, 2006, COMPUTER ENG APPL, V6, P7; ZHANG G, 1992, P 3 NAT C ROCK DYN W, P422	16	0	0	0	5	SCIENCE PRESS BEIJING	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100707, PEOPLES R CHINA			978-7-03-018737-6				2007							840	845				6	Mining & Mineral Processing	Mining & Mineral Processing	BGM26	WOS:000248332000146		
S	Garcia, V; Sanchez, J; Mollineda, R		Rueda, L; Mery, D; Kittler, J		Garcia, Vicente; Sanchez, Jose; Mollineda, Ramon			An empirical study of the behavior of classifiers on imbalanced and overlapped data sets	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		imbalance; overlapping; classifiers; performance measures		Class imbalance has been reported as an important obstacle to apply traditional learning algorithms to real-world domains. Recent investigations have questioned whether the imbalance is the unique factor that hinders the performance of classifiers. In this paper, we study the behavior of six algorithms when classifying imbalanced, overlapped data sets under uncommon situations (e.g., when the overall imbalance ratio is different from the local imbalance ratio in the overlap region). This is accomplished by analyzing the accuracy on each individual class, thus devising how those situations affect the majority and minority classes. The experiments corroborate that overlap is more important than imbalance for the classification performance. Also, they show that the classifiers behave differently depending on the nature of each model.	[Garcia, Vicente] Inst Tecnol Toluca, Lab Reconocimiento Patrones, Metepec 52140, Mexico	Garcia, V (reprint author), Inst Tecnol Toluca, Lab Reconocimiento Patrones, Av Tecnol S-N, Metepec 52140, Mexico.			Sanchez Garreta, Jose Salvador/0000-0003-1053-4658; Garcia, Vicente/0000-0003-2820-2918			Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; BATISTA GE, 2005, P 6 INT S INT DAT AN, P24; Bishop C.M., 1995, NEURAL NETWORKS PATT; Buhmann M. D., 2003, RADIAL BASIS FUNCTIO; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Duda R O, 2001, PATTERN CLASSIFICATI; Frank E., 2005, DATA MINING PRACTICA; JAPKOWICZ N, 2002, INTELL DATA ANAL, V6, P40; Jo T., 2004, ACM SIGKDD EXPLORATI, V6, P40, DOI 10.1145/1007730.1007737; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Orriols A, 2005, P 2005 WORKSH GEN EV, P74, DOI 10.1145/1102256.1102271; Prati R. C., 2004, P 3 MEX INT C ART IN, P312; Quinlan J. R., 1993, C4 5 PROGRAMS MACH L; Vapnik V, 2006, ESTIMATION DEPENDENC	16	13	13	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						397	406				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900042		
S	Hernandez-Rodriguez, S; Martinez-Trinidad, JF; Carrasco-Ochoa, JA		Rueda, L; Mery, D; Kittler, J		Hernandez-Rodriguez, Selene; Martinez-Trinidad, J. Fco.; Ariel Carrasco-Ochoa, J.			Fast k most similar neighbor classifier for mixed data based on a tree structure	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		nearest neighbors rule; fast k-most similar neighbors search; mixed data	SEARCH ALGORITHMS; NEAREST	In this work, a fast k most similar neighbor (k-MSN) classifier for mixed data is presented. The k nearest neighbor (k-NN) classifier has been a widely used nonparametric technique in Pattern Recognition. Many fast k-NN classifiers have been developed to be applied on numerical object descriptions, most of them based on metric properties to avoid object comparisons. However, in some sciences as Medicine, Geology, Sociology, etc., objects are usually described by numerical and non numerical features (mixed data). In this case, we can not assume the comparison function satisfies metric properties. Therefore, our classifier is based on search algorithms suitable for mixed data and non-metric comparison functions. Some experiments and a comparison against other two fast k-NN methods, using standard databases, are presented.	[Hernandez-Rodriguez, Selene; Martinez-Trinidad, J. Fco.; Ariel Carrasco-Ochoa, J.] Natl Inst Astrophys Opt & Elect, Puebla 72840, Mexico	Hernandez-Rodriguez, S (reprint author), Natl Inst Astrophys Opt & Elect, Luis Enr Erro 1,Sta Maria Tonantzintla, Puebla 72840, Mexico.						Blake C. L., 1998, UCI REPOSITORY MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1975, IEEE T COMPUT, V24, P743; GARCIASERRANO JF, 1999, 3 EUR C PRINC PRACT, P354; Gomez-Ballester E, 2006, PATTERN RECOGN, V39, P171, DOI 10.1016/j.patcog.2005.06.007; Gomez-Ballester E, 2003, LECT NOTES COMPUT SC, V2905, P456; KALANTARI I, 1983, IEEE T SOFTWARE ENG, V9, P631, DOI 10.1109/TSE.1983.235263; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Mico L, 1996, PATTERN RECOGN LETT, V17, P731, DOI 10.1016/0167-8655(96)00032-3; Moreno-Seco F, 2003, LECT NOTES COMPUT SC, V2905, P322; Omachi S., 2000, Systems and Computers in Japan, V31; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; YONGSHENG C, 2006, FAST VERSATILE ALGOR	15	3	3	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						407	416				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900043		
S	Chang, HY; Sun, CS		Rueda, L; Mery, D; Kittler, J		Chang, Hsin-Yun; Sun, Chung-Shan			A novel hybrid Taguchi-Grey-based method for feature subset selection	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		feature subset selection; taguchi methods; grey-based nearest neighbor rule; pattern classification	ALGORITHMS; CLASSIFICATION	In this paper, a novel hybrid Taguchi-Grey-based method for feature subset selection is proposed. The two-level orthogonal array is employed in the proposed method to provide a well-organized and balanced comparison of two levels of each feature (i.e., the feature is selected for pattern classification or not) and interactions among all features in a specific classification problem. That is, this two-dimensional matrix is mainly used to reduce the feature subset evaluation efforts prior to the classification procedure. Accordingly, the grey-based nearest neighbor rule and the signal-to-noise ratio (SNR) are used to evaluate and optimize the features of the specific classification problem. In this manner, important and relevant features can be identified for pattern classification. Experiments performed on different application domains are reported to demonstrate the performance of the proposed hybrid Taguchi-Grey-based method. It can be easily seen that the proposed method yields superior performance and is helpful for improving the classification accuracy in pattern classification.	[Chang, Hsin-Yun] Chin Min Inst Technol, Dept Business Adm, Toufen 305, Miaoli, Taiwan	Chang, HY (reprint author), Chin Min Inst Technol, Dept Business Adm, 110 Hsueh Fu Rd, Toufen 305, Miaoli, Taiwan.						AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C. L., 1998, UCI REPOSITORY MACH; Brassard G., 1996, FUNDAMENTALS ALGORIT; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1990, NEAREST NEIGHBOR NN; Deng Julong, 1989, Journal of Grey Systems, V1; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; Deng Julong, 1989, Journal of Grey Systems, V1; Doak J., 1992, EVALUATION FEATURE S; Duda R. O., 1973, PATTERN CLASSIFICATI; Hall M. A., 1998, THESIS U WAIKATO; Huang CC, 2006, APPL INTELL, V25, P243, DOI 10.1007/s10489-006-0105-0; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi Genichi, 1986, INTRO QUALITY ENG; WU Y, 2000, TAGUCHI METHODS ROBU, P7	23	0	0	0	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						457	465				9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900048		
S	Diaz, G; Gonzalez, F; Romero, E		Rueda, L; Mery, D; Kittler, J		Diaz, Gloria; Gonzalez, Fabio; Romero, Eduardo			Infected cell identification in thin blood images based on color pixel classification: Comparison and analysis	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	12th Iberoamerican Congress on Pattern Recognition	NOV 13-16, 2007	Valparaiso, CHILE	Univ Santiago Chile, Dept Indormat Ingn, Tech Univ Feder Santa Maria, Dept Informat Tech		cell detection; supervised classification; color spaces; performance comparison		Malaria is an infectious disease which is mainly diagnosed by visual microscopical evaluation of Giemsa-stained thin blood films using a differential analysis of color features. This paper presents the evaluation of a color segmentation technique, based on standard supervised classification algorithms. The whole approach uses a general purpose classifier, which is parameterized and adapted to the problem of separating image pixels into three different classes: parasite, blood red cells and background. Assessment included not only four different supervised classification techniques - KNN, Naive Bayes, SVM and MLP - but different color spaces -RGB, normalized RGB, HSV and YCbCr-. Results show better performance for the KNN classifiers along with an improving feature characterization in the normalized RGB color space.	[Diaz, Gloria; Gonzalez, Fabio; Romero, Eduardo] Univ Nacl Colombia, Bioingenium Res Grp, Bogota, Colombia	Diaz, G (reprint author), Univ Nacl Colombia, Bioingenium Res Grp, Bogota, Colombia.	gmdiazc@unal.edu.co; fagonzalezo@unal.edu.co; edromero@unal.edu.co	Gonzalez, Fabio/B-9502-2008; 	Gonzalez, Fabio/0000-0001-9009-7288; Diaz, Gloria/0000-0003-1028-9111			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daskalaki S, 2006, APPL ARTIF INTELL, V20, P381, DOI 10.1080/08839510500313653; Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0; DISTEFANO L, 1999, P 10 INT C IM AN PRO; Fix E., 1951, 2149004 USAF SCH AV; HALIM S, 2006, P IEEE INT C CONTR A; *OPS, 1998, 1 PAN AM ORG HLTH; Platt J., 1998, ADV KERNEL METHODS S; Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; SIO SWS, 2007, MICROBIOLOGICAL METH, V68; Tek F.B., 2006, P BRIT MACH VIS C; *WMR UNICEF, 2005, WORLD MAL REP; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	14	5	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-76724-4	LECT NOTES COMPUT SC			2007	4756						812	821				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHF58	WOS:000252725900084		
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Gpos-PLoc: an ensemble classifier for predicting subcellular localization of Gram-positive bacterial proteins	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article						amphiphilic pseudo amino acid composition; fusion; gene ontology; Gram-positive; OET-KNN rule	AMINO-ACID-COMPOSITION; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; LOCATION PREDICTION; NEGATIVE BACTERIA; SORTING SIGNALS; GENE ONTOLOGY; FOLDING TYPES	A statistical analysis indicated that, of the 35 016 Gram-positive bacterial proteins from the recent Swiss-Prot database, similar to 57% of these entries are without subcellular location annotations. In the gene ontology database, the corresponding percentage is similar to 67%, meaning the percentage of proteins without subcellular component annotations is even higher. With the avalanche of gene products generated in the post-genomic era, the number of such location-unknown entries will continuously increase. It is highly desired to develop an automated method for timely and accurately identifying their subcellular localization because the information thus obtained is very useful for both basic research and drug discovery practice. In view of this, an ensemble classifier called 'Gpos-PLoc' was developed for predicting Gram-positive protein subcellular localization. The new predictor is featured by fusing many basic classifiers, each of which was engineered according to the optimized evidence-theoretic K-nearest neighbors rule. As a demonstration, tests were performed on Gram-positive proteins among the following five subcellular location sites: (1) cell wall, (2) cytoplasm, (3) extracell, (4) periplasm and (5) plasma membrane. To eliminate redundancy and homology bias, only those proteins which have < 25% sequence identity to any other in a same subcellular location were allowed to be included in the benchmark datasets. The overall success rates thus achieved by Gpos-PLoc were > 80% for both jackknife cross-validation test and independent dataset test, implying that Gpos-PLoc might become a very useful vehicle for expediting the analysis of Gram-positive bacterial proteins. Gpos-PLoc is freely accessible to public as a web-server at http://202.120.37.186/bioinf/Gpos/. To support the need of many investigators in the relevant areas, a downloadable file is provided at the same website to list the results identified by Gpos-PLoc for 31898 Gram-positive bacterial protein entries in Swiss-Prot database that either have no subcellular location annotation or are annotated with uncertain terms such as 'probable', 'potential', 'perhaps' and 'by similarity'. Such large-scale results will be updated once a year to include the new entries of Gram-positive bacterial proteins and reflect the continuous development of Gpos-PLoc.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 1954 Hua Shan Rd, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2004, NUCLEIC ACIDS RES, V32, P115; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 2000, NUCLEIC ACIDS RES, V25, P31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; Chou KC, 2006, BIOCHEM BIOPH RES CO, V339, P1015, DOI 10.1016/j.bbrc.2005.10.196; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Liu H, 2005, BIOCHEM BIOPH RES CO, V338, P1005, DOI 10.1016/j.bbrc.2005.10.046; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Shafer G., 1976, MATH THEORY EVIDENCE; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565; Zuber B, 2006, J BACTERIOL, V188, P6652, DOI 10.1128/JB.00391-06	53	103	105	1	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126			PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	JAN	2007	20	1					39	46		10.1093/protein-gzl053		8	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	139KR	WOS:000244431200006	17244638	
S	Dion, J; Kumar, M; Ramuhalli, P		Thompson, DO; Chimenti, DE		Dion, Juanita; Kumar, Mrityunjay; Ramuhalli, Pradeep			Multi-sensor data fusion for high-resolution material characterization	Review of Progress in Quantitative Nondestructive Evaluation, Vols 26A and 26B	AIP CONFERENCE PROCEEDINGS		English	Proceedings Paper	33rd Annual Review of Progress in Quantitative Nondestructive Evaluation	JUL 30-AUG 04, 2006	Portland, OR			material characterization; classifier; classifier fusion; eddy current; ultrasound	CLASSIFIERS	In typical nondestructive evaluation (NDE) of materials, the material tinder test is inspected using one or more NDE techniques to evaluate its condition. However, measurement data from different inspection techniques are often complementary in nature and higher accuracy may be achieved by fusing information from these different inspection modes. This paper proposes a classifier-fusion based approach to combine multifrequency eddy current and ultrasound data for material characterization. The proposed algorithm uses a hierarchy of classifiers to determine the material state (e.g. stress, heat treatment etc.) and level of exposure to this condition, with classifier fusion achieved through a majority-voting rule. Preliminary results on applying the proposed algorithm to data from Inconel 600 samples are presented.	Michigan State Univ, Dept Elect & Comp Engn, Nondestruct Evaluat Lab, E Lansing, MI 48824 USA	Dion, J (reprint author), Michigan State Univ, Dept Elect & Comp Engn, Nondestruct Evaluat Lab, E Lansing, MI 48824 USA.						Bernardo J. M., 1996, BAYESIAN THEORY; Breiman L, 1993, CLASSIFICATION REGRE; Chen C. H., 1994, Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis (Cat. No.94TH8007), DOI 10.1109/TFSA.1994.467311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R O, 2001, PATTERN CLASSIFICATI; HAYKIN S, 1999, NEURAL NETWORKS COMP, P199; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Jain A. K., 1988, FUNDAMENTALS DIGITAL; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KUMAR A, 2003, IEEE INSIGHT, V45; KURZYNSKI MW, 1989, PATTERN RECOGN LETT, V10, P39, DOI 10.1016/0167-8655(89)90016-0; OZA N, 2005, SPRINGER LECT NOTES, V3541; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SIEWERT TA, 1999, ASTM STP, V1380; Vapnik V. N., 1995, NATURE STAT LEARNING; YIM J, 1994, P 3 ANN MIDW EL C AP, P10	17	2	2	0	4	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		978-0-7354-0399-4	AIP CONF PROC			2007	894						1189	1196				8	Materials Science, Characterization & Testing; Optics; Physics, Multidisciplinary	Materials Science; Optics; Physics	BGB17	WOS:000245889000153		
B	Ximing, SM; Yu, XP			Alfred University	Sun, Ximing; Yu, Xiaopeng			Collaborative filtering for recommendation using DAKNNS	Sixth Wuhan International Conference on E-Business, Vols 1-4: MANAGEMENT CHALLENGES IN A GLOBAL WORLD			English	Proceedings Paper	6th Wuhan International Conference on E-Business	MAY 26-27, 2007	Wuhan, PEOPLES R CHINA	China Univ Geosci, CICER, Journal Informat Technol, Int Journal Mobile Learning & Org, Int Journal Revenue Management, Int Journal Elect Markets, Int Journal Networking & Virtual Org, Int Journal Biomed Engn & Technol, Electr Govt, Int Journal		k-nearest neighbor searching; collaborative filtering; recommendation system; e-commerce	NEAREST; ALGORITHM; CLASSIFICATION; SEARCH; RULE	Recommendation is to offer information which fits user's interests and tastes to provide better services and to reduce information overload. It recently draws attention upon Internet users and information providers. Collaborative filtering (CF) is one of the widely used methods for recommendation. It recommends an item to a user based on the reference users' preferences for the target item or the target user's preferences for the reference items. In this paper, we propose an adaptive depth-first k-nearest neighbor search (DAKNNS) based collaborative filtering method. The algorithm can find k nearest neighbors of the object user in a small hypersphere in order to improve the efficiencies and forecast the rating. The hypersphere's. size can be automatically determined. It requires a quite moderate preprocessing effort, and the cost to classify an object user is O(alpha d)+O(k)(1<=alpha<<n). Our experiment shows the algorithm performance is superior to other known algorithms.	Wuhan Univ, Econ & Management Sch, Wuhan 430072, Peoples R China							Al Aghbari Z, 2005, DATA KNOWL ENG, V52, P333, DOI 10.1016/j.datak.2004.06.015; Batko M., 2004, Databases, Information Systems, and Peer-to-Peer Computing. Second International Workshop, DBISP2P 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol.3367); BRODER AJ, 1986, OATTERN RECOGNITION, V23, P171; BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donahue M, 1996, PROC CVPR IEEE, P7, DOI 10.1109/CVPR.1996.517046; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761; KUAN J, 1997, INT C INF COMM SIGN, P9; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Samet H., 2003, Proceedings 12th International Conference on Image Analysis and Processing; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; XIAOPENG Y, 2005, INT C SERVICES SYSTE, P1016; YU C, 2002, HIGH DIMENSIONAL IND, V2341, P5; ZHANG B, 2004, IEEE T PATTERN ANAL, V26, P116	17	0	0	0	1	ALFRED UNIV	ALFRED	ONE SAXON DR, ALFRED, NY 14802 USA			978-0-9604962-9-7				2007							1578	1584				7	Business; Computer Science, Information Systems; Management; Operations Research & Management Science	Business & Economics; Computer Science; Operations Research & Management Science	BGO56	WOS:000249025701101		
J	Cen, HY; He, Y				Cen, Haiyan; He, Yong			Theory and application of near infrared reflectance spectroscopy in determination of food quality	TRENDS IN FOOD SCIENCE & TECHNOLOGY			English	Review							PARTIAL LEAST-SQUARES; ORTHOGONAL SIGNAL CORRECTION; ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; MULTIVARIATE CALIBRATION; NIR-SPECTROSCOPY; PATTERN-RECOGNITION; INSTRUMENT STANDARDIZATION; NONDESTRUCTIVE MEASUREMENT; PRINCIPAL COMPONENT	Near infrared reflectance spectroscopy (NIRS) is a non-destructive and rapid technique applied increasingly for food quality evaluation in recent years. It provides us more information to research the quality of food products. This review intends to give an overview of the type of information that can be obtained based on some developed theory and food research of NIRS. It includes the principle of NIRS technique, the specific techniques with chemometrics for data pre-processing methods, qualitative and quantitative analysis and model transfer, and the wide applications of NIRS in food science. In addition, the promise of NIRS technique for food quality evaluation is demonstrated, and some problems which need to be solved or investigated further are also discussed.	Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310029, Peoples R China	He, Y (reprint author), Zhejiang Univ, Coll Biosyst Engn & Food Sci, Kaixuan Rd 258, Hangzhou 310029, Peoples R China.	yhe@zju.edu.cn	Cen, Haiyan/F-2633-2010; He, Yong/E-3218-2010	He, Yong/0000-0001-6752-1757			Andrews DT, 1997, ANAL CHIM ACTA, V350, P341, DOI 10.1016/S0003-2670(97)00270-5; Aske N, 2001, ENERG FUEL, V15, P1304, DOI 10.1021/ef010088h; BARNES RJ, 1989, APPL SPECTROSC, V43, P772, DOI 10.1366/0003702894202201; BENGERA I, 1968, ISRAEL J AGR RES, V18, P125; Blanco M, 1999, ANAL CHIM ACTA, V384, P207, DOI 10.1016/S0003-2670(98)00814-9; Blanco M, 2002, ANAL CHIM ACTA, V463, P295, DOI 10.1016/S0003-2670(02)00382-3; Bouveresse E, 1996, VIB SPECTROSC, V11, P3, DOI 10.1016/0924-2031(95)00055-0; Bras LP, 2005, CHEMOMETR INTELL LAB, V75, P91, DOI 10.1016/j.chemolab.2004.05.007; BUCCI R, 2002, J AGR FOOD CHEM, V20, P413; Byrne CE, 1998, MEAT SCI, V49, P399, DOI 10.1016/S0309-1740(98)00005-9; Candolfi A, 1999, J PHARMACEUT BIOMED, V21, P115, DOI 10.1016/S0731-7085(99)00125-9; Carlomagno G, 2004, INFRARED PHYS TECHN, V46, P23, DOI 10.1016/j.infrared.2004.03.004; Chalucova R, 2000, LEBENSM-WISS TECHNOL, V33, P489, DOI 10.1006/fstl.2000.0704; Chen DY, 2005, REMOTE SENS ENVIRON, V98, P225, DOI 10.1016/j.rse.2005.07.008; CHEN QS, SPECTROCHIMICA ACT A; Cocchi M, 2006, TALANTA, V68, P1505, DOI 10.1016/j.talanta.2005.08.005; Cocchi M, 2005, ANAL CHIM ACTA, V544, P100, DOI 10.1016/j.aca.2005.02.075; Contal L, 2002, J NEAR INFRARED SPEC, V10, P289; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COOMANS D, 1983, METHOD INFORM MED, V22, P93; Copikova J, 2003, CHEM LISTY, V97, P571; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cozzolino D, 2005, LWT-FOOD SCI TECHNOL, V38, P821, DOI 10.1016/j.lwt.2004.10.007; Cozzolino D, 2003, J AGR FOOD CHEM, V51, P7703, DOI 10.1021/jf034959s; DENOORD OE, 1994, CHEMOMETR INTELL LAB, V25, P85, DOI 10.1016/0169-7439(94)85037-2; DEAN T, 1993, NIR NEWS, V4, P14; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Despagne F, 1998, APPL SPECTROSC, V52, P732, DOI 10.1366/0003702981944157; Duponchel L, 1999, J NEAR INFRARED SPEC, V7, P155; Fassio A, 2004, IND CROP PROD, V20, P321, DOI 10.1016/j.indcrop.2003.11.004; FERTIG CC, 2003, EUROPEAN J PHARM SCI, V21, P155; Feudale R.N., 2002, CHEMOM INTELL LAB SY, V64, P181, DOI DOI 10.1016/S0169-7439(02)00085-0; Fu XG, 2005, J FOOD ENG, V69, P461, DOI 10.1016/j.jfoodeng.2004.08.039; Galvao LS, 2005, REMOTE SENS ENVIRON, V94, P523, DOI 10.1016/j.rse.2004.11.012; Garden SW, 1998, J AM SOC BREW CHEM, V56, P159; Geesink GH, 2003, MEAT SCI, V65, P661, DOI 10.1016/S0309-1740(02)00269-3; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Gomez AH, 2006, J FOOD ENG, V77, P313, DOI 10.1016/j.jfoodeng.2005.06.036; Goodacre R, 1997, ANAL CHIM ACTA, V348, P511, DOI 10.1016/S0003-2670(97)00062-7; GORRY PA, 1990, ANAL CHEM, V62, P570, DOI 10.1021/ac00205a007; Hahn F, 2004, BIOSYST ENG, V89, P93, DOI 10.1016/j.biosystemseng.2004.02.012; HALL MN, 1988, FOOD CHEM, V27, P61, DOI 10.1016/0308-8146(88)90036-2; He Y, 2006, FOOD RES INT, V39, P645, DOI 10.1016/j.foodres.2005.12.008; HE Y, 2006, J INFRARED MILLIMETE, V25; HE Y, 2006, SPECTROSCOPY SPECTRA, V26; HELLAND IS, 1995, CHEMOMETR INTELL LAB, V29, P233, DOI 10.1016/0169-7439(95)00031-1; Hoyer H, 1997, PROCESS CONTR QUAL, V9, P143; Indahl UG, 1999, CHEMOMETR INTELL LAB, V49, P19, DOI 10.1016/S0169-7439(99)00023-4; Inon FA, 2006, ANAL CHIM ACTA, V571, P167, DOI 10.1016/j.aca.2006.04.070; ISAKSSON T, 1988, APPL SPECTROSC, V42, P1273, DOI 10.1366/0003702884429869; Karoui R, 2006, FOOD RES INT, V39, P588, DOI 10.1016/j.foodres.2005.12.002; Kasemsumran S, 2005, SPECTROSC LETT, V38, P839, DOI 10.1080/00387010500316189; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; Kim J, 2000, CHEMOMETR INTELL LAB, V51, P201, DOI 10.1016/S0169-7439(00)00070-8; Kim S, 2003, FOOD SCI BIOTECHNOL, V12, P257; Kramer K, 2000, ANAL CHIM ACTA, V420, P155, DOI 10.1016/S0003-2670(00)00877-1; Laasonen M, 2002, ANAL CHEM, V74, P2493, DOI 10.1021/ac011108f; Lammertyn J, 1998, T ASAE, V41, P1089; LANZA E, 1984, J FOOD SCI, V49, P995, DOI 10.1111/j.1365-2621.1984.tb10378.x; Laporte MF, 1999, J AGR FOOD CHEM, V47, P2600, DOI 10.1021/jf980929r; Lee KM, 2005, J CEREAL SCI, V41, P85, DOI 10.1016/j.jcs.2004.09.006; LIZUKA K, 1999, J FOOD COMPOS ANAL, V12, P197; LORBER A, 1986, ANAL CHEM, V58, P1167, DOI 10.1021/ac00297a042; Lorber A, 1997, ANAL CHEM, V69, P1620, DOI 10.1021/ac960862b; LU QY, 2006, IN PRESS J FOOD ENG; Luypaert J, 2004, J PHARMACEUT BIOMED, V36, P495, DOI 10.1016/j.jpba.2004.06.023; Maraboli A, 2002, J NEAR INFRARED SPEC, V10, P63; Mariey L, 2001, VIB SPECTROSC, V26, P151, DOI 10.1016/S0924-2031(01)00113-8; MATHIAS JA, 1987, AQUACULTURE, V61, P303, DOI 10.1016/0044-8486(87)90158-X; McGlone VA, 2002, POSTHARVEST BIOL TEC, V25, P135, DOI 10.1016/S0925-5214(01)00180-6; Munck L, 2004, J CEREAL SCI, V40, P213, DOI 10.1016/j.jcs.2004.07.006; Ni YN, 2005, FOOD CHEM, V89, P465, DOI 10.1016/j.foodchem.2004.05.037; Norgaard L, 2005, INT DAIRY J, V15, P1261, DOI 10.1016/j.idairyj.2004.12.009; Ortiz-Somovilla V, 2007, FOOD CHEM, V101, P1031, DOI 10.1016/j.foodchem.2006.02.058; Osborne B., 1993, PRACTICAL NIR SPECTR; Paradkar MM, 2002, J SCI FOOD AGR, V82, P497, DOI 10.1002/jsfa.1067; Pedro AMK, 2005, ANAL CHEM, V77, P2505, DOI 10.1021/ac048651r; PERKINS JH, 1988, SPECTROCHIM ACTA B, V43, P575, DOI 10.1016/0584-8547(88)80082-X; Pizarro C, 2004, ANAL CHIM ACTA, V509, P217, DOI 10.1016/j.aca.2003.11.008; Pontes MJC, 2005, CHEMOMETR INTELL LAB, V78, P11, DOI 10.1016/j.chemolab.2004.12.001; Pontes MJC, 2006, FOOD RES INT, V39, P182, DOI 10.1016/j.foodres.2005.07.005; Richards T. J., 1998, Agricultural and Resource Economics Review, V27, P186; Rodriguez-Nogales JM, 2006, FOOD CHEM, V98, P782, DOI 10.1016/j.foodchem.2005.07.037; RODRIGUEZOTERO JL, 1995, J AOAC INT, V78, P802; Roggo Y, 2003, J MOL STRUCT, V654, P253, DOI 10.1016/S0022-2860(03)00248-5; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; SCOTTER CNG, 1997, TRENDS FOOD SCI TECH, V17, P344; Sirisomboon P, 2007, J FOOD ENG, V78, P701, DOI 10.1016/j.jfoodeng.2005.11.009; Sjoblom J, 1998, CHEMOMETR INTELL LAB, V44, P229, DOI 10.1016/S0169-7439(98)00112-9; Slobdan S, 2001, ANAL CHEM, V73, P64; Sorensen LK, 1998, INT DAIRY J, V8, P863, DOI 10.1016/S0958-6946(98)00130-7; Szlyk E, 2005, J AGR FOOD CHEM, V53, P6980, DOI 10.1021/jf050672e; Wang L, 2006, FOOD CHEM, V95, P529, DOI 10.1016/j.foodchem.2005.04.015; WANG YD, 1992, ANAL CHEM, V64, P562, DOI 10.1021/ac00029a021; WANG YD, 1991, ANAL CHEM, V63, P2750, DOI 10.1021/ac00023a016; Whitacre E, 2003, J FOOD SCI, V68, P2618, DOI 10.1111/j.1365-2621.2003.tb05779.x; Wilson ND, 2001, J PHARM PHARMACOL, V53, P95, DOI 10.1211/0022357011775064; Wold S, 1998, CHEMOMETR INTELL LAB, V44, P175, DOI 10.1016/S0169-7439(98)00109-9; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0; Xiccato G, 1999, ANIM FEED SCI TECH, V77, P201, DOI 10.1016/S0377-8401(98)00253-3; Xie F, 2004, CEREAL CHEM, V81, P249, DOI 10.1094/CCHEM.2004.81.2.249; Xie YL, 1999, ANAL CHIM ACTA, V384, P193, DOI 10.1016/S0003-2670(98)00832-0; YAN YL, 2005, BASEMENT APPL NIR AN; Yoon JG, 2002, CHEMOMETR INTELL LAB, V64, P1, DOI 10.1016/S0169-7439(02)00042-4; Zhang MH, 2004, TALANTA, V62, P25, DOI 10.1016/S0039-9140(03)00397-7; Zhao JW, 2006, J PHARMACEUT BIOMED, V41, P1198, DOI 10.1016/j.jpba.2006.02.053	106	238	254	25	121	ELSEVIER SCIENCE LONDON	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0924-2244			TRENDS FOOD SCI TECH	Trends Food Sci. Technol.		2007	18	2					72	83		10.1016/j.tifs.2006.09.003		12	Food Science & Technology	Food Science & Technology	147GF	WOS:000244990700002		
S	Lu, BL; Li, J		Chen, K; Wang, L		Lu, Bao-Liang; Li, Jing			A min-max modular network with Gaussian-zero-crossing function	TRENDS IN NEURAL COMPUTATION	Studies in Computational Intelligence		English	Proceedings Paper	1st International Conference on Natural Computation (ICNC 2005)	AUG 27-29, 2005	Changsha, PEOPLES R CHINA	Xiangtang Univ, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, IEEE Control Syst Soc, Int Neural Network Soc, European Neural Network Soc, Chinese Assoc Artificial Intelligence, Japanese Neural Network Soc, Int Fuzzy Syst Assoc, Asia Pacific Neural Network Assembly, Fuzzy Math & Syst Assoc China, Hunan Comp Federat		min-max modular network; Gaussian-zero-crossing function; brain-style computer; incremental learning; structure pruning	COMBINING MULTIPLE CLASSIFIERS; NEAREST-NEIGHBOR RULE; NEURAL-NETWORK; TASK DECOMPOSITION; PATTERN-CLASSIFICATION; LEARNING ALGORITHMS; GZC FUNCTION; RECOGNITION; IDENTIFICATION; ARCHITECTURE	This chapter presents a min-max modular neural network with Gaussian-zero-crossing function (M(3)-GZC). This modular network has the following attractive features: the highly modular structure, the ability of incremental learning; the guarantee of learning convergence, and the ability of saying 'unknown' to unfamiliar inputs. Its relationships with two traditional models, the nearest neighbor algorithm and the radius-basis function network are discussed for better understanding of M(3)-GZC network. Since the number of modules in a M(3)-GZC network is quadratic complexity with the number of training instances, two redundancy pruning strategies, instance pruning and structure pruning, are proposed to reduce the number of modules and speed up the responding time. Experimental results on several benchmark data sets and a practical industry application show the properties of M(3)-GZC network and the validity of the two redundancy pruning strategies.	Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Lu, BL (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dong Chuan Rd, Shanghai 200240, Peoples R China.	blu@cs.sjtu.edu.cn; jinglee@sjtu.edu.cn					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; BATTITI R, 1994, NEURAL NETWORKS, V7, P691, DOI 10.1016/0893-6080(94)90046-9; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; Chen C. H., 1993, Neural, Parallel & Scientific Computations, V1; Chen K, 1997, INT J PATTERN RECOGN, V11, P417, DOI 10.1142/S0218001497000196; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Fan ZG, 2005, LECT NOTES COMPUT SC, V3611, P396; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Huang B, 2004, LECT NOTES COMPUT SC, V3316, P842; JACOBS RA, 1991, COGNITIVE SCI, V15, P219, DOI 10.1207/s15516709cog1502_2; JENKINS RE, 1993, IEEE T NEURAL NETWOR, V4, P718, DOI 10.1109/72.238326; Langdon W. B., 2001, P GEN EV COMP C GECC, P66; Li J, 2005, LECT NOTES COMPUT SC, V3496, P467; Li J, 2005, LECT NOTES COMPUT SC, V3610, P293; Lian HC, 2005, LECT NOTES COMPUT SC, V3611, P438; Lian HC, 2005, IEEE IJCNN, P1983; LIU FY, 2005, P INT JOINT C NEUR N, V1, P570; Lowe Davod, 1989, P 1 IEE INT C ART NE, P171; LU B L, 2004, P INT JOINT C NEUR N, P735; LU BL, 2001, P 5 INT C KNOWL BAS, P298; Lu BL, 1997, LECT NOTES COMPUT SC, V1240, P330; Lu BL, 2004, IEEE T BIO-MED ENG, V51, P551, DOI 10.1109/TBME.2003.821023; Lu BL, 2003, APPL INTELL, V19, P65, DOI 10.1023/A:1023868723792; LU BL, 2002, P INT JOINT C NEUR N, V2, P1263; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Murphy P. M., 1994, UCI REPOSITORY MACHI; Rumelhart D., 1986, LEARNING INTERNAL RE; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Skalak D.B., 1994, P 11 INT C MACH LEAR, P293; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; TUMER K, 1995, P WORLD C NEUR NETW, P31; Wai Lam, 2002, IEEE Transactions on Pattern Analysis and Machine Intelligence, V24, DOI 10.1109/TPAMI.2002.1023804; Wang K, 2005, LECT NOTES COMPUT SC, V3496, P887; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P431; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yang Y, 2005, LECT NOTES COMPUT SC, V3496, P646; YANG Y, 2006, IN PRESS P 3 INT S N; Zhang J., 1992, P 9 INT MACH LEARN C, P470	44	1	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1860-949X		3-540-36121-9	STUD COMPUT INTELL			2007	35						285	313				29	Computer Science, Artificial Intelligence	Computer Science	BFN80	WOS:000243355000012		
S	Stiglic, G; Kokol, P		Kokol, P; Podgorelec, V; MiceticTurk, D; Zorman, M; Verlic, M		Stiglic, Gregor; Kokol, Peter			Effectiveness of rotation forest in meta-learning based gene expression classification	Twentieth IEEE International Symposium on Computer-Based Medical Systems, Proceedings	COMPUTER-BASED MEDICAL SYSTEMS : PROCEEDINGS OF THE ANNUAL IEEE SYMPOSIUM		English	Proceedings Paper	20th IEEE International Symposium on Computer-Based Medical Systems	JUN 20-22, 2007	Maribor, SLOVENIA	IEEE Comp Soc TCCM, Fac Elect Engn & Comp Sci, Fac Hlth Sci			SELECTION	A lot of research has been done in the field of assembling classifiers in ensembles and on the other hand selecting the most appropriate single classifiers for a given problem which was solved by ineta-learning techniques. This paper presents application of recently proposed ensemble of classifiers called Rotation Forest to Grading ineta-learning scheme, where it is used as one of the base classifiers and meta-level classifier at the same time. Our proposed Grading variation is compared to four widely used classifiers on 14 datasets from the domain of gene expression classification problems. Experimental evaluations show that using Rotation Forest at meta-level most significantly impacts the accuracy of Grading scheme and confirms that it can be used for estimation of classifiers regions of strong and weak classification.	Univ Maribor, Maribor, Slovenia	Stiglic, G (reprint author), Univ Maribor, Maribor, Slovenia.		Stiglic, Gregor/E-5286-2011				Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; BAY SD, 2000, 17 INT C MACH LEARN, P49; Blake CL, UCI REPOSITORY MACHI; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudoit S., 2003, STAT ANAL GENE EXPRE, P93, DOI 10.1201/9780203011232.ch3; Frank E., 2005, DATA MINING PRACTICA; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings; LEE J, COMPUTATIONAL STAT D, V48, P869; LI J, P IEEE ICDM 2003 C, P585; Liu Huiqing, 2002, Genome Inform, V13, P51; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; SEEWALD AK, 2001, 4 INT C IDA 2001 P S, P115; SYMONS S, MACHINE LEARNING ALG; Vapnik V., 1998, STAT LEARN THEORY; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; WU W, 2005, BMC BIOINFORMATICS, V6, P1	20	3	3	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-7125		978-0-7695-2905-9	COMP MED SY			2007							243	248		10.1109/CBMS.2007.43		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems; Engineering, Biomedical	Computer Science; Engineering	BGL02	WOS:000248094800041		
B	Tsypin, M; Roder, H		Ao, SI; Douglas, C; Grundfest, WS; Schruben, L; Wu, X	IAENG	Tsypin, Maxim; Roder, Heinrich			On the reliability of kNN classification	WCECS 2007: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE			English	Proceedings Paper	World Congress on Engineering and Computer Science (WCECS 2007)	OCT 24-26, 2007	San Francisco, CA	Int Assoc Engineers		classification; kNN; confidence; probability; error		We propose a formula that quantifies the reliability of kNN classification in the two class case. Let the training set consist of N-1 instances of class 1 and N-2 instances of class 2. Let the k nearest neighbors of the test instance contain k(1) instances of class 1 and k(2) instances of class 2, k = k(1) + k(2), k(1) << N-1, k(2) << N-2. We derive, under some additional assumptions, the estimate for the probability that the test instance belongs to class 1.	[Tsypin, Maxim; Roder, Heinrich] Biodesix, Steamboat Springs, CO 80487 USA	Tsypin, M (reprint author), Biodesix, Steamboat Springs, CO 80487 USA.						Cooper T. M., 1967, IEEE T INFORM THEORY, VIT-13, P21; E FIX, 1989, INT STAT REV, V57, P238; Fix E., 1952, 11 USAF SCH AV MED; Ma XJ, 2006, ARCH PATHOL LAB MED, V130, P465; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; WANG J, 2003, ICANN ACONIP, P200; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; Wang JG, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P3069	8	0	0	0	2	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-98671-6-4				2007							732	734				3	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHJ73	WOS:000253617900130		
J	Yu, XY; Liong, SY				Yu, Xinying; Liong, Shie-Yui			Forecasting of hydrologic time series with ridge regression in feature space	JOURNAL OF HYDROLOGY			English	Article						time series analysis; support vector machine; Gaussian kernel; features approximation; chaotic technique; evolutionary algorithm	SUPPORT VECTOR MACHINES; ARTIFICIAL NEURAL-NETWORKS; PREDICTION; RECONSTRUCTION; MODELS	Support vector machine (SVM) is one of the most elegant data mining engines developed most recently. It has been shown in various studies that SVM provides higher accuracy level than the local model in the chaotic time series analysis. Chaotic time series analysis usually requires a long data record and it is therefore computationally time consuming in addition to possible storage capacity problems. In this study a ridge linear regression is applied in a feature space. The feature space dimension of Gaussian kernel is infinite. With the use of a data sample set, the number of dimensions of feature space of Gaussian kernel can be estimated. The scheme can computationally be guaranteed to be faster and, at the same time, stable while the accuracy remains close to or much better than other existing techniques. Existing techniques used for comparisons are: (1) standard chaos technique; (2) Naive; (3) ARIMA; (4) Inverse Approach; and (5) SVM coupled the decomposition method. The parameters involved are calibrated with an evolutionary algorithm, Shuffled Complex Evolution (SCE). The performance of the proposed method is tested on Tryggevaelde catchment runoff and Mississippi river flow. Significantly higher prediction accuracies are obtained from the proposed scheme than from other existing techniques. In addition, the training speed of the scheme is very much faster than that of its counterparts (197 words < 300 words). (c) 2006 Elsevier B.V. All rights reserved.	Natl Univ Singapore, Dept Civil Engn, Singapore 119260, Singapore	Liong, SY (reprint author), Natl Univ Singapore, Dept Civil Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.	tmslsy@nus.edu.sg					Anctil F, 2004, J HYDROL, V286, P155, DOI 10.1016/j.jhydrol.2003.09.006; BABOVIC V, 2000, P 4 INT C HYDR IOW C; CASDAGLI M, 1989, PHYSICA D, V35, P335, DOI 10.1016/0167-2789(89)90074-2; Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibike YB, 2001, J COMPUT CIVIL ENG, V15, P208, DOI 10.1061/(ASCE)0887-3801(2001)15:3(208); Doan CD, 2005, J HYDROINFORM, V7, P219; DUAN QY, 1992, WATER RESOUR RES, V28, P1015, DOI 10.1029/91WR02985; GIBSON JF, 1992, PHYSICA D, V57, P1, DOI 10.1016/0167-2789(92)90085-2; Girolami M, 2002, NEURAL COMPUT, V14, P669, DOI 10.1162/089976602317250942; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; KARUNANITHI N, 1994, J COMPUT CIVIL ENG, V8, P201, DOI 10.1061/(ASCE)0887-3801(1994)8:2(201); LIONG SY, 2002, ROBUST EFFICIENT SCH; Liong SY, 2002, J AM WATER RESOUR AS, V38, P173, DOI 10.1111/j.1752-1688.2002.tb01544.x; Mitchell T. M., 1997, MACHINE LEARNING; Phoon KK, 2002, J HYDROL ENG, V7, P116, DOI 10.1061/(ASCE)1084-0699(2002)7:2(116); Sivakumar B, 2002, J HYDROL, V265, P225, DOI 10.1016/S0022-1694(02)00112-9; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Takens F., 1981, DYNAMICAL SYSTEMS TU, V898, P366, DOI DOI 10.1007/BFB0091924; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Vapnik V, 1997, ADV NEUR IN, V9, P281; VAPNIK V, 1992, ADV NEUR IN, V4, P831; Williams C, 2000, P 17 INT C MACH LEAR; Williams CKI, 2001, ADV NEUR IN, V13, P682; Yu XY, 2004, J HYDROINFORM, V6, P209; Zaldivar J. M., 2000, J HYDROINFORM, V2, P61; Zealand CM, 1999, J HYDROL, V214, P32, DOI 10.1016/S0022-1694(98)00242-X	27	40	42	1	8	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694			J HYDROL	J. Hydrol.	JAN 15	2007	332	3-4					290	302		10.1016/j.jhydrol.2006.07.003		13	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	133BH	WOS:000243986100004		
J	Wang, JG; Neskovic, P; Cooper, LN				Wang, Jigang; Neskovic, Predrag; Cooper, Leon N.			Improving nearest neighbor rule with a simple adaptive distance measure	PATTERN RECOGNITION LETTERS			English	Article						pattern classification; nearest neighbor rule; adaptive distance measure; adaptive metric; generalization error	CLASSIFICATION	The k-nearest neighbor rule is one of the simplest and most attractive pattern classification algorithms. However, it faces serious challenges when patterns of different classes overlap in some regions in the feature space. In the past, many researchers developed various adaptive or discriminant metrics to improve its performance. In this paper, we demonstrate that an extremely simple adaptive distance measure significantly improves the performance of the k-nearest neighbor rule. (c) 2006 Elsevier B.V. All rights reserved.	Brown Univ, Inst Brain & Neural Syst, Dept Phys, Providence, RI 02912 USA	Wang, JG (reprint author), Brown Univ, Inst Brain & Neural Syst, Dept Phys, POB 1843, Providence, RI 02912 USA.	jigang@physics.brown.edu; pedja@brown.edu; Leon_Cooper@brown.edu					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Fix E., 1951, 4 USAF SCH AV MED; Friedman J., 1994, 113 STANF U STAT DEP; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; WANG J, 2005, LECT NOTES ARTIFICIA; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; WEINBERGER K, 2005, ADV NEURAL INFORM PR, P18	10	76	82	2	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	JAN 15	2007	28	2					207	213		10.1016/j.patrec.2006.07.002		7	Computer Science, Artificial Intelligence	Computer Science	116CT	WOS:000242780800004		
J	Bankert, RL; Wade, RH				Bankert, Richard L.; Wade, Robert H.			Optimization of an instance-based GOES cloud classification algorithm	JOURNAL OF APPLIED METEOROLOGY AND CLIMATOLOGY			English	Article							LEARNING ALGORITHMS; AVHRR; IMAGERY; SURFACE	An instance-based nearest-neighbor algorithm was developed for a Geostationary Operational Environmental Satellite ( GOES) cloud classifier. Expert-labeled samples serve as the training sets for the various GOES image classification scenes. The initial implementation of the classifier using the complete set of available training samples has proven to be an inefficient method for real-time image classifications, requiring long computational run times and significant computer resources. A variety of training-set reduction methods were examined to find smaller training sets that provide quicker classifier run times with minimal reduction in classifier testing set accuracy. General differences within real-time image classifications as a result of using the various reduction methods were also analyzed. The fast condensed nearest-neighbor (FCNN)method reduced the size of the individual training sets by 68.3% ( fourfold cross-validation testing average) while the average overall accuracy of the testing sets decreased by only 4.1%. Training sets resulting from these reduction methods were also applied within a real-time classifier using a one-nearest-neighbor subroutine. Using the FCNN-reduced set, the subroutine run time on a 30 degrees latitude x 30 degrees longitude image (GOES-10 daytime) with 11 289 600 total pixels decreased by an average of 60.7%.	USN, Res Lab, Monterey, CA 93943 USA; Sci Appl Inst Corp, Monterey, CA USA	Bankert, RL (reprint author), USN, Res Lab, 7 Grace Hopper Ave, Monterey, CA 93943 USA.	rich.bankert@nrlmry.navy.mil					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; Bankert RLL, 1996, J APPL METEOROL, V35, P2036, DOI 10.1175/1520-0450(1996)035<2036:ITANNC>2.0.CO;2; Baum BA, 1997, J APPL METEOROL, V36, P1519, DOI 10.1175/1520-0450(1997)036<1519:ACCOGA>2.0.CO;2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERRIEN M, 1999, P 1999 EUMETSAT MET, P545; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hong Y, 2004, J APPL METEOROL, V43, P1834, DOI 10.1175/JAM2173.1; Lee Y, 2004, J ATMOS OCEAN TECH, V21, P159, DOI 10.1175/1520-0426(2004)021<0159:CCOSRD>2.0.CO;2; Lewis HG, 1997, INT J REMOTE SENS, V18, P899, DOI 10.1080/014311697218827; Li J, 2003, J APPL METEOROL, V42, P204, DOI 10.1175/1520-0450(2003)042<0204:HSRSAC>2.0.CO;2; LI Z, 2005, AM METEOR SOC; LIU GS, 1995, J GEOPHYS RES-ATMOS, V100, P13811, DOI 10.1029/95JD00823; Miller SW, 1997, J APPL METEOROL, V36, P1346, DOI 10.1175/1520-0450(1997)036<1346:AANNCC>2.0.CO;2; Pankiewicz G. S, 1995, METEOROL APPL, V2, P257; Pavolonis MJ, 2005, J APPL METEOROL, V44, P804, DOI 10.1175/JAM2236.1; Tag PM, 2000, J APPL METEOROL, V39, P125, DOI 10.1175/1520-0450(2000)039<0125:AAMCTC>2.0.CO;2; Tian B, 1999, IEEE T NEURAL NETWOR, V10, P138, DOI 10.1109/72.737500; Uddstrom MJ, 1996, J APPL METEOROL, V35, P839, DOI 10.1175/1520-0450(1996)035<0839:SCCARR>2.0.CO;2; WELCH RM, 1992, J APPL METEOROL, V31, P405, DOI 10.1175/1520-0450(1992)031<0405:PCASCU>2.0.CO;2; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	21	7	7	0	3	AMER METEOROLOGICAL SOC	BOSTON	45 BEACON ST, BOSTON, MA 02108-3693 USA	1558-8424			J APPL METEOROL CLIM	J. Appl. Meteorol. Climatol.	JAN 22	2007	46	1					36	49		10.1175/JAM2451.1		14	Meteorology & Atmospheric Sciences	Meteorology & Atmospheric Sciences	128DT	WOS:000243638900004		
J	Sun, TK; Chen, SC				Sun, Tingkai; Chen, Songcan			Class label versus sample label-based CCA	APPLIED MATHEMATICS AND COMPUTATION			English	Article						canonical correlation analysis (CCA); class label encoding; separability between classes; feature extraction	CANONICAL CORRELATION-ANALYSIS; CLASSIFICATION	When correlating the samples with the corresponding class labels, canonical correlation analysis (CCA) can be used for supervised feature extraction and subsequent classification. Intuitively, different encoding modes for class label can result in different classification performances. However, actually, when the samples in each class share a common class label as in usual cases, a unified formulation of CCA is not only derived naturally, but also more importantly from it, we can get some insight into the shortcoming of the existing feature extraction using CCA for sequent classification: the existing encodings for class label fail to reflect the difference among the samples such as in central region of class and those in mixture overlapping region among classes, consequently resulting in its equivalence to the traditional linear discriminant analysis (LDA) for some commonly-used class-label encodings. To reflect such a difference between the samples, we elaborately design an independent soft label for each sample of each class rather than a common label for all the samples of the same class. A purpose of doing so is to try to promote CCA classification performance. The experiments show that this soft label based CCA is better than or comparable to the original CCA/LDA in terms of the recognition performance. (c) 2006 Elsevier Inc. All rights reserved.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	s.chen@nuaa.edu.cn					BAEK J, 2004, PATTERN RECOGN, V37, P303; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Bishop C.M., 1995, NEURAL NETWORK PATTE; BORGA M, 1999, CANONICAL CORRELATIO; Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; GESTEL TV, 2001, P INT C ART NEUR NET, P384; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; HELOR Y, 2004, HPL2003164 HP; Horikawa Y, 2004, LECT NOTES COMPUT SC, V3316, P1235; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; JOHANSSON B, 2001, LITHISYR2375 LINK U; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; LOOG M, 2004, P EUR C COMP VIS PRA, P562; Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; YAN SC, 2005, P IEEE CVPR 05	18	19	22	0	3	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0096-3003			APPL MATH COMPUT	Appl. Math. Comput.	FEB 1	2007	185	1					272	283		10.1016/j.amc.2006.06.103		12	Mathematics, Applied	Mathematics	147FB	WOS:000244987700025		
J	Dragovic, S; Onjia, A				Dragovic, Snezana; Onjia, Antonije			Classification of soil samples according to geographic origin using gamma-ray spectrometry and pattern recognition methods	APPLIED RADIATION AND ISOTOPES			English	Article						radionuclides; soil classification; multivariate analysis; LDA; kNN; SIMCA; ANN	ARTIFICIAL NEURAL-NETWORKS; K-NEAREST NEIGHBOR; SPECTRA; RADIOCESIUM; MONTENEGRO; SERBIA	Multivariate data analysis methods were used to recognize and classify soils of unknown geographic origin. A total of 103 soil samples were differentiated into classes, according to regions in Serbia and Montenegro from which they were collected. Their radionuclide (Ra-226, U-238, U-235, K-40, Cs-134, Cs-137, Th-232 and Be-7) activities detected by gamma-ray spectrometry were then used as the inputs in different pattern recognition methods. For the classification of soil samples using eight selected radionuclides, the prediction ability of linear discriminant analysis (LDA), k-nearest neighbours (kNN), soft independent modelling of class analogy (SIMCA) and artificial neural network (ANN) were 82.8%, 88.6%, 60.0% and 92.1%, respectively. (c) 2006 Elsevier Ltd. All rights reserved.	INEP, Belgrade 11080, Serbia	Dragovic, S (reprint author), INEP, Banatska 31B, Belgrade 11080, Serbia.	sdragovic@inep.co.yu					Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Antonic O, 2003, ECOL MODEL, V170, P363, DOI 10.1016/S0304-3800(03)00239-4; Beebe K.R., 1998, CHEMOMETRICS PRACTIC; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; DIMITRIJEVIC M, 1995, GEOLOGY YUGOSLAVIA G; Di Natale C, 2001, SENSOR ACTUAT B-CHEM, V77, P561, DOI 10.1016/S0925-4005(01)00705-5; Dragovic S, 2005, NUCL INSTRUM METH A, V540, P455, DOI 10.1016/j.nima.2004.11.045; Dragovic S, 2005, APPL RADIAT ISOTOPES, V63, P363, DOI 10.1016/j.apradiso.2005.03.009; Dragovic S, 2004, J ENVIRON RADIOACTIV, V77, P381, DOI [10.1016/j.jenvrad.2004.04.007, 10.1016/j.jenvard.2004.04.007]; Dragovic S, 2006, RADIAT MEAS, V41, P611, DOI 10.1016/j.radmeas.2006.03.007; Einax JW, 1997, CHEMOMETRICS ENV CHE; Eswaran H, 2002, SOIL CLASSIFICATION; Fidencio PH, 2001, ANALYST, V126, P2194, DOI 10.1039/b107533k; Goovaerts P, 1998, BIOL FERT SOILS, V27, P315, DOI 10.1007/s003740050439; HOWARD BJ, 1991, HEALTH PHYS, V61, P715, DOI 10.1097/00004032-199112000-00002; Kanevski M, 1996, GEOINFORMATICS, V7, P5; KANEVSKI M, 1997, C ICANN 1997 LAUS; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; Lek S, 1999, ECOL MODEL, V120, P65, DOI 10.1016/S0304-3800(99)00092-7; Massart D. L., 1998, CHEMOMETRICS TXB; McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4; OLMOS P, 1991, IEEE T NUCL SCI, V38, P971, DOI 10.1109/23.83860; OLMOS P, 1994, IEEE T NUCL SCI, V41, P637, DOI 10.1109/23.299814; Otto M., 1999, CHEMOMETRICS; Pilato V, 1999, NUCL INSTRUM METH A, V422, P423, DOI 10.1016/S0168-9002(98)01110-3; Ramadan Z, 2001, ANAL CHIM ACTA, V446, P233; Rumelhart D. E., 1986, P PARALLEL DISTRIBUT, V1; Salisbury RT, 2005, J ENVIRON RADIOACTIV, V78, P353, DOI 10.1016/j.jenvrad.2004.05.013; Slavkovic L, 2004, ENVIRON CHEM LETT, V2, P105, DOI 10.1007/s10311-004-0073-8; Stein A, 2003, AGR ECOSYST ENVIRON, V94, P31, DOI 10.1016/S0167-8809(02)00013-0; UNSCEAR, 2000, SOURC EFF ION RAD RE; VANDEGINSTE G, 1988, HDB CHEMOMETRICS QUA, P207; Vigneron V, 1996, NUCL INSTRUM METH A, V369, P642, DOI 10.1016/S0168-9002(96)80068-4; Werbos P., 1974, THESIS HARVARD U CAM; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Yoshida E, 2002, NUCL INSTRUM METH A, V484, P557, DOI 10.1016/S0168-9002(01)01962-3; Zhu AX, 2000, WATER RESOUR RES, V36, P663, DOI 10.1029/1999WR900315	40	13	13	0	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0969-8043			APPL RADIAT ISOTOPES	Appl. Radiat. Isot.	FEB	2007	65	2					218	224		10.1016/j.apradiso.2006.07.005		7	Chemistry, Inorganic & Nuclear; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	Chemistry; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	128PO	WOS:000243670300010	16928448	
J	Yang, MQ; Yang, JY; Ersoy, OK				Yang, Mary Q.; Yang, Jack Y.; Ersoy, Okan K.			Classification of proteins multiple-labelled and single-labelled with protein functional classes	INTERNATIONAL JOURNAL OF GENERAL SYSTEMS			English	Article						computational intelligence; machine learning; classification; multifunctional proteins; bioinformatics	DATABASE	Advances in high-throughput genome sequencing technology have led to an explosion in the amount of sequence data that are available. The determination of protein function using experimental techniques is time-consuming and expensive; the use of machine-learning techniques rapidly to assess protein function may be useful in streamlining this process. The problem of assigning functional classes to proteins is complicated by the fact that a single protein can participate in several different pathways and thus can have multiple functions. We have developed a tree-based classifier that is capable of handling multiple-labelled data and gaining an insight into the multi-functional nature of proteins. We call the resulting tree a recursive maximum contrast tree (RMCT) and the resulting classifier a multiple-labelled instance classifier (MLIC). We investigate the synergy of machine-learning-based ensemble methods and physiochemical-based feature augments. We test our algorithm on protein phylogenetic profiles generated from 60 completely sequenced genomes and we compare our results with those achieved by algorithms such as support vector machines and decision trees.	Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA; US Dept HHS, NHGRI, NIH, Rockville, MD 20852 USA; Harvard Univ, Sch Med, Dept Radiat Oncol, Boston, MA 02114 USA; Harvard Univ, Massachusetts Gen Hosp, Boston, MA 02114 USA	Yang, JY (reprint author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.	jyang@hadron.mgh.harvard.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Choe W, 2000, BIOINFORMATICS, V16, P1062, DOI 10.1093/bioinformatics/16.12.1062; CODRINGTON CW, 1997, THESIS PURDUE U; CODRINGTON CW, 2001, P INT C MACH LEARN W; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daughdrill GW, 2005, PROTEIN FOLDING HANDBOOK; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; Dunker A K, 2000, Genome Inform Ser Workshop Genome Inform, V11, P161; DUNKER AK, 2005, JBCB, V3, P35; ERSOY OK, 1993, IEEE T CIRCUITS SYST, V40, P556; ERSOY OK, 2002, INT J SMART ENG SYST, P225; Frishman D, 2003, NUCLEIC ACIDS RES, V31, P207, DOI 10.1093/nar/gkg005; Joachims T, 2002, LEARNING CLASSIFY TE; Liu Li-Ping, 1998, Biopolymers, V47, P41, DOI 10.1002/(SICI)1097-0282(1998)47:1<41::AID-BIP6>3.0.CO;2-X; NEUHAUS D, 2002, NUCL OVERHAUSER EFFE; Pavlidis P, 2002, J COMPUT BIOL, V9, P401, DOI 10.1089/10665270252935539; Pavlidis P., 2001, P 5 ANN INT C COMP B, P249, DOI DOI 10.1145/369133.369228; Pellegrini M, 1999, P NATL ACAD SCI USA, V96, P4285, DOI 10.1073/pnas.96.8.4285; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., DATA MINING TOOLS SE; Radivojac P, 2004, J BIOMED INFORM, V37, P224, DOI 10.1016/j.jbi.2004.07.008; ROMERO P, 2002, AI REV, V14, P447; Uversky VN, 2002, FEBS LETT, V515, P79, DOI 10.1016/S0014-5793(02)02441-9; Vert Jean-Philippe, 2002, Bioinformatics, V18 Suppl 1, pS276; YANG JY, 2004, 1 IND BIOINF C IND I; YANG JY, 2003, P ART NEUR NETW ENG; YANG JY, 2002, P ART NEUR NETW ENG; YANG MQ, 2006, P INTC BIOINF COMP B; YANG MQ, 2006, WILEY SERIES BIOINFO	29	4	5	0	0	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0308-1079	1563-5104		INT J GEN SYST	Int. J. Gen. Syst.	FEB	2007	36	1					91	109		10.1080/03081070600950868		19	Computer Science, Theory & Methods; Ergonomics	Computer Science; Engineering	115XN	WOS:000242767200005		
J	Morrison, D; Wang, RL; De Silva, LC				Morrison, Donn; Wang, Ruili; De Silva, Liyanage C.			Ensemble methods for spoken emotion recognition in call-centres	SPEECH COMMUNICATION			English	Article						affect recognition; emotion recognition; ensemble methods; speech processing; speech databases	EXPRESSION; SPEECH; COMMUNICATION; FEATURES; VOICE; PITCH	Machine-based emotional intelligence is a requirement for more natural interaction between humans and computer interfaces and a basic level of accurate emotion perception is needed for computer systems to respond adequately to human emotion. Humans convey emotional information both intentionally and unintentionally via speech patterns. These vocal patterns are perceived and understood by listeners during conversation. This research aims to improve the automatic perception of vocal emotion in two ways. First, we compare two emotional speech data sources: natural, spontaneous emotional speech and acted or portrayed emotional speech. This comparison demonstrates the advantages and disadvantages of both acquisition methods and how these methods affect the end application of vocal emotion recognition. Second, we look at two classification methods which have not been applied in this field: stacked generalisation and unweighted vote. We show how these techniques can yield an improvement over traditional classification methods. (C) 2006 Elsevier B.V. All rights reserved.	Massey Univ Turutea, Inst Informat Sci & Technol, Palmerston North, New Zealand	Wang, RL (reprint author), Massey Univ Turutea, Inst Informat Sci & Technol, Private Bag 11222, Palmerston North, New Zealand.	d.morrison@massey.ac.nz; r.wang@massey.ac.nz					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Ang J., 2002, P INT C SPOK LANG PR; Anton H., 2000, ELEMENTARY LINEAR AL; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cleary J. G., 1995, ICML, P108; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVITZ JR, 1994, COMMUNICATION EMOTIO; Dellaert F., 1996, Proceedings ICSLP 96. Fourth International Conference on Spoken Language Processing (Cat. No.96TH8206), DOI 10.1109/ICSLP.1996.608022; Devillers L., 2002, P ISLE WORKSH DIAL T; DIETERLE F, 2003, THESIS; Dietterichl TG, 2002, HDB BRAIN THEORY NEU, P405; Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203; EMMANOUILIDIS C, 1999, P INT JOINT C NEUR N, P4387; Fairbanks G, 1941, SPEECH MONOGR, V8, P85; Fairbanks G, 1939, SPEECH MONOGR, V6, P87; Fonagy I., 1981, RES ASPECTS SINGING, V33, P51; Fonagy I., 1963, Z PHONETIK SPRACHWIS, V16, P293; FONAGY I, 1978, LANG SPEECH, V21, P34; FRICK RW, 1986, AGGRESSIVE BEHAV, V12, P121, DOI 10.1002/1098-2337(1986)12:2<121::AID-AB2480120206>3.0.CO;2-F; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; HUBER R, 1998, P WORKSH TEXT SPEECH, P223; HUBER R, 2000, P INT C SPOK LANG PR, V1, P665; JOHNSON WF, 1986, ARCH GEN PSYCHIAT, V43, P280; Lee C. M., 2004, P INT C SPOK LANG PR; Liscombe J., 2005, INTERSPEECH, P1845; McGilloway S., 2000, P ISCA WORKSH SPEECH, P200; MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558; Nakatsu R., 1999, P INT C MULT COMP SY; NWE TL, 2003, THESIS NATL U SINGAP; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; OShaughnessy D., 2000, SPEECH COMMUNICATION, V2nd; OSTER A, 1986, Q PROG STAT REP, V4, P79; Petrushin V.A., 2000, P 6 INT C SPOK LANG; Platt J., 1998, ADV KERNEL METHODS S; POLZIN T, 2000, P ISCA WORKSH SPEECH; Rabiner L. R., 1978, DIGITAL PROCESSING S; Salovey P., 2004, FEELINGS EMOTIONS, P321, DOI 10.1017/CBO9780511806582.019; SCHERER KR, 1996, P INT C SPOK LANG PR; Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5; SEEWALD A, 2002, P 19 INT C MACH LEAR; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Skinner ER, 1935, SPEECH MONOGR, V2, P81; Talkin D., 1995, SPEECH CODING SYNTHE, P495; VAFAIE H, 1992, P 4 INT C TOOLS ART; Vapnik V. N., 1995, NATURE STAT LEARNING; WILLIAMS CE, 1972, EMOTIONS SPEECH SOME; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YACOUB S, 2003, P EUR 2003 8 EUR C S	52	78	85	0	5	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-6393	1872-7182		SPEECH COMMUN	Speech Commun.	FEB	2007	49	2					98	112		10.1016/j.specom.2006.11.004		15	Acoustics; Computer Science, Interdisciplinary Applications	Acoustics; Computer Science	149OB	WOS:000245155200002		
J	Du, JX; Wang, XF; Zhang, GJ				Du, Ji-Xiang; Wang, Xiao-Feng; Zhang, Guo-Jun			Leaf shape based plant species recognition	APPLIED MATHEMATICS AND COMPUTATION			English	Article; Proceedings Paper	International Conference on Intelligent Computing	AUG 23-26, 2005	Hefei, PEOPLES R CHINA	Inst Intelligent Machines, Univ Sci & Technol, IEEE Computat Intelligence Soc, IEEE Hong Kong Computat Intelligence Chapter		digital morphological feature; plant recognition; leaf database; hypersphere classifier		Plant has plenty use in foodstuff, medicine and industry. And it is also vitally important for environmental protection. However, it is an important and difficult task to recognize plant species on earth. Designing a convenient and automatic recognition system of plants is necessary and useful since it can facilitate fast classifying plants, and understanding and managing them. In this paper, a leaf database from different plants is firstly constructed. Then, a new classification method, referred to as move median centers (MMC) hypersphere classifier, for the leaf database based on digital morphological feature is proposed. The proposed method is more robust than the one based on contour features since those significant curvature points are hard to find. Finally, the efficiency and effectiveness of the proposed method in recognizing different plants is demonstrated by experiments. (c) 2006 Elsevier Inc. All rights reserved.	Univ Sci & Technol China, Dept Automat, Anhua 230027, Peoples R China; Chinese Acad Sci, Inst Intelligent Machines, Intelligent Comp Lab, Anhua 230031, Peoples R China	Du, JX (reprint author), Univ Sci & Technol China, Dept Automat, Anhua 230027, Peoples R China.	du_jx@iim.ac.cn; xfwang@iim.ac.cn					ABBASI S, 1997, INT C SCAL SPAC THEO, P284; CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy BV, 1991, MCGRAW HILL COMPUTER; DU JX, 2004, AUTOMATIC PLANT LEAV; Gonzalez R C, 2004, DIGITAL IMAGE PROCES; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HEISTERKAMP D, 2001, P IEEE C COMP VIS PA, P236; HONG AX, 2003, ICASSP, V3, P589; Huang D. S., 1996, SYSTEMATIC THEORY NE; Huang DS, 1998, IEEE T SYST MAN CY B, V28, P477, DOI 10.1109/3477.678658; Im Cholhong, 1999, VISION INTERF, P397; Li B., 2003, P 20 INT C COMP PROC; Paredes R., 2000, Pattern Recognition and Applications (Frontiers in Artificial Intelligence and Applications Vol.56); Saitoh T., 2000, P IEEE INT C PATT RE, V2, P507, DOI 10.1109/ICPR.2000.906123; Sonka Milan, 2003, IMAGE PROCESSING ANA; Wan YY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P482; Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160; Wang Zhiyong, 2002, P FUZZY SYSTEMS, V1, P372; Zhang G. J., 2004, P 2004 INT S INT MUL, P165	20	52	66	2	10	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0096-3003			APPL MATH COMPUT	Appl. Math. Comput.	FEB 15	2007	185	2					883	893		10.1016/j.amc.2006.07.072		11	Mathematics, Applied	Mathematics	158AI	WOS:000245762700012		
J	Shen, HB; Chou, KC				Shen, Hong-Bin; Chou, Kuo-Chen			Virus-PLoc: A fusion classifier for predicting the subcellular localization of viral proteins within host and virus-infected cells	BIOPOLYMERS			English	Article						viral protein; subcellular compartment; gene ontology; amphiphilic pseudo amino acid composition; fusion; KNN rule; virus-infected cell	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; LOCATION PREDICTION; SORTING SIGNALS; PROTEASE TYPES; GENE ONTOLOGY; BIOINFORMATICS	Viruses can reproduce their progenies only within a host cell, and their actions depend both on its destructive tendencies toward a specific host cell and on environmental conditions. Therefore, knowledge of the subcellular localization of viral proteins in a host cell or virus-infected cell is very useful for in-depth studying of their functions and mechanisms as well as designing antiviral drugs. An analysis on the Swiss-Prot database (version 50.0, released on May 30, 2006) indicates that only 23.5% of viral protein entries are annotated for their subcellular locations in this regard. As for the gene ontology database, the corresponding percentage is 23.8%. Such a gap calls for the development of high throughput tools for timely annotating the localization of viral proteins within host and virus-infected cells. In this article, a predictor called "Virus-PLoc" has been developed that is featured by fusing many basic classifiers with each engineered according to the K-nearest neighbor rule. The overall jackknife success rate obtained by Virus-PLoc in identifying the subcellular compartments of viral proteins was 80% for a benchmark dataset in which none of proteins has more than 25% sequence identity to any other in a same location site. Virus-PLoc will be freely available as a web-server at http://202.120.37.1861bioinf/ virus for the public usage. Furthermore, Virus-PLoc has been used to provide large-scale predictions of all viral protein entries in Swiss-Prot database that do not have subcellular location annotations or are annotated as being uncertain. The results thus obtained have been deposited in a downloadable file prepared with Microsoft Excel and named "Tab_Virus-PLoc.xls." This file is available at the same website and will be updated twice a year to include the new entries of viral proteins and reflect the continuous development of Virus-PLoc. (c) 2006 Wiley Periodicals, Inc.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China; Gordon Life Sci Inst, San Diego, CA 92130 USA	Chou, KC (reprint author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 1954 Hua Shan Rd, Shanghai 200030, Peoples R China.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 2000, NUCLEIC ACIDS RES, V25, P31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 1999, BIOCHEM BIOPH RES CO, V264, P216, DOI 10.1006/bbrc.1999.1325; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; Chou KC, 2004, J CELL BIOCHEM, V91, P1085, DOI 10.1002/jcb.20083; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOCHEM BIOPH RES CO, V329, P1362, DOI 10.1016/j.bbrr.2005.02.098; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2005, CURR PROTEIN PEPT SC, V6, P423, DOI 10.2174/138920305774329368; Chou KC, 2006, BIOCHEM BIOPH RES CO, V339, P1015, DOI 10.1016/j.bbrc.2005.10.196; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou P Y, 1989, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dunker AK, 2002, ADV PROTEIN CHEM, V62, P25; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Liu H, 2005, BIOCHEM BIOPH RES CO, V338, P1005, DOI 10.1016/j.bbrc.2005.10.046; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Qian ZL, 2006, BIOCHEM BIOPH RES CO, V347, P141, DOI 10.1016/j.bbrc.2006.06.060; Rubenstein R, 1999, J NEUROVIROL, V5, P401, DOI 10.3109/13550289909029481; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yu XJ, 2006, J THEOR BIOL, V240, P175, DOI 10.1016/j.jtbi.2005.09.018; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	55	98	100	0	2	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0006-3525			BIOPOLYMERS	Biopolymers	FEB 15	2007	85	3					233	240		10.1002/bip.20640		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	133AS	WOS:000243984600005	17120237	
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Large-scale plant protein subcellular location prediction	JOURNAL OF CELLULAR BIOCHEMISTRY			English	Article						plant protein; fusion classifier; gene ontology; GO discrete model; amphiphilic pseudo amino acid composition; KNN rule; plant-PLoc	AMINO-ACID-COMPOSITION; STRUCTURAL CLASS PREDICTION; FUNCTIONAL DOMAIN COMPOSITION; SUPPORT VECTOR MACHINES; GENE ONTOLOGY; SECONDARY STRUCTURE; SORTING SIGNALS; NEURAL-NETWORKS; LOCALIZATION; SEQUENCE	Current plant genome sequencing projects have called for development of novel and powerful high throughput tools for timely annotating the subcellular location of uncharacterized plant proteins. In view of this, an ensemble classifier, Plant-PLoc, formed by fusing many basic individual classifiers, has been developed for large-scale subcellular location prediction for plant proteins. Each of the basic classifiers was engineered by the K-Nearest Neighbor (KNN) rule. Plant-PLoc discriminates plant proteins among the following 11 subcellular locations: (1) cell wall, (2) chloroplast, (3) cytoplasm, (4) endoplasmic reticulum, (5) extracell, (6) mitochondrion, (7) nucleus, (8) peroxisome, (9) plasma membrane, (10) plastid, and (11) vacuole. As a demonstration, predictions were performed on a stringent benchmark dataset in which none of the proteins included has >= 25% sequence identity to any other in a same subcellular location to avoid the homology bias. The overall success rate thus obtained was 32-51 % higher than the rates obtained by the previous methods on the same benchmark dataset. The essence of Plant-PLoc in enhancing the prediction quality and its significance in biological applications are discussed. Plant-PLoc is accessible to public as a free web-server at http://202.1 20.37.186/bioinf/plant. Furthermore, for public convenience, results predicted by Plant-PLoc have been provided in a downloadable file at the same website for all plant protein entries in the Swiss-Prot database that do not have subcellular location annotations, or are annotated as being uncertain. The large-scale results will be updated twice a year to include new entries of plant proteins and reflect the continuous development of Plant-PLoc.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, P115; Ashburner M, 2000, NAT GENET, V25, P25; Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2000, BIOCHIMIE, V82, P783, DOI 10.1016/S0300-9084(00)01161-5; Camon E, 2004, NUCLEIC ACIDS RES, V32, pD262, DOI 10.1093/nar/gkh021; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou K.C., 2006, EXCLI J, V5, P55; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 1998, PROTEIN ENG, V11, P523, DOI 10.1093/protein/11.7.523; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEAGE G, 1987, PROTEIN ENG, V1, P289, DOI 10.1093/protein/1.4.289; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Emanuelsson O, 1999, PROTEIN SCI, V8, P978; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Harris MA, 2004, NUCLEIC ACIDS RES, V32, pD258, DOI 10.1093/nar/gkh036; Jackson S, 2006, PLANT CELL, V18, P1100, DOI 10.1105/tpc.106.042192; Jorgensen R, 2006, PLANT CELL, V18, P1099, DOI 10.1105/tpc.106.180580; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lee S, 2006, PROTEINS, V62, P1107, DOI 10.1002/prot.20821; LEE Y, 2005, SILICO BIOL, V5, P5; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Liu WM, 1998, J PROTEIN CHEM, V17, P209, DOI 10.1023/A:1022576400291; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; MAO BY, 1994, PROTEIN ENG, V7, P319, DOI 10.1093/protein/7.3.319; MARDIA KV, 1979, MULTIVARIATE ANAL, P332; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Vapnik V., 1998, STAT LEARNING THEORY; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	65	148	151	2	8	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0730-2312			J CELL BIOCHEM	J. Cell. Biochem.	FEB 15	2007	100	3					665	678		10.1002/jcb.21096		14	Biochemistry & Molecular Biology; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	130CB	WOS:000243775700010	16983686	
J	Bondugula, R; Xu, D				Bondugula, Rajkumar; Xu, Dong			MUPRED: A tool for bridging the gap between template based methods and sequence profile based methods for protein secondary structure prediction	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						protein secondary structure prediction; fuzzy nearest neighbor; neural network; hybrid prediction system; sequence profile; template; prediction accuracy assessment	ALIGNMENTS; DATABASE	Predicting secondary structures from a protein sequence is an important step for characterizing the structural properties of a protein. Existing methods for protein secondary structure prediction can be broadly classified into template based or sequence profile based methods. We propose a novel framework that bridges the gap between the two fundamentally different approaches. Our framework integrates the information from the fuzzy k-nearest neighbor algorithm and position-specific scoring matrices using a neural network. It combines the strengths of the two methods and has a better potential to use the information in both the sequence and structure databases than existing methods. We implemented the framework into a software system MUPRED. MUPRED has achieved three-state prediction accuracy (Q(3)) ranging from 79.2 to 80.14%, depending on which benchmark dataset is used. A higher Q(3) can be achieved if a query protein has a significant sequence identity (> 25%) to a template in PDB. MUPRED also estimates the prediction accuracy at the individual residue level more quantitatively than existing methods. The MUPRED web server and executables are freely available at http://digbio.missouri.edu/mupred. Proteins 2007; 66:664-670. (c) 2006 Wiley-Liss, Inc.	Univ Missouri, Christopher S Bond Life Sci Ctr 271C, Digital Biol Lab, Dept Comp Sci, Columbia, MO 65211 USA	Xu, D (reprint author), Univ Missouri, Christopher S Bond Life Sci Ctr 271C, Digital Biol Lab, Dept Comp Sci, Columbia, MO 65211 USA.	xudong@missouri.edu					Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; BONDUGULA R, 2001, P 3 AS PAC BIOINF C; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Cheng HT, 2005, POLYMER, V46, P4314, DOI 10.1016/j.polymer.2005.02.040; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GEOURJON C, 1994, PROTEIN ENG, V7, P157, DOI 10.1093/protein/7.2.157; HOBOHM U, 1994, PROTEIN SCI, V3, P522; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Karplus K, 1998, BIOINFORMATICS, V14, P846, DOI 10.1093/bioinformatics/14.10.846; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Mathews B.W., 1975, BIOCHIM BIOPHYS ACTA, V405, P442; Meiler J, 2003, P NATL ACAD SCI USA, V100, P12105, DOI 10.1073/pnas.1831973100; Rost B, 2001, J STRUCT BIOL, V134, P204, DOI 10.1006/jsbi.2000.4336; ROST B, 1994, PROTEINS, V19, P55, DOI 10.1002/prot.340190108; Salamov AA, 1997, J MOL BIOL, V268, P31, DOI 10.1006/jmbi.1997.0958; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464; ZHANG X, 1992, J MOL BIOL, V225, P1049, DOI 10.1016/0022-2836(92)90104-R	23	20	20	0	0	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	FEB 15	2007	66	3					664	670		10.1002/prot.21177		7	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	126BR	WOS:000243487700015	17109407	
J	Tripathy, M; Maheshwari, RP; Verma, HK				Tripathy, M.; Maheshwari, R. P.; Verma, H. K.			Application of probabilistic neural network for differential relaying of power transformer	IET GENERATION TRANSMISSION & DISTRIBUTION			English	Article							PROTECTION; ALGORITHM; FAULT	Investigations towards the applicability of probabilistic neural networks (PNNs) as core classifiers to discriminate between magnetising inrush and internal fault of power transformer are made. An algorithm has been developed around the theme of conventional differential protection of transformer. It makes use of the ratio of the voltage-to-frequency and the amplitude of differential current for the detection of the operating condition of the transformer. The PNN has a significant advantage in terms of a much faster learning capability because it is constructed with a single pass of exemplar pattern set and without any iteration for weight adaptation. For the evaluation of the developed algorithm, transformer modelling and simulation of fault are carried out in power system computer-aided designing PSCAD/EMTDC. The operating condition detection algorithm is implemented in MATLAB.	Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India	Tripathy, M (reprint author), Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.	rudrafee@iitr.ernet.in					AIBE N, 2002, P IEEE INT C NEUR NE, V3, P2270; BASTARD P, 1995, IEE P-GENER TRANSM D, V142, P386, DOI 10.1049/ip-gtd:19951817; Berthold MR, 1998, NEUROCOMPUTING, V19, P167, DOI 10.1016/S0925-2312(97)00063-5; Bose NK, 1996, NEURAL NETWORK FUNDA; BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hammond MH, 2004, CHEMOMETR INTELL LAB, V71, P73, DOI 10.1016/j.chemolab.2003.12.001; Ma XX, 2000, ELECTR POW SYST RES, V56, P43, DOI 10.1016/S0378-7796(00)00099-7; MAHESHWARI RP, 1997, TAYLOR FRANCIS ELECT, V25, P459; MINCHIN G, 1999, P IEEE ICONIP 99, P556; Moravej Z, 2003, COMPUT ELECTR ENG, V29, P421, DOI 10.1016/S0045-7906(01)00033-7; MORAVEJ Z, 2003, J ELECT LETT, V84, P1; MURTY YVVS, 1990, IEEE T POWER DELIVER, V5, P1299, DOI 10.1109/61.57970; MUSAVI M, 1992, P IEEE INT JOINT C N, V1, P595, DOI 10.1109/IJCNN.1992.287147; PEREZ LG, 1994, IEEE T POWER DELIVER, V9, P431; Pihler J, 1997, IEEE T POWER DELIVER, V12, P1128, DOI 10.1109/61.636919; RAHMAN MA, 1988, IEEE T POWER DELIVER, V3, P534, DOI 10.1109/61.4290; SACHDEV MS, 1988, PUBLICATION IEEE TUT; Shin MC, 2003, IEEE T POWER DELIVER, V18, P718, DOI 10.1109/TPWRD.2003.813598; Specht D F, 1990, IEEE Trans Neural Netw, V1, P111, DOI 10.1109/72.80210; Specht D. F., 1988, P IEEE INT C NEURAL, V1, P525; Specht D. F., 1992, P INT JOINT C NEUR N, P761, DOI 10.1109/IJCNN.1992.287095; Specht D. F., 1991, IJCNN 91 SEATTLE INT, V1, P887; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Stigant S.A., 1973, J P TRANSFORMER BOOK; Tan KC, 2004, IEEE T NEURAL NETWOR, V15, P1562, DOI 10.1109/TNN.2004.830801; PHADKE AG, 1983, IEEE T POWER AP SYST, V102, P3624, DOI 10.1109/TPAS.1983.317711; Torfs P, 2001, PHYS CHEM EARTH PT B, V26, P9, DOI 10.1016/S1464-1909(01)85006-1; VERMA HK, 1990, ELECTR POW SYST RES, V18, P125, DOI 10.1016/0378-7796(90)90015-U; VERMA HK, 1986, J MICROCOMPUT APPL, V9, P313, DOI 10.1016/0745-7138(86)90028-X; WASHBURNE TP, 1991, INT JOINT C NEUR NET, V1, P513; Webb AR, 2002, STAT PATTERN RECOGNI; Zaman MR, 1998, IEEE T POWER DELIVER, V13, P510, DOI 10.1109/61.660922	33	5	5	1	2	INSTITUTION ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-8687			IET GENER TRANSM DIS	IET Gener. Transm. Distrib.	MAR	2007	1	2					218	222		10.1049/iet-gtd:20050273		5	Engineering, Electrical & Electronic	Engineering	167PV	WOS:000246464500003		
J	Manouselis, N; Costopoulou, C				Manouselis, Nikos; Costopoulou, Constantina			Experimental analysis of design choices in multiattribute utility collaborative filtering	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article; Proceedings Paper	International Workshop on Web Personalization, Recommender Systems and Intelligent User Interfaces	OCT, 2005	Reading, ENGLAND			recommender systems; multi-criteria decision making (MCDM); evaluation	RECOMMENDER SYSTEMS; EMPIRICAL-ANALYSIS; ALGORITHMS; INFORMATION; SIMILARITY	Recommender systems have already been engaging multiple criteria for the production of recommendations. Such systems, referred to as multicriteria recommenders, demonstrated early the potential of applying Multi-Criteria Decision Making (MCDM) methods to facilitate recommendation in numerous application domains. On the other hand, systematic implementation and testing of multicriteria recommender systems in the context of real-life applications still remains rather limited. Previous studies dealing with the evaluation of recommender systems have outlined the importance of carrying out careful testing and parameterization of a recommender system, before it is actually deployed in a real setting. In this paper, the experimental analysis of several design options for three proposed multiattribute utility collaborative filtering algorithms is presented for a particular application context (recommendation of e-markets to online customers), under conditions similar to the ones expected during actual operation. The results of this study indicate that the performance of recommendation algorithms depends on the characteristics of the application context, as these are reflected on the properties of evaluations' data set. Therefore, it is judged important to experimentally analyze various design choices for multicriteria recommender systems, before their actual deployment.	Agr Univ Athens, Div Informat Math & Stat, Informat Lab, GR-11855 Athens, Greece	Manouselis, N (reprint author), Agr Univ Athens, Div Informat Math & Stat, Informat Lab, 75 Iera Odos Str, GR-11855 Athens, Greece.	nikosm@ieee.org; tina@aua.gr					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bakos Y, 1998, COMMUN ACM, V41, P35, DOI 10.1145/280324.280330; Breese J. S., 1998, P 14 C UNC ART INT M; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; CARENINI G, 2005, P PERS WORKSH INT US; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELGADO J, 1999, P ACM SIGIR 99; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Guan S., 2002, ELECTRON COMMER R A, V1, P314, DOI 10.1016/S1567-4223(02)00023-6; Ha V, 2003, ARTIF INTELL, V146, P149, DOI 10.1016/S0004-3702(03)000134; Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Jacquet-Lagreze E, 2001, EUR J OPER RES, V130, P233, DOI 10.1016/S0377-2217(00)00035-7; Keeney R. L., 1992, VALUE FOCUSED THINKI; Konstan JA, 2004, ACM T INFORM SYST, V22, P1, DOI 10.1145/963770.963771; Lee WP, 2004, EXPERT SYST APPL, V27, P665, DOI 10.1016/j.eswa.2004.07.001; Liu DR, 2005, INFORM MANAGE-AMSTER, V42, P387, DOI 10.1016/j.im.2004.01.008; Manouselis N, 2005, INFORM SERV USE, V25, P95; MANOUSELIS N, 2006, 181 TR AGR U ATH; MANOUSELIS N, IN PRESS ENG LETT; MARITZA L, 2004, P 2004 ACM S APPL CO; Masthoff J, 2003, LECT NOTES ARTIF INT, V2702, P258; Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618; MONTANER M, P 6 INT C ENT INF SY, P303; NGUYEN H, 1998, P AAAI WORKSH REC SY; Papagelis M, 2005, ENG APPL ARTIF INTEL, V18, P781, DOI 10.1016/j.engappai.2005.06.010; PERNY P, 2001, INFORMATION INTERACT, V1, P9; PRICE B, 2005, P INF ANN M DENV 200; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P., 1994, P ACM C COMP SUPP CO, P175, DOI DOI 10.1145/192844.192905; ROY B., 1996, MULTICRITERIA METHOD; SARWAR B, 2000, P ACM EC 00; SCHICKELZUBER V, 2005, P WORKSH KNOWL DISCO; SCHMITT C, 2002, P ABIS WORKSH AD BEN; STOLZE M, 2003, P 2 WORLD C MASS CUS; Tewari G, 2003, DECIS SUPPORT SYST, V34, P127, DOI 10.1016/S0167-9236(02)00076-3; Vidgen R. A. T., 2002, J ELECTRON COMMER RE, V3, P114; Vincke P, 1992, MULTICRITERIA DECISI; Wolfinbarger M, 2003, J RETAILING, V79, P183, DOI 10.1016/S0022-4359(03)00034-4; YU K, 2001, P 2 INT WORKSH MAN I; Zeng C, 2004, INT J ELECTRON COMM, V8, P115	44	15	16	0	5	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAR	2007	21	2					311	331		10.1142/S021800140700548X		21	Computer Science, Artificial Intelligence	Computer Science	231NK	WOS:000250955100008		
J	Tahir, MA; Bouridane, A; Kurugollu, F				Tahir, Muhammad Atif; Bouridane, Ahmed; Kurugollu, Fatih			Simultaneous feature selection and feature weighting using Hybrid Tabu Search/K-nearest neighbor classifier	PATTERN RECOGNITION LETTERS			English	Article						Tabu Search; K-NN classifier; feature selection; feature weighting; prostate cancer diagnosis	GENETIC ALGORITHMS	Feature selection and feature weighting are useful techniques for improving the classification accuracy of K-nearest-neighbor (K-NN) rule. The term feature selection refers to algorithms that select the best subset of the input feature set. In feature weighting, each feature is multiplied by a weight value proportional to the ability of the feature to distinguish pattern classes. In this paper, a novel hybrid approach is proposed for simultaneous feature selection and feature weighting of K-NN rule based on Tabu Search (TS) heuristic. The proposed TS heuristic in combination with K-NN classifier is compared with several classifiers on various available data sets. The results have indicated a significant improvement in the performance in classification accuracy. The proposed TS heuristic is also compared with various feature selection algorithms. Experiments performed revealed that the proposed hybrid TS heuristic is superior to both simple TS and sequential search algorithms. We also present results for the classification of prostate cancer using multispectral images, an important problem in biomedicine. (c) 2006 Elsevier B.V. All rights reserved.	Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England; Queens Univ Belfast, Sch Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Tahir, MA (reprint author), Univ W England, Sch Comp Sci, Bristol BS16 1QY, Avon, England.	muhammad.tahir@uwe.ac.uk		Kurugollu, Fatih/0000-0002-2508-4496			Blake CL, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R O, 2001, PATTERN CLASSIFICATI; EBLE JN, 1996, UROLOGIC SURG PATHOL; Glover F., 1993, Annals of Operations Research, V41; Glover F., 1990, ORSA J COMP, V1, P4, DOI DOI 10.1287/IJOC.2.1.4; Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547; GUVERENIR HA, 1997, P 12 INT S COMP INF; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KORYCINSKI D, 2003, P IEEE INT GEOSC REM; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LOWE D, 1995, NEURAL COMPUT, V7; Michie D., 1994, MACHINE LEARNING NEU; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; PUCH WF, 1993, P 5 INT C GEN ALG IC; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Roula M. A., 2002, IEEE INT S BIOM IM; SAIT SM, 1999, GEN ITERATIVE ALGORI; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; TAHIR MA, 2005, IN PRESS ADV INTELLI; TAHIR MA, 2004, P 1M INT C PATT REC; TAHIR MA, 2004, LNCS, V3177; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	31	55	61	0	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAR 1	2007	28	4					438	446		10.1016/j.patrec.2006.08.016		9	Computer Science, Artificial Intelligence	Computer Science	127ZP	WOS:000243625400005		
J	Ramamohanarao, K; Fan, HJ				Ramamohanarao, Kotagiri; Fan, Hongjian			Patterns based classifiers	WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS			English	Article						data mining; classification; emerging pattern	GENE-EXPRESSION PROFILES; EMERGING PATTERNS; DISCOVERY; DATABASES; CLASSIFICATION; RULES	Data mining is one of the most important areas in the 21 century for its applications are wide ranging. This includes medicine, finance, commerce and engineering, to name a few. Pattern mining is amongst the most important and challenging techniques employed in data mining. Patterns are collections of items which satisfy certain properties. Emerging Patterns are those whose frequencies change significantly from one dataset to another. They represent strong contrast knowledge and have been shown very successful for constructing accurate and robust classifiers. In this paper, we examine various kinds of patterns. We also investigate efficient pattern mining techniques and discuss how to exploit patterns to construct effective classifiers.	Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic, Australia	Fan, HJ (reprint author), Univ Melbourne, Dept Comp Sci & Software Engn, Melbourne, Vic, Australia.	hfan@csse.unimelb.edu.au; rao@csse.unimelb.edu.au					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALHAMMADY H, 2004, P 8 PAC AS C KNOWL D, P207; ALHAMMADY H, 2005, P 2005 SIAM INT DAT; Alhammady H, 2004, P 4 IEEE INT C DAT M, P315; BAILEY J, 2003, P 4 INT C WEB AG INF, P226; BAILEY J, 2002, P 6 EUR C PRINC PRAC; Bailey J., 2003, P 3 IEEE INT C DAT M, P485; Bay SD, 2001, DATA MIN KNOWL DISC, V5, P213, DOI 10.1023/A:1011429418057; BAYUARDO RJ, 1998, P 1998 ACM SIGMOD IN, P85; Bethea R.M., 1995, STAT METHODS ENG SCI, Vthird; Bishop C.M., 1995, NEURAL NETWORKS PATT; Blake C, 1998, UCI REPOSITORY MACHI; Brachman RJ, 1996, COMMUN ACM, V39, P42, DOI 10.1145/240455.240468; Breiman L., 1984, CLASSIFICATION REGRE; Cheeseman P., 1996, P 2 INT C KNOWL DISC, P153; Christensen R, 1997, LOG LINEAR MODELS LO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Dong G., 1999, P 2 INT C DISC SCI, P30; Dong G. Z., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Duda R. O., 1973, PATTERN CLASSIFICATI; Fan H., 2003, P 14 AUSTR DAT C ADC, P39; FAN H, 2005, P IEEE INT C GRAN CO; Fan H, 2002, P 6 PAC AS C KNOWL D, P456; FAN H, 2003, P 4 INT C WEB AG INF, P189; Fan H, 2006, IEEE T KNOWL DATA EN, V18, P721, DOI 10.1109/TKDE.2006.95; Fayyad U, 1996, AI MAG, V17, P37; Freitas A.A., 2002, DATA MINING KNOWLEDG; Gunopulos D., 1997, Proceedings of the Sixteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, PODS 1997, DOI 10.1145/263661.263684; Han J., 2000, DATA MINING CONCEPTS; HAN JW, 1992, PROC INT CONF VERY L, P547; Han J, 2000, P 2000 ACM SIGMOD IN, P1, DOI 10.1145/342009.335372; HAN JW, 1993, IEEE T KNOWL DATA EN, V5, P29, DOI 10.1109/69.204089; Jinyan Li, 2001, KNOWL INF SYST, V3, P131, DOI DOI 10.1007/PL00011662; JOSHI MV, 2001, P ACM SIGMOD C SANT, P91, DOI 10.1145/375663.375673; KOHAVI R, 1994, MLC MACHINE LEARNING, P740; Li J, 2001, P 5 PAC AS C KNOWL D, P455; Li J, 2003, BIOINFORMATICS S2, V19, pii93; Li J, 2000, P 4 EUR C PRINC PRAC, P191; Li J., 2000, P 17 INT C MACH LEAR, P551; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Li JY, 2002, BIOINFORMATICS, V18, P725, DOI 10.1093/bioinformatics/18.5.725; Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58; Li JY, 2003, BIOINFORMATICS, V19, P71, DOI 10.1093/bioinformatics/19.1.71; Mitchell T. M., 1982, ARTIF INTELL, V18; Mitchell T. M., 1997, MACHINE LEARNING; PIATETSKYSHAPIR.G, 1991, KNOWLEDGE DISCOVERY; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Ripley BD, 1996, PATTERN RECOGNITION; *RULEQUEST, 2000, SEE5C C5 0; Sebag M., 1996, P 13 INT C MACH LEAR, P444; WANG Z, 2004, P 17 AUSTR JOINT C A, P1062; Zhang X. Zh., 2000, P 6 INT C KNOWL DISC, P310, DOI 10.1145/347090.347158	54	16	16	1	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1386-145X			WORLD WIDE WEB	World Wide Web	MAR	2007	10	1					71	83		10.1007/s11280-006-0012-7		13	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	146SR	WOS:000244955500003		
J	Shen, HB; Chou, KC				Shen, H.-B.; Chou, K.-C.			Using ensemble classifier to identify membrane protein types	AMINO ACIDS			English	Article						Type-I; Type-II; multi-pass transmembrane; lipid-chain-anchored; GPI-anchored; pseudo-amino acid composition; ensemble classifier; fusion; voting	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; SUBCELLULAR LOCATION; FOLDING TYPES	Predicting membrane protein type is both an important and challenging topic in current molecular and cellular biology. This is because knowledge of membrane protein type often provides useful clues for determining, or sheds light upon, the function of an uncharacterized membrane protein. With the explosion of newly-found protein sequences in the post-genomic era, it is in a great demand to develop a computational method for fast and reliably identifying the types of membrane proteins according to their primary sequences. In this paper, a novel classifier, the so-called "ensemble classifier", was introduced. It is formed by fusing a set of nearest neighbor (NN) classifiers, each of which is defined in a different pseudo amino acid composition space. The type for a query protein is determined by the outcome of voting among these constituent individual classifiers. It was demonstrated through the self-consistency test, jackknife test, and independent dataset test that the ensemble classifier outperformed other existing classifiers widely used in biological literatures. It is anticipated that the idea of ensemble classifier can also be used to improve the prediction quality in classifying other attributes of proteins according to their sequences.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Del Mar Dr, San Diego, CA 92130 USA.	kchou@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Alberts B., 1994, MOL BIOL CELL; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Cai YD, 2003, BIOPHYS J, V84, P3257; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2005, CURR PROTEIN PEPT SC, V6, P423, DOI 10.2174/138920305774329368; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou P Y, 1989, PREDICTION PROTEIN S, P549; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; LODISH H, 1995, MOL CELL BIOL, pCH3; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; ROST B, 1995, PROTEIN SCI, V4, P521; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, J THEOR BIOL, V235, P555, DOI 10.1016/j.jtbi.2005.02.008; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	38	67	70	2	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0939-4451			AMINO ACIDS	Amino Acids	MAY	2007	32	4					483	488		10.1007/s00726-006-0439-2		6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	170BP	WOS:000246636500004	17031474	
J	Kohler, M; Krzyzak, A				Kohler, Michael; Krzyzak, Adam			On the rate of convergence of local averaging plug-in classification rules under a margin condition	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	IEEE International Symposium on Information Theory	JUL 09-14, 2006	Seattle, WA	IEEE Informat Theory Soc, USN, Dept Navy Sci & Technol, Microsoft, Natl Sci Fdn		classification; plug-in classifiers; rate of convergence; statistical learning	NONPARAMETRIC REGRESSION; POINTWISE CONSISTENCY; NEIGHBOR; DISCRIMINATION; CLASSIFIERS	The rates of convergence of plug-in kernel, partitioning, and nearest neighbors classification rules are analyzed. A margin condition, which measures how quickly the a posteriori probabilities cross the decision boundary, smoothness conditions on the a posteriori probabilities, and boundedness of the feature vector are imposed. The rates of convergence of the plug-in classifiers shown in this paper are faster than previously known.	Univ Saarland, Fachrichtung Math 6 1, D-66041 Saarbrucken, Germany; Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada	Kohler, M (reprint author), Univ Saarland, Fachrichtung Math 6 1, D-66041 Saarbrucken, Germany.	kohler@math.uni-sb.de; krzyzak@cs.concordia.ca					AUDIBERT JY, 2004, CLASSIFICATION POLYN; Audibert JY, 2007, ANN STAT, V35, P608, DOI 10.1214/009053606000001217; Beck J., 1979, Problems of Control and Information Theory, V8; Beirlant J, 1998, J STAT PLAN INFER, V71, P93, DOI 10.1016/S0378-3758(98)00008-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; DEVROYE L, 1982, Z WAHRSCHEINLICHKEIT, V61, P467, DOI 10.1007/BF00531618; Devroye L., 1996, PROBABILISTIC THEORY; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DEVROYE L, 1983, P 4 PANN S MATH STAT, P67; GREBLICKI W, 1984, ANN STAT, V12, P1570, DOI 10.1214/aos/1176346815; GYORFI L, 1991, NATO ADV SCI I C-MAT, V335, P329; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; Gyorfi L., 2002, SPRINGER SERIES STAT; Kohler M, 2006, J MULTIVARIATE ANAL, V97, P311, DOI 10.1016/j.jmva.2005.03.006; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mammen E, 1999, ANN STAT, V27, P1808; Massart P, 2006, ANN STAT, V34, P2326, DOI 10.1214/009053606000000786; Nadaraya E., 1964, THEOR PROBAB APPL, V9, P141, DOI DOI 10.1137/1109020; STONE CJ, 1982, ANN STAT, V10, P1040, DOI 10.1214/aos/1176345969; Tsybakov AB, 2005, ANN STAT, V33, P1203, DOI 10.1214/009053604000001066; Tsybakov AB, 2004, ANN STAT, V32, P135; Vapnik V., 1998, STAT LEARNING THEORY; Walk H, 2001, ANN I STAT MATH, V53, P691, DOI 10.1023/A:1014692616736; Watson G. S., 1964, SANKHYA A, V26, P359	27	4	4	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	MAY	2007	53	5					1735	1742		10.1109/TIT.2007.894625		8	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	161RY	WOS:000246034600008		
J	Abbas, SR; Arif, M				Abbas, Syed Rahat; Arif, Muhammad			Modified nearest neighbor method for multistep ahead time series forecasting	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						multistep ahead forecasting; pattern selection; nearest neighbor; cross-correlation; long range forecasting; time series forecasting	CLASSIFICATION	Multistep ahead time series forecasting has become an important activity in various fields of science and technology due to its usefulness in future events management. Nearest neighbor search is a pattern matching algorithm for forecasting, and the accuracy of the method considerably depends on the similarity of the pattern found in the database with the reference pattern. Original time series is embedded into optimal dimension. The optimal dimension is determined by using autocorrelation function plot. The last vector in the embedded matrix is taken as the reference vector and all the previous vectors as candidate vectors. In nearest neighbor algorithm, the reference vector is matched with all the candidate vectors in terms of Euclidean distance and the best matched pattern is used for forecasting. In this paper, we have proposed a hybrid distance measure to improve the search of the nearest neighbor. The proposed method is based on cross-correlation and Euclidean distance. The candidate patterns are shortlisted by using cross-correlation and then Euclidean distance is used to select the best matched pattern. Moreover, in multistep ahead forecasting, standard nearest neighbor method introduces a bias in the search which results in higher forecasting errors. We have modified the search methodology to remove the bias by ignoring the latest forecasted value during the search of the nearest neighbor in the subsequent iteration. The proposed algorithm is evaluated on two benchmark time series as well as two real life time series.	Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Islamabad, Pakistan	Abbas, SR (reprint author), Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Islamabad, Pakistan.	rahatabbas@gmail.com; syedmarif2003@yahoo.com					ABBS SR, 2006, INT J PATTERN RECOGN, V20, P1261; ANDERSON O, 1976, SERIES ANAL FORECAST; Andrews D.F., 1985, DATA COLLECTION PROB; Atiya AF, 1999, IEEE T NEURAL NETWOR, V10, P402, DOI 10.1109/72.750569; BABOVIC V, 2000, 4 INT C HYDROINFORMA; BOX G, 1976, FORECASTING CONTROL; Chow TWS, 1996, IEEE T POWER SYST, V11, P1736, DOI 10.1109/59.544636; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DANGELMAYR G, 1999, APPL SCI NEURAL NETW, V2; DAY SB, 1998, 5 INT C MACHINE LEAR; DJOUADI A, 2002, IEEE T PATTERN ANAL, V24, P1281; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fernandez-Rodriguez F, 1999, INT J FORECASTING, V15, P383, DOI 10.1016/S0169-2070(99)00003-5; GAUTAMA T, 2003, IEEE INT C ACOUSTICS; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Makridakis S. G., 1998, FORECASTING METHODS, V3rd; Metaxiotis K, 2003, ENERG CONVERS MANAGE, V44, P1525, DOI 10.1016/S0196-8904(02)00148-6; Nock R, 2003, INT J PATTERN RECOGN, V17, P1369, DOI 10.1142/S0218001403002952; Principe JC, 1998, P IEEE, V86, P2240, DOI 10.1109/5.726789; SAUER T, 1993, TIME SERIES PREDICTI, P175; SMALL M, 2002, PHYS REV E, V66, P701; SMALL M, 2000, IEEE INTELLIGENT TRA, P252; Small M, 2004, PHYSICA D, V194, P283, DOI 10.1016/j.physd.2004.03.006; Takens F., 1981, LECT NOTES MATH, V898, P366, DOI DOI 10.1007/BFB0091924; Weigend A. S., 1994, TIME SERIES PREDICTI	26	0	0	1	6	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	2007	21	3					463	481		10.1142/S0218001407005545		19	Computer Science, Artificial Intelligence	Computer Science	234PH	WOS:000251175500002		
J	Bai, MR; Chen, MC				Bai, Mingsain R.; Chen, Meng-Chun			Intelligent preprocessing and classification of audio signals	JOURNAL OF THE AUDIO ENGINEERING SOCIETY			English	Article								An audio processor that integrates intelligent classification and preprocessing algorithms is presented. Audio features in the time and frequency domains are extracted and processed prior to classification. Classification algorithms, including the nearest neighbor rule (NNR), artificial neural networks (ANN), fuzzy neural networks (FNN), and hidden Markov models (HMM), are used to classify and identify singers and musical instruments. A training phase is required to establish a feature space template, followed by a test phase in which the audio features of the test data are calculated and matched to the feature space template. In addition to audio classification, the proposed system provides several independent component analysis (ICA)-based preprocessing functions for blind source separation, voice removal, and noise reduction. The proposed techniques were applied to process various kinds of audio program materials. The test results reveal that the performance of the methods is satisfactory, but varies slightly with the algorithm and program materials used in the tests.	Natl Chiao Tung Univ, Dept Mech Engn, Hsinchu 300, Taiwan	Bai, MR (reprint author), Natl Chiao Tung Univ, Dept Mech Engn, Hsinchu 300, Taiwan.	msbai@mail.nctu.edu.tw; MaggieChen@tp.cmcs.com.tw					Chai W, 2001, P INT C ART INT LAS; CHANG WS, 2001, THESIS NATL CHIAO TU; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRYSANDT H, 2003, P SPIE STORAGE RETRI; Demuth H, 1998, NEURAL NETWORK TOOLB; Harma A, 2001, IEEE T SPEECH AUDI P, V9, P769, DOI 10.1109/89.966080; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; HYVARINEN A, 1998, A51 HELS U TECHN HEL; LAMBROU T, 1998, P INT C AC SPEECH SI, V6, P3621, DOI 10.1109/ICASSP.1998.679665; LI CJ, 2001, INT MECH ENG C EXP N; Lin C.-T., 1996, NEURAL FUZZY SYSTEMS; Livshin A.A., 2004, P 7 INT C DIG AUD EF; LIVSHIN AA, 2003, P INT COMP MUS C; Logan B., 2000, P INT S MUS INF RETR; Martin K. D., 1998, 136 M AC SOC AM; MARTINEZ JM, MPEG 7 OVERVIEW VERS; PEETERS G, 2002, P 2002 INT COMP MUS, P455; Peeters Geoffroy, 2004, LARGE SET AUDIO FEAT; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SCOTT P, 2001, MUSIC CLASIFICATION; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; TZANETAKIS G, 2001, INT S MUS INF RETR; Wang CH, 2001, IEEE T SYST MAN CY B, V31, P467, DOI 10.1109/3477.931548; Zhang T, 2003, IEEE INT C MULT EXP; ZONGKER D, 1996, P 13 INT C PATT REC	25	2	2	0	5	AUDIO ENGINEERING SOC	NEW YORK	60 E 42ND ST, NEW YORK, NY 10165-2520 USA	1549-4950			J AUDIO ENG SOC	J. Audio Eng. Soc.	MAY	2007	55	5					372	384				13	Acoustics; Engineering, Multidisciplinary	Acoustics; Engineering	175CI	WOS:000246989800003		
J	Nicoletti, MD; Figueira, LB; Hruschka, ER				Nicoletti, Maria do Carmo; Figueira, Lucas Baggio; Hruschka, Estevarn R., Jr.			Transferring neural network based knowledge into an exemplar-based learner	NEURAL COMPUTING & APPLICATIONS			English	Article						knowledge transfer; RuleNet; NGE; hybrid systems	NEAREST-NEIGHBOR; CLASSIFICATION	This paper investigates knowledge transfer from a neural network based system into an exemplar-based learning system. In order to examine the possibilities of such transfer, it proposes and evaluates a system that implements a collaborative scheme, where a particular type of neural network induced by the neural system RuleNet is used by an exemplar-based system (NGE) to carry on a learning task. The proposed collaboration between the two learning models implemented as the hybrid system RuleNet -> NGE is feasible due to the similarity of the concept description languages employed by both. The paper also describes a few experiments conducted; results show that the RuIeNet-NGE collaboration is plausible and, in some domains, it improves the performance of NGE on its own.	UFCar, Dept Comp Sci, Sao Carlos, SP, Brazil; Univ Sao Paulo, Dept Math & Phys, DFM, FFCLRP, Sao Carlos, SP, Brazil	Nicoletti, MD (reprint author), UFCar, Dept Comp Sci, Sao Carlos, SP, Brazil.	carmo@dc.ufscar.br; lucas@neuron.ffclrp.usp.br; estevam@dc.ufscar.br	Hruschka Jr., Estevam/B-1073-2008				Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hettich S., 1998, UCI REPOSITORY MACHI; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Mitchell T. M., 1997, MACHINE LEARNING; Nauck D., 1997, FDN NEUROFUZZY SYSTE; NICOLETTI MC, 2005, P HYBR INT SYST HIS, P125; NICOLETTI MC, 2004, P INT C COMP CYB 200, P175; NICOLETTI MC, 2005, INTELLIGENT SYSTEMS, V2, P365; SALZBERG S, 1991, MACH LEARN, V6, P252; SALZBERG SL, 1989, THESIS HARVARD U CAM; TschicholdGurman N, 1997, FUZZY SET SYST, V85, P287, DOI 10.1016/0165-0114(95)00351-7; TSCHICHOLDGURMA.NN, 1995, THESIS ETH ZURICH; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658	15	1	1	1	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0941-0643			NEURAL COMPUT APPL	Neural Comput. Appl.	MAY	2007	16	3					257	265		10.1007/s00521-007-0088-8		9	Computer Science, Artificial Intelligence	Computer Science	175HN	WOS:000247004800006		
J	Srdoc, A; Bratko, I; Sluga, A				Srdoc, Alira; Bratko, Ivan; Sluga, Alojzij			Machine learning applied to quality management - A study in ship repair domain	COMPUTERS IN INDUSTRY			English	Article						quality management; knowledge acquisition; deep quality concept; delivery time estimate; dock works	KNOWLEDGE	The awareness about the importance of knowledge within the quality management community is increasing. For example, the Malcolm Baldrige Criteria for Performance Excellence recently included knowledge management into one of its categories. However, the emphasis in research related to knowledge management is mostly on knowledge creation and dissemination, and not knowledge formalisation process. On the other hand, identifying the expert knowledge and experience as crucial for the output quality, especially in dynamic industries with high share of incomplete and unreliable information such as ship repair, this paper argues how important it is to have such knowledge formalised. The paper demonstrates by example of delivery time estimate how for that purpose the deep quality concept (DQC)-a novel knowledge-focused quality management framework, and machine learning methodology could be effectively used. In the concluding part of the paper, the accuracy of the obtained prediction models is analysed, and the chosen model is discussed. The research indicates that standardisation of problem domain notions and expertly designed databases with possible interface to machine learning algorithms need to be considered as an integral part of any quality management system in the future, in addition to conventional quality management concepts. (C) 2006 Elsevier B.V. All rights reserved.	Dept Res & Dev, Rijeka 51000, Croatia; Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia; Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia; Jozef Stefan Inst, Fac Mech Engn, Ljubljana 1000, Slovenia	Srdoc, A (reprint author), Dept Res & Dev, 3 Maj Shipyard,Liburnijska 3, Rijeka 51000, Croatia.	alira.srdoc@3maj.hr	Sluga, Alojzij/A-7161-2008; 	Sluga, Alojzij/0000-0002-4973-4086			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Al-Hawamdeh S, 2002, INFORM RES, V8; ARMSTRONG J S, 2001, PRINCIPLES FORECASTI; BRATKO I, 2001, PROLOG PROGRAMMING A; Breiman L., 1984, CLASSIFICATION REGRE; Chryssolouris G, 2003, CIRP J MANUFACTURING, V32; Coff RW, 2002, J MANAGE, V28, P107, DOI 10.1177/014920630202800107; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOOLEY K, 2000, PARADIGMS QUALITY EV; DOOLEY K, 2000, J QUALITY MANAGEMENT, V4, P207; DZEROSKI S, 2003, ECOLOGICAL MODELLING, V170, P19; FILIPIC B, 1994, P 8 INT C COMP APPL; Karalic A, 1992, LINEAR REGRESSION RE; Linderman K, 2004, J OPER MANAG, V22, P589, DOI 10.1016/j.jom.2004.07.001; MASSOW C, 2005, P COMPIT; Meziane F., 2000, Integrated Manufacturing Systems, V11, DOI 10.1108/09576060010326221; Mitchell T. M., 1997, MACHINE LEARNING; MONOSTORI L, 1996, ANN CIRP, V45, P675; Peklenik J., 1995, MANUFACTURING SYSTEM, V24, P17; PETERAF MA, 1993, STRATEGIC MANAGE J, V14, P179, DOI 10.1002/smj.4250140303; Quinlan J. R., 1992, Proceedings of the 5th Australian Joint Conference on Artificial Intelligence. AI '92; Shigaki I, 2001, PROD PLAN CONTROL, V12, P379, DOI 10.1080/09537280010014695; Shigaki I, 1999, PROD PLAN CONTROL, V10, P727, DOI 10.1080/095372899232551; Simon H. A., 1981, SCI ARTIFICIAL; SIRE RA, 1992, INT J PRES VES PIP, V50, P297, DOI 10.1016/0308-0161(92)90044-G; Sluga A, 1998, COMPUT IND, V37, P185, DOI 10.1016/S0166-3615(98)00098-0; Spindler GR, 2001, QUAL PROG, V34, P83; Srdoc A., 2005, International Journal of Quality Reliability Management, V22, DOI 10.1108/02656710510582499; STIMSON WA, 1993, NAV ENG J, V105, P59; Todd J, 1999, NAV ENG J, V111, P257; Witten I.H., 2000, DATA MINING PRACTICA	31	5	5	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-3615			COMPUT IND	Comput. Ind.	JUN	2007	58	5					464	473		10.1016/j.compind.2006.09.013		10	Computer Science, Interdisciplinary Applications	Computer Science	168UI	WOS:000246549100008		
J	Scott, C; Davenport, M				Scott, Clayton; Davenport, Mark			Regression level set estimation via cost-sensitive classification	IEEE TRANSACTIONS ON SIGNAL PROCESSING			English	Article						cost-sensitive classification; learning reduction; regression level set estimation; supervised learning		Regression level set estimation is an important yet understudied learning task. It lies somewhere between regression function estimation and traditional binary classification, and in many cases is a more appropriate setting for questions posed in these more common frameworks. This note explains how estimating the level set of a regression function from training examples can be reduced to cost-sensitive classification. We discuss the theoretical and algorithmic benefits of this learning reduction, demonstrate several desirable properties of the associated risk, and report experimental results for histograms, support vector machines, and nearest neighbor rules on synthetic and real data.	Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA; Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA	Scott, C (reprint author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.	cscott@eecs.umich.edu; md@rice.edu					Beygelzimer A., 2005, P 22 INT MACH LEARN; Cavalier L, 1997, STATISTICS, V29, P131, DOI 10.1080/02331889708802579; Chang C.C., 2001, LIBSVM LIB SUPPORT V; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Elkan Charles, 2001, P 17 INT JOINT C ART, P973; Joachims T., 1999, ADV KERNEL METHODS S; Man TK, 2005, CANCER RES, V65, P8142, DOI 10.1158/0008-5472.CAN-05-0985; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; Scholkopf B., 2002, LEARNING KERNELS; Tsybakov AB, 2004, ANN STAT, V32, P135; Vapnik V., 1995, NATURE STAT LEARNIN; WILLETT R, 2006, IEEE T IMAGE PROCESS; WILLETT R, 2005, P SPIE, V5914; ZADROZNY B, 2003, P 3 INT C DAT MIN ME	17	8	8	2	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1053-587X			IEEE T SIGNAL PROCES	IEEE Trans. Signal Process.	JUN	2007	55	6	1				2752	2757		10.1109/TSP.2007.893758		6	Engineering, Electrical & Electronic	Engineering	170ZQ	WOS:000246705100035		
J	Carrizosa, E; Martin-Barragan, B; Plastria, F; Morales, DR				Carrizosa, Emilio; Martin-Barragan, Belen; Plastria, Frank; Morales, Dolores Romero			On the selection of the globally optimal prototype subset for nearest-neighbor classification	INFORMS JOURNAL ON COMPUTING			English	Article						classification; optimal prototype subset; nearest neighbor; dissimilarities; integer programming; variable neighborhood search; missing values	PATTERN-CLASSIFICATION; GENETIC ALGORITHMS; SEARCH	The nearest-neighbor classifier has been shown to be a powerful tool for multiclass classification. We explore both theoretical properties and empirical behavior of a variant method, in which the nearest-neighbor rule is applied to a reduced set of prototypes. This set is selected a priori by fixing its cardinality and minimizing the empirical misclassification cost. In this way we alleviate the two serious drawbacks of the nearest-neighbor method: high storage requirements and time-consuming queries. Finding this reduced set is shown to be NP-hard. We provide mixed integer programming (MIP) formulations, which are theoretically compared and solved by a standard MIP solver for small problem instances. We show that the classifiers derived from these formulations are comparable to benchmark procedures. We solve large problem instances by a metaheuristic that yields good classification rules in reasonable time. Additional experiments indicate that prototype-based nearest-neighbor classifiers remain quite stable in the presence of missing values.	Univ Seville, Fac Matemat, Seville 41012, Spain; Univ Carlos III Madrid, Dept Estadist, Madrid 28903, Spain; Vrije Univ Brussels, Dept Math Operat Res Stat & Informat Syst Managem, MOSI, B-1050 Brussels, Belgium; Univ Oxford, Said Sch Business, Oxford OX1 1HP, England	Carrizosa, E (reprint author), Univ Seville, Fac Matemat, Seville 41012, Spain.	ecarrizosa@us.es; belen.martin@uc3m.es; frank.plastria@vub.ac.be; dolores.romero-morales@sbs.ox.ac.uk		Carrizosa Priego, Emilio J./0000-0002-0832-8700; Romero Morales, Dolores/0000-0001-7945-1469			ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; ALTSCHUL SF, 1994, NAT GENET, V6, P119, DOI 10.1038/ng0294-119; Bennett MV, 2004, INFORMS J COMPUT, V16, P68, DOI 10.1287/ijoc.1020.0004; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Blake C. L., 1998, UCI REPOSITORY MACH; Breiman L., 1984, CLASSIFICATION REGRE; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CARRIZOSA E, 2005, RM02027 U MASSTR; Cochran W. G., 1977, SAMPLING TECHNIQUES, V3rd; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Devroye L., 1996, PROBABILISTIC THEORY; FREED N, 1981, EUR J OPER RES, V7, P44, DOI 10.1016/0377-2217(81)90048-5; Garey M. R., 1979, COMPUTERS INTRACTABI; GEHRLEIN WV, 1986, OPER RES LETT, V5, P299, DOI 10.1016/0167-6377(86)90068-4; GEVA S, 1991, IEEE T NEURAL NETWOR, V2, P318, DOI 10.1109/72.80344; Gochet W, 1997, OPER RES, V45, P213, DOI 10.1287/opre.45.2.213; Hansen P, 2001, J HEURISTICS, V7, P335, DOI 10.1023/A:1011336210885; Hansen P., 1997, Location Science, V5, DOI 10.1016/S0966-8349(98)00030-8; Hansen P, 2001, EUR J OPER RES, V130, P449, DOI 10.1016/S0377-2217(00)00100-4; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 2001, ELEMENTS STAT LEARNI; Kaufman L., 1990, FINDING GROUPS DATA; KING RD, 1995, APPL ARTIF INTELL, V9, P289, DOI 10.1080/08839519508945477; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Lipowezky U, 1998, PATTERN RECOGN LETT, V19, P907, DOI 10.1016/S0167-8655(98)00075-0; MANGASARIAN OL, 1994, J GLOBAL OPTIM, V5, P309, DOI 10.1007/BF01096681; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Plastria F, 2002, EUR J OPER RES, V140, P338, DOI 10.1016/S0377-2217(02)00073-5; PLASTRIA F, 2001, LOCATOR PUBLICATION, V2, P15; Plastria F, 1995, FACILITY LOCATION SU, P229; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Thompson SK, 2002, SAMPLING; Yang MS, 2001, FUZZY SET SYST, V120, P197, DOI 10.1016/S0165-0114(99)00146-3; ZIMMERMANN HJ, 1991, FUZZY SET THEORY APP	39	5	5	0	2	INFORMS	HANOVER	7240 PARKWAY DRIVE, STE 310, HANOVER, MD 21076-1310 USA	1091-9856			INFORMS J COMPUT	INFORMS J. Comput.	SUM	2007	19	3					470	479		10.1287/ijoc.1060.0183		10	Computer Science, Interdisciplinary Applications; Operations Research & Management Science	Computer Science; Operations Research & Management Science	203RD	WOS:000248990800014		
J	Ghosh, AK				Ghosh, Anil K.			On nearest neighbor classification using adaptive choice of k	JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS			English	Article						Bayesian strength function; cross-validation; misclassification rate; noninformative prior; optimal bayes risk; posterior probability; p value; robustness		Nearest neighbor classification is one of the simplest and popular methods for statistical pattern recognition. It classifies an observation x to the class, which is the most frequent in the neighborhood of x. The size of this neighborhood is usually determined by a predefined parameter k. Normally, one uses cross-validation techniques to estimate the optimum value of this parameter, and that estimated value is used for classifying all observations. However, in classification problems, in addition to depending on the training sample, a good choice of k depends on the specific observation to be classified. Therefore, instead of using a fixed value of k over the entire measurement space, a spatially adaptive choice of k may be more useful in practice. This article presents one such adaptive nearest neighbor classification technique, where the value of k is selected depending on the distribution of competing classes in the vicinity of the observation to be classified. The utility of the proposed method has been illustrated using some simulated examples and well-known benchmark datasets. Asymptotic optimality of its misclassification rate has been derived under appropriate regularity conditions.	Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India	Ghosh, AK (reprint author), Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India.	anilkghosh@rediffmail.com					Anderson T. W., 1984, INTRO MULTIVARIATE S, V2nd; Andrews D.F., 1985, DATA COLLECTION PROB; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1994, FLEXIBLE METRIC NEAR; GHOSH AK, 2004, THESIS INDIAN STAT I; Ghosh AK, 2006, IEEE T SYST MAN CY B, V36, P1139, DOI 10.1109/TSMCB.2006.873186; Gilks WR, 1996, MARKOV CHAIN MONTE C; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hodges J., 1951, 4 USAF SCH AV MED, P261; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Hopcroft J. E., 1974, DESIGN ANAL COMPUTER, V1st; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Opitz D., 1999, J ARTIFICIAL INTELLI, V11, P169, DOI DOI 10.1613/JAIR.614; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Ripley BD, 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; Seigmund D., 1985, SEQUENTIAL ANAL TEST; Silverman BW, 1986, DENSITY ESTIMATION S; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Tibshirani R, 1993, INTRO BOOTSTRAP; Wald A., 1973, SEQUENTIAL ANAL; Wettschereck D., 1994, ADV NEURAL INFORMATI, V1994, P184	34	5	7	0	0	AMER STATISTICAL ASSOC	ALEXANDRIA	1429 DUKE ST, ALEXANDRIA, VA 22314 USA	1061-8600			J COMPUT GRAPH STAT	J. Comput. Graph. Stat.	JUN	2007	16	2					482	502		10.1198/106186007x208380		21	Statistics & Probability	Mathematics	176AY	WOS:000247056300011		
J	Chin, CM; Popovic, MR; Thrasher, A; Cameron, T; Lozano, A; Chen, R				Chin, Cesar Marquez; Popovic, Milos R.; Thrasher, Adam; Cameron, Tracy; Lozano, Andres.; Chen, Robert			Identification of arm movements using correlation of electrocorticographic spectral components and kinematic recordings	JOURNAL OF NEURAL ENGINEERING			English	Article							BRAIN-COMPUTER-INTERFACE; HUMAN SENSORIMOTOR CORTEX; EVENT-RELATED DESYNCHRONIZATION; THOUGHT TRANSLATION DEVICE; LOCAL-FIELD POTENTIALS; SELF-PACED MOVEMENT; HUMAN MOTOR CORTEX; PARKINSONS-DISEASE; VISUOMOTOR TASKS; P300 SPELLER	The purpose of this study was to explore the possibility of using electrocorticographic (ECoG) recordings from subdural electrodes placed over the motor cortex to identify the upper limb motion performed by a human subject. More specifically, we were trying to identify features in the ECoG signals that could help us determine the type of movement performed by an individual. Two subjects who had subdural electrodes implanted over the motor cortex were asked to perform various motor tasks with the upper limb contralateral to the site of electrode implantation. ECoG signals and. upper limb kinematics were recorded while the participants were performing the movements. ECoG frequency components were identified that correlated well with the performed movements measured along 6D coordinates (X, Y, Z, roll, yaw and pitch). These frequencies were grouped using histograms. The resulting histograms had consistent and unique shapes that were representative of individual upper limb movements performed by the participants. Thus, it was possible to identify which movement was performed by the participant without prior knowledge of the arm and hand kinematics. To confirm these findings, a nearest neighbour classifier was applied to identify the specific movement that each participant had performed. The achieved classification accuracy was 89%.	Univ Toronto, Inst Biomat & Biomed Engn, Toronto, ON M5S 3G9, Canada; Toronto Rehabil Inst, Rehabil Engn Lab, Toronto, ON M4G 3V9, Canada; Univ Toronto, Univ Hlth Network, Toronto Western Res Inst, Toronto, ON M5T 2S8, Canada; Univ Toronto, Dept Surg, Toronto, ON M5T 2S8, Canada; Univ Toronto, Dept Med, Div Neurol, Toronto, ON M5T 2S8, Canada	Chin, CM (reprint author), Univ Toronto, Inst Biomat & Biomed Engn, 164 Coll St, Toronto, ON M5S 3G9, Canada.	cesar.marquezchin@utoronto.ca; milos.popovic@utoronto.ca	Chen, Robert/B-3899-2009	Chen, Robert/0000-0002-8371-8629			AN KN, 1988, J BIOMECH, V21, P613, DOI 10.1016/0021-9290(88)90225-4; Aoki F, 1999, CLIN NEUROPHYSIOL, V110, P524, DOI 10.1016/S1388-2457(98)00064-9; Aoki F, 2001, BIOSYSTEMS, V63, P89, DOI 10.1016/S0303-2647(01)00149-6; Birbaumer N, 2000, IEEE T REHABIL ENG, V8, P190, DOI 10.1109/86.847812; Cooper R, 2005, TECHNIQUES CLIN NEUR; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crone NE, 1998, BRAIN, V121, P2271, DOI 10.1093/brain/121.12.2271; Crone NE, 1998, BRAIN, V121, P2301, DOI 10.1093/brain/121.12.2301; Deng Jie, 2005, J Neural Eng, V2, P131, DOI 10.1088/1741-2560/2/4/009; Donchin E, 2000, IEEE T REHABIL ENG, V8, P174, DOI 10.1109/86.847808; Duda R O, 2001, PATTERN CLASSIFICATI; Friehs GM, 2004, STROKE, V35, P2702, DOI 10.1161/01.STR.0000143235.93497.03; Gonzalez SL, 2006, NEUROIMAGE, V32, P170, DOI 10.1016/j.neuroimage.2006.02.041; Graimann B, 2003, IEEE T NEUR SYS REH, V11, P276, DOI 10.1109/TNSRE.2003.816863; Graimann B, 2004, IEEE T BIO-MED ENG, V51, P954, DOI 10.1109/TBME.2004.826671; Hanajima R, 2002, CLIN NEUROPHYSIOL, V113, P635, DOI 10.1016/S1388-2457(02)00042-1; Heldman DA, 2006, IEEE T NEUR SYS REH, V14, P180, DOI 10.1109/TNSRE.2006.875549; Hill NJ, 2006, IEEE T NEUR SYS REH, V14, P183, DOI 10.1109/TNSRE.2006.875548; Hinterberger T, 2004, IEEE T BIO-MED ENG, V51, P1011, DOI 10.1109/TBME.2004.827067; Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970; Kauhanen L, 2006, IEEE T NEUR SYS REH, V14, P190, DOI 10.1109/TNSRE.2006.875546; Kauhanen L, 2006, CLIN NEUROPHYSIOL, V117, P430, DOI 10.1016/j.clinph.2005.10.024; Kennedy PR, 2000, IEEE T REHABIL ENG, V8, P198, DOI 10.1109/86.847815; Krusienski DJ, 2006, J NEURAL ENG, V3, P299, DOI 10.1088/1741-2560/3/4/007; Kubler A, 1999, EXP BRAIN RES, V124, P223, DOI 10.1007/s002210050617; Leuthardt Eric C, 2004, J Neural Eng, V1, P63, DOI 10.1088/1741-2560/1/2/001; Leuthardt EC, 2006, IEEE T NEUR SYS REH, V14, P194, DOI 10.1109/TNSRE.2006.875536; Levine SP, 2000, IEEE T REHABIL ENG, V8, P180, DOI 10.1109/86.847809; Levine SP, 1999, J CLIN NEUROPHYSIOL, V16, P439, DOI 10.1097/00004691-199909000-00005; Lozano AM, 2001, PARKINSONISM RELAT D, V7, P199, DOI 10.1016/S1353-8020(00)00057-2; Magnani G, 1998, MOVEMENT DISORD, V13, P653, DOI 10.1002/mds.870130408; Mayberg HS, 2005, NEURON, V45, P651, DOI 10.1016/j.neuron.2005.02.014; Mehring C, 2003, NAT NEUROSCI, V6, P1253, DOI 10.1038/nn1158; Mehring C, 2004, J PHYSIOLOGY-PARIS, V98, P498, DOI 10.1016/j.jphysparis.2005.09.016; Muller-Putz GR, 2005, NEUROSCI LETT, V382, P169, DOI 10.1016/j.neulet.2005.03.021; Naeem M, 2006, J NEURAL ENG, V3, P208, DOI 10.1088/1741-2560/3/3/003; Neuper C, 2003, CLIN NEUROPHYSIOL, V114, P399, DOI 10.1016/S1388-2457(02)00387-5; Pfurtscheller G, 2006, IEEE T NEUR SYS REH, V14, P205, DOI 10.1109/TNSRE.2006.875528; Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3; Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003; PFURTSCHELLER G, 1977, ELECTROEN CLIN NEURO, V42, P817, DOI 10.1016/0013-4694(77)90235-8; Pfurtscheller G, 2003, NEUROSCI LETT, V351, P33, DOI 10.1016/S0304-3940(03)00947-9; Pfurtscheller G, 2003, CLIN NEUROPHYSIOL, V114, P1226, DOI 10.1016/S1388-2457(03)00067-1; Popovic MR, 2001, IEEE ENG MED BIOL, V20, P82, DOI 10.1109/51.897831; Rickert J, 2005, J NEUROSCI, V25, P8815, DOI 10.1523/JNEUROSCI.0816-05.2005; Scherberger H, 2005, NEURON, V46, P347, DOI 10.1016/j.neuron.2005.03.004; Sellers EW, 2006, CLIN NEUROPHYSIOL, V117, P538, DOI 10.1016/j.clinph.2005.06.027; Sellers EW, 2006, IEEE T NEUR SYS REH, V14, P221, DOI 10.1109/TNSRE.2006.875580; Sellers EW, 2006, BIOL PSYCHOL, V73, P242, DOI 10.1016/j.biopsycho.2006.04.007; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; TORO C, 1994, ELECTROEN CLIN NEURO, V93, P390, DOI 10.1016/0168-5597(94)90127-9; Weiskopf N, 2004, IEEE T BIO-MED ENG, V51, P966, DOI 10.1109/TBME.2004.827063; Wessberg J, 2000, NATURE, V408, P361; Wilson JA, 2006, IEEE T NEUR SYS REH, V14, P246, DOI 10.1109/TNSRE.2006.875570; Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807; Yamawaki N, 2006, IEEE T NEUR SYS REH, V14, P250, DOI 10.1109/TNSRE.2006.875567	57	13	14	0	2	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1741-2560			J NEURAL ENG	J. Neural Eng.	JUN	2007	4	2					146	158		10.1088/1741-2560/4/2/014		13	Engineering, Biomedical; Neurosciences	Engineering; Neurosciences & Neurology	188VL	WOS:000247947300020	17409488	
J	Shen, HB; Yang, J; Chou, KC				Shen, H.-B.; Yang, J.; Chou, K.-C.			Euk-PLoc: an ensemble classifier for large-scale eukaryotic protein subcellular location prediction	AMINO ACIDS			English	Article						cellular networking; subcellular compartment; KNN classifier; fusion; voting; gene ontology; amphiphilic pseudo amino acid composition	AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; SORTING SIGNALS; GENE ONTOLOGY; LOCALIZATION; SEQUENCE; REPRESENTATION; SPECTRUM	With the avalanche of newly-found protein sequences emerging in the post genomic era, it is highly desirable to develop an automated method for fast and reliably identifying their subcellular locations because knowledge thus obtained can provide key clues for revealing their functions and understanding how they interact with each other in cellular networking. However, predicting subcellular location of eukaryotic proteins is a challenging problem, particularly when unknown query proteins do not have significant homology to proteins of known subcellular locations and when more locations need to be covered. To cope with the challenge, protein samples are formulated by hybridizing the information derived from the gene ontology database and amphiphilic pseudo amino acid composition. Based on such a representation, a novel ensemble hybridization classifier was developed by fusing many basic individual classifiers through a voting system. Each of these basic classifiers was engineered by the KNN ( K-Nearest Neighbor) principle. As a demonstration, a new benchmark dataset was constructed that covers the following 18 localizations: ( 1) cell wall, ( 2) centriole, ( 3) chloroplast, ( 4) cyanelle, ( 5) cytoplasm, ( 6) cytoskeleton, ( 7) endoplasmic reticulum, ( 8) extracell, ( 9) Golgi apparatus, ( 10) hydrogenosome, ( 11) lysosome, ( 12) mitochondria, ( 13) nucleus, ( 14) peroxisome, ( 15) plasma membrane, ( 16) plastid, ( 17) spindle pole body, and ( 18) vacuole. To avoid the homology bias, none of the proteins included has >= 25% sequence identity to any other in a same subcellular location. The overall success rates thus obtained via the 5-fold and jackknife cross-validation tests were 81.6 and 80.3%, respectively, which were 40-50% higher than those performed by the other existing methods on the same strict dataset. The powerful predictor, named "Euk-PLoc'', is available as a web-server at http:// 202.120.37.186/ bioinf/euk. Furthermore, to support the need of people working in the relevant areas, a downloadable file will be provided at the same website to list the results predicted by Euk-PLoc for all eukaryotic protein entries ( excluding fragments) in Swiss-Prot database that do not have subcellular location annotations or are annotated as being uncertain. The large-scale results will be updated twice a year to include the new entries of eukaryotic proteins and reflect the continuous development of Euk-PLoc.	Gordon Life Sci Inst, San Diego, CA 92130 USA; Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China	Shen, HB (reprint author), Gordon Life Sci Inst, 13784 Torrey Mar Dr, San Diego, CA 92130 USA.	kchow@san.rr.com	Chou, Kuo-Chen/A-8340-2009				Apweiler R, 2004, NUCLEIC ACIDS RES, V32, P115; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Camon E, 2004, NUCLEIC ACIDS RES, V32, P262; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 1997, PROTEINS, V28, P99, DOI 10.1002/(SICI)1097-0134(199705)28:1<99::AID-PROT10>3.0.CO;2-C; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; Chou KC, 2000, ANAL BIOCHEM, V286, P1, DOI 10.1006/abio.2000.4757; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; Chou KC, 2003, BIOCHEM BIOPH RES CO, V311, P743, DOI 10.1016/j.bbrc.2003.10.062; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hoglund A, 2006, BIOINFORMATICS, V22, P1158, DOI 10.1093/bioinformatics/btl002; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lee Vivian, 2005, In Silico Biology, V5, P5; Liu H, 2005, BIOCHEM BIOPH RES CO, V338, P1005, DOI 10.1016/j.bbrc.2005.10.046; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Radford T, 2003, SCIENTIST, V17, P24; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; Sun XD, 2006, AMINO ACIDS, V30, P469, DOI 10.1007/s00726-005-0239-0; Wang GL, 2003, BIOINFORMATICS, V19, P1589, DOI 10.1093/bioinformatics/btg224; Wang M, 2005, AMINO ACIDS, V28, P395, DOI 10.1007/s00726-005-0189-6; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; Wang SQ, 2006, J THEOR BIOL, V242, P941, DOI 10.1016/j.jtbi.2006.05.006; WEN Z, 2007, IN PRESS AMINO ACIDS; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	68	97	99	2	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0939-4451			AMINO ACIDS	Amino Acids	JUL	2007	33	1					57	67		10.1007/s00726-006-0478-8		11	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	192FM	WOS:000248186200006	17235453	
J	Read, I; Cox, S				Read, Ian; Cox, Stephen			Stochastic and syntactic techniques for predicting phrase breaks	COMPUTER SPEECH AND LANGUAGE			English	Article						text-to-speech; prosody; phrase breaks	PERFORMANCE STRUCTURES; SPEECH	Determining the position of breaks in a sentence is a key task for a text-to-speech system. A synthesized sentence containing incorrect breaks at best requires increased listening effort, and at worst, may have lower intelligibility and different semantics from a correctly phrased sentence. In addition, the position of breaks must be known before other components of the sentence's prosodic structure can be determined. We consider here some methods for phrase break prediction in which the whole sentence is analysed, in contrast to most previous work which has focused on analysing an area around an individual juncture. One of the main features we use is part-of-speech tags. First, we report an algorithm that reduces the number of tags in the tagset whilst improving break prediction accuracy. We then describe three approaches to break prediction: by analogy, in which we find the best-matching sentence in our training data to the unseen sentence; by phrase modelling, in which we build stochastic models of phrases and use these, together with a "phrase grammar", to segment the unseen sentence; and finally, using features derived from a syntactic parse of the sentence. All techniques achieve well above our baseline performance, which used punctuation symbols to determine break positions, and performance increased with each successive technique. Our best result, obtained on the MARSEC corpus and using a combination of parse tree derived features and a local feature, gave an F score of 81.6%, which we believe to be the highest published on this dataset. (c) 2006 Published by Elsevier Ltd.	Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England	Read, I (reprint author), Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.	ihr@cmp.uea.ac.uk; sjc@cmp.uea.ac.uk					ALLEN J, 1979, SPEECH COMM 7 M ASA, P507; Bachenko J., 1990, Computational Linguistics, V16; Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [10.1017/S095267570000066X, DOI 10.1017/S095267570000066X]; BELLMAN R, 1962, J ACM, V9, P61, DOI 10.1145/321105.321111; Breiman L., 1984, CLASSIFICATION REGRE; Brill E, 1995, COMPUT LINGUIST, V21, P543; Busser G., 2001, P 4 ISCA TUT RES WOR, P29; CAMPBELL WN, 1991, J PHONETICS, V19, P37; CHARNIAK E, 2000, P ANLP NAACL SEATTL; Church K. W., 1991, Computer Speech and Language, V5, DOI 10.1016/0885-2308(91)90016-J; Collins M., 1999, THESIS U PENNSYLVANI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX S, 2005, P EUR LISB PORT; Daelemans W., 1996, 4 WORKSH VER LARG CO, P14; DAELEMANS W, 2004, ILK RES GROUP TECHNI, V402; Decoste D, 2002, MACH LEARN, V46, P161, DOI 10.1023/A:1012454411458; DOMMERGUES JY, 1981, MEM COGNITION, V9, P478, DOI 10.3758/BF03202342; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; FACH M, 1999, EUROSPEECH, V1, P527; FORNEY GD, 1973, P IEEE, V61, P3; GEE JP, 1983, COGNITIVE PSYCHOL, V15, P411, DOI 10.1016/0010-0285(83)90014-2; GOOD IJ, 1953, BIOMETRIKA, V40, P16; GROSJEAN F, 1979, COGNITIVE PSYCHOL, V11, P58, DOI 10.1016/0010-0285(79)90004-5; Hirschberg J., 1993, ARTIFICIAL INTELLIGE, P63; Hirschberg J, 1996, SPEECH COMMUN, V18, P281, DOI 10.1016/0167-6393(96)00017-9; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; KOEHN P, 2000, P INT C AC SPEECH SI; Levenshtein VI, 1966, CYBERNETICS CONTROL, V10, P707; MARSI E, 2003, P 41 ANN M ASS COMP; Ostendorf M., 1995, ECS95001 BOST U; Ostendorf M., 1994, Computational Linguistics, V20; Pearl J., 1984, HEURISTICS INTELLIGE; Pierrehumbert J., 1980, THESIS MIT; Pitrelli J. F., 1994, P INT C SPOK LANG PR, P123; Quinlan J.R, 1992, C4 5 PROGRAMS MACHIN; READ IH, 2004, P INT C SPOK LANG PR; ROACH P, 1992, J INT PHONETIC ASS, V23, P47; SANTORINI B, 1990, PART OF SPEECH TAGGI; Silverman K., 1992, P INT C SPOK LANG PR, V2, P867; Silverman K. E. A., 1987, THESIS U CAMBRIDGE; SORIN C, 1987, P INT C PHON SCI, V1, P125; Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041; van Rijsbergen C. J, 1975, INFORM RETRIEVAL; van Santen J, 1998, MULTILINGUAL TEXT-TO-SPEECH SYNTHESIS: THE BELL LABS APPROACH, P115; WANG M, 1992, COMPUTER SPEECH LANG, V6; Young S., 2002, HTK BOOK HTK VERSION	46	5	6	0	0	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0885-2308			COMPUT SPEECH LANG	Comput. Speech Lang.	JUL	2007	21	3					519	542		10.1016/j.csl.2006.09.004		24	Computer Science, Artificial Intelligence	Computer Science	152IM	WOS:000245355600006		
J	Shang, WQ; Huang, HK; Zhu, HB; Lin, YM; Qu, YL; Wang, ZH				Shang, Wenqian; Huang, Houkuan; Zhu, Haibin; Lin, Yongmin; Qu, Youli; Wang, Zhihai			A novel feature selection algorithm for text categorization	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						text feature selection; text categorization; Gini index; kNN classifier; text preprocessing	NEAREST NEIGHBOR	With the development of the web, large numbers of documents are available on the Internet. Digital libraries, news sources and inner data of companies surge more and more. Automatic text categorization becomes more and more important for dealing with massive data. However the major problem of text categorization is the high dimensionality of the feature space. At present there are many methods to deal with text feature selection. To improve the performance of text categorization, we present another method of dealing with text feature selection. Our study is based on Gini index theory and we design a novel Gini index algorithm to reduce the high dimensionality of the feature space. A new measure function of Gini index is constructed and made to fit text categorization. The results of experiments show that our improvements of Gini index behave better than other methods of feature selection. (c) 2006 Elsevier Ltd. All rights reserved.	Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; Nipissing Univ, Dept Comp Sci, N Bay, ON P1B 8L7, Canada	Shang, WQ (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	shangwenqian@hotmail.com; haibinz@npissingu.ca					Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gupta S. K., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707410; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Rijsbergen V., 1979, INFORM RETRIEVAL, V2nd; SHANG W, 2005, P INT C COMP INT SEC, P741; Shankar S., FEATURE WEIGHT ADJUS; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vapnik V. N., 1995, NATURE STAT LEARNING; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y, 1997, INFORM RETRIEVAL, V1, P76	16	56	59	2	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JUL	2007	33	1					1	5		10.1016/j.eswa.2006.04.001		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	134UV	WOS:000244110600001		
J	Ball, NM; Brunner, RJ; Myers, AD; Strand, NE; Alberts, SL; Tcheng, D; Llora, X				Ball, Nicholas M.; Brunner, Robert J.; Myers, Adam D.; Strand, Natalie E.; Alberts, Stacey L.; Tcheng, David; Llora, Xavier			Robust machine learning applied to astronomical data sets. II. quantifying photometric redshifts for quasars using instance-based learning	ASTROPHYSICAL JOURNAL			English	Article						catalogs; cosmology : miscellaneous; methods : data analysis; quasars : general	DIGITAL-SKY-SURVEY; HUBBLE DEEP FIELD; ARTIFICIAL NEURAL-NETWORKS; LUMINOUS RED GALAXIES; EARLY DATA RELEASE; CLASSIFIED QUASARS; CLUSTERING ANALYSES; EVOLUTION; CATALOG; SDSS	We apply instance- based machine learning in the form of a k- nearest neighbor algorithm to the task of estimating photometric redshifts for 55,746 objects spectroscopically classified as quasars in the Fifth Data Release of the SloanDigital Sky Survey. We compare the results obtained to those froman empirical color- redshift relation ( CZR). In contrast to previously published results using CZRs, we find that the instance- based photometric redshifts are assigned with no regions of catastrophic failure. Remaining outliers are simply scattered about the ideal relation, in a manner similar to the pattern seen in the optical for normal galaxies at redshifts z less than or similar to 1. The instance- based algorithm is trained on a representative sample of the data and pseudoYblind- tested on the remaining unseen data. The variance between the photometric and spectroscopic redshifts is sigma(2) =0.123 +/- 0: 002 ( compared to sigma (2) =0.265 +/- 0. 006 for the CZR), and 54. 9% +/- 0: 7%, 73. 3% +/- 0.6%, and 80.7% +/- 0.3% of the objects are within Delta z < 0.1, 0.2, and 0.3, respectively. We also match our sample to the Second Data Release of the Galaxy Evolution Explorer legacy data, and the resulting 7642 objects show a further improvement, giving a variance of sigma(2) = 0.054 +/- 0. 005, with 70. 8% +/- 1. 2%, 85.8% +/- 1. 0%, and 90. 8% +/- 0.7% of objects within Delta z < 0. 1, 0.2, and 0.3. We show that the improvement is indeed due to the extra information provided by GALEX, by training on the same data set using purely SDSS photometry, which has a variance of sigma (2) = 0. 090 +/- 0. 007. Each set of results represents a realistic standard for application to further data sets for which the spectra are representative.	Univ Illinois, Dept Astron, Urbana, IL 61801 USA; Univ Illinois, Natl Ctr Supercomp Applicat, Urbana, IL 61801 USA; Univ Illinois, Dept Phys, Urbana, IL 61801 USA	Ball, NM (reprint author), Univ Illinois, Dept Astron, 1002 W Green St, Urbana, IL 61801 USA.						Abazajian K, 2004, ASTRON J, V128, P502, DOI 10.1086/421365; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Babbedge TSR, 2004, MON NOT R ASTRON SOC, V353, P654, DOI 10.1111/j.1365-2966.2004.08105.x; Ball NM, 2004, MON NOT R ASTRON SOC, V348, P1038, DOI 10.1111/j.1365-2966.2004.07429.x; Ball NM, 2006, ASTROPHYS J, V650, P497, DOI 10.1086/507440; Baum W. A., 1962, IAU S, V15, P390; Beckwith SVW, 2006, ASTRON J, V132, P1729, DOI 10.1086/507302; Benitez N, 2000, ASTROPHYS J, V536, P571, DOI 10.1086/308947; Brunner R. J., 1997, APJ, V482, P21; Brunner RJ, 2000, ASTROPHYS J, V541, P527, DOI 10.1086/309488; Budavari T, 2001, ASTRON J, V122, P1163, DOI 10.1086/322131; Cannon R, 2006, MON NOT R ASTRON SOC, V372, P425, DOI 10.1111/j.1365-2966.2006.10875.x; CARDELLI JA, 1989, ASTROPHYS J, V345, P245, DOI 10.1086/167900; Coe D, 2006, ASTRON J, V132, P926, DOI 10.1086/505530; Collister A, 2007, MON NOT R ASTRON SOC, V375, P68, DOI 10.1111/j.1365-2966.2006.11305.x; Collister AA, 2004, PUBL ASTRON SOC PAC, V116, P345, DOI 10.1086/383254; CONNOLLY AJ, 1998, APJ, V499, P125; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Croom SM, 2004, MON NOT R ASTRON SOC, V349, P1397, DOI 10.1111/j.1365-2966.2004.07619.x; Csabai I, 2003, ASTRON J, V125, P580, DOI 10.1086/345883; Eisenstein DJ, 2001, ASTRON J, V122, P2267, DOI 10.1086/323717; Firth AE, 2003, MON NOT R ASTRON SOC, V339, P1195, DOI 10.1046/j.1365-8711.2003.06271.x; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Goldberg DE, 2002, DESIGN INNOVATION; Gwyn SDJ, 1996, ASTROPHYS J, V468, pL77, DOI 10.1086/310237; Hastie T, 2001, ELEMENTS STAT LEARNI; Haupt R. L., 1998, PRACTICAL GENETIC AL; Hogg DW, 1998, ASTRON J, V115, P1418, DOI 10.1086/300277; HOLLAND JH, 1975, ADAPTATION NATURAL A; KOO DC, 1985, ASTRON J, V90, P418, DOI 10.1086/113748; Lanzetta KM, 1996, NATURE, V381, P759, DOI 10.1038/381759a0; LAWRENCE A, 2006, UNPUB MNRAS; LOH ED, 1986, ASTROPHYS J, V303, P154, DOI 10.1086/164062; Martin DC, 2005, ASTROPHYS J, V619, pL1, DOI 10.1086/426387; MOBASHER B, 1996, MNRAS, V282, P7; Myers AD, 2006, ASTROPHYS J, V638, P622, DOI 10.1086/499093; Myers AD, 2007, ASTROPHYS J, V658, P85, DOI 10.1086/511519; Myers AD, 2007, ASTROPHYS J, V658, P99, DOI 10.1086/511520; Padmanabhan N, 2005, MON NOT R ASTRON SOC, V359, P237, DOI 10.1111/j.1365-2966.2005.08915.x; Richards GT, 2001, ASTRON J, V122, P1151, DOI 10.1086/322132; Sawicki MJ, 1997, ASTRON J, V113, P1, DOI 10.1086/118231; Schlegel DJ, 1998, ASTROPHYS J, V500, P525, DOI 10.1086/305772; Skrutskie MF, 2006, ASTRON J, V131, P1163, DOI 10.1086/498708; Stoughton C, 2002, ASTRON J, V123, P485, DOI 10.1086/324741; TAGLIAFERRI R, 2002, ASTROPH0203445; Vanden Berk DE, 2005, ASTRON J, V129, P2047, DOI 10.1086/427856; Vanzella E, 2004, ASTRON ASTROPHYS, V423, P761, DOI 10.1051/0004-6361:20040176; Wadadekar Y, 2005, PUBL ASTRON SOC PAC, V117, P79, DOI 10.1086/427710; Wang Y, 1998, ASTRON J, V116, P2081, DOI 10.1086/300592; Way MJ, 2006, ASTROPHYS J, V647, P102, DOI 10.1086/505293; Weinstein MA, 2004, ASTROPHYS J SUPPL S, V155, P243, DOI 10.1086/425355; WELGE M, 2003, DATA KNOWLEDGE; Werner MW, 2004, ASTROPHYS J SUPPL S, V154, P1, DOI 10.1086/422992; Williams RE, 2000, ASTRON J, V120, P2735, DOI 10.1086/316854; Williams RE, 1996, ASTRON J, V112, P1335, DOI 10.1086/118105; Witten I. H., 2000, DATA MINING; Wolf C, 2004, ASTRON ASTROPHYS, V421, P913, DOI 10.1051/0004-6361:20040525; Wolf C, 2003, ASTRON ASTROPHYS, V408, P499, DOI 10.1051/0004-6361:20030990; Wu XB, 2004, CHINESE J ASTRON AST, V4, P17; York DG, 2000, ASTRON J, V120, P1579, DOI 10.1086/301513	60	27	27	1	8	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0004-637X			ASTROPHYS J	Astrophys. J.	JUL 10	2007	663	2	1				774	780		10.1086/518362		7	Astronomy & Astrophysics	Astronomy & Astrophysics	189PR	WOS:000248001500007		
J	Alfo, M; Farcomeni, A; Tardella, L				Alfo, Marco; Farcomeni, Alessio; Tardella, Luca			Robust semiparametric mixing for detecting differentially expressed genes in microarray experiments	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article; Proceedings Paper	Conference on Computational Statistics and Data Analysis	OCT 28-31, 2005	Limassol, CYPRUS	IASC-CSDA		microarray data; up-regulated genes; mixture models; counting distribution; false discovery rate	FALSE DISCOVERY RATE; CLASSIFICATION; MODELS; POWER	An important goal of microarray studies is the detection of genes that show significant changes in observed expressions when two or more classes of biological samples such as treatment and control are compared. Using the c-fold rule, a gene is declared to be differentially expressed if its average expression level varies by more than a constant factor c between treatment and control (typically c = 2). While often used, however, this simple rule is not completely convincing. By modeling this filter, a binary variable is defined at the gene x experiment level, allowing for a more powerful treatment of the corresponding information. A gene-specific random term is introduced to control for both dependence among genes and variability with respect to the c-fold threshold. Inference is carried out via a two-level finite mixture model under a likelihood approach. Then, parameter estimates are also derived using the counting distribution under a Bayesian nonparametric approach which allows to keep under control some error rate of erroneous discoveries. The effectiveness of both proposed approaches is illustrated through a large-scale simulation study and a well known benchmark data set. (C) 2006 Elsevier B.V. All rights reserved.	Univ Roma La Sapienza, Dipartimento Stat Probabil & Stat Applicate, I-00185 Rome, Italy	Alfo, M (reprint author), Univ Roma La Sapienza, Dipartimento Stat Probabil & Stat Applicate, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	marco.alfo@uniroma1.it					ALON U, 1999, P NATL ACAD SCI USA, V96, P6746; Amaratunga D., 2004, EXPLORATION ANAL DNA; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Boulesteix AL, 2006, COMPUT STAT DATA AN, V50, P783, DOI 10.1016/j.csda.2004.10.004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeCook R, 2006, COMPUT STAT DATA AN, V50, P518, DOI 10.1016/j.csda.2004.09.004; DETTE H, 1997, PROBABILITY ANAL; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; GEORGE EO, 1995, BIOMETRICS, V51, P512, DOI 10.2307/2532939; GIESEG M, 2002, BMC BIOINFORMATICS, P3; GILKS WR, 1992, APPL STAT-J ROY ST C, V41, P337, DOI 10.2307/2347565; GILKS WR, 1998, MARKOV CHAIN MONTE; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gusnanto A, 2005, STAT APPL GENET MO B, V4; HOCHBERG Y, 1987, MULITIPLE COMPARISIO; Huang SG, 2006, J COMPUT BIOL, V13, P786, DOI 10.1089/cmb.2006.13.786; Kerr MK, 2001, BIOSTATISTICS, V2, P183, DOI DOI 10.1093/BIOSTATISTICS/2.2.183; Landgrebe J, 2006, COMPUT STAT DATA AN, V50, P499, DOI 10.1016/j.csda.2004.08.014; Lee MLT, 2005, J BIOPHARM STAT, V15, P783, DOI 10.1081/BIP-200067778; Parmigiani G., 2003, ANAL GENE EXPRESSION; POLLARD K, 2003, 107 DIV BIOST UC BER; Sabatti C, 2002, MATH BIOSCI, V176, P17, DOI 10.1016/S0025-5564(01)00102-X; Schena M., 2000, MICROARRAY BIOCHIP T, P01760; Skubitz KM, 2006, J LAB CLIN MED, V147, P250, DOI 10.1016/j.lab.2006.04.001; Steibel JP, 2005, STAT APPL GENET MO B, V4; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Tardella L, 2002, BIOMETRIKA, V89, P807, DOI 10.1093/biomet/89.4.807; Tuscher VG, 2001, P NATL ACAD SCI USA, V98, P5116; Wolfinger RD, 2001, J COMPUT BIOL, V8, P625, DOI 10.1089/106652701753307520	30	2	2	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	JUL 15	2007	51	11					5253	5265		10.1016/j.csda.2006.08.009		13	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	192NB	WOS:000248207700006		
J	Roggo, Y; Chalus, P; Maurer, L; Lema-Martinez, C; Edmond, A; Jent, N				Roggo, Yves; Chalus, Pascal; Maurer, Lene; Lema-Martinez, Carmen; Edmond, Aurelie; Jent, Nadine			A review of near infrared spectroscopy and chemometrics in pharmaceutical technologies	JOURNAL OF PHARMACEUTICAL AND BIOMEDICAL ANALYSIS			English	Review						near infrared spectroscopy; chemometrics; pharmaceuticals; on-line; quality control; identification; qualification; quantification	ARTIFICIAL NEURAL-NETWORKS; CELL-CULTURE-MEDIA; DIFFUSE-REFLECTANCE SPECTROSCOPY; SUPPORT VECTOR MACHINES; SUPERVISED PATTERN-RECOGNITION; ORTHOGONAL SIGNAL CORRECTION; SUBMERGED FUNGAL BIOPROCESS; ALPHA-LACTOSE-MONOHYDRATE; LINE MOISTURE MEASUREMENT; LEAST-SQUARES REGRESSION	Near-infrared spectroscopy (NIRS) is a fast and non-destructive analytical method. Associated with chemometrics, it becomes a powerful tool for the pharmaceutical industry. Indeed, NIRS is suitable for analysis of solid, liquid and biotechnological pharmaceutical forms. Moreover, NIRS can be implemented during pharmaceutical development, in production for process monitoring or in quality control laboratories. This review focuses on chemometric techniques and pharmaceutical NIRS applications. The following topics are covered: qualitative analyses, quantitative methods and on-line applications. Theoretical and practical aspects are described with pharmaceutical examples of NIRS applications. (c) 2007 Elsevier B.V. All rights reserved.	F Hoffmann La Roche & Co Ltd, CH-4002 Basel, Switzerland	Roggo, Y (reprint author), F Hoffmann La Roche & Co Ltd, CH-4002 Basel, Switzerland.	yves.roggo@roche.com	roggo, yves/F-2214-2011; 	roggo, yves/0000-0003-3509-7642			Adams M. J., 1995, CHEMOMETRICS ANAL SP; Andersson M, 1999, J PHARMACEUT BIOMED, V20, P27, DOI 10.1016/S0731-7085(98)00237-4; Andersson M, 2000, ANAL CHEM, V72, P2099, DOI 10.1021/ac990256r; Andre M, 2003, ANAL CHEM, V75, P3460, DOI 10.1021/ac026393x; Arnold SA, 2000, ENZYME MICROB TECH, V27, P691, DOI 10.1016/S0141-0229(00)00271-4; ARNOLD SA, 2002, BIOPHARM INTERN  NOV; Arnold SA, 2003, BIOTECHNOL BIOENG, V84, P13, DOI 10.1002/bit.10738; ARNOLD SA, 2003, BIOPHARM INT     JAN; Atti E, 2002, BONE, V31, P675, DOI 10.1016/S8756-3282(02)00905-5; Bai SJ, 2005, J PHARM SCI-US, V94, P2030, DOI 10.1002/jps.20416; Bai SJ, 2004, J PHARM SCI-US, V93, P2439, DOI 10.1002/jps.20153; Baratieri SC, 2006, J PHARMACEUT BIOMED, V40, P51, DOI 10.1016/j.jpba.2005.05.025; Barnes R. J., 1993, J NEAR INFRARED SPEC, V1, P185; Bergman EL, 2006, J PHARMACEUT BIOMED, V41, P89, DOI 10.1016/j.jpba.2005.10.042; Berntsson O, 1998, ANAL CHIM ACTA, V364, P243, DOI 10.1016/S0003-2670(98)00196-2; Berntsson O, 1999, ANAL CHEM, V71, P617, DOI 10.1021/ac980652u; Berntsson O, 2002, POWDER TECHNOL, V123, P185, DOI 10.1016/S0032-5910(01)00456-9; Berntsson O, 2000, ANAL CHIM ACTA, V419, P45, DOI 10.1016/S0003-2670(00)00975-2; Berntsson O, 1997, J PHARMACEUT BIOMED, V15, P895, DOI 10.1016/S0731-7085(96)01926-7; BLANCO, 1998, ANALYST, V123, pR135; Blanco M, 2002, J PHARMACEUT BIOMED, V30, P467, DOI 10.1016/S0731-7085(02)00093-6; Blanco M, 1999, J PHARM SCI, V88, P551, DOI 10.1021/js980338f; Blanco M, 2006, ANAL CHIM ACTA, V557, P353, DOI 10.1016/j.aca.2005.09.070; Blanco M, 1997, ANALYST, V122, P761, DOI 10.1039/a700630f; Blanco M, 2001, APPL SPECTROSC, V55, P834, DOI 10.1366/0003702011952857; Blanco M, 2001, ANALYST, V126, P2212, DOI 10.1039/b105012p; Blanco M, 2000, FRESEN J ANAL CHEM, V368, P534, DOI 10.1007/s002160000506; Blanco M, 1998, ANALYST, V123, P2307, DOI 10.1039/a805946b; Blanco M, 1999, ANAL CHIM ACTA, V384, P207, DOI 10.1016/S0003-2670(98)00814-9; Blanco M, 2004, ANAL CHIM ACTA, V502, P221, DOI 10.1016/j.aca.2003.10.016; Blanco M, 2002, TALANTA, V56, P203, DOI 10.1016/S0039-9140(01)00559-8; Blanco M, 2004, TALANTA, V64, P597, DOI 10.1016/j.talanta.2004.03.027; Blanco M, 2000, ANAL CHIM ACTA, V407, P247, DOI 10.1016/S0003-2670(99)00828-4; Bokobza L, 1998, J NEAR INFRARED SPEC, V6, P3, DOI DOI 10.1255/JNIRS.116; BOUVERESSE E, 1994, ANAL CHIM ACTA, V297, P405, DOI 10.1016/0003-2670(94)00237-1; Breiman L., 1984, CLASSIFICATION REGRE; Brereton R. G., 2003, CHEMOMETRICS DATA AN; Broad NW, 2001, ANALYST, V126, P2207, DOI 10.1039/b106741a; Broad NW, 2000, ANALYST, V125, P2054, DOI 10.1039/b006789j; BRULLS, 2003, PHARM RES-DORDR, P494; Buckton G, 1998, INT J PHARM, V168, P231, DOI 10.1016/S0378-5173(98)00095-7; BUICE RG, 1995, PHARMACEUT RES, V12, P161; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burns D, 2001, HDB NEAR INFRARED AN; Candolfi A, 1998, J PHARMACEUT BIOMED, V16, P1329, DOI 10.1016/S0731-7085(97)00154-4; Candolfi A, 1999, J PHARMACEUT BIOMED, V21, P115, DOI 10.1016/S0731-7085(99)00125-9; Candolfi A, 2000, APPL SPECTROSC, V54, P48, DOI 10.1366/0003702001948105; Candolfi A, 1999, J PHARMACEUT BIOMED, V19, P923, DOI 10.1016/S0731-7085(98)00234-9; CAO, 2006, J PHARM SCI, V95, P2077; CHALUS P, 2005, SPECTRA ANAL, P44; Chalus P, 2005, TALANTA, V66, P1294, DOI 10.1016/j.talanta.2005.01.051; Chauchard F, 2004, CHEMOMETR INTELL LAB, V71, P141, DOI 10.1016/j.chemolab.2004.01.003; Chen YX, 2001, DRUG DEV IND PHARM, V27, P623, DOI 10.1081/DDC-100107318; Cho J, 1997, ANAL CHIM ACTA, V348, P303, DOI 10.1016/S0003-2670(97)00094-9; Cimander C, 2002, J CHEM TECHNOL BIOT, V77, P1157, DOI 10.1002/jctb.691; Ciurczak EW, 2002, PHARM MED APPL NEARI; *COE, 2006, EUR PHARM; COGDILL RP, 2005, AAPS PHARMSCI, V6; Cogdill Robert P, 2005, AAPS PharmSciTech, V6, pE273, DOI 10.1208/pt060238; Cogdill Robert P, 2005, AAPS PharmSciTech, V6, pE262, DOI 10.1208/pt060237; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; Coomans D., 1978, ANAL CHIM ACTA, V103, P409, DOI 10.1016/S0003-2670(01)83105-6; Corti P, 1999, ANALYST, V124, P755, DOI 10.1039/a809800j; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cui XJ, 2004, TALANTA, V64, P943, DOI 10.1016/j.talanta.2004.04.009; Dantas HA, 2004, CHEMOMETR INTELL LAB, V72, P83, DOI 10.1016/j.chemolab.2004.02.008; Danzer K., 2001, CHEMOMETRIK GRUNDLAG; Daszykowski M, 2001, CHEMOMETR INTELL LAB, V56, P83, DOI 10.1016/S0169-7439(01)00111-3; Daszykowski M, 2002, ANAL CHIM ACTA, V468, P91, DOI 10.1016/S0003-2670(02)00651-7; Davis TD, 2004, PHARM RES, V21, P860, DOI 10.1023/B:PHAM.0000026440.00508.cf; de Groot PJ, 2001, APPL SPECTROSC, V55, P173, DOI 10.1366/0003702011951470; de Maesschalck R, 2005, J PHARMACEUT BIOMED, V37, P109, DOI 10.1016/j.jpba.2004.10.016; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Derksen MWJ, 1998, J PHARMACEUT BIOMED, V17, P473, DOI 10.1016/S0731-7085(97)00216-1; Dhanoa M. S., 1994, J NEAR INFRARED SPEC, V2, P43, DOI DOI 10.1255/JNIRS.30; Donoso M, 2004, PHARM DEV TECHNOL, V9, P247, DOI 10.1081/PDT-200031423; Dou Y, 2005, J PHARMACEUT BIOMED, V37, P543, DOI 10.1016/j.jpba.2004.11.017; Dou Y, 2005, ANAL CHIM ACTA, V528, P55, DOI 10.1016/j.aca.2004.10.050; Duponchel L, 1999, J NEAR INFRARED SPEC, V7, P155; Ebube NK, 1999, PHARM DEV TECHNOL, V4, P19, DOI 10.1081/PDT-100101335; El-Hagrasy AS, 2001, J PHARM SCI, V90, P1298, DOI 10.1002/jps.1082; Eustaquio A, 1999, ANAL CHIM ACTA, V383, P283, DOI 10.1016/S0003-2670(98)00815-0; Fearn T, 2000, CHEMOMETR INTELL LAB, V50, P47, DOI 10.1016/S0169-7439(99)00045-3; Fearn T, 2001, J NEAR INFRARED SPEC, V9, P229; Fertig CC, 2004, EUR J PHARM SCI, V21, P155, DOI 10.1016/j.ejps.2003.09.011; Feudale R.N., 2002, CHEMOM INTELL LAB SY, V64, P181, DOI DOI 10.1016/S0169-7439(02)00085-0; Fevotte G, 2004, INT J PHARM, V273, P159, DOI 10.1016/j.ijpharm.2004.01.003; Findlay WP, 2005, J PHARM SCI-US, V94, P604; Fix I, 2004, DRUG DEV IND PHARM, V30, P513, DOI 10.1081/DDC-120037482; Forbes RA, 2001, J PHARMACEUT BIOMED, V25, P239, DOI 10.1016/S0731-7085(00)00497-0; Fountain W, 2003, J PHARMACEUT BIOMED, V33, P181, DOI 10.1016/S0731-7085(03)00345-5; Frake P, 1997, INT J PHARM, V151, P75, DOI 10.1016/S0378-5173(97)04894-1; FRAZIER BL, 2000, BIOTECHNOL BIOENG, V72, P364; Freitas MP, 2005, J PHARMACEUT BIOMED, V39, P17, DOI 10.1016/j.jpba.2005.03.023; Galvao RKH, 2005, TALANTA, V67, P736, DOI 10.1016/j.talanta.2005.03.025; Gaub M, 2004, J PHARMACEUT BIOMED, V36, P859, DOI 10.1016/j.jpba.2004.06.030; Gerhausser CI, 1997, APPL SPECTROSC, V51, P1504, DOI 10.1366/0003702971939000; Gombas A, 2003, INT J PHARMACEUT, V256, P25, DOI 10.1016/S0378-5173(03)00059-0; Gonzalez-Arjona D, 1999, ANAL CHIM ACTA, V381, P257, DOI 10.1016/S0003-2670(98)00764-8; Gupta A, 2005, J PHARM SCI-US, V94, P1589, DOI 10.1002/jps.20375; Gupta A, 2004, J PHARM SCI-US, V93, P1047, DOI 10.1002/jps.20003; Habib IHI, 2003, TALANTA, V60, P185, DOI 10.1016/S0039-9140(03)00123-1; Hailey PA, 1996, J PHARMACEUT BIOMED, V14, P551, DOI 10.1016/0731-7085(95)01674-0; Han SM, 1996, J PHARMACEUT BIOMED, V14, P1681, DOI 10.1016/0731-7085(96)01814-6; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Herkert T, 2001, EUR J PHARM BIOPHARM, V51, P9, DOI 10.1016/S0939-6411(00)00126-0; Huang ES, 2005, DRUG DISCOV TODAY, V10, P69, DOI 10.1016/S1359-6446(04)03349-5; Iyer M, 2002, J NEAR INFRARED SPEC, V10, P233; Izutsu KI, 2005, INT J PHARM, V301, P161, DOI 10.1016/j.ijpharm.2005.05.019; Izutsu KI, 2006, J PHARM SCI-US, V95, P781, DOI 10.1002/jps.20580; Jiang JH, 2002, ANAL CHEM, V74, P3555, DOI 10.1021/ac011177u; JONES JA, 1993, J PHARMACEUT BIOMED, V11, P1227, DOI 10.1016/0731-7085(93)80108-D; Jung BJ, 2002, APPL SPECTROSC, V56, P51, DOI 10.1366/0003702021954421; Kalivas JH, 2001, ANAL CHIM ACTA, V428, P31, DOI 10.1016/S0003-2670(00)01225-3; KAMAT MS, 1989, PHARMACEUT RES, V6, P961, DOI 10.1023/A:1015997530367; KEMPER MS, 2001, AAPS PHARMSCI, V3; Kirsch JD, 1999, J PHARMACEUT BIOMED, V19, P351, DOI 10.1016/S0731-7085(98)00132-0; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kramer K, 2000, ANAL CHIM ACTA, V420, P155, DOI 10.1016/S0003-2670(00)00877-1; Kreft K, 1999, INT J PHARM, V177, P1, DOI 10.1016/S0378-5173(98)00265-8; Laasonen M, 2004, EUR J PHARM SCI, V21, P493, DOI 10.1016/j.ejps.2003.11.011; Laasonen M, 2003, ANAL CHEM, V75, P754, DOI 10.1021/ac026262w; Larrechi MS, 2003, TRAC-TREND ANAL CHEM, V22, P634, DOI 10.1016/S0165-9936(03)01005-7; LAST IR, 1993, J PHARMACEUT BIOMED, V11, P1071, DOI 10.1016/0731-7085(93)80084-E; LAVINE, 2000, ANAL CHEM, V72; Leardi R., 2003, NATURE INSPIRED METH; Leion H, 2005, J PHARMACEUT BIOMED, V37, P47, DOI 10.1016/j.jpba.2004.09.046; Lewis CB, 2000, APPL SPECTROSC, V54, P1453, DOI 10.1366/0003702001948592; Li WY, 2005, J PHARM SCI-US, V94, P2800, DOI 10.1002/jps.20501; LIN TP, 2001, PHARM SCI TECHNOL, P196; Liu JS, 2006, PHARM DEV TECHNOL, V11, P3, DOI 10.1080/10837450500463729; Lopes JA, 2004, CHEMOMETR INTELL LAB, V74, P269, DOI 10.1016/j.chemolab.2004.07.006; Luypaert J, 2007, TALANTA, V72, P865, DOI 10.1016/j.talanta.2006.12.023; Marini F, 2004, CHEMOMETR INTELL LAB, V73, P85, DOI 10.1016/j.chemolab.2003.12.007; Mark H. L, 1985, ANAL CHEM, V57, P1449, DOI 10.1021/ac00284a061; Markopoulou CK, 2005, J PHARMACEUT BIOMED, V37, P249, DOI 10.1016/j.jpba.2004.10.024; Martens H., 2001, MULTIVARIATE ANAL QU; Martens H., 1996, MULTIVARIATE CALIBRA; Massart DL, 2003, CHEMOMETRICS TXB; Massart D.L., 1997, HDB CHEMOMETRICS QUA; McShane MJ, 1998, APPL SPECTROSC, V52, P1073, DOI 10.1366/0003702981944968; Merckle P, 1998, J PHARMACEUT BIOMED, V17, P365, DOI 10.1016/S0731-7085(97)00194-5; Morisseau KM, 1997, PHARMACEUT RES, V14, P108, DOI 10.1023/A:1012071904673; Naes T., 2002, USER FRIENDLY GUIDE; Navratil M, 2005, J BIOTECHNOL, V115, P67, DOI 10.1016/j.jbiotec.2004.07.013; Norris K.H., 1996, J NEAR INFRARED SPEC, V4, P31; Ns T., 2002, MULTIVARIATE CALIBRA; Otsuka M, 2004, POWDER TECHNOL, V141, P244, DOI 10.1016/j.powtec.2004.01.025; Otto M., 1999, CHEMOMETRICS STAT CO; Patel AD, 2000, INT J PHARM, V206, P63, DOI 10.1016/S0378-5173(00)00530-5; PEREZRAMOS JD, 2005, AAPS PHARMSCI, V6; Plumb AP, 2005, EUR J PHARM SCI, V25, P395, DOI 10.1016/j.ejps.2005.04.010; Plumb AP, 2002, EUR J PHARM SCI, V16, P281, DOI 10.1016/S0928-0987(02)00112-4; Popo Manuel, 2002, AAPS PharmSciTech, V3, pE24, DOI 10.1208/pt030324; Pretsch E., 2006, TRENDS ANAL CHEM, V25, P1043; Rager I, 2002, J PHARMACEUT BIOMED, V28, P439, DOI 10.1016/S0731-7085(01)00602-1; Ramirez J L, 2001, AAPS PharmSciTech, V2, pE11; Rantanen J, 2001, CHEMOMETR INTELL LAB, V56, P51, DOI 10.1016/S0169-7439(01)00108-3; Rantanen J, 1998, POWDER TECHNOL, V99, P163, DOI 10.1016/S0032-5910(98)00100-4; Rantanen J, 2000, EUR J PHARM BIOPHARM, V50, P271, DOI 10.1016/S0939-6411(00)00096-5; Rantanen J, 2000, PHARM DEV TECHNOL, V5, P209, DOI 10.1081/PDT-100100536; Reich G, 2005, ADV DRUG DELIVER REV, V57, P1109, DOI 10.1016/j.addr.2005.01.020; Rhiel M, 2002, BIOTECHNOL BIOENG, V77, P73, DOI 10.1002/bit.10093; Riley MR, 1997, BIOTECHNOL BIOENG, V55, P11, DOI 10.1002/(SICI)1097-0290(19970705)55:1<11::AID-BIT2>3.0.CO;2-#; Rodionova OY, 2005, ANAL CHIM ACTA, V549, P151, DOI 10.1016/j.aca.2005.06.018; Rodriguez-Saona LE, 2004, J FOOD PROTECT, V67, P2555; Rodriguez-Saona LE, 2001, J AGR FOOD CHEM, V49, P574, DOI 10.1021/jf000776j; Roggo Y, 2004, J AGR FOOD CHEM, V52, P1051; Roggo Y, 2005, EUR J PHARM BIOPHARM, V61, P100, DOI 10.1016/j.ejpb.2005.04.005; Roggo Y, 2005, ANAL CHIM ACTA, V535, P79, DOI 10.1016/j.aca.2004.12.037; Roggo Y, 2004, J PHARMACEUT BIOMED, V36, P777, DOI 10.1016/j.jpba.2004.08.009; Savage M, 1998, BIOLOGICALS, V26, P119, DOI 10.1006/biol.1998.0140; SAVOLAINEN M, IN PRESS EUR J PHARM; Scafi SHF, 2001, ANALYST, V126, P2218, DOI 10.1039/b106744n; Schneider RC, 2003, FORENSIC SCI INT, V134, P187, DOI 10.1016/S0379-0738(03)00125-7; Sekulic SS, 1996, ANAL CHEM, V68, P509, DOI 10.1021/ac950964m; Sekulic SS, 1998, J PHARMACEUT BIOMED, V17, P1285, DOI 10.1016/S0731-7085(98)00025-9; Seyer JJ, 2001, PHARM DEV TECHNOL, V6, P573, DOI 10.1081/PDT-120000295; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; Sharaf M. A., 1986, CHEMOMETRICS; SHENK JS, 1991, CROP SCI, V31, P1548; Siesler HW, 2002, NEAR INFRARED SPECTR; Simon L, 2001, BIOCHEM ENG J, V7, P41, DOI 10.1016/S1369-703X(00)00102-9; Sjoblom J, 1998, CHEMOMETR INTELL LAB, V44, P229, DOI 10.1016/S0169-7439(98)00112-9; Skibsted ETS, 2007, J PHARMACEUT BIOMED, V43, P1297, DOI 10.1016/j.jpba.2006.10.037; Skibsted ETS, 2006, J PHARMACEUT BIOMED, V41, P26, DOI 10.1016/j.jpba.2005.10.009; Smith MR, 2004, ANALYST, V129, P806, DOI 10.1039/b401267d; Sondermann N, 1999, FORENSIC SCI INT, V102, P133, DOI 10.1016/S0379-0738(99)00047-X; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; STAHLE L, 1987, Journal of Chemometrics, V1, P185, DOI 10.1002/cem.1180010306; Stokvold A, 2002, J PHARMACEUT BIOMED, V28, P867, DOI 10.1016/S0731-7085(01)00668-9; Sukowski L, 2005, PHARM IND, V67, P830; Tamburini E, 2003, APPL SPECTROSC, V57, P132, DOI 10.1366/000370203321535024; Tenenhaus M., 1998, REGRESSION PLS THEOR; The European Agency for the Evaluation of Medicinal Products, 2003, EMEACVMP96101; Thissen U, 2004, CHEMOMETR INTELL LAB, V73, P169, DOI 10.1016/j.chemolab.2004.01.002; Thissen U, 2004, ANAL CHEM, V76, P3099, DOI 10.1021/ac035522m; Thosar SS, 2001, PHARM DEV TECHNOL, V6, P19, DOI 10.1081/PDT-100000010; Tosi S, 2003, BIOTECHNOL PROGR, V19, P1816, DOI 10.1021/bp034101n; Trafford AD, 1999, ANALYST, V124, P163, DOI 10.1039/a806629i; Tumuluri SVS, 2004, DRUG DEV IND PHARM, V30, P505, DOI 10.1081/DDC-120037481; Ulmschneider M, 2000, ANALUSIS, V28, P83, DOI 10.1051/analusis:2000101; Ulmschneider M, 1999, ANALUSIS, V27, P854, DOI 10.1051/analusis:1999153; Ulmschneider M, 2000, PHARM IND, V62, P374; Ulmschneider M, 2000, ANALUSIS, V28, P336, DOI 10.1051/analusis:2000124; Vaidyanathan S, 2001, APPL SPECTROSC, V55, P444, DOI 10.1366/0003702011951957; Vaidyanathan S, 2000, BIOTECHNOL PROGR, V16, P1098, DOI 10.1021/bp0000656; Vaidyanathan S, 2001, ANAL CHIM ACTA, V428, P41, DOI 10.1016/S0003-2670(00)01205-8; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; VANDERVLIES C, 1994, EUR J PHARM SCI, V2, P79, DOI 10.1016/0928-0987(94)90078-7; Vora KL, 2004, EUR J PHARM SCI, V22, P97, DOI 10.1016/j.ejps.2004.01.009; Vredenbregt MJ, 2006, J PHARMACEUT BIOMED, V40, P840, DOI 10.1016/j.jpba.2005.07.048; Vredenbregt MJ, 2003, EUR J PHARM BIOPHARM, V56, P489, DOI 10.1016/S0939-6411(03)00119-X; Wang HF, 2004, CHEMOMETR INTELL LAB, V70, P23, DOI 10.1016/j.chemolab.2003.09.003; Wang YB, 2005, SPECTROSC SPECT ANAL, V25, P398; Wargo DJ, 1996, J PHARMACEUT BIOMED, V14, P1415, DOI 10.1016/0731-7085(96)01739-6; Webster GK, 2003, J PHARMACEUT BIOMED, V33, P21, DOI 10.1016/S0731-7085(03)00341-8; Westenberger BJ, 2005, INT J PHARM, V306, P56, DOI 10.1016/j.ijpharm.2005.08.027; Williams P.C., 1987, NEAR INFRARED TECHNO; Wilson ND, 2002, J PHARM PHARMACOL, V54, P1257, DOI 10.1211/002235702320402107; Wilson ND, 2001, J PHARM PHARMACOL, V53, P95, DOI 10.1211/0022357011775064; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wold S, 2001, CHEMOMETR INTELL LAB, V58, P131, DOI 10.1016/S0169-7439(01)00156-3; Wu W, 1996, CHEMOMETR INTELL LAB, V33, P35, DOI 10.1016/0169-7439(95)00077-1; WU W, 1995, ANAL CHIM ACTA, V315, P243, DOI 10.1016/0003-2670(95)00347-3; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0; Yang H, 2002, J PHARM PHARMACOL, V54, P1247, DOI 10.1211/002235702320402099; YEUNG KSY, 1998, BIOTECHNOL BIOENG, V63; Yoon JG, 2002, CHEMOMETR INTELL LAB, V64, P1, DOI 10.1016/S0169-7439(02)00042-4; YOON WL, 1999, P 9 INT C NEAR INFR, P547; Yoon WL, 1998, ANALYST, V123, P1029, DOI 10.1039/a800358k; YOON WL, 2002, AM PHARM REV, V5, P106; Yoon WL, 1999, ANALYST, V124, P1197; Yoon WL, 2004, J PHARMACEUT BIOMED, V34, P933, DOI 10.1016/j.jpba.2003.11.014; Zhou GX, 2003, J PHARM SCI, V92, P1058, DOI 10.1002/jps.10375; Zhou XJ, 1998, J PHARMACEUT BIOMED, V17, P219, DOI 10.1016/S0731-7085(97)00182-9; 2001, INT C HARM Q7A, V66, P49028; 1995, INT C HARM Q2A, V60, P11260; 2000, INT C HARM Q6A, V65, P83041; 1997, INT C HARM Q6B, V62, P27463	240	338	357	12	93	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0731-7085			J PHARMACEUT BIOMED	J. Pharm. Biomed. Anal.	JUL 27	2007	44	3			SI		683	700		10.1016/j.jpba.2007.03.023		18	Chemistry, Analytical; Pharmacology & Pharmacy	Chemistry; Pharmacology & Pharmacy	200BF	WOS:000248738200010	17482417	
J	Omachi, S; Omachi, M; Aso, H				Omachi, Shinichiro; Omachi, Masako; Aso, Hirotomo			An approximation method of the quadratic discriminant function and its application to estimation of high-dimensional distribution	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						pattern recognition; quadratic discriminant function; small sample size problem; simplified quadratic discriminant function; normal mixture	DENSITY-FUNCTION; RECOGNITION	In statistical pattern recognition, it is important to estimate the distribution of patterns precisely to achieve high recognition accuracy. In general, precise estimation of the parameters of the distribution requires a great number of sample patterns, especially when the feature vector obtained from the pattern is high-dimensional. For some pattern recognition problems, such as face recognition or character recognition, very high-dimensional feature vectors are necessary and there are always not enough sample patterns for estimating the parameters. In this paper, we focus on estimating the distribution of high-dimensional feature vectors with small number of sample patterns. First, we define a function, called simplified quadratic discriminant function (SQDF). SQDF can be estimated with small number of sample patterns and approximates the quadratic discriminant function (QDF). SQDF has fewer parameters and requires less computational time than QDF. The effectiveness of SQDF is confirmed by three types of experiments. Next, as an application of SQDF, we propose an algorithm for estimating the parameters of the normal mixture. The proposed algorithm is applied to face recognition and character recognition problems which require high-dimensional feature vectors.	Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan; Tohoku Bunka Gakuen Univ, Fac Sci & Technol, Sendai, Miyagi 9818551, Japan	Omachi, S (reprint author), Tohoku Univ, Grad Sch Engn, Sendai, Miyagi 9808579, Japan.	machi@ecei.tohoku.ac.jp					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BUTUROVIC LJ, 1994, IEEE T PATTERN ANAL, V16, P420, DOI 10.1109/34.277596; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; FIX E, 1951, 4 SCH AV MED RAND FI; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; FUKUNAGA K, 1990, INTRO STAT PATERN RE; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634; Grother Parick J, 1995, NIST SPECIAL DATABAS; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Hastie T, 2001, ELEMENTS STAT LEARNI; HONGO H, 2000, PRMU2000108 IEICE; ICHIMURA N, 1995, IEICE T INF SYST, P1184; IWAMURA M, 2003, IEICE T INF SYST, P22; Kato N, 1999, IEEE T PATTERN ANAL, V21, P258, DOI 10.1109/34.754617; KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; OMACHI S, 2004, P 17 INT C PATT REC, V1, P220, DOI 52214785,12,1; Omachi S, 2000, LECT NOTES COMPUT SC, V1876, P601; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Sakai M., 1998, Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170), DOI 10.1109/ICPR.1998.711089; TAKESHITA T, 1987, IEICE T D, V70, P567; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728	26	5	5	1	2	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532			IEICE T INF SYST	IEICE Trans. Inf. Syst.	AUG	2007	E90D	8					1160	1167		10.1093/ietisy/e90-d.8.1160		8	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	202WE	WOS:000248934000005		
J	Sanchez, JS; Mollineda, RA; Sotoca, JM				Sanchez, J. S.; Mollineda, R. A.; Sotoca, J. M.			An analysis of how training data complexity affects the nearest neighbor classifiers	PATTERN ANALYSIS AND APPLICATIONS			English	Article							PATTERN-RECOGNITION; CLASSIFICATION; ALGORITHMS	The k-nearest neighbors (k-NN) classifier is one of the most popular supervised classification methods. It is very simple, intuitive and accurate in a great variety of real-world domains. Nonetheless, despite its simplicity and effectiveness, practical use of this rule has been historically limited due to its high storage requirements and the computational costs involved. On the other hand, the performance of this classifier appears strongly sensitive to training data complexity. In this context, by means of several problem difficulty measures, we try to characterize the behavior of the k-NN rule when working under certain situations. More specifically, the present analysis focuses on the use of some data complexity measures to describe class overlapping, feature space dimensionality and class density, and discover their relation with the practical accuracy of this classifier.	Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Castellon de La Plana 12071, Spain	Sanchez, JS (reprint author), Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Vicent Sos Baynat S-N, Castellon de La Plana 12071, Spain.	sanchez@uji.es		Sanchez Garreta, Jose Salvador/0000-0003-1053-4658			BERNARDO E, 2004, P 17 INT C PATT REC, P136; Beyer K., 1999, P 7 INT C DAT THEOR, P217; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Dasarathy B. V., 1991, IEEE COMPUTER SOC; Devijver P., 1992, PATTERN RECOGNITION; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; GAMA J, 1995, P 7 PORT C AI EPIA 9, P83; Hand DJ, 2003, PATTERN RECOGN LETT, V24, P1555, DOI 10.1016/S0167-8655(02)00394-X; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; Hoekstra A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547429; Jain A. K., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1047451; Japkowicz N., 2002, Intelligent Data Analysis, V6; KUBAT M, 1998, P 1 SO S COMP, P27; Little R.J.A., 2002, STAT ANAL MISSING DA; Mollineda RA, 2005, LECT NOTES COMPUT SC, V3523, P27; Okamoto S, 2003, THEOR COMPUT SCI, V298, P207, DOI 10.1016/S0304-3975(02)00424-3; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Singh S, 2003, PATTERN ANAL APPL, V6, P134, DOI 10.1007/s10044-002-0186-2; Sohn SY, 1999, IEEE T PATTERN ANAL, V21, P1137; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Zhang J., 2003, P WORKSH LEARN IMB D	22	27	27	0	0	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	AUG	2007	10	3					189	201		10.1007/s10044-007-0061-2		13	Computer Science, Artificial Intelligence	Computer Science	194ZT	WOS:000248383000003		
J	Verduijn, M; Sacchi, L; Peek, N; Bellazzi, R; de Jonge, E; de Mol, BAJM				Verduijn, Marion; Sacchi, Lucia; Peek, Niels; Bellazzi, Riccardo; de Jonge, Evert; de Mol, Bas A. J. M.			Temporal abstraction for feature extraction: A comparative case study in prediction from intensive care monitoring data	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						temporal classification; feature extraction; temporal abstraction; monitoring data; prognosis; cardiac surgery; intensive care	PROLONGED MECHANICAL VENTILATION; CARDIAC-SURGERY; PREOPERATIVE PREDICTION; RISK-FACTORS; TIME-SERIES; SAPS-II; CLASSIFICATION; MULTICENTER; MODELS; SCORE	Objectives: To compare two temporal abstraction procedures for the extraction of meta features from monitoring data. Feature extraction prior to predictive modeling is a common strategy in prediction from temporal data. A fundamental dilemma in this strategy, however, is the extent to which the extraction should be guided by domain knowledge, and to which extent it should be guided by the available data. The two temporal abstraction procedures compared in this case study differ in this respect. Methods and material: The first temporal abstraction procedure derives symbolic descriptions from the data that are predefined using existing concepts from the medical language. In the second procedure, a large space of numerical meta features is searched through to discover relevant features from the data. These procedures were applied to a prediction problem from intensive care monitoring data. The predictive value of the resulting meta features were compared, and based on each type of features, a class probability tree model was developed. Results: The numerical meta features extracted by the second procedure were found to be more informative than the symbolic meta features of the first procedure in the case study, and a superior predictive performance was observed for the associated tree model. Conclusion: The findings indicate that for prediction from monitoring data, induction of numerical meta features from data is preferable to extraction of symbolic meta features using existing clinical concepts. (c) 2007 Elsevier B.V. All rights reserved.	Acad Med Ctr, Dept Med Informat, NL-1100 DE Amsterdam, Netherlands; Acad Med Ctr, Dept Intens Care Med, NL-1100 DE Amsterdam, Netherlands; Acad Med Ctr, Dept Cardio Thorac Surg, NL-1100 DE Amsterdam, Netherlands; Univ Pavia, Lab Med Informat, I-27100 Pavia, Italy; Tech Univ Eindhoven, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands	Verduijn, M (reprint author), Acad Med Ctr, Dept Med Informat, PO Box 22700, NL-1100 DE Amsterdam, Netherlands.	m.verduijn@amc.uva.nl					Abu-Hanna A, 2001, METHOD INFORM MED, V40, P1; BELLAZZI R, 1998, INTELL DATA ANAL, V2, P1; Bezanson JL, 2004, NURS RES, V53, P46, DOI 10.1097/00006199-200401000-00007; BICEGO M, 2003, MACHINE LEARNING DAT, V12, P86; BREIMAN L, 1984, CLASSIFIACATION REGR; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI [10.1175/1520-0493(1950)078<lessthan>0001:VOFEIT<greaterthan>2.0.CO;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; Combi C, 1999, ARTIF INTELL MED, V17, P271, DOI 10.1016/S0933-3657(99)00022-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diggle P, 2002, ANAL LONGITUDINAL DA; Dunning J, 2003, EUR J CARDIO-THORAC, V24, P270, DOI 10.1016/S1010-7940(03)00269-0; Habib RH, 1996, ANN THORAC SURG, V62, P1164, DOI 10.1016/0003-4975(96)00565-6; Haimowitz IJ, 1996, ARTIF INTELL MED, V8, P299, DOI 10.1016/0933-3657(95)00037-2; Harrell F, 2001, REGRESSION MODELING; Hastie T, 2001, ELEMENTS STAT LEARNI; Kadous MW, 2005, MACH LEARN, V58, P179, DOI 10.1007/s10994-005-5826-5; Keogh E., 2003, DATA MINING TIME SER, P1; Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347153; Kern H, 2001, INTENS CARE MED, V27, P407, DOI 10.1007/s001340000802; Laxman S, 2006, SADHANA-ACAD P ENG S, V31, P173, DOI 10.1007/BF02719780; LEGALL JR, 1993, JAMA-J AM MED ASSOC, V270, P2957, DOI 10.1001/jama.270.24.2957; Legare JF, 2001, EUR J CARDIO-THORAC, V20, P930, DOI 10.1016/S1010-7940(01)00940-X; Magenes G, 2004, METHOD INFORM MED, V43, P47; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Miksch S, 1996, ARTIF INTELL MED, V8, P543, DOI 10.1016/S0933-3657(96)00355-7; Mitchell T. M., 1997, MACHINE LEARNING; Roddick JF, 2002, IEEE T KNOWL DATA EN, V14, P750, DOI 10.1109/TKDE.2002.1019212; Rodriguez JJ, 2005, KNOWL-BASED SYST, V18, P171, DOI 10.1016/j.knosys.2004.10.007; Shahar Y, 1997, ARTIF INTELL, V90, P79, DOI 10.1016/S0004-3702(96)00025-2; Shahar Y, 1996, ARTIF INTELL MED, V8, P267, DOI 10.1016/0933-3657(95)00036-4; Spivack SD, 1996, CHEST, V109, P1222, DOI 10.1378/chest.109.5.1222; Stacey M, 2007, ARTIF INTELL MED, V39, P1, DOI 10.1016/j.artmed.2006.08.002; Therneau T. M., 1997, INTRO RECURSIVE PART; Verduijn M, 2007, METHOD INFORM MED, V46, P352, DOI 10.1160/ME0368; Vincent JL, 1998, CRIT CARE MED, V26, P1793; WU C, 1995, MACH LEARN, V21, P177, DOI 10.1007/BF00993384; Xi X., 2006, P 23 INT C MACH LEAR, P1033, DOI 10.1145/1143844.1143974; ZHANG H, 2006, P 3 INT S NEUR NETW, P1394	37	18	18	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	SEP	2007	41	1					1	12		10.1016/j.artmed.2007.06.003		12	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	215PJ	WOS:000249821200001	17698331	
J	Huang, WL; Chen, HM; Hwang, SF; Ho, SY				Huang, Wen-Lin; Chen, Hung-Ming; Hwang, Shiow-Fen; Ho, Shinn-Ying			Accurate prediction of enzyme subfamily class using an adaptive fuzzy k-nearest neighbor method	BIOSYSTEMS			English	Article						amino acid composition; enzyme subfamily class prediction; fuzzy theory; k-nearest neighbor; support vector machine	AMINO-ACID-COMPOSITION; PROTEIN SORTING SIGNALS; SUBCELLULAR-LOCALIZATION; STRUCTURAL CLASSES; NEURAL-NETWORKS; RECOGNITION; ALGORITHM; LOCATION	Amphiphilic pseudo-amino acid composition (Am-Pse-AAC) with extra sequence-order information is a useful feature for representing enzymes. This study first utilizes the k-nearest neighbor (k-NN) rule to analyze the distribution of enzymes in the Am-Pse-AAC feature space. This analysis indicates the distributions of multiple classes of enzymes are highly overlapped. To cope with the overlap problem, this study proposes an efficient non-parametric classifier for predicting enzyme subfamily class using an adaptive fuzzy r-nearest neighbor (AFK-NN) method, where k and a fuzzy strength parameter m are adaptively specified. The fuzzy membership values of a query sample Q are dynamically determined according to the position of Q and its weighted distances to the k nearest neighbors. Using the same enzymes of the oxidoreductases family for comparisons, the prediction accuracy of AFK-NN is 76.6%, which is better than those of Support Vector Machine (73.6%), the decision tree method C5.0 (75.4%) and the existing covariant-discriminate algorithm (70.6%) using a jackknife test. To evaluate the generalization ability of AFK-NN, the datasets for all six families of entirely sequenced enzymes are established from the newly updated SWISS-PROT and ENZYME database. The accuracy of AFK-NN on the new large-scale dataset of oxidoreductases family is 83.3%, and the mean accuracy of the six families is 92.1 %. (c) 2006 Elsevier Ireland Ltd. All rights reserved.	Feng Chia Univ, Inst Comp Sci & Informat Engn, Taichung 40724, Taiwan; Natl Chiao Tung Univ, Dept Biol Sci & Technol, Hsinchu, Taiwan; Natl Chiao Tung Univ, Inst Bioinformat, Hsinchu, Taiwan	Ho, SY (reprint author), 75 Bo Ai St, Hsinchu, Taiwan.	syho@mail.nctu.edu.tw					Bahar I, 1997, PROTEINS, V29, P172, DOI 10.1002/(SICI)1097-0134(199710)29:2<172::AID-PROT5>3.0.CO;2-F; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P304, DOI 10.1093/nar/28.1.304; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; Cai YD, 2000, BBA-PROTEIN STRUCT M, V1476, P1, DOI 10.1016/S0167-4838(99)00217-4; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; CHANDONIA JM, 1995, PROTEIN SCI, V4, P275; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2003, J PROTEOME RES, V2, P183, DOI 10.1021/pr0255710; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Ho SY, 2004, IEEE T EVOLUT COMPUT, V8, P522, DOI 10.1109/TEVC.2004.835176; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Joachims T., 1999, ADV KERNEL METHODS S; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lei ZD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-291; Leszczynski K, 1999, PHYS MED BIOL, V44, P253, DOI 10.1088/0031-9155/44/1/018; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nielsen H, 1999, PROTEIN ENG, V12, P3, DOI 10.1093/protein/12.1.3; Quinlan J.R., 2003, C5 0 ONLINE TUTORIAL; SNEDECOR GW, 1989, STAT METHODS, P142; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Webb EC, 1992, ENZYME NOMENCLATURE; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	30	16	17	0	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0303-2647			BIOSYSTEMS	Biosystems	SEP-OCT	2007	90	2					405	413		10.1016/j.biosystems.2006.10.004		9	Biology; Mathematical & Computational Biology	Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology	220VD	WOS:000250184500011	17140725	
J	Li, X; Cripps, RJ				Li, X.; Cripps, R. J.			Algorithm for finding all k-nearest neighbours in three-dimensional scattered points and its application in reverse engineering	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF ENGINEERING MANUFACTURE			English	Article						k-nearest neighbours; three-dimensional scattered point data; reverse engineering	CLASSIFICATION	A fast and exact algorithm for computing the k-nearest neighbours, or k-closest points in terms of Euclidean distance, for all data in three-dimensional point clouds is presented that avoids using complicated Voronoi diagrams or Dirichlet tessellations. Experimental evidence suggests that the algorithm has a timing of O(n) for most practical values of k under the condition: k < 0.05n, where n is the number of three-dimensional points in the cloud. Case studies are presented to illustrate the robustness and efficiency of the method and a comparison is made to an existing exact method.	Nathan S Kline Inst Psychiat Res, Ctr Adv Brain Imaging, New York, NY USA; Univ Birmingham, Goemetr Modelling Grp, Birmingham, W Midlands, England	Cripps, RJ (reprint author), Univ Birmingham, Sch Mfg & Mech Engn, Birmingham B15 2TT, W Midlands, England.	r.cripps@bham.ac.uk					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cripps RJ, 2004, PROCEEDINGS OF THE 34TH INTERNATIONAL MATADOR CONFERENCE, P75; DAVIS P, 1975, INERPOLATION APPROXI; Dey T. K., 1991, Proceedings. Symposium on Solid Modeling Foundations and CAD/CAM Applications, DOI 10.1145/112515.112578; Dickerson MT, 1992, INT J COMPUT GEOM AP, V2, P221, DOI 10.1142/S0218195992000147; Duda R O, 2001, PATTERN CLASSIFICATI; Duda R.O., 1979, PATTERN CLASSIFICATI; EDELSBRUNNER H, 1987, ALGORITHMS COMBINAT; Goodsell G, 2000, COMPUT AIDED GEOM D, V17, P387, DOI 10.1016/S0167-8396(00)00009-1; HOPPE H, 1992, COMP GRAPH, V26, P71; LI X, 2004, THESIS U BIRMINGHAM; Piegl LA, 2002, COMPUT AIDED DESIGN, V34, P167, DOI 10.1016/S0010-4485(00)00141-X; Preparata F. P., 1985, COMPUTATIONAL GEOMET; SARKAR M, 2000, P 2000 AMIA ANN S; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; DATASET 4 KINDLY SUP	16	0	1	3	3	PROFESSIONAL ENGINEERING PUBLISHING LTD	WESTMINISTER	1 BIRDCAGE WALK, WESTMINISTER SW1H 9JJ, ENGLAND	0954-4054			P I MECH ENG B-J ENG	Proc. Inst. Mech. Eng. Part B-J. Eng. Manuf.	SEP	2007	221	9					1467	1472		10.1243/09544054JEM477		6	Engineering, Manufacturing; Engineering, Mechanical	Engineering	216KQ	WOS:000249877300009		
J	Angiulli, F				Angiulli, Fabrizio			Condensed nearest neighbor data domain description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; data domain description; data condensation; nearest neighbor rule; novelty detection	CLASSIFICATION	A simple yet effective unsupervised classification rule to discriminate between normal and abnormal data is based on accepting test objects whose nearest neighbors' distances in a reference data set, assumed to model normal behavior, lie within a certain threshold. This work investigates the effect of using a subset of the original data set as the reference set of the classifier. With this aim, the concept of a reference-consistent subset is introduced and it is shown that finding the minimum-cardinality reference-consistent subset is intractable. Then, the Condensed Nearest Neighbor Domain Description (CNNDD) algorithm is described, which computes a reference-consistent subset with only two reference set passes. Experimental results revealed the advantages of condensing the data set and confirmed the effectiveness of the proposed approach. A thorough comparison with related methods was accomplished, pointing out the strengths and weaknesses of one-class nearest-neighbor-based training-set-consistent condensation.	Univ Calabria, Dipartimento Elettron Informat & Sistemist, I-87036 Arcavacata Di Rende, Italy	Angiulli, F (reprint author), Univ Calabria, Dipartimento Elettron Informat & Sistemist, Via P Bucci 41C, I-87036 Arcavacata Di Rende, Italy.	f.angiulli@deis.unical.it					Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431); Angiulli F., 2005, P 22 INT C MACH LEAR, P7; Blake C, 1998, UCI REPOSITORY MACHI; Breunig M., 2000, P ACM INT C MAN DAT; CERVERON V, 2001, IEEE T SYST MAN CYB, V31, P304; CHANG CC, 2001, LIBSVM LIB SUPORT VE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L., 1996, PROBABILISTIC THEORY; Eskin Eleazar, 2002, APPL DATA MINING COM; FIX E, 1951, 4 SCH AV MED US AIR; Floyd S, 1995, MACH LEARN, V21, P269; Garey M.R., 1979, COMPUTER INTRACTABIL; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases; Littlestone N., 1986, RELATING DATA COMPRE; Ramaswami S., 2000, P 2000 ACM SIGMOD IN, P427, DOI 10.1145/342009.335437; Ritter G, 1997, PATTERN RECOGN LETT, V18, P525, DOI 10.1016/S0167-8655(97)00049-4; Scholkopf B., 1995, P INT C KNOWL DISC D, P251; SCHOLKOPF B, 1999, 87 MICR RES REDM WAS; STONE C, 1977, ANN STAT, V8, P1348; Tax D. M. J., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.906164; Tax DM J, 1999, P EUR S ART NEUR NET, P251; TAX DMJ, 2001, THESIS U TECHN DELFT; TOUSSAINT G, 2002, SOCS025 MCG U SCH CO; YPMA A, 1998, P INT CORP ASS NAM N	28	8	15	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1746	1758		10.1109/TPAMI.2007.1086		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	199LA	WOS:000248696100005	17699920	
J	Pateritsas, C; Stafylopatis, A				Pateritsas, Christos; Stafylopatis, Andreas			Memory-based classification with dynamic feature selection using self-organizing maps for pattern evaluation	INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS			English	Article						classification; memory-based learning; self-organizing maps; feature weighting; hybrid systems	FEATURE SUBSET-SELECTION; NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	Memory-based learning is one of the main fields of machine learning. We Propose a new methodology for addressing the classification task that relies on the main idea of the k-nearest neighbors algorithm, which is the most important representative of this field. In the proposed approach, given an unclassified pattern, a set of neighboring patterns is found, not necessarily using all input feature dimensions. Also, following the concept of the naive Bayesian classifier, we adopt the assumption of independence of input features in the outcome of the classification task. The two concepts are merged in an attempt to take advantage of their good performance features. In order to further improve the performance of our approach, we propose a novel weighting scheme of the memory-base. Using the self-organizing maps model during the execution of the algorithm, dynamic weights of the memory-base patterns are produced. Experimental results have shown improved performance of the proposed method in comparison with the aforementioned algorithms and their variations.	Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15780 Athens, Greece	Pateritsas, C (reprint author), Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15780 Athens, Greece.	pater@softlab.ntua.gr; andreas@cs.ntua.gr					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Bay S.D., 1998, P 15 INT C MACH LEAR, P37; Blake CL, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DEMIROZ G, 1997, P 9 EUR C MACH LEAR; GUNN S, 2003, NIPS FEATURE SELECTI; GUVENIR HA, 1997, P 12 INT S COMP INF; GUYON I, 2006, FEATURES EXTRACTION; HAMMERTON J, 2001, P C COMP NAT LANG LE, P9; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KASKI S, 1997, THESIS U TECHNOLOGY; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohonen T, 1997, SELF ORGANIZING MAPS; Kononenko I, 1992, INFORMATICA, V16, P1; Liu H., 1998, FEATURE EXTRACTION C; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; OH KS, 2002, P CHALL IM VID RETR, P299; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PATERITSAS C, 2005, P INT C COMP INT MOD, V2, P781; PATERITSAS C, 2004, P IEEE INT C SYST MA, P4832; RAUBER A, 1999, P INT JOINT C NEUR N; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Salzberg S., 1991, MACH LEARN, V6, P277; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TONG X, 2004, P 3 INT C MACH LEARN, V4, P2406; Vesanto J., 2000, SOM TOOLBOX MATLAB 5, V5; Vesanto J., 2000, USING SOM DATA MININ; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wettschereck D., 1995, P 1 INT C CAS BAS RE, P347; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; Yang Y, 2001, P 12 EUR C MACH LEAR, P564	39	0	0	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-2130			INT J ARTIF INTELL T	Int. J. Artif. Intell. Tools	OCT	2007	16	5					875	899		10.1142/S0218213007003588		25	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	237QH	WOS:000251390300006		
J	Zhu, M; Chen, W; Hirdes, JP; Stolee, P				Zhu, Mu; Chen, Wenhong; Hirdes, John P.; Stolee, Paul			The K-nearest neighbor algorithm predicted rehabilitation potential better than current Clinical Assessment Protocol	JOURNAL OF CLINICAL EPIDEMIOLOGY			English	Article						Bayes' theorem; clinical decision making; diagnostic likelihood ratio; interRAI; machine learning; rehabilitation	HOME-CARE; MDS-HC; COMMUNITY	Objective: There may be great potential for using computer-modeling techniques and machine-learning algorithms in clinical decision making, if these can be shown to produce results superior to clinical protocols currently in use. We aim to explore the potential to use an automatic, data-driven, machine-learning algorithm in clinical decision making. Study Design and Setting: Using a database containing comprehensive health assessment information (the interRAI-HC) on home care clients (N = 24,724) from eight community-care regions in Ontario, Canada, we compare the performance of the K-nearest neighbor (KNN) algorithm and a Clinical Assessment Protocol (the "ADLCAP") currently used to predict rehabilitation potential. For our purposes, we define a patient as having rehabilitation potential if the patient had functional improvement or remained at home over a follow-up period of approximately 1 year. Results: The KNN algorithm has a lower false positive rate in all but one of the eight regions in the sample, and lower false negative rates in all regions. Compared using likelihood ratio statistics, KNN is uniformly more informative than the ADLCAP. Conclusion: This article illustrates the potential for a machine-learning algorithm to enhance clinical decision making. (C) 2007 Elsevier Inc. All rights reserved.	Univ Waterloo, Dept Hlth Studies & Gerontol, Waterloo, ON N2L 3G1, Canada; Univ Waterloo, Dept Stat & Actuarial Sci, Waterloo, ON N2L 3G1, Canada; Homewood Hlth Ctr, Homewood Res Inst, Guelph, ON, Canada; Univ Waterloo, Sch Optometry, Waterloo, ON N2L 3G1, Canada	Stolee, P (reprint author), Univ Waterloo, Dept Hlth Studies & Gerontol, Waterloo, ON N2L 3G1, Canada.	m3zhu@uwaterloo.ca; wchen@uwaterloo.ca; hirdes@uwaterloo.ca; stolee@uwaterloo.ca					Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diwan S, 2004, J APPL GERONTOL, V23, P193, DOI 10.1177/0733464804267970; Greenhalgh T, 1997, BRIT MED J, V315, P540; HARRELL FE, 1998, STAT MED, V4, P361; Hastie T, 2001, ELEMENTS STAT LEARNI; Hirdes J P, 1999, Healthc Manage Forum, V12, P30; Hirdes JP, 2004, GERONTOLOGIST, V44, P665; Landi F, 2000, MED CARE, V38, P1184, DOI 10.1097/00005650-200012000-00005; Mitnitski AB, 2003, J CLIN EPIDEMIOL, V56, P116, DOI 10.1016/S0895-4356(02)00581-4; Morris JN, 1999, J GERONTOL A-BIOL, V54, pM546, DOI 10.1093/gerona/54.11.M546; MORRIS JN, 1999, PRIMER USE MINIMUM D; Morris JN, 1997, J AM GERIATR SOC, V45, P1017; Ottenbacher KJ, 2004, ANN EPIDEMIOL, V14, P551, DOI 10.1016/j.annepidem.2003.10.005; Pepe MS, 2003, STAT EVALUATION MED; R Development Core Team, 2006, R LANG ENV STAT COMP; Sackett D, 1991, CLIN EPIDEMIOLOGY BA; Stoke P, 2004, GERIATR TODAY J CAN, V7, P38; Tam SF, 2004, INT J REHABIL RES, V27, P65, DOI 10.1097/01.mrr.0000119282.12233.0f; TREMBLAY M, 2005, PREDICTIVE HLTH POLI	20	2	2	1	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0895-4356			J CLIN EPIDEMIOL	J. Clin. Epidemiol.	OCT	2007	60	10					1015	1021		10.1016/j.jclinepi.2007.06.001		7	Health Care Sciences & Services; Public, Environmental & Occupational Health	Health Care Sciences & Services; Public, Environmental & Occupational Health	217OF	WOS:000249956500005	17884595	
J	Garrow, AG; Westhead, DR				Garrow, Andrew G.; Westhead, David R.			A consensus algorithm to screen genomes for novel families of transmembrane beta barrel proteins	PROTEINS-STRUCTURE FUNCTION AND BIOINFORMATICS			English	Article						transmembrane beta-barrel; outer membrane; porin; prediction; algorithm; TMB-hunt	OUTER-MEMBRANE PROTEINS; AMINO-ACID-COMPOSITION; GRAM-NEGATIVE BACTERIA; HIDDEN MARKOV-MODELS; DATA-BANK; SECONDARY STRUCTURE; TMB-HUNT; PREDICTION; CLASSIFICATION; DATABASE	The ability to search sequence datasets for membrane spanning proteins is an important requirement for genome annotation. However, the development of algorithms to identify novel types of transmembrane beta-barrel (TMB) protein has proven substantially harder than for transmembrane helical proteins, owing to a shorter TM domain in which only alternate residues are hydrophobic. Although recent reports have described important improvements in the development Of such algorithms, there is still concern over their ability to confidently screen genomes. Here we describe a new algorithm combining composition and hidden Markov model topology based classifiers (called TMB-Hunt2), which achieves a crossvalidation accuracy of > 95%, with 96.7% precision and 94.2% recall. An overview is given of the algorithm design, with a thorough assessment of performance and application to a number of genomes. Of particular note is that TMB/extracellular protein discrimination is significantly more difficult than TMB/cytoplasmic protein discrimination, with the predictor correctly rejecting just 74% of extracellular proteins, in comparison to 98% of cytoplasmic proteins. Focus is given to directions for further improvements in TMB/non-TMB protein discrimination, with a call for the development of standardized tests and assessments of such algorithms. Tools and datasets are made available through a website called TMB-Web.	Univ Leeds, Inst Biol Mol & Cellulaire, Leeds LS2 9JT, W Yorkshire, England	Westhead, DR (reprint author), Univ Leeds, Inst Biol Mol & Cellulaire, Leeds LS2 9JT, W Yorkshire, England.	d.r.westhead@leeds.ac.uk					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bagos PG, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-29; Bagos PG, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-7; Bairoch A, 2005, NUCLEIC ACIDS RES, V33, pD154, DOI 10.1093/nar/gki070; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Barker GC, 1999, GENE, V229, P131, DOI 10.1016/S0378-1119(99)00039-6; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Berven FS, 2004, NUCLEIC ACIDS RES, V32, pW394, DOI 10.1093/nar/gkh351; Bigelow HR, 2004, NUCLEIC ACIDS RES, V32, P2566, DOI 10.1093/nar/gkh580; Byvatov Evgeny, 2003, Appl Bioinformatics, V2, P67; Casadio R, 2003, PROTEIN SCI, V12, P1158, DOI 10.1110/ps.0223603; Chen Chien Peter, 2002, Appl Bioinformatics, V1, P21; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DURBIN R, 2006, BIOL SEQUENCE ANAL P, P63; Eyrich VA, 2001, BIOINFORMATICS, V17, P1242, DOI 10.1093/bioinformatics/17.12.1242; Fariselli P, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S4-S12; Fichera ME, 1997, NATURE, V390, P407, DOI 10.1038/37132; Fischer D, 2003, PROTEINS, V53, P503, DOI 10.1002/prot.10538; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Garrow AG, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-56; Garrow AG, 2005, NUCLEIC ACIDS RES, V33, pW188, DOI 10.1093/nat/gki384; Gobert GN, 2003, INT J PARASITOL, V33, P1561, DOI 10.1016/S0020-7519(03)00255-8; Liu Q, 2003, COMPUT BIOL CHEM, V27, P69, DOI 10.1016/S0097-8485(02)00051-7; Liu Q, 2003, COMPUT BIOL CHEM, V27, P355, DOI 10.1016/S1476-9271(02)00085-3; Marani P, 2006, PROTEIN SCI, V15, P884, DOI 10.1110/ps.051889506; Martelli P. L., 2002, BIOINFORMATICS, V18, P46; Mirus O, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-254; Moller S, 2000, BIOINFORMATICS, V16, P1159, DOI 10.1093/bioinformatics/16.12.1159; MURZIN AG, 1995, J MOL BIOL, V247, P536, DOI 10.1016/S0022-2836(05)80134-2; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Natt NK, 2004, PROTEINS, V56, P11, DOI 10.1002/prot.20092; Noguchi T, 2001, NUCLEIC ACIDS RES, V29, P219, DOI 10.1093/nar/29.1.219; Park KJ, 2005, BIOINFORMATICS, V21, P4223, DOI 10.1093/bioinformatics/bti697; Postle K, 2000, NAT STRUCT BIOL, V7, P527, DOI 10.1038/76726; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rey S, 2005, NUCLEIC ACIDS RES, V33, pD164, DOI 10.1093/nar/gki027; Rost Burkhard, 2003, Methods Biochem Anal, V44, P559; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Schleiff E, 2003, PROTEIN SCI, V12, P748, DOI 10.1110/ps.0237503; Schulz GE, 2000, CURR OPIN STRUC BIOL, V10, P443, DOI 10.1016/S0959-440X(00)00120-2; Song LZ, 1996, SCIENCE, V274, P1859, DOI 10.1126/science.274.5294.1859; Tusnady GE, 2005, NUCLEIC ACIDS RES, V33, pD275, DOI 10.1093/nar/gki002; Wimley WC, 2003, CURR OPIN STRUC BIOL, V13, P404, DOI 10.1016/S0959-440X(03)00099-X; Wimley WC, 2002, PROTEIN SCI, V11, P301, DOI 10.1110/ps.29402; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K; Zhai YF, 2002, PROTEIN SCI, V11, P2196, DOI 10.1110/ps.0209002	49	7	8	0	0	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	0887-3585			PROTEINS	Proteins	OCT	2007	69	1					8	18		10.1002/prot.21439		11	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	206NA	WOS:000249189000002	17557332	
J	Aluja-Banet, T; Daunis-I-Estadella, J; Pellicer, D				Aluja-Banet, Tomas; Daunis-i-Estadella, Josep; Pellicer, David			GRAFT, a complete system for data fusion	COMPUTATIONAL STATISTICS & DATA ANALYSIS			English	Article						data fusion; statistical matching; imputation; k-nn	MISSING-DATA	Data fusion concerns the problem of merging information coming from independent sources. Also known as statistical matching, file grafting or microdata merging, it is a challenging problem for statisticians. The increasing growth of collected data makes combining different sources of information an attractive alternative to single source data. The interest in data fusion derives, in certain cases, from the impossibility of attaining specific information from one source of data and the reduction of the cost entailed by this operation and, in all cases, from taking greater advantage of the available collected information. The GRAFT system is presented. It is a multipurpose data fusion system based on the k-nearest neighbor (k-nn) hot deck imputation method. The system aim is to cope with many data fusion problems and domains. The k-nn is a very demanding algorithm. The solutions envisaged and their cost, which allow this methodology to be used in a wide range of real problems, are presented. (C) 2006 Elsevier B.V. All rights reserved.	[Aluja-Banet, Tomas] Univ Politecn Cataluna, E-08034 Barcelona, Spain; [Daunis-i-Estadella, Josep] Univ Girona, E-17071 Girona, Spain; [Pellicer, David] TNS Audiencia Medios, E-08173 Sant Cugat Del Valles, Spain	Aluja-Banet, T (reprint author), Univ Politecn Cataluna, Jordi Girona Salgado 1-3,CN C5204, E-08034 Barcelona, Spain.	tomas.aluja@upc.edu	Daunis-i-Estadella, Josep/B-9082-2011; Aluja, Tomas/H-6895-2015; 	Aluja, Tomas/0000-0003-3096-0339; Daunis-i-Estadella, Josep/0000-0001-6134-9255			Ahuja Ravindra K., 1993, NETWORK FLOWS THEORY; ALUJA T, 2001, TRAITEMENT FICHIERS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; D'Orazio M, 2006, STAT MATCHING THEORY; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Fix E., 1951, 4 USAF SCH AV MED; Friedman JH, 1994, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1975, IEEE T COMPUT C, V26, P917; Hastie T, 2001, ELEMENTS STAT LEARNI; LEJEUNE M, 1995, P 50 SESS ISI BEIJ, V56, P923; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Ripley BD, 1996, PATTERN RECOGNITION; Rius R, 1999, APPL STOCH MODEL BUS, V15, P451, DOI 10.1002/(SICI)1526-4025(199910/12)15:4<451::AID-ASMB408>3.0.CO;2-C; Rubin D. B., 1987, STAT ANAL MISSING DA; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.1093/biomet/63.3.581; SANTINI G, 2004, METHODE FUSION REFER; Schafer JL, 1998, MULTIVAR BEHAV RES, V33, P545, DOI 10.1207/s15327906mbr3304_5; TENNENHAUS M, 1998, REGRESSION PLS THEOR; WINKLER WE, 1995, WILEY S PRO, P355	19	6	6	2	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9473			COMPUT STAT DATA AN	Comput. Stat. Data Anal.	OCT 15	2007	52	2					635	649		10.1016/j.csda.2006.11.029		15	Computer Science, Interdisciplinary Applications; Statistics & Probability	Computer Science; Mathematics	265ND	WOS:000253365300003		
J	Koukal, T; Suppan, F; Schneider, W				Koukal, Tatjana; Suppan, Franz; Schneider, Werner			The impact of relative radiometric calibration on the accuracy of kNN-predictions of forest attributes	REMOTE SENSING OF ENVIRONMENT			English	Article; Proceedings Paper	Conference on Operational Tools in Forestry Using Remote Sensing Techniques (ForestSAT 2005)	MAY 31-JUN 03, 2005	Boras, SWEDEN	Swedish Forest Agcy		scene-to-scene radiometric normalisation; k-nearest-neighbour method; cross-validation; forest inventory; phenology	NORMALIZATION; INVENTORY; IMAGES; VOLUME	The k-nearest-neighbour (kNN) algorithm is widely applied for the estimation of forest attributes using remote sensing data. It requires a large amount of reference data to achieve satisfactory results. Usually, the number of available reference plots for the kNN-prediction is limited by the size of the area covered by a terrestrial reference inventory and remotely sensed imagery collected from one overflight. The applicability of kNN could be enhanced if adjacent images of different acquisition dates could be used in the same estimation procedure. Relative radiometric calibration is a prerequisite for this. This study focuses on two empirical calibration methods. They are tested on adjacent LANDSAT TM scenes in Austria. The first, quite conventional one is based on radiometric control points in the overlap area of two images and on the determination of transformation parameters by linear regression. The other, recently developed method exploits the kNN-cross-validation procedure. Performance and applicability of both methods as well as the impact of phenology are discussed. (C) 2007 Elsevier Inc. All rights reserved.	Univ Nat Resources & Appl Life Sci, Inst Survejing Remote Sensing & Land Informat, Dept Landscape Spatial & Infrastruct Sci, Vienna, Austria	Koukal, T (reprint author), Univ Nat Resources & Appl Life Sci, Inst Survejing Remote Sensing & Land Informat, Dept Landscape Spatial & Infrastruct Sci, Vienna, Austria.	tariana.koukal@boku.ac.at					Congalton R, 1999, ASSESSING ACCURACY R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Du Y, 2002, REMOTE SENS ENVIRON, V82, P123, DOI 10.1016/S0034-4257(02)00029-9; Efron B., 1993, MONOGRAPHS STAT APPL, V57; ELVIDGE CD, 1995, PHOTOGRAMM ENG REM S, V61, P1255; Fazakas Z, 1999, AGR FOREST METEOROL, V98-9, P417, DOI 10.1016/S0168-1923(99)00112-4; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Goldberg D. E., 1989, GENETIC ALGORITHMS S; HALL FG, 1991, REMOTE SENS ENVIRON, V35, P11, DOI 10.1016/0034-4257(91)90062-B; Katila M, 2001, REMOTE SENS ENVIRON, V76, P16, DOI 10.1016/S0034-4257(00)00188-7; KILKKI P, 1987, REMOTE SENSING AIDED, P209; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Koukal T, 2004, THESIS U NATURAL RES; McRoberts RE, 2002, REMOTE SENS ENVIRON, V82, P457, DOI 10.1016/S0034-4257(02)00064-0; OVER M, 2003, P IEEE INT GEOSC RE; Richards J. A., 2006, REMOTE SENSING DIGIT; SANDMEIER S, 1995, PHYS BASED RADIOMET; SCHOTT JR, 1988, REMOTE SENS ENVIRON, V26, P1, DOI 10.1016/0034-4257(88)90116-2; Steinwendner J, 2001, DIGITAL IMAGE ANALYSIS: SELECTED TECHNIQUES AND APPLICATIONS, P337, DOI 10.1007/0-387-21643-X_16; Tomppo E, 2004, REMOTE SENS ENVIRON, V92, P1, DOI 10.1016/j.rse.2004.04.003; Tomppo E., 1991, INT ARCH PHOTOGRAMME, V28, P419; VERMOTE E, 1997, 2 U MAR DEP GEOGR	23	13	15	1	6	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0034-4257			REMOTE SENS ENVIRON	Remote Sens. Environ.	OCT 30	2007	110	4					431	437		10.1016/j.rse.2006.08.016		7	Environmental Sciences; Remote Sensing; Imaging Science & Photographic Technology	Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology	216QT	WOS:000249894800004		
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Recent progress in protein subcellular location prediction	ANALYTICAL BIOCHEMISTRY			English	Review							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINES; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; NEAREST-NEIGHBOR ALGORITHM; GRAM-NEGATIVE BACTERIA; LOCALIZATION PREDICTION; ENSEMBLE CLASSIFIER; CONOTOXIN SUPERFAMILY; FUSION CLASSIFIER		Gordon Life Sci Inst, San Diego, CA 92130 USA; Harvard Univ, Sch Med, Dept Biol Chem & Mol Pharmacol, Boston, MA 02115 USA	Chou, KC (reprint author), Gordon Life Sci Inst, San Diego, CA 92130 USA.	kcchou@gordonlifescience.org	Chou, Kuo-Chen/A-8340-2009				Alberts B., 2002, MOL BIOL CELL; Alberts B., 1994, MOL BIOL CELL; Altschul SE, 1997, THEORETICAL AND COMPUTATIONAL METHODS IN GENOME RESEARCH, P1; Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 1999, BIOCHEM BIOPH RES CO, V264, P216, DOI 10.1006/bbrc.1999.1325; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; CHOU KC, 1993, J BIOL CHEM, V268, P16938; Chou KC, 2005, BIOINFORMATICS, V21, P944, DOI 10.1093/bioinformatics/bti104; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; CHOU PY, PREDICTION PROTEIN S, P549; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Emanuelsson O, 2007, NAT PROTOC, V2, P953, DOI 10.1038/nprot.2007.131; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; FENG ZP, 2002, IN SILICO BIOL, V2, P291; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Hoglund A, 2006, BIOINFORMATICS, V22, P1158, DOI 10.1093/bioinformatics/btl002; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; KLEIN P, 1986, BIOPOLYMERS, V25, P1659, DOI 10.1002/bip.360250909; Lee K, 2006, NUCLEIC ACIDS RES, V34, P4655, DOI 10.1093/nar/gkl638; Lei ZD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-291; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lodish H, 1995, MOL CELL BIOL, V3rd; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mardia K. V., 1979, MULTIVARIATE ANAL; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; METFESSEL BA, 1993, PROTEIN SCI, V2, P1171; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Shafer G., 1976, MATH THEORY EVIDENCE; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shi JY, 2007, AMINO ACIDS, V33, P69, DOI 10.1007/s00726-006-0475-y; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; WOOTTON JC, 1993, COMPUT CHEM, V17, P149, DOI 10.1016/0097-8485(93)85006-X; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhang ZH, 2006, FEBS LETT, V580, P6169, DOI 10.1016/j.febslet.2006.10.017; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	94	575	587	8	48	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0003-2697			ANAL BIOCHEM	Anal. Biochem.	NOV 1	2007	370	1					1	16		10.1016/j.ab.2007.07.006		16	Biochemical Research Methods; Biochemistry & Molecular Biology; Chemistry, Analytical	Biochemistry & Molecular Biology; Chemistry	215FV	WOS:000249794600001	17698024	
J	Angiulli, F				Angiulli, Fabrizio			Fast nearest neighbor condensation for large data sets classification	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; large and high-dimensional data; nearest neighbor rule; prototype selection algorithms; training-set-consistent subset	LEARNING ALGORITHMS; RULE; RECOGNITION; RISK	This work has two main objectives, namely, to introduce a novel algorithm, called the Fast Condensed Nearest Neighbor (FCNN) rule, for computing a training-set-consistent subset for the nearest neighbor decision rule and to show that condensation algorithms for the nearest neighbor rule can be applied to huge collections of data. The FCNN rule has some interesting properties: it is order independent, its worst-case time complexity is quadratic but often with a small constant prefactor, and it is likely to select points very close to the decision boundary. Furthermore, its structure allows for the triangle inequality to be effectively exploited to reduce the computational effort. The FCNN rule outperformed even here-enhanced variants of existing competence preservation methods both in terms of learning speed and learning scaling behavior and, often, in terms of the size of the model while it guaranteed the same prediction accuracy. Furthermore, it was three orders of magnitude faster than hybrid instance-based learning algorithms on the MNIST and Massachusetts Institute of Technology (MIT) Face databases and computed a model of accuracy comparable to that of methods incorporating a noise-filtering pass.	Univ Calabria, Dipartimento Elettron Informat & Sistemat, I-87036 Cosenza, Italy	Angiulli, F (reprint author), Univ Calabria, Dipartimento Elettron Informat & Sistemat, Via P Bucci 41C, I-87036 Cosenza, Italy.	f.angiulli@deis.unical.it					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Angiulli F., 2005, P 22 INT C MACH LEAR, P25, DOI 10.1145/1102351.1102355; Bay S., 1998, P 15 INT C MACH LEAR; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bhattacharya B., 1998, P 14 INT C PATT REC; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Dasarathy BV, 1991, NEAREST NEIGHBOUR NN; Devi VS, 2002, PATTERN RECOGN, V35, P505; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Devroye L., 1996, PROBABILISTIC THEORY; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE C, 1977, ANN STAT, V8, P1348; TOUSSAINT G, 2002, P 34 S INT COMP SCI; Watson I., 1994, KNOWLEDGE ENG REV, V9; Wilfong G, 1992, INT J COMPUT GEOM AP, V2, P383, DOI 10.1142/S0218195992000226; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	32	55	63	4	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	NOV	2007	19	11					1450	1464		10.1109/TKDE.2007.190645		15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	211ZT	WOS:000249563900002		
J	Tang, YH; Gao, JH				Tang, Yaohua; Gao, Jinghuai			Improved classification for problem involving overlapping patterns	IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS			English	Article						boundary pattern; rough set; classification; support vector machine		The support vector machine has received wide acceptance for its high generalization ability in real world classification applications. But a drawback is that it uniquely classifies each pattern to one class or none. This is not appropriate to be applied in classification problem involves overlapping patterns. In this paper, a novel multi-model classifier (DR-SVM) which combines SVM classifier with kNN algorithm under rough set technique is proposed. Instead of classifying the patterns directly, patterns lying in the overlapped region are extracted firstly. Then, upper and lower approximations of each class are defined on the basis of rough set technique. The classification operation is carried out on these new sets. Simulation results on synthetic data set and benchmark data sets indicate that, compared with conventional classifiers, more reasonable and accurate information about the pattern's category could be obtained by use of DR-SVM.	Xian Jiaotong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China	Tang, YH (reprint author), Xian Jiaotong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.	tangsl@mail.xjtu.edu.cn					Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; GRA G, 2002, FUNDAMENTA INFORM, V51, P369; Gunn S. R., 1998, SUPPORT VECTOR MACHI; KORM F, 2000, P ACM SIGMOD, P201; LINGRAS P, 2005, INF SCI, V172, P216; LINGRAS P, 2005, P IEEE INT C GRAN CO, V1, P193; Lingras P, 2001, J INTELL INF SYST, V16, P215, DOI 10.1023/A:1011219918340; LINGRAS P, 2004, P N AM FUZZ INF PROC, P17; LINGRAS P, 2004, P NAFIPS 04 IEEE ANN, V2, P27; Pawlak Z, 2004, LECT NOTES COMPUT SC, V3100, P1; QUINLAN R., 1996, J ARTIFICIAL INTELLI, V4, P77, DOI [10.1613/jair.279, DOI 10.1613/JAIR.279]; Vapnik V, 2000, NATURE STAT LEARNING; WANG LS, 2005, P INT C MACH LEARN C, V3, P18; Xia C., 2004, P 30 INT C VER LARG, P756, DOI 10.1016/B978-012088469-8/50067-X; Xia CY, 2006, IEEE T KNOWL DATA EN, V18, P289; ZHANG B, 2006, P INT JOINT C NEUR N, P2583	18	5	6	3	5	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG MINATO-KU SHIBAKOEN 3 CHOME, TOKYO, 105, JAPAN	0916-8532			IEICE T INF SYST	IEICE Trans. Inf. Syst.	NOV	2007	E90D	11					1787	1795		10.1093/ietisy/e90-d.11.1787		9	Computer Science, Information Systems; Computer Science, Software Engineering	Computer Science	235IK	WOS:000251226900007		
J	Ghosh, AK; Bose, S				Ghosh, Anil Kumar; Bose, Smarajit			Feature extraction for classification using statistical networks	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						artificial neural networks; backfitting; classification using splines; cross-validation; feature selection; projection pursuit regression	DISCRIMINANT-ANALYSIS; NEURAL-NETWORKS; PROJECTION PURSUIT; REGRESSION	In a classification problem, quite often the dimension of the measurement vector is large. Some of these measurements may not be important for separating the classes. Removal of these measurement variables not only reduces the computational cost but also leads to better understanding of class separability. There are some methods in the existing literature for reducing the dimensionality of a classification problem without losing much of the separability information. However, these dimension reduction procedures usually work well for linear classifiers. In the case where competing classes are not linearly separable, one has to look for ideal "features" which could be some transformations of one or more measurements. In this paper, we make an attempt to tackle both, the problems of dimension reduction and feature extraction, by considering a projection pursuit regression model. The single hidden layer perceptron model and some other popular models can be viewed as special cases of this model. An iterative algorithm based on backfitting is proposed to select the features dynamically, and cross-validation method is used to select the ideal number of features. We carry out an extensive simulation study to show the effectiveness of this fully automatic method.	[Ghosh, Anil Kumar] Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India; [Bose, Smarajit] Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, India	Ghosh, AK (reprint author), Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India.	anilkghosh@rediffmail.com; smarajit@isical.ac.in					Anderson T. W., 1984, INTRO MULTIVARIATE S, V2nd; Bose S, 1996, COMPUT STAT DATA AN, V22, P505, DOI 10.1016/0167-9473(96)00009-6; BOSE S, 1992, THESIS U CALIFORNIA; Bose S, 2003, COMPUT STAT DATA AN, V42, P685, DOI 10.1016/S0167-9473(02)00171-8; BREIMAN L, 1985, J AM STAT ASSOC, V80, P580, DOI 10.2307/2288473; Breiman L., 1984, CLASSIFICATION REGRE; BREIMAN L, 1993, COMPUT STAT DATA AN, V15, P13, DOI 10.1016/0167-9473(93)90217-H; CHENG B, 1994, STAT SCI, V9, P2, DOI 10.1214/ss/1177010638; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristiani N., 2000, INTRO SUPPORT VECTOR; De Boor C., 1978, PRACTICAL GUIDE SPLI; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fisher RA, 1936, ANN EUGENIC, V7, P179; FIX E, 1951, 2149004 RAND FIELD; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Fukunaga K., 1990, INTRO STAT PATTERN R; Ghosh AK, 2004, COMPUTATION STAT, V19, P193, DOI 10.1007/BF02892056; Ghosh AK, 2005, BERNOULLI, V11, P1, DOI 10.3150/bj/1110228239; Hand D. J., 1982, KERNEL DISCRIMINANT; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hastie T. J., 1994, J COMPUTA GRAPHICAL, V3, P235, DOI 10.1080/10618600.1994.10474642; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Kooperberg C, 1997, J AM STAT ASSOC, V92, P117, DOI 10.2307/2291455; Laarhoven P.J. M., 1987, SIMULATED ANNEALING; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mika S, 2000, ADV NEUR IN, V12, P526; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; Ripley BD, 1996, PATTERN RECOGNITION; Scholkopf S, 1999, ADV KERNEL METHODS S; Scott D.W., 1992, MULTIVARIATE DENSITY; Seber G. A. F., 1989, NONLINEAR REGRESSION; Silverman BW, 1986, DENSITY ESTIMATION S; Stone M., 1978, Mathematische Operationsforschung und Statistik, Series Statistics, V9; Vapnik V., 1998, STAT LEARNING THEORY; Zhu M, 2003, J COMPUT GRAPH STAT, V12, P101, DOI 10.1198/1061860031220	43	5	5	1	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014	1793-6381		INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	NOV	2007	21	7					1103	1126		10.1142/S0218001407005855		24	Computer Science, Artificial Intelligence	Computer Science	242IY	WOS:000251720000001		
J	Morrison, D; De Silva, LC				Morrison, Donn; De Silva, Liyanage C.			Voting ensembles for spoken affect classification	JOURNAL OF NETWORK AND COMPUTER APPLICATIONS			English	Article; Proceedings Paper	3rd International Conference on Information Technology and Applications	JUL 04-07, 2005	Sydney, AUSTRALIA	IEEE NSW Sect, Univ Technol, FIT, Univ Technol, IICT		affect recognition; emotion recognition; ensemble methods; speech processing	EMOTION; SPEECH	Affect or emotion classification from speech has much to benefit from ensemble classification methods. In this paper we apply a simple voting mechanism to an ensemble of classifiers and attain a modest performance increase compared to the individual classifiers. A natural emotional speech database was compiled from 11 speakers. Listener-judges were used to validate the emotional content of the speech. Thirty-eight prosody-based features correlating characteristics of speech with emotional states were extracted from the data. A classifier ensemble was designed using a multi-layer perceptron, support vector machine, K* instance-based learner, K-nearest neighbour, and random forest of decision trees. A simple voting scheme determined the most popular prediction. The accuracy of the ensemble is compared with the accuracies of the individual classifiers. (c) 2006 Elsevier Ltd. All rights reserved.	Massey Univ, Inst Informat Sci & Technol, Palmerston North, New Zealand	De Silva, LC (reprint author), Massey Univ, Inst Informat Sci & Technol, Private Bag 11222, Palmerston North, New Zealand.	l.desilva@massey.ac.nz					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cleary J. G., 1995, ICML, P108; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWAN M, 1936, PITCH INTENSITY CHAR, P1; Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970; Devillers L., 2002, ISLE WORKSH DIAL TAG; Fairbanks G, 1941, SPEECH MONOGR, V8, P85; Fairbanks G, 1939, SPEECH MONOGR, V6, P87; Fonagy I., 1981, RES ASPECTS SINGING, V33, P51; FONAGY I, 1978, LANG SPEECH, V21, P34; FRICK RW, 1986, AGGRESSIVE BEHAV, V12, P121, DOI 10.1002/1098-2337(1986)12:2<121::AID-AB2480120206>3.0.CO;2-F; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; HUBER R, 2000, INT C SPOK LANG PROC, V1, P665; MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; Petrushin V.A., 2000, P 6 INT C SPOK LANG; Picard R. W., 1997, AFFECTIVE COMPUTING; Platt J., 1998, ADV KERNEL METHODS S; POLZIN TS, 2000, ISCA WORKSH SPEECH E; Rabiner L. R., 1978, DIGITAL PROCESSING S; SCHERER KR, 1996, INT C SPOK LANG PROC; Shipp C. A., 2002, Information Fusion, V3, DOI 10.1016/S1566-2535(02)00051-9; Talkin D., 1995, SPEECH CODING SYNTHE, P495; Vapnik V. N., 1995, NATURE STAT LEARNING; WILLILAMS CE, 1972, NONVERBAL COMMUNICAT; YACOUB S, 2003, EUROSPEECH 2003	28	7	9	2	3	ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1084-8045			J NETW COMPUT APPL	J. Netw. Comput. Appl.	NOV	2007	30	4					1356	1365		10.1016/j.jnca.2006.09.005		10	Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	217LN	WOS:000249949500009		
J	Besaw, LE; Rizzo, DM				Besaw, Lance E.; Rizzo, Donna M.			Stochastic simulation and spatial estimation with multiple data types using artificial neural networks	WATER RESOURCES RESEARCH			English	Article							MICROBIAL COMMUNITY STRUCTURE; LEACHATE-POLLUTED AQUIFER; JOINT INVERSION; COUNTERPROPAGATION NETWORKS; GROUNDWATER CONTAMINATION; HYDRAULIC CONDUCTIVITY; SOIL; CLASSIFICATION; IDENTIFICATION; HYDROCHEMISTRY	A novel data-driven artificial neural network ( ANN) that quantitatively combines large numbers of multiple types of soft data is presented for performing stochastic simulation and/or spatial estimation. A counterpropagation ANN is extended with a radial basis function to estimate parameter fields that reproduce the spatial structure exhibited in autocorrelated parameters. Applications involve using three geophysical properties measured on a slab of Berea sandstone and the delineation of landfill leachate at a site in the Netherlands using electrical formation conductivity as our primary variable and six types of secondary data ( e. g., hydrochemistry, archaea, and bacteria). The ANN estimation fields are statistically similar to geostatistical methods ( indicator simulation and cokriging) and reference fields ( when available). The method is a nonparametric clustering/ classification algorithm that can assimilate significant amounts of disparate data types with both continuous and categorical responses without the computational burden associated with the construction of positive definite covariance and cross-covariance matrices. The combination of simplicity and computational speed makes the method ideally suited for environmental subsurface characterization and other Earth science applications with spatially autocorrelated variables.	Univ Vermont, Sch Engn, Burlington, VT 05405 USA	Besaw, LE (reprint author), Univ Vermont, Sch Engn, Votey Hall,33 Colchester Ave, Burlington, VT 05405 USA.	lbesaw@cems.uvm.edu; drizzo@cems.uvm.edu					AZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P821; BALLARD JH, 1998, SAGEEP 1998 S APPL G; BASHKIRO.OA, 1964, AUTOMAT REM CONTR+, V25, P629; Bosch M, 2004, GEOPHYSICS, V69, P1272, DOI 10.1190/1.1801944; COPTY N, 1995, WATER RESOUR RES, V31, P1673, DOI 10.1029/95WR00947; COPTY N, 1993, WATER RESOUR RES, V29, P2813, DOI 10.1029/93WR00745; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de la Vega M, 2003, J APPL GEOPHYS, V54, P97, DOI 10.1016/j.jappgeo.2003.08.020; Fidencio PH, 2001, ANALYST, V126, P2194, DOI 10.1039/b107533k; Garcia LA, 2006, J HYDROL, V318, P215, DOI 10.1016/j.jhydrol.2005.05.028; GELB S, 1998, SAGEEP 1998 S APPL G; Gloaguen E, 2001, J APPL GEOPHYS, V47, P135, DOI 10.1016/S0926-9851(01)00057-X; Goovaerts P, 2005, WATER RESOUR RES, V41, DOI 10.1029/2004WR003705; Goovaerts P, 1998, BIOL FERT SOILS, V27, P315, DOI 10.1007/s003740050439; GOOVAERTS P, 1999, STOCH ENV RES RISK A, V13, P182; Goovaerts P, 2001, GEODERMA, V103, P3, DOI 10.1016/S0016-7061(01)00067-2; HECHTNIELSEN R, 1988, NEURAL NETWORKS, V1, P131, DOI 10.1016/0893-6080(88)90015-9; HECHTNIELSEN R, 1987, APPL OPTICS, V26, P4979, DOI 10.1364/AO.26.004979; Hohmann G.W., 1988, ELECTROMAGNETIC METH, V1, P469; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; Hsu KL, 1999, WATER RESOUR RES, V35, P1605, DOI 10.1029/1999WR900032; Istok JD, 1996, GROUND WATER, V34, P1050, DOI 10.1111/j.1745-6584.1996.tb02171.x; Journel AG, 1989, TERRA NOVA, V1, P123, DOI DOI 10.1111/J.1365-3121.1989.TB00344.X; Kis M, 2002, J APPL GEOPHYS, V50, P401, DOI 10.1016/S0926-9851(02)00167-2; KOHONEN T, 1989, SELF ORG ASSOCIATED; Li BL, 1999, WATER RESOUR RES, V35, P3663, DOI 10.1029/1999WR900268; MENKE W, 1984, GEOPHYS RES LETT, V11, P105, DOI 10.1029/GL011i002p00105; Morshed J, 1998, WATER RESOUR RES, V34, P1101, DOI 10.1029/98WR00006; Mouser PJ, 2005, ENVIRON SCI TECHNOL, V39, P7551, DOI 10.1021/es0502627; Nie JH, 1996, FUZZY SET SYST, V78, P5, DOI 10.1016/0165-0114(95)00118-2; Oldenburg D.W., 1998, LEADING EDGE, V17, P461, DOI 10.1190/1.1437989; Park YS, 2003, WATER RES, V37, P1749, DOI 10.1016/S0043-1354(02)00557-2; Patriarche D, 2005, MATH GEOL, V37, P587, DOI 10.1007/s11004-005-7308-5; PITKIN SE, 1998, S APPL GEOPH ENV ENG; PURDY C, 1998, S APPL GEOPH ENV ENG; Rizzo DM, 1996, GEOTECH SP, P167; RIZZO DM, 1994, THESIS U VERMONT BUR; RIZZO DM, 1994, WATER RESOUR RES, V30, P483, DOI 10.1029/93WR02477; Roling WFM, 2000, WATER SCI TECHNOL, V41, P47; Roling WFM, 2001, APPL ENVIRON MICROB, V67, P4619, DOI 10.1128/AEM.67.10.4619-4629.2001; Roling WFM, 2000, MICROBIAL ECOL, V40, P177; Rossabi J., 2000, Ground Water Monitoring and Remediation, V20, P72, DOI 10.1111/j.1745-6592.2000.tb00291.x; Rumelhart D.E., 1988, PARALLEL DISTRIBUTED; Tidwell VC, 1997, WATER RESOUR RES, V33, P1607, DOI 10.1029/97WR00804; Tidwell VC, 1999, MATH GEOL, V31, P749, DOI 10.1023/A:1007568632217; *US EPA, 2000, INN SIT CHAR GLOPH I; VOZOFF K, 1975, GEOPHYS J ROY ASTR S, V42, P977; Wasserman P.D., 1989, NEURAL COMPUTING; WINDROW G, 1960, ADAPTIVE SWITCHING C; YEH WWG, 1986, WATER RESOUR RES, V22, P95, DOI 10.1029/WR022i002p00095	51	6	7	0	3	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397			WATER RESOUR RES	Water Resour. Res.	NOV 8	2007	43	11							W11409	10.1029/2006WR005509		14	Environmental Sciences; Limnology; Water Resources	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	230ED	WOS:000250857900001		
J	Kasapoglu, NG; Ersoy, OK				Kasapoglu, N. Goekhan; Ersoy, Okan K.			Border vector detection and adaptation for classification of multispectral and hyperspectral remote sensing images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article; Proceedings Paper	4th International Workshop on Pattern Recognition in Remote Sensing	AUG   20, 2006	Hong Kong, PEOPLES R CHINA	Int Assoc Pattern Recognit, IEEE Geosci, Remote Sensing Soc		border vector detection and adaptation (BVDA); consensual classification; data classification; decision region borders; remote sensing	NEURAL-NETWORKS; PROJECTION PURSUIT; DECISION FUSION; MACHINES; PARALLEL; ACCURACY	Effective partitioning of the feature space for high classification accuracy with due attention to rare class members is often a difficult task. In this paper, the border vector detection and adaptation (BVDA) algorithm is proposed for this purpose. The BVDA consists of two parts. In the first part of the algorithm, some specially selected training samples are assigned as initial reference vectors called border vectors. In the second part of the algorithm, the border vectors are adapted by moving them toward the decision boundaries. At the end of the adaptation process, the border vectors are finalized. The method next uses the minimum distance to border vector rule for classification. In supervised learning, the training process should be unbiased to reach more accurate results in testing. In the BVDA, decision region borders are related to the initialization of the border vectors and the input ordering of the training samples. Consensus strategy can be applied with cross validation to reduce these dependencies. The performance of the BVDA and consensual BVDA were studied in comparison to other classification algorithms including neural network with backpropagation learning, support vector machines, and some statistical classification techniques.	Tech Univ Istanbul, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey; Purdue Univ, Dept Elect & Comp Engn, W Lafayette, IN 47907 USA	Kasapoglu, NG (reprint author), Tech Univ Istanbul, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey.						Alpaydin E, 1991, 91032 TR INT COMP SC; ARIKAN M, 2004, P ISPRS S IST INT AR, V34, P1085; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Benediktsson JA, 1997, IEEE T GEOSCI REMOTE, V35, P833, DOI 10.1109/36.602526; Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191; Benediktsson JA, 1999, IEEE T GEOSCI REMOTE, V37, P1367, DOI 10.1109/36.763301; Camps Valls G., 2006, IEEE GEOSCI REMOTE S, V3, P93; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Chee H.M., 2005, IEEE T GEOSCI REMOTE, V432, P1890; CHO S, 1993, IEEE T CIRCUITS-II, V40, P556, DOI 10.1109/82.257333; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawson M. S., 1993, Remote Sensing Reviews, V7; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764; Foody GM, 2006, REMOTE SENS ENVIRON, V103, P179, DOI 10.1016/j.rse.2006.04.001; Foody GM, 1999, INT J REMOTE SENS, V20, P3549, DOI 10.1080/014311699211192; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P99; Guttman A, 1984, P ACM SIGMOD INT C M, P47; Hoffsis GF, 1996, COMP CONT EDUC PRACT, V18, P7; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jia XP, 2005, IEEE GEOSCI REMOTE S, V2, P225, DOI 10.1109/LGRS.2005.846437; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P1360, DOI 10.1109/36.763300; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P2653, DOI 10.1109/36.803413; Joachims T., 1999, ADV KERNEL METHODS S; KARAKAHYA H, 2003, P 13 INT C ART NEUR, P1011; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; LANDGREBE D, MULTISPEC AVIRIS NW; Landgrebe D. A., 2003, SIGNAL THEORY METHOD; LEE CH, 1993, IEEE T PATTERN ANAL, V15, P388, DOI 10.1109/34.206958; LEE J, 2006, P IGARRS DENV CO JUL, P3915; Mather P.M., 1999, COMPUTER PROCESSING, V2nd; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; OMOHUNDRO SM, 1991, ADV NEURAL INFORM PR; Preparata F. P., 1985, COMPUTATIONAL GEOMET; SCHWAIGHOFER A, MATLAB INTERFACE SVM; Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VANNIEL TG, 2005, REMOTE SENS ENVIRON, V98, P416; Vapnik V., 1998, STAT LEARNING THEORY; Varshney PK, 2004, ADV IMAGE PROCESSING; SATIMAGE DATA SET	44	14	14	1	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	DEC	2007	45	12	1				3880	3893		10.1109/TGRS.2007.900699		14	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	236YL	WOS:000251339400004		
J	Martinez-Uso, A; Pla, F; Sotoca, JM; Garcia-Sevilla, P				Martinez-Uso, Adolfo; Pla, Filiberto; Sotoca, Jose Martinez; Garcia-Sevilla, Pedro			Clustering-based hyperspectral band selection using information measures	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						dimensionality reduction; feature clustering; feature selection; information theory	REMOTE-SENSING IMAGES; DIMENSIONALITY REDUCTION; CLASSIFICATION; EXTRACTION	Hyperspectral imaging involves large amounts of information. This paper presents a technique for dimensionality reduction to deal with hyperspectral images. The proposed method is based on a hierarchical clustering structure to group bands to minimize the intracluster variance and maximize the intercluster variance. This aim is pursued using information measures, such as distances based on mutual information or Kullback-Leibler divergence, in order to reduce data redundancy and nonuseful information among image bands. Experimental results include a comparison among some relevant and recent methods for hyperspectral band selection using no labeled information, showing their performance with regard to pixel image classification tasks. The technique that is presented has a stable behavior for different image data sets and a noticeable accuracy, mainly when selecting small sets of bands.	Univ Jaume 1, Dept Lenguajes & Syst Informat, E-12071 Castellon de La Plana, Spain	Martinez-Uso, A (reprint author), Univ Jaume 1, Dept Lenguajes & Syst Informat, E-12071 Castellon de La Plana, Spain.						Aczel J, 1975, MEASURES INFORM THEI; Breiman L., 1984, CLASSIFICATION REGRE; Bruzzone L, 1995, IEEE T GEOSCI REMOTE, V33, P1318, DOI 10.1109/36.477187; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Chang C.-I., 2003, HYPERSPECTRAL IMAGIN; Chang CI, 2002, IEEE T GEOSCI REMOTE, V40, P1065; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Dosil R, 2005, LECT NOTES COMPUT SC, V3523, P287; Gersho A., 1992, VECTOR QUANTIZATION; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P2653, DOI 10.1109/36.803413; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Landgrebe D. A., 2003, SIGNAL THEORY METHOD; MARTINEZUSO A, 2006, P ICPR, P760; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Mitchell T. M., 1997, MACHINE LEARNING; Plaza A, 2005, IEEE T GEOSCI REMOTE, V43, P466, DOI 10.1109/TGRS.2004.841417; Sanchez JS, 1998, PATTERN RECOGN LETT, V19, P1165, DOI 10.1016/S0167-8655(98)00108-1; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Slonim N., 2001, P 23 EUR C INF RETR, P191; Wang J, 2006, IEEE T GEOSCI REMOTE, V44, P1586, DOI 10.1109/TGRS.2005.80297; Ward J. H, 1963, AM STAT ASS J, V58, P236; Webb AR, 2002, STAT PATTERN RECOGNI	30	83	85	1	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	DEC	2007	45	12	2				4158	4171		10.1109/TGRS.2007.904951		14	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	236YM	WOS:000251339500012		
J	Angiulli, F; Folino, G				Angiulli, Fabrizio; Folino, Gianluigi			Distributed nearest neighbor-based condensation of very large data sets	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						classification; parallel and distributed algorithms; nearest neighbor rule; data condensation	LEARNING ALGORITHMS; PATTERN-CLASSIFICATION; RULE	In this work, the Parallel Fast Condensed Nearest Neighbor (PFCNN) rule, a distributed method for computing a consistent subset of a very large data set for the nearest neighbor classification rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. An analysis of spatial cost, CPU cost, and communication overhead is accomplished for all the algorithms. Experimental results, performed on both synthetic and real very large data sets, revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale up well and are efficient in memory consumption, confirming the theoretical analysis, and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule.	Univ Calabria, Dipartimento Elettr Informat & Sistemist, I-87036 Arcavacata Di Rende, CS, Italy; Italian Natl Res Council, Inst High Performance Comp & Networking, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, Dipartimento Elettr Informat & Sistemist, Via P Bucci,41C, I-87036 Arcavacata Di Rende, CS, Italy.	f.angiulli@deis.unical.it; folino@icar.cnr.it					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli Fabrizio, 2005, P 22 INT C MACH LEAR; APLAYDIN E, 1997, ARTIF INTELL, V11, P115; Bay S., 1998, P 15 INT C MACH LEAR; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Beygelzimer A., 2006, P 23 INT C MACH LEAR; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Foster I., 2003, GRID2 BLUEPRINT NEW; Freitas A.A., 1998, MINING VERY LARGE DA; Furnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605; Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GROOP W, 1996, PARALLEL COMPUT, V22, P789; Han J., 2005, DATA MINING CONCEPTS; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KARACALI B, 2002, IEEE T NEURAL NETWOR, V14, P127; Karonis NT, 2003, J PARALLEL DISTR COM, V63, P551, DOI 10.1016/S0743-7315(03)00002-9; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; STONE C, 1977, ANN STAT, V8, P1348; TOUSSAINT G, 2002, P 34 S INT COMP SCI; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Viswanath P., 2004, INFORM FUSION, V5, P239, DOI 10.1016/j.inffus.2004.02.003; Watson I., 1994, KNOWLEDGE ENG REV, V9; Wilfong G, 1992, INT J COMPUT GEOM AP, V2, P383, DOI 10.1142/S0218195992000226; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZHAO H, 2004, P 1 INT COMP INF SCI	35	16	20	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	DEC	2007	19	12					1593	1606		10.1109/TKDE.2007.190665		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	221GU	WOS:000250216200001		
J	Cai, WL; Chen, SC; Zhang, DQ				Cai, Weiling; Chen, Songcan; Zhang, Daoqiang			Robust fuzzy relational classifier incorporating the soft class labels	PATTERN RECOGNITION LETTERS			English	Article						fuzzy c-means clustering (FCM); fuzzy relations; fuzzy relational classifier; kernelized FCM (KFCM); soft class label; pattern classification	ALGORITHM	Fuzzy relational classifier (FRC) is a recently proposed two-step nonlinear classifier. At first, the unsupervised fuzzy c-means (FCM) clustering is performed to explore the underlying groups of the given dataset. Then, a fuzzy relation matrix indicating the relationship between the formed groups and the given classes is constructed for subsequent classification. It has been shown that FRC has two advantages: interpretable classification results and avoidance of overtraining. However, FRC not only lacks the robustness which is very important for a classifier, but also fails on the dataset with non-spherical distributions. Moreover, the classification mechanism of FRC is sensitive to the improper class labels of the training samples, thus leading to considerable decline in classification performance. The purpose of this paper is to develop a Robust FRC (RFRC) algorithm aiming at overcoming or mitigating all of the above disadvantages of FRC and maintaining its original advantages. In the proposed RFRC algorithm, we employ our previously proposed robust kernelized FCM (KFCM) to replace FCM to enhance its robustness against outliers and its suitability for the non-spherical data structures. In addition, we incorporate the soft class labels into the classification mechanism to improve its performance, especially for the datasets containing the improper class labels. The experimental results on 2 artificial and I I real-life benchmark datasets demonstrate that RFRC algorithm can consistently outperform FRC in classification performance. (c) 2007 Elsevier B.V. All rights reserved.	Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	caiwl@nuaa.edu.cn; s.chen@nuaa.edu.cn	Zhang, Daoqiang/D-3754-2011	Zhang, Daoqiang/0000-0002-5658-7643			Abe SG, 2005, LECT NOTES COMPUT SC, V3697, P571; Alippi E, 2001, IEEE INSTRU MEAS MAG, V4, P32; Bezdek J. C., 1981, PATTERN RECOGNITION; Bezdek JC, 1998, PATTERN RECOGN; Blake C, 1998, UCI REPOSITORY MACHI; Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264136; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, INTRO SVMS OTHER KER; Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; Huber P.J., 1981, ROBUST STAT; Jain A K, 1999, DATA CLUSTERING REV; JAJUGA K, 1991, FUZZY SET SYST, V39, P43, DOI 10.1016/0165-0114(91)90064-W; Kaufman L., 1990, FINDING GROUPS DATA; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KIM DW, 2004, PATTERN RECOGN, V38, P607; Klawonn F, 1999, LECT NOTES COMPUT SC, V1642, P291; Klir G. J., 1995, FUZZY SETS FUZZY LOG; Krzanowski W. J., 1988, PRINCIPLES MULTIVARI; Leski J, 2003, FUZZY SET SYST, V137, P215, DOI 10.1016/S0165-0114(02)00372-X; MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3; Pedrycz W., 1994, REASONING ANALOGY FU, P55; Pedrycz W., 2004, PATTERN RECOGN, V37, P1229; PIZZI NJ, 2000, INT JOINT C NEUR NET; RAMIREZ L, 2003, IEEE CANADIAN C ELEC, V3, P1465; Roth V, 2000, ADV NEUR IN, V12, P568; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Setnes M, 1999, IEEE T SYST MAN CY B, V29, P619, DOI 10.1109/3477.790444; SOHN S, 2001, INT JOINT C NEUR NET, V3, P1886, DOI 10.1109/IJCNN.2001.938451; Sung-Bae Cho, 1995, IEEE Transactions on Neural Networks, V6, DOI 10.1109/72.363487; Wu KL, 2002, PATTERN RECOGN, V35, P2267, DOI 10.1016/S0031-3203(01)00197-2; Xie X.L., 1991, IEEE T PAMI, V3, P841, DOI DOI 10.1109/34.85677; XU L, 1996, P 1996 IEEE INT C NE, V3, P1546; YAO YH, 1999, NEURAL NETWORKS, V2, P1097; Zadeh Lotfi A., 1965, FUZZY SETS INFORM CO, V8, P338, DOI DOI 10.1016/S0019-9958(65)90241-X; Zhang DQ, 2003, NEURAL PROCESS LETT, V18, P155, DOI 10.1023/B:NEPL.0000011135.19145.1b; Zhang SS, 2004, NUCLEIC ACIDS RES, V32, P1, DOI 10.1093/nar/gkg933	40	11	11	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC 1	2007	28	16					2250	2263		10.1016/j.patrec.2007.07.013		14	Computer Science, Artificial Intelligence	Computer Science	230TW	WOS:000250899800009		
J	Mjahed, M				Mjahed, Mostafa			LHC data classification using a new morphological boundary detection	INTERNATIONAL JOURNAL OF MODERN PHYSICS A			English	Article; Proceedings Paper	International Symposium on Supersymmetry at LHC: Theoretical and Experimental Perspectives	MAR 11-14, 2007	El Sherouk, EGYPT		British Univ Egypt, Ctr Theoret Phys	morphological boundary; classification; Higgs	WEAK INTERACTIONS; SYMMETRIES	A new morphological boundary detection approach is used to separate the signal from the background in the Standard Model Higgs boson search at LHC. Based on mathematical concepts, this method consists of a fast computation of probabilistic density functions of events and a smoothing using a combination of dilatation and erosion operators. In a binary search approach, the performances are improved and the results compare favourably with other multivariate analysis.	[Mjahed, Mostafa] Ecole Royale Air, Maths & Syst Dept, Marrakech 40000, Morocco; [Mjahed, Mostafa] Fac Sci Semlalia, LPTN, Marrakech 40000, Morocco	Mjahed, M (reprint author), Ecole Royale Air, Maths & Syst Dept, Marrakech 40000, Morocco.	mmjahed@hotmail.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; GLASHOW SL, 1961, NUCL PHYS, V22, P579, DOI 10.1016/0029-5582(61)90469-2; GLASHOW SL, 1970, PHYS REV D, V2, P1285, DOI 10.1103/PhysRevD.2.1285; Hartigan J. A., 1975, CLUSTERING ALGORITHM; HIGGS PW, 1964, PHYS LETT, V12, P132, DOI 10.1016/0031-9163(64)91136-9; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Kittler J., 1998, IEEE T PATTERN ANAL, V20; MIZOGUCHI R, 1976, IEEE T COMPUT, V25, P1109; Mjahed M, 2006, NUCL INSTRUM METH A, V559, P172, DOI 10.1016/j.nima.2005.11.137; MJAHED M, P LATTICE 2006 POS L; Mjahed M, 2002, NUCL PHYS B-PROC SUP, V106, P1094, DOI 10.1016/S0920-5632(01)01939-9; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Serra J., 1982, IMAGE ANAL MATH MORP; Sjostrand T, 2001, COMPUT PHYS COMMUN, V135, P238, DOI 10.1016/S0010-4655(00)00236-8; VANRYZIN, 1977, CLASSIFICATION CLUST	17	0	0	1	1	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0217-751X			INT J MOD PHYS A	Int. J. Mod. Phys. A	DEC 20	2007	22	31					6071	6079		10.1142/S0217751X07039249		9	Physics, Nuclear; Physics, Particles & Fields	Physics	261MP	WOS:000253083700039		
B	Kumar, MS; Selvarajan, S; Balu, S			IEEE	Kumar, M. Sayee; Selvarajan, S.; Balu, S.			ANODR Based Anomaly Detection for Black Hole and Route Disrupt Attacks	ICCN: 2008 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING			English	Proceedings Paper	International Conference on Computing, Communications and Networking	DEC 18-20, 2008	Karur, INDIA					An Anonymous on Demand Routing Protocol (ANODR) was designed based on the previous studies as the countermeasure for preventing passive attacks. ANODR is a purely on demand routing and identity free routing scheme that sets up an anonymous route as needed in real time. The proposed protocol ensures node privacy, route anonymity and location privacy and is robust against several known attacks. This limits the chances of eavesdropping and traffic analyzing to a time-critical on-demand window. Anonymity is one of the important characteristics in securing a wireless adhoc network routing. In this paper we study the unique anonymity threats in wireless adhoc environments. Two design principles of anonymous routing - Anonymous route discovery and Anonymous data forwarding are presented here. In the Anonymous route discovery design, a random route pseudonym for an on demand route is established. In the Anonymous data forwarding design, the source wraps its data packets for each end to end connection. This was implemented and tested using NS-2.0 simulator. The behavior of the proposed system has been studied for analysis like Packet delivery ratio, Packet delay and Overhead along with the existing system.	[Kumar, M. Sayee; Selvarajan, S.; Balu, S.] Paavai Engn Coll, Namakkal, India	Kumar, MS (reprint author), Paavai Engn Coll, Namakkal, India.	contact2sayee@gmail.com; asselvarajan@rediffmail.com; sbalu26@gmail.com					Banerjee S., 2001, P IEEE INFOCOM APR; Basagni S., 1999, INT S PAR ARCH ALG N; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng H., 2006, P 12 INT C PAR DISTR; Deng HM, 2002, IEEE COMMUN MAG, V40, P70; FALL K, 2000, NS MANUAL FORMELY NS; Huang Y., 2003, P 23 INT C DISTR COM; Huang Yi-an, 2003, P 1 ACM WORKSH SEC A, P135, DOI 10.1145/986858.986877; Krishna P., 1997, ACM SIGCOMM COMPUTER; LI JH, 2005, P INT C MOB AD HOC S; Marti S., 2000, P 6 ANN INT C MOB CO, P255, DOI DOI 10.1145/345910.345955; Sterne D., 2005, P 3 IEEE INT WORKSH, P57; TRAN QA, 2003, P 2003 IEEE INT C SY, P2388; Vapnik NV, 1998, STAT LEARNING THEORY; Younis O., 2004, IEEE T MOBILE COMPUT, V3	15	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3594-4				2008							199	203				5	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BKH76	WOS:000268136000033		
B	Oh, JS; Choi, KS; Kwon, JR; Lee, SH		Lee, G; Ahn, TN; Howard, D; Slezak, D		Oh, Jeong Seok; Choi, Kyung Suhk; Kwon, Jeong Rock; Lee, Sang Ho			Finding the near Workload Type between TPC-C and TPC-W Environments	ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS			English	Proceedings Paper	International Conference on Convergence and Hybrid Information Technology	AUG 28-29, 2008	Daejeon, SOUTH KOREA	SERC, Korean Informat Assoc Soc				Database system can be performed more than a database application and shown peculiar workload characteristics as a database application. However, as a database system can be performed a lot of database applications, detecting workload characteristics might be more difficult. This paper proposes the method of finding near workload characteristics by mixed workloads. The workload find method is evaluated by the modified k-NN algorithm that is an extension of the existing the fuzzy k-NN algorithm. The modified k-NN algorithm measures how close workloads in TPC-C or TPC-W are to the mixed workloads between TPC-C and TPC-W. Furthermore, the result of our method is better than others for finding near workloads because its results are lower than others in the oscillation depending on the k parameter and the error rate. This study is able to contribute to finding similar information for providing autonomic database analysis and intelligent service in ubiquitous environments.	[Oh, Jeong Seok] Korea Gas Safety Corp, Inst Gas Safety R&D, Shihung, Gyenggi Do, South Korea	Oh, JS (reprint author), Korea Gas Safety Corp, Inst Gas Safety R&D, Shihung, Gyenggi Do, South Korea.						BAYLIS R, 2002, DATABASE ADM GUIDE R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CYRAN M, 2001, ORACLE 9I DATABASE P; Elnaffar S., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; ELNAFFAR S, 2002, P CASCON C TOR CAN; Han J. H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.784711; Han Jiawei, 2001, DATA MINING CONCEPTS; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Martin P., 2002, International Journal on Digital Libraries, V3, DOI 10.1007/s007990100046; OH JS, 2004, J KISS D, V11, P747; *TPC, 2001, TPC BENCHM C SPEC RE; *TPC, 2002, TPC BENCHM W WEB COM	12	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3328-5				2008							334	337				4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics; Remote Sensing	Computer Science; Engineering; Robotics; Remote Sensing	BIK58	WOS:000260412900057		
B	Puteh, M; Omar, K; Hamdan, AR; Abu Bakar, A		Zaman, HB; Sembok, TMT; VanRijsbergen, K; Zadeh, L; Buza, P; Shih, T; Taib, MN		Puteh, Mazidah; Omar, Khairuddin; Hamdan, Abdul Razak; Abu Bakar, Azuraliza			Classifying Heterogeneous Data With Artificial Immune System	INTERNATIONAL SYMPOSIUM OF INFORMATION TECHNOLOGY 2008, VOLS 1-4, PROCEEDINGS: COGNITIVE INFORMATICS: BRIDGING NATURAL AND ARTIFICIAL KNOWLEDGE			English	Proceedings Paper	International Symposium on Information Technology	AUG 26-29, 2008	Kuala Lumpur, MALAYSIA	IEEE	Univ Kebangsaan, Fac Informat Sci & Technol			Artificial Immune System (AIS) is an emerging technique for the classification task and proved to be a reliable technique. In the previous researches, mainly classifiers including AIS classifiers require the data to be in numerical or categorical data types prior to processing. The transformation of data into any other specific types from their original form can degrade the originality of the data and consume more space and pre processing time. This paper introduces AIS model using clonal selection technique for classifying heterogeneous data in its original types. The model is able to process the data with the types as represented in the database and it solves some problems highlighted in the AIS reviews. To ensure the consistent conditions and fair comparison, the selected algorithms uses the same set of data as used in the proposed model. Experimental results show that this model produces a better accuracy rate than other immune algorithm and comparable to the standard classifiers on most of the benchmark data from UCI Machine Learning Repository.	[Puteh, Mazidah] Univ Teknol MARA, FTMSK, Terenggamu, Malaysia	Puteh, M (reprint author), Univ Teknol MARA, FTMSK, Terenggamu, Malaysia.						BROWNLEE J, 2005, 102 U TECHN FAC ICT; BROWNLEE J, 2005, 102 SWINB U TECHN FA; CARTER JH, 2000, J AM MED INFORM ASS, V7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY, 1991, NEAREST NEIGHBOR NN; Dasgupta D., 2006, IEEE COMPUTATIONAL I; De Castro L. N., 2002, ARTIFICIAL IMMUNE SY; de Castro L.N., 2000, CLONAL SELECTION ALG, P36; FREITAS A, 2007, IEEE T EVOLUTIONARY, V11, P4; HAMAKER J, 2004, P CEC2004; Hart E., 2008, J APPL SOFT COMPUTIN, V8, P191; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hunt JE, 1996, J NETW COMPUT APPL, V19, P189, DOI 10.1006/jnca.1996.0014; Keogh E., 2006, UCR TIME SERIES DATA; MERZ C, 1998, UCI MACHINE LEARNING; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Steed LG, 2003, SPSS ANAL ANGUISH VE; Timmis J, 2006, LECT NOTES COMPUT SC, V3931, P355; Timmis J.I., 2001, THESIS U WALES ABERY; WALKINS A, 2004, P ICARIS2004, P427; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Watkins A., 2001, THESIS MISSISSIPPI S; Watkins A., 2002, P 1 INT C ART IMM SY, P173; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I, 2005, DATA MINING	25	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2327-9				2008							1877	1881				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Telecommunications	Computer Science; Telecommunications	BIK22	WOS:000260353301065		
S	Mignani, AG; Cucci, C; Ciaccheri, L; Dall'Asta, C; Galaverna, G; Dossena, A; Marchelli, R		Sampson, D; Collins, S; Oh, K; Yamauchi, R		Mignani, A. G.; Cucci, C.; Ciaccheri, L.; Dall'Asta, C.; Galaverna, G.; Dossena, A.; Marchelli, R.			Optical fiber fluorescence spectroscopy for detecting AFM1 in milk	19TH INTERNATIONAL CONFERENCE ON OPTICAL FIBRE SENSORS, PTS 1 AND 2	Proceedings of SPIE		English	Proceedings Paper	19th International Conference on Optical Fibre Sensors	APR 15-18, 2008	Perth, AUSTRALIA	Univ Western Australia, Opt & Biomed Engn Lab, SPIE, Opt Soc Japan, Opt Soc India, Japan Soc Appl Phys, Inst Elect, Informat & Commun Engineers, Japan Elect Soc, Opt Soc Korea, Opt Soc Amer, Australian Opt Soc, Soc Instrument & Control Engineers, Perth Convent Bur		aflatoxin; AFM1; fluorescence; milk; optical fibers	LIQUID-CHROMATOGRAPHY; PASTEURIZED MILK; AFLATOXIN M-1; M1	Fluorescence spectroscopy carried out by means of optical fibers was used for the rapid screening of M1 aflatoxin in milk, enabling the detection of concentrations up to the legal limit, which is 50 ppt. A compact fluorometric device equipped with a LED source, a miniaturized spectrometer, and optical fibers for illumination/detection of the measuring micro-cell was tested for measuring threshold values of AFM1 in pre-treated milk samples. Multivariate processing of the spectral data made it possible to obtain a preliminary screening at the earlier stages of the industrial process, as well as to discard contaminated milk stocks before their inclusion in the production chain.	[Mignani, A. G.; Cucci, C.; Ciaccheri, L.] CNR IFAC, I-50019 Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR IFAC, Via Madonna del Piano 10, I-50019 Sesto Fiorentino, FI, Italy.	a.g.mignani@ifac.cnr.it	Dall'Asta, Chiara/C-3173-2008; 	Dall'Asta, Chiara/0000-0003-0716-8394; Galaverna, Gianni/0000-0001-9042-2378			Bertran E, 2001, ANAL CHIM ACTA, V431, P303, DOI 10.1016/S0003-2670(00)01328-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucci C, 2007, SENSOR ACTUAT B-CHEM, V126, P467, DOI 10.1016/j.snb.2007.03.036; Dragacci S, 2001, J AOAC INT, V84, P437; *FAO, 2003, WORLDW REG MYC FOOD, V81; Gilbert J, 2003, J TOXICOL-TOXIN REV, V22, P381, DOI 10.1081/TXR-120024099; Hassouan M, 2007, ANAL LETT, V40, P779, DOI 10.1080/00032710601017912; IGARASHI Y, 1995, INT DAIRY J, V5, P305, DOI 10.1016/0958-6946(94)00004-9; Magan N, 2004, MYCOTOXINS FOOD DETE; Maragos CM, 2004, J TOXICOL-TOXIN REV, V23, P317, DOI 10.1081/TXR-200027859; Markaki P, 1997, FOOD ADDIT CONTAM, V14, P451; Martens H., 2001, MULTIVARIATE ANAL QU; Weidenborner M., 2001, ENCY FOOD MYCOTOXINS; Zinedine A, 2007, INT J FOOD MICROBIOL, V114, P25, DOI 10.1016/j.ijfoodmicro.2006.11.001	14	0	0	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-7204-5	PROC SPIE			2008	7004		1-2						70045S	10.1117/12.786666		4	Engineering, Biomedical; Optics; Physics, Applied	Engineering; Optics; Physics	BIC54	WOS:000258398100194		
S	Wang, SY; Baird, HS			IEEE	Wang, Sui-Yu; Baird, Henry S.			Feature Selection Focused within Error Clusters	19TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, VOLS 1-6	INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION		English	Proceedings Paper	19th International Conference on Pattern Recognition (ICPR 2008)	DEC 08-11, 2008	Tampa, FL	IEEE			CLASSIFICATION	We propose a feature selection method that constructs each new feature by analysis of tight error clusters. This is a greedy, time efficient forward selection algorithm that iteratively constructs one feature at a time, until a desired error rate is reached. The algorithm finds error clusters in the current feature space, then projects one tight cluster into the null space of the feature mapping, where a new feature that helps to classify these errors can be discovered. Tight error clusters indicate that the current features are unable to discriminate these samples. The approach is strongly data driven and restricted to linear features, but other wise general. Large scale experiments show that it can achieve a monotonically decreasing error rate within the feature discovery set, and a generally decreasing error rate on a distinct test set.	[Wang, Sui-Yu; Baird, Henry S.] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18017 USA	Wang, SY (reprint author), Lehigh Univ, Dept Comp Sci & Engn, 19 Mem Dr W, Bethlehem, PA 18017 USA.	syw2@lehigh.edu; baird@cse.lehigh.edu					Baird H. S., 2006, P SPIE IS T DOC REC; Baird HS, 2006, LECT NOTES COMPUT SC, V3872, P280; Bellman R., 1961, ADAPTIVE CONTROL PRO; BENGIO Y, 2003, FEATURE EXTRACTION F, P519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datta B. N, 1994, NUMERICAL LINEAR ALG; Devroye L., 1996, PROBABILISTIC THEORY; DONGARRA J, 2006, HDB LINEAR ALGEBRA; Duda R O, 2001, PATTERN CLASSIFICATI; ELASHOFF JD, 1967, BIOMETRIKA, V54, P668, DOI 10.2307/2335061; Guyon I., 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HOHN FE, 2003, ELEMENTARY MATRIX AL; Mason L, 2000, ADV NEUR IN, V12, P512; MOMMA M, 2003, FEATURE EXTRACTION F, P551; Shannon C., 1948, BELL SYS TECH J, V27; Watanabe S., 1985, PATTERN RECOGNITION; Wold H., 1981, FIX POINT APPROACH I; Wolpert D. H., 1995, MATH GEN; Wolpert D. H., 1995, SFITR9502010; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	21	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1051-4651		978-1-4244-2174-9	INT C PATT RECOG			2008							2585	2588				4	Computer Science, Artificial Intelligence	Computer Science	BJC36	WOS:000264729001151		
B	Li, FY; Wechsler, H; Tistarelli, M			IEEE	Li, Fayin; Wechsler, Harry; Tistarelli, Massimo			Robust Fusion Using Boosting and Transduction for Component-Based Face Recognition	2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4			English	Proceedings Paper	10th International Conference on Control, Automation, Robotics and Vision	DEC 17-20, 2008	Hanoi, VIETNAM	IEEE		biometrics; boosting; component-based recognition; data fusion; face recognition; disguise; forensics; k-nearest neighbor; likelihood ratio; margin; Neyman-Pearson; occlusion; open set recognition; surveillance; transduction; strangeness; typicality	FORENSIC SPEAKER RECOGNITION; FEATURES	Face recognition performance depends upon the input variability as encountered during biometric data capture including occlusion and disguise. The challenge met in this paper is to expand the scope and utility of biometrics by discarding unwarranted assumptions regarding the completeness and quality of the data captured. Towards that end we propose a model-free and non-parametric component-based face recognition strategy with robust decisions for data fusion that are driven by transduction and boosting. The conceptual framework draws support throughout from discriminative methods using likelihood ratios. It links at the conceptual level forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Feature selection of local patch instances and their corresponding high-order combinations, exemplar-based clustering (of patches) as components including the sharing (of exemplars) among components, and finally decision-making regarding authentication using boosting driven by components that play the role of weak-learners, are implemented in a similar fashion using transduction driven by a strangeness measure akin to typicality. The feasibility, reliability, and utility of the proposed open set face recognition architecture vis-a-vis adverse image capture conditions are illustrated using FRGC data. The potential for future developments concludes the paper.	[Li, Fayin; Wechsler, Harry] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Li, FY (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fayin.li@gmail.com; wechsler@gmu.edu; tista@uniss.it					Balas BJ., 2006, ACM T APPL PERCEPT, V3, P354, DOI 10.1145/1190036.1190038; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Delorme A, 2001, NEURAL NETWORKS, V14, P795, DOI 10.1016/S0893-6080(01)00049-1; DESSIMOZ D, 2008, HDB BIOMETRICS; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Freund Y., 1996, 13 INT C MACH LEARN, P148; Gonzalez-Rodriguez J, 2007, IEEE T AUDIO SPEECH, V15, P2104, DOI 10.1109/TASL.2007.902747; GUTTA S, 2004, 1 INT C BIOM AUTH HO; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; Koller D., 1996, 13 INT C MACH LEARN; LAI H, 2008, COMPUTER VI IN PRESS; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Melluish T., 2001, TYPICALNESS FRAMEWOR; Phillips P., 2005, OVERVIEW FACE RECOGN; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Smith Paul F, 2005, Expert Opin Drug Saf, V4, P443, DOI 10.1517/14740338.4.3.443; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Tsunoda K, 2001, NAT NEUROSCI, V4, P832, DOI 10.1038/90547; Vapnik V., 1998, STAT LEARNING THEORY; Viola P., 2001, RAPID OBJECT DETECTI; VOVK V, 1999, 16 INT C MACH LEARN	25	3	3	1	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2286-9				2008							434	439				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BJK70	WOS:000266716600077		
B	Rouainia, M; Doghmane, N			IEEE	Rouainia, Mounira; Doghmane, Noureddine			Segmentation of Magnetic Resonance Images : A State of The Art	2008 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES: FROM THEORY TO APPLICATIONS, VOLS 1-5			English	Proceedings Paper	3rd International Conference on Information and Communication Technologies	APR 07-11, 2008	Damascus, SYRIA			Magnetic resonance image; segmentation; classification; regions of interest	BRAIN MR-IMAGES; AUTOMATIC SEGMENTATION; MULTIPLE-SCLEROSIS; CEREBRAL-CORTEX; TUMOR VOLUME; SURFACE; HEAD; SETS	Images segmentation constitutes a crucial task in magnetic resonance images analysis by automating and facilitating isolation of anatomical structures and other regions of interest. The purpose of this paper is to present a state of the art of current approaches dealing with anatomical magnetic resonance images segmentation. Emphasis will be placed on revealing the advantages and disadvantages of these methods for medical imaging applications.			rouainia_m@yahoo.fr					AMBROISE C, 1997, INTRO RECONNAISSANCE; Baillard C, 2001, MED IMAGE ANAL, V5, P185, DOI 10.1016/S1361-8415(01)00039-1; BAILLARD C, 2000, 1369 IRISA; Barra V, 2001, IEEE T MED IMAGING, V20, P549, DOI 10.1109/42.932740; Bedell BJ, 1998, MAGNET RESON MED, V39, P935, DOI 10.1002/mrm.1910390611; Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4; Bezdek J. C., 1981, PATTERN RECOGNITION; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; BOMANS M, 1990, IEEE T MED IMAGING, V9, P177, DOI 10.1109/42.56342; Bouchon-Meunier B., 1999, LOGIQUE FLOUE; BRUMMER ME, 1992, IEEE T MED IMAGING, V12, P90; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; COCQUEREZ JP, 1995, ANAL IMAGE FILTRAGE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI DY, 1993, IEEE T MED IMAGING, V12, P693; DELLEPIANE S, 1991, 13 IEEE ENG MED BIOL, V13, P253; Duda R. O., 1973, PATTERN CLASSIFICATI; GERAUD T, 1998, THESIS ENST PARIS; GERIG G, 1991, LECT NOTES COMPUT SC, V511, P175; GERIG G, 1992, IMAGE VISION COMPUT, V10, P349, DOI 10.1016/0262-8856(92)90021-T; Ghanei A, 1998, COMPUT MED IMAG GRAP, V22, P203, DOI 10.1016/S0895-6111(98)00026-3; Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883; Ho S., 2002, Proceedings 16th International Conference on Pattern Recognition, DOI 10.1109/ICPR.2002.1044788; HOJJATOLESLAMI A, 2001, IEEE T MED IMAGING, V20, P660; KAMBERT M, 1995, IEEE T MED IMAGING, P442; Kass M., 1988, INT J COMPUT VISION, P321; KIKINIS R, 1992, JMRI-J MAGN RESON IM, V2, P619, DOI 10.1002/jmri.1880020603; LI C, 1993, SPIE, V1905, P554; LUO S, 2003, WORKSH DIG IM COMP M, P9; MacDonald D, 2000, NEUROIMAGE, V12, P340, DOI 10.1006/nimg.1999.0534; MAHR D, 1980, P ROYAL SOC LOND, P197; Mangin J. F., 1998, P 1 MICCAI, P1230, DOI [10.1007/BFb0056313, DOI 10.1007/BFB0056313]; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; PANNIZZO F, 1992, MAGNET RESON MED, V24, P90, DOI 10.1002/mrm.1910240110; Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315; Prewitt J. M. S., 1970, PICTURE PROCESSING P, P75; RANGAYYAN RM, 2005, BIOMEDICAL IMAGE ANA, P363; ROBERTS LG, 1965, MACHINE PERCEPTION 3, P159; ROUAINIA M, 2005, WSEAS T COMPUTERS, V4, P272; Rouainia M, 2006, P 17 INT C COMP INF, P301; Ruan S, 2002, COMPUT VIS IMAGE UND, V85, P54, DOI 10.1006/cviu.2002.0957; Salzenstein F, 1997, GRAPH MODEL IM PROC, V59, P205, DOI 10.1006/gmip.1997.0431; Sandor S, 1997, IEEE T MED IMAGING, V16, P41, DOI 10.1109/42.552054; SANDOR S, 1995, P INFORMATION PROCES, P127; SCHMITT M, 1993, MORPHOLOGIE MATH; Schnack HG, 2001, NEUROIMAGE, V14, P95, DOI 10.1006/nimg.2001.0800; Serra J., 1988, IMAGE ANAL MATH MORP; SHAN Y, 2002, NEUROIMAGE, P1587; SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3; STATTUCK DW, 2001, NEUROIMAGE, P856; Tanabe JL, 1997, AM J NEURORADIOL, V18, P115; Thiran JP, 1997, SIGNAL PROCESS, V60, P1, DOI 10.1016/S0165-1684(97)00060-1; Tsai C, 1995, PATTERN RECOGN, V28, P1825; VAIDYANATHAN M, 1995, MAGN RESON IMAGING, V13, P719, DOI 10.1016/0730-725X(95)00012-6; VELTHUIZEN RP, 1995, JMRI-J MAGN RESON IM, V5, P594, DOI 10.1002/jmri.1880050520; Warfield S, 1995, J Image Guid Surg, V1, P326, DOI 10.1002/(SICI)1522-712X(1995)1:6<326::AID-IGS4>3.0.CO;2-C; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; Xu CY, 1999, IEEE T MED IMAGING, V18, P467, DOI 10.1109/42.781013; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zijdenbos Alex P., 1994, Critical Reviews in Biomedical Engineering, V22, P401	61	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1751-3				2008							1116	1122				7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BIP38	WOS:000261578000207		
B	Liu, Q; Lin, TS		Li, S; Li, T; Ruan, D		Liu Qing; Lin Tu-sheng			Wavelet-based Coefficients' Relationship Co-occurrence Histogram Algorithm of Texture Teature Extraction	2008 3rd International Conference on Intelligent System and Knowledge Engineering, Vols 1 and 2			English	Proceedings Paper	3rd International Conference on Intelligent System and Knowledge Engineering	NOV 17-19, 2008	Xiamen, PEOPLES R CHINA	Xiamen Univ, Fuzhou Univ, Fujian Agr & Fore Univ, Jimei Univ, Sanming Univ, Hunan Inst Humanities, Sci & Tech, Longyan Univ, IEEE Beijing Sect, Tsinghua Univ, SW Jiaotong Univ, Donghua Univ Ghent Univ, Belgian Nucl Res Ctr, Univ Technol			CLASSIFICATION; SEGMENTATION	We propose a novel texture feature extraction technique based on coefficients' co-occurrence histogram of discrete wavelet frame transformed image, which capture the information about relationship between each high frequency subband and the low frequency subband of the decomposed image at the corresponding level. It is not independently utilizing the information of each subband coefficient. The classification performance is analyzed using the k-NN classifier And the experimental results demonstrate the effectiveness of our proposed texture feature in achieving the improved classification performance. Comparisons with the Gabor filter and a recently proposed approach are also provided.	[Liu Qing; Lin Tu-sheng] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China	Liu, Q (reprint author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.	liu.qing3@mail.scut.edu.cn; eetshlin@scut.edu.cn					Brodatz P., 1966, TEXTURES PHOTOGRAPHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; Daugman J., 1990, COMPUTATIONAL NEUROS, P403; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; HARALICK RM, 1978, IEEE T SYSTERM MAN C, V8, P460; HIREMATH PS, 2008, PATTERN RECOGN; Laine A, 1996, IEEE T IMAGE PROCESS, V5, P771, DOI 10.1109/83.499915; LI XH, 2003, ACTA ELECT SINICA, V31, P2123; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; WU J, 2001, J REMOTE SENSING, V5, P100; Zuyuan Wang, 2001, J IMAGE GRAPHIC, V6A, P1065	14	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2196-1				2008							1050	1053		10.1109/ISKE.2008.4731084		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BIS44	WOS:000262437400197		
B	Wang, B; Zeng, Y; Yang, Y			IEEE	Wang, Bing; Zeng, Yong; Yang, Yupu			Generalized Nearest Neighbor Rule for Pattern Classification	2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23			English	Proceedings Paper	7th World Congress on Intelligent Control and Automation	JUN 25-27, 2008	Chongqing, PEOPLES R CHINA	Chongqing Univ, Chongqing Inst Technol, Chongqing Univ Sci & Technol, Xihua Univ, SW Univ Sci & Technol, IEEE Robot & Automat Soc, IEEE Control Syst Soc, Beijing Chapter, Chinese Assoc Automat, Chinese Assoc Artificial Intell, Natl Nat Sci Fdn, Chongqing Municipal Sci & Technol Comm, Chongqing Municipal Assoc Sci & Technol, KC Wong Educ Fdn		Nearest neighbor rule (NNR); generalized nearest neighbor rule (GNNR); weighted k-nearest neighbor rule; pseudo nearest neighbor (PNN)	ALGORITHM	In this paper, we propose a generalized nearest neighbor classification rule (GNNR). It is similar to but different from the previous nearest neighbor rule (NNR), this new rule utilizes more information of the neighbors of the unclassified sample point except its nearest neighbor. Theoretical analysis and experimental results confirm the validity of this new rule.	[Wang, Bing] Panzhihua Univ, Sch Informat & Elect Engn, Panzhihua, Sichuan, Peoples R China	Wang, B (reprint author), Panzhihua Univ, Sch Informat & Elect Engn, Xue Yuan Rd, Panzhihua, Sichuan, Peoples R China.						[Anonymous], UCI REPOSITORY MACHI; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARTHY BV, 1991, NEAREST NEIGHBOR NOR; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DEVROYE L, 1996, PROBABILISTIC THEORY, P63; Devroye L., 1996, PROBABILISTIC THEORY, P71; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 US AIR FORC SCH AV; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; THEODORIDIS S, 2006, PATTERN RECOGN, P48; Zavrel J., 1997, P 7 BELG DUTCH C MAC, P139	15	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2113-8				2008							8465	8470		10.1109/WCICA.2008.4594258		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BIJ02	WOS:000259965706220		
S	Yang, J; Lou, Z; Jin, Z; Yang, JY			IEEE	Yang, Jian; Lou, Zhen; Jin, Zhong; Yang, Jing-yu			Minimal local reconstruction error measure based discriminant feature extraction and classification	2008 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, VOLS 1-12	PROCEEDINGS - IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION		English	Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 23-28, 2008	Anchorage, AK	IEEE Comp Soc			FACE-RECOGNITION ALGORITHMS; PATTERN-CLASSIFICATION; NEAREST; CLASSIFIERS; PROJECTION	This paper introduces the minimal local reconstruction error (MLRE) as a similarity measure and presents a MLRE-based classifier. From the geometric meaning of the minimal local reconstruction error, we derive that the MLRE-based classifier is a generalization of the conventional nearest neighbor classifier and the nearest neighbor line and plane classifiers. We further apply the MLRE measure to characterize the within-class and between-class local scatters and then develop a MLRE measure based discriminant feature extraction method. The proposed MLRE-based feature extraction method is in line with the MLRE-based classification method in spirit, thus the two methods can be seamlessly combined in applications. The experimental results on the CENPARMI handwritten numeral database and the FERET face image database show effectiveness of the proposed MLRE-based feature extraction and classification method.	[Yang, Jian; Lou, Zhen; Jin, Zhong; Yang, Jing-yu] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China	Yang, J (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.						Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; He X., 2005, IEEE INT C COMP VIS; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lou Z., 2006, P 18 INT C PATT REC, V3, P87; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Saul L K, 2003, J MACHINE LEARNING R, P119, DOI DOI 10.1162/153244304322972667; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	14	1	1	0	12	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1063-6919		978-1-4244-2242-5	PROC CVPR IEEE			2008							173	178				6	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BII46	WOS:000259736800023		
S	Xiong, Y; Yang, Q; Qiu, BR; Zhu, YY		Chen, Y; He, J; Reddy, CK; Yang, J; Yoo, I; Zhang, X; Gao, J; Huang, Y; Song, M; Yang, J; Wu, Z		Xiong, Yun; Yang, Qing; Qiu, Boren; Zhu, Yangyong			An Integrated Approach of Sequence and Text Mining Technology for the Identification of Transcription Factor Binding Sites	2008 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE WORKSHOPS, PROCEEDINGS	IEEE International Conference on Bioinformatics and Biomedicine Workshop-BIBMW		English	Proceedings Paper	IEEE International Conference on Bioinformatics and Biomedicine	NOV 03-05, 2008	Philadelphia, PA	IEEE		transcription factor; binding site; text mining; sequence mining; data mining; bioinformatics	REGULATORY ELEMENTS; TOOL	The study of the complex mechanisms that regulated gene expression on the level of transcription is an important and challenging issue in post-genomic era. A crucial step is to identify transcription factor binding sites(TFBSs). However, the number of the known TFBSs is limited, and the accuracy of the state-of-the-art identification methods is still far from satisfactory. In this paper a novel integrated method for mining transcription factor binding sites is presented, which combines the sequence data mining method with the text mining method. Therefore, the method can not only obtain the putative TFBSs from the sequence data sets, but also acquire the experimentally verified TFBSs from the literatures. To evaluate the performance of our method, several experiments have been tested on real data sets. The results show that our integrated method outperforms each of the algorithms alone, furthermore, exhibits superior accuracy than existing algorithms.	[Xiong, Yun] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China	Xiong, Y (reprint author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.	yunx@fudan.edu.cn; yyzhu@fudan.edu.cn					ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Bailey T. L., 1995, P 3 INT C INT SYST M, P21; CHEN Y, 2002, IEEE INT C DAT MIN I; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hughes JD, 2000, J MOL BIOL, V296, P1205, DOI 10.1006/jmbi.2000.3519; JANG B, 2007, BIOINFORMATICS, V21, P2823; Joachimss T., 1999, INT C MACH LEARN ICM, P200; Kel AE, 2003, NUCLEIC ACIDS RES, V31, P3576, DOI 10.1093/nar/gkg585; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; MARCO DB, 2000, NEW DIRECTIONS QUEST, P138; MATHIAK B, 2004, 5 STEPS TEXT MINING; Sandelin A, 2004, NUCLEIC ACIDS RES, V32, P91; SELVI P, 2007, C COMP INT MULT APPL, V1, P9; STEIN A, 2008, GENOME BIOL, V9, pR31; Thijs G, 2001, BIOINFORMATICS, V17, P1113, DOI 10.1093/bioinformatics/17.12.1113; THOMPA M, 2005, NAT BIOTECHNOL, V23, P137; Vapnik V., 1998, STAT LEARNING THEORY; Wang Y, 2005, PATTERN RECOGN LETT, V26, P2187, DOI 10.1016/j.patrec.2005.03.034; Wingender E, 1996, NUCLEIC ACIDS RES, V24, P238, DOI 10.1093/nar/24.1.238; Workman C T, 2000, Pac Symp Biocomput, P467; ZHENG GY, 2008, BMC BIOINFORMATICS, P282	21	0	0	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2163-6966		978-1-4244-2890-8	IEEE INT C BIO BIO W			2008							178	184				7	Engineering, Biomedical	Engineering	BIQ62	WOS:000262067000033		
S	Yang, CS; Chuang, LY; Li, JC; Yang, CH			IEEE	Yang, Cheng-San; Chuang, Li-Yeh; Li, Jung-Chike; Yang, Cheng-Hong			Information Gain with Chaotic Genetic Algorithm for Gene Selection and Classification Problem	2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC), VOLS 1-6	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on System, Man, and Cybernetic	OCT 12-15, 2008	Singapore, SINGAPORE	IEEE		microarray data; feature selection; information gain; chaotic genetic algorithm; K-nearest neighbor	MICROARRAY DATA	For microarray data classification problem, selecting relevant genes from microarray data pose a formidable challenge to researchers due to the high-dimensionality of features, multi-class categories being involved and the usually small sample size. In order to correctly analyze microarray data, the goal of feature (gene) selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. In this paper, information gain and chaotic genetic algorithm are proposed to select the relevant genes, and a K-nearest neighbor with the leave-one-out cross-validation method serves as a classifier. Chaotic genetic algorithm is modified by using the chaotic mutation operator to increase the population diversity. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates.	[Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CS (reprint author), Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan.	p8896117@mail.ncku.edu.tw; chuang@isu.edu.tw; 1095320149@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					ALATAS B, CHAOS SOLIT IN PRESS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L. D., 1991, HDB GENETIC ALGORITH; Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Herrera F, 2000, APPL INTELL, V13, P187, DOI 10.1023/A:1026531008287; Holland J. H., 1992, ADAPTATION NATURAL A; KODAZ H, EXPERT SYST IN PRESS; Liu XX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-76; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Quinlan J., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; VERRON S, J PROCESS C IN PRESS; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	15	0	0	0	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-2383-5	IEEE SYS MAN CYBERN			2008							1127	1132				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BKT54	WOS:000269197300193		
S	Hartono, P; Saito, A			IEEE	Hartono, Pitoyo; Saito, Aya			Class-Proximity SOM and Its Applications in Classification	2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC), VOLS 1-6	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on System, Man, and Cybernetic	OCT 12-15, 2008	Singapore, SINGAPORE	IEEE			SELF-ORGANIZING MAP; VISUALIZATION	In this study, we propose a model of Self-Organizing Map (SOM) capable of mapping high dimensional data into a low dimension space by preserving not only the feature-proximity of the original data but also their class-proximity. A conventional SOM is known to map original high dimensional data with similar features into points located close to each other in the low dimensional map in a so called competitive layer. In addition to this feature, the proposed SOM is also able to map high dimensional data belonging to a same class in each other's proximities. These characteristics retains the ability of. the map to be used as a visualization tool of high dimensional data while also support the execution of high quality pattern classifications in the low dimensional map. In the experiments the classification performance of the proposed SOM is compared to that of MLP with regards to wide varieties of problems.	[Hartono, Pitoyo; Saito, Aya] Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido, Japan	Hartono, P (reprint author), Future Univ Hakodate, Dept Media Architecture, Hakodate, Hokkaido, Japan.	hartono@fun.ac.jp					Barreto GA, 2004, IEEE T NEURAL NETWOR, V15, P1244, DOI 10.1109/TNN.2004.832825; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; KOGA T, 2006, NEURAL NETWORKS, V19; Kohonen T., 1988, P IEEE INT C NEUR NE, P61; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 1995, SELF ORGANIZING MAPS; Wu ST, 2005, IEEE T NEURAL NETWOR, V16, P1362, DOI 10.1109/TNN.2005.853574; Yamakawa T, 1999, IEICE T FUND ELECTR, VE82A, P1674; Yin HJ, 2002, IEEE T NEURAL NETWOR, V13, P237, DOI 10.1109/72.977314; UCI REPOSITORY	10	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-2383-5	IEEE SYS MAN CYBERN			2008							2149	2154				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BKT54	WOS:000269197301049		
S	Gravina, R; Guerrieri, A; Fortino, G; Bellifemine, F; Giannantonio, R; Sgroi, M			IEEE	Gravina, Raffaele; Guerrieri, Antonio; Fortino, Giancarlo; Bellifemine, Fabio; Giannantonio, Roberta; Sgroi, Marco			Development of Body Sensor Network Applications using SPINE	2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC), VOLS 1-6	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, CONFERENCE PROCEEDINGS		English	Proceedings Paper	IEEE International Conference on System, Man, and Cybernetic	OCT 12-15, 2008	Singapore, SINGAPORE	IEEE		Body Sensor Networks; Domain-Specific Software Frameworks; Activity Monitoring Systems		SPINE (Signal Processing in Node Environment) is a Framework for the development of Body Sensor Network (BSN) applications. It provides developers of signal processing algorithms with APIs and libraries of protocols, utilities and data processing functions. Hence, it offers application developers new abstractions that improve interoperability and allow to reduce development time. This paper presents the architecture and the capabilities of the SPINE framework, and shows its use in the development of a real-time activity monitoring system prototype.	[Gravina, Raffaele; Guerrieri, Antonio; Fortino, Giancarlo] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Gravina, R (reprint author), Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy.	g.fortino@unical.it; fabioluigi.bellifemine@telecomitalia.it; roberta.giannantonio@telecomitalia.it; marco.sgroi@wsnlabberkeley.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2002, PATTERN CLASSIFICATI; GRAVINA R, 2008, P 5 EUR C WIR SENS N; Iyengar S., 2008, P 3 INT C BOD AR NET; LO B, 2005, P INT WORKSH WEAR IM; LOMBRISER C, 2007, 15 FACHT KOMM VERT S, P127; LOMBRISER C, 2007, P 2 INT C BOD AR NET; Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; RAVI N, P 27 C INN APPL ART, P1541; SHNAYDER V, 2005, TR0805 HARV U DIV EN; WADA H, 2007, P 11 IASTED INT C SO; YU Y, 2004, IEEE NETWORK MAGAZIN; LGPL LICENSE	14	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-2383-5	IEEE SYS MAN CYBERN			2008							2809	2814				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BKT54	WOS:000269197301161		
S	Korsrilabutr, T; Kijsirikul, B			IEEE	Korsrilabutr, Teesid; Kijsirikul, Boonserm			Pseudometrics for Time Series Classification by Nearest Neighbor	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			WORD RECOGNITION	Despite the success of its applications in many areas, the Dynamic Time Warping (DTW) distance does not satisfy the triangle inequality (subadditivity). Once we have a subadditive distance measure for time series, the measure will have at least one significant advantage over DTW; one can directly plug such distance measure into systems which exploit the subadditivity to perform faster similarity search techniques. We propose two frameworks for designing subadditive distance measures and a few examples of distance measures resulting from the frameworks. One framework is more general than the other and can be used to tailor distances from the other framework to gain better classification performance. Experimental results of nearest neighbor classification showed that the designed distance measures am practical for time series classification.	[Korsrilabutr, Teesid; Kijsirikul, Boonserm] Chulalongkorn Univ, Dept Comp Engn, Bangkok 10330, Thailand	Korsrilabutr, T (reprint author), Chulalongkorn Univ, Dept Comp Engn, Phayathai Rd, Bangkok 10330, Thailand.	teesid@gmail.com; boonserm.k@chula.ac.th					AACH J, 2001, BIOINF BIOINFORMATIC, V17; Barros J, 1996, P SOC PHOTO-OPT INS, V2670, P392, DOI 10.1117/12.234778; Chen L., 2004, MARRIAGE LP NORMS ED; Ciaccia P., 1997, VLDB, P426; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dohnal V, 2003, MULTIMED TOOLS APPL, V21, P9, DOI 10.1023/A:1025026030880; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9; Keogh E., 2006, UCR TIME SERIES CLAS; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; RABINER LR, 1978, J ACOUST SOC AM, V63, pS79, DOI 10.1121/1.2016831; Roussopoulos N., 1995, SIGMOD, P71; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Schmill M, 1999, 7 INT WORKSH ART INT	14	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							1382	1389		10.1109/IJCNN.2008.4633978		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827200221		
S	Saha, S; Bandyopadhyay, S; Singh, CT			IEEE	Saha, Sriparna; Bandyopadhyay, Sanghamitra; Singh, Chingtham Tejbanta			A New Line Symmetry Distance Based Pattern Classifier	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE		Pattern Classification; Kd-tree; Symmetry based distance; Nearest Neighbor Rule; Line Symmetry	NEAREST-NEIGHBOR CLASSIFICATION; ALGORITHMS	In this paper, a new line symmetry based classifier (LSC) is proposed to deal with pattern classification problems. In order to measure total amount of line symmetry of a particular point in a class, a new definition of line symmetry based distance is also proposed in this paper. The proposed line symmetry based classifier (LSC) utilizes this new definition of tine symmetry distance for classifying an unknown test sample. LSC assigns an unknown test sample pattern to that class with respect to whose major axis it is most symmetric. The mean of all the training patterns belonging to that particular class is taken as the prototype of that class. Thus training constitutes of computing only the class prototypes and the major axes of those classes. Kd-tree based nearest neighbor search is used for reducing complexity of line symmetry distance computation. The performance of LSC is demonstrated in classifying twelve artificial and real-life data sets of varying complexities. Experimental results show that LSC achieves, in general, higher classification accuracy compared to kappa-NN classifier. Results indicate that the proposed novel line symmetry based classifier is well-suited for classifying data sets having symmetrical classes, irrespective of any convexity, overlap and size. Statistical analysis, ANOVA is also performed to compare the performance of these classifications techniques.	[Saha, Sriparna; Bandyopadhyay, Sanghamitra] Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Saha, S (reprint author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.	sriparna_r@isical.ac.in; sangahmi@isical.ac.in; chingtham@gmail.com					ANDERBERG MR, 2000, COMPUTATIONAL GEOMET; Anderson T.W., 1978, INTRO STAT ANAL DATA; Asuncion A., 2007, UCI MACHINE LEARNING; ATTNEAVE F, 1955, Am J Psychol, V68, P209, DOI 10.2307/1418892; Bandyopadhyay S, 2007, PATTERN RECOGN, V40, P3430, DOI 10.1016/j.patcog.2007.03.026; Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P2791, DOI 10.1016/S0031-3203(01)00234-5; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferhatosmanoglu H, 2006, INFORM SYST, V31, P512, DOI 10.1016/j.is.2005.01.001; Fix E., 1951, 4 USAF SCH AV MED RA; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; Lai JZC, 2007, PATTERN RECOGN, V40, P351, DOI 10.1016/j.patcog.2006.04.024; LIU CL, 1999, ICDAR 99, P378; Mount DM, 2005, ANN LIB APPROXIMATE; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; Su MS, 2001, IEEE T PATTERN ANAL, V23, P674; Viswanath P, 2006, PATTERN RECOGN LETT, V27, P1714, DOI 10.1016/j.patrec.2006.04.015; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	23	3	3	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							1425	1432		10.1109/IJCNN.2008.4633984		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827200227		
S	Yang, CS; Chuang, LY; Li, JC; Yang, CH			IEEE	Yang, Cheng-San; Chuang, Li-Yeh; li, Jung-Chike; Yang, Cheng-Hong			A Novel BPSO Approach for Gene Selection and Classification of Microarray Data	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			MULTIPLE CANCER TYPES; EXPRESSION DATA; BREAST-CANCER; DISCRIMINATION; MACHINE; NUMBER; TUMORS; SETS	Selecting relevant genes from microarray data poses a huge challenge due to the high-dimensionality of the features multi-class categories and a relatively small sample size. The main task of the classification process is to decrease the microarray data dimensionality. In order to analyze microarray data, an optimal subset of features (genes) which adequately represents the original set of features has to be found. In this study, we used a novel binary particle swarm optimization (NBPSO) algorithm to perform microarray data selection and classification. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as a classifier. The experimental results showed that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates.	[Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CS (reprint author), Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan.	p8896117@mail.ncku.edu.tw; chuang@isu.edu.tw; 1095320149@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Chang JC, 2005, BREAST CANCER RES, V7, P100, DOI 10.1186/bcr1018; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deutsch JM, 2003, BIOINFORMATICS, V19, P45, DOI 10.1093/bioinformatics/19.1.45; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Hua JP, 2005, BIOINFORMATICS, V21, P1509, DOI 10.1093/bioinformatics/bti171; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; Huang HL, 2007, BIOSYSTEMS, V90, P516, DOI 10.1016/j.biosystems.2006.12.003; Jeffrey Stefanie S, 2005, J Natl Compr Canc Netw, V3, P291; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Kennedy J., 1995, IEEE INT C NEUR NETW, V4; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Liu XX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-76; Lonning PE, 2005, NAT CLIN PRACT ONCOL, V2, P26, DOI 10.1038/ncponc0072; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; SHI, 1998, EV COMP P IEEE WORLD, P69; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001	27	2	2	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							2147	2152				6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827201089		
S	Ang, KK; Chin, ZY; Zhang, HH; Guan, CT			IEEE	Ang, Kai Keng; Chin, Zheng Yang; Zhang, Haihong; Guan, Cuntai			Filter Bank Common Spatial Pattern (FBCSP) in Brain-Computer Interface	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			SINGLE-TRIAL EEG; MOTOR IMAGERY; CLASSIFICATION; MOVEMENT; DESYNCHRONIZATION; COMMUNICATION; SELECTION; ROUGH	In motor imagery-based Brain Computer Interfaces (BCI), discriminative patterns can be extracted from the electroencephalogram (EEG) using the Common Spatial Pattern (CSP) algorithm. However, the performance of this spatial filter depends on the operational frequency band of the EEG. Thus, setting a broad frequency range, or manually selecting a subject-specific frequency range, are commonly used with the CSP algorithm. To address this problem, this paper proposes a novel Filter Bank Common Spatial Pattern (FBCSP) to perform autonomous selection of key temporal-spatial discriminative EEG characteristics. After the EEG measurements have been bandpass-filtered into multiple frequency bands, CSP features are extracted from each of these bands. A feature selection algorithm is then used to automatically select discriminative pairs of frequency bands and corresponding CSP features. A classification algorithm is subsequently used to classify the CSP features. A study is conducted to assess the performance of a selection of feature selection and classification algorithms for use with the FBCSP. Extensive experimental results are presented on a publicly available dataset as well as data collected from healthy subjects and unilaterally paralyzed stroke patients. The results show that FBCSP, using a particular combination feature selection and classification algorithm, yields relatively higher cross-validation accuracies compared to prevailing approaches.	[Ang, Kai Keng; Chin, Zheng Yang; Zhang, Haihong; Guan, Cuntai] ASTAR, Inst Infocomm Res, Singapore 119613, Singapore	Ang, KK (reprint author), ASTAR, Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.	kkang@i2r.a-star.edu.sg; zychin@i2r.a-star.edu.sg; hhzhang@i2r.a-star.edu.sg; ctguan@i2r.a-star.edu.sg					ANG KK, 2006, P IEEE INT JOINT C N, P742; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Birbaumer N, 2006, CLIN NEUROPHYSIOL, V117, P479, DOI 10.1016/j.clinph.2005.11.002; Blankertz B, 2005, BCI COMPETITION 3; Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051; Bowman A.W., 1997, APPL SMOOTHING TECHN; Breiman L., 1984, CLASSIFICATION REGRE; Casillas J., 2003, INTERPRETABILITY ISS; Cover T. M., 2006, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Dornhege G, 2006, IEEE T BIO-MED ENG, V53, P2274, DOI 10.1109/TBME.2006.883649; Duda R O, 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; JENSEN R, 2007, IEEE T FUZZ IN PRESS; Kandel ER, 1995, ESSENTIALS NEURAL SC; Kasabov NK, 2002, IEEE T FUZZY SYST, V10, P144, DOI 10.1109/91.995117; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; Muller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8; Novi Q., 2007, 3 INT IEEE EMBS C NE, P204; Pawlak Z., 1991, ROUGH SETS THEORETIC; Penfield W., 1950, CEREBRAL CORTEX MAN; Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8; PFURTSCHELLER G, 1979, ELECTROEN CLIN NEURO, V46, P138, DOI 10.1016/0013-4694(79)90063-4; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Rebsamen B, 2007, IEEE INTELL SYST, V22, P18, DOI 10.1109/MIS.2007.26; Schnitzler A, 1997, NEUROIMAGE, V6, P201, DOI 10.1006/nimg.1997.0286; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Vapnik V., 1998, STAT LEARNING THEORY; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	33	53	53	1	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							2390	2397				8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827201126		
S	Oentaryo, RJ; Pasquier, M			IEEE	Oentaryo, Richard J.; Pasquier, Michel			A Reduced Rule-Based Localist Network for Data Comprehension	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE			YAGER-INFERENCE; FUZZY-LOGIC; CONTROLLER; ALGORITHM; SYSTEM; FCMAC	Localist networks and especially neuro-fuzzy systems constitute promising techniques for data comprehension, but generally exhibit poor system interpretability and generatization ability. This paper aims at addressing the issues through a novel localist Reduced Fuzzy Cerebellar Model Articulation Controller (RFCMAC), that models the two-stage development of cortical memories in the human brain to compress and refine the formulated (fuzzy) rule base respectively. The proposed mechanisms allow the RFCMAC associative memory to induce a concise, interpretable rule base, and at the same time to improve generalization, fostering in turn system scalabitity and robustness. Experimental results on several benchmark tasks have demonstrated the potential of the proposed system as an effective tool for understanding data.	[Oentaryo, Richard J.; Pasquier, Michel] Nanyang Technol Univ, Sch Controller Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Oentaryo, RJ (reprint author), Nanyang Technol Univ, Sch Controller Engn, Ctr Computat Intelligence, Nanyang Ave, Singapore 639798, Singapore.	asmbpasquier@ntu.edu.sg	Oentaryo, Richard/M-5948-2014	Oentaryo, Richard/0000-0002-4662-1561			ADELSONVELSKII GM, 1962, DOKL AKAD NAUK SSSR+, V146, P263; ALBUS JS, 1975, J DYNAMIC SYSTEMS ME, V97; Ang KK, 2003, IEEE T SYST MAN CY B, V33, P838, DOI 10.1109/TSMCB.2003.812850; Ang KK, 2005, NEURAL COMPUT, V17, P205, DOI 10.1162/0899766052530857; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duch W., 2004, P IEEE, V92; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fisher RA, 1936, ANN EUGENIC, V7, P179; Goldman RN, 1985, STAT INTRO; GUO Z, 2006, P IEEE C EV COMP CEC, P2375; Hall M.A., 1999, THESIS U WAIKATO; Hebb D, 1949, ORG BEHAV; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Juang CF, 1998, IEEE T FUZZY SYST, V6, P12; Kandel E. R., 2000, PRINCIPLES NEURAL SC; Kasabov N, 2001, IEEE T SYST MAN CY B, V31, P902, DOI 10.1109/3477.969494; KELLER JM, 1992, FUZZY SET SYST, V45, P1, DOI 10.1016/0165-0114(92)90086-J; Lin CJ, 1997, IEEE T FUZZY SYST, V5, P477; Lin C.-T., 1996, NEURAL FUZZY SYSTEMS; Liu F, 2007, NEURAL COMPUT, V19, P1656, DOI 10.1162/neco.2007.19.6.1656; Mamdani EH, 1999, INT J HUM-COMPUT ST, V51, P135, DOI 10.1006/ijhc.1973.0303; NAKANISHI H, 1993, FUZZY SET SYST, V57, P257, DOI 10.1016/0165-0114(93)90024-C; NIE JH, 1994, AUTOMATICA, V30, P655, DOI 10.1016/0005-1098(94)90154-6; OENTARYO RJ, EXPERT SYST IN PRESS; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Platt J., 1998, ADV KERNEL METHODS S; Powell M.J.D., 1987, ALGORITHMS APPROXIMA, P143; Quek C, 2005, EXPERT SYST APPL, V29, P229, DOI 10.1016/j.eswa.2005.03.001; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sim J, 2006, IEEE T NEURAL NETWOR, V17, P1394, DOI 10.1109/TNN.2006.880362; Smola A.J., 1998, NEUROCOLT2 TECHNICAL; VUORIMAA P, 1994, FUZZY SET SYST, V66, P223, DOI 10.1016/0165-0114(94)90312-3; WANG ZQ, 1996, P IEEE INT C NEUR NE, V3, P1698; Widrow B., 1985, ADAPTIVE SIGNAL PROC	35	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							2660	2667		10.1109/IJCNN.2008.4634171		8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827201167		
S	Barros, ACA; Cavalcanti, GDC			IEEE	Barros, Adelia C. A.; Cavalcanti, George D. C.			Combining Global Optimization Algorithms with a Simple Adaptive Distance for Feature Selection and Weighting	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE				This work focuses on a study about hybrid optimization techniques for improving feature selection and weighting applications. For this purpose, two global optimization methods were used: Tabu Search(TS) and Simulated Annealing (SA). These methods were combined to k-Nearest Neighbor (k-NN) composing two hybrid approaches: SA/k-NN and TS/k-NN. Those approaches try to use the main advantage from the global optimization methods: they work efficiently in searching for solutions in the global space. In this study, the methodology is proposed by [4]. In the referred work, a hybrid TS/k-NN approach was suggested and successfully applied for feature selection and weighting problems. Based on the later, this analysis indicates a new SA/k-NN combination and compares their results using the classical Euclidean Distance and a Simple Adaptive Distance [8]. The results demonstrate that feature sets optimized by the studied models are very efficient when compared to the well-known k-NN. Both accuracy classification and number of features in the resultant set are considered in the conclusions. Furthermore, the combined use of the Simple Adaptive Distance improves even more the results for all datasets analyzed.	[Barros, Adelia C. A.; Cavalcanti, George D. C.] Univ Fed Pernambuco, CIn, BR-50740540 Recife, PE, Brazil	Barros, ACA (reprint author), Univ Fed Pernambuco, CIn, POB 7851, BR-50740540 Recife, PE, Brazil.	acab@cin.ufpe.br; gdcc@cin.ufpe.br		Cavalcanti, George/0000-0001-7714-2283			Asuncion A., UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Hansen P., 1986, C NUM METH COMB OPT; Jain A. K., 1996, IEEE COMPUTER    MAR, P31; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Michie D., 1994, MACHINE LEARNING NEU; Pham D. T., 2000, INTELLIGENT OPTIMISA, P1; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Yao X, 1999, P IEEE, V87, P1423; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	14	1	1	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							3518	3523		10.1109/IJCNN.2008.4634300		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827202060		
S	Alippi, C; Fuhrman, M; Roveri, M			IEEE	Alippi, C.; Fuhrman, M.; Roveri, M.			k-NN classifiers: investigating the k = k (n) relationship	2008 IEEE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1-8	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 01-08, 2008	Hong Kong, PEOPLES R CHINA	IEEE				The paper proposes a theory-based method for estimating the optimal value of k in k-NN classifiers based on a n-sized training set. As expected, experiments show that the suggested k is such that k/n -> 0 when both k and n tend to infinity, as required by the asymptotical consistency condition. Interestingly, it appears that the generalization error is robust w.r.t. to k when n becomes large (probably as a consequence of the k/n -> 0 relationship); the immediate consequence is that there is no need to provide an accurate estimate for the optimal k and an approximated coarser value, eg., provided with cross validation, 1-fold cross validation or leave one out is more than adequate.	[Alippi, C.; Roveri, M.] Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettron & Informaz, I-20133 Milan, Italy.	alippi@elet.polimi; marco.fuhrman@polimi.it; roveri@elet.polimi					ALIPPI C, 2007, NEUR NETW 2007 IJCNN, P1008; ALIPPI C, 2008, K NN CLASSIFIERS INV; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; FUKUNAGA K, 1973, IEEE T INF THEORY, V19; Fukunaga K., 1972, INTRO STAT PATTERN R; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; KEANS M, 1999, NEURAL COMPUT, V11, P1427; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Mood A.M., 1963, INTRO THEORY STAT; STONE C, 1977, ANN STAT, V8, P1348	11	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-1820-6	IEEE IJCNN			2008							3676	3680		10.1109/IJCNN.2008.4634324		5	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic	Computer Science; Engineering	BIY81	WOS:000263827202084		
S	He, J; Zhao, HZ; Fu, Q			IEEE	He Jun; Zhao Hong-zhong; Fu Qiang			ATR Performance Assessment of Target Type Number for HRR Radar	2008 IEEE RADAR CONFERENCE, VOLS. 1-4	IEEE Radar Conference		English	Proceedings Paper	2008 IEEE Radar Conference	MAY 26-30, 2008	Rome, ITALY	IEEE, FINMECCANICA, SELEX, Agilent Technol, Dappolonia, Gedae, IDS, IET, MBDA, McGraw Hill, Natl Instruments, Off Naval Res, Sci & Technol, ROHDE & SCHWARZ, Tektronix, Thales Alenia, altran, ACCSCO, Raytheon		automatic target recognition (ATR); performance; evaluation	SAR ATR; CLASSIFICATION; MODEL	Automatic target recognition (ATR) performance evaluation has become an important subject in ATR theory community since the last two decades. The extended operation condition (EOC) and system cost are two key aspects in ATR performance evaluation. For the situation of air-to-ground (A-G) ATR using high range resolution (HRR) data, this paper analyzes the influence of target type number on ATR system performance. The system cost is also considered in evaluation process. An experiential performance model of typical ATR systems is given. The performance model and the corresponding conclusions have useful reference to ATR system performance prediction and assessment in the similar A-G applications.	[He Jun; Zhao Hong-zhong; Fu Qiang] Natl Univ Def Technol, ATR Lab, Changsha 410073, Hunan, Peoples R China	He, J (reprint author), Natl Univ Def Technol, ATR Lab, Changsha 410073, Hunan, Peoples R China.	hisjune@163.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUBA RO, 2004, PATTERN CLASSIFICATI; EISENBIES CL, 1994, THESIS AIR FORCE I T; Fukunaga K., 1990, INTRO STAT PATTERN R; GAO Q, 2004, INT C RAD SYST TOUL; Jacobs SP, 2000, IEEE T AERO ELEC SYS, V36, P364, DOI 10.1109/7.845214; MISHRA AK, 2006, INT CONF ACOUST SPEE, P1104; MITCHELL RA, 1994, OVERVIEW HIGH RANGE; Mossing JC, 1998, P SOC PHOTO-OPT INS, V3370, P554, DOI 10.1117/12.321858; O'Sullivan JA, 2001, IEEE T AERO ELEC SYS, V37, P91, DOI 10.1109/7.913670; Ross TD, 1999, P SOC PHOTO-OPT INS, V3721, P662, DOI 10.1117/12.357681; Ross TD, 2002, P SOC PHOTO-OPT INS, V4727, P310, DOI 10.1117/12.478692; Ross TD, 1997, P SOC PHOTO-OPT INS, V3070, P213, DOI 10.1117/12.281559	13	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1097-5764		978-1-4244-1538-0	IEEE RAD CONF			2008							1399	1403				5	Remote Sensing; Telecommunications	Remote Sensing; Telecommunications	BJC08	WOS:000264663001051		
B	Richert, W; Niehorster, O; Koch, M		Chatila, R; Kelly, A; Merlet, JP		Richert, Willi; Niehoerster, Oliver; Koch, Markus			Layered understanding for sporadic imitation in a multi-robot scenario	2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS			English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems	SEP 22-26, 2008	Nice, FRANCE	IEEE, Robot Soc Japan, IEEE Robot & Automat Soc, IEEE Ind Elect Soc, Soc Instrument & Control Engineers, Inst Natl Rech Informat & Automat, CNRS, Inst Control, Roibot & Syst				With imitation robots have a powerful means to drastically cut down the exploration space. However, as existing imitation approaches usually require repetitive demonstrations of the skill to learn in order to be useful, those are typically not applicable in groups of robots. In these scenarios usually each robot has its own task to accomplish and should not he disturbed by teaching others. Therefor, most of the time an imitating robot has only one observed performance of the behavior from which it can learn. Utilisation of these sparse observation data has largely been ignored. We present an approach that allows an individually learning robot to make use of such cases of sporadic imitation which is often the only possibility to learn from other robots in a group. The power of the algorithm comes from the fact that it uses the robots already known skills and strategies to understand the observed behavior. Thereby, a robot can use imitation in order to guide its exploration efforts towards more rewarding areas in the exploration space. This is inspired by imitation often found in nature where animals or humans try to map observations into their own capability space. We	[Richert, Willi; Niehoerster, Oliver; Koch, Markus] Univ Paderbom, Fac Comp Sci Elect Engn & Math, Paderborn, Germany	Richert, W (reprint author), Univ Paderbom, Fac Comp Sci Elect Engn & Math, Paderborn, Germany.						Alpaydin E., 2004, INTRO MACHINE LEARNI; ARBIB MA, 2001, MIRROR SYSTEM IMITAT; Bellman R, 2003, DYNAMIC PROGRAMMING; Bengio Y., 1999, NEURAL COMPUTING SUR, V2, P129; Bentivegna DC, 2001, IEEE INT CONF ROBOT, P1988; Billard A., 2000, LEARNING MOTOR SKILL; Billard A, 2004, ROBOT AUTON SYST, V47, P69, DOI 10.1016/j.robot.2004.03.002; BORENSTEIN E, 2003, 2 INT S IM AN ART; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demiris J, 2002, FROM ANIM ANIMAT, P327; Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5; Gatsoulis Y., 2002, Proceedings of the Second IASTED International Conference. Artificial Intelligence and Applications; IJSPEERT JA, 2002, INT C ROB AUT ICRA 2; INAMURA T, 2003, EXPT ROBOTICS, V8; KOCHENDERFER MJ, 2006, THESIS U EDINBURGH; NISHI T, 2007, IEEE RSJ INT C INT R, P70; PERERA M, 2007, IEEE RSJ INT C INT R, P1409; RICHERT W, 2008, INT C AUT AUT SYST I; Richert W, 2005, LECT NOTES COMPUT SC, V3644, P1004; Roweis S., 2000, NONLINEAR DIMENSIONA; Sutton R.S., 1998, REINFORCEMENT LEARNI; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010	23	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2057-5				2008							1287	1292		10.1109/IROS.2008.4650817		6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BIJ26	WOS:000259998200202		
S	Remus, JJ; Morton, KD; Torrione, PA; Tantum, SL; Collins, LA			IEEE	Remus, Jeremiah J.; Morton, Kenneth D.; Torrione, Peter A.; Tantum, Stacy L.; Collins, Leslie A.			Comparison of a distance-based likelihood ratio test and k-nearest neighbor classification methods	2008 IEEE WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING	IEEE Workshop on Machine Learning for Signal Processing		English	Proceedings Paper	IEEE Workshop on Machine Learning for Signal Processing	OCT 16-19, 2008	Cancun, MEXICO	IEEE Signal Processing Soc, IEEE			PATTERN-CLASSIFICATION; RULE	Several studies of the k-nearest neighbor (KNN) classifier have proposed the use of non-uniform weighting on the k neighbors. It has been suggested that the distance to each neighbor can be used to calculate the individual weights in a weighted KNN approach; however, a consensus has not yet been reached on the best method or framework for calculating weights using the distances. In this paper, a distance likelihood ratio test will be discussed and evaluated using simulated data. The distance likelihood ratio test (DLRT) shares several characteristics with the distance-weighted k-nearest neighbor methods but approaches the use of distance from a different perspective. Results illustrate the ability of the distance likelihood ratio test to approximate the likelihood ratio and compare the DLRT to two other k-neighborhood classification rules that utilize distance-weigbting. The DLRT performs favorably in comparisons of the classification performance using the simulated data and provides an alternative non-parametric classification method for consideration when designing a distance-weighted KNN classification rule.	[Remus, Jeremiah J.; Morton, Kenneth D.; Torrione, Peter A.; Tantum, Stacy L.; Collins, Leslie A.] Duke Univ, ECE Dept, Durham, NC 27708 USA	Remus, JJ (reprint author), Duke Univ, ECE Dept, Durham, NC 27708 USA.	jjr6@ee.duke.edu; kdm@ee.duke.edu; pt@ee.duke.edu; slt@ee.duke.edu; lcollins@ee.duke.edu	Tantum, Stacy/E-1830-2011				Cantone D, 2005, IEEE T KNOWL DATA EN, V17, P535, DOI 10.1109/TKDE.2005.53; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FIX E, 1952, 11 USAF SCH AV MED, P280; FUKUNAGA K, 1982, IEEE T PATTERN ANAL, V4, P427; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; Hodges J., 1951, 4 USAF SCH AV MED, P261; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kolahdouzan M. R., 2004, P 30 INT C VER LARG, P840, DOI 10.1016/B978-012088469-8/50074-7; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Seidl T., 1998, SIGMOD Record, V27	14	8	8	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1551-2541		978-1-4244-2375-0	MACHINE LEARN SIGN P			2008							362	367		10.1109/MLSP.2008.4685507		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BJK47	WOS:000266687900062		
B	Zhang, L; Ye, N; Zhou, WD; Jiao, LC			IEEE	Zhang, Li; Ye, Ning; Zhou, Weida; Jiao, Licheng			Support Vectors Pre-extracting for Support Vector Machine Based on K Nearest Neighbour Method	2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4			English	Proceedings Paper	IEEE International Conference on Information and Automation	JUN 20-23, 2008	Changsha, PEOPLES R CHINA	IEEE Robot & Automat Soc, CHUK NUDT Joint Ctr Intelligent Sensing & Syst, Natl Univ Def Technol, Sch Elect Sci & Engn, Natl Sci Fdn China, CAS, Inst Intelligent Machines, IEEE Hong Kong Joint Chapter Robot & Automat & Control Syst, Natl Univ Def Technol, Sch Mechatron Engn & Automat		support vector machine; K nearest neighbour; pre-extracting		Support vector machine, a universal method for learning from data, gains its development based on statistical learning theory. It shows many advantages in solving nonlinearly small sample and high dimensional problems of pattern recognition. Only a part of samples or support vectors (SVs) plays an important role in the final decision function. But SVs could not be obtained in advance until a quadratic programming is performed. In this paper, we use K-nearest neighbour method to extract a boundary vector set which may contain SVs. The number of the boundary set is smaller than the whole training set. Consequently it reduces the training samples, speeds up the training of support vector machine.	[Zhang, Li] Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Shaanxi Prov, Peoples R China	Zhang, L (reprint author), Xidian Univ, Inst Intelligent Informat Proc, Xian 710071, Shaanxi Prov, Peoples R China.	zhangli@mail.xidian.edu.cn; ye-ning@hotmail.com; wdzhou@mail.xidian.edu.cn; lchjiao@mail.xidian.edu.cn					Burges C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Cherkassky V, 1997, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DING AL, 2002, COMPUTER ENG APPL, V19, P116; EDGAR O, 1997, P IEEE NNSP 97 AM IS, P24; Jiao Li-Cheng, 2001, Acta Electronica Sinica, V29; Li Qing, 2005, Chinese Journal of Computers, V28; [裴继红 Pei Jihong], 2003, [电子与信息学报, Journal of electronics & information technology], V25, P1494; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Wu Zhong-dong, 2004, Journal of Fudan University (Natural Science), V43; ZHOU YL, 2006, AERONAUTICAL COMPUTI, V36, P62	12	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2183-1				2008							1353	1358				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Automation & Control Systems; Computer Science; Engineering; Robotics	BIQ50	WOS:000262054600256		
B	Kruatrachue, B; Hongsamart, M			IEEE	Kruatrachue, Boontee; Hongsamart, Marut			Prototype Selection based on Minimal Consistent Subset and Genetic Algorithms	2008 PROCEEDINGS OF SICE ANNUAL CONFERENCE, VOLS 1-7			English	Proceedings Paper	Annual Conference of the SICE	AUG 20-22, 2008	Chofu, JAPAN			prototype selection; minimal consistent subset; genetic algorithms; consistency property; nearest neighbor rule	NEAREST-NEIGHBOR RULE; CLASSIFICATION; SEARCH	This paper applies the genetic algorithms to identify the minimal "consistent" prototype subset [1]. This subset can be used as a prototype which correctly recognizes the entire original prototype set. This proposed genetic algorithm tries to find the minimal consistent subset to reduce recognition time in nearest neighbor [2] classification. The main difference from other genetic algorithm (GA) approaches is the hybrid of minimal consistent set identification (MCSI) method [3] and genetic algorithm. The MCSI method provides the local optimal number of prototype while the Genetic performs the global search. The proposed hybrid algorithm has been tested on several problems and compared with the results of MCSI and other GA approach [4].	[Kruatrachue, Boontee; Hongsamart, Marut] King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand	Kruatrachue, B (reprint author), King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok, Thailand.	booontee@yahoo.com; mnemonic329@hotmail.com					Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KANGKAN K, 2006, MINIMAL CONSISTENT S; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; MOLLINEDA RA, 2000, P 4 WORLD MULT SYST, P640; *U CA DEP INF COMP, 1998, UCI MACH LEARN REP	8	0	0	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-4-907764-30-2				2008							647	651				5	Automation & Control Systems; Instruments & Instrumentation	Automation & Control Systems; Instruments & Instrumentation	BIZ59	WOS:000263966700132		
S	Qi, YN; Atallah, MJ				Qi, Yinian; Atallah, Mikhail J.			Efficient Privacy-Preserving k-Nearest Neighbor Search	28TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS, VOLS 1 AND 2, PROCEEDINGS	INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS		English	Proceedings Paper	28th International Conference on Distributed Computing Systems	JUN 17-20, 2008	Beijing, PEOPLES R CHINA	IEEE				We give efficient protocols for secure and private k-nearest neighbor (k-NN) search, when the data is distributed between two parties who want to cooperatively compute the answers without revealing to each other their private data. Our protocol for the single-step k-NN search is provably secure and has linear computation and communication complexity Previous work on this problem had a quadratic complexity, and also leaked information about the parties' inputs. We adapt our techniques to also solve the general multi-step k-NN search, and describe a specific embodiment of it for the case of sequence data. The protocols and correctness proofs can be extended to suit other privacy-preserving data mining tasks, such as classification and outlier detection.	[Qi, Yinian; Atallah, Mikhail J.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Qi, YN (reprint author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.	yqi@cs.purdue.edu; mja@cs.purdue.edu	Qi, Yinian/L-5824-2013				AGGARWAL CC, SIGMOD 01; Atallah M, 2003, WPES 03, P39; BERCHTOLD S, 1998, IEEE INT C DAT ENG 1, P209; Canetti R, 2000, J CRYPTOL, V13, P143, DOI 10.1007/s001459910006; Clifton C., 2002, SIGKDD EXPLORATIONS, P28; Cormen T.H., 2001, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damgard I, 2006, LECT NOTES COMPUT SC, V3876, P285; DU W, 2001, P 17 ANN COMP SEC AP, P102; Goethals B, 2004, LECT NOTES COMPUT SC, V3506, P104; Goldreich O, 2004, FDN CRYPTOGRAPHY, V2; Goldreich O, 1996, J ACM, V43, P431, DOI 10.1145/233551.233553; Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; KANTARCIOGLU M, 2004, PKDD2004, P279; Kleinberg J. M., 1997, STOC 97, P599; LINDELL Y, 2000, CRYPTO; Malkhi D, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P287; NEEDLEMAN S, 1970, J MOL BIOL, P443; Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223; Ramaswamy S., 2000, SIGMOD, P427; Roussopoulos N., 1995, SIGMOD, P71; Seidl T., 1998, SIGMOD C, P154; Seidl T., 1997, VLDB J, P506; SHANECK M, 2006, ICDMW 06, P541; TENG Z, 2007, PAKDD, P296; VAIDYA J, 2003, PRIVACY PRESERVING K; VAIDYA J, 2004, ICDM 04, P233; Verykios VS, 2004, SIGMOD REC, V33, P50; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; XIONG L, 2007, SAC 07, P435; YAO AC, 1986, P 27 IEEE S FDN COMP, V27; YAO AC, 1998, P 23 IEEE S FDN COMP, P160	32	11	11	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6927		978-1-4244-3174-8	INT CON DISTR COMP S			2008							311	319		10.1109/ICDCS.2008.79		9	Computer Science, Theory & Methods	Computer Science	BIW60	WOS:000263415700037		
S	Caulier, Y; Bourennane, S		BlancTalon, J; Bourennane, S; Philips, W; Popescu, D; Scheunders, P		Caulier, Y.; Bourennane, S.			Fourier-Based Inspection of Free-Form Reflective Surfaces	ADVANCED CONCEPTS FOR INTELLIGENT VISION SYSTEMS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Advanced Concepts for Intelligent Vision Systems	OCT 20-24, 2008	Juan les Pins, FRANCE	SEE, Ghent Univ, Philips Res, DGA, NXP Semicond, IEEE Benelux Signal Proc Chapter, Eurasip, Barco, DSP Valley, FWO Res Community Audiovisual Syst			INTERFEROMETRY; TRANSFORM	A general free-form surface inspection approach relying oil the projection of a structured light pattern and the interpretation of the generated stripe structures by means of Fourier-based features is proposed in this paper. The major concerns of this paper are the determination of various refrence sets of stripe patterns, and the detailed investigation oil the subset of Fourier features that best characterizes free-form bright/dark structures. In order to tackle the inspection problem with a general approach, a first part of this paper is dedicated to the definition of different image data sets that correspond to various types of free-form specular shapes recorded with a structured illumination. A second part deals with the optimization of the most appropriate pattern recognition process. The optimization is dedicated to the use of different pattern arrangements, and the evaluation of different Fourier feature subsets. It is shown that with only 10 Fourier features and a certain pattern arrangement, high classification rates of free-form surfaces can be obtained.	[Caulier, Y.] Fraunhofer Inst Integrierte Schaltungen IIS, D-91058 Erlangen, Germany	Caulier, Y (reprint author), Fraunhofer Inst Integrierte Schaltungen IIS, Wolfsmantel 33, D-91058 Erlangen, Germany.	yannick.caulier@iis.fraunhofer.de; salah.bourennane@fresnel.fr; salah.bourennane@fresnel.fr	Bourennane, Salah/F-2928-2010				Babich Gregory A., 1996, IEEE T PATTERN ANAL, V18; CAULIER Y, 2008, J OPTICAL ENG, V47; CAULIER Y, 2008, EURASIP J IMAGE VIDE; *COM AG, 2005, FEINF FOX HIGH RES 2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Foresti G.L., 2002, IEEE T NEURAL NETWOR, V13; GEVA S, 1991, IEEE T NEURAL NETWOR, V2; GOLDSTEIN M, 1972, IEEE T INFORM THEORY, V18; GRUNDITZ C, 2004, P IJCNN BUD JUL, V3, P1881; GUTIERREZOSUNA R, 2003, IEEE SENS J, V2, P273; KAMMEL K, 2004, DEFLEKTOMETRISCHE UN; Kammel S, 2003, TECH MESS, V70, P193, DOI 10.1524/teme.70.4.193.20181; KNAUER M, 2004, OPTICAL METROLOGY PR, V5457, P366; KOHAVI R, 1995, P IJCAI, V3, P1137; KOHAVI R, 2002, ARTIF INTELL, V2, P189; KRUGER S, 2000, MACHINE VISION APP 8, V3966, P145; Kunttu I, 2006, MACH VISION APPL, V17, P211, DOI 10.1007/s00138-006-0030-6; LI WB, 2005, IEEE T ANTENN PROPAG, V53, P1154; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; PERNKOPF F, 2002, EURASIP J APPL SIG P, P667; QIAN K, 2005, FRINGE 2005 FAULT DE; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; REINDL I, 2004, GEOMETRIC SURFACE IN, P849; RUIZ A, 2001, IEEE T NEURAL NETWOR, V12; TAKEDA M, 1982, J OPT SOC AM, V72, P156, DOI 10.1364/JOSA.72.000156; TANG WH, 2008, IEEE T POWER DELIVER, V23; Tibshirani R, 1993, INTRO BOOTSTRAP; Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6; UNSALAN C, 1998, PATTERN RECOGNITION; WESKA JS, 1976, IEEE T SYST MAN CYB, V6, P269; Witten I, 2005, DATA MINING; 2005, ACERIS 3D FC SUBSTRA	33	1	1	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88457-6	LECT NOTES COMPUT SC			2008	5259						125	136				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIR31	WOS:000262163800012		
S	Yong, Z; Bing, W; Liang, Z; Yang, YP		Huang, DS; Wunsch, DC; Levine, DS; Jo, KH		Yong, Zeng; Bing, Wang; Liang, Zhao; Yang, Yu-Pu			Nonparametric classification based on local mean and class mean	ADVANCED INTELLIGENT COMPUTING THEORIES AND APPLICATIONS, PROCEEDINGS: WITH ASPECTS OF THEORETICAL AND METHODOLOGICAL ISSUES	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	4th International Conference on Intelligent Computing	SEP 15-18, 2008	Shanghai, PEOPLES R CHINA					The k-nearest neighbor classification rule (k-NNR) is a very simple, yet powerful nonparametric classification method. As a variant of the k-NNR, a nonparametric classification method based on the local mean vector has achieved good classification performance. In this paper, a new variant of the k-NNR, a nonparametric classification method based on the local mean vector and the class mean vector has been proposed. Not only the information of the local mean of the k nearest neighbors of the unlabeled pattern in each individual class but also the knowledge of the ensemble mean of each individual class are taken into account in this new classification method. The proposed classification method is compared with the k-NNR, and the local mean-based nonparametric classification in terms of the classification error rate on the unknown patterns. Experimental results confirm the validity of this new classification approach.		Yong, Z (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.						Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Jain A. K., 1988, PATTERN RECOGNITION; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1	7	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-87440-9	LECT NOTES COMPUT SC			2008	5226						593	600				8	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BIH57	WOS:000259555200074		
S	Fabris, F; Drago, I; Varejao, FM		Geffner, H; Prada, R; Alexandre, IM; David, N		Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.			A Multi-measure Nearest Neighbor Algorithm for Time Series Classification	ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2008, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	11th Ibero-American Conference on Artificial Intelligence	OCT 14-17, 2008	Lisbon, PORTUGAL	ADETTI, ISCTE, FCT, AEPIA, APPIA		Data Mining; Machine Learning; Time Series Classification; Multi-Measure Classifier	CLASSIFIERS	In this paper, we have evaluated some techniques for the time series classification problem. Many distance measures have been proposed as an alternative to the Euclidean Distance in the Nearest Neighbor Classifier. To verify the assumption that the combination of various similarity measures may produce a more accurate classifier, we have proposed an algorithm to combine several measures based on weights. We have carried out a set of experiments to verify the hypothesis that the new algorithm is better than the classical ones. Our results show an improvement over the well-established Nearest-Neighbor with DTW (Dynamic Time Warping), but in general, they were obtained combining few measures in each problem used in the experimental evaluation.	[Fabris, Fabio; Drago, Idilio; Varejao, Flavio M.] Univ Fed Espirito Santo, Dept Comp Sci, BR-29060900 Vitoria, ES, Brazil	Fabris, F (reprint author), Univ Fed Espirito Santo, Dept Comp Sci, BR-29060900 Vitoria, ES, Brazil.	ffabris@inf.ufes.br; idrago@inf.ufes.br; fvarejao@inf.ufes.br	David, Nuno/B-4662-2012	David, Nuno/0000-0001-8141-5053			Agrawal R., 1995, P 21 INT C VER LARG, P490; Agrawal R., 1993, P 4 INT C FDN DAT OR, P69; ANTUNES CM, 2001, P WORKSH TEMP DAT MI; Bozkaya T., 1997, CIKM, P128; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daubechies I., 1992, CBMS NSF REG C SERIE; David SHESKIN, 2000, HDB PARAMETRIC NONPA; Demsar J, 2006, J MACH LEARN RES, V7, P1; Devijver P. A., 1982, PATTERN RECOGNITION; Duda R O, 2001, PATTERN CLASSIFICATI; Gusfield D, 1997, ALGORITHMS STRINGS T; HAMMING RW, 1950, AT&T TECH J, V29, P147; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E., 2006, UCR TIME SERIES CLAS; KOHAVI R, 1997, 9 EUR C MACH LEARN P; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; SAVARY L, 2002, ECAI 2002 WORKSH KNO, P63; Xi X., 2006, ICML 06, P1033	20	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88308-1	LECT NOTES COMPUT SC			2008	5290						153	162				10	Computer Science, Artificial Intelligence	Computer Science	BIM81	WOS:000260922300016		
S	Costa, EP; Lorena, AC; Carvalho, ACPLF; Freitas, AA		Bazzan, ALC; Craven, M; Martins, NF		Costa, Eduardo P.; Lorena, Ana C.; Carvalho, Andre C. P. L. F.; Freitas, Alex A.			Top-down hierarchical ensembles of classifiers for predicting G-Protein-Coupled-Receptor functions	ADVANCES IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd Brazilian Symposium on Bioinformatics (BSB 2008)	AUG 28-30, 2008	Santo Andre, BRAZIL	UFABC, CMCC, Brazilian Comp Soc, FAPESP, CNPq, CAPES, CLC bio, SGI			CLASSIFICATION; DATABASE; FAMILIES	Despite the recent advances in Molecular Biology, the function of a large amount of proteins is still unknown. An approach that can be used in the prediction of a protein function consists of searching against secondary databases, also known as signature databases. Different strategies can be applied to use protein signatures in the prediction of function of proteins. A sophisticated approach consists of inducing a classification model for this prediction. This paper applies five hierarchical classification methods based on the standard Top-Down approach and one hierarchical classification method based on a new approach named Top-Down Ensembles - based on the hierarchical combination of classifiers - to three different protein functional classification datasets that employ protein signatures. The algorithm based on the Top-Down Ensembles approach presented slightly better results than the other algorithms, indicating that combinations of classifiers can improve the performance of hierarchical classification models.	[Costa, Eduardo P.; Freitas, Alex A.] USP, ICMC, Dept Ciencias Comp, BR-13560970 Sao Carlos, SP, Brazil	Costa, EP (reprint author), USP, ICMC, Dept Ciencias Comp, Caixa Postal 668, BR-13560970 Sao Carlos, SP, Brazil.		Freitas, Alex/H-1249-2011; Lorena, Ana Carolina/A-4494-2008; de Carvalho, Andre/A-6321-2008	Lorena, Ana Carolina/0000-0002-6140-571X; de Carvalho, Andre/0000-0002-4765-6459			Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI 10.1093/nar/gkh131; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Attwood Terri K, 2002, Brief Bioinform, V3, P252, DOI 10.1093/bib/3.3.252; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI 10.1093/nar/30.1.276; Blockeels H., 2002, P ACM SIGKDD 2002 WO, P21; Cohens W, 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dimitriadou E., 2006, E1071 MISC FUNCTIONS, P1; *E B I, PROT FUNCT; FILMORE D, 2004, MODERN DRUG DISCOVER, V1, P24; Freitas A., 2007, RES TRENDS DATA MINI, P175; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; *GPCRDB, 2006, INF SYST G PROT COUP; Holdens N., 2006, P IEEE SWARM INT S S, P77; HORNIK K, RWEKA R INTERFACE WE; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Mitchell T. M., 1997, MACHINE LEARNING; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Salzberg SL, 1997, DATA MIN KNOWL DISC, V1, P317, DOI 10.1023/A:1009752403260; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Sigrist Christian J A, 2002, Brief Bioinform, V3, P265, DOI 10.1093/bib/3.3.265; SUN A, 2003, COOPERATIVE INTERNET, V256; Sun A, 2003, J AM SOC INF SCI TEC, V54, P1014, DOI 10.1002/asi.10298; VENABLES WN, 2006, R DEV CORE TEAM INTR; 1972, E NOMENCLATURE IUPAC, P104; S I BIOINFORMATICS P	28	5	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-85556-9	LECT N BIOINFORMAT			2008	5167						35	46				12	Biochemical Research Methods; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIF67	WOS:000259140500004		
B	Khayat, O; Shahdoosti, HR; Khosravi, MH		Kazovsky, L; Borne, P; Mastorakis, N; KuriMorales, A; Sakellaris, I		Khayat, Omid; Shahdoosti, Hamid Reza; Khosravi, Mohammad Hosetin			Stable Relief in feature weighting	ADVANCES ON ARTIFICIAL INTELLIGENCE, KNOWLEDGE ENGINEERING AND DATA BASES, PROCEEDINGS	Artificial Intelligence Series-WSEAS		English	Proceedings Paper	7th WSEAS International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases	FEB 20-22, 2008	Cambridge, ENGLAND	WSEAS	Univ Cambridge	feature weighting; Relief; Neural Network; Stable Relief	LEARNING ALGORITHMS	Feature weighting algorithms assign weights to features according to their relevance to a particular task. Unfortunately, the best-known feature weighting algorithm, ReliefF, is biased. It decreases the relevance of some features and increases the relevance of others when irrelevant attributes are added to the data set. This paper presents an improved version of the algorithm, Stable Relief, for classification tasks by extracting relevant information. This method, using Stable Relief, is applied to feature weighting for the nearest neighbor classifier and is tested on real-world classification tasks. The results show that it can improve the nearest neighbor classifier on the tested tasks, and also outperforms the Relief. This paper shows that Stable Relief outperforms ReliefF on the task of cat and dog discrimination, using real images.	[Khayat, Omid; Shahdoosti, Hamid Reza; Khosravi, Mohammad Hosetin] Amirkabir Univ, Dept Biomed Engn, Tehran, Iran	Khayat, O (reprint author), Amirkabir Univ, Dept Biomed Engn, Tehran, Iran.						AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; BINS J, 2000, FEATURE SELECTION HU, P156; BINS J, 2001, FEATURE SELECTION HU; Breiman L., 1984, CLASSIFICATION REGRE; Cardie C., 1993, P 10 INT C MACH LEAR, P25; Caruana R., 1994, INT C MACH LEARN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; ISHIGURO H, 1996, IEEE RSJ INT C INT R; John G., 1994, P 11 INT C MACH LEAR, P121; KHAYAT O, 2007, EUR COMP C WSEAS GRE; KIRA K, 1992, 9 INT WORKSH MACH IN; KONONENKO I, 1994, EUR C MACH LEARN CAT; Ling CX, 1997, INT J PATTERN RECOGN, V11, P405, DOI 10.1142/S0218001497000184; Merz C. J., 1996, UCI REPOSITORY MACHI; ROBNIKSIKONJA M, 2001, INT C MACH LEARN WIL; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	18	0	0	0	0	WORLD SCIENTIFIC AND ENGINEERING ACAD AND SOC	ATHENS	AG LOANNOU THEOLOGOU 17-23, 15773 ZOGRAPHOU, ATHENS, GREECE			978-960-6766-41-1	ARTIF INT SER WSEAS			2008							193	197				5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BHY60	WOS:000257462700027		
J	Tan, SC; Rao, MVC; Lim, CP				Tan, Shing Chiang; Rao, M. V. C.; Lim, Chee Peng			Fuzzy ARTMAP dynamic decay adjustment: An improved fuzzy ARTMAP model with a conflict resolving facility	APPLIED SOFT COMPUTING			English	Article						adaptive resonance theory; classification; dynamic decay adjustment; fuzzy ARTMAP	PROBABILISTIC NEURAL-NETWORKS; PATTERN-RECOGNITION; DENSITY-FUNCTION; FAULT-DETECTION; DECISION TREES; CLASSIFICATION; ARCHITECTURE; CLASSIFIERS; ATTRIBUTES; INDUCTION	This paper presents a hybrid neural network classifier of fuzzy ARTMAP (FAM) and the dynamic decay adjustment (DDA) algorithm. The proposed FAMDDA model is a conflict-resolving classifier that can perform stable and incremental learning while settling overlapping of hyper-rectangular prototypes of different classes in minimizing misclassification rates. The performance of FAMDDA is evaluated using a number of benchmark data sets. The results are analyzed and compared with those from FAM and a number of machine learning classifiers. The outcomes show that FAMDDA has a better generalization capability than FAM, and its performance is comparable with those from other classifiers. The effectiveness of FAMDDA is also demonstrated in an application pertaining to condition monitoring of a circulating water system in a power generation station. Implications on the effectiveness of FAMDDA from the application point of view are discussed. (C) 2007 Elsevier B. V. All rights reserved.	Multimedia Univ, Fac Informat Sci & Technol, Cyberjaya 63100, Selangor, Malaysia; Multimedia Univ, Fac Engn & Technol, Selangor 63100, Malaysia; Univ Sci Malaysia, Sch Elect & Elect Engn, George Town 11800, Malaysia	Tan, SC (reprint author), Multimedia Univ, Fac Informat Sci & Technol, Cyberjaya 63100, Selangor, Malaysia.	sctan@mmu.edu.my					Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; Berthold MR, 1998, NEUROCOMPUTING, V19, P167, DOI 10.1016/S0925-2312(97)00063-5; Berzal F, 2004, INFORM SCIENCES, V165, P73, DOI 10.1016/j.ins.2003.09.018; CARPENTER GA, 1988, COMPUTER, V21, P77, DOI 10.1109/2.33; Carpenter G. A., 1995, Connection Science, V7, DOI 10.1080/09540099508915655; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P565, DOI 10.1016/0893-6080(91)90012-T; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P805, DOI 10.1109/72.392245; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; Carpenter GA, 1997, NEURAL NETWORKS, V10, P1473, DOI 10.1016/S0893-6080(97)00004-X; Castellano G, 2004, IEEE T SYST MAN CY B, V34, P725, DOI 10.1109/TSMCB.2003.811291; CHEANG SM, 2003, 2003 C EV COMP CEC 0, V1, P248; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, 1991, NEAREST NEIGHBOUR PA; DUDA RO, 1973, PATTERN CLASSIFICAIO; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; GILES CL, 1987, APPL OPTICS, V26, P4972, DOI 10.1364/AO.26.004972; Gupta CN, 2007, APPL SOFT COMPUT, V7, P286, DOI 10.1016/j.asoc.2005.06.006; HECKERMAN D, 1995, COMMUN ACM, V38, P27, DOI 10.1145/203330.203336; Hettich S., 1998, UCI REPOSITORY MACHI; Hong TP, 2000, FUZZY SET SYST, V112, P127, DOI 10.1016/S0165-0114(98)00179-1; Huber K.- P., 1995, IEEE INT C NEUR NETW, V3, P1263; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; KOHONEN T, 1988, SELF ORGANIZATION AS; KOSINOV S, 2004, IEEE INT C COMP VIS; Kurgan LA, 2004, IEEE T KNOWL DATA EN, V16, P145, DOI 10.1109/TKDE.2004.1269594; Lam W, 2002, IEEE T PATTERN ANAL, V24, P1075; Last M, 2004, IEEE T KNOWL DATA EN, V16, P203, DOI 10.1109/TKDE.2004.1269598; Ledezma A, 2004, PROC INT C TOOLS ART, P49; Li XB, 2003, IEEE T SYST MAN CY A, V33, P194, DOI 10.1109/TSMCA.2002.806499; Lim CP, 1997, NEURAL NETWORKS, V10, P925, DOI 10.1016/S0893-6080(96)00123-2; Liu H., 1998, FEATURE SELECTION KN; Lopes MLM, 2005, APPL SOFT COMPUT, V5, P235, DOI 10.1016/j.asoc.2004.07.003; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mangasarian OL, 1990, SIAM NEWS, V23, P1; Michie D., 1994, MACHINE LEARNING NEU; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; Moshou D, 2005, APPL SOFT COMPUT, V5, P391, DOI 10.1016/j.asoc.2004.09.001; Nauck D, 1999, ARTIF INTELL MED, V16, P149, DOI 10.1016/S0933-3657(98)00070-0; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Quinlan J. R., 1993, PROGRAMS MACHINE LEA, Vfirst; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Riquelme JC, 2003, INFORM SCIENCES, V156, P173, DOI 10.1016/S0020-0255(03)00175-0; Rizzi A, 2002, IEEE T NEURAL NETWOR, V13, P402, DOI 10.1109/72.991426; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Rumelhaxt D. E., 1986, PARALLEL DISTRIBUTED, P318; Shi D, 2005, NEURAL NETWORKS, V18, P951, DOI 10.1016/j.neunet.2005.02.006; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Ster B., 1996, P INT C ENG APPL NEU, P427; Tan SC, 2004, IEEE T ENERGY CONVER, V19, P369, DOI 10.1109/TEC.2003.821826; WANG D, 2007, APPL SOFT COMPUT J, V8, P166; Wu ST, 2004, IEEE T IND ELECTRON, V51, P183, DOI 10.1109/TIE.2003.821897; Yen CW, 2004, PATTERN RECOGN LETT, V25, P725, DOI 10.1016/j.patrec.2004.01.012; Zhang NL, 2004, ARTIF INTELL MED, V30, P283, DOI 10.1016/j.artmed.2003.11.004	61	8	8	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946			APPL SOFT COMPUT	Appl. Soft. Comput.	JAN	2008	8	1					543	554		10.1016/j.asoc.2007.03.006		12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	211FA	WOS:000249508500047		
S	Puteh, M; Hamdan, AR; Omar, K; Abu Bakar, A		Bentley, PJ; Lee, D; Jung, S		Puteh, Mazidah; Hamdan, Abdul Razak; Omar, Khairuddin; Abu Bakar, Azuraliza			Flexible immune network recognition system for mining heterogeneous data	ARTIFICIAL IMMUNE SYSTEMS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	7th International Conference on Artificial Immune Systems	AUG 10-13, 2008	Phuket, THAILAND			artificial immune system (AIS); classification; immune network; heterogeneous; accuracy; significant difference		Artificial Immune System (AIS) is all emerging technique for the classification task and proved to be a reliable technique. In previous studies, many classifiers including AIS classifiers require the data to be in numerical or categorical data. types prior to processing. The transformation of data into any other specific types from their original form call degrade the originality of the data and consume more space and pre processing time. This paper introduces AIS model using immune network for classifying heterogeneous data in its original types. The model is able to process the data with the types as represented in the database and it solves some bias problems highlighted in the AIS review papers. To ensure the consistent conditions and fair comparison, the selected existing algorithms use the same set of data as used in the proposed model. Experimental results show that this network-based model produces a better accuracy rate than the existing population-based immune algorithm and than the standard classifiers on most of the data from University of California, Irvive (UCI) Machine Learning Repository (MLR) and University of California, Riverside (UCR) Time Series Data (TSR).	[Puteh, Mazidah] Univ Teknol MARA, Terengganu, Malaysia	Puteh, M (reprint author), Univ Teknol MARA, Terengganu, Malaysia.			Omar, Khairuddin/0000-0003-1794-019X			BROWNLEE J, 2005, 102 CSCA CISCP SWINB; BROWNLEE J, 2005, 102 CISCP SWINB U FA; BROWNLEE J, 2005, 102 AIRS SWINB U TEC; CARTER JH, 2000, J AM MED INFORM ASS, V7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dasgupta D., 2006, IEEE COMPUTATIONAL I; De Castro L. N., 2002, ARTIFICIAL IMMUNE SY; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; Frank E., 2005, DATA MINING PRACTICA; FREITAS A, 2007, IEEE T EVOLUTIONARY, V11; HAMAKER J, 2004, P CEC 2004; Hart E, 2004, LECT NOTES COMPUT SC, V3239, P413; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hunt JE, 1996, J NETW COMPUT APPL, V19, P189, DOI 10.1006/jnca.1996.0014; Keogh E., 2006, UCR TIME SERIES DATA; MERZ C, 1998, UCI MACHINE LEARNING; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Steed LG, 2003, SPSS ANAL ANGUISH VE; Timmis J, 2006, LECT NOTES COMPUT SC, V3931, P355; Timmis J. I., 2001, ARTIFICIAL IMMUNE SY; Ventura D., 1995, P 10 INT S COMP INF, P443; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Watkins A., 2001, THESIS MISSISSIPPI S; Watkins A, 2004, LECT NOTES COMPUT SC, V3239, P427; Watkins A., 2002, P 1 INT C ART IMM SY, P173; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; ZWITTER M, 1998, I ONCOLOGY	28	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-85071-7	LECT NOTES COMPUT SC			2008	5132						232	241				10	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Computer Science	BID96	WOS:000258852800021		
S	Grudzinski, K		Rutkowski, L; Tadeusiewicz, R; Zadeh, LA; Zurada, JM		Grudzinski, Karol			Towards heterogeneous similarity function learning for the k-nearest neighbors classification	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING - ICAISC 2008, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	9th International Conference on Artificial Intelligence and Soft Computing (ICAISC 2008)	JUN 22-26, 2008	Zakopane, POLAND	Polish Neural Network Soc, Acad Humanities & Econ, Czestochowa Univ Technol, Dept Comp Engn, IEEE Computat Intelligence Soc, Polish Chapter		machine learning; concept learning; similarity-based methods; k-nearest neighbors data classification	ALGORITHMS	In order to classify an unseen (query) vector q with the k-Nearest Neighbors method (k-NN) one computes a similarity function between q and training vectors in a database. In the basic variant of the k-NN algorithm the predicted class of q is estimated by taking the majority class of the q's k-nearest neighbors. Various similarity functions may be applied leading to different classification results. In this paper a heterogeneous similarity function is constructed out of different 1-component metrics by minimization of the number of classification errors the system makes on a training set. The HSFL-NN system, which has been introduced in this paper, on five tested datasets has given better results on unseen samples than the plain k-NN method with the optimally selected k parameter and the optimal homogeneous similarity function.	[Grudzinski, Karol] Kazimierz Wielki Univ, Dept Phys, PL-85072 Bydgoszcz, Poland	Grudzinski, K (reprint author), Kazimierz Wielki Univ, Dept Phys, Plac Weyssenhoffa 11, PL-85072 Bydgoszcz, Poland.	karol.grudzinski@wp.pl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DUCH W, 2001, KOMPUTEROWE SYSTEMY, P59; Duch W, 2002, ADV SOFT COMP, P13; DUCH W, 2000, CONTROL CYBERN, V29, P1; Duch W, 2001, P INT C NEUR INF PRO, P235; Duda R. O., 1973, PATTERN CLASSIFICATI; Fix E., 1951, 4 US AIR FORC SCH AV; Frank E., 2005, DATA MINING PRACTICA; GRUDZINSKI K, SBL SIMILARITY BASED; GRUDZINSKI K, 2002, THESIS N COPERNICUS; Grudzinski K, 2004, LECT NOTES ARTIF INT, V3070, P586; HAB SH, SPOLECZNA WYZSZA SZK; Ingber L., 1996, Control and Cybernetics, V25; *KNIM, KNIM KONST INF MIN; Mertz C.J., UCI REPOSITORY MACHI; Mierswa Ingo, 2006, P 12 ACM SIGKDD INT; NELDER JA, 1965, COMPUT J, V7, P308; Ortega J., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011679; SEBESTYEN G. S., 1962, DECISION MAKING PROC; STAHL A, THESIS U KAISERSLAUT; Weiss SM, 1991, COMPUTER SYSTEMS LEA	26	0	0	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-69572-1	LECT NOTES ARTIF INT			2008	5097						578	587				10	Computer Science, Artificial Intelligence; Mathematical & Computational Biology; Robotics; Imaging Science & Photographic Technology	Computer Science; Mathematical & Computational Biology; Robotics; Imaging Science & Photographic Technology	BHX32	WOS:000257188100056		
S	Angiulli, F; Basta, S		Bramer, M		Angiulli, Fabrizio; Basta, Stefano			Optimal subset selection for classification through SAT encodings	ARTIFICIAL INTELLIGENCE IN THEORY AND PRACTICE II	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	20th World Computer Congress	SEP 07-10, 2008	Milano, ITALY	IFIP TC 13			NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; RISK	In this work we propose a method for computing a minimum size training set consistent subset for the Nearest Neighbor rule (also said CNN problem) via SAT encodings. We introduce the SAT-CNN algorithm, which exploits a suitable encoding of the CNN problem in a sequence of SAT problems in order to exactly solve it, provided that enough computational resources are available. Comparison of SAT-CNN with well-known greedy methods shows that SAT-CNN is able to return a better solution. The proposed approach can be extended to several hard subset selection classification problems.	[Angiulli, Fabrizio] Univ Calabria, DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Angiulli, F (reprint author), Univ Calabria, DEIS, Via P Bucci 41C, I-87036 Arcavacata Di Rende, CS, Italy.						Angiulli F, 2007, IEEE T PATTERN ANAL, V29, P1746, DOI 10.1109/TPAMI.2007.1086; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; ANGIULLI F, 2005, 22 INT C MACH LEARN; Cook S. A., 1971, 3RD P ANN ACM S THEO, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARWICHE A, 2007, D153 UCLA COMP SCI D; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DAVIS M, 1962, COMMUN ACM, V5, P394, DOI 10.1145/368273.368557; Devi VS, 2002, PATTERN RECOGN, V35, P505; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75; Floyd S, 1995, MACH LEARN, V21, P269; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Johnson D.S., 1979, COMPUTERS INTRACTABI; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; MADIGAN C, 2001, 39 DES AUT C DAC; MANYA F, 2004, P 7 INT C THEOR APPL, P111; PROSSER P, 2002, P 5 INT C THEOR APPL; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SORENSSON N, 2005, INT C THEOR APPL SAT; STONE C, 1977, ANN STAT, V8, P1348; TOUSSAINT G, 2002, P S COMP STAT MONTR; Wilfong G, 1992, INT J COMPUT GEOM AP, V2, P383, DOI 10.1142/S0218195992000226; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	27	0	0	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736		978-0-387-09694-0	INT FED INFO PROC			2008	276						309	318				10	Computer Science, Artificial Intelligence	Computer Science	BIF11	WOS:000259037000030		
S	Jirina, M; Jirina, M		Kurkova, V; Neruda, R; Koutnik, J		Jirina, Marcel; Jirina, Marcel, Jr.			Correlation integral decomposition for classification	ARTIFICIAL NEURAL NETWORKS - ICANN 2008, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	18th International Conference on Artificial Neural Networks (ICANN 2008)	SEP 03-06, 2008	Prague, CZECH REPUBLIC				CORRELATION DIMENSION; ALGORITHM; SYSTEMS	In this paper we show that the correlation integral can be decomposed into functions each related to a. particular point of data space. For these functions. One can use similar polynomial approximations as used in the correlation integral. The essential difference is that the value of the exponent, which would Correspond to the correlation dimension, differs in accordance to the position of the point in question. Moreover, we show that the multiplicative constant represents the probability density estimation at that point. This finding is used for the construction of a classifier. Tests with some data sets from the Machine Learning Repository show that this classifier can he very effective.	[Jirina, Marcel] AS CR, Inst Comp Sci, Prague 18207 8, Czech Republic	Jirina, M (reprint author), AS CR, Inst Comp Sci, Vodarenskou Vezi 2, Prague 18207 8, Czech Republic.	marcel@cs.cas.cz; marcel@cs.cas.cz	Jirina, Marcel/B-2846-2014				Camastra F, 2001, NEURAL PROCESS LETT, V14, P27, DOI 10.1023/A:1011326007550; Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; DVORAK I, 1990, PHYS LETT A, V145, P225, DOI 10.1016/0375-9601(90)90355-R; FRIEDMANN JH, 1994, FLEXIBLE METRIC NEAR, P32; Gama J, 2003, THEOR COMPUT SCI, V292, P417, DOI 10.1016/S0304-3975(02)00179-2; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; Guerrero A, 2003, PHYS LETT A, V318, P373, DOI 10.1016/j.physleta.2003.09.023; LEV N, 2006, HAUSDORFF DIMENSION; Merz C., 1997, UCI REPOSITORY MACHI; OSBORNE AR, 1989, PHYSICA D, V35, P357, DOI 10.1016/0167-2789(89)90075-4; PAREDES R, 2006, IEEE T PATTERN ANAL, V20, P1100; TAKENS F, 1985, LECT NOTES MATH, V1125, P99	14	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-87558-1	LECT NOTES COMPUT SC			2008	5164						62	71				10	Computer Science, Theory & Methods	Computer Science	BIH71	WOS:000259567200007		
S	Richert, W; Niehorster, O; Klompmaker, F		Hinchey, M; Pagnoni, A; Rammig, FJ; Schmeck, H		Richert, Willi; Niehoerster, Oliver; Klompmaker, Florian			Guiding exploration by combining individual learning and imitation in societies of autonomous robots	BIOLOGICALLY-INSPIRED COLLABORATIVE COMPUTING	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	2nd International Conference on Biologically-Inspired Collaborative Computing held at the 20th World Computer Congress	SEP 08-09, 2008	Milan, ITALY	IFIP TC 10				Robots have a powerful means to drastically cut down the exploration space with imitation. However, as existing imitation approaches usually require repetitive demonstrations of the skill to learn in order to be useful, those are typically not applicable in groups of robots. In these settings usually each robot has its own task to accomplish and should not be disturbed by teaching others. As a result an imitating robot most of the time has only one observation of a specific skill from which it can learn. We present an approach that allows an individually learning robot to make use of such cases of sporadic imitation which is the normal case in groups of robots. Thereby, a robot can use imitation in order to guide its exploration efforts towards more rewarding areas in the exploration space. This is inspired by imitation often found in nature where animals or humans try to map observations into their own capability space. We show the feasibility by realistic simulation of Pioneer robots.	[Richert, Willi; Niehoerster, Oliver; Klompmaker, Florian] Univ Gesamthsch Paderborn, Intelligent Mobile Syst, LAB C, D-4790 Paderborn, Germany	Richert, W (reprint author), Univ Gesamthsch Paderborn, Intelligent Mobile Syst, LAB C, D-4790 Paderborn, Germany.						Alpaydin E., 2004, INTRO MACHINE LEARNI; Bellman R, 2003, DYNAMIC PROGRAMMING; Bengio Y., 1999, NEURAL COMPUTING SUR, V2, P129; Billard A., 2000, LEARNING MOTOR SKILL; Billard A, 2004, ROBOT AUTON SYST, V47, P69, DOI 10.1016/j.robot.2004.03.002; BORENSTEIN E, 2003, 2 INT S IM AN ART; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demiris J, 2002, FROM ANIM ANIMAT, P327; GASOULIS Y, 2002, P 2 IASTED INT C ART, P485; IJSPEERT AJ, 2002, INT C ROB AUT ICRA20; INAMURA T, 2001, P 2001 ICRA IEEE INT; INAMURA T, 2003, EXPT ROBOTICS 8; KOCHENDERFER MJ, 2006, THESIS U EDINBURGH; RICHERT W, 2008, IEEE INT C AUT AUT S; Sutton R.S., 1998, REINFORCEMENT LEARNI; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010	16	0	0	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736		978-0-387-09654-4	INT FED INFO PROC			2008	268						233	244				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIE74	WOS:000258995700021		
J	Hewett, R; Kijsanayothin, P				Hewett, Rattikorn; Kijsanayothin, Phongphun			Tumor classification ranking from microarray data	BMC GENOMICS			English	Article								Background: Gene expression profiles based on microarray data are recognized as potential diagnostic indices of cancer. Molecular tumor classifications resulted from these data and learning algorithms have advanced our understanding of genetic changes associated with cancer etiology and development. However, classifications are not always perfect and in such cases the classification rankings (likelihoods of correct class predictions) can be useful for directing further research (e.g., by deriving inferences about predictive indicators or prioritizing future experiments). Classification ranking is a challenging problem, particularly for microarray data, where there is a huge number of possible regulated genes with no known rating function. This study investigates the possibility of making tumor classification more informative by using a method for classification ranking that requires no additional ranking analysis and maintains relatively good classification accuracy. Results: Microarray data of 11 different types and subtypes of cancer were analyzed using MDR (Multi-Dimensional Ranker), a recently developed boosting-based ranking algorithm. The number of predictor genes in all of the resulting classification models was at most nine, a huge reduction from the more than 12 thousands genes in the majority of the expression samples. Compared to several other learning algorithms, MDR gives the greatest AUC (area under the ROC curve) for the classifications of prostate cancer, acute lymphoblastic leukemia (ALL) and four ALL subtypes: BCR-ABL, E2A-PBX1, MALL and TALL. SVM (Support Vector Machine) gives the highest AUC for the classifications of lung, lymphoma, and breast cancers, and two ALL subtypes: Hyperdiploid >50 and TEL-AML1. MDR gives highly competitive results, producing the highest average AUC, 91.01%, and an average overall accuracy of 90.01% for cancer expression analysis. Conclusion: Using the classification rankings from MDR is a simple technique for obtaining effective and informative tumor classifications from cancer gene expression data. Further interpretation of the results obtained from MDR is required. MDR can also be used directly as a simple feature selection mechanism to identify genes relevant to tumor classification. MDR may be applicable to many other classification problems for microarray data.	[Hewett, Rattikorn; Kijsanayothin, Phongphun] Texas Tech Univ, Dept Comp Sci, Abilene, TX 79601 USA	Hewett, R (reprint author), Texas Tech Univ, Dept Comp Sci, Abilene, TX 79601 USA.	Rattikorn.Hewett@cs.ttu.edu; kphongph@gmail.com					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Burges CJC, 1997, ADV NEUR IN, V9, P375; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; GREEN DM, 1989, SIGNAL DETECTION THE; GROSS P, 2006, P 21 NAT C ART INT 8; HUANG J, 2005, USING AUC ACCURACY E, P17; LI J, 2007, KENT RIDGE BIOMEDICA; Li J, 2003, BIOINFORMATICS S2, V19, pii93; LI J, 2003, P 3 IEEE INT C DAT M, P585; LONG, 2005, MARTINGALE BOOSTING; Pedersen A G, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P226; Quilan J., 1993, C4 5 PROGRAMS MACHIN; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Witten Ian H., 2005, PRACTICAL MACHINE LE, V2nd; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	18	9	10	2	2	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics		2008	9			2					S21	10.1186/1471-2164-9-S2-S21		11	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	V92JQ	WOS:000206244200022	18831787	
S	Cai, YD; Zhou, GP			IEEE	Cai, Yu-Dong; Zhou, Guo-Ping			Predicting protein-protein interactions with pseudo amino acid composition	BMEI 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS, VOL 1	International Conference on Biomedical Engineering and Informatics		English	Proceedings Paper	1st International Conference on Biomedical Engineering and Informatics	MAY 27-30, 2008	Sanya, PEOPLES R CHINA	Tianjin Univ Technol, IEEE Comp Soc		protein network; network biology; fruitfly; pseudo-amino acid composition; NN-PseAA predictor; genomic scale	STRUCTURAL CLASS PREDICTION; SECONDARY STRUCTURE-CONTENT; SUBCELLULAR LOCATION; FOLDING TYPES; DOMAIN; CDK5	Given two proteins in a living system, can we predict whether they are interacting with each other merely according to the information of their sequences? This is an interesting problem because knowledge of protein-protein interactions may be applied to protein subunit aggregation, to computer-aided drug design, and to fundamental problems of cellular signalling and expression. With the explosion of newly-found protein sequences in the post-genomic era, its importance has become self-evident, and the challenge to address it even more urgent. Based on the pseudo amino acid composition (Chou, K.C.: PROTEINS: Structure, Function, and Genetics, 43: 246255, 2001) approach and nearest neighbor rule, a predictor called "NN-PseAA" classifier was developed to deal with this problem. As a showcase, prediction was performed on 8,797 fruitfly protein pairs. To avoid redundancy and homology bias, none of the protein pairs investigated has >= 25% sequence identity with any other. The overall success rate obtained by jackknife cross-validation for such a stringent dataset was 73.74%, indicating a quite promising sign of the new approach in stimulating the development of this important area and other related areas.	[Cai, Yu-Dong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Shanghai 200031, Peoples R China	Cai, YD (reprint author), Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, 320 Yue Yang Rd, Shanghai 200031, Peoples R China.	cyd@picb.ac.cn; gzhou@bidmc.harvard.edu					Ben-Hur A, 2005, BIOINFORMATICS, V21, pI38, DOI 10.1093/bioinformatics/bti1016; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2005, J PROTEOME RES, V4, P1681, DOI 10.1021/pr050145a; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 1999, BIOCHEM BIOPH RES CO, V259, P420, DOI 10.1006/bbrc.1999.0792; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou K.C., 2002, GENE CLONING EXPRESS, P57; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Feng KY, 2005, BIOCHEM BIOPH RES CO, V334, P213, DOI 10.1016/j.bbrc.2005.06.075; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Giot L, 2003, SCIENCE, V302, P1727, DOI 10.1126/science.1090289; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kanehisa M, 2004, NUCLEIC ACIDS RES, V32, pD277, DOI 10.1093/nar/gkh063; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Luo RY, 2002, EUR J BIOCHEM, V269, P4219, DOI 10.1046/j.1432-1033.2002.03115.x; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Vollert CS, 2004, MOL CELL PROTEOMICS, V3, P1053, DOI 10.1074/mcp.M400081-MCP200; Wang M, 2005, J THEOR BIOL, V232, P7, DOI 10.1016/j.jtbi.2004.07.023; YAN C, 2004, BIOINFORMATICS, V20, P1371; Zhang JW, 2002, PROTEINS, V48, P447, DOI 10.1002/prot.10173; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071	36	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1948-2914		978-0-7695-3118-2	INT CONF BIOMED			2008							158	163		10.1109/BMEI.2008.11		6	Engineering, Biomedical; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BHW79	WOS:000257096000031		
B	Bai, G; Zhu, Y; Ding, ZY		Li, D; Deng, G		Bai, Gang; Zhu, Yi; Ding, Zongyao			A hierarchical face recognition method based on Local Binary Pattern	CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS			English	Proceedings Paper	1st International Congress on Image and Signal Processing	MAY 27-30, 2008	Sanya, PEOPLES R CHINA	Tianjin Univ Technol		hierarchical face recognition; Local Binary Pattern; Multi-Expert Intelligent Decision System; facial pose estimation	CLASSIFICATION	This paper proposes a hierarchical method to deal with the multi-pose face recognition problem. The Local Binary Pattern (LBP) feature is used as the uniform feature throughout the two-hierarchy process. Also, a new method, named Multi-expert Intelligent Decision System, is proposed to improve the performance of the pose estimation process. According to the experiments, the method is proved to be efficient and robust.	[Bai, Gang; Zhu, Yi; Ding, Zongyao] Nankai Univ, Coll Informat & Technol, Tianjin 300071, Peoples R China	Bai, G (reprint author), Nankai Univ, Coll Informat & Technol, Tianjin 300071, Peoples R China.	baigang@nankai.edu.cn; seaeagle@mail.nankai.edu.cn; dzy@mail.nankai.edu.cn					AHONEN T, 2006, IEEE T PATTERN ANAL, P2037; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HU YL, 2005, J COMPUTER RES DEV A, P622; Li S. Z., 2005, HDB FACE RECOGNITION; Liao S., 2007, P IAPR IEEE INT C BI, P828; NG KC, 1990, P 1990 ACM ANN C FEB, P351, DOI 10.1145/100348.100401; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; WU JW, PATTERN RECOGNITION, P1138	9	3	3	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3119-9				2008							610	614		10.1109/CISP.2008.520		5	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BIE07	WOS:000258872400119		
B	Bo, SK; Ding, L; Jing, YJ		Li, D; Deng, G		Bo, Shukui; Ding, Lin; Jing, Yongju			On combining region-growing with non-parametric clustering for color image segmentation	CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS			English	Proceedings Paper	1st International Congress on Image and Signal Processing	MAY 27-30, 2008	Sanya, PEOPLES R CHINA	Tianjin Univ Technol				Region-based and clustering-based techniques are two of the most important segmentation methods, and both of them have their advantages and disadvantages. In this paper, we present a color image segmentation method combining region-growing with non-parametric clustering technique. First, a bottom-up region-merging technique is used to yield an intermediate result. This procedure takes into account simultaneously the spectral properties of pixels as well as their spatial information, which is not fully utilized in clustering technique. Second, a clustering technique based on mean shift algorithm is used to cluster similar image objects in the intermediate result. In the mean shift procedure, we adopt adaptive bandwidths instead of a single one over the entire feature space. The two steps of image segmentation are performed in an unsupervised way. The validity of the proposed method is verified on various color images.	[Bo, Shukui] Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou, Peoples R China	Bo, SK (reprint author), Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou, Peoples R China.						[Anonymous], 2009, BERKELEY SEGMENTATIO; Baatz M., 2004, ECOGNITION USER GUID; Baatz M, 2000, ANGEW GEOGRAPHISCHE; BO SK, LNCS, V4489; Comaniciu D., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Macaire L, 2006, COMPUT VIS IMAGE UND, V102, P105, DOI 10.1016/j.cviu.2005.12.001; Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015	10	2	2	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3119-9				2008							715	719				5	Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Engineering; Imaging Science & Photographic Technology	BIE09	WOS:000258872900143		
S	Papa, JP; Falcao, AX; Suzuki, CTN; Mascarenhas, NDA		Brimkov, VE; Barneva, RP; Hauptman, HA		Papa, Joao P.; Falcao, Alexandre X.; Suzuki, Celso. T. N.; Mascarenhas, Nelson D. A.			A discrete approach for supervised pattern recognition	COMBINATORIAL IMAGE ANALYSIS	Lecture Notes in Computer Science		English	Proceedings Paper	12th International Workshop on Combinatorial Image Analysis	APR 07-09, 2008	Buffalo, NY			supervised learning; optimum-path forest; image foresting transform; pattern recognition; graph-search algorithms	IMAGE SEGMENTATION; ALGORITHMS	We present an approach for supervised pattern recognition based on combinatorial analysis of optimum paths from key samples (prototypes), which creates a discrete optimal partition of the feature space such that any unknown sample can be classified according to this partition. A training set is interpreted as a complete graph with at least one prototype in each class. They compete among themselves and each prototype defines an optimum-path tree, whose nodes are the samples more strongly connected to it than to any other. The result is an optimum-path forest in the training set. A test sample is assigned to the class of the prototype which offers it the optimum path in the forest. The classifier is designed to achieve zero classification errors in the training set, without over-fitting, and to learn from its errors. A comparison with several datasets shows the advantages of the method in accuracy and efficiency with respect to support vector machines.	[Papa, Joao P.; Falcao, Alexandre X.; Suzuki, Celso. T. N.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil	Papa, JP (reprint author), Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1216, Campinas, SP, Brazil.	papa.joaopaulo@gmail.com; alexandre.falcao@gmail.com; celso.suzuki@gmail.com; nelson@dc.ufscar.br	Falcao, Alexandre/F-8361-2012				Allene C., 2007, MATH MORPHOLOGY ITS, P253; Asuncion A., 2007, UCI MACHINE LEARNING; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433; Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; Chang C.C., 2001, LIBSVM LIB SUPPORT V; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Collobert R., 2004, P 21 INT C MACH LEAR, P23; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Haykin S., 1994, NEURAL NETWORKS COMP; Jain A. K., 1988, ALGORITHMS CLUSTERIN; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Lotufo R. A., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), DOI 10.1109/SIBGRA.2000.883922; Martinez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074; Montoya-Zegarra JA, 2007, LECT NOTES COMPUT SC, V4842, P193; Panda N., 2006, P 23 INT C MACH LEAR, P681, DOI 10.1145/1143844.1143930; Papa J., 2007, MATH MORPHOLOGY ITS, P337; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Reyzin L., 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; ROCHA LM, 2008, IN PRESS 8 INT WORKS; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tang B., 2006, P 23 INT C MACH LEAR, P921, DOI 10.1145/1143844.1143960; Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; COREL COREL STOCK PH	30	11	11	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-78274-2	LECT NOTES COMPUT SC			2008	4958						136	147				12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BHN76	WOS:000254600100012		
J	Jeng, SL; Huang, YT				Jeng, Shuen-Lin; Huang, Ya-Ti			Time series classification based on spectral analysis	COMMUNICATIONS IN STATISTICS-SIMULATION AND COMPUTATION			English	Article						classification; k-nearest-neighbor; linear discriminant analysis; spectral analysis; time series		For time series data with obvious periodicity (e.g., electric motor systems and cardiac monitor) or vague periodicity (e.g., earthquake and explosion, speech, and stock data), frequency-based techniques using the spectral analysis can usually capture the features of the series. By this approach, we are able not only to reduce the data dimensions into frequency domain but also utilize these frequencies by general classification methods such as linear discriminant analysis (LDA) and k-nearest-neighbor (KNN) to classify the time series. This is a combination of two classical approaches. However, there is a difficulty in using LDA and KNN in frequency domain due to excessive dimensions of data. We overcome the obstacle by using Singular Value Decomposition to select essential frequencies. Two data sets are used to illustrate our approach. The classification error rates of our simple approach are comparable to those of several more complicated methods.	[Jeng, Shuen-Lin] Natl Cheng Kung Univ, Dept Stat, Tainan 701, Taiwan; [Huang, Ya-Ti] Tunghai Univ, Dept Stat, Taichung 40704, Taiwan	Jeng, SL (reprint author), Natl Cheng Kung Univ, Dept Stat, Tainan 701, Taiwan.	sljeng@mail.ncku.edu.tw					Box G., 1976, TIME SERIES ANAL; Box G. E. P., 1994, TIME SERIES ANAL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMERDASH NA, 1997, P NAV S EL MACH NEWP, P235; Demmel J., 1997, APPL NUMERICAL LINEA; Fisher RA, 1938, ANN EUGENIC, V8, P376; Gardner W. A., 1988, STAT SPECTRAL ANAL N; Gentle J. E., 1998, NUMERICAL LINEAR ALG, V1st; Giudici P., 2003, APPL DATA MINING STA; Harville D. A., 1997, MATRIX ALGEBRA STAT; Hastie T, 2001, ELEMENTS STAT LEARNI; Huang HY, 2004, J AM STAT ASSOC, V99, P763, DOI 10.1198/016214504000001105; KAKIZAWA Y, 1998, J AM STAT ASSOC, V93, P763; Lin C.-T., 1996, NEURAL FUZZY SYSTEMS; Povinelli RJ, 2004, IEEE T KNOWL DATA EN, V16, P779, DOI 10.1109/TKDE.2004.17; Shumway RH, 1988, APPL STAT TIME SERIE; Wei W, 1989, TIME SERIES ANAL UNI; ZIVOT E, 2002, MODELLING FIN TIMES	18	3	3	1	1	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	0361-0918			COMMUN STAT-SIMUL C	Commun. Stat.-Simul. Comput.		2008	37	1					132	142		10.1080/03610910701723971		11	Statistics & Probability	Mathematics	250SS	WOS:000252321400010		
S	Hendrickx, I; Hoste, V; Daelemans, W		Gelbukh, A		Hendrickx, Iris; Hoste, Veronique; Daelemans, Walter			Semantic and syntactic features for Dutch coreference resolution	COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	9th International Conference on Intelligent Text Processing and Computational Linguistics	FEB 17-23, 2008	Haifa, ISRAEL	Computat Linguist Grp, Univ Haifa, Caesarea Edmond Benjamin de Rothschild Fdn Inst Interdisciplinary Applicat Comp Sci	Univ Haifa			We investigate the effect of encoding additional semantic and syntactic information sources in a classification-based machine learning approach to the task of coreference resolution for Dutch. We experiment both with a memory-based learning approach and a maximum entropy modeling method. As an alternative to using external lexical resources, such as the low-coverage Dutch EuroWordNet, we evaluate the effect of automatically generated semantic clusters as information source. We compare these clusters, which group together semantically similar nouns, to two semantic features based on EuroWordNet encoding synonym and hypernym relations between nouns. The syntactic function of the anaphor and antecedent in the sentence can be an important clue for resolving coreferential relations. As baseline approach, we encode syntactic information as predicted by a memory-based shallow parser in a set of features. We contrast these shallow parse based features with features encoding richer syntactic information from a dependency parser. We show that using both the additional semantic information and syntactic information lead to small but significant performance improvement of our coreference resolution approach.	[Hendrickx, Iris; Daelemans, Walter] Univ Antwerp, CNTS Language Technol Grp, B-2020 Antwerp, Belgium	Hendrickx, I (reprint author), Univ Antwerp, CNTS Language Technol Grp, Prins Str 13, B-2020 Antwerp, Belgium.		Daelemans, Walter/N-5785-2014				Berger A. L., 1996, COMPUTATIONAL LINGUI, V22; BOUMA G, 2001, COMPUTATIONAL LINGUI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Culotta A., 2007, P NAACL HLT, P81; DAELEMANS A, 2004, ILK0402 TILB U; Daelemans W, 2003, LECT NOTES ARTIF INT, V2837, P84; DAELEMANS W, 2003, 0313 TILB U; Fellbaum Christiane, 1998, WORDNET ELECT LEXICA; Harabagiu S., 2001, P 2 M N AM CHAPT ASS, P55; Hoste V., 2006, 5 INT C LANG RES EV; Ji H., 2005, P HUM LANG TECHN C C, P17, DOI 10.3115/1220575.1220578; Kehler A., 2004, P HLT NAACL, P289; Lin D., 1998, COLING ACL, P768; LUO X, 2005, P HUM LANG TECHN C C, P660, DOI 10.3115/1220575.1220658; Markert K, 2005, COMPUT LINGUIST, V31, P367, DOI 10.1162/089120105774321064; McCarthy John J., 1996, THESIS U MASSACHUSET; Mitkov R., 1998, P 36 ANN M ASS COMP, P869; Ng V, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P55; NG V, 2007, P 45 ANN M ASS COMP, P536; NG V, 2007, P 20 INT JOINT C ART, P1689; Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102; Poesio M., 2004, P 42 ANN M ASS COMP, P143, DOI 10.3115/1218955.1218974; Ponzetto Simone Paolo, 2006, P HUM LANG TECHN C N, P192, DOI 10.3115/1220835.1220860; Rich E., 1988, P 2 C APPL NAT LANG, P18, DOI DOI 10.3115/974235.974239; Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653; TJONG KS, 2004, COMPUTATIONAL LINGUI, P109; TJONG KS, 2002, P CONLL 2002 TAIP TA, P203; VANDECRUYS T, 2005, P 16 COMP LING NETH, P17; Vilain M., 1995, P 6 MESS UND C MUC 6, P45, DOI 10.3115/1072399.1072405; VOSSEN P, 1998, EURO WORDNET MULTILI; Yang X., 2007, P 45 ANN M ASS COMP, P528; YANG XF, 2006, P 21 INT C COMP LING, P41, DOI 10.3115/1220175.1220181; Zhang Le, 2004, MAXIMUM ENTROPY MODE	33	2	2	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-78134-9	LECT NOTES COMPUT SC			2008	4919						351	361				11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BHJ77	WOS:000253658200030		
J	Caulier, Y; Bourennane, S				Caulier, Y.; Bourennane, S.			An Image Content Description Technique for the Inspection of Specular Objects	EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING			English	Article							FEATURE-SELECTION; PATTERN-RECOGNITION; FRINGE PATTERNS; CLASSIFICATION; ENVIRONMENTS; SURFACES; FEATURES; TEXTURE	This paper proposed an image content description method within the context of specular surface inspection. Such a method is based on a preliminary research concerning the generation of specific stripe patterns for the visual enhancement of defective surface parts of cylindrical specular objects. The goal of this paper is to address the stripe pattern interpretation within a general approach. For this purpose, different pattern recognition processes, consisting not only of the combination of different image segmentation, feature retrieval, and classification, but also of feature combination and selection, will be considered. Three top-down and one bottom-up approaches are evaluated for retrieving the most appropriate feature sets in terms of highest classification rates. It will be demonstrated that following a combination and appropriate selection of these feature sets, even better rates can be reached. With only half of the initial features, an increase of more than 2% is observable. Copyright (C) 2008 Y. Caulier and S. Bourennane.	[Caulier, Y.] Fraunhofer Inst, Image Proc & Med Engn Dept, D-91058 Erlangen, Germany; [Bourennane, S.] Ecole Cent Marseille, Fresnel Inst, Multidimens Signal Grp, F-13451 Marseille, France	Caulier, Y (reprint author), Fraunhofer Inst, Image Proc & Med Engn Dept, D-91058 Erlangen, Germany.	cau@iis.fraunhofer.de	Bourennane, Salah/F-2928-2010		Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS)	This work was supported by the Bavarian Research Foundation (Bayerische Forschungsstiftung-BFS).	ASADA M, 1988, IEEE T PATTERN ANAL, V10, P749, DOI 10.1109/34.6787; CAULIER Y, NEUES SYSTEM SCHNELL; Caulier Y, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/237459; CAULIER Y, 2008, J OPTICAL ENG, V47; CHEN YQ, 1995, PATTERN RECOGN, V28, P537, DOI 10.1016/0031-3203(94)00116-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Delcroix G, 2001, J ELECTRON IMAGING, V10, P196, DOI 10.1117/1.1314333; DJOUADI A, 1990, IEEE T PATTERN ANAL, V12, P92, DOI 10.1109/34.41388; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Fisher R.B., 1996, IMAGE TECHNOLOGY ADV, P385; Gutierrez-Lobos K, 2002, BMC PSYCHIATRY, V2, DOI 10.1186/1471-244X-2-3; Hall M. A., 1999, THESIS U WAIKATO HAM; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Hausler G., 1999, Patent DE, Patent No. [19944354 A1, 19944354]; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Juptner WP, 1994, P SOC PHOTO-OPT INS, V2342, P16; KAMMEL S, 2004, THESIS U KARLSRUHE K; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KRUGER S, 2000, MACHINE VISION APP 8, V3966, P145; Kruger S, 2001, J ELECTRON IMAGING, V10, P228, DOI 10.1117/1.1318908; LAKSHMINARASIMHAN AL, 1975, IEEE T COMPUT, V24, P948, DOI 10.1109/T-C.1975.224346; Leon FP, 1997, P SOC PHOTO-OPT INS, V3208, P394; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; LIU XM, 2003, P 2 INT C MACH LEARN, P2399; MARINO P, 1999, P 25 ANN C IEEE IND, V3, P1330; MATERKA A, 1998, B11 TU LODZ I EL, V18, P90; MUCCIARD.AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P208, DOI 10.1109/70.54736; Niemann H, 2003, KLASSIFIKATION MUSTE, V2nd; PAAKKARI J, 1998, THESIS U OULU OULU; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pernkopf F., 2004, P 17 INT C PATT REC, V3, P223; PETZ M, 2002, OPTICAL 3D MEASUREME; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Reindl I, 2007, P IEEE INSTR MEAS TE, P1; SEULIN R, 2001, P 5 INT C QUAL CONTR; Talavera L., 2000, Intelligent Data Analysis, V4; Tibshirani R, 1993, INTRO BOOTSTRAP; Tuceyran M., 1998, HDB PATTERN RECOGNIT, V2nd, P207; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; WAGNER T, 1999, AUTOMATISCHE KONFIGU; WEISS SM, 1991, IEEE T PATTERN ANAL, V13, P285, DOI 10.1109/34.75516; Weska J. S., 1978, COMPUT GRAPHICS IMAG, V7, P259; Witten I, 2005, DATA MINING; ZHI H, 1992, P 11 INT C PATT REC, V3, P105	50	2	2	0	4	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1687-6180			EURASIP J ADV SIG PR	EURASIP J. Adv. Signal Process.		2008									195263	10.1155/2008/195263		14	Engineering, Electrical & Electronic	Engineering	381XF	WOS:000261568500001		
J	Gomolinska, A				Gomolinska, Anna			Satisfiability of Formulas from the Standpoint of Object Classification: The RST Approach	FUNDAMENTA INFORMATICAE			English	Article; Proceedings Paper	Concurrency Specification and Programming Workshop	SEP 27-29, 2007	Lagow, POLAND			satisfiability of formulas; valuation; object classification; Pawlak's information system; descriptor language; analogy-based reasoning	ROUGH SET APPROACH; APPROXIMATION SPACES; FUZZY LOGIC; PROPOSITIONAL CALCULI; SIMILARITY; MODEL; INDUCTION; SYSTEMS; RULES	In this article we discuss judgment of satisfiability of formulas of it knowledge representation language as an object classification task. Our Viewpoint is that of the rough set theory (RST). and the descriptor language for Pawlak's information systems of a basic kind is taken as the study case. We show how certain analogy-based methods can be employed to judge satisfiability of formulas of that language.	Bialystok Univ, Dept Math, PL-15267 Bialystok, Poland	Gomolinska, A (reprint author), Bialystok Univ, Dept Math, Akad 2, PL-15267 Bialystok, Poland.	anna.gom@math.uwb.edu.pl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Albatineh AN, 2006, J CLASSIF, V23, P301, DOI 10.1007/s00357-006-0017-z; AAMODT A, 1994, AI COMMUN, V7, P39; BAZAN J, 2006, T ROUGH SETS 5 LNCS, V4100, P39, DOI 10.1007/11847465_3; BAZAN JG, 1998, LNCS, V1424, P521; BAZAN JG, 1998, THESIS WARSAW U; Belnap N., 1977, MODERN USES MULTIPLE, P8; Bolc L., 1992, MANY VALUED LOGICS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDA RO, 1973, PATTERN CLASSFICATIO; Getoor L., 2007, INTRO STAT RELATIONA; GOMOLINSKA A, 2007, P WORKSH CONC SPEC P, P212; Gomolinska A, 2004, FUND INFORM, V60, P159; Gomolinska A, 2005, FUND INFORM, V67, P77; Gomolinska A, 2007, FUND INFORM, V79, P319; Greco S, 2006, LECT NOTES ARTIF INT, V3885, P7; Grzymala-Busse J. W., 1992, HDB APPL ADV ROUGH S, P3; GRZYMALABUSSE JW, 2005, DATA MIN KNOWL DISC, P255; Guillet F, 2007, QUALITY MEASURES DAT; Honko P, 2007, LECT NOTES ARTIF INT, V4585, P553, DOI 10.1007/978-3-540-73451-2_58; Kleene S. C., 1952, INTRO METAMATHEMATIC; Lavrae N., 2001, RELATIONAL DATA MINI; Lukasiewicz J., 1930, CR HEBD ACAD SCI, V23, p[51, 144]; Lukasiewicz J., 1920, RUCH FILOZOFICZNY, V5, P170; MICHALSKI RS, 1993, MACH LEARN, V11, P111, DOI 10.1007/BF00993074; Mitchell Melanie, 2001, P335; MITCHELL M, 1993, ANALOG MAKING PERCEP; NGUYEN HS, 1997, THESIS WARSAW U; NGUYEN HS, 2005, LECT NOTES COMPUTER, V3518, P312; NGUYEN HS, 1998, MANY VALUED LOGIC, P451; OSHERSON DN, 1990, PSYCHOL REV, V97, P185, DOI 10.1037/0033-295X.97.2.185; PAVELKA J, 1979, Z MATH LOGIK, V25, P45, DOI 10.1002/malq.19790250304; PAVELKA J, 1979, Z MATH LOGIK, V25, P447, DOI 10.1002/malq.19790252510; PAVELKA J, 1979, Z MATH LOGIK, V25, P119, DOI 10.1002/malq.19790250706; PAWLAK Z, 1994, EUR J OPER RES, V72, P443, DOI 10.1016/0377-2217(94)90415-4; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; PAWLAK Z, 1981, INFORM SYST, V6, P205, DOI 10.1016/0306-4379(81)90023-5; Pawlak Z., 1987, B POLISH ACAD SCI TE, V35, P253; Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003; Pawlak Z., 1991, ROUGH SETS THEORETIC; Pawlak Z, 2005, LECT NOTES COMPUT SC, V3700, P1; PAWLAK Z, 1981, RES REPORT CC PAS, V429; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Peters J.F., 2007, P IEEE S SER FDN COM, P1; Peters JF, 2005, ADV SOFT COMP, P13, DOI 10.1007/3-540-32370-8_2; Peters JF, 2007, FUND INFORM, V79, P497; POGORZELSKI WA, 1994, NOTIONS THEOREMS ELE; Rauszer C. M., 1994, LECT NOTES ARTIF INT, V808, P161; Rescher N., 1969, MANY VALUED LOGIC; Rosser J.B., 1958, MANY VALUED LOGICS; Skowron A., 1995, SOFT COMPUTING SIMUL, P18; Skowron A, 2006, FUND INFORM, V72, P363; Skowron A., 1996, Fundamenta Informaticae, V27; Skowron A, 2005, LECT NOTES COMPUT SC, V3400, P175; Slowinski R., 1997, ADV MACHINE INTELLIG, P17; Slowinski R, 2007, LECT NOTES ARTIF INT, V4585, P5, DOI 10.1007/978-3-540-73451-2_2; STEFANOWSKI J, 2001, ALGORITHMS DECISION, V361; STEFANOWSKI J, 1998, MANY VALUED LOGIC, P500; Stepaniuk J, 2004, FUND INFORM, V61, P139; STEPANIUK J, 2007, T ROUGH SETS 6 J SUB, V4374, P351, DOI 10.1007/978-3-540-71200-8_19; SURAJ Z, 1972, FUNDAMENTA INFORM, V72, P393; Synak P, 2005, FUND INFORM, V67, P249; VONLUXBURG U, 2004, THESIS TU BERLIN; Wojna A, 2005, LECT NOTES COMPUT SC, V3700, P277; Wolski M, 2007, LECT NOTES ARTIF INT, V4585, P192, DOI 10.1007/978-3-540-73451-2_21; WROBLEWSKI J, 2002, THESIS WARSAW U; Yao Y., 1997, ROUGH SETS DATA MINI, P47; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575; Zadeh L. A., 1975, SYNTHESE, V30, P407, DOI DOI 10.1007/BF00485052; Ziarko W, 2001, COMPUT INTELL, V17, P593, DOI 10.1111/0824-7935.00165; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	72	1	1	2	2	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968			FUND INFORM	Fundam. Inform.		2008	85	1-4					139	153				15	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	358PL	WOS:000259929900011		
B	Gruhn, V; Richter, T			IEEE Comp Soc	Gruhn, Volker; Richter, Thomas			A General Model of Mobile Environments: Simulation Support for Strategic Management Decisions	GCC 2008: Seventh International Conference on Grid and Cooperative Computing, Proceedings			English	Proceedings Paper	7th International Conference on Grid and Cooperative Computing	OCT 24-26, 2008	Shenzhen, PEOPLES R CHINA	Chinese Acad Sci, Shenzhen Inst Adv Technol, Dawning Informat Ind Co Ltd, Chinese Natl Grid, European & Chinese Cooperat Grid, Chinese Acad Sci, Chinese Acad Engn		Mobile Environments; Enterprise Simulation; Workforce Management; Resource Modeling; Colored Petri Nets	ARCHITECTURE; WORKFLOW	Since the ability of Workflorce Management Systems to handle mobility induced challenges of mobile environments like data-communication cut-offs, reduced network bandwidth, and security concerns improved recently; the optimization efforts of mobile enterprises increasingly focus on the organizational setup of their mobile environment. This includes issues like, e.g., the dimension and staffing of regional subdivisions, qualification balance of the workforce, and resource allocation strategies. While this multitude of possible adjustment parameters for optimization prevents from the analytical prediction. of organizational change efforts, simulation is a promising approach to analyze mobile environments and their change. In this work we present a formal model representing a generalization of mobile environments. This model can be utilized to examine the cost situation and performance of both real mobile enterprises and projected future development scenarios of such enterprises. The model is developed using colored petri nets (CPN) and the software suite CPN Tools. We show that our model is capable of predicting the outcomes of organizational change projects by the utilization of simulation and present a validation of our model based on real-world data of a German gas and power supply.	[Gruhn, Volker; Richter, Thomas] Univ Leipzig, Dept Comp Sci, Chair Appl Telemat E Business, D-04109 Leipzig, Germany	Gruhn, V (reprint author), Univ Leipzig, Dept Comp Sci, Chair Appl Telemat E Business, Klostergasse 3, D-04109 Leipzig, Germany.	gruhn@ebus.informatik.uni-leipzig.de; richter@ebus.informatik.uni-leipzig.de					AGUILAR M, 1999, P 1999 WINT SIM C WS, V2, P1383, DOI 10.1145/324898.325282; Becker C, 2005, PERS UBIQUIT COMPUT, V9, P20, DOI 10.1007/s00779-004-0270-2; BERIO G, 2005, 16 IFAC WORLD C; BERIO G, 2004, P EMOI WORKSH JOINT; Bolcer GA, 2000, IEEE INTERNET COMPUT, V4, P46, DOI 10.1109/4236.845390; BORREGUERO FJM, 2005, P INT C MOB BUS ICMB, P274; BOWDEN SL, 2004, ECPPM 2004 EWORK EBU, P491; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVREEDE GJ, 2003, SIMULATION, P43; Doumeingts G., 1992, GIM GRAI INTEGRATED; Dustdar S, 2003, J SYST ARCHITECT, V49, P457, DOI 10.1016/S1383-7621(03)00092-4; Giaglis GM, 1999, INT J INFORM MANAGE, V19, P219, DOI 10.1016/S0268-4012(99)00015-8; GRUHN V, 2007, P 3 INT C INT ENT SO; GRUHN V, 2006, 1 INT WORKSH MOB COL; *I I TASK FORC ARC, 1999, GERAM GEN ENT REF AR; Innes D., 2005, P INT C MOB BUS ICMB, P49; JENSEN K, 1996, COLOURED PETRINETS B, V1; KADYTE V, 2005, P INT C MOB BUS ICMB, P159; Kakihara M., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.2002.994088; Kosanke K, 1999, COMPUT IND, V40, P83, DOI 10.1016/S0166-3615(99)00016-0; Kumar A., 2002, J MANAGE INFORM SYST, V18, P157; Lesaint D, 2003, BT TECHNOL J, V21, P23, DOI 10.1023/A:1027315016892; Luff P, 1998, P 1998 ACM C COMP SU, P305, DOI 10.1145/289444; MAY A, 2005, MOBILEHCI 05, P255; Melao N, 2003, J OPER RES SOC, V54, P2, DOI 10.1057/palgrave.jors.2601477; Nah FFH, 2005, COMMUN ACM, V48, P85, DOI 10.1145/1042091.1042095; NETJES M, 2005, 6 WORKSH TUT PRACT U; Pesic Maja, 2007, International Journal on Software Tools for Technology Transfer, V9, DOI 10.1007/s10009-007-0036-z; PICA D, 2004, P 37 ANN HAW INT C S; POPOVIC A, 2006, INTERDISCIPLINARY J, P1; RAMAMPIARO H, 2003, APPL INFORMATICS, P1153; ROMAN GC, 2000, FUTURE SOFTWARE ENG, P243; ROMAN H, 2007, EWDAS MAGAZIN ENERGI, V106, P56; Russell N, 2005, LECT NOTES COMPUT SC, V3520, P216; Vernadat F, 2002, INT J PROD RES, V40, P4309, DOI 10.1080/00207540210159626; VUKSIC VB, 2003, SIMULATION, V78, P731; VUKSIC VB, 2005, SYSTEMS INTEGRATION, P29; WILLIAMS TJ, 1994, COMPUT IND, V24, P141, DOI 10.1016/0166-3615(94)90017-5; Wilson A.M., 1998, MANAG SERV QUAL, V8, P414, DOI 10.1108/09604529810235123	39	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3449-7				2008							753	764		10.1109/GCC.2008.25		12	Computer Science, Theory & Methods	Computer Science	BIT11	WOS:000262480400112		
B	Shang, WQ; Dong, HB; Zhu, HB; Wang, YB				Shang, Wenqian; Dong, Hongbin; Zhu, Haibin; Wang, Yongbin			A Novel Feature Weight Algorithm for Text Categorization	IEEE NLP-KE 2008: PROCEEDINGS OF INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING			English	Proceedings Paper	IEEE International Conference on Natural Language Processing and Knowledge Engineering	OCT 19-22, 2008	Beijing, PEOPLES R CHINA	IEEE				With the development of the web, large numbers of documents are put onto the Internet. More and more digital libraries, news sources and inner data of companies are available. Automatic text categorization becomes more and more important for dealing with massive data. However, text preprocessing is still the bottleneck of text categorization based on Vector Space Model (VSM). The result of text preprocessing directly affects the performance and precision of categorization. Moreover, feature selection and feature weight become the major obstacles of text preprocessing. In this paper, we mainly focus on feature weight. We present a novel feature weight algorithm-TF-Gini that can improve the categorization peformance significantly. The experiment results verify the effectiveness of this algorithm.			shangwenqian@hotmail.com; donghongbin@gmail.com; Haibinz@npissingu.ca					APTE C, 1998, P C AUT LEARN DISC W, P487; Breiman L., 1984, CLASSIFICATION REGRE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Debole F., 2003, SAC 03, P784; Gupta S. K., 1998, Proceedings Ninth International Workshop on Database and Expert Systems Applications (Cat. No.98EX130), DOI 10.1109/DEXA.1998.707410; JOACHIMS T, 1997, MACH LEARN, P143; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; [李荣陆 Li Ronglu], 2005, [计算机研究与发展, Journal of Computer Research and Development], V42, P94, DOI 10.1360/crad20050113; LU Y, 2002, J COMPUTER RES DEV, P1205; MASAND B, 1992, 15 ANN INT ACM SIGIR, P59; McCallum A., 1998, AAAI 98 WORKSH LEARN, P41; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; NG HT, 1999, 20 ANN INT ACM SIGIR, P67; Nigam K., 1999, IJCAI 99 WORKSH MACH, P61; SHANG W, 2005, 2005 INT C COMP INT, P741; SHANKAR S, 2000, P KDD 2000; TANG H, 2005, J COMPUTER RES DEV, P47; van Rijsbergen CJ, 1979, INFORM RETRIEVAL, V2nd; Vapnik V. N., 1995, NATURE STAT LEARNING; Wiener E, 1995, P 4 ANN S DOC AN INF, P317; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y, 1997, INFORM RETRIEVAL, V1, P76; YANG Y, 1994, ACM T INFORM SYST, P252	26	0	0	0	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2779-6				2008							269	275				7	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BJL58	WOS:000266767300041		
S	Martinez-Uso, A; Pla, F; Sotoca, JM; Garcia-Sevilla, P		Campilho, A; Kamel, M		Martinez-Uso, Adolfo; Pla, Filiberto; Sotoca, Jose M.; Garcia-Sevilla, Pedro			From narrow to broad band design and selection in hyperspectral images	IMAGE ANALYSIS AND RECOGNITION, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	5th International Conference on Image Analysis and Recognition	JUN 25-27, 2008	Povoa de Varzim, PORTUGAL					Selecting the most relevant bands from a hyperspectral image would considerably reduce the amount of data without practically losing relevant information. In addition, if some physical and signal criteria of this selection are taken into account, the obtained results grouping consecutive bands would be useful to design new filters for hyperspectral cameras in order to improve the efficiency of these devices. Starting from certain number of pre-selected bands, intervals of spectrally adjacent instances to these initial bands are considered for calculating new broader bands. Results will show how a weighted average on these intervals can keep, or even improve, the performance respecting to a narrower selection, avoiding, at the same time, common drawbacks from the narrow-band acquisition devices.	[Martinez-Uso, Adolfo; Pla, Filiberto; Sotoca, Jose M.; Garcia-Sevilla, Pedro] Jaume I Univ, Dept Lenguajes & Sistemas Informat, Castellon de La Plana, Spain	Martinez-Uso, A (reprint author), Jaume I Univ, Dept Lenguajes & Sistemas Informat, Castellon de La Plana, Spain.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Landgrebe D. A., 2003, SIGNAL THEORY METHOD; Martinez-Uso A, 2007, LECT NOTES COMPUT SC, V4477, P30; Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951; Price JC, 1997, IEEE T GEOSCI REMOTE, V35, P1277, DOI 10.1109/36.628794; SUN L, 2006, GEOSC REM SENS S 200, P2064	6	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-69811-1	LECT NOTES COMPUT SC			2008	5112						1091	1100				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Computer Science; Engineering; Imaging Science & Photographic Technology	BHX79	WOS:000257302500109		
B	Chuang, LY; Li, JC; Yang, CH			IA ENG	Chuang, Li-Yeh; Li, Jung-Chike; Yang, Cheng-Hong			Chaotic binary particle swarm optimization for feature selection using logistic map	IMECS 2008: INTERNATIONAL MULTICONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multiconference of Engineers and Computer Scientists	MAR 19-21, 2008	Hong Kong, PEOPLES R CHINA	Int Assoc Engn, Int Assoc Engn, Soc Artificial Intelligence, Int Assoc Engn, Soc Bioinformat, Int Assoc Engn, Soc Comp Sci, Int Assoc Engn, Soc Data Mining, Int Assoc Engn, Soc Elect Engn, Int Assoc Engn, Soc Imaging Engn, Int Assoc Engn, Soc Info Syst Eng, Int Assoc Engn, Soc Internet Comp & Web Serv, Int Assoc Engn, Soc Mech Engn, Int Assoc Engn, Operat Res, Int Assoc Engn, Sci Comp, Int Assoc Engn, Soc Software Engn, Int Assoc Engn, Soc Wireless Networks		feature selection; binary particle swarm optimization; logistic map; K-nearest neighbor; leave-one-out cross-validation	CLASSIFIER	Feature selection is a useful technique for increasing classification accuracy. The primary objective is to remove irrelevant features in the feature space and identify relevant features. Binary particle swarm optimization (BPSO) has been applied successfully in solving feature selection problem. In this paper, chaotic binary particle swarm optimization (CBPSO) with logistic map for determining the inertia weight is used. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) serves as a classifier for evaluating classification. accuracies. Experimental results indicate that the proposed method not only reduces the number of features, but also achieves higher classification accuracy than other methods.	[Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan	Chuang, LY (reprint author), I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan.						Chuanwen J., 2005, MATH COMPUT SIMULAT, V68, P57, DOI 10.1016/j.matcom.2004.10.003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Huan Liu, 2005, IEEE Transactions on Knowledge and Data Engineering, V17, DOI 10.1109/TKDE.2005.66; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Liu H, 2005, IEEE INTELL SYST, V20, P64, DOI 10.1109/MIS.2005.105; Murphy PM, 1995, UCI REPOSITORY MACHI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Shi Y, 1998, P IEEE INT C EV COMP, P69, DOI DOI 10.1109/ICEC.1998.699146; Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	16	0	0	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-98671-8-8	LECT NOTES ENG COMP			2008							131	136				6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Manufacturing; Engineering, Electrical & Electronic; Mathematical & Computational Biology; Mathematics, Applied; Telecommunications	Automation & Control Systems; Computer Science; Engineering; Mathematical & Computational Biology; Mathematics; Telecommunications	BHV15	WOS:000256665700026		
B	Farooqi, AH; Munir, A			IEEE	Farooqi, Ashfaq Hussain; Munir, Ali			Intrusion Detection System for IP Multimedia Subsystem Using K-Nearest Neighbor classifier	INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE			English	Proceedings Paper	12th IEEE International Multitopic Conference	DEC 23-24, 2008	Karachi, PAKISTAN	IEEE Karachi Sect, Higher Educ Commiss	Bahria Univ	IMS; 3GPP; PCSCF; DoS; IDS; KNN		IP Multimedia Subsystem (IMS) is a new next generation networking architecture that will provide better quality of service, charging infrastructure and security. The basic idea behind IMS is convergence; providing a single interface to different traditional or modern networking architectures allowing better working environment for the end users. IMS is still not commercially adopted and used but research is in progress to explore it. IMS is an IP based overlay next generation network architecture. It inherent number of security threats of Session Initiation Protocol (SIP), TCP, UDP etc as it uses SIP and IP protocols. Some of them can degrade the performance of IMS seriously and may cause DoS or DDoS attacks. The paper presents a new approach keeping a vision of secure IMS based on Intrusion Detection System (IDS) using K-Nearest Neighbor (KNN) as classifier. The KNN classifier can effectively detect intrusive attacks and achieve a low false positive rate. It can distinguish between the normal behavior of the system or abnormal. In this paper. we have focused on the key element of IMS core known as Proxy Call Session Control Function (PCSCF). Network based anomaly detection mechanism is proposed using KNN as anomaly detector. Experiments are performed on OpenIMS Core and the result shows that IMS is vulnerable to different types of attacks such as UDP flooding, IP spoofing that can cause DoS. KNN classifier effectively distinguishes the behavior of the system as normal or intrusive and achieve low false positive rate.	[Farooqi, Ashfaq Hussain; Munir, Ali] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan	Farooqi, AH (reprint author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan.	i070801@nu.edu.pk; i070811@nu.edu.pk					ANDERSON JP, 1990, COMPUTER SECURITY TH; AXELSSON S, 1999, RES INTRUSION DETECT; BACE R, 2001, NIST; BELLMAN, 2007, BUSINESS COMMUNI JAN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISCUOLO PJ, 2004, DISTRIBUTED DENIAL S; Cunningham P., 2007, K NEAREST NEIGHBOUR; DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894; Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270; Herrero A, 2007, ADV SOFT COMP, V44, P320; HUNTER MT, 2007, ACM WORKSH MIDDL NEX; Kurapati K, 2006, BUS COMMUN REV, V36, P40; LAING B, 2000, GUIDE IMPLEMENTING N; LI Y, 2008, DETECTING DDOS ATTAC; Liao Y, 2002, P 11 USENIX SEC S, P51; *MCAF PROV SEC, 2005, COMPL SEC CAS COMB B; McHugh J, 2000, IEEE SOFTWARE, V17, P42, DOI 10.1109/52.877859; Mitchell T. M., 1997, MACHINE LEARNING; Poikselk M., 2006, IMS IP MULTIMEDIA CO; RAWAT S, 2006, J INFORM ASSURANCE S, V1, P43; SELVAKANI S, 2007, INT J COMPUTER SCI N, V7; TSAGKAROPOULOS M, 2007, IEEE INT S PIMRC SEP, P1; Velasco V., 2000, INTRO IP SPOOFING; VINGARZAN D, 2007, IEEE VEHICULAR TECHN, V2, P29; VU NH, 2008, DDOS ATTACK DETECTIO; OPENIMS CORE CLIENTS	26	1	1	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2823-6				2008							423	428				6	Engineering, Multidisciplinary; Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BJJ31	WOS:000266371600079		
S	Yang, CH; Huang, CC; Wu, KC; Chang, HY		Fyfe, C; Kim, D; Lee, SY; Yin, H		Yang, Cheng-Hong; Huang, Chi-Chun; Wu, Kuo-Chuan; Chang, Hsin-Yun			A Novel GA-Taguchi-Based Feature Selection Method	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2008	Lecture Notes in Computer Science		English	Proceedings Paper	9th International Conference on Intelligent Data Engineering and Automated Learn	NOV 02-05, 2008	Daejeon, SOUTH KOREA	Dept Bio & Brain Engn, KAIST, Air Force Off Sci Res, Asian Office Aerosp Res & Dev		Genetic Algorithm; Taguchi Method; Orthogonal Array; Feature subset selection; Pattern Classification	FEATURE SUBSET-SELECTION; CLASSIFICATION; ALGORITHMS	This work presents a novel GA-Taguchi-based feature selection method. Genetic algorithms are utilized with randomness for "global search" of the entire search space of the intractable search problem. Various genetic operations. including crossover. Mutation, selection and replacement are performed to assist the search procedure in escaping from sub-optimal Solutions. In each iteration in the proposed nature-inspired method, the Taguchi methods are employed for "local search" of the entire search space and thus can help explore better feature subsets for next iteration. The two-level orthogonal array is utilized for a well-organized and balanced comparison of two levels for features-a feature is or is not selected for pattern classification-and interactions among features. The signal-to-noise ratio (SNR) is then used to determine the robustness of the features. As a result feature subset evaluation efforts call be significantly reduced and a superior feature Subset with high classification performance call be obtained. Experiments arc performed oil different application domains to demonstrate the performance of the proposed nature-inspired method. The proposed hybrid GA-Taguchi-based approach, with wrapper nature, yields superior performance and improves classification accuracy in pattern classification.	[Yang, Cheng-Hong; Wu, Kuo-Chuan] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung 80778, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, 415 Chien Kung Rd, Kaohsiung 80778, Taiwan.	chyang@cc.kuas.edu.tw; cchuang@mail.nkmu.edu.tw; hsin@ms.chinmin.edu.tw; hsin@ms.chinmin.edu.tw					Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Blake C, 1998, UCI REPOSITORY MACHI; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1990, NORMS NN PATTERN CLA; DASH M, 1997, INTELL DATA ANAL, V2, P232; Doak J., 1992, EVALUATION FEATURE S; Duda R. O., 1973, PATTERN CLASSIFICATI; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Hall M. A., 1998, THESIS U WAIKATO; HOLLAND JH, 1975, ADAPTATION NATURAL A; JOHNSONGENTILE K, 1994, J EDUC COMPUT RES, V11, P121; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; MITCHELL M, 1992, INTRO GENETIC ALGORI; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 2000, ROBUST ENG; Wu Y, 2000, TAGUCHI METHODS ROBU	21	4	4	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88905-2	LECT NOTES COMPUT SC			2008	5326						112	119				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIP04	WOS:000261445100015		
S	Bayoudh, I; Bechet, N; Roche, M		Shi, Z; MercierLaurent, E; Leake, D		Bayoudh, Ines; Bechet, Nicolas; Roche, Mathieu			Blog Classification: Adding Linguistic Knowledge to Improve the K-NN Algorithm	INTELLIGENT INFORMATION PROCESSING IV	INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING		English	Proceedings Paper	5th IFIP International Conference on Intelligent Information Processing	OCT 19-22, 2008	Beijing, PEOPLES R CHINA	IFIP TC12, Chinese Assoc Artificial Intelligence, Inst Comp Technol, Chinese Acad Sci		blog; categorization; linguistic knowledge; K-NN		Blogs are interactive and regularly updated websites which can be seen as diaries. These websites are composed by articles based on distinct topics. Thus, it is necessary to develop Information Retrieval approaches for this new web knowledge. The first important step of this process is the categorization of the articles. The paper above compares several methods using linguistic knowledge with k-NN algorithm for automatic categorization of weblogs articles.	[Bayoudh, Ines] Univ 7 Novembre Carthage, INSAT, Ctr Urbain Nord, Tunis, Tunisia	Bayoudh, I (reprint author), Univ 7 Novembre Carthage, INSAT, Ctr Urbain Nord, Tunis, Tunisia.						BERGMAN MJN, 1998, IMPACT, V2, P167; Chen CM, 2006, IEEE S VIS ANAL, P59; CORMACK RM, 1971, REV CLASSIFICATION D, V3, P321; Cornuejols A, 2002, APPRENTISSAGE ARTIFI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Lewis DD, 2004, J MACH LEARN RES, V5, P361; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; Moulinier I., 1996, Proceedings. Fifth Annual Symposium on Document Analysis and Information Retrieval; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Schmid H., 1995, P ACL SIGDAT WORKSH; Vapnik V. N., 1995, NATURE STAT LEARNING; Weiss S. M., 2005, TEXT MINING PREDICTI; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42; Yang Y., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290	17	1	2	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1571-5736		978-0-387-87684-9	INT FED INFO PROC			2008							68	77				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BIK75	WOS:000260431400007		
J	Yang, JY; Yang, MQ				Yang, Jack Y.; Yang, Mary Qu			Identification of Intrinsically Unstructured Proteins using hierarchical classifier	INTERNATIONAL JOURNAL OF DATA MINING AND BIOINFORMATICS			English	Article						intrinsically unstructured regions and proteins; Recursive Maximum Contrast Tree; RMCT; IUP; machine learning; classification; data mining; bioinformatics	SEQUENCES; DISORDER; MEMBRANE	It is suggested, that protein functions only when folded into a particular 3-D structure. Recently, many protein regions and some entire proteins have been identified with no definite tertiary structure, but presenting instead as dynamic, disorder ensembles Under different physiochemical circimstances. These proteins and regions are known as Intrinsically Unstructured regions and Proteins (IUP). We constructcd a Recursive Maximum Contrast Tree (RMCT) based classifier to identify IUP. The classifier has been benchmarked against industrial standard PONDR VLXT on out-of-sample, clata byexternalrrial evaluators. The IUP predictor is a viable alternative software tool for identifying intrinsic unstructured regions and proteins.	[Yang, Jack Y.] Harvard Univ, Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA; [Yang, Jack Y.] Harvard Univ, Sch Med, Boston, MA 02114 USA; [Yang, Mary Qu] NHGRI, NIH, US Dept Hlth & Human Serv Bethesda, Rockville, MD 20852 USA	Yang, JY (reprint author), Harvard Univ, Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA.	yang@hadron.mgh.harvard.edu; yangma@mail.nih.gov					BEHR JP, 1994, STATE ART 100 YEARS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daughdrill GW, 2005, PROTEIN FOLDING HANDBOOK; Dunker AK, 2001, NAT BIOTECHNOL, V19, P805, DOI 10.1038/nbt0901-805; EISENBERG D, 1984, J MOL BIOL, V179, P125, DOI 10.1016/0022-2836(84)90309-7; ENGELMAN DM, 1986, ANNU REV BIOPHYS BIO, V15, P321, DOI 10.1146/annurev.bb.15.060186.001541; Fischer E., 1894, BER DTSCH CHEM GES, V27, P2985, DOI DOI 10.1002/CBER.18940270364; HECKER J, 2007, J COMPUTATI IN PRESS, V1; KOSHLAND DE, 1958, P NATL ACAD SCI USA, V44, P98, DOI 10.1073/pnas.44.2.98; KYTE J, 1982, J MOL BIOL, V157, P105, DOI 10.1016/0022-2836(82)90515-0; lakoucheva LM., 2004, NUCLEIC ACIDS RES, V32, P1037; Li X, 1999, GENOME INFORMATICS, V10, P30; Linding R, 2003, NUCLEIC ACIDS RES, V31, P3701, DOI 10.1093/nar/gkg519; LINDING R, 2003, PROTEIN STRUCTURE, V11, P1316; Liu Li-Ping, 1998, Biopolymers, V47, P41, DOI 10.1002/(SICI)1097-0282(1998)47:1<41::AID-BIP6>3.0.CO;2-X; Peng Kang, 2005, Journal of Bioinformatics and Computational Biology, V3, P35, DOI 10.1142/S0219720005000886; Radivojac P, 2004, PROTEIN SCI, V13, P71, DOI 10.1110/ps.03128904; Romero P, 2001, PROTEINS, V42, P38, DOI 10.1002/1097-0134(20010101)42:1<38::AID-PROT50>3.0.CO;2-3; Romero P, 2000, ARTIF INTELL REV, V14, P447, DOI 10.1023/A:1006678623815; SOLOVYEV VV, 1993, COMPUT APPL BIOSCI, V9, P17; Yang M., 2006, P IEEE PES 2006 GEN, P1, DOI DOI 10.1109/BIBE.2006.253309; Yang MQ, 2007, INT J GEN SYST, V36, P91, DOI 10.1080/03081070600950868; YANG MQ, 2005, THESIS PURDUE U W LA	23	3	4	0	0	INDERSCIENCE ENTERPRISES LTD	GENEVA	WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215 GENEVA, SWITZERLAND	1748-5673	1748-5681		INT J DATA MIN BIOIN	Int. J. Data Min. Bioinform.		2008	2	2					121	133		10.1504/IJDMB.2008.019093		13	Mathematical & Computational Biology	Mathematical & Computational Biology	341TZ	WOS:000258739300002	18767350	
B	Puteh, M; Omar, K; Hamdan, AR; Abu Bakar, A		Pan, JS; Abraham, A; Chang, CC		Puteh, Mazidah; Omar, Khairuddin; Hamdan, Abdul Razak; Abu Bakar, Azuraliza			Immune Network for Classifying Heterogeneous Data	ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS			English	Proceedings Paper	8th International Conference on Intelligent Systems Design and Applications (ISDA 2008)	NOV 26-28, 2008	Kaohsiung, TAIWAN	IEEE, IEEE SMC Soc, Natl Sci Council, Minist Educ				In the previous AIS research, most of the AIS classifiers use clonal selection and require the data to be in numerical or categorical data types prior to processing. These classifiers ignore the network feature of the immune system that is suitable for classification. Furthermore, the transformation of data into any other specific types from their original form can degrade the originality of the data and consume more space and pre processing time. This paper introduces resource limited immune network model with hybrid affinity measurement for classifying heterogeneous data in its original types. The model is able to process the data with the types as represented in the database. The paper shows comparisons between the model and the selected existing immune algorithms that also uses the same set of data and parameters. The experimental results show that the immune network model produces a better accuracy rate with shorter classifier on most of the heterogeneous data from University of California, Irvive (UCI) Machine Learning Repository (MLR).	[Puteh, Mazidah] Univ Teknol MARA, FTMSK, Selangor, Malaysia	Puteh, M (reprint author), Univ Teknol MARA, FTMSK, Selangor, Malaysia.			Omar, Khairuddin/0000-0003-1794-019X			BROWNLEE J, 2005, 102 CISCP SWINB U TE; CARTER JH, 2000, J AM MED INFORM ASS, V7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY, 1991, NEAREST NEIGHBOR NN; Dasgupta D., 2006, IEEE COMPUTATIONAL I; De Castro L. N., 2000, P GECCO 00 WORKSH AR, P36; De Castro L. N., 2002, ARTIFICIAL IMMUNE SY; FREITAS A, 2007, IEEE T EVOLUTIONARY, V11, P4; HAMAKER J, 2004, P CEC2004; Hart E., 2008, J APPL SOFT COMPUTIN, V8, P191; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hunt JE, 1996, J NETW COMPUT APPL, V19, P189, DOI 10.1006/jnca.1996.0014; Keogh E., 2006, UCR TIME SERIES DATA; METZ CJ, 1998, UCI MACHINE LEARNING; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Steed LG, 2003, SPSS ANAL ANGUISH VE; Timmis J, 2006, LECT NOTES COMPUT SC, V3931, P355; Timmis J.I., 2001, THESIS U WALES ABERY; Ventura D., 1995, P 10 INT S COMP INF, P443; Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, DOI 10.1023/B:GENP.0000030197.83685.94; Watkins A., 2001, THESIS MISSISSIPPI S; WATKINS A, 2004, P 3 INT C ART IMM SY, P427; Watkins A., 2002, P 1 INT C ART IMM SY, P173; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Witten I, 2005, DATA MINING	25	0	0	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3382-7				2008							373	377		10.1109/ISDA.2008.242		5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BJB31	WOS:000264422700065		
B	Zhang, QG; Zhang, CZ		Zhao, C; Wu, C; Wang, Y; Liu, Q		Zhang Qingguo; Zhang Chengzhi			Automatic Chinese Keyword Extraction Based on KNN for Implicit Subject Extraction	KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS			English	Proceedings Paper	International Symposium on Knowledge Acquisition and Modeling	DEC 21-22, 2008	Wuhan, PEOPLES R CHINA	IEEE Comp Soc, IEEE				In this paper, a method of automatic Chinese keyword extraction based on KNN is proposed. Firstly, it preprocesses the document by Vector Space Model. Secondly, it constructs a set of candidate keywords based on KNN method and the labeled dataset. Finally, it post-processes on candidate keywords by the character of keyword to meet readers' requirements Experimental results show the method proposed can not only improve the precision and recall of keyword extraction, but also extract implicit subject efficiently.	[Zhang Qingguo] Tongfang Knowledge Network Technol Co Ltd Beijing, Beijing 100084, Peoples R China	Zhang, QG (reprint author), Tongfang Knowledge Network Technol Co Ltd Beijing, Beijing 100084, Peoples R China.	qgzhang@cnki.net; zhangchz@istic.ac.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Edmundson H.P., 1959, R126 PRC, P1; Frank E, 1999, P 16 INT JOINT C ART, P668; LOIS LE, 1970, INFORM STORAGE RETRI, V6, P313; LUHN HP, 1957, IBM J RES DEV, V1, P309; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Turney P.D., 1999, ERB1057 NRC, P1; TURNEY PD, 1997, ERB1051 NAT RES COUN; Zhang Qingguo, 2006, Journal of the China Society for Scientific and Technical Information, V25	9	0	0	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3488-6				2008							689	692		10.1109/KAM.2008.87		4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BIV54	WOS:000263156800142		
J	Wu, XD; Kumar, V; Quinlan, JR; Ghosh, J; Yang, Q; Motoda, H; McLachlan, GJ; Ng, A; Liu, B; Yu, PS; Zhou, ZH; Steinbach, M; Hand, DJ; Steinberg, D				Wu, Xindong; Kumar, Vipin; Quinlan, J. Ross; Ghosh, Joydeep; Yang, Qiang; Motoda, Hiroshi; McLachlan, Geoffrey J.; Ng, Angus; Liu, Bing; Yu, Philip S.; Zhou, Zhi-Hua; Steinbach, Michael; Hand, David J.; Steinberg, Dan			Top 10 algorithms in data mining	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article							NEAREST NEIGHBOR RULES; ASSOCIATION RULES; CLASSIFICATION; QUANTIZATION; CLASSIFIERS; CONFIDENCE; REGRESSION; FRAMEWORK; PATTERNS; TREES	This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development.	[Wu, Xindong] Univ Vermont, Dept Comp Sci, Burlington, VT USA; [Kumar, Vipin] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA; [Quinlan, J. Ross] Rulequest Res pty Ltd, St Ives, NSW, Australia; [Ghosh, Joydeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Yang, Qiang] Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Peoples R China; [Motoda, Hiroshi] Osaka Univ, AFORS AOARD, Tokyo 10600326, Japan; [McLachlan, Geoffrey J.] Univ Queensland, Dept Math, Brisbane, Qld, Australia; [Ng, Angus] Griffith Univ, Sch Med, Brisbane, Qld, Australia; [Liu, Bing] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA; [Yu, Philip S.] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210008, Peoples R China; [Steinbach, Michael] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; [Hand, David J.] Univ London Imperial Coll Sci & Technol, Dept Math, London, England; [Steinberg, Dan] Maxwell Labs Inc, Salford Syst, San Diego, CA 92123 USA	Wu, XD (reprint author), Univ Vermont, Dept Comp Sci, Burlington, VT USA.	xwu@cs.uvm.edu; kumar@cs.umn.edu; quinlan@rulequest.com; ghosh@ece.utexas.edu; qyang@cs.ust.hk; motoda@ar.sanken.osaka-u.ac.jp; gjm@maths.uq.edu.au; psyu@us.ibm.com; steinbac@cs.umn.edu; d.j.hand@imperial.ac.uk; dsx@salford-systems.com	Adams, Niall/D-2472-2010; McLachlan, Geoffrey/A-1491-2008; Liu, Bing/C-5758-2014	McLachlan, Geoffrey/0000-0002-5921-3145; 			Agrawal R, 1994, P 20 INT C VER LARG, P487; Ahmed S, 2006, KNOWL INF SYST, V10, P315, DOI 10.1007/s10115-006-0010-1; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BEZDEK JC, 1986, FUZZY SET SYST, V18, P237, DOI 10.1016/0165-0114(86)90004-7; Bloch DA, 2002, J COMPUT GRAPH STAT, V11, P263, DOI 10.1198/106186002760180509; Bonchi F, 2006, KNOWL INF SYST, V9, P180, DOI 10.1007/s10115-005-0201-1; Breiman L, 1999, NEURAL COMPUT, V11, P1493, DOI 10.1162/089976699300016106; BREIMAN L, 1968, CLASSICS MATH; Breiman L., 1984, CLASSIFICATION REGRE; Brin S., 1998, COMPUTER NETWORKS IS, V30, P1; Chen JR, 2007, KNOWL INF SYST, V11, P369, DOI 10.1007/s10115-006-0042-6; CHEUNG DW, 1996, P ACM SIGMOD INT C D, P13; Chi Y, 2006, KNOWL INF SYST, V10, P265, DOI 10.1007/s10115-006-0003-0; COST S, 1993, MACH LEARN, V10; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NN PATTERN CLASSIFIC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Devroye L., 1996, PROBABILISTIC THEORY; Dhillon I.S., 2004, KDD, P551; Dietterich TG, 1997, AI MAG, V18, P97; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Fix E., 1951, 4 USAF SCH AV MED; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman JH, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P717; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Golub G. H., 1983, MATRIX COMPUTATIONS; Gondek D, 2007, KNOWL INF SYST, V12, P1, DOI 10.1007/s10115-006-0009-7; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Han EH, 1999, THESIS U MINNESOTA; Han J, 2000, P 2000 ACM SIGMOD IN, P1, DOI 10.1145/342009.335372; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Herbrich R, 2000, ADV NEUR IN, P115; Hu TM, 2006, KNOWL INF SYST, V10, P505, DOI 10.1007/s10115-006-0017-7; Hunt Earl B, 1966, EXPT INDUCTION; Inokuchi A, 2005, FUND INFORM, V66, P53; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jin RM, 2006, KNOWL INF SYST, V10, P17, DOI 10.1007/s10115-005-0210-0; Kobayashi M, 2006, KNOWL INF SYST, V10, P295, DOI 10.1007/s10115-006-0005-y; Koga H, 2007, KNOWL INF SYST, V12, P25, DOI 10.1007/s10115-006-0027-5; Kukar M, 2006, KNOWL INF SYST, V9, P364, DOI 10.1007/s10115-005-0203-z; Kuramochi M, 2005, INT J ARTIF INTELL T, V14, P641, DOI 10.1142/S0218213005002302; Langville A. N., 2006, GOOGLES PAGE RANK SC; Leung CKS, 2007, KNOWL INF SYST, V11, P287, DOI 10.1007/s10115-006-0032-8; Leung CWK, 2006, KNOWL INF SYST, V10, P357, DOI 10.1007/s10115-006-0002-1; Li T, 2006, KNOWL INF SYST, V10, P453, DOI 10.1007/s10115-006-0013-y; Liu Bing, 2007, WEB DATA MINING EXPL; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; McLachlan G., 2000, FINITE MIXTURE MODEL; MCLACHLAN GJ, 1987, APPL STAT-J ROY ST C, V36, P318, DOI 10.2307/2347790; McLachlan G J, 1997, EM ALGORITHM EXTENSI; MESSENGE.R, 1972, J AM STAT ASSOC, V67, P768, DOI 10.2307/2284634; Morishita S., 2000, P 19 ACM SIGACT SIGM, P226, DOI 10.1145/335168.335226; Olshen R, 2001, STAT SCI, V16, P184, DOI 10.1214/ss/1009213290; PAGE L, 1999, 19990120 STANF U; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1979, EXPERT SYSTEMS MICRO; QUINLAN R, 1989, UNKNOWN ATTRIBUTE VA, P164; R Srikant, 1995, P 21 INT C VER LARG, ppp; Reyzin L., 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; Ridgeway G., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; SCHAEFER P, 1990, EARTH ISL J, V5, P2; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHATTEN G, 1998, J LAW MED ETHICS, V26, P5; Scholkopf B., 2002, LEARNING KERNELS; Seidl T., 1998, P ACM SIGMOD INT C M, P154, DOI DOI 10.1145/276304.276319; STEINBACH M, 2000, P KDD WORKSH TEXT MI; Steinbach M, 2007, KNOWL INF SYST, V12, P279, DOI 10.1007/s10115-006-0041-7; Tan P.-N., 2006, INTRO DATA MINING; Tao DC, 2007, KNOWL INF SYST, V13, P1, DOI 10.1007/s10115-006-0050-6; Thabtah FA, 2006, KNOWL INF SYST, V9, P109, DOI 10.1007/s10115-005-0213-x; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; TOUSSAINT G, 2002, INT 2002 34 S COMP S; TOUSSAINT GT, 2002, JCDCG, P273; Tsang IW, 2005, J MACH LEARN RES, V6, P363; Uno T, 2004, LECT NOTES COMPUT SC, V3245, P16; Vapnik V. N., 1995, NATURE STAT LEARNING; Viola P, 2001, PROC CVPR IEEE, P511; Washio T, 2005, LECT NOTES ARTIF INT, V3721, P692; Wasserman S, 1994, SOCIAL NETWORK ANAL; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yan X., 2002, P 2002 IEEE INT C DA, P721; Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258; YU PS, 2005, P WEB INT WI 05; Zhang J, 2006, KNOWL INF SYST, V9, P157, DOI 10.1007/s10115-005-0211-z	92	505	546	56	278	SPRINGER LONDON LTD	ARTINGTON	ASHBOURNE HOUSE, THE GUILDWAY, OLD PORTSMOUTH ROAD, ARTINGTON GU3 1LP, GUILDFORD, ENGLAND	0219-1377			KNOWL INF SYST	Knowl. Inf. Syst.	JAN	2008	14	1					1	37		10.1007/s10115-007-0114-2		37	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	243KS	WOS:000251795900001		
S	Mitani, Y; Sugimura, Y; Hamamoto, Y		Lovrek, I		Mitani, Yoshihiro; Sugimura, Yuuki; Hamamoto, Yoshihiko			A method for reading a resistor by image processing techniques	KNOWLEDGE - BASED INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT 1, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	12th International Conference on Knowledge-Based Intelligent Information and Engineering Systems	SEP 03-05, 2008	Zagreb, CROATIA	KES Int, Innovat Knowledge Based & Intelligent Engn Syst, Univ Zagreb, Fac Elect Engn & Comp, Republic Croatia, Minist Sci, Educ & Sports, Ericsson Nikola Tesla, Croatian Natl Tourist Board, Zagreb Tourist Board				The resistance of a resistor is defined by colored lines printed on the resistor's body. Normally, people read it by sight. Though, if a computer performs this instead, we can reduce the costs. In this paper, we propose a method for reading this resistance by image processing techniques. We extract colors front a real resistor's picture, and classify it, by its colors. The experimental results show the effectiveness of the proposed method.	[Mitani, Yoshihiro; Sugimura, Yuuki] Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan	Mitani, Y (reprint author), Ube Natl Coll Technol, Ube, Yamaguchi 7558555, Japan.						Chan KL, 1997, P SOC PHOTO-OPT INS, V3185, P157, DOI 10.1117/12.284040; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Plataniotis K.N., 2000, COLOR IMAGE PROCESSI; Russ J.C., 1999, IMAGE PROCESSING HDB, VThird	7	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-85562-0	LECT NOTES ARTIF INT			2008	5177						433	439				7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BIF73	WOS:000259162700050		
S	Panigrahy, R		Laber, ES; Bornstein, C; Nogueira, LT; Faria, L		Panigrahy, Rina			An improved algorithm finding nearest neighbor using kd-trees	LATIN 2008: THEORETICAL INFORMATICS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	8th Latin American Symposium on Theoretical Informatics (LATIN 2008)	APR 07-JUL 11, 2008	Buzios, BRAZIL	Microsoft, UOL, IFIP, HP, Yahoo, FAPERJ, CNPq, CAPES, Springer			IMAGE	We suggest a simple modification to the Kd-tree search algorithm for nearest neighbor search resulting in an improved performance. The Kd-tree data structure seems to work well in finding nearest neighbors in low dimensions but its performance degrades even if the number of dimensions increases to more than two. Since the exact nearest neighbor search problem suffers from the curse of dimensionality we focus on approximate solutions; a c-approximate nearest neighbor is any neighbor within distance at most c times the distance to the nearest neighbor. We show that for a randomly constructed database of points if the query point is chosen close to one of the points in the data base, the traditional Kd-tree search algorithm has a very low probability of finding an approximate nearest neighbor; the probability of success drops exponentially in the number of dimensions d as e(- Omega(d/c)). However, a simple change to the search algorithm results in a much higher chance of success. Instead of searching for the query point in the Kd-tree we search for a random set of points in the neighborhood of the query point. It turns out that searching for e(Omega(d/c)) such points can find the c-approximate nearest neighbor with a much higher chance of success.	Microsoft Res, Mountain View, CA USA	Panigrahy, R (reprint author), Microsoft Res, Mountain View, CA USA.						Andoni A., 2006, P S FDN COMP SCI FOC; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Bentley J. L., 1977, ACM T MATH SOFTWARE, V3, P209; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; CLARKSON KL, 1997, P 29 ANN ACM S THEOR, P609, DOI 10.1145/258533.258655; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2004, P S COMP GEOM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Dolev D., 1993, Proceedings of the 2nd Israel Symposium on Theory and Computing Systems (Cat. No.93TH0520-7), DOI 10.1109/ISTCS.1993.253486; FAGIN R, 1998, P ACM S PRINC DAT SY, V1; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; HARPELED S, 2001, P S FDN COMP SCI; Indyk P., 1997, P 29 ANN ACM S THEOR, P618, DOI 10.1145/258533.258656; INDYK P, 2001, HIGH DIMENSIONAL COM; INDYK P, 1997, HDB DISCRETE COMPUTA, pCH39; INDYK P, 2002, HDB DISCRETE; INDYK P, 2001, EMBEDDING EARTHMOVER; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jayram T.S., 2003, P 35 ANN ACM S THEOR, P667; KLEMBERG J, 1997, P 29 ANN ACM SYMPOS, P599; Kushilevitz E., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276877; Linial N., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/237814.237999; MEISER S, 1993, INFORM COMPUT, V106, P286, DOI 10.1006/inco.1993.1057; MOTWANI R, 2006, P 22 ANN ACM S COMP; PANIGRAHY R, 2006, SODA, P1186; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; Salton G., 1989, AUTOMATIC TEXT PROCE; VANRIJSBERGEN CJ, 1990, INFORM RETRIEVAL BUT; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025	30	8	9	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-78772-3	LECT NOTES COMPUT SC			2008	4957						387	398		10.1007/978-3-540-78773-0_34		12	Computer Science, Theory & Methods	Computer Science	BHM87	WOS:000254390900034		
S	Nguyen, N; Guo, Y		Daelemans, W; Goethals, B; Morik, K		Nguyen, Nam; Guo, Yunsong			Metric Learning: A Support Vector Approach	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PART II, PROCEEDINGS	LECTURE NOTES IN ARTIFICIAL INTELLIGENCE		English	Proceedings Paper	European Conference on Principles of Data Mining and Knowledge Discovery	SEP 15-19, 2008	Antwerp, BELGIUM	Univ Antwerp, Computat Linguist Flanders, Google, hp, VADIS, COGNOS, European Off Aerosp, SPSS, textkernel, Data Mining & Knowledge Discovery, IBM, Machine Learning		metric learning; K-nearest neighbor classification; SVM	CLASSIFICATION	In this paper, we address the metric learning problem utilizing a margin-based approach. Our metric learning problem is formulated as a quadratic semi-definite programming problem (QSDP) with local neighborhood constraints, which is based on the Support Vector Machine (SVM) framework. The local neighborhood constraints ensure that examples of the same class are separated from examples of different classes by a margin. In addition to providing an efficient algorithm to solve the metric learning problem, extensive experiments on various data sets show that our algorithm is able to produce a new distance metric to improve the performance of the classical K-nearest neighbor (KNN) algorithm on the classification task. Our performance is always competitive and often significantly better than other state-of-the-art metric learning algorithms.	[Nguyen, Nam; Guo, Yunsong] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Nguyen, N (reprint author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.						Asuncion A., 2007, UCI MACHINE LEARNING; CHANG CC, 2001, LIBSVM DATA; Chopra S, 2005, P IEEE C COMP VIS PA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; Davis J. V., 2007, P 24 INT C MACH LEAR, P209, DOI DOI 10.1145/1273496.127352; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Globerson A., 2005, ADV NEURAL INFORM PR; Goldberger J., 2004, ADV NEURAL INFORM PR; Hastie T, 1996, ADV NEUR IN, V8, P409; He H., 2000, J ADV COMPUTATIONAL, V4, P130; Joachims T., 1998, ADV KERNEL METHODS S; Roweis Sam, 2000, SCIENCE, V290; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Schultz M., 2004, ADV NEURAL INFORM PR; Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598; Shalev-Shwartz S., 2004, P 21 INT C MACH LEAR; Shental N, 2002, P 7 EUR C COMP VIS, P776; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tsang I., 2003, P INT C ART NEUR NET; Vapnik V., 1998, STAT LEARNING THEORY; WEINBERGER KQ, 2006, ADV ING NEURAL INFOR; Xing E., 2003, ADV NEURAL INFORM PR	23	4	4	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-87480-5	LECT NOTES ARTIF INT			2008	5212		II				125	136				12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Information Systems	Computer Science	BIJ50	WOS:000260075900009		
J	Carson, HS; Morgan, SG; Green, PG				Carson, Henry S.; Morgan, Steven G.; Green, Peter G.			Fine-scale chemical fingerprinting of an open coast crustacean for the assessment of population connectivity	MARINE BIOLOGY			English	Article							MARINE INVERTEBRATE LARVAE; TEMPORAL VARIATION; TRACE-ELEMENTS; CALIFORNIA; DISPERSAL; RETENTION; FISH; HABITATS; OTOLITHS; TRACKING	Chemical fingerprinting techniques recently have been used to track larval dispersal of estuarine species that bear calcified structures, but the applicability of this important approach may be limited on the open coast where chemical signatures may be less distinctive and for the many species that do not retain calcified structures throughout development. Externally brooded embryos of the porcelain crab, Petrolisthes cinctipes, and inductively coupled plasma mass spectrometry were used to determine whether fine-scale variation in trace-elemental composition occurred along an open coast. Embryos were collected from 16 sites from 37.8 degrees to 39.5 degrees north latitude along the Pacific Coast of California, USA during late January and early February 2003. Discriminant function analysis revealed that collection sites, many separated by only a few kilometers along an open coast, could be differentiated with an overall accuracy of 73%, and combining the sites into three regions increased the accuracy to 88%. Thus, distinctive elemental signatures can be detected in open coast species even at a fine scale raising the possibility that larval tags can be developed for many more species than previously thought possible.	San Diego State Univ, Dept Biol, San Diego, CA 92182 USA; Univ Calif Davis, Dept Environm Sci & Policy, Bodega Marine Lab, Davis, CA 94923 USA; Univ Calif Davis, Dept Civil & Environm Engn, Davis, CA 95616 USA	Carson, HS (reprint author), San Diego State Univ, Dept Biol, 5500 Campanilc Dr, San Diego, CA 92182 USA.	hcarson@mail.sdsu.edu					Anastasia JR, 1998, LIMNOL OCEANOGR, V43, P362; Becker BJ, 2007, P NATL ACAD SCI USA, V104, P3267, DOI 10.1073/pnas.0611651104; Becker BJ, 2005, LIMNOL OCEANOGR, V50, P48; Chase Z, 2005, MAR CHEM, V95, P235, DOI 10.1016/j.marchem.2004.09.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DiBacco C, 2000, LIMNOL OCEANOGR, V45, P871; DiBacco C, 2001, J MAR RES, V59, P53, DOI 10.1357/002224001321237362; Faure G, 1998, PRINCIPLES APPL GEOC, Vsecond; Flegal AR, 2005, ECOTOXICOLOGY, V14, P645, DOI 10.1007/s10646-005-0016-6; Gillanders BM, 2005, ESTUAR COAST SHELF S, V64, P47, DOI 10.1016/j.ecss.2005.02.005; Gonor S. L., 1970, THESIS OREGON STATE; HUYER A, 1983, PROG OCEANOGR, V12, P259, DOI 10.1016/0079-6611(83)90010-1; JENSEN GC, 1991, J EXP MAR BIOL ECOL, V153, P49, DOI 10.1016/S0022-0981(05)80005-X; Lachenbruch PA, 1975, DISCRIMINANT ANAL; Lares ML, 2002, ENVIRON POLLUT, V120, P595; LEVIN LA, 1990, OPHELIA, V32, P115; LEVIN LA, 1993, LIMNOL OCEANOGR, V38, P346; Morris R.H., 1980, INTERTIDAL INVERTEBR; NRIAGU JO, 1989, NATURE, V338, P47, DOI 10.1038/338047a0; Sanudo-Wilhelmy SA, 1991, MAR CHEM, V33, P371, DOI DOI 10.1016/0304-4203(91)90078-B; SanudoWilhelmy SA, 1996, ENVIRON SCI TECHNOL, V30, P1575, DOI 10.1021/es9505560; Shanks AL, 2005, ECOL MONOGR, V75, P505, DOI 10.1890/05-0309; Swearer SE, 1999, NATURE, V402, P799, DOI 10.1038/45533; Thorrold SR, 2002, B MAR SCI, V70, P291; Warner RR, 2005, LIMNOL OCEANOGR, V50, P1529; WEEKS JM, 1992, HYDROBIOLOGIA, V245, P15, DOI 10.1007/BF00008725; Zacherl DC, 2003, MAR ECOL PROG SER, V248, P297, DOI 10.3354/meps248297; Zacherl DC, 2005, MAR ECOL PROG SER, V290, P145, DOI 10.3354/meps290145	28	12	12	2	11	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	0025-3162			MAR BIOL	Mar. Biol.	JAN	2008	153	3					327	335		10.1007/s00227-007-0808-8		9	Marine & Freshwater Biology	Marine & Freshwater Biology	238ZW	WOS:000251488200010		
S	Depeursinge, A; Lavindrasana, J; Hidki, A; Cohen, G; Geissbuhler, A; Platon, A; Poletti, PA; Muller, H		Andriole, KP; Siddiqui, KM		Depeursinge, Adrien; Lavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning			A classification framework for lung tissue categorization	MEDICAL IMAGING 2008: PACS AND IMAGING INFORMATICS	Proceedings of SPIE		English	Proceedings Paper	Medical Imaging 2008 Conference	FEB 17-19, 2008	San Diego, CA	SPIE, Amer Assoc Phys Med, Amer Physiol Soc, Comp Assisted Radiol & Surg, Soc Imaging Sci & Technol, Med Image Percept Soc, Radiol Soc N Amer, Soc Imaging Informat Med, Soc Mol Imaging, DICOM Standards Comm		quantitative image analysis; feature extraction; texture analysis; chest high-resolution CT; supervised learning; support vector machines	COMPUTER-AIDED DIAGNOSIS; SUPPORT VECTOR MACHINES; PATTERN-RECOGNITION; FUTURE-DIRECTIONS; DISEASE PATTERNS; RETRIEVAL; SEGMENTATION; TUTORIAL; IMAGES; SYSTEM	We compare five common classifier families in their ability to categorize six lung tissue patterns in high-resolution computed tomography (HRCT) images of patients affected with interstitial lung diseases (ILD) but also normal tissue. The evaluated classifiers are Naive Bayes, k-Nearest Neighbor (k-NN), J48 decision trees, Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM). The dataset used contains 843 regions of interest (ROI) of healthy and five pathologic lung tissue patterns identified by two radiologists at the University Hospitals of Geneva. Correlation of the feature space composed of 39 texture attributes is studied. A grid search for optimal parameters is carried out for each classifier family. Two complementary metrics are used to characterize the performances of classification. Those are based on McNemar's statistical tests and global accuracy. SVM reached best values for each metric and allowed a mean correct prediction rate of 87.9% with high class-specific precision on testing sets of 423 ROIs.	[Depeursinge, Adrien; Lavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Mueller, Henning] Univ & Hosp Geneva, Serv Med Informat, CH-1211 Geneva 14, Switzerland; [Platon, Alexandra; Poletti, Pierre-Alexandre] Univ & Hosp Geneva, Serv Emergency Radiol, CH-1211 Geneva 14, Switzerland; [Mueller, Henning] Univ Appl Sci Sierre, Sierre, Switzerland	Depeursinge, A (reprint author), Univ & Hosp Geneva, Serv Med Informat, 24 Rue Micheli Crest, CH-1211 Geneva 14, Switzerland.	adrien.depeursinge@sim.hcuge.ch					Aisen AM, 2003, RADIOLOGY, V228, P265, DOI 10.1148/radiol.2281020126; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Caban JJ, 2007, SPIE MED IMAGING, V6514; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cohen G, 2006, ARTIF INTELL MED, V37, P7, DOI 10.1016/j.artmed.2005.03.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEPEURSINGE A, 2007, EMBS 2007 29 ANN INT; DEPEURSINGE A, 2006, SWISS C MED INF SSIM; DEPEURSINGE A, 2007, SPIE MED IMAGING; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Flaherty KR, 2004, AM J RESP CRIT CARE, V170, P904, DOI 10.1164/rccm.200402-147OC; Frank E, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1305, DOI 10.1007/0-387-25465-X_62; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Shamsheyeva A, 2004, P SOC PHOTO-OPT INS, V5370, P1548, DOI 10.1117/12.534877; SHAMSHEYEVA A, 2006, P 2004 INT SENS SENS; Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768; STARK P, 2007, UPTODATE         SEP; Tourassi GD, 1999, RADIOLOGY, V213, P317; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648; van der Walt C., 2006, P 16 ANN S PATT REC, P166; Van De Ville D, 2005, IEEE T IMAGE PROCESS, V14, P1798, DOI 10.1109/TIP.2005.857249; Vapnik V., 1999, NATURE STAT LEARNING; Witten I. H., 2005, MORGAN KAUFMANN SERI, V2nd; Wong JSJ, 2006, LECT NOTES COMPUT SC, V4304, P233; ZAVALETTA V, 2007, SPIE MED IMAGING; Zrimec T, 2007, ST HEAL T, V129, P1324	35	2	2	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-7103-1	PROC SPIE			2008	6919								69190C	10.1117/12.769190		12	Engineering, Biomedical; Optics; Imaging Science & Photographic Technology; Physiology; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Optics; Imaging Science & Photographic Technology; Physiology; Radiology, Nuclear Medicine & Medical Imaging	BHU33	WOS:000256422200010		
S	Bonet, I; Rodriguez, A; Grau, R; Garcia, MM; Saez, Y; Nowe, A		Gelbukh, A; Morales, EF		Bonet, Isis; Rodriguez, Abdel; Grau, Ricardo; Garcia, Maria M.; Saez, Yvan; Nowe, Ann			Comparing Distance Measures with Visual Methods	MICAI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	7th Mexican International Conference on Artificial Intelligence (MICAI 2008)	OCT 27-31, 2008	Atizapan de Zaragoza, MEXICO	Mexican Soc Artificial Intelligence, Tecnol Monterrey, Campus Estado Mexico		MDS; kNN; similarity; distance measure; HIV		The selection of the distance measure to separate the objects of the knowledge space is critical in many classification algorithms. In this paper, we analyze the distance measures reported in the literature for the problem of HIV prediction. We propose a new distance for HIV viral sequences, based on the mutations with regard to the HXB2 reference sequence. In a first step, we reduce data dimensionality in order to subsequently analyze the distance measure's performance in terms of its ability to separate classes.	[Bonet, Isis; Rodriguez, Abdel; Grau, Ricardo; Garcia, Maria M.] Cent Univ Las Villas, Ctr Studies Informat, Santa Clara, Villa Clara, Cuba	Bonet, I (reprint author), Cent Univ Las Villas, Ctr Studies Informat, Santa Clara, Villa Clara, Cuba.	isisb@uclv.edu.cu; abdelr@uclv.edu.cu; rgrau@uclv.edu.cu; mmgarcia@uclv.edu.cu; yvsae@psb.ugent.be; ann.nowe@como.vub.ac.be					Bhaskar H, 2006, COMPUT BIOL MED, V36, P1104, DOI 10.1016/j.compbiomed.2005.09.002; Brunak S., 2001, BIOINFORMATICS MACHI, V2nd; Cover P., 1967, IEEE T INFORM THEORY, V13, P21; Cox TF, 1994, MULTIDIMENSIONAL SCA; Dayhoff M, 1978, ATLAS PROTEIN SEQ S3, V5, P345; HENIKOFF S, 1992, P NATL ACAD SCI USA, V89, P10915, DOI 10.1073/pnas.89.22.10915; JAMES R, 2004, PREDICTING HUMAN IMM; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; MCQUEEN J, 1967, 5 BERK S MATH STAT P, P182; Miyazawa S, 1996, J MOL BIOL, V256, P623, DOI 10.1006/jmbi.1996.0114; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; *STANF, STANF HIV RES DAT PR; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	14	2	2	0	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88635-8	LECT NOTES ARTIF INT			2008	5317						90	99				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BIQ13	WOS:000261873400008		
S	Cruz, B; Barron, R; Sossa, H		Gelbukh, A; Morales, EF		Cruz, Benjamin; Barron, Ricardo; Sossa, Humberto			Pattern Classification Based on Conformal Geometric Algebra and Optimization Techniques	MICAI 2008: ADVANCES IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	7th Mexican International Conference on Artificial Intelligence (MICAI 2008)	OCT 27-31, 2008	Atizapan de Zaragoza, MEXICO	Mexican Soc Artificial Intelligence, Tecnol Monterrey, Campus Estado Mexico		Conformal Geometric Algebra; Pattern Classification; Optimization		Conformal Geometric Algebra (CGA) is a high level language commonly used in mathematical, physics and engineering problems. At a top level, CGA is a free coordinate tool for designing and modeling geometric problems; at a low level CGA provides a new coordinate framework for numeric processing in problem solving. In this paper we show how to use quadratic programming and CGA for, given two sets p and g of points in R(n), construct an optimal separation sphere S such that, all points of p are contained inside of it, and all points of g are outside. To classify an unknown pattern x, an inner product must be applied between x and S. Some numerical and real examples to test the proposal are given.	[Cruz, Benjamin; Barron, Ricardo; Sossa, Humberto] IPN, Ctr Invest Computac, Mexico City 07738, DF, Mexico	Cruz, B (reprint author), IPN, Ctr Invest Computac, Av Juan Dios Batiz, Mexico City 07738, DF, Mexico.	benjamincruz@sagitario.cic.ipn.mx; rbarron@cic.ipn.mx; hsossa@cic.ipn.mx					BARRON R, 2008, AGACSE IN PRESS; BARRON R, 2006, RES COMPUTING SCI, V21, P49; Clifford W, 1878, AM J MATH, V1, P350; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DORST L, 2005, 3D EUCLIDEAN GEOMETR; Hestenes D., 1984, CLIFFORD ALGEBRA GEO; HILDEBRAND D, 2005, GEOMETRIC COMPUTING; HILDEBRAND D, 2004, EUROGRAPHICS 2004 TU; Perwass C., 2003, 0310 CHRIST ALBR U K	9	1	1	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88635-8	LECT NOTES ARTIF INT			2008	5317						273	283				11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BIQ13	WOS:000261873400026		
J	Castellana, L; Biagi, PF				Castellana, L.; Biagi, P. F.			Detection of hydrogeochemical seismic precursors by a statistical learning model	NATURAL HAZARDS AND EARTH SYSTEM SCIENCES			English	Article							OUT PREDICTION ERROR; STRONG EARTHQUAKES; KAMCHATKA RUSSIA; SUPPORT VECTOR; TIME-SERIES; CLASSIFICATION; MACHINES; CANNOT; SIZE	The problem of detecting the occurrence of an earthquake precursor is faced in the general framework of the statistical learning theory. The aim of this work is both to build models able to detect seismic precursors from time series of different geochemical signals and to provide an estimate of number of false positives. The model we used is k-Nearest-Neighbor classifier for discriminating "no-disturbed signal", "seismic precursor" and "co-post seismic precursor" in time series relative to thirteen different hydrogeochemical parameters collected in water samples from a natural spring in Kamchachta (Russia) peninsula. The measurements collected are ion content (Na, Cl, Ca, HCO(3), H(3)BO(3)), parameters (pH, Q, T) and gases (N(2), CO(2), CH(4), O(2), Ag). The classification error is measured by Leave-K-Out-Cross-Validation procedure. Our study shows that the most discriminative ions for detecting seismic precursors are Cl and Na having an error rates of 15%. Moreover, the most discriminative parameters and gases are Q and CH(4) respectively, with error rate of 21%. The ions result the most informative hydrogeochemicals for detecting seismic precursors due to the peculiarities of the mechanisms involved in earthquake preparation. Finally we show that the information collected some month before the event under analysis are necessary to improve the classification accuracy.	[Castellana, L.; Biagi, P. F.] Univ Bari, Dept Phys, I-70126 Bari, Italy	Biagi, PF (reprint author), Univ Bari, Dept Phys, Via Amendola 173, I-70126 Bari, Italy.	biagi@fisica.uniba.it					Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Ancona N, 2006, PHYSICA A, V365, P491, DOI 10.1016/j.physa.2005.09.065; Ancona N, 2006, BMC Bioinformatics, V7, P387, DOI 10.1186/1471-2105-7-387; Ancona N, 2003, IMAGE VISION COMPUT, V21, P675, DOI 10.1016/S0262-8856(03)00063-5; Ancona N, 2005, PHYSIOL MEAS, V26, P363, DOI 10.1088/0967-3334/26/4/003; Biagi PF, 2006, NAT HAZARD EARTH SYS, V6, P853; Biagi PF, 2001, NAT HAZARD EARTH SYS, V1, P9; Biagi PF, 2000, NAT HAZARDS, V21, P263, DOI 10.1023/A:1008178104003; Biagi PF, 2000, PURE APPL GEOPHYS, V157, P1359, DOI 10.1007/PL00001123; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; Distante C, 2003, SENSOR ACTUAT B-CHEM, V88, P30, DOI 10.1016/S0925-4005(02)00306-4; DOBROVOLSKY IP, 1979, PURE APPL GEOPHYS, V117, P1025, DOI 10.1007/BF00876083; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Geller RJ, 1997, SCIENCE, V275, P1616, DOI 10.1126/science.275.5306.1616; Guangcai Wang, 2005, Ground Water, V43, P478, DOI 10.1111/j.1745-6584.2005.0037.x; Hattori K, 2004, PHYS CHEM EARTH, V29, P481, DOI 10.1016/j.pce.2003.09.019; Kingsley SP, 2001, PHYS CHEM EARTH PT C, V26, P769, DOI 10.1016/S1464-1917(01)95023-8; Luntz A, 1969, TECHNICHESKAYA KIBER, V3, P563; Molchanov O, 2003, NAT HAZARD EARTH SYS, V3, P203; Mukherjee S, 2003, J COMPUT BIOL, V10, P119, DOI 10.1089/106652703321825928; Rozhnoi A, 2004, PHYS CHEM EARTH, V29, P589, DOI 10.1016/j.pce.2003.08.061; Stephenson RA, 2003, SEDIMENT GEOL, V156, P59, DOI 10.1016/S0037-0738(02)00282-8; Telesca L, 2005, NAT HAZARDS, V34, P177, DOI 10.1007/s11069-004-0687-y; Tibshirani R., 2001, ELEMENTS STAT LEARNI; Toutain JP, 1999, TECTONOPHYSICS, V304, P1, DOI 10.1016/S0040-1951(98)00295-9; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; VOROBIEVA IA, 1993, PURE APPL GEOPHYS, V141, P25, DOI 10.1007/BF00876232; Wyss M, 1997, SCIENCE, V278, P487, DOI 10.1126/science.278.5337.487	30	0	0	3	4	COPERNICUS PUBLICATIONS	KATHLENBURG-LINDAU	MAX-PLANCK-STR 13, KATHLENBURG-LINDAU, 37191, GERMANY	1561-8633			NAT HAZARD EARTH SYS	Nat. Hazards Earth Syst. Sci.		2008	8	6					1207	1216				10	Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources	Geology; Meteorology & Atmospheric Sciences; Water Resources	407RF	WOS:000263381300001		
J	Chou, KC; Shen, HB				Chou, Kuo-Chen; Shen, Hong-Bin			Cell-PLoc: a package of Web servers for predicting subcellular localization of proteins in various organisms	NATURE PROTOCOLS			English	Article							AMINO-ACID-COMPOSITION; SUPPORT VECTOR MACHINE; FUNCTIONAL DOMAIN COMPOSITION; STRUCTURAL CLASS PREDICTION; GRAM-NEGATIVE BACTERIA; LOCATION PREDICTION; SIGNAL PEPTIDES; ENSEMBLE CLASSIFIER; GENE ONTOLOGY; HYPOTHETICAL PROTEINS	Information on subcellular localization of proteins is important to molecular cell biology, proteomics, system biology and drug discovery. To provide the vast majority of experimental scientists with a user-friendly tool in these areas, we present a package of Web servers developed recently by hybridizing the 'higher level' approach with the ab initio approach. The package is called Cell-PLoc and contains the following six predictors: Euk-mPLoc, Hum-mPLoc, Plant-PLoc, Gpos-PLoc, Gneg-PLoc and Virus-PLoc, specialized for eukaryotic, human, plant, Gram-positive bacterial, Gram-negative bacterial and viral proteins, respectively. Using these Web servers, one can easily get the desired prediction results with a high expected accuracy, as demonstrated by a series of cross-validation tests on the benchmark data sets that covered up to 22 subcellular location sites and in which none of the proteins included had >= 25% sequence identity to any other protein in the same subcellular-location subset. Some of these Web servers can be particularly used to deal with multiplex proteins as well, which may simultaneously exist at, or move between, two or more different subcellular locations. Proteins with multiple locations or dynamic features of this kind are particularly interesting, because they may have some special biological functions intriguing to investigators in both basic research and drug discovery. This protocol is a step-by-step guide on how to use the Web-server predictors in the Cell-PLoc package. The computational time for each prediction is less than 5 s in most cases. The Cell-PLoc package is freely accessible at http://chou.med.harvard.edu/bioinf/Cell-PLoc.	[Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA; [Shen, Hong-Bin] Harvard Univ, Sch Med, Dept Biol Chem & Mol Pharmacol, Boston, MA 02115 USA	Chou, KC (reprint author), Gordon Life Sci Inst, 13784 Torrey Mar Dr, San Diego, CA 92130 USA.	kcchou@gordonlifescience.org; hbshen@crystal.harvard.edu	Chou, Kuo-Chen/A-8340-2009				Afjehi-Sadat L, 2007, J PROTEOME RES, V6, P711, DOI 10.1021/pr060453o; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Apweiler R, 2001, NUCLEIC ACIDS RES, V29, P37, DOI 10.1093/nar/29.1.37; Ashburner M, 2000, NAT GENET, V25, P25; Bairoch A, 1997, NUCLEIC ACIDS RES, V25, P31, DOI 10.1093/nar/25.1.31; Becker HF, 1997, NUCLEIC ACIDS RES, V25, P4493, DOI 10.1093/nar/25.22.4493; Bendtsen JD, 2004, J MOL BIOL, V340, P783, DOI 10.1016/j.jmb.2004.05.028; Cao YF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-20; Cedano J, 1997, J MOL BIOL, V266, P594, DOI 10.1006/jmbi.1996.0804; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chen YL, 2007, J THEOR BIOL, V245, P775, DOI 10.1016/j.jtbi.2006.11.010; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; DIAO Y, 2007, AMINO ACIDS; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Ehrlich JS, 2002, DEV CELL, V3, P259, DOI 10.1016/S1534-5807(02)00216-2; Emanuelsson O, 2007, NAT PROTOC, V2, P953, DOI 10.1038/nprot.2007.131; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Feng ZP, 2001, BIOPOLYMERS, V58, P491, DOI 10.1002/1097-0282(20010415)58:5<491::AID-BIP1024>3.0.CO;2-I; Feng ZP, 2001, INT J BIOL MACROMOL, V28, P255, DOI 10.1016/S0141-8130(01)00121-0; Feng Zhi-Ping, 2002, In Silico Biology, V2, P291; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Gao QB, 2005, FEBS LETT, V579, P3444, DOI 10.1016/j.febslet.2005.05.021; Gardy JL, 2003, NUCLEIC ACIDS RES, V31, P3613, DOI 10.1093/nar/gkg602; Garg A, 2005, J BIOL CHEM, V280, P14427, DOI 10.1074/jbc.M411789200; GEIER C, 1989, EUR J BIOCHEM, V183, P611, DOI 10.1111/j.1432-1033.1989.tb21090.x; Glory E, 2007, DEV CELL, V12, P7, DOI 10.1016/j.devcel.2006.12.007; Guo J, 2006, PROTEOMICS, V6, P5099, DOI 10.1002/pmic.200600064; Hill DP, 2002, GENOME RES, V12, P1982, DOI 10.1101/gr.580102; Hiller K, 2004, NUCLEIC ACIDS RES, V32, pW375, DOI 10.1093/nar/gkh378; Ho VSM, 2007, PROTEIN PEPTIDE LETT, V14, P828; Hoglund A, 2006, BIOINFORMATICS, V22, P1158, DOI 10.1093/bioinformatics/btl002; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; Huang Y, 2004, BIOINFORMATICS, V20, P21, DOI 10.1093/bioinformatics/btg366; Jackson S, 2006, PLANT CELL, V18, P1100, DOI 10.1105/tpc.106.042192; Jahandideh S, 2007, BIOPHYS CHEM, V128, P87, DOI 10.1016/j.bpc.2007.03.006; Jorgensen R, 2006, PLANT CELL, V18, P1099, DOI 10.1105/tpc.106.180580; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Kurgan LA, 2007, J THEOR BIOL, V248, P354, DOI 10.1016/j.jtbi.2007.05.017; Lee K, 2006, NUCLEIC ACIDS RES, V34, P4655, DOI 10.1093/nar/gkl638; Lei ZD, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-291; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Lubec G, 2007, CHEM REV, V107, P3568, DOI 10.1021/cr068213f; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Matsuda S, 2005, PROTEIN SCI, V14, P2804, DOI 10.1110/ps.051597405; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; Murphy R F, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P251; Nair R, 2002, PROTEIN SCI, V11, P2836, DOI 10.1110/ps.0207402; NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9; Nakai K, 2000, ADV PROTEIN CHEM, V54, P277, DOI 10.1016/S0065-3233(00)54009-1; Nakai K, 1999, TRENDS BIOCHEM SCI, V24, P34, DOI 10.1016/S0968-0004(98)01336-X; NAKASHIMA H, 1994, J MOL BIOL, V238, P54, DOI 10.1006/jmbi.1994.1267; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Park KJ, 2003, BIOINFORMATICS, V19, P1656, DOI 10.1093/bioinformatics/btg222; Pierleoni A, 2006, BIOINFORMATICS, V22, pE408, DOI 10.1093/bioinformatics/btl222; Pu Xian, 2007, J Theor Biol, V247, P259, DOI 10.1016/j.jtbi.2007.01.016; Regev-Rudzki N, 2007, BIOESSAYS, V29, P772, DOI 10.1002/bies.20609; Reinhardt A, 1998, NUCLEIC ACIDS RES, V26, P2230, DOI 10.1093/nar/26.9.2230; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; SHEN HB, 2007, ANAL BIOCH; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shi JY, 2007, AMINO ACIDS, V33, P69, DOI 10.1007/s00726-006-0475-y; Vapnik V, 1998, STAT LEAMING THEORY; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Xiao ZJ, 2006, LEUKEMIA RES, V30, P54, DOI 10.1016/j.leukres.2005.05.012; Yuan Z, 1999, FEBS LETT, V451, P23, DOI 10.1016/S0014-5793(99)00506-2; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhang ZH, 2006, FEBS LETT, V580, P6169, DOI 10.1016/j.febslet.2006.10.017; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	96	541	549	8	37	NATURE PUBLISHING GROUP	LONDON	MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1754-2189			NAT PROTOC	Nat. Protoc.		2008	3	2					153	162		10.1038/nprot.2007.494		10	Biochemical Research Methods	Biochemistry & Molecular Biology	276JL	WOS:000254137000001	18274516	
S	Luo, HE; Sudibyo, Y; Miller, LD; Karuturi, RKM		Chetty, M; Ngom, A; Ahmad, S		Luo, Huaien; Sudibyo, Yuliansa; Miller, Lance D.; Karuturi, R. Krishna Murthy			Weighted Top Score Pair Method for Gene Selection and Classification	PATTERN RECOGNITION IN BIOINFORMATICS, PROCEEDINGS	LECTURE NOTES IN BIOINFORMATICS		English	Proceedings Paper	3rd IAPR International Conference on Pattern Recognition in Bioinformatics	OCT 15-17, 2008	Melbourne, AUSTRALIA	IAPR		Microarray; Gene selection; Classification; Weighted Top Score Pairs; Cross-validation	MICROARRAY DATA; EXPRESSION DATA; CANCER; TUMOR; PREDICTION; DIAGNOSIS; PATTERNS	Gene selection and expression profiles classification are important for diagnosing the disease using microarray technology and revealing the underlying biological processes. This paper proposes a weighted top scoring pair (WTSP) method which is a generalization of the current top scoring pair (TSP) method. By considering the proportions of samples from different classes, the WTSP method aims to minimize the error or misclassification rate. Results from several experimental microarray data have shown the improved performance of classification using the WTSP method.	[Luo, Huaien; Miller, Lance D.; Karuturi, R. Krishna Murthy] Genome Inst Singapore, Singapore, Singapore	Karuturi, RKM (reprint author), Genome Inst Singapore, Singapore, Singapore.						Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Bo TH, 2002, GENOME BIOL, V3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dai JJ, 2006, STAT APPL GENET MOL, V5; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Dudoit S, 2002, STAT SINICA, V12, P111; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Geman D, 2004, STAT APPL GENET MOL, V3, P19; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gordon GJ, 2002, CANCER RES, V62, P4963; Hanczar B, 2007, BIOINFORMATICS, V23, P2866, DOI 10.1093/bioinformatics/btm429; KARUTURI RKM, 2004, P 4 IEEE S BIOINF BI; KARUTURI RKM, 2006, P INT C DAT MIN DMIN; KUO WP, 2003, P AM MED INF ASS AMI; Miller LD, 2005, P NATL ACAD SCI USA, V102, P13550, DOI 10.1073/pnas.0506230102; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Price ND, 2007, P NATL ACAD SCI USA, V104, P3414, DOI 10.1073/pnas.0611373104; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Rapaport F., 2007, BMC BIOINFORMATICS, V8; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Xiong MM, 2000, BIOTECHNIQUES, V29, P1264; XU L, 2007, BMC BIOINFORMATICS, V8	26	3	3	0	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-88434-7	LECT N BIOINFORMAT			2008	5265						323	333				11	Biochemical Research Methods; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Computer Science; Mathematical & Computational Biology	BIL87	WOS:000260634000028		
B	Manouselis, N; Costopoulou, C		Uchyigit, G; Ma, MY		Manouselis, Nikos; Costopoulou, Constantina			Experimental Analysis of Multiattribute Utility Collaborative Filtering on a Synthetic Data Set	PERSONALIZATION TECHNIQUES AND RECOMMENDER SYSTEMS			English	Proceedings Paper	International Workshop on Web Personalization, Recommender Systems and Intelligent User Interfaces	OCT, 2005	Reading, ENGLAND				RECOMMENDER SYSTEMS; EMPIRICAL-ANALYSIS; ALGORITHMS; INFORMATION; SIMILARITY	Recommender systems have already been engaging multiple criteria for the production of recommendations. Such systems, referred to as multi-criteria recommenders, early demonstrated the potential of applying Multi-Criteria Decision Making (MCDM) methods to facilitate recommendation in numerous application domains. On the other hand, systematic implementation and testing of multi-criteria recommender systems in the context of real-life applications still remains rather limited. Previous studies dealing with the evaluation of recommender systems have outlined the importance of carrying out careful testing and parameterization of a recommender system, before it is actually deployed in a real setting. In this paper, the experimental analysis of several design options for three proposed multi-attribute utility collaborative filtering algorithms is presented. The data set used is synthetic, with multi-criteria evaluations that have been created using an appropriate simulation environment. This synthetic data set tries to mimic the evaluations that are expected to be collected from users in a particular application setting. The aim of the experiment is to demonstrate how a synthetic data set may be created and used to facilitate the study and selection of an appropriate recommendation algorithm, in the case that multi-criteria evaluations from real users are not available.	[Manouselis, Nikos; Costopoulou, Constantina] Agr Univ Athens, Div Informat Math & Stat, Informat Lab, Athens 11855, Greece	Manouselis, N (reprint author), Agr Univ Athens, Div Informat Math & Stat, Informat Lab, 75 Iera Odos Str, Athens 11855, Greece.	nikosm@ieee.org; tina@aua.gr					Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bakos Y, 1998, COMMUN ACM, V41, P35, DOI 10.1145/280324.280330; Breese J. S., 1998, P 14 C UNC ART INT M; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; CARENINI G, 2005, P PERS WORKSH INT US; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELGADO J, 1999, P ACM SIGIR 99 REC S; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Guan S., 2002, ELECTRON COMMER R A, V1, P314, DOI 10.1016/S1567-4223(02)00023-6; Ha V, 2003, ARTIF INTELL, V146, P149, DOI 10.1016/S0004-3702(03)000134; Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834; Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; JACQUETLAGREZE E, 2001, EUR J OPER RES, V130; Keeney R. L., 1992, VALUE FOCUSED THINKI; Konstan JA, 2004, ACM T INFORM SYST, V22, P1, DOI 10.1145/963770.963771; Lee WP, 2004, EXPERT SYST APPL, V27, P665, DOI 10.1016/j.eswa.2004.07.001; Liu DR, 2005, INFORM MANAGE-AMSTER, V42, P387, DOI 10.1016/j.im.2004.01.008; Manouselis N, 2005, INFORM SERV USE, V25, P95; MANOUSELIS N, 2006, 181 TR AGR U ATH INF; MANOUSELIS N, 2006, ENG LETT SPECIAL ISS, V13; MARITZA L, 2004, P 2004 ACM S APPL CO; MASTHOFF J, 2003, LECT NOTES ARTIF INT, P258; Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618; MONTANER M, 2004, P 6 INT C ENT INF SY, P303; NGUYEN H, 1998, P AAAI WORKSH REC SY; Papagelis M, 2005, ENG APPL ARTIF INTEL, V18, P781, DOI 10.1016/j.engappai.2005.06.010; PERNY P, 2001, INFORMATION INTERACT, V1, P9; PRICE B, 2005, P INF ANN MED M DENV; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P., 1994, P ACM C COMP SUPP CO, P175, DOI DOI 10.1145/192844.192905; ROY B., 1996, MULTICRITERIA METHOD; SARWAR B, 2000, P ACM EC 00 MINN MIN; SCHICKELZUBER V, 2005, P WORKSH KNOWL DISC; SCHMITT C, 2002, P ABIS WORKSH AD BEN; STOLZE M, 2003, P 2 WORLD C MASS CUS; Tewari G, 2003, DECIS SUPPORT SYST, V34, P127, DOI 10.1016/S0167-9236(02)00076-3; Vidgen R. A. T., 2002, J ELECTRON COMMER RE, V3, P114; Vincke P, 1992, MULTICRITERIA DECISI; Wolfinbarger M, 2003, J RETAILING, V79, P183, DOI 10.1016/S0022-4359(03)00034-4; YU K, 2001, P 2 INT WORKSH MAN I; Zeng C, 2004, INT J ELECTRON COMM, V8, P115	44	2	2	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			978-981-279-701-8				2008							111	134				24	Computer Science, Artificial Intelligence	Computer Science	BQS29	WOS:000281716200005		
S	Tran, HM; Schonwalder, J		Ho, TB; Zhou, ZH		Tran, Ha Manh; Schoenwaelder, Juergen			Fault Resolution in Case-Based Reasoning	PRICAI 2008: TRENDS IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	10th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2008)	DEC 15-19, 2008	Hanoi, VIETNAM	Vietnamese Acad Sci & Technol, Minist Sci & Technol Vietnam, Hanoi Univ Technol, Vietnam Natl Univ, Air Force Off Sci Res, Asian Off Aerosp Res & Dev		Case-Based Reasoning; Probabilistic Reasoning; Fault Resolution; Fault Management	DERIVATIONAL ANALOGY	We present a study of reasoning methods in Case-Based Reasoning, which can be applied for the communication system fault domain. Inspired by the reasoning approach of the experts in medical diagnosis, we propose a probabilistic reasoning method which comprises two processes: a ranking process restricting the scope of a problem and a selection process finding promising solutions for the problem. We experimentally evaluate this method and draw lessons from the results to improve it.	[Tran, Ha Manh; Schoenwaelder, Juergen] Jacobs Univ Bremen, Bremen, Germany	Tran, HM (reprint author), Jacobs Univ Bremen, Bremen, Germany.	h.tran@jacobs-university.de; j.schoenwaelder@jacobs-university.de					AAMODT A, 1994, AI COMMUN, V7, P39; BAREISS R, 1989, BASED KNOWLEDGE ACQU; Berry MW, 1999, SIAM REV, V41, P335, DOI 10.1137/S0036144598347035; BLUMENTHAL B, 1994, ARTIF INTELL, V67, P287, DOI 10.1016/0004-3702(94)90055-8; CARBONELL JG, 1986, MACHINE LEARNING ART; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNNINGHAM P, 1994, P 1 EUR WORKSH CAS B, P234; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DINGSOYR T, 1998, P AAAI WORKSH CAS BA; GOMES P, 2004, P 7 EUR C CAS BAS RE, P184; Heckerman D., 1994, MSRTR9407; KOTON PA, 1988, THESIS MIT; Lazkano E, 2003, LECT NOTES ARTIF INT, V2902, P171; Lewis L, 1993, P IFIP IEEE INT S IN, P671; MELCHIORS C, 1999, P 3 INT C CAS BAS RE, P510; Pearl J, 1988, PROBABILISTIC REASON; RODRIGUEZ AF, 1997, P 2 INT C CAS BAS RE, P623; SZOLOVITS P, 1978, ARTIF INTELL, V11, P115, DOI 10.1016/0004-3702(78)90014-0; TIRRI H, 1996, P 3 EUR WORKSH CAS B, P413; TRAN HM, 2008, P 19 IFIP IEEE INT W, P55; TRAN HM, 2007, P 18 IFIP IEEE INT W, P50; TRAN HM, 2007, P 1 INT C AUT INFR M, P200; VELOSO MM, 1993, MACH LEARN, V10, P249, DOI 10.1023/A:1022686910523; WINSTON PH, 1980, COMMUN ACM, V23, P689, DOI 10.1145/359038.359042; 2008, NETWORKING FORUM	25	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-89196-3	LECT NOTES ARTIF INT			2008	5351						417	429				13	Computer Science, Artificial Intelligence	Computer Science	BIT57	WOS:000262624600035		
B	Shen, HY; Li, T; Li, Z; Ching, FL			IEEE	Shen, Haiying; Li, Ting; Li, Ze; Ching, Felix			Locality sensitive hashing based searching scheme for a massive database	PROCEEDINGS IEEE SOUTHEASTCON 2008, VOLS 1 AND 2			English	Proceedings Paper	IEEE SoutheastCon 2008	APR 03-06, 2008	Huntsville, AL	IEEE			IMAGE	The rapid growth of information nowadays makes efficient information searching increasingly important for a massive database with tremendous volume of information. Traditional methods either rely on linear searching or depend on a tree structure. These methods search information in the entire database and compare a query with the records in the database during the searching process, which lead to inefficiency. This paper presents a locality sensitive hashing based searching scheme (LSS) to achieve highly efficient information searching in a massive database. LSS classifies information based on their similarities to facilitate fast information location. Based on the study and analysis of LSS, an improved scheme is further proposed to enhance the searching efficiency. Simulation results demonstrate the efficiency and effectiveness of the LSS schemes in searching information. They yield significant improvements over the efficiency of traditional methods. In addition, they guarantee successful location of the queried records.	[Shen, Haiying; Li, Ting; Li, Ze; Ching, Felix] Univ Arkansas, Dept Comp Sci & Comp Engn, Fayetteville, AR 72701 USA	Shen, HY (reprint author), Univ Arkansas, Dept Comp Sci & Comp Engn, Fayetteville, AR 72701 USA.	hshen@uark.edu; tx1005@uark.edu; zx1008@uark.edu; ching@uark.edu					Andoni A., 2005, E2LSH 0 1 USER MANUA; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; Bentley J. L., 1977, ACM T MATH SOFTWARE, V3, P209; Brin S., 1995, P 21 INT C VER LARG, P574; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datar M., 2003, DIMACS WORKSH STREAM; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devroye L., 1982, HDB STAT, V2; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; Fu AW, 2000, VLDB J, V9, P154, DOI 10.1007/PL00010672; HU JJ, 2005, 6 INT C WAIM 2005 HA; Indyk P., 1998, P S THEOR COMP; Kruskal J, 1978, MULTIDIMENSIONAL SCA; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; PANIGRAHY R, 2006, NEAREST NEIGHBOR SEA; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; RIJSBERGEN CJV, 1990, INFORM RETRIEVAL; SALTON G, 1989, READING; White D.A., 1996, VCL96101 U CAL; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; ZOLOTAREV VM, 1986, T MATH MONOGRAPHS, V65; HAMMING DISTANCE; LSH ALGORITHM IMPLEM; 2006, NSA HAS MASSIVE DATA	25	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-1883-1				2008							123	128				6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BHW78	WOS:000257094700028		
B	Zhang, N; Wang, XZ; Xiao, T			IEEE	Zhang, Ning; Wang, Xi-Zhao; Xiao, Tao			An instance selection algorithm based on contribution	PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7			English	Proceedings Paper	7th International Conference on Machine Learning and Cybernetics	JUL 12-15, 2008	Kunming, PEOPLES R CHINA	Hebei Univ, IEEE Syst, Man & Cybernet Soc, Yunnan Univ, Machine Learning & Cybernet Res Inst		instance selection; nearest neighbor rule; condensed set; MCS; FCNN	NEAREST-NEIGHBOR RULE; CLASSIFICATION	This paper presents an approach to instance selection for the nearest neighbor rule which aims to obtain a condensed set with high condensing rate and prediction accuracy. By making an improvement on MCS algorithm and allowing certain error rate on the training set, a condensed set with high condensing rate and satisfying prediction accuracy is obtained. The condensed set is order-independent of the training instances and insensitive to noise. Comparative experiments have been conducted on real data sets, and the results show its superiority to MCS and FCNN in terms of condensing rate and prediction accuracy.	[Zhang, Ning; Wang, Xi-Zhao] Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding 071002, Hebei, Peoples R China	Zhang, N (reprint author), Hebei Univ, Coll Math & Comp Sci, Key Lab Machine Learning & Computat Intelligence, Baoding 071002, Hebei, Peoples R China.						Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CANO JR, 2003, IEEE T EVOLUTIONARY, V7; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JOSEFEDERICO, 2006, IEEE P 15 INT C COMP, P73; LI YG, 2005, IEEE INT C, V14, P950; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Vicente C., 2001, IEEE T SYST MAN CY B, V31, P408; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6	13	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2095-7				2008							919	923				5	Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BII01	WOS:000259604900168		
B	Lou, Z; Jin, Z; Zhao, XC		Gong, QY; Jiang, Y; Yao, DZ		Lou, Zhen; Jin, Zhong; Zhao, Xuecheng			Correlation-Based Local Mean Classifier For Pattern Recognition	PROCEEDINGS OF 2008 INTERNATIONAL PRE-OLYMPIC CONGRESS ON COMPUTER SCIENCE, VOL I: COMPUTER SCIENCE AND ENGINEERING			English	Proceedings Paper	International Pre-Olympic Congress on Computer Science	AUG 04-07, 2008	Nanjing, PEOPLES R CHINA			pattern recognition; local mean classifier; correlation coefficient	FACE RECOGNITION; NEAREST	There is a relatively recent interest in generalizing the representational capacity of available prototypes. In this paper, a correlation-based local mean classifier was proposed. Experiments were performed on UCI machine learning database and CENPAMI handwriting digit database. The proposed correlation-based local mean classifier was shown to be encouraging.	[Lou, Zhen; Jin, Zhong; Zhao, Xuecheng] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China	Zhao, XC (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.						Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; LIU CL, 1999, P 5 INT C DOC AN REC, V8, P378; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; Webb AR, 2002, STAT PATTERN RECOGNI; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	8	0	0	0	0	WORLD ACAD UNION-WORLD ACAD PRESS	LIVERPOOL	113, ACADEMIC HOUSE, MILL LANE, WAVERTREE TECHNOLOGY PARK, LIVERPOOL, L13 4 AH, ENGLAND			978-1-84626-051-3				2008							187	192				6	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Computer Science	BII02	WOS:000259605200039		
B	Yang, J; Yang, JY; Jin, Z			IEEE	Yang, Jian; Yang, Jingyu; Jin, Zhong			New Concept for Discriminator Design: From Classifier to Discriminator	PROCEEDINGS OF THE 2008 CHINESE CONFERENCE ON PATTERN RECOGNITION (CCPR 2008)			English	Proceedings Paper	Chinese Conference one Pattern Recognition	DEC 22-24, 2008	Beijing, PEOPLES R CHINA	Chinese Assoc Automat, Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, CAA, Pattern Recognit & Machine Intelligence Comm, IEEE		Classification; classifier; feature extraction; discriminant analysis; dimensionality reduction; pattern recognition	PATTERN-CLASSIFICATION; FACE RECOGNITION	This paper introduces a new concept of designing a discriminant analysis method (discriminator), which starts from a local mean based nearest neighbor (LM-NN) classifier and uses its decision rule to direct the design of a discriminator. The derived discriminator, called local mean based nearest neighbor discriminator (LM-NND), matches the LM-NN classifier optimally in theory. The proposed LM-NND method is evaluated using the CENPARMI handwritten numeral database, the ETH80 object category database and the PolyU Palmprint database. The experimental results demonstrate the effectiveness of LM-NND and the LM-NN classifier based pattern recognition system.	[Yang, Jian; Yang, Jingyu; Jin, Zhong] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China	Yang, J (reprint author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.	csjyang@mail.njust.edu.cn; yangjy@mail.njust.edu.cn; zhongjin@mail.njust.edu.cn					Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Du H, 2007, PATTERN RECOGN, V40, P1486, DOI 10.1016/j.patcog.2006.10.021; Fukunaga K., 1990, INTRO STAT PATTERN R; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Leibe B., 2003, INT C COMP VIS PATT; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Lou Z., 2006, P 18 INT C PATT REC, V3, P87; Mikat S., 1999, IEEE INT WORKSH NEUR, P41; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; Vincent P., 2002, ADV NEURAL INFORM PR; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	16	1	1	0	14	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2316-3				2008							18	23				6	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	BJC58	WOS:000264749900004		
B	Zeng, Y; Wang, B; Zhao, L; Yang, YP		Cheng, D		Zeng Yong; Wang Bing; Zhao Liang; Yang Yupu			The Extended Nearest Neighbor Classification	Proceedings of the 27th Chinese Control Conference, Vol 4			English	Proceedings Paper	27th Chinese Control Conference	JUL 16-18, 2008	Kunming, PEOPLES R CHINA	Chinese Assoc Automat, Tech Comm Control Theory, Kunming Univ Sci & Technol, Yunnan Div, Chinese Assoc Automat, IEEE Control Syst Soc, Soc Instrument & Control Engineers Japan, Inst Control Robot & Syst Korea, IEEE Control Syst Soc, Singapore Chapter, CAS, Inst Syst Sci, Acad Math & Syst Sci, Yunnan Normal Univ, CAI Div, Hong Kong Inst Engineers		k-nearest neighbor classification rule (k-NNR); Local mean vector; Class mean vector	RULE	The k-nearest neighbor classification rule (k-NNR) is among the most popular and successful pattern classification techniques. However, it usually suffers from the existing outliers, and in the small training samples situation, it performed poor. In this paper, a variant of the k-NNR, the extended nearest neighbor classification based on the local mean vector and the class mean Vector has been proposed. The proposed classification method overcomes the influence of the existing outliers and performs obviously well than the traditional k-NNR in terms of the classification error rate on the unknown: patterns.	[Zeng Yong; Zhao Liang; Yang Yupu] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China	Zeng, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.	zeng_yong@sjtu.edu.cn; wangb1009@163.com					Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; Hastie T, 1996, ADV NEUR IN, V8, P409; JAIN AK, 1998, PATTERN RECOGNITION; Kohavi R., 1997, P 9 EUR C MACH LEARN; Merz C., 1997, UCI REPOSITORY MACHI; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; PENROD C, 1977, IEEE T SYST MAN CYB, P92; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6	18	0	0	0	8	BEIJING UNIV AERONAUTICS & ASTRONAUTICS PRESS	HAIDIAN QU DISTRICT	37 XUE YUAN RD, HAIDIAN QU DISTRICT, BEIJING 100083, PEOPLES R CHINA							2008							559	563				5	Automation & Control Systems	Automation & Control Systems	BII51	WOS:000259745300122		
S	Olvera-Lopez, JA; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		RuizShulcloper, J; Kropatsch, WG		Olvera-Lopez, J. Arturo; Carrasco-Ochoa, J. Ariel; Martinez-Trinidad, J. Fco.			Prototype Selection Via Prototype Relevance	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS AND APPLICATIONS, PROCEEDINGS	LECTURE NOTES IN COMPUTER SCIENCE		English	Proceedings Paper	13th Iberoamerican Congress on Progress in Pattern Recognition, Image Analysis and Applications	SEP 09-12, 2008	Havana, CUBA	Adv Technol Applicat Ctr, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Cuban Soc Math & Comp Sci, Mexican Assoc Comp Vis, Neural Comp & Robotics, SIGPR-SBC, Spanish Assoc Pattern Recognit & Image Anal, Portuguese Assoc Pattern Recognit		Prototype selection; border prototypes; supervised classification; data reduction	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS	In Pattern recognition, the supervised classifiers use a training set T for classifying new prototypes. In practice, not all information in T is useful for classification therefore it is necessary to discard irrelevant prototypes from T. This process is known as prototype selection, which is an important task for classifiers since through this process the time in the training and/or classification stages could be reduced. Several prototype selection methods have been proposed following the Nearest Neighbor (NN) ruled in this work. we propose a new prototype selection method based oil the prototype relevance and border prototypes, which is faster (over large datasets) than the other tested prototype selection methods. We report experimental results showing the effectiveness of our method and compare accuracy and runtimes against other prototype selection methods.	[Olvera-Lopez, J. Arturo; Carrasco-Ochoa, J. Ariel; Martinez-Trinidad, J. Fco.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72840, Mexico	Olvera-Lopez, JA (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1,Sta Maria Tonantzintla, Puebla 72840, Mexico.						Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHIENHSING C, 2006, 18 INT C PATT REC, V2, P556, DOI 10.1109/ICPR.2006.1119; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1980, 5TH P INT C PATT REC, P72; Duda R O, 2001, PATTERN CLASSIFICATI; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; *U CAL SCH INF COM, UCI MACH LEARN REP; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	14	3	3	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-85919-2	LECT NOTES COMPUT SC			2008	5197						153	160				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BII86	WOS:000259899200019		
S	Ribeiro, JHB; Hashimoto, RF			IEEE Computer Society	Burckas Ribeiro, Joao Henrique; Hashimoto, Ronaldo Fumio			A New Training Algorithm for Pattern Recognition Technique Based on Straight Line Segments	SIBGRAPI 2008: XXI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING	SIBGRAPI - Brazilian Symposium on Computer Graphics and Image Processing		English	Proceedings Paper	21st Brazilian Symposium on Computer Graphics and Image Processing	OCT 12-15, 2008	Campo Grande, BRAZIL	Brazilian Comput Soc			NEAREST FEATURE LINE; FACE RECOGNITION; CLASSIFICATION; CLASSIFIERS	Recently, a new Pattern Recognition technique based oil straight line segments (SLSs) was presented. The key issue in this new technique is to find a function based on distances between points and two sets of SLSs that minimizes a certain error or risk criterion. An algorithm for solving this optimization problem is called training algorithm. Although this technique seems to be very promising, the first presented training algorithm is based on a heuristic. In fact, the search for this best function is a hard nonlinear optimization problem. In this paper we present a new and improved training algorithm for the SLS technique based on gradient descent optimization method. We have applied this new training algorithm to artificial and public data sets and their results confirm the improvement of this methodology.	[Burckas Ribeiro, Joao Henrique; Hashimoto, Ronaldo Fumio] Univ Sao Paulo, Inst Matemat & Estat, Dept Ciencia Computacao, Sao Paulo, Brazil	Ribeiro, JHB (reprint author), Univ Sao Paulo, Inst Matemat & Estat, Dept Ciencia Computacao, Rua Matao 1010, Sao Paulo, Brazil.	burckas@ime.usp.br; ronaldo@ime.usp.br	Hashimoto, Ronaldo/B-6544-2013	Hashimoto, Ronaldo/0000-0002-6399-8790			Asuncion A., 2007, UCI MACHINE LEARNING; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chen JH, 2004, PATTERN RECOGN, V37, P1913, DOI 10.1016/j.patcog.2003.12.003; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Du H, 2007, PATTERN RECOGN, V40, P1486, DOI 10.1016/j.patcog.2006.10.021; Duda R O, 2001, PATTERN CLASSIFICATI; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Gottfried BS, 1973, INTRO OPTIMIZATION T; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Michie D., 1994, MACHINE LEARNING NEU; Ribeiro JHB, 2006, ICMLA 2006: 5th International Conference on Machine Learning and Applications, Proceedings, P10; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; ZHOU JWY, 2004, EXTENDED NEAREST FEA, V3157	19	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1530-1834		978-0-7695-3358-2	SIBGRAPI			2008							19	26		10.1109/SIBGRAPI.2008.35		8	Computer Science, Software Engineering; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIN09	WOS:000260989600003		
B	Meher, SK				Meher, Saroj K.			A New Fuzzy Supervised Classification Method based on Aggregation Operator	SITIS 2007: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGIES & INTERNET BASED SYSTEMS			English	Proceedings Paper	IEEE International Conference on Signal Image Technology and Internet Based Systems	DEC 16-19, 2007	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Shanghai Jiatong Univ, SIGAPP fr		Pattern recognition; fuzzy classifier; aggregation operators	REMOTE-SENSING IMAGES; PATTERN-CLASSIFICATION; ALGORITHM; RULES; SETS	A new fuzzy supervised classification method based on aggregation operator is proposed in the present article. The proposed classifier aggregates the information extracted by exploring feature-wise degree of belonging to classes. It uses a pi-type membership function and MEAN (average) aggregation reasoning rule (operator). The effectiveness of the proposed classifier is verified with four benchmark data sets including a realtime financial domain data. Various performance measures are used for quantitative evaluation of the classifier Experimental results on these data sets illustrate significant improvement in the classification performance of the proposed method compared to three other fuzzy classifiers, namely, explicit fuzzy, fuzzy k-nearest neighbor and fuzzy maximum likelihood.	Satyam Comp Serv Ltd, Appl Res Grp, Entrepreneurship Ctr, Bangalore 560012, Karnataka, India	Meher, SK (reprint author), Satyam Comp Serv Ltd, Appl Res Grp, Entrepreneurship Ctr, SID Block,IISc Campus, Bangalore 560012, Karnataka, India.						ABE S, 1995, IEEE T FUZZY SYST, V3, P18, DOI 10.1109/91.366565; ABONYI J, 2000, SIMPLE FUZZY CLASSIF; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; CHEN CF, 1999, P AS C REM SENS ACRS; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D, 2004, FUZZY SET SYST, V142, P143, DOI 10.1016/j.fss.2003.10.038; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Haykin S., 1998, NEURAL NETWORKS COMP, V2nd; ISHIBUCHI H, 1992, FUZZY SET SYST, V52, P21, DOI 10.1016/0165-0114(92)90032-Y; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Klir G. J., 1995, FUZZY SETS FUZZY LOG; KUNCHEVA LI, 2000, FUZZY CLASSIFIER DES; MEHER SK, 2006, P INT C INF TECHN, P209; Melgani F, 2000, IEEE T GEOSCI REMOTE, V38, P287, DOI 10.1109/36.823921; Newman D., 1998, UCI REPOSITORY MACHI; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; Peneva V, 2003, FUZZY SET SYST, V139, P615, DOI [10.1016/S0165-0114(03)00141-6, 10.1016/S0165-01114(03)00141-6]; Tveter D. R., 1998, PATTERN RECOGNITION; van der Putten P., 2000, COIL CHALLENGE 2000; WANG F, 1990, IEEE T GEOSCI REMOTE, V28, P194, DOI 10.1109/36.46698; WATSON AB, 1993, DIGITAL IMAGE HUMAN; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	23	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3122-9				2008							876	882				7	Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BII29	WOS:000259670300115		
B	Chong, RM; Tanaka, T			IEEE Computer Society	Chong, Rachel Mabanag; Tanaka, Toshihisa			Image Extrema Analysis and Blur Detection with Identification	SITIS 2008: 4TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY AND INTERNET BASED SYSTEMS, PROCEEDINGS			English	Proceedings Paper	4th International Conference on Signal Image Technology and Internet Bases Systems	NOV 30-DEC 03, 2008	Bali, INDONESIA	IEEE, IEEE Comp Soc, Univ Gunadarma, Univ Bourgogne, ACM SIGAPP				In real image processing applications, images may be blurred or not. When blur is present, the type and degree of degradation vary from one image to another. The process of restoring these images are usually computationally demanding so that there is a need to first detect blurs. If an image is not blurred then it need not undergo the restoration process. In this work, a novel algorithm that simultaneously detects and identifies blurs, is proposed. This method is based on the analysis of extrema values in an image. The extrema histograms are first constructed then analyzed in order to extract feature values. The distinctness of these values in the presence of blur is used. It is computationally, simple and fast thereby making it suitable for preprocessing especially in practical imaging applications. Experimental results on natural images and its synthetically blurred versions show the validity of the proposed method.	[Chong, Rachel Mabanag; Tanaka, Toshihisa] Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Koganei, Tokyo 1848588, Japan	Chong, RM (reprint author), Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, 2-24-16 Naka Cho, Koganei, Tokyo 1848588, Japan.	chong@sip.tuat.ac.jp; tanakat@cc.tuat.ac.jp					AIZENBERG I, 2006, COMPUTATIONAL INTELL, V17, P441; AIZENBERG I, 2002, ICANN 02, P1231; AIZENBERG I, 2006, SOFT COMPUT, V11, P169; Chung Y.-C., 2004, 2004 IEEE C CYB INT, V1, P356; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363; KUNDUR D, 1996, IEEE SIGNAL PROCESSI, V13, P47; LAGENDIJK RL, 2000, HDB IMAGE VIDEO PROC, P125; Marziliano P., 2002, P INT C IM PROC ROCH, V3, P57; TONG H, 2004, 2004 IEEE INT C MULT, V1, P17	10	2	2	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3493-0				2008							320	326		10.1109/SITIS.2008.38		7	Computer Science, Software Engineering; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BIV55	WOS:000263157200043		
J	Morante, R			European Language Resources Association	Morante, Roser			Semantic role labeling tools trained on the Cast3LB-CoNNL-SemRol corpus	SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008			English	Proceedings Paper	6th International Conference on Language Resources and Evaluation (LREC)	MAY 28-30, 2008	Marrakech, MOROCCO	European Language Resources Assoc (ELRA), Evaluat & Language Resources Distribut Agcy (ELDA), Ist Linguistica Computazionale (ILC), Nuance, Inst Nederlandse Lexicologie (INL), Microsoft, European Media Lab GmBH (EML), Linguatec, Connexor, Orange, Telisma, AAMT, AMTA, ACL, AFNLP, ALTA, COCOSDA, Oriental COCOSDA, EACL, EAMT, ELSNET, EURALEX, GWA, IAMT, ISCA, KnowledgeWeb, LDC, NEMLAR Network, SIGLEX, TEI, Technolangue French Program, WRITE, Informat Soc & Media, European Commiss, Unit E 2 Content & Knowledge			CLASSIFICATION; STRATEGIES	In this paper we present the Cast3LB-CoNLL-SemRol corpus, currently the only corpus of Spanish annotated with dependency syntax and semantic roles, and the tools that have been trained on the corpus: an ensemble of parsers and two dependency-based semantic role labelers that are the only semantic role labelers based on dependency syntax available for Spanish at this moment. One of the systems uses information from gold standard syntax, whereas the other one uses information from predicted syntax. The results of the first system (86 F-1) are comparable to current state of the art results for constituent-based semantic role labeling of Spanish. The results of the second are 11 points lower. This work has been carried out as part of the project Tecnicas semiautomaticas para el etiquetado de roles semanticos en corpus del espanol.	[Morante, Roser] Tilburg Univ, ILK, NL-5000 LE Tilburg, Netherlands		R.Morante@uvt.nl					Buchholz S., 2006, P 10 CONLL SHAR TASK; Canisius S., 2007, P CONLL SHAR TASK SE, P1124; Carreras X., 2005, P 9 C COMP NAT LANG, P152, DOI 10.3115/1706543.1706571; Chang C., 2005, LIBSVM LIB SUPPORT V; CIVIT M, 2006, ADV NATURAL LANGUAGE, V4139, P141, DOI 10.1007/11816508_16; Civit M., 2002, WP0006 CLICUB X TRAC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 2007, TECHNICAL REPORT SER; Daelemans W., 2005, MEMORY BASED LANGUAG; Fillmore C. J., 1968, UNIVERSALS LINGUIST, P1; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; Hacioglu K., 2004, COLING 04; Henderson J., 1999, P 4 C EMP METH NAT L; Marquez Ll., 2004, P 8 C COMP NAT LANG, P89; Marquez Ll., 2007, P SEMEVAL; Morante R., 2007, P RANLP 07, P388; Morante R., 2008, PROCESAMIENTO LENGUA, V40; Morante R., 2006, 0603 ILK TILB U; Nivre J., 2006, P 10 C COMP NAT LANG; Nivre J, 2006, TEXT SPEECH LANG TEC, V34, pVII; Nivre J., 2007, P CONLL SHAR TASK SE, P915; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Pradhan S, 2005, MACH LEARN, V60, P11, DOI 10.1007/s10994-005-0912-2; Sagae K., 2006, P HUM LANG TECHN C N, P129, DOI 10.3115/1614049.1614082; Surdeanu M, 2007, J ARTIF INTELL RES, V29, P105; Surdeanu M, 2008, LECT NOTES COMPUT SC, V4919, P206, DOI 10.1007/978-3-540-78135-6_18; Toutanova K., 2005, P 43 ANN C ASS COMP; Zeman D., 2005, P INT WORKSH PARS TE	28	0	0	0	0	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE							2008							1548	1555				8	Linguistics	Linguistics	BGS66	WOS:000324028901108		
S	Ho, TK		DaVitoria Lobo, N; Kasparis, T; Roli, F; Kwok, JT; Georgiopoulos, M; Anagnostopoulos, GC; Loog, M		Ho, Tin Kam			Data Complexity Analysis: Linkage between Context and Solution in Classification	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	Joint International Workshop on Structural, Syntactic, and Statistical Pattern Recognition	DEC 04-16, 2008	Orlando, FL	Int Assoc Pattern Recognit, Tech Committee	Univ Central Florida		PATTERN-RECOGNITION	For a classification problem that is implicitly represented by a training data set, analysis of data complexity provides a linkage between context and solution. Instead of directly optimizing classification accuracy by tuning the learning algorithms, one may seek changes ill the data sources and feature transformations to simplify the data geometry. Simplified class geometry benefits learning in a way common to many methods. We review some early results in data complexity analysis, compare these to recent advances ill manifold learning; and suggest directions for further research.			tkh@research.bell-labs.com					BAIRD HS, COMPLES IMAGE RECOGN, P287; Bengio Y., 2003, NIPS 2003, P177; CARLSSON G, 2008, TOPOLOGY DATA; CHERKASSKY V, DATA COMPLEXITY MARG, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333; DEVROYE L, 1988, IEEE T PATTERN ANAL, V10, P530, DOI 10.1109/34.3915; DUIN RPW, OBJECT REPRESENTATIO, P25; He X., 2005, NIPS 2005; Ho Tin K., 2006, DATA COMPLEXITY PATT; Ho TK, 2002, IEEE T PATTERN ANAL, V24, P289; HO TK, CLASSIFIER DOMAINS C, P135; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067; Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009; HO TK, MEASURES GEOMETRICAL, P3; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; MACIA N, 2008, P 19 INT C PAT REC T; Mansilla E.B., 2004, P 17 INT C PATT REC, V1, P136; MANSILLA EB, 2005, IEEE T EVOLUT COMPUT, V9, P82; *MECH TURK, 2005, AM; PRANCKEVICIENE E, 2006, P 18 INT C PAT REC H, V2; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; RAUDYS S, MEASURES DATA CLASSI, P59; Srivastava A, 2000, IEEE T SIGNAL PROCES, V48, P1390, DOI 10.1109/78.839985; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1982, ESTIMATION DEPENDENC; von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294	27	4	4	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-89688-3	LECT NOTES COMPUT SC			2008	5342						986	995				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BIY10	WOS:000263676700098		
J	Farcomeni, A; Serranti, S; Bonifazi, G				Farcomeni, Alessio; Serranti, Silvia; Bonifazi, Giuseppe			Non-parametric analysis of infrared spectra for recognition of glass and glass ceramic fragments in recycling plants	WASTE MANAGEMENT			English	Article							CLASSIFICATION	Glass ceramic detection in glass recycling plants represents a still unsolved problem, as glass ceramic material looks like normal glass and is usually detected only by specialized personnel. The presence of glass-like contaminants inside waste glass products, resulting from both industrial and differentiated urban waste collection, increases process production costs and reduces final product quality. In this paper an innovative approach for glass ceramic recognition, based on the non-parametric analysis of infrared spectra, is proposed and investigated. The work was specifically addressed to the spectral classification of glass and glass ceramic fragments collected in an actual recycling plant from three different production lines: flat glass, colored container-glass and white container-glass. The analyses, carried out in the near and mid-infrared (NIR-MIR) spectral field (1280-4480 nm), show that glass ceramic and glass fragments can be recognized by applying a wavelet transform, with a small classification error. Moreover, a method for selecting only a small subset of relevant wavelength ratios is suggested, allowing the conduct of a fast recognition of the two classes of materials. The results show how the proposed approach can be utilized to develop a classification engine to be integrated inside a hardware and software sorting architecture for fast "on-line" ceramic glass recognition and separation. (C) 2007 Elsevier Ltd. All rights reserved.	[Serranti, Silvia; Bonifazi, Giuseppe] Univ Roma La Sapienza, Dipartimento Ingn Chim Mat Mat Prime & Met, I-00184 Rome, Italy; [Serranti, Silvia; Bonifazi, Giuseppe] Univ Roma La Sapienza, Dipartimento Stat Probabil & Stat Applicate, I-00185 Rome, Italy	Serranti, S (reprint author), Univ Roma La Sapienza, Dipartimento Ingn Chim Mat Mat Prime & Met, Via Eudossiana 18, I-00184 Rome, Italy.	silvia.serranti@uniromal.it	Serranti, Silvia/B-3125-2011				Bonifazi G, 2006, WASTE MANAGE, V26, P627, DOI 10.1016/j.wasman.2005.06.004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUBECHIES I, 1992, CBMS NSF REGIONAL C, V91; FARCOMENI A, 2004, THESIS U ROMA SAPIEN; Hastie T, 2001, ELEMENTS STAT LEARNI; HOLAND W, 2002, GLASS CERAMIC TECHNO; OGDEN TR, 1997, ESSENTIAL WAVELETS S, P1; Pannhorst W, 1997, J NON-CRYST SOLIDS, V219, P198, DOI 10.1016/S0022-3093(97)00270-6; Serranti S, 2006, WASTE MANAGE RES, V24, P48, DOI 10.1177/0734545X06061017	9	8	8	2	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0956-053X			WASTE MANAGE	Waste Manage.		2008	28	3					557	564		10.1016/j.wasman.2007.01.019		8	Engineering, Environmental; Environmental Sciences	Engineering; Environmental Sciences & Ecology	261RL	WOS:000253097600012	17433662	
B	Parvin, H; Alizadeh, H; Minael-Bidgoli, B			Int Assoc Engineers	Parvin, Hamid; Alizadeh, Hoscin; Minael-Bidgoli, Behrouz			MKNN: Modified K-Nearest Neighbor	WCECS 2008: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	World Congress on Engineering and Computer Science (WCECS 2008)	OCT 11-24, 2008	San Francisco, CA	Int Assoc Engineers		MKNN; KNN Classification; Modified K-Nearest Neighbor; Weighted K-Nearest Neighbor	CLASSIFICATION	In this paper, a new classification method for enhancing the performance of K-Nearest Neighbor is proposed which uses robust neighbors in training data. This new classification method is called Modified K-Nearest Neighbor, MKNN. Inspired the traditional KNN algorithm, the main idea is classifying the test samples according to their neighbor tags. This method is a kind of weighted KNN so that these weights are determined using a different procedure. The procedure computes the fraction of the same labeled neighbors to the total number of neighbors. The proposed method is evaluated on five different data sets. Experiments show the excellent improvement in accuracy in comparison with KNN method.	[Parvin, Hamid; Alizadeh, Hoscin; Minael-Bidgoli, Behrouz] Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran	Parvin, H (reprint author), Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran.	h_parvin@comp.iust.ac.ir; ho_alizadeh@comp.iust.ac.ir; b_minaei@iust.ac.ir					AEBERHARD S, 9202 J COOK U N QUEE; ALIZADEH H, 2008, P INT C CON IN PRESS; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bermejo S, 2000, PATTERN RECOGN, V33, P1999, DOI 10.1016/S0031-3203(99)00186-7; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARASAY BV, NEAREST NEIGHBOR PAT; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED RA; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gose E., 1996, PATTERN RECOGNITION; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Jozwik A, 1983, PATTERN RECOGN LETT, V1, P287, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KUNCHEVA L, 2005, COMBINING PATTERN CL; PARVIN H, 2008, P INT C CON IN PRESS; PARVIN H, 2008, P INT C NET IN PRESS; SHUNICHI K, 2001, IMPROVING PERFORMANC	19	1	1	2	2	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-98671-0-2	LECT NOTES ENG COMP			2008							831	834				4	Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Computer Science; Engineering	BIW70	WOS:000263417100156		
B	Oh, JS; Choi, KS; Kwon, JR; Kim, JY		Callaos, N; Lesso, W; Zinn, CD; Baralt, J; Rutkauskas, AV; Stasytyte, V		Oh, J. S.; Choi, K. S.; Kwon, J. R.; Kim, J. Y.			Identifying the near-Workload in the Mixed database Applications	WMSCI 2008: 12TH WORLD MULTI-CONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL VI, PROCEEDINGS			English	Proceedings Paper	12th World Multi-Conference on Systemics, Cybernetics and Informatics/14th International Conference on Information Systems Analysis and Synthesis	JUN 29-JUL 02, 2008	Orlando, FL	Int Inst Informat & System, Int Federat Syst Res		Mixed workloads; k-NN classifier algorithm		Database administrators should be aware of workload characteristics for managing database systems. Workload characteristics can be different depending on database application. In particular, identifying workloads in mixed database applications might be quite difficult. Therefore, a method is necessary for identifying workloads in the mixed database application. This paper aims to identify workloads in the mixed database application using data mining technologies. To construct the mixed database application, we use the TPC-C and TPC-W benchmark. We discriminate between train workloads (workloads using the TPC-C or TPC-W benchmarks) and test workloads (mixed workloads of both benchmarks), and modify the algorithm of k-NN (Nearest Neighbor) classifier in order to satisfy our objectives. The modified k-NN algorithm measures how close the test workloads are to the train workloads. The modified k-NN algorithm is better than others for identifying workloads because its results are lower than others in the oscillation depending on the k parameter and the error rate. This research contributes towards considering flexible tuning methods using workload identification information.	[Oh, J. S.; Choi, K. S.; Kwon, J. R.; Kim, J. Y.] Korea Gas Safety Corp, Inst Gas Safety Technol, Shihung Shi 429712, Gyeonggi Do, South Korea							BAYLIS R, 2002, DATABASE ADM GUIDE R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CYRAN M, 2001, ORACLE 9I DATABASE P; Elnaffar S., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; ELNAFFAR S, 2002, P CASCON C TOR CAN; Han J. H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), DOI 10.1109/CVPR.1999.784711; Han Jiawei, 2001, DATA MINING CONCEPTS; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Martin P., 2002, International Journal on Digital Libraries, V3, DOI 10.1007/s007990100046; OH JS, 2004, J KISS D, V11, P747; *TPC, 2001, TPC BENCHM C SPEC RE; *TPC, 2002, TPC BENCHM W WEB CAM	12	0	0	0	0	INT INST INFORMATICS & SYSTEMICS	ORLANDO	14269 LORD BARCLAY DR, ORLANDO, FL 32837 USA			978-1-934272-36-7				2008							206	211				6	Business, Finance; Computer Science, Information Systems; Computer Science, Theory & Methods; Education & Educational Research; Information Science & Library Science	Business & Economics; Computer Science; Education & Educational Research; Information Science & Library Science	BIZ14	WOS:000263875200038		
J	Chen, YH; Yao, YY				Chen, Yaohua; Yao, Yiyu			A multiview approach for intelligent data analysis based on data operators	INFORMATION SCIENCES			English	Article						multiview; intelligent data analysis; modal-style data operators; concept lattice; granular computing	ROUGH SET-THEORY; PATTERN-CLASSIFICATION	Multiview intelligent data analysis explores data from different perspectives to reveal various types of structures and knowledge embedded in the data. Each view may capture a specific aspect of the data and hence satisfy the needs of a particular group of users. Collectively, multiple views provide a comprehensive description and understanding of the data. In this paper, we propose a multiview framework of intelligent data analysis based on modal-style data operators. The classes of the data operators include basic set assignment, sufficiency, dual sufficiency, necessity and possibility operators. They demonstrate various types of data relationships and characterize various features and granulated views of the data. It is shown that different structures of the data can also be constructed based on the different data operators. Crown Copyright (C) 2007 Published by Elsevier Inc. All rights reserved.	Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada	Chen, YH (reprint author), Univ Regina, Dept Comp Sci, Regina, SK S4S 0A2, Canada.	chen115y@cs.uregina.ca; yyao@cs.uregina.ca	Yao, Yiyu/B-2926-2008	Yao, Yiyu/0000-0001-6502-6226			Agarwal R., 1993, P ACM SIGMOD C MAN D, P207, DOI DOI 10.1145/170035.170072; Aleksander I., 1990, INTRO NEURAL COMPUTI; AMARI S, 1990, P IEEE, V78, P1443, DOI 10.1109/5.58324; Anderberg M. R., 1973, CLUSTER ANAL APPL; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; Bargiela A., 2002, GRANULAR COMPUTING I; Belkhouche B, 2000, INT J SOFTW ENG KNOW, V10, P557, DOI 10.1142/S021819400000033X; BELKHOUCHE B, 1996, FDN SOFTWARE ENG, P159; Breiman L., 1984, CLASSIFICATION REGRE; Buszkowski W, 1998, LECT NOTES ARTIF INT, V1424, P115; Chen Y.-H., 2006, P 2006 IEEE INT C GR, P281; Cohn P.N., 1965, UNIVERSAL ALGEBRA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duntsch I., 2003, THEORY APPL RELATION, P216; Ester M., 1996, P 2 INT C KNOWL DISC, P226; FREITAS AA, 2000, SIGKDD EXPLORATIONS, V2, P65; Gediga G., 2002, P 2002 IEEE INT C DA, P155; Grenander U., 1993, GEN PATTERN THEORY; HAN H, 2003, P 26 ANN INT ACM SIG, P445; Hand D. J., 1998, INTELL DATA ANAL, V2, P67, DOI 10.1016/S1088-467X(99)80001-8; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JEFFRIES V, 1980, SOCIAL STRATIFICATIO; Jeon B, 1999, IEEE T GEOSCI REMOTE, V37, P1073; King B., 1967, J AM STAT ASSOC, P86; KOTSIANTIS S, 2004, T INFORM SCI APPL, V1, P73; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Lin CR, 2005, IEEE T KNOWL DATA EN, V17, P628; Liu B., 1998, P 4 INT C KNOWL DISC, P80; LU SY, 1978, IEEE T SYST MAN CYB, V8, P381, DOI 10.1109/TSMC.1978.4309979; Mcqueen J., 1967, P 5 BERK S MATH STAT, P281; Michalski R.S., 1993, MULTISTRATEGY LEARNI; Minsky M., 1988, PERCEPTRONS; Nguyen SH, 2001, COMPUT INTELL, V17, P514, DOI 10.1111/0824-7935.00161; Orlowska E., 1998, INCOMPLETE INFORM RO; Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Pearl J, 1988, PROBABILISTIC REASON; Pedrycz W, 2002, INT J INTELL SYST, V17, P173, DOI 10.1002/int.10015; Pedrycz W., 2001, Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569), DOI 10.1109/NAFIPS.2001.943745; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; Sneath P.H., 1973, NUMERICAL TAXONOMY; SPRANDEL HZ, 1985, PSYCHOEDUCATIONAL US; Vapnik V., 1998, STAT LEARNING THEORY; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Wille R., 1999, FORMAL CONCEPT ANAL; Wille R., 1982, ORDERED SETS, P445; Wolski M., 2003, FUNDAMENTA INFORM CS, P1; WONG SKM, 1995, COMPUT INTELL, V11, P406, DOI 10.1111/j.1467-8640.1995.tb00041.x; Yao Y. Y., 2004, COMPUTER SCI, V31, P1; Yao YY, 2004, LECT NOTES ARTIF INT, V3066, P59; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Yao YY, 2003, LECT NOTES ARTIF INT, V2639, P44; Yao YY, 2004, P 2004 ANN M N AM FU, P796; Yin XX, 2003, SIAM PROC S, P331; Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8; Zeng H.J., 2003, P 3 IEEE INT C DAT M, P443; ZHONG N, 2005, P ICDM WORKSH FDN SE, P130; Zhong N, 2005, LECT NOTES COMPUT SC, V3776, P98; Zhu W, 2007, INFORM SCIENCES, V177, P1499, DOI 10.1016/j.ins.2006.06.009; Zhu W, 2003, INFORM SCIENCES, V152, P217, DOI 10.1016/S0020-0255(03)00056-2; ZHU W, 2007, GEN ROUGH SETS BASED; ZIMMERMANN A, 2004, P 7 INT C DISC SCI D, P60	65	47	53	0	7	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	JAN 2	2008	178	1					1	20		10.1016/j.ins.2007.08.011		20	Computer Science, Information Systems	Computer Science	228LJ	WOS:000250731100001		
J	Solomatine, DP; Maskey, M; Shrestha, DL				Solomatine, Dirnitri P.; Maskey, Mahesh; Shrestha, Durga Lal			Instance-based learning compared to other data-driven methods in hydrological forecasting	HYDROLOGICAL PROCESSES			English	Article						hydrological modelling; floods; data-driven models; instance-based learning; artificial neural networks; locally weighted regression; k-nearest neighbour method	ARTIFICIAL NEURAL-NETWORKS; RAINFALL-RUNOFF MODELS; PREDICTION	Data-driven techniques based on machine learning algorithms are becoming popular in hydrological modelling, in particular for forecasting. Artificial neural networks (ANNs) are often the first choice. The so-called instance-based learning (IBL) has received relatively little attention, and the present paper explores the applicability of these methods in the field of hydrological forecasting. Their performance is compared with that of ANNs, M5 model trees and conceptual hydrological models. Four short-term flow forecasting problems were solved for two catchments. Results showed that the IBL methods often produce better results than ANNs and M5 model trees, especially if used with the Gaussian kernel function. The study showed that IBL is an effective data-driven method that can be successfully used in hydrological forecasting. Copyright (c) 2007 John Wiley & Sons, Ltd.	[Solomatine, Dirnitri P.; Shrestha, Durga Lal] UNESCO, IHE, Inst Water Educ, NL-2601 DA Delft, Netherlands; [Maskey, Mahesh] NepalConsult P Ltd, Civil Engn, Kathmandu, Nepal	Solomatine, DP (reprint author), UNESCO, IHE, Inst Water Educ, POB 3015, NL-2601 DA Delft, Netherlands.	d.solomatine@unesco-ihe.org	Shrestha, Durga/B-5610-2013	Shrestha, Durga/0000-0002-5545-1736			Abrahart RJ, 2000, HYDROL PROCESS, V14, P2157, DOI 10.1002/1099-1085(20000815/30)14:11/12<2157::AID-HYP57>3.0.CO;2-S; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Allegra A, 1998, MAGNESIUM RES, V11, P11; BECKER A, 1987, WATER RESOUR RES, V23, P1043, DOI 10.1029/WR023i006p01043; Bray M, 2004, J HYDROINFORM, V6, P265; Cigizoglu HK, 2003, HYDROLOG SCI J, V48, P349, DOI 10.1623/hysj.48.3.349.45288; CLEVELAND WS, 1994, 953 AT T BELL LAB ST; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawson CW, 2001, PROG PHYS GEOG, V25, P80, DOI 10.1177/030913330102500104; DIBIKE Y, 1999, GEOPH RES ABSTR; Dibike YB, 2001, PHYS CHEM EARTH PT B, V26, P1, DOI 10.1016/S1464-1909(01)85005-X; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; Franchini M, 1996, HYDROLOG SCI J, V41, P21, DOI 10.1080/02626669609491476; GALEATI G, 1990, HYDROLOG SCI J, V35, P79, DOI 10.1080/02626669009492406; Gasser T., 1979, LECT NOTES MATH, V757, P23; GOVINDARAJU RS, 2000, ARTIFICIAL NEURAL NE, P329; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; HSU KL, 1995, WATER RESOUR RES, V31, P2517, DOI 10.1029/95WR01955; KARLSSON M, 1987, WATER RESOUR RES, V23, P1300, DOI 10.1029/WR023i007p01300; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Maier HR, 2000, ENVIRON MODELL SOFTW, V15, P101, DOI 10.1016/S1364-8152(99)00007-9; MARSIGLI M, 2002, MUSIC MULTIPLE SENSO; Minns AW, 1996, HYDROLOG SCI J, V41, P399, DOI 10.1080/02626669609491511; Mitchell T. M., 1997, MACH LEARN, P414; Quinlan J. R., 1992, 5 AUSTR JOINT C ART, P343; QUINLAN JR, 1993, MACH LEARN P 10 INT, P236; REFSGAARD JC, 1996, DISTRIBUTED HYDROLOG, P321; Scott D.W., 1992, MULTIVARIATE DENSITY; Shamseldin AY, 1996, J HYDROL, V179, P353, DOI 10.1016/0022-1694(95)02833-1; Shrestha DL, 2006, NEURAL NETWORKS, V19, P225, DOI 10.1016/j.neunet.2006.01.012; SHRESTHA I, 2003, CONCEPTUAL DATA DRIV; Solomatine D., 2004, 6 INT C HYDR; Solomatine D. P., 2005, ENCY HYDROLOGICAL SC; Solomatine DP, 2003, HYDROLOG SCI J, V48, P399, DOI 10.1623/hysj.48.3.399.45291; SOLOMATINE DP, 2004, J HYDROLOGIC ENG, V9; Solomatine DP, 2006, NEURAL NETWORKS, V19, P215, DOI 10.1016/j.neunet.2006.01.008; Sugawaras M, 1995, COMPUTER MODELS WATE, P165; Todini E, 1996, J HYDROL, V175, P339, DOI 10.1016/S0022-1694(96)80016-3; Toth E, 2000, J HYDROL, V239, P132, DOI 10.1016/S0022-1694(00)00344-9; Weiss SM, 1995, J ARTIF INTELL RES, V3, P383; WITTEN IH, 2000, DATA MINING PRACTICA, P132; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	42	16	17	4	6	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0885-6087			HYDROL PROCESS	Hydrol. Process.	JAN 15	2008	22	2					275	287		10.1002/hyp.6592		13	Water Resources	Water Resources	259LE	WOS:000252940000010		
J	Schalk, G; Brunner, P; Gerhardt, LA; Bischof, H; Wolpaw, JR				Schalk, G.; Brunner, P.; Gerhardt, L. A.; Bischof, H.; Wolpaw, J. R.			Brain-computer interfaces (BCIs): Detection instead of classification	JOURNAL OF NEUROSCIENCE METHODS			English	Article						brain-computer interface (BCI); electruencephalography (EEG); electrocorticography (ECoG); augmentative communication; brain-machine interface; Gaussian mixture model; background modeling; SIGFRIED	EEG-BASED DISCRIMINATION; GAUSSIAN MIXTURE-MODELS; EM ALGORITHM; FEATURE-SELECTION; COMPETITION 2003; MOVEMENT SIGNAL; HAND MOVEMENTS; COMMUNICATION; DEVICE; IMAGINATION	Many studies over the past two decades have shown that people can use brain signals to convey their intent to a computer through brain-computer interfaces (BCIs). These devices operate by recording signals from the brain and translating these signals into device commands. They can be used by people who are severely paralyzed to communicate without any use of muscle activity. One of the major impediments in translating this novel technology into clinical applications is the current requirement for preliminary analyses to identify the brain signal features best suited for communication. This paper introduces and validates signal detection, which does not require such analysis procedures, as a new concept in BCI signal processing. This detection concept is realized with Gaussian mixture models (GMMs) that are used to model resting brain activity so that any change in relevant brain signals can be detected. It is implemented in a package called SIGFRIED (SIGnal modeling For Real-time Identification and Event Detection). The results indicate that SIGFRIED produces results that are within the range of those achieved using a common analysis strategy that requires preliminary identification of signal features. They indicate that such laborious analysis procedures could be replaced by merely recording brain signals during rest. In summary, this paper demonstrates how SIGFRIED could be used to overcome one of the present impediments to translation of laboratory BCI demonstrations into clinically practical applications. (C) 2007 Published by Elsevier B.V.	[Schalk, G.; Brunner, P.; Wolpaw, J. R.] New York State Dept Hlth, Wadsworth Ctr Labs & Res, Brain Comp Interface Res & Dev Program, Albany, NY 12237 USA; [Schalk, G.; Gerhardt, L. A.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY USA; [Brunner, P.; Bischof, H.] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; [Wolpaw, J. R.] SUNY Albany, Sch Publ Hlth, Albany, NY USA	Schalk, G (reprint author), New York State Dept Hlth, Wadsworth Ctr Labs & Res, Brain Comp Interface Res & Dev Program, Albany, NY 12237 USA.	schalk@wadsworth.org		Brunner, Peter/0000-0002-2588-2754			Akaike H., 1973, P 2 INT S INF THEOR, P267; Anderer P, 1999, NEUROPSYCHOBIOLOGY, V40, P150, DOI 10.1159/000026613; Babiloni F, 2000, IEEE T REHABIL ENG, V8, P186, DOI 10.1109/86.847810; Biernacki C, 2003, COMPUT STAT DATA AN, V41, P561, DOI 10.1016/S0167-9473(02)00163-9; Birbaumer N, 1999, NATURE, V398, P297, DOI 10.1038/18581; Blanchard G, 2004, IEEE T BIO-MED ENG, V51, P1062, DOI 10.1109/TBME.2004.826691; BLANKERTZ B, 2003, BCI COMPETITION 2003; Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Burg J. P., 1967, P 37 M SOC EXPL GEOP; BURG JP, 1968, NAT ADV STUD I SIGN, P42; CACOULLO.T, 1966, ANN I STAT MATH, V18, P179, DOI 10.1007/BF02869528; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P279; Childers D. G., 1978, MODERN SPECTRUM ANAL; Costa EJX, 2000, MED ENG PHYS, V22, P345, DOI 10.1016/S1350-4533(00)00051-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Donoghue JP, 2007, J PHYSIOL-LONDON, V579, P603, DOI 10.1113/jphysiol.2006.127209; Duda R.O., 2001, PATTERN CLASSIFICATI; FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6; FRIEDMAN N, 1997, IEEE P 23 C UNC ART; GARDNER A, 2005, J MACH LEARN RES, V7, P1025; Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441; Goncharova II, 2003, CLIN NEUROPHYSIOL, V114, P1580, DOI 10.1016/S1388-2457(03)00093-2; Gysels E, 2005, SIGNAL PROCESS, V85, P2178, DOI 10.1016/j.sigpro.2005.07.008; Harris KD, 2000, J NEUROPHYSIOL, V84, P401; Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3; Haykin S., 1998, NEURAL NETWORKS COMP, V2nd; Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970; Huan Nai-Jen, 2004, J Neural Eng, V1, P142, DOI 10.1088/1741-2560/1/3/003; Kennedy PR, 2000, IEEE T REHABIL ENG, V8, P198, DOI 10.1109/86.847815; Kubler A, 2005, NEUROLOGY, V64, P1775, DOI 10.1212/01.WNL.0000158616.43002.6D; Kubler A, 1999, EXP BRAIN RES, V124, P223, DOI 10.1007/s002210050617; KUO B, 2003, P GEOSC REM SENS S I, V1, P276; Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827; Liyuan Li, 2004, IEEE Transactions on Image Processing, V13, DOI 10.1109/TIP.2004.836169; Marple L., 1987, DIGITAL SPECTRAL ANA; McFarland DJ, 2005, IEEE T NEUR SYS REH, V13, P372, DOI 10.1109/TNSRE.2005.848627; McFarland DJ, 2006, IEEE T NEUR SYS REH, V14, P135, DOI 10.1109/TNSRE.2006.875637; McFarland DJ, 1997, BEHAV RES METH INS C, V29, P337, DOI 10.3758/BF03200585; McFarland DJ, 1997, ELECTROEN CLIN NEURO, V103, P386, DOI 10.1016/S0013-4694(97)00022-2; MCFARLAND DJ, 1993, PSYCHOBIOLOGY, V21, P77; McFarland DJ, 2000, BRAIN TOPOGR, V12, P177, DOI 10.1023/A:1023437823106; Millan JD, 2004, IEEE T BIO-MED ENG, V51, P1026, DOI 10.1109/TBME.2004.827086; Muller K. R., 2006, IEEE SIGNAL PROCESS, V23, P126; Muller KR, 2003, IEEE T NEUR SYS REH, V11, P165, DOI 10.1109/TNSRE.2003.814484; Neuper C, 2005, COGNITIVE BRAIN RES, V25, P668, DOI 10.1016/j.cogbrainres.2005.08.014; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pernkopf F, 2005, IEEE T PATTERN ANAL, V27, P1344, DOI 10.1109/TPAMI.2005.162; PFURTSCHELLER G, 1993, J MICROCOMPUT APPL, V16, P293, DOI 10.1006/jmca.1993.1030; Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3; Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1; Pless R., 2003, IEEE C COMP VIS PATT, V2, P73; Priestley MB, 1981, SPECTRAL ANAL TIME S; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072; SCHLOGL A, 1999, SLEEP RES ONLINE S1, V2, P586; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Serruya MD, 2002, NATURE, V416, P141, DOI 10.1038/416141a; Sharbrough F, 1991, J CLIN NEUROPHYSIOL, V8, P200; Stauffer C., 1999, INT C COMP VIS PATT, V2, P246; SUTTER EE, 1992, J MICROCOMPUT APPL, V15, P31, DOI 10.1016/0745-7138(92)90045-7; Taylor DM, 2002, SCIENCE, V296, P1829, DOI 10.1126/science.1070291; Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296; TOYAMA K, 1999, IEEE P 7 INT C COMP, V1, P20; Vapnik V., 1974, AUTOMAT REM CONTR+, V34, P1226; VAPNIK VN, 1974, AUTOMAT REM CONTR, V34, P1403; Vaughan TM, 2006, IEEE T NEUR SYS REH, V14, P229, DOI 10.1109/TNSRE.2006.875577; Wessberg J, 2000, NATURE, V408, P361; Wolpaw J. R., 1991, CLIN NEUROPHYSIOL, V78, P252, DOI 10.1016/0013-4694(91)90040-B; Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101; WOLPAW JR, 2002, ELECTROENCEPHALOGR C, V113, P767	75	35	37	0	12	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0270			J NEUROSCI METH	J. Neurosci. Methods	JAN 15	2008	167	1					51	62		10.1016/j.jneumeth.2007.08.010		12	Biochemical Research Methods; Neurosciences	Biochemistry & Molecular Biology; Neurosciences & Neurology	248OU	WOS:000252164300007	17920134	
J	Hu, QH; Yu, DR; Me, Z				Hu, Qinghua; Yu, Daren; Me, Zongxia			Neighborhood classifiers	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						metric space; neighborhood; rough set; reduction; classifier; norm	K-NEAREST NEIGHBOR; FEATURE-SELECTION; CLASSIFICATION; ROUGH; REDUCTION; DISTANCE; SEARCH; SPACES	K nearest neighbor classifier (K-NN) is widely discussed and applied in pattern recognition and machine learning, however, as a similar lazy classifier using local information for recognizing a new test, neighborhood classifier, few literatures are reported on. In this paper, we introduce neighborhood rough set model as a uniform framework to understand and implement neighborhood classifiers. This algorithm integrates attribute reduction technique with classification learning. We study the influence of the three norms on attribute reduction and classification, and compare neighborhood classifier with KNN, CART and SVM. The experimental results show that neighborhood-based feature selection algorithm is able to delete most of the redundant and irrelevant features. The classification accuracies based on neighborhood classifier is superior to K-NN, CART in original feature spaces and reduced feature subspaces, and a little weaker than SVM. (c) 2006 Elsevier Ltd. All rights reserved.	[Hu, Qinghua; Yu, Daren; Me, Zongxia] Harbin Inst Technol, Harbin 150001, Peoples R China	Hu, QH (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hcms.hit.edu.cn	Hu, Qinghua/B-8857-2008				Anil K.G., 2006, COMPUTATIONAL STAT D, V50, P3113; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED; Fu AW, 2000, VLDB J, V9, P154, DOI 10.1007/PL00010672; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086; Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/patrec.2005.09.004; Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Lin TY, 1988, P 1988 ACM 16 ANN CO; Lin T.Y., 1997, ADV MACHINE INTELLIG, P132; Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe; Muni DP, 2006, IEEE T SYST MAN CY B, V36, P106, DOI 10.1109/TSMCB.2005.854499; Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9; OWEN A, 1984, CANADIAN J STATISTIC, V12, P191, DOI 10.2307/3314747; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Salzberg S., 1991, MACH LEARN, V6, P277; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P1179, DOI 10.1016/S0167-8655(97)00112-8; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; Wu WZ, 2002, INFORM SCIENCES, V144, P201, DOI 10.1016/S0020-0255(02)00180-9; Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	34	108	139	4	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	FEB	2008	34	2					866	876		10.1016/j.eswa.2006.10.043		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	263TH	WOS:000253238900008		
J	Kubota, R; Uchino, E; Suetake, N				Kubotaa, Ryosuke; Uchino, Eiji; Suetake, Noriaki			Hierarchical k-nearest neighbor classification using feature and observation space information	IEICE ELECTRONICS EXPRESS			English	Article						k-nearest neighbor classification; pixel classification; image segmentation; learning vector quantization		A novel hierarchical k-nearest neighbor classification method using the feature and observation space information is proposed. The present method performs a fine classification when a pair of the spatial coordinate of the observation data in the observation space and its corresponding feature vector in the feature space is provided.	[Kubotaa, Ryosuke; Uchino, Eiji; Suetake, Noriaki] Yamaguchi Univ, Grad Sch Sci & Technol, Yamaguchi 7538512, Japan	Kubota, R (reprint author), Yamaguchi Univ, Grad Sch Sci & Technol, 1677-1 Yoshida, Yamaguchi 7538512, Japan.	kubota@ic.sci.yamaguchi-u.ac.jp					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103; JAIN AK, 2000, IEEE T PATTERN ANAL, V922, P4; Kohonen T., 1986, TKKFA601 HELS U TECH; Kohonen T., 1995, SELF ORGANIZING MAPS; LEE JS, 1994, INT J REMOTE SENS, V15, P2299; OKA S, 2006, IEEE T GEOSCI REMOTE, V44, P1642; Schowengerdt R. A., 1997, REMOTE SENSING MODEL, V2nd; Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5	10	5	5	0	1	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011, JAPAN	1349-2543			IEICE ELECTRON EXPR	IEICE Electron. Express	FEB 10	2008	5	3					114	119		10.1587/elex.5.114		6	Engineering, Electrical & Electronic	Engineering	295NR	WOS:000255481700006		
J	Kong, XR; Mas, V; Archer, KJ				Kong, Xiangrong; Mas, Valeria; Archer, Kellie J.			A non-parametric meta-analysis approach for combining independent microarray datasets: application using two microarray datasets pertaining to chronic allograft nephropathy	BMC GENOMICS			English	Article							GENE-EXPRESSION PROFILES; CONTROL MAQC PROJECT; INTEGRATIVE ANALYSIS; CANCER; PERFORMANCE; PLATFORMS; NORMALIZATION; PARVALBUMIN; CONSISTENCY	Background: With the popularity of DNA microarray technology, multiple groups of researchers have studied the gene expression of similar biological conditions. Different methods have been developed to integrate the results from various microarray studies, though most of them rely on distributional assumptions, such as the t-statistic based, mixed-effects model, or Bayesian model methods. However, often the sample size for each individual microarray experiment is small. Therefore, in this paper we present a non-parametric meta-analysis approach for combining data from independent microarray studies, and illustrate its application on two independent Affymetrix GeneChip studies that compared the gene expression of biopsies from kidney transplant recipients with chronic allograft nephropathy (CAN) to those with normal functioning allograft. Results: The simulation study comparing the non-parametric meta-analysis approach to a commonly used t-statistic based approach shows that the non-parametric approach has better sensitivity and specificity. For the application on the two CAN studies, we identified 309 distinct genes that expressed differently in CAN. By applying Fisher's exact test to identify enriched KEGG pathways among those genes called differentially expressed, we found 6 KEGG pathways to be over-represented among the identified genes. We used the expression measurements of the identified genes as predictors to predict the class labels for 6 additional biopsy samples, and the predicted results all conformed to their pathologist diagnosed class labels. Conclusion: We present a new approach for combining data from multiple independent microarray studies. This approach is non-parametric and does not rely on any distributional assumptions. The rationale behind the approach is logically intuitive and can be easily understood by researchers not having advanced training in statistics. Some of the identified genes and pathways have been reported to be relevant to renal diseases. Further study on the identified genes and pathways may lead to better understanding of CAN at the molecular level.	[Kong, Xiangrong; Archer, Kellie J.] Virginia Commonwealth Univ, Dept Biostat, Richmond, VA 23298 USA; [Mas, Valeria] Virginia Commonwealth Univ, Dept Surg, Richmond, VA 23298 USA; [Archer, Kellie J.] Virginia Commonwealth Univ, Massey Canc Ctr, Richmond, VA 23298 USA	Archer, KJ (reprint author), Virginia Commonwealth Univ, Dept Biostat, Richmond, VA 23298 USA.	kongx@vcu.edu; vmas@mcvh-vcu.edu; kjarcher@vcu.edu	Kong, Xiangrong/B-5098-2010				Adley BP, 2006, ANAL QUANT CYTOL, V28, P228; AGRESTI A, 2002, WILEY SERIES PROBABI, V15, P710; Benjamini Y, 2001, ANN STAT, V29, P1165; Canales RD, 2006, NAT BIOTECHNOL, V24, P1115, DOI 10.1038/nbt1236; Choi JK, 2003, BIOINFORMATICS, V19, pi84; Choi JK, 2004, FEBS LETT, V565, P93, DOI 10.1016/j.febslet.2004.03.081; COOPER HM, 1994, HDB RES SYNTHESIS, V14; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ghosh Debashis, 2003, Functional & Integrative Genomics, V3, P180; Grutzmann R, 2005, ONCOGENE, V24, P5079, DOI 10.1038/sj.onc.1208696; Guo L, 2006, NAT BIOTECHNOL, V24, P1162, DOI 10.1038/nbt1238; Hotchkiss H, 2006, TRANSPLANTATION, V81, P342, DOI 10.1097/01.tp.0000195773.24217.95; Hu PZ, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-128; Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249; Martignoni G, 2001, MODERN PATHOL, V14, P760, DOI 10.1038/modpathol.3880386; Mas V, 2007, TRANSPLANTATION, V83, P448, DOI 10.1097/01.tp.0000251373.17997.9a; Patterson TA, 2006, NAT BIOTECHNOL, V24, P1140, DOI 10.1038/nbt1242; Rhodes DR, 2004, P NATL ACAD SCI USA, V101, P9309, DOI 10.1073/pnas.0401994101; Rhodes DR, 2002, CANCER RES, V62, P4427; RIPLEY BD, 1996, PATTERN RECOGNITION, V11; Rotig A, 2003, J NEPHROL, V16, P286; Shen RL, 2004, BMC GENOMICS, V5, DOI 10.1186/1171-2164-5-94; Shi LM, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S2-S12; Shi LM, 2006, NAT BIOTECHNOL, V24, P1151, DOI 10.1038/nbt1239; Shi LM, 2004, EXPERT REV MOL DIAGN, V4, P761, DOI 10.1586/14737159.4.6.761; Shippy R, 2006, NAT BIOTECHNOL, V24, P1123, DOI 10.1038/nbt1241; Stevens JR, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-57; Hoffman EP, 2004, NAT REV GENET, V5, P229, DOI 10.1038/nrg1297; Tong WD, 2006, NAT BIOTECHNOL, V24, P1132, DOI 10.1038/nbt1237; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Wang J, 2004, BIOINFORMATICS, V20, P3166, DOI 10.1093/bioinformatics/bth381; WATS, 2004, PEARSON BENJAMIN CUM, P732; Wiesel M, 1997, UROLOGE A, V36, P126, DOI 10.1007/s001200050077	33	12	12	0	4	BIOMED CENTRAL LTD	LONDON	236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND	1471-2164			BMC GENOMICS	BMC Genomics	FEB 26	2008	9								98	10.1186/1471-2164-9-98		13	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	282ZZ	WOS:000254607600001	18302764	
J	Wang, RL; Bencic, D; Biales, A; Lattier, D; Kostich, M; Villeneuve, D; Ankley, GT; Lazorchak, J; Toth, G				Wang, Rong-Lin; Bencic, David; Biales, Adam; Lattier, David; Kostich, Mitch; Villeneuve, Dan; Ankley, Gerald T.; Lazorchak, Jim; Toth, Greg			DNA microarray-based ecotoxicological biomarker discovery in a small fish model species	ENVIRONMENTAL TOXICOLOGY AND CHEMISTRY			English	Article						algorithm; zebrafish; microarray; ecotoxicology; biomarker	GENE-EXPRESSION DATA; SUPPORT VECTOR MACHINES; MOLECULAR CLASSIFICATION; EXPERIMENTAL-DESIGN; CANCER-DIAGNOSIS; FATHEAD MINNOW; ALGORITHMS; SIGNATURES; SAMPLES	As potential biomarkers, gene classifiers are gene expression signatures or patterns capable of distinguishing biological samples belonging to different classes or conditions. This is the second of two papers on profiling gene expression in zebrafish (Danio rerio) treated with endocrine-disrupting chemicals of different modes of action, with a focus on comparative analysis of microarray data for gene classifier discovery. Various combinations of gene feature selection/class prediction algorithms were evaluated. with the use of microarray data organized by a chemical stressor or tissue type, for their accuracy in determining the class memberships of independent test samples. Two-way clustering of gene classifiers and treatment conditions offered another alternative to assess the performance of these potential biomarkers. Both gene feature selection methods and class prediction algorithms were shown to be important in identifying successful gene classifiers. The genetic algorithm and support vector machine yielded classifiers with the best prediction accuracy, regardless of sample size, nature of class prediction, and data complexity. A chemical stressor significantly altering the expression of a greater number of genes tended to generate gene classifiers with better performance. All combinations of gene feature selection/class prediction algorithms performed similarly well with data of high signal to noise ratio. Gene classifier discovery and application on the basis of individual sampling and sample data pooling, respectively, were found to enhance class predictions. Gene expression profiles of the top gene classifiers, identified from both microarray and quantitative polymerase chain reaction assays, displayed greater similarity between fadrozole and 17 beta-trenbolone than either one to 17 alpha-ethinylestradiol. These gene classifiers could serve as potential biomarkers of exposure to specific classes of endocrine disruptors.	[Wang, Rong-Lin; Bencic, David; Biales, Adam; Lattier, David; Kostich, Mitch; Lazorchak, Jim; Toth, Greg] US EPA, Ecol Exposure Res Div, Natl Exposure Res Lab, Cincinnati, OH 45268 USA; [Villeneuve, Dan; Ankley, Gerald T.] US EPA, Mid Continent Ecol Div, Natl Hlth & Environm Effects Res Lab, Duluth, MN 55804 USA	Wang, RL (reprint author), US EPA, Ecol Exposure Res Div, Natl Exposure Res Lab, 26 W Martine Luther King Dr, Cincinnati, OH 45268 USA.	wang.rong-lin@epa.gov					Agrawal D, 2002, J NATL CANCER I, V94, P513; Allison DB, 2006, NAT REV GENET, V7, P55, DOI 10.1038/nrg1749; Ankley GT, 2003, ENVIRON TOXICOL CHEM, V22, P1350, DOI 10.1897/1551-5028(2003)022<1350:EOTAGP>2.0.CO;2; Ankley GT, 2002, TOXICOL SCI, V67, P121, DOI 10.1093/toxsci/67.1.121; Ankley GT, 2006, ENVIRON SCI TECHNOL, V40, P4055, DOI 10.1021/es0630184; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Churchill GA, 2002, NAT GENET, V32, P490, DOI 10.1038/ng1031; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Fleiss JL, 1981, STAT METHODS RATES P, V2nd; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Kendziorski C, 2005, P NATL ACAD SCI USA, V102, P4252, DOI 10.1073/pnas.0500607102; Lettieri T, 2006, ENVIRON HEALTH PERSP, V114, P4, DOI 10.1289/ehp.8194; Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727; Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267; Liu Huiqing, 2002, Genome Inform, V13, P51; Liu JJ, 2005, BIOINFORMATICS, V21, P2691, DOI 10.1093/bioinformatics/bti419; Mitchell M., 1996, INTRO GENETIC ALGORI; Natsoulis G, 2005, GENOME RES, V15, P724, DOI 10.1101/gr.2807605; Peng SH, 2003, FEBS LETT, V555, P358, DOI 10.1016/S0014-5793(03)01275-4; Peng XJ, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-26; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500; SLONIM DK, 2000, 4 ANN INT C COMP MOL, P263; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STEGEMAN JJ, 1992, SETAC SP P, P235; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Villeneuve DL, 2007, ENVIRON SCI TECHNOL, V41, P321, DOI 10.1021/es061739x; Wang RL, 2008, ENVIRON TOXICOL CHEM, V27, P652, DOI 10.1897/07-191.1; Wright GW, 2003, BIOINFORMATICS, V19, P2448, DOI 10.1093/bioinformatics/btg345	32	25	26	1	11	SETAC PRESS	PENSACOLA	1010 N 12TH AVE, PENSACOLA, FL 32501-3367 USA	0730-7268			ENVIRON TOXICOL CHEM	Environ. Toxicol. Chem.	MAR	2008	27	3					664	675		10.1897/07-192.1		12	Environmental Sciences; Toxicology	Environmental Sciences & Ecology; Toxicology	265PX	WOS:000253374500022	17990946	
J	Bengtsson, T; Cavanaugh, JE				Bengtsson, Thomas; Cavanaugh, Joseph E.			State-space discrimination and clustering of atmospheric time series data based on Kullback information measures	ENVIRONMETRICS			English	Article						classification; pattern recognition; geostatistics; principal component analysis; principal oscillation pattern; state-space process	ENSEMBLE KALMAN FILTER; DATA ASSIMILATION; UNITED-STATES	Statistical problems in atmospheric science are frequently characterized by large spatio-temporal data sets and pose difficult challenges in classification and pattern recognition. Here, we consider the problem of identifying geographically homogeneous regions based on similarities in the temporal dynamics of weather patterns. Two disparity measures are proposed and applied to cluster time series of observed monthly temperatures from locations across Colorado, U.S.A. The two disparity measures are based on state-space models, where the monthly temperature anomaly dynamics and seasonal variation are represented by latent processes. Our disparity measures produce clusters consistent with known atmospheric flow structures. In particular, the temporal anomaly pattern is related to the topography of Colorado, where, separated by the Continental Divide, the flow structures in the western and eastern parts of the state have different dynamics. The results further suggest that seasonal variation may be affected by locally changing solar radiation levels primarily associated with elevation variations across the Rocky Mountains. The general methodology is outlined and developed in the Appendix. We conclude with a discussion of extensions to time varying and non-stationary systems. Copyright (c) 2007 John Wiley & Sons, Ltd.	[Bengtsson, Thomas] Stat & Data Mining Dept, Bell Labs, Summit, NJ 07901 USA; [Cavanaugh, Joseph E.] Univ Iowa, Dept Biostat, Iowa City, IA USA	Bengtsson, T (reprint author), Stat & Data Mining Dept, Bell Labs, Summit, NJ 07901 USA.	tocke@cgd.ucar.edu					Alagon J., 1989, J TIME SER ANAL, V10, P203, DOI 10.1111/j.1467-9892.1989.tb00024.x; Anderson D. B. D. O., 1979, OPTIMAL FILTERING; BENGTSSON T, 2003, J GEOPHYS RES, V108, P1; Brockwell P. J., 1991, TIME SERIES THEORY M, V2nd; Cavanaugh JE, 1999, BIOMETRIKA, V86, P183, DOI 10.1093/biomet/86.1.183; CHAUDHURI G, 1992, STAT PROBABIL LETT, V15, P277, DOI 10.1016/0167-7152(92)90162-X; Chen R, 2000, J ROY STAT SOC B, V62, P493, DOI 10.1111/1467-9868.00246; Coates DS, 1986, J TIME SER ANAL, V7, P7, DOI 10.1111/j.1467-9892.1986.tb00482.x; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOVELL RG, 1993, J CLIMATE, V6, P2103, DOI 10.1175/1520-0442(1993)006<2103:CZOTCU>2.0.CO;2; GERSCH W, 1981, APPL TIME SERIES ANA, V2, P221; GONG XF, 1995, J CLIMATE, V8, P897, DOI 10.1175/1520-0442(1995)008<0897:OTAOCA>2.0.CO;2; Gordon A.D., 1999, CLASSIFICATION; Dargahi-Noubary G. R., 1981, Journal of Time Series Analysis, V2, DOI 10.1111/j.1467-9892.1981.tb00313.x; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Harvey A. C., 1989, FORECASTING STRUCTUR; Houtekamer PL, 1998, MON WEATHER REV, V126, P796, DOI 10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2; Houtekamer PL, 2001, MON WEATHER REV, V129, P123, DOI 10.1175/1520-0493(2001)129<0123:ASEKFF>2.0.CO;2; Janacek G., 1993, TIME SERIES FORECAST; Jazwinski A. H., 1970, STOCHASTIC PROCESSES; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; JOLLIFFE P, 2002, PRINCIPAL COMPONENT; Jones R. H., 1993, LONGITUDINAL DATA SE; Kakizawa Y, 1998, J AM STAT ASSOC, V93, P328, DOI 10.2307/2669629; Kalman R. E., 1960, T ASME D, V82, P35, DOI DOI 10.1115/1.3662552; Kim KY, 1999, J CLIMATE, V12, P185, DOI 10.1175/1520-0442-12.1.185; Koopman S. J., 2001, TIME SERIES ANAL STA; Kullback S., 1968, INFORM THEORY STAT, V2nd; LIGGETT WS, 1971, ANN MATH STAT, V42, P1348, DOI 10.1214/aoms/1177693247; MELARD G, 1983, P AM STAT ASS BUS EC; MILLER RN, 1994, J ATMOS SCI, V51, P1037, DOI 10.1175/1520-0469(1994)051<1037:ADAISN>2.0.CO;2; MO KT, 1988, J GEOPHYS RES-ATMOS, V93, P10927, DOI 10.1029/JD093iD09p10927; RICHMAN MB, 1985, J CLIM APPL METEOROL, V24, P1325, DOI 10.1175/1520-0450(1985)024<1325:CPAOTA>2.0.CO;2; *SCI COMP DIV NAT, 1948, TD3200 NCDC SCI COMP; Shumway R, 2006, TIME SERIES ANAL ITS; SHUMWAY RH, 1974, J AM STAT ASSOC, V69, P948, DOI 10.2307/2286169; SHURNWAY R, 1982, J TIME SER ANAL, V3, P253; STONE RC, 1989, INT J CLIMATOL, V9, P3, DOI 10.1002/joc.3370090103; Wikle C, 2002, ENCY LIFE SUPPORT SY; Wikle CK, 1999, BIOMETRIKA, V86, P815, DOI 10.1093/biomet/86.4.815	40	10	10	4	7	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1180-4009			ENVIRONMETRICS	Environmetrics	MAR	2008	19	2					103	121		10.1002/env.859		19	Environmental Sciences; Mathematics, Interdisciplinary Applications; Statistics & Probability	Environmental Sciences & Ecology; Mathematics	280XL	WOS:000254460000001		
J	Yu, J; Amores, J; Sebe, N; Radeva, P; Tian, Q				Yu, Jie; Amores, Jaume; Sebe, Nicu; Radeva, Petia; Tian, Qi			Distance learning for similarity estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image classification; information retrieval; pattern recognition; artificial intelligence; algorithms	IMAGE RETRIEVAL; CLASSIFICATION; ALGORITHMS; FEATURES	In this paper, we present a general guideline to find a better distance measure for similarity estimation based on statistical analysis of distribution models and distance functions. A new set of distance measures are derived from the harmonic distance, the geometric distance, and their generalized variants according to the Maximum Likelihood theory. These measures can provide a more accurate feature model than the classical euclidean and Manhattan distances. We also find that the feature elements are often from heterogeneous sources that may have different influence on similarity estimation. Therefore, the assumption of single isotropic distribution model is often inappropriate. To alleviate this problem, we use a boosted distance measure framework that finds multiple distance measures, which fit the distribution of selected feature elements best for accurate similarity estimation. The new distance measures for similarity estimation are tested on two applications: stereo matching and motion tracking in video sequences. The performance of boosted distance measure is further evaluated on several benchmark data sets from the UCI repository and two image retrieval applications. In all the experiments, robust results are obtained based on the proposed methods.	[Yu, Jie] Kodak Res Labs, Intelligent Syst Grp, Rochester, NY 14615 USA; [Amores, Jaume] Inst Natl Rech Informat & Automat, IMEDIA Res Grp, Sophia Antipolis, France; [Sebe, Nicu] Univ Amsterdam, Fac Sci, NL-1098 SJ Amsterdam, Netherlands; [Radeva, Petia] Univ Autonoma Barcelona, Dept Informat, Comp Vis Ctr, Catalunya 08193, Spain; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA	Yu, J (reprint author), Kodak Res Labs, Intelligent Syst Grp, 1999 Lake Ave,Mail Code 02103, Rochester, NY 14615 USA.	Jerry.J.Yu@gmail.com; Jaume.Amores@inria.fr; nicu@science.uva.nl; petia@cvc.uab.es; qitian@gmail.com					AIGRAIN P, 1987, P I M OPT PUBL STOR, P257; Amores J, 2006, PATTERN RECOGN LETT, V27, P201, DOI 10.1016/j.patrec.2005.08.019; Athitsos V., 2004, P IEEE C COMP VIS PA; Bar-Hillel A., 2003, P 20 INT C MACH LEAR, P11; CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R O, 2001, PATTERN CLASSIFICATI; Duda R. O., 2004, PATTERN CLASSIFICATI, V2; Flichner M, 1995, IEEE COMPUT, V9, P23; FUKUNAGA K, 1997, IEEE T PATTERN ANAL, V19, P671; GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041; Haralick R. M., 1993, COMPUTER ROBOT VISIO; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HERTZ T, 2006, P ACM I C MACH LEARN; Hertz T, 2004, PROC CVPR IEEE, P570; Huber P.J., 1981, ROBUST STAT; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; KATO K, 1992, P SPIE C IM STOR RET, V1662, P112; LAFFERTY J, 1997, P CAN WORKSH INF THE; LeCun Y., 1998, MNIST DATABASE; LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682; Martinez A., 1998, THE AR FACE DATABASE; MATAS J, 1999, P INT C PATT REC, P858; Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6; Merz C, 1998, UCI REPOSITORY MACHI; Moghaddam B., 2000, PATTERN RECOGNITION; PENG J, 2001, P IEEEE C COMP VIS P, P940; PHILLIPS PJ, 1998, P ADV NEUR INF PROC, V11; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; RUBNER Y, 2000, I J COMPUTER VISION; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMITH JR, 1994, P IEEE I C IM PROC; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TANG L, 1994, P NSF ARPA WORKSH PE; TIAN Q, 2004, P IEEE I C IM PROC; TVERSKY A, 1977, J MATH PSYCHOL, V7, P572; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/0033-295X.84.4.327; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WALLACH MA, 1958, PSYCHOL REV, V65, P103, DOI 10.1037/h0042908; Xing EP, 2003, P NIPS, P505; YU J, 2006, P IEEE I C AC SPEECH; YU J, 2006, P IEEE I C COMP VIS; Zakai M., 1964, IEEE T INFORM TH JAN, P94	47	27	28	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					451	462		10.1109/TPAMI.2007.70714		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	250FT	WOS:000252286100007	18195439	
J	Kyperountas, M; Tefas, A; Pitas, L				Kyperountas, Marios; Tefas, Anastasios; Pitas, Loannis			Dynamic training using multistage clustering for face recognition	PATTERN RECOGNITION			English	Article						face recognition; dynamic training; multilevel clustering; discriminant analysis	SAMPLE-SIZE PROBLEM; DISCRIMINANT-ANALYSIS; LDA; REPRESENTATION; ALGORITHMS; CLASSIFICATION; EIGENFACES; IMAGES	A novel face recognition algorithm that uses dynamic training in a multistage clustering scheme is presented and evaluated. This algorithm uses discriminant analysis to project the face classes and a clustering algorithm to partition the projected face data, thus forming a set of discriminant clusters. Then, an iterative process creates subsets, whose cardinality is defined by an entropy-based measure, that contain the most useful clusters. The best match to the test face is found when only a single face class is retained. This method was tested on the ORL, XM2VTS and FERET face databases, whereas the UMIST database was used in order to train the proposed algorithm. Experimental results indicate that the proposed framework provides a promising solution to the face recognition problem. (C) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, GR-54006 Thessaloniki, Greece; Inst Educ Technol, Dept Informat Management, GR-65404 Kavala, Greece	Kyperountas, M (reprint author), Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, Box 451, GR-54006 Thessaloniki, Greece.	mkyper@aiia.csd.auth.gr; tefas@aiia.csd.auth.gr; pitas@aiia.csd.auth.gr	Tefas, Anastasios/F-1899-2010	Tefas, Anastasios/0000-0003-1288-3667			AT& T Laboratories Cambridge, 2002, DAT FAC; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bicego M., 2003, Proceedings 12th International Conference on Image Analysis and Processing; BRENNAN V, 1998, P IEEE WORKSH NEUR N, P506; Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI G, 2004, P INT S CIRC SYST, V2, P109; Daubechies I., 1992, 10 LECT WAVELETS CBM; Er MJ, 2002, IEEE T NEURAL NETWOR, V13, P697, DOI 10.1109/TNN.2002.1000134; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Graham D. B., 1998, NATO ASI SERIES F, V163, P446; GUO GD, 2001, P 8 IEEE INT C COMP, P282; HUANG R, 2004, P 17 INT C PATT REC, V3, P157; Koskela M., 2004, P 17 INT C PATT REC, V2, P1005; Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038; Lai JH, 2001, PATTERN RECOGN, V34, P95, DOI 10.1016/S0031-3203(99)00200-9; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; LEUTTIN J, 1998, IDIAP COMMUNICATION; Li Z., 2004, P IEEE INT C COMP VI, P374; LIAND SZ, 1999, IEEE T NEURAL NETWOR, V10, P439; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; LIU H, 2004, P INT C PATT REC, V4, P344; LU J, 2002, P IEEE INT C IM PROC; Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Strang G., 1996, WAVELETS FILTER BANK; Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652; Tang QS, 2003, LAR MAR ECOSYST, V12, P121; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG X, 2003, P ACM SIGMM 2003 MUL; XIAOJUN WU, 2004, C BRIT MACH VIS KING; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131; Yang M., 2002, P 5 IEEE INT C AUT F, P215, DOI 10.1109/AFGR.2002.4527207; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhang BL, 2004, IEEE T NEURAL NETWOR, V15, P166, DOI 10.1109/TNN.2003.820673; ZHENG W, 2004, P IEEE INT C AC SPEE, V5, P725	44	11	11	1	3	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	MAR	2008	41	3					894	905		10.1016/j.patcog.2007.06.017		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	237EQ	WOS:000251357100011		
J	Carrizosa, E; Martin-Barragan, B; Morales, DR				Carrizosa, Emilio; Martin-Barragan, Belen; Morales, Dolores Romero			Multi-group support vector machines with measurement costs: A biobjective approach	DISCRETE APPLIED MATHEMATICS			English	Article						multi-group classification; pareto optimality; biobjective mixed integer programming; feature cost; support vector machines	CLASSIFICATION; FORMULATIONS; SEPARATION; KNOWLEDGE	Support Vector Machine has shown to have good performance in many practical classification settings. In this paper we propose, for multi-group classification, a biobjective optimization model in which we consider not only the generalization ability (modeled through the margin maximization), but also costs associated with the features. This cost is not limited to an economical payment, but can also refer to risk, computational effort, space requirements, etc. We introduce a Biobjective Mixed Integer Problem, for which Pareto optimal solutions are obtained. Those Pareto optimal solutions cot-respond to different classification rules, among which the user would choose the one yielding the most appropriate compromise between the cost and the expected misclassification rate. (C) 2007 Elsevier B.V. All rights reserved.	[Carrizosa, Emilio] Univ Seville, Fac Matemat, Seville, Spain; [Martin-Barragan, Belen] Univ Carlos III Madrid, E-28903 Getafe, Spain; [Morales, Dolores Romero] Univ Oxford, Said Business Sch, Oxford OX1 2JD, England	Carrizosa, E (reprint author), Univ Seville, Fac Matemat, Seville, Spain.	ecarrizosa@us.es; belen.martin@uc3m.es; dolores.romero-morales@sbs.ox.ac.uk		Carrizosa Priego, Emilio J./0000-0002-0832-8700; Romero Morales, Dolores/0000-0001-7945-1469			Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; APTE C, 2003, OR MS TODAY      FEB; BAYERZUBEK V, 2003, THESIS OREGON STATE; Bennet K. P., 1992, OPTIMIZATION METHODS, V1, P23, DOI 10.1080/10556789208805504; Bennett KP, 1999, ADVANCES IN KERNEL METHODS, P307; Blake C, 1998, UCI REPOSITORY MACHI; BORES E, 1997, MATH PROGRAM, V79, P163; Bradley PS, 1999, INFORMS J COMPUT, V11, P217, DOI 10.1287/ijoc.11.3.217; Bradley PS, 2002, HDB MASSIVE DATASETS, P439; Breiman L., 1984, CLASSIFICATION REGRE; CORTES C, 1995, MACH LEARN, V1, P113; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; SILVA APD, 1994, EUR J OPER RES, V72, P4, DOI 10.1016/0377-2217(94)90324-7; Falk JE, 2001, COMPUT OPER RES, V28, P537, DOI 10.1016/S0305-0548(99)00134-3; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hastie T, 1998, ANN STAT, V26, P451; Herbrich R, 2002, LEARNING THEORY CLAS; Joachims T, 2002, LEARNING CLASSIFY TE; MANGASARIAN O, 1997, DATA MIN KNOWL DISC, V42, P183; MANGASAR.OL, 1965, OPER RES, V13, P444, DOI 10.1287/opre.13.3.444; Norton S.W., 1989, P 11 INT JOINT C ART, P800; NUNEZ M, 1991, MACH LEARN, V6, P231, DOI 10.1007/BF00114778; Paclik P., 2002, LECT NOTES COMPUTER, V2396, P461; Pedroso JP, 2001, PATTERN RECOGN LETT, V22, P1263, DOI 10.1016/S0167-8655(01)00071-X; RUBINOV AM, 2003, TOP, V11, P1; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; SMOLA A, 1999, ADV NEURAL INFORM PR, V10, P585; TAN M, 1993, MACH LEARN, V13, P7, DOI 10.1007/BF00993101; Turney P. D., 1995, Journal of Artificial Intelligence Research, V2; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Visee M, 1998, J GLOBAL OPTIM, V12, P139, DOI 10.1023/A:1008258310679; Weston J, 1999, ADVANCES IN KERNEL METHODS, P293; Weston J, 2001, ADV NEUR IN, V13, P668	36	4	4	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0166-218X			DISCRETE APPL MATH	Discret Appl. Math.	MAR 15	2008	156	6					950	966		10.1016/j.dam.2007.05.060		17	Mathematics, Applied	Mathematics	281FN	WOS:000254482400011		
J	Asselah, T; Bieche, I; Narguet, S; Sabbagh, A; Laurendeau, I; Ripault, MP; Boyer, N; Martinot-Peignoux, M; Valla, D; Vidaud, M; Marcellin, P				Asselah, T.; Bieche, I.; Narguet, S.; Sabbagh, A.; Laurendeau, I.; Ripault, M-P; Boyer, N.; Martinot-Peignoux, M.; Valla, D.; Vidaud, M.; Marcellin, P.			Liver gene expression signature to predict response to pegylated interferon plus ribavirin combination therapy in patients with chronic hepatitis C	GUT			English	Article							ALPHA-REGULATED GENE; VIRAL-INFECTION; VIRUS-INFECTION; PEGINTERFERON; FIBROSIS; IDENTIFICATION; NONRESPONDERS; MICROARRAY; DISEASE; TRIAL	Background and Aims: The gold standard treatment of chronic hepatitis C (CHC) is combined pegylated interferon and ribavirin. Considering side effects and treatment cost, prediction of treatment response before therapy is important. The aim of this study was to identify a liver gene signature to predict sustained virological response in patients with CHC. Methods: Group A (training set) comprised 40 patients with CHC including 14 non-responders (NRs) and 26 sustained virological responders (SVRs). Group B (validation set) comprised 29 patients including 9 NRs and 20 SVRs. Eleven responder-relapsers were also included. A total of 58 genes associated with liver gene expression dysregulation during CHC were selected from the literature. Real-time quantitative RT-PCR assays were used to analyse the mRNA expression of these 58 selected genes in liver biopsy specimens taken from the patients before treatment. Results: From the Group A data, three genes whose expression was significantly increased in NRs compared with SVRs were identified: IFI-6-16/G1P3, IFI27 and ISG15/G1P2. These three genes also showed significant differences in their expression profiles between NRs and SVRs in the independent sample (Group B). Supervised class prediction analysis identified a two-gene (IFI27 and CXCL9) signature, which accurately predicted treatment response in 79.3% (23/29) of patients from the validation set (Group B), with a predictive accuracy of 100% (9/9) and of 70% (14/20) in NRs and SVRs, respectively. The expression profiles of responder-relapsers did not differ significantly from those of NRs and SVRs, and 73% (8/11) of them were predicted as SVRs with the two-gene classifier. Conclusion: NRs and SVRs have different liver gene expression profiles before treatment. The most notable changes occurred mainly in interferon-stimulated genes. Treatment response could be predicted with a two-gene signature (IFI27 and CXCL9).	[Asselah, T.; Ripault, M-P; Boyer, N.; Martinot-Peignoux, M.; Valla, D.; Marcellin, P.] Univ Paris 07, INSERM, AP HP Beaujon Hosp, U773,CRB3, F-92110 Clichy, France; [Asselah, T.; Ripault, M-P; Boyer, N.; Martinot-Peignoux, M.; Valla, D.; Marcellin, P.] Hop Beaujon, Serv Hepatol, Pole Maladies Appareil Digest, F-92110 Clichy, France; [Asselah, T.; Bieche, I.; Narguet, S.; Sabbagh, A.; Laurendeau, I.; Vidaud, M.] Univ Paris 05, INSERM, UMR745, Paris, France; [Bieche, I.; Sabbagh, A.; Vidaud, M.] Hop Beaujon, Serv Biochim & Genet Mol, Clichy, France	Asselah, T (reprint author), Hop Beaujon, Serv Hepatol, Pole Maladies Appareil Digest, F-92110 Clichy, France.	tarik.asselah@bjn.aphp.fr					[Anonymous], 1999, J HEPATOL, V30, P956; Asselah T, 2007, SEMIN LIVER DIS, V27, P13, DOI 10.1055/s-2006-960168; Asselah T, 2005, GASTROENTEROLOGY, V129, P2064, DOI 10.1053/j.gastro.2005.09.010; Bedossa P, 1996, HEPATOLOGY, V24, P289, DOI 10.1002/hep.510240201; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Bieche I, 2005, VIROLOGY, V332, P130, DOI 10.1016/j/virol.2004.11.009; BRONOWICKI JP, 2006, GASTROENTEROLOGY, V1040, P1; Butera D, 2005, BLOOD, V106, P1175, DOI 10.1182/blood-2005-01-0126; Chen LM, 2005, GASTROENTEROLOGY, V128, P1437, DOI 10.1053/j.gastro.2005.01.059; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craxi A, 2003, SEMIN LIVER DIS, V23, P35; DeRisi J, 1996, NAT GENET, V14, P457; Devlin B, 2003, GENET EPIDEMIOL, V25, P36, DOI 10.1002/gepi.10237; Fried MW, 2002, NEW ENGL J MED, V347, P975, DOI 10.1056/NEJMoa020047; Gale M, 2005, NATURE, V436, P939, DOI 10.1038/nature04078; Hadziyannis SJ, 2004, ANN INTERN MED, V140, P346; Hayashida K, 2005, CLIN GASTROENTEROL H, V3, P1253, DOI 10.1016/S1542-3565(05)00412-X; Helbig KJ, 2005, HEPATOLOGY, V42, P702, DOI 10.1002/hep.20844; Honda M, 2001, GASTROENTEROLOGY, V120, P955, DOI 10.1053/gast.2001.22468; Ji XH, 2003, HEPATOLOGY, V37, P610, DOI 10.1053/jhep.2003.50105; Kim IJ, 2005, GASTROENTEROLOGY, V129, P1803, DOI 10.1053/j.gastro.2005.09.047; Lagging M, 2006, HEPATOLOGY, V44, P1617, DOI 10.1002/hep.21407; Li QX, 2001, ENDOCRINOLOGY, V142, P2390, DOI 10.1210/en.142.6.2390; Manns MP, 2001, LANCET, V358, P958, DOI 10.1016/S0140-6736(01)06102-5; Marcellin P, 2002, HEPATOLOGY, V36, pS47, DOI 10.1053/jhep.2002.36993; Mihm S, 2004, LAB INVEST, V84, P1148, DOI 10.1038/labinvest.3700135; Moucari R, 2007, J HEPATOL, V46, P596, DOI 10.1016/j.jhep.2006.10.016; Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500; Seeff Leonard B, 2003, Clin Liver Dis, V7, P261, DOI 10.1016/S1089-3261(02)00078-8; Smith MW, 2003, HEPATOLOGY, V38, P1458, DOI 10.1016/jhep.2003.09.024	30	150	152	3	7	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0017-5749			GUT	Gut	APR	2008	57	4					516	524		10.1136/gut.2007.128611		9	Gastroenterology & Hepatology	Gastroenterology & Hepatology	272RL	WOS:000253877300018	17895355	
J	Reformat, M; Yager, RR				Reformat, Marek; Yager, Ronald R.			Building ensemble classifiers using belief functions and OWA operators	SOFT COMPUTING			English	Article						ensemble systems; rule-based models; belief functions; Dempster-Shafer evidence theory; ordered weighted averaging operator	DEMPSTER-SHAFER THEORY; MULTICRITERIA DECISION-MAKING; PATTERN-CLASSIFICATION; COMBINING CLASSIFIERS; RULE; AGGREGATION; COMBINATION	A pervasive task in many forms of human activity is classification. Recent interest in the classification process has focused on ensemble classifier systems. These types of systems are based on a paradigm of combining the outputs of a number of individual classifiers. In this paper we propose a new approach for obtaining the final output of ensemble classifiers. The method presented here uses the Dempster-Shafer concept of belief functions to represent the confidence in the outputs of the individual classifiers. The combing of the outputs of the individual classifiers is based on an aggregation process which can be seen as a fusion of the Dempster rule of combination with a generalized form of OWA operator. The use of the OWA operator provides an added degree of flexibility in expressing the way the aggregation of the individual classifiers is performed.	[Yager, Ronald R.] Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA; [Reformat, Marek] Univ Alberta, Thinking Software & Syst Lab ThinkS2, Edmonton, AB T6G 2Y7, Canada	Yager, RR (reprint author), Iona Coll, Inst Machine Intelligence, New Rochelle, NY 10801 USA.	yager@panix.com					Ahmadzadeh MR, 2003, PATTERN ANAL APPL, V6, P41, DOI [10.1007/s10044-002-0176-4, 10.1007/s1004-002-0176-4]; Al-Ani M, 2002, J ARTIF INTELL RES, V17, P333; ALI K, 1995, 9547 U CAL DEP INF C; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1007/BF00058611; Altincay H, 2006, APPL INTELL, V25, P73, DOI 10.1007/s10489-006-8867-y; Altincay H, 2003, SPEECH COMMUN, V41, P531, DOI 10.1016/S0167-6393(03)00032-3; Altincay H, 2005, PATTERN ANAL APPL, V8, P287, DOI 10.1007/s10044-005-0010-x; Binaghi E, 1999, INT J INTELL SYST, V14, P559, DOI 10.1002/(SICI)1098-111X(199906)14:6<559::AID-INT2>3.0.CO;2-#; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buntine W., 1990, THESIS U TECHNOLOGY; Cios K. J., 1998, DATA MINING METHODS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Denoeux T, 2000, IEEE T SYST MAN CY A, V30, P131, DOI 10.1109/3468.833094; Denoeux T, 1997, PATTERN RECOGN, V30, P1095, DOI 10.1016/S0031-3203(96)00137-9; Dietterich T., 2000, LECT NOTES COMPUTER, P1; Duda R O, 2001, PATTERN CLASSIFICATI; Dunham M.H., 2003, DATA MINING; Freund Y., 1996, P 13 INT C MACH LEAR; Hagan M. O', 1990, P 24 ANN IEEE AS C S, P618; Han Jiawei, 2001, DATA MINING CONCEPTS; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Klement E.P., 2000, TRIANGULAR NORMS; KONONENKO M, 1992, P 9 INT WORKSH MACH, P257; Kramosil I, 2001, INT J UNCERTAIN FUZZ, V9, P105, DOI 10.1016/S0218-4885(01)00065-X; Kuncheva L. I., 2004, COMBINING PATTERN CL; Kwok SW, 1990, UNCERTAINTY ARTIFICI, V4, P327; Laha A, 2006, IEEE T GEOSCI REMOTE, V44, P1633, DOI 10.1109/TGRS.2006.864391; Lin T. Y., 2002, DATA MINING ROUGH SE; Mandler E., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop; Reformat M, 2005, INT J INTELL SYST, V20, P1093, DOI 10.1002/int.20113; ROGOVA G, 1994, NEURAL NETWORKS, V7, P777, DOI 10.1016/0893-6080(94)90099-X; ROLI F, 2006, IOS NATO PUBLICATION, P23; Shafer G., 1976, MATH THEORY EVIDENCE; Smets P., 1988, NONSTANDARD LOGICS A, P253; SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4; Todorovski L., 2000, Principles of Data Mining and Knowledge Discovery. 4th European Conference, PKDD 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1910); Winer BJ, 1991, STAT PRINCIPLES EXPT; Yager RR, 2008, STUD FUZZ SOFT COMP, V219, P1, DOI 10.1007/978-3-540-44792-4; YAGER RR, 1993, FUZZY SET SYST, V59, P125, DOI 10.1016/0165-0114(93)90194-M; Yager RR, 2005, INT J INTELL SYST, V20, P453, DOI 10.1002/int.20075; Yager RR, 2006, INFORM SCIENCES, V176, P577, DOI 10.1016/j.ins.2004.12.006; Yager RR, 1996, INT J INTELL SYST, V11, P49, DOI 10.1002/(SICI)1098-111X(199601)11:1<49::AID-INT3>3.3.CO;2-L; YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068; ZADEH LA, 1983, COMPUT MATH APPL, V9, P149, DOI 10.1016/0898-1221(83)90013-5; Zouhal LM, 1998, IEEE T SYST MAN CY C, V28, P263, DOI 10.1109/5326.669565	47	11	12	0	1	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1432-7643			SOFT COMPUT	Soft Comput.	APR	2008	12	6					543	558		10.1007/s00500-007-0227-2		16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	255SJ	WOS:000252677400004		
J	Zipitria, I; Larranaga, P; Armananzas, R; Arruarte, A; Elorriaga, JA				Zipitria, Iraide; Larranaga, Pedro; Armananzas, Ruben; Arruarte, Ana; Elorriaga, Jon A.			What is behind a summary-evaluation decision?	BEHAVIOR RESEARCH METHODS			English	Article							TEXT; COMPREHENSION; KNOWLEDGE; SUMMARIZATION; CLASSIFIERS; REVISION; MEMORY; MODEL	Research in psychology has reported that, among the variety of possibilities for assessment methodologies, summary evaluation offers a particularly adequate context for inferring text comprehension and topic understanding. However, grades obtained in this methodology are hard to quantify objectively. Therefore, we carried out an empirical study to analyze the decisions underlying human summary-grading behavior. The task consisted of expert evaluation of summaries produced in critically relevant contexts of summarization development, and the resulting data were modeled by means of Bayesian networks using an application called Elvira, which allows for graphically observing the predictive power (if any) of the resultant variables. Thus, in this article, we analyzed summary-evaluation decision making in a computational framework.	[Zipitria, Iraide; Larranaga, Pedro; Armananzas, Ruben; Arruarte, Ana; Elorriaga, Jon A.] Univ Basque Country, Dept Social Psychol & Behav Sci Methodol, Donostia San Sebastian 20018, Basque Country, Spain	Zipitria, I (reprint author), Univ Basque Country, Dept Social Psychol & Behav Sci Methodol, Tolosa Etorbidea 70, Donostia San Sebastian 20018, Basque Country, Spain.	iraide.zipitria@ehu.es	Armananzas, Ruben/C-2735-2013; Arruarte, Ana/L-1569-2014; Elorriaga, Jon A./L-3145-2014; Larranaga, Pedro/F-9293-2013	Armananzas, Ruben/0000-0003-4049-0000; Arruarte, Ana/0000-0002-5408-1227; Elorriaga, Jon A./0000-0003-2463-9186; 			Bandura A, 1977, SOCIAL LEARNING THEO; Bartlett FC, 1932, REMEMBERING STUDY EX; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; Blanco R, 2005, J BIOMED INFORM, V38, P376, DOI 10.1016/j.jbi.2005.05.004; Bower GH, 1981, THEORIES LEARNING; Bransford J. D., 1990, DIMENSIONS THINKING, P381; Breiman L., 1984, CLASSIFICATION REGRE; BULL S, 1995, 7 WORLD C ART INT ED; Burstein J, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P209; Cassany D, 1993, REPARAR ESCRITURA DI; CATLETT J, 1991, LECT NOTES ARTIF INT, V482, P164; Chung GKWK, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P23; Cizek GJ, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P125; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; Cook R., 1994, 4 INT C US MOD HYANN, P145; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dimitrova V., 2003, INT J ARTIFICIAL INT, V13, P35; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Elosúa M Rosa, 2002, Span J Psychol, V5, P90; Elvira-Consortium, 2002, P 1 EUR WORKSH PROB, P222; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; FITZGERALD J, 1987, REV EDUC RES, V57, P481, DOI 10.3102/00346543057004481; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GARNER R, 1987, EDUC PSYCHOL, V22, P299, DOI 10.1207/s15326985ep2203&4_6; GARNER R, 1982, J EDUC RES, V75, P275; Genesee F., 1996, CLASSROOM BASED EVAL; Glazer EM, 2006, TEACH TEACH EDUC, V22, P179, DOI 10.1016/j.tate.2005.09.004; Glymour C., 2001, MINDS ARROWS BAYES N; GOLDBERG GL, 1999, ED ASSESSMENT, V6, P257; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; Holland J., 1975, ADAPTATION NATURAL A; Hosmer D. W., 1989, APPL LOGISTIC REGRES; Inoue Asao B., 2005, ASSESS WRIT, V9, P208, DOI DOI 10.1016/J.ASW.2004.12.001; Jensen F.V., 2001, BAYESIAN NETWORKS DE; Kerber R., 1992, P 10 NAT C ART INT, P123; KINTSCH W, 1978, PSYCHOL REV, V85, P363, DOI 10.1037//0033-295X.85.5.363; Kirby J. R., 1991, EDUC PSYCHOL, V11, P297, DOI [10.1080/0144341910110306, DOI 10.1080/0144341910110306]; Kozminsky E., 1986, J RES READ, V9, P3, DOI 10.1111/j.1467-9817.1986.tb00107.x; KRUSKAL WILLIAM H., 1952, JOUR AMER STATIST ASSOC, V47, P583, DOI 10.2307/2280779; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Langley P., 1994, P 10 C UNC ART INT, P399; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEHNERT WG, 1981, COGNITIVE SCI, V5, P293; Long J., 1978, LANGUAGE INTERPRETAT, P273; Magnani L., 2001, ABDUCTION REASON SCI; Magnani L., 2004, FOUND SCI, V9, P219, DOI 10.1023/B:FODA.0000042841.18507.22; MANELIS L, 1984, J STRUCT LEARN, V8, P29; Mani I., 1999, ADV AUTOMATIC TEXT S; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; MINSKY M, 1961, P IRE, V49, P8, DOI 10.1109/JRPROC.1961.287775; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; Page EB, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P43; Pearl J, 1988, PROBABILISTIC REASON; PEARL J, 1987, ARTIF INTELL, V33, P173, DOI 10.1016/0004-3702(87)90034-8; Peirce C.S., 1955, PHILOS WRITINGS PEIR, P150; Robinson B., 1995, COLL TEACHING, V43, P57; Rumelhart D. E., 1975, REPRESENTATION UNDER, P185; SCHANK RC, 1980, AM J COMPUTATIONAL L, V6, P13; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Sherrard C., 1989, SYSTEM, V17, P1, DOI 10.1016/0346-251X(89)90055-9; SHIMONY SE, 1990, P 6 ANN C UNC ART IN, P185; Spirtes P, 1993, CAUSATION PREDICTION; STONE M, 1974, J R STAT SOC B, V36, P111; SYMONS S, 1993, READ RES QUART, V28, P250, DOI 10.2307/747997; TAYLOR BM, 1982, J EDUC PSYCHOL, V74, P323, DOI 10.1037/0022-0663.74.3.323; THORNDYKE PW, 1977, COGNITIVE PSYCHOL, V9, P77, DOI 10.1016/0010-0285(77)90005-6; VIRVOU M, 2001, INT J ARTIFICIAL INT, V12, P185; Whittaker J., 1990, GRAPHICAL MODELS APP; WINOGRAD PN, 1984, READ RES QUART, V19, P404, DOI 10.2307/747913; ZIPITRIA I, 2006, P 8 INT C INT TUT SY, P595	71	2	2	1	3	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	MAY	2008	40	2					597	612		10.3758/BRM.40.2.597		16	Psychology, Mathematical; Psychology, Experimental	Psychology	320IN	WOS:000257227000028	18522072	
J	Li, HQ; Dai, XB; Zhao, XC				Li, Haiquan; Dai, Xinbin; Zhao, Xuechun			A nearest neighbor approach for automated transporter prediction and categorization from protein sequences	BIOINFORMATICS			English	Article							TRANSMEMBRANE TOPOLOGY; COMPREHENSIVE DATABASE; MEMBRANE-PROTEINS; CLASSIFICATION; FAMILY; RECOGNITION; RESOURCE; CHANNELS; PROGRAM; BIOLOGY	Motivation: Membrane transport proteins play a crucial role in the import and export of ions, small molecules or macromolecules across biological membranes. Currently, there are a limited number of published computational tools which enable the systematic discovery and categorization of transporters prior to costly experimental validation. To approach this problem, we utilized a nearest neighbor method which seamlessly integrates homologous search and topological analysis into a machine-learning framework. Results: Our approach satisfactorily distinguished 484 transporter families in the Transporter Classification Database, a curated and representative database for transporters. A five-fold cross-validation on the database achieved a positive classification rate of 72.3 on average. Furthermore, this method successfully detected transporters in seven model and four non-model organisms, ranging from archaean to mammalian species. A preliminary literature-based validation has cross-validated 65.8 of our predictions on the 11 organisms, including 55.9 of our predictions overlapping with 83.6 of the predicted transporters in TransportDB. Availability and Supplementary information: http://www.w3.org/1999/xlink">http://bioinfo.noble.org/manuscript-support/transporter/ Contact: pzhao@noble.org.	[Li, Haiquan; Dai, Xinbin; Zhao, Xuechun] Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Lab, Ardmore, OK 73401 USA	Zhao, XC (reprint author), Samuel Roberts Noble Fdn Inc, Div Plant Biol, Bioinformat Lab, 2510 Sam Noble Pkwy, Ardmore, OK 73401 USA.						ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1006/jmbi.1990.9999; Apweiler R, 2001, Brief Bioinform, V2, P9, DOI 10.1093/bib/2.1.9; Ashburner M, 2000, NAT GENET, V25, P25; Bejerano G, 2001, BIOINFORMATICS, V17, P23, DOI 10.1093/bioinformatics/17.1.23; Busch W, 2002, CRIT REV BIOCHEM MOL, V37, P287, DOI 10.1080/10409230290771528; Chang AB, 2004, MOL MEMBR BIOL, V21, P171, DOI 10.1080/09687680410001720830; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dibrov P, 1998, FEBS LETT, V424, P1, DOI 10.1016/S0014-5793(98)00119-7; DOOLITTLE RF, 1981, SCIENCE, V214, P149, DOI 10.1126/science.7280687; Eskin E, 2003, J COMPUT BIOL, V10, P187, DOI 10.1089/106652703321825964; Haft DH, 2001, NUCLEIC ACIDS RES, V29, P41, DOI 10.1093/nar/29.1.41; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; Heil B, 2006, BIOINFORMATICS, V22, P1562, DOI 10.1093/bioinformatics/btl132; HENIKOFF S, 1994, GENOMICS, V19, P97, DOI 10.1006/geno.1994.1018; Horton P, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P147; John B, 2004, PROTEIN SCI, V13, P54, DOI 10.1110/ps.03335004; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Leonardi FG, 2006, BIOINFORMATICS, V22, P1302, DOI 10.1093/bioinformatics/bt/088; Lin HH, 2006, PROTEINS, V62, P218, DOI 10.1002/prot.20605; Paulsen IT, 1998, J MOL BIOL, V277, P573, DOI 10.1006/jmbi.1998.1609; Pruitt KD, 2005, NUCLEIC ACIDS RES, V33, pD501, DOI 10.1093/nar/gki025; Ren QH, 2004, NUCLEIC ACIDS RES, V32, pD284, DOI 10.1093/nar/gkh016; Ren QH, 2007, NUCLEIC ACIDS RES, V35, pD274, DOI 10.1093/nar/gkl925; RIGAUD JL, 1995, BBA-BIOENERGETICS, V1231, P223, DOI 10.1016/0005-2728(95)00091-V; Saier MH, 2006, NUCLEIC ACIDS RES, V34, pD181, DOI 10.1093/nar/gkj001; Saier MH, 2000, MICROBIOL MOL BIOL R, V64, P354, DOI 10.1128/MMBR.64.2.354-411.2000; SAKMANN B, 1984, ANNU REV PHYSIOL, V46, P455; SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137; Schwacke R, 2003, PLANT PHYSIOL, V131, P16, DOI 10.1104/pp.011577; Sonnhammer ELL, 1997, PROTEINS, V28, P405, DOI 10.1002/(SICI)1097-0134(199707)28:3<405::AID-PROT10>3.0.CO;2-L; Stoffel W., 1993, BIOL CHEM HOPPESEYLE, V374, P166, DOI DOI 10.1016/J.JTBI.2009.11.002; Tusnady GE, 2001, BIOINFORMATICS, V17, P849, DOI 10.1093/bioinformatics/17.9.849; YAN Q, 2003, MEMBRANE TRANSPORTER, V227; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847; Zhai YF, 2001, J MOL MICROB BIOTECH, V3, P501; Zhou XF, 2003, J MOL MICROB BIOTECH, V5, P7, DOI 10.1159/000068719	36	19	21	1	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803			BIOINFORMATICS	Bioinformatics	MAY 1	2008	24	9					1129	1136		10.1093/bioinformatics/btn099		8	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	293DB	WOS:000255313900002	18337257	
J	Tarakanov, AO				Tarakanov, Alexander O.			Immunocomputing for intelligent intrusion detection	IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE			English	Article							FORMAL IMMUNE NETWORK; PATTERN-RECOGNITION; RECEPTOR MOSAICS; TRANSFORM; SYSTEMS; MODEL	Based on immunocomputing, this paper describes an approach to intrusion detection. The approach includes both low-level signal processing (feature extraction) and high-level (intelligent) pattern recognition. The key model is the formal immune network (FIN) including apoptosis (programmed cell death) and immunization, both controlled by cytokines (messenger proteins). Such FIN can be formed from the network traffic signals using discrete tree transforms, singular value decomposition, and the proposed index of inseparability as a measure of quality of FIN. Recent results suggest that the approach outperforms (by training time and accuracy) state-of-the-art approaches of computational intelligence.	Russian Acad Sci, Moscow 117901, Russia	Tarakanov, AO (reprint author), Russian Acad Sci, Moscow 117901, Russia.						Adamatzky A., 1994, IDENTIFICATION CELLU; AGNATI LF, 2008, BRAIN RES R IN PRESS; Agnati LF, 2005, J MOL NEUROSCI, V26, P193, DOI 10.1385/JMN/26:02:193; Agnati LF, 2005, BIOSYSTEMS, V80, P165, DOI 10.1016/j.biosystems.2004.11.004; Atreas ND, 2004, COMP FUNCT GENOM, V5, P69, DOI 10.1002/cfg.367; Atreas ND, 2003, LECT NOTES COMPUT SC, V2787, P111; Bay S.D., 1999, UCI KDD ARCH; Chao DL, 2004, J THEOR BIOL, V228, P227, DOI 10.1016/j.jtbi.2003.12.011; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D., 2005, ENHANCING COMPUTER S, P165; Dasgupta D, 2004, LECT NOTES COMPUT SC, V3239, P1; Dasgupta D, 2006, IEEE COMPUT INTELL M, V1, P40, DOI 10.1109/MCI.2006.329705; Dasgupta D., 1999, ARTIFICIAL IMMUNE SY; De Castro L. N., 2002, ARTIFICIAL IMMUNE SY; Goncharova LB, 2007, BRAIN RES REV, V55, P155, DOI 10.1016/j.brainresrev.2007.02.003; Goncharova LB, 2005, LECT NOTES COMPUT SC, V3627, P72; Goncharova LB, 2008, CURR MED CHEM, V15, P210; Horn R. A., 1986, MATRIX ANAL; Johnson JE, 2005, LECT NOTES COMPUT SC, V3685, P129; Karanikas C, 2003, CHAOS SOLITON FRACT, V17, P195, DOI 10.1016/S0960-0779(02)00341-7; Kozyrev S. V., 2002, IZV MATH+, V66, p[149, 367], DOI 10.1070/IM2002v066n02ABEH000381; Renyi A, 1961, P 4 BERK S MATH STAT, P547; Tarakanov A, 2007, INT J UNCONV COMPUT, V3, P123; TARAKANOV A, 2007, P 1 IEEE S FDN COMP, P503; TARAKANOV A, 2007, RADIOSYSTEMS, V106, P90; Tarakanov A, 2007, J CELL AUTOM, V2, P39; TARAKANOV A, 2007, ADV APPL SELF ORG SY, P271; TARAKANOV A, 2002, KYBERNETES, V31, P394; Tarakanov AO, 2005, LECT NOTES ARTIF INT, V3630, P510; Tarakanov AO, 2004, LECT NOTES COMPUT SC, V3239, P236; Tarakanov AO, 2007, COMM COM INF SC, V1, P308, DOI 10.1007/978-3-540-73986-9_26; TARAKANOV AO, 2007, LNGC, V14, P252; TARAKANOV AO, 2003, IMMUNOCOMPUTING; Tarakanov AO, 2005, LECT NOTES COMPUT SC, V3685, P394; TARAKANOV AO, 2005, INT J UNCONV COMPUT, V1, P357; ZHAO W, 2005, ACM SIGACT NEWS, V36, P14, DOI 10.1145/1107523.1107532	36	10	14	1	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1556-603X			IEEE COMPUT INTELL M	IEEE Comput. Intell. Mag.	MAY	2008	3	2					22	30		10.1109/MCI.2008.919069		9	Computer Science, Artificial Intelligence	Computer Science	342ES	WOS:000258768000006		
J	Millett, RP				Millett, Ronald P.			Memory-based language processing	JOURNAL OF QUANTITATIVE LINGUISTICS			English	Book Review							CLASSIFICATION		[Millett, Ronald P.] Brigham Young Univ, Dept Linguist, Provo, UT 84602 USA	Millett, RP (reprint author), Brigham Young Univ, Dept Linguist, Provo, UT 84602 USA.						ALLEN J, 1995, NATURAL LANGUAGE UND; Barlow Michael, 2000, USAGE BASED MODELS L; BOD R, 1998, GRAMMER EXPERIENCE B; BUCHHOLZ S, 1999, EMNLP VLC 99 JOINT S; Carl M., 2003, TEXT SPEECH LANGUAGE, V21; Cohens W, 1995, P 12 INT C MACH LEAR, P115; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W., 2005, MEMORY BASED LANGUAG; DAELEMANS W, 2004, TIMBL TILBURG MEMORY; Daelemans W, 1997, ARTIF INTELL REV, V11, P407, DOI 10.1023/A:1006506017891; Daelemans W., 2002, ANALOGICAL MODELING, P157; EDDINGTON D, 2002, ANALOGICAL MODELING, P141; Fix E., 1952, DISCRIMINATORY ANAL; *ILK, 0402 ILK TILB U; KROTT A, 2002, ANALOGICAL MODELING, P181; MILLETT R, 2006, AUTOMATIC HOLISTIC S; PALMER FR, 1969, SELECTED PAPERS JR F; RATNAPARKHI A, 1994, WORKSH HUMAN LANGUAG; Saussure F., 1966, COURS LINGUISTIQUE G; Skousen R., 1989, ANALOGICAL MODELING; Skousen Royal, 2002, ANALOGICAL MODELING; VANDENBOSCH A, 2002, ANALOGICAL MODELING, P209	22	0	0	0	1	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXFORDSHIRE, ENGLAND	0929-6174			J QUANT LINGUIST	J. Quant. Linguist.	MAY	2008	15	2					212	219		10.1080/09296170801961934		8	Linguistics; Language & Linguistics	Linguistics	315KL	WOS:000256877500005		
J	Huang, CC; Chang, HY; Yang, CH				Huang, Chi-Chun; Chang, Hsin-Yun; Yang, Cheng-Hong			A novel grey-based feature ranking method for feature subset selection	JOURNAL OF THE CHINESE INSTITUTE OF ENGINEERS			English	Article						pattern classification; feature subset selection; feature ranking method	CLASSIFICATION; ALGORITHMS	In this paper, a novel grey-based feature ranking method for feature subset selection is proposed. The classification effectiveness of each attribute of a specific classification problem is proposed and then each attribute can be ranked. Features with higher classification effectiveness are more important and relevant and thus considered as the final feature subset for pattern classification. Experiments performed on various application domains are reported to demonstrate the performance of the proposed approach. The proposed approach yields better performance than other existing feature subset selection methods and is helpful for improving the classification accuracy in pattern classification.	[Huang, Chi-Chun] Natl Kaohsiung Marine Univ, Dept Informat Management, Kaohsiung 811, Taiwan; [Chang, Hsin-Yun] Chin Min Inst Technol, Dept Business Adm, Tou Fen, Miao Li, Taiwan; [Chang, Hsin-Yun] Natl Kaohsiung Normal Univ, Dept Ind Technol Educ, Kaohsiung 802, Taiwan; [Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung 80778, Taiwan	Huang, CC (reprint author), Natl Kaohsiung Marine Univ, Dept Informat Management, 142 Hai Jhuan RD, Kaohsiung 811, Taiwan.	cchuang@mail.nkmu.edu.tw					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Inza I, 2001, INT J APPROX REASON, V27, P143, DOI 10.1016/S0888-613X(01)00038-X; Blake C, 1998, UCI REPOSITORY MACHI; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1990, NEAREST NEIGHBOR NN; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Deng J., 1984, SOCIAL SCI CHINA, V6, P47; DENG JL, 1989, J GREY SYSTEM, V2, P103; Deng Julong, 1989, Journal of Grey Systems, V1; Duda R. O., 1973, PATTERN CLASSIFICATI; Hall M., 1998, THESIS U WAIKATO NZ; Huang CC, 2006, PATTERN RECOGN, V39, P1979, DOI 10.1016/j.patcog.2006.05.013; Huang CC, 2006, APPL INTELL, V25, P243, DOI 10.1007/s10489-006-0105-0; Kohavi R., 1997, ARTIF INTELL, V97, P1; Liu H., 1996, P 13 INT C MACH LEAR, P319; Liu H., 1998, FEATURE SELECTION KN; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; STONE M, 1974, J R STAT SOC B, V36, P111; Su YM, 2000, J CHIN INST ENG, V23, P653, DOI 10.1080/02533839.2000.9670586	21	0	0	1	2	CHINESE INST ENGINEERS	TAIPEI	#1, 4TH FL, SEC 2, JEN-AI RD, TAIPEI 10019, TAIWAN	0253-3839			J CHIN INST ENG	J. Chin. Inst. Eng.	MAY	2008	31	3					509	514		10.1080/02533839.2008.9671405		6	Engineering, Multidisciplinary	Engineering	332IN	WOS:000258076800015		
J	Caulier, Y; Spinnler, K; Wittenberg, T; Bourennane, S				Caulier, Yannick; Spinnler, Klaus; Wittenberg, Thomas; Bourennane, Salah			Specific features for the analysis of fringe images	OPTICAL ENGINEERING			English	Article						fringe analysis; nondestructive testing; pattern recognition; illumination	HOLOGRAPHIC-INTERFEROMETRY; CONVOLUTION PROCESSORS; WAVELET FILTERS; FAULT-DETECTION; PATTERNS	In optical nondestructive testing, a novel solution is presented for fault detection based on the interpretation of fringe images. These images can be acquired using different optical methods, such as structured lighting or interferometry. We propose a set of eight special features adapted to the problem of surface inspection using structured illumination. These characteristics are combined with six further features specially developed for the classification of faults using interferometric images. We apply two kinds of decision rules: the Bayesian and the nearest neighbor classifiers. The proposed features are evaluated using a noisy and a noise-free image data set. All patterns were obtained by means of structured lighting. Concerning the noisy data set, we obtain better classification rates when all the 14 features are used in combination with a one-nearest-neighbor classifier. In case of a noise-free data set, we show that similar classification rates are obtained when the 14 features or only the 8 specific features are involved. The methods described are designed to address a broad range of optical nondestructive applications involving the interpretation and classification of fringe patterns. (c) 2008 Society of Photo-Optical Instrumentation Engineers.	[Caulier, Yannick; Spinnler, Klaus; Wittenberg, Thomas] Fraunhofer Inst, D-91058 Erlangen, Germany; [Bourennane, Salah] Fresnel Inst, Ecole Cent Marseille, F-13397 Marseille 20, France	Caulier, Y (reprint author), Fraunhofer Inst, Wolfsmantel 33, D-91058 Erlangen, Germany.	yannick.caulier@iis.fraunhofer.de	Bourennane, Salah/F-2928-2010				CAULIER Y, EURASIP J A IN PRESS; CAULIER Y, NEUES SYSTEM ZURSCHN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; FEIN H, 1997, IND PHYS, V3, P37; Hall-Holt O., 2001, 8 IEEE INT C COMP VI, V2, P359; Juptner WP, 1994, P SOC PHOTO-OPT INS, V2342, P16; Kammel S., 2004, THESIS U KARLSRUHE T; KOZUCHI J, 2002, P 19 IEEE C INSTR ME, V1, P369; Kruger S, 2001, J ELECTRON IMAGING, V10, P228, DOI 10.1117/1.1318908; Kruger S, 2000, P SOC PHOTO-OPT INS, V3966, P145, DOI 10.1117/12.380068; LEENDERT.JA, 1970, J PHYS E SCI INSTRUM, V3, P214, DOI 10.1088/0022-3735/3/3/312; Li XD, 2000, OPT ENG, V39, P2821, DOI 10.1117/1.1308485; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; MONKS TP, 1992, P IEEE 4 INT C IM PR, P327; Niemann H, 2003, KLASSIFIKATION MUSTE, V2nd; Osten W., 1993, P SOC PHOTO-OPT INS, V2004, P256; QIAN K, 2005, MEASUREMENT SCI TECH, V15, P1582; SHELLABEAR MC, 1991, OPT LASER ENG, V15, P43, DOI 10.1016/0143-8166(91)90005-E; SIROHI RS, 2005, FRINGE 2005, P2; VIALARD A, 1999, SIMPLIFICATION CONTO; VILLAIN J, 1991, IEEE T COMPON HYBR, V14, P766, DOI 10.1109/33.105131; WANG WN, 1995, P ELECTR C, P835; Winkelbach S., 2002, LECT NOTES COMPUTER, V2449, P240; Witten I, 2005, DATA MINING; YAMAGUCHI I, 2005, FRINGE 2005, P396; ZHI H, 1992, 11 INT C PATT REC C, V3, P105	27	0	0	1	1	SPIE-SOC PHOTOPTICAL INSTRUMENTATION ENGINEERS	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA	0091-3286			OPT ENG	Opt. Eng.	MAY	2008	47	5							057201	10.1117/1.2927463		11	Optics	Optics	320IO	WOS:000257227100035		
J	Fang, YP; Feng, Y; Li, ML				Fang, Yaping; Feng, Yi; Li, Menglong			Optimal QSAR analysis of the carcinogenic activity of aromatic and heteroaromatic Amines	QSAR & COMBINATORIAL SCIENCE			English	Article						amines; carcinogenic activity; Genetic Algorithm (GA); Quantitative Structure-Activity Relationship (QSAR); Support Vector Regression (SVR)	PROTEIN SUBCELLULAR LOCATION; STRUCTURAL CLASS PREDICTION; PRINCIPAL COMPONENT REGRESSION; LIPOPHILICITY POTENTIAL HMLP; SECONDARY STRUCTURE-CONTENT; SUPPORT VECTOR MACHINES; GENETIC ALGORITHMS; ENSEMBLE CLASSIFIER; FEATURE-SELECTION; HYDROPATHIC FACTORS	Aromatic and heteroaromatic amines are widely used in industrial chemicals and can be found in cooked foods and in tobacco smoke. In this study, Quantitative Structure-Activity Relationships (QSARs) are developed that correlate the observed carcinogenic activities of 80 aromatic and heteroaromatic amines. Principal Component Regression and stepwise linear regression techniques have been applied to construct the QSAR models. The performance of these two models is slightly superior compared to the previous reported based on the same dataset by multiple linear regression techniques. To improve the performance, Support Vector Regression (SVR) has been used to construct the QSARs and Genetic Algorithm (GA) has been used to select the most informational descriptors. Additionally, by introducing the concept of the weighting technique into the model, a new SVR, optimized sample-weighted SVR is proposed. The optimal weighted coefficient is 0.2. The results suggest that approaches using GA selecting descriptors and weighting the descriptors can effectively improve the performance of the SVR models. The optimal Root Mean Square Error in Prediction is 0.799, which is relative smaller than other models. Jackknife-testing procedure has been used to validate the models. The results indicate that the selected descriptors by GA and weighting technique are important and necessary to improve the performance of QSAR models by SVR.	[Fang, Yaping; Feng, Yi; Li, Menglong] Sichuan Univ, Coll Chem, State Key Lab Biotherapy, Chengdu 610064, Peoples R China	Fang, YP (reprint author), Sichuan Univ, Coll Chem, State Key Lab Biotherapy, Chengdu 610064, Peoples R China.	liml@scu.edu.cn					Asikainen AH, 2004, ENVIRON SCI TECHNOL, V38, P6724, DOI 10.1021/es049665h; Barros AS, 1998, CHEMOMETR INTELL LAB, V40, P65, DOI 10.1016/S0169-7439(98)00002-1; Benigni R, 2000, CHEM REV, V100, P3697, DOI 10.1021/cr9901079; Benigni R, 1998, ENVIRON MOL MUTAGEN, V32, P75, DOI 10.1002/(SICI)1098-2280(1998)32:1<75::AID-EM9>3.0.CO;2-A; Bhat KL, 2005, QSAR COMB SCI, V24, P831, DOI 10.1002/qsar.200430921; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2006, CURR MED CHEM, V13, P3263, DOI 10.2174/092986706778773077; Chou K-C, 2006, FRONTIERS MED CHEM, V3, P455; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 1999, J PROTEIN CHEM, V18, P473, DOI 10.1023/A:1020696810938; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Depczynski U, 2000, ANAL CHIM ACTA, V420, P217, DOI 10.1016/S0003-2670(00)00893-X; Du QS, 2006, J COMPUT CHEM, V27, P685, DOI 10.1002/jcc.20369; DU QS, 2007, J COMPUT CHEM; Du QS, 2007, J COMPUT CHEM, V28, P2043, DOI 10.1002/jcc.20732; Du QS, 2005, J COMPUT CHEM, V26, P461, DOI 10.1002/jcc.20174; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Eriksson L, 2000, J CHEMOMETR, V14, P599, DOI 10.1002/1099-128X(200009/12)14:5/6<599::AID-CEM619>3.0.CO;2-8; Felton JS, 1999, CANCER LETT, V143, P127, DOI 10.1016/S0304-3835(99)00141-X; Franke R, 2001, CARCINOGENESIS, V22, P1561, DOI 10.1093/carcin/22.9.1561; Guo YZ, 2006, AMINO ACIDS, V30, P397, DOI 10.1007/s00726-006-0332-z; Hatch FT, 2001, ENVIRON MOL MUTAGEN, V38, P268, DOI 10.1002/em.10028; Haykin S., 1999, NEURAL NETWORKS COMP, P318; Hemmateenejad B, 2004, J CHEMOMETR, V18, P475, DOI 10.1002/cem.891; HSIEH KL, 2007, EXPERT SYS APPL, V34, P717; JOUANRIMBAUD D, 1995, ANAL CHEM, V67, P4295, DOI 10.1021/ac00119a015; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Kim D, 2004, BIOCHEMISTRY-US, V43, P981, DOI 10.1021/bi035593f; Knize MG, 2006, ENVIRON MOL MUTAGEN, V47, P132, DOI 10.1002/em.20177; LEARDI R, 1992, J CHEMOMETR, V6, P267, DOI 10.1002/cem.1180060506; Leardi R, 1998, CHEMOMETR INTELL LAB, V41, P195, DOI 10.1016/S0169-7439(98)00051-3; LEARDI R, 1994, J CHEMOMETR, V8, P65, DOI 10.1002/cem.1180080107; Li YK, 2007, TALANTA, V72, P217, DOI 10.1016/j.talanta.2006.10.022; Liu WM, 1999, PROTEIN ENG, V12, P1041, DOI 10.1093/protein/12.12.1041; Liu WM, 1998, J PROTEIN CHEM, V17, P209, DOI 10.1023/A:1022576400291; LU WC, 2005, QSAR COMB SCI, V9, P1021; Lu X., 2007, CHEMOM INTELL LAB SY, V85, P140; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; MALINOWSKI ER, 2002, FACTOR ANAL CHEM, P224; Maran U, 1999, QUANT STRUCT-ACT REL, V18, P3, DOI 10.1002/(SICI)1521-3838(199901)18:1<03::AID-QSAR3>3.0.CO;2-P; Martens H., 1996, MULTIVARIATE CALIBRA; Novak M, 2002, CHEM RES TOXICOL, V15, P1495, DOI 10.1021/tx025584s; Rasulev BF, 2005, QSAR COMB SCI, V24, P1056, DOI 10.1002/qsar.200430013; Sasaki JC, 2002, MUTAT RES-FUND MOL M, V506, P79, DOI 10.1016/S0027-5107(02)00154-9; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; SUTTER JM, 1992, J CHEMOMETR, V6, P217, DOI 10.1002/cem.1180060406; TAN F, 2006, AMINO ACIDS, P1; Turesky RJ, 2002, MUTAT RES-FUND MOL M, V506, P187, DOI 10.1016/S0027-5107(02)00165-3; Vapnik V N, 1998, NATURE STAT LEARNING; Wen Z., 2006, AMINO ACIDS, V32, P277; WOLD S, 1983, J CHEM INF COMP SCI, V23, P6, DOI 10.1021/ci00037a002; Xu L, 2007, TALANTA, V71, P561, DOI 10.1016/j.talanta.2006.04.039; Yao XJ, 2004, J CHEM INF COMP SCI, V44, P1257, DOI 10.1021/ci049965i; Zhang W, 2000, J CHEM INF COMP SCI, V40, P185; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251	68	2	2	3	8	WILEY-V C H VERLAG GMBH	WEINHEIM	PO BOX 10 11 61, D-69451 WEINHEIM, GERMANY	1611-020X			QSAR COMB SCI	QSAR Comb. Sci.	MAY	2008	27	5					543	554		10.1002/qsar.200710077		12	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications; Pharmacology & Pharmacy	Pharmacology & Pharmacy; Chemistry; Computer Science	305WQ	WOS:000256208900002		
J	Wu, K; Lu, BL; Utiyama, M; Isahara, H				Wu, Ke; Lu, Bao-Liang; Utiyama, Masao; Isahara, Hitoshi			An empirical comparison of min-max-modular k-NN with different voting methods to large-scale text categorization	SOFT COMPUTING			English	Article; Proceedings Paper	4th International Symposium on Neural Networks (ISNN 2007)	JUN 03-07, 2007	Nanjing, PEOPLES R CHINA	Natl Nat Sci Fdn China, KC Wong Educ Fdn, SE Univ China, Chinese Univ Hong Kong, Univ Illinois, Chicago		text categorization; k-NN algorithm; min-max-modular k-NN; parallel computing	PATTERN-CLASSIFICATION; NEURAL-NETWORK; TASK DECOMPOSITION	Text categorization refers to the task of assigning the pre-defined classes to text documents based on their content. k-NN algorithm is one of top performing classifiers on text data. However, there is little research work on the use of different voting methods over text data. Also, when a huge number of training data is available online, the response speed slows down, since a test document has to obtain the distance with each training data. On the other hand, min-max-modular k-NN (M-3-k-NN) has been applied to large-scale text categorization. M-3-k-NN achieves a good performance and has faster response speed in a parallel computing environment. In this paper, we investigate five different voting methods for k-NN and M-3-k-NN. The experimental results and analysis show that the Gaussian voting method can achieve the best performance among all voting methods for both k-NN and M-3-k-NN. In addition, M-3-k-NN uses less k-value to achieve the better performance than k-NN, and thus is faster than k-NN in a parallel computing environment.	[Wu, Ke; Lu, Bao-Liang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China; [Utiyama, Masao; Isahara, Hitoshi] Natl Inst Informat & Commun Technol, Knowledge Creating Commun Res Ctr, Kyoto 6190289, Japan	Lu, BL (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dong Chun Rd, Shanghai 200240, Peoples R China.	wuke@sjtu.edu.cn; bllu@sjtu.edu.cn; mutiyama@nict.go.jp; isahara@nict.go.jp					BERGO A, 2007, TEXT CATEGORIZATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FAN ZG, 2005, ICNC, P396; FIX E, 1951, RANDOLPH FIELD, V4; Joachims T, 1997, P 14 INT C MACH LEAR, P143; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; Lewis DD, 2004, J MACH LEARN RES, V5, P361; LIAN HC, 2005, ICNC, P438; LIU FY, 2005, IEEE INT JOINT C NEU, V1, P570; Liu T., 2005, WWW 05, P1106; LU B L, 2004, P INT JOINT C NEUR N, P735; Lu BL, 1997, LECT NOTES COMPUT SC, V1240, P330; LU BL, 2000, P 5 INT C KNOWL BAS, P298; Lu BL, 2004, IEEE T BIO-MED ENG, V51, P551, DOI 10.1109/TBME.2003.821023; Lu BL, 1999, IEEE T NEURAL NETWOR, V10, P1244, DOI 10.1109/72.788664; LUO J, 2006, ISNN, P210; Nigam K., 1999, IJCAI 99 WORKSH MACH, P61; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; WANG K, 2005, ISNN, P887; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; Yang Y., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; YANG Y, 2006, ISNN, P667; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; Zhao H, 2004, LECT NOTES COMPUT SC, V3314, P867; ZHAO H, 2006, ISNN, P537	26	4	6	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013 USA	1432-7643			SOFT COMPUT	Soft Comput.	MAY	2008	12	7					647	655		10.1007/s00500-007-0242-3		9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	265II	WOS:000253351900006		
J	Zhang, CQ; Ou, YB				Zhang, Cun-Quan; Ou, Yongbin			Clustering, Community Partition and Disjoint Spanning Trees	ACM TRANSACTIONS ON ALGORITHMS			English	Article						Spanning trees; clustering; dense subgraph; polynomial algorithm; community; dynamic density; hierarchical clustering	ALGORITHMS; NETWORK; GRAPH	Clustering method is one of the most important tools in statistics. In a graph theory model, clustering is the process of finding all dense subgraphs. A mathematically well-defined measure for graph density is introduced in this article as follows. Let G = (V, E) be a graph (or multi-graph) and H be a subgraph of G. The dynamic density of H is the greatest integer k such that min(VP){vertical bar E(H/P)vertical bar/vertical bar V(H/P)vertical bar-1} > k where the minimum is taken over all possible partitions P of the vertex set of H, and H/P is the graph obtained from H by contracting each part of P into a single vertex. A subgraph H of G is a level-k community if H is a maximal subgraph of G with dynamic density at least k. An algorithm is designed in this paper to detect all level-h communities of an input multi-graph G. The worst-case complexity of this algorithm is upper bounded by O(vertical bar V(G)vertical bar(2)h(2)). This new method is one of few available clustering methods that are mathematically well-defined, supported by rigorous mathematical proof and able to achieve the optimization goal with polynomial complexity. As a byproduct, this algorithm also can be applied for finding edge-disjoint spanning trees of a multi-graph. The worst-case complexity is lower than all known algorithms for multi-graphs.	[Zhang, Cun-Quan; Ou, Yongbin] W Virginia Univ, Dept Math, Morgantown, WV 26506 USA	Zhang, CQ (reprint author), W Virginia Univ, Dept Math, Morgantown, WV 26506 USA.	cqzhang@math.wvu.edu; ouyb@csbl.bmb.uga.edu			National Security Agency [MDA904-01-1-0022]; WV EPSCoR	C.-Q. Zhang was supported by a grant of the National Security Agency (MDA904-01-1-0022) and a grant of WV EPSCoR.	Anthonisse J.M., 1971, 971 BN STICHT MATH C; BARAHONA F, 1995, MATH OPER RES, V20, P104, DOI 10.1287/moor.20.1.104; BARAHONA F, 2004, NETWORK REINFORCEMEN; Berkhin P., 2002, SURVEY CLUSTERING DA; Bezdek J. C., 1981, PATTERN RECOGNITION; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNNINGHAM WH, 1985, J ACM, V32, P549, DOI 10.1145/3828.3829; CUNNINGHAM WH, 1984, J COMB THEORY B, V36, P161, DOI 10.1016/0095-8956(84)90023-6; Dandrade R., 1978, PSYCHOMETRIKA, P58; Ding C., 2004, P 2004 ACM S APPL CO, P584, DOI 10.1145/967900.968021; Dunn J. C., 1973, Journal of Cybernetics, V3; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543; GABOW HN, 1995, J COMPUT SYST SCI, V50, P259, DOI 10.1006/jcss.1995.1022; Gabow HN, 1998, J ALGORITHM, V26, P48, DOI 10.1006/jagm.1997.0904; GABOW HN, 1995, PROCEEDINGS OF THE SIXTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P88; GABOW HN, 1992, ALGORITHMICA, V7, P465, DOI 10.1007/BF01758774; Girvan M., 2002, P NATL ACAD SCI USA, V99, P8271; GOLDBERG AV, 1988, J ACM, V35, P921, DOI 10.1145/48014.61051; GUSFIELD D, 1991, SIAM J COMPUT, V20, P639, DOI 10.1137/0220040; Han J., 2000, MORGAN KAUFMANN SERI; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Hoppner F., 1999, FUZZY CLUSTER ANAL M; Jain AK, 1999, ACM COMPUT SURV, V31; Johnson SC, 1967, PSYCHOMETRIKA, V2, P241; LAMPINEN T, 2002, P INT C FUZZ SYST KN; Lukashin AV, 2001, BIOINFORMATICS, V17, P405, DOI 10.1093/bioinformatics/17.5.405; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Massart D. L., 1983, INTERPRETATION ANAL; Moore Andrew W., 2001, K MEANS HIERARCHICAL; NashWilliams C. S. J, 1961, J LOND MATH SOC, V2, P445; PELLEG D, 1999, C KNOWL DISC DAT P 5, P277; Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101; Roberts F. S., 2004, APPL COMBINATORICS; ROSKIND J, 1985, MATH OPER RES, V10, P701, DOI 10.1287/moor.10.4.701; *SAS I INC, SAS STAT US GUID, pCH8; SEIDMAN SB, 1983, SOC NETWORKS, V5, P269, DOI 10.1016/0378-8733(83)90028-X; Steinbach M., 2000, TEXTMINING WORKSH KD; STEPHEN SP, 1994, CONNECTIONS, V17, P78; Tutte W., 1961, J LOND MATH SOC, V36, P221; Wasserman S, 1994, SOCIAL NETWORK ANAL; Wu F, 2004, EUR PHYS J B, V38, P331, DOI 10.1140/epjb/e2004-00125-x; Xu Y, 2002, BIOINFORMATICS, V18, P536, DOI 10.1093/bioinformatics/18.4.536; Zhang C.-Q., 1997, INTEGER FLOWS CYCLE; Zhang XY, 2005, J MOL EVOL, V60, P677, DOI 10.1007/s00239-004-0259-5	46	2	4	1	3	ASSOC COMPUTING MACHINERY	NEW YORK	2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA	1549-6325			ACM T ALGORITHMS	ACM Trans. Algorithms	JUN	2008	4	3							35	10.1145/1367064.1367075		26	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	443AH	WOS:000265882100011		
J	Blanzieri, E; Melgani, F				Blanzieri, Enrico; Melgani, Farid			Nearest neighbor classification of remote sensing images with the maximal margin principle	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						kernel methods; k-nearest neighbor algorithm; maximal margin principle; support vector machines (SVMs)	SUPPORT VECTOR MACHINES; STRUCTURAL RISK; RULE; MINIMIZATION; ALGORITHM	In this paper, we present a new variant of the k-nearest neighbor (kNN) classifier based on the maximal margin principle. The proposed method relies on classifying a given unlabeled sample by first finding its k-nearest training samples. A local partition of the input feature space is then carried out by means of local support vector machine (SVM) decision boundaries determined after training a multiclass SVM classifier on the considered k training samples. The labeling of the unknown sample is done by looking at the local decision region to which it belongs. The method is characterized by resulting global decision boundaries of the piecewise linear type. However, the entire process can be kernelized through the determination of the k-nearest training samples in the transformed feature space by using a distance function simply reformulated on the basis of the adopted kernel. To illustrate the performance of the proposed method, an experimental analysis on three different remote sensing datasets is reported and discussed.	[Blanzieri, Enrico; Melgani, Farid] Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy	Blanzieri, E (reprint author), Univ Trent, Dept Informat & Commun Technol, I-38050 Trento, Italy.	blanzier@dit.unitn.it; melgani@dit.unitn.it	Melgani, Farid/A-7076-2013				[Anonymous], AVIRIS NW INDIANAS I; Bazi Y, 2006, IEEE T GEOSCI REMOTE, V44, P3374, DOI 10.1109/TGRS.2006.880628; Blanzieri E., 2006, P IGARSS DENV CO JUL, P3931; Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154; Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Ferecatu M, 2007, IEEE T GEOSCI REMOTE, V45, P818, DOI 10.1109/TGRS.2007.892007; FIX E, 1951, N4 USAF SCH AV MED, P261; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323; Karacali B, 2004, PATTERN RECOGN LETT, V25, P63, DOI 10.1016/j.patrec.2003.09.002; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lee CH, 2003, PROC INT C TOOLS ART, P411; Li LS, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P371; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Vapnik V. N., 1995, NATURE STAT LEARNING; Wohlberg B, 2006, IEEE T GEOSCI REMOTE, V44, P47, DOI 10.1109/TGRS.2005.859953; Shen XQ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P149; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525; Zhang L, 2006, J ALZHEIMERS DIS, V10, P1; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	24	39	42	3	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	JUN	2008	46	6					1804	1811		10.1109/TGRS.2008.916090		8	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	303QR	WOS:000256056100024		
J	Maas, MC; Schaart, DR; van der Laan, DJ; van Dam, HT; Huizenga, J; Brouwer, JC; Bruyndonckx, P; Lemaitre, C; van Eijk, CWE				Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); van Dam, Herman T.; Huizenga, Jan; Brouwer, J. C.; Bruyndonckx, Peter; Lemaitre, Cedric; van Eijk, Carel W. E.			Signal to noise ratio of APD-based monolithic scintillator detectors for high resolution PET	IEEE TRANSACTIONS ON NUCLEAR SCIENCE			English	Article						avalanche photodiode (APD); monolithic scintillator detector; positron emission tomography (PET); signal to noise ratio (SNR)	SMALL ANIMAL PET; AVALANCHE PHOTODIODES; SPATIAL-RESOLUTION; PERFORMANCE; READOUT; SCANNER; DESIGN; ARRAYS; DEPTH; SENSITIVITY	Monolithic scintillator detectors, consisting of several cm(3) of scintillating material coupled to one or more Hamamatsu S8550 avalanche photodiode (APD) arrays, are proposed as detectors for high resolution positron emission tomography (PET). in this work, the factors contributing to the variance on the signals are investigated, and their effects on the energy, time and spatial resolutions are analyzed. Good agreement was found between a model of the energy resolution and experiments with a 20 x 10 x 10 mm(3) LYSO: Ce crystal coupled to a single channel large-area APD (LAAPD). With the same crystal coupled to an APD array, differences between model and experiment were observed at high APD gain. The measured energy resolution of similar to 11% FWHM was dominated by scintillation photon statistics, with less important roles for the APD excess noise factor and electronic noise. On the other hand, electronic noise was an important factor both for the time and the spatial resolutions. The time resolution was found to depend strongly on the APD bias voltage, and was best at the highest bias. A time resolution of 1.6 ns full width at half maximum (FWHM) was measured against a BaF2-PMT detector. The best spatial resolution measured was 1.64 mm FWHM, without correction for the similar to 0.9 mm FWHM measurement beam. It is estimated that an intrinsic spatial resolution of 1.26 mm FWHM can be achieved at the center of the detector with an infinitely narrow test beam.	[Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); van Dam, Herman T.; Huizenga, Jan; Brouwer, J. C.; van Eijk, Carel W. E.] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Bruyndonckx, Peter; Lemaitre, Cedric] Vrije Univ Brussels, B-1050 Brussels, Belgium	Maas, MC (reprint author), Delft Univ Technol, NL-2629 JB Delft, Netherlands.	m.c.maas@tudelft.nl	Schaart, Dennis/C-7136-2014; Maas, Marnix/J-5101-2014	Schaart, Dennis/0000-0002-3199-5608; 			Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8; BERTUCCIO G, 1993, REV SCI INSTRUM, V64, P3294, DOI 10.1063/1.1144293; Birks J B, 1964, THEORY PRACTICE SCIN; Bloomfield PM, 1997, PHYS MED BIOL, V42, P389, DOI 10.1088/0031-9155/42/2/010; BOISVERT J, 1996, P NUCL SCI S C REC, V1, P16; Bruyndonckx P, 2003, IEEE T NUCL SCI, V50, P1415, DOI 10.1109/TNS.2003.817348; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; CARRICO B, 2006, LIP; CLEMENT D, 1998, P IEEE NSS, V3, P1448; Correia JA, 1999, IEEE T NUCL SCI, V46, P631, DOI 10.1109/23.775590; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Del Guerra A, 1998, NUCL INSTRUM METH A, V409, P537, DOI 10.1016/S0168-9002(97)01311-9; Dorenbos P, 1995, IEEE T NUCL SCI, V42, P2190, DOI 10.1109/23.489415; Fiorini C, 2004, IEEE T NUCL SCI, V51, P1091, DOI 10.1109/TNS.2004.829581; GATTI E, 1990, NUCL INSTRUM METH A, V297, P467, DOI 10.1016/0168-9002(90)91331-5; *GEANT4, 2005, GEANT4 US GUID APPL; GOYOT M, 1988, NUCL INSTRUM METH A, V263, P180, DOI 10.1016/0168-9002(88)91032-7; Kapusta M, 2003, NUCL INSTRUM METH A, V504, P139, DOI 10.1016/S0168-9002(03)00809-X; Lecomte R, 1996, IEEE T NUCL SCI, V43, P1952, DOI 10.1109/23.507252; MAAS MC, 2005, PET, V4, P2017; MAAS MC, MODEL ANAL IN PRESS; MAAS MC, 2004, P IEEE NUCL SCI S C, V5, P2942; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; McElroy DP, 2005, IEEE T NUCL SCI, V52, P199, DOI 10.1109/TNS.2004.843114; Mosset JB, 2003, NUCL INSTRUM METH A, V504, P325, DOI 10.1016/S0168-9002(03)00762-9; Mosset J-B, 2006, THESIS ECOLE POLYTEC; MOSZYNSKI M, 1979, NUCL INSTRUM METHODS, V158, P1, DOI 10.1016/S0029-554X(79)90170-8; Moszynski M, 2002, NUCL INSTRUM METH A, V485, P504, DOI 10.1016/S0168-9002(01)02117-9; Ochi A, 1996, NUCL INSTRUM METH A, V378, P267, DOI 10.1016/0168-9002(96)00442-1; Pansart JP, 1997, NUCL INSTRUM METH A, V387, P186, DOI 10.1016/S0168-9002(96)00987-4; Seidel J, 2003, IEEE T NUCL SCI, V50, P1347, DOI 10.1109/TNS.2003.817282; Surti S, 2003, IEEE T NUCL SCI, V50, P1357, DOI 10.1109/TNS.2003.817950; Tai YC, 2003, PHYS MED BIOL, V48, P1519, DOI 10.1088/0031-9155/48/11/303; Tsuda T, 2004, IEEE T NUCL SCI, V51, P2537, DOI 10.1109/TNS.2004.835739; VANDERLAAN DJ, SPATIAL RES IN PRESS; van der Laan DJJ, 2006, IEEE T NUCL SCI, V53, P1063, DOI 10.1109/TNS.2006.873710; WEBER S, P IEEE NUCL SCI S ME, V3, P1603; Ziemons K, 2005, NUCL INSTRUM METH A, V537, P307, DOI 10.1016/j.nima.2004.08.032	38	11	11	0	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9499			IEEE T NUCL SCI	IEEE Trans. Nucl. Sci.	JUN	2008	55	3	1				842	852		10.1109/TNS.2008.921493		11	Engineering, Electrical & Electronic; Nuclear Science & Technology	Engineering; Nuclear Science & Technology	316RO	WOS:000256967600003		
J	Chen, YH; Chen, F; Yang, JY; Yang, MQ				Chen, Yuehui; Chen, Feng; Yang, Jack Y.; Yang, Mary Qu			Ensemble voting system for multiclass protein fold recognition	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						protein fold recognition; particle swarm optimization (PSO); Tabu search; k-NN; probabilistic neural networks; ensemble learning	STRUCTURAL CLASS PREDICTION; STATISTICAL-METHOD; MEMBRANE-PROTEINS; SEQUENCE; CLASSIFICATION; PROFILES	Protein structure classification is an important issue in understanding the associations between sequence and structure as well as possible functional and evolutionary relationships. Recently structural genomes initiatives and other high-throughput experiments have populated the biological databases at a rapid pace. In this paper, three types of classifiers, k nearest neighbors, class center and nearest neighbor and probabilistic neural networks and their homogenous ensemble for multiclass protein fold recognition problem are evaluated firstly, and then a heterogenous ensemble Voting System is designed for the same problem. The different features and/or their combinations extracted from the protein fold dataset are used in these classification models. The heterogenous classification results are then put into a voting system to get the final result. The experimental results show that the proposed method can improve prediction accuracy by 4%-10% on a benchmark dataset containing 27 SCOP folds.	[Chen, Yuehui] Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China; [Chen, Feng] Univ Elect Sci & Technol China, Sch Software, Chengdu 610054, Peoples R China; [Yang, Jack Y.] Harvard Univ, Harvard Med Sch, Cambridge, MA 02140 USA; [Yang, Mary Qu] US Dept HHS, Natl Human Genome Res Inst, Natl Inst Hlth, Bethesda, MD 20852 USA	Chen, YH (reprint author), Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.	yhchen@ujn.edu.cn; chenfeng_ci@163.com; jyang@bwh.harvard.edu; yangma@mail.NIH.gov					Battiti R., 1994, ORSA Journal on Computing, V6; Bonneau R, 2001, ANNU REV BIOPH BIOM, V30, P173, DOI 10.1146/annurev.biophys.30.1.173; Bu WS, 1999, EUR J BIOCHEM, V266, P1043, DOI 10.1046/j.1432-1327.1999.00947.x; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Cheng JL, 2006, BIOINFORMATICS, V22, P1456, DOI 10.1093/bioinformatics/btl102; Chinnasamy A., 2004, PACIFIC S BIOCOMPUTI, V9, P387; Chou KC, 2000, CURR PROTEIN PEPT SC, V1, P171, DOI 10.2174/1389203003381379; CHOU KC, 1992, AIDS RES HUM RETROV, V8, P1967, DOI 10.1089/aid.1992.8.1967; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding CHQ, 2001, BIOINFORMATICS, V17, P349, DOI 10.1093/bioinformatics/17.4.349; Du QS, 2006, J BIOMOL STRUCT DYN, V23, P635; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Elofsson A, 1996, FOLD DES, V1, P451, DOI 10.1016/S1359-0278(96)00061-2; Exarchos TP, 2008, J BIOMED INFORM, V41, P165, DOI 10.1016/j.jbi.2007.05.004; Glover F., 1989, ORSA Journal on Computing, V1; GLOVER F, 1990, ORSA J COMPUTING, V2, P14; Goh ATC, 2002, CAN GEOTECH J, V39, P219, DOI 10.1139/T01-073; GROMIHA MM, 1995, INT J PEPT PROT RES, V45, P225; Gromiha MM, 1999, J PROTEIN CHEM, V18, P565, DOI 10.1023/A:1020603401001; Gromiha MM, 2005, BIOINFORMATICS, V21, P961, DOI 10.1093/bioinformatics/bti126; Gromiha MM, 2006, J CHEM INF MODEL, V46, P1503, DOI 10.1021/ci050417u; Hirokawa T, 1998, BIOINFORMATICS, V14, P378, DOI 10.1093/bioinformatics/14.4.378; HOBOHM U, 1994, PROTEIN SCI, V3, P522; HOBOHM U, 1992, PROTEIN SCI, V1, P409; Kennedy J., 2002, P C EV COMP CEC 02, P1671, DOI 10.1109/CEC.2002.1004493; KLEIN P, 1986, BIOCHIM BIOPHYS ACTA, V874, P205, DOI 10.1016/0167-4838(86)90119-6; Kumarevel TS, 2000, BIOPHYS CHEM, V88, P81, DOI 10.1016/S0301-4622(00)00201-5; Nanni L, 2006, NEUROCOMPUTING, V69, P2434, DOI 10.1016/j.neucom.2006.01.026; Okun O., 2004, P 11 FINN ART INT C, P207; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P577, DOI 10.1016/j.bbrc.2005.06.128; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shi JY, 2001, J MOL BIOL, V310, P243, DOI 10.1006/jmbi.2001.4762; Sun GM, 2006, NEUROCOMPUTING, V69, P387, DOI 10.1016/j.neucom.2005.04.005; TAGUCHI YH, 2007, BMC BIOINFO IN PRESS; Tan Aik Choon, 2003, Genome Inform, V14, P206; Wang H, 2005, J MATER SCI TECHNOL, V21, P86; Wang ZX, 2000, PROTEINS, V38, P165, DOI 10.1002/(SICI)1097-0134(20000201)38:2<165::AID-PROT5>3.0.CO;2-V; Zhou HY, 2005, PROTEINS, V58, P321, DOI 10.1002/prot.20308	38	5	5	1	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	JUN	2008	22	4					747	763		10.1142/S0218001408006454		17	Computer Science, Artificial Intelligence	Computer Science	327XM	WOS:000257761800006		
J	Marchiori, E				Marchiori, Elena			Hit miss networks with applications to instance selection	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						graph-based training set representation; nearest neighbor; instance selection for instance-based learning	NEAREST-NEIGHBOR RULE; COVER CATCH DIGRAPHS; LEARNING ALGORITHMS; PROTOTYPE SELECTION; PROXIMITY GRAPHS; DATA SETS; CLASSIFICATION; CLASSIFIERS	In supervised learning, a training set consisting of labeled instances is used by a learning algorithm for generating a model (classifier) that is subsequently employed for deciding the class label of new instances (for generalization). Characteristics of the training set, such as presence of noisy instances and size, influence the learning algorithm and affect generalization performance. This paper introduces a new network-based representation of a training set, called hit miss network (HMN), which provides a compact description of the nearest neighbor relation over pairs of instances from each pair of classes. We show that structural properties of HMN's correspond to properties of training points related to the one nearest neighbor (1-NN) decision rule, such as being border or central point. This motivates us to use HMN's for improving the performance of a 1-NN classifier by removing instances from the training set (instance selection). We introduce three new HMN-based algorithms for instance selection. HMN-C, which removes instances without affecting accuracy of 1-NN on the original training set, HMN-E, based on a more aggressive storage reduction, and HMN-EI, which applies iteratively HMN-E. Their performance is assessed on 22 data sets with different characteristics, such as input dimension, cardinality, class balance, number of classes, noise content, and presence of redundant variables. Results of experiments on these data sets show that accuracy of 1-NN classifier increases significantly when HMN-EI is applied. Comparison with state-of-the-art editing algorithms for instance selection on these data sets indicates best generalization performance of HMN-EI and no significant difference in storage requirements. In general, these results indicate that HMN's provide a powerful graph-based representation of a training set, which can be successfully applied for performing noise and redundance reduction in instance-based learning.	Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands	Marchiori, E (reprint author), Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands.	elenam@cs.ru.nl					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Bhattacharjee S, 1998, REV CHEM ENG, V14, P1; Bhattacharya B, 2005, LECT NOTES COMPUT SC, V3776, P60; BHATTACHARYA BK, 1982, 823 TR S FRAS U SCH; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; Chapelle O., 2005, P 10 INT WORKSH ART, P57; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVINNEY, 2005, STAT PROBABILITY LET, V73, P37; DeVinney J, 2006, DISCRETE APPL MATH, V154, P1975, DOI 10.1016/j.dam.2006.04.004; Dorogovtsev S. N., 2003, EVOLUTION NETWORKS B; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jankowski N, 2004, LECT NOTES ARTIF INT, V3070, P598; JAROMCZYK JW, 1992, P IEEE, V80, P1502, DOI 10.1109/5.163414; MUKHERJEE K, 2004, M SC PROJECT; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Priebe CE, 2003, J CLASSIF, V20, P3, DOI 10.1007/s00357-003-0003-7; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sankaranarayanan J, 2007, COMPUT GRAPH-UK, V31, P157, DOI 10.1016/j.cag.2006.11.011; Shin H, 2007, NEURAL COMPUT, V19, P816, DOI 10.1162/neco.2007.19.3.816; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT GT, 1984, P COMP SCI STAT 16 S, P97; TOUSSAINT GT, 2002, 34 S COMP STAT, P83; Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430; WEGMAN DJ, 2005, HDB STAT, V24, P331; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403; Zighed D. A., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431)	37	27	30	0	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	JUN	2008	9						997	1017				21	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	340LE	WOS:000258646300002		
J	Verron, S; Tiplica, T; Kobi, A				Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad			Fault detection and identification with a new feature selection based on mutual information	JOURNAL OF PROCESS CONTROL			English	Article						FDI; discriminant analysis; mutual information	MULTIVARIATE QUALITY-CONTROL; PRINCIPAL COMPONENT ANALYSIS; STATISTICAL PROCESS-CONTROL; EASTMAN CHALLENGE PROCESS; SUPPORT VECTOR MACHINES; DISCRIMINANT-ANALYSIS; CONTROL CHART; PART I; CLASSIFICATION; DIAGNOSIS	This paper presents a fault diagnosis procedure based on discriminant analysis and mutual information. In order to obtain good classification performances, a selection of important features is done with a new developed algorithm based on the mutual information between variables. The application of the new fault diagnosis procedure on a benchmark problem, the Tennessee Eastman Process, shows better results than other well known published methods. (c) 2007 Elsevier Ltd. All rights reserved.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad] Univ Angers, LASQUO ISTIA, F-49000 Angers, France	Verron, S (reprint author), Univ Angers, LASQUO ISTIA, 62 Ave Notre Dame Lac, F-49000 Angers, France.	sylvain.verron@univ-angers.fr					Bakshi BR, 1998, AICHE J, V44, P1596, DOI 10.1002/aic.690440712; Chiang L. H., 2001, FAULT DETECTION DIAG; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; Chiang LH, 2004, J PROCESS CONTR, V14, P143, DOI 10.1016/S0959-1524(03)00029-5; Chua M. K., 1992, QUALITY RELIABILITY, V8, P37, DOI 10.1002/qre.4680080107; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1969, METHODOLOGIES PATTER; Denoeux T., 1997, J EUROPEEN SYSTEMES, V31, P1509; Dhillon BS, 2005, RELIABILITY QUALITY; DOGANAKSOY N, 1991, COMMUN STAT THEORY, V20, P2775, DOI 10.1080/03610929108830667; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; DUBUISSON B, 2001, SERIE PRODUCTIQUE; Duda R O, 2001, PATTERN CLASSIFICATI; Dunia R, 1996, AICHE J, V42, P2797, DOI 10.1002/aic.690421011; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FUCHS C, 1994, TECHNOMETRICS, V36, P182, DOI 10.2307/1270230; Good P. J., 2004, PERMUTATION PARAMETR; Harkat MF, 2006, J PROCESS CONTR, V16, P625, DOI 10.1016/j.jprocont.2005.09.007; HAWKINS DM, 1993, J QUAL TECHNOL, V25, P170; Hoffbeck JP, 1996, IEEE T PATTERN ANAL, V18, P763, DOI 10.1109/34.506799; Hotelling H., 1947, TECHNIQUES STAT ANAL, P111; Huber P.J., 1981, ROBUST STAT; JACKSON JE, 1985, COMMUN STAT-THEOR M, V14, P2657, DOI 10.1080/03610928508829069; John G. H., 1994, INT C MACH LEARN, P121; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; KOBI A, 1994, THESIS I NATL POLYTE; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kourti T, 1996, J QUAL TECHNOL, V28, P409; Kruger U, 2004, J PROCESS CONTR, V14, P879, DOI 10.1016/j.jprocont.2004.02.002; Kulkarni A, 2005, COMPUT CHEM ENG, V29, P2128, DOI 10.1016/j.compchemeng.2005.06.006; Langley P., 1992, NAT C ART INT; Lee JM, 2004, CHEM ENG SCI, V59, P2995, DOI 10.1016/j.ces.2004.04.031; LOWRY CA, 1992, TECHNOMETRICS, V34, P46, DOI 10.2307/1269551; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MACGREGOR JF, 1995, CONTROL ENG PRACT, V3, P403, DOI 10.1016/0967-0661(95)00014-L; MASON RL, 1995, J QUAL TECHNOL, V27, P99; MICHEAUX DLD, 2001, QUALITA, P143; MONTGOMERY D, 1996, COMMUNICATIONS STAT, V25, P2203; Montgomery Douglas C, 1997, INTRO STAT QUALITY C; NOMIKOS P, 1994, AICHE J, V40, P1361, DOI 10.1002/aic.690400809; PAGE ES, 1954, BIOMETRIKA, V41, P100, DOI 10.1093/biomet/41.1-2.100; Patton R.J., 2000, ISSUES FAULT DIAGNOS; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; PIGNATIELLO JJ, 1990, J QUAL TECHNOL, V22, P173; Ricker NL, 1996, J PROCESS CONTR, V6, P205; Roberts S. W., 1959, TECHNOMETRICS, V1, P239, DOI DOI 10.1080/00401706.1959.10489860; Sahami M, 1996, 2 INT C KNOWL DISC D; Shannon E. C., 1948, BELL SYST TECH J, V27, P623; Shewhart WA, 1931, EC CONTROL QUALITY M; Singhal A, 2006, J PROCESS CONTR, V16, P601, DOI 10.1016/j.jprocont.2005.10.005; Stamatis D.H., 2003, FAILURE MODE EFFECT, V2nd; Thomaz CE, 2004, IEEE T CIRC SYST VID, V14, P214, DOI 10.1109/TCSVT.2003.821984; TIPLICA T, 2001, ACT C QUALITA ANN FR, P134; Tiplica T., 2003, J EUROPEAN SYSTEMES, V37, P477, DOI 10.3166/jesa.37.477-500; TRACY ND, 1995, J QUAL TECHNOL, V27, P370; Vapnik V. N., 1995, NATURE STAT LEARNING; Venkatsubramanian V, 2003, COMPUT CHEM ENG, V27, P293, DOI 10.1016/S0098-1354(02)00160-6; Westerhuis JA, 2000, J CHEMOMETR, V14, P335, DOI 10.1002/1099-128X(200007/08)14:4<335::AID-CEM579>3.0.CO;2-F; Wise BM, 1996, J PROCESS CONTR, V6, P329, DOI 10.1016/0959-1524(96)00009-1; Yoon SY, 2001, J PROCESS CONTR, V11, P387, DOI 10.1016/S0959-1524(00)00008-1; Zhang GX, 1984, WORLD QUAL C T AM SO, P175	63	28	31	1	11	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0959-1524			J PROCESS CONTR	J. Process Control	JUN	2008	18	5					479	490		10.1016/j.jprocont.2007.08.003		12	Automation & Control Systems; Engineering, Chemical	Automation & Control Systems; Engineering	305VA	WOS:000256204700006		
J	Cointault, F; Guerin, D; Guillemin, JP; Chopinet, B				Cointault, F.; Guerin, D.; Guillemin, J-P.; Chopinet, B.			In-field Triticum aestivum ear counting using colour-texture image analysis	NEW ZEALAND JOURNAL OF CROP AND HORTICULTURAL SCIENCE			English	Article						colour images; segmentation and classification methods; hybrid space; wheat counting	WEED DETECTION; CLASSIFICATION; SEGMENTATION; FEATURES	A colour and texture image analysis method based on the determination of a hybrid space was developed for a feasibility study for the (semi-)automatic counting of Triticum aestivum wheat ears to simplify manual counting. To detect ears, five textural and statistic features, and colour analyses were both used to give a new representation of the images within a specific space (hybrid space). This new representation was constructed with a priori knowledge about the images (especially the number of classes and training points), providing better recognition than in the standard RGB space (Red/Green/Blue). Classical methods of image segmentation and classification, combined with morphological information about wheat ears, were then applied to the new images to assist counting. Only 20 images were tested and classification accuracy ranged from 73% to 85%. The counting information, which needs to be validated on numerous images, will be in future combined with grain counting per ear and thousand-seed weight to obtain an estimation of wheat yields. The resulting information could prove to be relevant, for example, to allow French cooperatives to organise their harvest.	[Cointault, F.; Guerin, D.; Chopinet, B.] ENESAD, Dept Engn Sci, Agroengn Lab, F-21079 Dijon, France; [Guillemin, J-P.] ENESAD, Dept Agroenvironm, Weed Biol & Management Res Unit, F-21079 Dijon, France	Cointault, F (reprint author), ENESAD, Dept Engn Sci, Agroengn Lab, 26 Bd Docteur Petitjean,BP 87999, F-21079 Dijon, France.	f.cointault@enesad.fr					Benboudjema D, 2005, COMPUT VIS IMAGE UND, V99, P476, DOI 10.1016/j.cviu.2005.04.003; Burks TF, 2000, T ASAE, V43, P441; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; El-Faki MS, 2000, T ASAE, V43, P1001; FOUCHER P, 2001, SEGMENTATION IMAGES; Foucherot I, 2004, PATTERN RECOGN, V37, P1661, DOI 10.1016/j.patcog.2004.02.010; GERMAIN C, 1995, P 5 INT C IM PROC AP, P435; GUERIN D, 2004, CSIMTA 04, P658; HANSEN MF, 2007, P SPIE MED IMAGING 2, V6512; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HEIKKILA J, 1997, IEEE COMP SOC C COMP, P1106, DOI DOI 10.1109/CVPR.1997.609468; LuJunWei, 2001, Transactions of the Chinese Society of Agricultural Engineering, V17, P153; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; OMNES G, 2004, FRANCE AGRICOLE, V3023; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/cviu.1993.1024; SHEARER SA, 1990, T ASAE, V33, P2037; STEWARD BL, 1999, P ASAE CSAE SCGR ANN; Steward BL, 1999, T ASAE, V42, P1897; Tian LF, 1998, COMPUT ELECTRON AGR, V21, P153, DOI 10.1016/S0168-1699(98)00037-4; Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0; Vioix JB, 2004, J ELECTRON IMAGING, V13, P547, DOI 10.1117/1.1760756; YU W, 2005, P MIPPR 2005 SAR MUL, V6043	23	7	7	2	4	RSNZ PUBLISHING	WELLINGTON	PO BOX  598, WELLINGTON, 00000, NEW ZEALAND	0114-0671			NEW ZEAL J CROP HORT	N. Z. J. Crop Hortic. Sci.	JUN	2008	36	2					117	130				14	Agronomy; Horticulture	Agriculture	333SX	WOS:000258173800004		
J	Chen, YF; Wang, RC				Chen Yunfang; Wang Ruchuan			A classification algorithm based on artificial immune	CHINESE JOURNAL OF ELECTRONICS			English	Article						classification; artificial immune system; handwritten digit recognition	SYSTEMS	Based on the natural characteristic of artificial immune system in the field of pattern recognition, the paper proposes a novel Classification algorithm (CAAI). According to the principle of gene revolution, negative selection and clonal selection, a classification algorithm which is based on AIS is designed and implemented. The algorithm consists of two phases. For each word, in the antibody libraries initialization phase, characteristic vectors of the training datasets are extracted and antibody libraries continually evolve using the negative selection. In the classification phase, a clonal selection is introduced to classify the test sample into different categories. Then, the proposed algorithm is validated using classical handwritten digit recognition problem, and the experimental results indicate the robustness and accuracy of the proposed algorithm. Additionally, the comparison with other classification algorithm showed the proposed algorithm has a great competitiveness on recognition rate and recognition performance.	[Chen Yunfang; Wang Ruchuan] Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Peoples R China; [Wang Ruchuan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Chen, YF (reprint author), Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Peoples R China.	wangrc@njupt.edu.cn			National Natural Science Foundation of China [60573141, 60773041]; National 863 High Technology Research Program of China [2006AA01Z439, 2007AA01Z404, 2007AA01Z478]; High Technology Research Programme of Jiangsu Province [BG2006001]; Foundation of National Laboratory for Modern Communications [9140C1101010603]; Key Laboratory of Information Technology Processing of Jiangsu Province [kjs06006]; iangsu Provincial Research Scheme of Natural Science for Higher Education Institutions [07KJB520083]	This work is supported by the National Natural Science Foundation of China (No.60573141, No.60773041), National 863 High Technology Research Program of China (No.2006AA01Z439, No.2007AA01Z404, No.2007AA01Z478), High Technology Research Programme of Jiangsu Province (No.BG2006001), Foundation of National Laboratory for Modern Communications (No.9140C1101010603) and Key Laboratory of Information Technology Processing of Jiangsu Province (No.kjs06006). Project is sponsored by Jiangsu Provincial Research Scheme of Natural Science for Higher Education Institutions (No.07KJB520083).	Bahlmann C., 2002, Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition, DOI 10.1109/IWFHR.2002.1030883; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D., 1999, P 22 NAT INF SYST SE; DASGUPTA D, 2000, P IEEE INT C SYST MA; DASGUPTA D, 2003, IEEE C EL COMM; de Castro L, 2002, ARTIFICIAL NEURAL NE, P67; De Castro L. N., 2002, ARTIFICIAL IMMUNE SY; de Castro LN, 2003, SOFT COMPUT, V7, P526, DOI [10.1007/S00500-002-0237-Z, 10.1007/S00500-002-0237-z]; DEEPU V, 2004, P 17 INT C PATT REC, V2, P23; DEJONG KA, 1993, MACH LEARN, V13, P161, DOI 10.1023/A:1022617912649; DONG JX, 1999, COMPARISON ALGORITHM; DONG JX, 2001, STAT RESULT HUMAN PE; Forrest S, 1993, EVOL COMPUT, V1, P191, DOI 10.1162/evco.1993.1.3.191; Garrett SM, 2005, EVOL COMPUT, V13, P145, DOI 10.1162/1063656054088512; HART E, 2005, ICARIS, P29; HART E, 2005, INT C ART IMM SYST 2; Kegl B, 2002, IEEE T PATTERN ANAL, V24, P59, DOI 10.1109/34.982884; LANGLEY P, 1990, AAAI, P223; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P648; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; OPREA M, 1999, 1999 GEN EV COMP C J; Park Y, 2001, DIABETES METAB RES, V17, P2, DOI 10.1002/1520-7560(2000)9999:9999<::AID-DMRR164>3.0.CO;2-M; PAWLAK Z, 1984, INT J MAN MACH STUD, V20, P469, DOI 10.1016/S0020-7373(84)80022-X; Perelson AS, 1997, REV MOD PHYS, V69, P1219, DOI 10.1103/RevModPhys.69.1219; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; [芮挺 Rui Ting], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P1008; Rui Ting, 2005, Mini-Micro Systems, V26; Rumelhart D., 1986, LEARNING INTERNAL RE; SCHLAPBACH A, 2004, 17 INT C CAMBR UK, V2, P654; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; STEPNEY RE, 2004, P 3 INT C ART IMM SY; TIMMIS J, 2004, OVERVIEW ARTIFICIAL, P51; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893	33	0	1	1	3	TECHNOLOGY EXCHANGE LIMITED HONG KONG	SHATIN	26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN, 00000, PEOPLES R CHINA	1022-4653			CHINESE J ELECTRON	Chin. J. Electron.	JUL	2008	17	3					432	436				5	Engineering, Electrical & Electronic	Engineering	340ZR	WOS:000258684000008		
J	Mignani, AG; Ciaccheri, L; Cucci, C; Mencaglia, AA; Cimato, A; Attilio, C; Ottevaere, H; Thienpont, H; Paolesse, R; Mastroianni, M; Monti, D; Gerevini, M; Buonocore, G; Del Nobile, MA; Mentana, A; Grimaldi, MF; Dall'Asta, C; Faccini, A; Galaverna, G; Dossena, A				Mignani, Anna Grazia; Ciaccheri, Leonardo; Cucci, Costanza; Mencaglia, Andrea Azelio; Cimato, Antonio; Attilio, Cristina; Ottevaere, Heidi; Thienpont, Hugo; Paolesse, Roberto; Mastroianni, Marco; Monti, Donato; Gerevini, Marco; Buonocore, Giovanna; Del Nobile, Matteo Alessandro; Mentana, Annalisa; Grimaldi, Maria Francesca; Dall'Asta, Chiara; Faccini, Andrea; Galaverna, Gianni; Dossena, Arnaldo			EAT-by-LIGHT: Fiber-optic and micro-optic devices for food quality and safety assessment	IEEE SENSORS JOURNAL			English	Article						absorption spectroscopy; aflatoxins; beer; fluorescence spectroscopy; food authentication; milk; olive oil; scattered colorimetry	OLIVE OIL; CLASSIFICATION	A selection is presented of fiber-optic and micro-optic devices that have been designed and tested for guaranteeing the quality and safety of typical foods, such as extra virgin olive oil, beer, and milk. Scattered colorimetry is used to authenticate various types of extra virgin olive oil and beer, while a fiber-optic-based device for UV-VIS-NIR absorption spectroscopy is exploited in order to obtain the hyperspectral optical signature of olive oil. This is done not only for authentication purposes, but also so as to correlate the spectral data with the content of fatty acids, which are important nutritional factors. A micro-optic sensor for the detection of olive oil aroma that is capable of distinguishing different ageing levels of extra virgin olive oil is also presented. It shows effective potential for acting as a smart cap of bottled olive oil in order to achieve a nondestructive olfactory perception of oil ageing. Lastly, a compact portable fluorometer for the rapid monitoring of the carcinogenic M1 aflatoxin in milk, is experimented.	[Mignani, Anna Grazia; Ciaccheri, Leonardo; Cucci, Costanza; Mencaglia, Andrea Azelio] CNR IFAC, Sesto Fiorentino, FI, Italy; [Cimato, Antonio; Attilio, Cristina] CNR IVALSA, Sesto Fiorentino, FI, Italy; [Ottevaere, Heidi; Thienpont, Hugo] Vrije Univ Brussels, Dept Appl Phys & Photon, Brussels, Belgium; [Paolesse, Roberto; Mastroianni, Marco; Monti, Donato] Univ Roma Tor Vergata, Dipartimento Sci & Tecnol Chim, Rome, Italy; [Gerevini, Marco] Tecnoalimenti SCpA, Milan, Italy; [Buonocore, Giovanna] CNR IMCB, Naples, Italy; [Del Nobile, Matteo Alessandro; Mentana, Annalisa; Grimaldi, Maria Francesca] Univ Foggia, Dipartimento Sci Alimenti, Foggia, Italy; [Dall'Asta, Chiara; Faccini, Andrea; Galaverna, Gianni; Dossena, Arnaldo] Univ Parma, Dipartimento Chim Organ & Ind, I-43100 Parma, Italy	Mignani, AG (reprint author), CNR IFAC, Sesto Fiorentino, FI, Italy.	a.g.mignani@ifac.cnr.it	Ottevaere, Heidi/A-9294-2010; Mignani, Anna Grazia/B-3281-2010; Dall'Asta, Chiara/C-3173-2008; Paolesse, Roberto/B-8966-2013; Buonocore, Giovanna/G-4860-2013; Mencaglia, Andrea/C-1692-2015; 	Dall'Asta, Chiara/0000-0003-0716-8394; Paolesse, Roberto/0000-0002-2380-1404; Galaverna, Gianni/0000-0001-9042-2378	EU.SMT Programme [SMT4-CT972157]; MIUR-FIRB [RBNE01KZZM]; EU FP6 Network of Excellence [003887]	This work was supported by the EU.SM&T Programme, under Contract SMT4-CT972157 "OPTIMO"; Regione Toscana, ITT "CARABIOTEC"; MIUR-FIRB, under Contract RBNE01KZZM "BIOSENS"; EU FP6 Network of Excellence Contract 003887 "NEMO"; CNR Short Term Mobility Program; DWTC-IAP, FWO Vlaanderen and the OZR of the Vrije Universiteit Brussel; and Regione Sicilia, Assessorato Agricoltura e Foreste, Servizio IX degrees, Palermo. The work of H. Ottevaere was supported by the Flemish Fund for Scientific Research (FWO) under the "Postdoctoraal Onderzoeker" Fellowship. The associate editor coordinating the review of this paper and approving it for publication was Prof. Brian Culshaw.	ADAMS MJ, 1995, CHEMOMETRIC ANAL SPE; Buratti S, 2005, ITAL J FOOD SCI, V17, P203; CHIAVARO E, 2001, J CHROMATOGR A, V937, P257; Christy A. A., 2007, NEAR INFRARED SPECTR; Connolly C., 2005, Sensor Review, V25, DOI 10.1108/02602280510606453; COVE IA, 1985, APPL SPECTROSC, V39, P257; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucci C, 2007, SENSOR ACTUAT B-CHEM, V126, P467, DOI 10.1016/j.snb.2007.03.036; Di Natale C, 2007, SENSOR ACTUAT B-CHEM, V121, P238, DOI 10.1016/j.snb.2006.09.038; Dolphin D., 1978, PORPHYRINS, V3; Franco CM, 1998, J CHROMATOGR A, V815, P21, DOI 10.1016/S0021-9673(98)00509-3; Harwood JL, 1999, HDB OLIVE OIL; HESTER RE, 2001, FOOD SAFETY FOOD QUA; JACKSONS M, 2001, GREAT BEERS BELGIUM; JAE M, 2002, OILS FATS AUTHENTICA; KELLER JJ, 2000, COMPLIANCE MANUAL FO; Lees M., 2003, FOOD AUTHENTICITY TR; Mencaglia AA, 2003, P SOC PHOTO-OPT INS, V4763, P248, DOI 10.1117/12.508795; MIGNANI AG, 2006, P SPIE, V6189; Mignani AG, 2005, SENSOR ACTUAT B-CHEM, V111, P363, DOI 10.1016/j.snb.2005.03.023; MIGNANI AG, 2007, P SPIE, V6585; Mignani AG, 2005, P SOC PHOTO-OPT INS, V5855, P38, DOI 10.1117/12.623388; PAOLESSE R, 2003, 16 OPT FIB SENS C, P742; Rakow NA, 2000, NATURE, V406, P710, DOI 10.1038/35021028; SERVILI M, 1995, J SCI FOOD AGR, V67, P61, DOI 10.1002/jsfa.2740670111; Siesler HW, 2002, NEAR INFRARED SPECTR; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS QUA; VANEGMOND HP, 1998, INTRO MYCOTOXINS DAI; WEBB T, 2005, GOOD BEER GUIDE BELG; 1993, AGENCY FOR RES CANC, V56	30	22	24	4	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1530-437X			IEEE SENS J	IEEE Sens. J.	JUL-AUG	2008	8	7-8					1342	1354		10.1109/JSEN.2008.926971		13	Engineering, Electrical & Electronic; Instruments & Instrumentation; Physics, Applied	Engineering; Instruments & Instrumentation; Physics	338RP	WOS:000258526600044		
J	Samaniego, L; Bardossy, A; Schulz, K				Samaniego, Luis; Bardossy, Andras; Schulz, Karsten			Supervised classification of remotely sensed imagery using a modified k-NN technique	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						dimensionality reduction; ensemble prediction; k-nearest neighbors (NNs); land cover classification; simulated annealing (SA)	NEAREST-NEIGHBOR CLASSIFICATION; SENSING IMAGES; ACCURACY ASSESSMENT; FUZZY; RULE; SIZE	Nearest neighbor (NN) techniques are commonly used in remote sensing, pattern recognition, and statistics to classify objects into a predefined number of categories based on a given set of predictors. These techniques are particularly useful in those cases exhibiting a highly nonlinear relationship between variables. In most studies, the distance measure is adopted a priori. In contrast, we propose a general procedure to find Euclidean metrics in a low-dimensional space (i.e., one in which the number of dimensions is less than the number of predictor variables) whose main characteristic is to minimize the variance of a given class label of all those pairs of points whose distance is less than a predefined value. k-NN is used in each embedded space to determine the possibility that a query belongs to a given class label. The class estimation is carried out by an ensemble of predictions. To illustrate the application of this technique, a typical land cover classification using a Landsat-5 Thematic Mapper scene is presented. Experimental results indicate substantial improvement with regard to the classification accuracy as compared with approaches such as maximum likelihood, linear discriminant analysis, standard k-NN, and adaptive quasi-conformal kernel k-NN.	[Samaniego, Luis; Schulz, Karsten] UFZ Helmholtz Ctr Environm Res, D-04318 Leipzig, Germany; [Bardossy, Andras] Univ Stuttgart, Inst Hydraul Engn, D-70569 Stuttgart, Germany	Samaniego, L (reprint author), UFZ Helmholtz Ctr Environm Res, D-04318 Leipzig, Germany.		Bardossy, Andras/A-1160-2009; Samaniego, Luis/G-8651-2011	Samaniego, Luis/0000-0002-8449-4428			Aarts E, 1989, SIMULATED ANNEALING; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292; Bardossy A, 2002, IEEE T GEOSCI REMOTE, V40, P362, DOI 10.1109/36.992798; BARDOSSY A, 2005, WATER RESOUR RES, V41, DOI UNSP W08 404-1-W08 404-13; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P429, DOI 10.1109/36.823938; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P403; CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deer PJ, 2003, FUZZY SET SYST, V137, P191, DOI 10.1016/S0165-0114(02)00220-8; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Foody GM, 2005, INT J REMOTE SENS, V26, P1217, DOI 10.1080/01431160512331326521; Foody GM, 1996, INT J REMOTE SENS, V17, P1317; Foody GM, 2006, REMOTE SENS ENVIRON, V104, P1, DOI 10.1016/j.rse.2006.03.004; Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., 1990, INTRO STAT PATTERN R; Goodin DG, 2004, IEEE T GEOSCI REMOTE, V42, P154, DOI 10.1109/TGRS.2003.815674; GOPAL S, 1994, PHOTOGRAMM ENG REM S, V60, P181; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; *IMSL, 1997, FORTR SUBR MATH APPL; Isaaks E.H., 1989, INTRO APPL GEOSTATIS; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Mardia K. V., 1979, MULTIVARIATE ANAL; Massa A, 2005, IEEE T GEOSCI REMOTE, V43, P2084, DOI 10.1109/TGRS.2005.853186; MATHER PM, 2004, PROCESSING REMOTELY; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Omohundro S. M., 1987, Complex Systems, V1; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Poggi G, 2005, IEEE T GEOSCI REMOTE, V43, P1901, DOI 10.1109/TGRS.2005.852163; Richards J. A., 2006, REMOTE SENSING DIGIT; Roweis S., 2000, SCIENCE, V290, P5500; Scholkopf B., 2000, NEURAL COMPUT, V12; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; Shang WQ, 2006, LECT NOTES COMPUT SC, V3993, P216; SINGLETO.RC, 1969, COMMUN ACM, V12, P185, DOI 10.1145/362875.362901; Song C, 2001, REMOTE SENS ENVIRON, V75, P230, DOI 10.1016/S0034-4257(00)00169-3; Stathakis D, 2006, IEEE T GEOSCI REMOTE, V44, P2305, DOI 10.1109/TGRS.2006.872903; Tenenbaum J. B., 2000, SCIENCE, V290, P2; VAN LAARHOVEN P. J., 1992, SIMULATED ANNEALING; van de Vlag DE, 2007, IEEE T GEOSCI REMOTE, V45, P237, DOI 10.1109/TGRS.2006.885403; VANGENDEREN JL, 1978, REMOTE SENS ENVIRON, V7, P3, DOI 10.1016/0034-4257(78)90003-2; Van Niel TG, 2005, REMOTE SENS ENVIRON, V98, P468, DOI 10.1016/j.rse.2005.08.011; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874; ZHUANG X, 1994, INT J REMOTE SENS, V15, P3271	53	31	31	0	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892			IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing	JUL	2008	46	7					2112	2125		10.1109/TGRS.2008.916629		14	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	321DP	WOS:000257285200023		
J	Nanni, L; Lumini, A				Nanni, Loris; Lumini, Alessandra			Cluster-based nearest-neighbour classifier and its application on the lightning classification	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						nearest-neighbour classifier; clustering; adaptive distance	FEATURE LINE METHOD; PATTERN-CLASSIFICATION; FACE RECOGNITION; RETRIEVAL; RULE	The problem addressed in this paper concerns the prototype generation for a cluster-based nearest-neighbour classifier. It considers, to classify a test pattern, the lines that link the patterns of the training set and a set of prototypes. An efficient method based on clustering is here used for finding subgroups of similar patterns with centroid being used as prototype. A learning method is used for iteratively adjusting both position and local-metric of the prototypes. Finally, we show that a simple adaptive distance measure improves the performance of our nearest-neighbour-based classifier. The performance improvement with respect to other nearest-neighbour-based classifiers is validated by testing our method on a lightning classification task using data acquired from the Fast On-orbit Recording of Transient Events (FORTE) satellite, moreover the performance improvement is validated through experiments with several benchmark datasets. The performance of the proposed methods are also validated using the Wilcoxon Signed-Rank test.	[Nanni, Loris; Lumini, Alessandra] Univ Bologna, DEIS, IEIIT CNR, I-40136 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, IEIIT CNR, Viale Risorgimento 2, I-40136 Bologna, Italy.	loris.nanni@unibo.it; alessandra.lumini@unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354			Bezdek J. C., 1981, PATTERN RECOGNITION; BRILES S, 1993, P INT WORKSH ART INT; Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chen JH, 2004, PATTERN RECOGN, V37, P1913, DOI 10.1016/j.patcog.2003.12.003; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; EADS D, 2002, P 5 C APPL SCI NEUR, P74; Franco A, 2004, INT C PATT RECOG, P424, DOI 10.1109/ICPR.2004.1333793; FRIEDMAN J, 1994, 113 STANF U; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Ghosh AK, 2006, IEEE T SYST MAN CY B, V36, P1139, DOI 10.1109/TSMCB.2006.873186; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hua SJ, 2001, BIOINFORMATICS, V17, P721, DOI 10.1093/bioinformatics/17.8.721; KELLER JM, 1995, IEEE T SYST MAN CYB, V25, P804; KUNCHEVA LI, 2004, COMBINING PATTERN CL; Li B, 2008, IEEE T SYST MAN CY B, V38, P141, DOI 10.1109/TSMCB.2007.908363; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; MOORE K, 1997, P SPIE, V2492; PARADES R, 2006, PATTERN RECOGN, V39, P180; PEDREIRA C, 2006, IEEE T PATTERN ANAL, V18, P157; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	32	1	2	0	3	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000			J COMPUT SCI TECH-CH	J. Comput. Sci. Technol.	JUL	2008	23	4					573	581		10.1007/s11390-008-9153-8		9	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Computer Science	328PI	WOS:000257809900006		
J	Li, XH; Shu, L				Li, Xuehua; Shu, Lan			Kernel based nonlinear dimensionality reduction and classification for genomic microarray	SENSORS			English	Article						manifold learning; dimensionality reduction; locally linear embedding; kernel methods; support vector machine	SUPPORT VECTOR MACHINES; GENE-EXPRESSION DATA; DNA MICROARRAYS; PREDICTION; DISCOVERY	Genomic microarrays are powerful research tools in bioinformatics and modern medicinal research because they enable massively-parallel assays and simultaneous monitoring of thousands of gene expression of biological samples. However, a simple microarray experiment often leads to very high-dimensional data and a huge amount of information, the vast amount of data challenges researchers into extracting the important features and reducing the high dimensionality. In this paper, a nonlinear dimensionality reduction kernel method based locally linear embedding(LLE) is proposed, and fuzzy K-nearest neighbors algorithm which denoises datasets will be introduced as a replacement to the classical LLE's KNN algorithm. In addition, kernel method based support vector machine (SVM) will be used to classify genomic microarray data sets in this paper. We demonstrate the application of the techniques to two published DNA microarray data sets. The experimental results confirm the superiority and high success rates of the presented method.	[Li, Xuehua; Shu, Lan] Univ Elect Sci & Technol China, Sch Appl Math, Chengdu 610054, Peoples R China	Li, XH (reprint author), Univ Elect Sci & Technol China, Sch Appl Math, Chengdu 610054, Peoples R China.	leesoftcom@gmail.com					Alizadeh, 2000, NATURE, V403, P503; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2000, INTRO SUPPORT VECTOR, P96; Du PF, 2007, BIOCHEM BIOPH RES CO, V358, P336, DOI 10.1016/j.bbrc.2007.04.130; ELGAMMAL AM, 2004, IEEE COMP SOC C COMP, P478; Ellis M, 2002, CLIN CANCER RES, V8, P1155; HAYKIN S, 1999, NEURAL NETWORKS COMP, P330; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kouropteva O., 2002, P 1 INT C FUZZ SYST, P359; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; MARINA M, 2001, ADV NIPS, V13, P873; Mekuz N, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P290, DOI 10.1109/CRV.2005.42; NIKHIL RP, 2007, BMC BIOINFORMATICS, V8, P1; Orr MS, 2002, LEUKEMIA, V16, P473, DOI 10.1038/sj/leu/2402413; Qian ZL, 2006, BIOCHEM BIOPH RES CO, V348, P1034, DOI 10.1016/j.bbrc.2006.07.149; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAUL L, 2002, CIS0218 MS U PENNS, V37, P134; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shalon D, 1996, GENOME RES, V6, P639, DOI 10.1101/gr.6.7.639; SHAWETALYOR J, 2004, KERNEL METHODS PATTE; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; VAPNIK VN, 1998, STAT LEARNING THEORY, P157; Wang XC, 2003, PATTERN RECOGN, V36, P2429, DOI 10.1016/S0031-3203(03)00044-X; Yeo G., 2001, 2001018 AI; Young RA, 2000, CELL, V102, P9, DOI 10.1016/S0092-8674(00)00005-2; Zhang CS, 2004, PATTERN RECOGN, V37, P325, DOI 10.1016/j.patcog.2003.07.005	33	1	1	4	8	MOLECULAR DIVERSITY PRESERVATION INT	BASEL	MATTHAEUSSTRASSE 11, CH-4057 BASEL, SWITZERLAND	1424-8220			SENSORS-BASEL	Sensors	JUL	2008	8	7					4186	4200		10.3390/s8074186		15	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	333VI	WOS:000258180500010		
J	Labrador, B				Labrador, Boris			Strong pointwise consistency of the k(T)-occupation time density estimator	STATISTICS & PROBABILITY LETTERS			English	Article							NONPARAMETRIC ESTIMATE; UNIFORM CONSISTENCY; CONVERGENCE; RATES	In this paper, we study the k(T)-occupation time density estimator as an extension of the k-nearest neighbor estimator in continuous time. The rates of strong pointwise convergence for a-mixing and bounded processes in both optimal (when i.i.d. rates of density estimation are reached) and superoptimal cases (when parametric rates are reached) are established. (c) 2007 Elsevier B.V. All fights reserved.	Univ Paris 06, LSTA, F-75013 Paris, France	Labrador, B (reprint author), Univ Paris 06, LSTA, 175 Rue Chevaleret,Boite 158, F-75013 Paris, France.	labrador@ccr.jussieu.fr					Blanke D, 1997, STAT PROBABIL LETT, V33, P185, DOI 10.1016/S0167-7152(96)00126-5; BLANKE D, 2004, MATH METHODS STAT, V13, P123; BOENTE G, 1991, SANKHYA SER A, V53, P194; BOENTE G, 1988, J MULTIVARIATE ANAL, V25, P90, DOI 10.1016/0047-259X(88)90154-6; BOSQ D, 1987, COLLECTION EC STAT A; Bosq D., 1998, LECT NOTES STAT, V110; Bosq D, 1997, ANN STAT, V25, P982, DOI 10.1214/aos/1069362734; CASTELLANA JV, 1986, STOCH PROC APPL, V21, P179, DOI 10.1016/0304-4149(86)90095-5; CHEN XR, 1982, SCI SIN A-MATH P A T, V25, P455; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEHEUVELS P, 1992, ANN PROBAB, V20, P1248, DOI 10.1214/aop/1176989691; Devroye L., 1982, HDB STAT, V2, P193, DOI 10.1016/S0169-7161(82)02011-2; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; Doukhan P., 1994, LECT NOTES STAT, V85; Fix E., 1951, 4 USAF SCH AV MED; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; GEMAN D, 1980, ANN PROBAB, V8, P1, DOI 10.1214/aop/1176994824; Kutoyants Y.A., 2004, SPRINGER SERIES STAT; Labrador B, 2006, CR MATH, V343, P665, DOI 10.1016/j.crma.2006.10.015; LEVALLOIS S, 1998, THESIS U MONTPELLIER; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACK YP, 1983, J STAT PLAN INFER, V8, P185, DOI 10.1016/0378-3758(83)90037-X; Moore D. S., 1977, STAT DECISION THEORY, P269; MOORE DS, 1969, ANN MATH STAT, V40, P1499, DOI 10.1214/aoms/1177697524; NGUYEN HT, 1989, PUBL I STAT U PARIS, V34, P69; Pollard D., 1984, SPRINGER SERIES STAT; Rio E., 2000, MATH APPL, V31; TRAN LT, 1993, J MULTIVARIATE ANAL, V44, P23, DOI 10.1006/jmva.1993.1002; WAGNER TJ, 1973, IEEE T SYST MAN CYB, VSMC3, P289	29	2	2	2	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-7152			STAT PROBABIL LETT	Stat. Probab. Lett.	JUL 15	2008	78	9					1128	1137		10.1016/j.spl.2007.11.010		10	Statistics & Probability	Mathematics	314YO	WOS:000256845300011		
J	Liu, HC; Chen, CY; Liu, YT; Chu, CB; Liang, DC; Shih, LY; Lin, CJ				Liu, Hsi-Che; Chen, Chien-Yu; Liu, Yu-Ting; Chu, Cheng-Bang; Liang, Der-Cherng; Shih, Lee-Yung; Lin, Chih-Jen			Cross-generation and cross-laboratory predictions of Affymetrix microarrays by rank-based methods	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						affymetrix microarrays; cross-generation/laboratory prediction; rank-based normalization	GENE-EXPRESSION PROFILES; ACUTE LYMPHOBLASTIC-LEUKEMIA; BREAST-CANCER; MARKER GENES; CLASSIFICATION; OLIGONUCLEOTIDE; PLATFORMS; REPRODUCIBILITY; NORMALIZATION; INFORMATION	Past experiments of the popular Affymetrix (Affy) microarrays have accumulated a huge amount of public data sets. To apply them for more wide studies, the comparability across generations and experimental environments is an important research topic. This paper particularly investigates the issue of cross-generation/laboratory predictions. That is, whether models built upon data of one generation (laboratory) can differentiate data of another. We consider eight public sets of three cancers. They are from different laboratories and are across various generations of Affy human microarrays. Each cancer has certain subtypes, and we investigate if a model trained from one set correctly differentiates another. We propose a simple rank-based approach to make data from different sources more comparable. Results show that it leads to higher prediction accuracy than using expression values. We further investigate normalization issues in preparing training/testing data. In addition, we discuss some pitfalls in evaluating cross-generation/laboratory predictions. To use data from various sources one must be cautious on some important but easily neglected steps. (C) 2007 Elsevier Inc. All rights reserved.	[Chen, Chien-Yu] Natl Taiwan Univ, Dept Bioind Mechatron Engn, Taipei 106, Taiwan; [Liu, Hsi-Che; Liang, Der-Cherng] Mackay Mem Hosp, Dept Pediat, Taipei, Taiwan; [Liu, Yu-Ting; Chu, Cheng-Bang] Yuan Univ, Grad Sch Biotechnol & Bioinformat, Chungli, Taiwan; [Shih, Lee-Yung] Chang Gung Univ, Div Hematol Oncol, Tao Yuan, Taiwan; [Lin, Chih-Jen] Natl Taiwan Univ, Dept Comp Sci, Taipei 10764, Taiwan; [Liu, Hsi-Che] Mackay Med Nursing & Management Coll, Taipei, Taiwan; [Liu, Hsi-Che] Taipei Med Univ, Sch Med, Taipei, Taiwan	Chen, CY (reprint author), Natl Taiwan Univ, Dept Bioind Mechatron Engn, 1 Roosevelt Rd,Sec 4, Taipei 106, Taiwan.	hsiche@msl.mmh.org.tw; cychen@mars.csie.ntu.edu.tw; s938611@mail.yzu.edu.tw; s938613@mail.yzu.edu.tw; dcliang@ms2.mmh.org.tw; sly70l2@adm.cgmh.org.tw; cjlin@csie.ntu.edu.tw					*AFF, 2003, US GUID PROD COMP SP; Bammler T, 2005, NAT METHODS, V2, P351; BHATTACHARYA S, 2005, NUCLEIC ACIDS RES, V33, pEL57; Bloom G, 2004, AM J PATHOL, V164, P9, DOI 10.1016/S0002-9440(10)63090-8; Bolstad BM, 2003, BIOINFORMATICS, V19, P185, DOI 10.1093/bioinformatics/19.2.185; Brazma A, 2001, NAT GENET, V29, P365, DOI 10.1038/ng1201-365; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ELO LL, 2005, NUCLEIC ACIDS RES, V33, pEL93; Geman D, 2004, STAT APPL GENET MOL, V3, P19; Gutierrez N. C., 2005, Leukemia (Basingstoke), V19, P402, DOI 10.1038/sj.leu.2403625; Huang E, 2003, LANCET, V361, P1590, DOI 10.1016/S0140-6736(03)13308-9; Hwang KB, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-159; Irizarry RA, 2005, NAT METHODS, V2, P345, DOI 10.1038/nmeth756; Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81; Kong SW, 2005, BIOINFORMATICS, V21, P2116, DOI 10.1093/bioinformatics/bti288; Kuo WP, 2002, BIOINFORMATICS, V18, P405, DOI 10.1093/bioinformatics/18.3.405; Larkin JE, 2005, NAT METHODS, V2, P337, DOI 10.1038/nmeth757; Maglott D, 2005, NUCLEIC ACIDS RES, V33, pD54, DOI 10.1093/nar/gki031; Mah N, 2004, PHYSIOL GENOMICS, V16, P361, DOI 10.1152/physiolgenomics.00080.2003; Nimgaonkar A, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-27; Pontius JU, 2003, NCBI HDB; Qiu X, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-120; R Development Core Team, 2005, R LANG ENV STAT COMP; Rhodes DR, 2004, P NATL ACAD SCI USA, V101, P9309, DOI 10.1073/pnas.0401994101; Ross ME, 2003, BLOOD, V102, P2951, DOI 10.1182/blood-2003-01-0338; Ross ME, 2004, BLOOD, V104, P3679, DOI 10.1182/blood-2004-03-1154; Szabo A, 2002, MATH BIOSCI, V176, P71, DOI 10.1016/S0025-5564(01)00103-1; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; TODLING J, 2003, ASSESSMENT 5 MICROAR; Tothill RW, 2005, CANCER RES, V65, P4031, DOI 10.1158/0008-5472.CAN-04-3617; TSODIKOV A, 2002, BIOINFORMATICS, V18, P260; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; Valk PJM, 2004, NEW ENGL J MED, V350, P1617, DOI 10.1056/NEJMoa040465; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Warnat P, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-265; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Xu L, 2005, BIOINFORMATICS, V21, P3905, DOI 10.1093/bioinformatics/bti647; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	38	12	12	0	2	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464			J BIOMED INFORM	J. Biomed. Inform.	AUG	2008	41	4					570	579		10.1016/j.jbi.2007.11.005		10	Computer Science, Interdisciplinary Applications; Medical Informatics	Computer Science; Medical Informatics	330FE	WOS:000257924400006	18234562	
J	Rizzi, A; Fioni, A				Rizzi, Andrea; Fioni, Alessandro			Virtual screening using PLS discriminant analysis and ROC curve approach: An application study on PDE4 inhibitors	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							DOCKING; CLASSIFICATION; PREDICTION; DRUGS; SIMILARITY; DATABASE; DESIGN	Virtual screening (VS) represents an important tool for the drug discovery process, in particular for the hit generation phase. Classifiers are often inserted as filters at the beginning of a VS path, and in the present paper the performances of several PLS-DA classifiers (QikProp, Dragon, EVA descriptors) are evaluated in the effort to distinguish PDE4 inhibitors from other druglike molecules. As benchmark also docking scores and the fitness to pharmacophore hypotheses were used to perform the same task, checking in this way if docking or 3D search can be anticipated in the VS process. The visual analysis of the Receiver Operating Characteristic (ROC) curve was useful to have an overall picture of the classification and to select the right threshold that marks the boundary between active and inactive classes. The best classification was obtained by a model based on the Dragon descriptors that are calculated from the molecular 2D structure. Its performance was good for the training set in terms of recall, enrichment factor, and area under the ROC curve and was confirmed in the prediction of the test set.	[Rizzi, Andrea; Fioni, Alessandro] Chiesi Farmaceut, Chem Synth Dept, I-43100 Parma, Italy	Rizzi, A (reprint author), Chiesi Farmaceut, Chem Synth Dept, Via San Leonardo 96, I-43100 Parma, Italy.	a.rizzi@chiesigroup.com					Adenot M, 2004, J CHEM INF COMP SCI, V44, P239, DOI 10.1021/ci034205d; [Anonymous], 2005, GLID VERS 3 5; Baurin N, 2004, J CHEM INF COMP SCI, V44, P643, DOI 10.1021/ci034260m; Burnouf C, 2002, CURR PHARM DESIGN, V8, P1255, DOI 10.2174/1381612023394665; Card GL, 2004, STRUCTURE, V12, P2233, DOI 10.1016/j.str.2004.10.004; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dal P., 2000, EUR J MED CHEM, V35, P463; Evers A, 2005, J MED CHEM, V48, P5448, DOI 10.1021/jm050090o; Gasteiger J., 1999, NEURAL NETWORKS CHEM; Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+; Jacobsson M, 2003, J MED CHEM, V46, P5781, DOI 10.1021/jm030896t; Jorgensen WL, 2002, ADV DRUG DELIVER REV, V54, P355, DOI 10.1016/S0169-409X(02)00008-X; Leach AR, 2006, J MED CHEM, V49, P5851, DOI 10.1021/jm060999m; Li QL, 2007, J CHEM INF MODEL, V47, P1776, DOI 10.1021/ci700107y; Mason JS, 1999, J MED CHEM, V42, P3251, DOI 10.1021/jm9806998; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; *MDL INF SYST INC, 2005, MDL DRUG DAT REP MDD; Pearlman DA, 2001, J MED CHEM, V44, P502, DOI 10.1021/jm000375v; Pirard B, 2000, J CHEM INF COMP SCI, V40, P1431, DOI 10.1021/ci000386x; Plewczynski D, 2006, J CHEM INF MODEL, V46, P1098, DOI 10.1021/ci050519k; Rella M, 2006, J CHEM INF MODEL, V46, P708, DOI 10.1021/ci0503614; Schneider G, 2002, DRUG DISCOV TODAY, V7, P64, DOI 10.1016/S1359-6446(02)00004-1; *SCHR LLC, 2005, QIKPROP VERS 2 1; *SCHR LLC, 2005, PHASS VERS 1 0; Sirois S, 2004, J CHEM INF COMP SCI, V44, P1111, DOI 10.1021/ci034270n; Ståhle L, 1988, Prog Med Chem, V25, P291, DOI 10.1016/S0079-6468(08)70281-9; Sun HM, 2004, J CHEM INF COMP SCI, V44, P748, DOI 10.1021/ci030304f; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; *TAL, 2005, DRAGON PLUS VERS 5 4; Triballeau N, 2005, J MED CHEM, V48, P2534, DOI 10.1021/jm049092j; Turner DB, 1997, J COMPUT AID MOL DES, V11, P409, DOI 10.1023/A:1007988708826; *UM AB, 2005, SIMCA P VERS 10 0; Vandeginste B.G.M., 1997, HDB CHEMOMETRICS QUA; Vapnik V. N., 1995, NATURE STAT LEARNING; Vigers GPA, 2004, J MED CHEM, V47, P80, DOI 10.1021/jm030161o; Walters WP, 1998, DRUG DISCOV TODAY, V3, P160, DOI 10.1016/S1359-6446(97)01163-X; Wang RX, 2003, J MED CHEM, V46, P2287, DOI 10.1021/jm0203783; *WAV INC, 2003, SPART 02 LIN UN; Wold S., 1993, 3D QSAR DRUG DESIGN, P523; Xue L, 2004, J CHEM INF COMP SCI, V44, P1275, DOI 10.1021/ci040120g; 2005, SCHRODINGER QIKPROP	41	12	14	1	4	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596			J CHEM INF MODEL	J. Chem Inf. Model.	AUG	2008	48	8					1686	1692		10.1021/ci800072r		7	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	341EQ	WOS:000258697400014	18671384	
J	Cho, KH; Lee, J				Cho, Kwang-Hwi; Lee, Julian			Protein structure prediction using a hybrid energy function and an exact enumeration	JOURNAL OF THE KOREAN PHYSICAL SOCIETY			English	Article						protein folding; protein structure prediction; fragment assembly method; exact enumeration; hybrid energy function	NEAREST-NEIGHBOR METHOD; DOUBLE OPTIMIZATION; SEQUENCES	We develop a protein structure prediction method that utilizes fragment assembly and a hybrid energy function. In a fragment assembly method, the local structure of the backbone is obtained from a structural database by using similarity of sequence features, in contrast to a pure physics-based method in which all dihedral angles are allowed to vary continuously. Since the conformational space for the backbone is finite, we generate all possible conformations and vary only the side-chain dihedral angles for each of them. The conformations are scored using a hybrid energy function, where all the backbone atoms are described explicitly, but the side chain is modeled as a few interaction centers. We perform a test prediction on four proteins, 112y, 1e01, 1bdd and 1bk2, to demonstrate the feasibility of protein structure prediction based on exact enumeration.	Soongsil Univ, Dept Bioinformat & Life Sci, Seoul 156743, South Korea; Soongsil Univ, Bioinformat & Mol Design Res Ctr, Seoul 156743, South Korea	Lee, J (reprint author), Soongsil Univ, Dept Bioinformat & Life Sci, Seoul 156743, South Korea.	jul@ssu.ac.kr			Basic Research Program of the Korea Science & Engineering Foundation [R01-2003-000-10199-0]; Soongsil University Research Fund	This work was supported by grant R01-2003-000-10199-0 from the Basic Research Program of the Korea Science & Engineering Foundation and by the Soongsil University Research Fund.	Aloy P, 2003, PROTEINS, V53, P436, DOI 10.1002/prot.10546; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; Brenner SE, 2000, NUCLEIC ACIDS RES, V28, P254, DOI 10.1093/nar/28.1.254; Chikenji G, 2003, J CHEM PHYS, V119, P6895, DOI 10.1063/1.1597474; CHO KH, SIMPLIFIED POT UNPUB; Cho KH, 2008, J KOREAN PHYS SOC, V52, P143; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; JONES DT, 2001, PROTEINS S5, V45, P127, DOI 10.1002/prot.1171; Joo K, 2004, J KOREAN PHYS SOC, V45, P1441; Joo K, 2004, J KOREAN PHYS SOC, V44, P599; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kim SY, 2006, LECT NOTES COMPUT SC, V4115, P562; Kim SY, 2006, J CHEM PHYS, V125, DOI 10.1063/1.2364500; Kim TK, 2008, J KOREAN PHYS SOC, V52, P137; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Koradi R, 1996, J MOL GRAPHICS, V14, P51, DOI 10.1016/0263-7855(96)00009-4; Lee J, 2005, J KOREAN PHYS SOC, V46, P707; Lee J, 2008, PROTEINS, V70, P1074, DOI 10.1002/prot.21844; LEST AM, 2001, PROTEINS, V45, P98; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MOMANY FA, 1975, J PHYS CHEM-US, V79, P2361, DOI 10.1021/j100589a006; Shi XL, 2007, J KOREAN PHYS SOC, V50, P118; Sim J, 2005, BIOINFORMATICS, V21, P2844, DOI 10.1093/bioinformatics/bti423; Simons KT, 1997, J MOL BIOL, V268, P209, DOI 10.1006/jmbi.1997.0959; Vincent JJ, 2005, PROTEINS, V61, P67, DOI 10.1002/prot.20722; Xiang ZX, 2002, P NATL ACAD SCI USA, V99, P7432, DOI 10.1073/pnas.102179699	27	2	2	0	9	KOREAN PHYSICAL SOC	SEOUL	635-4, YUKSAM-DONG, KANGNAM-KU, SEOUL 135-703, SOUTH KOREA	0374-4884			J KOREAN PHYS SOC	J. Korean Phys. Soc.	AUG	2008	53	2					873	879				7	Physics, Multidisciplinary	Physics	338CA	WOS:000258481300072		
J	Kietzmann, TC; Lange, S; Riedmiller, M				Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin			Incremental GRLVQ: Learning relevant features for 3D object recognition	NEUROCOMPUTING			English	Article						object recognition; relevance learning; feature selection; incremental learning vector quantization; adaptive metric	CLASSIFICATION; INTERPOLATION; RETRIEVAL; SELECTION; NETWORK; FACES	We present a new variant of generalized relevance learning vector quantization (GRLVQ) in a computer vision scenario. A version with incrementally added prototypes is used for the non-trivial case of high-dimensional object recognition. Training is based upon a generic set of standard visual features, the learned input weights are used for iterative feature pruning. Thus, prototypes and input space are altered simultaneously, leading to very sparse and task-specific representations. The effectiveness of the approach and the combination of the incremental variant together with pruning was tested on the COIL100 database, It exhibits excellent performance with regard to codebook size, feature selection and recognition accuracy. (C) 2007 Elsevier B.V. All rights reserved.	[Kietzmann, Tim C.; Lange, Sascha; Riedmiller, Martin] Univ Osnabruck, Inst Cognit Sci, Inst Comp Sci, D-49069 Osnabruck, Germany	Kietzmann, TC (reprint author), Univ Osnabruck, Inst Cognit Sci, Inst Comp Sci, D-49069 Osnabruck, Germany.	tkietzma@uos.de; salange@uos.de; martin.riedmiller@uos.de					ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOJER T, 2003, EUR S ART NEUR NETW, P433; BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FRITZKE B, 1994, NEURAL NETWORKS, V7, P1441, DOI 10.1016/0893-6080(94)90091-4; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; Hammer B, 2005, NEURAL PROCESS LETT, V21, P21, DOI 10.1007/s11063-004-3255-2; HAMMER B, 2005, BIOINFORMATIC USING, P25; Hammer B, 2001, ADVANCES IN SELF-ORGANISING MAPS, P173; HAMMER B, 2002, INT C ART NEUR NETW; Heidemann G., 2000, Proceedings 15th International Conference on Pattern Recognition. ICPR-2000, DOI 10.1109/ICPR.2000.905265; HU M, 1962, IRE T INFORM THEOR, V8, P179; John G., 1994, P 11 INT C MACH LEAR, P121; Jolliffe I., 1986, PRINCIPLE COMPONENT; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Kira K., 1992, P 10 NAT C ART INT, P129; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KIRSTEIN S, 2005, 27 PATT REC S DAGM, P301; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D., 1996, INT C MACH LEARN; Kononenko I., 1994, EUR C MACH LEARN, P171; Korn F., 1996, FAST NEAREST NEIGHBO; KRZANOWSKI WJ, 1987, APPL STAT-J ROY ST C, V36, P22, DOI 10.2307/2347842; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.415; McCabe G. P., 1984, TECHNOMETRICS, V26, P127; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Neal R.M., 1996, BAYESIAN LEARNING NE; Nene S. A., 1996, CUCS00696; OBDRZLEK S, 2002, BMVC, P113; Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770; PERRETT DI, 1987, TRENDS NEUROSCI, V10, P358, DOI 10.1016/0166-2236(87)90071-3; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; QI YA, 2004, ACM INT C P SERIES; Roobaert D., 1999, NEURAL NETWORKS SIGN, VIX, P77; Sato A.S., 1995, ADV NEURAL INFORMATI, V7, P423; SCHNEIDER G, 2004, 3 WORKSH SELFORGANIZ, P104; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; SIMS K, 1993, P 8 SCIA THROMS NORW; Strickert M, 2001, LECT NOTES COMPUT SC, V2130, P677; TARR MJ, 1995, J EXP PSYCHOL HUMAN, V21, P1494, DOI 10.1037/0096-1523.21.6.1494; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0; WU P, 2001, P ACM MULT 01 ACM MU, P89; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	51	16	16	0	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	AUG	2008	71	13-15					2868	2879		10.1016/j.neucom.2007.08.018		12	Computer Science, Artificial Intelligence	Computer Science	347DP	WOS:000259121100047		
J	Farcomeni, A				Farcomeni, Alessio			A review of modern multiple hypothesis testing, with particular attention to the false discovery proportion	STATISTICAL METHODS IN MEDICAL RESEARCH			English	Review							QUANTITATIVE TRAIT LOCI; TRUE NULL HYPOTHESES; END-POINTS; CLINICAL-TRIALS; P-VALUES; TEST STATISTICS; PROBABILITY-INEQUALITIES; BONFERRONI PROCEDURE; MICROARRAY ANALYSIS; VARIABLE SELECTION	In the last decade a growing amount Of statistical research has been devoted to multiple testing, motivated by a variety of applications in medicine, bioinformatics, genomics, brain imaging, etc. Research in this area is focused on developing powerful procedures even when the number of tests is very large. This paper attempts to review research in modern multiple hypothesis testing with particular attention to the false discovery proportion, loosely defined as the number of false rejections divided by the number of rejections. We review the main ideas, stepwise and augmentation procedures; and resampling based testing. We also discuss the problem of dependence among the test statistics. Simulations make a comparison between the procedures and with Bayesian methods. We illustrate the procedures in applications in DNA microarray data analysis. Finally, few possibilities for further research are highlighted.	Univ Roma La Sapienza, I-00185 Rome, Italy	Farcomeni, A (reprint author), Univ Roma La Sapienza, Plazzale Aldo Moro 5, I-00185 Rome, Italy.	alessio.farcomeni@uniroma1.it					Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Abramovich F, 1996, COMPUT STAT DATA AN, V22, P351, DOI 10.1016/0167-9473(96)00003-5; AHMED SW, 1991, 1991 ASA P SURV RES, P344; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Amaratunga D., 2004, EXPLORATION ANAL DNA; Bayarri MJ, 2000, J AM STAT ASSOC, V95, P1127, DOI 10.2307/2669749; Bayarri MJ, 2004, STAT SCI, V19, P58, DOI 10.1214/088342304000000116; Benjamini Y, 2006, BIOMETRIKA, V93, P491, DOI 10.1093/biomet/93.3.491; Benjamini Y, 2001, ANN STAT, V29, P1165; Benjamini Y, 1997, SCAND J STAT, V24, P407, DOI 10.1111/1467-9469.00072; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Benjamini Y, 1999, J STAT PLAN INFER, V82, P163, DOI 10.1016/S0378-3758(99)00040-3; Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.2307/1165312; Berger JO, 1997, STAT SCI, V12, P133; Bernardo J. M., 1994, BAYESIAN THEORY; Berry DA, 1999, J STAT PLAN INFER, V82, P215, DOI 10.1016/S0378-3758(99)00044-0; Berry D.A., 1988, BAYESIAN STATISTICS, P79; BICKEL DR, 2004, STRONG CONTROL CONSE; Bolsover S., 1997, GENES CELLS; Bovenhuis H, 2000, J DAIRY SCI, V83, P173; Brown PO, 1999, NAT GENET, V21, P33, DOI 10.1038/4462; CABRAS S, 2004, CONTROL FALSE DISCOV; Chi GYH, 1998, DRUG INF J, V32, p1347S; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIACONIS P, 1985, EXPLORING DATA TABLE; Drigalenko EI, 1997, GENET EPIDEMIOL, V14, P779, DOI 10.1002/(SICI)1098-2272(1997)14:6<779::AID-GEPI36>3.0.CO;2-L; Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487; DUDOIT S, 2004, STAT APPL GENETICS M, V3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Duggan DJ, 1999, NAT GENET, V21, P10, DOI 10.1038/4434; DUNCAN DB, 1965, TECHNOMETRICS, V7, P171, DOI 10.2307/1266670; DUNNETT CW, 1992, J AM STAT ASSOC, V87, P162, DOI 10.2307/2290465; Durbin BP, 2004, BIOINFORMATICS, V20, P660, DOI 10.1093/bioinformatics/btg464; Efron B, 2001, J AM STAT ASSOC, V96, P1151, DOI 10.1198/016214501753382129; Efron B, 2002, GENET EPIDEMIOL, V23, P70, DOI 10.1002/gepi.01124; Ellis SP, 2000, PSYCHIAT RES-NEUROIM, V99, P111, DOI 10.1016/S0925-4927(00)00051-2; ESARY JD, 1967, ANN MATH STAT, V38, P1466, DOI 10.1214/aoms/1177698701; Farcomeni A., 2006, STAT METHODS APPL, V15, P43, DOI 10.1007/s10260-006-0002-z; Farcomeni A, 2007, SCAND J STAT, V34, P275, DOI 10.1111/j.1467-9469.2006.00530.x; Ferreira JA, 2006, ANN STAT, V34, P1827, DOI 10.1214/009053606000000425; Finner H, 2002, ANN STAT, V30, P220; Finner H, 1998, ANN STAT, V26, P505; Finner H, 1999, ANN STAT, V27, P274, DOI 10.1214/aos/1018031111; FOLLMANN D, 1995, STAT MED, V14, P1163, DOI 10.1002/sim.4780141103; GARRET RH, 2002, PRINCIPLES BYOCHEMIS; Ge YC, 2003, TEST, V12, P1, DOI 10.1007/BF02595811; Genovese C, 2004, ANN STAT, V32, P1035, DOI 10.1214/009053604000000283; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; Genovese CR, 2006, BIOMETRIKA, V93, P509, DOI 10.1093/biomet/93.3.509; Genovese CR, 2006, J AM STAT ASSOC, V101, P1408, DOI 10.1198/016214506000000339; George EI, 2000, J AM STAT ASSOC, V95, P1304, DOI 10.2307/2669776; George EI, 2000, BIOMETRIKA, V87, P731, DOI 10.1093/biomet/87.4.731; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Green PJ, 1994, NONPARAMETRIC REGRES; Greening L, 1997, ADOLESCENCE, V32, P51; Heyen DW, 1999, PHYSIOL GENOMICS, V1, P165; HOCHBERG Y, 1988, BIOMETRIKA, V75, P800, DOI 10.1093/biomet/75.4.800; HOLM S, 1979, SCAND J STAT, V6, P65; Hommel G, 1983, BIOMETR J, V25, P423; Ip EH, 2001, PSYCHOMETRIKA, V66, P109, DOI 10.1007/BF02295736; Jeffreys H., 1961, THEORY PROBABILITY; JOGDEO K, 1977, ANN STAT, V5, P495, DOI 10.1214/aos/1176343846; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; Kaufman L., 1990, FINDING GROUPS DATA; Khatri P, 2001, ANN THORAC SURG, V71, P110, DOI 10.1016/S0003-4975(00)02350-X; Langaas M, 2005, J ROY STAT SOC B, V67, P555, DOI 10.1111/j.1467-9868.2005.00515.x; Lauter J, 1996, BIOMETRICS, V52, P964, DOI 10.2307/2533057; LEHMACHER W, 1991, BIOMETRICS, V47, P511, DOI 10.2307/2532142; Lehmann EL, 2005, ANN STAT, V33, P1138, DOI 10.1214/009053605000000084; LEIBERMANN B, 1971, CONT PROBLEMS STAT; Logan BR, 2004, NEUROIMAGE, V22, P95, DOI 10.1016/j.neuroimage.2003.12.047; Meinert CL, 1986, CLIN TRIALS DESIGN C; Meinshausen N, 2006, ANN STAT, V34, P373, DOI 10.1214/009053605000000741; Merriam EP, 2003, NEURON, V39, P361, DOI 10.1016/S0896-6273(03)00393-3; Miller CJ, 2001, ASTRON J, V122, P3492, DOI 10.1086/324109; Miller R. G. J., 1981, SIMULTANEOUS STAT IN; Mosig MO, 2001, GENETICS, V157, P1683; Moye LA, 2000, STAT MED, V19, P767, DOI 10.1002/(SICI)1097-0258(20000330)19:6<767::AID-SIM518>3.0.CO;2-U; Moye LA, 1998, ANN EPIDEMIOL, V8, P351, DOI 10.1016/S1047-2797(98)00003-9; Muller P, 2004, J AM STAT ASSOC, V99, P990, DOI 10.1198/016214504000001646; NEUHAUS KL, 1992, J AM COLL CARDIOL, V19, P885; OBRIEN PC, 1984, BIOMETRICS, V40, P1079, DOI 10.2307/2531158; OBRIEN PC, 1995, BIOMETRICS, V51, P1580; Ottenbacher KJ, 1998, AM J EPIDEMIOL, V147, P615; Owen AB, 2005, J ROY STAT SOC B, V67, P411, DOI 10.1111/j.1467-9868.2005.00509.x; Pacifico MP, 2004, J AM STAT ASSOC, V99, P1002, DOI 10.1198/0162145000001655; Parmigiani G., 2003, ANAL GENE EXPRESSION; Pesarin F, 2001, MULTIVARIATE PERMUTA; Pocock SJ, 1997, CONTROL CLIN TRIALS, V18, P530, DOI 10.1016/S0197-2456(97)00008-1; POCOCK SJ, 1987, BIOMETRICS, V43, P487, DOI 10.2307/2531989; Pollard KS, 2004, J STAT PLAN INFER, V125, P85, DOI 10.1016/j.jspi.2003.07.019; R Development Core Team, 2004, R LANG ENV STAT COMP; Reiner A, 2003, BIOINFORMATICS, V19, P368, DOI 10.1093/bioinformatics/btf877; Robert C. P., 1999, MONTE CARLO STAT MET; Sarkar SK, 1997, J AM STAT ASSOC, V92, P1601, DOI 10.2307/2965431; Sarkar SK, 2002, ANN STAT, V30, P239, DOI 10.1214/aos/1015362192; Sarkar SK, 1998, ANN STAT, V26, P494; Sarkar SK, 2004, J STAT PLAN INFER, V125, P119, DOI 10.1016/j.jspi.2003.06.019; SARKAR SK, 2005, STEPUP PROCEDURES CO; Schaffer CM, 1998, J MARKET RES SOC, V40, P155; Schervish MJ, 1996, AM STAT, V50, P203, DOI 10.2307/2684655; Schlaeppi M, 1996, BRIT J CLIN PRACT, V50, P14; SCHWEDER T, 1982, BIOMETRIKA, V69, P493; Scott JG, 2006, J STAT PLAN INFER, V136, P2144, DOI 10.1016/j.jspi.2005.08.031; Sebastiani P, 2003, STAT SCI, V18, P33, DOI 10.1214/ss/1056397486; SEEGER P, 1968, TECHNOMETRICS, V10, P586, DOI 10.2307/1267112; Seneta E., 1997, THEORY STOCHASTIC PR, V3, P393; Seneta E, 2005, INT STAT REV, V73, P1; SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.psych.46.1.561; Shaffer JP, 1999, J STAT PLAN INFER, V82, P197, DOI 10.1016/S0378-3758(99)00042-7; Shaffer JP, 2002, PSYCHOL METHODS, V7, P356, DOI 10.1037//1082-989X.7.3.356; SIDAK Z, 1971, ANN MATH STAT, V42, P169, DOI 10.1214/aoms/1177693504; SIDAK Z, 1967, J AM STAT ASSOC, V62, P626, DOI 10.2307/2283989; SIMES RJ, 1986, BIOMETRIKA, V73, P751, DOI 10.2307/2336545; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Storey JD, 2004, J ROY STAT SOC B, V66, P187, DOI 10.1111/j.1467-9868.2004.00439.x; Storey JD, 2003, P NATL ACAD SCI USA, V100, P9440, DOI 10.1073/pnas.1530509100; Storey JD, 2001, ESTIMATING FALSE DIS; Storey JD, 2003, ANN STAT, V31, P2013, DOI 10.1214/aos/1074290335; Swanepoel JWH, 1999, ANN STAT, V27, P24, DOI 10.1214/aos/1018031099; Tamhane A., 1987, MULTIPLE COMP PROCED; Tibshirani R, 1993, INTRO BOOTSTRAP; Troendle JF, 2004, AM STAT, V58, P25, DOI 10.1198/0003130042845; Tseng GC, 2001, NUCLEIC ACIDS RES, V29, P2549, DOI 10.1093/nar/29.12.2549; Turkheimer FE, 2001, NEUROIMAGE, V13, P920, DOI 10.1006/nimg.2001.0764; Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498; van der Laan MJ, 2004, STAT APPL GENETICS M, P3; VANDERLAAN MJ, 2005, STAT APPL GENETICS M, V4; VANDERLAAN MJ, 2000, BIOSTATISTICS, V1, P1; Vedantham K, 2001, CAN J PSYCHIAT, V46, P149; WEI LJ, 1984, J AM STAT ASSOC, V79, P653, DOI 10.2307/2288413; WEI LJ, 1989, J AM STAT ASSOC, V84, P1065, DOI 10.2307/2290084; Weller JI, 1998, GENETICS, V150, P1699; Westfall Peter H., 1993, RESAMPLING BASED MUL; Westfall P.H., 2004, IMS LECT NOTES MONOG, V47, P143; Worsley KJ, 1996, HUM BRAIN MAPP, V4, P58, DOI 10.1002/(SICI)1097-0193(1996)4:1&lt;58::AID-HBM4&gt;3.0.CO;2-O; WRIGHT SP, 1992, BIOMETRICS, V48, P1005, DOI 10.2307/2532694; YANG YH, 2001, SPIE BIOS 2001; Yekutieli D, 2006, STAT NEERL, V60, P414, DOI 10.1111/j.1467-9574.2006.00343.x; Yekutieli D, 1999, J STAT PLAN INFER, V82, P171, DOI 10.1016/S0378-3758(99)00041-5; Zweiger Gary, 2001, TRANSDUCING GENOME I	141	56	59	4	29	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0962-2802			STAT METHODS MED RES	Stat. Methods Med. Res.	AUG	2008	17	4					347	388		10.1177/0962280206079046		42	Health Care Sciences & Services; Mathematical & Computational Biology; Medical Informatics; Statistics & Probability	Health Care Sciences & Services; Mathematical & Computational Biology; Medical Informatics; Mathematics	341YY	WOS:000258753000001	17698936	
J	Pedreira, CE; Costa, ES; Barrena, S; Lecrevisse, Q; Almeida, J; van Dongen, JJM; Orfao, A				Pedreira, Carlos E.; Costa, Elaine S.; Barrena, Susana; Lecrevisse, Quentin; Almeida, Julia; van Dongen, Jacques J. M.; Orfao, Alberto		EuroFlow Consoritum	Generation of flow cytometry data files with a potentially infinite number of dimensions	CYTOMETRY PART A			English	Article						B-cell chronic lymphoproliferative disorders; flow cytometry; immunophenotyping; FCS files; data calculation; nearest neighbor	CHRONIC LYMPHOCYTIC-LEUKEMIA; CHRONIC LYMPHOPROLIFERATIVE DISORDERS; MINIMAL RESIDUAL DISEASE; MYELODYSPLASTIC SYNDROMES; BONE-MARROW; CELL CLONE; EXPRESSION; LYMPHOMAS; NEOPLASIAS; CLASSIFICATION	Immunophenotypic characterization of B-cell chronic lymphoproliferative disorders (B-CLPD) is associated with the use of increasingly larger panels of multiple combinations of 3 to >= 6 monoclonal antibodies (Mab), data analysis being separately performed for each of the different stained sample aliquots. Here, we describe and validate an automated method for calculation of flow cytometric data from several multicolor stainings of the same cell sample-i.e., the merging of data from different aliquots stained with partially overlapping combinations of Mab reagents (focusing on >= 1 cell populations)-into one data file as if it concerned a single "super" multicolor staining. Evaluation of the performance of the method described was done in a group of 60 B-CLPD studied at diagnosis with 18 different reagents in a panel containing six different 3- and 4-color stainings, which systematically contained CD19 for the identification of B-cells. Our results show a high degree of correlation and agreement between originally measured and calculated data about cell surface stainings, providing a basis for the use of this approach for the generation of flow cytometric data files containing information about a virtually infinite number of stainings for each individual cellular event measured in a sample, using a limited number of fluorochrome stainings. (C) 2008 International Society for Advancement of Cytometry.	[Pedreira, Carlos E.] Univ Fed Rio de Janeiro, Fac Med, Rio De Janeiro, Brazil; [Pedreira, Carlos E.] Univ Fed Rio de Janeiro, COPPE, Engn Grad Program, Rio De Janeiro, Brazil; [Costa, Elaine S.] Univ Fed Rio de Janeiro, Inst Pediat & Puericultura Martagao Gesteira, Rio De Janeiro, Brazil; [Costa, Elaine S.] Univ Fed Rio de Janeiro, Dept Clin Med, Rio De Janeiro, Brazil; [Barrena, Susana; Lecrevisse, Quentin; Almeida, Julia; Orfao, Alberto] Univ Salamanca, Cytometry Serv, Dept Med, E-37008 Salamanca, Spain; Univ Salamanca, Cytometry Serv, Canc Res Ctr, IBMCC,CSIC, E-37008 Salamanca, Spain; [van Dongen, Jacques J. M.] Univ Med Ctr Rotterdam, Dept Immunol, Erasmus MC, Rotterdam, Netherlands	Orfao, A (reprint author), Paseo Univ Coimbra, Ctr Invest Cancer, S-N,Campus Miguel Unamuno, Salamanca 37007, Spain.	orfao@usal.es	2008, Ibsal/A-1268-2012; van Dongen, Jacques/F-8537-2015; Pedreira, Carlos Eduardo/I-5629-2013; Costa, Elaine/O-6523-2014	van Dongen, Jacques/0000-0001-7686-0021; Pedreira, Carlos Eduardo/0000-0002-9312-4023; Costa, Elaine/0000-0002-5340-5816	Departamento de Clinica Medica, Federal University of Rio de Janeiro, Brazil	The authors thank Prof. Nelson Spector (Departamento de Clinica Medica, Federal University of Rio de Janeiro, Brazil) for his helpful support.	Ashman M, 2007, CYTOM PART B-CLIN CY, V72B, P380, DOI 10.1002/cyto.b.20178; Bakke AC, 2006, CYTOM PART B-CLIN CY, V70B, P227, DOI 10.1002/cyto.b.20079; Barlage S, 1999, ANAL CELL PATHOL, V19, P81; Bigos Martin, 1999, Cytometry, V36, P36, DOI 10.1002/(SICI)1097-0320(19990501)36:1<36::AID-CYTO5>3.0.CO;2-9; Braylan RC, 2001, CYTOMETRY, V46, P23, DOI 10.1002/1097-0320(20010215)46:1<23::AID-CYTO1033>3.0.CO;2-Z; Braylan RC, 2004, CYTOM PART A, V58A, P57, DOI 10.1002/cyto.a.10101; Costa ES, 2006, LEUKEMIA, V20, P1221, DOI 10.1038/sj.leu.2404241; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; del Canizo MC, 2003, HAEMATOLOGICA, V88, P402; Del Principe MI, 2006, BLOOD, V108, P853, DOI 10.1182/blood-2005-12-4986; Deneys V, 2001, J IMMUNOL METHODS, V253, P23, DOI 10.1016/S0022-1759(01)00338-6; DiGiuseppe JA, 1998, SEMIN ONCOL, V25, P6; Duda R O, 2001, PATTERN CLASSIFICATI; Gervasi F, 2004, ANN NY ACAD SCI, V1028, P457, DOI 10.1196/annals.1322.054; Harris NL, 1999, J CLIN ONCOL, V17, P3835; Hayat A, 2006, LEUKEMIA LYMPHOMA, V47, P2371, DOI 10.1080/10428190600947727; Kaleem Z, 2006, ARCH PATHOL LAB MED, V130, P1850; Kappelmayer J, 2000, J IMMUNOL METHODS, V242, P53, DOI 10.1016/S0022-1759(00)00220-9; MACEDO A, 1995, LEUKEMIA, V9, P1896; Matutes E, 2002, J CLIN PATHOL, V55, P180; Montillo M, 2005, CANCER INVEST, V23, P488, DOI 10.1080/07357900500201418; Moreton P, 2005, J CLIN ONCOL, V23, P2971, DOI 10.1200/JCO.2005.04.021; Ortuno F, 1997, HAEMATOLOGICA, V82, P334; Pagnucco G, 2006, ANN NY ACAD SCI, V1089, P383, DOI 10.1196/annals.1386.031; Pantelias A, 2007, BLOOD, V109, P4980, DOI 10.1182/blood-2006-11-056895; Perfetto SP, 2004, NAT REV IMMUNOL, V4, P648, DOI 10.1038/nri1416; Rawstron AC, 2001, BLOOD, V98, P29, DOI 10.1182/blood.V98.1.29; ROBINSON JP, 1992, CYTOMETRY, V13, P75, DOI 10.1002/cyto.990130112; ROBINSON JP, 1991, CYTOMETRY, V12, P82, DOI 10.1002/cyto.990120112; Rossmann E D, 2001, Hematol J, V2, P300, DOI 10.1038/sj.thj.6200119; Sanchez ML, 2006, HAEMATOL-HEMATOL J, V91, P331; Sanchez ML, 2003, BLOOD, V102, P2994, DOI 10.1182/blood-2003-01-0045; Sanchez ML, 2002, LEUKEMIA, V16, P1460, DOI 10.1038/sj.leu.2402584; Stetler-Stevenson M, 2001, SEMIN HEMATOL, V38, P111, DOI 10.1053/shem.2001.21923; Tung JW, 2004, CLIN IMMUNOL, V110, P277, DOI 10.1016/j.clim.2003.11.016; Valent P, 2007, LEUKEMIA RES, V31, P727, DOI 10.1016/j.leukres.2006.11.009; Van Lochem EG, 1997, LEUKEMIA, V11, P2208, DOI 10.1038/sj.leu.2400862; Wang LL, 2006, CYTOM PART B-CLIN CY, V70B, P410, DOI 10.1002/cyto.b.20140	38	35	37	0	4	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4922			CYTOM PART A	Cytom. Part A	SEP	2008	73A	9					834	846		10.1002/cyto.a.20608		13	Biochemical Research Methods; Cell Biology	Biochemistry & Molecular Biology; Cell Biology	343XV	WOS:000258890500009	18629843	
J	Rovatti, R; Mazzini, G				Rovatti, Riccardo; Mazzini, Gianluca			On the nearest neighbor of the nearest neighbor in multidimensional continuous and quantized space	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						dimensionality effect; Euclidean distances; nearest neighbor; Poisson point processes; quantized distances	WIRELESS NETWORKS	The probability that an entity in a set of entities uniformly distributed in space is the nearest neighbor of its nearest neighbor is evaluated for generic distances in a multidimensional environment. Such an expression is then specialized for systems with norm-based distances and for systems with quantized norm-based distance. Examples for scalar products and sup-norm are derived. When appticable, invariances with respect to the underlying distance and entities density are highlighted. Dimensionality effects are investigated.	[Rovatti, Riccardo] Univ Bologna, ARCES, I-40125 Bologna, Italy; [Mazzini, Gianluca] Univ Ferrara, ENDIF, I-44100 Ferrara, Italy	Rovatti, R (reprint author), Univ Bologna, ARCES, I-40125 Bologna, Italy.	riccardo.rovatti@unibo.it; g.mazzini@ieee.org					ANDROUTSOS P, 2006, IEEE SIGNAL PROC MAG, P142; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Csanyi G, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.036131; Helmy A, 2003, IEEE COMMUN LETT, V7, P490, DOI 10.1109/LCOMM.2003.818887; Holme P., 2001, PHYS REV E, V65; Jakllari G, 2007, IEEE J SEL AREA COMM, V25, P484, DOI 10.1109/JSAC.2007.070222; Mauve M, 2001, IEEE NETWORK, V15, P30, DOI 10.1109/65.967595; Slivnyak I., 1962, THEOR PROBAB APPL, V7, P336, DOI 10.1137/1107034; Tao YF, 2006, IEEE T KNOWL DATA EN, V18, P1239; VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942; WANG XIAO FAN, 2003, IEEE CIRCUITS SYSTEM, P6	12	0	0	2	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	SEP	2008	54	9					4069	4080		10.1109/TIT.2008.928246		12	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	344FX	WOS:000258913400013		
J	Garcia, V; Mollineda, RA; Sanchez, JS				Garcia, V.; Mollineda, R. A.; Sanchez, J. S.			On the k-NN performance in a challenging scenario of imbalance and overlapping	PATTERN ANALYSIS AND APPLICATIONS			English	Article						imbalanced data; nearest neighbour rule; class overlap; local and global learning; overall imbalance ratio; local imbalance ratio	LEARNING ALGORITHMS; CLASSIFIERS	A two-class data set is said to be imbalanced when one (minority) class is heavily under-represented with respect to the other (majority) class. In the presence of a significant overlapping, the task of learning from imbalanced data can be a very difficult problem. Additionally, if the overall imbalance ratio is different from local imbalance ratios in overlap regions, the task can become in a major challenge. This paper explains the behaviour of the k-nearest neighbour (k-NN) rule when learning from such a complex scenario. This local model is compared to other machine learning algorithms, attending to how their behaviour depends on a number of data complexity features (global imbalance, size of overlap region, and its local imbalance). As a result, several conclusions useful for classifier design are inferred.	[Garcia, V.] Inst Tecnol Toluca, Lab Reconocimiento Patrones, Metepec 52140, Mexico; [Mollineda, R. A.; Sanchez, J. S.] Univ Jaume 1, Dept Llenguatges & Sistemes Informat, Castellon de La Plana 12071, Spain	Garcia, V (reprint author), Inst Tecnol Toluca, Lab Reconocimiento Patrones, Av Tecnol S-N, Metepec 52140, Mexico.	vgarciaj@hotmail.com		Sanchez Garreta, Jose Salvador/0000-0003-1053-4658; Garcia, Vicente/0000-0003-2820-2918	DPI2006-15542 [Spanish CICYT]; CSD2007-00018 [Spanish Ministry of Science and Education]; SEP-2003C02-44225 [Mexican CONACyT]	This work has been partially supported by grants DPI2006-15542 from the Spanish CICYT, CSD2007-00018 from the Spanish Ministry of Science and Education and SEP-2003C02-44225 from the Mexican CONACyT.	Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Beyer K., 1999, P 7 INT C DAT THEOR, P217; Bishop C.M., 1995, NEURAL NETWORKS PATT; Buhmann M. D., 2003, RADIAL BASIS FUNCTIO; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; Daskalaki S, 2006, APPL ARTIF INTELL, V20, P381, DOI 10.1080/08839510500313653; Devijver P., 1992, PATTERN RECOGNITION; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Duda R O, 2001, PATTERN CLASSIFICATI; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P882, DOI 10.1016/j.patrec.2005.10.012; Frank E., 2005, DATA MINING PRACTICA; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Gordon D., 1989, Computational Intelligence, V5, DOI 10.1111/j.1467-8640.1989.tb00317.x; Hand DJ, 2003, PATTERN RECOGN LETT, V24, P1555, DOI 10.1016/S0167-8655(02)00394-X; Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299; Japkowicz N., 2002, Intelligent Data Analysis, V6; Jo T., 2004, SIGKDD EXPLORATIONS, V6, P40, DOI DOI 10.1145/1007730.1007737; KUBAT M, 1998, P 1 SO S COMP, P27; Kubat M., 1997, P 14 INT C MACH LEAR, P179; LANDGREBE TCW, 2006, P 18 INT C PATT REC, P123; Little R.J.A., 2002, STAT ANAL MISSING DA; Okamoto S, 2003, THEOR COMPUT SCI, V298, P207, DOI 10.1016/S0304-3975(02)00424-3; Orriols A, 2005, P 2005 WORKSH GEN EV, P74, DOI 10.1145/1102256.1102271; Pazzani M., 1994, P 11 INT C MACH LEAR, P217; Prati R. C., 2004, P 3 MEX INT C ART IN, P312; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Visa S, 2003, P INF PROC MAN UNC K, P97; Weiss G., 2003, THESIS RUTGERS U; Zhang J., 2003, P WORKSH LEARN IMB D, P42	35	42	44	0	1	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	SEP	2008	11	3-4					269	280		10.1007/s10044-007-0087-5		12	Computer Science, Artificial Intelligence	Computer Science	339LU	WOS:000258579900005		
J	Garain, U				Garain, Utpal			Prototype reduction using an artificial immune model	PATTERN ANALYSIS AND APPLICATIONS			English	Article						nearest neighbor classification; prototype selection; artificial immune system; clonal selection algorithm; statistical significance	NEAREST-NEIGHBOR RULE; CLONAL SELECTION; LEARNING ALGORITHMS; INSTANCE SELECTION; CLASSIFICATION; RECOGNITION; SYSTEM	Artificial immune system (AIS)-based pattern classification approach is relatively new in the field of pattern recognition. The study explores the potentiality of this paradigm in the context of prototype selection task that is primarily effective in improving the classification performance of nearest-neighbor (NN) classifier and also partially in reducing its storage and computing time requirement. The clonal selection model of immunology has been incorporated to condense the original prototype set, and performance is verified by employing the proposed technique in a practical optical character recognition (OCR) system as well as for training and testing of a set of benchmark databases available in the public domain. The effect of control parameters is analyzed and the efficiency of the method is compared with another existing techniques often used for prototype selection. In the case of the OCR system, empirical study shows that the proposed approach exhibits very good generalization ability in generating a smaller prototype library from a larger one and at the same time giving a substantial improvement in the classification accuracy of the underlying NN classifier. The improvement in performance has been statistically verified. Consideration of both OCR data and public domain datasets demonstrate that the proposed method gives results better than or at least comparable to that of some existing techniques.	Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India	Garain, U (reprint author), Indian Stat Inst, Comp Vis & Pattern Recognit Unit, 203 BT Rd, Kolkata, India.	utpal@isical.ac.in					BAIRD HS, 1993, P 2 INT C DOC AN REC, P593; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Blake CL, UCI REPOSITORY MACHI; Box G. E. P., 1978, STAT EXPT; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Burnet F. M., 1959, CLONAL SELECTION THE; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Carter JH, 2000, J AM MED INFORM ASSN, V7, P28; CHAUDHURI BB, 2003, TISICVPR032003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasgupta D., 1998, ARTIFICIAL IMMUNE SY, P3; DASGUPTA D, 2003, P 2003 IEEE C EV COM, V3, P123; de Castro L, 2002, ARTIFICIAL NEURAL NE, P67; de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539; Devi VS, 2002, PATTERN RECOGN, V35, P505; Garain U, 2006, LECT NOTES COMPUT SC, V4163, P256; Garain U, 1998, P SOC PHOTO-OPT INS, V3305, P90, DOI 10.1117/12.304622; GARAIN U, 2006, P 18 INT C PATT REC, P1046; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Huang D, 2006, NEURAL COMPUT, V18, P470, DOI 10.1162/089976606775093927; JERNE NK, 1974, ANN INST PASTEUR IMM, VC125, P373; Ji Z, 2004, LECT NOTES COMPUT SC, V3102, P287; Kim SW, 2003, PATTERN ANAL APPL, V6, P232, DOI 10.1007/s10044-003-0191-0; Kohonen T., 1990, P IEEE 1, V78, P464; Li YG, 2005, LECT NOTES COMPUT SC, V3610, P528; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; PEKALSKA E, 2002, P INT C PATT REC, V3, P37; PERELSON AS, 1979, J THEOR BIOL, V81, P645, DOI 10.1016/0022-5193(79)90275-3; Sanchez JS, 2003, PATTERN RECOGN LETT, V24, P1015, DOI 10.1016/S0167-8655(02)00225-8; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; SKALAK DB, 1995, THESIS U MASSACHUSET; Swonger C., 1972, FRONTIERS PATTERN RE, P511; Tang Z., 2003, Systems and Computers in Japan, V34, DOI 10.1002/scj.10243; Timmis J.I., 2001, THESIS U WALES ABERY; Watkins A., 2001, THESIS MISSISSIPPI S; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	39	18	19	2	3	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541	1433-755X		PATTERN ANAL APPL	Pattern Anal. Appl.	SEP	2008	11	3-4					353	363		10.1007/s10044-008-0106-1		11	Computer Science, Artificial Intelligence	Computer Science	339LU	WOS:000258579900011		
J	Chen, CH; Ho, PGP				Chen, Chi Hau; Ho, Pei-Gee Peter			Statistical pattern recognition in remote sensing	PATTERN RECOGNITION			English	Article						remote sensing; statistical pattern classification; contextual information; neural networks; support vector machine; vector 2-D autoregressive; time series; Markov random field	SUPPORT VECTOR MACHINES; MARKOV RANDOM-FIELDS; NEURAL-NETWORKS; HYPERSPECTRAL DATA; CLASSIFICATION; IMAGES; SELECTION; CONTEXT; RESTORATION; ALGORITHM	Remote sensing with sensors mounted on satellites or aircrafts is much needed for resource management, environmental monitoring, disaster response, and homeland defense. Remote sensing data considered include those from multispectral, hyperspectral, radar, optical, and infrared sensors. Classification is often one of the major tasks in information processing. For example, we need to identify vegetations, waterways, and man-made structures from remote sensing of earth. The large amount of data available makes remote sensing data uniquely suitable for statistical pattern recognition. This paper will address several issues on statistical pattern recognition that are related to information processing in remote sensing. Though the paper is largely tutorial in nature, some specific issues considered are image models for characterization of contextual information, neural networks for image classification, and the performance measures. Either to supplement the capability of sensors or to effectively utilize the enormous amount of sensor data, many advances in statistical pattern recognition can be very useful in machine recognition of the data. The potentials and opportunities of using statistical pattern recognition in remote sensing are indeed unlimited. (c) 2008 Elsevier Ltd. All rights reserved.	[Chen, Chi Hau; Ho, Pei-Gee Peter] Univ Massachusetts Dartmouth, Elect & Comp Engn Dept, N Dartmouth, MA 02747 USA	Chen, CH (reprint author), Univ Massachusetts Dartmouth, Elect & Comp Engn Dept, 285 Old Westport Rd, N Dartmouth, MA 02747 USA.	cchen@umassd.edu					Benediktsson J.A., 1999, HDB PATTERN RECOGNIT, P507, DOI 10.1142/9789812384737_0016; Bishop C. M., 2006, PATTERN RECOGNITION; BOVOLO F, 2006, P IGARSS DENV; Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1179, DOI 10.1109/36.752239; BRUZZONE L, 2005, FRONTIERS REMOTE SEN, P285; Carpenter GA, 1997, IEEE T GEOSCI REMOTE, V35, P308, DOI 10.1109/36.563271; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Chen C. H, 2000, P INT GEOSC REM SENS; CHEN CH, 1999, INFORMATION PROCESSI, P167; CHEN CH, 2003, FRONTIERS REMOTE SEN, P23, DOI 10.1142/9789812796752_0002; CHEN CH, 2007, SIGNAL PROCESSING RE; Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CLAUSI DA, 2007, IEEE T GEOSCI REMOTE, V45; CONGALTON RB, REMOTE SENSING THEMA, P73; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P35; DATTATREYA GR, 1991, PATTERN RECOGN, V24, P685, DOI 10.1016/0031-3203(91)90036-5; Del Frate F, 2007, IEEE T GEOSCI REMOTE, V45, P800, DOI 10.1109/TGRS.2007.892009; Duda R., 1972, PATTERN CLASSIFICATI; Duda R. O., 2003, PATTERN CLASSIFICATI; Duin R. P. W., 2005, HDB PATTERN RECOGNIT, P3, DOI 10.1142/9789812775320_0001; Figueiredo MAT, 1997, IEEE T IMAGE PROCESS, V6, P1089, DOI 10.1109/83.605407; FU KS, 1982, APPL PATTERN RECOGNI, pCH4; Fu K.S., 1980, STAT PATTERN CLASSIF; Fukunaga K., 1990, INTRO STAT PATTERN R; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721; Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861; GRABOSWKI S, 2003, FRONTIERS REMOTE SEN, P315, DOI 10.1142/9789812796752_0013; Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481; HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218; HO P, 2008, THESIS U MASSACHUSET; HSU SM, 2005, HDB PATTERN RECOGNIT, P347, DOI 10.1142/9789812775320_0019; Hyvarinen A., 2001, INDEPENDENT COMPONEN; Jain A. K., 1999, BIOMETRICS PERSONAL; JENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683, DOI 10.1109/78.80887; JEON B, 1992, IEEE T GEOSCI REMOTE, V30, P663, DOI 10.1109/36.158859; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; JOELSSON SR, 2006, SIGNAL IMAGE PROCESS, P327; KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Kindermann R., 1980, MARKOV RANDOM FIELDS; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Kuncheva L. I., 2004, COMBINING PATTERN CL; Kuo BC, 2007, IEEE T GEOSCI REMOTE, V45, P756, DOI 10.1109/TGRS.2006.885074; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Landgrebe D. A., 2003, SIGNAL THEORY METHOD; Lee J, 2007, IEEE T GEOSCI REMOTE, V45, P2953, DOI 10.1109/TGRS.2007.900675; LEE JS, 1999, REMOTE SENSING INFOR, P113; LILLESAND TM, 1988, REMOTE SENSING IMAGE; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; MOSER G, 2005, FRONTIERS REMOTE SEN, P405; NISHII R, 2006, SIGNAL IMAGE PROCESS, P345; PAARZEN E, 1962, ANN MATH STAT, V33, P1065; PETROU M, 1999, INFORM PROCESSING RE, P69; RICHARDS J, 2003, FRONTIERS REMOTE SEN, P3, DOI 10.1142/9789812796752_0001; RICHARDS J, 2005, P SOC PHOTO-OPT INS, V5982, P1; Serpico S. B., 2006, SIGNAL IMAGE PROCESS, P305; SERPICO SB, 1995, IEEE T GEOSCI REMOTE, V33, P562, DOI 10.1109/36.387573; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; Smits PC, 2002, IEEE T GEOSCI REMOTE, V40, P801, DOI 10.1109/TGRS.2002.1006354; Solberg A.H.S., 2006, SIGNAL IMAGE PROCESS, P515, DOI 10.1201/9781420003130.ch23; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; Vapnik V. N., 1998, NATURE STAT LEARNING; Waske B, 2007, IEEE T GEOSCI REMOTE, V45, P3858, DOI 10.1109/TGRS.2007.898446; Webb A, 2003, STAT PATTERN RECOGNI; WELCH JR, 1971, IEEE T SYST MAN CYB, VSMC1, P24; WHARTON SW, 1982, PATTERN RECOGN, V15, P317, DOI 10.1016/0031-3203(82)90034-6; Wilkinson GG, 2005, IEEE T GEOSCI REMOTE, V43, P433, DOI 10.1109/TGRS.2004.837325; YOSHIOKA M, 2006, SIGNAL IMAGE PROCESS, P607; Zhang B, 2008, IEEE T GEOSCI REMOTE, V46, P159, DOI 10.1109/TGRS.2007.907972; ZHANG X, 2004, J VLSI SIGNAL PROCES, V37	74	48	52	6	29	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	SEP	2008	41	9					2731	2741		10.1016/j.patcog.2008.04.013		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	325HW	WOS:000257581000001		
J	Espana, GM; Florez, JM; Torres, HV				Espana, German Morales; Florez, Juan Mora; Torres, Hermann Vargas			k-NN based regression strategy used to estimate the fault distance in radial power systems	REVISTA FACULTAD DE INGENIERIA-UNIVERSIDAD DE ANTIOQUIA			Spanish	Article						faults location; k nearest neighbors (k-NN); radial systems; regression	LOCATION ALGORITHM	A regression strategy based on k nearest neighbors (k-NN) to estimate the fault distance in radial power systems is proposed. This fault location approach uses measurements of the fundamental components of voltage and current measured at the power substation. In addition, the approach is not constrained by the power system modeling and it is easily adaptable to the special characteristics of radial systems. The proposed fault locator is tested in a power distribution system and the obtained mean error is lower than 3%, by considering all fault types, several faulted nodes and fault resistances.	[Florez, Juan Mora] Univ Tecnol Pereira, Program Ingn Elect, GISEL, La Julita, Pereira, Colombia; Univ Tecnol Pereira, Program Ingn Elect, ICE3, La Julita, Pereira, Colombia	Florez, JM (reprint author), Univ Tecnol Pereira, Program Ingn Elect, GISEL, La Julita, Pereira, Colombia.	jjmora@utp.edu.co					Aggarwal RK, 1997, IEE P-GENER TRANSM D, V144, P309, DOI 10.1049/ip-gtd:19971137; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Choi MS, 2004, IEEE T POWER DELIVER, V19, P35, DOI 10.1109/TPWRD.2003.820433; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagenhart J, 2000, IEEE T IND APPL, V36, P30, DOI 10.1109/28.821792; DAS R, 1998, THESIS U SASKATCHEWA, P16; Girgis A., 1993, IEEE T IND APPL, V26, P1170; *IEEE, 2004, 37114 IEEE; Mora-Florez J, 2007, IEEE T POWER DELIVER, V22, P1715, DOI 10.1109/TPWRD.2006.883021; Morales G., 2006, REV INGENIERIA, V11, P43; MORALES G, 2007, P 12 ENC REG IB CIGR, P52; MORALES G, 2005, THESIS U IND SANTAND; MORENO F, 2004, THESIS U ALICANTE, P56; SRINIVASAN K, 1989, IEEE T POWER DELIVER, V4, P1676, DOI 10.1109/61.32658; WARRINGTON A, 1968, PROTECTIVE RELAYS TH, P125; Zhu J, 1997, IEEE T POWER DELIVER, V12, P801	16	1	1	0	1	IMPRENTA UNIV ANTIOQUIA	MEDELLIN	67 N 53-108, BLOQUE 28, CIUDAD UNIV, UNIV ANTIQUIA, MEDELLIN, 00000, COLOMBIA	0120-6230			REV FAC ING-UNIV ANT	Rev. Fac. Ing.-Univ. Antioquia	SEP	2008		45					100	108				9	Engineering, Multidisciplinary	Engineering	330BO	WOS:000257914500010		
J	Hall, P; Park, BU; Samworth, RJ				Hall, Peter; Park, Byeong U.; Samworth, Richard J.			CHOICE OF NEIGHBOR ORDER IN NEAREST-NEIGHBOR CLASSIFICATION	ANNALS OF STATISTICS			English	Article						Bayes classifier; bootstrap resampling; Edgeworth expansion; error probability; misclassification error; nonparametric classification; Poisson distribution	NONPARAMETRIC DISCRIMINATION; PATTERN-CLASSIFICATION; CONVERGENCE; ERROR; RATES; PROBABILITY; CONSISTENCY; CLASSIFIERS; RULES; RISK	The kth-nearest neighbor rule is arguably the simplest and most intuitively appealing nonparametric classification procedure. However, application of this method is inhibited by lack of knowledge about its properties, in particular, about the manner in which it is influenced by the value of k; and by the absence of techniques for empirical choice of k. In the present paper we detail the way in which the value of k determines the misclassification error. We consider two models, Poisson and Binomial, for the training samples. Under the first model, data are recorded in a Poisson stream and are "assigned" to one or other of the two populations in accordance with the prior probabilities. In particular, the total number of data in both training samples is a Poisson-distributed random variable. Under the Binomial model, however, the total number of data in the training samples is fixed, although again each data value is assigned in a random way. Although the values of risk and regret associated with the Poisson and Binomial models are different, they are asymptotically equivalent to first order, and also to the risks associated with kernel-based classifiers that are tailored to the case of two derivatives. These properties motivate new methods for choosing the value of k.	[Hall, Peter] Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia; [Park, Byeong U.] Seoul Natl Univ, Dept Stat, Seoul 151747, South Korea; [Samworth, Richard J.] Univ Cambridge, Ctr Math Sci, Stat Lab, Cambridge CB3 0WB, England	Hall, P (reprint author), Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia.	bupark2000@gmail.com			KOSEF [R02-2004-000-10040-0]	Supported by KOSEF (project R02-2004-000-10040-0).	Audibert JY, 2007, ANN STAT, V35, P608, DOI 10.1214/009053606000001217; Bax E, 2000, IEEE T INFORM THEORY, V46, P2746, DOI 10.1109/18.887892; Cover T. M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; Devroye L., 1982, HDB STAT, V2, P193, DOI 10.1016/S0169-7161(82)02011-2; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; Devroye L., 1996, PROBABILISTIC THEORY; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; FIX E, 1951, 4 RAND FIELD; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; Gyorfi L, 2002, DISTRIBUTION FREE TH; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P509, DOI 10.1109/TIT.1978.1055898; GYORFI L, 1978, IEEE T INFORM THEORY, V24, P512, DOI 10.1109/TIT.1978.1055900; Hall P, 2005, ANN STAT, V33, P284, DOI 10.1214/009053604000000959; HALL P, 2007, CHOICE NEIGHBOUR ORD; Holst M, 2001, ANN STAT, V29, P1424; KHARIN YS, 1979, STAT PROBLEMS CONTRO, V38, P77; KHARIN YS, 1982, T 9 PRAG C INF THEOR, P11; KOHLER M, 2006, RATE CONVERGEN UNPUB; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Mammen E, 1999, ANN STAT, V27, P1808; MARRON JS, 1983, ANN STAT, V11, P1142; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Raudys S, 2004, J MULTIVARIATE ANAL, V89, P1, DOI 10.1016/S0047-259X(02)00021-0; Snapp RR, 1998, ANN STAT, V26, P850; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	28	28	30	1	7	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	OCT	2008	36	5					2135	2152		10.1214/07-AOS537		18	Statistics & Probability	Mathematics	367LS	WOS:000260554100005		
J	Morton, KD; Torrione, PA; Throckmorton, CS; Collins, LM				Morton, Kenneth D.; Torrione, Peter A., Jr.; Throckmorton, Chandra S.; Collins, Leslie M.			Mandarin Chinese tone identification in cochlear implants: Predictions from acoustic models	HEARING RESEARCH			English	Article						Cochlear implant; Mandarin Chinese tones; F0 estimation; Particle filter	SPEECH CODING STRATEGY; AUDITORY-PERCEPTION; PITCH PERCEPTION; FINE-STRUCTURE; RECOGNITION; STIMULATION; NOISE; CUES; INFORMATION; AMPLITUDE	It has been established that current cochlear implants do not supply adequate spectral information for perception of tonal languages. Comprehension of a tonal language, such as Mandarin Chinese, requires recognition of lexical tones. New strategies of cochlear stimulation such as variable stimulation rate and current steering may provide the means of delivering more spectral information and thus may provide the auditory fine-structure required for tone recognition. Several cochlear implant signal processing strategies are examined in this study, the continuous interleaved sampling (CIS) algorithm, the frequency amplitude modulation encoding (FAME) algorithm, and the multiple carrier frequency algorithm (MCFA). These strategies provide different types and amounts of spectral information. Pattern recognition techniques can be applied to data from Mandarin Chinese tone recognition tasks using acoustic models as a means of testing the abilities of these algorithms to transmit the changes in fundamental frequency indicative of the four lexical tones. The ability of processed Mandarin Chinese tones to be correctly classified may predict trends in the effectiveness of different signal processing algorithms in cochlear implants. The proposed techniques can predict trends in performance of the signal processing techniques in quiet conditions but fail to do so in noise. (C) 2008 Elsevier B.V. All rights reserved.	[Morton, Kenneth D.; Torrione, Peter A., Jr.; Throckmorton, Chandra S.; Collins, Leslie M.] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Collins, LM (reprint author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	lcollins@ee.duke.edu			NIH [1-R01-DC007994-01]	The authors would like to acknowledge Dr. Zeng at the University of California Irvine for his help in acquiring the speech material used in this research. They would also like to thank the subjects who participated in the experiment. This research was supported in part by NIH Grant 1-R01-DC007994-01.	Arnoldner C, 2007, ACTA OTO-LARYNGOL, V127, P1298, DOI 10.1080/00016480701275261; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; BLAMEY PJ, 1984, J ACOUST SOC AM, V76, P97, DOI 10.1121/1.391012; BLAMEY PJ, 1984, J ACOUST SOC AM, V76, P104, DOI 10.1121/1.391104; Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.2307/2331986; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603; Duda RO, 2004, PATTERN CLASSIFICATI; FEARN R, 2001, 7 S COCHL IMPL CHILD, P51; Fearn R. A., 2001, THESIS U NEW S WALES; FLANAGAN JL, 1966, AT&T TECH J, V45, P1493; Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251; GORDON NJ, 1993, IEE PROC-F, V140, P107; GRAYDEN DB, 2006, P 11 AUSTR INT C SPE, P323; GREENWOOD D, 1961, J ACOUST SOC AM, V33, P1344, DOI 10.1121/1.1908437; GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052; KOCH DB, 2005, C IMPL AUD PROSTH A; Kong YY, 2006, J ACOUST SOC AM, V120, P2830, DOI 10.1121/1.2346009; Lan N, 2004, IEEE T BIO-MED ENG, V51, P752, DOI 10.1109/TBME.2004.826597; LAROCHE J, 1999, IEEE WORKSH APPL SIG; LI J, 1999, FUZZ SYST C P FUZZ I, V2, P1059; Luo RC, 2004, IEEE T AUTOM SCI ENG, V1, P4, DOI [10.1109/TASE.2004.829344, 10.1109/TASE.2004.839344]; Luo Xin, 2004, Journal of the Acoustical Society of America, V116, P3659, DOI 10.1121/1.1783352; MARKEL JD, 1972, IEEE T ACOUST SPEECH, VAU20, P367, DOI 10.1109/TAU.1972.1162410; McDermott HJ, 1997, J ACOUST SOC AM, V101, P1622, DOI 10.1121/1.418177; Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799; NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469; Nogueira W, 2005, EURASIP J APPL SIG P, V2005, P3044, DOI 10.1155/ASP.2005.3044; NOGUEIRA W, 2007, ENG MED BIOL SOC EMB, P4127; REMUS J, 2003, C IMPL AUD PROSTH MO; Seneff S., 1988, READINGS SPEECH RECO, P101; SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303; SHI Y, 2003, P IEEE INT C AC SPEE; Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a; Strope B, 1997, IEEE T SPEECH AUDI P, V5, P451, DOI 10.1109/89.622569; Tchorz J, 1999, J ACOUST SOC AM, V106, P2040, DOI 10.1121/1.427950; THROCKMORTON C, 2006, HEARING RES; TIAN Y, 2004, P ICASSP, V1, P105; TONG YC, 1985, J ACOUST SOC AM, V77, P1881, DOI 10.1121/1.391939; TOWNSHEND B, 1987, J ACOUST SOC AM, V82, P106, DOI 10.1121/1.395554; Vandali AE, 2005, J ACOUST SOC AM, V117, P3126, DOI 10.1121/1.1874632; van Hoesel RJM, 2003, J ACOUST SOC AM, V113, P1617, DOI 10.1121/1.1539520; WEI CG, 2004, HEARING RES, P57; Whalen A.D, 1971, DETECTION SIGNALS NO; WHALEN DH, 1992, PHONETICA, V49, P25; WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0; Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786; Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843; Zakis JA, 2007, SPEECH COMMUN, V49, P113, DOI 10.1016/j.specom.2006.12.001; Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102; Zeng FG, 2002, HEARING RES, V174, P101, DOI 10.1016/S0378-5955(02)00644-5; Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102; ZHENG Y, 2004, P IEEE INT C AC SPEE; ZHENG Y, 2003, IEEE WORKSH STAT SIG	54	4	4	0	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-5955			HEARING RES	Hear. Res.	OCT	2008	244	1-2					66	76		10.1016/j.heares.2008.07.008		11	Audiology & Speech-Language Pathology; Neurosciences; Otorhinolaryngology	Audiology & Speech-Language Pathology; Neurosciences & Neurology; Otorhinolaryngology	368XC	WOS:000260655200008	18706497	
J	Ghosh, AK				Ghosh, Anil K.			Kernel discriminant analysis using case-specific smoothing parameters	IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS			English	Article						bandwidth; Bayes risk; bootstrap; cross validation; kernel smoothing; misclassification rate; nearest neighbor; p-value	BANDWIDTH CHOICE; NONPARAMETRIC REGRESSION; DENSITY-ESTIMATION; CLASSIFICATION; ESTIMATORS; SELECTION; CURVES	In kernel discriminant analysis, one common practice is to use a fixed level of smoothing (estimated from training data) for classifying all unlabeled observations. But, in classification, a good choice of smoothing parameters also depends on the observation to be classified. Therefore, instead of using a fixed level of smoothing over the entire measurement space, it may be more useful to estimate the smoothing parameters depending on that specific observation. Here, we propose a simple method for this case-specific smoothing. Some benchmark data sets are analyzed to illustrate the performance of the proposed method.	[Ghosh, Anil K.] Indian Inst Technol, Dept Math & Stat, Kanpur 208016, Uttar Pradesh, India	Ghosh, AK (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, India.	akghosh@isical.ac.in					ABRAMSON IS, 1982, ANN STAT, V10, P1217, DOI 10.1214/aos/1176345986; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Chapelle O., 2006, SEMISUPERVISED LEARN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Ghosh AK, 2004, STAT SINICA, V14, P457; Ghosh AK, 2007, INT J PATTERN RECOGN, V21, P1103, DOI 10.1142/S0218001407005855; Ghosh AK, 2007, J COMPUT GRAPH STAT, V16, P482, DOI 10.1198/106186007x208380; GHOSH AK, 2008, KERNEL DISCRIMINANT; HALL P, 1981, BIOMETRIKA, V68, P287, DOI 10.1093/biomet/68.1.287; Hall P, 2005, ANN STAT, V33, P284, DOI 10.1214/009053604000000959; Hand D. J., 1982, KERNEL DISCRIMINANT; HARDLE W, 1985, ANN STAT, V13, P1465, DOI 10.1214/aos/1176349748; Hastie T, 1998, ANN STAT, V26, P451; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Jones MC, 1995, KERNEL SMOOTHING; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MULLER HG, 1987, ANN STAT, V15, P182, DOI 10.1214/aos/1176350260; MULLER HG, 1984, ANN STAT, V12, P766, DOI 10.1214/aos/1176346523; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; RICE J, 1984, ANN STAT, V12, P1215, DOI 10.1214/aos/1176346788; Ripley BD, 1996, PATTERN RECOGNITION; Sain SR, 1996, J AM STAT ASSOC, V91, P1525, DOI 10.2307/2291578; SCHUCANY WR, 1995, J AM STAT ASSOC, V90, P535, DOI 10.2307/2291064; Scott D.W., 1992, MULTIVARIATE DENSITY; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; Silverman BW, 1986, DENSITY ESTIMATION S; Sklansky J., 1981, PATTERN CLASSIFIERS; STAINWALIS JG, 1989, J AM STAT ASSOC, V84, P284; TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768; Tukey JW, 1977, EXPLORATORY DATA ANA; VIEU P, 1991, J ROY STAT SOC B MET, V53, P453; WASSEL GN, 1972, IEEE T SYST MAN CYB, VSMC2, P533, DOI 10.1109/TSMC.1972.4309163; Zhang ZH, 2006, MACH LEARN, V63, P69, DOI 10.1007/s10994-006-6130-8	36	3	3	1	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1083-4419	1941-0492		IEEE T SYST MAN CY B	IEEE Trans. Syst. Man Cybern. Part B-Cybern.	OCT	2008	38	5					1413	1418		10.1109/TSMCB.2008.925754		6	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	348DT	WOS:000259191900017	18784021	
J	Aimeur, E; Brassard, G; Fernandez, JM; Onana, FSM				Aimeur, Esma; Brassard, Gilles; Fernandez, Jose M.; Onana, Flavien Serge Mani			ALAMBIC: a privacy-preserving recommender system for electronic commerce	INTERNATIONAL JOURNAL OF INFORMATION SECURITY			English	Article						privacy protection; recommender system; secure two-party computation; semi-trusted third party; web personalization	WEB; PERSONALIZATION; IDENTIFICATION	Recommender systems enable merchants to assist customers in finding products that best satisfy their needs. Unfortunately, current recommender systems suffer from various privacy-protection vulnerabilities. Customers should be able to keep private their personal information, including their buying preferences, and they should not be tracked against their will. The commercial interests of merchants should also be protected by allowing them to make accurate recommendations without revealing legitimately compiled valuable information to third parties. We introduce a theoretical approach for a system called Alambic, which achieves the above privacy-protection objectives in a hybrid recommender system that combines content-based, demographic and collaborative filtering techniques. Our system splits customer data between the merchant and a semi-trusted third party, so that neither can derive sensitive information from their share alone. Therefore, the system could only be subverted by a coalition between these two parties.	[Fernandez, Jose M.] Ecole Polytech, Dept Genie Informat, Montreal, PQ H3C 3A7, Canada; [Aimeur, Esma; Brassard, Gilles; Onana, Flavien Serge Mani] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada	Fernandez, JM (reprint author), Ecole Polytech, Dept Genie Informat, Montreal, PQ H3C 3A7, Canada.	aimeur@iro.umontreal.ca; brassard@iro.umontreal.ca; jose.fernandez@polymtl.ca; manionaf@iro.umontreal.ca					Ackerman B, 1999, COLUMBIA LAW REV, V99, P1, DOI 10.2307/1123596; AIELLO B, 2001, P ADV CRYPTOLOGY EUR, P119; Aimeur E., 2006, IADIS INT J, V4, P55; Aimeur E., 2006, P 2006 ACM S APPL CO, P872, DOI 10.1145/1141277.1141479; AIMEUR E, 2002, P ITS 2002, P718; Aimeur E., 2006, Journal of Computer Security, V14; ARDISSONO L, 2005, P 10 INT C US MOD ED; Barak B., 2001, P 21 ANN INT CRYPT C, P1; BENOR M, 1988, P 20 ANN ACM S THEOR, P11; BOYAN J, 1997, COMPUT MEDIATED COMM, V4; Breese J S, 1998, P 14 C UNC ART INT, P43; BURKE R, 2005, P 3 INT WORKSH INT T, P17; BURKE R, 2002, CUSTOMER MODELING CU, V4, P331; CAMENISCH J., 2005, P CRYPT 2005 SANT BA, P169; Canny J, 2002, P IEEE S SECUR PRIV, P45, DOI 10.1109/SECPRI.2002.1004361; Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564419; CHANG Y, 2004, SINGLE DATABASE PRIV; CHAUM D, 1985, P CRYPT 85 SANT BARB, P477; Chaum D., 1983, P ADV CRYPT 83 NEW Y, P153; CHAUM D, 1988, P 20 ANN ACM S THEOR, P1; Chaum D., 1982, P CRYPTO 82, P199; CHAUM DL, 1981, COMMUN ACM, V24, P84, DOI 10.1145/358549.358563; CHAUM D, 1985, COMMUN ACM, V28, P1030, DOI 10.1145/4372.4373; Chen S., 2005, STRATEGIC MANAGEMENT; Chor B., 1995, Proceedings. 36th Annual Symposium on Foundations of Computer Science (Cat. No.95CB35834), DOI 10.1109/SFCS.1995.492461; COOLEY T, 1888, TREATISE CONSTITUTIO; Cover T. M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cramer R, 1997, P INT C THEOR APPL C, P103; FLINN S, 2005, P C PRIV SEC TRUST P, P15; Fox S., 2001, TRUST PRIVACY ONLINE; FREYNE J, 2005, P 3 WORKSH INT TECHN, P73; Gabber E, 1999, COMMUN ACM, V42, P42, DOI 10.1145/293411.293447; Gertner Y., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276723; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Goldreich O., 1987, P 19 ANN ACM S THEOR, P218, DOI 10.1145/28395.28420; Goldschlag D., 1999, COMMUN ACM, V42, P84; GREENSPAN R, 2004, SURFERS PREFER PERSO; Grossklags J., 2001, P 3 ACM C EL COMM TA, P38, DOI DOI 10.1145/501158.501163; *HARR INT, 2000, SURV CONS PRIV ATT B; *HARR INT, 2003, MOST PEOPL AR PRIV P; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; JHA S, 2005, P 10 EUR S RES COMP; KATZ J, 2004, P CRYPTO, P335; Kilian J., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/62212.62215; Kobsa A, 2001, KNOWL ENG REV, V16, P111, DOI 10.1017/S0269888901000108; Kushilevitz E., 1997, Proceedings. 38th Annual Symposium on Foundations of Computer Science (Cat. No.97CB36150), DOI 10.1109/SFCS.1997.646125; Lam SK, 2004, P 13 INT C WORLD WID, P393, DOI 10.1145/988672.988726; Lynn B., 2004, P EUR 2004, P20; MALKHI D, 2004, P US SEC S SAN DIEG, P9; Meregu S., 2003, P 3 IEEE INT C DAT M, P211; Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618; MOBASHER B, 2005, P 3 INT WORKSH INT T; Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Pedersen T. P., 1991, P EUR 91, P522; Pennock D., 2000, P 16 C UNC ART INT S, P473; Perkowitz M., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Pierrakos D, 2003, USER MODEL USER-ADAP, V13, P311, DOI 10.1023/A:1026238916441; Polat H, 2005, INT J ELECTRON COMM, V9, P9; PRETSCHNER A, 1999, FY2000TR1359101 ITTC; Resnick P., 1994, P ACM C COMP SUPP CO, P175, DOI DOI 10.1145/192844.192905; *ROY MORG RES, 2001, PRIV COMM; Rucker J, 1997, COMMUN ACM, V40, P73, DOI 10.1145/245108.245125; Salinger J., 1951, CATCHER RYE; SANDER T, 1998, P IEEE S SEC PRIV OA, P162; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; Schafer J.B., 1999, P 1 ACM C EL COMM DE, P158, DOI DOI 10.1145/336992.337035; SURYAVANSHI BS, 2005, P 3 WORKSH INT TECHN, P1; Teltzrow M., 2004, DESIGNING PERSONALIZ, P315; Turban E., 2006, ELECT COMMERCE MANAG; *UMR, 2001, PRIV CONC LOOM LARG; VERYKIOS VS, 2004, ACM SIGMOD RECORD, V33, P50, DOI DOI 10.1145/974121.974131; Westin A. F., 1967, PRIVACY FREEDOM; Yao A., 1986, P 27 IEEE S FDN COMP, P162, DOI DOI 10.1109/SFCS.1986.25; Yao Andrew Chi-Chih, 1982, P 23 IEEE S FDN COMP, P160, DOI DOI 10.1109/SFCS.1982.88; Zhu K, 2004, MANAGE SCI, V50, P670, DOI 10.1287/mnsc.1040.0226	78	10	11	0	6	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1615-5262			INT J INF SECUR	Int. J. Inf. Secur.	OCT	2008	7	5					307	334		10.1007/s10207-007-0049-3		28	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	354WV	WOS:000259671500001		
J	Laguia, M; Castro, JL				Laguia, Manuel; Castro, Juan Luis			Local distance-based classification	KNOWLEDGE-BASED SYSTEMS			English	Article						Distance measure; k-NN; Classification; Similarity; Machine learning	NEAREST-NEIGHBOR; LEARNING ALGORITHMS	In this paper, we have introduced a new method in which every training point learns what is happening in its neighborhood. So, a hyperplane is learned and associated to each point. With this hyperplane we can define the bands distance, a distance measure that bring closer or move away points depending on its classes. We have used this new distance in classification tasks and have performed tests over 68 datasets: IS well-known UCI-Repository datasets, one private dataset, and 49 ad hoc synthetic datasets. We have used 10-fold cross-validation and, in order to compare the results of the classifiers, we have considered the mean accuracy and have also performed a paired two-tailored t-Student's test with a significance level of 95%. The results are encouraging and confirm the good behavior of the new proposed classification method. The bands distance has obtained the best overall results with 1-NN and k-NN classifiers when compared with other distances. Finally, we extract conclusions and outline some lines of future work. (c) 2008 Elsevier B.V. All rights reserved.	[Laguia, Manuel] Univ Cadiz, ES Ingn Cadiz, Dept Lenguajes & Sistemas Informat, Cadiz 11002, Spain; [Castro, Juan Luis] Univ Granada, ETS Ingn Informat, Dept C Comp & Inteligencia Artificial, E-18071 Granada, Spain	Laguia, M (reprint author), Univ Cadiz, ES Ingn Cadiz, Dept Lenguajes & Sistemas Informat, Cadiz 11002, Spain.	manuel.laguia@uca.es; castro@decsai.ugr.es	Castro, Juan Luis/C-2403-2012; 	Laguia Bonillo, Manuel/0000-0002-7117-4759			AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake C, 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Domingos P, 1997, ARTIF INTELL REV, V11, P227; Fix E., 1951, 4 US AIR FORC SCH AV; LAGUIA M, 2005, 11 WORLD C INT FUZZ; LAGUIA M, 2001, C EUR SOC FUZZ LOG T; LAGUIA M, 2007, MATHWARE SOFT COMPUT, V14, P5; PLAZA E, 1996, 3 EUR WORKSH CAS BAS; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; RICCI F, 1995, 1 INT C ICCBR 95, P301; RITCHER MM, 1995, MATH STAT METHODS AR, P171; RITCHER MM, 1992, 16 JAHR GES KLASS GF; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Weiss SM, 1991, COMPUTER SYSTEMS LEA; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Wettschereck D, 1994, THESIS OREGON STATE; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	22	9	9	0	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	OCT	2008	21	7					692	703		10.1016/j.knosys.2008.03.050		12	Computer Science, Artificial Intelligence	Computer Science	362RC	WOS:000260213800020		
J	Xu, RW; He, L				Xu, Rongwu; He, Lin			GACEM: Genetic Algorithm Based Classifier Ensemble in a Multi-sensor System	SENSORS			English	Article						Genetic algorithm; classifier ensemble; multi-sensor system; optimization; fusion	NEURAL-NETWORKS; DATA FUSION; PERFORMANCE; COMBINATION; TRACKING	Multi-sensor systems (MSS) have been increasingly applied in pattern classification while searching for the optimal classification framework is still an open problem. The development of the classifier ensemble seems to provide a promising solution. The classifier ensemble is a learning paradigm where many classifiers are jointly used to solve a problem, which has been proven an effective method for enhancing the classification ability. In this paper, by introducing the concept of Meta-feature (MF) and Trans-function (TF) for describing the relationship between the nature and the measurement of the observed phenomenon, classification in a multi-sensor system can be unified in the classifier ensemble framework. Then an approach called Genetic Algorithm based Classifier Ensemble in Multi-sensor system (GACEM) is presented, where a genetic algorithm is utilized for optimization of both the selection of features subset and the decision combination simultaneously. GACEM trains a number of classifiers based on different combinations of feature vectors at first and then selects the classifiers whose weight is higher than the pre-set threshold to make up the ensemble. An empirical study shows that, compared with the conventional feature-level voting and decision-level voting, not only can GACEM achieve better and more robust performance, but also simplify the system markedly.	[Xu, Rongwu; He, Lin] Naval Univ Engn, Inst Noise & Vibrat, Wuhan 430033, Peoples R China	He, L (reprint author), Naval Univ Engn, Inst Noise & Vibrat, Wuhan 430033, Peoples R China.	r.xu@ieee.org; helin202@public.wh.hb.cn			National Natural Science Foundation of P. R. China [50775218]	This work was supported by the National Natural Science Foundation of P. R. China under Grant No. 50775218. And the authors would like to thank the anonymous referees for many useful comments and suggestions.	Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Brooks RR, 2003, P IEEE, V91, P1163, DOI 10.1109/JPROC.2003.814923; Buczak AL, 1996, INFORM SCIENCES, V93, P265, DOI 10.1016/0020-0255(96)00078-3; CLOUQUEUR T, 2001, P 4 ANN C INF FUS; COSTA AD, 2003, INT C AC SPEECH SIGN, P832; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 1997, AI MAG, V18, P97; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Gardner JW, 2005, SENSOR ACTUAT B-CHEM, V106, P114, DOI 10.1016/j.snb.2004.05.043; Hall DL, 1997, P IEEE, V85, P6, DOI 10.1109/5.554205; KACALENGA R, 2003, IEEE AEROSPACE ELECT, V18, P13; Kittler J, 1997, PATTERN RECOGN LETT, V18, P845, DOI 10.1016/S0167-8655(97)00062-7; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KITTLER J, 2001, P DERA IEE WORKSH IN, P1; Kuncheva LI, 2000, IEEE T EVOLUT COMPUT, V4, P327, DOI 10.1109/4235.887233; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Lawrence RL, 2001, PHOTOGRAMM ENG REM S, V67, P1137; Lin XF, 2003, PATTERN RECOGN LETT, V24, P1959, DOI 10.1016/S0167-8655(03)00035-7; Luo RC, 2002, IEEE SENS J, V2, P107, DOI 10.1109/JSEN.2002.1000251; Maslov IV, 2006, INFORM FUSION, V7, P304, DOI 10.1016/j.inffus.2005.01.001; Narasimhamurthy A, 2005, IEEE T PATTERN ANAL, V27, P1988, DOI 10.1109/TPAMI.2005.249; PERRONE MP, 1993, IMPROVING REGRESSION; POLIKAR R, 2006, SAS 2006 IEEE SENS A, P180; RAJAGOPAL R, 1990, INT CONF ACOUST SPEE, P2911, DOI 10.1109/ICASSP.1990.116235; ROLI F, 2001, P SPIE IM SIGN PROC, P103; Roli F., 2001, P 2 INT WORKSH MULT, P78; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Schapire R. E., 1999, P 16 INT JOINT C ART, P1401; SETO ML, 2004, UNDERWATER DEFENCE T, P1; Smith D, 2006, IEEE T KNOWL DATA EN, V18, P1696, DOI 10.1109/TKDE.2006.183; Tumer K., 1999, COMBINING ARTIFICIAL, P127; Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759; Worden K, 2001, ENG STRUCT, V23, P885, DOI 10.1016/S0141-0296(00)00118-8; Xu Rongwu, 2008, Chinese Journal of Mechanical Engineering, V44, DOI 10.3901/JME.2008.07.151; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	37	2	2	0	2	MOLECULAR DIVERSITY PRESERVATION INTERNATIONAL-MDPI	BASEL	KANDERERSTRASSE 25, CH-4057 BASEL, SWITZERLAND	1424-8220			SENSORS-BASEL	Sensors	OCT	2008	8	10					6203	6224		10.3390/s8106203		22	Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation	Chemistry; Electrochemistry; Instruments & Instrumentation	366TB	WOS:000260505200006		
J	Oentaryo, RJ; Pasquier, M; Quek, C				Oentaryo, R. J.; Pasquier, M.; Quek, C.			GenSoFNN-Yager: A novel brain-inspired generic self-organizing neuro-fuzzy system realizing Yager inference	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						decision support system; declarative knowledge; hippocampus; rule induction; sequential learning; neuro-fuzzy system; Yager inference scheme	NETWORK; IDENTIFICATION; MEMORY; LOGIC	Pattern recognition is increasingly becoming a key component of decision support systems (DSSs) in many application areas, especially when automatically extracting semantic rules from data is a chief concern. Accordingly, this paper presents a novel evolving neuro-fuzzy DSS, the generic self-organizing fuzzy neural network realizing Yager inference (GenSoFNN-Yager), that emulates the sequential learning paradigm of the hippocampus in the brain to synthesize from low-level numerical data to high-level declarative fuzzy rules. The proposed system exhibits simple and conceptually firm computational steps that correspond closely to a plausible human logical reasoning and decision-making. Experimental results on sample benchmark problems and realistic medical diagnosis applications show the potential of the proposed system as a competent DSS. (C) 2007 Elsevier Ltd. All rights reserved.	[Oentaryo, R. J.; Pasquier, M.; Quek, C.] Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Singapore 639798, Singapore	Quek, C (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Computat Intelligence, Nanyang Ave, Singapore 639798, Singapore.	ashcquek@ntu.edu.sg	Oentaryo, Richard/M-5948-2014	Oentaryo, Richard/0000-0002-4662-1561			ALON U, 1999, P NATL ACAD SCI USA, V96, P5745; Anderson J., 1983, ARCHITECTURE COGNITI; Asuncion A., 2007, UCI MACHINE LEARNING; Bishop C.M., 1995, NEURAL NETWORKS PATT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damasio A. R., 1996, NEUROBIOLOGY DECISIO, V1st; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dubois D, 1996, FUZZY SET SYST, V84, P169, DOI 10.1016/0165-0114(96)00066-8; Eichenbaum H., 2002, COGNITIVE NEUROSCIEN; Fisher RA, 1936, ANN EUGENIC, V7, P179; Gluck MA, 2003, TRENDS COGN SCI, V7, P269, DOI 10.1016/S1364-6613(03)00105-0; KELLER JM, 1992, FUZZY SET SYST, V45, P1, DOI 10.1016/0165-0114(92)90086-J; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Lin CJ, 1997, IEEE T FUZZY SYST, V5, P477; Lin C.-T., 1996, NEURAL FUZZY SYSTEMS; Mamdani EH, 1999, INT J HUM-COMPUT ST, V51, P135, DOI 10.1006/ijhc.1973.0303; Mantaras R.L.D., 1990, APPROXIMATE REASONIN; Michalski R. S., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence; OENTARYO RJ, 2005, C2ITR00205 NAN TECHN; OENTARYO RJ, 2004, P 8 IEEE INT C CONTR, V2, P1005; OENTARYO RJ, 2006, P IEEE INT JOINT C N, P1684; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; Pasquier M, 2001, NEURAL NETWORKS, V14, P1099, DOI 10.1016/S0893-6080(01)00048-X; PASQUIER M, INT J VEHIC IN PRESS; Quek C, 2005, EXPERT SYST APPL, V29, P229, DOI 10.1016/j.eswa.2005.03.001; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; SCOVILLE WB, 1957, J NEUROL NEUROSUR PS, V20, P11, DOI 10.1136/jnnp.20.1.11; Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308; Sim J, 2006, IEEE T NEURAL NETWOR, V17, P1394, DOI 10.1109/TNN.2006.880362; Sprague R.H., 1993, DECISION SUPPORT SYS; Squire L, 1984, NEUROBIOLOGY LEARNIN; SUGENO M, 1988, FUZZY SET SYST, V28, P15, DOI 10.1016/0165-0114(88)90113-3; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tomporowski P. D., 2003, PSYCHOL SKILL LIFE S; Tulving E., 1972, ORG MEMORY; Tung WL, 2002, IEEE T NEURAL NETWOR, V13, P1075, DOI 10.1109/TNN.2002.1031940; Tung WL, 2005, ARTIF INTELL MED, V33, P61, DOI 10.1016/j.artmed.2004.03.009; TURKSEN IB, 1990, FUZZY SET SYST, V34, P323, DOI 10.1016/0165-0114(90)90218-U; Zadeh L. A., 1975, FUZZY SETS THEIR APP, P1; Zhou RW, 1996, NEURAL NETWORKS, V9, P1569, DOI 10.1016/S0893-6080(96)00027-5	42	14	14	2	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	NOV	2008	35	4					1825	1840		10.1016/j.eswa.2007.08.108		16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	351OB	WOS:000259432600034		
J	Kang, P; Cho, S				Kang, Pilsung; Cho, Sungzoon			Locally linear reconstruction for instance-based learning	PATTERN RECOGNITION			English	Article						instance-based learning; memory-based reasoning; k-nearest neighbor; weight allocation; local reconstruction	NEAREST-NEIGHBOR CLASSIFICATION; PATTERN-CLASSIFICATION; FACE RECOGNITION; METRICS	Instance-based learning (IBL), so called memory-based reasoning (MBR), is a commonly used nonparametric learning algorithm. k-nearest neighbor (k-NN) learning is the most popular realization of IBL. Due to its usability and adaptability, k-NN has been Successfully applied to a wide range of applications. However, in practice, one has to set important model parameters only empirically: the number of neighbors (k) and weights to those neighbors. In this paper, we propose structured ways to set these parameters, based on locally linear reconstruction (LLR). We then employed sequential minimal optimization (SMO) for solving quadratic programming step involved in LLR for classification to reduce the computational complexity. Experimental results from 11 classification and eight regression tasks were Promising enough to merit further investigation: not only did LLR Outperform the conventional weight allocation methods without much additional computational cost, but also LLR Was found to be robust to the change of k. (C) 2008 Elsevier Ltd. All rights reserved.	[Kang, Pilsung; Cho, Sungzoon] Seoul Natl Univ, Dept Ind Engn, Seoul 151744, South Korea	Cho, S (reprint author), Seoul Natl Univ, Dept Ind Engn, Sari 56-1, Seoul 151744, South Korea.	xfeel80@snu.ac.kr; zoon@snu.ac.kr			Korea Science and Engineering Foundation (KOSEF); Korea government [R01-2005-000-103900-0]; Engineering Research Institute of SNU	This work was supported by the Korea Science and Engineering Foundation (KOSEF) grant funded by the Korea government (R01-2005-000-103900-0), the Brain Korea 21 program in 2007, and partially supported by Engineering Research Institute of SNU.	AHA DW, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P534; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; COPPERSMITH D, 1990, J SYMB COMPUT, V9, P251, DOI 10.1016/S0747-7171(08)80013-2; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding Y., 2006, P 17 AUSTR DAT C, P99; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R O, 2001, PATTERN CLASSIFICATI; FAN JQ, 1994, ANN STAT, V22, P867, DOI 10.1214/aos/1176325499; FEDOROV VV, 1993, NONPARAMETRIC STAT, V2, P355; GOWDA KC, 1991, PATTERN RECOGN LETT, V12, P259; GOWDA KC, 1991, PATTERN RECOGN, V24, P567; Han E.H., 2001, P 5 PAC AS C KNOWL D, P53; Hardie W., 1990, APPL NONPARAMETRIC R; Hastie T, 2001, ELEMENTS STAT LEARNI; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; Hechenbichler K., 2004, 399 LUDW MAX U MUN; HOWE N, 1997, P 2 INT C CAS BAS RE, P455; ICHINO M, 1994, IEEE T SYST MAN CYB, V24, P698, DOI 10.1109/21.286391; Jiang SY, 2006, PATTERN RECOGN LETT, V27, P802, DOI 10.1016/j.patrec.2005.11.007; Jing XY, 2006, PATTERN RECOGN LETT, V27, P1465, DOI 10.1016/j.patrec.2006.02.050; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mitchell T. M., 1997, MACHINE LEARNING; MOHAN BK, 2006, P ACM C EL COMM, P250, DOI 10.1145/1134707.1134735; O'Mahony M., 2004, ACM T INTERNET TECHN, V4, P344, DOI 10.1145/1031114.1031116; OSUNA E, 1997, P IEEE WORKSH NEUR N, P276; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Platt J, 1998, ADV KERNEL METHODS S, P41; Roweis S., 2003, J MACHINE LEARNING R, V4, P119; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; RUPRECHT D, 1994, 539 U DORTM; Sarwar B, 2000, P 2 ACM C EL COMM, P158, DOI DOI 10.1145/352871.352887; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Vapnik V. N., 1982, ESTIMATION DEPENDENC; Vijayakumar S., 2006, NEAREST NEIGHBOR MET, P103; WAND MP, 1990, CAN J STAT, V18, P197, DOI 10.2307/3315450; WANG ZY, 1994, ANAL CHEM, V66, P249, DOI 10.1021/ac00074a012; Wolberg G, 1990, DIGITAL IMAGE WARPIN; Xue G., 2005, P 28 ANN INT ACM SIG, P114, DOI 10.1145/1076034.1076056; Zhang XX, 2006, PATTERN RECOGN LETT, V27, P1927, DOI 10.1016/j.patrec.2006.03.015	40	26	27	3	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	NOV	2008	41	11					3507	3518		10.1016/j.patcog.2008.04.009		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	342XV	WOS:000258817800022		
J	Villa, JL; Boque, R; Ferre, J				Villa, Joe Luis; Boque, Ricard; Ferre, Joan			Calculation of the probability of correct classification in probabilistic bagged k-Nearest Neighbours	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Classification; Nearest neighbours; Bootstrap; Probability of classification; Reliability	PATTERN-RECOGNITION; BOOTSTRAP METHODS; PREDICTION ERROR; CLASSIFIERS; SPECTRA; DESIGN; TREE	This paper presents a new method for computing the probability of correct classification for the k-Nearest Neighbours (kNN) method. The method uses bootstrap to provide the posterior probability which a new object is classified with. This is a measure of the reliability of the classification: it increases as the test object is closer to the training objects of a given class and is more sensitive to the position of the test object in the calibration space than the classical measure of posterior probability in kNN. This reliability of the classification is also used to derive a new rule for classification. (C) 2008 Elsevier B.V. All rights reserved.	[Villa, Joe Luis; Boque, Ricard; Ferre, Joan] Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, Tarragona 43007, Catalonia, Spain	Boque, R (reprint author), Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, C Marcel Li Domingo S-N, Tarragona 43007, Catalonia, Spain.	ricard.boque@urv.cat	Ferre Baldrich, Joan/L-5172-2014	Ferre Baldrich, Joan/0000-0001-6240-413X	Department of Universities, Research and information Society of Catalonia - Spain; Spanish Ministry of Education and Science [CTQ2007-66918]	The authors thank support of Department of Universities, Research and information Society of Catalonia - Spain, for providing Joe Luis Villa's doctoral fellowship and project CTQ2007-66918 of the Spanish Ministry of Education and Science.	Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Asuncion A., 2007, UCI MACHINE LEARNING; Beckonert O, 2003, ANAL CHIM ACTA, V490, P3, DOI 10.1016/S0003-2670(03)00060-6; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caprile B, 2004, LECT NOTES COMPUT SC, V3077, P72; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda RO, 2001, PATTERN CLASSIFICATI, V2nd, P654, DOI DOI 10.1007/S00357-007-0015-9; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Fisher RA, 1936, ANN EUGENIC, V7, P179; FORINA M, 2008, PARVUS OFFICIAL WEB; FORINA M, 1986, VITIS, V25, P189; Gurov S. I., 2004, Computational Mathematics and Modeling, V15, DOI 10.1023/B:COMI.0000047346.87442.ef; Hall P, 2005, J ROY STAT SOC B, V67, P363, DOI 10.1111/j.1467-9868.2005.00506.x; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; HINKLEY DV, 1988, J ROY STAT SOC B MET, V50, P321; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; KENNARD RW, 1969, TECHNOMETRICS, V11, P137, DOI 10.2307/1266770; Lei S, 2003, IEEE T SOFTWARE ENG, V29, P996; Lukasiak BM, 2006, ANALYST, V131, P73, DOI 10.1039/b510561g; Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499; PARTHASARATHY G, 1990, IEEE T SYST MAN CYB, V20, P715, DOI 10.1109/21.57285; Pirogov AV, 1998, ANAL CHIM ACTA, V369, P47, DOI 10.1016/S0003-2670(98)00210-4; Ros F, 1997, J CHEMOMETR, V11, P483, DOI 10.1002/(SICI)1099-128X(199711/12)11:6<483::AID-CEM490>3.0.CO;2-8; Steele BM, 2000, STAT COMPUT, V10, P349, DOI 10.1023/A:1008933626919; Tibshirani R, 1993, INTRO BOOTSTRAP; TODESCHINI R, 1992, CHEMOMETR INTELL LAB, V16, P25, DOI 10.1016/0169-7439(92)80075-F; TODESCHINI R, 1990, CHEMOMETR INTELL LAB, V9, P201, DOI 10.1016/0169-7439(90)80098-Q; Todeschini R, 2007, CHEMOMETR INTELL LAB, V87, P3, DOI 10.1016/j.chemolab.2005.11.001; Viswanath P, 2005, PATTERN RECOGN, V38, P1187, DOI 10.1016/j.patcog.2004.10.007; Webb AR, 2002, STAT PATTERN RECOGNI; Wehrens R, 2000, CHEMOMETR INTELL LAB, V54, P35, DOI 10.1016/S0169-7439(00)00102-7; Wu W, 1997, ANAL CHIM ACTA, V349, P253, DOI 10.1016/S0003-2670(97)00285-7	33	3	3	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	NOV 15	2008	94	1					51	59		10.1016/j.chemolab.2008.06.007		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	408OD	WOS:000263443400006		
J	Tanriverdi, S; Grinberg, A; Chalmers, RM; Hunter, PR; Petrovic, Z; Akiyoshi, DE; London, E; Zhang, LH; Tzipori, S; Tumwine, JK; Widmer, G				Tanriverdi, Sultan; Grinberg, Alex; Chalmers, Rachel M.; Hunter, Paul R.; Petrovic, Zorana; Akiyoshi, Donna E.; London, Eric; Zhang, Linghui; Tzipori, Saul; Tumwine, James K.; Widmer, Giovanni			Inferences about the Global Population Structures of Cryptosporidium parvum and Cryptosporidium hominis	APPLIED AND ENVIRONMENTAL MICROBIOLOGY			English	Article							SUBTYPE ANALYSIS; HEALTHY-ADULTS; SEQUENCE; GENOTYPES; CHILDREN; CALVES; IDENTIFICATION; RECOMBINATION; APICOMPLEXAN; GLYCOPROTEIN	Cryptosporidium parvum and Cryptosporidium hominis are two related species of apicomplexan protozoa responsible for the majority of human cases of cryptosporidiosis. In spite of their considerable public health impact, little is known about the population structures of these species. In this study, a battery of C. parvum and C. hominis isolates from seven countries was genotyped using a nine-locus DNA subtyping scheme. To assess the existence of geographical partitions, the multilocus genotype data were mined using a cluster analysis based on the nearest-neighbor principle. Within each country, the population genetic structures were explored by combining diversity statistical tests, linkage disequilibrium, and eBURST analysis. For both parasite species, a quasi-complete phylogenetic segregation was observed among the countries. Cluster analysis accurately identified recently introduced isolates. Rather than conforming to a strict paradigm of either a clonal or a panmictic population structure, data are consistent with a flexible reproductive strategy characterized by the cooccurrence of both propagation patterns. The relative contribution of each pattern appears to vary between the regions, perhaps dependent on the prevailing ecological determinants of transmission.	[Tanriverdi, Sultan; Akiyoshi, Donna E.; London, Eric; Zhang, Linghui; Tzipori, Saul; Widmer, Giovanni] Tufts Cummings Sch Vet Med, Div Infect Dis, North Grafton, MA 01536 USA; [Grinberg, Alex] Massey Univ, Inst Vet Anim & Biomed Sci, Palmerston North, New Zealand; [Chalmers, Rachel M.] Singleton Hosp, NPHS Microbiol Swansea, United Kingdom Cryptosporidium Reference Unit, Swansea SA2 8QA, W Glam, Wales; [Hunter, Paul R.] Univ E Anglia, Sch Med Hlth Policy & Practice, Norwich NR4 7TJ, Norfolk, England; [Petrovic, Zorana] Univ Belgrade, Fac Vet Med, Belgrade, Serbia; [Tumwine, James K.] Makerere Univ, Dept Pediat & Child Hlth, Sch Med, Kampala, Uganda; [Tumwine, James K.] Mulago Hosp, Kampala, Uganda	Widmer, G (reprint author), Tufts Cummings Sch Vet Med, Div Infect Dis, 200 Westboro Rd, North Grafton, MA 01536 USA.	giovanni.widmer@tufts.edu	Hunter, Paul/A-7172-2008	Hunter, Paul/0000-0002-5608-6144	National Institutes of Allergy and Infectious Diseases [AI052781]	Funding from the National Institutes of Allergy and Infectious Diseases (AI052781) is gratefully acknowledged.	Abrahamsen MS, 2004, SCIENCE, V304, P441, DOI 10.1126/science.1094786; Akiyoshi DE, 2002, INFECT IMMUN, V70, P5670, DOI 10.1128/IAI.70.10.5670-5675.2002; Caccio S, 2000, PARASITOLOGY, V120, P237, DOI 10.1017/S0031182099005508; Caccio S, 2001, INT J PARASITOL, V31, P1082, DOI 10.1016/S0020-7519(01)00233-8; Cevallos AM, 2000, INFECT IMMUN, V68, P5167, DOI 10.1128/IAI.68.9.5167-5175.2000; Chalmers RM, 2008, EMERG INFECT DIS, V14, P496, DOI 10.3201/eid1403.071320; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Elwin K, 2001, APPL ENVIRON MICROB, V67, P5581, DOI 10.1128/AEM.67.12.5581-5584.2001; Enemark HL, 2002, PARASITOLOGY, V125, P331, DOI 10.1017/S0031182002002226; Feil EJ, 2001, ANNU REV MICROBIOL, V55, P561, DOI 10.1146/annurev.micro.55.1.561; Feil EJ, 2004, J BACTERIOL, V186, P1518, DOI 10.1128/JB.186.5.1518-1530.2004; Gatei W, 2006, J EUKARYOT MICROBIOL, V53, pS43, DOI 10.1111/j.1550-7408.2006.00169.x; Gatei W, 2007, INFECT GENET EVOL, V7, P197, DOI 10.1016/j.meegid.2006.08.006; Geurden T, 2007, PARASITOLOGY, V134, P1981, DOI 10.1017/S0031182007003460; Gilbert M, 2005, NATURE, V435, P491, DOI 10.1038/nature03548; Grinberg A, 2008, EPIDEMIOL INFECT, V136, P273, DOI 10.1017/S0950268807008345; HAMMING RW, 1950, AT&T TECH J, V29, P147; Haubold B, 2000, BIOINFORMATICS, V16, P847, DOI 10.1093/bioinformatics/16.9.847; Hughes JB, 2001, APPL ENVIRON MICROB, V67, P4399, DOI 10.1128/AEM.67.10.4399-4406.2001; Hunter PR, 2004, EMERG INFECT DIS, V10, P1241; Hunter PR, 2007, EMERG INFECT DIS, V13, P82; Magurran A. E., 2004, MEASURING BIOL DIVER; Mallon M, 2003, J MOL EVOL, V56, P407, DOI 10.1007/s00239-002-2412-3; Mallon ME, 2003, INFECT GENET EVOL, V3, P207, DOI 10.1016/S1567-1348(03)00089-3; Misic Z, 2007, PARASITOLOGY, V134, P351, DOI 10.1017/S0031182006001508; Morrison LJ, 2008, INFECT GENET EVOL, V8, P121, DOI 10.1016/j.meegid.2007.10.010; Ngouanesavanh T, 2006, J EUKARYOT MICROBIOL, V53, pS33, DOI 10.1111/j.1550-7408.2006.00166.x; Okhuysen PC, 1999, J INFECT DIS, V180, P1275, DOI 10.1086/315033; Okhuysen PC, 2002, J INFECT DIS, V185, P1320, DOI 10.1086/340132; SMITH JM, 1993, P NATL ACAD SCI USA, V90, P4384, DOI 10.1073/pnas.90.10.4384; Spano F, 1997, FEMS MICROBIOL LETT, V150, P209, DOI 10.1016/S0378-1097(97)00115-8; Strong WB, 2000, INFECT IMMUN, V68, P4117, DOI 10.1128/IAI.68.7.4117-4134.2000; Tanriverdi S, 2006, APPL ENVIRON MICROB, V72, P2507, DOI 10.1128/AEM.72.4.2507-2513.2006; Tanriverdi S, 2006, INFECT GENET EVOL, V6, P113, DOI 10.1016/j.meegid.2005.02.002; Tanriverdi S, 2007, MOL MICROBIOL, V63, P1432, DOI 10.1111/j.1365-2958.2007.05594.x; Tanriverdi S, 2003, MOL BIOCHEM PARASIT, V130, P13, DOI 10.1016/S0166-6851(03)00138-5; Tumwine JK, 2003, AM J TROP MED HYG, V68, P710; Tumwine JK, 2005, AM J TROP MED HYG, V73, P921; Turner KME, 2007, BMC MICROBIOL, V7, DOI 10.1186/1471-2180-7-30; WHITTAKE.RH, 1965, SCIENCE, V147, P250, DOI 10.1126/science.147.3655.250; Widmer G, 1998, J INFECT DIS, V178, P834; Xiao LH, 2004, CLIN MICROBIOL REV, V17, P72, DOI 10.1128/CMR.17.1.72-97.2004	42	27	27	1	10	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	0099-2240			APPL ENVIRON MICROB	Appl. Environ. Microbiol.	DEC	2008	74	23					7227	7234		10.1128/AEM.01576-08		8	Biotechnology & Applied Microbiology; Microbiology	Biotechnology & Applied Microbiology; Microbiology	374FZ	WOS:000261030400017	18836013	
J	Myrick, AJ; Park, KC; Hetling, JR; Baker, TC				Myrick, A. J.; Park, K-C; Hetling, J. R.; Baker, T. C.			Real-time odor discrimination using a bioelectronic sensor array based on the insect electroantennogram	BIOINSPIRATION & BIOMIMETICS			English	Article							BAYES-RISK-ESTIMATION; PATTERN-CLASSIFICATION; RECEPTOR-CELLS; SEX-PHEROMONES; MOTH; ATTRACTANT; OLFACTION; RESPONSES; ERROR; NOSE	Current trends in artificial nose research are strongly influenced by knowledge of biological olfactory systems. Insects have evolved over millions of years to detect and maneuver toward a food source or mate, or away from predators. The insect olfactory system is able to identify volatiles on a time scale that matches their ability to maneuver. Here, biological olfactory sense organs, insect antennae, have been exploited in a hybrid-device biosensor, demonstrating the ability to identify individual strands of odor in a plume passing over the sensor on a sub-second time scale. A portable system was designed to utilize the electrophysiological responses recorded from a sensor array composed of male or female antennae from four or eight different species of insects (a multi-channel electroantennogram, EAG). A computational analysis strategy that allows discrimination between odors in real time is described in detail. Following a training period, both semi-parametric and k-nearest neighbor (k-NN) classifiers with the ability to discard ambiguous responses are applied toward the classification of up to eight odors. EAG responses to individual strands in an odor plume are classified or discarded as ambiguous with a delay (sensor response to classification report) on the order of 1 s. The dependence of classification error rate on several parameters is described. Finally, the performance of the approach is compared to that of a minimal conditional risk classifier.	[Myrick, A. J.; Hetling, J. R.] Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA; [Park, K-C; Baker, T. C.] Penn State Univ, Dept Entomol, Chem Ecol Lab, University Pk, PA 16802 USA	Myrick, AJ (reprint author), Univ Illinois, Dept Bioengn, SEO 232,MC 063,851 S Morgan St, Chicago, IL 60607 USA.				Defense Advanced Research Projects Agency (DARPA); Office of Naval Research (ONR); Defense Threat Reduction Agency (DTRA); Keystone Alliance grant from the State of Pennsylvania	This research was initially funded by the Controlled Biological Systems Program of Defense Advanced Research Projects Agency (DARPA). It was subsequently funded by the Office of Naval Research (ONR) and the Defense Threat Reduction Agency (DTRA), through grants to TCB at Iowa State University (DARPA) and at Penn State University (ONR Counter-IED Program; DTRA). This research was also supported by a Keystone Alliance grant from the State of Pennsylvania, through Penn State University. The authors would like to thank Bryan Banks, Penn State University, for rearing the test insects and for his after-hours assistance in setting up the wind tunnel for humidification. We would also like to thank Emily Kuhns, Penn State University, for insects used in this study.	ANDERSON PAV, 1985, BRAIN RES, V338, P273, DOI 10.1016/0006-8993(85)90157-X; Arshak K., 2004, Sensor Review, V24, DOI 10.1108/02602280410525977; Arshak K., 2003, Sensor Review, V23, DOI 10.1108/02602280310496854; BAKER TC, 1989, PHYSIOL ENTOMOL, V14, P1, DOI 10.1111/j.1365-3032.1989.tb00931.x; BAUM CW, 1992, IEEE T COMMUN, V40, P1231, DOI 10.1109/26.153368; BERGER RS, 1966, ANN ENTOMOL SOC AM, V59, P767; BROWN TA, 1979, IEEE T INFORM THEORY, V25, P617, DOI 10.1109/TIT.1979.1056092; CHEN Z, 1977, IEEE T SYST MAN CYB, V7, P651, DOI 10.1109/TSMC.1977.4309802; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dickinson TA, 1998, TRENDS BIOTECHNOL, V16, P250, DOI 10.1016/S0167-7799(98)01185-8; PERSAUD K, 1982, NATURE, V299, P352, DOI 10.1038/299352a0; FRALICK SC, 1971, IEEE T INFORM THEORY, V17, P440, DOI 10.1109/TIT.1971.1054663; French AS, 2007, CHEM SENSES, V32, P681, DOI 10.1093/chemse/bjm035; Galan RF, 2004, NEURAL COMPUT, V16, P999, DOI 10.1162/089976604773135078; GETCHELL TV, 1984, PROG NEUROBIOL, V23, P317, DOI 10.1016/0301-0082(84)90008-X; Gose E., 1996, PATTERN RECOGNITION; Grate JW, 2000, CHEM REV, V100, P2627, DOI 10.1021/cr980094j; Greiner B, 2004, J COMP NEUROL, V475, P202, DOI 10.1002/cne.20173; HETLING JR, 2003, P 1 INT IEEE EMBS C; HILL A, 1974, ENVIRON ENTOMOL, V3, P249; Hodges J., 1951, 4 USAF SCH AV MED, P261; Justus KA, 2005, J NEUROPHYSIOL, V93, P2233, DOI 10.1152/jn.00888.2004; Karagiannopoulos M. G., 2007, MED 07 MED C 27 29 J, P1; KARG G, 1995, J CHEM ECOL, V21, P1299, DOI 10.1007/BF02027563; KRISHNAN T, 2001, PATTERN RECOGN, P25, DOI 10.1142/9789812386533_0002; LILJEFORS T, 1985, J CHEM SOC P2, V12, P1957; LILJEFORS T, 1987, J CHEM ECOL, V13, P2023, DOI 10.1007/BF01041729; LILJEFORS T, 1984, J CHEM ECOL, V10, P1661, DOI 10.1007/BF00987353; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MARTIN EC, 2002, CELL, V102, P243; MILLER JR, 1978, J CHEM ECOL, V4, P178; Murray GM, 2002, IEEE INSTRU MEAS MAG, V5, P12, DOI 10.1109/MIM.2002.1048978; MYRICK AJ, 2005, P 2 INT IEEE EMBS C; Park KC, 2002, CHEM SENSES, V27, P343, DOI 10.1093/chemse/27.4.343; Pearce T. C., 2002, HDB MACHINE OLFACTIO; POPE MM, 1984, J INSECT PHYSIOL, V30, P943; Principe JC, 1998, IEEE T AERO ELEC SYS, V34, P706, DOI 10.1109/7.705880; ROELOFS W, 1971, SCIENCE, V174, P297, DOI 10.1126/science.174.4006.297; ROELOFS WL, 1985, J CHEM ECOL, V11, P829, DOI 10.1007/BF01012071; SCHILD D, 1988, BIOPHYS J, V54, P1001; Shaffer RE, 1999, ANAL CHIM ACTA, V384, P305, DOI 10.1016/S0003-2670(98)00780-6; SHANMUGA.K, 1971, IEEE T SYST MAN CYB, VSMC1, P223, DOI 10.1109/TSMC.1971.4308289; Shields VDC, 2001, MICROSC RES TECHNIQ, V55, P307, DOI 10.1002/jemt.1180; Silverman B. W., 1986, DENSITY ESTIMATION; Solis JL, 2005, IEEE SENS J, V5, P1338, DOI 10.1109/JSEN.2005.857882; Tan SL, 2006, IEE P-SCI MEAS TECH, V153, P94, DOI 10.1049/ip-smt:20050035; Tegoni M, 2004, TRENDS BIOCHEM SCI, V29, P257, DOI 10.1016/j.tibs.2004.03.003; Theodoridis S., 1999, PATTERN RECOGNITION; Torre V, 1995, J NEUROSCI, V15, P7757; van der Pers JNC, 1998, ENTOMOL EXP APPL, V87, P209; Ziegler C, 1998, BIOSENS BIOELECTRON, V13, P539, DOI 10.1016/S0956-5663(97)00093-6	53	8	8	4	8	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	1748-3182			BIOINSPIR BIOMIM	Bioinspir. Biomim.	DEC	2008	3	4							046006	10.1088/1748-3182/3/4/046006		19	Engineering, Multidisciplinary; Materials Science, Biomaterials; Robotics	Engineering; Materials Science; Robotics	377OG	WOS:000261259900006	18997275	
J	Chuang, LY; Yang, CS; Li, JC; Yang, CH				Chuang, Li-Yeh; Yang, Cheng-San; Li, Jung-Chike; Yang, Cheng-Hong			COMBAT GA-BASED GENE SELECTION FOR CLASSIFICATION OF MICROARRAY DATA	BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS			English	Article						Feature selection; microarray data; combat genetic algorithm; K-nearest neighbor; leave-one-out cross-validation	MULTIPLE CANCER TYPES; EXPRESSION DATA; BREAST-CANCER; DISCRIMINATION; OPTIMIZATION; PREDICTION; PATTERNS; TUMORS	Microarray data can provide valuable results for a variety of gene expression profile problems and contribute to advances in clinical medicine. The application of microarray data on cancer-type classification has recently gained in popularity. The properties of microarray data contain a large number of features ( genes) with high dimensions, and one in the multi-class category. These facts make testing and training of general classification methods difficult. Reducing the number of genes and achieving lower classification error rates are the main issues to be solved. The classification of microarray data samples can be regarded as a feature selection and classifier design problem. The goal of feature selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. Classical genetic algorithms (GAs) may suffer from premature convergence and thus lead to poor experimental results. In this paper, combat genetic algorithm (CGA) is used to implement the feature selection, and a K-nearest neighbor with the leave-one-out cross-validation method serves as a classifier of the CGA fitness function for the classification problem. The proposed method was applied to 10 microarray data sets that were obtained from the literature. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels but also achieved lower classification error rates.	[Li, Jung-Chike; Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 80708, Taiwan; [Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung 80041, Taiwan; [Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 80708, Taiwan.	chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011; Yang, Cheng-Hong/M-7984-2013; Najafi, Ali/K-1113-2015	Yang, Cheng-Hong/0000-0002-2741-0072; 	National Science Council in Taiwan [NSC96-2622-E-151-019CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151004-MY3, NSC95-2221-E-214-087, NSC95-2622-E214-004]	This work is partly supported by the National Science Council in Taiwan under grant NSC96-2622-E-151-019CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151004-MY3, NSC95-2221-E-214-087, and NSC95-2622-E214-004.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Chang JC, 2005, BREAST CANCER RES, V7, P100, DOI 10.1186/bcr1018; CONVER WJ, 1986, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Eksin I., 2001, IEE Proceedings-Software, V148, DOI 10.1049/ip-sen:20010503; Erol OK, 2006, ADV ENG SOFTW, V37, P106, DOI 10.1016/j.advengsoft.2005.04.005; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Holland J. H., 1992, ADAPTATION NATURAL A; Jeffrey Stefanie S, 2005, J Natl Compr Canc Netw, V3, P291; Jirapech-Umpai T, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-148; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Liu XX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-76; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	28	1	1	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	1016-2372	1793-7132		BIOMED ENG-APP BAS C	Biomed. Eng.-Appl. Basis Commun.	DEC	2008	20	6					345	352				8	Engineering, Biomedical	Engineering	390BJ	WOS:000262139000002		
J	Kagie, M; van Wezel, M; Groenen, PJF				Kagie, Martijn; van Wezel, Michiel; Groenen, Patrick J. F.			A graphical shopping interface based on product attributes	DECISION SUPPORT SYSTEMS			English	Article						Recommender systems; Multidimensional scaling; Similarity; Electronic commerce; Case-based reasoning	RECOMMENDER SYSTEMS; MAP	Most recommender systems present recommended products in lists to the user. By doing so, much information is lost about the mutual similarity between recommended products. We propose to represent the mutual similarities of the recommended products in a two dimensional map, where similar products are located close to each other and dissimilar products far apart. As a dissimilarity measure we use an adaptation of Gower's similarity coefficient based on the attributes of a product. Two recommender systems are developed that use this approach. The first, the graphical recommender system, uses a description given by the user in terms of product attributes of an ideal product. The second system, the graphical shopping interface, allows the user to navigate towards the product she wants. We show a prototype application of both systems to MP3-players. (c) 2008 Elsevier B.V. All rights reserved.	[Kagie, Martijn; van Wezel, Michiel; Groenen, Patrick J. F.] Erasmus Univ, Inst Econometr, NL-3000 DR Rotterdam, Netherlands	Kagie, M (reprint author), Erasmus Univ, Inst Econometr, NL-3000 DR Rotterdam, Netherlands.	kagie@few.eur.nl; mvanwezel@few.eur.nl; groenen@few.eur.nl	Groenen, Patrick/D-3667-2009	Groenen, Patrick/0000-0001-6683-8971			Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Arslan B, 2002, MANAG INFORMAT SYST, V6, P999; Ayanso A, 2007, DECIS SUPPORT SYST, V44, P326, DOI 10.1016/j.dss.2007.04.005; Bettman JR, 1998, J CONSUM RES, V25, P187, DOI 10.1086/209535; Borg I., 2005, SPRINGER SERIES STAT, V2nd; Burke R., 2000, ENCY LIB INFORM SYST, V69; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Chaudhuri S., 1999, P 25 INT C VER LARG, P397; Chung WY, 2006, DECIS SUPPORT SYST, V42, P1697, DOI 10.1016/j.dss.2006.02.015; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELEEUW J, 1988, J CLASSIF, V5, P163; DONALDSON J, 2007, P 23 INT C DAT ENG W, P811; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; KAGIE M, 2008, P IUI WORKSH REC COL; Kagie M, 2007, LECT NOTES COMPUT SC, V4655, P89; KELLER I, 2000, P CHI 2000 WORKSH 1; Kohonen T, 2001, SPRINGER SERIES INFO, V30; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Lorenzi F, 2005, LECT NOTES ARTIF INT, V3169, P89; MCGINTY L, 2002, LECT NOTES COMPUTER, V2416, P731; Ong TH, 2005, DECIS SUPPORT SYST, V39, P583, DOI 10.1016/j.dss.2004.03.008; PECENOVIC Z, 2000, LECT NOTES COMPUTER, V1929, P173; Prasad B., 2003, J ELECT COMMERCE RES, V4, P65; Pu P., 2004, P ACM C EL COMM EC 0, P208, DOI 10.1145/988772.988804; RICCI F, 2005, INFORM COMMUNICATION, P172, DOI 10.1007/3-211-27283-6_16; Schafer J. B., 2001, Data Mining and Knowledge Discovery, V5, DOI 10.1023/A:1009804230409; Schneiderman B., 1992, ACM Transactions on Graphics, V11; Schwartz B., 2004, PARADOX CHOICE WHY M; Shimazu H, 2002, ARTIF INTELL REV, V18, P223, DOI 10.1023/A:1020757023711; STAPPERS PJ, 2000, P IEA 2000 HFES 2000; STAPPERS PJ, 1999, HUMAN FACTORS COMPUT, P184; TORGERSON WS, 1952, PSYCHOMETRIKA, V17, P401; Turetken O, 2004, DECIS SUPPORT SYST, V37, P415, DOI 10.1016/S0167-9236(03)00047-2; VANGULIK R, 2004, P 5 INT C MUS INF RE; Yang CC, 2003, DECIS SUPPORT SYST, V35, P89, DOI 10.1016/S0167-9236(02)00101-X	37	5	5	3	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-9236			DECIS SUPPORT SYST	Decis. Support Syst.	DEC	2008	46	1					265	276		10.1016/j.dss.2008.06.011		12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science	Computer Science; Operations Research & Management Science	412EH	WOS:000263706000021		
J	Alippi, C; Roveri, M				Alippi, Cesare; Roveri, Manuel			Just-in-Time Adaptive Classifiers-Part II: Designing the Classifier	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Intelligent systems; learning systems; neural networks; pattern classification	NEAREST-NEIGHBOR RULE; PATTERN-CLASSIFICATION; SYSTEMS; SURVEILLANCE; NETWORKS; SURFACES	Aging effects, environmental changes, thermal drifts, and soft and hard faults affect physical systems by changing their nature and behavior over time. To cope with a process evolution adaptive solutions must be envisaged to track its dynamics; in this direction, adaptive classifiers are generally designed by assuming the stationary hypothesis for the process generating the data with very few results addressing nonstationary environments. This paper proposes a methodology based on k-nearest neighbor (NN) classifiers for designing adaptive classification systems able to react to changing conditions just-in-time (JIT), i.e., exactly when it is needed. k-NN classifiers have been selected for their computational-free training phase, the possibility to easily estimate the model complexity k and keep under control the computational complexity of the classifier through suitable data reduction mechanisms. A JIT classifier requires a temporal detection of a (possible) process deviation (aspect tackled in a companion paper) followed by an adaptive management of the knowledge base (KB) of the classifier to cope with the process change. The novelty of the proposed approach resides in the general framework supporting the real-time update of the KB of the classification system in response to novel information coming from the process both in stationary conditions (accuracy improvement) and in nonstationary ones (process tracking) and in providing a suitable estimate of k. It is shown that the classification system grants consistency once the change targets the process generating the data in a new stationary state, as it is the case in many real applications.	[Alippi, Cesare; Roveri, Manuel] Politecn Milan, Dipartimento Elettr & Informaz, I-20133 Milan, Italy	Alippi, C (reprint author), Politecn Milan, Dipartimento Elettr & Informaz, I-20133 Milan, Italy.	alippi@elet.polimi.it; roveri@elet.polimi.it					Alippi C, 2008, IEEE T NEURAL NETWOR, V19, P1145, DOI 10.1109/TNN.2008.2000082; Alippi C, 2006, IEEE T SYST MAN CY C, V36, P649, DOI 10.1109/TSMCC.2005.855508; Azimi-Sadjadi MR, 2002, IEEE T NEURAL NETWOR, V13, P1099, DOI 10.1109/TNN.2002.1031942; Blake C., UCI MACHINE LEARNING; Bollani M, 2001, APPL SURF SCI, V175, P379, DOI 10.1016/S0169-4332(01)00129-5; Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337; CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P1330, DOI 10.1109/72.471374; Chernoff H., 1972, SEQUENTIAL ANAL OPTI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1996, PROBABILISTIC THEORY; DEVROYE LP, 1979, IEEE T INFORM THEORY, V25, P601, DOI 10.1109/TIT.1979.1056087; DOHERTY LE, 1998, P INT C KNOWL BAS IN, V3, P303; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Fukunaga K., 1972, INTRO STAT PATTERN R; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hautamaki V., 2004, P 17 INT C PATT REC, V3, P430; Iwayama N., 2002, Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition, DOI 10.1109/IWFHR.2002.1030904; Jackson Q, 2001, IEEE T GEOSCI REMOTE, V39, P2664, DOI 10.1109/36.975001; KASABOV N, 2002, P INT C NEUR INF PRO, V2, P590, DOI 10.1109/ICONIP.2002.1198126; KEANS M, 1999, NEURAL COMPUT, V11, P1427; Kohlmorgen J, 2000, BIOL CYBERN, V83, P73, DOI 10.1007/s004220000144; Kuh A, 1997, IEEE T SIGNAL PROCES, V45, P640, DOI 10.1109/78.558480; KUH A, 1999, P IEEE INT JOINT C N, V4, P2406; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Land W. H.  Jr., 1998, Proceedings. IEEE International Joint Symposia on Intelligence and Systems (Cat. No.98EX174), DOI 10.1109/IJSIS.1998.685413; LI P, 1997, P IEEE NAT RAD C SYR, P372; LINGARKAR R, 1990, IEEE T SYST MAN CYB, V20, P606, DOI 10.1109/21.57273; Narducci D, 2003, APPL SURF SCI, V212, P491, DOI 10.1016/S0169-4332(03)00047-3; NIKIFOROV IV, 1995, IEEE T INFORM THEORY, V41, P171, DOI 10.1109/18.370109; Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768; POULSEN RS, 1981, P INT S INF THEOR SA, P1; Rizki MM, 2002, IEEE T EVOLUT COMPUT, V6, P594, DOI 10.1109/TEVC.2002.806167; Robertson P, 1999, IEEE INTELL SYST APP, V14, P30, DOI 10.1109/5254.769882; RUSSEL EL, 2001, FAULT DETECTION DIAG; Rutkowski L, 2004, IEEE T NEURAL NETWOR, V15, P811, DOI 10.1109/TNN.2004.828757; SHAHHOSSEINI H, 2000, P IEEE INT C EL CIRC, V1, P495; Siddique A., 2003, P IEEE INT S DIAGN E, P29; STONE C, 1977, ANN STAT, V8, P1348; TAN SC, 2000, P TENCON SEPT, V1, P13; VIRILI F, 2000, P INT JOINT C NEUR N, V5, P129, DOI 308159105,12,1; Wang JQ, 2004, IEEE T NEURAL NETWOR, V15, P159, DOI 10.1109/TNN.2003.820622; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; ZONGHAI C, 2007, J SYST ENG ELECTRON, V18, P566, DOI 10.1016/S1004-4132(07)60130-3	44	26	29	2	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	DEC	2008	19	12					2053	2064		10.1109/TNN.2008.2003998		12	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	381OD	WOS:000261544900006	19054730	
J	Gil-Pita, R; Yao, X				Gil-Pita, Roberto; Yao, Xin			EVOLVING EDITED k-NEAREST NEIGHBOR CLASSIFIERS	International Journal of Neural Systems			English	Article	8th International Conference on Intelligent Data Engineering and Automated Learning	DEC 16-19, 2007	Birmingham, ENGLAND			Nearest neighbour classifiers; evolutionary algorithms; machine learning; genetic algorithms; classification	ALGORITHM; DESIGN; RULE	The k-nearest neighbor method is a classifier based on the evaluation of the distances to each pattern in the training set. The edited version of this method consists of the application of this classifier with a subset of the complete training set in which some of the training patterns are excluded, in order to reduce the classification error rate. In recent works, genetic algorithms have been successfully applied to determine which patterns must be included in the edited subset. In this paper we propose a novel implementation of a genetic algorithm for designing edited k-nearest neighbor classifiers. It includes the definition of a novel mean square error based fitness function, a novel clustered crossover technique, and the proposal of a fast smart mutation scheme. In order to evaluate the performance of the proposed method, results using the breast cancer database, the diabetes database and the letter recognition database from the UCI machine learning benchmark repository have been included. Both error rate and computational cost have been considered in the analysis. Obtained results show the improvement achieved by the proposed editing method.	[Gil-Pita, Roberto] Univ Alcala de Henares, Signal Theory & Commun Dept, Madrid 28805, Spain; [Yao, Xin] Univ Birmingham, Sch Comp Sci, CERCIA, Birmingham B15 2TT, W Midlands, England; [Yao, Xin] Univ Sci & Technol China, Dept Comp Sci & Technol, NICAL, Hefei 230027, Anhui, Peoples R China	Gil-Pita, R (reprint author), Univ Alcala de Henares, Signal Theory & Commun Dept, Madrid 28805, Spain.	roberto.gil@uah.es; X.Yao@cs.bham.ac.uk	Gil-Pita, Roberto/N-3748-2014	Gil-Pita, Roberto/0000-0002-1790-3834			Bishop C.M., 1995, NEURAL NETWORKS PATT; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; Chen JH, 2004, LECT NOTES ARTIF INT, V3157, P262, DOI 10.1109/ISIMP.2004.1434050; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Haupt R. L., 2004, PRACTICAL GENETIC AL; He H., 2000, J ADV COMPUTATIONAL, V4, P130; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Islam M, 2003, IEEE T NEURAL NETWOR, V14, P820, DOI 10.1109/TNN.2003.813832; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; Mollineda RA, 2005, LECT NOTES COMPUT SC, V3523, P27; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107	14	12	12	0	2	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0129-0657			INT J NEURAL SYST	Int. J. Neural Syst.	DEC	2008	18	6					459	467				9	Computer Science, Artificial Intelligence	Computer Science	396NR	WOS:000262598900002	19145662	
J	Furao, S; Hasegawa, O				Furao, Shen; Hasegawa, Osamu			A fast nearest neighbor classifier based on self-organizing incremental neural network	NEURAL NETWORKS			English	Article						Self-organizing incremental neural network; Nearest neighbor; Fast; Prototype-based classifier		A fast prototype-based nearest neighbor classifier is introduced. The proposed Adjusted SOINN Classifier (ASC) is based on SOINN (self-organizing incremental neural network), it automatically learns the number of prototypes needed to determine the decision boundary, and learns new information without destroying old learned information. It is robust to noisy training data, and it realizes very fast classification. In the experiment, we use some artificial datasets and real-world datasets to illustrate ASC. We also compare ASC with other prototype-based classifiers with regard to its classification error, compression ratio, and speed up ratio. The results show that ASC has the best performance and it is a very efficient classifier. (C) 2008 Elsevier Ltd. All rights reserved.	[Furao, Shen] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China; [Hasegawa, Osamu] Tokyo Inst Technol, Imaging Sci & Engn Lab, Tokyo, Japan	Furao, S (reprint author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	frshen@nju.edu.cn			NSF [60573157, 60723003, 60775046]	This work was supported in part by the China NSF grant (#60573157, #60723003, and #60775046).	Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Hastie T, 2001, ELEMENTS STAT LEARNI; Kohonen T., 1990, P INT JOINT C NEUR N, P545; MERZ CJ, 1996, UCI RESPOSITORY MACH; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; PASSERINI A, 2002, P 15 EUR C ART INT; SHEN F, 2005, IEEE COMP SOC INT C; Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006; Shen Furao, 2007, NEURAL NETWORKS, V20, P893; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	15	6	7	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080			NEURAL NETWORKS	Neural Netw.	DEC	2008	21	10					1537	1547		10.1016/j.neunet.2008.07.001		11	Computer Science, Artificial Intelligence	Computer Science	387BG	WOS:000261926100015		
J	Boutsinas, B; Papastergiou, T				Boutsinas, B.; Papastergiou, T.			On clustering tree structured data with categorical nature	PATTERN RECOGNITION			English	Article						clustering; (dis)similarity measures; data mining	CLASSIFICATION; ALGORITHM	Clustering consists in partitioning a set of objects into disjoint and homogeneous clusters. For many years, clustering methods have been applied in a wide variety of disciplines and they also have been utilized in many scientific areas. Traditionally, clustering methods deal with numerical data, i.e. objects represented by a conjunction of numerical attribute Values. However, nowadays commercial or scientific databases Usually contain categorical data, i.e. objects represented by categorical attributes. In this paper we present a dissimilarity measure which is capable to deal with tree structured categorical data. Thus, it can be used for extending the various versions of the very popular k-means clustering algorithm to deal with Such data. We discuss how such an extension can be achieved. Moreover, we empirically prove that the proposed dissimilarity measure is accurate, compared to other well-known (dis)similarity measures for categorical data. (C) 2008 Elsevier Ltd. All rights reserved.	[Boutsinas, B.] Univ Patras, Dept Business Adm, GR-26500 Rion, Greece; [Boutsinas, B.; Papastergiou, T.] Univ Patras, Artificial Intelligence Res Ctr, GR-26500 Rion, Greece	Boutsinas, B (reprint author), Univ Patras, Dept Business Adm, GR-26500 Rion, Greece.	vutsinas@upatras.gr					Aldenderfer M. S., 1984, QUANTITATIVE APPL SO; Anderberg M. R., 1973, CLUSTER ANAL APPL; BERGE C, 1985, N HOLLAND MATH LIB, V6, P72; BLANCHARD E, 2005, OP INT WORKSH ENT MO; BOCK HH, 2000, STUDIES CLASSIFICATI, V15; Boutsinas B., 2006, Pattern Recognition and Image Analysis, V16, DOI 10.1134/S1054661806020015; BOUTSINAS B, 2008, INT J INF TECHNOL DE; CHENG V, 2004, PATTERN RECOGN, V37, P1471, DOI DOI 10.1016/J.PATCOG.2003.12.015; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox TF, 1994, MULTIDIMENSIONAL SCA; DAI BT, COLUMN HETEROGENEITY; DUBES R, 1980, ADV COMPUT, V19, P113, DOI 10.1016/S0065-2458(08)60034-0; Dunn-Rankin Peter, 1983, SCALING METHODS; ESPOSITO F, 1992, IEEE T PATTERN ANAL, V14, P390, DOI 10.1109/34.120333; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1007/BF00114265; Greenacre M., 1984, THEORY APPL CORRESPO; Hirst G., 1998, WORDNET ELECT LEXICA, P305; Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jiang J., 1997, P INT C RES COMP LIN; Johnson S. C., 1967, PSYCHOMETRIKA, p[2, 241]; JOHNSON T, 2003, SIGMOD; Kalfoglou Y, 2003, KNOWL ENG REV, V18, P1, DOI 10.1017/S0269888903000651; Kaufman L., 1990, WILEY SERIES PROBABI; KODRATOFF Y, 1988, INTRO MACHINE LEARNI; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; Leacock C, 1998, WORDNET ELECT LEXICA, P265; Lenat D.B., 1995, COMMUN ACM, V38; Lin D., 1998, P 15 INT C MACH LEAR, P296; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; Malerba D, 2001, P JOINT C NEW TECHN, P473; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; Michalski R.S., 1983, MACHINE LEARNING ART, V1; Niles I., 2001, 2 INT C FORM ONT INF; Quillian M. R., 1968, SEMANTIC INFORM PROC; RADA R, 1989, IEEE T SYST MAN CYB, V19, P17, DOI 10.1109/21.24528; Resnik P., 1995, P 14 INT JOINT C ART, V1, P448; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81; SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409; Sussna M, 1993, P 2 INT C INF KNOWL, P67, DOI 10.1145/170088.170106; Vrahatis MN, 2002, J COMPLEXITY, V18, P375, DOI 10.1006/jcom.2001.0633; Wache H, 2001, IJCAI WORKSH ONT INF; Warin M., 2005, P MEANING 2005 WORKS; ZHANG B, 2003, P INT C COMP VIS PAT; Zhibiao Wu, 1994, P 32 ANN M ASS COMP, P133, DOI DOI 10.3115/981732.981751	46	9	9	0	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	DEC	2008	41	12					3613	3623		10.1016/j.patcog.2008.05.023		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	353EC	WOS:000259547900009		
B	Yang, CS; Chuang, LY; Li, JC; Yang, CH			IEEE	Yang, Cheng-San; Chuang, Li-Yeh; Li, Jung-Chike; Yang, Cheng-Hong			Chaotic Maps in Binary Particle Swarm Optimization for Feature Selection	2008 IEEE CONFERENCE ON SOFT COMPUTING IN INDUSTRIAL APPLICATIONS SMCIA/08			English	Proceedings Paper	IEEE Conference on Soft Computing in Industrial Applications	JUN 25-28, 2008	Muroran, JAPAN	IEEE Syst, Man & Cybernet Soc, TCIA			CLASSIFIER	Feature selection is a useful pre-processing technique for solving classification problems. The challenge of using evolutionary algorithms lies in solving the feature selection problem caused by the number of features. Classification data may contain useless, redundant or misleading features. To increase the classification accuracy, the primary objective is to remove irrelevant features in the feature space and identify the relevant features. Binary particle swarm optimization (BPSO) has been applied successfully in solving feature selection problem. In this paper, two kinds of chaotic maps are embedded in binary particle swarm optimization (BPSO), a logistic map and a tent map, respectively. The purpose of the chaotic maps is to determine the inertia weight of the BPSO. In this study, we propose the chaotic binary particle swarm optimization (CBPSO) method to implement feature selection, and the K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) serves as a classifier to evaluate the classification accuracies. The proposed method showed promising results for feature selection with respect to the number of feature subsets. The classification accuracy obtained by the proposed method is superior to ones obtained by the other methods from the literature.	[Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CS (reprint author), Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan.	p8896117@mail.ncku.edu.tw; chuang@isu.edu.tw; 1095320149@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					ALATAS B, CHAOS SOLIT IN PRESS; Chuanwen J., 2005, MATH COMPUT SIMULAT, V68, P57, DOI 10.1016/j.matcom.2004.10.003; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE; Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104; Murphy PM, 1995, UCI REPOSITORY MACHI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Shi Y, 1998, EV COMP P 1998 IEEE, P69; Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003	13	0	0	0	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3782-5				2009							107	112				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BMF96	WOS:000272228200019		
B	Chuang, LY; Wu, KC; Yang, CH			IEEE	Chuang, Li-Yeh; Wu, Kuo-Chuan; Yang, Cheng-Hong			Hybrid Feature Selection Method using Gene Expression Data	2008 IEEE CONFERENCE ON SOFT COMPUTING IN INDUSTRIAL APPLICATIONS SMCIA/08			English	Proceedings Paper	IEEE Conference on Soft Computing in Industrial Applications	JUN 25-28, 2008	Muroran, JAPAN	IEEE Syst, Man & Cybernet Soc, TCIA			FEATURE SUBSET-SELECTION; MICROARRAY DATA; CLASSIFICATION; ALGORITHMS; CLASSIFIERS; MACHINE	Gene expression profiles, which represent the state of a cell at a molecular level, have great potential as a medical diagnosis tool. Compared to the number of genes involved available training data sets generally have a fairly small sample size in cancer type classification. These training data limitations constitute a challenge to certain classification methodologies. The gene (feature) selection can extract genes which influence classification accuracy effectively, to eliminate the useless genes, and to improve the calculate performance and the classification accuracy. This paper presents hybrid feature selection method Taguchi-Genetic algorithm to rind optimal feature subset, to appraise feature set using K-nearest neighbor with leave-one-out cross-validation based on Euclidean distance calculation. Experimental results show that our method simplifies features effectively and obtains a higher classification accuracy compared to other classification methods from the literature.	[Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan	Chuang, LY (reprint author), I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan.	chuang@isu.edu.tw; kuo.chuan.wu@gmail.com; chyang@cc.kuas.edu.tw					BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN, P1; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Holland J., 1992, ADAPTATION NATURE AR; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; SAHAMI M, 1998, WS9805 AAAI, V62; SPECHT DF, 1990, PROBABILISTIC NEURAL, V3, P109; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 2000, ROBUST ENG; Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; Wu Y, 2000, TAGUCHI METHODS ROBU; Xiong MM, 2001, GENOME RES, V11, P1878; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YEANG CH, 2001, MOL CLASSIFICATION T, V17, pS316	24	0	0	0	13	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3782-5				2009							199	204				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BMF96	WOS:000272228200035		
B	Goeger, D; Ecker, N; Woern, H			IEEE	Goeger, Dirk; Ecker, Nico; Woern, Heinz			Tactile sensor and algorithm to detect slip in robot grasping processes	2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4			English	Proceedings Paper	IEEE International Conference on Robotics and Biomimetics (ROBIO)	FEB 22-25, 2009	Bangkok, THAILAND	IEEE Robot & Automat Soc		tactile sensor; slip detection algorithm; humanoid robot		In this paper we introduce a tactile slip sensor for an anthropomorphic robot hand, the measurement circuit and the corresponding algorithm to determine slip states. The main slip sensor components consist of a silicone rubber surface which covers a PVDF sensor. After the amplification of the signal it is processed by a discrete short-time Fourier transform. The resulting spectrogram is processed by a principal component analysis to determine the main signal components. For a classification of three states ('slip', 'signal but no slip' and 'noise') a k-nearest neighbour classifier has been trained with the main signal components and serves for discrimination of slip states on the sensor's surface. The build-up of the sensor and the experimental setup will be briefly explained, the signal processing and the results will be discussed in detail.	[Goeger, Dirk; Ecker, Nico; Woern, Heinz] Univ Karlsruhe, Inst Proc Control & Robot, D-76131 Karlsruhe, Germany	Goeger, D (reprint author), Univ Karlsruhe, Inst Proc Control & Robot, Engler Bunte Ring 8, D-76131 Karlsruhe, Germany.	goeger@ira.uka.de					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOGER D, 2007, IEEE C SENS ATL GA U; HOLWEG E, 1996, IEEE INT C ROB AUT M; JOCKUSCH J, 1997, IEEE INT C ROB AUT A; Schulz A., 2004, MECHATRONICS ROBOTIC, P936; SON J, 1994, IEEE INT C ROB AUT S; Turk M.A., 1991, COMPUTER VISION PATT; Worn H., 2005, P IEEE INT C MECH AU	8	0	0	3	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2678-2				2009							1480	1485		10.1109/ROBIO.2009.4913219		6	Engineering, Electrical & Electronic; Instruments & Instrumentation; Robotics	Engineering; Instruments & Instrumentation; Robotics	BME14	WOS:000271966900250		
B	Liu, XS; Liu, Q; Fu, GL		Thalmann, D; Shah, JJ; Peng, QS		Liu Xiaoshan; Liu Qing; Fu Guolan			Texture Analyse Based on Coefficients' Relationship Co-occurrence Histogram	2009 11TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN AND COMPUTER GRAPHICS, PROCEEDINGS	International Conference on Computer-Aided Design and Computer Graphics-CAD GRAPHICS		English	Proceedings Paper	11th International Conference on Computer-Aided Design and Computer Graphics	AUG 19-21, 2009	Yellow Mountain City, PEOPLES R CHINA	IEEE, Natl Nat Sci Fdn China, Zhejiang Prov			CLASSIFICATION; SEGMENTATION	We propose a novel texture feature extraction technique based on coefficients' co-occurrence histogram of discrete wavelet frame transformed image, which capture the information about relationship between each high frequency subband and the low frequency subband of the decomposed image at the corresponding level. It is not independently utilizing the information of each subband coefficient: The classification performance is analyzed using the k-NN classifier. And the experimental results demonstrate the effectiveness of our proposed texture feature in achieving the improved classification performance. Comparisons with the Gabor filter and a recently proposed approach are also provided.	[Liu Xiaoshan; Fu Guolan] Jiangxi Normal Univ, Sch Phys & Commun Elect, Nanchang 330022, Jiangxi, Peoples R China	Liu, XS (reprint author), Jiangxi Normal Univ, Sch Phys & Commun Elect, Nanchang 330022, Jiangxi, Peoples R China.	xsliu@163.com; liu.qing3@mail.scut.edu.cn; guolanfu@126.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25; Daugman J., 1990, COMPUTATIONAL NEUROS, P403; EHRICH RW, 1978, COMPUT VISION GRAPH, V8, P174, DOI 10.1016/0146-664X(78)90048-5; HARALICK RM, 1978, IEEE T SYSTERM MAN C, V8, P460; Hiremath P. S., 2006, GVIP J, V6; Hiremath PS, 2008, PATTERN RECOGN LETT, V29, P1182, DOI 10.1016/j.patrec.2008.01.012; Laine A, 1996, IEEE T IMAGE PROCESS, V5, P771, DOI 10.1109/83.499915; LI XH, 2003, ACTA ELECT SINICA, V31, P2123; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; WU J, 2001, J REMOTE SENSING, V5, P100; Zuyuan Wang, 2001, J IMAGE GRAPHIC, V6A, P1065	14	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3700-9	INT C COMP AID DES C			2009							584	587		10.1109/CADCG.2009.5246832		4	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing	Computer Science; Engineering	BNX95	WOS:000275856400113		
B	Zagouras, A; Argiriou, AA; Flocas, HA; Economou, G; Fotopoulos, S			IEEE	Zagouras, A.; Argiriou, A. A.; Flocas, H. A.; Economou, G.; Fotopoulos, S.			A MACHINE VISION BASED METHOD FOR ATMOSPHERIC CIRCULATION CLASSIFICATION	2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2			English	Proceedings Paper	16th International Conference on Digital Signal Processing	JUL 05-07, 2009	Santorini, GREECE			machine vision; chain code; k- nearest neighbors algorithm; synoptic climatology		Weather maps refer to meteorological data that characterize the atmospheric circulation in a region. The classification of weather maps into categories becomes an important task for understanding regional climate. Towards this goal, manual and semiautomatic techniques have been used, requiring manpower and supervision. In this paper, we propose a machine vision based method for the classification of weather maps into distinct classes. The chain code descriptor is applied to extract the feature of isobaric lines and we introduce the Double-Side Chain Code (DSCC) histogram for feature representation. Handling DSCC histograms as multidimensional vectors, the k-nearest neighbors (k-NN) algorithm classifies the objects to an appropriate number of classes, based on closest training set in the feature space. This method provides an automated and more 'objective' classification scheme, applying straightforward to the input weather map's image.	[Zagouras, A.; Economou, G.; Fotopoulos, S.] Univ Patras, Dept Phys, Elect Lab, GR-26110 Patras, Greece	Zagouras, A (reprint author), Univ Patras, Dept Phys, Elect Lab, GR-26110 Patras, Greece.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freeman H., 1961, Institute of Radio Engineers Transactions on Electronic Computers, VEC-10; HAGELBERG C, 1995, J ATMOS OCEAN TECH, V12, P633, DOI 10.1175/1520-0426(1995)012<0633:TLDIMR>2.0.CO;2; Kassomenos P, 1998, THEOR APPL CLIMATOL, V59, P215, DOI 10.1007/s007040050025; MICHALAKOU G, 2002, J APPL METEOROL, V41, P519; Tenenbaum J. B., 2000, SCIENCE, V290, P2; Wong K. Y., 2008, EXPERT SYST APPL, V35, P542, DOI 10.1016/j.eswa.2007.07.032; Wong KY, 2007, METEOROL APPL, V14, P49, DOI 10.1002/met.5; Yarnal B., 1993, SYNOPTIC CLIMATOLOGY	9	1	1	0	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3297-4				2009							496	500				5	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BOF71	WOS:000276494500084		
B	Li, Y; Cheng, B		Di, L; Chen, A		Li, Ying; Cheng, Bo			An Improved k-Nearest Neighbor Algorithm and Its Application to High Resolution Remote Sensing Image Classification	2009 17TH INTERNATIONAL CONFERENCE ON GEOINFORMATICS, VOLS 1 AND 2			English	Proceedings Paper	17th International Conference on Geoinformatics	AUG 12-14, 2009	Fairfax, VA		George Mason Univ	KNN classification; high resolution remote sensing image; object-oriented; segmentation		K-nearest neighbor (KNN) is a common classification method for data mining techniques. It has been widely used in many fields because of the implementation simplicity, the clarity of theory and the excellent classification performance. But KNN will increase classification error rate when training samples distribute unevenly or sample number of each class is very different. So, learning from the idea of clipping-KNN, this paper adopts an improved KNN classification algorithm and applies it to object-oriented classification of high resolution remote sensing image. Firstly, as sample points, image objects are obtained through image segmentation. Secondly, original KNN, clipping-KNN and the improved KNN are introduced and used to classify those sample points respectively. Finally, classification results are compared. Experiment shows that in the same training set and testing set, the improved KNN algorithm can achieve higher accuracy in the classification of high resolution remote sensing image.	[Li, Ying; Cheng, Bo] Chinese Acad Sci, Ctr Earth Observat & Digital Earth, Beijing, Peoples R China	Li, Y (reprint author), Chinese Acad Sci, Ctr Earth Observat & Digital Earth, Beijing, Peoples R China.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1982, PATTERN RECOGNITION; Shah J K, 2004, EUR SIGN PROC C VIEN; ZHANG J, 2003, THESIS XIAN JIAOTONG; ZHAO YT, 2002, CHIN J APPL ECOL, V13, P495	5	0	0	0	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4562-2				2009							1066	1069				4	Computer Science, Information Systems; Engineering, Electrical & Electronic; Remote Sensing	Computer Science; Engineering; Remote Sensing	BOU28	WOS:000277622400202		
B	Liu, ZY; Zhang, QY; Zhang, NT			IEEE	Liu Zhiyong; Zhang Qinyu; Zhang Naitong			Composite Pulse-Multipath Channel Estimation for IR-UWB Communication System	2009 5TH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND MOBILE COMPUTING, VOLS 1-8			English	Proceedings Paper	5th International Conference on Wireless Communications, Networking and Mobile Computing	SEP 24-26, 2009	Beijing, PEOPLES R CHINA	IEEE Commun Soc, Beijing Univ Posts & Telecommun, Tsinghua Univ, Hunan Univ, Wuhan Univ, Sci Res Publishing		Composite Pulse-Multipath Channel Estimation; Nearest Neighbor (NN); Detection; UWB	NEAREST-NEIGHBOR RULE; EQUALIZATION	In this paper, we develop a composite pulse-multipath channel estimation approach for impulse radio-ultra wideband (IR-UWB) system. The approach is realized by means of the nearest neighbor (NN) estimation algorithm. This reconstructed signal is subsequently used as a reference template in a correlator-based detector. The bit error rate (BER) performance of the proposed approach is analyzed and compared to that of traditional correlator-based detector. Extensive simulations show that for different propagation scenarios and transfer rates, detectors based on NN composite pulse-multipath channel estimation outperform traditional correlator-based detector.	[Liu Zhiyong; Zhang Qinyu] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China	Liu, ZY (reprint author), Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.	liuzhiyong79@yahoo.com.cn; zqy@hit.edu.cn; ntzhang@hit.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; FOERSTER J, 8021502490 IEEE; LI Y, 2003, CHANNEL ESTIMATION S; Sato H, 2006, IEE P-COMMUN, V153, P93, DOI 10.1049/ip-com:20050328; Savazzi P, 1998, IEEE J SEL AREA COMM, V16, P1640, DOI 10.1109/49.737633; XU L, 2006, IEEE J SELETC AREAS, V24, P808; Yang LQ, 2004, IEEE T WIREL COMMUN, V3, P1236, DOI 10.1109/twc.2004.830827; Yang LQ, 2004, IEEE SIGNAL PROC MAG, V21, P26; Zhuang WH, 2003, WIREL COMMUN MOB COM, V3, P663, DOI 10.1002/wcm.149	10	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3692-7				2009							1769	1773				5	Engineering, Electrical & Electronic; Telecommunications	Engineering; Telecommunications	BNX02	WOS:000275789400430		
B	Chuang, LY; Wu, KC; Yang, CH			IEEE	Chuang, Li-Yeh; Wu, Kuo-Chuan; Yang, Cheng-Hong			A Hybrid Feature Selection Method Using Gene Expression Data	2009 9TH IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOENGINEERING			English	Proceedings Paper	9th IEEE International Conference on BioInformatics and BioEngineering	JUN 22-24, 2009	Taichung, TAIWAN	IEEE		Feature selection; Taguchi-genetic algorithm; K-nearest neighbor; Leave-one-out cross-validation	CLASSIFICATION; ALGORITHMS	In this paper, correlation-based feature selection (CFS) and the Taguchi-genetic algorithm (TGA) method were combined in a hybrid method, and the K-nearest neighbor (KNN) method with leave-one-out cross-validation (LOOCV) served as a classifier for eleven classification profiles. With the help of this classifier classification accuracy were calculated. Experimental results show that this method effectively simplifies features selection by reducing the total number of features needed. The proposed method obtained the highest classification accuracy in five out of the six gene expression data set test problems when compared to other classification methods from the literature.	[Chuang, Li-Yeh] I Shou Univ, Kaohsiung, Taiwan	Chuang, LY (reprint author), I Shou Univ, Kaohsiung, Taiwan.	chuang@isu.edu.tw; 1097308101@cc.kuas.edu.tw; chyang@cc.kuas.edu.tw					BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Blake C, 1998, UCI REPOSITORY MACHI; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Chuang LY, 2008, COMPUT BIOL CHEM, V32, P29, DOI 10.1016/j.compbiolchem.2007.09.005; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Hall M.A., 1999, THESIS U WAIKATO; Holland J., 1975, ADAPTATION NATURAL A; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; Mitchell M., 1996, INTRO GENETIC ALGORI; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Taguchi G, 2000, ROBUST ENG; Tsai JT, 2004, IEEE T EVOLUT COMPUT, V8, P365, DOI 10.1109/TEVC.2004.826895; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; ZHU Z, 2007, SYSTEMS MAN CYBERN B, V37, P70	17	2	2	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4294-2				2009							100	106		10.1109/BIBE.2009.24		7	Engineering, Biomedical	Engineering	BOP23	WOS:000277202300014		
B	Quinzan, I; Sotoca, JM; Pla, F			IEEE	Quinzan, Ianisse; Sotoca, Jose M.; Pla, Filiberto			Clustering-based Feature Selection in Semi-supervised Problems	2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS			English	Proceedings Paper	9th International Conference on Intelligent Systems Design and Applications	NOV 30-DEC 02, 2009	Pisa, ITALY	Machine Intelligence Res Lab, IEEE Syst, Man & Cybernet Soc (SMCS), Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Fed Soft Comp	Univ Pisa	Semi-supervised learning; feature selection; information measures	MUTUAL INFORMATION; CLASSIFICATION	In this contribution a feature selection method in semi-supervised problems is proposed. This method selects variables using a feature clustering strategy, using a combination of supervised and unsupervised feature distance measure, which is based on Conditional Mutual Information and Conditional Entropy. Real databases were analyzed with different ratios between labelled and unlabelled samples in the training set, showing the satisfactory behaviour of the proposed approach.	[Quinzan, Ianisse; Sotoca, Jose M.; Pla, Filiberto] Univ Jaume 1, Inst Noves Tecnol Imatge, Dept Llenguatges & Sistemes Informat, Castellon De La Plana, Spain	Quinzan, I (reprint author), Univ Jaume 1, Inst Noves Tecnol Imatge, Dept Llenguatges & Sistemes Informat, Castellon De La Plana, Spain.	ianisseqs@yahoo.es; sotoca@lsi.uji.es; pla@lsi.uji.es					BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Chen Y.H., 2008, 19 INT C PATT REC IC, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMANTARAS RL, 1989, METHODOLOGIES INTELL, V3, P342; Handl J, 2006, IEEE IJCNN, P3319; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Liu H, 2008, CH CRC DATA MIN KNOW, P3; Martinez-Uso A, 2006, INT C PATT RECOG, P760; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Ren JT, 2008, LECT NOTES ARTIF INT, V5012, P970; WANG B, 2008, INT C COMP SCI SOFTW, P210; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Zhao JD, 2008, NEUROCOMPUTING, V71, P1842, DOI 10.1016/j.neucom.2007.06.014; ZHAO Z, 2007, SDM, P641; ZHU X., 2006, 1530 TR U WISC MAD	17	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4735-0				2009							535	540		10.1109/ISDA.2009.211		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTY07	WOS:000288405800092		
B	Valls, JM; Aler, R			IEEE	Valls, Jose M.; Aler, Ricardo			Optimizing Linear and Quadratic Data Transformations for Classification Tasks	2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS			English	Proceedings Paper	9th International Conference on Intelligent Systems Design and Applications	NOV 30-DEC 02, 2009	Pisa, ITALY	Machine Intelligence Res Lab, IEEE Syst Man & Cybernetics Soc, Int Fuzzy Syst Assoc, European Neural Network Soc, European Soc Fuzzy Log & Technol, World Fed Soft Comp	Univ Pisa	Data transformations; General Euclidean Distances; Evolutionary Computation; Evolutionary-based Machine Learning	DISCRIMINANT-ANALYSIS	Many classification algorithms use the concept of distance or similarity between patterns. Previous work has shown that it is advantageous to optimize general Euclidean distances (GED). In this paper, we optimize data transformations, which is equivalent to searching for GEDs, but can be applied to any learning algorithm, even if it does not use distances explicitly. Two optimization techniques have been used: a simple Local Search (LS) and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). CMA-ES is an advanced evolutionary method for optimization in difficult continuous domains. Both diagonal and complete matrices have been considered. The method has also been extended to a quadratic non-linear transformation. Results show that in general, the transformation methods described here either outperform or match the classifier working on the original data.	[Valls, Jose M.; Aler, Ricardo] Univ Carlos III Madrid, Madrid, Spain	Valls, JM (reprint author), Univ Carlos III Madrid, Madrid, Spain.	jvalls@inf.uc3m.es; aler@inf.uc3m.es					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3056, P3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gonzalez R. C., 1974, PATTERN RECOGNITION; Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; OSTERMEIER A, 1994, EVOLUTIONARY COMPUTA, V4, P369; Ripley BD, 1996, PATTERN RECOGNITION; Sierra A, 2006, IEEE T EVOLUT COMPUT, V10, P81, DOI 10.1109/TEVC.2005.856069; Sierra A, 2002, PATTERN RECOGN, V35, P1291, DOI 10.1016/S0031-3203(01)00107-8; Valls JM, 2007, COMPUT INFORM, V26, P33; Weisberg S., 1985, APPL LINEAR REGRESSI	12	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4735-0				2009							1025	1030		10.1109/ISDA.2009.222		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BTY07	WOS:000288405800175		
S	Tafazzoli, E; Saif, M			IEEE	Tafazzoli, Esmaeil; Saif, Mehrdad			Application of combined support vector machines in process fault diagnosis	2009 AMERICAN CONTROL CONFERENCE, VOLS 1-9	PROCEEDINGS OF THE AMERICAN CONTROL CONFERENCE		English	Proceedings Paper	American Control Conference 2009	JUN 10-12, 2009	St Louis, MO				NEAREST-NEIGHBOR CLASSIFICATION; FISHER DISCRIMINANT-ANALYSIS	The performance of Combined Support Vector Machines, C-SVM, is examined by comparing it's classification results with k-nearest neighbor and simple SVM classifier. For our experiments we use training and testing data obtained from two benchmark industrial processes. The first set is simulated data generated from Tennessee Eastman process simulator and the second set is the data obtained by running experiment on a Three Tank system. Our results show that the C-SVM classifier gives the lowest classification error compared to other methods. However, the complexity and computation time become issues, which depend on the number of faults in the data and the data dimension. We also examined Principal Component Analysis, using PC scores as input features for the classifiers but the performance was not comparable to other classifiers' results. By selecting appropriate number of variables using contribution charts for classification, the performance of the classifiers on Tennessee Eastman data enhances significantly. Therefore, using contribution charts for selecting the most important variables is necessary when the number of variables is large.	[Tafazzoli, Esmaeil; Saif, Mehrdad] Simon Fraser Univ, Sch Engn Sci, Vancouver, BC V5A 1S6, Canada	Saif, M (reprint author), Simon Fraser Univ, Sch Engn Sci, 8888 Univ Dr, Vancouver, BC V5A 1S6, Canada.	saif@ensc.sfu.ca					*AMIRA, 2002, DTS200 LAB SET 3 TAN; ATHITSOS V, 2005, IEEE COMPT SOC C COM, V3, P45; Bishop C. M., 2006, PATTERN RECOGNITION; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; Chiang LH, 2000, CHEMOMETR INTELL LAB, V50, P243, DOI 10.1016/S0169-7439(99)00061-1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; Gunn S. R., 1998, SUPPORT VECTOR MACHI; GUO M, 2003, IEEE P SYST MAN CYBE, V3, P2710; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HE Q, 2008, IEEE T SEMICONDUCTOR, V20, P345; MORI G, 2008, LECT NOTES; PING L, 2007, P 4 INT S NEUR NETW, P448; PINGPENG Y, 2008, IEEE INT WORKSH SEM, P133; SHUBIN W, 2008, INT C BIOM ENG INF, P240; Song Y., 2007, IKNN INFORM K NEARES; Zhang H., 2006, IEEE INT C COMP VIS, V2, P2126; ZHAO X, 2005, IEEE T IND ELECT ISI, V4, P1715	19	3	3	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0743-1619		978-1-4244-4523-3	P AMER CONTR CONF			2009							3429	3433		10.1109/ACC.2009.5160577		5	Automation & Control Systems	Automation & Control Systems	BLF29	WOS:000270044901237		
B	Giguere, P; Dudek, G; Prahacs, C; Plamondon, N; Turgeon, K			IEEE	Giguere, Philippe; Dudek, Gregory; Prahacs, Christopher; Plamondon, Nicolas; Turgeon, Katrine			Unsupervised Learning of Terrain Appearance for Automated Coral Reef Exploration	2009 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION			English	Proceedings Paper	6th Canadian Conference on Computer and Robot Vision	MAY 25-27, 2009	Kelowna, CANADA	Canadian Image Proc & Pattern Recognit Soc, Int Assoc Pattern Recognit			IMAGE SEGMENTATION	We describe a navigation and coverage system based on unsupervised learning driven by visual input. Our objective is to allow a robot to remain continuously, moving above a terrain of interest using visual feedback to avoid leaving this region. As a particular application domain, we are interested in doing this in open water, but the approach makes few domain-specific assumptions. Specifically, our system employed an unsupervised learning technique to train a k-Nearest Neighbor classifier to distinguish between images of different terrain types through image segmentation. A simple random exploration strategy was used with this classifier to allow the robot to collect data while remaining confined above a coral reef without the need to maintain pose estimates. We tested the technique in simulation, and a live deployment was conducted in open water During the latter, the robot successfully navigated autonomously, above a coral reef during a 20 minutes period.	[Giguere, Philippe; Dudek, Gregory; Prahacs, Christopher; Plamondon, Nicolas] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	Giguere, P (reprint author), McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.	philg@cim.mcgill.ca; dudek@cim.mcgill.ca; cprahacs@cim.mcgill.ca; nicola@cim.mcgill.ca; katrine.turgeon@mail.mcgill.ca					BUEHLER M, 2001, RHEX SIMPLE HIGHLY M, V20, P616; Chen CW, 1998, IEEE T IMAGE PROCESS, V7, P1673, DOI 10.1109/83.730379; Corke P, 2007, IEEE INT CONF ROBOT, P4556, DOI 10.1109/ROBOT.2007.364181; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devroye L., 1997, PROBABILISTIC THEORY; Dudek G., 2005, IEEE RSJ INT C INT R; DUNBABIN M, 2005, SPRINGER TRACTS ADV, V25, P31; Eustice R., 2005, P ROB SCI SYST CAMBR; GIGUERE P, 2008, P ROB SCI SYST ZUR S, V4; GIGUERE P, 2009, P IEEE INT C ROB AUT; Plamondon N., 2008, OC 08 MTS IEEE QUEB; SATTAR J, 2005, IEEE RSJ INT C INT R; SATTAR J, 2008, P 11 INT S EXP ROB I; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884	16	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4211-9				2009							268	275		10.1109/CRV.2009.41		8	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	BPS74	WOS:000279806900037		
B	Celebi, AT; Gullu, MK; Erturk, S			IEEE	Celebi, Aysun Tasyapi; Gullu, M. Kemal; Erturk, Sarp			Low-Complexity Iris Recognition Using One-Bit Transform and Angular Radial Partitioning	2009 IEEE 17TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, VOLS 1 AND 2			Turkish	Proceedings Paper	IEEE 17th Signal Processing and Communications Applications Conference	APR 09-11, 2009	Antalya, TURKEY	IEEE				In this paper, a novel low-complexity iris recognition system based on-bit transform BTg and angular radial partitioning zARPg is proposed. A binary iris image is obtained using BT on iris image. ARP is applied to this binary image and a feature vector is extracted considering the amount of data in the partitions and identification is executed. An important advantage of the proposed approach is its low-complexity. Furthermore, the method gives high identification and verification accuracies.	[Celebi, Aysun Tasyapi; Gullu, M. Kemal; Erturk, Sarp] Kocaeli Univ, Elekt & Haberlesme Muhendisligi Bolumu Veziroglu, TR-41040 Izmir, Turkey	Celebi, AT (reprint author), Kocaeli Univ, Elekt & Haberlesme Muhendisligi Bolumu Veziroglu, TR-41040 Izmir, Turkey.	aysun.tasyapi@gmail.com; kemalg@kou.edu.tr; sertur@kou.edu.tr					BLACK E, DICT ALGORITHMS DATA; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Chalechale A, 2004, IEE P-VIS IMAGE SIGN, V151, P93, DOI 10.1049/ip-vis:20040332; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN, 2002, PREC C C INT C IM PR; Dobes M., IRIS DATABASE; Masek L., 2003, MATLAB SOURCE CODE B; MURON JP, 2000, HUMAN IRIS STRUCTURE, P87; Natarajan B, 1997, IEEE T CIRC SYST VID, V7, P702, DOI 10.1109/76.611181; VATSA M, 2008, SYSTEMS MAN CYBERN B, P1021; Wildes R. P., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341298	11	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4435-9				2009							910	913				4	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Telecommunications	Computer Science; Engineering; Telecommunications	BMY66	WOS:000273935600228		
S	Register, AH; Mallik, M; Blair, WD; Burton, C; Burns, P			IEEE	Register, Andy H.; Mallik, Mahendra; Blair, W. Dale; Burton, Chris; Burns, Paul			Detection and Diagnosis of Radar Modeling Errors using Covariance Consistency	2009 IEEE AEROSPACE CONFERENCE, VOLS 1-7	IEEE Aerospace Conference Proceedings		English	Proceedings Paper	2009 IEEE Aerospace Conference	MAR 07-14, 2009	Big Sky, MT				RAYLEIGH TARGETS; DATA ASSOCIATION; ALGORITHM; TRACKING; CLASSIFICATION	Often, detection-based tracking algorithms are developed without much regard for the effects of either the radar's analog signal processing or its digital signal-processing algorithms. In this paper, we combine the effects of the radar's signal processing and tracking algorithms to assess the combined effect on covariance consistency of various algorithms. To do this, we first define the terms detection, detection primitive, and measurement. Next, we provide a detailed dataflow diagram for the processing chain of an electronically-scanned radar so that we can examine the propagation of truth data through various coordinate frames relative to radar signal processing. We examine issues related to expressing truth data in different frames and different relationships among targets. We describe in detail many of the algorithms in the signal-processing chain of typical monopulse radar and finally analyze and demonstrate the covariance consistency of various algorithms in the radar processing chain. When properly applied, covariance consistency analysis can be used to detect and correct inconsistent algorithms, invalid assumptions, and coding errors. The techniques described in this paper provide insight in determining system covariance requirements and may be used to ensure that both the design and implementation of radar processing algorithms provide good covariance consistency. The example simulations provide a baseline for algorithm covariance consistency, examine some common approximations used to simplify radar simulations, and demonstrate the effect of implementation errors that actually occurred during model development.(12)	[Register, Andy H.; Mallik, Mahendra; Blair, W. Dale; Burton, Chris; Burns, Paul] Georgia Tech Res Inst, Sensors & Electromagnet Applicat Lab, Air & Missile Def Div, Smyrna, GA 30080 USA	Register, AH (reprint author), Georgia Tech Res Inst, Sensors & Electromagnet Applicat Lab, Air & Missile Def Div, 7220 Richardson Rd, Smyrna, GA 30080 USA.	andy.register@gtri.gatech.edu; mahendra.mallik@gtri.gatech.edu; dale.blair@gtri.gatech.edu; chris.burton@gtri.gatech.edu; paul.burns@gtri.gatech.edu					Anderson B. D. O., 1979, OPTIMAL FILTERING; Bar-Shalom Y., 1995, MULTITARGET MULTISEN; Bar-Shalom Y., 1998, MULTITARGET MULTISEN, VI; BARSHALOM Y, 2001, ESTIMATION APPL TRAC, P166; Bar-Shalom Y, 2005, IEEE T AERO ELEC SYS, V41, P868, DOI 10.1109/TAES.2005.1541436; Blackman S. S., 1999, DESIGN ANAL MODERN T; Blair WD, 1996, PROCEEDINGS OF THE TWENTY-EIGHTH SOUTHEASTERN SYMPOSIUM ON SYSTEM THEORY, P285, DOI 10.1109/SSST.1996.493515; BLAIR WD, 1997, NSWCDDTR97167; Blair WD, 1998, IEEE T AERO ELEC SYS, V34, P597, DOI 10.1109/7.670340; Blair WD, 2001, IEEE T AERO ELEC SYS, V37, P452, DOI 10.1109/7.937461; BLOM HAP, 1988, IEEE T AUTOMAT CONTR, V33, P780, DOI 10.1109/9.1299; BURNS P, 2004, P 2004 MULT TRACK ON; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Hotelling H, 1931, ANN MATH STAT, V2, P360, DOI 10.1214/aoms/1177732979; JAIN V, 2006, IEEE 38 SSST P 5 7 M, P85; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; KENDALL M, 1983, ADV THEORY STAT, V3, P290; Kirubarajan T., 2001, P WORKSH EST TRACK F; KURIEN T, 1990, MULTITARGET MULTISEN, P48; LI XR, 2002, P IFAC 15 WORLD C BA; Li X.R., 2003, P SIGN DAT PROC SMAL; Mahler R.P.S., 2007, STAT MULTISOURCE MUL; PAPANICOLOPOULO.CD, 2007, P IEEE RAD C; Poore A. B., 1994, Computational Optimization and Applications, V3, DOI 10.1007/BF01299390; POORE AB, 1995, P SOC PHOTO-OPT INS, V2561, P448, DOI 10.1117/12.217718; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ristic B., 2004, KALMAN FILTER; Skolnik Merrill I., 1990, RADAR HDB; Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190	30	0	0	0	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1095-323X		978-1-4244-2621-8	AEROSP CONF PROC			2009							1654	1670				17	Engineering, Aerospace; Engineering, Electrical & Electronic	Engineering	BME07	WOS:000271964000169		
B	Jo, T			IEEE	Jo, Taeho			Categorization of News Articles using Neural Text Categorizer	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE			SUPPORT VECTOR MACHINES; CLASSIFICATION	This research proposes the application or NTC (Neural Text Categorizer) for categorizing news articles. Even if the research on text categorization has been progressed very much, documents should be still encoded into numerical vectors. Encoding so causes the two main problems: huge dimensionality and sparse distribution. The idea of this research as the solution to the problems is to encode documents into string vectors and apply the NTC as a string vector based approach to text categorization. The idea will be described in detail and validated.	Inha Univ, Inchon, South Korea	Jo, T (reprint author), Inha Univ, Inchon, South Korea.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI, V1st; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Joachims T, 1998, P 10 EUR C MACH LEAR, P143; Kononenko I, 1989, P 4 EUR WORK SESS LE, P91; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Massand B, 1992, P 15 ACM INT C RES D, P59; McClelland J. L., 1986, PARALLEL DISTRIBUTED, VI; McClelland J. L., 1986, PARALLEL DISTRIBUTED, VII; Mitchell T. M., 1997, MACHINE LEARNING; Mladenic D, 1999, P INT C MACH LEARN, P256; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Wiener ED, 1995, THESIS U COLORADO; Yang Y, 1999, INFORMATION RETRIEVA, V1, P67	17	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3596-8				2009							19	22		10.1109/FUZZY.2009.5277330		4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600004		
B	Ko, DQ; Oentaryo, RJ; Pasquier, M			IEEE	Ko Dequan; Oentaryo, Richard J.; Pasquier, Michel			An Adaptive History Network Method to Improve the Genetic Optimization of Pattern Recognition Systems	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE			NEURAL-NETWORKS; ALGORITHM	The existence of many pattern recognition systems (PRSs) and their relative merits and drawbacks highlights the need for a metalearning framework that can find the best PRS method for a given task. To address this issue, a hyperparameter evolutionary optimization (HPEO) framework was previously devised, initially using a genetic algorithm to tune external PRS parameters in a modular fashion, decoupled from its internal components. To further improve the effectiveness of HPEO and improve the diversity of the hyperparameter solutions found, this paper presents an extension that realizes cross-generation learning with an adaptive history network (AHN), which promotes exploring new regions in the search space while avoiding regions that have been searched extensively. The proposed approach, termed HPEO-AHN, is particularly suitable for tuning powerful but complex PRSs such as neuro-fuzzy systems (NFS). Preliminary experiments with two state-of-the-art NFSs optimized using the new approach have shown encouraging results.	[Ko Dequan; Oentaryo, Richard J.; Pasquier, Michel] Nanyang Technol Univ, Ctr Computat Intelligence, Sch Comp Engn, Singapore 639798, Singapore	Ko, DQ (reprint author), Nanyang Technol Univ, Ctr Computat Intelligence, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	pasquier@ieee.org	Oentaryo, Richard/M-5948-2014	Oentaryo, Richard/0000-0002-4662-1561			Avriel M., 1966, FIBONACCI QUART, V4, P265; Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585888; Baldwin J. M., 1896, AM NAT, V30, P441, DOI DOI 10.1086/276408; Bhagat P, 2005, PATTERN RECOGNITION; Coello C. A. C., 1999, Knowledge and Information Systems, V1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fisher RA, 1936, ANN EUGENIC, V7, P179; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Guo XC, 2008, NEUROCOMPUTING, V71, P3211, DOI 10.1016/j.neucom.2008.04.027; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; JACOBS I, 1989, HUM REPROD, V1, P1; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; John G.H., 1995, P 11 C UNC ART INT, P338; KENNEDY J, 1995, P IEEE INT C NEUR NE, P1942, DOI DOI 10.1109/ICNN.1995.488968; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317; Lin C.-T., 1996, NEURAL FUZZY SYSTEMS; LUMANPAUW E, 2007, P IEEE C EV COMP SIN, P1593; Maguire LP, 1998, INFORM SCIENCES, V112, P125, DOI 10.1016/S0020-0255(98)10026-9; Siarry P, 2008, NAT COMPUT SER, P1, DOI 10.1007/978-3-540-72960-0; Milano M, 2004, IEEE T SYST MAN CY B, V34, P925, DOI 10.1109/TSMCB.2003.818432; Oentaryo RJ, 2008, EXPERT SYST APPL, V35, P1825, DOI 10.1016/j.eswa.2007.08.108; OENTARYO RJ, 2008, P IEEE INT JOINT C N, P2660; Pedrycz W, 2005, IEEE T SYST MAN CY B, V35, P633, DOI 10.1109/TSMCB.2005.843975; Podlena JR, 1998, APPL INTELL, V8, P103, DOI 10.1023/A:1008227606285; QUEK HC, 1999, EXPERT SYSTEMS TECHN; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Seng TL, 1999, IEEE T SYST MAN CY B, V29, P226, DOI 10.1109/3477.752795; Smith AFM, 2000, BAYESIAN THEORY; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Wang CH, 2001, IEEE T SYST MAN CY B, V31, P467, DOI 10.1109/3477.931548; Watanabe S., 1985, PATTERN RECOGNITION; Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585893; Yao X, 1999, P IEEE, V87, P1423	34	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3596-8				2009							23	28				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600005		
B	Chua, T; Tan, W			IEEE	Chua, TeckWee; Tan, WoeiWan			A New Fuzzy Rule-Based Initialization Method for K-Nearest Neighbor Classifier	2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3			English	Proceedings Paper	18th IEEE International Conference on Fuzzy Systems	AUG 20-24, 2009	Jeju Isl, SOUTH KOREA	IEEE			ALGORITHM	The performances of conventional crisp and fuzzy K-Nearest neighbor (K-NN) algorithms trained using finite samples tends to be poor [1], [2]. With "holes" in the training data, it is unlikely that the decision area formed can actually represent the underlying data distribution. There is a need to capture more useful information from the limited training samples, therefore we propose a new fuzzy rule-based K-NN algorithm. A fuzzy rule-based initialization procedure differentiates our proposed algorithm from the conventional fuzzy K-NN algorithm. The new initialization procedure allows us to handle the imprecise inputs (neighborhood density and distance) through the natural framework of fuzzy logic system. Unlike conventional K-NN algorithms, the ability to fine tune the membership functions can lead to a highly versatile decision boundary. Thus, the new algorithm can be specifically tuned for different problems to achieve better results. The advantage is demonstrated on a synthetic data set in two-dimensional space. In addition, we also adopt weighted Euclidean distance measurement to overcome the curse of dimensionality [3]. The Euclidean distance weights and the parameters of the fuzzy rule-based system are then optimized with Genetic Algorithm (GA) simultaneously. The practical applicability of the proposed algorithm is verified on four UCI data sets (Bupa liver disorders, Glass, Pima Indians diabetes and Wisconsin breast cancer) and Ford automotive data set with an improvement of 3.42% in classification rate on average.	[Chua, TeckWee; Tan, WoeiWan] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	Chua, T (reprint author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.	cteckwee@nus.edu.sg; eletanww@nus.edu.sg					ABOUNASR M, 2007, FORD CLASSIFICATION; Asuncion A., 2007, UCI MACHINE LEARNING; Chua TW, 2008, LECT NOTES COMPUT SC, V5361, P101; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; EAGEN, 2008, Patent No. 7353088; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kuncheva L., 2000, FUZZY CLASSIFIER DES; Mendel J.M., 2001, UNCERTAIN RULE BASED; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Pedrycz W, 1997, FUZZY SET SYST, V90, P171, DOI 10.1016/S0165-0114(97)00083-3; Shang WQ, 2005, LECT NOTES ARTIF INT, V3801, P741; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403	14	1	1	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3596-8				2009							415	420		10.1109/FUZZY.2009.5277215		6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BND85	WOS:000274242600072		
B	Ishii, I; Sukenobe, R; Yamamoto, K; Takaki, T			IEEE	Ishii, Idaku; Sukenobe, Ryo; Yamamoto, Kenkichi; Takaki, Takeshi			Real-time Image Recognition using HLAC Features at 1000 fps	2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4			English	Proceedings Paper	IEEE International Conference on Robotics and Biomimetics (ROBIO)	DEC 19-23, 2009	Guilin, PEOPLES R CHINA	IEEE Robot & Automat Soc, Natl Univ Defense Technol, Chinese Univ Hong Kong, City Univ Hong Kong, Guangxi Normal Univ, Natl Univ Defense Technol, Sch Elect Sci & Engn, IEEE Hong Kong Joint Chapter Robot & Automat & Control Syst			VISION CHIP; PROCESSOR	Real-time image recognition at 1000 fps is realized by implementing a parallel processing circuit module to calculate higher-order local auto-correlation (HLAC) features on a high-speed vision platform. The circuit module is compactly designed in order to decrease the number of multiplications required in the HLAC calculation. The circuit module is integrated on a user-specific FPGA of the high-speed vision platform. The high-speed vision platform, on which the HLAC circuit module is hardware-implemented, can extract 25 HLAC features at 1000 fps from 1024 X 1024 pixel images, which include 0th, 1st, and 2nd order HLAC features. In the experimental results, projected images switching at frame rates as high as 250 fps are recognised by using HLAC features extracted at 1000 fps on the high-speed vision platform.	[Ishii, Idaku; Sukenobe, Ryo; Yamamoto, Kenkichi; Takaki, Takeshi] Hiroshima Univ, Hiroshima 7398527, Japan	Ishii, I (reprint author), Hiroshima Univ, Hiroshima 7398527, Japan.	iishii@robotics.hiroshima-u.ac.jp					Albiol A, 2008, PATTERN RECOGN LETT, V29, P1537, DOI 10.1016/j.patrec.2008.03.017; BERNARD TM, 1993, IEEE J SOLID-ST CIRC, V28, P789, DOI 10.1109/4.222178; Bicego M., 2006, P IEEE INT WORKSH BI, P35; Cover TM, 1967, IEEE T INFORM THEORY, V13, P2127, DOI 10.1109/TIT.1967.1053964; Dalal N, 2005, PROC CVPR IEEE, P886; Eklund JE, 1996, IEEE T VLSI SYST, V4, P322, DOI 10.1109/92.532033; Hirai S., 2005, J ROBOTICS MECHATRON, V17, P401; ISHII I, 2009, P IEEE RSJ INT C INT, P3671; Ishii I, 2006, IEEE T ELECTRON DEV, V53, P1797, DOI 10.1109/TED.2006.878024; KOBAYASHI T, 2007, P 14 INT C NEUR INF, P598; Komuro T, 2004, IEEE J SOLID-ST CIRC, V39, P265, DOI 10.1109/JSSC.2003.820876; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790410; NANRI T, 2004, P IAPR C MACH VIS, P574; Otsu N., 1988, Proceedings of IAPR Workshop on Computer Vision: Special Hardware and Industrial Applications; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), DOI 10.1109/ACV.1994.341300; TSUDUKI Y, 2009, P 3 PAC RIM S ADV IM, P2536; Watanabe Y, 2007, IEEE INT CONF ROBOT, P3192, DOI 10.1109/ROBOT.2007.363965	17	1	1	2	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4774-9				2009							954	959		10.1109/ROBIO.2009.5420721		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Computer Science; Engineering; Robotics	BSR15	WOS:000285530500163		
S	Teixeira, LA; de Oliveira, ALI			IEEE	Teixeira, Lamartine Almeida; Inacio de Oliveira, Adriano Lorena			Predicting Stock Trends through Technical Analysis and Nearest Neighbor Classification	2009 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC 2009), VOLS 1-9	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 11-14, 2009	San Antonio, TX	IEEE		stock trend prediction; financial forecasting; machine learning; nearest neighbor prediction	NEURAL-NETWORKS; MARKETS	This paper presents the results of method designed to predict price trends in the stock market. Our first and foremost objective is to study the feasibility of the practical use of an intelligent prediction system exclusively based on the history of daily stock closing prices and volumes. To this end we propose a technique that consists of a combination of a nearest neighbor classifier and some well known tools of technical analysis, namely, stop loss, stop gain and RSI filter. For assessing the potential use of the proposed method in practice we compared the results obtained to the results that would be obtained by adopting a buy-and-hold strategy. The key performance measure in this comparison was profitability. The proposed method was shown to generate considerable higher profits than buy-and-hold for most of the companies, with few buy operations generated and, consequently, minimizing the risk of market exposure.	[Teixeira, Lamartine Almeida] Univ Pernambuco, Dept Comp Syst, Recife, PE, Brazil	Teixeira, LA (reprint author), Univ Pernambuco, Dept Comp Syst, Recife, PE, Brazil.	lat@dsc.upe.br; alio@cin.ufpe.br					AFOLABI MO, 2007, P 40 HAW INT C SYST, P48; Bao DP, 2008, EXPERT SYST APPL, V34, P620, DOI 10.1016/j.eswa.2006.09.043; Cao L. J., 2003, IEEE T NEURAL NETWOR, V14; Chang J., 2007, P 2 INT C INN COMP I, P390, DOI 10.1109/ICICIC.2007.568; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486; GUO X, 2007, 3 INT C NAT COMP ICN, P518, DOI 10.1109/ICNC.2007.145; Hassoun Mohamad H., 1995, FUNDAMENTALS ARTIFIC; Haugen RA, 1999, NEW FINANCE CASE EFF; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Kim HJ, 2007, APPL SOFT COMPUT, V7, P569, DOI 10.1016/j.asoc.2006.03.004; Kwon YK, 2007, IEEE T NEURAL NETWOR, V18, P851, DOI 10.1109/TNN.2007.891629; Leigh W, 2008, IEEE T SYST MAN CY A, V38, P93, DOI 10.1109/TSMCA.2007.909508; Los CA, 2000, ADV E, V14, P329; MANDZIUK J, 2007, P INT JOINT C NEUR N, P2515; Murphy J., 1999, TECHNICAL ANAL FINAN; Nagarajan V., 2005, INT C CONTR AUT ICCA, P259; Nanni L, 2006, PATTERN RECOGN LETT, V27, P109, DOI 10.1016/j.patrec.2005.07.008; Saad EW, 1998, IEEE T NEURAL NETWOR, V9, P1456, DOI 10.1109/72.728395; SAI Y, 2007, IEEE INT C GRAN COMP, P659; TAN P, 1994, P 2 SING INT C INT S; TEIXCIRA LA, P 2008 10 BRAZ S NEU, P33; Vanstone B., 2003, Proceedings of the Eighth Australian and New Zealand Intelligent Information Systems Conference (ANZIIS 2003); White H, 1988, IEEE INT C NEURAL NE, V2, P451	25	1	1	2	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-2793-2	IEEE SYS MAN CYBERN			2009							3094	3099		10.1109/ICSMC.2009.5345944		6	Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BPP02	WOS:000279574601227		
S	Kaya, GT; Ersoy, OK; Kamasak, ME			IEEE	Kaya, G. Taskin; Ersoy, O. K.; Kamasak, M. E.			SUPPORT VECTOR SELECTION AND ADAPTATION FOR CLASSIFICATION OF EARTHQUAKE IMAGES	2009 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, VOLS 1-5	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	IEEE International Geoscience and Remote Sensing Symposium	JUL 12-17, 2009	Cape Town, SOUTH AFRICA	IEEE		Support Vector Machines; Support Vector Selection and Adaptation; Classification of Earthquake Images		In this paper, we propose a new machine learning algorithm that we named Support Vector Selection and Adaptation (SVSA). Our aim is to achieve the classification performance of the nonlinear support vector machines (SVM) by using only the support vectors of the linear SVM. The proposed method does not require any type of kernels, and requires less computation time compared to the nonlinear SVM The SVSA algorithm has two steps. selection and adaptation. In the first step, some of the support vectors obtained from linear SVM are selected. Then the selected support vectors are adapted iteratively in the traning algorithm. The proposed method are compared against the linear and nonlinear SVM on sythetic and real remote sensing data. The results show that the proposed SVSA algorithm achieves very close performance to nonlinear SVM without any kernels in less computation time.	[Kaya, G. Taskin] Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey	Kaya, GT (reprint author), Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey.	gulsen@be.itu.edu.tr; ersoy@purdue.edu; kamasak@itu.edu.tr					Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cherkassky V., 1998, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duin R., 2007, MATLAB TOOLBOX PATTE; Kasapoglu NG, 2007, IEEE T GEOSCI REMOTE, V45, P3880, DOI 10.1109/TGRS.2007.900699; KAYA GT, 2008, TRECE092 PURD U; KOHONEN T, 1986, TKKFA601 HEL U TECHN; [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B, A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5	8	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-6996		978-1-4244-3394-0	INT GEOSCI REMOTE SE			2009							1102	1105		10.1109/IGARSS.2009.5418229		4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BQI05	WOS:000281054100279		
B	Buondonno, L; Fortino, G; Galzarano, S; Giannantonio, R; Giordano, A; Gravina, R; Guerrieri, A			IEEE	Buondonno, Luigi; Fortino, Giancarlo; Galzarano, Stefano; Giannantonio, Roberta; Giordano, Antonio; Gravina, Raffaele; Guerrieri, Antonio			Programming Signal Processing Applications on Heterogeneous Wireless Sensor Platforms	2009 IEEE INTERNATIONAL WORKSHOP ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS	IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems-Technology and Applications-IDAACS		English	Proceedings Paper	5th IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems	SEP 21-23, 2009	Rende, ITALY	Res Inst Intelligent Comp Syst & Fac Comp Informat Technologies, Univ Calabria, IEEE, Ukraine Sect		Wireless body sensor networks; software development methodology; task-oriented programming; distributed signal processing; SPINE		This paper proposes the SPINE frameworks (SPINE1.x and SPINE2) for the programming of signal processing applications on heterogeneous wireless sensor platforms. In particular, two integrable approaches based on the proposed frameworks are described that allow to develop applications for wireless body sensor networks (WBSNs) constituted by heterogeneous sensor nodes. The approaches are exemplified through a human activity recognition system based on a WBSN composed of two types of sensor nodes, heterogeneous with respect to base software and hardware.	[Buondonno, Luigi; Fortino, Giancarlo; Galzarano, Stefano; Giordano, Antonio; Gravina, Raffaele; Guerrieri, Antonio] Univ Calabria, Dept Elect Informat & Syst DEIS, I-87036 Arcavacata Di Rende, CS, Italy	Buondonno, L (reprint author), Univ Calabria, Dept Elect Informat & Syst DEIS, I-87036 Arcavacata Di Rende, CS, Italy.	luigi.buondonno@guest.telecomitalia.it; g.fortino@unical.it; galzarano@si.deis.unical.it; roberta.giannantonio@telecomitalia.it; agiordano@si.deis.unical.it; rgravina@deis.unical.it; aguerrieri@deis.unical.it		Fortino, Giancarlo/0000-0002-4039-891X			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fortino G., 2009, P IEEE S IND EMB SYS; Fortino G., 2009, P 2009 IEEE INT C SY; GAMA O, 2007, IEEE INT C SENS TECH; Gravina R., 2008, P IEEE INT C SYST MA; Iyengar S., 2008, P 3 INT C BOD AR NET; LOMBRISER C, 2007, P 2 INT C BOD AR NET; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; Selic B, 2003, IEEE SOFTWARE, V20, P19, DOI 10.1109/MS.2003.1231146; Shnayder V., 2005, TR0805 HARV U DIV EN; *SPINE, SPINE DOC SOFTW; ZigBee, ZIGBEE ALL; CONTIKI DOCUMENTATIO; Z STACK ZIGBEE PROTO	14	0	0	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4881-4	INT WORKSH INT DATA			2009							682	687		10.1109/IDAACS.2009.5342888		6	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BPZ03	WOS:000280406400135		
S	He, W; Wang, Y		Lan, H		He Wei; Wang Yu			Text Representation and Classification Based on Multi-Instance Learning	2009 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE & ENGINEERING (16TH), VOLS I AND II, CONFERENCE PROCEEDINGS	International Conference on Management Science and Engineering-Annual Conference Proceedings		English	Proceedings Paper	16th International Conference on Management Science and Engineering	SEP 14-16, 2009	Moscow, RUSSIA	Natl Nat Sci Fdn China, Harbin Inst Technol, State Univ Management, IEEE Technol Management Council		bag of sentences; multi-instance learning; text classification; text representation		In multi-instance learning, the training set comprises labeled bags which are composed of unlabeled instances, and the task is to predict the labels of unseen bags. In this paper, a text mining problem, i.e. text representation, is investigated from a multi-instance view. In detail, each text is regarded as a bag while each of its sentences is regarded as an instance. Bag can be labeled by its class label and its similarity is defined by sentence similarity The text classification problem is translated into multi-instance learning problem. In order to solve this problem, a Chinese text classifier focusing on bag has been built by KNN algorithm and good average precision 92.12% and recall 92.01% have been achieved in the experiments.	[He Wei; Wang Yu] Dalian Univ Technol, Sch Management, Dalian 116024, Peoples R China	He, W (reprint author), Dalian Univ Technol, Sch Management, Dalian 116024, Peoples R China.						Chen Yuzhu, 2006, COMPUTER ENG DESIGN, V18, P3444; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Foltz PW, 1998, DISCOURSE PROCESS, V25, P285; FOLTZ PW, 1999, P 16 INT C ICML 99 B, P27; JUN W, 2000, SOLVING MULTIPLE INS; LI RL, 2008, TEXT CLASSIFICATION; Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130; LIU JH, 2007, COMPUTER ENG DESIGN, V13, P3213; LIU JH, 2007, COMPUTER ENG DESIGN, V13, P3219; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; [吕学强 Lu Xueqiang], 2003, [东北大学学报. 自然科学版, Journal of Northeastern University], V24, P531; Maron O., 1998, FRAMEWORK MULTIPLE I; Maron O, 1998, LEARNING AMBIGUITY; Meadow C., 2000, TEXT INFORM RETRIEVA; Mitra M., 1997, P ACL 97 EACL 97 WOR, P39; Montes-y-Gomez M, 2002, LECT NOTES ARTIF INT, V2393, P122; SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; WEN YK, 2005, J CHINA SOC SCI TECH, V6, P663; WEN YK, 2004, J CHINA SOC SCI TECH, V6, P643; WEN YK, 2005, KNOWLEDGE ELEMENT MI; YANG SC, 2008, J CHINA SOC SCI TECH, V1, P35; ZHANG HP, ICTCLAS3 0 API OL; ZHANG XL, 2002, J CHINA SOC SCI TECH, V4, P413; Zhou ZH, 2006, J COMPUT SCI TECHNOL, V21, P800, DOI 10.1007/s11390-006-0800-7; TEXT CLASSIFICATION	27	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2155-1847		978-1-4244-3970-6	INT C MANAGE SCI ENG			2009							34	39		10.1109/ICMSE.2009.5317537		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Engineering, Industrial; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	BMY95	WOS:000273956800005		
B	Starzacher, A; Rinner, B			IEEE	Starzacher, Andreas; Rinner, Bernhard			Single Sensor Acoustic Feature Extraction for Embedded Realtime Vehicle Classification	2009 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2009)			English	Proceedings Paper	10th International Conference on Parallel and Distributed Computing, Applications and Technologies	DEC 08-11, 2009	Higashi, JAPAN			acoustic feature extraction; signal processing; vehicle classification; embedded sensor fusion	FUSION	Vehicle classification is an important task for various traffic monitoring applications. This paper investigates the capabilities of acoustic feature generation for vehicle classification. Six temporal and spectral features are extracted from the audio recordings and six different classification algorithms are compared using the extracted features. We focus on a single sensor setting to keep the computational effort low and evaluate its classification accuracy and realtime performance. The experimental evaluation is performed on our embedded platform using recorded data of about 150 vehicles. The results are applied in our ongoing research on fusing video, laser and acoustic data for realtime traffic monitoring.	[Starzacher, Andreas; Rinner, Bernhard] Klagenfurt Univ, Inst Networked & Embedded Syst, Vienna, Austria	Starzacher, A (reprint author), Klagenfurt Univ, Inst Networked & Embedded Syst, Vienna, Austria.	andreas.starzacher@uni-klu.ac.at; bernhard.rinner@uni-klu.ac.at					BAOFENG G, 2008, 11 INT C INF FUS COL, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duarte MF, 2004, J PARALLEL DISTR COM, V64, P826, DOI 10.1016/j.jpdc.2004.03.020; Geiger D., 1997, MACH LEARN, P131; Hu H., 2005, CSM422 U ESS DEP COM; Klausner A, 2008, IEEE J-STSP, V2, P538, DOI 10.1109/JSTSP.2008.925988; KOLAHDOUZAN M, 2004, VLDB 2004, V30, P840; KUSHWAHA M, 2008, IEEE INT C MULT FUS, P14; NECIOGLU BF, 2005, P SPIE C, V14, P409; Nooralahiyan AY, 1998, MATH COMPUT MODEL, V27, P205, DOI 10.1016/S0895-7177(98)00060-0; Ruser H, 2007, TM-TECH MESS, V74, P93, DOI 10.1524/teme.2007.74.3.93; STARZACHER A, 2009, P 12 INT C INF FUS F; STARZACHER A, 2008, P 4 INT C INT SENS S, P85; SULZMANN JN, 2007, P 18 EUR C MACH LEAR, P371; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560	15	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5291-0				2009							378	383		10.1109/PDCAT.2009.18		6	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BUJ28	WOS:000289503500055		
S	Pradhan, G; Kalyan, GV; Satapathy, SC; Mitra, B; Pattnaik, S		Abraham, A; Herrera, F; Carvalho, A; Pai, V		Pradhan, Gunanidhi; Kalyan, Gadde Vyshnavi; Satapathy, Suresh Chandra; Mitra, Bhabatosh; Pattnaik, Sabyasachi			Minimal ANN (MANN) model for Data Classification	2009 WORLD CONGRESS ON NATURE & BIOLOGICALLY INSPIRED COMPUTING (NABIC 2009)	World Congress on Nature and Biologically Inspired Computing		English	Proceedings Paper	World Congress on Nature and Biologically Inspired Computing	DEC 09-12, 2009	Coimbatore, INDIA			ANN; Genetic Algorithm; Data classification	ARTIFICIAL NEURAL-NETWORKS	Data Classification is a prime task in Data mining. Accurate and simple data classification task can help the clustering of large dataset appropriately. In this paper we have experimented and suggested a simple ANN based classification models called as Minimal ANN ( MANN) for different classification problems. The GA is used for optimally finding out the number of neurons in the single hidden layered model. Further, the model is trained with Back Propagation (BP) algorithm and GA (Genetic Algorithm) and classification accuracies are compared. It is revealed from the simulation that our suggested model can be a very good candidate for many applications as these are simple with good performances.	[Pradhan, Gunanidhi] Bhubanananda Orissa Sch Engn, Cuttack, Orissa, India	Pradhan, G (reprint author), Bhubanananda Orissa Sch Engn, Cuttack, Orissa, India.	gunanidhi_p@rediffmail.com; vyshv.sanjana@gmail.com; sureshsatapathy@ieee.org; bhaba_mit@yahoo.co.uk; spattnaik40@yahoo.co.in					Abraham A, 2004, NEUROCOMPUTING, V56, P1, DOI 10.1016/S0925-2312(03)00369-2; Bishop C.M., 1995, NEURAL NETWORKS PATT; BUNTINE WL, 1992, STAT COMPUT, P63; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman J.H., 1984, CLASSIFICATION REGRE; Goldberg D. E., 1989, GENETIC ALGORITHMS S; HANSON R, 1992, P 12 INT JOINT C ART, P692; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Michie D., 1994, MACHINE LEARNING NEU; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Tsoi A. C., 1991, ADV NEURAL INFORMATI, V3, P963; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Yao X, 1999, P IEEE, V87, P1423	14	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2164-7364		978-1-4244-5053-4	WOR CONG NAT BIOL			2009							1058	1063				6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Mathematical & Computational Biology	Computer Science; Engineering; Mathematical & Computational Biology	BUA82	WOS:000288686500180		
J	Xing, ZZ; Pei, JA; Yu, PS		Boutilier, C		Xing, Zhengzheng; Pei, Jian; Yu, Philip S.			Early Prediction on Time Series: A Nearest Neighbor Approach	21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS			English	Proceedings Paper	21st Internation Joint Conference on Artifical Intelligence (IJCAI-09)	JUL 11-17, 2009	Pasadena, CA					In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health-informatics. We introduce a novel concept of MPL (Minimum Prediction Length) and develop ECTS (Early Classification on Time Series), an effective 1-nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable to that of a 1NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classification is effective.	[Xing, Zhengzheng; Pei, Jian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Xing, ZZ (reprint author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	zxing@cs.sfu.ca; jpei@cs.sfu.ca; psyu@cs.uic.edu					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DING C, 2005, P PKDD 2005, P224; Ding C., 2004, P 2004 ACM S APPL CO, P584, DOI 10.1145/967900.968021; EADS D, 2005, NIPS 05; GONZALEZ CJ, 2002, ECAI 02 WORKSH KNOWL, P51; Griffin MP, 2001, PEDIATRICS, V107, P97, DOI 10.1542/peds.107.1.97; Keogh E., 2002, KDD 02, P102; Keogh E., 2006, UCR TIME SERIES CLAS; Lesh N., 1999, P 5 ACM SIGKDD INT C, P342, DOI 10.1145/312129.312275; MYERS CS, 1981, AT&T TECH J, V60, P1389; Nanopoulos A., 2001, INT J COMPUTER RES, V10, P49; Wei L., 2006, P 12 ACM SIGKDD INT, P748, DOI 10.1145/1150402.1150498; Xi X., 2006, P 23 INT C MACH LEAR, P1033, DOI 10.1145/1143844.1143974; Xing Z., 2008, P SIAM INT C DAT MIN, P644	14	7	7	0	1	IJCAI-INT JOINT CONF ARTIF INTELL	FREIBURG	ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB 052, FREIBURG, D-79110, GERMANY			978-1-57735-426-0				2009							1297	1302				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BRU77	WOS:000283727900206		
S	Mennicke, J; Munzenmayer, C; Wittenberg, T; Schmid, U		VanderSloten, J; Verdonck, P; Nyssen, M; Haueisen, J		Mennicke, J.; Muenzenmayer, C.; Wittenberg, T.; Schmid, U.			An optimization framework for classifier learning from image data for computer-assisted diagnosis	4TH EUROPEAN CONFERENCE OF THE INTERNATIONAL FEDERATION FOR MEDICAL AND BIOLOGICAL ENGINEERING	IFMBE Proceedings		English	Proceedings Paper	4th European Conference of the International Federation for Medical and Biological Engineering (ECIFMBE)	NOV 23-27, 2008	Antwerp, BELGIUM			Classifier Learning; Computer-Assisted Diagnosis; Medical Image Data		In computer-assisted medical diagnosis it is often hard or even impossible to obtain a valid set of rules for disease classification by classical knowledge engineering methods. Alternatively, machine learning methods are applied to obtain classifiers from sets of data pre-classified by medical experts. Typically in a medical context, available data sets are imbalanced with respect to the possible classifications. E.g., in dermatology, there are only few data representing cases of malign melanoma vs. many cases representing benign nevi. Furthermore, there are different missclassification costs assigned to different classes. E.g., it is much more critical (i.e. costly) to erroneously classify a malign melanoma as benign than the other way around. We propose a universally applicable optimization framework that successfully corrects the error-based inductive bias of classifier learning methods on image data. The framework integrates several techniques of common optimization techniques, such as modifying the optimization procedure for inducer-specific parameters, modifying input data by an arcing algorithm, combining classifiers of several classifier learning methods (kNN, SVM and C4.5) with different settings according to locally-adaptive, cost-sensitive voting schemes. The framework is designed to make the learning process cost-sensitive and enforcing more balanced missclassification costs between classes. The framework was evaluated on image data for Barrett's esophagus with promising results compared to the base learners.	[Schmid, U.] Univ Bamberg, Fac WIAI, D-96045 Bamberg, Germany	Schmid, U (reprint author), Univ Bamberg, Fac WIAI, Feldkirchenstr 21, D-96045 Bamberg, Germany.	ute.schmid@uni-bamberg.de					Cohen P.R., 1982, HDB ARTIFICIAL INTEL, V3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cuilen J., 1988, EXPERT SYST, V5, P216; Domingos P., 1999, KNOWLEDGE DISCOVERY, P155; Mennicke J., 2008, THESIS J MENNICKE U; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T. M., 1997, MACHINE LEARNING; Munzenmayer C., 2006, COLOR TEXTURE ANAL M; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Scholkopf B., 1999, ADV KERNEL METHODS S	10	0	0	0	3	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1680-0737		978-3-540-89207-6	IFMBE PROC			2009	22	1-3					629	632				4	Engineering, Biomedical	Engineering	BYS76	WOS:000299998500150		
S	Matsushita, Y; Wada, T		Wada, T; Huang, F; Lin, S		Matsushita, Yusuke; Wada, Toshikazu			Principal Component Hashing: An Accelerated Approximate Nearest Neighbor Search	ADVANCES IN IMAGE AND VIDEO TECHNOLOGY, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	3rd Pacific-Rim Symposium on Image and Video Technology (PSIVT 2009)	JAN 13-16, 2009	Tokyo, JAPAN	Natl Inst Informat, Microsoft Res, Forum Image Informat Japan, ACM SIG Multimedia, IEEE Japan Council, IEEE Comp Soc Japan Chapter, IPSJ SIG Comp Vis & Image Media, IEICE TG Pattern Recognit & Media Understanding, Int Informat Sci Fdn, Tateisi Sci & Technol Fdn, Telecommun Advancement Fdn		Approximate Nearest Neighbor Search; High dimensional space; p-stable Locality Sensitive Hashing	ALGORITHM	Nearest Neighbor (NN) search is a basic algorithm for data mining and machine learning applications. However, its acceleration in high dimensional space is a difficult problem. For solving this problem, approximate NN search algorithms have been investigated. Especially, LSH is getting highlighted recently, because it has a clear relationship between relative error ratio and the computational complexity. However, the p-stable LSH computes hash values independent of the data distributions, and hence, sometimes the search fails or consumes considerably long time. For solving this problem, we propose Principal Component Hashing (PCH), which exploits the distribution of the stored data. Through experiments, we confirmed that PCH is faster than ANN and LSH at the same accuracy.	[Matsushita, Yusuke; Wada, Toshikazu] Wakayama Univ, Grad Sch Syst Engn, Wakayama 6408510, Japan	Matsushita, Y (reprint author), Wakayama Univ, Grad Sch Syst Engn, 930 Sakaedani, Wakayama 6408510, Japan.	ymatsushita@vrl.sys.wakayama-u.ac.jp; twada@vrl.sys.wakayama-u.ac.jp; twada@vrl.sys.wakayama-u.ac.jp					ANDONI A, 2006, P 47 ANN IEEE S FDN, P459; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Brin S., 1995, P 21 INT C VER LARG, P574; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Mayur Datar, 2004, P 20 ANN S COMP GEOM; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Vidal Ruiz E., 1986, Pattern Recognition Letters, V4, DOI 10.1016/0167-8655(86)90013-9; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Zhang Z., 1992, 1658 INRIA; ANN LIB APPROXIMATE	12	2	2	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-540-92956-7	LECT NOTES COMPUT SC			2009	5414						374	385				12	Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Computer Science; Imaging Science & Photographic Technology	BIV75	WOS:000263213300033		
S	Funes, A; Ferri, C; Hernandez-Orallo, J; Ramirez-Quintana, MJ		Theeramunkong, T; Kijsirikul, B; Cercone, N; Ho, TB		Funes, A.; Ferri, C.; Hernandez-Orallo, J.; Ramirez-Quintana, M. J.			An Instantiation of Hierarchical Distance-Based Conceptual Clustering for Propositional Learning	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	13th Pacific-Asia Conference on Knowledge Discovery and Data Mining	APR 27-30, 2009	Bangkok, THAILAND	Sirindhorn Int Inst Technol, Thammasat Univ, Chulalongkorn Univ, Asian Inst Technol, Natl Elect & Comp Technol Ctr, Thailand Convent & Exhibit Bureau, AF Off Sci Res, Asian Off Aerosp Res & Dev		conceptual clustering; hierarchical clustering; generalisation; distances; propositional learning		In this work we analyse the relationship between distance and generalisation operators for real numbers, nominal data and tuples in the context of hierarchical distance-based conceptual clustering (HDCC). HDCC is a general approach to conceptual clustering that extends the traditional algorithm for hierarchical clustering by producing conceptual generalisations of the discovered clusters. This snakes it possible to combine the flexibility of changing distances for several clustering problems and the advantage of having concepts which are crucial l or tasks as summarisation and descriptive data mining in general. In this work we propose it set of generalisation operators and distances for the data types mentioned before and we analyse the properties by them satisfied on the basis of three different levels of agreement between the clustering hierarchy obtained from the linkage distance and the hierarchy obtained by using generalisation operators.	[Funes, A.; Ferri, C.; Hernandez-Orallo, J.; Ramirez-Quintana, M. J.] Univ Politecn Valencia, DSIC, Valencia 46022, Spain	Funes, A (reprint author), Univ Politecn Valencia, DSIC, Camino Vera S-N, Valencia 46022, Spain.	afunes@dsic.upv.es; cferri@dsic.upv.es; jorallo@dsic.upv.es; mramirez@dsic.upv.es	Ramirez Quintana, Maria Jose/H-9174-2015; Ferri Ramirez, Cesar/H-9181-2015; Hernandez-Orallo, Jose/H-9166-2015	Ramirez Quintana, Maria Jose/0000-0002-0559-3568; Ferri Ramirez, Cesar/0000-0002-8975-1120; Hernandez-Orallo, Jose/0000-0001-9746-7632			Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25, DOI 10.1007/3-540-28349-8_2; Black C. L., 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; ESTRUCH V, 2008, THESIS DSIC UPV; Fisher D. H., 1987, Machine Learning, V2, DOI 10.1007/BF00114265; Fisher RA, 1936, ANN EUGENIC, V7, P179; FUNES A, 2008, LNCS, V5212, P349; FUNES A, 2008, THESIS DSIC UPV; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; Michalski R. S., 1983, MACHINE LEARNING ART, P331; Michalski R. S., 1980, International Journal of Policy Analysis and Information Systems, V4; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Talavera L, 2001, IEEE T PATTERN ANAL, V23, P196, DOI 10.1109/34.908969	14	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01306-5	LECT NOTES ARTIF INT			2009	5476						637	646				10	Computer Science, Artificial Intelligence	Computer Science	BKN07	WOS:000268632000060		
S	Vo, N; Moran, B; Challa, S		Yu, W; He, HB; Zhang, N		Vo, Nhat; Moran, Bill; Challa, Subhash			Nonnegative-Least-Square Classifier for Face Recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	6th International Symposium on Neural Networks	MAY 26-29, 2009	Wuhan, PEOPLES R CHINA	Huazhong Univ Sci & Technol, Chinese Univ Hong Kong, Natl Nat Sci Fdn, IEEE Wuhan Sect, IEEE Computat Intel Soc, Int Neural Network Soc		Face Recognition; Eigenfaces; Fisherfaces; Nonnegative-Least-Square		In this paper, we propose a novel classification method, based on Nonnegative-Least-Square, (NNLS) algorithm, for face, recognition. Different from traditional classifiers, in our classifier, we consider each new sample (face) as a nonnegative linear combination of training samples (faces). By forcing the nonnegative constraint on linear coefficients, we obtain the nonnegative sparse representation that automatically discriminates between those classes present in the training set, Experimental results show the promising aspects of new classifier when comparing with the most popular classifiers such as Nearest Neighborhood (NN), Nearest Centroid (NC), and Nearest, Subspace (NS) in terms of recognition accuracy, efficiency, and numerical stability. Eigenfaces Fisherfaces, and Laplacianfaces are performed on Yale and ORL databases as feature extraction in these experiments	[Vo, Nhat; Moran, Bill; Challa, Subhash] Univ Melbourne, Melbourne, Vic 3010, Australia	Vo, N (reprint author), Univ Melbourne, Melbourne, Vic 3010, Australia.	n.vo@pgrad.unimelb.edu.au; b.moran@ee.unimelb.edu.au; subhash.challa@nicta.com.au					Bellhumeur P. N., 1997, IEEE T PATTERN ANAL, V19, P711; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, INTRO STAT PATTERN R; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Huang R., 2002, P INT C PATT REC QUE, V3, P29; Lawson C. L., 1974, PRENTICE HALL SERIES; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhao W., 1998, FG, P336	11	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01512-0	LECT NOTES COMPUT SC			2009	5553						449	456				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BKG61	WOS:000268029200049		
S	Gu, SC; Tan, Y; He, XG		Yu, W; He, HB; Zhang, N		Gu, Suicheng; Tan, Ying; He, Xhigui			Orthogonal Quadratic Discriminant Functions for Face Recognition	ADVANCES IN NEURAL NETWORKS - ISNN 2009, PT 3, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	6th International Symposium on Neural Networks	MAY 26-29, 2009	Wuhan, PEOPLES R CHINA	Huazhong Univ Sci & Technol, Chinese Univ Hong Kong, Natl Nat Sci Fdn, IEEE Wuhan Sect, IEEE Computat Intel Soc, Int Neural Network Soc		Orthogonal quadratic discriminant functions (OQDF); modified quadratic discriminant function (MQDF); small sample size (SSS); face recognition (FR); Laplacian Smoothing Transform(LST); Fisher's linear discriminant(FLD)	CLASSIFICATION	Small sample size (SSS) problem is usually a limit, to the robustness of learning methods hi face recognition. Especially in the quadratic discriminant functions (QDF), too many parameters need to be estimated and covariance matrix Of a Class is usually singular. In order to overcome the SSS problems, we proposed a, novel approach called orthogonal quadratic discriminate functions (C)QDF). The OQDF assumes probability distribution Functions of each two classes of face images have a uniform shape. Then, three OQDF models are developed. The Laplacian smoothing transform (LST) and Fisher's linear discriminant (FLD) are employed to preprocess the face images for the OQDF classifier. Finally, we evaluate, our proposed algorithms on two face databases, ORL and Yale.	[Gu, Suicheng; Tan, Ying; He, Xhigui] Peking Univ, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China	Gu, SC (reprint author), Peking Univ, Dept Machine Intelligence, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	ytan@pku.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; ER MJ, 2005, IEEE T NEURAL NETWOR, V16; Fan RE, 2005, J MACH LEARN RES, V6, P1889; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; GU S, 2008, LAPLACIAN SMOO UNPUB; Heisele B., 2001, ICCV; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149; Liu C.-L., 2004, IEEE T NEURAL NETWOR; Long LA, 2008, FRONTIERS, V29, P1; LU J, 2003, PATTEN RECOGNITION L, P3079; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG J, 2008, PATTERN RECOGN, P1528; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	16	1	1	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-01512-0	LECT NOTES COMPUT SC			2009	5553						466	475				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BKG61	WOS:000268029200051		
S	Khoo, S; Gedeon, T		Koppen, M; Kasbov, N; Coghill, G		Khoo, Suisin; Gedeon, Tom			Generalisation Performance vs. Architecture Variations in Constructive Cascade Networks	ADVANCES IN NEURO-INFORMATION PROCESSING, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Conference on Neuro-Information Processing	NOV 25-28, 2008	Auckland, NEW ZEALAND	Asia Pacific Neural Network Assembly, Int Neural Network Soc, IEEE Computat Intell Soc, Japanese Neural Network Soc, European Neural Network Soc, Knowledge Engn & Discovery Res Inst, Auckland Univ Technol, Toyota USA, Auckland Sky City, Auckand Univ Technol, Sch Comp & Math Sci			FACE RECOGNITION	Constructive cascade algorithms are powerful methods for training feedforward neural networks with automation of the task of specifying the size and topology of network to use. A series of empirical studies were performed to examine the effect of imposing constraints on constructive cascade neural network architectures. Building a priori knowledge of the task into the network gives better generalisation performance. We introduce our Local Feature Constructive Cascade (LoCC) and Symmetry Local Feature Constructive Cascade (SymLoCC) algorithms, and show them to have good generalisation and network construction properties on face recognition tasks.	[Khoo, Suisin; Gedeon, Tom] Australian Natl Univ, Coll Engn & Comp Sci, Sch Comp Sci, Canberra, ACT 0200, Australia	Khoo, S (reprint author), Australian Natl Univ, Coll Engn & Comp Sci, Sch Comp Sci, GPO Box 4, Canberra, ACT 0200, Australia.	suisin.khoo@cs.anu.edu.au; tom@cs.anu.edu.au					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fahlman S.E., 1990, CASCADE CORRELATION; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Grudin MA, 2000, PATTERN RECOGN, V33, P1161, DOI 10.1016/S0031-3203(99)00104-1; KHOO S, 2008, THESIS AUSTR NATL U; Kwok TY, 1997, IEEE T NEURAL NETWOR, V8, P630; LeCun Y, 1989, GEN NETWORK DESIGN S; Nguyen D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), DOI 10.1109/IJCNN.1990.137819; Riedmiller M., 1993, IEEE INT C NEUR NETW, P586, DOI 10.1109/ICNN.1993.298623; TREADGOLD NK, 1998, P 1998 IEEE INT C SY, P4465; Treadgold NK, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P343	11	0	0	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-03039-0	LECT NOTES COMPUT SC			2009	5507						236	243				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BLN31	WOS:000270578200029		
B	Wu, CH; Yeh, JF; Chuang, ZJ		Tao, J; Tan, T		Wu, Chung-Hsien; Yeh, Jui-Feng; Chuang, Ze-Jing			Emotion Perception and Recognition from Speech	AFFECTIVE INFORMATION PROCESSING			English	Proceedings Paper	1st International Conference on Affective Computing and Intelligent Interaction	OCT 22-24, 2005	Beijing, PEOPLES R CHINA	Nokia Ltd, Siemens Ltd, Int Speech Commun Assoc, Natl Nat Sci Fdn China, Chinese Assoc Automat, China Soc Image & Graph, China Comp Federat, Natl High-Tech Res & Dev Program			HUMAN-COMPUTER INTERACTION; DIRECTED SPEECH; CLASSIFICATION; FEATURES	With the increasing role of speech interfaces in human-computer interaction applications, automatically recognizing emotions from human speech becomes more and more important. This chapter begins by introducing the correlations between basic speech features such as pitch, intensity, formants, MFCC, and so on, and the emotions. Several recognition methods are then described to illustrate the performance of the previously proposed models, including support vector machine (SVM), K-nearest neighbors (KNN), neural networks, and the like. To give a more practical description of all emotion recognition procedure, a new approach to emotion recognition is provided as a case study. In this case study, the Intonation Groups (IGs) of the input speech signals are first defined and extracted for C feature extraction. With the assumption of linear mapping between feature spaces in different emotional states, a feature compensation approach is proposed to characterize the feature space with better discriminability among emotional states. The compensation vector with respect to each emotional state is estimated using the Minimum Classification Err or (MCE) algorithm. The IG-based feature vectors compensated by the compensation vectors are used to train the Gaussian Mixture Models (GMMs) for each emotional state. The emotional state with the GMM having the maximal likelihood ratio is determined as the emotion state output.	[Wu, Chung-Hsien; Chuang, Ze-Jing] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan	Wu, CH (reprint author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.	chwu@csie.ncku.edu.tw					BHATTI MW, 2004, IEEE INT S CIRC SYST, P181; Borod J. C., 2000, NEUROPSYCHOLOGY EMOT, P3; Breazeal C, 2002, AUTON ROBOT, V12, P83, DOI 10.1023/A:1013215010749; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chuang Z.J., 2004, INT J COMPUTATIONAL, V9, P1; Cichosz J., 2007, EMOTION RECOGNITION; Cichosz J, 2005, INTERSPEECH 2005 LIS, P477; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Damasio Antonio, 1994, DESCARTES ERROR EMOT; Deng L, 2003, IEEE T SPEECH AUDI P, V11, P568, DOI 10.1109/TSA.2003.818076; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; DMELLO S, 2007, IEEE INTELL SYST APP, P53; Engberg I. S., 1996, DOCUMENTATION DANISH; FERNANDEZ R, 2005, INTERSPEECH, P473; Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006; HUBER R, 1998, P WORKSH TEXT SPEECH, P223; Inanoglu Z., 2005, IEEE INTELLIGENT USE, P251; Katz GS, 1996, CHILD DEV, V67, P205, DOI 10.1111/j.1467-8624.1996.tb01729.x; Kwon O., 2003, P 8 EUR C SPEECH COM, P125; Lee Chin-Hui, 2007, P INT, P1825; Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534; LEVITY M, 2001, PROSODY SPEECH RECOG; Liscombe J., 2005, P INT LISB PORT, P1845; Litman D., 2004, P 4 HLT NAACL C, P233; Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004; MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558; Nakayama T, 1999, ELEC SOC S, V99, P2; Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S01167-6393(03)00099-2; ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037//0033-295X.97.3.315; Oudeyer P.-Y., 2003, INT J HUMAN COMPUTER, V59, P157, DOI DOI 10.1016/S1071-581(02)00141-6; Paeschke A., 2000, P ISCA WORKSH SPEECH, P75; Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122; Parrott W. G, 2001, EMOTIONS SOCIAL PSYC; Petrushin V., 1999, P ART NEUR NETW ENG, P7; Petrushin V.A., 2000, P 6 INT C SPOK LANG, P222; Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607; Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6; RAHURKAR MA, 2003, 8 EUR C SPEECH COMM, P721; Reeves Byron, 1996, MEDIA EQUATION PEOPL; Scherer K. R., 1999, HDB COGNITION EMOTIO, P637; Shami M, 2007, SPEECH COMMUN, V49, P201, DOI 10.1016/j.specom.2007.01.006; SHAMI M, 2005, IEEE C MULT EXP ICME; SHRIBERG E, 2005, EUR 2005 LISB PORT; Slaney M, 2003, SPEECH COMMUN, V39, P367, DOI 10.1016/S0167-6393(02)00049-3; ten Bosch L, 2003, SPEECH COMMUN, V40, P213, DOI 10.1016/S0167-6393(02)00083-3; Vapnik V. N., 2005, NATURE STAT LEARNING; VERVERIDIS D, 2005, IEEE INT C AC SPEECH, P593; WU J, 2002, 7 INT C SPOK LANG DE, P453; Yacoub S., 2003, P EUROSPEECH, P729	49	7	7	0	1	SPRINGER-VERLAG LONDON LTD	GODALMING	SWEETAPPLE HOUSE CATTESHALL RD FARNCOMBE, GODALMING GU7 1NH, SURREY, ENGLAND			978-1-84800-305-7				2009							93	110		10.1007/978-1-84800-306-4_6		18	Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Computer Science	BIZ98	WOS:000264082400006		
S	Gagliardi, F		Serra, R; Cucchiara, R		Gagliardi, Francesco			The Necessity of Machine Learning and Epistemology in the Development of Categorization Theories: A Case Study in Prototype-Exemplar Debate	AI (ASTERISK) IA 2009: EMERGENT PERSPECTIVES IN ARTIFICIAL INTELLIGENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	11th Congress of the Italian-Association-for-Artificial-Intelligence	DEC 09-12, 2009	Reggio Emilia, ITALY	Italian Assoc Artificial Intelligence, Univ Modena Reggio Emilia		Machine Learning; Epistemology; Cognitive Psychology; Categorization Theories; Bias-Variance Dilemma; Instance-Based Learning	ATTENTIONAL ALLOCATION; CLASSIFICATION; ALGORITHMS; ACCOUNTS	In the present paper we discuss some aspects of the development of categorization theories concerning cognitive psychology and machine learning. We consider the thirty-year debate between prototype-theory and exemplartheory in the studies of cognitive psychology regarding the categorization processes. We propose this debate is ill-posed, because it neglects some theoretical and empirical results of machine learning about the bias-variance theorem and the existence of some instance-based classifiers which can embed models subsuming both prototype and exemplar theories. Moreover this debate lies on a epistemological error of pursuing a, so called, experimentum crucis. Then we present how an interdisciplinary approach, based on synthetic method for cognitive modelling, can be useful to progress both the fields of cognitive psychology and machine learning.	[Gagliardi, Francesco] Univ Roma La Sapienza, Dept Philosoph & Epistemol Studies, I-00161 Rome, Italy	Gagliardi, F (reprint author), Univ Roma La Sapienza, Dept Philosoph & Epistemol Studies, Via Carlo Fea, I-00161 Rome, Italy.	francesco.gagliardi@libero.it					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; CORDESCHI R, 1994, FILOSOFIA AUTOMI ORI, P19; Cordeschi R., 2008, MECH MIND HIST, P219; CORDESCHI R, 2001, DISCOVERY ARTIFICIAL; CORDESCHI R, 2003, RIV FILOSOFIA INTELL, V1, P1; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fayyad U., 1996, ADV KNOWLEDGE DISCOV; Frank E., 2005, DATA MINING PRACTICA; Gagliardi F., 2008, P 30 ANN C COGN SCI, P1176; Gardenfors P., 2000, CONCEPTUAL SPACES GE; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Henery R. J., 1994, MACHINE LEARNING NEU, P107; HOUDE O., 1998, VOCABULAIRE SCI COGN; KRUSCHKEA JK, 2001, INT ENCY SOCIAL BEHA, P1532; LANGLEY P, 2006, ARTIFICIAL INTELLIGE; MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037//0033-295X.85.3.207; MEDIN DL, 1989, AM PSYCHOL, V44, P1469, DOI 10.1037/0003-066X.44.12.1469; Medin Douglas L., 1999, MIT ENCY COGNITIVE S, P104; Merton R. K., 1949, SOCIAL THEORY SOCIAL; Merton R. K., 1973, SOCIOLOGY SCI THEORE; Merton RK, 1968, SOCIAL THEORY SOCIAL; Minda JP, 2002, J EXP PSYCHOL LEARN, V28, P275, DOI 10.1037//0278-7393.28.2.275; Murphy G, 2002, BIG BOOK CONCEPTS; Nieddu L, 2000, EUR J OPER RES, V120, P459, DOI 10.1016/S0377-2217(98)00368-3; Rogoff B., 1991, APPRENTICESHIP THINK; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037//0096-3445.104.3.192; Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379; Thagard P, 2005, MIND INTRO COGNITIVE, V2nd; Vanpaemel W., 2005, P 27 ANN C COGN SCI, P2277; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1417, DOI 10.1109/TPAMI.2005.187; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zaki SR, 2003, J EXP PSYCHOL LEARN, V29, P1160, DOI 10.1037/0278-7393.29.6.1160	36	1	1	2	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-10290-5	LECT NOTES ARTIF INT			2009	5883						182	191				10	Computer Science, Artificial Intelligence	Computer Science	BPK22	WOS:000279047900019		
J	Kagie, M; van der Loos, M; van Wezel, M				Kagie, Martijn; van der Loos, Matthijs; van Wezel, Michiel			Including item characteristics in the probabilistic latent semantic analysis model for collaborative filtering	AI COMMUNICATIONS			English	Article						Recommender systems; probabilistic latent semantic analysis; hybrid recommender systems	RECOMMENDER SYSTEMS; MAXIMUM-LIKELIHOOD; REGRESSION; ALGORITHM; FRAMEWORK	We propose a new hybrid recommender system that combines some advantages of collaborative and content-based recommender systems. While it uses ratings data of all users, as do collaborative recommender systems, it is also able to recommend new items and provide an explanation of its recommendations, as do content-based systems. Our approach is based on the idea that there are communities of users that find the same characteristics important to like or dislike a product. This model is an extension of the probabilistic latent semantic model for collaborative filtering with ideas based on clusterwise linear regression. On a movie data set, we show that the model, at the cost of a very small loss in overall performance, is able to recommend new items and give an explanation of its recommendations to its users.	[Kagie, Martijn; van der Loos, Matthijs; van Wezel, Michiel] Erasmus Univ, Erasmus Sch Econ, NL-3000 DR Rotterdam, Netherlands	Kagie, M (reprint author), Erasmus Univ, Erasmus Sch Econ, POB 1738, NL-3000 DR Rotterdam, Netherlands.	kagie@ese.eur.nl; mvanderloos@ese.eur.nl; mvanwezel@ese.eur.nl	Sucunuta, Manuel/G-7550-2015	Sucunuta, Manuel/0000-0002-9334-8625			Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Aikake H, 1974, IEEE T AUTOMAT CONTR, V19, P716, DOI 10.1109/TAC.1974.1100705; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124; Basu C., 1998, Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98). Tenth Conference on Innovative Applications of Artificial Intelligence; Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781; Bishop C. M., 2006, PATTERN RECOGNITION; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Breese J S, 1998, P 14 C UNC ART INT, P43; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Camargo SJ, 2007, J CLIMATE, V20, P3635, DOI 10.1175/JCLI4188.1; Claypool M., 1999, P ACM SIGIR WORKSH R; CONDLIFF MK, 1999, P ACM SIGIR WORKSH R; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167; Desarbo WS, 2005, STRATEGIC MANAGE J, V26, P47, DOI 10.1002/smj.431; DeSarbo W.S., 1992, MARKET LETT, V3, P273, DOI 10.1007/BF00994135; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209; Good N., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772; Herlocker JL, 2000, P 2000 ACM C COMP SU, P241, DOI DOI 10.1145/358916.358995; Herlocker J. L., 1999, Proceedings of SIGIR '99. 22nd International Conference on Research and Development in Information Retrieval, DOI 10.1145/312624.312682; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; HOFMANN T, 1999, P 15 C UNC ART INT U, P289; KOREN Y, 2009, IEEE COMPUT, V42, P30; KRIEGLER M, 2006, EUR J AGEING, V2, P13; Larcker DF, 2004, J ACCOUNTING RES, V42, P625, DOI 10.1111/j.1475-679X.2004.t01-1-00143.x; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; McCullagh PN, 1989, MONOGRAPHS STAT APPL, V37; Mcsherry D, 2005, ARTIF INTELL REV, V24, P179, DOI 10.1007/s10462-005-4612-x; Melville P., 2002, P 18 NAT C ART INT, P187; Pazzani M., 2007, LNCS, V4321, P325, DOI DOI 10.1007/978-3-540-72079-9_10; Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Pennings JME, 2004, J BANK FINANC, V28, P951, DOI 10.1016/S0378-4266(03)00046-3; Popescul A., 2001, P 17 C UNC ART INT U, P437; Prasad B., 2003, J ELECT COMMERCE RES, V4, P65; RAMASWAMY V, 1993, MARKET SCI, V12, P103, DOI 10.1287/mksc.12.1.103; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P., 1994, P ACM C COMP SUPP CO, P175, DOI DOI 10.1145/192844.192905; Sarwar BM, 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/564376.564421; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shardanand U., 1995, P C HUM FACT COMP SY, P210, DOI DOI 10.1145/223904.223931; Sinha R, 2002, C HUM FACT COMP SYST, P830; SOBOROFF I, 1999, P IJCAI WORKSH MACH; Takacs Gabor, 2008, P 2008 ACM C REC SYS, P267, DOI 10.1145/1454008.1454049; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; Tintarev N., 2007, P 23 INT C DAT ENG W, P801, DOI 10.1109/ICDEW.2007.4401070; TRAN T, 2000, P KNOWL BAS EL MARK; Vriens M, 1996, J MARKETING RES, V33, P73, DOI 10.2307/3152014; WEDEL M, 1995, J CLASSIF, V12, P21, DOI 10.1007/BF01202266; Zhou YH, 2008, LECT NOTES COMPUT SC, V5034, P337	57	0	1	0	6	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0921-7126			AI COMMUN	AI Commun.		2009	22	4					249	265		10.3233/AIC-2009-0467		17	Computer Science, Artificial Intelligence	Computer Science	535HR	WOS:000272958500004		
S	Salmeri, A; Licciardi, CA; Lamorte, L; Valla, M; Giannantonio, R; Sgroi, M		Mokhtari, M; Khalil, I; Bauchet, J; Zhang, D; Nugent, C		Salmeri, Alessia; Licciardi, Carlo Alberto; Lamorte, Luca; Valla, Massimo; Giannantonio, Roberta; Sgroi, Marco			An Architecture to Combine Context Awareness and Body Sensor Networks for Health Care Applications	AMBIENT ASSISTIVE HEALTH AND WELLNESS MANAGEMENT IN THE HEART OF THE CITY, PROCEEDING	Lecture Notes in Computer Science		English	Proceedings Paper	7th International Conference on Smart Homes and Health Telematics	JUL 01-03, 2009	Tour, FRANCE			Body Sensor Network; Wireless Sensor Network; SPINE; Context Awareness Platform; Context Broker; ContextML; Context Query Language; health care monitoring		Information derived from wearable sensors, such as illness/fall alarms, can be enhanced with context information to provide advanced health care and assisted living applications. In this paper we describe an architecture that combines sensor and context data into a telecommunication service to detect emergency situations and generate alarm calls according to user's preferences and contacts geographic proximity.	[Salmeri, Alessia; Licciardi, Carlo Alberto; Lamorte, Luca; Valla, Massimo; Giannantonio, Roberta] Telecom Italia Lab, I-10148 Turin, Italy	Salmeri, A (reprint author), Telecom Italia Lab, Via Reiss Romoli 274, I-10148 Turin, Italy.	alessia.salmeri@telecomitalia.it; carlo.licciardi@telecomitalia.it; luca.lamorte@telecomitalia.it; massimo.valla@telecomitalia.it; roberta.giannantonio@telecomitalia.it; marco.sgroi@wsnlabberkeley.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEY AK, 2001, SPECIAL ISSUE CONTEX, V16, P97; GRAVINA R, 2008, 2008 IEEE INT C SYST; Henricksen K, 2005, LECT NOTES COMPUT SC, V3760, P846; LAMORTE L, 2007, 11 WORKSH CONT AW PR; LOMBRISER C, 2007, 15 FACHT KOMM VERT S, P127; LOMBRISER C, 2007, P 2 INT C BOD AR NET; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Reichle R, 2008, P 5 IEEE WORKSH CONT, P434; Roman M., 2002, IEEE Pervasive Computing, V1, DOI 10.1109/MPRV.2002.1158281; SEPPA VP, 2008, P 4 EUR C MED BIOM E; SHNAYDER V, 2005, TR0805 HARV U DIV EN	12	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02867-0	LECT NOTES COMPUT SC			2009	5597						90	97				8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BLG61	WOS:000270130800012		
J	Umezawa, K; Ikebe, J; Nomizu, M; Nakamura, H; Higo, J				Umezawa, Koji; Ikebe, Jinzen; Nomizu, Motoyoshi; Nakamura, Haruki; Higo, Junichi			Conformational Requirement on Peptides to Exert Laminin's Activities and Search for Protein Segments With Laminin's Activities	BIOPOLYMERS			English	Article						laminin; molecular dynamics; peptide conformation; database search; structure-function relationship	BETA-HAIRPIN PEPTIDE; ENERGY LANDSCAPE; CELL-ADHESION; DISORDERED CONFORMATIONS; MOLECULAR-DYNAMICS; CRYSTAL-STRUCTURE; EXPLICIT WATER; SWISS-MODEL; G-DOMAIN; CHAIN	The human laminin alpha 3 chain LG4 module has biological activities of cell adhesion, heparin binding, migration, and neurite outgrowth. The authors had previously identified that the active site of this protein is in residues 1411-1429 (amino-acid sequence = KNSFMALYLSKGRLVFALG called A3G756) and that a three-amino-acid sequence KGR in A3G756 is crucial for exerting the activities. An experiment has shown that a cyclo-hEF3A peptide (a cyclic analog of A3G756) exhibits stronger activities than a linear-hEF3A peptide (a linearized peptide of the cyclo-hEF3A peptide). This experiment implies that adopting a loop conformation may be important for exerting the activities. In this study, the authors first computed the solution structures of the cyclo-hEF3A and linear-hEF3A peptides by molecular dynamics simulations. The obtained conformational ensembles consisted of a variety of conformations, which is a usual property of short peptides in solution. The ensembles involved a fraction where the peptide adopted beta-hairpins and KGR was located at the hairpin head. If there are protein segments that adopt beta-hairpins similar to those sampled from the simulation and have the KGR sequence at the hairpin head, these segments may have some activities. Then, the authors searched a database for segments satisfying these requirements and detected six functional segments. Three of them had laminin's activity, and the remaining three had activities similar to laminin's activities. Analyses on the conformational ensembles of cyclo- and linear-hEF3A peptides suggest that not only the KGR position in the hairpin but also the inter-strand packing is important for exerting laminin's activities. (c) 2009 Wiley Periodicals, Inc. Biopolymers (Pept Sci) 92: 124-131, 2009.	[Higo, Junichi] Osaka Univ, Open Labs Adv Biosci & Biotechnol, Ctr Adv Med Engn & Informat, Osaka 5640874, Japan; [Umezawa, Koji; Ikebe, Jinzen] Osaka Univ, Open Labs Adv Biosci & Biotechnol, Grad Sch Frontier Biosci, Osaka 5650874, Japan; [Nomizu, Motoyoshi] Tokyo Univ Pharm & Life Sci, Sch Pharm, Lab Clin Biochem, Tokyo 1920392, Japan; [Nakamura, Haruki] Osaka Univ, Inst Prot Res, Suita, Osaka 5650871, Japan	Higo, J (reprint author), Osaka Univ, Open Labs Adv Biosci & Biotechnol, Ctr Adv Med Engn & Informat, 6-2-3 Furuedai, Osaka 5640874, Japan.	higo@protein.osaka-u.ac.jp					Arnold K, 2006, BIOINFORMATICS, V22, P195, DOI 10.1093/bioinformatics/bti770; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Burke DF, 2000, BIOINFORMATICS, V16, P513, DOI 10.1093/bioinformatics/16.6.513; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dai JY, 2004, CELL, V116, P649, DOI 10.1016/S0092-8674(04)00172-2; Espadaler J, 2004, NUCLEIC ACIDS RES, V32, pD185, DOI 10.1093/nar/gkh002; Frank BS, 2004, J BIOL CHEM, V279, P7909, DOI 10.1074/jbc.M310524200; Fukunishi Y, 2003, J PHYS CHEM B, V107, P13201, DOI 10.1021/jp035478e; Guex N, 1997, ELECTROPHORESIS, V18, P2714, DOI 10.1002/elps.1150181505; Gutteridge A, 2005, J MOL BIOL, V346, P21, DOI 10.1016/j.jmb.2004.11.013; Higo J, 2001, CHEM PHYS LETT, V337, P169, DOI 10.1016/S0009-2614(01)00118-X; Higo J, 2001, PROTEIN SCI, V10, P1160, DOI 10.1110/ps.44901; Iivanainen A, 1999, J BIOL CHEM, V274, P14107, DOI 10.1074/jbc.274.20.14107; Ikeda K, 2003, J COMPUT CHEM, V24, P310, DOI 10.1002/jcc.10160; Kamiya N, 2002, PROTEIN SCI, V11, P2297, DOI 10.1110/ps.0213102; Kasper C, 2000, NAT STRUCT BIOL, V7, P389; Katayama M, 2004, J MOL HISTOL, V35, P277; Kato K, 2002, BIOCHEMISTRY-US, V41, P10747, DOI 10.1021/bi020180k; Kato-Takagaki K, 2007, BIOCHEMISTRY-US, V46, P1952, DOI 10.1021/bi0620981; Kim JG, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.057103; Kim JG, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.021110; Kollman P. A., 1997, COMPUTER SIMULATION; Laskowski RA, 2005, NUCLEIC ACIDS RES, V33, pW89, DOI 10.1093/nar/gki414; Laskowski RA, 2005, J MOL BIOL, V351, P614, DOI 10.1016/j.jmb.2005.05.067; Libby RT, 2000, J NEUROSCI, V20, P6517; Miner JH, 1997, J CELL BIOL, V137, P685, DOI 10.1083/jcb.137.3.685; Momota Y, 2005, J RECEPT SIG TRANSD, V25, P1, DOI 10.1081/RRS-200047870; Narasimhan J, 2005, J BIOL CHEM, V280, P27356, DOI 10.1074/jbc.M502814200; Onufriev A, 2000, J PHYS CHEM B, V104, P3712, DOI 10.1021/jp994072s; Rajarathnam K, 2001, J BIOL CHEM, V276, P4909, DOI 10.1074/jbc.M005085200; REYES AA, 1990, CELL REGUL, V1, P567; Ritchie KJ, 2004, SEMIN CELL DEV BIOL, V15, P237, DOI 10.1016/j.semcdb.2003.12.005; ROUSSELLE P, 1994, J CELL BIOL, V125, P205, DOI 10.1083/jcb.125.1.205; Rychaert J. P., 1977, J COMPUT PHYS, V23, P327; Sauder JM, 2000, PROTEINS, V40, P6, DOI 10.1002/(SICI)1097-0134(20000701)40:1<6::AID-PROT30>3.0.CO;2-7; Shirai H, 1999, FEBS LETT, V455, P188, DOI 10.1016/S0014-5793(99)00821-2; Terada T, 2002, J CHEM PHYS, V116, P33, DOI 10.1063/1.1423938; Tisi D, 2000, EMBO J, V19, P1432, DOI 10.1093/emboj/19.7.1432; Utani A, 2001, J BIOL CHEM, V276, P28779, DOI 10.1074/jbc.M101420200; Yang J, 2003, J BIOL CHEM, V278, P6516, DOI 10.1074/jbc.M210430200; Yang MY, 2006, J BIOL CHEM, V281, P28307, DOI 10.1074/jbc.M604413200	41	0	0	0	1	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0006-3525			BIOPOLYMERS	Biopolymers		2009	92	2					124	131		10.1002/bip.21148		8	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	426ES	WOS:000264691400006	19180521	
S	Jo, T		Slezak, D; Kim, TH; Zhang, Y; Ma, J; Chung, KI		Jo, Taeho			Categorizing News Articles Using NTC without Decomposition	DATABASE THEORY AND APPLICATION	Communications in Computer and Information Science		English	Proceedings Paper	International Conference on Database Theory and Application held at the FGIT 2009 Conference	DEC 10-12, 2009	Cheju Isl, SOUTH KOREA				SUPPORT VECTOR MACHINES; CLASSIFICATION	In this research, we attempt to apply the NTC (Neural Text Categorizer) to the text categorization without decomposing it into binary classifications. Because a single classifier has its very weak robustness to the entire text categorization, it is usually decomposed into binary classifications as many as categories. However, it requires to rearrange and relabel the given training examples with positive or negative labels for decomposing the text categorization. The task of this research is to apply the NTC to the text categorization without the decomposition and validate its feasibility. Therefore, we will compare the NTC with other approaches in the text categorization in the environment where the text categorization is not decomposed and validate that the NTC is practical tool for implement a light version of text categorization system.	Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea	Jo, T (reprint author), Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea.	tjo018@inha.ac.kr					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI, V1st; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Joachims T, 1998, P 10 EUR C MACH LEAR, P143; Kononenko I, 1989, P 4 EUR WORK SESS LE, P91; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Massand B, 1992, P 15 ACM INT C RES D, P59; McClelland J. L., 1986, PARALLEL DISTRIBUTED, VI; McClelland J. L., 1986, PARALLEL DISTRIBUTED, VII; Mitchell T. M., 1997, MACHINE LEARNING; Mladenic D, 1999, P INT C MACH LEARN, P256; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Wiener ED, 1995, THESIS U COLORADO; Yang Y, 1999, INFORMATION RETRIEVA, V1, P67	17	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-642-10582-1	COMM COM INF SC			2009	64						34	40				7	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Computer Science	BPZ42	WOS:000280424500005		
S	Lee, YH; Tsao, WJ; Chu, TH		Weinhardt, C; Luckner, S; Stober, J		Lee, Yen-Hsien; Tsao, Wan-Jung; Chu, Tsai-Hsin			Use of Ontology to Support Concept-Based Text Categorization	DESIGNING E-BUSINESS SYSTEMS	Lecture Notes in Business Information Processing		English	Proceedings Paper	7th Workshop on e-Business (WeB 2008)	DEC 13, 2008	Paris, FRANCE	AIS SIGeBIZ, Karlsruhe Inst Technol, Natl Sun Yat Sen Univ, Univ Illinois, Ctr IT & eBusiness Manage, IESEG Sch Manage	Univ Karlsruhe, Inst Informat Syst & Manage	Document-category management; Concept-based text categorization; Ontology; k-nearest neighbors		Huge volumes of worldwide accessible information have led to the tool necessity for better handling of massive information to overcome the conventional manual method. Thus, automated text categorization technique serves to Support a more effective document organization management. Fundamentally. conventional text categorization techniques concentrate on the analysis of document contents and and measure the similarity based on the overlap among the features Of unlabeled documents and that of pre-classified documents. However, Such feature-based approach will be confront with the problems of word mismatch and word ambiguity. To lessen these problems, this study proposes an ontology-based text categorization technique. It employs the specific domain ontology to enable documents to be classified in accordance to their range of relevant concepts. The effectiveness of the proposed technique is measured and compared with its benchmark technique. The evaluation results Suggest Our proposed technique is more effective than the benchmarks.	[Chu, Tsai-Hsin] Natl Chiayi Univ, Dept E Learning Design & Management, Chiayi, Taiwan		yhlee@mail.ncyu.edu.tw; s0951317@mail.ncyu.edu.tw; thchu@mail.ncyu.edu.tw					Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Breiman L., 1984, CLASSIFICATION REGRE; BRILL E, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P152; BRILL E, 1994, 12 INT C ART INT, P722; Cardoso-Cachopo A, 2003, LECT NOTES COMPUT SC, V2857, P183; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; CLARK P, 1991, 5TH P EUR WORK SESS, P151; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; *DELPH GROUP, 2002, TAX CONT CLASS MARK; Dumais S., 1998, 7 INT C INF KNOWL MA, P148, DOI 10.1145/288627.288651; Fensel D., 2000, ONTOLOGIES SILVER BU; GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008; Heckerman D, 1997, DATA MIN KNOWL DISC, V1, P79, DOI 10.1023/A:1009730122752; Hotho A., 2001, IJCAI 2001 WORKSH TE; Ikonomakis M., 2005, WSEAS Transactions on Computers, V4; Kass GV, 1980, APPL STATIST, V29, P119, DOI DOI 10.2307/2986296; Keet C. M., 2004, ASPECTS ONTOLOGY INT; Kohler J, 2003, BIOINFORMATICS, V19, P2420, DOI 10.1093/bioinformatics/btg340; Kohler J, 2006, KNOWL-BASED SYST, V19, P744, DOI 10.1016/j.knosys.2006.04.015; LEE YH, 2007, 7 PAC AS C INF SYST; Lewis D., 1994, 3 ANN S DOC AN INF R, P81; Maedche A., 2002, ONTOLOGY LEARNING SE; MAEDCHE A, 2000, 12 INT C SOFTW KNOWL; McCallum A., 1998, AAAI 1998 WORKSH LEA; MORIN E, 1999, 5 INT C TERM KNOWL E; Moulinier I, 1997, LAFORIALIP6 U PAR 6; PEREZ AG, 1999, IJCAI 1999 WORKSH ON; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1986, MACH LEARN, V1, P106; Roussinov DG, 1999, DECIS SUPPORT SYST, V27, P67, DOI 10.1016/S0167-9236(99)00037-8; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; SURYANTO H, 2000, WORKSH ONT LEARN BER; SZPAKOWICZ S, 1990, INT J MAN MACHINE ST; VOUTILAINEN A, 1993, WVLC, P48; WACHE H, 2001, 17 INT JOINT C ART I, P108; WEI C, 2002, HDB KNOWLEDGE MANAGE; YAMAGUCHI T, 2001, 2 WORKSH ONT LEARN S; Yang Y., 1997, ICML 97, P412; Yang Y., 1999, INFORM RETRIEVAL, V1, P69, DOI 10.1023/A:1009982220290; ZELIKOVITZ S, 2001, 10 ACM INT C INF KNO	43	5	5	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-1348		978-3-642-01255-6	LECT NOTES BUS INF			2009	22						201	213				13	Business; Computer Science, Hardware & Architecture; Computer Science, Information Systems	Business & Economics; Computer Science	BKK39	WOS:000268378000017		
B	Zhang, CZ; Xu, HJ				Zhang, Chengzhi; Xu, Hongjiao			Using Citation-KNN for Automatic Keyword Assignment	ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS			English	Proceedings Paper	International Conference on Electronic Commerce and Business Intelligence	JUN 06-07, 2009	Beijing, PEOPLES R CHINA	Soc Management Sci China, Acad Comm		Keyword Extraction; Keyword Assignment; mplicit Keyword Extraction; Citation-KNN		Currently, the automatic keywords extraction method can only extract keywords appeared in the articles and it cannot extract the implicit keyword which does not appear in the articles. It is a difficult work to extract implicit keywords in an article in the task of automatic keywords extraction. This work can also be called automatic keyword assignment. In this paper, an automatic keyword assignment method based on Citation-KNN (Citation-K Nearest Neighborhood) is proposed. Experimental results show that the proposed method can not only improve the precision and recall of keyword extraction, but also extract implicit keyword which does not appear in the articles efficiently.	[Zhang, Chengzhi] Nanjing Univ Sci & Technol, Dept Informat Management, Nanjing, Peoples R China		zhangchz@istic.ac.cn; xuhongjiao_1111@163.com					ANJEWIERDEN A, 2001, P 13 BELG NETH C ART, P23; BAETZYATES R, 1999, MODEM INFORM RETRIEV, P27; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EDMUNDSO.HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519; Edmundson H.P., 1959, R126 PRC, P1; Ercan G, 2007, INFORM PROCESS MANAG, V43, P1705, DOI 10.1016/j.ipm.2007.01.015; Frank E, 1999, P 16 INT JOINT C ART, P668; Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216; Li Su-Jian, 2004, Chinese Journal of Computers, V27; LOIS LE, 1970, INFORM STORAGE RETRI, V6, P313; LUHN HP, 1957, IBM J RES DEV, V1, P309; LUHN HP, 1958, IBM J RES DEV, V2, P159; RAUBER A, 1999, P 4 ACM C DIG LIB DL, P240, DOI 10.1145/313238.313412; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; TAN P, 2006, INTRO DATA MINING, P225; Tomokiyo Takashi, 2003, P ACL WORKSH MULT EX, V18, P33, DOI DOI 10.3115/1119282.1119287; Turney P. D., 2000, Information Retrieval, V2, DOI 10.1023/A:1009976227802; Turney P.D., 1999, ERB1057 NRC, P1; Turney P.D, 1997, ERB1051 I INF TECHN; Wang J., 2000, P 17 INT C MACH LEAR, P1119; Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI 10.1145/312624.312647; ZHANG CZ, 2008, RECENT ADV CHINESE C, V3, P260	22	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3661-3				2009							131	134		10.1109/ECBI.2009.25		4	Business; Computer Science, Information Systems; Economics; Management	Business & Economics; Computer Science	BMJ48	WOS:000272586700031		
J	Nanni, L; Lumini, A				Nanni, Loris; Lumini, Alessandra			Genetic nearest feature plane	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Nearest feature plane classifier; Clustering; Genetic algorithm	CLEAVAGE SITE PREDICTION; FACE RECOGNITION; PATTERN-CLASSIFICATION; NEIGHBOR CLASSIFIER; SELECTION; SYSTEM	The problem addressed in this paper concerns the complexity reduction of the nearest feature plane classifier, so that it may be applied also in dataset where the training set contains many patterns. This classifier considers, to classify a test pattern, the subspaces created by each combination of three training patterns. The main problem is that in dataset of high cardinality this method is unfeasible. A genetic algorithm is here used for dividing the training patterns in several clusters which centroids are used to build the feature planes used to classify the test set. The performance improvement with respect to other nearest neighbor based classifiers is validated through experiments with several benchmark datasets. (C) 2007 Elsevier Ltd. All rights reserved.	[Nanni, Loris; Lumini, Alessandra] Univ Bologna, DEIS, I-40126 Bologna, Italy	Nanni, L (reprint author), Univ Bologna, DEIS, Viale Risorgimento 2, I-40126 Bologna, Italy.	lnanni@deis.unibo.it	Lumini, Alessandra/B-6100-2013	Lumini, Alessandra/0000-0003-0290-7354	European Commission [IST-2002-507634]	This work has been supported by European Commission IST-2002-507634 Biosecure NoE projects. The authors would like to thank T. Rognvaldsson for sharing the HIV dataset; M. Moradi for providing the chromosome images and the features used in this study.	Bezdek J. C., 1981, PATTERN RECOGNITION; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; CAPPELLI R, 2002, P WORKSH BIOM AUTH E, P133; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 2001, SELF ORG MAPS; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; Lumini A, 2006, PATTERN RECOGN LETT, V27, P1390, DOI 10.1016/j.patrec.2006.01.013; Moradi M, 2006, PATTERN RECOGN LETT, V27, P19, DOI 10.1016/j.patrec.2005.06.011; Nanni L, 2006, NEUROCOMPUTING, V69, P1739, DOI 10.1016/j.neucom.2006.01.005; Nanni L, 2007, PATTERN RECOGN LETT, V28, P487, DOI 10.1016/j.patrec.2006.09.002; Nanni L, 2006, PATTERN RECOGN, V39, P711, DOI 10.1016/j.patcog.2005.11.002; OROZCOALZATE M, 2006, SOURCE MACHINE VISIO, V17, P279; PARADES R, 2006, PATTERN RECOGN, V39, P180; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004; Zhou YL, 2004, LECT NOTES COMPUT SC, V3175, P204	24	1	1	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JAN	2009	36	1					838	843		10.1016/j.eswa.2007.10.009		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	418XI	WOS:000264182800082		
B	Fu, XX; Wei, H		Luo, Q; Gong, MM		Fu, Xixu; Wei, Hui			On Hierarchical Knowledge Acquisition and Application	FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS			English	Proceedings Paper	1st IITA International Joint Conference on Artificial Intelligence	APR 25-MAY 26, 2009	Hainan Isl, PEOPLES R CHINA	IITA, Engn Technol Press, IEEE SMC TC Educ Technol & Training, Intelligent Informat Technol Applicat Res Assoc, Wuhan Inst Technol, Huazhong Normal Univ		knowledge acquisition; knowledge representation; class hierarchy; ontology		Classification is a famous branch of machine learning. We have tried many ways to invent and improve algorithms to get better results from given data. However, few have been done on how to revise data to adapt machine learning. In this paper, the same classifiers are implemented on same object sets which are different in the granularity of classification to show different classification can make great difference in the quality of classification first. Then the development of knowledge-base is studied. At last, a progressive knowledge acquisition method is advanced inspired by human's cognition behavior.	[Fu, Xixu; Wei, Hui] Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China	Fu, XX (reprint author), Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China.	xxfu@shou.edu.cn; weihui@fudan.edu.cn					CALVANESEL D, 2008, P KR2008; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Flavell J. H., 2001, COGNITIVE DEV; FU XX, 2007, APPL TEXT MINING RSS; HUI W, 2007, INT C MACH LEARN CYB, V1, P131; KISELYOVA NN, 2002, ENG APPL ARTIF INTEL, V13, P533; NECHES R, 1993, ARTIF INTELL, V61, P65, DOI 10.1016/0004-3702(93)90094-R; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sowa John F., 2003, KNOWLEDGE REPRESENTA	10	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3615-6				2009							185	189		10.1109/JCAI.2009.147		5	Computer Science, Artificial Intelligence	Computer Science	BLX40	WOS:000271280800048		
S	Schumacher, T; Plessl, C; Platzner, M		Danek, M; Kadlec, J		Schumacher, Tobias; Plessl, Christian; Platzner, Marco			AN ACCELERATOR FOR K-TH NEAREST NEIGHBOR THINNING BASED ON THE IMORC INFRASTRUCTURE	FPL: 2009 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND APPLICATIONS	International Conference on Field Programmable and Logic Applications		English	Proceedings Paper	19th International Conference on Field Programmable Logic and Applications	AUG 31-SEP 02, 2009	Prague, CZECH REPUBLIC	UTIA, AV, CR	ASCR, Informat Theory & Automat		FRAMEWORK	The creation and optimization of FPGA accelerators comprising several compute cores and memories are challenging tasks in high performance reconfigurable computing. In this paper, we present the design of such an accelerator for the k-th nearest neighbor thinning problem on an XD1000 reconfigurable computing system. The design leverages IMORC, an architectural template and highly versatile on-chip interconnect, to achieve speedups of 74 x over a 2.2GHz Opteron. Using IMORC with its asynchronous FIFOs and bitwidth conversion in the links between the cores, we are able to quickly create acclerator versions with varying degrees of core-level parallelism and memory mappings. Through the performance monitoring infrastructure of IMORC we gain insight into the data-dependent behavior of the accelerator which facilitates further performance optimizations.	[Schumacher, Tobias; Plessl, Christian; Platzner, Marco] Univ Gesamthsch Paderborn, D-4790 Paderborn, Germany	Schumacher, T (reprint author), Univ Gesamthsch Paderborn, Warburger Str 100, D-4790 Paderborn, Germany.	tobe@uni-paderborn.de; christian.plessl@uni-paderborn.de; platzner@uni-paderborn.de		Plessl, Christian/0000-0001-5728-9982			COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; HOLLAND B, 2007, P HIGH PERF REC COMP; Koehler S, 2008, PARALLEL COMPUT, V34, P217, DOI 10.1016/j.parco.2008.01.008; SCHUMACHER T, 2009, P IEEE S FIELD PROGR; Schumacher Tobias, 2008, Proceedings of the 2008 International Conference on Engineering of Reconfigurable Systems & Algorithms (ERSA 2008); Shannon L, 2007, IEEE T VLSI SYST, V15, P377, DOI 10.1109/TVLSI.2007.893645; Shannon L., 2005, Proceedings. 13th Annual IEEE Symposium on Field-Programmable Custom Computing Machines; Slogsnat D, 2007, FPGA 2007: FIFTEENTH ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45; SMITH M, 2002, P INT S PERF EV COMP; STEFFEN C. P., 2007, P REC SYST SUMM I RS, P17; XtremeData Inc., 2008, XD1000 DEV SYST	11	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1946-1488		978-1-4244-3891-4	I C FIELD PROG LOGIC			2009							338	344				7	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BOT08	WOS:000277506300052		
J	Saha, S; Bandyopadhyay, S				Saha, Sriparna; Bandyopadhyay, Sanghamitra			Some Symmetry Based Classifiers	FUNDAMENTA INFORMATICAE			English	Article						Pattern Classification; Point Symmetry; Kd-tree; Symmetry based distance; Nearest Neighbor Rule; Line Symmetry	CLASSIFICATION; ALGORITHMS	In this paper, a novel point symmetry based pattern classifier (PSC) is proposed. A recently developed point symmetry based distance is utilized to determine the amount of point symmetry of a particular test pattern with respect to a class prototype. Kd-tree based nearest neighbor search is used for reducing the complexity of point symmetry distance computation. The proposed point symmetry based classifier is well-suited for classifying data sets having point symmetric classes, irrespective of any convexity, overlap or size. In order to classify data sets having line symmetry property, a line symmetry based classifier (LSC) along the lines of PSC is thereafter proposed in this paper. To measure the total amount of line symmetry of a particular point in a class, a new definition of line symmetry based distance is also provided. Proposed LSC preserves the advantages of PSC. The performance of PSC and LSC are demonstrated in classifying fourteen artificial and real-life data sets of varying complexities. For the purpose of comparison, k-NN classifier and the well-known support vector machine (SVM) based classifiers are executed on the data sets used here for the experiments. Statistical analysis, ANOVA, is also performed to compare the performance of these classification techniques.	[Saha, Sriparna; Bandyopadhyay, Sanghamitra] Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India	Saha, S (reprint author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.	sriparna_r@isical.ac.in; sanghami@isical.ac.in	Bandyopadhyay, Sanghamitra/A-6597-2010				ANDERBERG MR, 2000, COMPUTATIONAL GEOMET; Anderson T.W., 1978, INTRO STAT ANAL DATA; Asuncion A., 2007, UCI MACHINE LEARNING; ATTNEAVE F, 1955, Am J Psychol, V68, P209, DOI 10.2307/1418892; Bandyopadhyay S, 2007, PATTERN RECOGN, V40, P3430, DOI 10.1016/j.patcog.2007.03.026; Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P2791, DOI 10.1016/S0031-3203(01)00234-5; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Chou C.-H., 2002, 2 WSEAS INT C SCI CO, P209; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2001, ALGORITHMIC IMPLEMEN; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, 4 USAF SCH AV MED; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Gonzalez R. C., 1992, DIGITAL IMAGE PROCES; JOACHIMS T, 2007, SV MMULTICLASS MULTI; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; LIU CL, 1999, ICDAR 99 P 5 INT C D; Mount DM, 2005, ANN LIB APPROXIMATE; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Su MS, 2001, IEEE T PATTERN ANAL, V23, P674	22	0	0	0	4	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968	1875-8681		FUND INFORM	Fundam. Inform.		2009	90	1-2					107	123		10.3233/FI-2009-0009		17	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	417SB	WOS:000264096600009		
J	Halder, A; Ghosh, A; Ghosh, S				Halder, Anindya; Ghosh, Ashish; Ghosh, Susmita			Aggregation Pheromone Density Based Pattern Classification	FUNDAMENTA INFORMATICAE			English	Article						Swarm intelligence; Ant colony optimization; Aggregation pheromone; Pattern classification	ANT COLONY OPTIMIZATION; RECOGNITION	The study of ant colonies behavior and their self-organizing capabilities is of interest to machine learning community, because it provides models of distributed adaptive organization which are useful to solve difficult optimization and classification problems among others. Social insects like ants, bees deposit pheromone (a type of chemical) in order to communicate between the members of their community. Pheromone, that causes clumping behavior in a species and brings individuals into a closer proximity, is called aggregation pheromone. This article presents a new algorithm (called, APC) for pattern classification based on this property of aggregation pheromone found in natural behavior of real ants. Here each data pattern is considered as an ant, and the training patterns (ants) form several groups or colonies depending on the number of classes present in the data set. A new test pattern (ant) will move along the direction where average aggregation pheromone density (at the location of the new ant) formed due to each colony of ants is higher and hence eventually it will join that colony. Thus each individual test pattern (ant) will finally join a particular colony. The proposed algorithm is evaluated with a number of benchmark data sets as well as various kinds of artificially generated data sets using three evaluation measures. Results are compared with four other well known conventional classification techniques. Experimental results show the potentiality of the proposed algorithm in terms of all the evaluation measures compared to other algorithms.	[Halder, Anindya; Ghosh, Ashish] Indian Stat Inst, Ctr Soft Comp Res, Kolkata 700108, India; [Ghosh, Ashish] Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India; [Ghosh, Susmita] Dept Comp Sci Engn, Kolkata 700032, India; [Ghosh, Susmita] Jadavpur Univ, Kolkata 700032, India	Halder, A (reprint author), Indian Stat Inst, Ctr Soft Comp Res, Kolkata 700108, India.	anindya_t@isical.ac.in; ash@isical.ac.in			Department of Science and Technology, Govt. of India	Support of the Department of Science and Technology, Govt. of India to the Center for Soft Computing Research is thankfully acknowledged by Mr. Anindya Halder, Research Scholar of the Center, Indian Statistical Institute, Kolkata.	Bell W.J., 1984, P93; Chen L, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, DOI 10.1109/4235.585892; Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436; Dorigo M, 2004, ANT COLONY OPTIMIZATION, P1, DOI 10.1007/b99492; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Englebrecht A.P., 2002, COMPUTATIONAL INTELL; Ghosh A, 2008, INFORM SCIENCES, V178, P2816, DOI 10.1016/j.ins.2008.02.015; GHOSH A, 2009, PATTERN REC IN PRESS; Ghosh S, 2006, LECT NOTES COMPUT SC, V4338, P118; Hand DJ, 1981, DISCRIMINATION CLASS; Handl J., 2007, SWARM INTELLIGENCE, V1, P95, DOI 10.1007/s11721-007-0008-7; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kennedy J., 2001, SWARM INTELLIGENCE; Kothari M, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P193; KOTHARI M, 2006, P 9 INT C INF TECHN, P259; Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536; Kuncheva L., 2000, FUZZY CLASSIFIER DES; LIU B, 1920, P 6 AUSTR JAP JOINT, P180; Liu B., 2003, P IEEE WIC INT C INT, P83; Martens D, 2007, IEEE T EVOLUT COMPUT, V11, P651, DOI 10.1109/TEVC.2006.890229; Newman D., 1998, UCI REPOSITORY MACHI; ONO M, 1995, NATURE, V377, P334, DOI 10.1038/377334a0; PAL SK, 1994, INFORM SCIENCES, V76, P297, DOI 10.1016/0020-0255(94)90014-0; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452; PLATT JC, 1999, ADV NEURAL INFORM PR; Ripley BD, 1995, PATTERN RECOGNITION; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Salton G, 1983, INTRO MODERN INFORM; Smola P., 2002, LEARNING KERNELS SUP; SOCHA K, EUROPEAN J OPERATION; SUKAMA M, 1993, J CHEM ECOL, V19, P2521; Tsutsui S., 2004, P 5 INT C REC ADV SO, P207; Tsutsui S., 2004, P 5 AS PAC C SIM EV; Wang XN, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5355; *WEK MACH LEARN PR, WEK	38	8	8	1	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0169-2968	1875-8681		FUND INFORM	Fundam. Inform.		2009	92	4					345	362		10.3233/FI-2009-78		18	Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	469LU	WOS:000267901400002		
S	Derrac, J; Garcia, S; Herrera, F		Corchado, E; Wu, X; Oja, E; Herrero, A; Baruque, B		Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco			A First Study on the Use of Coevolutionary Algorithms for Instance and Feature Selection	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	4th International Workshop on Hybrid Artificial Intelligence Systems	JUN 10-12, 2009	Salamanca, SPAIN					Cooperative Coevolution is a technique in the area of Evolutionary Computation. it has been applied to many combinatorial problems with great success. This contribution proposes a Cooperative Coevolution model for simultaneous performing some data, reduction processes in classification with nearest, neighbours methods through feature, and instance selection. In order to check its performance, we have compared the proposal with other evolutionary approaches for performing data reduction. Results have been analyzed and contrasted by using non-parametric statistical tests, finally showing that the proposed model outperforms the noncooperative evolutionary techniques.	[Derrac, Joaquin; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Derrac, J (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.	jderrac@correo.ugr.es; herrera@decsai.ugr.es; sglopez@ujaen.es	Herrera, Francisco/C-6856-2008; Garcia, Salvador/N-3624-2013	Herrera, Francisco/0000-0002-7283-312X; Garcia, Salvador/0000-0003-4494-7565			AU C, 2007, IEEE INT C TOOLS ART, P407; Baluja S, 1994, POPULATION BASED INC; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Eshelman L. J., 1990, FDN GENETIC ALGORITH, P265; FRAGOUDIS D, 2002, 8 ACM SIGKDD INT C K, P501; Freitas A.A., 2002, DATA MINING KNOWLEDG; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Goldberg D. E., 1989, GENETIC ALGORITHMS S; Jansen T, 2004, EVOL COMPUT, V12, P405, DOI 10.1162/1063656043138905; Liu H., 2001, SPRINGER INT SERIES; Liu H, 2008, CH CRC DATA MIN KNOW, P3; NEWMAN DJ, 1998, UCI REPOSITORY ML DA; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; PANAIT L, 2003, INT JOINT C ART INT, P653; Panait L, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P345; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; Pyle D., 1999, DATA PREPARATION DAT; Smith J. E., 2003, INTRO EVOLUTIONARY C; White S. D., 1989, Veterinary Dermatology, V1, P1; Wolpert DH, 2005, IEEE T EVOLUT COMPUT, V9, P721, DOI 10.1109/TEVC.2005.856205	22	27	27	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02318-7	LECT NOTES ARTIF INT			2009	5572						557	564				8	Computer Science, Artificial Intelligence	Computer Science	BKC98	WOS:000267794600067		
S	Parvin, H; Alizadeh, H; Minaei-Bidgoli, B		Ao, SL		Parvin, Hamid; Alizadeh, Hosein; Minaei-Bidgoli, Behrouz			Validation Based Modified K-Nearest Neighbor	IAENG TRANSACTIONS ON ENGINEERING TECHNOLOGIES, VOL II	AIP Conference Proceedings		English	Proceedings Paper	International Conference on Advances in Engineering Technologies held at the World Congress on Engineering and Computer Sciences	OCT 22-24, 2008	San Francisco, CA	Int Assoc Engn		MKNN; KNN Classification; Modified K-Nearest Neighbor; Weighted K-Nearest Neighbor; Neighbor Validation	CLASSIFICATION	In this paper, a new classification method for enhancing the performance of K-Nearest Neighbor is proposed which uses robust neighbors in training data. The robust neighbors are detected using a validation process. This method is more robust than traditional equivalent methods. This new classification method is called Modified K-Nearest Neighbor. Inspired the traditional KNN algorithm, the main idea is classifying the test samples according to their neighbor tags. This method is a kind of weighted KNN so that these weights are determined using a different procedure. The procedure computes the fraction of the same labeled neighbors to the total number of neighbors. The proposed method is evaluated on a variety of several standard UCI data sets. Experiments show the excellent improvement in accuracy in comparison with KNN method.	[Parvin, Hamid; Alizadeh, Hosein; Minaei-Bidgoli, Behrouz] Iran Univ Sci & Technol, Dept Comp Engn, Tehran, Iran	Parvin, H (reprint author), Iran Univ Sci & Technol, Dept Comp Engn, POB 16765-163, Tehran, Iran.						AEBERHARD S, 9202 J COOK U N QUEE; ALIZADEH H, 2009, 11 C INT FED CLASS S; ALIZAEDH H, 2008, P INT C CONV HYBR IN; BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; Bermejo S, 2000, PATTERN RECOGN, V33, P1999, DOI 10.1016/S0031-3203(99)00186-7; Blake C. L., 1998, UCI RESPOSITORY MACH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARASAY BV, NEAREST NEIGHBOR PAT; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fix E., 1951, 4 USAF SCH AV MED; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373; Gose E., 1996, PATTERN RECOGNITION; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; ITQON K, 2001, SPRINGER T I ELECT I; Jozwik A, 1983, PATTERN RECOGN LETT, V1, P287, DOI 10.1016/0167-8655(83)90064-8; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; KUNCHEVA L, 2005, COMBINING PATTERN CL; PARVIN H, 2009, INT J DIGIT IN PRESS; PARVIN H, 2008, P INT C CONV HYBR IN; Parvin H, 2008, P INT C NETW COMP AD; ROUSSEAUW, 1983, S AFRICAN MED J	22	0	0	2	2	AMER INST PHYSICS	MELVILLE	2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA	0094-243X		978-0-7354-0663-6	AIP CONF PROC			2009	1127						153	161				9	Engineering, Multidisciplinary	Engineering	BKK66	WOS:000268391900015		
B	Xiong, W; Ong, SH; Le, TT; Lim, JH; Liu, J; Foong, K			IEEE	Xiong, Wei; Ong, S. H.; Le, T. T.; Lim, Joo Hwee; Liu, Jiang; Foong, Kelvin			Combining a Global SVM and Local Nearest-Neighbor Classifiers Driven by Local Discriminative Boundaries	ICIEA: 2009 4TH IEEE CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS, VOLS 1-6			English	Proceedings Paper	4th IEEE Conference on Industrial Electronics and Applications	MAY 25-27, 2009	Xian, PEOPLES R CHINA	IEEE, Ind Elect Chapter Singapore, NW Polytechn Univ, IEEE Xian Sect, IEEE Control Syst Soc, IEEE Ind Elect Soc, Natl Nat Sci Fdn China, Inst Engn & Technol, Shaanxi Key Lab Informat Acquist & Proc		Support vector machines; nearest neighbors; local; combination; adaptive metric; boundary driven	CLASSIFICATION	Nonlinear support vector machines (SVMs) rely on the kernel trick and tradeoff parameters to build nonlinear models to classify complex problems and balance misclassification and generalization. The inconvenience in determining the kernel and the parameters has motivated the use of local nearest neighbor (NN) classifiers in lieu of global classifiers. This substitution ignores the advantage of SV-M in global error minimization. On the other hand, the NN rule assumes that class conditional probabilities are locally constant. Such an assumption does not hold near class boundaries and in any high dimensional space due to the curse of dimensionality. We propose a hybrid classification method combining the global SVM and local NN classifiers. Local classifiers occur only when the global SVM is likely to fail. Furthermore, local NN classifiers adopt an adaptive metric driven by local SVM discriminative boundaries. Improved performance has been demonstrated compared to partially similar.	[Xiong, Wei; Lim, Joo Hwee; Liu, Jiang] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore	Xiong, W (reprint author), ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.	wxiong@i2r.a-star.edu.sg					AINARI S, 1999, NEURAL NETWORKS, V12, P783; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cheng HB, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P461; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Duda R. O., 1973, PATTERN CLASSIFICATI; LI R, 2001, INT C INF INF ICII; Peng J, 2003, IEEE T NEURAL NETWOR, V14, P940, DOI 10.1109/TNN.2003.813835; TIAN M, 2003, P IEEE INT TRANSP SY, V1, P373; Vapnik V. N., 1995, NATURE STAT LEARNING; Zhang H, 2006, IEEE C COMP VIS PATT	11	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-2799-4				2009							3588	3591				4	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BMO85	WOS:000273183201320		
B	Dehzangi, O; Younessian, E; Fard, FH		Filipe, J		Dehzangi, Omid; Younessian, Ehsan; Fard, Fariborz Hosseini			AN ADAPTIVE CLASSIFIER DESIGN FOR ACCURATE SPEECH DATA CLASSIFICATION	ICINCO 2009: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL 2: ROBOTICS AND AUTOMATION			English	Proceedings Paper	6th International Conference on Informatics in Control, Automation and Robotics	JUL 02-05, 2009	Milan, ITALY	Inst Syst & Technologies Informat, Control & Commun, IFAC, Assoc Advancement Artificial Intelligence		Nearest neighbor; Linear discriminant analysis; Adaptive distance measure; Weight learning algorithm	NEAREST-NEIGHBOR CLASSIFICATION	In this paper, an adaptive approach to designing accurate classifiers using Nearest Neighbor (NN) and Linear Discriminant Analysis (LDA) is proposed. A novel NN rule with an adaptive distance measure is proposed to classify input patterns. An iterative learning algorithm is employed to incorporate a local weight to the Euclidean distance measure that attempts to minimize the number of misclassified patterns in the training set. In case of data sets with highly overlapped classes, this may cause the classifier to increase its complexity and overfit. As a solution, LDA is considered as a popular feature extraction technique that aims at creating a feature space that best discriminates the data distributions and reduces overlaps between different classes of data. In this paper, an improved variation of LDA (im-LDA) is investigated which aims to moderate the effect of outlier classes. The proposed classifier design is evaluated by 6 standard data sets from UCI ML repository and eventually by TIMIT data set for framewise classification of speech data. The results show the effectiveness of the designed classifier using im-LDA with the proposed ad-NN method.	[Dehzangi, Omid; Younessian, Ehsan] Nanyang Technol Univ, Singapore, Singapore	Dehzangi, O (reprint author), Nanyang Technol Univ, Singapore, Singapore.	dehzangi@pmail.ntu.edu.sg; ehsa0001@ntu.edu.sg; cbfn87@motorola.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Duda R O, 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J., 1994, 113 STANF U STAT DEP; Garofolo J., 1988, GETTING STARTED DARP; GRAVES A, 2005, INT JOINT C NEUR NET; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; JARCHI D, 2006, T ENG COMPUTATIONAL, V18, P18; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; MERZ CJ, 1996, UCIREPOSITORY MACHIN; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002	13	0	0	0	5	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL			978-989-674-000-9				2009							67	71				5	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Information Systems; Robotics	Automation & Control Systems; Computer Science; Robotics	BQW84	WOS:000282034200014		
S	Goger, D; Gorges, N; Worn, H			IEEE	Goeger, Dirk; Gorges, Nicolas; Woern, Heinz			Tactile Sensing for an Anthropomorphic Robotic Hand: Hardware and Signal Processing	ICRA: 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-7	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation	MAY 12-17, 2009	Kobe, JAPAN	IEEE			EXPLORATION	In this paper, a tactile sensing system for an anthropomorphic robot hand is presented. The tactile sensing system is designed as a construction kit making it very versatile. The sensor data preprocessing is embedded into the hand's hardware structure and is fully integrated. The sensor system is able to gather tactile pressure profiles and to measure vibrations in the sensor's cover. Additionally to the introduction of the hardware, the signal processing and the classification of the acquired sensor data will be explained in detail. These algorithms make the tactile sensing system capable to detect contact points, to classify contact patterns and to detect slip conditions during object manipulation and grasping.	[Goeger, Dirk; Gorges, Nicolas; Woern, Heinz] Univ Karlsruhe TH, Inst Proc Control & Robot, Karlsruhe, Germany	Goger, D (reprint author), Univ Karlsruhe TH, Inst Proc Control & Robot, Karlsruhe, Germany.	goeger@ira.uka.de; gorges@ira.uka.de; woern@ira.uka.de					Beucher S, 1991, SCANNING MICROSCOPY, P299, DOI 10.1.1.24.5229; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAI J, 1994, P 2 BIENN EUR JOINT; GOGER D, 2007, IEEE C SENS ATL GA U; GORGES N, 2008, INT C INF CONTR AUT; Heidemann G., 2004, P IEEE INT C ROB AUT, P813; HOLWEG E, 1996, IEEE INT C ROB AUT M; HU M, 1962, IRE T INFORM THEOR, V8, P179; JOCKUSCH J, 1997, IEEE INT C ROB AUT A; Okamura AM, 2001, INT J ROBOT RES, V20, P925, DOI 10.1177/02783640122068191; SCHMID A, 2008, IEEE INT C ROB AUT P; Schmidt PA, 2006, ROBOT AUTON SYST, V54, P1005, DOI 10.1016/j.robot.2006.05.013; Schulz A., 2004, MECHATRONICS ROBOTIC, P936; SON J, 1994, IEEE INT C ROB AUT S; Turk M.A., 1991, COMPUTER VISION PATT; WEISS K, 2006, 4 DTSCH ROB K MUNCH; Weiss K., 2004, IEEE RAS INT C HUM R; Worn H., 2005, P IEEE INT C MECH AU	18	1	1	0	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729		978-1-4244-2788-8	IEEE INT CONF ROBOT			2009							2972	2978				7	Automation & Control Systems; Robotics	Automation & Control Systems; Robotics	BOB06	WOS:000276080401166		
S	Martin, JA; de Lope, J			IEEE	Antonio Martin H, Jose; de Lope, Javier			Ex < a >: An Effective Algorithm for Continuous Actions Reinforcement Learning Problems	IECON: 2009 35TH ANNUAL CONFERENCE OF IEEE INDUSTRIAL ELECTRONICS, VOLS 1-6	IEEE Industrial Electronics Society		English	Proceedings Paper	35th Annual Conference of the IEEE-Industrial-Electronics-Society	NOV 03-05, 2009	Porto, PORTUGAL	IEEE Ind Elect Soc				In this paper the Ex < a > Reinforcement Learning algorithm is presented. This algorithm is designed to deal with problems where the use of continuous actions have clear advantages over the use of fine grained discrete actions. This new algorithm is derived from a baseline discrete actions algorithm implemented within a kind of k-nearest neighbors approach in order to produce a probabilistic representation of the input signal to construct robust state descriptions based on a collection (knn) of receptive field units and a probability distribution vector p(knn) over the knit collection. The baseline continuous-space-discreteactions kNN-TD(lambda) algorithm introduces probability traces as the natural adaptation of eligibility traces in the probabilistic context. Later the Ex < a >(lambda) algorithm is described as an extension of the baseline algorithms. Finally experimental results are presented for two (not easy) problems such as the Cart-Pole and Helicopter Hovering.	[Antonio Martin H, Jose] Univ Complutense Madrid, E-28040 Madrid, Spain	Martin, JA (reprint author), Univ Complutense Madrid, E-28040 Madrid, Spain.		Martin H., Jose Antonio/A-2388-2009				Abbeel P., 2005, NIPS; Anderson C. W., 1987, Proceedings of the Fourth International Workshop on Machine Learning; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Gordon Geoff, 1995, ICML, P261; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; MARTIN JA, 2009, LECT NOTES COMPUTER, V5901, P305; Martin JAH, 2007, LECT NOTES COMPUT SC, V4739, P138; Ng A., 2003, NIPS; Singh SP, 1996, MACH LEARN, V22, P123; Sutton R. S., 1988, Machine Learning, V3, DOI 10.1007/BF00115009; Sutton R.S., 1998, REINFORCEMENT LEARNI; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	15	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1553-572X		978-1-4244-4648-3	IEEE IND ELEC			2009							1944	1949				6	Engineering, Electrical & Electronic	Engineering	BQE04	WOS:000280762000328		
B	AlSukker, A; Al-Ani, A; Atiya, A		Dourado, A; Rosa, A; Madani, K		AlSukker, Akram; Al-Ani, Ahmed; Atiya, Amir			A MODIFIED K-NEAREST NEIGHBOR CLASSIFIER TO DEAL WITH UNBALANCED CLASSES	IJCCI 2009: PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL INTELLIGENCE			English	Proceedings Paper	1st International Joint Conference on Computational Intelligence	OCT 05-07, 2009	Funchal, PORTUGAL	Inst Syst & Technol Informat, Control & Commun, Int Fuzzy Syst Assoc		kNN classifier; Unbalanced classes; Class-wise classification accuracy		We present in this paper a simple, yet valuable improvement to the traditional k-Nearest Neighbor (kNN) classifier. It aims at addressing the issue of unbalanced classes by maximizing the class-wise classification accuracy. The proposed classifier also gives the option of favoring a particular class through evaluating a small set of fuzzy rules. When tested on a number of UCI datasets, the proposed algorithm managed to achieve a uniformly good performance.	[AlSukker, Akram; Al-Ani, Ahmed] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	AlSukker, A (reprint author), Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.	alsukker@eng.uts.edu.au; ahmed@eng.uts.edu.au; amir@alumni.caltech.edu					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, SMC, VSMC-6, P325; GOLDBERGER J, NIPS; KELLER JM, FUZZY K NEAREST NEIG; Newman A.A., 2007, UCI MACHINE LEARNING; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Westin LK, 2001, RECEIVER OPERATING C; YONG Z, 2009, EXPERT SYST APPL, V36, P3587; ZENG Y, EXPERT SYST IN PRESS	12	0	0	0	4	INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION	SETUBAL	AVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL			978-989-674-014-6				2009							408	413				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BVA72	WOS:000290915300059		
S	Martinez-Rego, D; Fontenla-Romero, O; Porto-Diaz, I; Alonso-Betanzos, A			IEEE	Martinez-Rego, David; Fontenla-Romero, Oscar; Porto-Diaz, Iago; Alonso-Betanzos, Amparo			A New Supervised Local Modelling Classifier Based On Information Theory	IJCNN: 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1- 6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 14-19, 2009	Atlanta, GA	Int Neural Network Soc, IEEE Computat Intelligence Soc				In this paper, a novel supervised architecture for binary classification based on local modelling and information theory is described. The architecture is composed of two steps: in the first one, a separating borderline between the two classes is piecewise constructed by a set of centroids calculated by a modified clustering algorithm, based on information theory; each of these centroids define a region where, in the second step of the proposed architecture, a hyperplane is constructed and adjusted by means of one-layer neural networks. This new method allows for binary classification while maintaining adequate use of computational resources, a common problem for machine learning methods. The proposed architecture is applied over classical benchmark classification problems and data sets, and its results are compared with those obtained by other well-known statistical and machine learning classifiers.	[Martinez-Rego, David; Fontenla-Romero, Oscar; Porto-Diaz, Iago; Alonso-Betanzos, Amparo] Univ A Coruna, Dept Comp Sci, La Coruna, Spain	Martinez-Rego, D (reprint author), Univ A Coruna, Dept Comp Sci, La Coruna, Spain.	dmartinez@udc.es; ofontenla@udc.es; iporto@udc.es; ciamparo@udc.es	Fontenla-Romero, Oscar/A-1142-2015; Martinez-Rego, David/I-2710-2015	Fontenla-Romero, Oscar/0000-0003-4203-8720; 			[Anonymous], UCI MACH LEARN REP; BAUM EB, 1990, NISP 3 P 1990 C ADV, V3, P904; Bishop C.M., 1995, NEURAL NETWORKS PATT; BREIMAN L, 1996, MACHINE LEARNING J, V26; Castillo E, 2002, NEURAL COMPUT, V14, P1429, DOI 10.1162/089976602753713007; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cox D, 1970, ANAL BINARY DATA; Dimitrakakis C., 2004, 12 EUR S ART NEUR NE; Drucker H., 1997, P 14 INT C MACH LEAR; Fahlman S. E., 1990, ADV NEURAL INFORMATI, V2, P524; Fisher RA, 1936, ANN EUGEN, V7, P178; FONTENLAROMERO O, 2002, LECT NOTES COMPUTER, V2415, P1429; FREUND Y, 1997, J COMPUTER SYSTEM SC, V55, P19139; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI DOI 10.1145/502512.502527; Kiang MY, 2003, DECIS SUPPORT SYST, V35, P441, DOI 10.1016/S0167-9236(02)00110-0; Kuncheva L. I., 2004, COMBINING PATTERN CL; Lee Y.J., 2001, P 1 SIAM INT C DAT M; Martinez-Rego D., 2008, EUR S ART NEUR NETW, P295; MERCER J, 1909, PHILOS T R SOC A, V209; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; PRINCIPE J, 2005, NATURAL COMPUTING, V4, P39; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1986, MACH LEARN, V1, P106; RAMAKRISHNAN R, 2000, KDD 2000 P 6 ACM SIG, P64; Shawe-Taylor J., 2000, SUPPORT VECTOR MACHI; Suykens J. A. K., 2002, LEAST SQUARES SUPPOR; Weston J, 2006, SPIDER SVM TOOLBOX; WILLIAMFLAKE G, 1998, NEURAL NETWORKS TRIC, P145; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	29	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-3549-4	IEEE IJCNN			2009							166	172				7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BQB78	WOS:000280591600025		
S	Malof, JM; Mazurowski, MA; Tourassi, GD			IEEE	Malof, Jordan M.; Mazurowski, Maciej A.; Tourassi, Georgia D.			The Effect of Class Imbalance on Case Selection for Case-Based Classifiers, with Emphasis on Computer-Aided Diagnosis Systems	IJCNN: 2009 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, VOLS 1- 6	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks	JUN 14-19, 2009	Atlanta, GA	Int Neural Network Soc, IEEE Computat Intelligence Soc		Cased-Based Learning; Computer-Aided Decision; Imbalance	LEARNING ALGORITHMS	in this paper the effect of class imbalance in the case base of a case-based classifier is investigated as it pertains to case base reduction and the resulting classifier performance. A k-nearest neighbor algorithm is used as a classifier and the Random Mutation Hill Climbing (RMHC) algorithm is used for case base reduction. The effects at various levels of positive class prevalence are tested in a binary classification problem. The results indicate that class imbalance is detrimental to both case base reduction and classifier performance. Selection with RMHC generally improves the classification performance regardless of the case base prevalence.	[Malof, Jordan M.] Univ Louisville, Dept Elect & Comp Engn, Louisville, KY 40292 USA	Malof, JM (reprint author), Univ Louisville, Dept Elect & Comp Engn, Louisville, KY 40292 USA.	jmmalo03@gmail.com; maciej.mazurowski@duke.edu; georgia.tourassi@duke.edu	Mazurowski, Maciej/D-4719-2011				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda, 2001, PATTERN CLASSIFICATI; MAZUROWSKI MA, 2007, P INT JOINT C NEUR N, P2005; Mazurowski MA, 2008, PHYS MED BIOL, V53, P6079, DOI 10.1088/0031-9155/53/21/013; Mitchell Tom, MACHINE LEARNING; Obuchowski NA, 2003, RADIOLOGY, V229, P3, DOI 10.1148/radiol.2291010898; Skalak D., 2004, P 11 INT C MACH LEAR, P293; Tourassi GD, 2003, MED PHYS, V30, P2123, DOI 10.1118/1.1589494; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zurada J. M., 1992, INTRO ARTIFICIAL NEU	12	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-3549-4	IEEE IJCNN			2009							1246	1251				6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BQB78	WOS:000280591600182		
B	Phyu, TN	Ao, SI	Castillo, O; Douglas, C; Feng, DD; Lee, JA		Phyu, Thair Nu	Ao, SI		Survey of Classification Techniques in Data Mining	IMECS 2009: INTERNATIONAL MULTI-CONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multi-Conference of Engineers and Computer Scientists	MAR 18-20, 2009	Kowloon, PEOPLES R CHINA	Int Assoc Engineers, IAENG, Soc Artificial Intelligence, IAENG, Soc Bioinformat, IAENG, Soc Comp Sci, IAENG, Soc Data Min, IAENG, Soc Elect Engn, IAENG, Soc Imaging Engn, IAENG, Soc Ind Engn, IAENG, Soc Informat Syst Engn, IAENG, Soc Internet Comp & Web Serv, IAENG, Soc Mech Engn, IAENG, Soc Operat Res, IAENG, Soc Sci Comp, IAENG, Soc Software Engn, IAENG, Soc Wireless Networks		Bayesian; classification technique; fuzzy logic	NAIVE-BAYES CLASSIFIERS; LEARNING ALGORITHMS; DECISION TREES; NETWORKS	Classification is a data mining (machine learning) technique used to predict group membership for data instances. In this paper, we present the basic classification techniques. Several major kinds of classification method including decision tree induction, Bayesian networks, k-nearest neighbor classifier, case-based reasoning, genetic algorithm and fuzzy logic techniques. The goal of this survey is to provide a comprehensive review of different classification techniques in data mining.	Univ Comp Studies, Pakokku, Myanmar	Phyu, TN (reprint author), Univ Comp Studies, Pakokku, Myanmar.	Thair54@gmail.com					Baik S, 2004, LECT NOTES COMPUT SC, V3046, P206; Bouckaert RR, 2004, LECT NOTES ARTIF INT, V3339, P1089; Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cheng J., 2001, LECT NOTES COMPUTER, V2056, P141, DOI DOI 10.1007/3-540-45153-6_14; Cheng J, 2002, ARTIF INTELL, V137, P43, DOI 10.1016/S0004-3702(02)00191-1; Clark P., 1989, Machine Learning, V3, DOI 10.1007/BF00116835; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COWELL RG, 2001, P 17 INT C UNC ART I; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Elomaa T, 1999, LECT NOTES COMPUT SC, V1642, P63; Frank E., 2005, DATA MINING PRACTICA; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Kubat M., 2001, Intelligent Data Analysis, V5; MADDEN M, 2003, P EUR C MACH LEARN W, P59; McSherry D, 1999, KNOWL-BASED SYST, V12, P269, DOI 10.1016/S0950-7051(99)00024-6; Vivarelli F, 2001, NEURAL NETWORKS, V14, P427, DOI 10.1016/S0893-6080(01)00024-7; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yang Y, 2003, LECT NOTES ARTIF INT, V2903, P440; Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072; Zheng ZJ, 2000, MACH LEARN, V40, P35, DOI 10.1023/A:1007626017208	23	3	3	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-17012-2-0	LECT NOTES ENG COMP			2009							727	731				5	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Computer Science; Engineering	BJI30	WOS:000266097200136		
S	Tarakanov, A		Popovich, VV; Schrenk, M; Claramunt, C; Korolenko, KV		Tarakanov, Alexander			Immunocomputing for Geoinformation Fusion and Forecast	INFORMATION FUSION AND GEOGRAPHIC INFORMATION SYSTEMS, PROCEEDINGS	Lecture Notes in Geoinformation and Cartography		English	Proceedings Paper	4th International Workshop on Information Fusion and Geographical Information Systems	MAY 17-20, 2009	St Petersburg, RUSSIA	RAS, St Petersburg Inst Informat & Automat		Immunocomputing; Geoinformation fusion; Spatio-temporal modeling; Forecast	INTRUSION DETECTION	Based on immunocomputing (IC), this paper proposes a new way for geoinformation fusion, spatio-temporal modeling, and forecast. The approach includes mathematically, rigorous mapping of high-dimensional spatio-temporal data into a scalar index, discrete tree transform (DTT) of the index values into states Of Cellular automata (CA), and identification of CA by IC. Numerical examples use official data of International Association for the Development of Freediving (AIDA), World Health Organization (WHO), as well as time series of Solar Influences Data Analysis Center (SIDC) and National Aeronautics and Space Administration (NASA). Anomaly index is also proposed using special the case of DTT. Recent results suggest that the IC approach Outperforms (by training time and accuracy) state-of-the-art approaches Of Computational intelligence.	RAS, St Petersburg Inst Informat & Automat, St Petersburg 199178, Russia	Tarakanov, A (reprint author), RAS, St Petersburg Inst Informat & Automat, 39,14 Liniya, St Petersburg 199178, Russia.	tar@iias.spb.su					Agnati LF, 2008, BRAIN RES REV, V58, P400, DOI 10.1016/j.brainresrev.2007.10.002; Atreas ND, 2003, LECT NOTES COMPUT SC, V2787, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fuxe KG, 2008, BRAIN RES REV, V58, P453, DOI 10.1016/j.brainresrev.2008.04.003; Goncharova LB, 2007, BRAIN RES REV, V55, P155, DOI 10.1016/j.brainresrev.2007.02.003; Goncharova LB, 2008, CURR MED CHEM, V15, P1297, DOI 10.2174/092986708784535009; Goncharova LB, 2008, CURR MED CHEM, V15, P210; IVANCIUC Q, 2007, REV COMP CH, V23, P291; KUZNETSOV VI, 1999, ECOLOGICAL ATLAS; *NASA, OC COL TIM SER PROJ; Tarakanov A, 2007, INT J UNCONV COMPUT, V3, P123; Tarakanov A, 2007, J CELL AUTOM, V2, P39; Tarakanov A. O., 2003, IMMUNOCOMPUTING PRIN; TARAKANOV AO, HDB RES ART IN PRESS; TARAKANOV AO, 2007, LNGC, V14, P252; Tarakanov AO, 2008, IEEE COMPUT INTELL M, V3, P22, DOI 10.1109/MCI.2008.919069; Yao JT, 2006, LECT NOTES ARTIF INT, V4062, P538	17	1	1	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1863-2246		978-3-642-00303-5	LEC NOT GEO CARTO			2009							125	134		10.1007/978-3-642-00304-2_8		10	Computer Science, Interdisciplinary Applications; Geosciences, Multidisciplinary; Remote Sensing	Computer Science; Geology; Remote Sensing	BMU62	WOS:000273609500008		
J	Vanderlooy, S; Sprinkhuizen-Kuyper, IG; Smirnov, EN; van den Herik, HJ				Vanderlooy, Stijn; Sprinkhuizen-Kuyper, Ida G.; Smirnov, Evgueni N.; van den Herik, H. Jaap			The ROC isometrics approach to construct reliable classifiers	INTELLIGENT DATA ANALYSIS			English	Article						ROC analysis; isometrics; abstaining classifiers; reliable classifiers; cost-sensitive classification	ABSTAINING CLASSIFIERS; REJECT RULE; CLASSIFICATION	We address the problem of applying machine-learning classifiers in domains where incorrect classifications have severe consequences. In these domains we propose to apply classifiers only when their performance can be defined by the domain expert prior to classification. The classifiers so obtained are called reliable classifiers. In the article we present three main contributions. First, we establish the effect on an ROC curve when ambiguous instances are left unclassified. Second, we propose the ROC isometrics approach to tune and transform a classifier in such a way that it becomes reliable. Third, we provide an empirical evaluation of the approach. From our analysis and experimental evaluation we may conclude that the ROC isometrics approach is an effective and efficient approach to construct reliable classifiers. In addition, a discussion about related work clearly shows the benefits of the approach when compared with existing approaches that also have the option to leave ambiguous instances unclassified.	[Vanderlooy, Stijn; Smirnov, Evgueni N.; van den Herik, H. Jaap] Univ Limburg, MICC, NL-6200 MD Maastricht, Netherlands; [Sprinkhuizen-Kuyper, Ida G.] Radboud Univ Nijmegen, NICI, NL-6500 HE Nijmegen, Netherlands	Vanderlooy, S (reprint author), Univ Limburg, MICC, POB 616, NL-6200 MD Maastricht, Netherlands.	s.vanderlooy@micc.unimaas.nl	Sprinkhuizen-Kuyper, Ida/E-2829-2010	Sprinkhuizen-Kuyper, Ida/0000-0003-0273-9354	Dutch Organization for Scientific Research (NWO); POL [634.000.435]	We thank the reviewers for useful comments and suggestions. The first author is supported by the Dutch Organization for Scientific Research (NWO), ToKeN programme, viz. the IPOL project, grant nr: 634.000.435.	Agarwal S, 2005, J MACH LEARN RES, V6, P393; Atiya AF, 2005, NEURAL COMPUT, V17, P731, DOI 10.1162/0899766053019971; Cestnik B., 1990, P EUR C ART INT, P147; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; DZEROSKI S, 1992, P 2 INT WORKSH IND L, P109; Elkan Charles, 2001, P 17 INT JOINT C ART, P973; Fawcett T., 2003, HPL20034; Fawcett T, 2005, MACH LEARN, V58, P33, DOI 10.1007/s10994-005-5256-4; Ferri C., 2004, P 1 INT WORKSH ROC A, P27; Ferri C, 2004, P 21 INT C MACH LEAR, P37; Flach P. A., 2003, P 20 INT C MACH LEAR, P194; FLACH PA, 2005, P 19 INT JOINT C ART, P702; Frelicot C, 2002, PATTERN ANAL APPL, V5, P234; Friedel C. C., 2006, P ICML 2006 WORKSH R, P33; Furnkranz J, 2005, MACH LEARN, V58, P39, DOI 10.1007/s10994-005-5011-x; GUYON I, 2007, 20 INT JOINT C NEUR; Lachiche N., 2003, P 20 INT C MACH LEAR, P416; Lavrac N., 1994, INDUCTIVE LOGIC PROG; Ling C. X., 2003, P 18 INT JOINT C ART; LU J, 2006, P 2 INT C ADV DAT MI, P223; Macskassy S, 2004, P 1 WORKSH ROC AN AI, P61; MARROCCO C, 2007, P 5 INT C MACH LEARN, P47; Muzzolini R, 1998, PATTERN RECOGN, V31, P345, DOI 10.1016/S0031-3203(97)00056-3; Newman D., 1998, UCI REPOSITORY MACHI; Niculescu-Mizil A., 2005, P 22 INT C MACH LEAR, P625, DOI 10.1145/1102351.1102430; PAZZANI M, 1994, AAAI S AI MED STANF, P106; Pietraszek T, 2007, INTELL DATA ANAL, V11, P293; Pietraszek T, 2007, MACH LEARN, V68, P137, DOI 10.1007/s10994-007-5013-y; PROEDROU K, 2001, 0102 ROYAL HOLL U LO; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; PROVOST F, 1998, P 15 INT C MACH LEAR, P43; Rijsbergen C. V., 1979, INFORM RETRIEVAL, V2nd; Santos-Pereira CM, 2005, PATTERN RECOGN LETT, V26, P943, DOI 10.1016/j.patrec.2004.09.042; Swets JA, 2000, SCI AM, V283, P82; TING KM, 2002, P 5 INT C DISV SCI, P98; Tortorella F, 2005, PATTERN RECOGN LETT, V26, P167, DOI 10.1016/j.patrec.2004.09.004; Tortorella F, 2004, PATTERN ANAL APPL, V7, P128, DOI 10.1007/s10044-004-0209-2; Van Den Bossche R, 2006, J SLEEP RES, V15, P113; VANDERLOOY S, 2006, P ICML 2006 WORKSH R, P55; Weiss Gary M, 2007, Proceedings of the International Conference on Data Mining. DMIN 2007; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Ye J., 2004, ADV NEURAL INFORM PR, P1569	46	4	5	0	2	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X			INTELL DATA ANAL	Intell. Data Anal.		2009	13	1					3	37		10.3233/IDA-2009-0354		35	Computer Science, Artificial Intelligence	Computer Science	439KW	WOS:000265627000001		
J	Olvera-Lopez, JA; Martinez-Trinidad, JF; Carrasco-Ochoa, JA; Kittler, J				Olvera-Lopez, J. A.; Martinez-Trinidad, J. Fco.; Carrasco-Ochoa, J. A.; Kittler, J.			Prototype selection based on sequential search	INTELLIGENT DATA ANALYSIS			English	Article						Prototype selection; quality training set; supervised classification; sequential search	NEAREST-NEIGHBOR RULE; ORDERED PROJECTIONS; LEARNING ALGORITHMS; INSTANCE SELECTION; GENETIC ALGORITHMS; CLASSIFICATION; SET	In this paper, we propose and explore the use of the sequential search for solving the prototype selection problem since this kind of search has shown good performance for solving selection problems. We propose three prototype selection methods based on sequential search. The main goal of our methods is to reduce the training data without losing too much classification accuracy. Experiments and results are reported showing the effectiveness of the proposed methods and comparing their performance against other prototype selection methods.	[Olvera-Lopez, J. A.; Martinez-Trinidad, J. Fco.; Carrasco-Ochoa, J. A.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72840, Mexico; [Kittler, J.] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Olvera-Lopez, JA (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.	aolvera@ccc.inaoep.mx					Aguilar-Ruiz JS, 2006, LECT NOTES COMPUT SC, V4031, P1339; Asuncion A., 2007, UCI MACHINE LEARNING; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; Chien HC, 2006, IEEE PHOTONIC TECH L, V18, P559, DOI 10.1109/LPT.2005.863994; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KITTLER J, 1986, HDB PATTERN RECOGNIT, P203; Kuncheva LI, 1997, PATTERN RECOGN, V30, P1041, DOI 10.1016/S0031-3203(96)00134-3; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Rumelhart D.E., 1986, LEARNING INTERNAL RE, V1, P318; Spillmann B, 2006, LECT NOTES COMPUT SC, V4109, P287; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vapnik V. N., 1995, NATURE STAT LEARNING; VENMANN CJ, 2002, IEEE T PATTERN ANAL, V24, P1273; VENMANN CJ, 2005, IEEE T PATTERN ANAL, V27, P1417; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	32	1	1	1	5	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1088-467X			INTELL DATA ANAL	Intell. Data Anal.		2009	13	4					599	631		10.3233/IDA-2009-0383		33	Computer Science, Artificial Intelligence	Computer Science	494HP	WOS:000269802800005		
S	Caises, Y; Gonzalez, A; Leyva, E; Perez, R		Corchado, E; Yin, H		Caises, Yoel; Gonzalez, Antonio; Leyva, Enrique; Perez, Raul			SCIS: Combining Instance Selection Methods to Increase Their Effectiveness over a Wide Range of Domains	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC		Instance selection; data reduction; machine learning	PROTOTYPE REDUCTION SCHEMES; LEARNING ALGORITHMS	Instance selection is a feasible strategy to solve the problem of dealing with large databases in inductive learning. There are several proposals in this area, but none of them consistently outperforms the others over it wide range of domains. In this paper(1) we present a set of measures to characterize the databases, as well as a new algorithm that uses these measures and, depending on the data characteristics, it applies the method or combination of methods expected to produce the best results. This approach was evaluated over 20 databases and with six different learning paradigms. The results have been compared with those achieved by five well-known state-of-the-art methods.			ycaises@facinf.uho.edu.cu; A.Gonzalez@decsai.ugr.es; eleyvam@facinf.uho.edu.cu; Raul_Perez@decsai.ugr.es	Leyva, Enrique/H-5244-2011; Gonzalez Munoz, Antonio/C-2427-2012; Perez Rodriguez, F.G. Raul/C-2440-2012	Gonzalez Munoz, Antonio/0000-0001-8889-7593; Perez Rodriguez, F.G. Raul/0000-0002-1355-1122			Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; [Anonymous], UCI MACH LEARN REP; Bernado E, 2002, LECT NOTES ARTIF INT, V2321, P115; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Frank E., 1998, 15 INT C MACH LEARN, P144; Gonzalez A, 1999, IEEE T FUZZY SYST, V7, P176, DOI 10.1109/91.755399; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; John G. H., 1995, 11 C UNC ART INT, P338; Kim SW, 2003, PATTERN ANAL APPL, V6, P232, DOI 10.1007/s10044-003-0191-0; Kim SW, 2003, PATTERN RECOGN, V36, P1083, DOI 10.1016/S0031-3203(02)00115-2; Kruskal J. B., 1956, P AM MATH SOC, V48, P48, DOI DOI 10.1090/S0002-9939-1956-0078686-7; Mollineda RA, 2005, LECT NOTES COMPUT SC, V3523, P27; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Quinlan J. R., 1993, C4 5 PROGRAM MACHINE; Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; ZHAO K, 2003, INT C MACH LEARN CYB, V1, P94	23	2	2	0	10	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-04393-2	LECT NOTES COMPUT SC			2009	5788						17	24				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BND11	WOS:000274188700003		
S	Ishii, N; Hoki, Y; Okada, Y; Bao, YG		Corchado, E; Yin, H		Ishii, Naohiro; Hoki, Yuta; Okada, Yuki; Bao, Yongguang			Nearest Neighbor Classification by Relearning	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC				Since the k-nearest neighbor (kNN) classification is a simple and effective classification approach, it is well known in the data classification. However, improving performance of the classifier is still attractive to cope with the high accuracy processing. A tolerant rough set is considered as a basis of the classification of data. The data classification is realized by applying the kNN with distance function. To improve the classification accuracy, a distance function with weights is considered. Then, weights of the function are optimized by the genetic algorithm. After the learning of training data, an unknown data is classified by the kNN with distance function. To improve further the performance of the kNN classifier, a relearning method is proposed. The proposed relearning method shows a higher generalization accuracy when compared to the basic kNN with distance function and other conventional learning algorithms. Experiments have been conducted on some benchmark datasets from the UCI Machine Learning Repository.	[Ishii, Naohiro; Hoki, Yuta; Okada, Yuki; Bao, Yongguang] Aichi Inst Technol, Toyota 4700392, Japan	Ishii, N (reprint author), Aichi Inst Technol, Toyota 4700392, Japan.	ishii@aitech.ac.jp					Bao YG, 2002, LECT NOTES COMPUT SC, V2534, P340; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ishii N, 2006, LECT NOTES COMPUT SC, V4224, P57; Merz C, 1998, UCI REPOSITORY MACHI; Wilson DR, 2000, COMPUT INTELL, V16, P1, DOI 10.1111/0824-7935.00103	6	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-04393-2	LECT NOTES COMPUT SC			2009	5788						42	49				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BND11	WOS:000274188700006		
S	Valls, JM; Aler, R		Corchado, E; Yin, H		Valls, Jose M.; Aler, Ricardo			Optimizing Data Transformations for Classification Tasks	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2009)	SEP 23-26, 2009	Burgos, SPAIN	Junta Castilla Leon, Univ Burgos, Diputac Burgos, Ayuntamiento Burgos, GCI, CSA, FAE, FEC		Data transformations; General Euclidean Distances; Evolutionary Computation; Evolutionary-based Machine Learning		Many classification algorithms use the concept of distance or similarity between patterns. Previous work has shown that it is advantageous to optimize general Euclidean distances (GED). In this paper, data transformations are optimized instead. This is equivalent to searching for GEDs, but can be applied to any learning algorithm, even if it does not use distances explicitly. Two optimization techniques have been used: a simple Local Search (LS) and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). CMA-ES is an advanced evolutionary method for optimization in difficult continuous domains. Both diagonal and complete matrices have been considered. Results show that in general, complete matrices found by CMA-ES either outperform or match both Local Search, and the classifier working on the original untransformed data.	[Valls, Jose M.; Aler, Ricardo] Univ Carlos III Madrid, E-28903 Getafe, Spain	Valls, JM (reprint author), Univ Carlos III Madrid, E-28903 Getafe, Spain.	jvalls@inf.uc3m.es; aler@inf.uc3m.es					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gonzalez R. C., 1974, PATTERN RECOGNITION; Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398; Moody J., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.2.281; OSTERMEIER A, 1994, EVOLUTIONARY COMPUTA, V4, P369; Ripley BD, 1996, PATTERN RECOGNITION; Sierra A, 2006, IEEE T EVOLUT COMPUT, V10, P81, DOI 10.1109/TEVC.2005.856069; Valls JM, 2007, COMPUT INFORM, V26, P33; Weinberger K. Q., 2005, NEURAL INFORM PROCES; Weisberg S., 1985, APPL LINEAR REGRESSI	11	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-04393-2	LECT NOTES COMPUT SC			2009	5788						176	183				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BND11	WOS:000274188700022		
J	Shao, YN; He, Y; Bao, YD; Mao, JY				Shao, Yongni; He, Yong; Bao, Yidan; Mao, Jingyuan			Near-Infrared Spectroscopy for Classification of Oranges and Prediction of the Sugar Content	INTERNATIONAL JOURNAL OF FOOD PROPERTIES			English	Article						Vis; NIR spectroscopy; Orange; PCA; PLS; WT; BP-ANN	NIR-SPECTROSCOPY; SOLUBLE SOLIDS; REFLECTANCE SPECTROSCOPY; PATTERN-RECOGNITION; WAVELET TRANSFORM; CALIBRATION; REGRESSION; SPECTRA; DISCRIMINATION; CHEMISTRY	A nondestructive method for the classification of orange samples according to their growing conditions and geographic areas was developed using Vis/Near infrared spectroscopy. The results showed that the NIR spectra of the samples were moderately clustered in the principle component space and pattern recognition wavelet transform (WT) combined artificial neural network (BP-ANN) provided satisfactory classification results. Additionally, a partial least square (PLS) method was constructed to predict the sugar content of certain oranges. It showed excellent predictions of the sugar content of oranges, with standard error of prediction (SEP) values of 0.290 and 0.301 for Shatangju and Huangyanbendizao, respectively.	[Shao, Yongni; He, Yong; Bao, Yidan; Mao, Jingyuan] Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310029, Zhejiang, Peoples R China	He, Y (reprint author), Zhejiang Univ, Coll Biosyst Engn & Food Sci, Hangzhou 310029, Zhejiang, Peoples R China.	yhe@zju.edu.cn	He, Yong/E-3218-2010	He, Yong/0000-0001-6752-1757	National Science and Technology Support Program of China [2006BAD10A0403]; Zhejiang Provincial Natural Science Foundation of China [Y307158]; Science and Technology Department of Ningbo [2008C10037]; Scientific Research Fund of Zhejiang Provincial Education Department [20071064]	This study was supported by the National Science and Technology Support Program of China (2006BAD10A0403) Zhejiang Provincial Natural Science Foundation of China (Project No: Y307158), Science and Technology Department of Ningbo (2008C10037) and Scientific Research Fund of Zhejiang Provincial Education Department (20071064).	Carlini P, 2000, J AGR FOOD CHEM, V48, P5236, DOI 10.1021/jf000408f; Cen HY, 2007, TRENDS FOOD SCI TECH, V18, P72, DOI 10.1016/j.tifs.2006.09.003; COOMANS D, 1982, ANAL CHIM ACTA, V138, P153, DOI 10.1016/S0003-2670(01)85298-3; COOMANS D, 1983, METHOD INFORM MED, V22, P93; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DERDE MP, 1987, ANAL CHEM, V59, P1868, DOI 10.1021/ac00141a029; Dinc E, 2003, TALANTA, V59, P707, DOI 10.1016/S0039-9140(02)00611-2; He Y, 2006, SPECTROSC SPECT ANAL, V26, P850; HE YDF, 1998, ANAL BASIC APPL NEAR; HOLST H, 1992, APPL SPECTROSC, V46, P1780, DOI 10.1366/0003702924123601; Jetter K, 2000, ANAL CHIM ACTA, V420, P169, DOI 10.1016/S0003-2670(00)00889-8; KARSTANG TV, 1991, ANAL CHEM, V63, P767, DOI 10.1021/ac00008a006; Kawano S., 1994, NIR NEWS, V5, P10; Lammertyn J, 1998, T ASAE, V41, P1089; LI WJ, 2001, ANAL SCI           S, V117, P429; Liu F, 2009, ANAL CHIM ACTA, V635, P45, DOI 10.1016/j.aca.2009.01.017; LIZUKA K, 1999, J FOOD COMPOS ANAL, V12, P197; Lu R, 2001, T ASAE, V44, P1265; Mittermayr CR, 2001, APPL SPECTROSC, V55, P827, DOI 10.1366/0003702011952848; Miyamoto K., 1995, J NEAR INFRARED SPEC, V3, P227, DOI DOI 10.1255/JNIRS.73; NAES T, 1990, ANAL CHEM, V62, P664, DOI 10.1021/ac00206a003; Paradkar RP, 1996, APPL SPECTROSC, V50, P753, DOI 10.1366/0003702963905718; Peiris KHS, 1999, HORTSCIENCE, V34, P114; Pontes MJC, 2005, CHEMOMETR INTELL LAB, V78, P11, DOI 10.1016/j.chemolab.2004.12.001; Rodriguez-Saona LE, 2001, CARBOHYD RES, V336, P63, DOI 10.1016/S0008-6215(01)00244-0; Shao XG, 2003, ACCOUNTS CHEM RES, V36, P276, DOI 10.1021/ar990163w; Shao XG, 1999, SPECTROSC SPECT ANAL, V19, P139; Shao XG, 2000, FRESEN J ANAL CHEM, V367, P525, DOI 10.1007/s002160000404; Sjoblom J, 1998, CHEMOMETR INTELL LAB, V44, P229, DOI 10.1016/S0169-7439(98)00112-9; Steuer B, 2001, FOOD CHEM, V72, P113, DOI 10.1016/S0308-8146(00)00209-0; Tang Q.Y., 2002, DPS DATA PROCESSING; Walczak B, 1997, TRAC-TREND ANAL CHEM, V16, P451, DOI 10.1016/S0165-9936(97)00065-4; Wu W, 1996, ANAL CHIM ACTA, V329, P257, DOI 10.1016/0003-2670(96)00142-0	33	15	16	1	19	TAYLOR & FRANCIS INC	PHILADELPHIA	325 CHESTNUT ST, SUITE 800, PHILADELPHIA, PA 19106 USA	1094-2912			INT J FOOD PROP	Int. J. Food Prop.		2009	12	3					644	658	PII 910910637	10.1080/10942910801992991		15	Food Science & Technology	Food Science & Technology	439UP	WOS:000265653100016		
J	Arroyo, J; Mate, C				Arroyo, Javier; Mate, Carlos			Forecasting histogram time series with k-nearest neighbours methods	INTERNATIONAL JOURNAL OF FORECASTING			English	Article						Density forecast; Finance; Nonlinear time series models; Non-parametric forecasting; Symbolic data analysis; Weather forecast	DENSITY FORECASTS; ACCURACY	Histogram time series (HTS) describe situations where a distribution of values is available for each instant of time. These situations usually arise when contemporaneous or temporal aggregation is required. In these cases, histograms provide a summary of the data that is more informative than those provided by other aggregates such as the mean. Some fields where HTS are useful include economy, official statistics and environmental science. This article adapts the k-Nearest Neighbours (k-NN) algorithm to forecast HTS and, more generally, to deal with histogram data. The proposed k-NN relies on the choice of a distance that is used to measure dissimilarities between sequences of histograms and to compute the forecasts. The Mallows distance and the Wasserstein distance are considered. The forecasting ability of the k-NN adaptation is illustrated with meteorological and financial data, and promising results are obtained. Finally, further research issues are discussed. (C) 2008 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.	[Arroyo, Javier] Univ Complutense, Dept Ingn Software & Inteligencia Artificial, E-28040 Madrid, Spain; [Mate, Carlos] Univ Pontificia Comillas, Inst Invest Tecnol, ETSI, ICAI, Madrid 28015, Spain	Arroyo, J (reprint author), Univ Complutense, Dept Ingn Software & Inteligencia Artificial, Prof Garcia Santesmases S-N, E-28040 Madrid, Spain.	javier.arroyo@fdi.ucm.es	Arroyo, Javier/K-3353-2014	Arroyo, Javier/0000-0001-6127-7538			Aparicio T., 2002, APPL FINANCIAL EC, V12, P517, DOI 10.1080/09603100010007986; ARROYO JC, 2008, EXPONENTIAL SMOOTHIN; Billard L, 2003, J AM STAT ASSOC, V98, P470, DOI 10.1198/016214503000242; BILLARD L, 2006, SYMBLIC DATA ANAL CO; Brath A, 2002, HYDROL EARTH SYST SC, V6, P627; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diday E., 2008, SYMBOLIC DATA SODAS; Diebold FX, 1998, INT ECON REV, V39, P863, DOI 10.2307/2527342; ENGLE RF, HDB FINANCI IN PRESS; FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845; Fernandez-Rodriguez F, 1999, INT J FORECASTING, V15, P383, DOI 10.1016/S0169-2070(99)00003-5; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; Gonzalez-Rivera G, 2008, J APPL ECONOM, V23, P585, DOI 10.1002/jae.1015; Hall SG, 2007, INT J FORECASTING, V23, P1, DOI 10.1016/j.ijforecast.2006.08.001; H-H Bock, 2000, ANAL SYMBOLIC DATA E, P153; Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001; Irpino A, 2006, ST CLASS DAT ANAL, P185, DOI 10.1007/3-540-34416-0_20; Jayawardena AW, 2002, J HYDROL, V258, P40, DOI 10.1016/S0022-1694(01)00557-1; Levina E., 2001, P IEEE 8 INT C COMP, V2, P251, DOI 10.1109/ICCV.2001.937632; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; Meade N, 2002, INT J FORECASTING, V18, P67, DOI 10.1016/S0169-2070(01)00111-X; Pasley A, 2004, DECIS SUPPORT SYST, V37, P501, DOI 10.1016/S0167-9236(03)00083-6; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Schweizer B, 1984, P MATH FUZZY SYSTEMS, P137; Sorjamaa A, 2005, LECT NOTES COMPUT SC, V3512, P985; Tay AS, 2000, J FORECASTING, V19, P235, DOI 10.1002/1099-131X(200007)19:4<235::AID-FOR772>3.3.CO;2-C; Verde R, 2007, SELECTED CONTRIBUTIO, P123, DOI 10.1007/978-3-540-73560-1_12; Wand MP, 1997, AM STAT, V51, P59, DOI 10.2307/2684697; Yakowitz S. J., 1987, J TIME SER ANAL, V8, P235, DOI 10.1111/j.1467-9892.1987.tb00435.x	29	14	16	0	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-2070			INT J FORECASTING	Int. J. Forecast.	JAN-MAR	2009	25	1					192	207		10.1016/j.ijforecast.2008.07.003		16	Economics; Management	Business & Economics	415OZ	WOS:000263944800017		
J	Papa, JP; Falcao, AX; Suzuki, CTN				Papa, J. P.; Falcao, A. X.; Suzuki, C. T. N.			Supervised Pattern Classification Based on Optimum-Path Forest	INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY			English	Article	12th International Workshop on Combinatorial Image Analysis	APR 07-09, 2008	Buffalo, NY			supervised learning; image foresting transform; pattern recognition; image analysis; graph-search algorithms	FUZZY CONNECTEDNESS; IMAGE SEGMENTATION; ALGORITHMS	We present a supervised classification method which represents each class by one or more optimum-path trees rooted at some key samples, called prototypes. The training samples are nodes of a complete graph, whose arcs are weighted by the distances between the feature vectors of their nodes. Prototypes are identified in all classes and the minimization of a connectivity function by dynamic programming assigns to each training sample a minimum-cost path from its most strongly connected prototype. This competition among prototypes partitions the graph into an optimum-path forest rooted at them. The class of the samples in an optimum-path tree is assumed to be the same of its root. A test sample is classified similarly, by identifying which tree would contain it, if the sample were part of the training set. By choice of the graph model and connectivity function, one can devise other optimum-path forest classifiers. We present one of them, which is fast, simple, multiclass, parameter independent, does not make any assumption about the shapes of the classes, and can handle some degree of overlapping between classes. We also propose a general algorithm to learn from errors on an evaluation set without increasing the training set, and show the advantages of our method with respect to SVM, ANN-MLP, and k-NN classifiers in several experiments with datasets of various types. (C) 2009 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 19, 120-131, 2009; Published online in Wiley InterScience (www.intersciencewiley.com). DOI 10.1002/ima.20188	[Papa, J. P.; Falcao, A. X.; Suzuki, C. T. N.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil	Falcao, AX (reprint author), Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.	afalcao@ic.unicamp.br	Falcao, Alexandre/F-8361-2012				Allene C., 2007, MATH MORPHOLOGY ITS, P253; Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3; Audigier Romaric, 2007, 2007 20th Brazilian Symposium on Computer Graphics and Image Processing - SIBGRAPI '07; Audigier R., 2007, MATH MORPHOLOGY ITS, P277; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CALLUT J, 2008, P 17 ANN MACH LEARN, P67; CAPPABIANCO FAM, 2008, 5 IEEE INT S BIOM IM, P428; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cohen J, 1960, EDUC PSYCHOL MEAS, V20, P46; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Collobert R., 2004, P 21 INT C MACH LEAR, P23; *COR CORP, 2007, COR STOCK PHOT IM; Cormen T., 1990, INTRO ALGORITHMS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; FALCAO AX, 2008, Patent No. 2008064442; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Haykin S., 1994, NEURAL NETWORKS COMP; Herman GT, 2001, IEEE T PATTERN ANAL, V23, P460, DOI 10.1109/34.922705; HU M, 1962, IRE T INFORM THEOR, V8, P179; HUANG SC, 1991, IEEE T NEURAL NETWOR, V2, P47, DOI 10.1109/72.80290; HUBERT LJ, 1974, PSYCHOMETRIKA, V39, P283, DOI 10.1007/BF02291704; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Joachims T., 1999, P 16 INT C MACH LEAR, V99, P200; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Koza J., 1992, GENETIC PROGRAMMING; Kulis B., 2005, ICML, P457; Kumar N, 2008, IEEE T KNOWL DATA EN, V20, P496, DOI 10.1109/TKDE.2007.190715; KUNCHEVA L, 1996, ARTIFICIAL DATA SCH; KUNCHEVA LI, 2004, COMBINING PATTERN CL; LOTUFO RA, 2000, MATH MORPHOLOGY ITS, V18, P341; Martinez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074; MIRANDA PAV, 2008, EURASIP J ADV SIG PR, P1; MONTOYAZEGARRA JA, 2008, EURASIP J ADV SIG PR, P1, DOI DOI 10.1155/2008/691924; Nissen S., 2003, IMPLEMENTATION FAST; Panda N., 2006, P 23 INT C MACH LEAR, P681, DOI 10.1145/1143844.1143930; Papa J., 2007, MATH MORPHOLOGY ITS, P337; Papa JP, 2008, PROCEEDINGS OF IWSSIP 2008: 15TH INTERNATIONAL CONFERENCE ON SYSTEMS, SIGNALS AND IMAGE PROCESSING, P249; PAPA JP, 2008, LNCS, P136; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Reyzin L., 2006, P 23 INT C MACH LEAR, P753, DOI 10.1145/1143844.1143939; ROCHA LM, 2008, 8 INT WORKSH COMB IM, P29; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; SPADOTTO AA, 2008, P 3 IEEE INT S COMM, P735; Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tang B., 2006, P 23 INT C MACH LEAR, P921, DOI 10.1145/1143844.1143960; Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010; Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007; WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhou D., 2005, ADV NEURAL INFORM PR, V17, P1633; ZHU X, 2000, 1530 U WISC MAD	58	73	75	3	10	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0899-9457			INT J IMAG SYST TECH	Int. J. Imaging Syst. Technol.		2009	19	2					120	131		10.1002/ima.20188		12	Engineering, Electrical & Electronic; Optics; Imaging Science & Photographic Technology	Engineering; Optics; Imaging Science & Photographic Technology	451YD	WOS:000266505900009		
J	Bo, S; Ding, L; Li, H; Di, F; Zhu, C				Bo, S.; Ding, L.; Li, H.; Di, F.; Zhu, C.			Mean shift-based clustering analysis of multispectral remote sensing imagery	INTERNATIONAL JOURNAL OF REMOTE SENSING			English	Article							PATTERN-CLASSIFICATION; MULTIVARIATE DATA; SCALE; SPACES	In clustering analysis of remote sensing imagery, a commonly held assumption is that the feature space can be modelled as a mixture of Gaussians. However, the assumption is not true for many real data and therefore incorrect classification results are often obtained by parametric methods. Nonparametric methods in feature space analysis can avoid the use of the normality assumption. Arbitrarily structured feature spaces can be analysed only by means of nonparametric methods as these methods do not have embedded assumptions. The mean shift is a basic computational module of the nonparametric technique in pattern recognition. The mean shift procedure can be used to cluster multispectral remote sensing imagery. Earlier clustering techniques based on the mean shift used a single scale over the entire feature space and were not feasible for the analysis of complex multimodal feature spaces. In this paper, we present an adaptive mean shift method in which local scale information is involved. The proposed algorithm can find arbitrary density, size and shape clusters in remote sensing imagery. The method is a simple technique of unsupervised image classification. We demonstrate its advantages in classification accuracy over earlier methods described in this paper.	[Bo, S.] Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou 450015, Peoples R China; [Ding, L.; Li, H.; Di, F.; Zhu, C.] Chinese Acad Sci, Inst Remote Sensing Applicat, Beijing 100101, Peoples R China	Bo, S (reprint author), Zhengzhou Inst Aeronaut Ind Management, Dept Comp Sci & Applicat, Zhengzhou 450015, Peoples R China.	bsk586@163.com			National Natural Science Foundation of China [40771140/D0118]; China's Special Funds [2007CB714406]	We gratefully acknowledge support for this work from the National Natural Science Foundation of China (40771140/D0118), China's Special Funds for Major State Basic Research Project (2007CB714406). We thank the referees for their useful comments and Dr C. Cassells for improving the style in our manuscript.	Baatz M., 2004, ECOGNITION PROFESSIO; Bestelmeyer BT, 2006, J ARID ENVIRON, V65, P296, DOI 10.1016/j.jaridenv.2005.06.028; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790; Comaniciu D., 2001, Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790416; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVID JM, 2003, PATTERN RECOGN, V36, P45; Ghosh AK, 2006, COMPUT STAT DATA AN, V50, P3113, DOI 10.1016/j.csda.2005.06.007; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Jalba AC, 2004, PATTERN RECOGN, V37, P901, DOI 10.1016/j.patcog.2003.09.009; Li Xiang-Ru, 2005, Journal of Software, V16, DOI 10.1360/jos160365; Lofy B, 2001, PATTERN RECOGN, V34, P1825, DOI 10.1016/S0031-3203(00)00107-2; Nakamura E, 1998, PATTERN RECOGN LETT, V19, P1265, DOI 10.1016/S0167-8655(98)00099-3; Tran TN, 2006, COMPUT STAT DATA AN, V51, P513, DOI 10.1016/j.csda.2005.10.001; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009	18	12	13	1	5	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0143-1161			INT J REMOTE SENS	Int. J. Remote Sens.		2009	30	4					817	827		10.1080/01431160802395193		11	Remote Sensing; Imaging Science & Photographic Technology	Remote Sensing; Imaging Science & Photographic Technology	436JD	WOS:000265409100001		
B	Nakagawa, T; Shibata, T			IEEE	Nakagawa, Takuki; Shibata, Tadashi			A Real-Time Image Feature Vector Generator Employing Functional Cache Memory for Edge Flags	ISCAS: 2009 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-5			English	Proceedings Paper	IEEE International Symposium on Circuits and Systems (ISCAS 2009)	MAY 24-27, 2009	Taipei, TAIWAN	IEEE				A feature-vector-generation VLSI architecture has been developed aiming at building real-time image recognition systems based on the directional edge based algorithm. The functional cache memory developed in the present work cyclically buffers newly extracted edge flags from an input image, while supplying edge flags to a vector generation circuitry. As a result, it has become possible to generate a 64-dimetional feature vector in every cycle of operation. The chip was designed in a 0.18-mu m 5-metal CMOS technology and sent to fabrication, and correct operation of the entire system was confirmed by Nanosim simulation. The architecture enables us to generate 3.9x10(7) feature vectors/sec (@100MHz), which is 5x10(3) times faster than the software processing using 2.16-GHz processor.	[Nakagawa, Takuki] Univ Tokyo, Dept Elect Engn, Tokyo 113, Japan	Nakagawa, T (reprint author), Univ Tokyo, Dept Elect Engn, 7-3-1 Hongo, Tokyo 113, Japan.	takuki@else.k.u-tokyo.ac.jp; shibata@ee.t.u-tokyo.ac.jp					Boser B, 1992, P 5 ANN WORKSH COMP, V5, P144, DOI DOI 10.1145/130385.130401; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalai N., 2005, INT C COMP VIS PATT, V1, P886, DOI DOI 10.1109/CVPR.2005.177; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574; Lowe D. G., 2004, INT J COMPUT VISION, V60; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shibata T., 1999, P 2 INT C INF FUS SU, V1, P648; Yagi M, 2003, IEEE T NEURAL NETWOR, V14, P1144, DOI 10.1109/TNN.2003.819038; Yamasaki H, 2007, IEEE J SOLID-ST CIRC, V42, P2046, DOI 10.1109/JSSC.2007.903099	10	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3827-3				2009							3026	3029				4	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BNZ33	WOS:000275929801443		
B	Li, XA; Feng, L; Zhou, LZ			IEEE	Li, Xiang; Feng, Ling; Zhou, Lizhu			Contextual Ranking of Query Results with Incomplete Preferences	JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING			English	Proceedings Paper	Joint Conference on Pervasive Computing	DEC 03-05, 2009	Tamsui, TAIWAN		Tamsui & Tamkang Univ	Context-aware; preference; incomplete; ranking		Context-aware database is frequently used in user-centric applications. The users normally tend to express their preferences through comparisons. For example, Bob prefers Cornell to USC. Because the users only compare a small proportion of the products under difference contexts, "incomplete" preferences are a common occurrence. We propose a ranking approach which can contextually rank the query results when the users preferences are incomplete. We empirically evaluate the practical effectiveness of our method.	[Li, Xiang; Feng, Ling; Zhou, Lizhu] Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China	Li, XA (reprint author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China.	li-xiang06@mails.tsinghua.edu.cn; fengling@tsinghua.edu.cn; dcszlz@tsinghua.edu.cn					BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BUNNINGEN A, DEXA 2006; Chomicki J, 2003, ACM T DATABASE SYST, V28, P427, DOI 10.1145/958942.958946; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY B, NEAREAST NEIGHOR PAT; Fix E., 1951, 4 USAF SCH AV MED; GENG X, SIGIR 08; INDYK P, P S THEOR COMP 1998; KENDALL MG, 1955, BIOMETRICS, V11, P43, DOI 10.2307/3001479; LI X, 2008, P IEEE 3 EUR C SMART; Omohundro S.M., 1989, TR89063 INT COMP SCI; STEFANIDIS K, 1 INT WORKSH MAN CON; STEFANIDIS K, EDBT 2008; Stefanidis K., 2007, ICDE; Wei T.-H., 1952, ALGEBRAIC FDN RANKIN; You GW, 2008, INFORM SCIENCES, V178, P3925, DOI 10.1016/j.ins.2008.06.009; NATL REPORT 2007 COL	17	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5227-9				2009							349	354				6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BQT40	WOS:000281790400061		
J	Varnek, A; Gaudin, C; Marcou, G; Baskin, I; Pandey, AK; Tetko, IV				Varnek, Alexandre; Gaudin, Cedric; Marcou, Gilles; Baskin, Igor; Pandey, Anil Kumar; Tetko, Igor V.			Inductive Transfer of Knowledge: Application of Multi-Task Learning and Feature Net Approaches to Model Tissue-Air Partition Coefficients	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							ASSOCIATIVE NEURAL NETWORKS; STRUCTURE-PROPERTY; COMBINATORIAL LIBRARY; CROSS-VALIDATION; DATA SETS; PREDICTION; DATABASE; BIAS; CLASSIFICATION; LIPOPHILICITY	Two inductive knowledge transfer approaches - multitask learning (MTL) and Feature Net (FN) - have been used to build predictive neural networks (ASNN) and PLS models for I I types of tissue-air partition coefficients (TAPC). Unlike conventional single-task learning (STL) modeling focused only on a single target property without any relations to other properties, in the framework of inductive transfer approach, the individual models are viewed as nodes in the network of interrelated models built in parallel (MTL) or sequentially (FN). It has been demonstrated that MTL and FN techniques are extremely useful in structure-property modeling on small and structurally diverse data sets, when conventional STL modeling is unable to produce any predictive model. The predictive STL individual models were obtained for 4 out of I I TAPC, whereas application of inductive knowledge transfer techniques resulted in models for 9 TAPC. Differences in prediction performances of the models as a function of the machine-learning method, and of the number of properties simultaneously involved in the learning, has been discussed.	[Varnek, Alexandre; Gaudin, Cedric; Marcou, Gilles] Univ Strasbourg, CNRS, UMR 7177, Lab Infochim, F-67000 Strasbourg, France; [Baskin, Igor] Moscow MV Lomonosov State Univ, Dept Chem, Moscow 119991, Russia; [Pandey, Anil Kumar; Tetko, Igor V.] Inst Bioinformat & Syst Biol, Helmholtz Zentrum Munchen, German Res Ctr Environm Hlth GmbH, D-85764 Neuherberg, Germany; [Tetko, Igor V.] Natl Ukrainian Acad Sci, Inst Bioorgan & Petrochem, UA-02660 Kiev, Ukraine	Varnek, A (reprint author), Univ Strasbourg, CNRS, UMR 7177, Lab Infochim, 4 Rue B Pascal, F-67000 Strasbourg, France.	vamek@chimie.u-strasbg.fr	Tetko, Igor/B-1540-2010; Baskin, Igor/I-2490-2012; MARCOU, Gilles/F-8592-2015	Tetko, Igor/0000-0002-6855-0012; 	Go-Bio BMBF [0313883]; ARCUS; Louis Pasteur University	We thank CAMO ASA for providing us a demo version of Unscrambler 9.7 software to perform PLS analysis. This study was partially supported by the Go-Bio BMBF grant 0313883, the ARCUS "Alsace-Russia/Ukraine" project, and Louis Pasteur University for the Invited Professor's position to I.V.T.	Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, DOI 10.1016/0885-064X(90)90006-Y; *ACC INC, DIVA 2 1 PROGR; [Anonymous], 2004, P 21 INT C MACH LEAR; Balakin KV, 2006, CURR MED CHEM, V13, P223, DOI 10.2174/092986706775197917; BASKIN II, 1993, DOKL AKAD NAUK+, V332, P713; Baxter J, 2000, J ARTIF INTELL RES, V12, P149; Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663; BAXTER J, 1997, LEARNING LEARN; *CAMO ASA, UNSCR 9 7 SOFTW; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Caruana R., 1997, THESIS CARNEGIE MELL, P2; CARUANA R, 1993, P 10 INT C MACH LEAR, P4148; CARUANA R, 1993, P 1993 CONN MOD SUMM, P372; CARUANA R, 1995, ADV NEURAL INFORMATI, V7, P656; Chang C.-C., 2008, LIBSVM LIB SUPPORT V; Clark T., 2003, EUROQSAR 2002 DESIGN, P111; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAVIS I, 1995, P IEEES INT ROB SYST; Erhan D, 2006, J CHEM INF MODEL, V46, P626, DOI 10.1021/ci050367t; ERIKSSON L, 2001, UMETRICS UMEA, V425; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; FU LM, 1992, CONNECT SCI, V1, P325; GENTNER D, 1989, SIMILARITY AND ANALOGICAL REASONING, P199, DOI 10.1017/CBO9780511529863.011; GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Heskes T, 2000, P 17 INT C MACH LEAR, P367; Katritzky AR, 2005, BIOORGAN MED CHEM, V13, P6450, DOI 10.1016/j.bmc.2005.06.066; Kohavi R., 1995, ARTIF INTELL, V2, P1137; KOVAC K, 2005, THESIS COMPUTER SCI; Lu W.C., 2004, P 7 INT C INF FUS SV, V1, P79; MAHONEY J, 1992, P 1992 MACH LEARN WO; MICCHELLI CA, 2005, P 18 C NEUR INF PROC; MOORE AW, 1992, COMPUTATIONAL LEARNI, V3; MURPHY GL, 1985, PSYCHOL REV, V92, P289, DOI 10.1037//0033-295X.92.3.289; MUSLEA IA, 2002, THESIS; NAKAMURA GV, 1985, MEM COGNITION, V13, P377, DOI 10.3758/BF03198450; Oloff S, 2005, J MED CHEM, V48, P7322, DOI 10.1021/jm049116m; PAZZANI MJ, 1991, J EXP PSYCHOL LEARN, V17, P416, DOI 10.1037/0278-7393.17.3.416; PRESS WH, 1994, NUMERICAL RECIPES C, P998; RANNAR S, 1995, J CHEMOMETR, V9, P459, DOI 10.1002/cem.1180090604; RENDELL L., 1987, P 10 INT JOINT C ART, P308; SCHANK RC, 1986, BEHAV BRAIN SCI, V9, P639; Schmidhuber J, 1997, MACH LEARN, V28, P105, DOI 10.1023/A:1007383707642; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Solov'ev VP, 2003, J CHEM INF COMP SCI, V43, P1703, DOI 10.1021/ci020388c; SUDDARTH SC, 1991, INT J MAN MACH STUD, V35, P291, DOI 10.1016/S0020-7373(05)80130-0; Tetko IV, 2004, J PHARM SCI-US, V93, P3103, DOI 10.1002/jps.20217; Tetko IV, 2004, J MED CHEM, V47, P5601, DOI 10.1021/jm049509l; Tetko IV, 2008, J INORG BIOCHEM, V102, P1424, DOI 10.1016/j.jinorgbio.2007.12.029; Tetko IV, 2001, J CHEM INF COMP SCI, V41, P1407, DOI 10.1021/ci010368v; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P1136, DOI 10.1021/ci025515j; Tetko IV, 2002, J CHEM INF COMP SCI, V42, P717, DOI 10.1021/ci010379o; Tetko IV, 1997, NEURAL NETWORKS, V10, P1361, DOI 10.1016/S0893-6080(97)00005-1; TETKO IV, 1995, J CHEM INF COMP SCI, V35, P826, DOI 10.1021/ci00027a006; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Tetko IV, 2006, J CHEM INF MODEL, V46, P808, DOI 10.1021/ci0504216; Tetko IV, 2002, NEURAL PROCESS LETT, V16, P187, DOI 10.1023/A:1019903710291; THRUN S, 1995, CMUCS95208 COMP SCI; Thrun S., 1998, LEARNING LEARN; THRUN S, 1996, INT C MACH LEARN, P489; Thrun S, 1996, ADV NEUR IN, V8, P640; TOWELL GG, 1994, ARTIF INTELL, V70, P119, DOI 10.1016/0004-3702(94)90105-8; UTGOFF P, 1986, MACHINE LEARNING ART, V2; Vapnik V. N., 1995, NATURE STAT LEARNING; Varnek A, 2004, J CHEM INF COMP SCI, V44, P1365, DOI 10.1021/ci049976b; Varnek A, 2008, CURR COMPUT-AID DRUG, V4, P191, DOI 10.2174/157340908785747465; YU K, 2005, NIPS 2005 WORKSH IND; Zhang J, 2006, ADV NEURAL INFORM PR, V18, P1585	69	16	17	0	10	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	JAN	2009	49	1					133	144		10.1021/ci8002914		12	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Pharmacology & Pharmacy; Chemistry; Computer Science	399SB	WOS:000262818500015	19125628	
J	Chuang, LY; Yang, CH; Yang, CH				Chuang, Li-Yeh; Yang, Cheng-Huei; Yang, Cheng-Hong			Tabu Search and Binary Particle Swarm Optimization for Feature Selection Using Microarray Data	JOURNAL OF COMPUTATIONAL BIOLOGY			English	Article						feature selection; K-nearest neighbor; leave-one-out cross-validation; particle swarm optimization; support vector machines; tabu search	SUPPORT VECTOR MACHINES; GENE-EXPRESSION SIGNATURES; MOLECULAR CLASSIFICATION; CANCER-DIAGNOSIS; NEURAL NETWORKS; PREDICTION; ALGORITHMS; CARCINOMAS	Gene expression profiles have great potential as a medical diagnosis tool because they represent the state of a cell at the molecular level. In the classification of cancer type research, available training datasets generally have a fairly small sample size compared to the number of genes involved. This fact poses an unprecedented challenge to some classification methodologies due to training data limitations. Therefore, a good selection method for genes relevant for sample classification is needed to improve the predictive accuracy, and to avoid incomprehensibility due to the large number of genes investigated. In this article, we propose to combine tabu search (TS) and binary particle swarm optimization (BPSO) for feature selection. BPSO acts as a local optimizer each time the TS has been run for a single generation. The K-nearest neighbor method with leave-one-out cross-validation and support vector machine with one-versus-rest serve as evaluators of the TS and BPSO. The proposed method is applied and compared to the 11 classification problems taken from the literature. Experimental results show that our method simplifies features effectively and either obtains higher classification accuracy or uses fewer features compared to other feature selection methods.	[Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan; [Chuang, Li-Yeh] I Shou Univ, Dept Chem Engn, Kaohsiung, Taiwan; [Yang, Cheng-Huei] Natl Kaohsiung Marine Univ, Dept Elect Commun Engn, Kaohsiung, Taiwan; [Yang, Cheng-Hong] Toko Univ, Dept Network Syst, Chiayi, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.	chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011; Yang, Cheng-Hong/M-7984-2013	Yang, Cheng-Hong/0000-0002-2741-0072	National Science Council in Taiwan [NSC94-2622-E151-025-CC3, NSC94-2311-B037-001, NSC93-2213-E-214-037, NSC92-2213-E-214-036]	This work is partly supported by the National Science Council in Taiwan under grants NSC94-2622-E151-025-CC3, NSC94-2311-B037-001, NSC93-2213-E-214-037, and NSC92-2213-E-214-036.	Ancona N, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S4-S2; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bottino A, 1994, ASTROPART PHYS, V2, P77, DOI 10.1016/0927-6505(94)90019-1; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN, P1; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Duarte A, 2007, EUR J OPER RES, V178, P71, DOI 10.1016/j.ejor.2006.01.021; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Friess T. T., 1998, P 15 INT C MACH LEAR, P188; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Glover F., 1989, ORSA Journal on Computing, V1; Glover F., 1990, ORSA Journal on Computing, V2; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T, 2001, ELEMENTS STAT LEARNI; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kennedy J., 1995, IEEE INT C NEUR NETW, V4, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J., 2001, SWARM INTELLIGENCE; KENNEDY J, 1997, P WORLD MULT SYST CY, P4104, DOI DOI 10.1109/ICSMC.1997.637339; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102; Liu XX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-76; Mitchell T. M., 1997, MACHINE LEARNING; Narendra P.M., 1977, IEEE T COMPUT, V6, P917; Nutt CL, 2003, CANCER RES, V63, P1602; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Platt J.C., 2000, LARGE MARGIN DAGS MU, P547; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Sait SM, 2006, ENG APPL ARTIF INTEL, V19, P257, DOI 10.1016/j.engappai.2005.09.008; Shi Y, 1998, P IEEE INT C EV COMP, P69, DOI DOI 10.1109/ICEC.1998.699146; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Smola P., 2002, LEARNING KERNELS SUP; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; STONE M, 1974, J R STAT SOC B, V36, P111; Su AI, 2001, CANCER RES, V61, P7388; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95; West M.A., 1999, CENTREPIECE, V4, P6; Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Zhang CY, 2007, COMPUT OPER RES, V34, P3229, DOI 10.1016/j.cor.2005.12.002; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; Zhou X, 2007, BIOINFORMATICS, V23, P1106, DOI 10.1093/bioinformatics/btm036	57	8	8	0	8	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1066-5277	1557-8666		J COMPUT BIOL	J. Comput. Biol.		2009	16	12					1689	1703		10.1089/cmb.2007.0211		15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	545CG	WOS:000273709400005	20047491	
J	Cantero, R; Riba, JR; Canals, T; Izquierdo, LL; Iturriaga, H				Cantero, R.; Riba, J. R.; Canals, T.; Izquierdo, L. L.; Iturriaga, H.			CHARACTERIZATION OF LEATHER FINISHING BY IR SPECTROSCOPY AND CANONICAL VARIATE ANALYSIS	JOURNAL OF THE SOCIETY OF LEATHER TECHNOLOGISTS AND CHEMISTS			English	Article							PROCESS ANALYTICAL-CHEMISTRY; REFLECTANCE SPECTROSCOPY; NEAREST-NEIGHBOR; CLASSIFICATION; DISCRIMINATION; CHEMOMETRICS; CALIBRATION; TECHNOLOGY; REGRESSION; OILS	The finishing process is one of the crucial steps in the process by which the tanning industry transforms leather into an end-product. Therefore, ensuring the required quality in the product requires careful control of this step. Traditionally, the leather tanning industry has used polluting processes and slow analytical methods involving time-consuming separations and also, frequently, the use of environmentally unfriendly reagents. In this work, we used a large matrix of spectroscopic data obtained from 63 leather specimens (34 from Pielcolor and 29 from the laboratories of the Leather Technology School of Igualada) to develop a method allowing the finishing method used on a leather (viz. a resin, wax/oil or grain correction treatment) to be expeditiously, non-destructively identified with the need for no sample treatment. To this end, Fourier transform infrared (FTIR) spectra were recorded with the aid of an ATR module and near-infrared (NIR) spectra with a fibre-optic probe. Chemometric processing of the FTIR or NIR spectral information thus obtained by Principal Component Analysis (PCA) and Canonical Variate Analysis (CVA) allowed the identification of the finishing treatment used on the studied leather samples. The results for the external prediction set (80% of hits with the FTIR model and 60% with the NIR model) were of the same order of magnitude than those obtained by leave-one-out cross-validation of the calibration set (85% with FTIR and 72% with NIR).	[Iturriaga, H.] Univ Autonoma Barcelona, Dept Quim, Unitat Quim Analit, E-08193 Bellaterra, Spain; [Cantero, R.; Riba, J. R.; Canals, T.] Univ Politecn Cataluna, EUETII Leather Technol Sch, Barcelona, Spain; [Izquierdo, L. L.] Pielcolor SLU, Barcelona 08291, Spain	Iturriaga, H (reprint author), Univ Autonoma Barcelona, Dept Quim, Unitat Quim Analit, E-08193 Bellaterra, Spain.	hortensia.iturriaga@uab.es		Riba Ruiz, Jordi-Roger/0000-0001-8774-2389	Spain's Ministry of Education and Science [CTQ 2006-12923]	The authors are grateful to Spain's Ministry of Education and Science for funding this research within the framework of Project CTQ 2006-12923.	ADZET JM, 1989, ACABADO PIEL; Alsberg BK, 1997, ANAL CHIM ACTA, V348, P389, DOI 10.1016/S0003-2670(97)00064-0; Alves MR, 2004, J CHEMOMETR, V18, P393, DOI 10.1002/cem.884; Bacardit A., 2000, ACABADO CUERO; Berrueta LA, 2007, J CHROMATOGR A, V1158, P196, DOI 10.1016/j.chroma.2007.05.024; Blanco M, 1996, J SOC LEATH TECH CH, V80, P110; Cantero R, 2007, TALANTA, V71, P1690, DOI 10.1016/j.talanta.2006.08.005; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUNKIN MJ, 1995, J SOC LEATHER TECHNO, V79, P8; ESTEVEZ J, 1986, AQEIC, V12, P481; ESTEVEZ J, 1987, AQEIC, V1, P1; Geladi P, 2003, SPECTROCHIM ACTA B, V58, P767, DOI 10.1016/S0584-8547(03)00037-5; Geladi P, 2004, SPECTROCHIM ACTA B, V59, P1347, DOI 10.1016/j.sab.2004.06.009; Blanco M, 2000, ANAL CHIM ACTA, V419, P209, DOI 10.1016/S0003-2670(00)00976-4; GUZMAN JJ, 2004, CPMC, V80, P155; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; JUAN L, 2007, JISUANJI YU YINGYONG, V24, P247; KLIVERI HT, 1992, TECHNOMETRICS, V34, P321; KOWALSKI BR, 1991, J CHEMOMETR, V5, P129, DOI 10.1002/cem.1180050303; Krzanowski W. J., 1993, PRINCIPLES MULTIVARI; MARJONIEMI M, 1995, J SOC LEATH TECH CH, V79, P41; Marjoniemi M., 1992, J AM LEATHER CHEM AS, V87, P249; McClure WF, 2003, J NEAR INFRARED SPEC, V11, P487; NAVIGLIO B, 1993, CPMC, V69, P79; Paradkar MM, 2003, J SCI FOOD AGR, V83, P714, DOI 10.1002/jsfa.1332; PLATE D, 2000, LEDER HAUTE MARKT, V2, P25; Plate D., 2003, LEDER HAUTE MARKT, V6, P30; RENCHER AC, 1992, AM STAT, V46, P217, DOI 10.2307/2685219; Shelly DC, 1999, J AM LEATHER CHEM AS, V94, P315; Workman J, 2005, ANAL CHEM, V77, P3789, DOI 10.1021/ac050620o; Workman J, 2007, ANAL CHEM, V79, P4345, DOI 10.1021/ac070765q; Yang H, 2005, FOOD CHEM, V93, P25, DOI 10.1016/j.foodchem.2004.08.039	32	1	1	1	5	SOC LEATHER TECHNOL CHEMISTS	MOULTON	8 COPPER LEAF CLOSE, MOULTON NN3 7HS, NORTHAMPTON, ENGLAND	0144-0322			J SOC LEATH TECH CH	J. Soc. Leather Technol. Chem.	JAN-FEB	2009	93	1					12	17				6	Materials Science, Textiles	Materials Science	415LU	WOS:000263936100003		
J	Liou, SW; Wang, CM; Huang, YF				Liou, Sing-Wu; Wang, Chia-Ming; Huang, Yin-Fu			Integrative Discovery of Multifaceted Sequence Patterns by Frame-Relayed Search and Hybrid PSO-ANN	JOURNAL OF UNIVERSAL COMPUTER SCIENCE			English	Article	2nd KES International Symposium on Agent and Multi-Agent Systems	MAR 26-28, 2008	Incheon, SOUTH KOREA	Inha Univ, Sch Comp & Informat Engn, KES Int, KES Focus Grp Agent & Multi Agent Syst		pattern mining; multifaceted sequence patterns; computation-oriented pattern definition model; computational concerns; frame-relayed pattern model	DNA-BINDING SITES; INFORMATION-CONTENT; REGULATORY MOTIFS; PROTEIN; INTRONS; GENOME; GENES; RECOGNITION; SELECTION	For de novo pattern mining in genomic sequences, the main issues are constructing pattern definition model (PDM) and mining sequence patterns (MSP). The representations of PDMs and the discovery of patterns are functionally dependent; the performances thus depend on the adopted PDMs. The popular PDMs provide only descriptive patterns; they lack multifaceted considerations. Many of existing MSP methods are tied up with the exclusively devised PDMs, and the specialized and sophisticated models make the mined results hard to be reused. In this research, an integrative pattern mining system is proposed, which consists of a computation-oriented PDM (CO-PDM) and general-purpose MSP (GP-MSP) methods. The CO-PDM defines four computational concerns (CCs) as facets of MSP: expression (E), location (L), range (R) and weight (W), which are integrated into a frame-relayed pattern model (FRPM). The GP-MSP develops a frame-relayed search strategy to resolve the ELR-CCs firstly, with the aids of critical-parameter automating (CPA) procedure; and then the W-CC is determined by hybridizing particle swarm optimization (PSO) and artificial neural network (ANN). The proposed FRPM and GP-MSP had been implemented and applied to 22,448 human introns; from the results, all the well-known patterns were recovered and some new ones were also discovered. Furthermore, the effectiveness of identified patterns were verified by a two-layered k-nearest neighbor (k-NN) classifier; the average precision and recall are 0.88 and 0.92, respectively. By the case study, the integrative PDM-MSP system is believed to be effective and reliable; it is optimistic the proposed CO-PDM and GP-MSP are both widely applicable and reusable for mining sequence patterns in the eukaryotic protein-coding genes.	[Liou, Sing-Wu; Wang, Chia-Ming; Huang, Yin-Fu] Natl Yunlin Univ Sci & Technol, Yunlin, Taiwan; [Huang, Yin-Fu] Grad Sch Engn Sci & Technol, Yunlin, Taiwan; [Liou, Sing-Wu; Wang, Chia-Ming] Grad Sch Engn Sci & Technol, Yunlin, Taiwan	Huang, YF (reprint author), Natl Yunlin Univ Sci & Technol, Yunlin, Taiwan.	g9110808@yuntech.edu.tw; g9410805@yuntech.edu.tw; huangyf@yuntech.edu.tw					ALTSCHUL SF, 1994, NAT GENET, V6, P119, DOI 10.1038/ng0294-119; Arques DG, 1996, J THEOR BIOL, V182, P45, DOI 10.1006/jtbi.1996.0142; BERG OG, 1987, J MOL BIOL, V193, P723, DOI 10.1016/0022-2836(87)90354-8; Brazma A, 1998, J COMPUT BIOL, V5, P279, DOI 10.1089/cmb.1998.5.279; Che DS, 2005, BIOINFORMATICS, V21, P2909, DOI 10.1093/bioinformatics/bti425; Chen Xin, 2007, Comput Syst Bioinformatics Conf, V6, P249, DOI 10.1142/9781860948732_0027; Coolidge CJ, 1997, NUCLEIC ACIDS RES, V25, P888, DOI 10.1093/nar/25.4.888; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAY WHE, 1992, NUCLEIC ACIDS RES, V20, P1093, DOI 10.1093/nar/20.5.1093; Eberhart R. C., 1998, P 7 ANN C EV PROGR, P69, DOI DOI 10.1007/BFB0040753; Fedorov A, 2002, NUCLEIC ACIDS RES, V30, P1192, DOI 10.1093/nar/30.5.1192; FICKETT JW, 1992, NUCLEIC ACIDS RES, V20, P6441, DOI 10.1093/nar/20.24.6441; Fratkin E, 2006, BIOINFORMATICS, V22, pE150, DOI 10.1093/bioinformatics/btl243; Gopalan V, 2004, NUCLEIC ACIDS RES, V32, pD59, DOI 10.1093/nar/gkh051; GOUY M, 1982, NUCLEIC ACIDS RES, V10, P7055, DOI 10.1093/nar/10.22.7055; Hu JJ, 2005, NUCLEIC ACIDS RES, V33, P4899, DOI 10.1093/nar/gki791; Keich U, 2002, BIOINFORMATICS, V18, P1374, DOI 10.1093/bioinformatics/18.10.1374; KENNEDY K, 1995, IEEE INT C NEUR NETW, V4, P1942; Lim LP, 2001, P NATL ACAD SCI USA, V98, P11193, DOI 10.1073/pnas.201407298; Liu X, 2001, Pac Symp Biocomput, P127; MacIsaac KD, 2006, PLOS COMPUT BIOL, V2, P201, DOI 10.1371/journal.pcbi.0020036; Majewski J, 2002, GENOME RES, V12, P1827, DOI 10.1101/gr.606402; McCullough AJ, 1997, MOL CELL BIOL, V17, P4562; MERINO E, 1992, ORIGINS LIFE EVOL B, V21, P251, DOI 10.1007/BF01809860; Mitchell T. M., 1997, MACHINE LEARNING; Moore MJ, 2000, NAT STRUCT BIOL, V7, P14, DOI 10.1038/71207; Patel AA, 2003, NAT REV MOL CELL BIO, V4, P960, DOI 10.1038/nrm1259; PRIBNOW D, 1975, P NATL ACAD SCI USA, V72, P784, DOI 10.1073/pnas.72.3.784; Reddy CK, 2006, ALGORITHM MOL BIOL, V1, DOI 10.1186/1748-7188-1-23; Roth FP, 1998, NAT BIOTECHNOL, V16, P939, DOI 10.1038/nbt1098-939; Rumelhart D. E., 1986, LEARNING INTERNAL RE, P318; Runger G. C., 2006, APPL STAT PROBABILIT, V4th; SCHNEIDER TD, 1986, J MOL BIOL, V188, P415, DOI 10.1016/0022-2836(86)90165-8; SHARP PA, 1987, SCIENCE, V235, P766, DOI 10.1126/science.3544217; SHEPHERD JCW, 1981, P NATL ACAD SCI-BIOL, V78, P1596, DOI 10.1073/pnas.78.3.1596; Sinha S, 2006, BIOINFORMATICS, V22, pE454, DOI 10.1093/bioinformatics/btl227; Steiger DM, 1996, EUR J OPER RES, V93, P387, DOI 10.1016/0377-2217(96)00036-7; Stormo GD, 2000, BIOINFORMATICS, V16, P16, DOI 10.1093/bioinformatics/16.1.16; STORMO GD, 1982, NUCLEIC ACIDS RES, V10, P2971, DOI 10.1093/nar/10.9.2971; Tomita M, 1996, MOL BIOL EVOL, V13, P1219; Werbos P., 1974, THESIS HARVARD U CAM; Wu YH, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.061916; Yao ZZ, 2006, BIOINFORMATICS, V22, P445, DOI 10.1093/bioinformatics/btk008; YOON Y, 1994, DECISION SUPPORT SYS	44	5	5	2	3	GRAZ UNIV TECHNOLGOY, INST INFORMATION SYSTEMS COMPUTER MEDIA-IICM	GRAZ	INFFELDGASSE 16C, GRAZ, A-8010, AUSTRIA	0948-695X			J UNIVERS COMPUT SCI	J. Univers. Comput. Sci.		2009	15	4					742	764				23	Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	487NF	WOS:000269280700004		
S	Marchiori, E		Buntine, W; Grobelnik, M; Mladenic, D; ShaweTaylor, J		Marchiori, Elena			Graph-Based Discrete Differential Geometry for Critical Instance Filtering	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	Joint European Conference on Machine Learning (ECML)/European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)	SEP 07-11, 2009	Bled, SLOVENIA	Inst Jozef Stefan, Pascal2, Google, Microsoft Res, Yahoo Res, QUINTELLIGENCE, LABS hp, ACTIVE, Machine Learning, Data Min & Knowledge Discovery, Nokia			NEAREST-NEIGHBOR CLASSIFICATION; LEARNING ALGORITHMS; PROTOTYPE SELECTION; CLASSIFIERS; NETWORKS	Graph theory has been shown to provide a powerful tool for representing and tackling machine learning problems, such as clustering semi-supervised learning, and feature ranking. This paper proposes a graph-based discrete differential operator for detecting and eliminating competence-critical instances and class label noise from a training set in order to improve classification performance. Results of extensive experiments on artificial and real-life classification problems substantiate the effectiveness of the proposed approach.	Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands	Marchiori, E (reprint author), Radboud Univ Nijmegen, Dept Comp Sci, NL-6525 ED Nijmegen, Netherlands.						Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1593, DOI 10.1109/TKDE.2007.190665; Angiulli F, 2005, ICML 2005, P25; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Belkin M, 2002, ADV NEUR IN, V14, P585; Beygelzimer A., 2006, ICML 2006, P97; Boser B. E., 1992, COMPUTATIONAL LEARNI, P144; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; CAYTON L, 2007, NIPS, V20; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chapelle O., 2005, P 10 INT WORKSH ART, P57; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; He X., 2005, ADV NEURAL INFORM PR, V18; Luxburg U.V., 2007, STAT COMPUT, V17, P395, DOI DOI 10.1007/S11222-007-9033-Z; Marchiori E, 2008, J MACH LEARN RES, V9, P997; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4; Sebban M., 2002, J MACHINE LEARNING R, V3, P863; SEBBAN M, 2001, ICML, P505; SHIN H, 2007, NEURAL COMPUT, P816; Toussaint G.T., 2002, INTERFACE 2002, P83; Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson D.R., 1997, P 14 INT C MACH LEAR, P403; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhao Z., 2007, ICML, P1151; Zhou D, 2005, ICML, P1036; Zhou DY, 2005, LECT NOTES COMPUT SC, V3663, P361	36	1	1	0	16	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-04173-0	LECT NOTES ARTIF INT			2009	5782						63	78				16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BMF17	WOS:000272076400005		
S	Martin, JA; de Lope, J; Maravall, D		Mira, J; Ferrandez, JM; Alvarez, JR; DelaPaz, F; Toledo, FJ		Antonio Martin H, Jose; de Lope, Javier; Maravall, Dario			The kNN-TD Reinforcement Learning Algorithm	METHODS AND MODELS IN ARTIFICIAL AND NATURAL COMPUTATION, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	3rd International Work-Conference on the Interplay Between Natural and Artificial Computation	JUN 22-26, 2009	Santiago de Compostela, SPAIN					A reinforcement learning algorithm called kNN-TD is introduced. This algorithm has been developed using the classical formulation of temporal difference methods and a k-nearest neighbors scheme as its expectations memory. By means of this kind of memory the algorithm is able to generalize properly over continuous state spaces and also take benefits from collective action selection and learning processes. Furthermore, with the addition of probability traces, we obtain the kNN-TD(A) algorithm which exhibits a state of the art performance. Finally the proposed algorithm has been tested on a series of well known reinforcement learning problems and also at the Second Annual RL Competition with excellent results.	[Antonio Martin H, Jose] Univ Complutense Madrid, Dep Sistemas Informat & Computac, E-28040 Madrid, Spain	Martin, JA (reprint author), Univ Complutense Madrid, Dep Sistemas Informat & Computac, E-28040 Madrid, Spain.	jamartinh@fdi.ucm.es; javier.delope@upm.es; dmaravall@fi.upm.es	Martin H., Jose Antonio/A-2388-2009				Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BOSMAN S, 1996, THESIS U AMSTERDAM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Gordon Geoff, 1995, ICML, P261; Indyk P., 1998, STOC, P604; Martin JAH, 2007, LECT NOTES COMPUT SC, V4739, P138; Singh SP, 1996, MACH LEARN, V22, P123; Sutton R.S., 1998, REINFORCEMENT LEARNI; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698	11	3	3	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-02263-0	LECT NOTES COMPUT SC			2009	5601						305	314				10	Computer Science, Cybernetics; Computer Science, Theory & Methods	Computer Science	BKT63	WOS:000269203400032		
J	Montagnuolo, M; Messina, A				Montagnuolo, Maurizio; Messina, Alberto			Parallel neural networks for multimodal video genre classification	MULTIMEDIA TOOLS AND APPLICATIONS			English	Article						Video annotation; Genre recognition; Neural network; Feature extraction; Multimedia semantics	CATEGORIZATION; RECOGNITION; MODELS	Improvements in digital technology have made possible the production and distribution of huge quantities of digital multimedia data. Tools for high-level multimedia documentation are becoming indispensable to efficiently access and retrieve desired content from such data. In this context, automatic genre classification provides a simple and effective solution to describe multimedia contents in a structured and well understandable way. We propose in this article a methodology for classifying the genre of television programmes. Features are extracted from four informative sources, which include visual-perceptual information (colour, texture and motion), structural information (shot length, shot distribution, shot rhythm, shot clusters duration and saturation), cognitive information (face properties, such as number, positions and dimensions) and aural information (transcribed text, sound characteristics). These features are used for training a parallel neural network system able to distinguish between seven video genres: football, cartoons, music, weather forecast, newscast, talk show and commercials. Experiments conducted on more than 100 h of audiovisual material confirm the effectiveness of the proposed method, which reaches a classification accuracy rate of 95%.	[Montagnuolo, Maurizio] Univ Turin, Dept Comp Sci, I-10149 Turin, Italy; [Messina, Alberto] RAI Radiotelevis Italiana, Ctr Res & Technol Innovat, I-10135 Turin, Italy	Montagnuolo, M (reprint author), Univ Turin, Dept Comp Sci, Corso Svizzera 185, I-10149 Turin, Italy.	montagnuolo@di.unito.it; a.messina@rai.it					ALBIOL A, 2004, INT WORKSH IM AN MUL; Bellman R., 1961, ADAPTIVE CONTROL PRO; BLUM DW, 1992, Patent No. 5151788; BOGGS J, 2006, ART WATCHING FILMS T; BRUGNARA F, 2000, RIAO CONTENT BASED M; CALIC J, 2004, THESIS U LONDON; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; CHENG W, 2006, 8 INT C ADV CONC INT, P1210; Covell M, 2006, IEEE WORKSH MULT SIG, P461; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIMITROVA N, 2000, EUR C SIGN PROC TAMP; DIMITROVA N, 2002, P 9 INT C INF PROC M, P481; DINH PQ, 2002, ACCV2002; Dorado A, 2004, IEEE T CIRC SYST VID, V14, P622, DOI 10.1109/TCSVT.2004.826764; *EBU UER, 2007, TECHN REV EBU, V3322; FISCHER S, 1995, ACM MULTIMEDIA 1995, P295; GLASBERG R, 2005, 13 EUR SIGN PROC C E; GOH KS, 2004, 2004008 MERL; IANEVA TJ, 2003, INT C MULT EXP BALT, P449; Igel C., 2000, P 2 INT S NEUR COMP; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Liu Z, 1998, IEEE WORKSH MULT SIG, P27; Liu Z, 1997, IEEE 1 WORKSH MULT S, P343; LOIACONO A, 2005, TECHNICAL REV EBU, V303; MESSINA A, 2008, IEEE INT C MULT EXP; MESSINA A, 2008, INT WORKSH AMB MED D; Messina A., 2006, IEEE INT C SIGN IM T; Montagnuolo M., 2007, Journal of Digital Information Management, V5; Montagnuolo M, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P99; MONTAGNUOLO M, 2008, 2 INT WORKSH MULT DA; NOVAK AP, 1988, Patent No. 4750213; PARNAL S, 2003, TV ANYTIME NEW STAND; POLI JP, 2006, CIMCA 06, P31; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; ROACH M, 2001, INT S INT MULT, P146; ROACH MJ, 2002, THESIS U WALES SWANS; Roach MJ, 2001, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2001.941230; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; Sanchez J. M., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614); Satterwhite B, 2004, IEEE POTENTIALS, V23, P9, DOI 10.1109/MP.2004.1309790; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; TAKAGI S, 2003, INT C MULT EXP BALT, P461; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; TASKIRAN CM, 2003, 8 INT WORKSH VIS CON, P84; Taskiran C. M., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, DOI 10.1117/12.451098; Tekalp M., 1995, DIGITAL VIDEO PROCES; TOMASI C, 2005, ESTIMATING GAUSSIAN; Truong BT, 2000, INT C PATT RECOG, P230; Vakkalanka S, 2005, ICISIP 05, P187; Vapnik V., 1999, NATURE STAT LEARNING; Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595; VROOMEN J, 1993, EUROSPEECH 93 BERL S, P577; Wang J, 2006, J CHEM THEORY COMPUT, V2, P18, DOI 10.1021/ct050118b; Wickenberg-Bolin U, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-127; Xu L-Q, 2003, IEEE INT C MULT EXP, P485; Yuan X, 2006, IEEE IMAGE PROC, P2905, DOI 10.1109/ICIP.2006.313037; YUAN Y, 2002, IEEE 1 INT C MACH LE, V3, P1153; ZHIWEN Y, 2004, IEEE INT C INF TECHN, P658	62	17	17	5	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1380-7501			MULTIMED TOOLS APPL	Multimed. Tools Appl.	JAN	2009	41	1					125	159		10.1007/s11042-008-0222-3		35	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	387LJ	WOS:000261953400006		
B	Jo, T			IEEE	Jo, Taeho			Automatic Text Categorization using NTC	NDT: 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKED DIGITAL TECHNOLOGIES			English	Proceedings Paper	1st International Conference on Networked Digital Technologies (NDT 2009)	JUL 28-31, 2009	Ostrava, CZECH REPUBLIC	IEEE Commun Soc	VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci		SUPPORT VECTOR MACHINES; CLASSIFICATION	In this research, we propose NTC (Neural Text Categorizer) as the approach to text categorization. Traditional approaches to text categorization require encoding documents into numerical vectors which leads to the two main problems: huge dimensionality and sparse distribution in each numerical vector. In this research, documents are encoded into string vectors instead of numerical vectors, and a new neural network called NTC which receive a string vector as its input vector is used for text categorization. The goal of this research is to avoid the two main problems by encoding documents into alternative structured data to numerical vectors. We will validate the performance of NTC by comparing it with other machine learning algorithms on the standard test bed, Reuter 21578.	Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea	Jo, T (reprint author), Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea.	tjo018@inha.ac.kr					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristianini N., 2000, SUPPORT VECTOR MACHI, V1st; Estabrooks A, 2004, COMPUT INTELL, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Joachims T, 1998, P 10 EUR C MACH LEAR, P143; Kononenko I, 1989, P 4 EUR WORK SESS LE, P91; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Massand B, 1992, P 15 ACM INT C RES D, P59; McClelland J. L., 1986, PARALLEL DISTRIBUTED, VI; McClelland J. L., 1986, PARALLEL DISTRIBUTED, VII; Mitchell T. M., 1997, MACHINE LEARNING; Mladenic D, 1999, P INT C MACH LEARN, P256; Ruiz ME, 2002, INFORM RETRIEVAL, V5, P87, DOI 10.1023/A:1012782908347; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Wiener ED, 1995, THESIS U COLORADO; Yang Y, 1999, INFORMATION RETRIEVA, V1, P67	17	0	0	0	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4614-8				2009							26	31				6	Computer Science, Information Systems	Computer Science	BPQ76	WOS:000279656200006		
B	Kam-Art, R; Raicharoen, T; Khera, V			IEEE	Kam-Art, Rojana; Raicharoen, Thanapant; Khera, Varin			Face Recognition using Feature Extraction based on Descriptive Statistics of a Face Image	PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6			English	Proceedings Paper	International Conference on Machine Learning and Cybernetics	JUL 12-15, 2009	Baoding, PEOPLES R CHINA	Hebei Univ, IEEE Syst, Man & Cybernet Soc, Chongqing Univ, S China Univ Technol, Hong Kong Baptist Univ, Hebei Univ Sci & Technol			EIGENFACES	This paper proposes a new method of feature extraction for face recognition based on descriptive statistics of a face image. Our method works by first converting the face image with all the corresponding face components such as eyes, now, and mouth to a grayscale images. The features are then extracted from the grayscale image, based on a descriptive statistics of the image and its corresponding face components. The edges of a face image and its corresponding face components are detected by using the canny algorithm. In the recognition step, different classifiers such as Multi Layer Perceptron (MLP), Support Vector Machine (SVM), k-Nearest Neighbors (k-NN) and Pairwise Opposite Class-Nearest Neighbor (POC-NN) can be used for face recognition. We evaluated our method with more conventional Eigenface method bawd upon the AT&T and Yale face databases. The evaluation clearly confirm that for both databases our proposed method yields a higher recognition rate and requires less computational time than the Eigenface method.	[Kam-Art, Rojana; Raicharoen, Thanapant] Eartern Asia Univ, Fac Informat Technol, Thanyaburi, Pathumthani, Thailand	Kam-Art, R (reprint author), Eartern Asia Univ, Fac Informat Technol, Thanyaburi, Pathumthani, Thailand.	rojana@eau.ac.th; thanapant@eau.ac.th; varin.khera@nsn.com					Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GALTON F, 1888, NATURE          0621, P269; Hakin S., 1999, NEURAL NETWORKS COMP; Hastie T., 2001, SPRINGER SERIES STAT; Hlavac V., 2004, STAT PATTERN RECOGNI; KANADE T, 1973, FACE RECOGNITION PIC; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Moghaddam B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790407; OMIDVARNIA AH, EIGENFACE FACE RECOG; RAICHAROEN T, 2005, PATTERN RECOGN, V16, P1554; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Stonham T.J., 1984, ASPECTS FACE PROCESS, P426; Sung K.K., 1995, COMPUTER ANAL IMAGES, P432; Tolba A.S., 2006, INT J SIGNAL PROCESS, V2, P88; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VALENTIN D, 1994, PATTERN RECOGN, V27, P1209, DOI 10.1016/0031-3203(94)90006-X; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; YALE DATABASE; AT T DATABASE FACE	26	0	0	0	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4705-3				2009							193	197				5	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics	Automation & Control Systems; Computer Science	BQS31	WOS:000281720400036		
B	Mignani, AG; Cucci, C; Ciaccheri, L; Dall'Asta, C; Galaverna, G; Dossena, A; Marchelli, R		DiNatale, C; DAmico, A; Martinelli, E; Paolesse, R		Mignani, A. G.; Cucci, C.; Ciaccheri, L.; Dall'Asta, C.; Galaverna, G.; Dossena, A.; Marchelli, R.			FLUORESCENCE SPECTROSCOPY FOR THE DETECTION OF M1 AFLATOXIN IN MILK	PROCEEDINGS OF THE 13TH ITALIAN CONFERENCE ON SENSORS AND MICROSYSTEMS			English	Proceedings Paper	13th Italian Conference on Sensors and Microsystems	FEB 19-21, 2008	Rome, ITALY					Fluorescence spectroscopy carried out by means of optical fibers was used for the rapid screening of M1 aflatoxin in milk, enabling the detection of concentrations up to the legal limit, which is 50 ppt. A compact fluorometric device equipped with an LED source, a miniaturized spectrometer, and optical fibers for illumination/detection of the measuring micro-cell was tested for measuring threshold values of AFM1 in pre-treated milk samples. Multivariate processing of the spectral data made it possible to obtain a preliminary screening at the earlier stages of the industrial process, as well as to discard contaminated milk stocks before their inclusion in the production chain.	[Mignani, A. G.; Cucci, C.; Ciaccheri, L.] CNR, IFAC, I-50019 Sesto Fiorentino, FI, Italy	Mignani, AG (reprint author), CNR, IFAC, Via Madonna Piano 10, I-50019 Sesto Fiorentino, FI, Italy.		Dall'Asta, Chiara/C-3173-2008	Dall'Asta, Chiara/0000-0003-0716-8394			Bertran E, 2001, ANAL CHIM ACTA, V431, P303, DOI 10.1016/S0003-2670(00)01328-3; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucci C, 2007, SENSOR ACTUAT B-CHEM, V126, P467, DOI 10.1016/j.snb.2007.03.036; *FAO, 2003, WORLDW REG MYC FOOD, V81; Magan N, 2004, MYCOTOXINS FOOD DETE; Martens H., 2001, MULTIVARIATE ANAL QU; WEIDENBOMER M, 2001, ENCY FOOD MYCOTOXINS	7	0	0	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			978-981-283-597-0				2009							366	371				6	Engineering, Electrical & Electronic; Nanoscience & Nanotechnology; Remote Sensing	Engineering; Science & Technology - Other Topics; Remote Sensing	BIY69	WOS:000263783800060		
B	Pan, F; Wang, JD; Lin, XH			IEEE	Pan, Feng; Wang, Jiandong; Lin, Xiaohui			Feature Extraction Algorithm Based on K Nearest Neighbor Local Margin	PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2			English	Proceedings Paper	Chinese Conference on Pattern Recognition/1st CJK Joint Workshop on Pattern Recognition	NOV 04-06, 2009	Nanjing, PEOPLES R CHINA			feature extraction; margin; linear discriminant analysis	FACE RECOGNITION	Feature extraction is the transformation of high-dimensional data into a meaningful representation of reduced dimensionality. The representation extracted are often beneficial to mitigate the computational complexity and improve the accuracy of a particular classifier. In this paper we introduce a novel feature extraction algorithm called K nearest neighbor local margin maximization and apply it to measure the quality of the reduced features in the context of supervised classification problems. Using the concept of the hypothesis margin, we aim to find a discriminant subspace in which each projected point is well separated from the affine hull of its K local nearest neighbors. The experimental results on three high dimensional data sets demonstrate the effectiveness of our algorithm.	[Pan, Feng; Wang, Jiandong] Nanjing Univ Aeronaut & Astronaut, Coll Informat Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China	Pan, F (reprint author), Nanjing Univ Aeronaut & Astronaut, Coll Informat Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.	stridence@gmail.com					Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; CEVIKALP H, P 25 INT C MACH LEAR; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMMER K, 2003, ADV NEURAL INFORM PR, P462; Fukunaga K., 1990, INTRO STAT PATTERN R; GILADBACHRACH R, 2004, P 21 INT C MACH LEAR, V69, P43; Golub G. H., 1996, MATRIX COMPUTATIONS, VThird; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kocsor A, 2004, LECT NOTES COMPUT SC, V3201, P227; Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852; Sun Y., 2006, P 23 ACM INT C MACH, V148, P913; Vincent P, 2001, ADV NEURAL INFORM PR, P985; WEINBERGER K, ADV NEURAL INFORM PR, P1473; Xing E, 2003, ADV NEURAL INFORM PR, P505; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X	18	0	0	0	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-4199-0				2009							20	24				5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BOY30	WOS:000278039800005		
S	Leite, P; Teixeira, JM; Farias, T; Teichrieb, V; Kelner, J			IEEE	Leite, Pedro; Teixeira, Joao M.; Farias, Thiago; Teichrieb, Veronica; Kelner, Judith			Massively Parallel Nearest Neighbor Queries for Dynamic Point Clouds on the GPU	PROCEEDINGS OF THE 21ST INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH PERFORMANCE COMPUTING	International Symposium on Computer Architecture and High Performance Computing		English	Proceedings Paper	21st International Symposium on Computer Architecture and High Performance Computing	OCT 28-31, 2009	Sao Paulo, BRAZIL	Brazilian Comp Soc, IEEE Comp Soc, Tech Comm Comp Architecture, Scalable Comp, IFIP, Brazilian Govt Agcy, CAPES, FAPESP		nearest neighbor query; massive parallel programming; KNN; ANN	ALGORITHM	We introduce a parallel algorithm to solve approximate and exact nearest neighbor queries on the GPU, exploiting its massively parallel processing power. Both data structure construction and nearest neighbor queries are performed on the GPU, avoiding memory copies from system memory to device memory. This algorithm achieves real-time performance, enabling its usage in dynamic scenarios, by minimizing the sorting comparisons needed for a large K value. The underlying data structure for spatial subdivision handles 3D points and is based on grid spatial hashing. Users can specify the grid size interactively. Comparisons were done with other nearest neighbor algorithms implemented on both CPU and GPU. Our approach clearly surpasses CPU implementations regarding processing time, while it presents a competitive solution to GPU ones. Real-time results were obtained with ANN searches (K = 10) for data sets up to 163K points and the potential of our algorithm is demonstrated through a point-based rendering application.	[Leite, Pedro; Teixeira, Joao M.; Farias, Thiago; Teichrieb, Veronica; Kelner, Judith] Univ Fed Pernambuco, Ctr Comp Sci, Virtual Real & Multimedia Res Grp, Recife, PE, Brazil	Leite, P (reprint author), Univ Fed Pernambuco, Ctr Comp Sci, Virtual Real & Multimedia Res Grp, Recife, PE, Brazil.	pjsl@cin.ufpe.br; jmxnt@cin.ufpe.br; tsmcf@cin.ufpe.br; vt@cin.ufpe.br; jk@cin.ufpe.br					Adams B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276437, 10.1145/1239451.1239499]; Alexa M, 2001, IEEE VISUAL, P21; Alexa M., 2004, SIGGRAPH 04 ACM SIGG, P7; Anderson JA, 2008, J COMPUT PHYS, V227, P5342, DOI 10.1016/j.jcp.2008.01.047; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Botsch M., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), DOI 10.1109/PBG.2005.194059; CLARENZ U, 2004, S POINT BAS GRAPH 20; Connor M., 2008, P VOL POINT BAS GRAP, P25; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURTIS S, 2008, 13D 08, P61; Harris M., 2009, OPTIMIZING PARALLEL; JENSEN H. W., 2001, REALISTIC IMAGE SYNT; Knuth D. E., 1998, ART COMPUTER PROGRAM, V3; Lacoste J, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P87; Levin D., 2003, GEOMETRIC MODELING S, P37; Levoy M., 1985, 85022 U N CAR CHAP H; LIN KI, 2001, DASFAA 01, P174; Losasso F., 2004, SIGGRAPH 04, P457, DOI DOI 10.1145/1186562.1015745; Mitra NJ, 2003, S COMP GEOM, P322; NVIDIA, 2009, COMP UN DEV ARCH PRO; Pantazopoulos I, 2002, J INTELL ROBOT SYST, V35, P123, DOI 10.1023/A:1021175220384; Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771; Pharr M., 2004, PHYS BASED RENDERING; SAFAR M, 2005, MOB INF SYST, V1; Samet H., 2005, M KAUFMANN SERIES CO; Sankaranarayanan J, 2007, COMPUT GRAPH-UK, V31, P157, DOI 10.1016/j.cag.2006.11.011; SENUPTA S, 2007, GH 07, P97; Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47; Zhou K., 2008, SIGGRAPH ASIA 08, P1; GA DYNAMIC SAMPLING	30	6	6	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-6533		978-0-7695-3857-0	INT SYM COMP ARCHIT			2009							19	25		10.1109/SBAC-PAD.2009.18		7	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BNK61	WOS:000274804600003		
B	Chaudhari, BM; Barhate, AA; Bhole, AA			Allied Publishers PVT LTD	Chaudhari, Bhupendra M.; Barhate, Atul A.; Bhole, Anita A.			Signature Recognition using Fuzzy Min-Max Neural Network	PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1			English	Proceedings Paper	International Conference on Control, Automation, Communication and Energy Conservation	JUN 04-06, 2009	Perundurai, INDIA	Kongu Vellar Inst Tech Trust, IEEE, Inst Elect Telecomm Engn, Council Sci Indust Res, Freescale Semiconductor Inc, Trident Techlabs Pvt ltd, Mighty Electr Equipment Corp	Kongu Engn Coll	Signature verification; fuzzy min-max neural network; classification; moment invariant; neural network for category learning	PATTERN-CLASSIFICATION	The signature recognition system has been inspired from the human capability to recognize any pattern, which is a very difficult task for normal computer system having computing power of more then billions instructions per second. In this system the input is given in the form of a digital image by using writing pad, optical scanner, or Digital camera. This input image is processed to extract the information by using data acquisition and HU's seven moment invariant [21] to the order of three. Then the fuzzy min-max algorithm can applied to classify the signature pattern and this fuzzy min-max algorithm [1] is totally fit to the neural network framework. The neural network middle layer is work as fuzzified neuron and because of this the output can be correctly classified Use of fuzzy membership function is increase the accuracy of the classification of signature pattern because the decision boundaries are not crisp rather it is fuzzy. The neural network is designed for this work is for the category learning which can increase the speed of recognition because in this fuzzy min-max neural network [1] the supervised learning algorithm is used also it can learn nonlinear class boundaries in a single pass through the data and provides the ability to incorporate new and refute existing classes without retraining. The advantage of our system is its accuracy in recognizing signature is nearly 53% for single signature pattern per class and if the signature pattern per class are increased then the accuracy is increased up to 92% because patterns per class with slighter changes in it can increase the recognition efficiency naturally and there is no increase in training time because the neural network used is for category learning in which the dataset & index of the class is used for training.	[Chaudhari, Bhupendra M.] Dept Godavari COE, E&Tc Engn, Jalgaon, India	Chaudhari, BM (reprint author), Dept Godavari COE, E&Tc Engn, Jalgaon, India.	Bhupendra_scorpion29@rediffmail.com; atbarhate@yahoo.co.in; bholeanita@yahoo.co.in					BELLMAN R, 1964, RM4307PR RAND; BELLMAN R, 1966, J MATH ANAL APPL, V13, P1, DOI 10.1016/0022-247X(66)90071-0; BEZDEK, 1991, PATTERNS RECOGNITION; BEZDEK J, 1996, FUZZY SETS SYSTEMS, V18, P237; BEZDEK J, 1991, IEEE C NEUR NET OC E; CARPENTER G, NEURAL NETWORKS, V4, P565; Carpenter G, 1991, P INT JOINT C NEUR N, V2, P411; COTTER N, 1991, IEEE T NEURAL NETWOR, V1, P290; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747; HU M, 1962, IRE T INFORM THEOR, V8, P179; NANDEDKAR AV, 2004, P 17 INT C PATT REC, V4, P553, DOI 52228650,12,1; SIMPSON P, P 1991 INT JOINT C N; SIMPSON P, 2002, IEEE T FUZZY S UNPUB; Simpson P. K., 1990, ARTIFICIAL NEURAL SY; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; SIMPSON PK, 1991, HEURISTICS J KNOWLED, V4, P1; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; YAGER RR, 1979, INT J MAN MACH STUD, V11, P189, DOI 10.1016/S0020-7373(79)80016-4; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	21	0	0	0	1	ALLIED PUBLISHERS LTD	NEW DELHI	13-14 ASAF ALI ROAD, NEW DELHI 110002, INDIA			978-81-8424-439-7				2009							242	248				7	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BRI36	WOS:000282769800044		
S	Garcia-Borroto, M; Villuendas-Rey, Y; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		BayroCorrochano, E; Eklundh, JO		Garcia-Borroto, Milton; Villuendas-Rey, Yenny; Ariel Carrasco-Ochoa, Jesus; Fco. Martinez-Trinidad, Jose			Finding Small Consistent Subset for the Nearest Neighbor Classifier Based on Support Graphs	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	14th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2009	Guadalajara, MEXICO	Mexican Assoc Comp Vis, Neurocomp & Robot, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Chilean Assoc Pattern Recognit, Brizilian Comp Soc Special Interest Grp, Spanish Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, CINVESTAV, IEEE GRSS, CoecytJal, INTEL Educ, Gobierno Municipal, Direcc Turismo Guadalajara, Oficina Vistantes & Convenciones Guadalajara		nearest neighbor; condensing; prototype selection; minimal consistent subset	RULE	Finding a minimal subset of objects that correctly classify the training set for the nearest neighbors classifier has been an active research area in Pattern Recognition and Machine Learning communities for decades. Although finding the Minimal Consistent Subset is not feasible in many real applications, several authors have proposed methods to find small consistent subsets. In this paper, we introduce a novel algorithm for this task, based on support graphs. Experiments over a wide range of repository databases show that our algorithm finds consistent subsets with lower cardinality than traditional methods.	[Garcia-Borroto, Milton] UNICA, Bioplantas Ctr, C De Avila, Cuba	Garcia-Borroto, M (reprint author), UNICA, Bioplantas Ctr, Carretera Moron Km 9 1-2, C De Avila, Cuba.	mil@bioplantas.cu; yennyv@bioplantas.cu; ariel@inaoep.mx; fmartine@inaoep.mx					ATHITSOS V, 2006, THESIS BOSTON U, P156; CHOU CH, 2006, 18 INT C PATT REC IC; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Garcia-Borroto M, 2005, LECT NOTES COMPUT SC, V3773, P450; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Kuncheva L. I., 2004, COMBINING PATTERN CL; MERZ CJ, 1998, UC1 REPOSITORY MACHI; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; WILFONG G, 1991, 7 ANN ACM S COMP GEO, P224; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	13	3	3	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-10267-7	LECT NOTES COMPUT SC			2009	5856						465	472				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPQ26	WOS:000279629500054		
S	Garcia-Borroto, M; Villuendas-Rey, Y; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		BayroCorrochano, E; Eklundh, JO		Garcia-Borroto, Milton; Villuendas-Rey, Yenny; Ariel Carrasco-Ochoa, Jesus; Fco. Martinez-Trinidad, Jose			Using Maximum Similarity Graphs to Edit Nearest Neighbor Classifiers	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	14th Iberoamerican Congress on Pattern Recognition	NOV 15-18, 2009	Guadalajara, MEXICO	Mexican Assoc Comp Vis, Neurocomp & Robot, Int Assoc Pattern Recognit, Cuban Assoc Pattern Recognit, Chilean Assoc Pattern Recognit, Brizilian Comp Soc Special Interest Grp, Spanish Assoc Pattern Recognit, Portuguese Assoc Pattern Recognit, CINVESTAV, IEEE GRSS, CoecytJal, INTEL Educ, Gobierno Municipal, Direcc Turismo Guadalajara, Oficina Vistantes & Convenciones Guadalajara		nearest neighbor; error-based editing; prototype selection	PATTERN-CLASSIFICATION; RULES	The Nearest Neighbor classifier is a simple but powerful non-parametric technique for supervised classification. However, it is very sensitive to noise and outliers, which could decrease the classifier accuracy. To overcome this problem, we propose two new editing methods based on maximum similarity graphs. Numerical experiments in several databases show the high quality performance of our methods according to classifier accuracy.	[Garcia-Borroto, Milton] UNICA, Bioplantas Ctr, C De Avila, Cuba	Garcia-Borroto, M (reprint author), UNICA, Bioplantas Ctr, Carretera Moron Km 9 1-2, C De Avila, Cuba.	mil@bioplantas.cu; yennyv@bioplantas.cu; ariel@inaoep.mx; fmartine@inaoep.mx	Garcia-Borroto, Milton/D-8301-2015	Garcia-Borroto, Milton/0000-0002-3154-177X			Caballero Y., 2007, INT J COMPUTATIONAL, V3, P219; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Devijver P. A., 1980, 5TH P INT C PATT REC, P72; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Hattori K, 2000, PATTERN RECOGN, V33, P521, DOI 10.1016/S0031-3203(99)00068-0; KOPLOWITZ J, 1981, PATTERN RECOGN, V13, P251, DOI 10.1016/0031-3203(81)90102-3; Kuncheva L. I., 2004, COMBINING PATTERN CL; Merz C, 1998, UCI REPOSITORY MACHI; Pons-Porrata A, 2007, INFORM PROCESS MANAG, V43, P752, DOI 10.1016/j.ipm.2006.06.001; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Toussaint G. T., 2002, 34 S COMP STAT INTER, P1; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	14	3	3	0	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-10267-7	LECT NOTES COMPUT SC			2009	5856						489	496				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BPQ26	WOS:000279629500057		
B	Kaya, GT; Ersoy, OK; Kamasak, ME		Kurnaz, S; Ince, F; Onbasioglu, S; Basturk, S		Kaya, Guelsen Taskin; Ersoy, Okan K.; Kamasak, Mustafa E.			Support Vector Selection and Adaptation and Its Application in Remote Sensing	RAST 2009: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES			English	Proceedings Paper	4th International Conference on Recent Advances in Space Technologies	JUN 11-13, 2009	Istanbul, TURKEY	turkish Air Force Acad, Istanbul Tech Univ, Bogazici Univ, Marmara Univ, Bahcesehir Univ, Istanbul Commerce Univ, Halic Univ, Yeditepe Univ, IEEE, AIAA		Support Vector Machines; Classification of Remote Sensing Data; Support Vector Machines; Support Vector Selection and Adaptation	CLASSIFICATION	Classification of nonlinearly separable data by nonlinear support vector machines is often a difficult task, especially due to the necessity of a choosing a convenient kernel type. Moreover, in order to get high classification accuracy with the nonlinear SVM, kernel parameters should be determined by using a cross validation algorithm before classification. However, this process is time consuming. In this study, we propose a new classification method that we name Support Vector Selection and Adaptation (SVSA). SVSA does not require any kernel selection and it is applicable to both linearly and nonlinearly separable data. The results show that the SVSA has promising performance that is competitive with the traditional linear and nonlinear SVM methods.	[Kaya, Guelsen Taskin; Kamasak, Mustafa E.] Istanbul Tech Univ, TR-80626 Istanbul, Turkey	Kaya, GT (reprint author), Istanbul Tech Univ, TR-80626 Istanbul, Turkey.	gtaskink@purdue.edu; ersoy@purdue.edu; kamasak@itu.edu.tr					BENEDIKTSSON JA, 1990, IEEE T GEOSCI REMOTE, V28, P540, DOI 10.1109/TGRS.1990.572944; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Courant R., 1953, METHODS MATH PHYS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kasapoglu NG, 2007, IEEE T GEOSCI REMOTE, V45, P3880, DOI 10.1109/TGRS.2007.900699; Kaya S, 2005, INT J REMOTE SENS, V26, P2731, DOI 10.1080/01431160500099428; Kohonen T., 1992, P INT JOINT C NEUR N, VI, P725, DOI 10.1109/IJCNN.1992.287101; Kohonen T., 1986, TKKFA601 HELS U TECH; Melgani F., 2004, IEEE T GEOSCIENCE RE, V42; SHMILOVICI GA, 2005, DATA MINING KNOWLEDG; [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B, A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5	11	1	1	0	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-3626-2				2009							408	412				5	Engineering, Aerospace	Engineering	BLZ72	WOS:000271613000080		
B	Ma, LT; Wang, SY; Wang, JZ; Fu, BW; Kong, J		Tang, Y; Lawry, J		Ma, Lintian; Wang, Shuyan; Wang, Jianzhong; Fu, Baowei; Kong, Jun			Relative transformation with CamNN applied to isometric embedding	SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, PROCEEDINGS			English	Proceedings Paper	2nd International Symposium on Computational Intelligence and Design	DEC 12-14, 2009	Changsha, PEOPLES R CHINA	IEEE, Hong Kong Computat Intelligence Chapter, Bristol Univ, Zhejiang Univ, Tsinghua Univ		manifold learning; isomap; relative transformation; neighborhood graph; locally linear embedding; cam weighted distance	NONLINEAR DIMENSIONALITY REDUCTION; CLASSIFICATION	Neighborhood selection is one of the most important link in low-dimensional representations of high-dimensional data sets. Also, a good distance measure among the data points is where the shoe pinches. In this paper, we use the cam weighted distance to find a more flexible neighborhood of a data point in a newly-created space of r-isomap algorithm. It is a major advantage of r-isomap to optimize the process of intrinsic structure of the local information in a data set. Short-circuit edges are reduced in a certain extent because of the relative transformation space which is constructed in r-isomap. Furthermore, we can get a well performance on both orientation and scale adaptive side, because we utilize the cam weighted distance to search the neighborhood of a data point. It has been proved that this distance measure is more efficient than the Euclidean distance. Experiments demonstrated that the proposed method can give better results on dimension reduction than r-isomap, Weighted Locally Linear Embedding (WLLE) and some other approaches on the data sets which have obvious classifications. Especially robust to data sets with noise.	[Ma, Lintian; Wang, Shuyan; Wang, Jianzhong; Fu, Baowei; Kong, Jun] NE Normal Univ, Dept Comp Applicat & Technol, Jilin, Peoples R China	Ma, LT (reprint author), NE Normal Univ, Dept Comp Applicat & Technol, Jilin, Peoples R China.	Malt442@nenu.edu.com					ASANO T, 2007, LINEAR SPACE ALGORIT; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2002, LAPLACIAN EIGENMAPS, DOI 10.1.1.19.9400; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONOHO DL, HESSIAN EIGENMAPS NE; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314; GE SS, MACH VISION IN PRESS; Kang P, 2008, PATTERN RECOGN, V41, P3507, DOI 10.1016/j.patcog.2008.04.009; Kokiopoulou E, 2009, PATTERN RECOGN, V42, P2392, DOI 10.1016/j.patcog.2009.04.005; LEWISBECK MS, 2004, MULTIDIMENSIONAL SCA; Pan YZ, 2009, PATTERN RECOGN, V42, P798, DOI 10.1016/j.patcog.2008.08.024; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Samko O, 2006, PATTERN RECOGN LETT, V27, P968, DOI 10.1016/j.patrec.2005.11.017; Saul L K, 2003, J MACHINE LEARNING R, P119, DOI DOI 10.1162/153244304322972667; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tenenbaum Joshua B., 2000, SCIENCE, V290; WEN GH, 2006, P 2006 IEEE INT C SY, P3491; WENA GH, 2009, PATTERN RECOGN, V30, P203; ZHANG ZY, 2002, ARXIVCS0212008V1CS1G; Zhou CY, 2006, PATTERN RECOGN, V39, P635, DOI 10.1016/j.patocog.2005.09.004	20	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3865-5				2009							6	10		10.1109/ISCID.2009.9		5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BOC99	WOS:000276212800002		
B	Zhu, QY; Cao, SQ			IEEE COMPUTER SOC	Zhu, Quanyin; Cao, Suqun			A Novel Classifier-independent Feature Selection Algorithm for Imbalanced Datasets	SNPD 2009: 10TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCES, NETWORKING AND PARALLEL DISTRIBUTED COMPUTING, PROCEEDINGS			English	Proceedings Paper	3rd International Workshop on e-Activity (IWEA2009)/10th ACIS International Conference on Software Engineering Artificial Intelligence, Networking and Parallel/Distributed Computing	MAY 27-29, 2009	Daegu, SOUTH KOREA	IEEE Comp Soc, ACIS	Catholic Univ	imbalanced datasets; feature selection; posterior probability		A novel classifier-independent feature selection algorithm based on the posterior probability is proposed for imbalanced datasets. First, an imbalanced factor is introduced and computed by Parzen-window estimation. The middle point of Tomek links is chosen as the initial point. Accordingly, this algorithm is iterated to find out the boundary points which have the equality of posterior probability. Through the project computation on the normal vectors of these points, the weight of each feature can be obtained, which actually indicates the importance degree of each feature. The experimental results on 3 real-word datasets demonstrate that this proposed algorithm can not only reduce the computational cost but also overcome the shortcoming that lite majority class may be defected well but the minority class may be ignored in the conventional feature selection algorithm.	[Zhu, Quanyin] Huaiyin Inst Technol, Dept Comp Engn, Huaian, Peoples R China	Zhu, QY (reprint author), Huaiyin Inst Technol, Dept Comp Engn, Huaian, Peoples R China.	zqy@hyit.edu.cn; caosuqun@126.com					Abe N, 2006, PATTERN RECOGN, V39, P737, DOI 10.1016/j.patcog.2005.11.007; Barandela R, 2003, PATTERN RECOGN, V36, P849, DOI 10.1016/S0031-3203(02)00257-1; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Liu Tian-Yu, 2008, International Journal of Computational Biology and Drug Design, V1, P334; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769; Wang ST, 2005, SOFT COMPUT, V9, P732, DOI [10.1007/s00500-004-0406-3, 10.1007/s00500-004-406-3]	7	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			978-0-7695-3642-2				2009							77	82		10.1109/SNPD.2009.47		6	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Computer Science; Engineering	BNN08	WOS:000275031800014		
B	Wang, XM; Sykora, MD; Archer, R; Parish, D; Bez, HE			IEEE	Wang, Xiaoming; Sykora, Martin D.; Archer, Robert; Parish, David; Bez, Helmut E.			Case Based Reasoning Approach for Transaction Outcomes Prediction on Currency Markets	SOFA 2009: 3RD INTERNATIONAL WORKSHOP ON SOFT COMPUTING APPLICATIONS, PROCEEDINGS			English	Proceedings Paper	3rd International Workshop on Soft Computing Applications	JUL 29-AUG 01, 2009	Szeged, HUNGARY	IEEE Computat Intelligence soc, IEEE Hungary Sect, EUROFUSE, Hungarian Fuzzy Assoc, BMT Resources, Grupul Scolar Transporturi Auto, Henri Coanda Arad			CLASSIFICATION; STRATEGIES	This paper presents a case based reasoning approach for making profit in the foreign exchange (forex) market with controlled risk using k nearest neighbour (kNN) and improving on the results with neural networks (NNs) and a combination of both. Although many professionals have proven that exchange rates can be forecast using neural networks for example, poor trading strategies and unpredictable market fluctuation can inevitably still result in substantial loss. As a result, the method proposed in this paper will focus on predicting the outcome of potential trades with fixed stop loss (ST) and take profit (TP) positions, in terms of a win or loss. With the help of the Monte Carlo method, randomly generated trades together with different traditional technical indicators are fed into the models, resulting in a win or lose output. This is clearly a case based reasoning approach, in terms of searching similar past trade setups for selecting successful trades. There are several advantages over classical forecasting associated with such an approach, and the technique presented in this paper brings a novel perspective to problem of exchange trades predictability. The strategies implemented have not been empirically investigated with such wide a range of time granularities as is done in this paper, in any to the authors known academic literature. The profitability of this approach is back-tested at the end of this paper and highly encouraging results are reported.	[Wang, Xiaoming; Sykora, Martin D.; Archer, Robert; Parish, David; Bez, Helmut E.] Univ Loughborough, Res Sch Informat, Dept Comp Sci, Loughborough LE11 3TU, Leics, England	Wang, XM (reprint author), Univ Loughborough, Res Sch Informat, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.	elxw@lboro.ac.uk; m.d.sykora@lboro.ac.uk; cora3@lboro.ac.uk; d.j.parish@lboro.ac.uk; h.e.bez@lboro.ac.uk					Azoff E.M., 1994, NEURAL NETWORK TIME; Bachelier Louis, 1900, ANN SCI ECOLE NORM S, V3, P21; BROCK W, 1992, J FINANC, V47, P1731, DOI 10.2307/2328994; BURRELL J, 2007, COMPLETE GUIDE CURRE; CAGINALP G, 1998, APPL MATH FINANCE, V5, P181; Chan LKC, 1996, J FINANC, V51, P1681, DOI 10.2307/2329534; Chatfield C, 1996, ANAL TIME SERIES INT; COVEL MW, 2007, COMPLETE TURTLETRADE; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DeLurgio S. A., 1998, FORECASTING PRINCIPL; FAMA E, 1965, FINANCIAL ANAL J, V51; Foucault T., 1999, J FINANCIAL MARKETS, V2, P99, DOI 10.1016/S1386-4181(98)00012-3; Frank E., 2005, DATA MINING PRACTICA; Garliauskas A., 1999, IEEE INT C SYST MAN, V2, P638, DOI 10.1109/ICSMC.1999.825335; GEAPA B, 2003, P 2 BRAZ WORKSH BIOI; HELLSTRM T, 1998, PREDICTING STOCK MAR; HELLSTRM T, 1998, THESIS UME U UME SWE; HSIEH DA, 1991, J FINANC, V46, P1839, DOI 10.2307/2328575; Kamruzzaman J, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P793; Kamruzzaman J., 2003, P 3 IEEE INT C DAT M, P557; Leung MT, 2000, INT J FORECASTING, V16, P173, DOI 10.1016/S0169-2070(99)00048-5; LIVERMORE J, 2006, TRADE STOCKS; Lo A, 2004, J PORTFOLIO MANAGE, V30, P15, DOI 10.3905/jpm.2004.442611; LO A, 1989, STOCK MARKET PRICES; Lo AW, 2000, J FINANC, V55, P1705, DOI 10.1111/0022-1082.00265; Malkiel B., 1973, RANDOM WALK DOWN WAL; McNelis P. D., 2004, NEURAL NETWORKS FINA; Murphy J., 1999, TECHNICAL ANAL FINAN; MURPHY J, 1996, VISUAL INVESTOR SPOT; Osler CL, 2005, J INT MONEY FINANC, V24, P219, DOI 10.1016/j.jimonfin.2004.12.002; Pan M, 2004, J EMPIR FINANC, V11, P185, DOI 10.1016/j.jempfin.2003.02.001; Peters E., 1991, CHAOS ORDER CAPITAL; Peters E. E., 1994, FRACTAL MARKET ANAL; Refenes A.-P., 1995, NEURAL NETWORKS CAPI; Rubinstein M, 2001, FINANC ANAL J, V57, P15, DOI 10.2469/faj.v57.n3.2447; SAMUELSON P, 1965, IND MANAGEMENT REV, V6, P4149; SAMUELSON P.A., 1955, BROWNIAN MOTION STOC; SCHWAGER JD, 2006, MARKET WIZARDS INTER; Schwager J.D, 2008, NEW MARKET WIZARDS C; Schwager JS, 2008, STOCK MARKET WIZARDS; Shen S, 2001, APPL MATH COMPUT, V119, P317, DOI 10.1016/S0096-3003(99)00229-5; Sullivan R, 1999, J FINANC, V54, P1647, DOI 10.1111/0022-1082.00163; SYKORA MD, 2007, IWAPR 2007 C P; Taylor J. G., 2002, NEURAL NETWORKS FINA; WILLIAMS GP, 1997, CHAOS THEORTY TAMED, V1; Yao JT, 2000, NEUROCOMPUTING, V34, P79, DOI 10.1016/S0925-2312(00)00300-3; ZEMKE S, 2003, THESIS ROYAL I TECHN	47	0	0	0	38	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5054-1				2009							91	96				6	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Computer Science; Engineering	BNO96	WOS:000275159600017		
J	Gigerenzer, G; Brighton, H				Gigerenzer, Gerd; Brighton, Henry			Homo Heuristicus: Why Biased Minds Make Better Inferences	TOPICS IN COGNITIVE SCIENCE			English	Article						Heuristics; Decision-making; Inferences; Rationality; Uncertainity; Induction	REASON DECISION-MAKING; TAKE-THE-BEST; ECOLOGICAL RATIONALITY; BOUNDED RATIONALITY; SENSORIMOTOR SKILLS; EMPIRICAL TESTS; NEURAL-NETWORKS; LINEAR-MODELS; HOT HAND; RECOGNITION	Heuristics are efficient cognitive processes that ignore information. In contrast to the widely held view that less processing reduces accuracy, the study of heuristics shows that less information, computation, and time can in fact improve accuracy. We review the major progress made so far: (a) the discovery of less-is-more effects; (b) the study of the ecological rationality of heuristics, which examines in which environments a given strategy succeeds or fails, and why; (c) an advancement from vague labels to computational models of heuristics; (d) the development of a systematic theory of heuristics that identifies their building blocks and the evolved capacities they exploit, and views the cognitive system as relying on an "adaptive toolbox;'' and (e) the development of an empirical methodology that accounts for individual differences, conducts competitive tests, and has provided evidence for people's adaptive use of heuristics. Homo heuristicus has a biased mind and ignores part of the available information, yet a biased mind can handle uncertainty more efficiently and robustly than an unbiased mind relying on more resource-intensive and general-purpose processing strategies.	[Gigerenzer, Gerd; Brighton, Henry] Max Planck Inst Human Dev, D-14195 Berlin, Germany	Gigerenzer, G (reprint author), Max Planck Inst Human Dev, Lentzeal Lee 94, D-14195 Berlin, Germany.	gigerenzer@mpib-berlin.mpg.de	Brighton, Henry/A-3504-2011; Gigerenzer, Gerd/A-6250-2012				Alpaydin E., 2004, INTRO MACHINE LEARNI; ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409; Axelrod R., 1984, EVOLUTION COOPERATIO; Ayton P, 2004, MEM COGNITION, V32, P1369, DOI 10.3758/BF03206327; Barbey AK, 2007, BEHAV BRAIN SCI, V30, P241, DOI 10.1017/S0140525X07001653; Beilock SL, 2004, PSYCHON B REV, V11, P373, DOI 10.3758/BF03196585; Beilock SL, 2002, J EXP PSYCHOL-APPL, V8, P6, DOI 10.1037/1076-898X.8.1.6; Bergert FB, 2007, J EXP PSYCHOL LEARN, V33, P107, DOI 10.1037/0278-7393.33.1.107; BIRMBAUM MH, 2008, PSYCHOL REV, V115, P253; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; BOOKSTABER R, 1985, J THEOR BIOL, V116, P161, DOI 10.1016/S0022-5193(85)80262-9; Boyd R., 2005, ORIGIN EVOLUTION CUL; Brandstatter E, 2008, PSYCHOL REV, V115, P281, DOI 10.1037/0033-295X.115.1.281; Brandstatter E, 2006, PSYCHOL REV, V113, P409, DOI 10.1037/0033-295X.113.2.409; Breiman L., 1994, CLASSIFICATION REGRE; Brighton H, ECOLOGICAL IN PRESS; Brighton H., 2006, AAAI SPRING S COGN S, P17; Broder A, 2003, J EXP PSYCHOL LEARN, V29, P611, DOI 10.1037/0278-7393.29.4.611; Broder A, 2007, PSYCHON B REV, V14, P895, DOI 10.3758/BF03194118; BRODER A, ECOLOGICAL IN PRESS; Bruss F. T., 2000, SPEKTRUM WISSENSCHAF, V6, P106; Carnap R., 1947, PHILOS PHENOMENOLOGI, V8, P133, DOI DOI 10.2307/2102920; Chater N, 2003, ORGAN BEHAV HUM DEC, V90, P63, DOI 10.1016/S0749-5978(02)00508-3; CLUTTONBROCK TH, 1979, BEHAVIOUR, V69, P145, DOI 10.1163/156853979X00449; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Czerlinski J., 1999, SIMPLE HEURISTICS MA, P97; DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613; DAWES RM, 1979, AM PSYCHOL, V34, P571, DOI 10.1037//0003-066X.34.7.571; Dawkins R, 1989, SELFISH GENE; DEMIGUEL V, REV FINANCI IN PRESS; Dieckmann A, 2007, MEM COGNITION, V35, P1801, DOI 10.3758/BF03193511; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dudey T., 2002, J BIOECONOMICS, V3, P195; EINHORN HJ, 1975, ORGAN BEHAV HUM PERF, V13, P171, DOI 10.1016/0030-5073(75)90044-6; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; FISHBURN PC, 1974, MANAGE SCI, V20, P1442, DOI 10.1287/mnsc.20.11.1442; FORD JK, 1989, ORGAN BEHAV HUM DEC, V43, P75, DOI 10.1016/0749-5978(89)90059-9; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; GIGERENZER G, 1991, PSYCHOL REV, V98, P254, DOI 10.1037/0033-295X.98.2.254; Gigerenzer G., 2001, BOUNDED RATIONALITY; Gigerenzer G., 2007, GUT FEELINGS INTELLI; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037//0033-295X.103.4.650; Gigerenzer G, 1996, PSYCHOL REV, V103, P592, DOI 10.1037/0033-295X.103.3.592; Gigerenzer G., 2000, ADAPTIVE THINKING RA; Gigerenzer G, 1996, PSYCHOL BULL, V119, P23, DOI 10.1037/0033-2909.119.1.23; Gigerenzer G., 1999, SIMPLE HEURISTICS MA; Gigerenzer G., 1999, SIMPLE HEURISTICS MA, P75; Gigerenzer G., ECOLOGICAL IN PRESS; Gigerenzer Gerd, 2008, RATIONALITY MORTALS; Gilbert J. P., 1966, AM STAT ASS J, V61, P35; GILOVICH T, 1985, COGNITIVE PSYCHOL, V17, P295, DOI 10.1016/0010-0285(85)90010-6; Gilovich T., 2002, PSYCHOL INTUITIVE JU, P1; Goldstein DG, 2002, PSYCHOL REV, V109, P75, DOI 10.1037//0033-295X.109.1.75; GOOD I.J., 1967, BRIT J PHILOS SCI, V17, P319, DOI 10.1093/bjps/17.4.319; Griffiths TL, 2006, PSYCHOL SCI, V17, P767, DOI 10.1111/j.1467-9280.2006.01780.x; Guttman L, 1944, AM SOCIOL REV, V9, P139, DOI 10.2307/2086306; Hastie T, 2001, ELEMENTS STAT LEARNI; Hertwig R, 2003, THINKING PSYCHOL PER, P213, DOI DOI 10.1002/047001332X.CH11; Martignon L, 2002, THEOR DECIS, V52, P29, DOI 10.1023/A:1015516217425; HOGARTH RM, ECOLOGICAL IN PRESS; Hogarth RM, 2005, J MATH PSYCHOL, V49, P115, DOI 10.1016/j.jmp.2005.01.001; Hogarth RM, 2006, THEOR DECIS, V61, P205, DOI 10.1007/s11238-006-9000-8; Hutchinson JMC, 2005, BEHAV PROCESS, V69, P97, DOI 10.1016/j.beproc.2005.02.019; JACOBY LL, 1981, J EXP PSYCHOL GEN, V110, P306, DOI 10.1037/0096-3445.110.3.306; Johnson EJ, 2003, SCIENCE, V302, P1338, DOI 10.1126/science.1091721; Johnson JG, 2003, ORGAN BEHAV HUM DEC, V91, P215, DOI 10.1016/S0749-5978(03)00027-X; Jolls C, 1998, STANFORD LAW REV, V50, P1471, DOI 10.2307/1229304; Kahneman D, 1996, PSYCHOL REV, V103, P582, DOI 10.1037//0033-295X.103.3.582; Karelaia N, 2006, ORGAN BEHAV HUM DEC, V100, P128, DOI 10.1016/j.obhdp.2005.09.003; Katsikopoulos KV, 2008, J RISK UNCERTAINTY, V37, P35, DOI 10.1007/s11166-008-9042-0; Katsikopoulos KV, 2006, J MATH PSYCHOL, V50, P488, DOI 10.1016/j.jmp.2006.06.001; Keeney R. L., 1993, DECISIONS MULTIPLE O; Lee MD, 2002, AUST J PSYCHOL, V54, P137, DOI 10.1080/00049530412331312704; Luria AR, 1968, MIND MNEMONIST; Martignon L, 2008, J MATH PSYCHOL, V52, P352, DOI 10.1016/j.jmp.2008.04.003; Martignon L., 1999, SIMPLE HEURISTICS MA, P119; Mitchell TR, 1978, ACAD MANAGE REV, V3, P439, DOI DOI 10.2307/257535; Mugford ST, 2001, BEHAV ECOL, V12, P655, DOI 10.1093/beheco/12.6.655; Newell BR, 2003, ORGAN BEHAV HUM DEC, V91, P82, DOI 10.1016/S0749-5978(02)00525-3; Newell BR, 2005, TRENDS COGN SCI, V9, P11, DOI 10.1016/j.tics.2004.11.005; Newell BR, 2003, J EXP PSYCHOL LEARN, V29, P53, DOI 10.1037/0278-7393.29.1.53; NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1207/s15516709cog1401_2; NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A; Nosofsky RM, 2007, J EXP PSYCHOL LEARN, V33, P999, DOI 10.1037/0278-7393.33.6.999; Oaksford M., 1998, RATIONAL MODELS COGN; Pachur T, 2008, J BEHAV DECIS MAKING, V21, P183, DOI 10.1002/bdm.581; Payne J.W., 1993, ADAPTIVE DECISION MA; Perlich C., 2003, J MACHINE LEARNING R, V4, P211; PETRIE M, 1994, BEHAV ECOL SOCIOBIOL, V35, P213, DOI 10.1007/BF00167962; Pichert D, 2008, J ENVIRON PSYCHOL, V28, P63, DOI 10.1016/j.jenvp.2007.09.004; Pohl RF, 2006, J BEHAV DECIS MAKING, V19, P251, DOI 10.1002/bdm.522; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Richter T, 2006, J EXP PSYCHOL LEARN, V32, P150, DOI 10.1037/0178-7393.32.1.150; Rieskamp J, 2006, J EXP PSYCHOL GEN, V135, P207, DOI 10.1037/0096-3445.135.2.207; Rieskamp J, 2008, ACTA PSYCHOL, V127, P258, DOI 10.1016/j.actpsy.2007.05.004; Roberts S, 2000, PSYCHOL REV, V107, P358, DOI 10.1037//0033-295X.107.2.358; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; SCHEIBEHENNE B, 2007, INT J FORECASTING, V3, P415; Fehr E, 1999, Q J ECON, V114, P817, DOI 10.1162/003355399556151; SCHMIDT FL, 1971, EDUC PSYCHOL MEAS, V31, P699, DOI 10.1177/001316447103100310; Schmitt M, 2006, J MACH LEARN RES, V7, P55; Schooler LJ, 2005, PSYCHOL REV, V112, P610, DOI 10.1037/0033-295X.112.3.610; Sedlmeier P, 1998, J EXP PSYCHOL LEARN, V24, P754, DOI 10.1037/0278-7393.24.3.754; Selten R, 2001, DAHL WS ENV, P13; Serwe S, 2006, J BEHAV DECIS MAKING, V19, P321, DOI 10.1002/bdm.530; Shaffer DM, 2004, PSYCHOL SCI, V15, P437, DOI 10.1111/j.0956-7976.2004.00698.x; SHAH AK, 2008, PSYCHOL BULL, V137, P207; SHEPARD RN, 1974, PSYCHOMETRIKA, V39, P373, DOI 10.1007/BF02291665; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Simon H. A., 1991, MODELS OF MY LIFE; Simon HA, 1955, Q J ECON, V69, P99, DOI 10.2307/1884852; SIMON HA, 1992, PSYCHOL SCI, V3, P150, DOI 10.1111/j.1467-9280.1992.tb00017.x; Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037//0033-2909.119.1.3; STIGLER GJ, 1961, J POLIT ECON, V69, P213, DOI 10.1086/258464; STONE M, 1974, J R STAT SOC B, V36, P111; Sunstein C., 2000, BEHAV LAW EC; Tinbergen N., 1958, CURIOUS NATURALISTS; Todd P. M., 1999, SIMPLE HEURISTICS MA, P287, DOI DOI 10.1111/.1745-9125.2010.00223.X; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/0033-295X.84.4.327; TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Volz KG, 2006, J COGNITIVE NEUROSCI, V18, P1924, DOI 10.1162/jocn.2006.18.11.1924; Weisberg S., 1985, APPL LINEAR REGRESSI; Wubben M, 2008, J MARKETING, V72, P82, DOI 10.1509/jmkg.72.3.82; Yee M, 2007, MARKET SCI, V26, P532, DOI 10.1287/mksc.1060.0213	127	209	210	10	58	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	1756-8757			TOP COGN SCI	Top. Cogn. Sci.	JAN	2009	1	1					107	143		10.1111/j.1756-8765.2008.01006.x		37	Psychology, Experimental	Psychology	675UG	WOS:000283862000006	25164802	
B	Anantapornkit, E; Kruatrachue, B		Ao, SI; Douglas, C; Grundfest, WS; Burgstone, J		Anantapornkit, Ekaphol; Kruatrachue, Boontee			Reinforcement Learning Algorithm for the Minimal Consistent Subset Identification	WCECS 2009: WORLD CONGRESS ON ENGINEERING AND COMPUTER SCIENCE, VOLS I AND II	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	World Congress on Engineering and Computer Science	OCT 20-22, 2009	San Francisco, CA	Int Assoc Engineers		minimal consistent subset; nearest neighbor rule; prototype selection; reinforcement learning	NEAREST-NEIGHBOR RULE	This paper describes the reinforcement learning (RL) algorithm for the minimal consistent subset identification (MCSI) problem. MCSI is widely used in pattern recognition to select prototypes from a training set to be used in nearest neighbor classification. The RL agent solves the MCSI problem by deselecting a prototype one by one from the original data set to search for the best subset. Because the algorithm rarely descends to the smaller solution via its exploration strategy, a simple modification to the algorithm is proposed. The modification encourages the agent to try as many actions as possible at the current best solution to improve the results obtained. The paper concludes by comparing the performance of the proposed algorithm in handling the MCSI problem with the RL algorithm and the standard MCSI method.	[Anantapornkit, Ekaphol; Kruatrachue, Boontee] King Mongkuts Inst Technol, Dept Comp Engn, Fac Engn, Bangkok, Thailand	Anantapornkit, E (reprint author), King Mongkuts Inst Technol, Dept Comp Engn, Fac Engn, Bangkok, Thailand.	ekreal@yahoo.com; booontee@yahoo.com					Cerveron V, 2001, IEEE T SYST MAN CY B, V31, P408, DOI 10.1109/3477.931531; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; KANGKAN K, 2006, ISCIT 2006 OCT; Sutton R.S., 1998, REINFORCEMENT LEARNI; *U CA DEP INF COMP, 1998, UCI MACH LEARN REP	7	0	0	0	4	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA			978-988-17012-6-8	LECT NOTES ENG COMP			2009							848	852				5	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BPZ34	WOS:000280421400160		
J	Watanabe, T; Kobunai, T; Sakamoto, E; Yamamoto, Y; Konishi, T; Horiuchi, A; Shimada, R; Oka, T; Nagawa, H				Watanabe, Toshiaki; Kobunai, Takashi; Sakamoto, Etsuko; Yamamoto, Yoko; Konishi, Tsuyoshi; Horiuchi, Atsushi; Shimada, Ryu; Oka, Toshinori; Nagawa, Hirokazu			Gene Expression Signature for Recurrence in Stage III Colorectal Cancers	CANCER			English	Article						colorectal cancer; recurrence; lymph node metastasis; stage III; microarray; prediction; copy number; CABIN1; Duke stage C; tailored therapy	MICROARRAY ANALYSIS; DNA MICROARRAY; HYBRIDIZATION; POLYMORPHISM; PREDICTION; MUTATIONS; PROFILES; SURVIVAL	BACKGROUND: Colorectal cancer patients with lymph node metastases (stage III) show poorer prognosis than those without. Predicting development of recurrence may guide the need for intensive follow-up and/or adjuvant chemotherapy in such patients. The authors' objective was to identify a set of discriminating genes that could predict recurrence in stage III colorectal cancer. METHODS: Thirty-six stage III colorectal cancer patients were studied. Tumor samples were obtained from surgically resected specimens. Thirteen patients developed recurrence, whereas 23 patients did not. Gene expression profiles were determined using human HG-U133 Plus 2.0 Gene Chip (Affymetrix, Santa Clara, Calif). RESULTS: The authors identified 45 discriminating genes between patients with and without recurrence. By using this gene set, they established a new model to predict recurrence with an accuracy of 90.9%. The discriminating genes included calcineurin-binding protein 1 (CABIN1), whose expression differed remarkably between patients with and without recurrence (P = .0073). The authors further examined the DNA copy number of CABIN1 and were able to show a significant relation with recurrence (P < .012). Patients having CABIN1 gene loss demonstrated a higher risk of recurrence (odds ratio, 18.8). DNA copy number of CABIN1 alone could predict recurrence with an accuracy of 80.0%. CONCLUSIONS: The results of the current study demonstrated that gene expression profiling is useful in predicting recurrence in stage III colorectal cancer. The authors identified CABIN1 among discriminating genes that may play a key role in the development of recurrence. These results may help to establish an individualized therapy for stage III colorectal cancer. Cancer 2009;115:28392. (C) 2009 American Cancer Society.	[Watanabe, Toshiaki] Teikyo Univ, Sch Med, Dept Surg, Itabashi Ku, Tokyo 1738605, Japan; [Sakamoto, Etsuko; Oka, Toshinori] Taiho Pharmaceut Co Ltd, Tokushima Res Ctr, Personalized Med Res Lab, Tokushima, Japan; [Konishi, Tsuyoshi; Nagawa, Hirokazu] Univ Tokyo, Dept Surg Oncol, Tokyo, Japan	Watanabe, T (reprint author), Teikyo Univ, Sch Med, Dept Surg, Itabashi Ku, 2-11-1 Kaga, Tokyo 1738605, Japan.	toshwatanabe@yahoo.co.jp			Ministry of Education, Culture, sports, Science, and Technology of Japan; Ministry of Health, Labor and Welfare of Japan	This study was supported by a Grant-in-Aid for Scientific Research from the Ministry of Education, Culture, sports, Science, and Technology of Japan and a grant from the Ministry of Health, Labor and Welfare of Japan.	Arango D, 2005, GASTROENTEROLOGY, V129, P874, DOI 10.1053/j.gastro.2005.06.066; BELL SM, 1993, GASTROENTEROLOGY, V104, P57; BENHATTAR J, 1993, GASTROENTEROLOGY, V104, P1044; Buckley PG, 2005, HUM MUTAT, V26, P540, DOI 10.1002/humu.20255; Chin KV, 2002, PHARM RES-DORDR, V19, P1773, DOI 10.1023/A:1021425004264; Clarke PA, 2001, BIOCHEM PHARMACOL, V62, P1311, DOI 10.1016/S0006-2952(01)00785-7; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOH HS, 1995, CANCER RES, V55, P5217; Landi S, 2000, MUTAT RES-REV MUTAT, V463, P247, DOI 10.1016/S1383-5742(00)00050-8; Pauletti G, 1996, ONCOGENE, V13, P63; PEMBLE S, 1994, BIOCHEM J, V300, P271; Pinkel D, 2005, NAT GENET, V37, pS11, DOI 10.1038/ng1569; Wang TL, 2002, P NATL ACAD SCI USA, V99, P16156, DOI 10.1073/pnas.202610899; Watanabe T, 2006, CANCER RES, V66, P9804, DOI 10.1158/0008-5472.CAN-06-1163; Watanabe T, 2001, NEW ENGL J MED, V344, P1196, DOI 10.1056/NEJM200104193441603; Watanabe T, 2007, CLIN CANCER RES, V13, P415, DOI 10.1158/1078-0432.CCR-06-0753; Watanabe T, 2006, CANCER RES, V66, P3370, DOI 10.1158/0008-5472.CAN-05-3834; Youn HD, 2000, IMMUNITY, V13, P85, DOI 10.1016/S1074-7613(00)00010-8; Zhang H, 1999, INT J CANCER, V84, P135, DOI 10.1002/(SICI)1097-0215(19990420)84:2<135::AID-IJC7>3.0.CO;2-C; Zhao XJ, 2004, CANCER RES, V64, P3060, DOI 10.1158/0008-5472.CAN-03-3308	20	17	18	1	1	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0008-543X			CANCER	Cancer	JAN 15	2009	115	2					283	292		10.1002/cncr.24023		10	Oncology	Oncology	401LJ	WOS:000262941900008	19016304	
J	Dixon, SJ; Brereton, RG				Dixon, Sarah J.; Brereton, Richard G.			Comparison of performance of five common classifiers represented as boundary methods: Euclidean Distance to Centroids, Linear Discriminant Analysis, Quadratic Discriminant Analysis, Learning Vector Quantization and Support Vector Machines, as dependent on data structure	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Classification; Boundary methods; Euclidean distance; Mahalanobis distance; Linear Discriminant Analysis; Quadratic Discriminant Analysis; Learning Vector Quantization; Support Vector Machines	CHROMATOGRAPHY-MASS-SPECTROMETRY; PATTERN-RECOGNITION; ELECTRONIC NOSE; CLASSIFICATION; PARAMETERS; ALGORITHMS; SELECTION	Five methods for discrimination are described, namely Euclidean Distance to centroids (EDC), Linear Discriminant Analysis (LDA) (based on the Mahalanobis distance and pooled variance covariance matrix), Quadratic Discriminant Analysis (QDA) (based on the Mahalanobis distance and individual class variance covariance matrix - non-Bayesian form), Learning Vector Quantization (LVQ) and Support Vector Machines (SVMs) (using soft boundaries and Radial Basis Functions), and illustrated graphically as boundary methods. The performance of each method was determined using four synthetic datasets each consisting of 200 samples half belonging to one of two classes, and a further two synthetic datasets containing 400 samples, again equally split between the two classes. In datasets 1 to 3. five variables were distributed multinormally, in dataset 1 the classes are distributed roughly circularly but with a significant degree of overlap, in dataset 2. the distribution is in elongated hyperellipsoids with small overlap, and in dataset 3 there is a region of complete overlap between classes. In dataset 4 two variables are distributed in a crescent shape. In datasets 5 and 6, 100 variables were generated from multinormal populations, some of which were potential discriminators, however a large proportion of the variables were designed to be uninformative. The methods were optimised using a training set and their performance evaluated using a test set: this was repeated 100 times for different test and training set splits. The average % correctly classified was computed for each class and model, as well as the model stability for each sample (the proportion of times the sample is classified into the same group over all 100 iterations). The conclusions are that the performance of the classifiers depends very much on the distribution of data. Approaches such as LVQ and SVMs that try to determine complex boundaries perform best when the data is not normally distributed such as in dataset 4, but can be prone to overfitting otherwise. QDA tends to perform best on multinormal data although it can be influenced by non-discriminative variables which show a difference in variance. It is recommended to look at the data structure prior to model building to determine the optimal type of model. (c) 2008 Elsevier B.V. All rights reserved.	[Dixon, Sarah J.; Brereton, Richard G.] Univ Bristol, Sch Chem, Ctr Chemometr, Bristol BS8 1TS, Avon, England	Brereton, RG (reprint author), Univ Bristol, Sch Chem, Ctr Chemometr, Bristol BS8 1TS, Avon, England.	r.g.brereton@bristol.ac.uk					Abe S., 2005, SUPPORT VECTOR MACHI; Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5; BRERETON RG, 2003, CHEMOMETRICS DATA AN; Brereton RG, 2006, TRAC-TREND ANAL CHEM, V25, P1103, DOI 10.1016/j.trac.2006.10.005; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAGNONI S, 1994, IEEE INT C NEUR NETW, P762; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7; Dixon SJ, 2007, CHEMOMETR INTELL LAB, V87, P161, DOI 10.1016/j.chemolab.2006.12.004; DUAN KB, 2005, MULTIPLE CLASSIFIER; Duda R O, 2001, PATTERN CLASSIFICATI; FRANK IE, 1989, J CHEMOMETR, V3, P453; Fraser LA, 1997, PHYTOCHEM ANALYSIS, V8, P301, DOI 10.1002/(SICI)1099-1565(199711/12)8:6<301::AID-PCA373>3.0.CO;2-2; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedrichs F, 2005, NEUROCOMPUTING, V64, P107, DOI 10.1016/j.neucom.2004.11.022; FROHLICH H, 2005, IEEE INT JOINT C NEU, V3, P1431; Gardner JW, 2000, SENSOR ACTUAT B-CHEM, V69, P336, DOI 10.1016/S0925-4005(00)00482-2; GUNN SR, 1998, ONLINE REFERENCE MAN; Guo Guodong, 2000, P INT C AUT FAC GEST, p[196, 201]; HSU CW, 2003, ONLINE REFERENCE MAN; Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955; Khuwaja GA, 2003, CYBERNET SYST, V34, P725, DOI 10.1080/01969720390241511; Kohonen T., 1992, P INT JOINT C NEUR N, VI, P725, DOI 10.1109/IJCNN.1992.287101; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1997, SELF ORG MAPS; Lloyd GR, 2007, J CHEM INF MODEL, V47, P1553, DOI 10.1021/ci700019q; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Roggo Y, 2003, ANAL CHIM ACTA, V477, P187, DOI 10.1016/S0003-2670(02)01422-8; SCHMIDBAUER O, 1992, IEEE INT C AC SPEECH, V1, P441; Shawe-Taylor J, 2002, IEEE T INFORM THEORY, V48, P2721, DOI 10.1109/TIT.2002.802647; Smits G.F., 2002, P 2002 INT JOINT C N, V3, P2785; STEFANO CD, 2004, P 17 INT C PATT REC, V604, P601; Tong S, 2002, J MACH LEARN RES, V2, P45; Vapnik V. N., 1995, NATURE STAT LEARNING; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; Xu Y, 2006, CRIT REV ANAL CHEM, V36, P177, DOI 10.1080/10408340600969486; Zomer S, 2004, ANALYST, V129, P175, DOI 10.1039/b312982a; Zomer S, 2004, J CHEMOMETR, V18, P294, DOI 10.1002/cem.872; Zuppa M, 2004, SENSOR ACTUAT B-CHEM, V98, P305, DOI 10.1016/j.snb.2003.10.029	41	42	42	6	15	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	JAN 15	2009	95	1					1	17		10.1016/j.chemolab.2008.07.010		17	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	396OA	WOS:000262599800001		
J	Niu, B; Lu, L; Liu, L; Gu, TH; Feng, KY; Lu, WC; Cai, YD				Niu, Bing; Lu, Lin; Liu, Liang; Gu, Tian Hong; Feng, Kai-Yan; Lu, Wen-Cong; Cai, Yu-Dong			HIV-1 Protease Cleavage Site Prediction Based on Amino Acid Property	JOURNAL OF COMPUTATIONAL CHEMISTRY			English	Article						mRMR (maximum relevance, minimum redundancy); HIV protease; cleavage sites; KNN (K-nearest neighbors); AAindex	HUMAN-IMMUNODEFICIENCY-VIRUS; HYBRIDIZATION SPACE; INDEX DATABASE; PROTEINS; NETWORK; TYPE-1; SPECIFICITY; ALGORITHM; SELECTION; AAINDEX	Knowledge of the polyprotein cleavage sites by HIV protease will refine our understanding of its specificity, and the information thus acquired is useful for designing specific and efficient HIV protease inhibitors. Recently, several works have approached the HIV-1 protease specificity problem by applying a number of classifier creation and combination methods. The pace in searching for the proper inhibitors of HIV protease will be greatly expedited if one can find an accurate, robust, and rapid method for predicting the cleavage sites in proteins by HIV protease. In this article, we selected HIV-1 protease as the Subject of the study. 299 oligopeptides were chosen for the training set, while the other 63 oligopeptides were taken as a test set. The peptides are represented by features constructed by AAIndex (Kawashima et al., Nucleic Acids Res 1999, 27, 368; Kawashima and Kanehisa, Nucleic Acids Res 2000, 28, 374). The mRMR method (Maximum Relevance, Minimum Redundancy; Ding and Peng, Proc Second IEEE Comput Syst Bioinformatics Conf 2003, 523; Peng et al., IEEE Trans Pattern Anal Mach Intell 2005, 27, 1226) combining with incremental feature selection (IFS) and feature forward search (FFS) are applied to find the two important cleavage sites and to select 364 important biochemistry features by jackknife test. Using KNN (K-nearest neighbors) to combine the selected features, the prediction model obtains high accuracy rate of 91.3% for Jackknife cross-validation test and 87.3% for independent-set test. It is expected that our feature selection scheme can be referred to as a useful assistant technique for finding effective inhibitors of HIV protease, especially for the scientists in this field. (C) 2008 Wiley Periodicals, Inc. J Comput Chem 30: 33-39, 2009	[Lu, Wen-Cong; Cai, Yu-Dong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Niu, Bing; Liu, Liang; Gu, Tian Hong] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China; [Lu, Lin] Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200040, Peoples R China; [Feng, Kai-Yan] Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England; [Cai, Yu-Dong] Chinese Acad Sci, MPG Partner Computat Biol, Dept Combinator & Geometry, Shanghai Inst Biol Sci, Shanghai 200031, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, 99 Shand Da Rd, Shanghai 200444, Peoples R China.	wclu@shu.edu.cn; cyd@picb.ac.cn			National Natural Science Foundation of China [20503015]; Systems Biology Research Foundation of Shanghai university	Contract/grant sponsor: Systems Biology Research Foundation of Shanghai university	BECK ZQ, 2000, VIROLOGY, V75, P9502; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 1998, ADV ENG SOFTW, V29, P119, DOI 10.1016/S0965-9978(98)00046-5; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; JASKOLSKI M, 1991, BIOCHEMISTRY-US, V30, P1600, DOI 10.1021/bi00220a023; Kawashima S, 1999, NUCLEIC ACIDS RES, V27, P368, DOI 10.1093/nar/27.1.368; Kawashima S, 2000, NUCLEIC ACIDS RES, V28, P374, DOI 10.1093/nar/28.1.374; Kim JH, 2004, BIOINFORMATICS, V20, P3179, DOI 10.1093/bioinformatics/bth382; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; NAKAI K, 1988, PROTEIN ENG, V2, P93, DOI 10.1093/protein/2.2.93; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; POORMAN RA, 1991, J BIOL CHEM, V266, P14554; Qian ZL, 2006, BIOCHEM BIOPH RES CO, V348, P1034, DOI 10.1016/j.bbrc.2006.07.149; Ridky TW, 1996, J BIOL CHEM, V271, P4709; Rognvaldsson T, 2004, BIOINFORMATICS, V20, P1702, DOI 10.1093/bioinformatics/bth144; Song H, 2007, COMPUT BIOL MED, V37, P1759, DOI 10.1016/j.compbiomed.2007.05.002; Thompson TB, 1995, J THEOR BIOL, V177, P369, DOI 10.1006/jtbi.1995.0254; WLODAWER A, 2000, BIOCHIM BIOPHYS ACTA, V7, P16	25	14	14	1	8	JOHN WILEY & SONS INC	HOBOKEN	111 RIVER ST, HOBOKEN, NJ 07030 USA	0192-8651			J COMPUT CHEM	J. Comput. Chem.	JAN 15	2009	30	1					33	39		10.1002/jcc.21024		7	Chemistry, Multidisciplinary	Chemistry	386UB	WOS:000261907000003	18496789	
J	Nassiri-Mofakham, F; Nematbakhsh, MA; Baraani-Dastjerdi, A; Ghasem-Aghaee, N				Nassiri-Mofakham, Faria; Nematbakhsh, Mohammad Ali; Baraani-Dastjerdi, Ahmad; Ghasem-Aghaee, Nasser			Electronic promotion to new customers using mkNN learning	INFORMATION SCIENCES			English	Article						e-Commerce; e-Marketing; e-Advertisement; mkNN learning; Heuristic promotion strategy; New customer; Customer annoyance; Seller reputation; Customer anonymity; Association link	SIMILARITY MEASURE; PRODUCT TAXONOMY; E-COMMERCE; CLASSIFICATION; MARKET; RECOMMENDATIONS; SENSITIVITY; RETENTION; IMPACT; ONLINE	In recent years, several techniques have been proposed to model electronic promotions for existing customers. However, these techniques are not applicable for new customers with no previous profile or behavior data. This study models promotions to new customers in an electronic marketplace. We introduce a multi-valued k-Nearest Neighbor (mkNN) learning capability for modeling promotions to new customers. In this modified learning algorithm, instead of a single product category, the seller sends the new customer a promotion on a variable set of In categories (where m is a variable) with the highest rank of desirability among the most similar previous customers. Previous studies consider sellers' profits in promotion and marketing models. In addition to the sellers' profits, three important factors annoyance of customers, sellers' reputations, and customers' anonymity - are considered in this study. Without considering the customer's profile, we minimize unrelated and disliked offers to reduce the customer's annoyance and elevate the seller's reputation. The promotion models are evaluated in two separate experiments on populations with different degrees of optimism: (1) with fixed number of customers; and (2) in a fixed period of time. The evaluation is based on the parameters of customer population size and behavior as well as time interval. seller payoff, seller reputation, and the number of promotions canceled by the customers. The simulation results demonstrate that the proposed mkNN-based promotion strategies are moderately efficient with respect to all parameters for providing services in a large population. In addition, purchasing preferences of past customers, which are based on periodic promotions that a seller sends to customers, can generate future rapidly expanding demands in the market. By using these approaches, an advertising company can send acceptable promotions to customers without having specific profile information. (c) 2008 Elsevier Inc. All rights reserved.	[Nassiri-Mofakham, Faria; Nematbakhsh, Mohammad Ali; Baraani-Dastjerdi, Ahmad; Ghasem-Aghaee, Nasser] Univ Isfahan UI, Dept Comp Engn, Esfahan, Iran; [Nassiri-Mofakham, Faria] Univ Isfahan UI, Dept Informat Technol Engn, Esfahan, Iran	Nassiri-Mofakham, F (reprint author), Univ Isfahan UI, Dept Comp Engn, PO Code 81746-73441,Hezar Jerib Ave, Esfahan, Iran.	fnasirimofakham@yahoo.com; nematbakhsh@eng.ui.ac.ir; ahmad-b@eng.ui.ac.ir; aghaee@eng.ui.ac.ir	Nassiri-Mofakham, Faria/I-7118-2015	Nassiri-Mofakham, Faria/0000-0001-5147-9136			Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024; ATKESON CC, 1997, ARTIF INTELL, P75; Berry M. J. A., 2000, MASTERING DATA MININ; Bhattacharya CB, 1998, J ACAD MARKET SCI, V26, P31, DOI 10.1177/0092070398261004; Buckinx W, 2004, EXPERT SYST APPL, V26, P509, DOI 10.1016/j.eswa.2003.10.009; Chen LS, 2008, INFORM SCIENCES, V178, P1032, DOI 10.1016/j.ins.2007.09.027; Chen MC, 2007, EXPERT SYST APPL, V33, P1110, DOI 10.1016/j.eswa.2006.08.007; Chiu CC, 2002, EXPERT SYST APPL, V22, P163, DOI 10.1016/S0957-4174(01)00052-5; Cho YH, 2004, EXPERT SYST APPL, V26, P233, DOI 10.1016/S0957-4174(03)00138-6; Colgate MR, 2000, J ACAD MARKET SCI, V28, P375, DOI 10.1177/0092070300283006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crone SF, 2006, EUR J OPER RES, V173, P781, DOI 10.1016/j.ejor.2005.07.023; DEITEL HM, 2001, E COMMERCE E BUSINES; FAYYAD U, 1996, A1 MAGAZINE      FAL, P38; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Ganesh J, 2000, J MARKETING, V64, P65, DOI 10.1509/jmkg.64.3.65.18028; Han J., 2006, DATA MINING CONCEPTS; Hauser J. R., 1984, MARKET SCI, V3, P83, DOI 10.1287/mksc.3.2.83; Hay B, 2003, LECT NOTES ARTIF INT, V2703, P50; Hung LP, 2005, EXPERT SYST APPL, V29, P383, DOI 10.1016/j.eswa.2005.04.016; Jain A., 1998, PRENTICE HALL ADV RE; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; Kaefer F, 2005, COMPUT OPER RES, V32, P2595, DOI 10.1016/j.cor.2004.06.021; Kantardzic M., 2003, DATA MINING CONCEPTS; Kaufman L., 1990, FINDING GROUPS DATA; Kazienko P, 2007, INFORM SCIENCES, V177, P2269, DOI 10.1016/j.ins.2007.01.002; Kiang MY, 2000, DECIS SUPPORT SYST, V27, P383, DOI 10.1016/S0167-9236(99)00062-7; Kim E, 2003, DECIS SUPPORT SYST, V34, P167, DOI 10.1016/S0167-9236(02)00079-9; Kogan K, 2008, EUR J OPER RES, V188, P273, DOI 10.1016/j.ejor.2007.04.012; Lariviere B, 2004, EXPERT SYST APPL, V27, P277, DOI 10.1016/j.eswa.2004.02.002; LARIVIERE B, 2004, WP04282 U GENT FAC E; Larose D. T., 2005, DISCOVERING KNOWLEDG; Lee JS, 2005, EXPERT SYST APPL, V29, P700, DOI 10.1016/j.eswa.2005.04.037; Lewis D.D., 1992, REPRESENTATION LEARN; Linoff G., 1997, DATA MINING TECHNIQU; Mitchell T. M., 1997, MACHINE LEARNING; Mitchell TM, 1999, COMMUN ACM, V42, P30, DOI 10.1145/319382.319388; Nassiri-Mofakham Faria, 2008, Simulation & Gaming, V39, DOI 10.1177/1046878107308094; Nassiri-Mofakham F., 2006, IRANIAN J INFORM SCI, V4, P15; Nassiri-Mofakham F, 2009, INT J HUM-COMPUT ST, V67, P1, DOI 10.1016/j.ijhcs.2008.08.001; PERNER P, 2002, ADV DATA MINING APPL, V2394, P39; Ponniah Paulraj, 2001, DATA WAREHOUSING FUN; Raghavan NRS, 2005, SADHANA-ACAD P ENG S, V30, P275; Ramakrishnan R., 2000, DATABASE MANAGEMENT; Rud O.P., 2001, DATA MINING COOKBOOK; Silberschatz A., 2002, DATABASE SYSTEM CONC, V4th; Smith KA, 2000, J OPER RES SOC, V51, P532, DOI 10.1057/palgrave.jors.2600941; Tsao YC, 2008, COMPUT OPER RES, V35, P3562, DOI 10.1016/j.cor.2007.01.024; TVERSKY A, 1986, PSYCHOL REV, V93, P3, DOI 10.1037/0033-295X.93.1.3; TZONGRU L, 2006, ELECTRON COMMER R A, V5, P105; Van den Poel D, 2004, EXPERT SYST APPL, V27, P53, DOI [10.1016/j.eswa.2003.12.003, 10.1016/j.eswa.2003.12.2003]; VANRIJSBERGEN CJ, 1977, J DOC, V33, P106; VANTOMME D, 2004, WP04224 U GENT FAC E; VINDEVOGEL B, 2004, WP04276 U GENT FAC E; Vindevogel B, 2005, EXPERT SYST APPL, V28, P583, DOI 10.1016/j.eswa.2004.12.019; Wang FH, 2008, INFORM SCIENCES, V178, P1848, DOI 10.1016/j.ins.2007.11.018; Weng SS, 2004, EXPERT SYST APPL, V26, P493, DOI 10.1016/j.eswa.2003.10.008; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540	58	3	3	2	5	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	JAN 16	2009	179	3					248	266		10.1016/j.ins.2008.09.019		19	Computer Science, Information Systems	Computer Science	412FE	WOS:000263708600004		
J	Sakiyama, Y				Sakiyama, Yojiro			The use of machine learning and nonlinear statistical tools for ADME prediction	EXPERT OPINION ON DRUG METABOLISM & TOXICOLOGY			English	Review						ADME; ensemble; in silico; kernel; machine learning; nonlinear	SUPPORT VECTOR MACHINES; STRUCTURE-PROPERTY RELATIONSHIPS; RECURSIVE-PARTITIONING MODEL; HUMAN INTESTINAL-ABSORPTION; LIVER MICROSOMAL STABILITY; BRAIN-BARRIER PERMEATION; SELF-ORGANIZING MAPS; GENE-EXPRESSION DATA; IN-SILICO; AQUEOUS SOLUBILITY	Absorption, distribution, metabolism and excretion (ADME)-related failure of drug candidates is a major issue for the pharmaceutical industry today. Prediction of ADME by in silico tools has now become an inevitable paradigm to reduce cost and enhance efficiency in pharmaceutical research. Recently, machine learning as well as nonlinear statistical tools has been widely applied to predict routine ADME end points. To achieve accurate and reliable predictions, it would be a prerequisite to understand the concepts, mechanisms and limitations of these tools. Here, we have devised a small synthetic nonlinear data set to help understand the mechanism of machine learning by 2D-visualisation. We applied six new machine learning methods to four different data sets. The methods include Naive Bayes classifier, classification and regression tree, random forest, Gaussian process, support vector machine and k nearest neighbour. The results demonstrated that ensemble learning and kernel machine displayed greater accuracy of prediction than classical methods irrespective of the data set size. The importance of interaction with the engineering field is also addressed. The results described here provide insights into the mechanism of machine learning, which will enable appropriate usage in the future.	Sandwich Labs, Pfizer Global Res & Dev, Pharmacokinet Dynam Metab, Sandwich CT13 9NJ, Kent, England	Sakiyama, Y (reprint author), Sandwich Labs, Pfizer Global Res & Dev, Pharmacokinet Dynam Metab, Sandwich CT13 9NJ, Kent, England.	Yojiro.Sakiyama@pfizer.com					AKAIKE H, 1978, BIOMETRIKA, V65, P53, DOI 10.1093/biomet/65.1.53; [Anonymous], WEKA 3 DATA MINING S; Arimoto R, 2005, J BIOMOL SCREEN, V10, P197, DOI 10.1177/1087057104274091; ATKSON CG, 1997, ARTIF INTELL REV, V11, P11; Balakin Konstantin V, 2005, Curr Drug Discov Technol, V2, P99, DOI 10.2174/1570163054064666; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; BARRETT SJ, 2005, ADV APPL MACHINE LEA; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; Bellman R., 1961, ADAPTIVE CONTROL PRO; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boubacar HA, 2008, NEURAL NETWORKS, V21, P1287, DOI 10.1016/j.neunet.2008.03.016; BOX GBP, 2005, FRACTIONAL FACTORIAL; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Broomhead D. S., 1988, Complex Systems, V2; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Bruneau P, 2001, J CHEM INF COMP SCI, V41, P1605, DOI 10.1021/ci010363y; Burbidge R, 2001, COMPUT CHEM, V26, P5, DOI 10.1016/S0097-8485(01)00094-8; Burden FR, 2000, J CHEM INF COMP SCI, V40, P1423, DOI 10.1021/ci000450a; Burden FR, 2001, J CHEM INF COMP SCI, V41, P830, DOI 10.1021/ci000459c; Burton J, 2006, J MED CHEM, V49, P6231, DOI 10.1021/jm060267u; Cartmell J, 2005, J COMPUT AID MOL DES, V19, P821, DOI 10.1007/s10822-005-9029-8; CATUANA R, 2008, P 25 INT C MACH LEAR; Chohan KK, 2005, J MED CHEM, V48, P5154, DOI 10.1021/jm048959a; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Cerqueira L. P., 2006, J CHEM INF MODEL, V46, P1245; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P1021, DOI 10.1016/j.jpba.2005.05.034; Deconinck E, 2005, J PHARMACEUT BIOMED, V39, P91, DOI 10.1016/j.jpba.2005.03.008; de Graaf C, 2005, J MED CHEM, V48, P2725, DOI 10.1021/jm040180d; de Groot MJ, 2002, ADV DRUG DELIVER REV, V54, P367, DOI 10.1016/S0169-409X(02)00009-1; Delaney JS, 2004, J CHEM INF COMP SCI, V44, P1000, DOI 10.1021/ci034243x; Devillers J, 1998, J PHARM SCI-US, V87, P1086, DOI 10.1021/js980101j; DOGRA SK, 2008, CHOICE MODELS QSARWO; EFRON B, 1983, J AM STAT ASSOC, V78, P316, DOI 10.2307/2288636; Ekins Sean, 2005, Expert Opin Drug Metab Toxicol, V1, P303, DOI 10.1517/17425255.1.2.303; Ekins S, 2006, J MED CHEM, V49, P5059, DOI 10.1021/jm060076r; Embrechts MJ, 2007, DRUG METAB DISPOS, V35, P325, DOI 10.1124/dmd.106.013185; Fox T, 2006, CURR TOP MED CHEM, V6, P1579, DOI 10.2174/156802606778108915; FRIEDMAN J, 1988, MULTIVARIATE ADAPTIV; Frohlich H, 2006, QSAR COMB SCI, V25, P317, DOI 10.1002/qsar.200510135; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Gamerman D., 1997, MARKOV CHAIN MONTE C; Ghose AK, 2008, J MED CHEM, V51, P5149, DOI 10.1021/jm800475y; Gleeson MP, 2006, J MED CHEM, V49, P1953, DOI 10.1021/jm0510070; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; GOOD IJ, 1964, ESTIMATION PROBABILI; Green D M, 1966, SIGNAL DETECTION THE, P45; Kurogi Y, 2001, CURR MED CHEM, V8, P1035; GUPTA N, QSARWORLD STRAND LIF; Hansch C, 2004, DRUG METAB REV, V36, P105, DOI 10.1081/DMR-120028428; Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i; Hebb D, 1949, ORG BEHAV; HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044; Holland J., 1975, ADAPTATION NATURAL A; Hopfield J., 1982, NATL ACAD SCI, V79, P2554, DOI DOI 10.1073/PNAS.79.8.2554; Hou TJ, 2007, J CHEM INF MODEL, V47, P208, DOI 10.1021/ci600343x; Hou TJ, 2007, J CHEM INF MODEL, V47, P2408, DOI 10.1021/ci7002076; Hsu C., PRACTICAL GUIDE SUPP; Hunt Earl B, 1966, EXPT INDUCTION; Huuskonen J, 1997, J PHARM SCI, V86, P450, DOI 10.1021/js960358m; Jeff Wu CF, 2000, EXPT PLANNING ANAL P; Jensen TS, 2002, EUR J PAIN-LONDON, V6, P3, DOI 10.1016/S1090-3801(02)90002-9; Jin B, 2007, INT J DATA MIN BIOIN, V1, P270, DOI 10.1504/IJDMB.2007.011613; Jordan M., 1999, LEARNING GRAPHICAL M; Jung E, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-245; Kaiser D, 2007, J MED CHEM, V50, P1698, DOI 10.1021/jm060604z; Karthikeyan M, 2005, J CHEM INF MODEL, V45, P581, DOI 10.1021/ci0500132; Keefer CE, 2006, CHEMOMETR INTELL LAB, V84, P40, DOI 10.1016/j.chemolab.2006.04.013; Klon AE, 2006, J CHEM INF MODEL, V46, P1945, DOI 10.1021/ci0601315; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Kohonen T., 1984, SELF ORG ASS MEMORY; Kola I, 2004, NAT REV DRUG DISCOV, V3, P711, DOI 10.1038/nrd1470; Kononenko I., 2007, MACHINE LEARNING DAT; Kriegl JM, 2005, J COMPUT AID MOL DES, V19, P189, DOI 10.1007/s10822-005-3785-3; Kuentz M, 2003, PHARM DEV TECHNOL, V8, P453, DOI 10.1081/PDT-120024698; Lamanna C, 2008, J MED CHEM, V51, P2891, DOI 10.1021/jm701407x; Lee PH, 2007, J COMPUT AID MOL DES, V21, P665, DOI 10.1007/s10822-007-9124-0; Li GZ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S6-S7; Li H, 2007, J PHARM SCI-US, V96, P2838, DOI 10.1002/jps.20985; Li H, 2005, J CHEM INF MODEL, V45, P1376, DOI 10.1021/ci050135u; Liu HX, 2005, J COMPUT AID MOL DES, V19, P499, DOI 10.1007/s10822-005-9003-5; Liu KH, 2008, COMPUT BIOL MED, V38, P601, DOI 10.1016/j.compbiomed.2008.02.007; Liu Q, 2008, J BIOMOL STRUCT DYN, V25, P685; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; Lombardo F, 2006, J MED CHEM, V49, P2262, DOI 10.1021/jm050200r; Ma WP, 2006, J CHROMATOGR A, V1113, P140, DOI 10.1016/j.chroma.2006.01.136; Ma Xiao Hua, 2008, Curr Drug Saf, V3, P100, DOI 10.2174/157488608784529224; MACKAY DJC, 1992, NEURAL COMPUT, V4, P720, DOI 10.1162/neco.1992.4.5.720; MACKAY DJC, 1995, MAXIMUM ENTROPY BAYE, P211; Mente SR, 2005, J COMPUT AID MOL DES, V19, P465, DOI 10.1007/s10822-005-9001-7; Minka T.P, 2001, P 17 C UNC ART INT, P362; Mitchell T. M., 1997, MACHINE LEARNING; MOSTELLER F, 1948, ANN MATH STAT, V19, P58, DOI 10.1214/aoms/1177730290; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Narasimhan B, 2006, CHEM PHARM BULL, V54, P1067, DOI 10.1248/cpb.54.1067; Narayanan R, 2005, BIOORGAN MED CHEM, V13, P3017, DOI 10.1016/j.bmc.2005.01.061; NEAL RM, 1997, 9702 U TOR DEP STAT, V45, P5; Neal R.M., 1996, BAYESIAN LEARNING NE; Netzeva TI, 2005, ATLA-ALTERN LAB ANIM, V33, P155; Neumann MH, 2000, STAT SINICA, V10, P399; Nilsson NJ, 1965, LEARNING MACHINES; Nocedal J, 1999, NUMERICAL OPTIMIZATI; Obrezanova O, 2008, J COMPUT AID MOL DES, V22, P431, DOI 10.1007/s10822-008-9193-8; Obrezanova O, 2007, J CHEM INF MODEL, V47, P1847, DOI 10.1021/ci7000633; O'Brien SE, 2005, J MED CHEM, V48, P1287, DOI 10.1021/jm049254b; OSUNA E, 1997, NEURAL NETWORKS SIGN, V7, P276; Palmer DS, 2007, J CHEM INF MODEL, V47, P150, DOI 10.1021/ci060164k; Pedersen A G, 1997, Proc Int Conf Intell Syst Mol Biol, V5, P226; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; Polley MJ, 2005, AUST J CHEM, V58, P859, DOI 10.1071/CH05202; QUINLAIN JR, 1979, EXPERT SYSTEMS MICRO; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; ROGERS D, 1994, J CHEM INF COMP SCI, V34, P854, DOI 10.1021/ci00020a020; Rosenblatt F., 1962, PRINCIPLES NEURODYNA; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1; SAKIYAMA Y, 2008, P 2008 INT C MACH LE, V2, P784; Sakiyama Y, 2008, J MOL GRAPH MODEL, V26, P907, DOI 10.1016/j.jmgm.2007.06.005; Sato T, 2008, J MED CHEM, V51, P7705, DOI 10.1021/jm800504q; Schroeter T, 2007, MOL PHARMACEUT, V4, P524, DOI 10.1021/mp0700413; Schroeter TS, 2007, J COMPUT AID MOL DES, V21, P651, DOI 10.1007/s10822-007-9160-9; Schwaighofer A, 2007, J CHEM INF MODEL, V47, P407, DOI 10.1021/ci600205g; Schwaighofer A, 2008, J CHEM INF MODEL, V48, P785, DOI 10.1021/ci700142c; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Skinner BT, 2007, C P IEEE ENG MED BIO, P3120; SONNENBURG S, J MACH LEARN, P2443; Sorich MJ, 2008, CURR DRUG METAB, V9, P60, DOI 10.2174/138920008783331167; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; STOKES ME, 1995, CATEGORICAL DATA ANA, P98; STONE M, 1974, J R STAT SOC B, V36, P111; Banka H, 2008, CH CRC COMP SCI DATA, P277; Susnow RG, 2003, J CHEM INF COMP SCI, V43, P1308, DOI 10.1021/ci030283p; Svetnik V, 2005, J CHEM INF MODEL, V45, P786, DOI 10.1021/ci0500379; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Team RDC, 2011, R LANG ENV STAT COMP; Tong WD, 2005, CURR COMPUT-AID DRUG, V1, P195, DOI 10.2174/1573409053585663; TOPLISS JG, 1979, J MED CHEM, V22, P1238, DOI 10.1021/jm00196a017; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; Tropsha A, 2003, QSAR COMB SCI, V22, P69, DOI 10.1002/qsar.200390007; Trotter MWB, 2003, QSAR COMB SCI, V22, P533, DOI 10.1002/qsar.200310006; Vapnik V. N., 1995, NATURE STAT LEARNING; Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91; Votano JR, 2006, J MED CHEM, V49, P7169, DOI 10.1021/jm051245v; Wang YH, 2005, J COMPUT AID MOL DES, V19, P137, DOI 10.1007/s10822-005-3321-5; Wang YH, 2005, J CHEM INF MODEL, V45, P750, DOI 10.1021/ci050041k; Wang YH, 2005, BIOORG MED CHEM LETT, V15, P4076, DOI 10.1016/j.bmcl.2005.06.015; Whittaker J., 1990, GRAPHICAL MODELS APP; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Winkler DA, 2004, DRUG FUTURE, V29, P1043, DOI 10.1358/dof.2004.029.10.863395; Yamashita F, 2006, J CHEM INF MODEL, V46, P1054, DOI 10.1021/ci0504770; Yamashita F, 2008, J CHEM INF MODEL, V48, P364, DOI 10.1021/ci700262y; Yap CW, 2007, MINI-REV MED CHEM, V7, P1097, DOI 10.2174/138955707782331696; Yap CW, 2005, J CHEM INF MODEL, V45, P982, DOI 10.1021/ci0500536; Yap CW, 2006, CURR TOP MED CHEM, V6, P1593, DOI 10.2174/156802606778108942; Yin YH, 1996, NUCLEIC ACIDS RES, V24, P1279, DOI 10.1093/nar/24.7.1279; Yoo PD, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-272; Zhang LY, 2008, PHARM RES-DORDR, V25, P1902, DOI 10.1007/s11095-008-9609-0; Zhang SX, 2006, J CHEM INF MODEL, V46, P1984, DOI 10.1021/ci060132x; Zhao CY, 2006, PHARM RES, V23, P41, DOI 10.1007/s11095-005-8716-4; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799; 2008, INT C MACH LEARN MOD	165	10	10	6	14	INFORMA HEALTHCARE	LONDON	TELEPHONE HOUSE, 69-77 PAUL STREET, LONDON EC2A 4LQ, ENGLAND	1742-5255	1744-7607		EXPERT OPIN DRUG MET	Expert Opin. Drug Metab. Toxicol.	FEB	2009	5	2					149	169		10.1517/17425250902753261		21	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	419QH	WOS:000264233800005	19239395	
J	Frigui, H; Gader, P				Frigui, Hichem; Gader, Paul			Detection and Discrimination of Land Mines in Ground-Penetrating Radar Based on Edge Histogram Descriptors and a Possibilistic K-Nearest Neighbor Classifier	IEEE TRANSACTIONS ON FUZZY SYSTEMS			English	Article						Edge histogram descriptor; feature-based discrimination; land mine detection; possibilistic K-nearest neighbor (K-NN)	PATTERN-CLASSIFICATION; LANDMINES; GPR; RULE	This paper describes an algorithm for land mine detection using sensor data generated by a ground-penetrating radar (GPR) system that uses edge histogram descriptors for feature extraction and a possibilistic K-nearest neighbors (K-NNs) rule for confidence assignment. The algorithm demonstrated the best performance among several high-performance algorithms in extensive testing on a large real-world datasets associated with the difficult problem of land mine detection. The superior performance of the algorithm is attributed to the use of the possibilistic K-NN algorithm, thereby providing important evidence supporting the use of possibilistic methods in real-world applications. The GPR produces a 3-D array of intensity values, representing a volume below the surface of the ground. First, a computationally inexpensive pre-screening algorithm for anomaly detection is used to focus attention and identify candidate signatures that resemble mines. The identified regions of interest are processed further by a feature extraction algorithm to capture their salient features. We use translation-invariant features that are based on the local edge distribution of the 3-D GPR signatures. Specifically, each 3-D signature is divided into subsignatures, and the local edge distribution for each subsignature is represented by a histogram. Next, the training signatures are clustered to identify prototypes. The main idea is to identify few prototypes that can capture the variations of the signatures within each class. These variations could be due to different mine types, different soil conditions, different weather conditions, etc. Fuzzy memberships are assigned to these representatives to capture their degree of sharing among the mines and false alarm classes. Finally, a possibilistic K-NN-based rule is used to assign a confidence value to distinguish true detections from false alarms. The proposed algorithm is implemented and integrated within a complete land mine prototype system. It is trained, field-tested, evaluated, and compared using a large-scale cross-validation experiment that uses a diverse dataset acquired from four outdoor test sites at different geographic locations. This collection covers over 41807 m(2) of ground and includes 1593 mine encounters.	[Frigui, Hichem] Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA; [Gader, Paul] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	Frigui, H (reprint author), Univ Louisville, Dept Comp Sci & Comp Engn, Louisville, KY 40292 USA.	h.frigui@louisville.edu; pgader@cise.ufl.edu			National Science Foundation (NSF) [CBET-0730802, CBET-0730484]; Kentucky Science and Engineering Foundation [KSEF-148-502-05-153]; U.S. Army [DAAB 15-02-D-0003]; Office of Naval Research [N00014-05-10789]; Army Research Office and U.S. Army Research Laboratory [DAAD19-02-2-0012]	Manuscript received February 27, 2(K)S; revised June 23, 2008; accepted August 16, 2008. First published September 3, 2008; current version published February 4, 2009. This work was supported in part by (he National Science Foundation (NSF) under Award CBET-0730802 and Award CBET-0730484, by the Kentucky Science and Engineering Foundation under Grant KSEF-148-502-05-153, by the U.S. Army under Grant DAAB 15-02-D-0003, by the Office of Naval Research under Award N00014-05-10789, and by an Army Research Office and U.S. Army Research Laboratory under Cooperative Agreement DAAD19-02-2-0012.	Ayers L., 2004, MIDAS MINE DETECTION; Brunzell H, 1999, IEEE T GEOSCI REMOTE, V37, P875, DOI 10.1109/36.752207; Carevic D, 1999, P SOC PHOTO-OPT INS, V3710, P973, DOI 10.1117/12.357117; Carevic D., 1999, SPIE C DET REM TECHN, P1284; CHEN AT, 1999, IEEE T PATTERN ANAL, V21, P77; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dubois D., 1988, POSSIBILITY THEORY; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; FRIGUI H, 2007, P SPIE C DET REM TEC, V6553; FRIGUI H, 2006, P SPIE C DET REM TEC, P6217; Frigui H, 2005, EURASIP J APPL SIG P, V12, P1867; FRIGUI H, 2003, P IEEE INT C FUZZ SY, V2, P834; Gader P, 2004, IEEE T GEOSCI REMOTE, V42, P2522, DOI 10.1109/TGRS.2004.837333; Gader PD, 2004, P SOC PHOTO-OPT INS, V5415, P953, DOI 10.1117/12.544320; Gader PD, 2001, IEEE T GEOSCI REMOTE, V39, P1231, DOI 10.1109/36.927446; Gader PD, 2000, SIGNAL PROCESS, V80, P1069, DOI 10.1016/S0165-1684(00)00020-7; Gader PD, 1999, P SOC PHOTO-OPT INS, V3710, P1075, DOI 10.1117/12.356988; Gunatilaka A. H., 2000, P SPIE C DET REM TEC, VV, P1008; Hastie T, 1996, ADV NEUR IN, V8, P409; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; HINTZ KJ, 2004, P SPIE C DET REM TEC, V9, P399; Ho KC, 2008, IEEE T GEOSCI REMOTE, V46, P1177, DOI 10.1109/TGRS.2008.915747; JUIFENG H, 2004, P INT C SIGN PROC IC, V3, P2159; Kacprzyk J., 1997, ORDERED WEIGHTED AVE; KASKETT HT, 1999, P SPIE C DET REM TEC, P942; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; KRISHNAPURAM R, 1993, INT J FUZZY SYST, V2, P98; Lee WH, 2007, IEEE T GEOSCI REMOTE, V45, P389, DOI 10.1109/TGRS.2006.887018; Lopera O, 2007, IEEE T GEOSCI REMOTE, V45, P707, DOI 10.1109/TGRS.2006.888136; MacDonald J., 2003, ALTERNATIVES LANDMIN; Manjunath B. S., 2002, INTRO MPEG 7 MULTIME; Milisavljevic N, 2008, IEEE T GEOSCI REMOTE, V46, P1488, DOI 10.1109/TGRS.2008.916210; Nguyen TT, 2005, P SOC PHOTO-OPT INS, V5794, P198, DOI 10.1117/12.626263; OHKI M, 1991, IEEE T CONSUM ELECTR, V37, P66, DOI 10.1109/30.73648; Proakis John G, 1996, DIGITAL SIGNAL PROCE, VThird; Somasundaram SD, 2006, CLIMBING AND WALKING ROBOTS, P833, DOI 10.1007/3-540-26415-9_100; Stiles JM, 1999, P SOC PHOTO-OPT INS, V3710, P992, DOI 10.1117/12.357118; Tantum S.L., 2002, P SPIE C DET REM TEC, P728; Tax D. M. J., 2001, THESIS TU DELFT DELF; TORRIONE P, 2008, P SPIE C DET REM TEC, V6953; Torrione PA, 2006, IEEE T AERO ELEC SYS, V42, P644, DOI 10.1109/TAES.2006.1642579; *US DEP STAT, 1998, US DEP STAT PUBL; Wilson JN, 2007, IEEE T GEOSCI REMOTE, V45, P2560, DOI 10.1109/TGRS.2007.900993; Witten TR, 1998, PROC SPIE, V3392, P576, DOI 10.1117/12.324230; Won IJ, 2001, IEEE T GEOSCI REMOTE, V39, P703, DOI 10.1109/36.917876; Yang CC, 2005, IEEE T NEURAL NETWOR, V16, P743, DOI 10.1109/TNN.2005.844906; Yu SH, 1999, P SOC PHOTO-OPT INS, V3710, P961, DOI 10.1117/12.357116; Zahid N, 2001, FUZZY SET SYST, V120, P239, DOI 10.1016/S0165-0114(99)00074-3; ZHANG J, 2004, P INT S NEUR NETW 1, P636; 1998, UN MAGAZINE	51	51	51	1	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1063-6706			IEEE T FUZZY SYST	IEEE Trans. Fuzzy Syst.	FEB	2009	17	1					185	199		10.1109/TFUZZ.2008.2005249		15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	405LB	WOS:000263225100016		
J	Vaidya, J; Clifton, CW				Vaidya, Jaideep; Clifton, Christopher W.			Privacy-Preserving Kth Element Score over Vertically Partitioned Data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Privacy; security; kth element score; top-k queries		Given a large integer data set shared vertically by two parties, we consider the problem of securely computing a score separating the kth and the (k+1)th element. An efficient secure protocol is developed to compute such a score while revealing little additional information. The proposed protocol is implemented using the Fairplay system and experimental results are reported. We show a real application of this protocol as a component used in the secure processing of top-k queries over vertically partitioned data.	[Vaidya, Jaideep] Rutgers State Univ, Management Sci & Informat Syst Dept, Newark, NJ 07102 USA; [Clifton, Christopher W.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA	Vaidya, J (reprint author), Rutgers State Univ, Management Sci & Informat Syst Dept, 180 Univ Ave, Newark, NJ 07102 USA.	jsvaidya@business.rutgers.edu; clifton@cs.purdue.edu			US National Science Foundation [CNS-0746943, IIS-0428168]; Rutgers Business School	This material is based upon work supported by the US National Science Foundation under Grants CNS-0746943 and IIS-0428168 and by a Research Resources Grant from Rutgers Business School.	AGGARWAL G, 2004, P IACR INT C THEOR A; AGRAWAL R, 2003, P ACM SIGMOD 03 JUN; Bawa M., 2003, P 29 INT C VER LARG, P922, DOI 10.1016/B978-012722442-8/50086-0; Breunig Markus M., 2000, P ACM SIGMOD INT C M, P93, DOI DOI 10.1145/342009.335388; Bruno N, 2002, PROC INT CONF DATA, P369, DOI 10.1109/ICDE.2002.994751; Chaudhuri S., 1999, P 25 INT C VER LARG, P397; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Donjerkovic D, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P411; ERTOZ L, 2001, P TEXT MIN 1 SIAM IN; Fagin R, 2003, J COMPUT SYST SCI, V66, P614, DOI 10.1016/S0022-0000(03)00026-6; Fagin R., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, DOI 10.1145/237661.237715; Fagin R., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275488; Fagin R, 1999, J COMPUT SYST SCI, V58, P83, DOI 10.1006/jcss.1998.1600; Fischlin M, 2001, LECT NOTES COMPUT SC, V2020, P457; FREEDMAN MJ, 2004, P INT C THEOR APPL C; Goethals B, 2004, LECT NOTES COMPUT SC, V3506, P104; Goldreich O, 2004, FDN CRYPTOGRAPHY, V2; Ilyas Ihab F., 2003, P 29 INT C VER LARG, P754, DOI 10.1016/B978-012722442-8/50072-0; Ioannidis I, 2003, P 36 HAW INT C SYST, P205; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; JIANG W, 2007, P 7 SIAM INT C DAT M; Kantarcioglu M, 2004, IEEE T KNOWL DATA EN, V16, P1026, DOI 10.1109/TKDE.2004.45; Malkhi D., 2004, Proceedings of the 13th USENIX Security Symposium; POHLIG SC, 1978, IEEE T INFORM THEORY, V24, P106, DOI 10.1109/TIT.1978.1055817; Shaneck M, 2006, P 6 IEEE INT C DAT M, P541; Vaidya J., 2005, Journal of Computer Security, V13; Vaidya J., 2005, ADV INFORM SECURITY, V19; Yao A., 1986, P 27 IEEE S FDN COMP, P162, DOI DOI 10.1109/SFCS.1986.25; Zhang N., 2005, P 31 INT C VER LARG, P889; 2003, SIGKDD EXPLORATIONS, V4, P48	30	6	7	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347	1558-2191		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	FEB	2009	21	2					253	258		10.1109/TKDE.2008.167		6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	385KT	WOS:000261813800007		
J	Perez, A; Larranaga, P; Inza, I				Perez, Aritz; Larranaga, Pedro; Inza, Inaki			Bayesian classifiers based on kernel density estimation: Flexible classifiers	INTERNATIONAL JOURNAL OF APPROXIMATE REASONING			English	Article						Bayesian network; Kernel density estimation; Supervised classification; Flexible naive Bayes	NETWORK CLASSIFIERS; CLASSIFICATION; EQUIVALENCE; VARIANCE; MIXTURES; BIAS	When learning Bayesian network based classifiers continuous variables are usually handled by discretization, or assumed that they follow a Gaussian distribution. This work introduces the kernel based Bayesian network paradigm for supervised classification. This paradigm is a Bayesian network which estimates the true density of the continuous variables using kernels. Besides, tree-augmented naive Bayes, k-dependence Bayesian classifier and complete graph classifier are adapted to the novel kernel based Bayesian network paradigm. Moreover, the strong consistency properties of the presented classifiers are proved and an estimator of the mutual information based on kernels is presented. The classifiers presented in this work can be seen as the natural extension of the flexible naive Bayes classifier proposed by John and Langley [G.H. John, P. Langley, Estimating continuous distributions in Bayesian classifiers, in: Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence, 1995, pp. 338-345], breaking with its strong independence assumption. Flexible tree-augmented naive Bayes seems to have superior behavior for supervised classification among the flexible classifiers. Besides, flexible classifiers presented have obtained competitive errors compared with the state-of-the-art classifiers. (C) 2008 Elsevier Inc. All rights reserved.	[Perez, Aritz; Larranaga, Pedro; Inza, Inaki] Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Madrid, Spain	Perez, A (reprint author), Univ Basque Country, Intelligent Syst Grp, Dept Comp Sci & Artificial Intelligence, Madrid, Spain.	aritz.perez@ehu.es; pedro.larranaga@ehu.es; inza@si.ehu.es	Larranaga, Pedro/F-9293-2013		Etortek, Saiotek and Research Groups [2007-2012 (IT-242-07)]; Basque Goverment [TIN2005-03824]; Consolider Ingenio [2010-CSD2007-00018]; Spanish Ministry of Education and Science; COMBIOMED	First, thanks to the helpful comments of the anonymous reviewers which have improved the quality of the paper. This work has been possible thanks to the Ph.D. grant Beca para la Formacion de Investigadores 2003-07 of the Basque Government. This work has been also supported by the Etortek, Saiotek and Research Groups 2007-2012 (IT-242-07) programs (Basque Goverment), TIN2005-03824 and Consolider Ingenio 2010-CSD2007-00018 projects (Spanish Ministry of Education and Science) and COMBIOMED network in computational biomedicine (Carlos III Health Institute).	Aladjem M, 2005, IEEE T SIGNAL PROCES, V53, P4376, DOI 10.1109/TSP.2005.857007; ALADJEM M, 2002, LECT NOTES COMPUTER, V2396, P396; Bilmes J. A., 1997, ICSITR97021 U BERK; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C. M., 1999, LEARNING GRAPHICAL M, P371; Bishop C.M., 1995, NEURAL NETWORKS PATT; Bottcher SG, 2004, THESIS AALBORG U; BOUCKAERT R, 2004, P 17 AUSTR C ART INT, P1089; Casella G., 1990, STAT INFERENCE; Castillo E., 1997, EXPERT SYSTEMS PROBA; Cheng J., 1999, P 15 C UNC ART INT U, P101; Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Cormen T.H., 2003, INTRO ALGORITHMS; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Groot Morris, 1970, OPTIMAL STAT DECISIO; DELAIGLE A, 2002, COMPUTATIONAL STAT D, V39, P1; Demsar J, 2006, J MACH LEARN RES, V7, P1; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; Diamantidis NA, 2000, ARTIF INTELL, V116, P1, DOI 10.1016/S0004-3702(99)00094-6; Domingos P., 2000, P 17 INT C MACH LEAR, P231; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P 12 INT C MACH LEAR, P194; Duda R. O., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; FIGUEIREDO MAT, 1999, LECT NOTES COMPUTER, V1654, P732; Frank E., 2005, DATA MINING PRACTICA; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; FUKUNAGA K, 1972, STAT PATTERN RECOGNI; Geiger D., 1994, LEARNING GAUSSIAN NE; German S., 1992, NEURAL COMPUT, V4, P1; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GREINER R, 2005, MACH LEARN, V59, P97; GURWICZ Y, 2004, P 17 INT C PATT REC, V3, P700, DOI 52224783,12,1; Gurwicz Y, 2005, PATTERN RECOGN LETT, V26, P1761, DOI 10.1016/j.patrec.2004.12.008; Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x; James GM, 2003, MACH LEARN, V51, P115, DOI 10.1023/A:1022899518027; Jebara T., 2004, MACHINE LEARNING DIS; John G.H., 1995, P 11 C UNC ART INT, P338; Kohavi R, 1995, INT JOINT C ART INT, V14, P1137; Kohavi R., 1995, THESIS STANFORD U; KOHAVI R, 1997, IMPROVING SIMPLE BAY; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kohavi R., 1996, ICML, P275; Kononerko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1992, P 10 NAT C ART INT, P223; Lauritzen S. L., 1996, GRAPHICAL MODELS; LAURITZEN SL, 1989, ANN STAT, V17; LAURITZEN SL, 1984, 848 AALB U I EL SYST; Lerner B, 2001, NEURAL COMPUT APPL, V10, P39, DOI 10.1007/s005210170016; Lerner B, 2004, ARTIF INTELL MED, V30, P301, DOI 10.1016/j.artmed.2003.11.005; Lozano J. A., 2002, ESTIMATION DISTRIBUT; McLachlan G., 2000, FINITE MIXTURE MODEL; Minsky M., 1961, T I RADIO ENG, V49, P8; MOON YI, 1995, PHYS REV E, V52, P2318, DOI 10.1103/PhysRevE.52.2318; MORAL S, 2002, 1 EUR WHORKSH PROB G, P156; Murphy PM, 1995, UCI REPOSITORY MACHI; Neapolitan R. E., 2003, LEARNING BAYESIAN NE; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PAZZANI M, 1997, LEARNING DATA ARTIFI, V5, P239; Pearl J, 1988, PROBABILISTIC REASON; Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002; Perez A, 2006, LECT NOTES ARTIF INT, V4265, P347; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1986, MACH LEARN, V1, P106; Raudys S., 1991, Informatica, V2; Romero V, 2006, INT J APPROX REASON, V42, P54, DOI 10.1016/j.ijar.2005.10.004; Roos T, 2005, MACH LEARN, V59, P267; Rosenblatt F., 1959, PRINCIPLES NEURODYNA; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; SANTAFE G, 2005, P 8 EUR C SYMB QUANT, P148; Scott DW, 2001, TECHNOMETRICS, V43, P323, DOI 10.1198/004017001316975916; Scott D.W., 1992, MULTIVARIATE DENSITY; Silverman BW, 1986, DENSITY ESTIMATION S; Simonoff J. S., 1996, SMOOTHING METHODS ST; Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99; Wand M.P., 1995, MONOGRAPHS STAT APPL; YANG Y, 2003, 2003131 MON U SCH CO; Zhou A., 2003, P 8 INT C DAT SYST A, P285	82	26	33	1	5	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0888-613X			INT J APPROX REASON	Int. J. Approx. Reasoning	FEB	2009	50	2					341	362		10.1016/j.ijar.2008.08.008		22	Computer Science, Artificial Intelligence	Computer Science	421LD	WOS:000264359500014		
J	Weinberger, KQ; Saul, LK				Weinberger, Kilian Q.; Saul, Lawrence K.			Distance Metric Learning for Large Margin Nearest Neighbor Classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						convex optimization; semi-definite programming; Mahalanobis distance; metric learning; multi-class classification; support vector machines	RECOGNITION	The accuracy of k-nearest neighbor (kNN) classification depends significantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classification from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classification using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modification or extension for problems in multiway (as opposed to binary) classification. In our framework, the Mahalanobis distance metric is obtained as the solution to a semidefinite program. On several data sets of varying size and difficulty, we find that metrics trained in this way lead to significant improvements in kNN classification. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.	[Weinberger, Kilian Q.] Yahoo Res, Santa Clara, CA USA; [Saul, Lawrence K.] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA	Weinberger, KQ (reprint author), Yahoo Res, 2821 Mission Coll Blvd, Santa Clara, CA USA.	KILIAN@YAHOO-INC.COM; SAUL@CS.UCSD.EDU			NSF [0238323]	We especially thank John C. Blitzer for his many suggestions to improve the algorithm and his generous help with various data sets. We also thank Koby Crammer for many useful comments and suggestions. This work was supported by NSF Award 0238323.	Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Beygelzimer A., 2006, P 23 INT C MACH LEAR, P97, DOI 10.1145/1143844.1143857; BILENKO M, 2004, P 21 INT C MACH LEAR, P839; Boyd S., 2004, CONVEX OPTIMIZATION; Chopra S., 2005, P IEEE C COMP VIS PA, P349; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2001, J MACHINE LEARNING R, V2, P265; DASGUPTA S, 1999, 99006 UC BERK INT CO; De Bie T, 2003, LECT NOTES ARTIF INT, V2842, P175; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2; Fisher RA, 1936, ANN EUGENIC, V7, P179; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; Globerson A., 2006, ADV NEURAL INFORM PR, V18; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P513; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; KUMARA MT, 2007, J NANOSCI NANOTECHNO, V7, P1; Kwok J.T., 2003, P 20 INT C MACH LEAR, P400; Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27; LeCun Y., 1995, P INT C ART NEUR NET, P53; Liu T, 2005, ADV NEURAL INFORM PR, V17, P825; McCallum A.K., 1996, BOW TOOLKIT STAT LAN; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Omohundro S. M., 1987, Complex Systems, V1; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shalev-Shwartz S, 2004, P 21 INT C MACH LEAR, P94; SHENTAL N, 2002, P 7 EUR C COMP VIS C, V4, P776; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888; Simard P. Y., 1993, ADV NEURAL INFORM PR, V6, P50; Smola P., 2002, LEARNING KERNELS SUP; Torresani L., 2007, ADV NEURAL INFORM PR, V19, P1385; TSANG IW, 2005, P 2005 IEEE INT JOIN, V2, P954, DOI 10.1109/IJCNN.2005.1555981; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Varma M., 2007, P IEEE INT C COMP VI, P1; Weinberger K., 2005, ADV NEURAL INFORM PR, V18, P1473; Weinberger K. Q., 2008, P 25 INT C MACH LEAR, P1160, DOI 10.1145/1390156.1390302; Xing E., 2002, ADV NEURAL INFORM PR, V14, P521	40	344	363	12	26	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2009	10						207	244				38	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	507BG	WOS:000270824200005		
J	Lozano, A; Manfredi, G; Nieddu, L				Lozano, Angelica; Manfredi, Giuseppe; Nieddu, Luciano			An algorithm for the recognition of levels of congestion in road traffic problems	MATHEMATICS AND COMPUTERS IN SIMULATION			English	Article	6th Pan-American Workshop on Applied and Computational Mathematics	JUL 23-28, 2006	Oaxaca, MEXICO	Third PanAmer Adv Studies Inst, Computat Sci & Engn, USA Natl Sci Fdn, DOE		Vehicle detection; Image recognition; Traffic information	PROCESSING TECHNIQUES; PATTERN-RECOGNITION; CLASSIFICATION	Detection and recognition of the level of congestion at an intersection is a very important problem and a valuable source of information in traffic management. Although it is just one of all the aspects that make up a traffic management system, it seems to be a crucial point for gathering information. In this paper, we present a technique based on a k-means clustering algorithm for classification, which has been already successfully used in a number of pattern recognition problems, namely: as an algorithm for face recognition problems and in a number of medical diagnosis problems and it compares very well with the state of the art techniques. (C) 2007 IMACS. Published by Elsevier B.V. All rights reserved.	[Nieddu, Luciano] Libera Univ S Pio V, Dept Econ, Rome, Italy; [Lozano, Angelica] Univ Nacl Autonoma Mexico, Inst Ingn, Lab Transporte & Sistemas Territoriales, Mexico City, DF, Mexico; [Manfredi, Giuseppe] Libera Univ S Pio V, Dept Polit Sci, Rome, Italy	Nieddu, L (reprint author), Libera Univ S Pio V, Dept Econ, Rome, Italy.	alozanoc@iingen.unam.mx; g.manfredi@luspio.it; l.nieddu@luspio.it					Bellman R., 1961, ADAPTIVE CONTROL PRO; Cifarelli C, 2007, COMPUT OPER RES, V34, P3154, DOI 10.1016/j.cor.2005.11.023; Cochran W. G., 1977, SAMPLING TECHNIQUES, V3rd; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; David SHESKIN, 2000, HDB PARAMETRIC NONPA; Duda R. O., 1973, PATTERN CLASSIFICATI; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Firschein O., 1963, IEEE Transactions on Electronic Computers, VEC-12; Fix E., 1951, 2149004 US AIR FORC; Gordon A. D., 1981, CLASSIFICATION; Grimaldi G., 2002, CENTRAL EUROPEAN J O, V10, P29; Hand DJ, 1981, DISCRIMINATION CLASS; Harlow C, 2001, TRANSPORT RES C-EMER, V9, P231, DOI 10.1016/S0968-090X(00)00034-6; Hastie T, 2001, ELEMENTS STAT LEARNI; Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0; KATRE UA, 1989, PATTERN RECOGN, V22, P423, DOI 10.1016/0031-3203(89)90051-4; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Nieddu L, 2000, EUR J OPER RES, V120, P459, DOI 10.1016/S0377-2217(98)00368-3; NIEDDU L, 2001, APPROXIMATION OPTIMI; NIEDDU L, 1999, THESIS U ROME; PATRIZI G, RICERCA OPERATIVA, V10; Siyal MY, 1999, REAL-TIME IMAGING, V5, P271, DOI 10.1006/rtim.1998.0140; Tibshirani R, 1993, INTRO BOOTSTRAP; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Watanabe S., 1985, PATTERN RECOGNITION; Zhang X, 1997, TRANSPORT RES C-EMER, V5, P141, DOI 10.1016/S0968-090X(97)00007-7	27	7	9	1	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0378-4754			MATH COMPUT SIMULAT	Math. Comput. Simul.	FEB	2009	79	6					1926	1934		10.1016/j.matcom.2007.06.008		9	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Mathematics, Applied	Computer Science; Mathematics	417RG	WOS:000264093700011		
J	Yang, CY; Hsu, CC; Yang, JS				Yang, Chan-Yun; Hsu, Che-Chang; Yang, Jr-Syu			Stray Example Sheltering by Loss Regularized SVM and kNN Preprocessor	NEURAL PROCESSING LETTERS			English	Article						k-nearest-neighbor preprocessor; Stray training examples; Support vector machines; Classification; Pattern recognition	RISK MINIMIZATION; CLASSIFICATION	This paper presents a new model developed by merging a non-parametric k-nearest-neighbor (kNN) preprocessor into an underlying support vector machine (SVM) to provide shelters for meaningful training examples, especially for stray examples scattered around their counterpart examples with different class labels. Motivated by the method of adding heavier penalty to the stray example to attain a stricter loss function for optimization, the model acts to shelter stray examples. The model consists of a filtering kNN emphasizer stage and a classical classification stage. First, the filtering kNN emphasizer stage was employed to collect information from the training examples and to produce arbitrary weights for stray examples. Then, an underlying SVM with parameterized real-valued class labels was employed to carry those weights, representing various emphasized levels of the examples, in the classification. The emphasized weights given as heavier penalties changed the regularization in the quadratic programming of the SVM, and brought the resultant decision function into a higher training accuracy. The novel idea of real-valued class labels for conveying the emphasized weights provides an effective way to pursue the solution of the classification inspired by the additional information. The adoption of the kNN preprocessor as a filtering stage is effective since it is independent of SVM in the classification stage. Due to its property of estimating density locally, the kNN method has the advantage of distinguishing stray examples from regular examples by merely considering their circumstances in the input space. In this paper, detailed experimental results and a simulated application are given to address the corresponding properties. The results show that the model is promising in terms of its original expectations.	[Yang, Chan-Yun] Technol & Sci Inst No Taiwan, Dept Mech Engn, Taipei 112, Taiwan; [Hsu, Che-Chang; Yang, Jr-Syu] Tamkang Univ, Dept Mech & Electromech Engn, Tamsui 25137, Taipei County, Taiwan	Yang, CY (reprint author), Technol & Sci Inst No Taiwan, Dept Mech Engn, 2 Xue Yuan Rd, Taipei 112, Taiwan.	cyyang.research@gmail.com; 692342792@s92.tku.edu.tw; 096034@mail.tku.edu.tw		Yang, Chan-Yun/0000-0001-5329-6368			BARTLETT PL, 2003, 638 DEP STAT; BREIMAN L, 1996, 460 DEP STAT; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; FUKUNAGA K, 1990, STAT PATTERN RECOGNI, V2; Hastie T, 2001, ELEMENTS STAT LEARNI; HSU CC, 2005, INT C COMP INT SEC X, P550; Murphy PM, 1995, UCI BENCHMARK REPOSI; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J, 1998, IEEE T INFORM THEORY, V44, P1926, DOI 10.1109/18.705570; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Vlachos P., 1989, STATLIB; Webb AR, 2002, STAT PATTERN RECOGNI, V2; YANG CY, 2003, IEEE INT C COMP CYB; YANG CY, 2006, INT C COMP INT SEC G, P172; Zhang T, 2004, ANN STAT, V32, P56	21	1	1	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621			NEURAL PROCESS LETT	Neural Process. Lett.	FEB	2009	29	1					7	27		10.1007/s11063-008-9092-y		21	Computer Science, Artificial Intelligence; Neurosciences	Computer Science; Neurosciences & Neurology	407SI	WOS:000263384200002		
J	Orozco-Alzate, M; Duin, RPW; Castellanos-Dominguez, G				Orozco-Alzate, Mauricio; Duin, Robert P. W.; Castellanos-Dominguez, German			A generalization of dissimilarity representations using feature lines and feature planes	PATTERN RECOGNITION LETTERS			English	Article						Dissimilarity; Representation; Feature lines; Feature planes; Generalization	NEAREST FEATURE LINE; FACE RECOGNITION; PATTERN-CLASSIFICATION; FEATURE CLASSIFIERS; RETRIEVAL	Even though, under representational restrictions, the nearest feature rules and the dissimilarity-based classifiers are feasible alternatives to the nearest neighbor method; individually, they may not be sufficiently powerful if a very small set of prototypes is required, e.g. when it is computationally expensive to deal with larger sets of prototypes. In this paper, we show that combining both strategies, taking advantage of their individual properties, provides an improvement, particularly for correlated data sets. The combined strategy consists in deriving an enriched (generalized) dissimilarity representation by using the nearest feature rules, namely feature lines and feature planes. On top of that enriched representation, Bayesian classifiers can be constructed in order to obtain a good generalization. (C) 2008 Elsevier B.V. All rights reserved.	[Orozco-Alzate, Mauricio] Univ Nacl Colombia, Dept Informat & Computac, Manizales, Caldas, Colombia; [Duin, Robert P. W.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Informat & Commun Theory Grp, NL-2600 GA Delft, Netherlands; [Orozco-Alzate, Mauricio; Castellanos-Dominguez, German] Univ Nacl Colombia, Grp Control & Procesamiento Digital Senales, Manizales, Caldas, Colombia	Orozco-Alzate, M (reprint author), Univ Nacl Colombia, Dept Informat & Computac, Kilometro 7 Via Aeropuerto,Campus Nubia Bloque Q, Manizales, Caldas, Colombia.	morozcoa@bt.unal.edu.co; r.p.w.duin@tudelft.nl; cgcastellanosd@unal.edu.co	Orozco-Alzate, Mauricio/B-4911-2014		TU Delft Research; Universidad Nacional de Colombia [UN-VRI-20201004224]; Delft University of Technology; The Netherlands	This work is supported by a TU Delft Research Grant, the Scholarship Program for Outstanding Postgraduate Students from Universidad Nacional de Colombia and the research project UN-VRI-20201004224 (Universidad Nacional de Colombia). The work was undertaken while the first author was a Research Fellow at Delft University of Technology, The Netherlands.	Chen K, 2002, PATTERN RECOGN LETT, V23, P1735, DOI 10.1016/S0167-8655(02)00147-2; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Veld DCG, 2003, LASER SURG MED, V32, P367, DOI 10.1002/lsm.10185; Du H, 2007, PATTERN RECOGN, V40, P1486, DOI 10.1016/j.patcog.2006.10.021; DUIN RPW, 2002, P PRIS 2002 2002 INT, P20; Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; HIGHLEYMAN WH, 1962, P IRE, V50, P1501, DOI 10.1109/JRPROC.1962.288194; Kuncheva LI, 2005, REAL MED DATA SETS; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Orozco-Alzate M, 2006, MACH VISION APPL, V17, P279, DOI 10.1007/s00138-006-0037-z; Pekalska E, 2005, SER MACH PERCEPT ART, V64, P1, DOI 10.1142/9789812703170; PEKALSKA E, 2006, ICPR 06, V3, P137; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Pekalska E., 2001, J MACHINE LEARNING R, V2, P175; Pekalska E, 2006, PATTERN RECOGN, V39, P189, DOI 10.1016/j.patcog.2005.06.012; RPW Duin, 2004, MATLAB TOOLBOX PATTE; TOUSSAINT GT, 1982, PATTERN RECOGN, P569; Uspensky J.V., 1948, THEORY EQUATIONS; Zheng WM, 2004, PATTERN RECOGN, V37, P1307, DOI 10.1016/j.patcog.2003.11.004	24	6	6	0	1	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	FEB 1	2009	30	3					242	254		10.1016/j.patrec.2008.09.010		13	Computer Science, Artificial Intelligence	Computer Science	402XA	WOS:000263045200008		
J	Diaz, NN; Krause, L; Goesmann, A; Niehaus, K; Nattkemper, TW				Diaz, Naryttza N.; Krause, Lutz; Goesmann, Alexander; Niehaus, Karsten; Nattkemper, Tim W.			TACOA - Taxonomic classification of environmental genomic fragments using a kernelized nearest neighbor approach	BMC BIOINFORMATICS			English	Article							HORIZONTAL GENE-TRANSFER; PHYLOGENETIC CLASSIFICATION; DNA FRAGMENTS; PREDICTION; SEQUENCES; BACTERIAL; DATABASE; PROKARYOTES; FREQUENCIES; ALGORITHMS	Background: Metagenomics, or the sequencing and analysis of collective genomes (metagenomes) of microorganisms isolated from an environment, promises direct access to the "unculturable majority". This emerging field offers the potential to lay solid basis on our understanding of the entire living world. However, the taxonomic classification is an essential task in the analysis of metagenomics data sets that it is still far from being solved. We present a novel strategy to predict the taxonomic origin of environmental genomic fragments. The proposed classifier combines the idea of the k-nearest neighbor with strategies from kernel-based learning. Results: Our novel strategy was extensively evaluated using the leave-one-out cross validation strategy on fragments of variable length (800 bp - 50 Kbp) from 373 completely sequenced genomes. TACOA is able to classify genomic fragments of length 800 bp and 1 Kbp with high accuracy until rank class. For longer fragments >= 3 Kbp accurate predictions are made at even deeper taxonomic ranks (order and genus). Remarkably, TACOA also produces reliable results when the taxonomic origin of a fragment is not represented in the reference set, thus classifying such fragments to its known broader taxonomic class or simply as "unknown". We compared the classification accuracy of TACOA with the latest intrinsic classifier PhyloPythia using 63 recently published complete genomes. For fragments of length 800 bp and 1 Kbp the overall accuracy of TACOA is higher than that obtained by PhyloPythia at all taxonomic ranks. For all fragment lengths, both methods achieved comparable high specificity results up to rank class and low false negative rates are also obtained. Conclusion: An accurate multi-class taxonomic classifier was developed for environmental genomic fragments. TACOA can predict with high reliability the taxonomic origin of genomic fragments as short as 800 bp. The proposed method is transparent, fast, accurate and the reference set can be easily updated as newly sequenced genomes become available. Moreover, the method demonstrated to be competitive when compared to the most current classifier PhyloPythia and has the advantage that it can be locally installed and the reference set can be kept up-to-date.	[Diaz, Naryttza N.; Goesmann, Alexander] Univ Bielefeld, Ctr Biotechnol CeBiTec, Bielefeld, Germany; [Diaz, Naryttza N.; Nattkemper, Tim W.] Univ Bielefeld, Biodata Min & Appl Neuroinformat Grp, Fac Technol, Bielefeld, Germany; Univ Bielefeld, Fac Biol, Proteome & Metabolome Res, Bielefeld, Germany; [Krause, Lutz] Nestle Res Ctr, BioAnalyt Sci Dept, CH-1000 Lausanne, Switzerland	Diaz, NN (reprint author), Univ Bielefeld, Ctr Biotechnol CeBiTec, Bielefeld, Germany.	ndiaz@CeBiTec.Uni-Bielefeld.DE; Lutz.Krause@rdls.nestle.com; agoesman@CeBiTec.Uni-Bielefeld.DE; karsten.niehaus@CeBiTec.Uni-Bielefeld.DE; tim.nattkemper@Uni-Bielefeld.DE	Niehaus, Karsten/A-3966-2010; Krause, Lutz/G-6283-2013	Krause, Lutz/0000-0003-3806-0845	Deutscher Akademischer Austauschdienst	NND was supported by the Deutscher Akademischer Austauschdienst. The authors wish to thank Torsten Kasch, Achim Neumann, Ralf Nolte, Bjrn Fischer and Volker Tlle as members of the Bioinformatics Resource Facility for providing the computational and technical support to accomplish this work. We thank I. Rigoutsos from the Bioinformatics and Pattern Discovery Group, IBM Thomas J Watson Research Center for all the help in using the PhyloPythia web server.	Abe T, 2005, DNA RES, V12, P281, DOI 10.1093/dnares/dsi015; ABE T, 2006, POLAR BIOSCI, V20, P103; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Berrar D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-73; Bohlin J, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-104; Bohlin J, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000057; Brown JR, 2003, NAT REV GENET, V4, P121, DOI 10.1038/nrg1000; Campbell A, 1999, P NATL ACAD SCI USA, V96, P9184, DOI 10.1073/pnas.96.16.9184; Chan CKK, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-215; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Finn RD, 2008, NUCLEIC ACIDS RES, V36, pD281, DOI 10.1093/nar/gkm960; FLEISCHMANN RD, 1995, SCIENCE, V269, P496, DOI 10.1126/science.7542800; Foerstner KU, 2005, EMBO REP, V6, P1208, DOI 10.1038/sj.embor.7400538; Garcia-Vallve S, 2000, GENOME RES, V10, P1719, DOI 10.1101/gr.130000; Hastie T., 2002, ELEMENTS STAT LEARNI; Huson DH, 2007, GENOME RES, V17, P377, DOI 10.1101/gr.5969107; Karlin S, 1997, J BACTERIOL, V179, P3899; Keeling PJ, 2008, NAT REV GENET, V9, P605, DOI 10.1038/nrg2386; Koonin EV, 2001, ANNU REV MICROBIOL, V55, P709, DOI 10.1146/annurev.micro.55.1.709; Krause L, 2008, J BIOTECHNOL, V136, P91, DOI 10.1016/j.jbiotec.2008.06.003; Krause L, 2008, NUCLEIC ACIDS RES, V36, P2230, DOI 10.1093/nar/gkn038; Margulies M, 2005, NATURE, V437, P376, DOI 10.1038/nature03959; McHardy AC, 2007, NAT METHODS, V4, P63, DOI 10.1038/NMETH976; Overbeek R, 2005, NUCLEIC ACIDS RES, V33, P5691, DOI 10.1093/nar/gki866; Podell S, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-2-r16; Raes J, 2007, CURR OPIN MICROBIOL, V10, P490, DOI 10.1016/j.mib.2007.09.001; Ruepp A, 2000, NATURE, V407, P508; Saha S, 2006, GENET MOL RES, V5, P224; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Sandberg R, 2001, GENOME RES, V11, P1404, DOI 10.1101/gr.186401; SANGER F, 1977, P NATL ACAD SCI USA, V74, P5463, DOI 10.1073/pnas.74.12.5463; Stein JL, 1996, J BACTERIOL, V178, P591; Teeling H, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-163; Teeling H, 2004, ENVIRON MICROBIOL, V6, P938, DOI 10.1111/j.1462-2920.2004.00624.x; Tran TN, 2006, COMPUT STAT DATA AN, V51, P513, DOI 10.1016/j.csda.2005.10.001; Tyson GW, 2004, NATURE, V428, P37, DOI 10.1038/nature02340; Venter JC, 1998, SCIENCE, V280, P1540, DOI 10.1126/science.280.5369.1540; Wheeler DL, 2002, NUCLEIC ACIDS RES, V30, P13, DOI 10.1093/nar/30.1.13; Yao ZZ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S1-S11; ZHANG SH, 2008, NATURE PRECEDINGS, P1; Zhu M, 2007, BMC MED INFORM DECIS, V7, DOI 10.1186/1472-6947-7-41	42	70	73	0	9	BIOMED CENTRAL LTD	LONDON	CURRENT SCIENCE GROUP, MIDDLESEX HOUSE, 34-42 CLEVELAND ST, LONDON W1T 4LB, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	FEB 11	2009	10								56	10.1186/1471-2105-10-56		16	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	416LP	WOS:000264007900001	19210774	
J	Satapathy, SC; Murthy, JVR; Reddy, PVGDP; Misra, BB; Dash, PK; Panda, G				Satapathy, Suresh Chandra; Murthy, J. V. R.; Reddy, P. V. G. D. Prasad; Misra, B. B.; Dash, P. K.; Panda, G.			Particle swarm optimized multiple regression linear model for data classification	APPLIED SOFT COMPUTING			English	Article						Particle swarm optimization (PSO); Least square estimation; Multiple linear regression	PATTERN-CLASSIFICATION; CLASSIFIERS	This paper presents a new data classification method based on particle swarm optimization (PSO) techniques. The paper discusses the building of a classifier model based on multiple regression linear approach. The coefficients of multiple regression linear models (MRLMs) are estimated using least square estimation technique and PSO techniques for percentage of correct classification performance comparisons. The mathematical models are developed for many real world datasets collected from UCI machine repository. The mathematical models give the user an insight into how the attributes are interrelated to predict the class membership. The proposed approach is illustrated on many real data sets for classification purposes. The comparison results on the illustrative examples show that the PSO based approach is superior to traditional least square approach in classifying multi-class data sets. (c) 2008 Elsevier B.V. All rights reserved.	[Satapathy, Suresh Chandra] Anil Neerukonda Inst Technol & Sci, Vishakapatnam, Andhra Pradesh, India; [Murthy, J. V. R.] JNTU Coll Engn, Kakinada, India; [Misra, B. B.; Dash, P. K.] Coll Engn, Bhubaneswar, Orissa, India; [Panda, G.] Natl Inst Technol, Rourkela, India	Satapathy, SC (reprint author), Anil Neerukonda Inst Technol & Sci, Vishakapatnam, Andhra Pradesh, India.	sureshsatapathy@ieee.org					Adem J, 2006, EUR J OPER RES, V168, P181, DOI 10.1016/j.ejor.2004.04.031; Blake C, 1998, UCI REPOSITORY MACHI; Bojarczuk CC, 2000, IEEE ENG MED BIOL, V19, P38, DOI 10.1109/51.853480; Buntine W., 1992, Statistics and Computing, V2, DOI 10.1007/BF01889584; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 1973, PATTERN CLASSIFICATI; Eberhart RC, 2000, IEEE C EVOL COMPUTAT, P84, DOI 10.1109/CEC.2000.870279; ERENGUC SS, 1990, MANAGE DECIS ECON, V11, P215, DOI 10.1002/mde.4090110403; Friedman J.H., 1984, CLASSIFICATION REGRE; HANSON R, 1992, P 12 INT JOINT C ART, P692; Kenneth J, 1995, P IEEE INT C NEUR NE, P1942, DOI DOI 10.1109/ICNN.1995.488968; Kennedy J, 2002, IEEE C EVOL COMPUTAT, P1671; Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235; KOZA JR, 1992, PROGRAMMING PROGRAMS; Lawson CL, 1974, SOLVING LEAST SQUARE; Michie D., 1994, MACHINE LEARNING NEU; MORF M, 1975, IEEE T AUTOMAT CONTR, V20, P487, DOI 10.1109/TAC.1975.1100994; Muni DP, 2004, IEEE T EVOLUT COMPUT, V8, P183, DOI 10.1109/TEVC.2004.825567; RAUSS PJ, 2000, P GEN EV COMP C GECC, P726; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Tsoi A. C., 1991, ADV NEURAL INFORMATI, V3, P963	21	8	8	3	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1568-4946			APPL SOFT COMPUT	Appl. Soft. Comput.	MAR	2009	9	2					470	476		10.1016/j.asoc.2008.05.007		7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	400SE	WOS:000262888100003		
J	Zeng, Y; Yang, YP; Zhao, L				Zeng, Yong; Yang, Yupu; Zhao, Liang			Pseudo nearest neighbor rule for pattern classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						The k-nearest neighbor classification rule (k-NNR); Pseudo nearest neighbor classification rule (PNNR); Distance weighted k-nearest neighbor rule; The local mean-based learning; Pseudo nearest neighbor (PNN)		In this paper, we propose a new pseudo nearest neighbor classification rule (PNNR). It is different from the previous nearest neighbor rule (NNR), this new rule utilizes the distance weighted local learning in each class to get a new nearest neighbor of the unlabeled pattern-pseudo nearest neighbor (PNN), and then assigns the label associated with the PNN for the unlabeled pattern using the NNR. The proposed PNNR is compared with the k-NNR, distance weighted k-NNR, and the local mean-based nonparametric classification [Mitani, Y., & Hamamoto, Y. (2006). A local mean-based nonparametric classifier. Pattern Recognition Letters, 27, 1151-1159] in terms of the classification accuracy oil the unknown patterns. Experimental results confirm the validity of this new classification rule even in practical situations. (C) 2008 Elsevier Ltd. All rights reserved.	[Zeng, Yong; Yang, Yupu; Zhao, Liang] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China	Zeng, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.	zeng_yong@sjtu.cdu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NOR; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Ferri FJ, 1999, IEEE T SYST MAN CY B, V29, P667, DOI 10.1109/3477.790454; FIX E, 1951, TR4 USAF SCH AV MED; Fukunaga K., 1990, INTRO STAT PATTERN R; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Kohavi R., 1997, P 9 EUR C MACH LEARN; Merz C. J., 1996, UCI REPOSITORY MACHI; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; MORIN RL, 1981, IEEE T SYST MAN CYB, V11, P241; Paredes R, 2000, PATTERN RECOGN LETT, V21, P1027, DOI 10.1016/S0167-8655(00)00064-7; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Ricci F, 1999, IEEE T PATTERN ANAL, V21, P380, DOI 10.1109/34.761268; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6; Wilson D. R., 1996, Proceedings of the IASTED International Conference. Artificial Intelligence, Expert Systems and Neural Networks	18	7	8	2	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	MAR	2009	36	2					3587	3595		10.1016/j.eswa.2008.02.003		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	390QF	WOS:000262178100105		
J	van den Bosch, A; van Erp, M; Sporleder, C				van den Bosch, Antal; van Erp, Marieke; Sporleder, Caroline			Making a Clean Sweep of Cultural Heritage	IEEE INTELLIGENT SYSTEMS			English	Article									[van den Bosch, Antal; van Erp, Marieke] Tilburg Univ, Tilburg, Netherlands	van den Bosch, A (reprint author), Tilburg Univ, Tilburg, Netherlands.	antal.vdnbosch@uvt.nl; m.g.j.vanerp@uvt.nl; csporled@coli.uni-sb.de					Chapman A.D., 2005, PRINCIPLES METHODS D; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAELEMANS PPW, 2005, MEMORY BASED LANGUAG; Kubica J, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P131, DOI 10.1109/ICDM.2003.1250912; MALETIC SJ, 2000, P INT C INF QU ICIQ, P200; Reynaert Martin, 2005, THESIS TILBURG U; SPORLEDER C, 2006, P EACL 2006 WORKSH A, P40; Van Hulse JD, 2007, KNOWL INF SYST, V11, P171, DOI 10.1007/s10115-006-0022-x; Zhu XQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P378	9	4	4	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672			IEEE INTELL SYST	IEEE Intell. Syst.	MAR-APR	2009	24	2					54	63				10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	421ZT	WOS:000264397500011		
J	Steele, BM				Steele, Brian M.			Exact bootstrap k-nearest neighbor learners	MACHINE LEARNING			English	Article						Bagging; k-nearest neighbor; Classification; Regression; Ensemble methods	DISCRIMINANT-ANALYSIS; REGRESSION; CLASSIFICATION; CLASSIFIERS; SAMPLE	Bootstrap aggregation, or bagging, is a method of reducing the prediction error of a statistical learner. The goal of bagging is to construct a new learner which is the expectation of the original learner with respect to the empirical distribution function. In nearly all cases, the expectation cannot be computed analytically, and bootstrap sampling is used to produce an approximation. The k-nearest neighbor learners are exceptions to this generalization, and exact bagging of many k-nearest neighbor learners is straightforward. This article presents computationally simple and fast formulae for exact bagging of k-nearest neighbor learners and extends exact bagging methods from the conventional bootstrap sampling (sampling n observations with replacement from a set of n observations) to bootstrap sub-sampling schemes (with and without replacement). In addition, a partially exact k-nearest neighbor regression learner is developed. The article also compares the prediction error associated with elementary and exact bagging k-nearest neighbor learners, and several other ensemble methods using a suite of publicly available data sets.	Univ Montana, Dept Math Sci, Missoula, MT 59812 USA	Steele, BM (reprint author), Univ Montana, Dept Math Sci, Missoula, MT 59812 USA.	steeleb@mso.umt.edu					ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; BHATTACH.PK, 1974, ANN STAT, V2, P1034, DOI 10.1214/aos/1176342823; BIAU G, 2008, CONSISTENCY RANDOM F; Bickel PJ, 1997, STAT SINICA, V7, P1; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buhlmann P, 2002, ANN STAT, V30, P927; Buja A, 2006, STAT SINICA, V16, P323; Caprile B, 2004, LECT NOTES COMPUT SC, V3077, P72; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman JH, 2007, J STAT PLAN INFER, V137, P669, DOI 10.1016/j.jspi.2006.06.002; GERTHEISS J, 2008, 033 U MUNICH DEP STA; Grandvalet Y, 2004, MACH LEARN, V55, P251, DOI 10.1023/B:MACH.0000027783.34431.42; Hall P, 2005, J ROY STAT SOC B, V67, P363, DOI 10.1111/j.1467-9868.2005.00506.x; Hastie T, 2001, ELEMENTS STAT LEARNI; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI DOI 10.1080/00401706.1970.10488634; Hutson AD, 2000, J ROY STAT SOC B, V62, P89, DOI 10.1111/1467-9868.00221; Loader C., 1999, LOCAL REGRESSION LIK; LOH WL, 1995, J MULTIVARIATE ANAL, V53, P264, DOI 10.1006/jmva.1995.1036; Maclin R., 1997, P 14 NAT C ART INT, P546; Mood Alexander M., 1974, INTRO THEORY STAT, Vthird; PANCOV P, 2007, ADV INTELLIGENT DATA, V7, P118; Ripley BD, 1996, PATTERN RECOGNITION; Skurichina M, 1998, PATTERN RECOGN, V31, P909, DOI 10.1016/S0031-3203(97)00110-6; Steele BM, 2003, ENVIRON ECOL STAT, V10, P333, DOI 10.1023/A:1025111108050; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	32	6	6	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125	1573-0565		MACH LEARN	Mach. Learn.	MAR	2009	74	3					235	255		10.1007/s10994-008-5096-0		21	Computer Science, Artificial Intelligence	Computer Science	407RV	WOS:000263382900001		
J	Garcia-Laencina, PJ; Sancho-Gomez, JL; Figueiras-Vidal, AR; Verleysen, M				Garcia-Laencina, Pedro J.; Sancho-Gomez, Jose-Luis; Figueiras-Vidal, Anibal R.; Verleysen, Michel			K nearest neighbours with mutual information for simultaneous classification and missing data imputation	NEUROCOMPUTING			English	Article	18th European Symposium on Artificial Neural Networks	APR, 2008	Brugge, BELGIUM			Missing data; Pattern classification; Imputation; K nearest neighbours; Mutual information	LEARNING VECTOR QUANTIZATION; FEATURE-SELECTION; ALGORITHMS; VALUES	Missing data is a common drawback in many real-life pattern classification scenarios. One of the most popular solutions is missing data imputation by the K nearest neighbours (KNN) algorithm. In this article, we propose a novel KNN imputation procedure using a feature-weighted distance metric based on mutual information (MI). This method provides a missing data estimation aimed at solving the classification task, i.e., it provides an imputed dataset which is directed toward improving the classification performance. The MI-based distance metric is also used to implement an effective KNN classifier. Experimental results on both artificial and real classification datasets are provided to illustrate the efficiency and the robustness of the proposed algorithm. (C) 2009 Elsevier B.V. All rights reserved.	[Garcia-Laencina, Pedro J.; Sancho-Gomez, Jose-Luis] Univ Politecn Cartagena, Dept Informat & Commun Technol, Murcia 30202, Spain; [Figueiras-Vidal, Anibal R.] Univ Carlos III Madrid, Dept Signal Theory & Commun, Madrid 28911, Spain; [Verleysen, Michel] Univ Catholique Louvain, DICE, Machine Learning Grp, B-1348 Louvain, Belgium	Garcia-Laencina, PJ (reprint author), Univ Politecn Cartagena, Dept Informat & Commun Technol, Plaza Hosp 1, Murcia 30202, Spain.	pedroj.garcia@upct.es	Garcia-Laencina, Pedro J./I-2173-2012				Acuna E, 2004, ST CLASS DAT ANAL, P639; Aha D. W., 1997, LAZY LEARNING; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Allison P.D., 2001, SAGE U PAPERS SERIES; Batista G.E., 2002, 2 INT C HYBR INT SYS, V87, P251; Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI 10.1080/08839510390219309; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brown JG, 2002, APPL ECON LETT, V9, P311, DOI 10.1080/13504850110069980; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; Cristianini N., 2000, SUPPORT VECTOR MACHI, V1st; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Francois D, 2007, NEUROCOMPUTING, V70, P1276, DOI 10.1016/j.neucom.2006.11.019; Gabrys B, 2002, INT J APPROX REASON, V30, P149, DOI 10.1016/S0888-613X(02)00070-1; Ghahramani Z., 1994, ADV NEURAL INFORMATI, V6, P120; Halatchev M., 2005, COMAD, P83; Hammer B, 2002, NEURAL NETWORKS, V15, P1059, DOI 10.1016/S0893-6080(02)00079-5; HECHENBICHLER K, 2007, WEIGHTED K NEAREST N; ISHIBUCHI H, 1993, P IEEE INT JOINT C N, P1871; Jerez J.M., 2006, BIOMED 06, P323; Kim H, 2005, BIOINFORMATICS, V21, P187, DOI 10.1093/bioinformatics/bth499; KIM H, 2004, IEEE COMP SYST BIOIN; Kullback S., 1959, INFORM THEORY STAT; Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861; Little R.J.A., 2002, STAT ANAL MISSING DA; Little RJA, 1999, J RHEUMATOL, V26, P1654; MARKEY MK, 2004, INT C MACH LEARN APP, P351; McLachlan G J, 1997, EM ALGORITHM EXTENSI; Mitchell T. M., 1997, MACHINE LEARNING; Narayanan S, 2002, IEEE IJCNN, P2872, DOI 10.1109/IJCNN.2002.1007604; Newman D., 1998, UCI REPOSITORY MACHI; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Rossi F, 2006, CHEMOMETR INTELL LAB, V80, P215, DOI 10.1016/j.chemolab.2005.06.010; Rubin D. B., 1987, MULTIPLE IMPUTATION; Schafer J. L., 1997, ANAL INCOMPLETE MULT; Sehgal MSB, 2005, BIOINFORMATICS, V21, P2417, DOI 10.1093/bioinformatics/bti345; SONG Y, 2007, 11 EUR C PRINC PRACT, P248; Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520; Tsumoto S, 2000, P INT COMP SOFTW APP, V24, P467; Villmann T, 2006, NEURAL NETWORKS, V19, P610, DOI 10.1016/j.neunet.2005.07.013; Weinberger K., 2005, ADV NEURAL INFORM PR, V18, P1473; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	44	24	30	3	13	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	MAR	2009	72	7-9					1483	1493		10.1016/j.neucom.2008.11.026		11	Computer Science, Artificial Intelligence	Computer Science	430MM	WOS:000264993200012		
J	Liu, L; Cai, YD; Lu, WC; Feng, KY; Peng, CR; Niu, B				Liu, Liang; Cai, Yudong; Lu, Wencong; Feng, Kaiyan; Peng, Chunrong; Niu, Bing			Prediction of protein-protein interactions based on PseAA composition and hybrid feature selection	BIOCHEMICAL AND BIOPHYSICAL RESEARCH COMMUNICATIONS			English	Article						Bioinformatics; Proteomics; Protein-protein interactions; KNNs; Feature selection	AMINO-ACID-COMPOSITION; HYBRIDIZATION SPACE; FOLDING TYPES; INTERFACES; DROSOPHILA; GENE; TRANSACTIVATION; SEQUENCES; INTACT; E2F	Based on pseudo amino acid (PseAA) composition and a novel hybrid feature selection frame, this paper presents a computational system to predict the PPIs (protein-protein interactions) using 8796 protein pairs. These pairs are coded by PseAA composition, resulting in 114 features. A hybrid feature selection system, mRMR-KNNs-wrapper, is applied to obtain an optimized feature set by excluding poor-performed and/or redundant features, resulting in 103 remaining features. Using the optimized 103-feature subset, a prediction model is trained and tested in the k-nearest neighbors (KNNs) learning system. This prediction model achieves an overall accurate prediction rate of 76.18%, evaluated by 10-fold cross-validation test, which is 1.46% higher than using the initial 114 features and is 6.51% higher than the 20 features, coded by amino acid compositions. The PPIs predictor, developed for this research, is available for public use at http://chemdata.shu.edu.cn/ppi. (c) 2009 Elsevier Inc. All rights reserved.	[Cai, Yudong] Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China; [Liu, Liang; Lu, Wencong; Peng, Chunrong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Liu, Liang; Niu, Bing] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China; [Cai, Yudong] Chinese Acad Sci, Shanghai Inst Biol Sci, Dept Combinator & Geometry, MPG Partner Inst Computat Biol, Shanghai 200031, Peoples R China; [Feng, Kaiyan] Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England	Cai, YD (reprint author), Shanghai Univ, Inst Syst Biol, 99 Shang Da Rd, Shanghai 200444, Peoples R China.	cyd@picb.ac.cn; wclu@shu.edu.cn			National Natural Science Foundation of China [20503015, 30672671]; Shanghai Leading Academic Discipline Project [J50101]	This work was funded by National Natural Science Foundation of China (20503015 and 30672671), Shanghai Leading Academic Discipline Project (J50101) and Systems Biology Research Foundation of Shanghai University.	Alberts B, 2004, MOL BIOL CELL; Ben-Hur A, 2005, BIOINFORMATICS S1, V21, pi38, DOI DOI 10.1093/BI0INF0RMATICSIBTIL; Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Cai YD, 2006, J THEOR BIOL, V238, P395, DOI 10.1016/j.jtbi.2005.05.035; Chen XW, 2005, BIOINFORMATICS, V21, P4394, DOI 10.1093/bioinformatics/bti721; CHOU JJW, 1993, J THEOR BIOL, V161, P251, DOI 10.1006/jtbi.1993.1053; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou K.C., 2006, EXCLI J, V5, P55; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2006, BIOCHEM BIOPH RES CO, V339, P1015, DOI 10.1016/j.bbrc.2005.10.196; CHOU KC, 1994, J BIOL CHEM, V269, P22014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DING C, 2003, P 2 IEEE COMP SYST B, V11, P523; Du W, 1996, GENE DEV, V10, P1206, DOI 10.1101/gad.10.10.1206; DYNLACHT BD, 1994, P NATL ACAD SCI USA, V91, P6359, DOI 10.1073/pnas.91.14.6359; Enright AJ, 1999, NATURE, V402, P86; Giot L, 2003, SCIENCE, V302, P1727, DOI 10.1126/science.1090289; HELIN K, 1993, GENE DEV, V7, P1850, DOI 10.1101/gad.7.10.1850; Hermjakob H, 2004, NUCLEIC ACIDS RES, V32, pD452, DOI 10.1093/nar/gkh052; HUBBARD SJ, 1994, PROTEIN SCI, V3, P2194; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Jansen R, 2003, SCIENCE, V302, P449, DOI 10.1126/science.1087361; Kerrien S, 2007, NUCLEIC ACIDS RES, V35, pD561, DOI 10.1093/nar/gkl958; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LANGLEY P, 1994, AAAI FALL S REV; LAWRENCE MC, 1993, J MOL BIOL, V234, P946, DOI 10.1006/jmbi.1993.1648; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; Mering CV, 2005, NUCLEIC ACIDS RES, V33, pD433; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Ofran Y, 2003, J MOL BIOL, V325, P377, DOI 10.1016/S0022-2836(02)01223-8; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226; Pitre S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-365; Sprinzak E, 2001, J MOL BIOL, V311, P681, DOI 10.1006/jmbi.2001.4920; Tayers M., 1999, NATURE, V422, P193; Tsai CJ, 1997, PROTEIN SCI, V6, P53; YOUNG L, 1994, PROTEIN SCI, V3, P717; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898	41	20	24	2	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0006-291X			BIOCHEM BIOPH RES CO	Biochem. Biophys. Res. Commun.	MAR 6	2009	380	2					318	322		10.1016/j.bbrc.2009.01.077		5	Biochemistry & Molecular Biology; Biophysics	Biochemistry & Molecular Biology; Biophysics	412RP	WOS:000263742200021	19171120	
J	Giguere, P; Dudek, G				Giguere, Philippe; Dudek, Gregory			Clustering sensor data for autonomous terrain identification using time-dependency	AUTONOMOUS ROBOTS			English	Article; Proceedings Paper	4th Robotics Science and Systems Conference	JUN, 2008	Zurich, SWITZERLAND			Terrain identification; Unsupervised learning; Clustering; Mobile robots; Legged robots; Machine learning; Hidden Markov model	CLASSIFICATION	In this paper we are interested in autonomous vehicles that can automatically develop terrain classifiers without human interaction or feedback. A key issue is the clustering of time-series data collected by the sensors of a ground-based vehicle moving over several terrain surfaces (e.g. concrete or soil). In this context, we present a novel off-line windowless clustering algorithm that exploits time-dependency between samples. In terrain coverage, sets of sensory measurements are returned that are spatially, and hence temporally, correlated. Our algorithm works by finding a set of parameter values for a user-specified classifier that minimize a cost function. This cost function is related to the change in classifier probability estimates over time. The main advantage over other existing methods is its ability to cluster data for fast-switching systems that either have high process or observation noise, or complex distributions that cannot be properly characterized within the time interval that the system stays in a single state. The algorithm was evaluated using three different classifiers (linear separator, mixture of Gaussians and k-Nearest Neighbor), over both synthetic data sets and two different mobile robotic platforms, with success. Comparisons are provided against a window-based algorithm and against a hidden Markov model trained with Expectation-Maximization, with positive results.	[Giguere, Philippe; Dudek, Gregory] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	Giguere, P (reprint author), McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.	philg@cim.mcgill.ca; dudek@cim.mcgill.ca	Dudek, Gregory/H-3567-2012				Brooks CA, 2005, IEEE T ROBOT, V21, P1185, DOI 10.1109/TRO.2005.855994; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUDEK G, 2005, P IEEE RSJ INT C INT; DuPont EM, 2008, AUTON ROBOT, V24, P337, DOI 10.1007/s10514-007-9077-0; GIGUERE P, 2009, CAN C COMP ROB VIS K; Giguere P., 2006, P ROB SCI SYST PHIL; GIGUERE P, 2009, P IEEE INT C ROB AUT; KOHLMORGEN J, 2001, NNSP 2001 NEURAL NET, V11, P113; KOHLMORGEN J, 2000, P IEEE NEUR NETW SIG, P85; LENSER S, 2004, P IEEE RSJ INT C INT, V3, P2719; LENSER S, 2003, P 2003 IEEE INT C RO; Murphy K., 2005, HIDDEN MARKOV MODEL; Pawelzik K, 1996, NEURAL COMPUT, V8, P340, DOI 10.1162/neco.1996.8.2.340; Rabiner L.R., 1989, IEEE P, V77, P257, DOI DOI 10.1109/5.18626; SADHUKAN D, 2003, P FLOR C REC ADV ROB; SREBRO N, 2005, PASCAL WORKSH STAT O; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Weiss C, 2006, 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-12, P4429, DOI 10.1109/IROS.2006.282076; Weiss C., 2007, P 3 EUR C MOB ROB EC, P7	19	7	7	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0929-5593			AUTON ROBOT	Auton. Robot.	APR	2009	26	2-3					171	186		10.1007/s10514-009-9114-2		16	Computer Science, Artificial Intelligence; Robotics	Computer Science; Robotics	440EV	WOS:000265684000006		
J	Jarchi, D; Boostani, R; Taheri, M; Sanei, S				Jarchi, Delaram; Boostani, Reza; Taheri, Mohammad; Sanei, Saeid			Seizure source localization using a hybrid second order blind identification and extended rival penalized competitive learning algorithm	BIOMEDICAL SIGNAL PROCESSING AND CONTROL			English	Article						Seizure; SOBI; RPCL; Clustering; Localization; BSS	SOURCE SEPARATION; EPILEPTIC FOCI; TOMOGRAPHY	Localization of seizure sources prior to neurosurgery is crucial. In this paper, a new method is proposed to localize the seizure sources from multi-channel electroencephalogram (EEG) signals. Blind source separation based on second order blind identification (SOBI) is primarily applied to estimate the brain source signals in each window of the EEG signals. A new clustering method based on rival penalized competitive learning (RPCL) is then developed to cluster the rows of the estimated unmixing matrices in all the windows. The algorithm also includes pre and post-processing stages. By multiplying each cluster center to the EEG signals, the brain signal sources are approximated. According to a complexity value measure, the main seizure source signal is separated from the others. This signal is projected back to the electrodes' space and is subjected to the dipole source localization using a single dipole model. The simulation results verify the accuracy of the system. in addition, correct localization of the seizure source is consistent with the clinical tests derived using the simultaneous intracranial recordings. (C) 2009 Elsevier Ltd. All rights reserved.	[Jarchi, Delaram; Boostani, Reza; Taheri, Mohammad] Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran; [Sanei, Saeid] Cardiff Univ, Sch Engn, Ctr DSP, Cardiff, S Glam, Wales	Jarchi, D (reprint author), Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.	delaram.jarchi@gmail.com					BAI X, 2006, IEEE T BIOMEDICAL EN, V53; Ball GH., 1965, ISODATA NOVEL METHOD; Bell A J, 1995, NEURAL COMPUT, V7, P1004; Belouchrani A, 1997, IEEE T SIGNAL PROCES, V45, P434, DOI 10.1109/78.554307; CARDOSO JF, 1993, IEE PROC-F, V140, P362; Cardoso JF, 1996, SIAM J MATRIX ANAL A, V17, P161, DOI 10.1137/S0895479893259546; Corsini J, 2006, IEEE T BIO-MED ENG, V53, P790, DOI 10.1109/TBME.2005.862551; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; daSilva EA, 1997, EPILEPSIA, V38, P1198; Iasemidis Leon D, 2003, IEEE Trans Biomed Eng, V50, P549, DOI 10.1109/TBME.2003.810705; IASEMIDIS LD, 2000, NONLINEAR BIOMEDICAL; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Jarchi D, 2007, Proceedings of the 2007 15th International Conference on Digital Signal Processing, P183; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; KAVANAGH RN, 1978, IEEE T BIO-MED ENG, V25, P421, DOI 10.1109/TBME.1978.326339; Ma JW, 2006, IEEE T SYST MAN CY B, V36, P722, DOI 10.1109/TSMCB.2006.870633; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MARKS DA, 1992, ANN NEUROL, V31, P250, DOI 10.1002/ana.410310304; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; MISHRA SK, 1994, MACH INTELL PATT REC, V16, P425; MOSHER JC, 1992, IEEE T BIO-MED ENG, V39, P541, DOI 10.1109/10.141192; Pataraia E, 2002, NEUROSURG REV, V25, P141, DOI 10.1007/s10143-001-0197-2; Sanei S., 2007, EEG SIGNAL PROCESSIN; SARVAS J, 1987, PHYS MED BIOL, V32, P11, DOI 10.1088/0031-9155/32/1/004; Scherg Michael, 1992, Brain Topography, V5, P103, DOI 10.1007/BF01129037; Scherg M., 1990, ADV AUDIOL, V6, P40; *W JOHN LTD, 2002, SONS STAT PATT REC; XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318	28	2	2	0	2	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1746-8094			BIOMED SIGNAL PROCES	Biomed. Signal Process. Control	APR	2009	4	2					108	117		10.1016/j.bspc.2009.01.004		10	Engineering, Biomedical; Medical Laboratory Technology	Engineering; Medical Laboratory Technology	440MR	WOS:000265704900005		
J	Chen, SM; Shie, JD				Chen, Shyi-Ming; Shie, Jen-Da			Fuzzy classification systems based on fuzzy information gain measures	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Fuzzy information gain; Fuzzy entropy; Classification problems; Feature weights; Membership grades	MEMBERSHIP FUNCTIONS; RULES	In this paper, we present a new method for handling classification problems using a new fuzzy information gain measure. Based on the proposed fuzzy information gain measure, we propose an algorithm for constructing membership functions, calculating the class degree of each subset of training instances with respect to each class and Calculating the fuzzy entropy of each subset of training instances. Based on the constructed membership function of each fuzzy set of each feature, the obtained class degree of each subset of training instances with respect to each class and the obtained fuzzy entropy of each subset of training instances, we propose an evaluating function for classifying testing instances. The proposed method gets higher average classification accuracy rates than the methods presented in [John, G. H., & Langley. P. (1995). Estimating continuous distributions in Bayesian classifiers. In Proceedings of the 11th conference oil uncertainty in artificial intelligence, Montreal, Canada (pp. 338-345): Platt, J. C. (1999). Using analytic QP and sparseness to speed training of support vector machines. In Proceedings of the 13th annual conference on neural information processing systems, Denver, Colorado (pp. 557-563); Quinlan, J. R. (1993). C4.5: Programs for machine learning. San Francisco: Morgan Kaufmann]. (c) 2008 Elsevier Ltd. All rights reserved.	[Chen, Shyi-Ming; Shie, Jen-Da] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan	Chen, SM (reprint author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.	smchen@mail.ntust.edu.tw			National Science Council, Republic of China [NSC 95-2221-E-011-116-MY2]	This work was supported in part by the National Science Council, Republic of China, under Grant NSC 95-2221-E-011-116-MY2.	BAIM PW, 1988, IEEE T PATTERN ANAL, V10, P888, DOI 10.1109/34.9110; BANERJI RB, 1964, GEN SYST, V9, P135; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130401; Caruana R., 1994, P 11 INT C MACH LEAR, P28; Catlett J., 1991, P EUR WORK SESS LEAR, P164; Chaikla N., 1999, P 1999 IEEE INT C SY, V5, P538; Chen SM, 2002, CYBERNET SYST, V33, P841, DOI 10.1080/01969720290040867; Chen SM, 2002, CYBERNET SYST, V33, P723, DOI 10.1080/01969720290040812; Chen S.M., 2005, P 2005 IEEE INT C FU, P183, DOI 10.1109/FUZZY.2005.1452390; Chen SM, 2005, CYBERNET SYST, V36, P397, DOI 10.1080/01969720490929562; Chmielewski M.R., 1994, P 3 INT WORKSH ROUGH, P294; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De RK, 1997, PATTERN RECOGN, V30, P1579, DOI 10.1016/S0031-3203(96)00190-2; Fayyad U. M., 1993, P 13 INT JOINT C ART, P1022; Fisher RA, 1936, ANN EUGENIC, V7, P179; GOMEZ J, 2005, P 2005 IEEE C EV COM, P1637; Hartigan JA, 2002, J ROYAL STAT SOC C, V28, P100, DOI DOI 10.2307/2346830; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; John G.H., 1995, P 11 C UNC ART INT, P338; Maass W., 1994, Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, COLT 94, DOI 10.1145/180139.181016; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570; ONGKOWIJAYA BT, 2004, P 7 INT C SIGN PROC, P663; Platt J, 1999, P 13 ANN C NEUR INF, P557; Quinlan JR, 1986, MACH LEARN, V1, P106; Quinlan JR, 1993, C 45 PROGRAMS MACHIN; Ramesh VE, 1999, PATTERN RECOGN, V32, P217, DOI 10.1016/S0031-3203(98)00141-1; SHIE JD, 2006, P 2006 IEEE INT C FU, P5427; SHIE JD, 2007, APPL INTELL, V28, P69; WINKLER SM, 2006, P 20 INT S PAR DISTR, P2295; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90036-5	31	6	8	1	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					4517	4522		10.1016/j.eswa.2008.05.020		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100043		
J	Chen, JN; Huang, HK; Tian, SF; Qu, YL				Chen, Jingnian; Huang, Houkuan; Tian, Shengfeng; Qu, Youli			Feature selection for text classification with Naive Bayes	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Feature selection; Text preprocessing; Naive Bayes	NEAREST-NEIGHBOR; CATEGORIZATION	As an important preprocessing technology in text classification, feature selection can improve the scalability, efficiency and accuracy of a text classifier. In general, a good feature selection method should consider domain and algorithm characteristics. As the Naive Bayesian classifier is very simple and efficient and highly sensitive to feature selection, so the research of feature selection specially for it is significant. This paper presents two feature evaluation metrics for the Naive Bayesian classifier applied on multi-class text datasets: Multi-class Odds Ratio (MOR), and Class Discriminating Measure (CDM). Experiments of text classification with Naive Bayesian classifiers were carried out on two multi-class texts collections. As the results indicate, CDM and MOR gain obviously better selecting effect than other feature selection approaches. (C) 2008 Elsevier Ltd. All rights reserved.	[Chen, Jingnian; Huang, Houkuan; Tian, Shengfeng; Qu, Youli] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China; [Chen, Jingnian] Shandong Univ Finance, Dept Informat & Comp Sci, Jinan 250014, Shandong, Peoples R China	Chen, JN (reprint author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.	jnchen06@163.com			National Natural Science Foundation of China [60503017, 60673089]	This research is supported by National Natural Science Foundation of China under Grant Nos. 60503017 and 60673089.	COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Forman G., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753670; Frank E., 2006, P 10 EUR C PRINC PRA, P503; Joachims T., 1998, P 10 EUR C MACH LEAR, P137; John G., 1994, P 11 INT C MACH LEAR, P121; Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457; Lewis D., 1998, P 10 EUR C MACH LEAR, P4; Lewis D., 1994, P 3 ANN S DOC AN INF, P81; McCallum A., 1998, AAAI 98 WORKSH LEARN; Mladenic D., 1999, P 16 INT C MACH LEAR, P258; Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0; Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Wiener E, 1995, P 4 ANN S DOC AN INF, P317; Yang Y., 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Yang Y., 1999, INFORMATION RETRIEVA, V1, P76; YANG YM, 1994, ACM T INFORM SYST, V12, P252, DOI 10.1145/183422.183424; [周茜 Zhou Qian], 2004, [中文信息学报, Journal of Chinese Information Processing], V18, P17	18	70	81	7	22	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					5432	5435		10.1016/j.eswa.2008.06.054		4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100156		
J	Jung, S; Lim, T; Kim, D				Jung, Sabum; Lim, Taesoo; Kim, Dongsoo			Integrating radial basis function networks with case-based reasoning for product design	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Case-based reasoning (CBR); Radial basis function network (RBFN); Design expert system; Product design	ADAPTATION; ALGORITHM; KNOWLEDGE	This paper presents a case-based design expert system that automatically determines the design values of a product. We focus on the design problem of a shadow mask which is a core component of monitors in the electronics industry. In case-based reasoning (CBR), it is important to retrieve similar cases and adapt them to meet design specifications exactly. Notably, difficulties in automating the adaptation process have prevented designers from being able to use design expert systems easily and efficiently. In this paper, we present a hybrid approach combining CBR and artificial neural networks in order to solve the problems Occurring during the adaptation process. We first constructed a radial basis function network (RBFN) composed of representative cases created by K-means clustering. Then, the representative case most similar to the current problem was adjusted using the network. The rationale behind the proposed approach is discussed, and experimental results acquired from real shadow mask design are presented. Using the design expert system, designers can reduce design time and errors and enhance the total quality of design. Furthermore, the expert system facilitates effective sharing of design knowledge among designers. (C) 2008 Elsevier Ltd. All rights reserved.	[Kim, Dongsoo] Soongsil Univ, Dept Ind & Informat Syst Engn, Seoul 156743, South Korea; [Jung, Sabum] LG Prod Engn Res Inst, Dev Res Grp, Pyongtaek 451713, Gyeonggi, South Korea; [Lim, Taesoo] Sungkyul Univ, Dept Comp Engn, Anyang 430742, Gyeonggi, South Korea	Kim, D (reprint author), Soongsil Univ, Dept Ind & Informat Syst Engn, Seoul 156743, South Korea.	skk1991@hotmail.com; tshou@sungkyul.edu; dskim@ssu.ac.kr			Soongsil University Research Fund	This work was supported by the Soongsil University Research Fund.	Chan FTS, 2005, EXPERT SYST APPL, V29, P121, DOI 10.1016/j.eswa.2005.01.010; CIOS KJ, 1998, KLUWER INT SERIES EN, P319; CORCHARDO JM, 1998, IEEE WORLD C COMPUTA, V1, P713; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Craw S, 2006, ARTIF INTELL, V170, P1175, DOI 10.1016/j.artint.2006.09.001; GARZA AGD, 1999, INT C CAS BAS REAS I; GOLDING AR, 1995, TR9419A MERL; Hanney K., 1997, P 2 INT C CAS BAS RE, P359; Haque BU, 2000, KNOWL-BASED SYST, V13, P101, DOI 10.1016/S0950-7051(00)00051-4; Kim SM, 2003, GENE DEV, V17, P330, DOI 10.1101/gad.1046203; Kolodner J. L., 1993, CASE BASED REASONING; MAHER M, 1997, IEEE EXPERT INTE MAR, P34; Mille A, 2006, ANNU REV CONTROL, V30, P223, DOI 10.1016/j.arcontrol.2006.09.003; Pal S., 2004, FDN SOFT CASE BASED; Passone S, 2006, KNOWL-BASED SYST, V19, P192, DOI 10.1016/j.knosys.2005.07.007; Quinlan JR, 1986, MACH LEARN, V1, P106; Rumelhart D. E., 1986, PARALLEL DISTRIBUTED, V1; Zheng GL, 1996, NEURAL NETWORKS, V9, P1619, DOI 10.1016/0893-6080(95)00139-5	18	9	11	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					5695	5701		10.1016/j.eswa.2008.06.099		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	410NJ	WOS:000263584100186		
J	Kianmehr, K; Alhajj, R				Kianmehr, Keivan; Alhajj, Reda			Calling communities analysis and identification using machine learning techniques	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Social communities; Classification; Clustering; Customer behavior; Machine learning	NETWORKS	The analysis of social communities related logs has recently received considerable attention for its importance in shedding light on social concerns by identifying different groups, and hence helps in resolving issues like predicting terrorist groups. In the customer analysis domain, identifying calling communities can be used for determining a particular customer's value according to the general pattern behavior of the community that the customer belongs to; this helps the effective targeted marketing design, which is Significantly important for increasing profitability. In telecommunication industry, machine learning techniques have been applied to the Call Detail Record (CDR) for predicting customer behavior such as churn prediction. In this paper, we pursue identifying the calling communities and demonstrate how cluster analysis can be used to effectively identify communities using information derived from the CDR data. We use the information extracted from the cluster analysis to identify customer calling patterns. Customers calling patterns are then given to a classification algorithm to generate a classifier model for predicting the calling communities of a customer. We apply different machine learning techniques to build classifier models and compare them in terms of classification accuracy and computational performance. The reported test results demonstrate the applicability and effectiveness of the proposed approach. (C) 2008 Elsevier Ltd. All rights reserved.	[Kianmehr, Keivan; Alhajj, Reda] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada; [Alhajj, Reda] Global Univ, Dept Comp Sci, Beirut, Lebanon	Alhajj, R (reprint author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.	alhajj@cpsc.ucalgary.ca					ALLWEIN E, 2000, REDUCING MULTICLASS, P83006; BISHOP CM, 1995, NEURAL NETWORKS PATT, P83006; BREIMAN L, 1984, CLASSIFICATION REGRE, P83006; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2000, INTRO SUPPORT VECTOR, P83006; Dandrade R., 1978, PSYCHOMETRIKA, P58; DUNHAM MH, 2000, DATA MINING TECHNIQU, P83006; EDELSTEIN HA, 1999, INTRO DATA MINING KN, P83006; Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, DOI 10.1145/347090.347121; Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799; HAN J, 2000, DATA MINING CONCEPTS, P83006; HASAN M, 2006, P WORKSH LINK AN COU, P83006; HAYKIN S, 1998, NEURAL NETWORKS COMP, P83006; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1007/BF00994016; John G.H., 1995, P 11 C UNC ART INT, P338; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; NASRULLAH M, 2006, LECT NOTES ARTIF INT, V4093, P1037; Pearl J, 1985, P 7 C COGN SCI SOC, P329; QUINLAN J, 1993, C4 5 PROGRAMS MACHIN, P83006; RATSCH G, 2002, ADAPTING CODES EMBED, P83006; ROMESBURG HC, 2004, CLUSTER ANAL RES, P83006; VAPNIK VN, 1998, STAT LEARNING THEORY, P83006; YAN L, 2005, P IEEE INT JOINT C A, V4, P2555	25	6	6	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	APR	2009	36	3					6218	6226		10.1016/j.eswa.2008.07.072		9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	413UD	WOS:000263817100058		
J	Mora-Florez, J; Morales-Espana, G; Perez-Londono, S				Mora-Florez, J.; Morales-Espana, G.; Perez-Londono, S.			Learning-based strategy for reducing the multiple estimation problem of fault zone location in radial power systems	IET GENERATION TRANSMISSION & DISTRIBUTION			English	Article							ALGORITHM	A learning-based strategy that uses support vector machines and k nearest neighbours is proposed for locating the faulted zone in radial power systems, specifically in distribution networks. The main goal is to reduce the multiple estimation of the fault location, inherent in those methods that use single end measurements. A selection of features obtained from the fundamentals of voltages and currents, measured at the power substation, are analysed and used as inputs of the proposed zone locator. Performance of several combinations of these features considering all fault types, different short-circuit levels and variation of the fault resistance, and the system load is evaluated. An application example illustrates the high precision to locate the faulted zone, obtained with the proposed methodology. The proposal provides appropriate information for the prevention and opportune attention of faults, requires minimum investment and overcomes the multiple estimation problem of the classic impedance based methods.	[Mora-Florez, J.; Perez-Londono, S.] Technol Univ Pereira, Dept Elect Engn, Pereira, Colombia; [Morales-Espana, G.] Delft Univ Technol, Delft, Netherlands	Mora-Florez, J (reprint author), Technol Univ Pereira, Dept Elect Engn, Pereira, Colombia.	jjmora@utp.edu.co	Morales-Espana, German Andres/B-3713-2012	Morales-Espana, German Andres/0000-0002-6372-6197			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Chih-Wei H., 2003, PRACTICAL GUIDE SUPP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dagenhart J, 2000, IEEE T IND APPL, V36, P30, DOI 10.1109/28.821792; Das R., 1998, THESIS U SASKATCHEWA; IEEE, 2004, C37114 IEEE; IEEE Distribution System Analysis Subcommittee, 1993, RAD TEST FEED; MESCAL A, 2003, ELECTR POW SYST RES, V64, P87; MORA J, 2006, TRANSM DISTR C EXP L; Mora-Florez J, 2007, IEEE T POWER DELIVER, V22, P1715, DOI 10.1109/TPWRD.2006.883021; Mora-Florez J., 2006, THESIS U GIRONA SPAI; Mora-Florez J, 2008, ELECTR POW SYST RES, V78, P657, DOI 10.1016/j.epsr.2007.05.010; NOVOSEL D, 1998, Patent No. 5839093; Purushothama GK, 2001, INT J ELEC POWER, V23, P491, DOI 10.1016/S0142-0615(00)00068-5; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Short T. A., 2003, ELECT POWER DISTRIBU; TAKAGI T, 1981, IEEE T POWER AP SYST, V100, P1316, DOI 10.1109/TPAS.1981.316604; THUKARAM D, 2006, POW IND C IEEE, DOI DOI 10.1109/POWERI.2006.1632510; Thukaram D, 2005, IEEE T POWER DELIVER, V20, P710, DOI 10.1109/TPWRD.2005.844307; Vapnik V, 2000, NATURE STAT LEARNING; WARRINGTON A, 1978, PROTECTIVE RELAYS TH	22	8	10	0	3	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-8687			IET GENER TRANSM DIS	IET Gener. Transm. Distrib.	APR	2009	3	4					346	356		10.1049/iet-gtd.2008.0164		11	Engineering, Electrical & Electronic	Engineering	434ET	WOS:000265258700004		
J	Xiao, X; Wang, P; Chou, KC				Xiao, Xuan; Wang, Pu; Chou, Kuo-Chen			Predicting the quaternary structure attribute of a protein by hybridizing functional domain composition and pseudo amino acid composition	JOURNAL OF APPLIED CRYSTALLOGRAPHY			English	Article							SUBCELLULAR LOCATION PREDICTION; COMPLEXITY MEASURE FACTOR; ENZYME SUBFAMILY CLASSES; SUPPORT VECTOR MACHINE; INFLUENZA-A VIRUS; ENSEMBLE CLASSIFIER; APOPTOSIS PROTEINS; MEMBRANE-PROTEIN; PHOSPHOLAMBAN PENTAMER; FUSION CLASSIFIER	In vivo, some proteins exist as monomers (single polypeptide chains) and others as oligomers. The latter are composed of two or more chains (subunits) that are associated with each other through noncovalent interactions and, occasionally, disulfide bonds. Oligomers can be further classified into homo-oligomers (formed by identical subunits) and hetero-oligomers (formed by different subunits), and they form the structural basis of various biological functions such as cooperative effects, the allosteric mechanism and ion-channel gating. Therefore, it would be of less interest or of low priority for crystallographic scientists to crystallize a single protein chain and determine its three-dimensional structure if it is already known as part of an oligomer. However, it is both time-consuming and laborious to acquire such information on the quaternary structure attribute purely by experiment. In particular, with the avalanche of protein sequences generated in the post-genomic age, it is highly desirable to develop an automated method by which crystallographic scientists can rapidly and effectively identify which quaternary attribute a particular protein chain has according to its sequence information. In view of this, a computational method has been developed by hybridizing the approaches of functional domain composition and pseudo amino acid composition. For the convenience of crystallographic scientists, a user-friendly web server, PQSA-Pred, has been established at http://218.65.61.89:8080/bioinfo/pqsa-pred, by which the desired information can be easily obtained.	[Xiao, Xuan; Wang, Pu] Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 33300, Peoples R China; [Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Xiao, X (reprint author), Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 33300, Peoples R China.	xiaoxuan0326@yahoo.com.cn	Chou, Kuo-Chen/A-8340-2009				ALTSCHUL SF, 1997, NUCLEIC ACIDS RES, V25, P3402; Carugo O, 2007, J APPL CRYSTALLOGR, V40, P986, DOI 10.1107/S0021889807041076; Chen C, 2008, J THEOR BIOL, V253, P388, DOI 10.1016/j.jtbi.2008.03.009; Chen K, 2008, J COMPUT CHEM, V29, P1596, DOI 10.1002/jcc.20918; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chen YL, 2007, J THEOR BIOL, V245, P775, DOI 10.1016/j.jtbi.2006.11.010; Chen ZH, 2002, J BIOL CHEM, V277, P24653, DOI 10.1074/jbc.M111862200; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2004, BIOCHEM BIOPH RES CO, V319, P433, DOI 10.1016/j.bbrc.2004.05.016; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2006, J CELL BIOCHEM, V99, P517, DOI 10.1002/jcb.20879; CHOU KC, 1988, P NATL ACAD SCI USA, V85, P4295, DOI 10.1073/pnas.85.12.4295; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; Chou KC, 2004, J PROTEOME RES, V3, P856, DOI 10.1021/pr049931q; CHOU KC, 1994, J BIOL CHEM, V269, P22014; Chou KC, 2004, BIOCHEM BIOPH RES CO, V316, P636, DOI 10.1016/j.bbrc.2004.02.098; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Doyle DA, 1998, SCIENCE, V280, P69, DOI 10.1126/science.280.5360.69; Du PF, 2008, J THEOR BIOL, V253, P579, DOI 10.1016/j.jtbi.2008.04.006; Finn RD, 2006, NUCLEIC ACIDS RES, V34, pD247, DOI 10.1093/nar/gkj149; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; Garian R, 2001, BIOINFORMATICS, V17, P551, DOI 10.1093/bioinformatics/17.6.551; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Kannan S, 2008, PROTEIN PEPTIDE LETT, V15, P1107, DOI 10.2174/092986608786071085; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Letunic I, 2006, NUCLEIC ACIDS RES, V34, pD257, DOI 10.1093/nar/gkj079; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Marchler-Bauer A, 2007, NUCLEIC ACIDS RES, V35, pD237, DOI 10.1093/nar/gkl951; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Niu B, 2008, PROTEIN PEPTIDE LETT, V15, P590, DOI 10.2174/092986608784966921; Oxenoid K, 2007, PROTEIN SCI, V16, P1977, DOI 10.1110/ps.072975107; Oxenoid K, 2005, P NATL ACAD SCI USA, V102, P10870, DOI 10.1073/pnas.0504920102; Perutz M. F., 1964, SCI AM, V211, P65; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Schnell JR, 2008, NATURE, V451, P591, DOI 10.1038/nature06531; Chou KC, 2006, J PROTEOME RES, V5, P3420, DOI 10.1021/pr060404b; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2008, ANAL BIOCHEM, V373, P386, DOI 10.1016/j.ab.2007.10.012; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shi MG, 2008, PROTEIN PEPTIDE LETT, V15, P692, DOI 10.2174/092986608785133627; Tatusov RL, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-41; Tian FF, 2008, PROTEIN PEPTIDE LETT, V15, P1033, DOI 10.2174/092986608786071120; Tretter V, 1997, J NEUROSCI, V17, P2728; Wang T, 2008, PROTEIN PEPTIDE LETT, V15, P915, DOI 10.2174/092986608785849308; Wu G, 2008, PROTEIN PEPTIDE LETT, V15, P144; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhang SW, 2006, AMINO ACIDS, V30, P461, DOI 10.1007/s00726-006-0263-8; Zhang SW, 2003, BIOINFORMATICS, V19, P2390, DOI 10.1093/bioinformatics/btg331; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	79	63	63	1	5	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0021-8898			J APPL CRYSTALLOGR	J. Appl. Crystallogr.	APR	2009	42						169	173		10.1107/S0021889809002751		5	Crystallography	Crystallography	420MB	WOS:000264292800003		
J	Maas, MC; Schaart, DR; van der Laan, DJ; Bruyndonckx, P; Lemaitre, C; Beekman, FJ; van Eijk, CWE				Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); Bruyndonckx, Peter; Lemaitre, Cedric; Beekman, Freek J.; van Eijk, Carel W. E.			Monolithic scintillator PET detectors with intrinsic depth-of-interaction correction	PHYSICS IN MEDICINE AND BIOLOGY			English	Article							SMALL ANIMAL PET; SPATIAL-RESOLUTION; MICROPET SCANNER; READ-OUT; PERFORMANCE; DESIGN; TOMOGRAPH; MODULES; SENSITIVITY	We developed positron emission tomography ( PET) detectors based on monolithic scintillation crystals and position-sensitive light sensors. Intrinsic depth-of-interaction (DOI) correction is achieved by deriving the entry points of annihilation photons on the front surface of the crystal from the light sensor signals. Here we characterize the next generation of these detectors, consisting of a 20 mm thick rectangular or trapezoidal LYSO:Ce crystal read out on the front and the back (double-sided readout, DSR) by Hamamatsu S8550SPL avalanche photodiode (APD) arrays optimized for DSR. The full width at half maximum (FWHM) of the detector point-spread function (PSF) obtained with a rectangular crystal at normal incidence equals similar to 1.05 mm at the detector centre, after correction for the similar to 0.9 mm diameter test beam of annihilation photons. Resolution losses of several tenths of a mm occur near the crystal edges. Furthermore, trapezoidal crystals perform almost equally well as rectangular ones, while improving system sensitivity. Due to the highly accurate DOI correction of all detectors, the spatial resolution remains essentially constant for angles of incidence of up to at least 30 degrees. Energy resolutions of similar to 11% FWHM are measured, with a fraction of events of up to 75% in the full-energy peak. The coincidence timing resolution is estimated to be 2.8 ns FWHM. The good spatial, energy and timing resolutions, together with the excellent DOI correction and high detection efficiency of our detectors, are expected to facilitate high and uniform PET system resolution.	[Maas, Marnix C.; Schaart, Dennis R.; van der Laan, D. J. (Jan); Beekman, Freek J.; van Eijk, Carel W. E.] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Bruyndonckx, Peter; Lemaitre, Cedric] Vrije Univ Brussels, B-1050 Brussels, Belgium; [Beekman, Freek J.] Univ Med Ctr Utrecht, Utrecht, Netherlands	Maas, MC (reprint author), Delft Univ Technol, Mekelweg 15, NL-2629 JB Delft, Netherlands.	d.r.schaart@tudelft.nl	Schaart, Dennis/C-7136-2014; Maas, Marnix/J-5101-2014	Schaart, Dennis/0000-0002-3199-5608; 			Abreu MC, 2006, IEEE T NUCL SCI, V53, P71, DOI 10.1109/TNS.2006.870173; Bloomfield PM, 1997, PHYS MED BIOL, V42, P389, DOI 10.1088/0031-9155/42/2/010; Bruyndonckx P, 2003, IEEE T NUCL SCI, V50, P1415, DOI 10.1109/TNS.2003.817348; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; Catana C, 2006, J NUCL MED, V47, P1968; Clement D., 1998, 1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255), DOI 10.1109/NSSMIC.1998.773818; Correia JA, 1999, IEEE T NUCL SCI, V46, P631, DOI 10.1109/23.775590; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Haas JTM, 2005, NUCL INSTRUM METH A, V537, P97, DOI 10.1016/j.nima.2004.07.243; Del Guerra A, 1998, NUCL INSTRUM METH A, V409, P537, DOI 10.1016/S0168-9002(97)01311-9; Du HN, 2008, PHYS MED BIOL, V53, P1829, DOI 10.1088/0031-9155/53/7/002; Judenhofer MS, 2008, NAT MED, V14, P459, DOI 10.1038/nm1700; Lecomte R, 1996, IEEE T NUCL SCI, V43, P1952, DOI 10.1109/23.507252; Maas MC, 2008, IEEE T NUCL SCI, V55, P842, DOI 10.1109/TNS.2008.921493; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; MAAS MC, 2008, THESIS DELFT U TECHN; McElroy DP, 2005, IEEE T NUCL SCI, V52, P199, DOI 10.1109/TNS.2004.843114; Orita N, 2005, IEEE T NUCL SCI, V52, P8, DOI 10.1109/TNS.2004.843158; Seidel J, 2003, IEEE T NUCL SCI, V50, P1347, DOI 10.1109/TNS.2003.817282; Surti S, 2003, IEEE T NUCL SCI, V50, P1357, DOI 10.1109/TNS.2003.817950; Tai YC, 2003, PHYS MED BIOL, V48, P1519, DOI 10.1088/0031-9155/48/11/303; Tai YC, 2005, J NUCL MED, V46, P455; van der Laan DJ, 2007, NUCL INSTRUM METH A, V571, P227, DOI 10.1016/j.nima.2006.10.069; van der Laan DJJ, 2006, IEEE T NUCL SCI, V53, P1063, DOI 10.1109/TNS.2006.873710; Wang GC, 2004, IEEE T NUCL SCI, V51, P775, DOI 10.1109/TNS.2004.829785; Weber S, 1999, IEEE NUCL SCI CONF R, P1603, DOI 10.1109/NSSMIC.1999.842872; Woody C, 2007, NUCL INSTRUM METH A, V571, P102, DOI 10.1016/j.nima.2006.10.039; Ziemons K, 2005, NUCL INSTRUM METH A, V537, P307, DOI 10.1016/j.nima.2004.08.032	28	52	52	1	8	IOP PUBLISHING LTD	BRISTOL	DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND	0031-9155			PHYS MED BIOL	Phys. Med. Biol.	APR 7	2009	54	7					1893	1908		10.1088/0031-9155/54/7/003		16	Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Radiology, Nuclear Medicine & Medical Imaging	420LY	WOS:000264292500003	19265203	
J	Zeng, Y; Yang, YP; Zhao, L				Zeng, Yong; Yang, Yupu; Zhao, Liang			Nonparametric classification based on local mean and class statistics	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						k-nearest neighbor classification rule (k-NNR); Local mean; Statistic; Distance measure; Cross-validation		The k-nearest neighbor classification rule (k-NNR) is a very simple, yet powerful nonparametric classification method. As a variant of the k-NNR, a nonparametric classification method based on the local mean vector has achieved good classification performance. In pattern classification, the sample mean and sample covariance are the most important statistics related to class discriminatory information. In this paper, a new variant of the k-NNR, a nonparametric classification method based on the local mean vector and class statistics has been proposed. Not only the local information of the k nearest neighbors of the unclassified pattern in each individual class but also the global knowledge of samples in each individual class are taken into account in this new classification method. The proposed classification method is compared with the k-NNR, and the local mean-based nonparametric classification in terms of the classification error rate on the unknown patterns. Experimental results confirm the validity of this new classification approach. (C) 2008 Elsevier Ltd. All rights reserved.	[Zeng, Yong; Yang, Yupu; Zhao, Liang] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China	Zeng, Y (reprint author), Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.	zeng_yong@sjtu.edu.cn					Asuncion A., 2007, UCI MACHINE LEARNING; Bhattacharyya A., 1943, Bulletin of the Calcutta Mathematical Society, V35; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R. O., 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K., 1990, INTRO STAT PATTERN R; Jain A. K., 1988, PATTERN RECOGNITION; Mitani Y, 2006, PATTERN RECOGN LETT, V27, P1151, DOI 10.1016/j.patrec.2005.12.016; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P667; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6	11	9	10	0	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	MAY	2009	36	4					8443	8448		10.1016/j.eswa.2008.10.041		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	423WX	WOS:000264528600126		
J	Wang, Q; Kulkarni, SR; Verdu, S				Wang, Qing; Kulkarni, Sanjeev R.; Verdu, Sergio			Divergence Estimation for Multidimensional Densities Via k-Nearest-Neighbor Distances	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article; Proceedings Paper	IEEE International Symposium on Information Theory	JUL 09-14, 2006	Seattle, WA	IEEE Informat Theory Soc, USN, Dept Navy Sci & Technol, Microsoft, Natl Sci Fdn		Divergence; information measure; Kullback-Leibler; nearest-neighbor; partition; random vector; universal estimation	MUTUAL INFORMATION; CONSISTENCY; ENTROPY	A new universal estimator of divergence is presented for multidimensional continuous densities based on k-nearest-neighbor (k-NN) distances. Assuming independent and identically distributed (i.i.d.) samples, the new estimator is proved to be asymptotically unbiased and mean-square consistent. In experiments with high-dimensional data, the k-NN approach generally exhibits faster convergence than previous algorithms. It is also shown that the speed of convergence of the k-NN method can be further improved by an adaptive choice of k.	[Wang, Qing] Credit Suisse Grp, New York, NY 10010 USA; [Kulkarni, Sanjeev R.; Verdu, Sergio] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA	Wang, Q (reprint author), Credit Suisse Grp, New York, NY 10010 USA.	qingwang@princeton.edu; kulkarni@princeton.edu; verdu@princeton.edu					BENTLEY J. L., 1975, COMMUN ACM, V18, P509; BHATTACH.PK, 1967, ANN MATH STAT, V38, P1770, DOI 10.1214/aoms/1177698611; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasu T., 2006, P 38 S INT STAT COMP; Dawy Z, 2006, IEEE ACM T COMPUT BI, V3, P47, DOI 10.1109/TCBB.2006.9; DAWY Z, 2005, P 2005 IEEE INT C CO, V2, P815; DEVROYE L, 1996, PROBABLISTIC THEORY; DEVROYE L, 1994, ANN STAT, V22, P1371, DOI 10.1214/aos/1176325633; DEVROYE LP, 1977, ANN STAT, V5, P536, DOI 10.1214/aos/1176343851; Devroye L., 1987, PROGR PROBABILITY ST, V14; Dhillon I. S., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753661; Feller W, 1970, INTRO PROBABILITY TH; Fix E., 1951, 4 USAF SCH AV MED; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Goldberger J, 2003, P 9 IEEE INT C COMP, V1, P487, DOI [DOI 10.1109/ICCV.2003.1238387, 10.1109/ICCV.2003.1238387]; Goria MN, 2005, J NONPARAMETR STAT, V17, P277, DOI 10.1080/104852504200026815; Hinneburg A., 2000, P 26 INT C VER LARG, P506; Johnson DH, 2001, J COMPUT NEUROSCI, V10, P47, DOI 10.1023/A:1008968010214; Kozachenko L. F., 1987, Problems of Information Transmission, V23; Kraskov A., 2004, PHYS REV E, V69; KRISHNAMURTHY B, 2005, P 21 INT C DAT ENG W, P1185; Kulkarni SR, 2002, IEEE T INFORM THEORY, V48, P2785, DOI 10.1109/TIT.2002.802611; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lebesgue H., 1910, ANN ECOLE NORM, V27, P361; Leonenko N, 2008, TATRA MT MATH PUBL, V39, P265; Liu C., 2003, P IEEE C COMP VIS PA, P1; Loeve M., 1977, PROBABILITY THEORY; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MATHIASSEN JR, 2002, P 7 EUR C COMP VIS 3, P133; Ramirez J, 2004, IEEE SIGNAL PROC LET, V11, P266, DOI 10.1109/LSP.2003.821762; Sarkis M, 2007, IEEE SIGNAL PROC MAG, V24, P83, DOI 10.1109/MSP.2007.273061; SCHNEIDMAN E, 2003, ADV NEURAL INFORM PR, V15, P197; Silverman BW, 1986, DENSITY ESTIMATION S; Steuer R, 2002, BIOINFORMATICS, V18, pS231; Tsybakov AB, 1996, SCAND J STAT, V23, P75; Verdu S, 2005, Proceedings of the IEEE ITSOC Information Theory Workshop 2005 on Coding and Complexity, P232; VICTOR JD, 2002, PHYS REV E, V66; Wang Q, 2006, P IEEE INT S INF THE, P242; Wang Q, 2005, IEEE T INFORM THEORY, V51, P3064, DOI 10.1109/TIT.2005.853314; Wilson R, 2007, IEEE T INF FOREN SEC, V2, P364, DOI 10.1109/TIFS.2007.902666; Ye C., 2006, P IEEE INT S INF THE, P2593	41	33	33	1	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	MAY	2009	55	5					2392	2405		10.1109/TIT.2009.2016060		14	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	440PU	WOS:000265713000034		
J	Lazzaroni, M; Ferrari, S; Cristaldi, L; Annoni, M				Lazzaroni, Massimo; Ferrari, Stefano; Cristaldi, Loredana; Annoni, Massimiliano			Nozzle and Working-Condition Classifications for Water Jet Systems	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Fault diagnosis; feature extraction; pattern classification; pattern recognition (PR); power measurement; statistical process control; water jet systems		In this paper, a technique for assessing both the working and healthy conditions of water jet-system nozzles is presented. The proposed classifier is based on the discrete Fourier transform (DFT) of the instantaneous electrical power signal. With this in mind, it will be shown that the electrical power signal supports all necessary information to characterize both the working condition of the system and the nozzle type. Furthermore, the same signal can be analyzed with the aim of predicting the presence of an incoming faulty behavior. The presented technique is also used to build a second type of classifier. While the first one is of general application, the second one can be used when the properties of the orifice are known, and only the working conditions have to be classified. Results show the effectiveness of the proposed approach, which, due to its simplicity, can be embedded in a low-cost real-time diagnostic system. For the sake of clarity, a brief description of a water jet system is also presented.	[Lazzaroni, Massimo; Ferrari, Stefano] Univ Milan, Dept Informat Technol, I-26013 Crema, Italy; [Cristaldi, Loredana] Politecn Milan, Dipartimento Elettrotecn, I-20133 Milan, Italy; [Annoni, Massimiliano] Politecn Milan, Dipartimento Meccan, I-20133 Milan, Italy	Lazzaroni, M (reprint author), Univ Milan, Dept Informat Technol, I-26013 Crema, Italy.	lazzaroni@dti.unimi.it; ferrari@dti.unimi.it; loredana.cristaldi@polimi.it; massimiliano.annoni@polimi.it	Ferrari, Stefano/F-3407-2010	Ferrari, Stefano/0000-0002-4982-6212			ANNONI A, 2005, P IMTC OTT ON CAN MA, P1311; ANNONI M, 2007, P IEEE INSTR MEAS TE, P1; ANNONI M, 2004, P 17 INT C WAT JETT, P415; BRIAN C, 2003, MATH COMP MODEL DYN, V9, P45; CHALMERS EJ, 1993, P 7 AM WAT JET C AUG, P327; Cherkassky V., 1998, LEARNING DATA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristaldi L, 2004, IEEE T INSTRUM MEAS, V53, P1020, DOI 10.1109/TIM.2004.830589; Friedman M, 1999, INTRO PATTERN RECOGN; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; LAZZARONI M, 2008, P IEEE INT INSTR MEA, P1435; RAMULU M, 1999, P 10 AM WAT C; SINGH PJ, 1997, P 9 AM WAT C, P397; TUNKEL RN, 1997, P 9 AM WAT C	15	0	0	0	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9456			IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	MAY	2009	58	5					1546	1554		10.1109/TIM.2009.2012961		9	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	435WH	WOS:000265373500033		
J	Diamantini, C; Potena, D				Diamantini, Claudia; Potena, Domenico			Bayes Vector Quantizer for Class-Imbalance Problem	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Class imbalance; labeled vector quantizer; average misclassification risk minimization; cost-sensitive learning		The class-imbalance problem is the problem of learning a classification rule from data that are skewed in favor of one class. On these data sets, traditional learning techniques tend to overlook the less numerous classes, at the advantage of the majority class. However, the minority class is often the most interesting one for the task at hand. For this reason, the class-imbalance problem has received increasing attention in the last few years. In the present paper, we point the attention of the reader to a learning algorithm for the minimization of the average misclassification risk. In contrast to some popular class-imbalance learning methods, this method has its roots in statistical decision theory. A particular interesting characteristic is that when class distributions are unknown, the method can work by resorting to stochastic gradient algorithm. We study the behavior of this algorithm on imbalanced data sets, demonstrating that this principled approach allows to obtain better classification performances compared to the principal methods proposed in the literature.	[Diamantini, Claudia; Potena, Domenico] Univ Politecn Marche, Dipartimento Ingn Informat Gest & Automaz, I-60131 Ancona, Italy	Diamantini, C (reprint author), Univ Politecn Marche, Dipartimento Ingn Informat Gest & Automaz, Via Brecce Bianche 12, I-60131 Ancona, Italy.	diamantin@diiga.univpm.it; potena@diiga.univpm.it	Potena, Domenico/J-8653-2013	Potena, Domenico/0000-0002-7067-5463			Akbani R, 2004, P 15 EUR C MACH LEAR, P39; Asuncion A., 2007, UCI MACHINE LEARNING; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Diamantini C., 2000, ACM SIGKDD EXPLORATI, V2, P54; Diamantini C, 1998, IEEE T NEURAL NETWOR, V9, P174, DOI 10.1109/72.655039; Dietterich T, 2002, HDB BRAIN THEORY NEU; Domingos P., 1999, P 5 INT C KNOWL DISC, P155, DOI 10.1145/312129.312220; Drummond C., 2003, ICML WORKSH LEARN IM; Elkan Charles, 2001, P 17 INT JOINT C ART, P973; Frank E., 2005, DATA MINING PRACTICA; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; Fukunaga K., 1990, INTRO STAT PATTERN R; Gersho A., 1992, VECTOR QUANTIZATION; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; KARAKOULAS G, 1999, P NEUR INF PROC WORK, P253; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Kohonen T., 1988, P IEEE INT C NEUR NE, P61; Kubal M., 1997, P 9 EUR C MACH LEARN, P146; KUKAR M, 1998, P 10 EUR C MACH LEAR, P268; Liu XY, 2006, IEEE DATA MINING, P965; Liu XY, 2006, IEEE DATA MINING, P970; Maloof M.A., 2003, ICML WORKSH LEARN IM; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; MELVILLE P, 2005, P 16 EUR C MACH LEAR, P268; Provost F, 2000, AAAI WORKSH LEARN IM, P1; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Richard M. D., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.4.461; Saitta L., 2000, MACHINE LEARNING TEC; Sheng V.S., 2006, P 21 NAT C ART INT, P476; Ting KM, 2000, P 17 INT C MACH LEAR, P983; Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659; Vapnik V., 1998, STAT LEARNING THEORY; Veropoulos K., 1999, P INT JOINT C ART IN, P55; Vlachos M., 2002, P 8 ACM SIGKDD INT C, P645; Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849; Weiss G. M., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI DOI 10.1145/1007730.1007734; Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63	41	7	9	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAY	2009	21	5					638	651		10.1109/TKDE.2008.187		14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	420PB	WOS:000264300600003		
J	Li, FY; Wechsler, H				Li, Fayin; Wechsler, Harry			FACE AUTHENTICATION USING RECOGNITION-BY-PARTS, BOOSTING AND TRANSDUCTION	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Authentication; biometrics; boosting; clustering; cross-validation; data fusion; dimensionality reduction; face recognition; feature selection; forensics; k-nearest neighbor; likelihood ratio; margin; Neyman-Pearson; occlusion; open set recognition; p-values; ranking; recognition-by-parts; segmentation; SIFT; strangeness; surveillance; transduction; typicality	FORENSIC SPEAKER RECOGNITION; OBJECT RECOGNITION; CORTEX	The paper describes an integrated recognition-by-parts architecture for reliable and robust face recognition. Reliability and robustness are characteristic of the ability to deploy full-fledged and operational biometric engines, and handling adverse image conditions that include among others uncooperative subjects, occlusion, and temporal variability, respectively. The architecture proposed is model-free and non-parametric. The conceptual framework draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak-learners. Face authentication shares the same implementation with face detection. The implementation, driven by transduction, employs proximity and typicality (ranking) realized using strangeness and p-values, respectively. The feasibility and reliability of the proposed architecture are illustrated using FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the proposed architecture.	[Li, Fayin; Wechsler, Harry] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Li, FY (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	fayin.li@gmail.com; wechsler@gmu.edu					Anderson K, 2004, COMPUT VIS IMAGE UND, V95, P184, DOI 10.1016/j.cviu.2004.01.001; ASHRAF AB, 2008, LEARNING PATCH CORRE; Balas BJ., 2006, ACM T APPL PERCEPT, V3, P354, DOI 10.1145/1190036.1190038; Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; BLACK B, 1994, TEX LAW REV, V72, P715; Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3; Chapelle O., 2006, SEMISUPERVISED LEARN; Cherkassky V., 2007, LEARNING FROM DATA; Cott H., 1966, ADAPTIVE COLORATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DESSIMOZ D, 2008, HDB BIOMETRICS; Dhillon I.S., 2004, KERNEL K MEANS SPECT; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Edelman G.M., 1987, NEURAL DARWINISM; El-Yaniv R, 2005, PATTERN RECOGN LETT, V26, P2104, DOI 10.1016/j.patrec.2005.03.025; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freund Y., 1996, 13 INT C MACH LEARN, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gonzalez-Rodriguez J, 2007, IEEE T AUDIO SPEECH, V15, P2104, DOI 10.1109/TASL.2007.902747; GURARI EM, 1982, IEEE T PATTERN ANAL, V4, P304; GUTTA S, 2004, 1 INT C BIOM AUTH HO; Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z; Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; Koller D., 1996, 13 INT C MACH LEARN; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lai H, 2008, COMPUT VIS IMAGE UND, V111, P329, DOI 10.1016/j.cviu.2008.01.003; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686; Li M., 1997, INTRO KOLMOGOROV COM; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUCEY S, 2006, LEARNING PATCH DEPEN; McNeill Daniel, 1998, FACE NATURAL HIST; Melluish T., 2001, TYPICALNESS FRAMEWOR; PHILLIPS PJ, 2005, COMPUTER VISION PATT; Pinto N., 2008, PLOS COMPUTATIONAL B, V4, P151; PRODROU K, 2002, P 13 EUR C MACH LEAR, P381; Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714; Rubinstein Y., 1997, KDD, P49; Rullen R. V., 1998, BIOSYSTEMS, V48, P229; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Singh R, 2009, IMAGE VISION COMPUT, V27, P245, DOI 10.1016/j.imavis.2007.06.010; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Tsunoda K, 2001, NAT NEUROSCI, V4, P832, DOI 10.1038/90547; Vapnik V, 2000, NATURE STAT LEARNING; Vapnik V., 1998, STAT LEARNING THEORY; Viola P., 2001, RAPID OBJECT DETECTI; VOVK V, 1999, 16 INT C MACH LEARN; WISCOTT L, 1997, IEEE PATTERN RECOGNI, V19, P775	49	4	4	1	5	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	MAY	2009	23	3					545	573				29	Computer Science, Artificial Intelligence	Computer Science	459PC	WOS:000267114600009		
J	Wang, LW; Sugiyama, M; Yang, C; Hatano, K; Feng, JF				Wang, Liwei; Sugiyama, Masashi; Yang, Cheng; Hatano, Kohei; Feng, Jufu			Theory and Algorithm for Learning with Dissimilarity Functions	NEURAL COMPUTATION			English	Article							COVARIATE SHIFT; REPRESENTATION; CLASSIFICATION; RECOGNITION; DISTANCE; KERNELS; IMAGES	We study the problem of classification when only a dissimilarity function between objects is accessible. That is, data samples are represented not by feature vectors but in terms of their pairwise dissimilarities. We establish sufficient conditions for dissimilarity functions to allow building accurate classifiers. The theory immediately suggests a learning paradigm: construct an ensemble of simple classifiers, each depending on a pair of examples; then find a convex combination of them to achieve a large margin. We next develop a practical algorithm referred to as dissimilarity-based boosting (DBoost) for learning with dissimilarity functions under theoretical guidance. Experiments on a variety of databases demonstrate that the DBoost algorithm is promising for several dissimilarity measures widely used in practice.	[Wang, Liwei; Yang, Cheng; Feng, Jufu] Peking Univ, MOE Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Beijing 100871, Peoples R China; [Sugiyama, Masashi] Tokyo Inst Technol, Dept Comp Sci, Meguro Ku, Tokyo 1528552, Japan; [Hatano, Kohei] Kyushu Univ, Dept Informat, Nishi Ku, Fukuoka 8190395, Japan	Wang, LW (reprint author), Peking Univ, MOE Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Beijing 100871, Peoples R China.	wanglw@cis.pku.edu.cn; sugi@cs.titech.ac.jp; yangch@cis.pku.edu.cn; hatano@i.kyushu-u.ac.jp; fjf@cis.pku.edu.cn			NSFC [60775005, 60635030]; Tokyo Institute of Technology	We thank Masayuki Takeda for kindly providing us Japanese song data, and we also thank Kazuhito Hagio for preprocessing them. This work was supported by NSFC(60775005, 60635030) and Global COE Program of the Tokyo Institute of Technology.	Asuncion A., 2007, UCI MACHINE LEARNING; BALCAN MF, 2006, P INT C MACH LEARN; Balcan MF, 2006, MACH LEARN, V65, P79, DOI 10.1007/s10994-006-7550-1; BALCAN MF, 2008, P 21 ANN C LEARN THE; BALCAN MF, 2004, P INT WORKSH ALG LEA; Balcan MF, 2008, MACH LEARN, V72, P89, DOI 10.1007/s10994-008-5059-5; BREIMAN L, 1984, CLASSIFICATION TREES; Chang Chih-Chung, 2001, LIB SUPPORT VECTOR M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FREUND Y, 1996, P INT C MACH LEARN S; Fukunaga K., 1990, INTRO STAT PATTERN R; GARTNER T, 2003, SIGKDD EXPLORATIONS, V5, pS268; Goldfarb L, 1985, PROGR PATTERN RECOGN, V2, P241; GRAEPEL T, 1999, ADV NEURAL INFORM PR, V12; HAGIO K, 2006, THESIS KYUSHU U; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Li JL, 2002, IEEE T IMAGE PROCESS, V11, P636, DOI 10.1109/TIP.2002.1014995; Maltoni Davide, 2003, HDB FINGERPRINT RECO; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Saigo H, 2004, BIOINFORMATICS, V20, P1682, DOI 10.1093/bioinformatics/bth141; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 1998, ANN STAT, V26, P1651; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Simard P., 1993, ADV NEURAL INFORM PR, V5; SREBRO N, 2007, P 20 ANN C LEARN THE; Sugiyama M, 2007, J MACH LEARN RES, V8, P985; Vapnik V., 1998, STAT LEARNING THEORY; WANG L, 2008, P 21 ANN C LEARN THE; Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	32	4	4	1	2	M I T PRESS	CAMBRIDGE	238 MAIN STREET, STE 500, CAMBRIDGE, MA 02142-1046 USA	0899-7667			NEURAL COMPUT	Neural Comput.	MAY	2009	21	5					1459	1484		10.1162/neco.2008.08-06-805		26	Computer Science, Artificial Intelligence	Computer Science	446FT	WOS:000266106800010	19718819	
J	Wang, Y; Li, L; Ni, J; Huang, SH				Wang, Yong; Li, Lin; Ni, Jun; Huang, Shuhong			Feature selection using tabu search with long-term memories and probabilistic neural networks	PATTERN RECOGNITION LETTERS			English	Article						Feature selection; Tabu Search; Probabilistic neural network; Curse of dimensionality; Smoothing parameter	PATTERN-CLASSIFICATION; BOUND ALGORITHM; BRANCH	Feature selection is a dimensionality reduction problem in order to reduce measurement costs, shorten computational time, relieve the curse of dimensionality. and improve classification accuracy. In this paper, a hybrid approach using tabu search and probabilistic neural networks is proposed and applied to feature selection problems. The proposed tabu search algorithm differs from previous research by using a long-term memory instead of a short-term memory to avoid the necessity of the delicate tuning of the memory length and to decrease the risk of generating a cycle that traps the search in local optimal Solutions. The probabilistic neural networks integrated in the proposed hybrid approach are an outgrowth of Bayesian classifiers that outperform backpropagation-based neural networks in their global convergence and rapid training. Extensive experiments on real-world data sets are performed and the comparison with previous research indicates that the proposed hybrid approach can select an equal or smaller number of features while improving classification accuracy. (C) 2009 Elsevier B.V. All rights reserved.	[Wang, Yong; Li, Lin; Ni, Jun] Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48105 USA; [Wang, Yong; Huang, Shuhong] Huazhong Univ Sci & Technol, Sch Energy & Power Engn, Wuhan 430074, Peoples R China	Li, L (reprint author), Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48105 USA.	lilz@umich.edu			China Scholarship Council; S.M. Wu Manufacturing Research Center at the University of Michigan-Ann Arbor	This work is sponsored by China Scholarship Council and S.M. Wu Manufacturing Research Center at the University of Michigan-Ann Arbor. The authors Would like to thank the UCI Machine Learning Repository for providing the data sets used in this paper. The authors Would also like to thank Dr. Muhammad Atif Tahir for his helpful explanations to our questions regarding to his work (Tahir et al., 2007).	Asuncion A., 2007, UCI MACHINE LEARNING; Billings SA, 2007, NEURAL NETWORKS, V20, P1081, DOI 10.1016/j.neunet.2007.09.017; Bishop C.M., 1995, NEURAL NETWORKS PATT; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Dreo J., 2006, METAHEURISTICS HARD; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; Glover F., 1997, TABU SEARCH; GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; HUANG CJ, 2003, P 15 IEEE INT C TOOL; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kohavi R, 1997, ARTIF INTELL, V1, P273; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; Mao KZ, 2000, IEEE T NEURAL NETWOR, V11, P1009, DOI 10.1109/72.857781; NARENDRA P, 1977, IEEE T COMPUT, V26, P917; Pudil P., 1994, PATTERN RECOGN, V2, P279, DOI 10.1109/ICPR.1994.576920; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ripley BD, 1996, PATTERN RECOGNITION; SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8; Somol P, 1999, PATTERN RECOGN LETT, V20, P1157, DOI 10.1016/S0167-8655(99)00083-5; SPECHT DF, 1992, INT JOINT C NEUR NET; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Wasserman PD, 1993, ADV METHODS NEURAL C; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2	28	8	11	0	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY 1	2009	30	7					661	670		10.1016/j.patrec.2009.02.001		10	Computer Science, Artificial Intelligence	Computer Science	440VI	WOS:000265727400002		
J	Castro, JL; Navarro, M; Sanchez, JM; Zurita, JM				Castro, J. L.; Navarro, M.; Sanchez, J. M.; Zurita, J. M.			Loss and gain functions for CBR retrieval	INFORMATION SCIENCES			English	Article						CBR; Similarity; Probability; Fuzzy system; Retrieval stage	REASONING SYSTEM; INCREMENTAL DEVELOPMENT; REDUCTION TECHNIQUE; SIMILARITY MEASURES; MEDICAL DIAGNOSIS; DECISION-THEORY; CLASSIFICATION; PREDICTION; WEIGHTS; MODEL	The method described in this article evaluates case similarity in the retrieval stage of case-based reasoning (CBR). It thus plays a key role in deciding which case to select, and therefore, in deciding which solution will be eventually applied. In CBR, there are many retrieval techniques. One feature shared by most is that case retrieval is based on attribute similarity and importance. However, there are other crucial factors that should be considered, such as the possible consequences of a given solution, in other words its potential loss and gain. As their name clearly implies, these concepts are defined as functions measuring loss and gain when a given retrieval case solution is applied. Moreover, these functions help the user to choose the best solution so that when a mistake is made the resulting loss is minimal. In this way, the highest benefit is always obtained. (C) 2009 Elsevier Inc. All rights reserved.	[Castro, J. L.; Navarro, M.; Sanchez, J. M.; Zurita, J. M.] Univ Granada, ETSI Informat, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain	Zurita, JM (reprint author), Univ Granada, ETSI Informat, Dept Comp Sci & Artificial Intelligence, C Daniel Saucedo Aranda S-N, E-18071 Granada, Spain.	castro@decsai.ugr.es; marianj@decsai.ugr.es; jmsa@decsai.ugr.es; zurita@decsai.ugr.es	Castro, Juan Luis/C-2403-2012; Zurita , Jose Manuel/E-1037-2012		Ministerio de Educacion y Ciencia [TIN2006-03122, TIN2004-07236]	The authors would like to thank and Ministerio de Educacion y Ciencia that support this paper with its Projects: TIN2006-03122 and TIN2004-07236. And also to Dr. Lucia Martin Romera for checking the examples.	Ahn H, 2007, EXPERT SYST APPL, V32, P1011, DOI 10.1016/j.eswa.2006.02.021; Allais Maurice, 1979, EXPECTED UTILITY HYP; AAMODT A, 1994, AI COMMUN, V7, P39; Bayes T., 1763, PHILOS T ROY SOC LON, V53, P370, DOI DOI 10.1098/RSTL.1763.0053; BECKER GM, 1964, BEHAV SCI, V9, P226, DOI 10.1002/bs.3830090304; Bichindaritz I, 2006, ARTIF INTELL MED, V36, P127, DOI 10.1016/j.artmed.2005.10.008; CASTRO JL, 2006, P EUR MED C INF SYST; CASTRO JL, 2008, P IADIS MULT C COMP, P151; Castro J.L., 2007, P 7 INT C CAS BAS RE, P21; Chang PC, 2008, EXPERT SYST APPL, V34, P2049, DOI 10.1016/j.eswa.2007.02.011; Cheng MY, 2009, EXPERT SYST APPL, V36, P4106, DOI 10.1016/j.eswa.2008.03.025; Chiu C.C., 2007, LECT NOTES COMPUTER, P541; CHIU CY, 2007, P 4 INT C FUZZ SYST, P344; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daengdej J, 1997, KNOWL-BASED SYST, V10, P153, DOI 10.1016/S0950-7051(97)00027-0; De Groot Morris, 1970, OPTIMAL STAT DECISIO; Dogan SZ, 2008, J CONSTR ENG M ASCE, V134, P146, DOI 10.1061/(ASCE)0733-9364(2008)134:2(146); EDWARDS AWF, 1974, INT STAT REV, V42, P9, DOI 10.2307/1402681; ELTER M, 2007, COMPUTER ASSISTED RA, V2, P340; FISHBURN PC, 1981, THEOR DECIS, V13, P39; Frank E., 2005, DATA MINING PRACTICA; Gancarski P, 2008, PATTERN RECOGN, V41, P983, DOI 10.1016/j.patcog.2007.07.008; Gu M., 2005, IEEE INT C INF REUS, P427; Ha SH, 2008, APPL INTELL, V29, P279, DOI 10.1007/s10489-007-0094-7; Hammond K. J., 1989, CASE BASED PLANNING; Hoffmann A, 2006, APPL ARTIF INTELL, V20, P507, DOI 10.1080/08839510600753782; Hsu CC, 2004, INFORM SCIENCES, V166, P231, DOI 10.1016/j.ins.2003.11.009; Im KH, 2007, EXPERT SYST APPL, V32, P77, DOI 10.1016/j.eswa.2005.11.020; Juarez JM, 2009, FUZZY SET SYST, V160, P214, DOI 10.1016/j.fss.2008.05.017; KOLODNER JL, 1983, COGNITIVE SCI, V7, P281, DOI 10.1207/s15516709cog0704_2; Kolodner J. L., 1993, CASE BASED REASONING; Lavrac N, 1999, ARTIF INTELL MED, V16, P3, DOI 10.1016/S0933-3657(98)00062-1; Leake D. B., 1996, CASE BASED REASONING; Li H, 2008, KNOWL-BASED SYST, V21, P868, DOI 10.1016/j.knosys.2008.03.047; Li H, 2006, INFORM SCIENCES, V176, P2960, DOI 10.1016/j.ins.2005.09.003; Li Qing, 2007, Journal of Beijing University of Aeronautics and Astronautics, V33; Liao TW, 2000, ENG APPL ARTIF INTEL, V13, P199, DOI 10.1016/S0952-1976(99)00052-4; Liao TW, 1998, APPL ARTIF INTELL, V12, P267, DOI 10.1080/088395198117730; Liu CH, 2008, INFORM SCIENCES, V178, P3347, DOI 10.1016/j.ins.2008.05.006; Nash JF, 1950, ECONOMETRICA, V18, P155, DOI 10.2307/1907266; Negny S, 2008, COMPUT-AIDED CHEM EN, V25, P1009; Nunez H, 2004, ENVIRON MODELL SOFTW, V19, P809, DOI 10.1016/j.envsoft.2003.03.003; Park CS, 2002, EXPERT SYST APPL, V23, P255, DOI 10.1016/S0957-4174(02)00045-3; Park YJ, 2006, EXPERT SYST, V23, P2, DOI 10.1111/j.1468-0394.2006.00321.x; Peng J.C., 1975, 78 STANF U DEP STAT; Raiffa H., 1976, DECISIONS MULTIPLE O; Raphael B, 2007, ADV ENG INFORM, V21, P311, DOI [10.1016/j.aei.2007.02.001, 10.1109/TCAD.2007.02.001]; Renaud J, 2008, MATH COMPUT SIMULAT, V77, P499, DOI 10.1016/j.matcom.2007.11.024; Rubin H., 1987, STATISTICS DECISIONS, V5, P47; Sadek AW, 2001, TRANSPORT RES C-EMER, V9, P353, DOI 10.1016/S0968-090X(00)00046-2; Schaaf JW, 1996, LECT NOTES ARTIF INT, V1168, P362; Schank R., 1977, SCRIPTS PLANS GOALS; Schank R., 1982, DYNAMIC MEMORY THEOR; Shin KS, 1999, EXPERT SYST APPL, V16, P85, DOI 10.1016/S0957-4174(98)00063-3; Singh M, 2005, PATTERN RECOGN LETT, V26, P1995, DOI 10.1016/j.patrec.2005.03.015; Smyth B, 1998, ARTIF INTELL, V102, P249, DOI 10.1016/S0004-3702(98)00059-9; Sun ZH, 2004, INFORM SCIENCES, V165, P21, DOI 10.1016/j.ins.2003.09.020; TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116; Tsatsoulis C, 1997, IEEE EXPERT, V12, P46, DOI 10.1109/64.608193; Tsui K.W., 1979, CANAD J STAT, V7, P193, DOI 10.2307/3315119; Wald A, 1950, STAT DECISION FUNCTI; Watson I, 1999, KNOWL-BASED SYST, V12, P303, DOI 10.1016/S0950-7051(99)00020-9; WEERAHANDI S, 1983, ANN STAT, V11, P1032; Zhuang ZY, 2009, EUR J OPER RES, V195, P662, DOI 10.1016/j.ejor.2007.11.003; ZIDEK JV, 1986, STAT DECISIONS, V4, P1	65	27	32	2	13	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	MAY 13	2009	179	11					1738	1750		10.1016/j.ins.2009.01.017		13	Computer Science, Information Systems	Computer Science	435BL	WOS:000265318100017		
J	Baroni, MV; Arrua, C; Nores, ML; Faye, P; Diaz, MDP; Chiabrando, GA; Wunderlin, DA				Veronica Baroni, Maria; Arrua, Carina; Laura Nores, Maria; Faye, Pablo; del Pilar Diaz, Maria; Alberto Chiabrando, Gustavo; Alberto Wunderlin, Daniel			Composition of honey from Cordoba (Argentina): Assessment of North/South provenance by chemometrics	FOOD CHEMISTRY			English	Article						Honey; Geographical origin; Metals; Chemical traceability; Multivariate statistics	AMINO-ACID-COMPOSITION; MINERAL-CONTENT; PHYSICOCHEMICAL CHARACTERISTICS; FLUORESCENCE SPECTROSCOPY; GEOGRAPHICAL ORIGIN; BOTANICAL ORIGIN; SPANISH HONEYS; FLORAL ORIGIN; CLASSIFICATION; POLLEN	We report the characterisation of honey samples produced in Cordoba (Argentina) and their classification by geographical provenance (North/South) using chemometrics. Twenty-two variables were analysed considering both chemical properties and mineral profile. Honey samples were found to meet the international specifications for the evaluated parameters. Classification of honey in according to its geographical provenance (North/South) was achieved by pattern recognition techniques applied to 15 out of 22 variables. Glucose. pH, free acidity, free amino acids, calcium and zinc were selected by stepwise discriminant analysis, explaining the classification of honey according to their geographical origin. Application of k-nearest-neighbour classification procedure to these six selected variables produced a successful assignation (99% correct) of honey to its provenance. On the other hand only 83% right assignation was observed, when the 15 variables were used, confirming that the use of all available features is unnecessary to get good geographical discrimination. (C) 2008 Elsevier Ltd. All rights reserved.	[Veronica Baroni, Maria; Arrua, Carina; Alberto Chiabrando, Gustavo; Alberto Wunderlin, Daniel] Univ Nacl Cordoba, CONICET, Fac Ciencias Quim, Dto Bioquim Clin, RA-5000 Cordoba, Argentina; [Laura Nores, Maria] Univ Nacl Cordoba, CONICET, Fac Ciencias Med, RA-5000 Cordoba, Argentina; [Faye, Pablo] Univ Nacl Cordoba, Fac Ciencias Agropecuarias, RA-5000 Cordoba, Argentina; [del Pilar Diaz, Maria] Univ Nacl Cordoba, Fac Ciencias Med, Escuela Nutr, RA-5000 Cordoba, Argentina	Wunderlin, DA (reprint author), Univ Nacl Cordoba, CONICET, Fac Ciencias Quim, Dto Bioquim Clin, Ciudad Univ, RA-5000 Cordoba, Argentina.	dwunder@fcq.unc.edu.ar		Baroni, Maria Veronica/0000-0001-9316-7907	CONICET (National Research Council-Argentina); Secretaria de Ciencia y Tecnica-Universidad Nacional de Cordoba (Science Secretary of the University of Cordoba)	We thank CONICET (National Research Council-Argentina) and Secretaria de Ciencia y Tecnica-Universidad Nacional de Cordoba (Science Secretary of the University of Cordoba) for a fellowship and financial support.	Anklam E, 1998, FOOD CHEM, V63, P549, DOI 10.1016/S0308-8146(98)00057-0; *AOAC, 1995, OFF METH AN ASS OFF, P44; Baroni MV, 2004, J AGR FOOD CHEM, V52, P7222, DOI 10.1021/jf049068e; Baroni MV, 2002, J AGR FOOD CHEM, V50, P1362, DOI 10.1021/jf011214i; Baroni MV, 2006, J AGR FOOD CHEM, V54, P7235, DOI 10.1021/jf061080e; Buldini PL, 2001, FOOD CHEM, V73, P487, DOI 10.1016/S0308-8146(01)00132-7; *CAA, 1997, CAP 10 PROD AZ; *COD AL COMM, 1993, 199314 FAOWHO COD AL; Cometto PM, 2006, J AGR FOOD CHEM, V54, P9458, DOI 10.1021/jf061325n; Corbella E, 2006, LWT-FOOD SCI TECHNOL, V39, P534, DOI 10.1016/j.lwt.2005.03.011; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devillers J, 2004, FOOD CHEM, V86, P305, DOI 10.1016/j.foodchem.2003.09.029; Downey G, 2005, FOOD CHEM, V91, P347, DOI 10.1016/j.foodchem.2004.06.020; Fernandez-Torres R, 2005, TALANTA, V65, P686, DOI 10.1016/j.talanta.2004.07.030; González Paramás A. M., 2000, Journal of the Science of Food and Agriculture, V80, P157, DOI 10.1002/(SICI)1097-0010(20000101)80:1<157::AID-JSFA506>3.3.CO;2-2; Guler A, 2007, FOOD CHEM, V105, P1119, DOI 10.1016/j.foodchem.2007.02.024; Hernandez OM, 2005, FOOD CHEM, V93, P449, DOI 10.1016/j.foodchem.2004.10.036; Iglesias MT, 2004, J AGR FOOD CHEM, V52, P84, DOI 10.1021/jf030454q; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; Latorre MJ, 2000, ANALYST, V125, P307, DOI 10.1039/a905978d; Munoz E, 2006, FOOD CHEM, V94, P478, DOI 10.1016/j.foodchem.2005.01.022; Nanda V, 2003, J FOOD COMPOS ANAL, V16, P613, DOI 10.1016/S0889-1575(03)00062-0; NELLY S, 2005, TRENDS FOOD SCI TECH, V16, P555; Nozal MJ, 2005, J AGR FOOD CHEM, V53, P3095, DOI 10.1021/jf0489724; Ouchemoukh S, 2007, FOOD CONTROL, V18, P52, DOI 10.1016/j.foodcont.2005.08.007; Perez RA, 2007, J AGR FOOD CHEM, V55, P360, DOI 10.1021/jf062055b; Popek S, 2002, FOOD CHEM, V79, P401, DOI 10.1016/S0308-8146(02)00391-6; Przybylowski P, 2001, FOOD CHEM, V74, P289, DOI 10.1016/S0308-8146(01)00153-4; Rebolo S, 2000, ANAL CHIM ACTA, V417, P211, DOI 10.1016/S0003-2670(00)00929-6; Ruoff K, 2006, J AGR FOOD CHEM, V54, P6858, DOI 10.1021/jf060697t; Sikorska E, 2005, FOOD CHEM, V89, P217, DOI 10.1016/j.foodchem.2004.02.028; Terrab A, 2004, FOOD CHEM, V88, P537, DOI 10.1016/j.foodchem.2004.01.068; Woodcock T, 2007, J AGR FOOD CHEM, V55, P9128, DOI 10.1021/jf072010q; Wunderlin DA, 1998, J AGR FOOD CHEM, V46, P1855, DOI 10.1021/jf9710140	34	47	50	1	15	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0308-8146			FOOD CHEM	Food Chem.	MAY 15	2009	114	2					727	733		10.1016/j.foodchem.2008.10.018		7	Chemistry, Applied; Food Science & Technology; Nutrition & Dietetics	Chemistry; Food Science & Technology; Nutrition & Dietetics	411PT	WOS:000263662400056		
J	Hong, SH; Hendrickx, JMH; Borchers, B				Hong, Sung-ho; Hendrickx, Jan M. H.; Borchers, Brian			Up-scaling of SEBAL derived evapotranspiration maps from Landsat (30 m) to MODIS (250 m) scale	JOURNAL OF HYDROLOGY			English	Article						Up-scaling; Evapotranspiration; SEBAL; Landsat; MODIS	SOIL HEAT-FLUX; DIGITAL ELEVATION MODEL; REMOTELY-SENSED DATA; ENERGY-BALANCE; NET-RADIATION; HETEROGENEOUS TERRAIN; EVAPORATIVE FRACTION; SURFACE-TEMPERATURE; SPATIAL VARIABILITY; AVHRR DATA		[Hong, Sung-ho; Hendrickx, Jan M. H.; Borchers, Brian] New Mexico Inst Min & Technol, Earth & Environm Sci, Socorro, NM 87801 USA	Hendrickx, JMH (reprint author), New Mexico Inst Min & Technol, Earth & Environm Sci, Socorro, NM 87801 USA.	hendrick@nmt.edu	Borchers, Brian/C-1984-2008	Borchers, Brian/0000-0001-5370-5811			Allen R. G., 1998, 56 FAO; Allen RG, 2007, J IRRIG DRAIN E-ASCE, V133, P380, DOI 10.1061/(ASCE)0733-9437(2007)133:4(380); ANSELIN L, 1993, SPATIAL STAT ANAL GE; ATKINSON P, 1985, ACSM ASPRS FALL C, P929; Bastiaanssen WGM, 2000, J HYDROL, V229, P87, DOI 10.1016/S0022-1694(99)00202-4; Bastiaanssen WGM, 2005, J IRRIG DRAIN E-ASCE, V131, P85, DOI 10.1061/(ASCE)0733-9437(2005)131:1(85); Bastiaanssen WGM, 1998, J HYDROL, V212, P198, DOI 10.1016/S0022-1694(98)00253-4; Bian L, 1999, PHOTOGRAMM ENG REM S, V65, P73; BIAN L, 1997, MULTISCALE NATURE SP; BROWN DG, 1993, COMPUT GEOSCI, V19, P499, DOI 10.1016/0098-3004(93)90078-J; Brutsaert W, 1982, EVAPORATION ATMOSPHE; BRUTSAERT W, 1992, J GEOPHYS RES-ATMOS, V97, P18377; Carmel Y, 2004, IEEE GEOSCI REMOTE S, V1, P39, DOI 10.1109/LGRS.2004.823453; Carmel Y, 2001, PHOTOGRAMM ENG REM S, V67, P865; CHEHBOUNI A, 1995, J CLIMATE, V8, P1386, DOI 10.1175/1520-0442(1995)008<1386:AFASPA>2.0.CO;2; CHOUDHURY BJ, 1987, AGR FOREST METEOROL, V39, P283, DOI 10.1016/0168-1923(87)90021-9; Cihlar J, 1997, REMOTE SENS ENVIRON, V60, P35, DOI 10.1016/S0034-4257(96)00137-X; CLOTHIER BE, 1986, AGR FOREST METEOROL, V37, P319, DOI 10.1016/0168-1923(86)90069-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crago RD, 1996, J HYDROL, V180, P173, DOI 10.1016/0022-1694(95)02903-6; Croley TE, 2005, J HYDROL ENG, V10, P182, DOI 10.1061/(ASCE)1084-0699(2005)10:3(182); Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566; DAUGHTRY CST, 1990, REMOTE SENS ENVIRON, V32, P111, DOI 10.1016/0034-4257(90)90012-B; DECOLA L, 1994, INT J GEOGR INF SYST, V8, P411, DOI 10.1080/02693799408902011; Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195; EBLERINGER JR, 1993, SCALING PHYSL PROCES; *ERDAS, 2002, FIELD GUID; Eugenio F, 2003, IEEE T GEOSCI REMOTE, V41, P2869, DOI 10.1109/TGRS.2003.817226; Farah H, 2004, INT J APPL EARTH OBS, V5, P129, DOI DOI 10.1016/J.JAG.2004.01.003; French AN, 2002, AGRONOMIE, V22, P105, DOI 10.1051/agro:2001010; FRENCH AN, 2001, THESIS U MARYLAND CO; Gentine P, 2007, AGR FOREST METEOROL, V143, P13, DOI 10.1016/j.agrformet.2006.11.002; Gupta V. K., 1986, SCALE PROBLEMS HYDRO; Hendrickx JMH, 2005, P SOC PHOTO-OPT INS, V5811, P138, DOI 10.1117/12.603361; Hong SH, 2005, P SOC PHOTO-OPT INS, V5811, P147, DOI 10.1117/12.603385; Hong S.-h., 2008, THESIS NEW MEXICO I; KUSTAS WP, 1993, REMOTE SENS ENVIRON, V46, P319, DOI 10.1016/0034-4257(93)90052-Y; LAM NSN, 1992, PROF GEOGR, V44, P88, DOI 10.1111/j.0033-0124.1992.00088.x; LHOMME JP, 1992, AGR FOREST METEOROL, V61, P11, DOI 10.1016/0168-1923(92)90022-V; LI B, 1994, J CLIMATE, V7, P527, DOI 10.1175/1520-0442(1994)007<0527:TIOSVO>2.0.CO;2; Liang SL, 2002, REMOTE SENS ENVIRON, V83, P149, DOI 10.1016/S0034-4257(02)00092-5; Liang S.L., 2004, QUANTITATIVE REMOTE; Liang SP, 2000, J PROTEIN CHEM, V19, P225, DOI 10.1023/A:1007011904904; Maayar M. E., 2006, Remote Sensing of Environment, V102, DOI 10.1016/j.rse.2006.01.017; MARK DM, 1984, J INT ASS MATH GEOL, V16, P671, DOI 10.1007/BF01033029; Mecikalski JR, 1999, J APPL METEOROL, V38, P1352, DOI 10.1175/1520-0450(1999)038<1352:EFOCSU>2.0.CO;2; Mengelkamp HT, 2006, B AM METEOROL SOC, V87, P775, DOI 10.1175/BAMS-87-6-775; Morse A., 2000, APPL SEBAL METHODOLO; NELLIS M D, 1989, Landscape Ecology, V2, P93, DOI 10.1007/BF00137153; NISHIDA K, 2003, J GEOGRAPH RES, V108, DOI DOI 10.1029/2002JD002062; PRICE JC, 1984, J GEOPHYS RES-ATMOS, V89, P7231, DOI 10.1029/JD089iD05p07231; QUATTROCHI DA, 1997, SCALE MULTISCALING R; SEGUIN B, 1991, REMOTE SENS ENVIRON, V35, P141, DOI 10.1016/0034-4257(91)90007-S; SEYFRIED MS, 1995, WATER RESOUR RES, V31, P173, DOI 10.1029/94WR02025; Shuttleworth W.J., 1989, IAHS PUBL, V186, P67; SHUTTLEWORTH WJ, 1991, REV GEOPHYS, V29, P585, DOI 10.1029/91RG01815; STOMS DM, 1992, PHOTOGRAMM ENG REM S, V58, P1587; Tasumi M., 2003, THESIS U IDAHO MOSCO; TOWNSHEND JRG, 1992, IEEE T GEOSCI REMOTE, V30, P1054, DOI 10.1109/36.175340; Turner MG, 1989, LANDSCAPE ECOL, V3, P153, DOI 10.1007/BF00131534; Van Rompaey AJJ, 1999, INT J GEOGR INF SCI, V13, P577, DOI 10.1080/136588199241120; Vazquez DP, 1997, REMOTE SENS ENVIRON, V62, P215, DOI 10.1016/S0034-4257(97)00091-6; Vieux B E, 1993, J COMPUT CIVIL ENG, V7, P310, DOI DOI 10.1061/(ASCE)0887-3801(1993)7:3(310); WOLOCK DM, 1994, WATER RESOUR RES, V30, P3041, DOI 10.1029/94WR01971; ZHANG WH, 1994, WATER RESOUR RES, V30, P1019, DOI 10.1029/93WR03553	65	23	24	3	19	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0022-1694			J HYDROL	J. Hydrol.	MAY 30	2009	370	1-4					122	138		10.1016/j.jhydrol.2009.03.002		17	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Engineering; Geology; Water Resources	453WY	WOS:000266644800012		
J	Harmon, RS; Remus, J; McMillan, NJ; McManus, C; Collins, L; Gottfried, JL; DeLucia, FC; Miziolek, AW				Harmon, Russell S.; Remus, Jeremiah; McMillan, Nancy J.; McManus, Catherine; Collins, Leslie; Gottfried, Jennifer L., Jr.; DeLucia, Frank C.; Miziolek, Andrzej W.			LIBS analysis of geomaterials: Geochemical fingerprinting for the rapid analysis and discrimination of minerals	APPLIED GEOCHEMISTRY			English	Article; Proceedings Paper	Goldschmidt Conference 2006	2006	Cologne, GERMANY				INDUCED BREAKDOWN SPECTROSCOPY; REAL-TIME; SENSOR TECHNOLOGY; BERYL; SOILS; AIR	Laser-induced breakdown spectroscopy (LIBS) is a simple atomic emission spectroscopy technique capable of real-time, essentially non-destructive determination of the elemental composition of any substance (solid, liquid, or gas). LIBS, which is presently undergoing rapid research and development as a technology for geochemical analysis, has attractive potential as a field tool for rapid man-portable and/or stand-off chemical analysis. In LIBS, a pulsed laser beam is focused such that energy absorption produces a high-temperature microplasma at the sample surface resulting in the dissociation and ionization of small amounts of material, with both continuum and atomic/ionic emission generated by the plasma during cooling. A broadband spectrometer-detector is used to spectrally and temporally resolve the light from the plasma and record the intensity of elemental emission lines. Because the technique is simultaneously sensitive to all elements, a single laser shot can be used to track the spectral intensity of specific elements or record the broadband LIBS emission spectra, which are unique chemical 'fingerprints' of a material. In this study, a broad spectrum of geological materials was analyzed using a commercial bench-top LIBS system with broadband detection from similar to 200-965 nm, with multiple single-shot spectra acquired. The subsequent use of statistical signal processing approaches to rapidly identify and classify samples highlights the potential of LIBS for 'geochemical fingerprinting' in a variety of geochemical, mineralogical, and environmental applications that would benefit from either real-time or in-field chemical analysis. Published by Elsevier Ltd.	[Harmon, Russell S.] ARL Army Res Off, Res Triangle Pk, NC USA; [Remus, Jeremiah; Collins, Leslie] Duke Univ, Dept Elect Engn, Durham, NC 27703 USA; [McMillan, Nancy J.] New Mexico State Univ, Dept Geol Sci, Las Cruces, NM 88003 USA; [McManus, Catherine] Baylor Univ, Dept Chem, Waco, TX 76798 USA; [Gottfried, Jennifer L., Jr.; DeLucia, Frank C.; Miziolek, Andrzej W.] USA, Res Lab, Aberdeen Proving Ground, MD 21005 USA	Harmon, RS (reprint author), ARL Army Res Off, POB 12211, Res Triangle Pk, NC USA.	russell.harmon@us.army.mil	Gottfried, Jennifer/G-6333-2010; De Lucia, Frank/D-5630-2012				ABDURIYIM A, 2003, ANAL CS PINK BERYL U; Arca G, 1997, APPL SPECTROSC, V51, P1102, DOI 10.1366/0003702971941863; Carranza JE, 2001, SPECTROCHIM ACTA B, V56, P851, DOI 10.1016/S0584-8547(01)00183-5; Corsi M., 2000, RES ADV APPL SPECTRO, V1, P41; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cremers DA, 2006, LASER-INDUCED BREAKDOWN SPECTROSCOPY (LIBS): FUNDAMENTALS AND APPLICATIONS, P1; CREMERS DA, 1984, APPL SPECTROSC, V38, P721, DOI 10.1366/0003702844555034; Detalle V, 2003, APPL OPTICS, V42, P5971, DOI 10.1364/AO.42.005971; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Eppler AS, 1996, APPL SPECTROSC, V50, P1175, DOI 10.1366/0003702963905123; Fabre C, 2002, GEOCHIM COSMOCHIM AC, V66, P1401, DOI 10.1016/S0016-7037(01)00858-4; Fritsch E., 1988, GEMS GEMOL, V24, P81; Fritsch E., 1988, GEMS GEMOL, V24, P81; FRITSCH E, 1987, GEMS GEMOL, V23, P26; Harmon RS, 2005, GEOCHEM-EXPLOR ENV A, V5, P21, DOI 10.1144/1467-7873/03-059; Harmon RS, 2006, APPL GEOCHEM, V21, P730, DOI 10.1016/j.apgeochem.2006.02.003; Hodges J., 1951, 4 USAF SCH AV MED, P261; Klein C., 2008, MINERAL SCI; McManus CE, 2008, APPL OPTICS, V47, pG72, DOI 10.1364/AO.47.000G72; McMillan NJ, 2007, SPECTROCHIM ACTA B, V62, P1528, DOI 10.1016/j.sab.2007.10.037; McMillan NJ, 2006, ANAL BIOANAL CHEM, V385, P263, DOI 10.1007/s00216-006-0374-9; Russo RE, 2006, LASER-INDUCED BREAKDOWN SPECTROSCOPY (LIBS): FUNDAMENTALS AND APPLICATIONS, pXV; MONKEBLANKENBUR.L, 1989, LASER MICROANALYSIS; Parriger C.G., 2006, LASER INDUCED BREAKD, P171; Pasquini C, 2007, J BRAZIL CHEM SOC, V18, P463, DOI 10.1590/S0103-50532007000300002; Payling R., 2000, OPTICAL EMISSION LIN; Price D.C., 1976, J PHYSIQUE         C, V6, P811; Ralchenko Yu., 2008, NIST ATOMIC SPECTRA; Rusak DA, 1997, CRIT REV ANAL CHEM, V27, P257, DOI 10.1080/10408349708050587; SABSABI M, 2007, 1 N AM LIBS S NASLIB; Salle B, 2004, SPECTROCHIM ACTA B, V59, P1413, DOI 10.1016/j.sab.2004.06.006; SCHALLER WT, 1962, AM MINERAL, V47, P672; Song K, 1997, APPL SPECTROSC REV, V32, P183, DOI 10.1080/05704929708003314; Theriault GA, 1998, FIELD ANAL CHEM TECH, V2, P117, DOI 10.1002/(SICI)1520-6521(1998)2:2<117::AID-FACT8>3.0.CO;2-T; Viana RR, 2002, PHYS CHEM MINER, V29, P668, DOI 10.1007/s00269-002-0278-y	35	54	58	11	26	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0883-2927			APPL GEOCHEM	Appl. Geochem.	JUN	2009	24	6					1125	1141		10.1016/j.apgeochem.2009.02.009		17	Geochemistry & Geophysics	Geochemistry & Geophysics	459VV	WOS:000267141200018		
J	Sun, YM; Wong, AKC; Kamel, MS				Sun, Yanmin; Wong, Andrew K. C.; Kamel, Mohamed S.			CLASSIFICATION OF IMBALANCED DATA: A REVIEW	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Classification; class imbalance problem	CLASSIFIERS; DISCOVERY; INDUCTION	Classification of data with imbalanced class distribution has encountered a significant drawback of the performance attainable by most standard classifier learning algorithms which assume a relatively balanced class distribution and equal misclassification costs. This paper provides a review of the classification of imbalanced data regarding: the application domains; the nature of the problem; the learning difficulties with standard classifier learning algorithms; the learning objectives and evaluation measures; the reported research solutions; and the class imbalance problem in the presence of multiple classes.	[Sun, Yanmin] Pattern Discovery Technol Inc, Waterloo, ON N2L 5Z4, Canada; [Wong, Andrew K. C.] Univ Waterloo, Syst Design Dept, Waterloo, ON N2L 3G1, Canada; [Kamel, Mohamed S.] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada	Sun, YM (reprint author), Pattern Discovery Technol Inc, 554 Parkside Dr, Waterloo, ON N2L 5Z4, Canada.		Kamel, Mohamed/D-9323-2011; 	Kamel, Mohamed/0000-0001-6173-8082			Abe N., 2004, P 10 ACM SIGKDD INT, P3, DOI 10.1145/1014052.1014056; Akbani R, 2004, P 15 EUR C MACH LEAR, P39; ANAND R, 1993, IEEE T NEURAL NETWOR, V4, P962, DOI 10.1109/72.286891; Batista G.E., 2004, SIGKDD EXPLORATIONS, V1, P20, DOI DOI 10.1145/1007730.1007735; Bradford J.P., 1998, P 10 EUR C MACH LEAR, P131; Breiman L, 1998, ANN STAT, V26, P801; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Cardie Claire, 1997, P 14 INT C MACH LEAR, P57; Carvajal K, 2004, INSIGHT, V46, P399, DOI 10.1784/insi.46.7.399.55578; Chawla N., 2004, SIGKDD EXPLORATIONS, V6, P1; Chawla N.V., 2004, SIGKDD EXPLORATIONS, V6; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321; Chawla N.V., 2003, P ICML 2003 WORKSH L; CHAWLA NV, 2005, WORKSH UT BAS DAT MI; Chawla N.V., 2003, P 7 EUR C PRINC PRAC, P107; CHAWLA NV, DATA MINING KNOWLEDG; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMINGOS P, 1999, ACM SIGKDD 1999, P155; Dong G. Z., 1999, P 5 ACM SIGKDD INT C, P43, DOI 10.1145/312129.312191; Duda R O, 2001, PATTERN CLASSIFICATI; Duda R. O., 1973, PATTERN CLASSIFICATI; Elkan Ch., RESULTS KDD 99 CLASS; ESTABROOKS A, 2000, THESIS DALHOUSIE U H; Ezawa K, 1996, P 13 INT C MACH LEAR, P139; Fan W, 1999, P 16 INT C MACH LEAR, P97; Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Guo H., 2004, SIGKDD EXPLORATIONS, V6, P30; HANLEY JA, 1982, RADIOLOGY, V143, P29; HECHERMAN D, 1996, ADV KNOWLEDGE DISCOV, P273; Hertz J, 1991, INTRO THEORY NEURAL; Holte RC, 1989, P 11 INT JOINT C ART, P813; JAPKOWICZ N, 2001, MACH LEARN, V41; Japkowicz N, 2001, P 14 C CAN SOC COMP, P67; Japkowicz N., 2002, Intelligent Data Analysis, V6; Japkowicz Nathalie, 2000, P AAAI 2000 WORKSH L; JOSHI M, 2001, P 1 IEEE INT C DAT M; JOSHI MV, 2002, THESIS U MINNESOTA T; KAMEL MS, 2003, P 4 INT WORKSH MULT; KITTLER J, 1998, IEEE T PATT ANAL MAC, V20; Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027; Kuck H., 2004, THESIS U BRIT COLUMB; Lewis D., 1998, P 17 ANN INT ACM SIG, P73; Li JY, 2004, MACH LEARN, V54, P99, DOI 10.1023/B:MACH.0000011804.08528.7d; Li W., 2001, P IEEE INT C DAT MIN, P369; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Ling C. X., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; Ling C. X., 2004, P 21 INT C MACH LEAR; Liu B., 1999, P 5 ACM SIGKDD INT C, P337, DOI 10.1145/312129.312274; Liu B., 2000, P 4 EUR C PRINC DAT, P504; Liu B., 1998, P 4 INT C KNOWL DISC, P80; Manevitz L., 2001, J MACHINE LEARNING R, V2, P139; Margineantu D., 2002, P 13 EUR C MACH LEAR, P270; MURPH PM, 1991, UCI REPOSITORY MACHI; Pearl J, 1988, PROBABILISTIC REASON; Prati R. C., 2004, P 3 MEX INT C ART IN, P312; Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan JR, 1986, MACH LEARN, V1, P106; QUINLAN JR, 1991, MACH LEARN, V6, P93, DOI 10.1007/BF00153762; RASKUTTI B, 2004, P EUR C MACH LEARN P, P60; RIDDLE P, 1994, APPL ARTIF INTELL, V8, P125, DOI 10.1080/08839519408945435; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Schapire R., 2002, MSRI WORKSH NONL EST, P149; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; STEWARD S, 1997, CELLULAR BUSINESS, P23; SUN Y, 2006, P 6 INT C DAT MIN, P592; SUN Y, 2005, 4 INT C MACH LEARN D, P21; Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009; Tan P.-N., 2006, INTRO DATA MINING; TAX DMJ, 2002, INT C PATT REC QUEB; Ting K., 1994, P 10 CAN C ART INT, P91; Ting KM, 2000, P 17 INT C MACH LEAR, P983; Turney P. D., 2000, P WORKSH COST SENS L, P15; Vapnik V.N., 1963, Avtomatika i Telemekhanika, V24; WALTERS D, 1994, MOBILE PHONE NEWS, P4; Wang K., 2000, P 6 ACM SIGKDD INT C, P265, DOI 10.1145/347090.347147; Wang Y., 1997, THESIS U WATERLOO WA; Wang Y, 2003, IEEE T KNOWL DATA EN, V15, P764, DOI 10.1109/TKDE.2003.1198405; Weiss G.M., 2004, SIGKDD EXPLORATIONS, V6, P7, DOI DOI 10.1145/1007730.1007734; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315; Wong AKC, 1997, IEEE T KNOWL DATA EN, V9, P877, DOI 10.1109/69.649314; WU G, 2003, P ICML 03 WORKSH LEA; Yin XX, 2003, SIAM PROC S, P331; Zadrozny B., 2003, P 3 IEEE INT C DAT M, P435; Zadrozny B., 2001, P 7 ACM SIGKDD INT C, P204, DOI 10.1145/502512.502540; Zhang J., 2003, P ICML 03 WORKSH LEA; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63	92	94	98	2	20	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	JUN	2009	23	4					687	719				33	Computer Science, Artificial Intelligence	Computer Science	459QC	WOS:000267117500002		
J	Wechsler, H				Wechsler, Harry			Linguistics and face recognition	JOURNAL OF VISUAL LANGUAGES AND COMPUTING			English	Article						Authentication; Biometrics; Boosting; Clustering; Cross-validation; Data fusion; Face recognition; Feature selection; FERET; Forensics; FRGC; ICA; k Nearest neighbor; Likelihood ratio; Linguistics; Margin; MDL; Multimodal integration; Neyman-Pearson; Occlusion; Recognition; p-Values; Parsing; Random deficiency; Ranking; Recognition-by-parts; Segmentation; SIFT; Strangeness; Surveillance; Transcluction; Typicality	FORENSIC SPEAKER RECOGNITION; NATURAL IMAGE SEQUENCES; CORTEX; CATEGORIZATION; TRANSDUCTION; CLASSIFIER; FILTERS; SEARCH; MODEL	We describe in this paper a novel biometric methodology for face recognition suitable to address pose, illumination, and expression (PIE) image variability, temporal change, flexible matching, and last but not least occlusion and disguise that are usually referred to as denial and deception. The adverse conditions listed above affect the scope and performance of biometric analysis vis-A-vis both training and testing. The conceptual framework proposed here draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory. As many of the concerns listed usually affect only parts of the face, a non-parametric recognition-by-part approach is advanced here for the purpose of reliable face recognition. Recognition-by-parts facilitates authentication because it does not seek for explicit invariance. Instead, it handles variability using component-based configurations that are flexible enough to compensate among others for limited pose changes, if any, and limited occlusion and disguise. The recognition-by-parts approach proposed here supports incremental and progressive processing. It is similar in nature to modern linguistics and practical intelligence with the emphasis on semantics and pragmatics. Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak learners. The implementation. driven by transcluction, employs proximity and typicality (ranking) realized using strangeness and random deficiency p-values, respectively. The feasibility and reliability of the proposed architecture has been validated using FERET and FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the recognition-by-parts architecture. (c) 2009 Elsevier Ltd. All rights reserved.	George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Wechsler, H (reprint author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	wechsler@gmu.edu					Barlow H. B., 1989, Neural Computation, V1, DOI 10.1162/neco.1989.1.3.295; Becker B., 2008, 8 INT C AUT FAC GEST; BLACK B, 1994, TEX LAW REV, V72, P715; Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3; Chapelle O., 2006, SEMISUPERVISED LEARN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COX IJ, 1996, P C COMP VIS PATT RE; Delorme A, 2001, NEURAL NETWORKS, V14, P795, DOI 10.1016/S0893-6080(01)00049-1; DESSIMOZ D, 2008, HDB BIOMETRICS; El-Yaniv R, 2005, PATTERN RECOGN LETT, V26, P2104, DOI 10.1016/j.patrec.2005.03.025; Freund Y., 1996, 13 INT C MACH LEARN, P148; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gonzalez-Rodriguez J, 2007, IEEE T AUDIO SPEECH, V15, P2104, DOI 10.1109/TASL.2007.902747; GUTTA S, 2004, 1 INT C BIOM AUTH HO; Hand DJ, 2006, STAT SCI, V21, P1, DOI 10.1214/088342306000000060; Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811; Hyvarinen A, 2003, J OPT SOC AM A, V20, P1237, DOI 10.1364/JOSAA.20.001237; Kahneman D., 2000, CHOICES VALUES FRAME; Koller D., 1996, 13 INT C MACH LEARN; Lai H, 2008, COMPUT VIS IMAGE UND, V111, P329, DOI 10.1016/j.cviu.2008.01.003; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686; LI F, 2009, INT J PATTE IN PRESS; Li M., 1997, INTRO KOLMOGOROV COM; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Phillips P., 2005, OVERVIEW FACE RECOGN; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Pinto N., 2008, PLOS COMPUTATIONAL B, V4; Pinto N., 2008, WORKSH FAC REAL LIF; PONCE J, 2006, LECT NOTES COMPUTER; PUJOL A, 2001, INT C IM AN PROC, P273; RAMANATHAN V, 2009, ROBUST FACE I PRESS; Rubinstein Y., 1997, KDD, P49; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Rullen R. V., 1998, BIOSYSTEMS, V48, P229; Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Shi J, 2006, COMPUT VIS IMAGE UND, V102, P117, DOI 10.1016/j.cviu.2005.10.002; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Smith JD, 2005, J EXP PSYCHOL GEN, V134, P443, DOI 10.1037/0096-3445.134.4.443; Smith JD, 2005, J EXP PSYCHOL LEARN, V31, P1171, DOI 10.1037/0278-7393.31.6.1171; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Tsunoda K, 2001, NAT NEUROSCI, V4, P832, DOI 10.1038/90547; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315; Vapnik V., 1998, STAT LEARNING THEORY; VOVK V, 1999, 16 INT C MACH LEARN; VYGOTSKY L, 1976, MIND SOC	48	0	0	1	4	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	1045-926X			J VISUAL LANG COMPUT	J. Vis. Lang. Comput.	JUN	2009	20	3					145	155		10.1016/j.jvlc.2009.01.001		11	Computer Science, Software Engineering	Computer Science	449RI	WOS:000266347300003		
J	Yang, HQ; Huang, KZ; King, I; Lyu, MR				Yang, Haiqin; Huang, Kaizhu; King, Irwin; Lyu, Michael R.			Localized support vector regression for time series prediction	NEUROCOMPUTING			English	Article						Support vector regression; Second order conic programming; Time series prediction	MINIMAX PROBABILITY MACHINE	Time series prediction, especially financial time series prediction, is a challenging task in machine learning. In this issue, the data are usually non-stationary and volatile in nature. Because of its good generalization power, the support vector regression (SVR) has been widely applied in this application. The standard SVR employs a fixed epsilon-tube to tolerate noise and adopts the l(p)-norm (p = 1 or 2) to model the functional complexity of the whole data set. One problem of the standard SVR is that it considers data in a global fashion only. Therefore it may lack the flexibility to capture the local trend of data; this is a critical aspect of volatile data, especially financial time series data. Aiming to attack this issue, we propose the localized support vector regression (LSVR) model. This novel model is demonstrated to provide a systematic and automatic scheme to adapt the margin locally and flexibly; while the margin in the standard SVR is fixed globally. Therefore, the LSVR can tolerate noise adaptively. The proposed LSVR is promising in the sense that it not only captures the local information in data, but more importantly, it establishes connection with several models. More specifically: (1) it can be regarded as the regression extension of a recently proposed promising classification model, the Maxi-Min Margin Machine: (2) it incorporates the standard SVR as a special case under certain mild assumptions. We provide both theoretical justifications and empirical evaluations for this novel model. The experimental results on synthetic data and real financial data demonstrate its advantages over the standard SVR. Crown Copyright (C) 2008 Published by Elsevier B.V. All rights reserved.	[Yang, Haiqin; Huang, Kaizhu; King, Irwin; Lyu, Michael R.] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Yang, HQ (reprint author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	hqyang@cse.cuhk.edu.hk			Council of the Hong Kong SAR, China [CUHK 4125/07E, CUHK 4150/07E]	The work described in this paper was fully supported by two grants from the Research Grants Council of the Hong Kong SAR, China (Project nos. CUHK 4125/07E and CUHK 4150/07E).	Bertsekas D P, 1999, NONLINEAR PROGRAMMIN; BERTSIMAS D, 1997, INDUCTION LINEAR OPT; Boyd S., 2004, CONVEX OPTIMIZATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FERNANDEZ R, 1999, P ECCAI ADV COURS AR; Fukunaga K., 1990, INTRO STAT PATTERN R; HUANG K, 2004, 21 INT C MACH LEARN, P401; HUANG K, 2004, P 2004 IEEE COMP SOC, V2, P558; Huang KZ, 2006, IEEE T SYST MAN CY B, V36, P913, DOI 10.1109/TSMCB.2006.870610; HUANG K, 2006, P INT JOINT C NEUR N; Huang KZ, 2004, J MACH LEARN RES, V5, P1253; Huang KZ, 2008, IEEE T NEURAL NETWOR, V19, P260, DOI 10.1109/TNN.2007.905855; Huang KZ, 2006, IEEE T BIO-MED ENG, V53, P821, DOI 10.1109/TBME.2006.872819; KHEMCHANDANI R, 2007, EXPERT SYSTEMS APPL, V36, P132; Lanckriet G. R. G., 2002, J MACHINE LEARNING R, V3, P555; Lobo MS, 1998, LINEAR ALGEBRA APPL, V284, P193, DOI 10.1016/S0024-3795(98)10032-0; Montgomery D. C., 1999, APPL STAT PROBABILIT; Nesterov Y., 1994, STUDIES APPL MATH; Platt J., 1998, MSRTR9814; Povinelli RJ, 2003, IEEE T KNOWL DATA EN, V15, P339, DOI 10.1109/TKDE.2003.1185838; PRUESSNER A, 2003, OPTIMIZATION SOFTWAR; Scholkopf B, 1999, ADV NEUR IN, V11, P330; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Smola A.J., 1998, NCTR98030 NEUROCOLT; STROHMANN TR, 2003, ADV NEURAL INFORM PR, V15; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Sturm JF, 2000, HIGH PERFORMANCE OPT, P157; Tay FEH, 2002, NEURAL PROCESS LETT, V15, P179, DOI 10.1023/A:1015249103876; Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093; Vapnik V., 1999, NATURE STAT LEARNING; Vapnik V., 1998, STAT LEARNING THEORY; Yang HQ, 2002, LECT NOTES COMPUT SC, V2412, P391; Yang HQ, 2004, STUD FUZZ SOFT COMP, V152, P334	34	33	39	4	7	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	JUN	2009	72	10-12					2659	2669		10.1016/j.neucom.2008.09.014		11	Computer Science, Artificial Intelligence	Computer Science	454SG	WOS:000266702300064		
J	Guan, D; Yuan, W; Lee, YK; Lee, S				Guan, Donghai; Yuan, Weiwei; Lee, Young-Koo; Lee, Sungyoung			Nearest neighbor editing aided by unlabeled data	INFORMATION SCIENCES			English	Article						Nearest neighbor editing; Unlabeled data; Edited nearest neighbor; Repeated edited nearest neighbor; All k-NN	IMAGE RETRIEVAL; RULE; CLASSIFICATION; FRAMEWORK; REDUCTION; SELECTION	This paper proposes a novel method for nearest neighbor editing. Nearest neighbor editing aims to increase the classifier's generalization ability by removing noisy instances from the training set. Traditionally nearest neighbor editing edits (removes/retains) each instance by the voting of the instances in the training set (labeled instances). However, motivated by semi-supervised learning, we propose a novel editing methodology which edits each training instance by the voting of all the available instances (both labeled and unlabeled instances). We expect that the editing performance could be boosted by appropriately using unlabeled data. Our idea relies on the fact that in many applications, in addition to the training instances, many unlabeled instances are also available since they do not need human annotation effort. Three popular data editing methods, including edited nearest neighbor, repeated edited nearest neighbor and All k-NN are adopted to verify our idea. They are tested on a set of LICI data sets. Experimental results indicate that all the three editing methods can achieve improved performance with the aid of unlabeled data. Moreover, the improvement is more remarkable when the ratio of training data to unlabeled data is small. (C) 2009 Elsevier Inc. All rights reserved.	[Guan, Donghai; Yuan, Weiwei; Lee, Young-Koo; Lee, Sungyoung] Kyung Hee Univ, Dept Comp Engn, Yongin 446701, South Korea	Lee, YK (reprint author), Kyung Hee Univ, Dept Comp Engn, Yongin 446701, South Korea.	yklee@khu.ac.kr			IITA (Institute of Information Technology Advancement) [IITA-2009-(CIO90-0902-0002)]; Korea government (MOST) [2008-1342]	Many thanks to Prof. Brian J. d'Auriol for proofreading of our paper. We also thank the reviewers for their constructive comments. This research was supported by the MKE (Ministry of Knowledge Economy), Korea, under the ITRC (Information Technology Research Center) support program supervised by the IITA (Institute of Information Technology Advancement) (IITA-2009-(CIO90-0902-0002)). This work was also supported by the Korea Science and Engineering Foundation (KOSEF) grant funded by the Korea government (MOST) (No. 2008-1342).	Angluin D., 1988, Machine Learning, V2, DOI 10.1007/BF00116829; Bennett K., 2002, P 8 ACM SIGKDD INT C, P289; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, DOI 10.1145/279943.279962; Cheng J, 2007, PATTERN RECOGN, V40, P330, DOI 10.1016/j.patcog.2006.06.005; Constantinopoulos C, 2008, NEUROCOMPUTING, V71, P2489, DOI 10.1016/j.neucom.2007.11.039; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De RK, 2001, INFORM SCIENCES, V132, P179, DOI 10.1016/S0020-0255(01)00070-6; Devijver P. A., 1982, PATTERN RECOGNITION; Ferri F. J., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems, DOI 10.1109/ICPR.1992.201851; HAND DJ, 1978, INFORM SCIENCES, V14, P171, DOI 10.1016/0020-0255(78)90040-3; HANDL J, 2006, P INT JOINT C NEUR N, P3319; Liu CH, 2008, INFORM SCIENCES, V178, P3347, DOI 10.1016/j.ins.2008.05.006; Liu H., 2001, INSTANCE SELECTION C; PENROD CS, 1977, IEEE T SYST MAN CYB, V7, P92; Qin T, 2008, PATTERN RECOGN LETT, V29, P637, DOI 10.1016/j.patrec.2007.11.015; Riloff E., 2003, P 7 C NAT LANG LEARN, P25; Ripley B D, 1996, PATTERN RECOGN, P198; Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, V2, P431; Zhang DQ, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P629; Zhao JD, 2008, NEUROCOMPUTING, V71, P1842, DOI 10.1016/j.neucom.2007.06.014; Zhu XQ, 2008, PATTERN RECOGN, V41, P2980, DOI 10.1016/j.patcog.2008.03.008	23	13	16	2	7	ELSEVIER SCIENCE INC	NEW YORK	360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA	0020-0255			INFORM SCIENCES	Inf. Sci.	JUN 13	2009	179	13					2273	2282		10.1016/j.ins.2009.02.011		10	Computer Science, Information Systems	Computer Science	447UA	WOS:000266216100016		
J	Kodell, RL; Pearce, BA; Baek, S; Moon, H; Ahn, H; Young, JF; Chen, JJ				Kodell, Ralph L.; Pearce, Bruce A.; Baek, Songjoon; Moon, Hojin; Ahn, Hongshik; Young, John F.; Chen, James J.			A model-free ensemble method for class prediction with application to biomedical decision making	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						Cancer; Disease classification; Convex hull; Gene imprinting; Genomics; k-Nearest-neighbor; Medical screening	HIGH-DIMENSIONAL DATA; GENE-EXPRESSION; CLASSIFICATION; CANCER	Objective: A classification algorithm that utilizes two-dimensional convex hulls of training-set samples is presented. Methods and material: For each pair of predictor variables, separate convex hulls of positive and negative samples in the training set are formed, and these convex hulls are used to classify test points according to a nearest-neighbor criterion. An ensemble of these two-dimensional convex-hull classifiers is formed by trimming the (m)C(2) possible classifiers derived from the m predictors to a set of classifiers comprised of only unique predictor variables. Because only two-dimensional spaces are required to be populated by training-set samples, the "curse of dimensionality" is not an issue. At the same time, the power of ensemble voting is exploited by combining the classifications of the unique two-dimensional classifiers to reach a final classification. Results: The algorithm is illustrated by application to three publicly available biomedical data sets with genomic predictors and is shown to have prediction accuracy that is competitive with a number of published classification procedures. Conclusion: Because of its superior performance in terms of sensitivity and negative predictive value compared to its competitors, the convex-hull ensemble classifier demonstrates good potential for medical screening, where often the major emphasis is placed on having reliable negative predictions. (C) 2008 Elsevier B.V. All rights reserved.	[Kodell, Ralph L.] Univ Arkansas Med Sci, Dept Biostat, Little Rock, AR 72205 USA; [Pearce, Bruce A.] Natl Ctr Toxicol Res, Informat Technol Staff, Jefferson, AR 72079 USA; [Baek, Songjoon; Young, John F.; Chen, James J.] Natl Ctr Toxicol Res, Div Personalized Nutr & Med, Jefferson, AR 72079 USA; [Moon, Hojin] Calif State Univ Long Beach, Dept Math & Stat, Long Beach, CA 90840 USA; [Ahn, Hongshik] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA	Kodell, RL (reprint author), Univ Arkansas Med Sci, Dept Biostat, 781,4301 W Markham St,COPH 3218, Little Rock, AR 72205 USA.	rlkodell@uams.edu					Ahn H, 2007, COMPUT STAT DATA AN, V51, P6166, DOI 10.1016/j.csda.2006.12.043; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Bellman Richard, 1957, DYNAMIC PROGRAMMING; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Chen JJ, 2005, SAR QSAR ENVIRON RES, V16, P517, DOI 10.1080/10659360500468468; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; EFRON B, 1981, BIOMETRIKA, V68, P589, DOI 10.1093/biomet/68.3.589; Foster DP, 2004, J AM STAT ASSOC, V99, P303, DOI 10.1198/016214504000000287; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Greally JM, 2002, P NATL ACAD SCI USA, V99, P327, DOI 10.1073/pnas.012539199; Hastie T, 2001, ELEMENTS STAT LEARNI; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; KIM H, 2002, COMPUTING SCI STAT, V33, P608; Krogh A., 1994, ADV NEURAL INFORMATI, V7, P231; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017; Liu Y, 2000, IEEE T EVOLUT COMPUT, V4, P380; Mardia K. V., 1979, MULTIVARIATE ANAL; Moon H, 2007, ARTIF INTELL MED, V41, P197, DOI 10.1016/j.artmed.2007.07.003; MOON H, 2006, GENOME BIOL, V7; Opitz DW, 1996, ADV NEUR IN, V8, P535; Perrone M.P., 1993, NEURAL NETWORKS SPEE, P126; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, DOI 10.1109/MCAS.2006.1688199; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; SIMON R, 2005, J CLIN ONCOL, V96, P1; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tong WD, 2003, J CHEM INF COMP SCI, V43, P525, DOI 10.1021/ci020058s; Tsymbal A., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.003; Turner K., 1996, CONNECT SCI, V8, P385; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V. N., 1995, NATURE STAT LEARNING; Young JF, 2006, J TOXICOL ENV HEAL A, V69, P1527, DOI 10.1080/15287390500468746	39	8	8	0	0	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0933-3657			ARTIF INTELL MED	Artif. Intell. Med.	JUL	2009	46	3					267	276		10.1016/j.artmed.2008.11.001		10	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Computer Science; Engineering; Medical Informatics	471GC	WOS:000268043000006	19081231	
J	Miao, DQ; Duan, QG; Zhang, HY; Jiao, N				Miao, Duoqian; Duan, Qiguo; Zhang, Hongyu; Jiao, Na			Rough set based hybrid algorithm for text classification	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Text classification; Variable precision rough set (VPRS); k-nearest neighbor (kNN); Rocchio algorithm		Automatic classification of text documents, one of essential techniques for Web mining, has always been a hot topic flue to the explosive growth of digital documents available on-line. In text classification community, k-nearest neighbor (kNN) is a simple and yet effective classifier. However, as being a lazy learning method Without premodelling, kNN has a high cost to classify new documents when training set is large. Rocchio algorithm is another well-known and widely used technique for text classification. One drawback of [tie Rocchio classifier is that it restricts the hypothesis space to the set of linear separable hyperplane regions. When the data does not fit its underlying assumption well, Rocchio classifier suffers. In this paper, a hybrid algorithm based on variable precision rough set is proposed to combine the strength of both kNN and Rocchio techniques and overcome their weaknesses. Art experimental evaluation of different methods is carried out oil two common text corpora, i.e., the Reuters-21578 collection and the 20-newsgroup collection. The experimental results indicate that the novel algorithm achieves significant performance improvement. (C) 2008 Elsevier Ltd. All rights reserved.	[Miao, Duoqian; Duan, Qiguo; Zhang, Hongyu; Jiao, Na] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China	Miao, DQ (reprint author), Tongji Univ, Dept Comp Sci & Technol, Caoan St 4800, Shanghai 201804, Peoples R China.	miaoduoqian@163.com; dqgcn@126.com			National Natural Science Foundation of China [60775036, 60475019]; Foundation of Ministry of Education of China [20060247039]	This study is supported by the National Natural Science Foundation of China (Granted Nos. 60775036 and 60475019) and the Ph.D. programs Foundation of Ministry of Education of China (No. 20060247039).	BUCKLEY C, 1994, P 17 ANN ACM SIGIR C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T., 2000, LECT NOTES COMPUTER, P1; Han EH, 2000, CENTROID BASED DOCUM; Joachims T., 1997, P 14 INT C MACH LEAR; Joachimss T., 1998, 10 EUR C MACH LEARN, P137; Lam W., 1998, SIGIR 98, P81; Lewis D.D., 1998, 10 EUR C MACH LEARN, P4; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; TANG SB, 2007, EXPERT SYSTEMS APPL, V33, P215; Tang YH, 2007, IEICE T INF SYST, VE90D, P1787, DOI 10.1093/ietisy/e90-d.11.1787; YANG Y, 1999, 22 ANN INT ACM SIGIR; Yang Y., 1997, ICML 97, P412; ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2	17	13	17	2	9	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JUL	2009	36	5					9168	9174		10.1016/j.eswa.2008.12.026		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	427MG	WOS:000264782800050		
J	Chevrefils, C; Cheriet, F; Aubin, CE; Grimard, G				Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric; Grimard, Guy			Texture Analysis for Automatic Segmentation of Intervertebral Disks of Scoliotic Spines From MR Images	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article; Proceedings Paper	5th IEEE International Special Topic Conference on Information Technology in Biomedicine	OCT, 2006	Ioannina, GREECE	IEEE Engn Med & Biol Soc, Univ Ioanniana, Natl Tech Univ Athens		Classification; MRI; segmentation; texture features	MAGNETIC-RESONANCE IMAGES; WATERSHED SEGMENTATION; CLASSIFICATION; SHAPE; SPECTROSCOPY; CARTILAGE; FEATURES; TUMORS; MODEL	This paper presents a unified framework for automatic segmentation of intervertebral disks of scoliotic spines from different types of magnetic resonance (MR) image sequences. The method exploits a combination of statistical and spectral texture features to discriminate closed regions representing intervertebral disks from background in MR images of the spine. Specific texture features are evaluated for three types of MR sequences acquired in the sagittal plane: 2-D spin echo, 3-D multiecho data image combination, and 3-D fast imaging with steady state precession. A total of 22 texture features (18 statistical and 4 spectral) are extracted from every closed region obtained from an automatic segmentation procedure based on the watershed approach. The feature selection step based on principal component analysis and clustering process permit to decide among all the extracted features which ones resulted in the highest rate of good classification. The proposed method is validated using a supervised k-nearest-neighbor classifier on 505 MR images coming from three different scoliotic patients and three different MR acquisition protocols. Results suggest that the selected texture features and classification can contribute to solve the problem of oversegmentation inherent to existing automatic segmentation methods by successfully discriminating intervertebral disks from the background on MRI of scoliotic spines.	[Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric] Ecole Polytech, Inst Biomed Engn, Montreal, PQ H3C 3A7, Canada; [Cheriet, Farida] Ecole Polytech, Dept Comp Engn & Software, Montreal, PQ H3C 3A7, Canada; [Chevrefils, Claudia; Cheriet, Farida; Aubin, Carl-Eric] St Justine Univ Hosp Ctr, Montreal, PQ H3T 1C5, Canada; [Grimard, Guy] Hop St Justine, Dept Orthopaed, Montreal, PQ H3T 1C5, Canada; [Aubin, Carl-Eric] Ecole Polytech, Dept Mech Engn, Montreal, PQ H3C 3A7, Canada	Chevrefils, C (reprint author), Ecole Polytech, Inst Biomed Engn, Montreal, PQ H3C 3A7, Canada.	claudia.chevrefils@polymtl.ca; farida.cheriet@polymtl.ca; carl-eric.aubin@polymtl.ca; guy_grimard@ssss.gouv.qc.ca					BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; BOOTH S, 2001, P CAN C EL COMP ENG, P1303; CAI H, P 07 4 IEEE INT S BI, P600; Carballido-Gamio J, 2004, IEEE T MED IMAGING, V23, P36, DOI 10.1109/TMI.2003.819929; Cates JE, 2005, MED IMAGE ANAL, V9, P566, DOI 10.1016/j.media.2005.04.007; Chen P, 2006, STUD NONLINEAR DYN E, V10; CHEVREFILS C, P IM AN REC 4 INT C, P1017; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; Coulon O, 2002, MAGN RESON MED, V47, P1176, DOI 10.1002/mrm.10162; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dokladal P, 2003, PATTERN RECOGN, V36, P2463, DOI 10.1016/S0031-3203(03)00118-3; Duda R O, 2001, PATTERN CLASSIFICATI; FRALICK SC, 1971, IEEE T INFORM THEORY, V17, P440, DOI 10.1109/TIT.1971.1054663; Galanaud D, 2006, MAGN RESON MED, V55, P1236, DOI 10.1002/mrm.20886; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6; GEORGIADIS P, 2008, COMPUT METH PROG BIO, V89, P264; GEORGY BA, 1994, AM J ROENTGENOL, V162, P923; Ginneken B.V., 2002, IEEE T MED IMAGING, V21, P924; Gonzalez R C, 2004, DIGITAL IMAGE PROCES; Grau V, 2004, PATTERN RECOGN, V37, P47, DOI 10.1016/j.patcog.2003.07.009; Han Jiawei, 2001, DATA MINING CONCEPTS; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HERLIDOU S, 2001, P 23 ANN INT C IEEE, P2340; HOAD CL, 2001, PHYS MED BIOL, V46, P213; HURTUT T, P IM AN REC 4 INT C, P187; Isgum I, 2007, MED PHYS, V34, P1450, DOI 10.1118/1.2710548; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; Martel A L, 1998, Comput Aided Surg, V3, P40, DOI 10.3109/10929089809148127; MODIC MT, 1983, AM J ROENTGENOL, V141, P1129; Mu TT, 2008, J DIGIT IMAGING, V21, P153, DOI 10.1007/s10278-007-9102-z; Muensterer OJ, 1996, CLIN BIOMECH, V11, P260, DOI 10.1016/0268-0033(95)00069-0; Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62; Patino L, 2005, PATTERN RECOGN LETT, V26, P819, DOI 10.1016/j.patrec.2004.09.036; Peng Zhigang, 2005, Conf Proc IEEE Eng Med Biol Soc, V3, P2527; SCHAD LR, 1993, MAGN RESON IMAGING, V11, P889, DOI 10.1016/0730-725X(93)90206-S; Schmid MR, 2005, AM J ROENTGENOL, V184, P1744; SEBBAHI A, P CAR 96 COMP ASS RA, P302; Seghers D, 2007, IEEE T MED IMAGING, V26, P1115, DOI 10.1109/TMI.2007.896924; Smyth PP, 1997, IMAGE VISION COMPUT, V15, P575, DOI 10.1016/S0262-8856(97)00006-1; SOLANAS E, P 01 INT C IM PROC 7, P885; Sonka M., 2004, HDB MED IMAGING MED; TAXT T, 1994, IEEE T MED IMAGING, V13, P470, DOI 10.1109/42.310878; Tek FB, 2004, ELECTRON LETT, V40, P1332, DOI 10.1049/el:20045834; van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; ZHU H, 2001, P IEEE INT C FUZZ SY, P27	49	13	13	1	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	JUL	2009	13	4					608	620		10.1109/TITB.2009.2018286		13	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	468QU	WOS:000267835800025	19369169	
J	Chaudhuri, P; Ghosh, AK; Oja, H				Chaudhuri, Probal; Ghosh, Anil K.; Oja, Hannu			Classification Based on Hybridization of Parametric and Nonparametric Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes risk; bandwidth; kernel density estimation; LDA; misclassification rate; multiscale smoothing; nearest neighbor; QDA	NEAREST-NEIGHBOR CLASSIFICATION; KERNEL DENSITY-ESTIMATION; PATTERN-CLASSIFICATION; DISCRIMINANT-ANALYSIS; SCALE-SPACE; REGRESSION; VISUALIZATION; VIEW	Parametric methods of classification assume specific parametric models for competing population densities (e. g., Gaussian population densities can lead to linear and quadratic discriminant analysis) and they work well when these model assumptions are valid. Violation in one or more of these parametric model assumptions often leads to a poor classifier. On the other hand, nonparametric classifiers (e. g., nearest-neighbor and kernel-based classifiers) are more flexible and free from parametric model assumptions. But, the statistical instability of these classifiers may lead to poor performance when we have small numbers of training sample observations. Nonparametric methods, however, do not use any parametric structure of population densities. Therefore, even when one has some additional information about population densities, that important information is not used to modify the nonparametric classification rule. This paper makes an attempt to overcome these limitations of parametric and nonparametric approaches and combines their strengths to develop some hybrid classification methods. We use some simulated examples and benchmark data sets to examine the performance of these hybrid discriminant analysis tools. Asymptotic results on their misclassification rates have been derived under appropriate regularity conditions.	[Chaudhuri, Probal; Ghosh, Anil K.] Indian Stat Inst, Theoret Stat & Math Unit, Kolkata 700108, India; [Oja, Hannu] Univ Tampere, Tampere Sch Publ Hlth, Tampere 33014, Finland	Chaudhuri, P (reprint author), Indian Stat Inst, Theoret Stat & Math Unit, 203 BT Rd, Kolkata 700108, India.	probal@isical.ac.in; anilkghosh@rediffmail.com; Hannu.Oja@uta.fi			Council of Scientific and Industrial Research; Department of Biotechnology, Government of India; Academy of Finland	The authors would like to thank the reviewers for their careful reading of the earlier version of the paper and for providing them with several helpful comments. The research of Probal Chaudhuri was partially supported by the grants of the Council of Scientific and Industrial Research and the Department of Biotechnology, Government of India. The research of Hannu Oja was partially supported by the grants of the Academy of Finland.	Bolance C, 2003, INSUR MATH ECON, V32, P19, DOI 10.1016/S0167-6687(02)00191-9; Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buch-Larsen T, 2005, STATISTICS, V39, P503, DOI 10.1080/02331880500439782; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Chaudhuri P, 2000, ANN STAT, V28, P408; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fix E., 1951, DISCRIMINATORY ANAL; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1994, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Ghosh AK, 2006, TECHNOMETRICS, V48, P120, DOI 10.1198/004017005000000391; Ghosh AK, 2007, INT J PATTERN RECOGN, V21, P1103, DOI 10.1142/S0218001407005855; Ghosh AK, 2005, IEEE T PATTERN ANAL, V27, P1592, DOI 10.1109/TPAMI.2005.204; Glad IK, 1998, SCAND J STAT, V25, P649, DOI 10.1111/1467-9469.00127; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; Hand D. J., 1982, KERNEL DISCRIMINANT; Hastie T, 2001, ELEMENTS STAT LEARNI; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HJORT NL, 1995, ANN STAT, V23, P882, DOI 10.1214/aos/1176324627; Hjort NL, 1996, ANN STAT, V24, P1619; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Hoti F, 2004, PATTERN RECOGN, V37, P409, DOI 10.1016/j.patcog.2003.08.004; Johnson R., 1992, APPL MULTIVARIATE ST, V3th; JONES MC, 1995, BIOMETRIKA, V82, P327; Jones MC, 1995, KERNEL SMOOTHING; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LAI SL, 1977, THESIS U CALIFORNIA; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; MACK YP, 1981, SIAM J ALGEBRA DISCR, V2, P311, DOI 10.1137/0602035; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; OLKIN I, 1987, J AM STAT ASSOC, V82, P858, DOI 10.2307/2288797; Ripley BD, 1996, PATTERN RECOGNITION; Schapire RE, 1998, ANN STAT, V26, P1651; Scott D.W., 1992, MULTIVARIATE DENSITY; SHALAK DB, 1996, THESIS U MASSACHUSET; SILVERMAN BW, 1978, ANN STAT, V6, P177, DOI 10.1214/aos/1176344076; Silverman BW, 1986, DENSITY ESTIMATION S; Vapnik V., 1998, STAT LEARNING THEORY	45	8	9	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1153	1164		10.1109/TPAMI.2008.149		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	447KB	WOS:000266188900001	19443915	
J	Medina, JLV; Boque, R; Ferre, J				Villa Medina, Joe L.; Boque, Ricard; Ferre, Joan			Bagged k-nearest neighbours classification with uncertainty in the variables	ANALYTICA CHIMICA ACTA			English	Article						Uncertainty; Classification; Reliability; Nearest neighbours; Bootstrap	BOOTSTRAP METHODS	An analytical result should be expressed as x +/- U, where x is the experimental result obtained for a given variable and U is its uncertainty. This uncertainty is rarely taken into account in supervised classification. In this paper, we propose to include the information about the uncertainty of the experimental results to compute the reliability of classification. The method combines k-nearest neighbours (M) with a nested bootstrap scheme, in which a new bootstrap training set is generated using the classical bootstrap in the first level (B times) and a new bootstrap method, called U-bootstrap, in the second level (D times). Two bootstraps are used to reduce the effect of sampling in the first level and the effect of the uncertainty in the second one. These B x D new training bootstrap sets are used to compute the reliability of classification for an unknown object using kNN. The object is classified into the class with the highest reliability. In this method, unlike the classical kNN and Probabilistic Bagged k-nearest neighbours (PBkNN), the reliability of classification changes (increases or decreases) when the uncertainty is increased. These changes depend on the position of the unknown object with respect to the training objects. For the benchmark Wine dataset, we found similar values of classification error rate (CER) than for kNN (5.57%), but lower than Probabilistic Bagged k-nearest neighbours using Hamamoto's bootstrap (7.96%) or Efron's bootstrap (8.97%). (C) 2009 Elsevier B.V. All rights reserved.	[Villa Medina, Joe L.; Boque, Ricard; Ferre, Joan] Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, Tarragona 43007, Catalonia, Spain	Boque, R (reprint author), Univ Rovira & Virgili, Dept Analyt Chem & Organ Chem, C Marcel Li Domingo S-N, Tarragona 43007, Catalonia, Spain.	ricard.boque@urv.cat	Ferre Baldrich, Joan/L-5172-2014	Ferre Baldrich, Joan/0000-0001-6240-413X	Spanish Ministry of Education and Science [CTQ2007-66918]	The authors thank support of Department of Universities, Research and Information Society of Catalonia - Spain, for providing Joe Luis Villa's doctoral fellowship and project CTQ2007-66918 of the Spanish Ministry of Education and Science.	[Anonymous], 2005, 17025 ISOIEC; Asuncion A., UCI MACHINE LEARNING; Brieman L, 1996, MACH LEARN, V24, P123; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De la Rosa JI, 2006, IEEE T INSTRUM MEAS, V55, P820, DOI 10.1109/TIM.2006.873779; Duda R O, 2001, PATTERN CLASSIFICATI; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Ellison S. L. R., 2000, EURACHEM CITAC GUIDE; FORINA M, 1986, VITIS, V25, P189; Gurov S. I., 2004, Computational Mathematics and Modeling, V15, DOI 10.1023/B:COMI.0000047346.87442.ef; Hamamoto Y, 1997, IEEE T PATTERN ANAL, V19, P73, DOI 10.1109/34.566814; Henderson AR, 2005, CLIN CHIM ACTA, V359, P1, DOI 10.1016/j.cccn.2005.04.002; HINKLEY D, 1997, BOOTSTRAP METHODS TH, P575; HINKLEY DV, 1988, J ROY STAT SOC B MET, V50, P321; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Horwitz W, 2006, J AOAC INT, V89, P1095; Massart D. L., 1997, HDB CHEMOMETRICS Q A; Mooney C. Z., 1993, BOOTSTRAPPING NONPAR; Ramsey MH, 1998, J ANAL ATOM SPECTROM, V13, P97, DOI 10.1039/a706815h; Tibshirani R, 1993, INTRO BOOTSTRAP; Villa JL, 2008, CHEMOMETR INTELL LAB, V94, P51, DOI 10.1016/j.chemolab.2008.06.007; WEBB AR, 2002, STAT PATTERN RECOGNI, P252; Wehrens R, 2000, CHEMOMETR INTELL LAB, V54, P35, DOI 10.1016/S0169-7439(00)00102-7	23	3	5	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0003-2670	1873-4324		ANAL CHIM ACTA	Anal. Chim. Acta	JUL 30	2009	646	1-2					62	68		10.1016/j.aca.2009.05.016		7	Chemistry, Analytical	Chemistry	464RX	WOS:000267525000008		
J	Heimann, T; van Ginneken, B; Styner, MA; Arzhaeva, Y; Aurich, V; Bauer, C; Beck, A; Becker, C; Beichel, R; Bekes, G; Bello, F; Binnig, G; Bischof, H; Bornik, A; Cashman, PMM; Chi, Y; Cordova, A; Dawant, BM; Fidrich, M; Furst, JD; Furukawa, D; Grenacher, L; Hornegger, J; Kainmuller, D; Kitney, RI; Kobatake, H; Lamecker, H; Lange, T; Lee, J; Lennon, B; Li, R; Li, S; Meinzer, HP; Nemeth, G; Raicu, DS; Rau, AM; van Rikxoort, EM; Rousson, M; Rusko, L; Saddi, KA; Schmidt, G; Seghers, D; Shimizu, A; Slagmolen, P; Sorantin, E; Soza, G; Susomboon, R; Waite, JM; Wimmer, A; Wolf, I				Heimann, Tobias; van Ginneken, Bram; Styner, Martin A.; Arzhaeva, Yulia; Aurich, Volker; Bauer, Christian; Beck, Andreas; Becker, Christoph; Beichel, Reinhard; Bekes, Gyoergy; Bello, Fernando; Binnig, Gerd; Bischof, Horst; Bornik, Alexander; Cashman, Peter M. M.; Chi, Ying; Cordova, Andres; Dawant, Benoit M.; Fidrich, Marta; Furst, Jacob D.; Furukawa, Daisuke; Grenacher, Lars; Hornegger, Joachim; Kainmueller, Dagmar; Kitney, Richard I.; Kobatake, Hidefumi; Lamecker, Hans; Lange, Thomas; Lee, Jeongjin; Lennon, Brian; Li, Rui; Li, Senhu; Meinzer, Hans-Peter; Nemeth, Gabor; Raicu, Daniela S.; Rau, Anne-Mareike; van Rikxoort, Eva M.; Rousson, Mikael; Rusko, Laszlo; Saddi, Kinda A.; Schmidt, Guenter; Seghers, Dieter; Shimizu, Akinobu; Slagmolen, Pieter; Sorantin, Erich; Soza, Grzegorz; Susomboon, Ruchaneewan; Waite, Jonathan M.; Wimmer, Andreas; Wolf, Ivo			Comparison and Evaluation of Methods for Liver Segmentation From CT Datasets	IEEE TRANSACTIONS ON MEDICAL IMAGING			English	Article						Evaluation; liver; segmentation	FREE-FORM DEFORMATIONS; IMAGE SEGMENTATION; DIAGNOSTIC SYSTEM; SHAPE MODELS; REGISTRATION; ALGORITHM; EFFICIENT; CLASSIFICATION; CLASSIFIERS; VALIDATION	This paper presents a comparison study between 10 automatic and six interactive methods for liver segmentation from contrast-enhanced CT images. It is based on results from the "MICCAI 2007 Grand Challenge" workshop, where 16 teams evaluated their algorithms on a common database. A collection of 20 clinical images with reference segmentations was provided to train and tune algorithms in advance. Participants were also allowed to use additional proprietary training data for that purpose. All teams then had to apply their methods to 10 test datasets and submit the obtained results. Employed algorithms include statistical shape models, atlas registration, level-sets, graph-cuts and rule-based systems. All results were compared to reference segmentations five error measures that highlight different aspects of segmentation accuracy. All measures were combined according to a specific scoring system relating the obtained values to human expert variability. In general, interactive methods reached higher average scores than automatic approaches and featured a better consistency of segmentation quality. However, the best automatic methods (mainly based on statistical shape models with some additional free deformation) could compete well on the majority of test images. The study provides an insight in performance of different segmentation approaches under real-world conditions and highlights achievements and limitations of current image analysis techniques.	[Heimann, Tobias; Meinzer, Hans-Peter; Rau, Anne-Mareike; Wolf, Ivo] German Canc Res Ctr, Div Med & Biol Informat, D-69121 Heidelberg, Germany; [van Ginneken, Bram; Arzhaeva, Yulia; van Rikxoort, Eva M.] Univ Med Ctr Utrecht, Image Sci Inst, NL-3584 CX Utrecht, Netherlands; [Styner, Martin A.] Univ N Carolina, Dept Psychiat & Comp Sci, Chapel Hill, NC 27514 USA; [Aurich, Volker; Beck, Andreas] Univ Dusseldorf, Inst Comp Sci, D-40225 Dusseldorf, Germany; [Bauer, Christian; Bischof, Horst; Bornik, Alexander] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; [Beichel, Reinhard] Univ Iowa, Dept Elect & Comp Engn, Iowa City, IA 52242 USA; [Beichel, Reinhard] Univ Iowa, Dept Internal Med, Iowa City, IA 52242 USA; [Sorantin, Erich] Med Univ Graz, Dept Radiol, A-8036 Graz, Austria; [Becker, Christoph] Univ Hosp Munich, Dept Clin Radiol, D-81377 Munich, Germany; [Cordova, Andres] Clin Alemana Santiago, Dept Oncol, Santiago, Chile; [Grenacher, Lars] Univ Heidelberg Hosp, Dept Diagnost Radiol, D-69118 Heidelberg, Germany; [Bekes, Gyoergy; Fidrich, Marta; Nemeth, Gabor; Rusko, Laszlo] GE Hungary ZRT, Healthcare Div, H-6720 Szeged, Hungary; [Bello, Fernando] Univ London Imperial Coll Sci Technol & Med, Dept Biosurg & Surg Technol, London SW7 2AZ, England; [Cashman, Peter M. M.; Chi, Ying; Kitney, Richard I.] Univ London Imperial Coll Sci Technol & Med, Dept Bioengn, London SW7 2AZ, England; [Binnig, Gerd; Schmidt, Guenter] Definiens AG Res, D-80339 Munich, Germany; [Dawant, Benoit M.; Li, Rui] Vanderbilt Univ, Dept Elect Engn & Comp Sci, Nashville, TN 37235 USA; [Lennon, Brian; Li, Senhu; Waite, Jonathan M.] Pathfinder Therapeut Inc, Nashville, TN 37203 USA; [Furst, Jacob D.; Raicu, Daniela S.; Susomboon, Ruchaneewan] Depaul Univ, Coll Comp & Digital Media, Sch Comp, Intelligent Multimedia Proc Lab, Chicago, IL 60604 USA; [Furukawa, Daisuke; Kobatake, Hidefumi; Shimizu, Akinobu] Tokyo Univ Agr & Technol, Fuchu, Tokyo 183, Japan; [Hornegger, Joachim; Wimmer, Andreas] Univ Erlangen Nurnberg, Dept Comp Sci, Chair Pattern Recognit, D-91058 Erlangen, Germany; [Soza, Grzegorz] Siemens AG, Healthcare Sector, Computed Tomog, Forchheim, Germany; [Kainmueller, Dagmar; Lamecker, Hans] Zuse Inst Berlin, D-14195 Berlin, Germany; [Lange, Thomas] Charite Univ Med Berlin, Dept Surg & Surg Oncol, D-10117 Berlin, Germany; [Lee, Jeongjin] Catholic Univ Korea, Dept Digital Media, Seoul, South Korea; [Rousson, Mikael; Saddi, Kinda A.] Siemens Corp Res, Dept Imaging & Visualizat, Princeton, NJ 08540 USA; [Seghers, Dieter; Slagmolen, Pieter] Univ Hosp Gasthuisberg, Fac Med, Med Image Comp ESAT PSI, B-3000 Louvain, Belgium; [Seghers, Dieter; Slagmolen, Pieter] Univ Hosp Gasthuisberg, Fac Engn, B-3000 Louvain, Belgium	Heimann, T (reprint author), German Canc Res Ctr, Div Med & Biol Informat, D-69121 Heidelberg, Germany.	t.heimann@dkfz.de; bram@isi.uu.nl; martin_styner@ieee.org	van Ginneken, Bram/A-3728-2012; SHIMIZU, Akinobu/G-1085-2013; van Rikxoort, Eva/P-2640-2014; 	van Ginneken, Bram/0000-0003-2028-8972; van Rikxoort, Eva/0000-0001-6418-9760; Beck, Andreas/0000-0003-0563-0805; Kitney, Richard/0000-0002-6499-5209; Styner, Martin/0000-0002-8747-5118	Siemens AG, Healthcare Sector (Forchheim, Germany)	This work was supported by Siemens AG, Healthcare Sector (Forchheim, Germany).	Alkoot FM, 2002, PATTERN ANAL APPL, V5, P326; Armato SG, 1998, P SOC PHOTO-OPT INS, V3338, P916, DOI 10.1117/12.310968; Armato SG, 2004, RADIOLOGY, V232, P739, DOI 10.1148/radiol.2323032035; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Beck A, 2007, P MICCAI WORKSH 3 D, P225; Beichel R, 2007, P MICCAI WORKSH 3 D, P235; BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34; Bornik A., 2006, P ACM S VIRT REAL SO, P197, DOI 10.1145/1180495.1180536; BORNIK A, 2006, P IEEE S 3D US INT, P29; Bouix S, 2007, NEUROIMAGE, V36, P1207, DOI 10.1016/j.neuroimage.2007.04.031; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; CARR JC, 2001, P ACM SIGGRAPH 2001, P67, DOI DOI 10.1145/383259.383266; Chaney E, 2005, MED PHYS, V32, P3507, DOI 10.1118/1.2131093; Chen EL, 1998, IEEE T BIO-MED ENG, V45, P783; Chi Y., 2007, P MICCAI WORKSH 3D S, P167; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; COOTES T, 1994, IMAGE VISION COMPUT, V6, P355; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dawant BM, 2007, P MICCAI WORKSH 3 D, P215; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Floater MS, 2005, MATH VISUAL, P157, DOI 10.1007/3-540-26808-1_9; Fogel L. J., 1966, ARTIFICIAL INTELLIGE; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Furukawa D., 2007, P MICCAI WORKSH 3 D, P117; Gerig G, 2001, LNCS, V2208, P516; Gletsos M, 2003, IEEE T INF TECHNOL B, V7, P153, DOI 10.1109/TITB.2003.813793; Haralick R. M., 1973, IEEE T SYST MAN CYB, V6, P610; HEIMANN T, 2007, P MICCAI WORKSH 3 D; Heimann T, 2007, METHOD INFORM MED, V46, P275, DOI 10.1160/ME9043; Heimann T, 2007, LECT NOTES COMPUT SC, V4584, P1; Heimann T., 2007, P MICCAI WORKSH 3 D, P161; Heimann T, 2006, LECT NOTES COMPUT SC, V4191, P41; Heimann T, 2004, INT ARCH PHOTOGRAMME, V35, P317; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jaccard P., 1901, B SOC VAUD SCI NAT, V37, P547; Kainmuller D., 2007, P MICCAI WORKSH 3D S, P109; Lamecker H., 2004, SEGMENTATION LIVER U; Lee J., 2007, P MICCAI WORKSH 3 D, P189; Li K, 2005, LECT NOTES COMPUT SC, V3565, P406; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072; McLachlan GJ, 2008, EM ALGORITHM EXTENSI, V2nd; Meinzer HP, 2002, COMPUT GRAPH-UK, V26, P569, DOI 10.1016/S0097-8493(02)00102-4; NIESSEN WJ, 2000, PERFORMANCE CHARACTE, P275; Osher S., 2003, GEOMETRIC LEVEL SET; Pan S., 2001, P SOC PHOTO-OPT INS, V4322, P128, DOI 10.1117/12.431019; Park H, 2003, IEEE T MED IMAGING, V22, P483, DOI 10.1109/TMI.2003.809139; POHLE R, 2001, P SPIE MED IMAGING, V4322, P1337, DOI 10.1117/12.431013; PRICE K, 1986, COMPUT VISION GRAPH, V36, P387, DOI 10.1016/0734-189X(86)90083-6; Radtke A, 2007, WORLD J SURG, V31, P175, DOI 10.1007/s00268-005-0718-1; Rohlfing T., 2005, HDB MED IMAGE ANAL, V3, P435; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Rusko L., 2007, P MICCAI WORKSH 3 D, P143; Saddi K. A., 2007, P MICCAI WORKSH 3 D, P207; Schmidt G., 2007, P MICCAI WORKSH 3 D, P125; Schwefel H.P., 1995, EVOLUTION OPTIMUM SE; Seghers D, 2007, P MICCAI WORKSH 3 D, P135; Sethian J. A., 1999, LEVEL SET METHODS FA; Shimizu A, 2006, INT J CARS, V1, P525; Shimizu A, 2004, P COMP ASS RAD SURG, P1361; Shimizu A, 2007, INT J COMPUT ASS RAD, V2, P135, DOI 10.1007/s11548-007-0135-z; Slagmolen P, 2007, P MICCAI WORKSH 3 D, P197; Soler L, 2001, Comput Aided Surg, V6, P131, DOI 10.3109/10929080109145999; Sonka M., 2007, IMAGE PROCESSING ANA; Styner MA, 2002, PROC SPIE, V4684, P278, DOI 10.1117/12.467167; Susomboon R., 2007, P MICCAI WORKSH 3 D, P151; Tanimoto T., 1958, ELEMENTARY MATH THEO; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; van Rikxoort E., 2007, P MICCAI WORKSH 3 D, P101; Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Whitaker R. T., 2001, P INT C IM PROC, V3, P142; Wimmer A., 2007, P MICCAI WORKSH 3 D, P179; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7	79	185	200	8	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0278-0062			IEEE T MED IMAGING	IEEE Trans. Med. Imaging	AUG	2009	28	8					1251	1265		10.1109/TMI.2009.2013851		15	Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	477NJ	WOS:000268525500012	19211338	
J	Lee, H; Hong, S; Nizami, IF; Kim, E				Lee, Heesung; Hong, Sungjun; Nizami, Imran Fareed; Kim, Euntai			A Noise Robust Gait Representation: Motion Energy Image	INTERNATIONAL JOURNAL OF CONTROL AUTOMATION AND SYSTEMS			English	Article						Biometrics; gait recognition; MEI; NLPR database; noise	RECOGNITION; IDENTIFICATION	Gait-based human identification aims to discriminate individuals by the way they walk. A unique advantage of gait as a biometric is that it requires no subject contact and is easily acquired at a distance, which stands in contrast to other biometric techniques involving face, fingerprints, iris, etc. This paper proposes a new gait representation called motion energy image (MEI). Compared with other gait features, MEI is more robust against noise that can be included in binary gait silhouette images due to various factors. The effectiveness of the proposed method for gait recognition is demonstrated using experiments performed on the NLPR database.	[Lee, Heesung; Hong, Sungjun; Kim, Euntai] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea; [Nizami, Imran Fareed] Bahria Univ, Islamabad, Pakistan	Kim, E (reprint author), Yonsei Univ, Sch Elect & Elect Engn, 134 Sinchon Dong, Seoul 120749, South Korea.	4u2u@yonsei.ac.kr; imjune@yonsei.ac.kr; imran2k2@gmail.com; etkim@yonsei.ac.kr			Korea Science and Engineering Foundation (KOSEF) through the Biometrics Engineering Research Center (BERC) at Yonsei University [R11-2002-105-09002-0]	This work was supported by the Korea Science and Engineering Foundation (KOSEF) through the Biometrics Engineering Research Center (BERC) at Yonsei University. Grant Number: R11-2002-105-09002-0 (2009).	Bazin A., 2005, P IEE WORKSH APPL CO, P60; BenAbdelkader C, 2001, P INT C AUD VID BAS, P284; Bobick AF, 2001, PROC CVPR IEEE, P423; Collins R. T., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004181; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ekinci M, 2006, Proceedings of the Seventh International Conference on Automatic Face and Gesture Recognition - Proceedings of the Seventh International Conference, P517; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; HONG S, 2006, P SICE ICCAS2006, P3937; HORPRASER T, 1999, P IEEE INT C COMP VI; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; KALE A, 2003, P INT C AUD VID BAS, P706; LAM T, 2006, P INT C BIOM, P612; Lee L., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004148; Phillips P. J., 2002, Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition, DOI 10.1109/AFGR.2002.1004145; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505	16	11	11	0	2	INST CONTROL ROBOTICS & SYSTEMS, KOREAN INST ELECTRICAL ENGINEERS	BUCHEON	BUCHEON TECHNO PARK 401-1506, 193 YAKDAE-DONG WONMI-GU, BUCHEON, GYEONGGI-DO 420-734, SOUTH KOREA	1598-6446			INT J CONTROL AUTOM	Int. J. Control Autom. Syst.	AUG	2009	7	4					638	643		10.1007/s12555-009-0414-2		6	Automation & Control Systems	Automation & Control Systems	477HF	WOS:000268509200014		
J	Niu, B; Jin, YH; Lu, L; Fen, KY; Gu, L; He, ZS; Lu, WC; Li, YX; Cai, Y				Niu, Bing; Jin, Yuhuan; Lu, Lin; Fen, Kaiyan; Gu, Lei; He, Zhisong; Lu, Wencong; Li, Yixue; Cai, Yudong			Prediction of interaction between small molecule and enzyme using AdaBoost	MOLECULAR DIVERSITY			English	Article						Small molecule-enzyme couple; Chemical functional group; Biochemical and physicochemical properties; AdaBoost; Metabolic pathway	SUPPORT VECTOR MACHINES; MEMBRANE-PROTEIN TYPES; AMINO-ACID-COMPOSITION; FUNCTIONAL DOMAIN COMPOSITION; NEURAL-NETWORK MODEL; BETA-TURN TYPES; SUBCELLULAR LOCATION; STRUCTURAL CLASS; CLASSIFICATION; ALGORITHM	The knowledge of whether one enzyme can interact with a small molecule is essential for understanding the molecular and cellular functions of organisms. In this paper, we introduce a classifier to predict the small molecule- enzyme interaction, i.e., whether they can interact with each other. Small molecules are represented by their chemical functional groups, and enzymes are represented by their biochemical and physicochemical properties, resulting in a total of 160 features. These features are input into the AdaBoost classifier, which is known to have good generalization ability to predict interaction. As a result, the overall prediction accuracy, tested by tenfold cross-validation and independent sets, is 81.76% and 83.35%, respectively, suggesting that this strategy is effective. In this research, we typically choose interactions between small molecules and enzymes involved in metabolism to ultimately improve further understanding of metabolic pathways. An online predictor developed by this research is available at http://chemdata.shu.edu.cn.	[Jin, Yuhuan; Lu, Wencong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Niu, Bing] Shanghai Univ, Shanghai 200072, Peoples R China; [Lu, Lin] Shanghai Jiao Tong Univ, Dept Biomed Engn, Shanghai 200040, Peoples R China; [Fen, Kaiyan] Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England; [Gu, Lei; Li, Yixue] Chinese Acad Sci, Shanghai Inst Biol Sci, Key Lab Mol Syst Biol, Bioinformat Ctr, Shanghai 200031, Peoples R China; [He, Zhisong] Zhejiang Univ, Coll Life Sci, Dept Bioinformat, Hangzhou 310058, Zhejiang, Peoples R China; [Li, Yixue] Shanghai Ctr Bioinformat Technol, Shanghai 200235, Peoples R China; [Li, Yixue] Shanghai Jiao Tong Univ, Coll Life Sci & Biotechnol, Shanghai 200030, Peoples R China; [Cai, Yudong] Shanghai Univ, Inst Syst Biol, Shanghai 200244, Peoples R China; [Cai, Yudong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Dept Combinator & Geometry, Shanghai 200031, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Coll Sci, Dept Chem, 99 Shang Da Rd, Shanghai 200444, Peoples R China.	wclu@shu.edu.cn; cyd@picb.ac.cn	Jin, Yuhuan/G-9005-2013		National Natural Science Foundation of China [20503015]; Chinese Academy of Science [KSCX2-YWR-112]; Shanghai Leading Academic Discipline Project [J50101]	This work was supported by National Natural Science Foundation of China (No. 20503015), basic research grant of the Chinese Academy of Science (KSCX2-YWR-112), and the Shanghai Leading Academic Discipline Project (No. J50101).	BENDER ML, 1973, CATALYSIS ENZYME ACT; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brooksbank C., 2005, NUCLEIC ACIDS RES, V33, P46; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Bugg T. D. H., 1997, INTRO ENZYME COENZYM; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2002, PEPTIDES, V23, P205, DOI 10.1016/S0196-9781(01)00597-6; Cai YD, 2006, J THEOR BIOL, V238, P172, DOI 10.1016/j.jtbi.2005.05.034; Cai YD, 2002, COMPUT CHEM, V26, P179, DOI 10.1016/S0097-8485(01)00106-1; Cai YD, 2002, J COMPUT CHEM, V23, P267, DOI 10.1002/jcc.10017; Cai YD, 2002, COMPUT CHEM, V26, P347, DOI 10.1016/S0097-8485(01)00125-5; Cai YD, 2002, J PEPT SCI, V8, P297, DOI 10.1002/psc.401; Cai YD, 2003, J THEOR BIOL, V221, P115, DOI 10.1006/jtbi.2003.3179; CAI YD, 2007, METABOLIC PATHWAYMOD, P1; Cai YD, 2001, J BIOMOL STRUCT DYN, V18, P607; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Caspi R, 2006, NUCLEIC ACIDS RES, V34, pD511, DOI 10.1093/nar/gkj128; CHOTHIA C, 1990, ANNU REV BIOCHEM, V59, P1007, DOI 10.1146/annurev.biochem.59.1.1007; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou K.C., 2006, EXCLI J, V5, P55; Chou KC, 2004, BIOCHEM BIOPH RES CO, V321, P1007, DOI 10.1016/j.bbrc.2004.07.059; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 1997, J PROTEIN CHEM, V16, P575, DOI 10.1023/A:1026366706677; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Creighton T.E, 1993, PROTEINS STRUCTURES; Dubchak I, 1999, PROTEINS, V35, P401, DOI 10.1002/(SICI)1097-0134(19990601)35:4<401::AID-PROT3>3.0.CO;2-K; Fix E., 1951, DISCRIMINATORY ANAL, P261; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Freund Y, 2004, ANN STAT, V32, P1698, DOI 10.1214/009053604000000058; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 2000, ANN STAT, V28, P391; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Frishman D, 1997, PROTEINS, V27, P329, DOI 10.1002/(SICI)1097-0134(199703)27:3<329::AID-PROT1>3.0.CO;2-8; Goto S, 1998, BIOINFORMATICS, V14, P591, DOI 10.1093/bioinformatics/14.7.591; HERMANN D, 2005, BIOORGANIC CHEM CHEM, pCH2; HUBERTY C, 1994, APPL DISCRIMINANT AN; HYONEMYONG E, 1996, ENZYMOLOGY PRIMER RE; Jiang XY, 2008, AMINO ACIDS, V34, P669, DOI 10.1007/s00726-008-0034-9; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Johnson RA, 1982, APPL MULTIVARIATE ST; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; Kohonen T, 1998, NEUROCOMPUTING, V21, P19, DOI 10.1016/S0925-2312(98)00031-9; Kohonen T, 1997, NEURAL COMPUT, V9, P1321, DOI 10.1162/neco.1997.9.6.1321; Kuhn M, 2008, NUCLEIC ACIDS RES, V36, P684; Marchand-Geneste N, 2002, J MED CHEM, V45, P399, DOI 10.1021/jm0155244; Mardia K. V., 1979, MULTIVARIATE ANAL; Metzler D.E., 1977, BIOCH CHEM REACTIONS; MICHAEL P, 1997, ORGANIC BIOORGANIC M; Mucchielli-Giorgi MH, 1999, BIOINFORMATICS, V15, P176, DOI 10.1093/bioinformatics/15.2.176; Niu B, 2008, MOL DIVERS, V12, P41, DOI 10.1007/s11030-008-9073-0; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Ochs RA, 2007, MED IMAGE ANAL, V11, P315, DOI 10.1016/j.media.2007.03.004; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; SARAH AT, 2001, TRENDS BIOTECHNOL, V19, P482; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 1998, ANN STAT, V26, P1651; Scholkopf B., 2002, LEARNING KERNELS; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Tan C, 2007, ANAL BIOANAL CHEM, V389, P667, DOI 10.1007/s00216-007-1461-2; Tusnady GE, 1998, J MOL BIOL, V283, P489, DOI 10.1006/jmbi.1998.2107; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; Wheeler D. L., 2007, NUCLEIC ACIDS RES, V35, P5, DOI DOI 10.1093/NAR/GKL1031; Wishart DS, 2007, NUCLEIC ACIDS RES, V35, pD521, DOI 10.1093/nar/gkl923; Xie XD, 2006, BIOINFORMATICS, V22, P2722, DOI 10.1093/bioinformatics/btl482	68	20	20	1	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1381-1991			MOL DIVERS	Mol. Divers.	AUG	2009	13	3					313	320		10.1007/s11030-009-9116-1		8	Biochemistry & Molecular Biology; Chemistry, Applied; Chemistry, Medicinal; Chemistry, Multidisciplinary	Biochemistry & Molecular Biology; Chemistry; Pharmacology & Pharmacy	474SO	WOS:000268304500006	19219560	
J	Lu, J; Niu, B; Liu, L; Lu, WC; Cai, YD				Lu, Jin; Niu, Bing; Liu, Liang; Lu, Wen-Cong; Cai, Yu-Dong			Prediction of Small Molecules' Metabolic Pathways Based on Functional Group Composition	PROTEIN AND PEPTIDE LETTERS			English	Review						Adaboost; Jackknife cross-validation test; Independent set test; Metabolism	AMINO-ACID-COMPOSITION; PROTEIN SUBCELLULAR LOCATION; SUPPORT VECTOR MACHINES; STRUCTURAL CLASS PREDICTION; MODIFIED MAHALANOBIS DISCRIMINANT; NEAREST-NEIGHBOR ALGORITHM; ENZYME SUBFAMILY CLASSES; IMPROVED HYBRID APPROACH; NEURAL-NETWORK MODEL; DOMAIN COMPOSITION	How to correctly and efficiently determine small molecules' biological function is a challenge and has a positive effect on further metabonomics analysis. Here, we introduce a computational approach to address this problem. The new approach is based on AdaBoost method and featured by function group composition to the metabolic pathway analysis, which can fast and automatically map the small chemical molecules back to the possible metabolic pathway that they belong to. As a result, jackknife cross validation test and independent set test on the model reached 73.7% and 73.8%, respectively. It can be concluded that the current approach is very promising for mapping some unknown molecules' possible metabolic pathway. An online predictor developed by this research is available at http://chemdata.shu.edu.cn/pathway.	[Lu, Jin; Niu, Bing; Liu, Liang; Lu, Wen-Cong] Shanghai Univ, Sch Mat Sci & Engn, Shanghai 200072, Peoples R China; [Liu, Liang; Lu, Wen-Cong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China; [Cai, Yu-Dong] Shanghai Univ, Inst Syst Biol, Shanghai 200444, Peoples R China; [Cai, Yu-Dong] Chinese Acad Sci, Shanghai Inst Biol Sci, CAS MPG Partner Inst Computat Biol, Beijing 100864, Peoples R China	Lu, WC (reprint author), Shanghai Univ, Sch Mat Sci & Engn, 149 Yan Chang Rd, Shanghai 200072, Peoples R China.	wclu@shu.edu.cn; cyd@picb.ac.cn			Shanghai Leading Academic Discipline Project [J50101]	Financial support to this work is from Shanghai Leading Academic Discipline Project (Project Number: J50101).	Andraos J, 2008, CAN J CHEM, V86, P342, DOI 10.1139/V08-020; Anishetty S, 2005, COMPUT BIOL CHEM, V29, P368, DOI 10.1016/j.compbiolchem.2005.07.001; Dea-Ayuela MA, 2008, BIOORGAN MED CHEM, V16, P7770, DOI 10.1016/j.bmc.2008.07.023; Bishop C.M., 1995, NEURAL NETWORKS PATT; Boros L G, 2007, Ernst Schering Found Symp Proc, P189; Burkart MD, 2003, ORG BIOMOL CHEM, V1, P1, DOI 10.1039/b210173d; Cai YD, 2003, BIOPHYS J, V84, P3257; Cai YD, 2004, BIOINFORMATICS, V20, P1292, DOI 10.1093/bioinformatics/bth085; Cai YD, 2006, J THEOR BIOL, V238, P172, DOI 10.1016/j.jtbi.2005.05.034; Cai YD, 2003, BIOCHEM BIOPH RES CO, V305, P407, DOI 10.1016/S0006-291X(03)00775-7; Cai YD, 2002, COMPUT CHEM, V26, P179, DOI 10.1016/S0097-8485(01)00106-1; Cai YD, 2007, MIMS EPRINT, V110, P1; Cai YD, 2005, J PROTEOME RES, V4, P967, DOI 10.1021/pr0500399; Cai YD, 2004, J THEOR BIOL, V226, P373, DOI 10.1016/j.jtbi.2003.08.015; Cai YD, 2006, J THEOR BIOL, V238, P395, DOI 10.1016/j.jtbi.2005.05.035; Cai YD, 2004, BIOINFORMATICS, V20, P1151, DOI 10.1093/bioinformatics/bth054; Cai YD, 2001, J BIOMOL STRUCT DYN, V18, P607; Cai YD, 2002, J CELL BIOCHEM, V84, P343, DOI 10.1002/jcb.10030; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen C, 2008, J THEOR BIOL, V253, P388, DOI 10.1016/j.jtbi.2008.03.009; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen J, 2007, AMINO ACIDS, V33, P423, DOI 10.1007/s00726-006-0485-9; CHOU KC, 1995, PROTEINS, V21, P319, DOI 10.1002/prot.340210406; CHOU KC, 1998, ABSTR PAP AM CHEM S, V208, pU208; Chou KC, 2002, J BIOL CHEM, V277, P45765, DOI 10.1074/jbc.M204161200; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 2004, J CELL BIOCHEM, V91, P1197, DOI 10.1002/jcb.10790; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2006, BIOCHEM BIOPH RES CO, V348, P1479, DOI 10.1016/j.bbrc.2006.08.030; Chou KC, 2004, BIOCHEM BIOPH RES CO, V320, P1236, DOI 10.1016/j.bbrc.2004.06.073; Chou KC, 2000, BIOCHEM BIOPH RES CO, V278, P477, DOI 10.1006/bbrc.2000.3815; Chou KC, 2008, BIOCHEM BIOPH RES CO, V376, P321, DOI 10.1016/j.bbrc.2008.08.125; Chou KC, 2005, J CHEM INF MODEL, V45, P407, DOI 10.1021/ci049686v; Chou K.C., 2006, EXCLI J, V5, P55; Chou KC, 1998, BIOCHEM BIOPH RES CO, V252, P63, DOI 10.1006/bbrc.1998.9498; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2003, J CELL BIOCHEM, V90, P1250, DOI 10.1002/jcb.10719; CHOU KC, 1988, BIOPHYS CHEM, V30, P3, DOI 10.1016/0301-4622(88)85002-6; CHOU KC, 1992, J MOL BIOL, V223, P509, DOI 10.1016/0022-2836(92)90666-8; Chou KC, 1999, PROTEINS, V34, P137, DOI 10.1002/(SICI)1097-0134(19990101)34:1<137::AID-PROT11>3.0.CO;2-O; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Chou KC, 2004, CURR MED CHEM, V11, P2105; CHOU KC, 1994, ANAL BIOCHEM, V221, P217, DOI 10.1006/abio.1994.1405; CHOU KC, 1981, J THEOR BIOL, V89, P581, DOI 10.1016/0022-5193(81)90030-8; Chou KC, 2003, BIOCHEM BIOPH RES CO, V310, P675, DOI 10.1016/j.bbrc.2003.09.053; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2007, J CELL BIOCHEM, V100, P665, DOI 10.1002/jcb.21096; CHOU KC, 1993, J BIOL CHEM, V268, P16938; CHOU KC, 1990, BIOPHYS CHEM, V35, P1, DOI 10.1016/0301-4622(90)80056-D; Chou KC, 2003, BIOCHEM BIOPH RES CO, V308, P148, DOI 10.1016/S0006-291X(03)01342-1; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; CHOU KC, 1989, J BIOL CHEM, V264, P12074; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Atauri P, 2000, BIOTECHNOL BIOENG, V68, P18, DOI 10.1002/(SICI)1097-0290(20000405)68:1<18::AID-BIT3>3.0.CO;2-5; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Ding YS, 2007, PROTEIN PEPTIDE LETT, V14, P811; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Du PF, 2008, J THEOR BIOL, V253, P579, DOI 10.1016/j.jtbi.2008.04.006; Du QS, 2008, CURR PROTEIN PEPT SC, V9, P248, DOI 10.2174/138920308784534005; Fang Y, 2008, AMINO ACIDS, V34, P103, DOI 10.1007/s00726-007-0568-2; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; Freund Y, 2004, ANN STAT, V32, P1698, DOI 10.1214/009053604000000058; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 2000, ANN STAT, V28, P391; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Gao Y, 2005, AMINO ACIDS, V28, P373, DOI 10.1007/s00726-005-0206-9; Girgis RR, 2008, MOL PSYCHIATR, V13, P918, DOI 10.1038/mp.2008.40; Gordon Glen A, 2008, Journal of Biomedical Science & Engineering, V1, DOI 10.4236/jbise.2008.13025; JACKSON RC, 1995, TOXICOLOGY, V102, P197, DOI 10.1016/0300-483X(95)03048-K; Jahandideh S, 2007, J THEOR BIOL, V249, P785, DOI 10.1016/j.jtbi.2007.09.002; Jia PL, 2007, BIOCHEM BIOPH RES CO, V357, P366, DOI 10.1016/j.bbrc.2007.03.139; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; Jin YH, 2008, PROTEIN PEPTIDE LETT, V15, P286; Kanehisa M, 2006, NUCLEIC ACIDS RES, V34, pD354, DOI 10.1093/nar/gkj102; Kannan S, 2008, PROTEIN PEPTIDE LETT, V15, P1107, DOI 10.2174/092986608786071085; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Li FM, 2008, AMINO ACIDS, V34, P119, DOI 10.1007/s00726-007-0545-9; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Liu DQ, 2007, AMINO ACIDS, V32, P493, DOI 10.1007/s00726-006-0466-z; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; MARCHANDGENESTE N, 2002, NEW APPROACH PHARMAC, P399; Mardia K. V., 1979, MULTIVARIATE ANAL; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Moreno-Sanchez R, 2008, FEBS J, V275, P3454, DOI 10.1111/j.1742-4658.2008.06492.x; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; MYERS D, 1985, COMPUT APPL BIOSCI, V1, P105; Nicholson JK, 2004, NAT BIOTECHNOL, V22, P1268, DOI 10.1038/nbt1015; Niu B, 2008, MOL DIVERS, V12, P41, DOI 10.1007/s11030-008-9073-0; Niu B, 2006, PROTEIN PEPTIDE LETT, V13, P489, DOI 10.2174/092986606776819619; Pireddu L, 2006, NUCLEIC ACIDS RES, V34, pW714, DOI 10.1093/nar/gkl228; SALZBERG S, 1992, J MOL BIOL, V227, P371, DOI 10.1016/0022-2836(92)90892-N; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 1998, ANN STAT, V26, P1651; Shawe-Taylor J., 2000, INTRO SUPPORT VECTOR; Shen HB, 2009, ANAL BIOCHEM, V385, P153, DOI 10.1016/j.ab.2008.10.020; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen HB, 2007, EXPERT REV PROTEOMIC, V4, P453, DOI 10.1586/14789450.4.4.453; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, BIOPOLYMERS, V85, P233, DOI 10.1002/bip.20640; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Sirois S, 2004, J CHEM INF COMP SCI, V44, P1111, DOI 10.1021/ci034270n; Tian FF, 2008, PROTEIN PEPTIDE LETT, V15, P1033, DOI 10.2174/092986608786071120; Vapnik V., 1998, STAT LEARNING THEORY; Wang M, 2005, AMINO ACIDS, V28, P395, DOI 10.1007/s00726-005-0189-6; Wang M, 2004, PROTEIN ENG DES SEL, V17, P509, DOI 10.1093/protein/gzh061; Wang T, 2008, PROTEIN PEPTIDE LETT, V15, P915, DOI 10.2174/092986608785849308; Wardani AK, 2006, BIOCHEM ENG J, V28, P220, DOI 10.1016/j.bej.2005.10.003; Xiao X, 2006, AMINO ACIDS, V30, P49, DOI 10.1007/s00726-005-0225-6; Xiao X, 2007, PROTEIN PEPTIDE LETT, V14, P871, DOI 10.2174/092986607782110293; Xiao X, 2005, AMINO ACIDS, V28, P29, DOI 10.1007/s00726-004-0154-9; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Yamanishi Y, 2007, FEBS J, V274, P2262, DOI 10.1111/j.1742-4658.2007.05763.x; Yang ZR, 2008, OPEN BIOINFORM J, V2, P90; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; ZHOU GP, 1984, BIOCHEM J, V222, P169; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	132	19	19	0	4	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	0929-8665			PROTEIN PEPTIDE LETT	Protein Pept. Lett.	AUG	2009	16	8					969	976				8	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	482LO	WOS:000268890600015	19689424	
J	Dalton, L; Ballarin, V; Brun, M				Dalton, Lori; Ballarin, Virginia; Brun, Marcel			Clustering Algorithms: On Learning, Validation, Performance, and Applications to Genomics	CURRENT GENOMICS			English	Article						Clustering; genomics; profiling; microarray; validation index	GENE-EXPRESSION DATA; SELF-ORGANIZING MAPS; MOLECULAR CLASSIFICATION; PATTERNS; DISCOVERY; LYMPHOMA; MATRIX	The development of microarray technology has enabled scientists to measure the expression of thousands of genes simultaneously, resulting in a surge of interest in several disciplines throughout biology and medicine. While data clustering has been used for decades in image processing and pattern recognition, in recent years it has joined this wave of activity as a popular technique to analyze microarrays. To illustrate its application to genomics, clustering applied to genes from a set of microarray data groups together those genes whose expression levels exhibit similar behavior throughout the samples, and when applied to samples it offers the potential to discriminate pathologies based on their differential patterns of gene expression. Although clustering has now been used for many years in the context of gene expression microarrays, it has remained highly problematic. The choice of a clustering algorithm and validation index is not a trivial one, more so when applying them to high throughput biological or medical data. Factors to consider when choosing an algorithm include the nature of the application, the characteristics of the objects to be analyzed, the expected number and shape of the clusters, and the complexity of the problem versus computational power available. In some cases a very simple algorithm may be appropriate to tackle a problem, but many situations may require a more complex and powerful algorithm better suited for the job at hand. In this paper, we will cover the theoretical aspects of clustering, including error and learning, followed by an overview of popular clustering algorithms and classical validation indices. We also discuss the relative performance of these algorithms and indices and conclude with examples of the application of clustering to computational biology.	[Dalton, Lori] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA; [Ballarin, Virginia; Brun, Marcel] Univ Nacl Mar del Plata, Fac Ingn, Mar Del Plata, Argentina	Dalton, L (reprint author), Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.	ldalton@tamu.edu	Dalton, Lori/G-7254-2012		Agencia Nacional de Promocion Cientifica y Tecnologica [PICT2006-02313]	We would like to acknowledge the Agencia Nacional de Promocion Cientifica y Tecnologica (PICT2006-02313) for supporting part of the work behind this paper. We would also thank the reviewers for their helpful comments.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Andenberg M.R., 1973, CLUSTER ANAL APPL; Azuaje F, 2002, BIOINFORMATICS, V18, P319, DOI 10.1093/bioinformatics/18.2.319; AZUAJE F, 2002, PRACTICAL APPROACH M, P230; Bach FR, 2004, ADV NEUR IN, V16, P305; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; Bittner M, 2000, NATURE, V406, P536, DOI 10.1038/35020115; Bolshakova N, 2003, SIGNAL PROCESS, V83, P825, DOI 10.1016/S0165-1684(02)00475-9; Bottou L., 1995, ADV NEURAL INFORMATI, P585; Brazma A, 2000, FEBS LETT, V480, P17, DOI 10.1016/S0014-5793(00)01772-5; Brun M, 2007, PATTERN RECOGN, V40, P807, DOI 10.1016/j.patcog.2006.06.026; BRUN M, 2005, P SOC PHOTO-OPT INS, V5916, P283; BRUN MCD, 2005, GENOMIC SIGNAL PROCE, P129; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Bullinger L, 2004, NEW ENGL J MED, V350, P1605, DOI 10.1056/NEJMoa031046; Chipman H., 2003, STAT ANAL GENE EXPRE, P159; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dembele D, 2003, BIOINFORMATICS, V19, P973, DOI 10.1093/bioinformatics/btg119; Devroye L., 1996, PROBABILISTIC THEORY; Dougherty ER, 2002, J COMPUT BIOL, V9, P105, DOI 10.1089/10665270252833217; Dougherty ER, 2004, PATTERN RECOGN, V37, P917, DOI 10.1016/j.patcog.2003.10.003; Duda R. O., 2002, PATTERN CLASSIFICATI; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; FISHER L, 1971, BIOMETRIKA, V58, P91, DOI 10.2307/2334320; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gose E., 1996, PATTERN RECOGNITION; Guenter S., 2001, P 3 IAPR TC15 WORKSH, P229; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hua JP, 2007, BIOINFORMATICS, V23, P57, DOI 10.1093/bioinformatics/btl536; Jain A., 2004, P 17 INT C PATT REC, V1, P260; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504; Johnson CD, 2003, PHYSIOL GENOMICS, V13, P263, DOI 10.1152/physiolgenomics.00006.2003; Kalton A., 2001, P 7 ACM SIGKDD INT C, P299, DOI 10.1145/502512.502555; Kamishima T, 2003, MACH LEARN, V53, P199, DOI 10.1023/A:1026351106797; Kerr MK, 2001, P NATL ACAD SCI USA, V98, P8961, DOI 10.1073/pnas.161273698; Lubovac Z., 2001, P MATH COMP BIOL CHE, P149; Morrison C, 2004, AM J PATHOL, V165, P565, DOI 10.1016/S0002-9440(10)63321-4; Ramoni MF, 2002, P NATL ACAD SCI USA, V99, P9121, DOI 10.1073/pnas.132656399; ROSALES R, 2004, P 21 INT C MACH LEAR; Roth V, 2002, LECT NOTES COMPUT SC, V2415, P607; ROTH V, 2002, P INT C COMP STAT, P123; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Schliep A., 2003, BIOINFORMATICS, V19, pi255; Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307; Somogyi R, 1997, NONLINEAR ANAL-THEOR, V30, P1815, DOI 10.1016/S0362-546X(97)00217-4; Tamayo P, 1999, P NATL ACAD SCI USA, V96, P2907, DOI 10.1073/pnas.96.6.2907; Tavazoie S, 1999, NAT GENET, V22, P281; Theodoridis S., 1999, PATTERN RECOGNITION; Toronen P, 1999, FEBS LETT, V451, P142, DOI 10.1016/S0014-5793(99)00524-4; VANNESS JW, 1973, BIOMETRIKA, V60, P422, DOI 10.1093/biomet/60.2.422; Wang JB, 2002, BMC BIOINFORMATICS, V3, DOI 10.1186/1471-2105-3-36; Xing E.P., 2003, ADV NEURAL INFORMATI, V15, P505; Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977; Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309; ZHAO H, 2006, PLOS MED, V3, P13	57	11	11	1	4	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1389-2029			CURR GENOMICS	Curr. Genomics	SEP	2009	10	6					430	445				16	Biochemistry & Molecular Biology; Genetics & Heredity	Biochemistry & Molecular Biology; Genetics & Heredity	487AB	WOS:000269241500007	20190957	
J	Chen, ZS; Ji, CY				Chen, Zesheng; Ji, Chuanyi			An Information-Theoretic View of Network-Aware Malware Attacks	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Attack models; network security; performance metrics	WORMS	This work provides an information-theoretic view to better understand the relationships between aggregated vulnerability information viewed by attackers and a class of randomized epidemic scanning algorithms. In particular, this work investigates three aspects: 1) a network vulnerability as the nonuniform vulnerable-host distribution, 2) threats, i.e., intelligent malwares that exploit such a vulnerability, and 3) defense, i.e., challenges for fighting the threats. We first study five large data sets and observe consistent clustered vulnerable-host distributions. We then present a new metric, referred to as the nonuniformity factor, that quantifies the unevenness of a vulnerable-host distribution. This metric is essentially the Renyi information entropy that unifies the nonuniformity of a vulnerable-host distribution with different malware-scanning methods. Next, we draw a relationship between Renyi entropies and randomized epidemic scanning algorithms. We find that the infection rates of malware-scanning methods are characterized by the Renyi entropies that relate to the information bits in a nonunform vulnerable-host distribution extracted by a randomized scanning algorithm. Meanwhile, we show that a representative network-aware malware can increase the spreading speed by exactly or nearly a nonuniformity factor when compared to a random-scanning malware at an early stage of malware propagation. This quantifies that how much more rapidly the Internet can be infected at the early stage when a malware exploits an uneven vulnerable-host distribution as a network-wide vulnerability. Furthermore, we analyze the effectiveness of defense strategies on the spread of network-aware malwares. Our results demonstrate that counteracting network-aware malwares is a significant challenge for the strategies that include host-based defenses and IPv6.	[Chen, Zesheng] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA; [Ji, Chuanyi] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Chen, ZS (reprint author), Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA.	zchen@fiu.edu; jic@ece.gatech.edu			NSF [ECS 0300605]	This work was supported in part by NSF ECS 0300605.	[Anonymous], 2007, INT J SECURITY NETWO, V2, P71, DOI 10.1504/IJSN.2007.012826; Barford P., 2006, P PASS ACT MEAS C PA; Bellovin Steven M, 2006, LOGIN USENIX MAGAZIN, V31, P70; BRUMLEY D, 2006, ACM S INFORMATION CO; Cachin C., 1997, THESIS SWISS FEDERAL; *CERT COORD CTR, 2008, IN200109 CERT COORD; Chen L, 2007, LECT NOTES OPER RES, V7, P5; CHEN Z, 2007, P INFOCOM 07 ANCH AK; CHEN Z, 2003, P IEEE INFOCOM, V3, P1890; CHEN Z, 2008, ARXIV08050802V2; Chen Z., 2008, P INFOCOM 08 MIN C P; Cheng MF, 2005, BMC INFECT DIS, V5, DOI 10.1186/1471-2334-5-22; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FENG H, 2005, P INFOCOM05 MIAM FL, V4, P2405; Gu G., 2007, P 3 INT C SEC PRIV C; Gu G., 2004, P 20 ANN COMP SEC AP; KOHLER E, 2002, ACM SIGCOMM INT MEAS; MOORE D, 2002, ACM SIGCOMM INT MEAS; Moore D, 2003, IEEE SECUR PRIV, V1, P4; PRYADKIN Y, 2004, ISIT2004598 USC INF; Rajab M. A., 2005, Proceedings of the 14th USENIX Security Symposium; Renyi A., 1976, SELECTED PAPERS, V2, P526; Renyi A., 1970, PROBABILITY THEORY; Ross S., 2002, SIMULATION; Shakkottai S, 2007, IEEE J SEL AREA COMM, V25, P1745, DOI 10.1109/JSAC.2007.071212; Shannon C, 2004, IEEE SECUR PRIV, V2, P46, DOI 10.1109/MSP.2004.59; Staniford S., 2002, P 11 USENIX SEC S SE; Twycross J., 2003, P 12 USENIX SEC S AU, P285; VENKATARAMAN S, 2007, P 16 USENIX SEC S SE; VOJNOVIC M, 2008, P INFOCOM 08 PHOEN A; Vojnovic M, 2008, IEEE ACM T NETWORK, V16, P1066, DOI 10.1109/TNET.2007.909678; *WIK, 2008, SAM XSS; *WIK, 2008, AG COMP WORM; *WIK, 2008, SELF INF; YEGNESWARAN V, 2004, P S REC ADV INTR DET; ZOU CC, 2003, 10 ACM C COMP COMM S; Zou CC, 2006, SIMUL-T SOC MOD SIM, V82, P75, DOI 10.1177/0037549706065344; ZOU CC, 2006, ELSEVIER J PERFORMAN, V63, P700; 2008, ANALYSIS BLASTER WOR; 2008, INTERNET PROTOCOL V4	41	10	12	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	1556-6013			IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.	SEP	2009	4	3					530	541		10.1109/TIFS.2009.2025847		12	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	485WQ	WOS:000269155900022		
J	Babu, VS; Viswanath, P				Babu, V. Suresh; Viswanath, P.			Rough-fuzzy weighted k-nearest leader classifier for large data sets	PATTERN RECOGNITION			English	Article						k-NNC; Rough-fuzzy sets; Leaders-subleaders; Bayes classifier and RF-wk-NLC	LEARNING ALGORITHMS; NEIGHBOR RULE; REDUCTION; CATEGORIZATION; SELECTION	A leaders set which is derived using the leaders clustering method can be used in place of a large training set to reduce the computational burden of a classifier. Recently, a fast and efficient leader-based classifier called weighted k-nearest leader-based classifier is shown by us to be an efficient and faster classifier. But, there exist some uncertainty while calculating the relative importance (weight) of the prototypes. This paper proposes a generalization over the earlier proposed k-nearest leader-based classifier where a novel soft computing approach is used to resolve the uncertainty. Combined principles of rough set theory and fuzzy set theory are used to analyze the proposed method. The proposed method called rough-fuzzy weighted k-nearest leader classifier (RF-wk-NLC) uses a two level hierarchy of prototypes along with their relative importance. RF-wk-NLC is shown by using some standard data sets to have improved performance and is compared with the earlier related methods. (C)2008 Elsevier Ltd. All rights reserved.	[Babu, V. Suresh] Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India; [Viswanath, P.] Rajeev Gandhi Mem Coll Engn & Technol, Dept Comp Sci & Engn, Nandyal 518501, Andhra Pradesh, India	Babu, VS (reprint author), Indian Inst Technol, Dept Comp Sci & Engn, Gauhati 781039, India.	vsbabu@iitg.ernet.in; viswanath.pulabaigari@gmail.com					Aha DW, 1997, ARTIF INTELL REV, V11, P7, DOI 10.1023/A:1006538427943; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; Asharaf S, 2003, PATTERN RECOGN, V36, P3015, DOI 10.1016/S0031-3203(03)00081-5; Asharaf S, 2004, FUZZY SET SYST, V148, P119, DOI 10.1016/j.fss.2004.03.009; BABU VS, 2007, LECT NOTES COMPUTER, P17; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Bezdek JC, 1998, IEEE T SYST MAN CY C, V28, P67, DOI 10.1109/5326.661091; Bian H., 2003, 22 INT C N AM FUZZ I, P500, DOI 10.1109/NAFIPS.2003.1226836; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHANAS S, 1992, FUZZY SET SYST, V47, P391, DOI 10.1016/0165-0114(92)90305-N; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; DEVI VS, 2000, THESIS DEP ELECT ENG; DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628; Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Kohonen T., 1995, SELF ORGANIZING MAPS; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; NANDA S, 1992, FUZZY SET SYST, V45, P157, DOI 10.1016/0165-0114(92)90114-J; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 2004, PATTERN RECOGN, V37, P1561, DOI 10.1016/j.patcog.2003.12.012; Sanchez JS, 2006, NEUROCOMPUTING, V69, P922, DOI 10.1016/j.neucom.2005.10.001; Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023; Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1; Spath H., 1980, CLUSTER ANAL ALGORIT; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vijaya PA, 2004, PATTERN RECOGN LETT, V25, P505, DOI 10.1016/j.patrec.2003.12.013; WATSON I, KNOWLEDGE ENG REV, V9; Wilfong G, 1992, INT J COMPUT GEOM AP, V2, P383, DOI 10.1142/S0218195992000226; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yao YY, 1998, INFORM SCIENCES, V109, P227, DOI 10.1016/S0020-0255(98)10023-3; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	42	11	11	1	4	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	SEP	2009	42	9					1719	1731		10.1016/j.patcog.2008.11.021		13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	459GI	WOS:000267089000001		
J	Li, Y; Lu, BL				Li, Yun; Lu, Bao-Liang			Feature selection based on loss-margin of nearest neighbor classification	PATTERN RECOGNITION			English	Article						Feature selection; Loss function; Margin; Energy-based model	SIMILARITY	The problem of selecting a subset of relevant features is classic and found in many branches of science including-examples in pattern recognition. In this paper, we propose a new feature selection criterion based on low-loss nearest neighbor classification and a novel feature selection algorithm that optimizes the margin of nearest neighbor classification through minimizing its loss function. At the same time, theoretical analysis based on energy-based model is presented, and some experiments are also conducted on several benchmark real-world data sets and facial data sets for gender classification to show that the proposed feature selection method outperforms other classic ones. (C) 2008 Elsevier Ltd. All rights reserved.	[Li, Yun] Nanjing Univ Posts & Telecommun, Inst Comp Technol, Nanjing 210003, Peoples R China; [Lu, Bao-Liang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China	Li, Y (reprint author), Nanjing Univ Posts & Telecommun, Inst Comp Technol, 66 Xinmofan Rd, Nanjing 210003, Peoples R China.	yuncloudlee@gmail.com			National Natural Science Foundation of China [NSFC 60773090]; Shanghai Jiao Tong University; Microsoft Research Asian Joint Laboratory for Intelligent Computing and Intelligent Systems; Natural science fund for colleges and universities in Jiangsu Province [08KJB520007]; Scientific Research Foundation of Nanjing University of Posts and Telecommunications [NY207137]	We gratefully thank OMRON Cooperation for supplying facial images and R.G. Bachral for the code of Simba. This work was done in part while the first author was a Postdoctoral fellow at Department of Computer Science and Engineering, Shanghai Jiao Tong University, P.R. China. This research was partially supported by the National Natural Science Foundation of China via the Grants NSFC 60773090, and Shanghai Jiao Tong University and Microsoft Research Asian Joint Laboratory for Intelligent Computing and Intelligent Systems, Natural science fund for colleges and universities in Jiangsu Province via the Grants 08KJB520007, and Scientific Research Foundation of Nanjing University of Posts and Telecommunications via the Grants NY207137.	Bachrach R.G., 2004, P INT C MACH LEARN B; Chang C. C., 2002, LIBSVM LIB SUPPORT V; Chopra S, 2005, PROC CVPR IEEE, P539; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRAMMER K, 2002, P ADV NEUR INF PROC; Devijver P. A., 1982, PATTERN RECOGNITION; Guyon I., 2006, FEATURE EXTRACTION F; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Kira K., 1992, P 9 INT C MACH LEARN, P249; KOHAVI R, 1997, ARTIF INTELL, V97, P234; Kononenko I., 1994, P EUR C MACH LEARN, P171; LeCun Y., 2005, P INT WORKSH ART INT; LeCun Y., 2006, PREDICTING STRUCTURE; LI Y, 2007, LECT NOTES COMPUTER, V4781, P196; Lian H. C., 2005, LNCS, V3611, P433; Liu H., 2005, IEEE T KNOWL DATA EN, V17, P494; Liu H., 1998, FEATURE SELECTION KN; Merz C. J., 1996, UCI REPOSITORY MACHI; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Schapire RE, 1998, ANN STAT, V26, P1651; Sikonja M.R., 1997, P 14 INT C ICML 97, P296; WEINBERGER KQ, 2006, P ADV NEUR INF PROC, V18; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; XU LL, 2006, NAT C ART INT AAAI, P536	25	20	22	1	6	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	SEP	2009	42	9					1914	1921		10.1016/j.patcog.2008.10.011		8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	459GI	WOS:000267089000020		
J	Farcomeni, A				Farcomeni, Alessio			Generalized Augmentation to Control the False Discovery Exceedance in Multiple Testing	SCANDINAVIAN JOURNAL OF STATISTICS			English	Article						dependence; DNA microarrays; false discovery exceedance; false discovery rate; family-wise error rate; multiple testing	PROPORTION; NUMBER; CLASSIFICATION; HYPOTHESES; VARIANCE; HEALTH; RATES	A new multiple testing procedure, the generalized augmentation procedure (GAUGE), is introduced. The procedure is shown to control the false discovery exceedance and to be competitive in terms of power. It is also shown how to apply the idea of GAUGE to achieve control of other error measures. Extensions to dependence are discussed, together with a modification valid under arbitrary dependence. We present an application to an original study on prostate cancer and on a benchmark data set on colon cancer.	Univ Roma La Sapienza, I-00185 Rome, Italy	Farcomeni, A (reprint author), Univ Roma La Sapienza, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	alessio.farcomeni@uniroma1.it					Abramovich F, 2006, ANN STAT, V34, P584, DOI 10.1214/009053606000000074; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Benjamini Y, 2006, BIOMETRIKA, V93, P491, DOI 10.1093/biomet/93.3.491; BENJAMINI Y, 1995, J ROY STAT SOC B MET, V57, P289; Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.2307/1165312; BICKEL DR, 2004, ARXIVQBIO0404032V1 M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOUKAN P, 1994, LECT NOTES STAT, V85; Dudoit S., 2004, STAT APPL GENET MOL, V3; DUDOIT S, 2004, 166 U CAL DIV BIOST; ESARY JD, 1967, ANN MATH STAT, V38, P1466, DOI 10.1214/aoms/1177698701; Farcomeni A, 2007, SCAND J STAT, V34, P275, DOI 10.1111/j.1467-9469.2006.00530.x; Farcomeni A, 2008, STAT METHODS MED RES, V17, P347, DOI 10.1177/0962280206079046; Finner H, 2002, ANN STAT, V30, P220; Genovese C, 2002, J ROY STAT SOC B, V64, P499, DOI 10.1111/1467-9868.00347; Genovese CR, 2006, J AM STAT ASSOC, V101, P1408, DOI 10.1198/016214506000000339; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guo WG, 2007, STAT APPL GENET MOL, V6; Kerr MK, 2000, J COMPUT BIOL, V7, P819, DOI 10.1089/10665270050514954; KUMAR JD, 1983, ANN STAT, V11, P286; Lehmann EL, 2005, ANN STAT, V33, P1138, DOI 10.1214/009053605000000084; MARSHALL AW, 1967, J AM STAT ASSOC, V62, P30, DOI 10.2307/2282907; Meinshausen N, 2006, ANN STAT, V34, P373, DOI 10.1214/009053605000000741; Ottenbacher KJ, 1998, AM J EPIDEMIOL, V147, P615; Owen AB, 2005, J ROY STAT SOC B, V67, P411, DOI 10.1111/j.1467-9868.2005.00509.x; Pacifico MP, 2004, J AM STAT ASSOC, V99, P1002, DOI 10.1198/0162145000001655; R Development Core Team, 2007, R LANG ENV STAT COMP; Sarkar SK, 2007, ANN STAT, V35, P2405, DOI 10.1214/009053607000000398; Schaffer CM, 1998, J MARKET RES SOC, V40, P155; Schlaeppi M, 1996, BRIT J CLIN PRACT, V50, P14; SMITH RL, 2001, LECT NOTES U N CAROL; Soon SYT, 1996, STAT SINICA, V6, P703; Storey JD, 2002, J ROY STAT SOC B, V64, P479, DOI 10.1111/1467-9868.00346; Tamhane A., 1987, MULTIPLE COMP PROCED; Valentini A, 2007, DRUG METAB DISPOS, V35, P968, DOI 10.1124/dmd.107.014662; van der Lann M. J., 2004, STAT APPL GENET MOL, V3; van der Laan MJ, 2005, STAT APPL GENET MO B, V4; Vedantham K, 2001, CAN J PSYCHIAT, V46, P149; Westfall Peter H., 1993, RESAMPLING BASED MUL	39	3	3	0	0	WILEY-BLACKWELL PUBLISHING, INC	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0303-6898			SCAND J STAT	Scand. J. Stat.	SEP	2009	36	3					501	517		10.1111/j.1467-9469.2008.00633.x		17	Statistics & Probability	Mathematics	483SP	WOS:000268988600008		
J	Batsakis, S; Petrakis, EGM; Milios, E				Batsakis, Sotiris; Petrakis, Euripides G. M.; Milios, Evangelos			Improving the performance of focused web crawlers	DATA & KNOWLEDGE ENGINEERING			English	Article						Focused crawler; Learning crawler; Hidden Markov Model (HMM) crawler; World Wide Web	CLASSIFICATION; ALGORITHM	This work addresses issues related to the design and implementation of focused crawlers. Several variants of state-of-the-art crawlers relying on web page content and link information for estimating the relevance of web pages to a given topic are proposed. Particular emphasis is given to crawlers capable of learning not only the content of relevant pages (as classic crawlers do) but also paths leading to relevant pages. A novel learning crawler inspired by a previously proposed Hidden Markov Model (HMM) crawler is described as well. The crawlers have been implemented using the same baseline implementation (only the priority assignment function differs in each crawler) providing an unbiased evaluation framework for a comparative analysis of their performance. All crawlers achieve their maximum performance when a combination of web page content and (link) anchor text is used for assigning download priorities to web pages. Furthermore, the new HMM crawler improved the performance of the original HMM crawler and also outperforms classic focused crawlers in searching for specialized topics. (C) 2009 Elsevier B.V. All rights reserved.	[Batsakis, Sotiris; Petrakis, Euripides G. M.] TUC, Dept Elect & Comp Engn, GR-73100 Khania, Crete, Greece; [Milios, Evangelos] Dalhousie Univ, Fac Comp Sci, Halifax, NS B3H 1W5, Canada	Batsakis, S (reprint author), TUC, Dept Elect & Comp Engn, GR-73100 Khania, Crete, Greece.	batsakis@softnet.tuc.gr; petrakis@intelligence.tuc.gr; eem@cs.dal.ca					Aggarwal C.C., 2001, P 10 INT WORLD WID W, P96, DOI DOI 10.1145/371920.371955; Badia A., 2006, P 15 INT C WORLD WID, P1043, DOI 10.1145/1135777.1136006; Bao SH, 2008, IEEE T KNOWL DATA EN, V20, P1297, DOI 10.1109/TKDE.2008.98; BERGMARK D, 2002, 6 EUR C DIG LIB ROM; BERGMARK D, 2002, P 2 ACM IEEE CS JOIN; Brin S., 1998, P 7 INT WORLD WID WE, P107; Chakrabarti S, 1999, P 8 INT WORLD WID WE; Chakrabarti S., 2002, P 11 INT WORLD WID W, P148; Chang C.-H., 2006, IEEE T KNOWLEDGE DAT; CHEN Y, 2007, THESIS VIRGINIA POLY; Cho J, 2001, THESIS STANFORD U; Corley Courtney, 2005, P ACL WORKSH EMP MOD, P13, DOI 10.3115/1631862.1631865; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Bra P., 1994, P 4 RIAO C NEW YORK, P481; Diligenti M., 2000, P 26 INT C VER LARG, P527; Ehrig M., 2003, P S APPL COMP SAC 20; Hersovici M, 1998, COMPUT NETWORKS ISDN, V30, P317, DOI 10.1016/S0169-7552(98)00038-5; HLIAOUTAKIS A, 2006, INT J SEMANT WEB INF, V3, P55; Kraft R, 2003, FIRST LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P84; Li J., 2005, P 14 INT WORLD WID W, P1190; Liu HY, 2006, DATA KNOWL ENG, V59, P270, DOI 10.1016/j.datak.2006.01.012; Liu H., 2004, P 6 ANN ACM INT WORK, P16, DOI 10.1145/1031453.1031458; McCown F., 2007, ACM IEEE JOINT C DIG, P309; MENCZER F, 2004, ACM T INTERNET TECHN, V4, P378, DOI 10.1145/1031114.1031117; Pant G, 2005, ACM T INFORM SYST, V23, P430, DOI 10.1145/1095872.1095875; Pant G, 2006, IEEE T KNOWL DATA EN, V18, P107; Pant G., 2004, P 4 ACM IEEE CS JOIN, P142, DOI 10.1145/996350.996384; Pivk A, 2007, DATA KNOWL ENG, V60, P567, DOI 10.1016/j.datak.2006.04.002; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Rabiner L. R., 1986, IEEE ASSP Magazine, V3, DOI 10.1109/MASSP.1986.1165342; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Steinbach M., 2000, 6 ACM SIGKDD WORLD T; Varelas G., 2005, 7 ACM INT WORKSH WEB; Xu Q., 2007, P 16 INT C WORLD WID, P1159, DOI 10.1145/1242572.1242744	34	20	21	9	22	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-023X			DATA KNOWL ENG	Data Knowl. Eng.	OCT	2009	68	10					1001	1013		10.1016/j.datak.2009.04.002		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	504GK	WOS:000270603900007		
J	Annoni, M; Cristaldi, L; Lazzaroni, M; Ferrari, S				Annoni, Massimiliano; Cristaldi, Loredana; Lazzaroni, Massimo; Ferrari, Stefano			Nozzles Classification in a High-Pressure Water Jet System	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Classification; diagnosis; water jet (WJ) systems		In this paper, a technique for classifying the working condition of a water jet system is presented. The classifier is based on the discrete Fourier transform (DFT) of the electrical power signal. It is shown that this information can characterize the working condition of the system and predict the presence of (an incoming) faulty behavior. Experiments and comparisons with the 1-nearest-neighbor (1-NN) classifier have been carried out, showing promising results.	[Annoni, Massimiliano] Politecn Milan, Dipartimento Meccan, I-20156 Milan, Italy; [Cristaldi, Loredana] Politecn Milan, Dipartimento Elettrotecn, I-20133 Milan, Italy; [Lazzaroni, Massimo; Ferrari, Stefano] Univ Milan, Dipartimento Tecnol Informaz, I-26013 Crema, Italy	Annoni, M (reprint author), Politecn Milan, Dipartimento Meccan, I-20156 Milan, Italy.	massimiliano.annoni@polimi.it; loredana.cristaldi@polimi.it; lazzaroni@dti.unimi.it; ferrari@dti.unimi.it	Ferrari, Stefano/F-3407-2010	Ferrari, Stefano/0000-0002-4982-6212			ANNONI A, 2005, IMTC, P1311; ANNONI M, 2004, 17 INT C WAT JETT, P415; CHALMERS E, 1993, 7 AM WAT JET C SEATT, P327; Cherkassky V., 1998, LEARNING DATA; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cristaldi L, 2004, IEEE T INSTRUM MEAS, V53, P1020, DOI 10.1109/TIM.2004.830589; Fabien BC, 2003, MATH COMP MODEL DYN, V9, P45, DOI 10.1076/mcmd.9.1.45.16513; Friedman M, 1999, INTRO PATTERN RECOGN; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Jain A. K., 2000, IEEE T PATTERN ANAL, V22, P1; SINGH PJ, 1997, 9 AM WAT C DEAB MICH, P397; TREMBLAY M, 1999, 10 AM WAT C, P167; TUNKEL PJ, 1997, 9 AM WAT C, P397	13	2	2	0	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9456			IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	OCT	2009	58	10					3739	3745		10.1109/TIM.2009.2019702		7	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	493XP	WOS:000269772900045		
J	Manns, JR; Eichenbaum, H				Manns, Joseph R.; Eichenbaum, Howard			A cognitive map for object memory in the hippocampus	LEARNING & MEMORY			English	Article							IMPAIRED RECOGNITION MEMORY; ENTORHINAL CORTEX; SPATIAL REPRESENTATION; EPISODIC MEMORY; PLACE CELLS; DECLARATIVE MEMORY; PERIRHINAL CORTEX; RATS; DAMAGE; NEURONS	The hippocampus has been proposed to support a cognitive map, a mental representation of the spatial layout of an environment as well as the nonspatial items encountered in that environment. In the present study, we recorded simultaneously from 43 to 61 hippocampal pyramidal cells as rats performed an object recognition memory task in which novel and repeated objects were encountered in different locations on a circular track. Multivariate analyses of the neural data indicated that information about object identity was represented secondarily to the primary information dimension of object location. In addition, the neural data related to performance on the recognition memory task. The results suggested that objects were represented as points of interest on the hippocampal cognitive map and that this map was useful in remembering encounters with particular objects in specific locations.	[Manns, Joseph R.] Emory Univ, Dept Psychol, Atlanta, GA 30322 USA; [Eichenbaum, Howard] Boston Univ, Ctr Memory & Brain, Boston, MA 02215 USA	Manns, JR (reprint author), Emory Univ, Dept Psychol, Atlanta, GA 30322 USA.	jmanns@emory.edu			NIH [MH079564, MH51570]; NSF [SBE0354378]	We thank Kimberly Ong, Lisa Pytka, Carolyn Pearson, and Hannah Dalke for their assistance. This research was supported by grants NIH MH079564 (J. R. M), NIH MH51570 (H. E.), and NSF SBE0354378 (H. E.).	Alvarez P, 2001, LEARN MEMORY, V8, P79, DOI 10.1101/lm.38201; SUZUKI WA, 1994, J COMP NEUROL, V350, P497, DOI 10.1002/cne.903500402; Bachevalier J, 2008, HIPPOCAMPUS, V18, P64, DOI 10.1002/hipo.20369; Bunsey M, 1996, NATURE, V379, P255, DOI 10.1038/379255a0; Burgess N, 2002, NEURON, V35, P625, DOI 10.1016/S0896-6273(02)00830-9; Burwell RD, 1998, NEUROREPORT, V9, P3013, DOI 10.1097/00001756-199809140-00017; Clark RE, 2002, J NEUROSCI, V22, P4663; Clark RE, 2000, J NEUROSCI, V20, P8853; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Eichenbaum H, 1999, NEURON, V23, P209, DOI 10.1016/S0896-6273(00)80773-4; ENNACEUR A, 1988, BEHAV BRAIN RES, V31, P47, DOI 10.1016/0166-4328(88)90157-X; Fortin NJ, 2002, NAT NEUROSCI, V5, P458, DOI 10.1038/nn834; Fortin NJ, 2004, NATURE, V431, P188, DOI 10.1038/nature02853; Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901; Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721; Hargreaves EL, 2005, SCIENCE, V308, P1792, DOI 10.1126/science.1110449; JUNG MW, 1994, J NEUROSCI, V14, P7347; Kesner RP, 2002, BEHAV NEUROSCI, V116, P286, DOI 10.1037//0735-7044.116.2.286; Kjelstrup KB, 2008, SCIENCE, V321, P140, DOI 10.1126/science.1157086; Knierim JJ, 2006, HIPPOCAMPUS, V16, P755, DOI 10.1002/hipo.20203; Leutgeb S, 2005, SCIENCE, V309, P619, DOI 10.1126/science.1114037; Manns JR, 2007, NEURON, V56, P530, DOI 10.1016/j.neuron.2007.08.017; Manns JR, 2000, P NATL ACAD SCI USA, V97, P12375, DOI 10.1073/pnas.220398097; Manns JR, 2006, HIPPOCAMPUS, V16, P795, DOI 10.1002/hipo.20205; McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932; MILLER EK, 1993, J NEUROSCI, V13, P1460; Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723; Mumby DG, 2002, LEARN MEMORY, V9, P49, DOI 10.1101/lm.41302; O'keefe J, 1978, HIPPOCAMPUS COGNITIV; O'Keefe J, 1999, HIPPOCAMPUS, V9, P352, DOI 10.1002/(SICI)1098-1063(1999)9:4<352::AID-HIPO3>3.0.CO;2-1; Pascalis O, 2004, NEUROPSYCHOLOGIA, V42, P1293, DOI 10.1016/j.neuropsychologia.2004.03.005; Pihlajamaki M, 2004, EUR J NEUROSCI, V19, P1939, DOI 10.1111/j.1460.9568.2004.03282.x; SAVE E, 1992, BEHAV NEUROSCI, V106, P447, DOI 10.1037/0735-7044.106.3.447; Suzuki WA, 1997, J NEUROPHYSIOL, V78, P1062; TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626; Witter MP, 2000, HIPPOCAMPUS, V10, P398; WITTER MP, 1991, J COMP NEUROL, V307, P437, DOI 10.1002/cne.903070308; Wood ER, 1999, NATURE, V397, P613; Wood ER, 2000, NEURON, V27, P623, DOI 10.1016/S0896-6273(00)00071-4; Young BJ, 1997, J NEUROSCI, V17, P5183; Zola SM, 2000, J NEUROSCI, V20, P451	41	70	76	0	6	COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT	WOODBURY	500 SUNNYSIDE BLVD, WOODBURY, NY 11797-2924 USA	1072-0502			LEARN MEMORY	Learn. Mem.	OCT	2009	16	10					616	624		10.1101/lm.1484509		9	Neurosciences; Psychology, Experimental	Neurosciences & Neurology; Psychology	501GH	WOS:000270368500007	19794187	
J	Murphy, K; van Ginneken, B; Schilham, AMR; de Hoop, BJ; Gietema, HA; Prokop, M				Murphy, K.; van Ginneken, B.; Schilham, A. M. R.; de Hoop, B. J.; Gietema, H. A.; Prokop, M.			A large-scale evaluation of automatic pulmonary nodule detection in chest CT using local image features and k-nearest-neighbour classification	MEDICAL IMAGE ANALYSIS			English	Article						Nodule detection; Lung nodule; CT; Automatic detection; kNN; Shape index	COMPUTER-AIDED DETECTION; THIN-SECTION CT; LUNG-CANCER; HELICAL CT; SPIRAL CT; TOMOGRAPHY; SEGMENTATION; ALGORITHM; FEASIBILITY; EXPERIENCE	A scheme for the automatic detection of nodules in thoracic computed tomography scans is presented and extensively evaluated. The algorithm uses the local image features of shape index and curvedness in order to detect candidate structures in the lung volume and applies two successive k-nearest-neighbour classifiers in the reduction of false-positives. The nodule detection system is trained and tested on three databases extracted from a large-scale experimental screening study. The databases are constructed in order to evaluate the algorithm on both randomly chosen screening data as well as data containing higher proportions of nodules requiring follow-up. The system results are extensively evaluated including performance measurements on specific nodule types and sizes within the databases and on lesions which later proved to be malignant. In a random selection of 813 scans from the screening study a sensitivity of 80% with an average 4.2 false-positives per scan is achieved. The detection results presented are a realistic measure of a CAD system performance in a low-dose screening study which includes a diverse array of nodules of many varying sizes, types and textures. (C) 2009 Elsevier B.V. All rights reserved.	[Murphy, K.; van Ginneken, B.; Schilham, A. M. R.] Univ Med Ctr, Image Sci Inst, NL-3584 CX Utrecht, Netherlands; [de Hoop, B. J.; Gietema, H. A.; Prokop, M.] Univ Med Ctr, Dept Radiol, NL-3584 CX Utrecht, Netherlands	Murphy, K (reprint author), Univ Med Ctr, Image Sci Inst, Heidelberglaan 100,Room Q0S-459, NL-3584 CX Utrecht, Netherlands.	keelin@isi.uu.nl	van Ginneken, Bram/A-3728-2012; Prokop, W.M./H-8081-2014	van Ginneken, Bram/0000-0003-2028-8972; 			American Cancer Society, 2008, CANC FACTS FIG; Aoki T, 2000, AM J ROENTGENOL, V174, P763; Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009; Bae KT, 2005, RADIOLOGY, V236, P286, DOI 10.1148/radiol.2361041286; Bellotti R, 2007, MED PHYS, V34, P4901, DOI 10.1118/1.2804720; Betke M, 2003, MED IMAGE ANAL, V7, P265, DOI 10.1016/S1361-8415(03)00007-0; Brown MS, 2003, RADIOLOGY, V226, P256, DOI 10.1148/radiol.2261011708; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679; Chang S, 2004, LECT NOTES COMPUT SC, V3217, P821; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dehmeshki J, 2007, COMPUT MED IMAG GRAP, V31, P408, DOI 10.1016/j.compmedimag.2007.03.002; Duda R O, 2001, PATTERN CLASSIFICATI; Enquobahrie AA, 2007, ACAD RADIOL, V14, P579, DOI 10.1016/j.acra.2007.01.029; Ge ZY, 2005, MED PHYS, V32, P2443, DOI 10.1118/1.1944667; Gohagan JK, 2005, LUNG CANCER-J IASLC, V47, P9, DOI 10.1016/j.lungcan.2004.06.007; GURNEY JW, 1996, RADIOLOGY, V199, P122; Henschke CI, 2001, ONCOLOGIST, V6, P147, DOI 10.1634/theoncologist.6-2-147; Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615; Jeong YJ, 2007, AM J ROENTGENOL, V188, P57, DOI 10.2214/AJR.05.2131; Kakinuma R, 1999, RADIOLOGY, V212, P61; Kawata Y, 2004, LECT NOTES COMPUT SC, V3217, P838; Koenderink Jan J., 1990, SOLID SHAPE; Kostis WJ, 2003, IEEE T MED IMAGING, V22, P1259, DOI 10.1109/TMI.2003.817785; Li Q, 2008, ACAD RADIOL, V15, P165, DOI 10.1016/j.acra.2007.09.018; Matsumoto S, 2006, MED IMAGE ANAL, V10, P343, DOI 10.1016/j.media.2005.07.001; McCulloch CC, 2004, ACAD RADIOL, V11, P258, DOI 10.1016/S1076-6332(03)00729-3; Mendonca PRS, 2007, LECT NOTES COMPUT SC, V4584, P134; METZ CE, 1986, INVEST RADIOL, V21, P720; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; MURPHY K, 2007, P SPIE, V6514; New York Early Lung Cancer Action Project I, 2007, RADIOLOGY, V243, P239; Novello S, 2005, ANN ONCOL, V16, P1662, DOI 10.1093/annonc/mdi314; Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Reeves AP, 2006, IEEE T MED IMAGING, V25, P435, DOI 10.1109/TMI.2006.871548; Retico A, 2008, COMPUT BIOL MED, V38, P525, DOI 10.1016/j.compbiomed.2008.02.001; Rubin GD, 2005, RADIOLOGY, V234, P274, DOI 10.1148/radiol.2341040589; Sluimer I, 2005, IEEE T MED IMAGING, V24, P1025, DOI 10.1109/TMI.2005.851757; Swensen SJ, 2002, AM J RESP CRIT CARE, V165, P508, DOI 10.1164/rccm.2107006; Swensen SJ, 2005, RADIOLOGY, V235, P259, DOI 10.1148/radiol.2351041662; White CS, 1996, RADIOLOGY, V199, P109; Wiemker R, 2005, BRIT J RADIOL, V78, pS46, DOI 10.1259/bjr/30281702; Xu DM, 2006, LUNG CANCER, V54, P177, DOI 10.1016/j.lungcan.2006.08.006; YE X, 2007, C P IEEE ENG MED BIO, V1, P4449; Zhang XW, 2005, LECT NOTES COMPUT SC, V3565, P664; Zhao Binsheng, 2003, J Appl Clin Med Phys, V4, P248, DOI 10.1120/1.1582411; Zhou Jinghao, 2006, Med Image Comput Comput Assist Interv, V9, P784	47	45	49	1	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	1361-8415			MED IMAGE ANAL	Med. Image Anal.	OCT	2009	13	5					757	770		10.1016/j.media.2009.07.001		14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	499YY	WOS:000270264200006	19646913	
J	Chuang, LY; Yang, CS; Li, JC; Yang, CH				Chuang, Li-Yeh; Yang, Cheng-San; Li, Jung-Chike; Yang, Cheng-Hong			Chaotic Genetic Algorithm for Gene Selection and Classification Problems	OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY			English	Article							MICROARRAY DATA; CANCER CLASSIFICATION; DESIGN OPTIMIZATION; SYSTEM	Pattern recognition techniques suffer from a well-known curse, the dimensionality problem. The microarray data classification problem is a classical complex pattern recognition problem. Selecting relevant genes from microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multiclass categories being involved, and the usually small sample size. The goal of feature (gene) selection is to select those subsets of differentially expressed genes that are potentially relevant for distinguishing the sample classes. In this paper, information gain and chaotic genetic algorithm are proposed for the selection of relevant genes, and a K-nearest neighbor with the leave-one-out crossvalidation method serves as a classifier. The chaotic genetic algorithm is modified by using the chaotic mutation operator to increase the population diversity. The enhanced population diversity expands the GA's search ability. The proposed approach is tested on 10 microarray data sets from the literature. The experimental results show that the proposed method not only effectively reduced the number of gene expression levels, but also achieved lower classification error rates than other methods.	[Li, Jung-Chike; Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan; [Chuang, Li-Yeh] I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung, Taiwan; [Yang, Cheng-San] Chiayi Christian Hosp, Dept Plast Surg, Chiayi, Taiwan; [Yang, Cheng-San] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.	chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011; Yang, Cheng-Hong/M-7984-2013	Yang, Cheng-Hong/0000-0002-2741-0072	National Science Council in Taiwan [NSC96-2622-E-151-019-CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151-004-MY3, NSC95-2221-E-214-087, NSC95-2622-E-214-004, NSC94-2622E-151-025-CC3, NSC94-2622-E-151-025-CC3]	This work is partly supported by the National Science Council in Taiwan under grants NSC96-2622-E-151-019-CC3, NSC96-2622-E214-004-CC3, NSC95-2221-E-151-004-MY3, NSC95-2221-E-214-087, NSC95-2622-E-214-004, NSC94-2622E-151-025-CC3, and NSC94-2622-E-151-025-CC3.	ALATAS B, 2007, CHAOS SOLIT IN PRESS; Coelho LDS, 2008, EXPERT SYST APPL, V34, P1905, DOI 10.1016/j.eswa.2007.02.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis L. D., 1991, HDB GENETIC ALGORITH; Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Fallahi K, 2008, COMMUN NONLINEAR SCI, V13, P763, DOI 10.1016/j.cnsns.2006.07.006; Gupta S, 2007, MECH MACH THEORY, V42, P1418, DOI 10.1016/j.mechmachtheory.2006.10.002; Hastie T, 2001, ELEMENTS STAT LEARNI; Herrera F, 2000, APPL INTELL, V13, P187, DOI 10.1023/A:1026531008287; Holland J. H., 1992, ADAPTATION NATURAL A; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; KODAZ H, 2009, MED APPL INFORM GAIN; Liu SY, 2008, J SOUND VIB, V310, P855, DOI 10.1016/j.jsv.2007.08.006; Liu XX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-76; Martin-Valdivia MT, 2008, INFORM PROCESS MANAG, V44, P1146, DOI 10.1016/j.ipm.2007.09.014; MUKRAS R, 2007, P IJCAI; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; PEASE A, P NATL ACAD SCI US, V96, P5022; Shadrokh S, 2007, EUR J OPER RES, V181, P86, DOI 10.1016/j.ejor.2006.03.056; Snyder LV, 2006, EUR J OPER RES, V174, P38, DOI 10.1016/j.ejor.2004.09.057; Srinivasa KG, 2007, INFORM SCIENCES, V177, P4295, DOI 10.1016/j.ins.2007.05.008; Statnikov A, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-319; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TAHIR MA, 2005, EURASIP J APPL SIG P, V14, P2241; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; VERRON S, 2009, J PROCESS CONTROL; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Yang DX, 2007, CHAOS SOLITON FRACT, V34, P1366, DOI 10.1016/j.chaos.2006.04.057	29	7	7	0	0	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1536-2310	1557-8100		OMICS	OMICS	OCT	2009	13	5					407	420		10.1089/omi.2009.0007		14	Biotechnology & Applied Microbiology; Genetics & Heredity	Biotechnology & Applied Microbiology; Genetics & Heredity	500TO	WOS:000270328100005	19594377	
J	Dekel, O; Shalev-Shwartz, S; Singer, Y				Dekel, Ofer; Shalev-Shwartz, Shai; Singer, Yoram			Individual Sequence Prediction Using Memory-Efficient Context Trees	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						Context trees; online learning; perceptron; shifting bounds	PROBABILISTIC-AUTOMATA; LENGTH	Context trees are a popular and effective tool for tasks such as compression, sequential prediction, and language modeling. We present an algebraic perspective of context trees for the task of individual sequence prediction. Our approach stems from a generalization of the notion of margin used for linear predictors. By exporting the concept of margin to context trees, we are able to cast the individual sequence prediction problem as the task of finding a linear separator in a Hilbert space, and to apply techniques from machine learning and online optimization to this problem. Our main contribution is a memory efficient adaptation of the perceptron algorithm for individual sequence prediction. We name our algorithm the shallow perceptron and prove a shifting mistake bound, which relates its performance with the performance of any sequence of context trees. We also prove that the shallow perceptron grows a context tree at a rate that is upper bounded by its mistake rate, which imposes an upper bound on the size of the trees grown by our algorithm.	[Dekel, Ofer] Microsoft Res, Redmond, WA 98052 USA; [Shalev-Shwartz, Shai] Hebrew Univ Jerusalem, Dept Comp Sci & Engn, IL-91904 Jerusalem, Israel; [Singer, Yoram] Google Res, Mountain View, CA 94043 USA	Dekel, O (reprint author), Microsoft Res, Redmond, WA 98052 USA.	oferd@microsoft.com; shais@cs.huji.ac.il; singer@google.com			Israeli Science Foundation [522-04]	This work was supported in part by the Israeli Science Foundation under Grant 522-04.	AGMON S, 1954, CAN J MATH, V6, P382, DOI 10.4153/CJM-1954-037-2; Apostolico A, 2000, J COMPUT BIOL, V7, P381, DOI 10.1089/106652700750050844; Blackwell D, 1956, PAC J MATH, V6, P1; Buhlmann P, 1999, ANN STAT, V27, P480; Cesa-Bianchi N, 2006, PREDICTION LEARNING; Cesa-Bianchi N., 2006, P 19 ANN C COMP LEAR, P483; Cover T. M., 1965, P 4 PRAG C INF THEOR, P263; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P421, DOI 10.1109/TSMC.1977.4309738; Crammer K, 2006, J MACH LEARN RES, V7, P551; Duda R. O., 1973, PATTERN CLASSIFICATI; FEDER M, 1992, IEEE T INFORM THEORY, V38, P1258, DOI 10.1109/18.144706; GENTILE C, 2002, MACH LEARN, V53; Hannan J., 1957, CONTRIBUTIONS THEORY, V3, P97; Helmbold DP, 1997, MACH LEARN, V27, P51, DOI 10.1023/A:1007396710653; Novikoff ABJ, 1962, P S MATH THEOR AUT, VXII, P615; Pereira FC, 1999, MACH LEARN, V36, P183, DOI 10.1023/A:1007670818503; Robbins H., 1951, P 2 BERK S MATH STAT, P131; Ron D, 1996, MACH LEARN, V25, P117, DOI 10.1023/A:1026490906255; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Shalev-Shwartz S., 2007, THESIS HEBREW U JERU; SHALEVSHWARTZ S, 2006, ADV NEURAL INFORM PR, V20; WILLEMS FMJ, 1995, IEEE T INFORM THEORY, V41, P653, DOI 10.1109/18.382012; Willems F. M. J., 1994, Proceedings. 1994 IEEE International Symposium on Information Theory (Cat. No.94CH3467-8), DOI 10.1109/ISIT.1994.394632; WILLEMS FMJ, 1993, P 1993 IEEE INT S IN, P59, DOI 10.1109/ISIT.1993.748374; ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934	26	3	3	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855 USA	0018-9448			IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	NOV	2009	55	11					5251	5262		10.1109/TIT.2009.2030460		12	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	509LQ	WOS:000271019700033		
J	Lin, WZ; Xiao, X; Chou, KC				Lin, Wei-Zhong; Xiao, Xuan; Chou, Kuo-Chen			GPCR-GIA: a web-server for identifying G-protein coupled receptors and their families with grey incidence analysis	PROTEIN ENGINEERING DESIGN & SELECTION			English	Article						ensemble classifier; fusion; K nearest neighbor algorithm; pseudo amino acid composition; web server	AMINO-ACID-COMPOSITION; SUBCELLULAR LOCATION PREDICTION; SUPPORT VECTOR MACHINE; MODIFIED MAHALANOBIS DISCRIMINANT; STRUCTURAL CLASS PREDICTION; COMPLEXITY MEASURE FACTOR; ENZYME SUBFAMILY CLASSES; IMPROVED HYBRID APPROACH; APOPTOSIS PROTEINS; MEMBRANE-PROTEINS	G-protein-coupled receptors (GPCRs) play fundamental roles in regulating various physiological processes as well as the activity of virtually all cells. Different GPCR families are responsible for different functions. With the avalanche of protein sequences generated in the post-genomic age, it is highly desired to develop an automated method to address the two problems: given the sequence of a query protein, can we identify whether it is a GPCR? If it is, what family class does it belong to? Here, a two-layer ensemble classifier called GPCR-GIA was proposed by introducing a novel scale called 'grey incident degree'. The overall success rate by GPCR-GIA in identifying GPCR and non-GPCR was about 95%, and that in identifying the GPCRs among their nine family classes was about 80%. These rates were obtained by the jackknife cross-validation tests on the stringent benchmark data sets where none of the proteins has >= 50% pairwise sequence identity to any other in a same class. Moreover, a user-friendly web-server was established at http://218.65.61.89:8080/bioinfo/GPCR-GIA. For user's convenience, a step-by-step guide on how to use the GPCR-GIA web server is provided. Generally speaking, one can get the desired two-level results in around 10 s for a query protein sequence of 300-400 amino acids; the longer the sequence is, the more time that is needed.	[Lin, Wei-Zhong; Xiao, Xuan] Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 333001, Peoples R China; [Chou, Kuo-Chen] Gordon Life Sci Inst, San Diego, CA 92130 USA	Xiao, X (reprint author), Jing De Zhen Ceram Inst, Dept Comp, Jing De Zhen 333001, Peoples R China.	xiaoxuan0326@yahoo.com.cn	Chou, Kuo-Chen/A-8340-2009		National Natural Science Foundation of China [60661003]; department of education of JiangXi Province [GJJ09271]	The work in this research was supported by the grants from the National Natural Science Foundation of China (No. 60661003), the department of education of JiangXi Province (No. GJJ09271), and the plan for training youth scientists (stars of Jing-Cang) of Jiangxi Province.	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; Bhasin M, 2005, NUCLEIC ACIDS RES, V33, pW143, DOI 10.1093/nar/gki351; Cai YD, 2005, J THEOR BIOL, V234, P145, DOI 10.1016/j.jtbi.200.11.017; Call ME, 2006, CELL, V127, P355, DOI 10.1016/j.cell.2006.08.044; Chen C, 2006, J THEOR BIOL, V243, P444, DOI 10.1016/j.jtbi.2006.06.025; Chen C, 2009, PROTEIN PEPTIDE LETT, V16, P27; Chen C, 2006, ANAL BIOCHEM, V357, P116, DOI 10.1016/j.ab.2006.07.022; Chen YL, 2007, J THEOR BIOL, V248, P377, DOI 10.1016/j.jtbi.2007.05.019; Chen YL, 2007, J THEOR BIOL, V245, P775, DOI 10.1016/j.jtbi.2006.11.010; Chou KC, 2005, J PROTEOME RES, V4, P1681, DOI 10.1021/pr050145a; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, J PROTEOME RES, V5, P1888, DOI 10.1021/pr060167c; Chou KC, 1999, PROTEIN ENG, V12, P107, DOI 10.1093/protein/12.2.107; Chou KC, 2004, PROTEIN SCI, V13, P2857, DOI 10.1110/ps.04981104; Chou KC, 2006, J PROTEOME RES, V5, P316, DOI 10.1021/pr050331g; Chou KC, 2002, J PROTEOME RES, V1, P429, DOI 10.1021/pr025527k; Chou KC, 2001, PROTEINS, V44, P60, DOI 10.1002/prot.1072; Chou K.C., 2009, OPEN BIOINFORMATICS, V3, P31; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2008, NAT PROTOC, V3, P153, DOI 10.1038/nprot.2007.494; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2005, BIOINFORMATICS, V21, P10, DOI 10.1093/bioinformatics/bth466; Chou KC, 2005, J PROTEOME RES, V4, P1413, DOI 10.1021/pr050087t; Chou KC, 2003, PROTEINS, V53, P282, DOI 10.1002/prot.10500; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; Chou KC, 2007, J PROTEOME RES, V6, P1728, DOI 10.1021/pr060635i; Chou KC, 2007, ANAL BIOCHEM, V370, P1, DOI 10.1016/j.ab.2007.07.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENG JL, 1985, SYST CONTROL LETT, V1, P288; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Ding H, 2009, PROTEIN PEPTIDE LETT, V16, P351; Ding YS, 2008, PATTERN RECOGN LETT, V29, P1887, DOI 10.1016/j.patrec.2008.06.007; Douglas SM, 2007, P NATL ACAD SCI USA, V104, P6644, DOI 10.1073/pnas.0700930104; Du PF, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-518; Gao QB, 2006, PROTEIN ENG DES SEL, V19, P511, DOI 10.1093/protein/gzl038; Georgiou DN, 2009, J THEOR BIOL, V257, P17, DOI 10.1016/j.jtbi.2008.11.003; Gonzalez-Diaz H, 2008, PROTEOMICS, V8, P750, DOI 10.1002/pmic.200700638; GONZALEZDIAZ H, 2007, CURR TOP MED CHEM, V10, P1015; Gonzalez-Diaz H, 2008, CURR TOP MED CHEM, V8, P1676, DOI 10.2174/156802608786786543; Hall RA, 2002, CIRC RES, V91, P672, DOI 10.1161/01.RES.0000037000.74258.03; Heuss C, 2000, TRENDS NEUROSCI, V23, P469, DOI 10.1016/S0166-2236(00)01643-X; Hill CA, 2002, SCIENCE, V298, P176, DOI 10.1126/science.1076196; HOPP TP, 1981, P NATL ACAD SCI-BIOL, V78, P3824, DOI 10.1073/pnas.78.6.3824; Jiang XY, 2008, PROTEIN PEPTIDE LETT, V15, P392, DOI 10.2174/092986608784246443; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Li FM, 2008, PROTEIN PEPTIDE LETT, V15, P612, DOI 10.2174/092986608784966930; Lin H, 2008, PROTEIN PEPTIDE LETT, V15, P739, DOI 10.2174/092986608785133681; Lin H, 2008, J THEOR BIOL, V252, P350, DOI 10.1016/j.jtbi.2008.02.004; Lin H, 2009, ACTA BIOTHEOR, V57, P321, DOI 10.1007/s10441-008-9067-4; Lin H, 2007, J COMPUT CHEM, V28, P1463, DOI 10.1002/jcc.20554; Lin H, 2007, BIOCHEM BIOPH RES CO, V354, P548, DOI 10.1016/j.bbrc.2007.01.011; Liu H, 2005, BIOCHEM BIOPH RES CO, V336, P737, DOI 10.1016/j.bbrc.2005.08.160; LIU SF, 2006, SCI INQ, V7, P111; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Mardia K.V., 1979, MULTIVARIATE ANAL, P322; Matsunami H, 2000, NATURE, V404, P601; Milligan G, 2001, TRENDS PHARMACOL SCI, V22, P513, DOI 10.1016/S0165-6147(00)01801-0; Mondal S, 2006, J THEOR BIOL, V243, P252, DOI 10.1016/j.jtbi.2006.06.014; Mundra P, 2007, PATTERN RECOGN LETT, V28, P1610, DOI 10.1016/j.patrec.2007.04.001; Nakashima H., 1986, J BIOCHEM-TOKYO, V99, P152; Otaki JM, 2003, J THEOR BIOL, V223, P27, DOI 10.1016/S0022-5193(03)00068-7; Oxenoid K, 2005, P NATL ACAD SCI USA, V102, P10870, DOI 10.1073/pnas.0504920102; Pan YX, 2003, J PROTEIN CHEM, V22, P395, DOI 10.1023/A:1025350409648; Pillai KCS, 1985, ENCY STATISTICAL SCI, P176; Qiu JD, 2009, ANAL BIOCHEM, V390, P68, DOI 10.1016/j.ab.2009.04.009; Schnell JR, 2008, NATURE, V451, P591, DOI 10.1038/nature06531; Shen HB, 2005, BIOCHEM BIOPH RES CO, V337, P752, DOI 10.1016/j.bbrc.2005.09.117; Shen HB, 2005, BIOCHEM BIOPH RES CO, V334, P288, DOI 10.1016/j.bbrc.2005.06.087; Shen H.B., 2009, J BIOMED SCI ENG, V2, P136, DOI DOI 10.4236/JBISE.2009.23024; Shen HB, 2006, J THEOR BIOL, V240, P9, DOI 10.1016/j.jtbi.2005.08.016; Shen HB, 2007, BIOCHEM BIOPH RES CO, V364, P53, DOI 10.1016/j.bbrc.2007.09.098; Shen HB, 2008, ANAL BIOCHEM, V373, P386, DOI 10.1016/j.ab.2007.10.012; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen HB, 2007, BIOCHEM BIOPH RES CO, V363, P297, DOI 10.1016/j.bbrc.2007.08.140; Shen HB, 2009, J THEOR BIOL, V256, P441, DOI 10.1016/j.jtbi.2008.10.007; TANFORD C, 1962, J AM CHEM SOC, V84, P4240, DOI 10.1021/ja00881a009; Wang SQ, 2006, J THEOR BIOL, V242, P941, DOI 10.1016/j.jtbi.2006.05.006; Wen Z, 2007, AMINO ACIDS, V32, P277, DOI 10.1007/s00726-006-0341-y; Xiao X, 2008, J COMPUT CHEM, V29, P2018, DOI 10.1002/jcc.20955; Xiao X, 2009, J APPL CRYSTALLOGR, V42, P169, DOI 10.1107/S0021889809002751; Xiao X, 2009, J COMPUT CHEM, V30, P1414, DOI 10.1002/jcc.21163; Xiao X, 2008, J THEOR BIOL, V254, P691, DOI 10.1016/j.jtbi.2008.06.016; Xiao X, 2006, J COMPUT CHEM, V27, P478, DOI 10.1002/jcc.20354; Xiao X, 2005, AMINO ACIDS, V28, P57, DOI 10.1007/s00726-004-0148-7; Zeng YH, 2009, J THEOR BIOL, V259, P366, DOI 10.1016/j.jtbi.2009.03.028; Zhang GY, 2008, J THEOR BIOL, V253, P310, DOI 10.1016/j.jtbi.2008.03.015; Zhang GY, 2008, PROTEIN PEPTIDE LETT, V15, P1132, DOI 10.2174/092986608786071184; Zhang TL, 2008, J THEOR BIOL, V250, P186, DOI 10.1016/j.jtbi.2007.09.014; Zhou GP, 1998, J PROTEIN CHEM, V17, P729, DOI 10.1023/A:1020713915365; Zhou GP, 2006, PROTEINS, V63, P681, DOI 10.1002/prot.20898; Zhou GP, 2003, PROTEINS, V50, P44, DOI 10.1002/prot.10251; Zhou GP, 2001, PROTEINS, V44, P57, DOI 10.1002/prot.1071; Zhou XB, 2007, J THEOR BIOL, V248, P546, DOI 10.1016/j.jtbi.2007.06.001	94	59	59	0	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1741-0126			PROTEIN ENG DES SEL	Protein Eng. Des. Sel.	NOV	2009	22	11					699	705		10.1093/protein/gzp057		7	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	510RU	WOS:000271109800007	19776029	
J	Gertheiss, J; Tutz, G				Gertheiss, Jan; Tutz, Gerhard			Feature selection and weighting by nearest neighbor ensembles	CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS			English	Article						Nearest neighbor methods; Variable selection; Ensemble methods; Classification	PATTERN-RECOGNITION; CLASSIFICATION; DISCRIMINATION; REGRESSION	In the field of statistical discrimination nearest neighbor methods are a well known, quite simple but successful nonparametric classification tool If the number of predictors increases, however, predictive power normally deteriorates. In general. if some covariates are assumed to be noise variables. variable selection is a promising approach. The paper's main focus is on the development and evaluation of a nearest neighbor ensemble with implicit variable selection. In contrast to other nearest neighbor approaches we are not primarily interested in classification, but in estimating the (posterior) class probabilities. In simulation studies and for real world data the proposed nearest neighbor ensemble is compared to an extended forward/backward variable selection procedure for nearest neighbor classifiers, and some alternative well established classification tools (that offer probability estimates as well). Despite its simple structure, the proposed method's performance is quite good - especially if relevant covariates can be separated from noise variables. Another advantage of the presented ensemble is the easy identification of interactions that are usually hard to detect. So not simply variable selection but rather some kind of feature selection is performed. (C) 2009 Elsevier B.V. All rights reserved	[Gertheiss, Jan; Tutz, Gerhard] Univ Munich, D-80799 Munich, Germany	Gertheiss, J (reprint author), Univ Munich, Akad Str 1, D-80799 Munich, Germany.						Breiman L., 1984, CLASSIFICATION REGRE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brier G. W., 1950, MONTHLY WEATHER REVI, V78, P1, DOI [10.1175/1520-0493(1950)078<lessthan>0001:VOFEIT<greaterthan>2.0.CO;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DOMENICONI C, 2004, P 17 INT C PATT REC; Efron B, 2004, ANN STAT, V32, P407; Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273; Ferraty F., 2006, NONPARAMETRIC FUNCTI; Fix E., 1951, DISCRIMINATORY ANAL; FORINA M, 1982, FOOD RES DATA ANAL, P189; FRIEDMAN JH, 1994, FLEIBLE METRIC NEARE; Gertheiss J, 2009, J CHEMOMETR, V23, P149, DOI 10.1002/cem.1211; Hastie T, 2001, ELEMENTS STAT LEARNI; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HECHENBICHLER K, 2004, 399 SFB386 L M U MUN; Japon-Lujan R, 2006, J AGR FOOD CHEM, V54, P9706, DOI 10.1021/jf062546w; Karama M, 2004, SCI ENG COMPOS MATER, V11, P1; KOWALSKI BR, 1972, ANAL CHEM, V44, P1405, DOI 10.1021/ac60316a008; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; LEISCH F, MLBENCH MACHINE LEAR; Liaw A., 2002, R NEWS, V2, P18, DOI DOI 10.1016/J.MEMSCI.2010.02.036; Lukasiak BM, 2007, CHEMOMETR INTELL LAB, V87, P18, DOI 10.1016/j.chemolab.2006.01.003; Newman D., 1998, UCI REPOSITORY MACHI; R Development Core Team R, 2009, R LANG ENV STAT COMP; Ripley BD, 1996, PATTERN RECOGNITION; Selten R., 1998, EXPT EC, V1, P43, DOI [10.1007/BF01426214, DOI 10.1007/BF01426214]; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Therneau T, RPART RECURSIVE PART; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267; TURLACH BA, QUADPROG FUNCTIONS S; Venables W. N., 2002, MODERN APPL STAT S; Yankow D., 2006, LECT NOTES COMPUTER, P545	33	8	9	1	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0169-7439			CHEMOMETR INTELL LAB	Chemometrics Intell. Lab. Syst.	NOV 15	2009	99	1					30	38		10.1016/j.chemolab.2009.07.004		9	Automation & Control Systems; Chemistry, Analytical; Computer Science, Artificial Intelligence; Instruments & Instrumentation; Mathematics, Interdisciplinary Applications; Statistics & Probability	Automation & Control Systems; Chemistry; Computer Science; Instruments & Instrumentation; Mathematics	512MU	WOS:000271254400004		
J	Haouari, B; Ben Amor, N; Elouedi, Z; Mellouli, K				Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied; Mellouli, Khaled			Naive possibilistic network classifiers	FUZZY SETS AND SYSTEMS			English	Article; Proceedings Paper	8th Conference of the International-Association-for-Fuzzy-Set-Management-and-Economy (SIGEF)	NOV 30-DEC 02, 2006	Hammamet, TUNISIA	Int Assoc Fuzzy Set Management & Econ		Possibility theory; Classification; Naive Bayes classifier; Possibilistic classifier; Aggregation operators	FEATURE SUBSET-SELECTION; INDEPENDENCE	Naive Bayesian network classifiers have proved their effectiveness to accomplish the classification task, even if they work under the strong assumption of independence of attributes in the context of the class node. However, as all of them are based on probability theory, they run into problems when they are faced with imperfection. This paper proposes a new approach of classification under the possibilistic framework with naive classifiers. To output the naive possibilistic network classifier, two procedures are studied namely the building phase, which deals with imperfect (imprecise/uncertain) dataset attributes and classes, and the classification phase, which is used to classify new instances that may be characterized by imperfect attributes. To improve the performance of our classifier, we propose two extensions namely selective naive possibilistic classifier and semi-naive possibilistic classifier. Experimental study has shown naive Bayes style possibilistic classifier, and is efficient in the imperfect case. (C) 2009 Elsevier B.V. All rights reserved.	[Haouari, Bakhta; Ben Amor, Nahla; Elouedi, Zied] Inst Super Gest Tunis, LARODEC, Le Bardo 2000, Tunisia; [Mellouli, Khaled] Inst Hautes Etud Commerciales Tunis, Tunis, Tunisia	Haouari, B (reprint author), Inst Super Gest Tunis, LARODEC, 41 Ave Liberte, Le Bardo 2000, Tunisia.	bakhtahaouari@yahoo.fr					Ben Amor N., 2003, Soft Computing, V8, DOI 10.1007/S00500-002-0255-X; BENAMOR N, 2004, P IEEE INT C FUZZ SY, V2, P653; Ben Amor N, 2002, INT J UNCERTAIN FUZZ, V10, P117; Bishop C.M., 1996, NEURAL NETWORKS PATT; Borgelt C., 1999, P 7 EUR C INT TECHN, P556; Borgelt C., 1998, P 7 IEEE INT C FUZZ, P663; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dubois D., 1988, POSSIBILITY THEORY; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; DUBOIS D, 2000, P 3 INT C INF FUS PA, P21; DUBOIS D, 1994, POSSIBILITY THEORY A; Duda R. O., 1973, PATTERN CLASSIFICATI; ELOUEDI Z, 2006, LFA TOULOUSE, P61; Fonck P, 1997, INT J APPROX REASON, V16, P149, DOI 10.1016/S0888-613X(96)00095-3; FRIEH JM, 1997, ANN ORTHOP OUEST, V29, P161; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; Grossman D., 2004, P MACH LEARN, P46; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononerko I., 1991, P 6 EUR WORK SESS LE, P206; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P 10 NAT C ART INT, P223; LI X, 2003, IEEE WORKSH AUT SPEE; Liu H., 1998, FEATURE SELECTION KN; Murphy P., 1996, UCI REPOSITORY MACHI; PAZZANI M, 1997, LEARNING DATA ARTIFI, P239; PEARL J, 1988, PROBABILISTIC REASON, P221; Quinlan JR, 1986, MACH LEARN, V1, P106; Sahami M., 1996, P 2 INT C KNOWL DISC, P335; Shafer G., 1976, MATH THEORY EVIDENCE; Yager RR, 1997, INT J INTELL SYST, V12, P1; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, DOI 10.1016/0165-0114(78)90029-5; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	34	12	12	0	3	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0165-0114			FUZZY SET SYST	Fuzzy Sets Syst.	NOV 16	2009	160	22					3224	3238		10.1016/j.fss.2009.01.009		15	Computer Science, Theory & Methods; Mathematics, Applied; Statistics & Probability	Computer Science; Mathematics	504TU	WOS:000270641400004		
J	Chan, YB; Hall, P				Chan, Yao-Ban; Hall, Peter			ROBUST NEAREST-NEIGHBOR METHODS FOR CLASSIFYING HIGH-DIMENSIONAL DATA	ANNALS OF STATISTICS			English	Article						Classification boundary; detection boundary; false discovery rate; heterogeneous components; higher criticism; optimal classification; threshold; zero-one data	PATTERN-CLASSIFICATION; CONVERGENCE; PERFORMANCE	We suggest a robust nearest-neighbor approach to classifying high-dimensional data. The method enhances sensitivity by employing a threshold and truncates to a sequence of zeros and ones in order to reduce the deleterious impact of heavy-tailed data. Empirical rules are suggested for choosing the threshold. They require the bare minimum of data only one data vector is needed from each population. Theoretical and numerical aspects of performance are explored, paying particular attention to the impacts of correlation and heterogeneity among data components. On the theoretical side, it is shown that our truncated, thresholded, nearest-neighbor classifier enjoys the same classification boundary as more conventional, nonrobust approaches, which require finite moments in order to achieve good performance. In particular, the greater robustness of our approach does not come at the price of reduced effectiveness. Moreover, when both training sample sizes equal 1, our new method can have performance equal to that of optimal classifiers that require independent and identically distributed data with known marginal distributions; yet, our classifier does not itself need conditions of this type.	[Chan, Yao-Ban; Hall, Peter] Univ Melbourne, Dept Math & Stat, Parkville, Vic 3010, Australia	Chan, YB (reprint author), Univ Melbourne, Dept Math & Stat, Parkville, Vic 3010, Australia.	y.chan@ms.unimelb.edu.au; P.Hall@ms.unimelb.edu.au					Cover T. M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Devroye L., 1996, PROBABILISTIC THEORY; Donoho D, 2004, ANN STAT, V32, P962, DOI 10.1214/009053604000000265; Efron B, 2004, J AM STAT ASSOC, V99, P96, DOI 10.1198/016214504000000089; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; Hall P, 2008, J ROY STAT SOC B, V70, P159; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; Holst M, 2001, ANN STAT, V29, P1424; INGSTER Y. I., 1999, MATH METHODS STAT, V7, P401; Ingster Y. I., 2001, MATH METHODS STAT, V10, P395; INGSTER YI, 2002, MATH METHODS STAT, V11, P37; JIN J, 2002, DETECTION BOUN UNPUB; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Shakhnarovich G., 2006, NEAREST NEIGHBOR MET; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	18	1	1	0	1	INST MATHEMATICAL STATISTICS	CLEVELAND	3163 SOMERSET DR, CLEVELAND, OH 44122 USA	0090-5364			ANN STAT	Ann. Stat.	DEC	2009	37	6A					3186	3203		10.1214/08-AOS591		18	Statistics & Probability	Mathematics	518EO	WOS:000271673500004		
J	Chong, RM; Tanaka, T				Chong, Rachel Mabanag; Tanaka, Toshihisa			Detection and Classification of Invariant Blurs	IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND COMPUTER SCIENCES			English	Article						image extrema; invariant blurs; blur detection; blur classification	BLIND IMAGE DECONVOLUTION; NEURAL-NETWORK; PARAMETERS IDENTIFICATION; MULTIVALUED NEURONS; RESTORATION	A new algorithm for simultaneously detecting and identifying invariant blurs is proposed. This is mainly based on the behavior of extrema values in an image. It is computationally simple and fast thereby making it suitable for preprocessing especially fit practical imaging applications. Benefits of employing this method includes the elimination of unnecessary processes since unblurred images will be separated from the blurred ones which require deconvotution. Additionally, it can improve reconstruction performance by proper identification of blur type so that a more effective blur specific deconvolution algorithm can be applied. Experimental results on natural images and its synthetically blurred versions show the characteristics and validity of the proposed method. Furthermore, it can be observed that feature selection makes the method more efficient and effective.	[Chong, Rachel Mabanag; Tanaka, Toshihisa] Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Koganei, Tokyo 1848588, Japan	Chong, RM (reprint author), Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Koganei, Tokyo 1848588, Japan.	chong@sip.tuat.ac.jp; tanakat@cc.tuat.ac.jp			KAKENHI [1830057]; Support Center for Advanced Telecommunications Technology Research (SCAT)	This work is supported in part by KAKENHI, Grant-in-Aid for Scientific Research (1830057) and the Support Center for Advanced Telecommunications Technology Research (SCAT), 2009.	Aizenberg I, 2007, SOFT COMPUT, V11, P169, DOI 10.1007/s00500-006-0075-5; AIZENBERG I, 2006, COMPUTATIONAL INTELL, V17, P441; Aizenberg I, 2002, P SOC PHOTO-OPT INS, V4667, P460, DOI 10.1117/12.468009; Aizenberg I, 2008, IEEE T NEURAL NETWOR, V19, P883, DOI 10.1109/TNN.2007.914158; Aizenberg I, 2002, LECT NOTES COMPUT SC, V2415, P1231; Bhutta AA, 2006, LECT NOTES COMPUT SC, V4141, P94; CHANG MM, 1991, IEEE T SIGNAL PROCES, V39, P2323, DOI 10.1109/78.91207; CHONG RM, 2008, IEEE INT C SIGN IM T, V1, P320; Chung Y, 2004, IEEE C CYB INT SYST, V1, P356; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P61, DOI 10.1109/79.543976; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; LAGENDIJK RL, 2005, HDB IMAGE VIDEO PROC, P125; Marziliano P., 2002, P INT C IM PROC ROCH, V3, P57; ROOMS F, 2002, IEEE INT C AC SPEECH, V4, P4190; SAVAKIS AE, 1999, IEEE INT C IM PROC, V2, P885; Savakis AE, 1993, IEEE T IMAGE PROCESS, V2, P141, DOI 10.1109/83.217219; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; TONG H, 2004, IEEE INT C MULT EXPO, V1, P17; Wu SQ, 2007, IEEE IC COMP COM NET, P1166	21	2	2	1	3	IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG	TOKYO	KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011, JAPAN	0916-8508	1745-1337		IEICE T FUND ELECTR	IEICE Trans. Fundam. Electron. Commun. Comput. Sci.	DEC	2009	E92A	12					3313	3320		10.1587/transfun.E92.A.3313		8	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	538NH	WOS:000273190700045		
J	Qian, Y; Yao, F; Jia, S				Qian, Y.; Yao, F.; Jia, S.			Band selection for hyperspectral imagery using affinity propagation	IET COMPUTER VISION			English	Article							REMOTE-SENSING IMAGES; CLASSIFICATION; ALGORITHMS	Hyperspectral imagery generally contains enormous amounts of data because of hundreds of spectral bands. Band selection is often adopted to reduce computational cost and accelerate knowledge discovery and other tasks such as subsequent classification. An exemplar-based clustering algorithm termed affinity propagation for band selection is proposed. Affinity propagation is derived from factor graph, and operates by initially considering all data points as potential cluster centres (exemplars) and then exchanging messages between data points until a good set of exemplars and clusters emerges. Affinity propagation has been applied to computer vision and bioinformatics, and shown to be much faster than other clustering methods for large data. By combining the information about the discriminative capability of each individual band and the correlation/similarity between bands, the exemplars generated by affine propagation have higher importance and less correlation/similarity. The performance of band selection is evaluated through a pixel image classification task. Experimental results demonstrate that, compared with some popular band selection methods, the bands selected by affinity propagation best characterise the hyperspectral imagery from the pixel classification standpoint.	[Qian, Y.; Yao, F.] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China; [Jia, S.] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China	Qian, Y (reprint author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.	ytqian@zju.edu.cn			National Natural Science Foundation of China [60872071]	This work was supported by National Natural Science Foundation of China under project No. 60872071. We would like to thank anonymous reviewers who helped us considerably to improve the quality of this paper, and gave us many valuable suggestions.	Agarwal PK, 2002, ALGORITHMICA, V33, P201, DOI 10.1007/s00453-001-0110-y; Cardoso J., 2003, J MACHINE LEARNING R, V4, P1177, DOI 10.1162/jmlr.2003.4.7-8.1177; Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; Chang C.-I., 2003, HYPERSPECTRAL IMAGIN; Cover T. M., 1991, ELEMENTS INFORM THEO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dash M, 1997, PROC INT C TOOLS ART, P532, DOI 10.1109/TAI.1997.632300; Dueck D., 2009, THESIS U TORONTO; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Goutte C, 1999, NEUROIMAGE, V9, P298, DOI 10.1006/nimg.1998.0391; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Jain AK, 1999, ACM COMPUT SURV, V31; Jimenez-Rodriguez LO, 2007, IEEE T GEOSCI REMOTE, V45, P469, DOI 10.1109/TGRS.2006.885412; Kohavi R., 1995, INT JOINT C ART INT, V2, P1137; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar S, 2001, IEEE T GEOSCI REMOTE, V39, P1368, DOI 10.1109/36.934070; Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Neher R, 2005, IEEE T GEOSCI REMOTE, V43, P1363, DOI 10.1109/TGRS.2005.846865; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069; SOTOCA JM, 2006, P SSPR SPR 2006 AUG, P853	25	27	31	5	16	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-9632			IET COMPUT VIS	IET Comput. Vis.	DEC	2009	3	4					213	222		10.1049/iet-cvi.2009.0034		10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	536KP	WOS:000273043600005		
J	Fayed, HA; Atiya, AF; Hashem, SMR				Fayed, Hatem A.; Atiya, Amir F.; Hashem, Sherif M. R.			HYPERSPHERICAL PROTOTYPES FOR PATTERN CLASSIFICATION	INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE			English	Article						Pattern classification; nearest neighbor; hyperspherical prototypes	NEAREST-NEIGHBOR CLASSIFICATION; ALGORITHM; SEARCH; RULE; CLASSIFIERS; SELECTION; MODEL	The nearest neighbor method is one of the most widely used pattern classification methods. However its major drawback in practice is the curse of dimensionality. In this paper, we propose a new method to alleviate this problem significantly. In this method, we attempt to cover the training patterns of each class with a number of hyperspheres. The method attempts to design hyperspheres as compact as possible, and we pose this as a quadratic optimization problem. We performed several simulation experiments, and found that the proposed approach results in considerable speed-up over the k-nearest-neighbor method while maintaining the same level of accuray. It also significantly beats other prototype classification methods (Like LVQ, RCE and CCCD) in most performance aspects.	[Fayed, Hatem A.; Hashem, Sherif M. R.] Cairo Univ, Dept Engn Math & Phys, Giza, Egypt; [Atiya, Amir F.] Cairo Univ, Dept Comp Engn, Giza, Egypt	Fayed, HA (reprint author), Cairo Univ, Dept Engn Math & Phys, Giza, Egypt.	h_fayed@eng.cu.edu.eg; amir@alumni.caltech.edu; shashem@ieee.org					ATIYA A, 2004, P 1 INT COMP ENG C I, P258; ATIYA A, 2006, LECT NOTES COMPUTER, V4223, P116; Barandela R, 2005, INT J PATTERN RECOGN, V19, P787, DOI 10.1142/S0218001405004332; Bazaraa MS, 1979, NONLINEAR PROGRAMMIN; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Blake CL, UCI REPOSITORY MACHI; Blumenthal L. M., 1941, B AM MATH SOC, V47, P771, DOI 10.1090/S0002-9904-1941-07565-8; BURMAN P, 1989, BIOMETRIKA, V76, P503, DOI 10.1093/biomet/76.3.503; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Duda R O, 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fayed HA, 2007, PATTERN RECOGN, V40, P1498, DOI 10.1016/j.patcog.2006.10.018; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Fukunaga K., 1990, INTRO STAT PATTERN R; Gagne C, 2007, INT J PATTERN RECOGN, V21, P921, DOI 10.1142/S0218001407005752; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hattori K, 1999, PATTERN RECOGN, V32, P425, DOI 10.1016/S0031-3203(98)00097-1; HUDAK MJ, 1992, CYBERNET SYST, V23, P483, DOI 10.1080/01969729208927478; John F., 1948, COURANT ANNIVERSARY, P187; Kaufman L., 1990, FINDING GROUPS DATA; Khachiyan LG, 1996, MATH OPER RES, V21, P307, DOI 10.1287/moor.21.2.307; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; Kositsky M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, DOI 10.1109/ICPR.1996.547664; Kumar P, 2003, SIAM PROC S, P45; LEE EW, 1998, IEEE T PATTERN ANAL, V20, P567; Mehrotra S., 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028; Michie D., 1994, MACHINE LEARNING NEU; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Nock R, 2003, INT J PATTERN RECOGN, V17, P1369, DOI 10.1142/S0218001403002952; Post M.J., 1984, P 16 ANN ACM S THEOR, P108, DOI 10.1145/800057.808672; Prechelt L., 1994, PROBEN1 SET NEURAL N; Priebe CE, 2003, J CLASSIF, V20, P3, DOI 10.1007/s00357-003-0003-7; Qiu XP, 2006, INT J PATTERN RECOGN, V20, P1245, DOI 10.1142/S0218001406005186; REILLY DL, 1982, BIOL CYBERN, V45, P35, DOI 10.1007/BF00387211; Salzberg S., 1991, MACH LEARN, V6, P277; SILVERMAN BW, 1980, SIAM J SCI STAT COMP, V1, P401, DOI 10.1137/0901028; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; TSUMURA N, 1995, PATTERN RECOGN, V28, P1621, DOI 10.1016/0031-3203(95)00027-W; VOLMER S, 2002, P 5 INT C VIS INF SY, P36; WELZL E, 1991, LECT NOTES COMPUT SC, V555, P359; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wolfe P, 1961, Q APPL MATH, V19, P239; Wright S., 1997, PRIMAL DUAL INTERIOR; Zhang HB, 2002, PATTERN RECOGN, V35, P1481, DOI 10.1016/S0031-3203(01)00137-6	46	1	1	1	3	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-0014			INT J PATTERN RECOGN	Int. J. Pattern Recognit. Artif. Intell.	DEC	2009	23	8					1549	1575		10.1142/S0218001409007740		27	Computer Science, Artificial Intelligence	Computer Science	541OK	WOS:000273425500002		
J	Hu, JN; Deng, WH; Guo, J; Xu, WR				Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran			Learning a locality discriminating projection for classification	KNOWLEDGE-BASED SYSTEMS			English	Article						Feature exaction; Manifold learning; Discriminant analysis	NONLINEAR DIMENSIONALITY REDUCTION; FACE RECOGNITION; PALM BIOMETRICS; LAPLACIANFACES; EIGENFACES; FRAMEWORK	This paper introduces a new algorithm called locality discriminating projection (LDP) for subspace learning, which provides a new scheme for discriminant analysis by considering both the manifold structure and the prior class information. In the LDP algorithm, the overlap among the class-specific manifolds is approximated by an invader graph, and a locality discriminant criterion is proposed to find the projections that best preserve the within-class local structures while decrease the between-class overlap. The feasibility of the LDP algorithm has been successfully tested in text data and visual recognition experiments. Experiment results show it is an effective technique for data modeling and classification comparing to linear discriminant analysis, locality preserving projection, and marginal Fisher analysis. (C) 2009 Elsevier B.V. All rights reserved.	[Hu, Jiani; Deng, Weihong; Guo, Jun; Xu, Weiran] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China	Hu, JN (reprint author), Beijing Univ Posts & Telecommun, Xi Tu Chen Rd 10, Beijing 100876, Peoples R China.	cughu@126.com			National High-Tech Development Plan of China [2007AA01Z417]; Foundation of China Education Ministry	This work was partially sponsored by National High-Tech Development Plan of China (2007AA01Z417), and the Foundation of China Education Ministry for III project.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2002, ADV NEUR IN, V14, P585; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; CHUNG FRK, 1997, AMS REGIONAL C SER M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deng WH, 2008, IEEE T PATTERN ANAL, V30, P1503, DOI 10.1109/TPAMI.2007.70783; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151; He X., 2003, P C ADV NEUR INF PRO; He XF, 2005, IEEE T PATTERN ANAL, V27, P328; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; HU J, 2007, P IEEE RAD FREQ INT, P689, DOI 10.1145/1277741.1277860; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sebastiani F., 2002, ACM COMPUT SURV, V34, P47; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VASCONCELOS N, 2004, P 8 EUR C COMP VIS, V3, P430; Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394	22	13	14	0	2	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0950-7051			KNOWL-BASED SYST	Knowledge-Based Syst.	DEC	2009	22	8					562	568		10.1016/j.knosys.2009.02.010		7	Computer Science, Artificial Intelligence	Computer Science	524AY	WOS:000272117400002		
J	Li, J; Allinson, NM				Li, Jing; Allinson, Nigel M.			Subspace learning-based dimensionality reduction in building recognition	NEUROCOMPUTING			English	Article						Subspace learning; Building recognition; Biologically-inspired feature extraction; Gist features; Dimensionality reduction	DISCRIMINANT-ANALYSIS; RELEVANCE-FEEDBACK; VISUAL-ATTENTION; FACE RECOGNITION; IMAGE RETRIEVAL; FEATURES; CLASSIFICATION; SCENE	Building recognition is a relatively specific recognition task in object recognition, which is challenging since it encounters rotation, scaling, illumination changes, occlusion. etc. Subspace learning, which dominates dimensionality reduction, has been widely exploited in computer vision research in recent years. it consists of classical linear dimensionality reduction methods, manifold learning, etc. To explore how different subspace learning algorithms affect building recognition, some representative algorithms, i.e., principal component analysis, linear discriminant analysis, locality preserving projections (unsupervised/supervised), and semi-supervised discriminant analysis, are applied for dimensionality reduction. Moreover, a building recognition scheme based on biologically-inspired feature extraction is proposed in this paper. Experiments undertaken on our own building database demonstrate that the proposed scheme embedded with subspace learning can achieve satisfactory results. (C) 2009 Elsevier B.V. All rights reserved.	[Li, Jing; Allinson, Nigel M.] Univ Sheffield, Vis & Informat Engn Res Grp, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England	Li, J (reprint author), Univ Sheffield, Vis & Informat Engn Res Grp, Dept Elect & Elect Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.	elq06jl@sheffield.ac.uk; n.allinson@sheffield.ac.uk		Allinson, Nigel/0000-0002-4775-8332			Ali H., 2007, P INT S MOB MAPP TEC, P28; Belkin M, 2002, ADV NEUR IN, V14, P585; Bellman R., 1961, ADAPTIVE CONTROL PRO; Cai D., 2007, P IEEE INT C COMP VI, P1; CAI D, 2005, 2636 U ILL URB DEP C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; Dorko G., 2003, P INT C COMP VIS, V1, P634; Fergus R., 2003, P IEEE C COMP VIS PA, V2; Ferrari V, 2006, LECT NOTES COMPUT SC, V4170, P145; FRITZ G, 2005, P IEEE INT C ICRA, P131, DOI 10.1109/ROBOT.2005.1570108; Harris C., 1988, ALV VIS C, P147; He X., 2003, P C ADV NEUR INF PRO; He X., 2007, ACM T MULTIMEDIA COM, V3; He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692; Hutchings R., 2005, CSTR06017 U BRIST; Iqbal Q., 1999, P IEEE INT C COMP VI, V1, P42, DOI 10.1.1.76.750; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jolliffe I. T., 2002, PRINCIPAL COMPONENT; Lazebnik S., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; LEE DC, 2003, CYTOKINE HDB, V2, P959; Leibe B., 2003, P BRIT MACH VIS C, P759; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li F, 2003, P IEEE INT C COMP VI, V2, P1134; Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032; LI Y, 2002, P INT C PATT REC, V3, P952; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Mikolajczyk K., 2005, P ICCV, V2, P1792; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Song D., 2008, P IEEE INT C PATT RE, P1; SONG D, IEEE T IMAG IN PRESS; TAO D, 2008, IEEE T CIRCUITS SYST, V18, P1; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2007, IEEE T KNOWL DATA EN, V19, P568, DOI 10.1109/TKDE.2007.1003; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375; Tao DC, 2004, INT C PATT RECOG, P1013; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Torralba A., 2003, P 9 IEEE INT C COMP, V1, p[273, 280]; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TURNER RS, 1994, EYES MIND VISION H H; Ullah MM, 2008, IEEE INT CONF ROBOT, P530, DOI 10.1109/ROBOT.2008.4543261; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Wu Jiang, 2008, V446, P1, DOI 10.1007/978-1-60327-084-7_1; Xu D, 2007, IEEE T SYST MAN CY B, V37, P1226, DOI 10.1109/TSMCB.2006.888925; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; ZHANG T, 2008, IEEE T KNOWLEDGE DAT; Zhang T., 2008, P 10 EUR C COMP VIS, P725; ZHANG T, 2008, P IEEE INT JOINT C N, P1671; Zhang W., 2005, IEEE COMP SOC C COMP, P21	55	6	8	0	6	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	DEC	2009	73	1-3			SI		324	330		10.1016/j.neucom.2009.08.016		7	Computer Science, Artificial Intelligence	Computer Science	530QI	WOS:000272607000038		
J	Yang, XB; Chen, SC; Chen, B; Pan, ZS				Yang, Xubing; Chen, Songcan; Chen, Bin; Pan, Zhisong			Proximal support vector machine using local information	NEUROCOMPUTING			English	Article						Proximal classification; Eigenvalue; Manifold learning; Outlier	NONLINEAR DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; GENERALIZED EIGENVALUES; FACE RECOGNITION; CLASSIFICATION	Instead of standard support vector machines (SVMs) that classify points to one of two disjoint half-spaces by solving a quadratic program, the plane classifier GEPSVM (proximal SVM classification via generalized eigenvalues) classifies points by assigning them to the closest of two nonparallel planes which are generated by their corresponding generalized eigenvalue problems. A simple geometric interpretation of GEPSVM is that each plane is closest to the points of its own class and furthest to the points of the other class. Analysis and experiments have demonstrated its capability in both computation time and test correctness. In this paper, following the geometric intuition of GEPSVM, a new supervised learning method called proximal support vector machine using local information (LIPSVM) is proposed. With the introduction of proximity information (consideration of underlying information such as correlation or similarity between points) between the training points, LIPSVM not only keeps aforementioned characteristics of CEPSVM, but also has its additional advantages: (1) robustness to outliers; (2) each plane is generated from its corresponding standard rather than generalized eigenvalue problem to avoid matrix singularity; (3) comparable classification ability to the eigenvalue-based classifiers GEPSVM and LDA. Furthermore, the idea of LIPSVM can be easily extended to other classifiers, such as LDA. Finally, some experiments on the artificial and benchmark datasets show the effectiveness of LIPSVM. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.	[Yang, Xubing; Chen, Songcan; Chen, Bin] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China; [Yang, Xubing] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210037, Peoples R China; [Pan, Zhisong] PLA Univ Sci Technol, Inst Command Automat, Nanjing 210007, Peoples R China	Chen, SC (reprint author), Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Peoples R China.	xbyang@nuaa.edu.cn; s.chen@nuaa.edu.cn; b.chen@nuaa.edu.cn; pzsong@nuaa.edu.cn			National Natural Science Foundations of China [60773061, 60603029]; Jiangsu Science Foundation [BK2008381, BK2009393]	We thank the anonymous reviewers for their valuable comments and suggestions. This research was supported by the National Natural Science Foundations of China (60773061, 60603029), and the Jiangsu Science Foundation (BK2008381, BK2009393).	BERKES P, LECT NOTES COMPUTER, V3696, P285; Blanz V., 1996, LNCS, V112, P251; Burges C., 1998, DATA MIN KNOWL DISC, V2, P1, DOI DOI 10.1023/A:1009715923555; Centeno TP, 2006, J MACH LEARN RES, V7, P455; CHEN HT, 2005, P INT C COMP VIS PAT; Chen SC, 2004, PATTERN RECOGN, V37, P1545, DOI 10.1016/j.pateog.2003.11.008; Cifarelli C, 2007, J CLASSIF, V24, P205, DOI 10.1007/s00357-007-0012-z; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fung G., 2001, P KDD 2001 KNOWL DIS, P77, DOI DOI 10.1145/502512.502527; Guarracino M., 2006, 20 INT C ADV INF NET, V2, P588, DOI 10.1109/AINA.2006.47; Guarracino MR, 2007, OPTIM METHOD SOFTW, V22, P73, DOI 10.1080/10556780600883874; Joachims T., 1999, P 10 EUR C MACH LEAR, P137; Kuss M., 2003, 108 M PLANCK I BIOL; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223; Li H., 2004, P C ADV NEUR INF PRO, P97; Li T., 2003, P 12 INT C INF KNOWL, P317; LIN RS, 2004, 17 INT C PATT REC IC, P757; Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594; Liu J, 2008, PATTERN RECOGN, V41, P102, DOI 10.1016/j.patcog.2007.06.001; Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17; MARNO V, 1993, J ECONOMETRICS, V59, P125; MIKA S, 2002, THESIS TU BERLIN; MIKE S, 2001, ADV NEURAL INFORM PR, V13, P591; Mitchell T. M., 1997, MACHINE LEARNING; Mordohai P, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P798; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Murphy P, 1992, UCI MACHINE LEARNING; Nelkin M., 2002, ADV NEURAL INFORM PR, P585; OSUNA E, 1997, IEEE C COMP VIS PATT, P130; Ratsch G., 1999, NEURAL NETWORKS SIGN, V9, P41, DOI DOI 10.1109/NNSP.1999.788121; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SCHLKOPF B, 1998, NEURAL COMPUTATION, V10; Schmidt M., 1996, INT 96 P SYDN; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 1999, ADV KERNEL METHODS; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Scholkopf B., 2002, LEARNING KERNELS; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WANG M, IEEE T NEURAL NETWOR, V16, P557; Weinberger K., 2004, P IEEE C COMP VIS PA, V2, P988, DOI 10.1109/CVPR.2004.1315272; Wu YQ, 2002, PATTERN RECOGN, V35, P2311, DOI 10.1016/S0031-3203(01)00132-7; Yan S., P 2005 IEEE COMP SOC; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; ZHANG H, 2005, IEEE T SYSTEMS MAN B, V35	44	10	13	5	10	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0925-2312			NEUROCOMPUTING	Neurocomputing	DEC	2009	73	1-3			SI		357	365		10.1016/j.neucom.2009.08.002		9	Computer Science, Artificial Intelligence	Computer Science	530QI	WOS:000272607000042		
J	Eskofier, B; Oleson, M; DiBenedetto, C; Hornegger, J				Eskofier, B.; Oleson, M.; DiBenedetto, C.; Hornegger, J.			Embedded surface classification in digital sports	PATTERN RECOGNITION LETTERS			English	Article						Microprocessor; Embedded classification; Digital sports; adidas_1; Surface classification	TEXTURAL FEATURES; RUNNERS	In this presentation, we give a detailed analysis of the considerations needed for mapping the complete pattern classification chain to the restricted embedded system hardware environment. We describe the methodology of the design, realization and testing process that takes these hardware limitations into account. For this purpose, we consider a particular embedded application from the field of digital sports: a novel running shoe that is capable of sensing run-specific parameters and adapting the cushioning setting accordingly. Of utmost importance in this context is the classification of the current surface condition in order to enable optimal adaptation to the prevailing situation. Following our design approach, we provide a classification system with a runner-independent surface classification rate of more than 80%. This system is implemented in the current version of the aforementioned running shoe. The presented methodology is quite general as it makes no system-dependent assumptions and can thus be transferred to many other embedded classification applications. (C) 2009 Elsevier B.V. All rights reserved.	[Eskofier, B.; Hornegger, J.] Univ Erlangen Nurnberg, Dept Comp Sci, Inst Pattern Recognit, D-91058 Erlangen, Germany; [Oleson, M.; DiBenedetto, C.] Adidas AG, Adidas Innovat Team, Portland, OR 97217 USA	Eskofier, B (reprint author), Univ Erlangen Nurnberg, Dept Comp Sci, Inst Pattern Recognit, Martensstr 3, D-91058 Erlangen, Germany.	bjoern.eskofier@informatik.uni-erlangen.de; mark.oleson@adidas.com; christian.dibenedetto@adidas.com; joachim.hornegger@informatik.uni-erlangen.de					Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060; BISIANI R, 1987, ENCY ARTIFICIAL INTE, P55; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIBENEDETTO C, 2004, Patent No. 20040177531; DIBENEDETTO C, 2005, Patent No. 1582108; Duda R. O., 1973, PATTERN CLASSIFICATI; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; EIBE F, 1998, MACH LEARN, P144; Englehart K, 2003, IEEE T BIO-MED ENG, V50, P848, DOI [10.1109/TBME.2003.813539, 10.1109/TMBE.2003.813539]; Eskofier B. M., 2008, 19 INT C PATT REC 20, P1; Fisher RA, 1936, ANN EUGENIC, V7, P179; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, P 13 INT C MACH LEAR, P148; Fukunaga K., 1990, INTRO STAT PATTERN R; Furui S, 2004, ACOUSTICAL SOC AM J, V116, P2497; Hacker C, 2006, LECT NOTES ARTIF INT, V4188, P581; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223; Lee Y, 1991, NEURAL COMPUT, V3, P440, DOI 10.1162/neco.1991.3.3.440; Lun V, 2004, BRIT J SPORT MED, V38, P576, DOI 10.1136/bjsm.2003.005488; MILGROM C, 1992, CLIN ORTHOP RELAT R, P189; OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I; Olds EG, 1938, ANN MATH STAT, V9, P133, DOI 10.1214/aoms/1177732332; Schapire RE, 1998, ANN STAT, V26, P1651; SCHMIDT RO, 1986, IEEE T ANTENN PROPAG, V34, P276, DOI 10.1109/TAP.1986.1143830; Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; Vapnik V., 1998, STAT LEARNING THEORY; von Tscharner V, 2003, J ELECTROMYOGR KINES, V13, P253, DOI 10.1016/S1050-6411(02)00111-6; Wolf L, 2002, INT J COMPUT VISION, V48, P53, DOI 10.1023/A:1014855311993	30	8	8	1	4	ELSEVIER SCIENCE BV	AMSTERDAM	PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS	0167-8655			PATTERN RECOGN LETT	Pattern Recognit. Lett.	DEC 1	2009	30	16					1448	1456		10.1016/j.patrec.2009.08.004		9	Computer Science, Artificial Intelligence	Computer Science	520MR	WOS:000271849300002		
J	Samaniego, L; Schulz, K				Samaniego, Luis; Schulz, Karsten			Supervised Classification of Agricultural Land Cover Using a Modified k-NN Technique (MNN) and Landsat Remote Sensing Imagery	REMOTE SENSING			English	Article						land use classification; supervised classification; nearest neighbors; agricultural land cover; crops		Nearest neighbor techniques are commonly used in remote sensing, pattern recognition and statistics to classify objects into a predefined number of categories based on a given set of predictors. These techniques are especially useful for highly nonlinear relationship between the variables. In most studies the distance measure is adopted a priori. In contrast we propose a general procedure to find an adaptive metric that combines a local variance reducing technique and a linear embedding of the observation space into an appropriate Euclidean space. To illustrate the application of this technique, two agricultural land cover classifications using mono-temporal and multi-temporal Landsat scenes are presented. The results of the study, compared with standard approaches used in remote sensing such as maximum likelihood (ML) or k-Nearest Neighbor (k-NN) indicate substantial improvement with regard to the overall accuracy and the cardinality of the calibration data set. Also, using MNN in a soft/fuzzy classification framework demonstrated to be a very useful tool in order to derive critical areas that need some further attention and investment concerning additional calibration data.	[Schulz, Karsten] Univ Munich, Dept Geog, D-80333 Munich, Germany; [Samaniego, Luis] UFZ Helmholtz Ctr Environm Res, Dept Computat Hydrosyst, D-04318 Leipzig, Germany	Schulz, K (reprint author), Univ Munich, Dept Geog, Luisenstr 37, D-80333 Munich, Germany.	luis.samaniego@ufz.de; k.schulz@lmu.de					Aarts E, 1989, SIMULATED ANNEALING; Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700; Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292; Bardossy A, 2005, WATER RESOUR RES, V41, DOI 10.1029/2004WR003851; Bardossy A, 2002, IEEE T GEOSCI REMOTE, V40, P362, DOI 10.1109/36.992798; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deer PJ, 2003, FUZZY SET SYST, V137, P191, DOI 10.1016/S0165-0114(02)00220-8; Dennison PE, 2009, REMOTE SENS ENVIRON, V113, P1646, DOI 10.1016/j.rse.2009.03.010; Falkenauer E., 1997, GENETIC ALGORITHMS G; Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257; Foody GM, 1996, INT J REMOTE SENS, V17, P1317; Franco-Lopez H, 2001, REMOTE SENS ENVIRON, V77, P251, DOI 10.1016/S0034-4257(01)00209-7; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Fukunaga K., 1990, INTRO STAT PATTERN R; Goodin DG, 2004, IEEE T GEOSCI REMOTE, V42, P154, DOI 10.1109/TGRS.2003.815674; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Isaaks E.H., 1989, INTRO APPL GEOSTATIS; Joshi PKK, 2006, REMOTE SENS ENVIRON, V103, P190, DOI 10.1016/j.rse.2006.04.010; Liu JY, 2005, REMOTE SENS ENVIRON, V98, P442, DOI 10.1016/j.rse.2005.08.012; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Mahalanobis P, 1936, P NATL I SCI INDIA, V2, P495; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; Massa A, 2005, IEEE T GEOSCI REMOTE, V43, P2084, DOI 10.1109/TGRS.2005.853186; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Poggi G, 2005, IEEE T GEOSCI REMOTE, V43, P1901, DOI 10.1109/TGRS.2005.852163; Potapov P, 2008, REMOTE SENS ENVIRON, V112, P3708, DOI 10.1016/j.rse.2008.05.006; Powell SL, 2008, REMOTE SENS ENVIRON, V112, P1895, DOI 10.1016/j.rse.2007.09.010; Richards J. A., 2006, REMOTE SENSING DIGIT; Samaniego L, 2008, IEEE T GEOSCI REMOTE, V46, P2112, DOI 10.1109/TGRS.2008.916629; Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177; Tolson BA, 2007, WATER RESOUR RES, V43, DOI 10.1029/2005WR004723; Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874	35	6	6	4	15	MDPI AG	BASEL	POSTFACH, CH-4005 BASEL, SWITZERLAND	2072-4292			REMOTE SENS-BASEL	Remote Sens.	DEC	2009	1	4					875	895		10.3390/rs1040875		21	Remote Sensing	Remote Sensing	V24HH	WOS:000208401000013		
J	Larrua, A; Olivera, I; Caballero, Y; Filiberto, Y; Guerra, M; Bello, R; Bonilla, J				Larrua, A.; Olivera, I; Caballero, Y.; Filiberto, Y.; Guerra, M.; Bello, R.; Bonilla, J.			Application of the Artificial Intelligence to the Prediction of the Ultimate Resistant Capacity of Connections in Steel-Concrete Composite Structures	REVISTA DE LA CONSTRUCCION			Spanish	Article						Composite structures; connectors; artificial intelligence	STUD SHEAR CONNECTORS	In the work the connections in steel-concrete composite structures are treated and different variants of the 'push out" test are described when stud connectors are used in composite beams made up with steel deck oriented perpendicularly to the axis of the steel beams. A database is presented with experimental results that serve as base for the realization of the predictions using artificial intelligence. The algorithm k-NN is described and the technique of optimization Particle Swan Optimization (PSO) is introduced in the assignment of weight to the attributes. It is developed an experiment with the objective of determining the precision of the algorism k-NN, considering two variables: k (near neighbours' number) and "variants of weight", being 20 study combinations. The automated system PROCON was developed that speeded up the obtaining of results. The results reached with the variant of more effectiveness are compared with those that are obtained when evaluating the entrance data using the formulations of the current codes: AISC and Eurocode-4. Promissory results are obtained, being demonstrated that the algorism k - NN is an effective technique that favours the creation of new data for the generation of a representative group of the possible design situations, from face to the improvement of the calculation methods, in a quick and simple way, supplementing, to those ends, to classic experimentation and the numeric simulation.	[Larrua, A.; Olivera, I] Univ Camaguey, Grp Invest Estructuras, Camaguey, Cuba; [Caballero, Y.; Filiberto, Y.; Guerra, M.] Univ Camaguey, Grp Invest Inteligencia Artificial, Camaguey, Cuba; [Bello, R.] Univ Cent Martha Abreu Las Villas, Ctr Estudio Informat, Santa Clara, Cuba; [Bonilla, J.] Univ Ciego Avila, Fac Informat, Ciego De Avila, Cuba	Larrua, A (reprint author), Univ Camaguey, Grp Invest Estructuras, Camaguey, Cuba.	rafael.larrua@reduc.edu.cu	Ignacio Agramonte Loynaz, Univ. de Camaguey/G-5748-2015; UCIAL, UC/K-2416-2015; Filiberto, Yaima/J-8229-2014	Filiberto, Yaima/0000-0003-2279-2953			*AISC, 2005, 3605 ANSIAISC, P77; BONILLA J, 2008, THESIS UCLV SANTA CL; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIAZ B, 1998, BEHAV WELDED SHEAR S; European Committee for Standardization, 2004, 199411 EN EUR COMM S; FIX E, 1951, 44 USAF SCH AV MED; GARCIA JM, 2003, K NN WORKSHOP SUITE; JAYAS BS, 1998, CANADIAN J CIVIL ENG, V15, P240; Johnson RP, 1998, P I CIVIL ENG-STR B, V128, P244; KENNEDY J, 1995, P 1995 IEEE INT C NE; Lam D, 2005, J STRUCT ENG-ASCE, V131, P96, DOI 10.1016/(ASCE)0733-9445(2005)131:1(96); LYONS JC, 1994, 9407 CENPIST VIRG PO; Quinlan J., 1993, C 4 5 PROGRAMS MACHI; RAMBORODDENBERR.MD, 2002, THESIS U BLACKSBURG; Reyes-Sierra M., 2006, INT J COMPUTATIONAL, V2, P287; ROBINSON H, 1988, CAN J CIVIL ENG, V15, P553; ROSEMBLATT F, 1962, PRINCIPLES NEURODYNA; SUBLETT CN, 1992, 9203 CENPIST VIRG PO; WILSON DR, 1997, ADV INSTANCE BASED L	19	0	0	0	4	PONTIFICIA UNIV CATOLICA CHILE, ESCUELA CONSTRUCCION CIVIL	SANTIAGO	AV VICUNA MACKENNA 4860, SANTIAGO, 0000, CHILE	0718-915X			REV CONSTR	Rev. Constr.	DEC	2009	8	2					109	119				11	Construction & Building Technology; Engineering, Civil	Construction & Building Technology; Engineering	539BG	WOS:000273227800010		
S	Bounsiar, A; Madden, MG		Kleijn, B; Larsen, J		Bounsiar, Abdenour; Madden, Michael G.			SUPPORT VECTOR ONE-CLASS CLASSIFICATION FOR MULTIPLE-DISTRIBUTION DATA	18TH EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO-2010)	European Signal Processing Conference		English	Proceedings Paper	18th European Signal Processing Conference (EUSIPCO)	AUG 23-27, 2010	Aalborg, DENMARK	Aalborg Univ, European Assoc Signal, Speech, & Image Proc			MACHINES	One-class support vector algorithms such as One-Class Support Vector Machine (OCSVM) and Support Vector Data Description (SVDD) often perform poorly with multi-distributed data. Because in the one-class classification context, only the target class is well represented, the classification problem is ill-posed and the task is more a class description or a class density estimation problem. To deal with multi-distributed data, we propose in this paper the Multi-Cluster One-Class Support Vector Machine (MCOS) algorithm, which first clusters the data and then applies a one-class support vector algorithm on each cluster separately. A test sample is then classified by using the corresponding local description. K-means clustering and a dendogram based clustering methods are tested and classification results are presented for synthetic and real world data by using the MCOS. Experiments show that in many cases, MCOS outperforms the OCSVM algorithm.	[Bounsiar, Abdenour; Madden, Michael G.] Natl Univ Ireland, Coll Engn & Informat, Galway, Ireland	Bounsiar, A (reprint author), Natl Univ Ireland, Coll Engn & Informat, Galway, Ireland.	abdenour.bounsiar@nuigalway.ie; Michael.madden@nuigalway.ie					Alashwal H., 2006, INT J BIOMEDICAL SCI, V1, P120; Arthur D., 2007, P 18 ANN ACMSIAM S D, V8, P1027; Asuncion A., 2007, UCI MACHINE LEARNING; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Bradley P. S., 1998, P 15 INT C MACH LEAR, P91; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hartigan J. A., 1979, Applied Statistics, V28, DOI 10.2307/2346830; Jain A. K., 1988, ALGORITHMS CLUSTERIN; Kaufman L., 1990, FINDING GROUPS DATA; Lloyd S., 1982, IEEE T INFORMATION T, V28, P129, DOI DOI 10.1109/TIT.1982.1056489; MacQueen J., 1967, P 5 BERK S MATH STAT, P281; Moody J., 1989, NEURAL COMPUTATION, V1; Sain S. R., 1994, THESIS RICE U TEXAS; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Seo KK, 2007, EXPERT SYST APPL, V33, P491, DOI 10.1016/j.eswa.2006.05.030; Shawe- Taylor J., 2004, KERNEL METHODS PATTE; Shawe-Taylor J., 2000, SUPPORT VECTOR MACHI; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Xu H, 2008, IEEE INT C NETW SENS, P602	22	0	0	1	1	EUROPEAN ASSOC SIGNAL SPEECH & IMAGE PROCESSING-EURASIP	KESSARIANI	PO BOX 74251, KESSARIANI, 151 10, GREECE	2076-1465			EUR SIGNAL PR CONF			2010	18						1189	1193				5	Engineering, Electrical & Electronic	Engineering	BC1DO	WOS:000349999100241		
S	Verron, S; Tiplica, T; Kobi, A			IEEE	Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad			New Informative Features for Fault Diagnosis of Industrial Systems by Supervised Classification	18TH MEDITERRANEAN CONFERENCE ON CONTROL AND AUTOMATION	Mediterranean Conference on Control & Automation		English	Proceedings Paper	18th Annual International Mediterranean Conference on Control and Automation (MED)	JUN 23-25, 2010	Marrakech, MOROCCO	Mediterranean Control Assoc, IEEE Control Syst Soc, IEEE Robot & Automat Soc, IEEE, Univ Lille 1, Hautes Etudes Ingenieur, Picardie Jules Verne Univ, Cadi Ayyad Univ			DECOMPOSITION; T-2	The purpose of this article is to present a method for industrial process diagnosis. We are interested in fault diagnosis considered as a supervised classification task. The interest of the proposed method is to take into account new features (and so new informations) in the classifier. These new features are probabilities extracted from a Bayesian network comparing the faulty observations to the normal operating conditions. The performances of this method are evaluated on the data of a benchmark example: the Tennessee Eastman Process. Three kinds of fault are taken into account on this complex process. We show on this example that the addition of these new features allows to decrease the misclassification rate.	[Verron, Sylvain; Tiplica, Teodor; Kobi, Abdessamad] Univ Angers, LASQUO ISTIA, F-49000 Angers, France	Verron, S (reprint author), Univ Angers, LASQUO ISTIA, F-49000 Angers, France.	sylvain.verron@univ-angers.fr					Aizerman A., 1964, AUTOMAT REM CONTR, V25, P821; Breiman L, 1993, CLASSIFICATION REGRE; Chiang L. H., 2001, FAULT DETECTION DIAG; Chiang LH, 2004, COMPUT CHEM ENG, V28, P1389, DOI 10.1016/j.compchemeng.2003.10.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dhillon B., 2005, RELIABILITY QUALLITY; DOWNS JJ, 1993, COMPUT CHEM ENG, V17, P245, DOI 10.1016/0098-1354(93)80018-I; Duda R O, 2001, PATTERN CLASSIFICATI; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Isermann R., 2006, FAULT DIAGNOSIS SYST; Jackson E. J., 1985, COMMUNICATION STAT T, V14, p2657 ; Jensen F. V., 1996, INTRO BAYESIAN NETWO; Kano M, 2002, COMPUT CHEM ENG, V26, P161, DOI 10.1016/S0098-1354(01)00738-4; Li J, 2008, J QUAL TECHNOL, V40, P46; LYMAN PR, 1995, COMPUT CHEM ENG, V19, P321, DOI 10.1016/0098-1354(94)00057-U; MASON RL, 1995, J QUAL TECHNOL, V27, P99; Montgomery Douglas C, 1997, INTRO STAT QUALITY C; Patton R.J., 2000, ISSUES FAULT DIAGNOS; Ricker NL, 1996, J PROCESS CONTR, V6, P205; Stamatis D.H., 2003, FAILURE MODE EFFECT, V2nd; Vapnik V. N., 1995, NATURE STAT LEARNING; Venkatasubramanian V, 2003, COMPUT CHEM ENG, V27, P327, DOI 10.1016/S0098-1354(02)00162-X; Verron S., 2008, 5 C INT FRANC AUT BU; Verron S, 2008, J PROCESS CONTR, V18, P479, DOI 10.1016/j.jprocont.2007.08.003; Westerhuis JA, 2000, J CHEMOMETR, V14, P335, DOI 10.1002/1099-128X(200007/08)14:4<335::AID-CEM579>3.0.CO;2-F	25	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2325-369X		978-1-4244-8092-0	MED C CONTR AUTOMAT			2010							454	459		10.1109/MED.2010.5547710		6	Automation & Control Systems; Robotics	Automation & Control Systems; Robotics	BHB21	WOS:000324864700072		
S	Laranjeiro, N; Oliveira, R; Vieira, M			IEEE	Laranjeiro, Nuno; Oliveira, Rui; Vieira, Marco			Applying Text Classification Algorithms in Web Services Robustness Testing	2010 29TH IEEE INTERNATIONAL SYMPOSIUM ON RELIABLE DISTRIBUTED SYSTEMS SRDS 2010	Symposium on Reliable Distributed Systems Proceedings		English	Proceedings Paper	29th IEEE International Symposium on Reliable Distributed Systems	OCT 31-NOV 03, 2010	New Delhi, INDIA	IEEE Comp Soc Tech Comm, Microsoft Res, IBM, NSF		web services; robustnes testing; classification	LINEAR CLASSIFICATION; OPERATING-SYSTEMS; CATEGORIZATION	Testing web services for robustness is an effective way of disclosing software bugs. However, when executing robustness tests, a very large amount of service responses has to be manually classified to distinguish regular responses from responses that indicate robustness problems. Besides requiring a large amount of time and effort, this complex classification process can easily lead to errors resulting from the human intervention in such a laborious task. Text classification algorithms have been applied successfully in many contexts (e.g., spam identification, text categorization, etc) and are considered a powerful tool for the successful automation of several classification-based tasks. In this paper we present a study on the applicability of five widely used text classification algorithms in the context of web services robustness testing. In practice, we assess the effectiveness of Support Vector Machines, Naive Bayes, Large Linear Classification, K-nearest neighbor (Ibk), and Hyperpipes in classifying web services responses. Results indicate that these algorithms can be effectively used to automate the identification of robustness issues while reducing human intervention. However, in all mechanisms there are cases of misclassified responses, which means that there is space for improvement.	[Laranjeiro, Nuno; Oliveira, Rui; Vieira, Marco] Univ Coimbra, CISUC, Dept Informat Engn, P-3000 Coimbra, Portugal	Laranjeiro, N (reprint author), Univ Coimbra, CISUC, Dept Informat Engn, P-3000 Coimbra, Portugal.	cnl@dei.uc.pt; racoliv@student.dei.uc.pt; mvieira@dei.uc.pt	Vieira, Marco/L-4087-2014; 	Oliveira, Rui/0000-0002-2408-6457; Vieira, Marco/0000-0001-5103-8541; Laranjeiro, Nuno/0000-0003-0011-9901			Cohen W. W., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Curbera F, 2002, IEEE INTERNET COMPUT, V6, P86, DOI 10.1109/4236.991449; Eisenstein J, 2004, P 6 INT C MULT INT I, P113, DOI 10.1145/1027933.1027954; Erl T., 2005, SERVICE ORIENTED ARC; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278; Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings; KALAPANIDAS SE, 2003, 1 BALC C INF THESS, P356; Kobayashi T, 2009, LECT NOTES ARTIF INT, V5632, P137, DOI 10.1007/978-3-642-03070-3_11; Koopman P, 1997, SYM REL DIST SYST, P72; Koopman P, 1999, DIG PAP INT SYMP FAU, P30, DOI 10.1109/FTCS.1999.781031; Laranjeiro N, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING, PROCEEDINGS, VOL 2, P187, DOI 10.1109/SCC.2008.123; LIU FY, HUMAN INTERACTION MA, P13; OLIVEIRA R, DATASET CLASSIFICATI; Popa IS, 2007, COMP MED SY, P421, DOI 10.1109/CBMS.2007.108; RODRIGUEZ M, 1999, 3 EUR DEP COMP C EDD, P143; Rogati M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; SIBLINI R, 2005, 3 ACS IEEE INT C COM, P135; Vieira M, 2007, I C DEPEND SYS NETWO, P131, DOI 10.1109/DSN.2007.16; Wang BY, 2005, PDCAT 2005: SIXTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P913; Xu WZ, 2005, 16TH IEEE INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, PROCEEDINGS, P257, DOI 10.1109/ISSRE.2005.44; Yang Y., 1994, 17 ANN INT ACM SIGIR, P13; Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217	26	2	2	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1060-9857		978-0-7695-4250-8	SYM REL DIST SYST			2010							255	264		10.1109/SRDS.2010.36		10	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO39	WOS:000287486100028		
B	Lai, JC; Leung, FH; Ling, SH			IEEE	Lai, Johnny C.; Leung, Frank H.; Ling, Sai-Ho			A New Differential Evolution with Self-terminating Ability using Fuzzy Control and K-Nearest Neighbors	2010 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			OPTIMIZATION	A new Differential Evolution (DE) that incorporates fuzzy control and k-nearest neighbors algorithm to determine the terminating condition is proposed. A technique called Iteration Windows is introduced to govern the number of iteration in each searching stage. The size of the iteration windows is controlled by a fuzzy controller, which uses the information provided by the k-nearest neighbors system to analyze the population during the searching process. The controller keeps controlling the iteration windows until the end of the searching process. The wavelet based mutation process is embedded in the DE searching process to enhance the searching performance of DE. The F weight of DE is also controlled by the fuzzy controller to further speed up the searching process. A suite of benchmark test functions is employed to evaluate the performance of the proposed method. It is shown empirically that the proposed method can terminate the searching process with a reasonable number of iteration.	[Lai, Johnny C.; Leung, Frank H.] Hong Kong Polytech Univ, Dept Elect & Informat Engg, Ctr Signal Proc, Hung Ham, Hong Kong, Peoples R China	Lai, JC (reprint author), Hong Kong Polytech Univ, Dept Elect & Informat Engg, Ctr Signal Proc, Hung Ham, Hong Kong, Peoples R China.	08900438r@polyu.edu.hk; enfrank@inet.polyu.edu.hk; steve.ling@uts.edu.au					Babu B., 2001, P 12 ISME INT C MECH, P153; BOSC P, 1997, FUZZY INFORM ENG GUI, P233; Bremner D, 2005, DISCRETE COMPUT GEOM, V33, P593, DOI 10.1007/s00454-004-1152-0; Chakraborty U. K., 2008, ADV DIFFERENTIAL EVO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EFTEKHARI MM, 2003, ENERGY BUILDINGS, V35; Fogel L. J., 1994, COMPUTATIONAL INTELL; Goldberg D. E., 1989, GENETIC ALGORITHMS S; GRABOT B, 1997, FUZZY INFORM ENG GUI, P695; Klir G. J., 1988, FUZZY SETS UNCERTAIN; Ling SH, 2008, IEEE T SYST MAN CY B, V38, P743, DOI 10.1109/TSMCB.2008.921005; MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2; Paterlini S., 2004, P IEEE C EV COMP, V2, P2004; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Toussaint G, 2005, INT J COMPUT GEOM AP, V15, P101, DOI 10.1142/S0218195905001622; Van Sickel J. H., 2007, P INT SYST APPL POW, P1; Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82; Zahan S., 1999, FUZZY NEURO FUZZY SY	18	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-8126-2	IEEE C EVOL COMPUTAT			2010												8	Engineering, Electrical & Electronic; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BTM91	WOS:000287375801030		
J	Triguero, I; Garcia, S; Herrera, F			IEEE	Triguero, Isaac; Garcia, Salvador; Herrera, Francisco			A preliminary study on the use of differential evolution for adjusting the position of examples in nearest neighbor classification	2010 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)	IEEE Congress on Evolutionary Computation		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			MULTIPLE DATA SETS; STATISTICAL COMPARISONS; GLOBAL OPTIMIZATION; LEARNING ALGORITHMS; CLASSIFIERS; REDUCTION; SELECTION; SPACES	Nearest neighbor is one of the most successfully used techniques for performing classification and pattern recognition tasks. Its simplicity and effectiveness justify the use of this technique in certain domains but it however presents several drawbacks referring to time response, noise sensitivity and storage requirements. Several solutions have been proposed in order to alleviate these problems, such as improving the technique for speeding up or carrying out a data reduction process. Prototype generation is a suitable process for data reduction that allows to fit a data set for nearest neighbor classification. Position adjustment of prototypes is a successful technique within the prototype generation methodology. Evolutionary algorithms are adaptive methods based on natural evolution that may be used for search and optimization. Position adjustment of prototypes can be viewed as a search problem, thus it could be solved using evolutionary algorithms. In this paper, we perform a preliminary study on the use of differential evolution algorithms to the prototype generation problem. Differential evolution models are compared with other algorithms for adjusting the position of prototypes and the results are contrasted through non-parametrical statistical tests. The results show that some differential evolution models consistently outperform previously proposed methods.	[Triguero, Isaac; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR Res Ctr Informat & Commun Technol, E-18071 Granada, Spain	Triguero, I (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR Res Ctr Informat & Commun Technol, E-18071 Granada, Spain.	triguero@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Garcia, Salvador/N-3624-2013	Herrera, Francisco/0000-0002-7283-312X; Garcia, Salvador/0000-0003-4494-7565			AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Alpaydin Ethem, 2010, INTRO MACHINE LEARNI, V2nd; Asuncion A., 2007, UCI MACHINE LEARNING; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Cervantes A, 2009, IEEE T SYST MAN CY B, V39, P1082, DOI 10.1109/TSMCB.2008.2011816; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179; Chen CH, 1996, PATTERN RECOGN LETT, V17, P819, DOI 10.1016/0167-8655(96)00041-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Das S, 2009, IEEE T EVOLUT COMPUT, V13, P526, DOI 10.1109/TEVC.2008.2009457; Demsar J, 2006, J MACH LEARN RES, V7, P1; Fernandez A, 2010, IEEE T EVOLUT COMPUT, V14, P913, DOI 10.1109/TEVC.2009.2039140; Fernandez F, 2004, J HEURISTICS, V10, P431, DOI 10.1023/B:HEUR.0000034715.70386.5b; Garain U, 2008, PATTERN ANAL APPL, V11, P353, DOI 10.1007/s10044-008-0106-1; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; Garcia S, 2008, J MACH LEARN RES, V9, P2677; Kennedy J., 1995, IEEE INT C NEUR NETW, P1942, DOI DOI 10.1109/ICNN.1995.488968; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Llora X, 2001, P 18 INT C MACH LEAR, P337; Lozano M, 2006, PATTERN RECOGN, V39, P1827, DOI 10.1016/j.patcog.2006.04.005; Nanni L., 2008, NEUROCOMPUTING, V72, P1092; NERI F, 2001, MEMETIC COMPUTING, V2, P153; Neri F, 2010, ARTIF INTELL REV, V33, P61, DOI 10.1007/s10462-009-9137-2; PRICE KV, 2005, NAT COMP SER, pR7; Qin AK, 2009, IEEE T EVOLUT COMPUT, V13, P398, DOI 10.1109/TEVC.2008.927706; Rahnamayan S, 2008, IEEE T EVOLUT COMPUT, V12, P64, DOI 10.1109/TEVC.2007.894200; Sheskin D.J., 2006, HDB PARAMETRIC NONPA; Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Zhang JQ, 2009, IEEE T EVOLUT COMPUT, V13, P945, DOI 10.1109/TEVC.2009.2014613	29	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-8126-2	IEEE C EVOL COMPUTAT			2010												8	Engineering, Electrical & Electronic; Mathematical & Computational Biology	Engineering; Mathematical & Computational Biology	BTM91	WOS:000287375804024		
S	Ashkezari, S; Akbarzadeh, MR			IEEE	Ashkezari-T, Soheila; Akbarzadeh-T, Mohammad-R			Fuzzy-Bayesian Network Approach to Genre-based Recommender Systems	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET				The World Wide Web has created a new media for mass marketing that can also be highly customized to online customers' needs and expectations. Recommender Systems (RS) play an important role in this area. Here, we aim to establish a genre-based collaborative RS to automatically suggest and rank a list of appropriate items (movies) to a user based on the user profile and the past voting patterns of other users with similar tastes. The contribution of this paper is using genre based information in a hybrid fuzzy-Bayesian network collaborative RS. The interest to the different genres is computed based on a hybrid user model. The similarity of like-minded users according to the fuzzy distance and also Pearson correlation coefficient is involved in a Bayesian network.	[Ashkezari-T, Soheila; Akbarzadeh-T, Mohammad-R] Ferdowsi Univ Mashhad, Ctr Appl Res Soft Comp & Intelligent Syst, Dept Comp Engn, Cognit Comp Lab, Mashhad 917751111, Iran	Ashkezari, S (reprint author), Ferdowsi Univ Mashhad, Ctr Appl Res Soft Comp & Intelligent Syst, Dept Comp Engn, Cognit Comp Lab, Mashhad 917751111, Iran.	Soheila.Ashkezari@stu-mil.um.ac.ir					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; de Campos LM, 2008, FUZZY SET SYST, V159, P1554, DOI 10.1016/j.fss.2008.01.016; HERLOCKER JL, 2003, EVALUATING COLLABORA; Krulwich B, 1997, AI MAG, V18, P37; Kyoung-jae Kim, 2008, Expert Systems with Applications, V34, DOI 10.1016/j.eswa.2006.12.025; LANG K, P 1995 12 INT C MACH; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; Martinez A. B. B., 2009, IEEE T CONSUMER ELEC, V55; MILLER B, 2002 P INT C INT US, P263; MOONEY RJ, DL 00, P195; O'Sullivan D, 2004, USER MODEL USER-ADAP, V14, P5, DOI 10.1023/B:USER.0000010131.72217.12; Pazzani M., 1999, ARTIF INTELL, p393~408; Resnick P., P 1994 ACM C COMP SU, P175; SHARDANAND U, P 1995 C HUM FACT CO, P210; Symeonidis P., 2008, IEEE T SYSTEMS MAN C, V38; SYMEONIDIS P, 2008, EXPERT SYSTEMS APPL, V34; YAHYA M, 2008, EXPERT SYSTEMS APPL, V35, P1386; YOSHII K, 2008, IEEE T AUDIO SPEECH, V16	18	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584		978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453601108		
S	Hartert, L; Mouchaweh, MS; Billaudel, P			IEEE	Hartert, L.; Mouchaweh, M. Sayed; Billaudel, P.			Dynamic K-Nearest Neighbors For The Monitoring Of Evolving Systems	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			CLASSIFICATION	In this article, a new Pattern Recognition (PR) approach is proposed to monitor the functioning modes evolutions in dynamic systems. When a functioning mode evolves, the system characteristics change and the observations, i.e. the patterns, obtained on the system change too. In this case, classes representing the system functioning modes have to be updated by keeping representative patterns only. The developed PR approach is based on the K-Nearest Neighbors (KNN) method. It is named Dynamic KNN (DKNN) and comprises two phases: a detection phase to detect and confirm classes evolutions and an adaptation phase realized incrementally to update the evolved classes parameters and reduce the dataset. To illustrate this approach, the monitoring of weldings quality (good or bad) is realized on an industrial system, based on acoustic noises issued of weldings operations.	[Hartert, L.; Mouchaweh, M. Sayed; Billaudel, P.] Univ Reims, Ctr Rech STIC URCA CReSTIC, F-51687 Reims, France	Hartert, L (reprint author), Univ Reims, Ctr Rech STIC URCA CReSTIC, Moulin Housse,BP 1039, F-51687 Reims, France.	laurent.hartert@univ-reims.fr; moamar.sayed-mouchaweh@univ-reims.fr; patrice.billaudel@univ-reims.fr					AMADOUBOUBACAR H, 2005, IEEE IJCNN05 P MONTR; Angelov P, 2004, INFORM SCIENCES, V161, P21, DOI 10.1016/j.ins.2003.03.006; Angstenberger L., 2000, THESIS RHEINISCH WES; Chiementin X, 2008, J VIB CONTROL, V14, P1675, DOI 10.1177/1077546307082985; Cohen L., 2004, TDM WORKSH BRIGHT UK; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUBUISSON B, 1990, TRAITE NOUVELLES DM; Duda R O, 2001, PATTERN CLASSIFICATI; Fix E., 1951, DISCRIMINATORY ANAL, P261; GIBB WJ, 1994, IEEE T BIO-MED ENG, V41, P804, DOI 10.1109/10.310096; Guedalia ID, 1999, NEURAL COMPUT, V11, P521, DOI 10.1162/089976699300016755; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; LAW YN, 2005, 9 EUR C PRINC PRACT; Manders EJ, 2000, IEEE T INSTRUM MEAS, V49, P503, DOI 10.1109/19.850384; MIN R, 2005, THESIS U TORONTO; Nakhaeizadeh G., 1997, CLASSIFICATION KNOWL, P123; RONCAGLIA A, 2004, IEEE SENSOR J, V4; VACHKOV G, 2009, IFSA EUSFLAT 09 LISB	18	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584		978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453602047		
S	Heo, G; Klette, R; Woo, YW; Kim, KB; Kim, NH			IEEE	Heo, Gyeongyong; Klette, Reinhard; Woo, Young Woon; Kim, Kwang-Baek; Kim, Nam Ho			Fuzzy Support Vector Machine with a Fuzzy Nearest Neighbor Classifier for Insect Footprint Classification	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			SVM	The support vector machine (SVM) of statistical learning theory was successfully applied in various fields, but still suffers from noise sensitivity originating from the fact that all the data points are treated equally. To relax this problem, the SVM was extended into a fuzzy SVM (FSVM) by the introduction of fuzzy memberships. The FSVM also has been further extended in two ways, by adopting a different objective function with the help of domain-specific knowledge, or by employing a different membership calculation method. In this paper we follow the second approach by proposing a new membership calculation method using a fuzzy k nearest neighbor classifier (F-KNN). Although there are already several membership calculation methods to enhance the performance of the FSVM, one problem in those methods is that they assume a specific data distribution. The F-KNN does not assume any data distribution, which helps the proposed method to accommodate various data distributions in real world problems. The proposed algorithm was applied to an insect footprint classification problem, and results verify the effectiveness of the method.	[Heo, Gyeongyong; Woo, Young Woon] Dong Eui Univ, Dept Multimedia Engn, Pusan, South Korea	Heo, G (reprint author), Dong Eui Univ, Dept Multimedia Engn, Pusan, South Korea.	gyeongy-ong.heo@gmail.com; r.klette@auckland.ac.nz; ywwoo@deu.ac.kr; gbkim@silla.ac.kr; nhk@pknu.ac.kr					ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTIANINI N, 2004, J MACHINE LEARNING R, V5, P27; FULIN C, 2004, PATTERN RECOGN, V25, P1647; HEO G, 2009, P 2009 INT C FUZZ SY; Hsu C., 2003, PRACTICAL GUIDE SUPP; Jiang XF, 2006, NEURAL COMPUT APPL, V15, P268, DOI 10.1007/s00521-006-0028-z; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432; Liu Y, 2007, IEEE T SIGNAL PROCES, V55, P3272, DOI 10.1109/TSP.2007.894403; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shilton A., 2007, P IEEE INT C FUZZ SY, P1; Shin BS, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P97, DOI 10.1109/BICTA.2008.4656710; SHIN BS, 2007, P 2 PAC RIM S SANT C, P311; Tao Q, 2005, IEEE T NEURAL NETWOR, V16, P1561, DOI 10.1109/tnn.2005.857955; Vapnik V., 1998, STAT LEARNING THEORY; Wang L, 2004, INT C PATT RECOG, P981; Wang YQ, 2005, IEEE T FUZZY SYST, V13, P820, DOI 10.1109/TFUZZ.2005.859320	18	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584		978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453600058		
S	Iglesias, JA; Angelov, P; Ledezma, A; Sanchis, A			IEEE	Iglesias, Jose A.; Angelov, Plamen; Ledezma, Agapito; Sanchis, Araceli			User Modeling: Through Statistical Analysis and an Evolving Classifier	2010 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2010)	IEEE International Conference on Fuzzy Systems		English	Proceedings Paper	2010 IEEE World Congress on Computational Intelligence	JUL 18-23, 2010	Barcelona, SPAIN	IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc, Evolut Program Soc, IET			SEQUENCE CLASSIFICATION; FUZZY MODELS	Knowledge about computer users is very beneficial for assisting them, predicting their future actions or detecting masqueraders. In this paper, an approach for creating and recognizing automatically the behavior profile of a computer user is combined with an evolving method to keep up to date the created profiles. The behavior of a computer is represented in this research as the sequence of commands s/he types during a period of time. This sequence is treated using statistical methods in order to create the corresponding user profile. However, as a user profile is usually not fixed but rather it changes and evolves, we propose a user profile classifier based on Evolving Systems. This paper describes briefly the model creation method and the evolving classifier, which are compared with well established off-line and on-line classifiers.	[Iglesias, Jose A.; Ledezma, Agapito; Sanchis, Araceli] Univ Carlos III Madrid, CAOS Grp, E-28903 Getafe, Spain	Iglesias, JA (reprint author), Univ Carlos III Madrid, CAOS Grp, E-28903 Getafe, Spain.	jiglesia@inf.uc3m.es; p.angelov@lancaster.ac.uk; ledezma@inf.uc3m.es; masm@inf.uc3m.es					Agrawal R, 1995, INT C DAT ENG, P3; Anderson J. R., 1995, LEARNING MEMORY INTE; Angelov P., 2007, COMP INT IM SIGN PRO, P220; ANGELOV P, 2002, RULE BASED MODELS TO; Angelov P, 2005, IEEE INT CONF FUZZY, P1068; Angelov PP, 2008, IEEE T FUZZY SYST, V16, P1462, DOI 10.1109/TFUZZ.2008.925904; Angelov PP, 2004, IEEE T SYST MAN CY B, V34, P484, DOI 10.1109/TSMCB.2003.817053; Barrow L., 2008, 14240 NAT BUR EC RES; COULL S, 2003, ACSAC 03 P 19 ANN CO, P24; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FREDKIN E, 1960, COMMUN ACM, V3, P490, DOI 10.1145/367390.367400; Greenberg S., 1988, THESIS U CALGARY ALB; Hackos J. T., 1998, USER TASK ANAL INTER; Iglesias JA, 2009, LECT NOTES COMPUT SC, V5535, P90, DOI 10.1007/978-3-642-02247-0_11; Iglesias JA, 2006, LECT NOTES ARTIF INT, V3885, P117; Iglesias JA, 2009, 2009 IEEE WORKSHOP ON EVOLVING AND SELF-DEVELOPING INTELLIGENT SYSTEMS, P16, DOI 10.1109/ESDIS.2009.4938994; Iglesias JA, 2007, LECT NOTES COMPUT SC, V4723, P207; Kaminka GA, 2003, LECT NOTES ARTIF INT, V2752, P111; Ma QC, 2001, IEEE T SYST MAN CY C, V31, P468; MACEDO AA, 2003, HYPERTEXT 2003, P48; Nasoz F, 2007, LECT NOTES COMPUT SC, V4552, P421; Pepyne DL, 2004, P AMER CONTR CONF, P982; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 2003, DATA MINING TOOLS SE; Rish I., 2001, P IJCAI 01 WORKSH EM; Schonlau M., 2001, STAT SCI; Spiliopoulou M., 1998, P EDBT WORKSH WEBDB9, P109; Webb G. I, 1993, P AI ED93 WORLD C AR, P497; Webb GI, 2001, USER MODEL USER-ADAP, V11, P19, DOI 10.1023/A:1011117102175; ZHOU X, 2007, COMP INT SEC DEF APP, P131	30	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7584		978-1-4244-6920-8	IEEE INT CONF FUZZY			2010												8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	BTO07	WOS:000287453602125		
S	Jia, S; Qian, YT; Li, JM; Liu, WX; Ji, Z			IEEE	Jia, Sen; Qian, Yuntao; Li, Jiming; Liu, Weixiang; Ji, Zhen			FEATURE EXTRACTION AND SELECTION HYBRID ALGORITHM FOR HYPERSPECTRAL IMAGERY CLASSIFICATION	2010 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	30th IEEE International Geoscience and Remote Sensing Symposium (IGARSS) on Remote Sensing - Global Vision for Local Action	JUN 25-30, 2010	Honolulu, HI	IEEE		Hyperspectral imagery classification; dimensionality reduction; discrete wavelet transform; affinity propagation		Due to the enormous amounts of data contained in hyper-spectral imagery, the main challenge for hyperspectral image classification is to improve the accuracy with less computation complexity. Hence, dimensionality reduction (DR) is often adopted, which includes two different kinds of methods, feature extraction and feature selection. In this paper, discrete wavelet transform (DWT) and affinity propagation (AP), which belong to feature extraction and feature selection respectively, are combined together to accomplish the DR task. Firstly, DWT-based features are extracted from the original hyperspectral data; secondly, AP is applied to select representative features from the obtained ones. Experimental results demonstrate that, compared with some other DR methods which only make use of feature extraction or feature selection, the features acquired by the hybrid technique make the classification results more accurate.	[Jia, Sen; Liu, Weixiang; Ji, Zhen] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen City Key Lab Embedded Syst Design, Shenzhen, Peoples R China	Jia, S (reprint author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen City Key Lab Embedded Syst Design, Shenzhen, Peoples R China.						[Anonymous], AVIRIS NW INDIANAS I; Berkhin P., 2002, SURVEY CLUSTERING DA; Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Frey J. F., 2007, SCIENCE, V315, P972; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Jia S., 2008, P DICTA 08 DIG IM CO, P137, DOI DOI 10.1109/DICTA.2008.42; Lillesand TM, 2004, REMOTE SENSING IMAGE; Mallat S. G., 1999, WAVELET TOUR SIGNAL; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Neher R, 2005, IEEE T GEOSCI REMOTE, V43, P1363, DOI 10.1109/TGRS.2005.846865	11	7	7	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-6996		978-1-4244-9566-5	INT GEOSCI REMOTE SE			2010							72	75		10.1109/IGARSS.2010.5652463		4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BTS07	WOS:000287933800019		
J	Kaya, GT; Ersoy, OK; Kamasak, ME			IEEE	Kaya, G. Taskin; Ersoy, O. K.; Kamasak, M. E.			HYBRID SVM AND SVSA METHOD FOR CLASSIFICATION OF REMOTE SENSING IMAGES	2010 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM	IEEE International Symposium on Geoscience and Remote Sensing IGARSS		English	Proceedings Paper	30th IEEE International Geoscience and Remote Sensing Symposium (IGARSS) on Remote Sensing - Global Vision for Local Action	JUN 25-30, 2010	Honolulu, HI	IEEE		Support Vector Machines; Support Vector Selection and Adaptation; Hybrid SVM and SVSA		A linear support vector machine (LSVM) is based on determining an optimum hyperplane that separates the data into two classes with the maximum margin. The LSVM typically has high classification accuracy for linearly separable data. However, for nonlinearly separable data, it usually has poor performance. For this type of data, the Support Vector Selection and Adaptation (SVSA) method was developed, but its classification accuracy is not very high for linearly separable data in comparison to LSVM. In this paper, we present a new classifier that combines the LSVM with the SVSA, to be called the Hybrid SVM and SVSA method (HSVSA), for classification of both linearly and nonlinearly separable data and remote sensing images as well. The experimental results show that the HSVSA has higher classification accuracy than the traditional LSVM, the nonlinear SVM (NSVM) with the radial basis kernel, and the previous SVSA.	[Kaya, G. Taskin] Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey	Kaya, GT (reprint author), Istanbul Tech Univ, Inst Informat, TR-80626 Istanbul, Turkey.	gulsen@be.itu.edu.tr; ersoy@purdue.edu; kamasak@itu.edu.tr					Cherkassky V., 1998, LEARNING DATA CONCEP; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kasapoglu NG, 2007, IEEE T GEOSCI REMOTE, V45, P3880, DOI 10.1109/TGRS.2007.900699; KAYA G, 2009, 4 INT REC ADV SPAC T, P408; KAYA GT, 2009, INT S INN INT SYST A; KAYA GT, 2009, IEEE INT GEOSC REM S; Kohonen T., 1986, TKKFA601 HELS U TECH; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B, A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5	9	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-9566-5	INT GEOSCI REMOTE SE			2010							2828	2831				4	Geosciences, Multidisciplinary; Remote Sensing	Geology; Remote Sensing	BTS07	WOS:000287933802250		
S	van Dam, HT; Seifert, S; Vinke, R; Dendooven, P; Lohner, H; Beekman, FJ; Schaart, DR			IEEE	van Dam, Herman T.; Seifert, Stefan; Vinke, Ruud; Dendooven, Peter; Lohner, Herbert; Beekman, Freek J.; Schaart, Dennis R.			An Improved Nearest Neighbor Method for the Estimation of the Gamma Photon Entry Point in Monolithic Scintillator Detectors for PET	2010 IEEE NUCLEAR SCIENCE SYMPOSIUM CONFERENCE RECORD (NSS/MIC)	IEEE Nuclear Science Symposium Conference Record		English	Proceedings Paper	IEEE Nuclear Science Symposium (NSS)/Medical Imaging Conference (MIC)/17th International Workshop on Room-Temperature Semiconductor X-ray and Gamma-ray Detectors	OCT 30-NOV 06, 2010	Knoxville, TN	Inst Elect & Elect Engineers, Nucl & Plasma Sci Soc, IEEE			CLASSIFICATION; DEPTH	Several improvements of the k-nearest neighbor (k-NN) method for the determination of the entry point (x,y) of a gamma photon in a monolithic scintillator PET detector have been investigated with the aim to obtain better spatial resolution and/or to enable faster detector calibration by reducing the amount of required reference data and by allowing for calibrating with a line source. These methods were tested on a dataset measured with a SiPM-array-based monolithic LYSO detector. It appears that similar to 10% to similar to 25% better spatial resolution can be obtained compared to the standard approach. Moreover, some of the improved methods using two orders of magnitude less reference data, yield essentially the same spatial resolution as the standard method, which reduces the time needed for calibration as well as entry point computation. Finally, line source calibration is shown to be possible with some of the methods, yielding better results than the standard method and allowing much faster and easier collection of the reference data.	[van Dam, Herman T.; Seifert, Stefan; Beekman, Freek J.; Schaart, Dennis R.] Delft Univ Technol, NL-2629 JB Delft, Netherlands	Schaart, DR (reprint author), Delft Univ Technol, NL-2629 JB Delft, Netherlands.	d.r.schaart@tudelft.nl	Schaart, Dennis/C-7136-2014	Schaart, Dennis/0000-0002-3199-5608			BAILEY T, 1978, IEEE T SYST MAN CYB, V8, P311; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493; Fix E., 1951, 4 USAF SCH AV MED; Hotta S, 2004, INT C PATT RECOG, P412, DOI 10.1109/ICPR.2004.1333790; Ling T, 2007, PHYS MED BIOL, V52, P2213, DOI 10.1088/0031-9155/52/8/012; Maas MC, 2010, MED PHYS, V37, P1904, DOI 10.1118/1.3355889; Maas MC, 2006, IEEE T NUCL SCI, V53, P1071, DOI 10.1109/TNS.2006.873711; Maas MC, 2009, PHYS MED BIOL, V54, P1893, DOI 10.1088/0031-9155/54/7/003; Schaart DR, 2009, PHYS MED BIOL, V54, P3501, DOI 10.1088/0031-9155/54/11/015	10	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1082-3654		978-1-4244-9106-3	IEEE NUCL SCI CONF R			2010							3088	3092				5	Engineering, Electrical & Electronic; Nuclear Science & Technology; Physics, Applied	Engineering; Nuclear Science & Technology; Physics	BBB94	WOS:000306402903056		
S	Liyanage, SR; Xu, JX; Guan, CT; Ang, KK; Lee, TH			IEEE	Liyanage, S. R.; Xu, J. -X.; Guan, C. T.; Ang, K. K.; Lee, T. H.			EEG Signal Separation for Multi-Class Motor Imagery using Common Spatial Patterns Based on Joint Approximate Diagonalization	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE			EXTRACTION	The design of multiclass BCI is a very challenging task because of the need to extract complex spatial and temporal patterns from noisy multidimensional time series generated from EEG measurements. This paper proposes a Multiclass Common Spatial Pattern (MCSP) based on Joint Approximate Diagonalization (JAD) for multiclass BCIs. The proposed method based on fast Frobenius diagonalization (FFDIAG) is compared with another method based on Jacobi angles on the BCI competition IV dataset 2a. The classification accuracies obtained from 10x10-fold cross-validations on the training dataset are compared using K-Nearest Neighbor, Classification Trees and Support Vector Machine classifiers. The proposed MCSP based on FFDIAG yields an averaged accuracy of 53.6% compared to 32.8% given by the method based on Jacobi angles and 27.8% of the one versus rest CSP methods.	[Liyanage, S. R.; Lee, T. H.] Natl Univ Singapore, Grad Sch Integrat Sci & Engn, Singapore, Singapore	Liyanage, SR (reprint author), Natl Univ Singapore, Grad Sch Integrat Sci & Engn, Singapore, Singapore.	sidath@nus.edu.sg; elexujx@nus.edu.sg; ctguan@i2r.a-star.edu.sg; kkang@i2r.a-star.edu.sg; eleleeth@nus.edu.sg					Ang K. K., 2008, P IJCNN 08, P2391; Blankertz B., BCI COMPETITION 4; Breiman L., 1984, CLASSIFICATION REGRE; BUNSEGERSTNER A, 1993, SIAM J MATRIX ANAL A, V14, P927, DOI 10.1137/0614062; CARDOSO JF, 1993, IEE PROC-F, V140, P362; Cardoso JF, 1996, SIAM J MATRIX ANAL A, V17, P161, DOI 10.1137/S0895479893259546; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Duda R O, 2001, PATTERN CLASSIFICATI; Fukunaga K., 1990, INTRO STAT PATTERN R; Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154; Hori G., 1999, P NOLTA 99, P675; Joho M., 2002, P IEEE SENS ARR MULT, P403; KOLES ZJ, 1991, ELECTROEN CLIN NEURO, V79, P440, DOI 10.1016/0013-4694(91)90163-X; Mueller-Gerking Johannes, 1999, Clinical Neurophysiology, V110, P787; Press W.H., 1992, NUMERICAL RECIPES C; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Vapnik V., 1998, STAT LEARNING THEORY; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3; Ziehe A, 2004, J MACH LEARN RES, V5, P777	20	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												6	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421402034		
S	Monteith, K; Martinez, T			IEEE	Monteith, Kristine; Martinez, Tony			Using Multiple Measures to Predict Confidence in Instance Classification	2010 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS IJCNN 2010	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	World Congress on Computational Intelligence (WCCI 2010)	2010	Barcelona, SPAIN	IEEE				Selecting an effective method for combining the votes of classifiers in an ensemble can have a significant impact on the ensemble's overall classification accuracy. Some methods cannot even achieve as high a classification accuracy as the most accurate individual classifying component. To address this issue, we present the strategy of Aggregate Confidence Ensembles, which uses multiple measures to estimate a classifier's confidence in its predictions on an instance-by-instance basis. Using these confidence estimators to weight the votes in an ensemble results in an overall average increase in classification accuracy compared to the most accurate classifier in the ensemble. These aggregate measures result in higher classification accuracy than using a collection of single confidence estimates. Aggregate Confidence Ensembles outperform three baseline ensemble creation strategies, as well as the methods of Modified Stacking and Arbitration, both in terms of average classification accuracy and algorithm-by-algorithm comparisons in accuracy over 36 data sets.	[Monteith, Kristine; Martinez, Tony] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Monteith, K (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.	kristinemonteith@gmail.com; martinez@cs.byu.edu					Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Caruana R., 2006, P 23 INT C MACH LEAR, P161, DOI DOI 10.1145/1143844.1143865; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domingos P., 2000, P 17 INT C MACH LEAR, P223; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Ferri C., 2004, P 21 INT C MACH LEAR, P289; Frank E., 2005, DATA MINING PRACTICA; Freund Y., 1996, P 13 INT C MACH LEAR; Giacinto G., 2000, P 15 INT C PATT REC; Hettich S., 1998, UCI REPOSITORY MACHI; Hoeting JA, 1999, STAT SCI, V14, P382; Jacobs R. A., 1991, Neural Computation, V3, DOI 10.1162/neco.1991.3.1.79; KOHAVI R, 1995, P 8 EUR C MACH LEARN; Kohavi R., 1996, P 13 INT C MACH LEAR, P275; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Lang K., 1995, P 12 INT C MACH LEAR, P331; MERZ CJ, 1995, P 5 INT WORKSH ART I, P386; Mitchell T. M., 1997, MACHINE LEARNING; Ortega J., 2001, Knowledge and Information Systems, V3, DOI 10.1007/PL00011679; Peterson A. H., 2005, P ICML WORKSH MET, P68; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318; Ruta D., 2005, Information Fusion, V6, DOI 10.1016/j.inffus.2004.04.008; Ruta D., 2001, P 4 INT S SOFT COMP; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1	26	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1098-7576		978-1-4244-6917-8	IEEE IJCNN			2010												8	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BTN74	WOS:000287421400121		
J	Xiao, YL		Xu, H		Xiao, Yongliang			An Effective Video Shot Boundary Detection Method Based on Supervised Learning	2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4			English	Proceedings Paper	2nd IEEE International Conference on Advanced Computer Control	MAR 27-29, 2010	Shenyang, PEOPLES R CHINA	IEEE		shot boundary detection; supervised learning; Non-locality preserving projections; SVM	RECOGNITION	Video shot boundary detection plays an every important role in video processing. It is the first step toward video content analysis and content-based video retrieval. We develop a novel approach for video shot boundary detection based on supervised learning. Our method consists in first extracting video frame feature using a supervised kernel non-locality preserving projections, then video frames are split into abrupt transitions, gradual transitions or normal frames using two cascaded Localized-SVM classifiers. Experimental results show the effectiveness of our method.	Hunan Coll Finance & Econ, Dept Informat Management, Changsha, Hunan, Peoples R China	Xiao, YL (reprint author), Hunan Coll Finance & Econ, Dept Informat Management, Changsha, Hunan, Peoples R China.	xylroc@gmail.com					Albanese M, 2004, MULTIMED TOOLS APPL, V24, P253, DOI 10.1023/B:MTAP.0000039421.91449.10; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794; CHAVEZ GC, 2007, P 14 INT C SYST SIGN, P209; CHENG HB, SDM 2007; COOPER M, 2007, IEEE T MULTIMEDIA, P610; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656; He X. F., 2003, P ADV NEUR INF PROC, P153; HECHENBICHLER K, 2006, 399 SFB, P386; Jiang Youlu, 2006, P CONTR AUT ROB VIS, P1; JINHUI Y, 2007, IEEE T CIRCUITS SYST, P168; SCHOLKOPF B, 2002, LEARNING KERNELS SUP, P34; Vasconcelos N, 2003, PROC CVPR IEEE, P762; Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595; Zhang H., 2006, P IEEE C COMP VIS PA, P2126, DOI DOI 10.1109/CVPR.2006.301; Zhang H. J., 1993, MULTIMEDIA SYSTEMS, V1, P10, DOI 10.1007/BF01210504	17	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-4244-5847-9				2010							371	374				4	Automation & Control Systems; Engineering, Electrical & Electronic	Automation & Control Systems; Engineering	BUG30	WOS:000289202000085		
S	Shaneck, M; Kim, Y			IEEE	Shaneck, Mark; Kim, Yongdae			Efficient Cryptographic Primitives for Private Data Mining	43RD HAWAII INTERNATIONAL CONFERENCE ON SYSTEMS SCIENCES VOLS 1-5 (HICSS 2010)	Proceedings of the Annual Hawaii International Conference on System Sciences		English	Proceedings Paper	43rd Hawaii International Conference on Systems Sciences (HICSS 2010)	JAN 05-08, 2010	Honolulu, HI	Univ Hawaii, Shidler Coll Business			PROTOCOL	Data mining is frequently obstructed by privacy concerns In many cases data is distributed, and bringing the data together in one place for analysis is not possible due to privacy laws (e g HIPAA) or policies Privacy preserving data mining techniques have been developed to address this issue by providing mechanisms to mine the data while giving certain privacy guarantees However when these techniques are built on cryptographic primitives, while providing strong privacy they are often too inefficient to be used in practical settings To this end, we address the problem of efficiency by investigating trade-offs that can be made in the trust model By making reasonable concessions in the trust model, that is, by adding a non-collaborative third party, we can achieve great gains in efficiency We show this by creating a novel protocol for privately computing dot product, a foundational primitive for many private data mining activities We also investigate how to extend our protocol in the case when a third party cannot be completely trusted by both participating parties, thus reducing the amount of trust needed in the third party We then show experimentally the gains in efficiency that can be realized in the computation of the private dot product using this model	[Shaneck, Mark] Liberty Univ, Dept Comp Sci, Lynchburg, VA USA	Shaneck, M (reprint author), Liberty Univ, Dept Comp Sci, Lynchburg, VA USA.	mshaneck@liberty.edu; kyd@cs.umn.edu					AIELLO B, 2001, P ADV CRYPT EUR; ALGESHEIMER J, 2002, P 22 ANN INT CRYPT C; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; ARYA S, 1994, P ACM SIAM S DISCR A; ARYA S, 1993, P ACM SIAM S DISCR A; ARYA S, 2002, P S THEOR COMP; ARYA S, 2002, P ACM SIAM S DISCR A; BENOR M, 1988, P 20 ANN S THEOR COM; BLAKE I, 2006, P FIN CRYPT; Breunig M., 2000, P ACM INT C MAN DAT; BREUNIG MM, 1999, P 3 EUR C PRINC DAT; CLARKSON K, 1994, P ACM S COMP GEOM; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CREPEAU C, 1987, P ADV CRYPT; Du W., 2002, P WORKSH PRIV SEC DA; Du W., 2001, P 17 ANN COMP SEC AP; DU WL, 2002, P 2002 WORKSH NEW SE; ERTOZ L., 2001, WORKSH CLUST HIGH DI; EVEN S, 1985, COMMUN ACM, V28, P637, DOI 10.1145/3812.3818; GENNARO R, 1998, P 17 ANN ACM S PRINC; Goethals B., 2004, P 7 ANN INT C INF SE; Goldreich O, 2004, FDN CRYPTOGRAPHY, V2; Indyk P., 1998, P S THEOR COMP; IOANNIDIS I, 2003, P HAW INT C SYST SCI; IOANNIDIS I, 2002, P 31 INT C PAR PROC; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; KILTZ E, 2006, P 3 THEOR CRYPT C; KLEINGBERG J, 1997, P ACM S THEOR COMP; Kumar V., 2003, P SIAM INT C DAT MIN; KUSHLEVITZ E, 1998, P ACM S THEOR COMP; LAUR S, 2004, P 9 NORD WORKSH SEC; LIN HY, 2005, P 3 INT C APPL CRYPT; LIPMAA H, 2005, P 8 INF SEC C; NAOR M, 2001, P 12 ANN S DISCR ALG; NAOR M, 1999, P 31 ANN ACM S THEOR; PAILLIER P, 1999, P EUR; Rabin M. O., 1981, TR81 HARV U; RAVIKUMAR P, 2004, P ICDM WORKSH PRIV S; SHAMIR A, 1979, COMMUN ACM, V22, P512; SHANECK M, 2006, 06014 U MINN; Tzeng WG, 2004, IEEE T COMPUT, V53, P232; VAIDYA J, 2004, P 4 IEEE INT C DAT M; VAIDYA J, 2003, P 2003 ACM WORKSH PR; Vaidya J., 2002, P ACM INT C KNOWL DI; Yang ZQ, 2006, COMPUT SYST SCI ENG, V21, P47; Yao A. C., 1986, P 27 IEEE S FDN COMP; 2007, GNU MULTIPLE PRECISI	47	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1060-3425		978-1-4244-5509-6	P ANN HICSS			2010							917	925				9	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BRD18	WOS:000282391801002		
S	Sainin, MS; Alfred, R		Cao, L; Feng, Y; Zhong, J		Sainin, Mohd Shamrie; Alfred, Rayner			Nearest Neighbour Distance Matrix Classification	ADVANCED DATA MINING AND APPLICATIONS, ADMA 2010, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Advanced Data Mining and Applications (ADMA)	NOV 19-21, 2010	Chongqing, PEOPLES R CHINA	Chongqing Univ, Univ Queensland, Sch Informat Technol & Elect Engn, Natl Nat Sci Fdn China, Chongqing Acad Sci & Technol, Chongqing Sci & Technol Commiss, IEEE Queensland Sect		data mining; machine learning; nearest neighbour; distance matrix; classification		A distance based classification is one of the popular methods for classifying instances using a point-to-point distance based on the nearest neighbour or k-NEAREST NEIGHBOUR (k-NN). The representation of distance measure can be one of the various measures available (e.g. Euclidean distance, Manhattan distance, Mahalanobis distance or other specific distance measures). In this paper, we propose a modified nearest neighbour method called Nearest Neighbour Distance Matrix (NNDM) for classification based on unsupervised and supervised distance matrix. In the proposed NNDM method, an Euclidean distance method coupled with a distance loss function is used to create a distance matrix. In our approach, distances of each instance to the rest of the training instances data will be used to create the training distance matrix (TADM). Then, the TADM will be used to classify a new instance. In supervised NNDM, two instances that belong to different classes will be pushed apart from each other. This is to ensure that the instances that are located next to each other belong to the same class. Based on the experimental results, we found that the trained distance matrix yields reasonable performance in classification.	[Sainin, Mohd Shamrie; Alfred, Rayner] Univ Malaysia Sabah, Sch Engn & Informat Technol, Kota Kinabalu, Sabah, Malaysia	Sainin, MS (reprint author), Univ Malaysia Sabah, Sch Engn & Informat Technol, Locked Bag 2073, Kota Kinabalu, Sabah, Malaysia.	shamrie@uum.edu.my; ralfred@ums.edu.my	Alfred, Rayner /M-8376-2013	Alfred, Rayner /0000-0002-3080-3264			Agarwal G, 2006, TAXON, V55, P597; Asuncion A., 2007, UCI MACHINE LEARNING; Bai X., 2009, IEEE T PATTERN ANAL, V31; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P705; Chopra S., 2005, P IEEE C COMP VIS PA, P349; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P513; Keogh E., 2006, UCR TIME SERIES CLAS; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Mahalanobis P.C., 1936, P NAT I SCI INDIA, P49; Shalev-Shwartz S, 2004, P 21 INT C MACH LEAR, P94; Shental N, 2002, LECT NOTES COMPUT SC, V2353, P776; Simard P. Y., 1993, ADV NEURAL INFORM PR, V6, P50; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Zhang B, 2004, IEEE T PATTERN ANAL, V26, P525	15	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17315-8	LECT NOTES ARTIF INT			2010	6440						114	124				11	Computer Science, Artificial Intelligence	Computer Science	BHL07	WOS:000325760100011		
S	Mendialdua, I; Sierra, B; Lazkano, E; Irigoien, I; Jauregi, E		Cao, L; Feng, Y; Zhong, J		Mendialdua, I.; Sierra, B.; Lazkano, E.; Irigoien, I.; Jauregi, E.			Surrounding Influenced K-Nearest Neighbors: A New Distance Based Classifier	ADVANCED DATA MINING AND APPLICATIONS, ADMA 2010, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Advanced Data Mining and Applications (ADMA)	NOV 19-21, 2010	Chongqing, PEOPLES R CHINA	Chongqing Univ, Univ Queensland, Sch Informat Technol & Elect Engn, Natl Nat Sci Fdn China, Chongqing Acad Sci & Technol, Chongqing Sci & Technol Commiss, IEEE Queensland Sect		Nearest Neighbor; Supervised Classification	LEARNING ALGORITHMS	The nearest neighbor classification method assigns to an unclassified point the class of the nearest of a set of previously classified points. An extension to this approach is the K-NN method, in which the classification is made taking into account the K nearest points and classifying the unclassified point by a voting criteria from this k points. We present a new method that extends the K-NN limits, taking into account, for each neighbor, its I nearest neighbors. Experimental results are promising, obtaining better results for two class problems than the original K-NN.	[Mendialdua, I.; Sierra, B.; Lazkano, E.; Irigoien, I.; Jauregi, E.] Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Donostia San Sebastian 20018, Basque Country, Spain	Mendialdua, I (reprint author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, P Manuel Lardizabal 1, Donostia San Sebastian 20018, Basque Country, Spain.	inigo.mendialdua@ehu.es; b.sierra@ehu.es; e.lazkano@ehu.es; itziar.irigoien@ehu.es; ekaitz.jauregi@ehu.es	Jauregi Iztueta, Ekaitz/K-9742-2015	Jauregi Iztueta, Ekaitz/0000-0001-7418-9326			AHA DW, 1992, INT J MAN MACH STUD, V36, P267, DOI 10.1016/0020-7373(92)90018-G; AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Blake B.L., 1998, UCI REPOSITORY MACHI; COST S, 1993, MACH LEARN, V10, P57, DOI 10.1007/BF00993481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Demsar J, 2006, J MACH LEARN RES, V7, P1; Fix E., 1951, TECHNICAL REPORT PRO; Martnez-Otzeta J.M., 2004, 6 INT C ENT INF SYST, V2, P233; Mitchell T. M., 1997, MACHINE LEARNING; Sierra B., 2002, P KES 2002, P932; Stanfill C., 1986, Communications of the ACM, V29, DOI 10.1145/7902.7906; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wettschereck D, 1994, THESIS OREGON STATE; Younes Z., 2008, 16 EUR SIGN PROC C L	17	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17315-8	LECT NOTES ARTIF INT			2010	6440						270	277				8	Computer Science, Artificial Intelligence	Computer Science	BHL07	WOS:000325760100026		
S	Zhang, QJ; Sun, SL		Cao, L; Feng, Y; Zhong, J		Zhang, Qingjiu; Sun, Shiliang			A Centroid k-Nearest Neighbor Method	ADVANCED DATA MINING AND APPLICATIONS, ADMA 2010, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th International Conference on Advanced Data Mining and Applications (ADMA)	NOV 19-21, 2010	Chongqing, PEOPLES R CHINA	Chongqing Univ, Univ Queensland, Sch Informat Technol & Elect Engn, Natl Nat Sci Fdn China, Chongqing Acad Sci & Technol, Chongqing Sci & Technol Commiss, IEEE Queensland Sect		Distance metric learning; k-nearest neighbor; Euclidean distance; Mahalanobis distance	CLASSIFICATION	k-nearest neighbor method (kNN) is a very useful and easy-implementing method for real applications. The query point is estimated by its k nearest neighbors. However, this kind of prediction simply uses the label information of its neighbors without considering their space distributions. This paper proposes a novel kNN method in which the centroids instead of the neighbors themselves are employed. The centroids can reflect not only the label information but also the distribution information of its neighbors. In order to evaluate the proposed method, Euclidean distance and Mahalanobis distance is used in our experiments. Moreover, traditional kNN is also implemented to provide a comparison with the proposed method. The empirical results suggest that the propose method is more robust and effective.	[Zhang, Qingjiu; Sun, Shiliang] E China Normal Univ, Dept Comp Sci & Technol, Shanghai 200241, Peoples R China	Zhang, QJ (reprint author), E China Normal Univ, Dept Comp Sci & Technol, 500 Dongchuan Rd, Shanghai 200241, Peoples R China.	qjzh08@gmail.com; slsun@cs.ecnu.edu.cn					Achtert E., 2009, P 12 INT C EXT DAT T, P886, DOI 10.1145/1516360.1516462; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R O, 2001, PATTERN CLASSIFICATI; Duda R. O., 1973, PATTERN CLASSIFICATI; Friedman JH, 1994, FLEXIBLE METRIC NEAR; Hastie T., 1996, IEEE PATTERN ANAL MA, V18; Jin CQ, 2007, LECT NOTES ARTIF INT, V4632, P239; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; MacKay D. J. C., 2003, INFORM THEORY INFERE; Ng A. Y., 2001, ADV NEURAL INFORM PR; Sun S., 2010, P 7 INT C FUZZ SYST, P91; Sun SL, 2010, PATTERN RECOGN LETT, V31, P119, DOI 10.1016/j.patrec.2009.09.017; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Yang L., 2006, DISTANCE METRIC LEAR	14	2	2	0	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17315-8	LECT NOTES ARTIF INT			2010	6440						278	285				8	Computer Science, Artificial Intelligence	Computer Science	BHL07	WOS:000325760100027		
S	Yang, T; Cao, LB; Zhang, CQ		Zaki, MJ; Yu, JX; Ravindran, B; Pudi, V		Yang, Tao; Cao, Longbing; Zhang, Chengqi			A Novel Prototype Reduction Method for the K-Nearest Neighbor Algorithm with K >= 1	ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PT II, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th Pacific-Asia Conference on Knowledge Discovery and Data Mining	JUN 21-24, 2010	Hyderabad, INDIA	IIIT Hyderbad, AFOSR, AOARD, ONRG			CLASSIFICATION; ERROR	In this paper, a novel prototype reduction algorithm is proposed, which aims at reducing the storage requirement and enhancing the online speed while retaining the same level of accuracy for a K-nearest neighbor (KNN) classifier. To achieve this goal, our proposed algorithm learns the weighted similarity function for a KNN classifier by maximizing the leave-one-out cross-validation accuracy. Unlike the classical methods PW, LPD and WDNN which can only work with K = 1 our developed algorithm can work with K >= 1. This flexibility allows our lean it algorithm to have superior classification accuracy and noise robustness. The proposed approach is assessed through experiments with twenty real world benchmark data sets. In all these experiments, the proposed approach shows it can dramatically reduce the storage requirement and online time for KNN while having equal or better accuracy than KNN, and it also shows comparable results to several prototype reduction methods proposed in literature.	[Yang, Tao; Cao, Longbing; Zhang, Chengqi] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	Yang, T (reprint author), Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.						COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Hastie T, 2009, ELEMENTS STAT LEARNI, V2nd; Jahromi MZ, 2009, INFORM SCIENCES, V179, P2964, DOI 10.1016/j.ins.2009.04.012; Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Paredes R, 2006, PATTERN RECOGN, V39, P180, DOI 10.1016/j.patcog.2005.06.001; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Ridder D., 2004, P 17 INT C PATT REC, V2, P295; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Yang T, 2008, NEUROCOMPUTING, V71, P3001, DOI 10.1016/j.neucom.2008.01.014	12	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13671-9	LECT NOTES ARTIF INT			2010	6119		II				89	100				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQR44	WOS:000281629400010		
S	Solorio-Fernandez, S; Carrasco-Ochoa, JA; Martinez-Trinidad, JF		CarrascoOchoa, JA; MartinezTrinidad, JF; Kittler, J		Solorio-Fernandez, Saul; Ariel Carrasco-Ochoa, J.; Fco. Martinez-Trinidad, Jose			Hybrid Feature Selection Method for Supervised Classification Based on Laplacian Score Ranking	ADVANCES IN PATTERN RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	2nd Mexican Conference on Pattern Recognition	SEP 27-29, 2010	Puebla, MEXICO	Natl Inst Astrophys, Comp Sci Dept, Opt & Elect, Natl Polytechn Inst, Comp Res	Natl Inst Astrophys	Supervised Feature Selection; Laplacian Score; Feature Ranking		In this paper, we introduce a new hybrid filter-wrapper method for supervised feature selection, based on the Laplacian Score ranking combined with a wrapper strategy. We propose to rank features with the Laplacian Score to reduce the search space, and then we use this order to find the best feature subset. We compare our method against other based on ranking feature selection methods, namely, Information Gain Attribute Ranking, Relief, Correlation-based Feature Selection, and additionally we include in our comparison a Wrapper Subset Evaluation method. Empirical results over ten real-world datasets from the UCI repository show that our hybrid method is competitive and outperforms in most of the cases to the other feature selection methods used in our experiments.	[Solorio-Fernandez, Saul; Ariel Carrasco-Ochoa, J.; Fco. Martinez-Trinidad, Jose] Natl Inst Astrophys Opt & Elect, Puebla 72840, Mexico	Solorio-Fernandez, S (reprint author), Natl Inst Astrophys Opt & Elect, Luis Enrique Erro 1, Puebla 72840, Mexico.	sausolofer@ccc.inaoep.mx; ariel@ccc.inaoep.mx; fmartine@ccc.inaoep.mx					Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Das S., 2001, ICML 01, P74; Dash M, 1998, LECT NOTES ARTIF INT, V1531, P238; Dash M, 1997, INTELL DATA ANAL, V1, P131, DOI DOI 10.1016/S1088-467X(97)00008-5; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, DOI 10.1145/288627.288651; Frank E., 2005, DATA MINING PRACTICA; GARCIA DG, 2009, 4 INT C MACH LEARN A, P425; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall MA, 2003, IEEE T KNOWL DATA EN, V15, P1437, DOI 10.1109/TKDE.2003.1245283; Hall MA, 1998, THESIS U WAIKATO HAM; Hall Mark, 2009, SIGKDD EXPLORATIONS, V11; He X., 2006, ADV NEURAL INFORM PR, V18, P507; JENSEN R, 2008, COMPUT INTELL, P61; JOHN GH, 1995, ESTIMATING CONTINUOU, P338; KIM Y, 2003, FEATURE SELECTION DA, P80; KIRA K, 1992, MACHINE LEARNING /, P249; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1994, EUR C MACH LEARN, P171; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491; LIU R, 2009, WORKSH INT INF TECHN, V3, P65; LOUGHREY J, 2005, TCDCS200537 DEP COMP; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Niijima S, 2009, IEEE ACM T COMPUT BI, V6, P605, DOI 10.1109/TCBB.2007.70257; PAL SK, 2004, PATTERN RECOGN, P59; Quinlan R, 1993, C4 5 PROGRAMS MACHIN; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Xing E., 2001, P 18 INT C MACH LEAR, P601; Yu L, 2004, J MACH LEARN RES, V5, P1205; ZHANG L, 2004, INT C COMP INF TECHN, P233; Zhao Z., 2007, ICML, P1151	31	1	1	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15991-6	LECT NOTES COMPUT SC			2010	6256						260	269				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTC02	WOS:000286415900028		
B	Walters-Williams, J; Li, Y		Elleithy, K		Walters-Williams, Janett; Li, Yan			Comparative Study of Distance Functions for Nearest Neighbors	ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING			English	Proceedings Paper	International Conference on Systems, Computing Sciences and Software Engineering	2008	Bridgeport, CT			Kullback-Leibler distance; Euclidean distance; Mahalanobis distance; Manhattan distance; Hamming distance; Minkowski distance; Nearest Neighbor		Many learning algorithms rely on distance metrics to receive their input data. Research has shown that these metrics can improve the performance of these algorithms. Over the years an often popular function is the Euclidean function. In this paper, we investigate a number of different metrics proposed by different communities, including Mahalanobis, Euclidean, Kullback-Leibler and Hamming distance. Overall, the best-performing method is the Mahalanobis distance metric.	[Walters-Williams, Janett] Univ Technol, Sch Comp & Informat Technol, Kingston 6, Jamaica	Walters-Williams, J (reprint author), Univ Technol, Sch Comp & Informat Technol, Kingston 6, Jamaica.	jwalters@utech.edu.jm; liyan@usq.edu.au					Abdi H., 2007, ENCY MEASUREMENT STA; Bar-Hillel A., 2006, THESIS HEBREW U JERU; BEITAO L, 2002, P IEEE C IM PROC SEP; BORIAH S, 2008, P 2008 SOC IND APPL, P23; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davis J., 2007, P 24 INT C MACH LEAR; GRIFFITHS R, 1992, P SURV RES METH SECT; JENSEN DD, 2002, MULTIPLE COMPARISONS, P1; JONES WP, 1987, J AM SOC INFORM SCI, V38, P420, DOI 10.1002/(SICI)1097-4571(198711)38:6<420::AID-ASI3>3.0.CO;2-S; KAMICHETY HM, 2002, EMPIRICAL FRAMEWORK; NOREAULT T, 1981, SIGIR 80 P 3 ANN ACM, P76; QIAN G, 2004, P ACM S APPL COMP; Tumminello M, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.031123; Weinberger K., 2006, ADV NEURAL INFORM PR; WEINBERGER KQ, 2007, INT C MACH IN PRESS; WILSON DR, 1997, THESIS B YOUNG U; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1; WOLFEL M, 2005, P 13 EUR SIGN PROC C; Zwick R., 1987, International Journal of Approximate Reasoning, V1, DOI 10.1016/0888-613X(87)90015-6	19	2	2	1	2	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY			978-90-481-3659-9				2010							79	84		10.1007/978-90-481-3660-5_14		6	Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BQR66	WOS:000281650200014		
S	McSherry, D; Stretch, C		Coyle, L; Freyne, J		McSherry, David; Stretch, Christopher			An Analysis of Order Dependence in k-NN	ARTIFICIAL INTELLIGENCE AND COGNITIVE SCIENCE	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	20th Irish Conference on Artificial Intelligence and Cognitive Science	AUG 19-21, 2009	Dublin, IRELAND	Sch Comp Sci & Informat, CLARITY, Sci Fdn Ireland Ctr Sci, Engn & Technol, Tyndall Natl Inst, CLIQUE, Strateg Res Cluster, Sci Fdn Ireland (SFI), IBM, Idiro Technol, Norkom Technol	Univ Coll Dublin	classification; k-NN; instance-based learning; case-based reasoning		In classification based on k-NN with majority voting, the class assigned to a given problem is the one that occurs most frequently in the k most similar cases (or instances) in the dataset. However, different versions of k-NN may use different strategies to select the cases on which the solution is based when there are ties for the kth most similar case. One strategy is to break ties for the kth most similar case based on the ordering of cases in the dataset. We present an analysis of the order dependence introduced by this strategy and its effects on the algorithm's performance.	[McSherry, David; Stretch, Christopher] Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland	McSherry, D (reprint author), Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland.	dmg.mcsherry@ulster.ac.uk; ct.stretch@ulster.ac.uk					Aha DW, 1998, KNOWL-BASED SYST, V11, P261, DOI 10.1016/S0950-7051(98)00066-5; Asuncion A., 2007, UCI MACHINE LEARNING; BROOKS AD, 2001, KNNFLEX MORE FLEXIBL; CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Langley P, 1995, LEARNING HUMANS MACH; Leake D, 2007, LECT NOTES COMPUT SC, V4626, P194; McSherry D, 2002, LECT NOTES ARTIF INT, V2416, P219; Mitchell T. M., 1997, MACHINE LEARNING; *R FDN STAT COMP, 2009, R DEV COR TEAM LANG; Ripley B. D., 1996, PATTERN CLASSIFICATI; Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2; Zhua M., 2007, J CLIN EPIDEMIOL, V60, P1015	14	0	0	0	6	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17079-9	LECT NOTES ARTIF INT			2010	6206						207	218				12	Computer Science, Artificial Intelligence	Computer Science	BTF44	WOS:000286799900023		
S	Jagannathan, R; Petrovic, S; McKenna, A; Newton, L		Papadopoulos, H; Andreou, AS; Bramer, M		Jagannathan, Rupa; Petrovic, Sanja; McKenna, Angela; Newton, Louise			A Fuzzy Non-linear Similarity Measure for Case-Based Reasoning Systems for Radiotherapy Treatment Planning	ARTIFICIAL INTELLIGENCE APPLICATIONS AND INNOVATIONS	IFIP Advances in Information and Communication Technology		English	Proceedings Paper	6th IFIP Conference on Artificial Intelligence Applications and Innovations	OCT 06-07, 2010	Larnaca, CYPRUS	Univ Cyprus, Cyprus Univ Technol, Frederick Univ, Cyprus Tourism Org		Case-based Reasoning; Fuzzy Logic; Radiotherapy Treatment Planning; Decision-Support Systems		This paper presents a decision support system for treatment planning in brain cancer radiotherapy. The aim of a radiotherapy treatment plan is to apply radiation in a way that destroys tumour cells but minimizes the damage to healthy tissue and organs at risk. Treatment planning for brain cancer patients is a complex decision-making process that relies heavily on the subjective experience and expert domain knowledge of clinicians. We propose to capture this experience by using case-based reasoning. Central to the working of our case-based reasoning system is a novel similarity measure that takes into account the non-linear effect of the individual case attributes on the similarity measure. The similarity measure employs fuzzy sets. Experiments, which were carried out to evaluate the similarity measure using real brain cancer patient cases show promising results.	[Jagannathan, Rupa; Petrovic, Sanja] Univ Nottingham, Automated Scheduling Optimisat & Planning Res Grp, Sch Comp Sci, Nottingham NG7 2RD, England	Jagannathan, R (reprint author), Univ Nottingham, Automated Scheduling Optimisat & Planning Res Grp, Sch Comp Sci, Nottingham NG7 2RD, England.	rxj@cs.nott.ac.uk; sxp@cs.nott.ac.uk; angela.mckenna@nuh.nhs.uk; louise.newton@nuh.nhs.uk					Berger J., 1994, Proceedings of the Tenth Conference on Artificial Intelligence for Applications (Cat. No. 94CH3421-5), DOI 10.1109/CAIA.1994.323677; Cheng CB, 2003, MATH COMPUT MODEL, V38, P385, DOI 10.1016/S0895-7177(03)00228-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Haas O. C. L., 1998, P 1998 IEEE INT C CO; Holt A, 2005, KNOWL ENG REV, V20, P289, DOI 10.1017/S0269888906000622; Kolodner J. L., 1993, CASE BASED REASONING; Mishra N, 2009, PROC INT C TOOLS ART, P776; NEMA, DICOM DIG IM COMM ME; Oldham M, 1998, PHYS MED BIOL, V43, P2123, DOI 10.1088/0031-9155/43/8/010; Schmidt R, 2001, INT J MED INFORM, V64, P355, DOI 10.1016/S1386-5056(01)00221-0; SONG X, 2007, ICCBR 2007 LNCS LNAI, V4626, P348; WANG R, 2005, INFORM TECHNOLOGY AP, V1, P341	12	1	1	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1868-4238		978-3-642-16238-1	IFIP ADV INF COMM TE			2010	339						112	119				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Computer Science	BWD73	WOS:000293683700017		
S	Moka, E; Refanidis, I		Konstantopoulos, S; Perantonis, S; Karkaletsis, V; Spyropoulos, CD; Vouros, G		Moka, Evangelia; Refanidis, Ioannis			Towards Intelligent Management of a Student's Time	ARTIFICIAL INTELLIGENCE: THEORIES, MODELS AND APPLICATIONS, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	6th Hellenic Conference on Artificial Intelligence	MAY 04-07, 2010	Athens, GREECE	Hellen Soc Artificial Intelligence, Inst Informat & Telecommun, NCSR		Intelligent systems; scheduling; calendar applications		In parallel with studies, a lot of extra activities need to be fitted in a student's schedule. Frequently, excessive workload results in poor performance or in failing to finish the studies. The problem is more severe in lifelong learning, where students are professionals with family duties. So, the need of making informative decisions as of whether taking a specific course fits into a student's schedule is of great importance. This paper illustrates a system, called EDUPLAN and being currently under development, which aims at helping the student to make intelligent management of her time. EDUPLAN aims at informing the student as for which learning objects can fit her schedule or not, as well as at organizing her time. This can be achieved using scheduling algorithms and a description of the user's tasks and events. In the paper we also extend the LOM 1484.12.3 (TM)-2005 ontology with classes that can be used to describe the temporal distribution of the workload of any learning object. Finally, we provide EDUPLAN'S architecture, being built around the existing SELFPLANNER intelligent calendar application.	[Moka, Evangelia; Refanidis, Ioannis] Univ Macedonia, Dept Appl Informat, Thessaloniki 54006, Greece	Moka, E (reprint author), Univ Macedonia, Dept Appl Informat, Egnatia Str 156, Thessaloniki 54006, Greece.	emoka@uom.gr; yrefanid@uom.gr					ALEXIADIS A, 2009, 5 IFIP C ART INT APP, P399; Cormen T. H., 2009, INTRO ALGORITHMS, V3nd; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237; Refanidis I., 2007, P 17 INT C AUT PLANN, P272; REFANIDIS I, 2010, COMPUTATION IN PRESS	6	0	0	0	3	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-12841-7	LECT NOTES ARTIF INT			2010	6040						383	388				6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQO34	WOS:000281445400047		
J	Raniszewski, M				Raniszewski, Marcin			The Edited Nearest Neighbor Rule Based on the Reduced Reference Set and the Consistency Criterion	BIOCYBERNETICS AND BIOMEDICAL ENGINEERING			English	Article						editing techniques; nearest neighbor rule; consistency criterion; reference set reduction; representativeness measure		In this paper a new editing procedure for the Nearest Neighbor Rule (NN) is presented. The representativeness measure is introduced and used to choose the most representative samples of the classes. These samples constitute a reduced reference set. An edited reference set is created from all the training set samples (including samples from the reduced set), which are correctly classified by the NN rule operating with the reduced set. The performance of the presented method is evaluated and compared with five other well-known editing techniques, on five medical datasets.	Tech Univ Lodz, Dept Comp Engn, PL-90924 Lodz, Poland	Raniszewski, M (reprint author), Tech Univ Lodz, Dept Comp Engn, Stefanowskiego 18-22, PL-90924 Lodz, Poland.	mranisz@kis.p.lodz.pl					Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Duda R O, 2001, PATTERN CLASSIFICATI; FIX E, 1952, 11 USAF SCH AV MED, P280; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hodges J., 1951, 4 USAF SCH AV MED, P261; Kohavi R., 1995, P 14 INT JOINT C ART, P338; KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K; NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203; RANISZEWSKI M, 2007, COMPUTER RECOGNITION, V2, P258; Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137	14	2	2	1	2	PWN-POLISH SCIENTIFIC PUBL	WARSAW	UL KS TROJDENA 4, WARSAW, 02-109, POLAND	0208-5216			BIOCYBERN BIOMED ENG	Biocybern. Biomed. Eng.		2010	30	1					31	40				10	Engineering, Biomedical	Engineering	565PY	WOS:000275307700003		
S	Hu, ZB; Cai, ZH		Cai, Z; Tong, HJ; Kang, Z; Liu, Y		Hu, Zhenbang; Cai, Zhihua			Feature Synthesis Algorithm Combined with k-NN Classifier for Spectral Data Classification	COMPUTATIONAL INTELLIGENCE AND INTELLIGENT SYSTEMS	Communications in Computer and Information Science		English	Proceedings Paper	5th International Symposium on Intelligence Computation and Applications	OCT 22-24, 2010	Wuhan, PEOPLES R CHINA	China Univ Geosciences, China Univ Geosciences, Sch Comp Sci		feature extraction; feature selection; spectral data; k-NN	HYPERSPECTRAL DATA; IMAGES	A feature synthesis algorithm combined with modified k-NN classifier is described in this paper. The feature information of the training data is extracted firstly. In the classification phase, the feature information of the training data and the testing data are compared to make the initial prediction. If the predicting result is {C} which has only one element, testing data will be labeled class C. If the predicting result is {C(1), C(2), ... C(i)}, the corresponding subset of the training data set will be used in the k-NN algorithm to attain the predicted result. It is shown that this algorithm combined k-NN rule reduces computing time. If the feature information set could well generalize the training data, the error rate of the algorithm is decreased. The effectiveness of this proposed approach is verified on a public remote sensing data set.	[Hu, Zhenbang; Cai, Zhihua] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China	Hu, ZB (reprint author), China Univ Geosci, Sch Comp Sci, 388 Lumo Rd, Wuhan 430074, Peoples R China.	gelduoe@126.com; zhcai@cug.edu.cn					Blake C, 1998, UCI REPOSITORY MACHI; Budevska BO, 2003, APPL SPECTROSC, V57, P124, DOI 10.1366/000370203321535015; CLARKE LP, 1993, MAGN RESON IMAGING, V11, P95, DOI 10.1016/0730-725X(93)90417-C; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deer PJ, 2003, FUZZY SET SYST, V137, P191, DOI 10.1016/S0165-0114(02)00220-8; DOSSANTOS JA, 2010, INFORM SCI; Erives H, 2005, COMPUT ELECTRON AGR, V47, P103, DOI 10.1016/j.compag.2004.11.016; FIX E, 11 USAF SCH AV MED, P280; Freeman JE, 2004, BREAST CANCER RES TR, V88, pS41; GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001; GUPTA MR, 2006, IEEE IMAGE PROC, P1585; Krishnaswamy J, 2009, REMOTE SENS ENVIRON, V113, P857, DOI 10.1016/j.rse.2008.12.011; Moussaoui S, 2008, NEUROCOMPUTING, V71, P2194, DOI 10.1016/j.neucom.2007.07.034; Muhammed HH, 2005, BIOSYST ENG, V91, P9, DOI 10.1016/j.biosystemseng.2005.02.007; Nakariyakul S, 2009, J FOOD ENG, V94, P358, DOI 10.1016/j.jfoodeng.2009.04.001; Overton G, 2004, LASER FOCUS WORLD, V40, P33; Peddle DR, 2001, COMPUT GEOSCI-UK, V27, P203, DOI 10.1016/S0098-3004(00)00096-0; Richards J.A., 1999, REMOTE SENSING DIGIT; Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010; Wang J, 2006, IEEE T GEOSCI REMOTE, V44, P1586, DOI 10.1109/TGRS.2005.80297; Yang CC, 2002, BIOSYST ENG, V83, P291, DOI 10.1016/S1537-5110(02)00195-2; Zuzak KJ, 2003, AM J PHYSIOL-HEART C, V285, pH1183, DOI 10.1152/ajpheart.00243.2003	22	0	0	1	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	1865-0929		978-3-642-16387-6	COMM COM INF SC			2010	107						254	263		10.1007/978-3-642-16388-3_28		10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTZ20	WOS:000288485100028		
B	Cheng, JM; Yan, L; Zhang, C; Pei, Z		Ruan, D; Li, TR; Xu, Y; Chen, GQ; Kerre, EE		Cheng, Jianmei; Yan, Li; Zhang, Chao; Pei, Zheng			A COMBINED METHOD TO DEAL WITH UNCERTAIN DATA IN FUZZY K-NEAREST NEIGHBOR CLASSIFIER	COMPUTATIONAL INTELLIGENCE: FOUNDATIONS AND APPLICATIONS: PROCEEDINGS OF THE 9TH INTERNATIONAL FLINS CONFERENCE	World Scientific Proceedings Series on Computer Engineering and Information Science		English	Proceedings Paper	9th International FLINS Conference on Computational Intelligence: Foundations and Applications	AUG 02-04, 2010	Emei, PEOPLES R CHINA			FKNN; Editing Technique; Membership Functions; Fuzzy Set; Pattern Recognition		To improve the accuracy of recognition, we propose an approach to modify initial membership function in fuzzy k-nearest neighbors classifier (FKNN). The aim of the approach is that it will specify degree of the object which belongs to each class. The modified function is based on the relationship between patterns in labeled sample set that can deal with some uncertain data. In addition, the combination of edited technique and the modified initial membership technique based on FKNN was used to deal with uncertain data.	[Cheng, Jianmei; Yan, Li; Zhang, Chao; Pei, Zheng] Xihua Univ, Sch Math & Comp Engn, Chengdu 610039, Sichuan, Peoples R China	Cheng, JM (reprint author), Xihua Univ, Sch Math & Comp Engn, Chengdu 610039, Sichuan, Peoples R China.	freecjm2003@163.com					Choi BI, 2009, INFORM SCIENCES, V179, P2102, DOI 10.1016/j.ins.2008.04.009; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Guan D, 2009, INFORM SCIENCES, V179, P2273, DOI 10.1016/j.ins.2009.02.011; Hung WL, 2008, PATTERN RECOGN LETT, V29, P1317, DOI 10.1016/j.patrec.2008.02.003; KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580; Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1; Wang X, 2009, STUD FUZZ SOFT COMP, V245, P1, DOI 10.1007/978-3-540-78311-4; Wang XZ, 2004, PATTERN RECOGN LETT, V25, P1123, DOI 10.1016/j.patrec.2004.03.008; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Yang MS, 1998, IEEE T SYST MAN CY B, V28, P461, DOI 10.1109/3477.678652	11	0	0	0	0	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE			978-981-4324-69-4	WD SCI P COMP ENG			2010	4						282	287				6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BVA99	WOS:000290926800041		
S	Kim, J; Shen, CH; Wang, L		Zha, H; Taniguchi, RI; Maybank, S		Kim, Junae; Shen, Chunhua; Wang, Lei			A Scalable Algorithm for Learning a Mahalanobis Distance Metric	COMPUTER VISION - ACCV 2009, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	9th Asian Conference on Computer Vision	SEP 23-27, 2009	Xian, PEOPLES R CHINA	Peking Univ, Key Lab Machine Percept, Chinese Acad Sci, Natl lab Pattern Recognit, Inst Automat, Natl Nat Sci Fdn China, Microsoft Res, Fujitsu, Microview, Luster				A distance metric that can accurately reflect the intrinsic characteristics of data is critical for visual recognition tasks. An effective solution to defining such a metric is to learn it from a set of training samples. In this work, we propose a fast and scalable algorithm to learn a Mahalanobis distance. By employing the principle of margin maximization to secure better generalization performances, this algorithm formulates the metric learning as a convex optimization problem with a positive semidefinite (psd) matrix variable. Based on an important theorem that a psd matrix with trace of one can always be represented as a convex combination of multiple rank-one matrices, our algorithm employs a differentiable loss function and solves the above convex optimization with gradient descent methods. This algorithm not only naturally maintains the psd requirement; of the matrix variable that is essential for metric learning; but also significantly cuts down computational overhead, making it much more efficient with the increasing dimensions of feature vectors. Experimental study on benchmark data sets indicates that, compared with the existing metric learning algorithms, our algorithm can achieve higher classification accuracy with much less computational load.	[Kim, Junae; Shen, Chunhua; Wang, Lei] Australian Natl Univ, Canberra, ACT, Australia	Kim, J (reprint author), Australian Natl Univ, Canberra, ACT, Australia.	junae.kim@anu.edu.au; chunhua.shen@nicta.com.au; lei.wang@anu.edu.au					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FEIPEI L, 2004, WORKSH GEN MOD BAS V; Goldberger J., 2005, P ADV NEUR INF PROC; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, DOI 10.1109/ICCV.1999.790410; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Nocedal J, 1999, NUMERICAL OPTIMIZATI; Scholkpf B., 2002, LEARNING KERNELS SUP; Shen C., 2008, P ADV NEUR INF PROC, P1473; SMEULDERS AWM, 2000, IEEE T PATTERN ANAL, V22, P1; Vapnik V., 1998, STAT LEARNING THEORY; Weinberger K, 2006, P NIPS, P1475; Winn J., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Xing EP, 2003, P NIPS, P505; YANG L, 2008, IEEE T PATTERN ANAL, V10	15	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-12296-5	LECT NOTES COMPUT SC			2010	5996						299	310				12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BPQ60	WOS:000279642800029		
J	Kral, P; Cerisara, C				Kral, Pavel; Cerisara, Christophe			DIALOGUE ACT RECOGNITION APPROACHES	COMPUTING AND INFORMATICS			English	Article						Bayesian approaches; dialogue act; lexical information; prosody; syntactic information	MULTIPARTY MEETINGS; CLASSIFICATION; SPEECH	This paper deals with automatic dialogue act (DA) recognition. Dialogue acts are sentence-level units that represent states of a dialogue, such as questions, statements, hesitations, etc. The knowledge of dialogue act realizations in a discourse or dialogue is part of the speech understanding and dialogue analysis process. It is of great importance for many applications: dialogue systems, speech recognition, automatic machine translation, etc. The main goal of this paper is to study the existing works about DA recognition and to discuss their respective advantages and drawbacks. A major concern in the DA recognition domain is that, although a few DA annotation schemes seem now to emerge as standards, most of the time, these DA tag-sets have to be adapted to the specificities of a given application, which prevents the deployment of standardized DA databases and evaluation procedures. The focus of this review is put on the various kinds of information that can be used to recognize DAs, such as prosody, lexical, etc., and on the types of models proposed so far to capture this information. Combining these information sources tends to appear nowadays as a prerequisite to recognize DAs.	[Kral, Pavel] Univ W Bohemia, Dept Comp Sci & Engn, Plzen 30614, Czech Republic; [Cerisara, Christophe] LORIA UMR 7503, F-54506 Vandoeuvre Les Nancy, France	Kral, P (reprint author), Univ W Bohemia, Dept Comp Sci & Engn, Plzen 30614, Czech Republic.	pkral@kiv.zcu.cz; cerisara@loria.fr	Kral, Pavel/C-5631-2013				AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; ALEXANDERSSON J, 1997, 191 VERBMOBIL; ALLEN J, 1997, DRAFT DAMSL DIALOG A; ANDERNACH T, 1996, NEMLAP 2; Andernach T., 1997, ECML MLNET WORKSH EM, P85; ANG J, 2005, P ICASSP MARCH; Austin J. L., 1962, DO THINGS WORDS; BANGALORE S, 2006, ICASSP 06; BARD EG, 1996, ICSLP 96, V3, P1958; Berger J. O., 1985, STAT DECISION THEORY; BILMES J, 2003, HUM LANG TECHN C EDM; Breiman L., 1984, CLASSIFICATION REGRE; Brill Eric, 1993, THESIS U PENNSYLVANI; CARLETTA J, 2005, MULT INT REL MACH LE, P11; Carletta J, 1997, COMPUT LINGUIST, V23, P13; COHEN W, 1996, 13 NAT C ART INT AAA, V1, P709; Cottrell M, 1998, NEUROCOMPUTING, V21, P119, DOI 10.1016/S0925-2312(98)00034-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Daelemans W, 2003, TIMBL TILBURG MEMORY; Dhillon R. B. S., 2004, TR04002 INT COMP SCI; Dielmann A, 2007, INT CONF ACOUST SPEE, P133; DOUGLAS PT, 2004, 37 ANN HAW INT C SYS; GARNER PN, 1996, ICSLP 96, V3, P1880; Godfrey J. J., 1992, ICASSP 92 IEEE INT C, V1, P517; Grau S., 2004, 9 INT C SPEECH COMP, P495; Haykin S., 1999, NEURAL NETWORKS COMP, V2nd; IVANOVA EI, 2005, AKTUALNYE PROBLEMY B, P79; JANIN A, 2003, ICASSP 2003, P364; Jekat S., 1995, 65 VERBM; JEONG M, 2006, JOINTLY PREDICTING D; JI G, 2005, P ICASSP PHIL US, V1, P33; Jurafsky D., 1997, 9701 U COL I COGN SC; KEIZER S, 2002, DIALOGUE ACT CLASSIF; Keizer S. A. R., 2002, 3 ACL SIGDIAL WORKSH, P88; Kohonen T., 1995, SPRINGER SERIES INFO, V30; KOLAR J, 2007, INTERSPEECH 2007, P1621; Kral Pavel, 2007, Journal of Multimedia, V2, DOI 10.4304/jmm.2.3.1-8; LANGLAIS P, 1995, THESIS U AVIGNON PAY; LENDVAI P, 2003, EACL 03 WORKSH DIAL, P69; Levin L., 2003, 4 SIGDIAL WORKSH DIS; Liu Y., 2004, THESIS PURDUE U; MacIntyre R, 1995, DYSFLUENCY ANNOTATIO; MANA N, 2003, EUROSPEECH 2003; MARTIN P, 1987, LINGUISTICS, V2, P925; Mast M., 1996, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing; QUANG VM, 2007, INTERSPEECH 2007, P2257; REITHINGER N, 1995, 33 ANN M ASS COMP LI, P116; REITHINGER N, 1997, EUROSPEECH 97, P2235; RIES K, 1999, ICASSP 99, V3, P497; ROSSET S, 2008, COMMUNICATION; ROTARU M, 2002, DIALOG ACT TAGGING U; SAMUEL K, 1998, 17 INT C COMP LING M, V2, P1150; SANCHIS E, 2002, 2 INT C HYBR INT SYS, P644; Shriberg E., 1998, LANG SPEECH, V41, P439; Shriberg E, 2000, SPEECH COMMUN, V32, P127, DOI 10.1016/S0167-6393(00)00028-5; Stolcke A., 1998, Applying Machine Learning to Discourse Processing. Papers from the 1998 AAAI Symposium; Stolcke A., 1996, P INT C SPOK LANG PR, P1005, DOI 10.1109/ICSLP.1996.607773; Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737; TUR G, 2006, MODEL ADAPTATION DIA; van den Bosch A, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P499; WEBB N, 2005, CS0501 U SHEFF DEP C; Woller J., 1996, BASICS MONTE CARLO S; WRIGHT H, 1998, ICSLP 98, V4, P1403; Zimmermann M, 2006, LECT NOTES COMPUT SC, V4299, P190	64	0	0	0	1	SLOVAK ACAD SCIENCES INST INFORMATICS	BRATISLAVA	DUBRAVSKA CESTA 9, 84237 BRATISLAVA, SLOVAKIA	1335-9150			COMPUT INFORM	Comput. Inform.		2010	29	2					227	250				24	Computer Science, Artificial Intelligence	Computer Science	623OR	WOS:000279752200004		
J	Marini, F				Marini, Federico			Classification Methods in Chemometrics	CURRENT ANALYTICAL CHEMISTRY			English	Article						Pattern recognition; Classification; Chemometrics; Discriminant analysis; Class modeling	SUPERVISED PATTERN-RECOGNITION; CLASS-MODELING TECHNIQUES; MULTILAYER FEEDFORWARD NETWORKS; ARTIFICIAL NEURAL-NETWORKS; SOLVING CHEMICAL PROBLEMS; OLIVE OIL VARIETIES; FLUORESCENCE SPECTROSCOPY; GEOGRAPHICAL ORIGIN; AUTHENTICATION; DISCRIMINATION	Pattern recognition methods, i.e. the methods concentrating on the possibility of assigning an object to a class based on the result of a set of measurements are ubiquitous in chemometrics. In this paper, the main chemometric classification methods are discussed in terms of their nature, behavior, advantages and drawbacks. Both parametric and non parametric or discriminant and modeling techniques are illustrated together with a discussion of some applications to real world problems.	Univ Roma La Sapienza, Dept Chem, I-00185 Rome, Italy	Marini, F (reprint author), Univ Roma La Sapienza, Dept Chem, Piazzale Aldo Moro 5, I-00185 Rome, Italy.	fmmonet@hotmail.com		Marini, Federico/0000-0001-8266-1117			Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Bellanti F, 2008, MICROCHEM J, V88, P113, DOI 10.1016/j.microc.2007.11.019; Bishop C.M., 1995, NEURAL NETWORKS PATT; Brodnjak-Voncina D, 2002, ANAL CHIM ACTA, V462, P87, DOI 10.1016/S0003-2670(02)00298-2; Bucci R, 2002, J AGR FOOD CHEM, V50, P413, DOI 10.1021/jf010696v; Checa-Moreno R, 2008, TALANTA, V75, P697, DOI 10.1016/j.talanta.2007.12.020; Christensen JH, 2007, J CHROMATOGR A, V1169, P1, DOI 10.1016/j.chroma.2007.08.077; COOMANS D, 1982, ANAL CHIM ACTA, V136, P15, DOI 10.1016/S0003-2670(01)95359-0; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; De Benedetto GE, 2005, J CULT HERIT, V6, P205, DOI 10.1016/j.culher.2005.06004; DERDE MP, 1989, ANAL CHIM ACTA, V223, P19, DOI 10.1016/S0003-2670(00)84072-6; DERDE MP, 1986, ANAL CHIM ACTA, V184, P33, DOI 10.1016/S0003-2670(00)86468-5; Dixon SJ, 2007, CHEMOMETR INTELL LAB, V87, P161, DOI 10.1016/j.chemolab.2006.12.004; Duda R O, 2001, PATTERN CLASSIFICATI; Fisher RA, 1936, ANN EUGENIC, V7, P179; Forina M, 2008, CHEMOMETR INTELL LAB, V93, P132, DOI 10.1016/j.chemolab.2008.05.003; Garcia JCR, 2006, J AGR FOOD CHEM, V54, P7206, DOI 10.1021/jf060823t; Gasteiger J., 1999, NEURAL NETWORKS CHEM; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T; Kohonen Teuvo, 2001, SELF ORGANIZING MAPS; Kowalkowski T, 2007, J ENVIRON SCI HEAL A, V42, P421, DOI 10.1080/10934520601187336; KOWALSKI BR, 1972, J AM CHEM SOC, V94, P5632, DOI 10.1021/ja00771a016; KOWALSKI BR, 1975, NATURWISSENSCHAFTEN, V62, P10; KVASNICKA V, 1993, J AM CHEM SOC, V115, P1495, DOI 10.1021/ja00057a039; Lukasiak BM, 2007, CHEMOMETR INTELL LAB, V87, P18, DOI 10.1016/j.chemolab.2006.01.003; Marini F, 2006, CHEMOMETR INTELL LAB, V80, P140, DOI 10.1016/j.chemolab.2005.05.002; Marini F, 2004, CHEMOMETR INTELL LAB, V73, P85, DOI 10.1016/j.chemolab.2003.12.007; Marini F, 2004, ANAL CHIM ACTA, V510, P231, DOI 10.1016/j.aca.2004.01.009; Marini F, 2003, EUR J LIPID SCI TECH, V105, P697, DOI 10.1002/ejlt.200300797; Marini F, 2006, CHEMOMETR INTELL LAB, V84, P164, DOI 10.1016/j.chemolab.2006.04.017; Marini F, 2003, MICROCHEM J, V74, P239, DOI 10.1016/S0026-265X(03)00028-6; Marini F, 2004, ANAL CHIM ACTA, V515, P117, DOI 10.1016/j.aca.2004.01.013; McLachlan G. J., 1992, DISCRIMINANT ANAL ST; Melssen W, 2006, CHEMOMETR INTELL LAB, V83, P99, DOI 10.1016/j.chemolab.2006.02.003; NOMIKOS P, 1995, TECHNOMETRICS, V37, P41, DOI 10.2307/1269152; Norgaard L, 2007, J CHEMOMETR, V21, P451, DOI 10.1002/cem.1042; Pomerantsev AL, 2008, J CHEMOMETR, V22, P601, DOI 10.1002/cem.1147; Ramos PM, 2008, TALANTA, V75, P926, DOI 10.1016/j.talanta.2007.12.030; Stenlund H, 2008, ANAL CHEM, V80, P6898, DOI 10.1021/ac8005318; Todeschini R, 2007, CHEMOMETR INTELL LAB, V87, P3, DOI 10.1016/j.chemolab.2005.11.001; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS Q B, P207; Vandeginste B.G.M., 1998, HDB CHEMOMETRICS Q B, P649; Whelehan OP, 2006, CHEMOMETR INTELL LAB, V84, P82, DOI 10.1016/j.chemolab.2006.03.008; WOLD S, 1976, PATTERN RECOGN, V8, P127, DOI 10.1016/0031-3203(76)90014-5; Wold S., 1983, FOOD RES DATA ANAL, P147; Wold S., 1977, ACS SYM SER, V52, P243, DOI DOI 10.1021/BK-1977-0052.CH012; Wold S., 1983, LECT NOTES MATH, P286; ZUPAN J, 1991, ANAL CHIM ACTA, V248, P1, DOI 10.1016/S0003-2670(00)80865-X; Zupan J, 1997, CHEMOMETR INTELL LAB, V38, P1, DOI 10.1016/S0169-7439(97)00030-0	50	9	10	2	6	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1573-4110			CURR ANAL CHEM	Curr. Anal. Chem.	JAN	2010	6	1					72	79				8	Chemistry, Analytical	Chemistry	543TP	WOS:000273601800011		
J	da Costa, ES; Peres, RT; Almeida, J; Lecrevisse, Q; Arroyo, ME; Teodosio, C; Pedreira, CE; van Dongen, JJM; Orfao, A				da Costa, Elaine Sobral; Peres, Rodrigo Tosta; Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Pedreira, Carlos Eduardo; van Dongen, Jacques J. M.; Orfao, Alberto		EuroFlow Consortium	Harmonization of Light Scatter and Fluorescence Flow Cytometry Profiles Obtained After Staining Peripheral Blood Leucocytes for Cell Surface-Only Versus Intracellular Antigens with the Fix & Perm (TM) Reagent	CYTOMETRY PART B-CLINICAL CYTOMETRY			English	Article						light scatter; intracellular proteins; immunofluorescence; flow cytometry; cell fixation; automation; eigenvectors	ACUTE MYELOID-LEUKEMIA; CYTOPLASMIC ANTIGENS; MALIGNANT LEUKOCYTES; MYELOPEROXIDASE; CLASSIFICATION; EXPRESSION; DISORDERS; DIAGNOSIS; MEMBRANE; FIXATION	Staining for intracellular markers with the Fix & PerM (TM) reagent is associated with variations in the scatter properties of leucocytes, limiting automated analysis of flow cytometry (FCM) data. Here, we investigated those variables significantly contributing to changes in the light scatter, autofluorescence, and bcl2 staining characteristics of peripheral blood (PB) leucocytes, after fixation with Fix & Perm (TM). Our major aim was to evaluate a new mathematical approach for automated harmonization of FCM data from datafiles corresponding to aliquots of a sample treated with cell-surface-only versus Fix & Perm intracellular staining techniques. Overall, neither the anticoagulant used nor sample storage for <24 h showed significant impact on the light scatter and fluorescence properties of PB leucocytes; similarly, the duration of the fixation period (once >15 min were used) had a minimum impact on the FCM properties of PB leucocytes. Conversely, changes in cell/protein concentrations and the fixative/sample (vol/vol) ratio had a clear impact on the light scatter features of some populations of leucocytes. Accordingly, lower cell/protein concentrations were associated with lower scatter values, particularly for the neutrophils. Such changes could be partially corrected through the use of higher fixative to sample volume ratios. Despite the variable changes detected between aliquots of the same sample treated with cell surface-only versus intracellular staining procedures, the new mathematical approach here proposed and evaluated for automated harmonization of common parameters in both datafiles, could correct the FCM profiles of leucocytes derived from cells undergoing conventional fixation/permeabilization procedures, and made them indistinguishable from those corresponding to aliquots of the same sample treated with cell-surface-only staining techniques.	[Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Orfao, Alberto] USAL, CSIC, IBMCC, Ctr Invest Canc,Serv Gen Citometria, Salamanca 37007, Spain; [Almeida, Julia; Lecrevisse, Quentin; Elena Arroyo, Maria; Teodosio, Cristina; Orfao, Alberto] Univ Salamanca, Dept Med, E-37008 Salamanca, Spain; [da Costa, Elaine Sobral] Univ Fed Rio de Janeiro, Inst Pediat & Puericultura Martagao Gesteira, Rio De Janeiro, Brazil; [da Costa, Elaine Sobral] Univ Fed Rio de Janeiro, Programa Posgrad, Med Clin, Rio De Janeiro, Brazil; [Peres, Rodrigo Tosta; Pedreira, Carlos Eduardo] Univ Fed Rio de Janeiro, Sch Med, Rio De Janeiro, Brazil; [Peres, Rodrigo Tosta; Pedreira, Carlos Eduardo] Univ Fed Rio de Janeiro, COPPE, PEE, Engn Grad Program, BR-21945 Rio De Janeiro, Brazil; [van Dongen, Jacques J. M.] Erasmus MC, Dept Immunol, Rotterdam, Netherlands	Orfao, A (reprint author), USAL, CSIC, IBMCC, Ctr Invest Canc,Serv Gen Citometria, Paseo Univ Coimbra S-N,Campus Miguel Unamuno, Salamanca 37007, Spain.	orfao@usal.es	IBSAL, Secretaria/H-3719-2011; van Dongen, Jacques/F-8537-2015; Pedreira, Carlos Eduardo/I-5629-2013; Costa, Elaine/O-6523-2014	van Dongen, Jacques/0000-0001-7686-0021; Pedreira, Carlos Eduardo/0000-0002-9312-4023; Costa, Elaine/0000-0002-5340-5816	Prof. Nelson Spector (Department of Clinica Medica, Federal University of Rio de Janeiro, Brazil)	The authors thank Prof. Nelson Spector (Department of Clinica Medica, Federal University of Rio de Janeiro, Brazil) for his helpful support.	Basso G, 2001, HAEMATOLOGICA, V86, P675; BAUER KD, 1994, METHOD CELL BIOL, V41, P351; BENE MC, 1995, LEUKEMIA, V9, P1783; Braylan RC, 2001, CYTOMETRY, V46, P23, DOI 10.1002/1097-0320(20010215)46:1<23::AID-CYTO1033>3.0.CO;2-Z; BRUNO S, 1992, CYTOMETRY, V13, P496, DOI 10.1002/cyto.990130508; CATOVSKY D, 1992, LEUKEMIA, V6, P1; CLEVENGER CV, 1993, CLIN FLOW CYTOMETRY, P157; Costa ES, 2006, LEUKEMIA, V20, P1221, DOI 10.1038/sj.leu.2404241; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DRACH D, 1993, LEUKEMIA RES, V17, P455, DOI 10.1016/0145-2126(93)90102-Q; Duda R., 2001, PATTERN CLASSIFICATI, V2nd, P174; Francis C, 1996, CYTOMETRY, V25, P58, DOI 10.1002/(SICI)1097-0320(19960901)25:1<58::AID-CYTO7>3.0.CO;2-A; Gibbs G, 2005, CLIN LAB HAEMATOL, V27, P258, DOI 10.1111/j.1365-2257.2005.00703.x; Groeneveld K, 1996, LEUKEMIA, V10, P1383; ISLAM D, 1995, CYTOMETRY, V22, P128, DOI 10.1002/cyto.990220208; Jacobberger JW, 2000, IMMUNOPHENOTYPING, P361; Kappelmayer J, 2000, J IMMUNOL METHODS, V242, P53, DOI 10.1016/S0022-1759(00)00220-9; KNAPP W, 1994, CYTOMETRY, V18, P187, DOI 10.1002/cyto.990180402; Konikova E, 1998, NEOPLASMA, V45, P282; Lacombe F, 1997, LEUKEMIA, V11, P1878, DOI 10.1038/sj.leu.2400847; Lanza F, 1997, CYTOMETRY, V30, P134; Macey MG, 1999, CYTOMETRY, V38, P153, DOI 10.1002/(SICI)1097-0320(19990815)38:4<153::AID-CYTO2>3.0.CO;2-E; Millard I, 1998, CLIN CHEM, V44, P2320; Nakase K, 1998, CYTOMETRY, V34, P198, DOI 10.1002/(SICI)1097-0320(19980815)34:4<198::AID-CYTO4>3.0.CO;2-C; Pedreira CE, 2008, CYTOM PART A, V73A, P1141, DOI 10.1002/cyto.a.20638; PIZOLLO G, 1994, LEUKEMIA, V8, P672; Ruiz-Arguelles A, 2006, CYTOM PART B-CLIN CY, V70B, P39, DOI 10.1002/cyto.20083; SARTOR M, 1994, CYTOMETRY, V18, P119, DOI 10.1002/cyto.990180302; SCHIMENTI KJ, 1992, CYTOMETRY, V13, P48, DOI 10.1002/cyto.990130109; SLAPERCORTENBACH ICM, 1988, BLOOD, V72, P1639; STELZER GT, 1993, ANN NY ACAD SCI, V677, P265, DOI 10.1111/j.1749-6632.1993.tb38783.x; STEWART CC, 1992, CANCER, V69, P1543, DOI 10.1002/1097-0142(19920315)69:6+<1543::AID-CNCR2820691307>3.0.CO;2-O; STRANG G, 2006, LINEAR ALGEBRA ITS A, P243; STRANG G, 2006, LINEAR ALGEBRA ITS A, P80; Van Lochem EG, 1997, LEUKEMIA, V11, P2208, DOI 10.1038/sj.leu.2400862; VANZAANEN HCT, 1995, BRIT J HAEMATOL, V91, P55	36	3	3	0	6	WILEY-LISS	HOBOKEN	DIV JOHN WILEY & SONS INC, 111 RIVER ST, HOBOKEN, NJ 07030 USA	1552-4949			CYTOM PART B-CLIN CY	Cytom. Part B-Clin. Cytom.	JAN	2010	78B	1					11	20		10.1002/cyto.b.20486		10	Medical Laboratory Technology; Pathology	Medical Laboratory Technology; Pathology	538EW	WOS:000273168100003	19575389	
S	Aug, HH; Gopalkrishnan, V; Hoi, SCH; Ng, WK		Kitagawa, H; Ishikawa, Y; Li, Q; Watanabe, C		Aug, Hock Hee; Gopalkrishnan, Vivekanand; Hoi, Steven C. H.; Ng, Wee Keong			Adaptive Ensemble Classification in P2P Networks	DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PT I, PROCEEDINGS	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Conference on Database Systems for Advanced Applications	APR 01-04, 2010	Tsukuba, JAPAN				TO-PEER NETWORKS	Classification in P2P networks has become an important research problem in data mining due to the popularity of P2P computing environments. This is still an open difficult research problem due to a variety of challenges, such as non-i.i.d. data distribution, skewed or disjoint class distribution, satiability; peer dynamism and a synchronism. In this paper, we present a novel P2P Adaptive Classification Ensemble (PACE.) framework to perform classification in P2P networks. Unlike regular ensemble classification approaches, our new framework adapts to the test data. distribution and dynamically adjusts the voting scheme by combining a subset of classifiers/peers according to the test data example. In our approach, we implement the proposed PACE solution together with the state-of-the-art linear SVM as the base classifier for scalable P2P classification. Extensive empirical studies show that the proposed PACE method is both efficient and effective in improving classification performance over regular methods under various adverse conditions.	[Aug, Hock Hee; Gopalkrishnan, Vivekanand; Hoi, Steven C. H.; Ng, Wee Keong] Nanyang Technol Univ, Singapore, Singapore	Aug, HH (reprint author), Nanyang Technol Univ, Singapore, Singapore.		HOI, Steven Chu Hong/A-3736-2011; Ng, Wee Keong/A-3724-2011	Ng, Wee Keong/0000-0001-7106-2768			ANDONI A, 2006, FOCS, P459; Ang HH, 2008, LECT NOTES ARTIF INT, V5211, P55; ANG HH, 2008, VLDB WORKSH DBISP2P, P13; Arthur D., 2007, SODA 07, P1027; Asuncion A., 2007, UCI MACHINE LEARNING; BERCHTOLD S, 1998, IEEE INT C DAT ENG 1, P209; Bhaduri K., 2008, STAT ANAL DATA MININ, V1, P85, DOI 10.1002/sam.10006; Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331; Chan Philip, 1998, KNOWLEDGE DISCOVERY, P164; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Datta S, 2006, IEEE INTERNET COMPUT, V10, P18, DOI 10.1109/MIC.2006.74; Gorodetskiy V., 2006, HYBRID INFORM TECHNO, P224; Hsieh C. J., 2008, ICML, P408; Jordan MI, 1995, NEURAL NETWORKS, V8, P1409, DOI 10.1016/0893-6080(95)00014-3; Luo P, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P968; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; SIERSDORFER S, 2006, ECIR, P265	17	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-12025-1	LECT NOTES COMPUT SC			2010	5981		I				34	48				15	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BPO85	WOS:000279562400003		
S	Narvaez, F; Diaz, G; Romero, E		Marti, J; Oliver, A; Freixenet, J; Marti, R		Narvaez, Fabian; Diaz, Gloria; Romero, Eduardo			Automatic BI-RADS Description of Mammographic Masses	DIGITAL MAMMOGRAPHY	Lecture Notes in Computer Science		English	Proceedings Paper	10th International Workshop on Digital Mammography	JUN 16-18, 2010	Girona, SPAIN	Univ Girona, Comp Vision & Robot Grp		Automatic Annotation; BI-RADS; Computer Aided Diagnosis; Content-based Image Retrieval	COMPUTER-AIDED DIAGNOSIS; ZERNIKE MOMENTS; CLASSIFICATION	This paper presents a Call (Content Based Information Retrieval) framework for automatic description of mammographic masses according to the well known BI-RADS lexicon. Unlike other approaches, we do not attempt to segment masses but instead, we describe the regions an expert selects, after the series of rules defined in the BI-RADS lexicon. The content based retrieval strategy searches similar regions by automatically computing the Mahalanobis distance of feature vectors that describe main shape and texture characteristics of the selected regions. A description of a. test region is based on the BI-RADS description associated to the retrieved regions. The strategy was assessed in a set of 444 masses with different shapes and margins. Suggested descriptions were compared with a ground truth already provided by the data base, showing a precision rate of 82.6% for the retrieval task and a sensitivity rate of 80% for the annotation task.	[Narvaez, Fabian; Diaz, Gloria; Romero, Eduardo] Univ Nacl Colombia, Bioingenium Res Grp, Dept Med, Bogota, Colombia	Narvaez, F (reprint author), Univ Nacl Colombia, Bioingenium Res Grp, Dept Med, Bogota, Colombia.	frnarvaeze@unal.edu.co; gmdiazc@unal.edu.co; edromero@unal.edu.co		Diaz, Gloria/0000-0003-1028-9111			AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046; American college of Radiology (ACR), 1998, ILL BREAST IM REP DA; [Anonymous], 2007, AM CANC STAT; Belkasim S., 2004, 4 INT C COMP INF TEC, V1, P790; Bird R., 1992, RADIOLOGY, V178, P234; BOVIS K, 2002, MED IMAGE UNDERSTAND; Buseman S, 2003, CANCER, V97, P352, DOI 10.1002/cncr.11050; Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Gur D, 2004, RADIOLOGY, V233, P418, DOI 10.1148/radiol.2332040277; Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7; Heath M., 2001, P 5 INT WORKSH DIG M, P212; Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5; Maggio C. D., 2004, EUR J NUCL MED MO S1, V31, pS59; MARIAS K, 2005, P IEEE ENG MED BIOL; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; Petrick N, 1996, IEEE T MED IMAGING, V15, P59, DOI 10.1109/42.481441; PETROUDI S, 2003, IEEE INT C ENG MED B; Rangayyan RM, 2007, J FRANKLIN I, V344, P312, DOI 10.1016/j.jfranklin.2006.09.003; Rosa NA, 2008, IEEE ENG MED BIO, P406, DOI 10.1109/IEMBS.2008.4649176; Tao YM, 2007, P SOC PHOTO-OPT INS, V6514, pZ5141, DOI 10.1117/12.711528; TAO Y, 2008, P SPIE; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; VERMA K, 2002, IEEE T INF TECHNOL B, V16, P219; Wee CY, 2007, IMAGE VISION COMPUT, V25, P967, DOI 10.1016/j.imavis.2006.07.010; Zheng B, 2007, ACAD RADIOL, V14, P917, DOI 10.1016/j.acra.2007.04.012	26	2	2	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13665-8	LECT NOTES COMPUT SC			2010	6136						673	681				9	Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BSN74	WOS:000285030000091		
J	Pughineanu, C				Pughineanu, C.			Evaluation of the Performances of a Parallel Algorithm to Recognize the Patterns in Relation with the Sequential Variant	ELEKTRONIKA IR ELEKTROTECHNIKA			English	Article								C. Pughineanu. Evaluation of the Performances of a Parallel Algorithm to Recognize the Patterns in Relation with the Sequential Variant // Electronics and Electrical Engineering. - Kaunas: Technologija, 2010. - No. 9(105). - P. 65-68. To achieve an algorithm to efficiently recognize the patterns to return the best solution, we need an intensive processing of the entrance set data. In most cases there is a compromise between the taking over of the entrance set data and the algorithm execution time. The intensive processing of the entrance set data needs rather high calculation resources which cannot always be obtained from the ordinary calculation systems. In this paper we suggest the parallelization of an algorithm to recognize the patterns in scientific literature, its parallelization and the evaluation of this variant in relation to the sequential algorithm. This algorithm will be tested using a cluster formed of 28 nods, each nod having 2 quad core 2.33GHz processors. Bibl. 13 (in English; abstracts in English and Lithuanian).	Stefan Cel Mare Univ Suceava, Fac Elect Engn & Comp Sci, Suceava 720229, Romania	Pughineanu, C (reprint author), Stefan Cel Mare Univ Suceava, Fac Elect Engn & Comp Sci, Str Univ 13, Suceava 720229, Romania.						Alexa D, 2008, IET POWER ELECTRON, V1, P224, DOI 10.1049/iet-pel:20070149; Asuncion A., 2007, UCI MACHINE LEARNING; Ciufudean C, 2009, ELEKTRON ELEKTROTECH, P65; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dambrauskas A, 2008, ELEKTRON ELEKTROTECH, P25; JETINSKIS J, 2009, ELEKTRON ELEKTROTECH, P3; Kohonen T., 1988, SELF ORG ASS MEMORY; PENTIUC SG, 1997, APLICATII ALE RECUNO; Rata G, 2010, ELEKTRON ELEKTROTECH, P62; Pentiuc SG, 2010, ELEKTRON ELEKTROTECH, P87; Ungurean I, 2010, ELEKTRON ELEKTROTECH, P57; VANDATNEJAD H, 2009, ADV ELECTR COMPUT EN, V9, P22; Zamir O., 1998, RES DEV INFORM RETRI, P46	13	0	0	1	7	KAUNAS UNIV TECHNOLOGY	KAUNAS	KAUNAS UNIV TECHNOL, DEPT ELECTRONICS ENGINEERING, STUDENTU STR 50, KAUNAS, LT-51368, LITHUANIA	1392-1215			ELEKTRON ELEKTROTECH	Elektron. Elektrotech.		2010		9					65	68				4	Engineering, Electrical & Electronic	Engineering	708NH	WOS:000286368000014		
J	Yang, W; Triggs, B; Dai, DX; Xia, GS				Yang, Wen; Triggs, Bill; Dai, Dengxin; Xia, Gui-Song			Scene Segmentation with Low-Dimensional Semantic Representations and Conditional Random Fields	EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING			English	Article							MARKOV RANDOM-FIELDS; ENERGY MINIMIZATION; OBJECT RECOGNITION; FEATURE SPACE; GRAPH CUTS; CLASSIFICATION	This paper presents a fast, precise, and highly scalable semantic segmentation algorithm that incorporates several kinds of local appearance features, example-based spatial layout priors, and neighborhood-level and global contextual information. The method works at the level of image patches. In the first stage, codebook-based local appearance features are regularized and reduced in dimension using latent topic models, combined with spatial pyramid matching based spatial layout features, and fed into logistic regression classifiers to produce an initial patch level labeling. In the second stage, these labels are combined with patch-neighborhood and global aggregate features using either a second layer of Logistic Regression or a Conditional Random Field. Finally, the patch-level results are refined to pixel level using MRF or over-segmentation based methods. The CRF is trained using a fast Maximum Margin approach. Comparative experiments on four multi-class segmentation datasets show that each of the above elements improves the results, leading to a scalable algorithm that is both faster and more accurate than existing patch-level approaches.	[Yang, Wen; Dai, Dengxin] Wuhan Univ, Sch Elect Informat, Wuhan 430079, Peoples R China; [Triggs, Bill] Lab Jean Kuntzmann, AI Team, F-38402 Grenoble, France; [Xia, Gui-Song] TELECOM ParisTech, CNRS LTCI, F-75013 Paris, France	Yang, W (reprint author), Wuhan Univ, Sch Elect Informat, Wuhan 430079, Peoples R China.	yangwen@whu.edu.cn			Chinese National Natural Sciences Foundation [40801183, 60890074]; European Union [027978]	The authors would like to thank Professor T. Joachims of Cornell University for his help with SVMStruct. The research was supported in part by the Chinese National Natural Sciences Foundation Grants 40801183 and 60890074 and by European Union IST project 027978 CLASS.	Anguelov D, 2005, PROC CVPR IEEE, P169; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cao L., 2007, P IEEE 11 INT C COMP; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Criminisi A., 2004, MICROSOFT RES CAMBRI; Csurka G., 2008, P BRIT MACH VIS C; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Galleguillos C., 2008, P 26 IEEE C COMP VIS; Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x; Grauman K., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; He X., 2008, P 26 IEEE C COMP VIS; He X., 2006, P 9 EUR C COMP VIS, V1, P338; He X., 2008, ADV NEURAL INFORM PR; He XM, 2004, PROC CVPR IEEE, P695; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Joachims T., 2009, MACH LEARN, V76, P27; Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Kumar S., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Kyrki V, 2004, PATTERN RECOGN LETT, V25, P311, DOI 10.1016/j.patrec.2003.10.008; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282; Lazebnik S., 2006, P IEEE C COMP VIS PA, P2169; Li F., 2005, P 2005 IEEE COMP SOC, P524; Li W, 2006, P 23 INT C MACH LEAR, P577, DOI DOI 10.1145/1143844.1143917; Lin C., 2007, P 24 INT C MACH LEAR, P561, DOI 10.1145/1273496.1273567; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Quelhas P., 2005, Proceedings. Tenth IEEE International Conference on Computer Vision; Rabinovich A., 2007, P IEEE 11 INT C COMP; Rasiwasia N., 2008, P 26 IEEE C COMP VIS; Schroff F., 2008, P BRIT MACH VIS C; SCHROFF F, 2006, P IND C COMP VIS GRA; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Shotton J., 2008, P 26 IEEE C COMP VIS; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Szummer M., 2008, P 10 EUR C COMP VIS; Taskar B, 2006, J MACH LEARN RES, V7, P1627; Taskar B., 2005, P 22 INT C MACH LEAR, P896, DOI 10.1145/1102351.1102464; Torralba A., 2005, ADV NEURAL INFORM PR, P1401; Toyoda T, 2008, IEEE T PATTERN ANAL, V30, P1483, DOI 10.1109/TPAMI.2008.105; Tsochantaridis I., 2005, J MACHINE LEARNING R, V6; Tu Z., 2008, P 26 IEEE C COMP VIS; van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334; Verbeek J., 2007, P IEEE COMP SOC C CO; VERBEEK J, 2008, ADV NEURAL INFORM PR, P1553; Vishwanathan S., 2006, P 23 INT C MACH LEAR, P969, DOI 10.1145/1143844.1143966; Xing E., 2005, P 21 ANN C UNC ART I; Yang L., 2007, P IEEE COMP SOC C CO	50	0	0	2	6	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	1687-6180			EURASIP J ADV SIG PR	EURASIP J. Adv. Signal Process.		2010									196036	10.1155/2010/196036		14	Engineering, Electrical & Electronic	Engineering	760MF	WOS:000290327700001		
J	Govindarajan, M; Chandrasekaran, RM				Govindarajan, M.; Chandrasekaran, R. M.			Evaluation of k-Nearest Neighbor classifier performance for direct marketing	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Data mining; Cross-validation; k-Nearest Neighbor; Runtime; Accuracy		Text data mining is a process of exploratory data analysis. Classification maps data into predefined groups or classes. It is often referred to as supervised learning because the classes are determined before examining the data. This paper describes the proposed k-Nearest Neighbor classifier that performs comparative cross-validation for the existing k-Nearest Neighbor classifier. The feasibility and the benefits of the proposed approach are demonstrated by means of data mining problem: direct marketing. Direct marketing has become an important application field of data mining. Comparative cross-validation involves estimation of accuracy by either stratified k-fold cross-validation or equivalent repeated random subsampling. While the proposed method may have a high bias; its performance (accuracy estimation in our case) may be poor due to a high variance. Thus the accuracy with the proposed k-Nearest Neighbor classifier was less than that with the existing k-Nearest Neighbor classifier, and the smaller the improvement in runtime the larger the improvement in precision and recall. In our proposed method we have determined the classification accuracy and prediction accuracy where the prediction accuracy is comparatively high. (C) 2009 Elsevier Ltd. All rights reserved.	[Govindarajan, M.; Chandrasekaran, R. M.] Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India	Govindarajan, M (reprint author), Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.	govind_aucse@yahoo.com; aurmc@sify.com			All India Council for Technical Education, New Delhi	The authors gratefully acknowledge the authorities of Annamalai University for the facilities offered and encouragement to carry out this work. This part of work is Supported in part by the first author who got Career Award for Young Teachers (CAYT) grant from All India Council for Technical Education, New Delhi. They would also like to thank the reviewers for their Valuable remarks	Bauer C. L., 1988, J DIRECT MARKETING, V2, P16, DOI 10.1002/dir.4000020305; Blake C, 1998, UCI REPOSITORY MACHI; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR PAT; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; DUNHAM MH, 2003, DATA MINING INTRO AD, P90; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; HAN J, 2003, DATA MINING CONCEPTS, P359; HOTTA S, 2004, P 17 INT C PATT REC; ISHIIL N, 2005, P 2005 3 ACIS INT C; Jacobs C.E., 1995, P SIGGRAPH 95, P277, DOI 10.1145/218380.218454; JOVANOVIC N, 2002, MEMBER IEEE FDN PRED; Knuth D.E., 1973, ART COMPUTER PROGRAM; Kohavi R., 1995, P 14 INT JOINT C ART, P1137; Lee HJ, 2007, EXPERT SYST APPL, V33, P522, DOI 10.1016/j.eswa.2006.05.016; MADEIRA S, 2002, 1049001 IDMEC TU LIS; Mitchell T. M., 1997, MACHINE LEARNING; Phillips P.J., 1998, ADV NEURAL INFORM PR, V11, P803; Ross S. M., 1988, 1 COURSE PROBABILITY; SALTON G, 1971, SMART INFORM RETRIEV; SAMET H, 2003, P 12 INT C IM AN PRO; SOUSA JM, 2002, P 11 IEEE INT C FUZZ; TANA S, 2006, EXPERT SYSTEMS APPL, V30, P290; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V., 1998, STAT LEARNING THEORY; WISKOTT L, 1997, TPAMI, V19, P775; Zhu H., 2003, P 3 IEEE INT C DAT M	28	6	7	3	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174			EXPERT SYST APPL	Expert Syst. Appl.	JAN	2010	37	1					253	258		10.1016/j.eswa.2009.04.055		6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	516VI	WOS:000271571000029		
S	Perkovic, T; Cagalj, M; Saxena, N		Sion, R		Perkovic, Toni; Cagalj, Mario; Saxena, Nitesh			Shoulder-Surfing Safe Login in a Partially Observable Attacker Model	FINANCIAL CRYPTOGRAPHY AND DATA SECURITY	Lecture Notes in Computer Science		English	Proceedings Paper	14th Financial Cryptography and Data Security International Conference	JAN 25-28, 2010	Tenerife, SPAIN					Secure login methods based on human cognitive skills can be classified into two categories based on information available to a passive attacker: (i) the attacker fully observes the entire input and output of a login procedure, (ii) the attacker only partially observes the input and output. Login methods secure in the fully observable model imply very long secrets and/or complex calculations. In this paper, we study three simple PIN-entry methods designed for the partially observable attacker model. A notable feature of the first method is that the user needs to perform a very simple mathematical operation, whereas, in the other two methods, the user performs a simple table lookup. Our usability study shows that all the methods have reasonably low login times and minimal error rates. These results, coupled with low-cost hardware requirements (only earphones), are a significant improvement over existing approaches for this model [9,10]. We also show that side-channel timing attacks present a real threat to the security of login schemes based on human cognitive skills.	[Perkovic, Toni; Cagalj, Mario] Univ Split, FESB, Split, Croatia	Perkovic, T (reprint author), Univ Split, FESB, Split, Croatia.						BACKES M, 2008, IEEE S SEC PRIV MAY; Brooke J, 1996, USABILITY EVALUATION; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GOLLE P., 2007, P IEEE S SEC PRIV; Hatcher L., 2005, STEP BY STEP APPROAC; Hopper N.J., 2001, LNCS, V2248, P52; Kocher P., 1996, LECT NOTES COMPUTER, V1109, P104; KUBER R, 2006, INTERACTIVE EXPERIEN; SASAMOTO H, 2008, ACM C HIM FACT COMP; Tari F., 2006, SOUPS; WEINSHALL D., 2006, P IEEE S SEC PRIV; WILFONG GT, 1999, METHOD APPARTUS SECU; SCI BEHIND PASSFACES	13	4	4	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-14576-6	LECT NOTES COMPUT SC			2010	6052						351	358				8	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTC09	WOS:000286416700029		
J	Gayer, G				Gayer, Gabrielle			Perception of probabilities in situations of risk: A case based approach	GAMES AND ECONOMIC BEHAVIOR			English	Article						Distortion of probabilities; Case based decision theory; Similarity	PROSPECT-THEORY; SIMILARITY; DECISION; UNCERTAINTY; UTILITY; CHOICE	This paper provides a description of a possible mental process individuals go through in their attempt to comprehend stated probabilities in simple lotteries. The evaluation of probabilities is based on the following main components: lotteries encountered in the past, the realizations of these lotteries, and the similarity between stated probabilities. A probability is evaluated based on the experienced relative frequencies of outcomes that had that stated probability, as well as outcomes of other lotteries that had similar stated probabilities. This process may result in distortion of probabilities as observed in the literature, and in particular, in overvaluing low probabilities and undervaluing high probabilities. If the decision maker uses a less permissive similarity function as the size of memory grows, she will learn the real value of the stated probabilities. If, however, the similarity function is independent of memory, biases persist even when data are accumulated. (C) 2009 Elsevier Inc. All rights reserved.	Univ Haifa, Dept Econ, IL-31905 Haifa, Israel	Gayer, G (reprint author), Univ Haifa, Dept Econ, IL-31905 Haifa, Israel.	gabi.gayer@gmail.com					Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI 10.1007/BF02900741; Allais M, 1953, ECONOMETRICA, V21, P503, DOI 10.2307/1907921; Berger J. O., 1985, STAT DECISION THEORY; Billot A, 2008, MATH SOC SCI, V55, P107, DOI 10.1016/j.mathsocsci.2007.08.002; Billot A, 2005, ECONOMETRICA, V73, P1125, DOI 10.1111/j.1468-0262.2005.00611.x; Chew S. H., 1983, ECONOMETRICA, V51, P1065; COMBS B, 1979, JOURNALISM QUART, V56, P837; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; DEVROYE L, 1983, ANN STAT, V11, P896, DOI 10.1214/aos/1176346255; Devroye L., 1985, NONPARAMETRIC DENSIT; Duda R. O., 1973, PATTERN CLASSIFICATI; Gilboa I, 2003, ECONOMETRICA, V71, P1, DOI 10.1111/1468-0262.00388; Gilboa I, 2006, REV ECON STAT, V88, P433, DOI 10.1162/rest.88.3.433; Gilboa I, 2001, THEORY CASE BASED DE; GILBOA I, 1995, Q J ECON, V110, P605, DOI 10.2307/2946694; Guerdjikova A, 2008, GAME ECON BEHAV, V63, P107, DOI 10.1016/j.geb.2007.10.004; Hertwig R, 2004, PSYCHOL SCI, V15, P534, DOI 10.1111/j.0956-7976.2004.00715.x; TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Mosteller F, 1951, J POLIT ECON, V59, P371, DOI 10.1086/257106; Pagan A. R., 1999, NONPARAMETRIC ECONOM; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Prakasa-Rao B., 1983, NONPARAMETRIC FUNCTI; PRESTON MG, 1948, AM J PSYCHOL, V61, P183, DOI 10.2307/1416964; Quiggin J., 1982, J ECON BEHAV ORGAN, V3, P225; Rosenblatt M., 1956, ANN MATH STAT, V27, P642; RUBINSTEIN A, 1988, J ECON THEORY, V46, P145, DOI 10.1016/0022-0531(88)90154-8; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Von Neumann J, 1944, THEORY GAMES EC BEHA; Wakker PP, 2004, PSYCHOL REV, V111, P236, DOI 10.1037/0033-295X.111.1.236; YAARI ME, 1987, ECONOMETRICA, V55, P95, DOI 10.2307/1911158	34	6	6	0	3	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0899-8256			GAME ECON BEHAV	Games Econ. Behav.	JAN	2010	68	1					130	143		10.1016/j.geb.2009.05.002		14	Economics	Business & Economics	547ZP	WOS:000273928700010		
J	David-Tabibi, O; Netanyahu, NS; Rosenberg, Y; Shimoni, M		Branke, J		David-Tabibi, Omid; Netanyahu, Nathan S.; Rosenberg, Yoav; Shimoni, Moshe			Genetic Algorithms for Automatic Classification of Moving Objects	GECCO-2010 COMPANION PUBLICATION: PROCEEDINGS OF THE 12TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE			English	Proceedings Paper	12th Annual Genetic and Evolutionary Computation Conference (GECCO)	JUL 07-11, 2010	Portland, OR	Assoc Comp Machinery, Special Interest Grp Genet & Evolutionary Computat (ACM SIGEVO)		Genetic algorithms; parameter tuning; computer vision; automatic object recognition		This paper presents an integrated approach, combining a state-of-the-art commercial object detection system and genetic algorithms (GA)-based learning for automatic object classification. Specifically, the approach is based on applying weighted nearest neighbor classification to feature vectors extracted from the detected objects, where the weights are evolved due to GA-based learning. Our results demonstrate that this GA-based approach is considerably superior to other standard classification methods.	[David-Tabibi, Omid; Netanyahu, Nathan S.] Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel	David-Tabibi, O (reprint author), Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel.	mail@omiddavid.com; nathan@cs.biu.ac.il; yoav@protrack.co.il; moshe.shimoni@gmail.com					Bose B., 2004, CVPR; Chen L., 2008, AVSS 2008; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalal N., CVPR 2005; Duda R O, 2001, PATTERN CLASSIFICATI; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8	8	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-4503-0073-5				2010							2069	2070				2	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	BGA53	WOS:000322071400093		
S	Ghorbani, AA; Onut, IV		Romay, MG; Corchado, E; GarciaSebastian, MT		Ghorbani, Ali A.; Onut, Iosif-Viorel			Y-Means: An Autonomous Clustering Algorithm	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS, PT 1	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Hybrid Artificial Intelligence Systems	JUN 23-25, 2010	San Sebastian, SPAIN		Univ Pais Vasco	Clustering; Data mining; K-means; Machine learning; Unsupervised learning		This paper proposes an unsupervised clustering technique for data classification based on the K-means algorithm. The K-means algorithm is well known for its simplicity and low time complexity. However, the algorithm has three main drawbacks: dependency on the initial centroids, dependency on the number of clusters, and degeneracy. Our solution accommodates these three issues, by proposing an approach to automatically detect a semi-optimal number of clusters according to the statistical nature of the data. As a side effect; the method also makes choices of the initial centroid-seeds not critical to the clustering results. The experimental results show the robustness of the Y-means algorithm as well as its good performance against a set of other well known unsupervised clustering techniques. Furthermore, we study the performance of our proposed solution against different distance and outlier-detection functions and recommend the best combinations.	[Ghorbani, Ali A.; Onut, Iosif-Viorel] Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada	Ghorbani, AA (reprint author), Univ New Brunswick, Fac Comp Sci, Fredericton, NB E3B 5A3, Canada.						CHAN PK, 2005, LEARNING RULES CLUST, P81; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; Dunn J. C., 1973, Journal of Cybernetics, V3; FRIGGE M, 1989, AM STAT, V43, P50, DOI 10.2307/2685173; GIBSON HR, 1994, ELEMENTARY STAT; Guan Y., 2003, P CAN C EL COMP ENG, P1083; Han Jiawei, 2001, DATA MINING CONCEPTS; Hansen P, 2001, PATTERN RECOGN, V34, P405, DOI 10.1016/S0031-3203(99)00216-2; Jain A, 1988, ALGORITHMS CLUSTER D; Kohonen T., 1997, SELF ORG MAP; Lei JZ, 2004, SECOND ANNUAL CONFERENCE ON COMMUNICATION NETWORKS AND SERVICES RESEARCH, PROCEEDINGS, P190; Lin Y. T., 2001, PATTERN RECOGN, V34, P415; LIPPMAN RP, 1987, P ASSP MAGAZINE, V4, P4; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; MAHALANOBIS P, 2002, P NATL I SCI, V2, P49; *MIT LINC LAB, 1998, INTR DET EV DAT SET; Pelleg D., 2000, P 17 INT C MACH LEAR, P727; Portnoy L, 2001, P ACM CSS WORKSH DAT; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Spath H., 1980, CLUSTERING ANAL ALGO, P1980; *U CA IRV, 1999, KNOWL DISC DAT MIN D; WALPOLE RE, 1983, ELEMENTARY STAT CONC	24	1	1	0	5	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13768-6	LECT NOTES ARTIF INT			2010	6076						1	13				13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BTF66	WOS:000286842000001		
S	Tellaeche, A; Arana, R; Ibarguren, A; Martinez-Otzeta, JM		Romay, MG; Corchado, E; GarciaSebastian, MT		Tellaeche, A.; Arana, R.; Ibarguren, A.; Martinez-Otzeta, J. M.			Automatic Quality Inspection of Percussion Cap Mass Production by Means of 3D Machine Vision and Machine Learning Techniques	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS, PT 1	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Hybrid Artificial Intelligence Systems	JUN 23-25, 2010	San Sebastian, SPAIN		Univ Pais Vasco	3D imaging; high speed inspection; machine learning classifiers		The exhaustive quality control is becoming very important in the world's globalized market. One of these examples where quality control becomes critical is the percussion cap mass production. These elements must achieve a minimum tolerance deviation in their fabrication. This paper outlines a machine vision development using a 3D camera for the inspection of the whole production of percussion caps. This system presents multiple problems, such as metallic reflections in the percussion caps, high speed movement of the system and mechanical errors and irregularities in percussion cap placement. Due to these problems, it is impossible to solve the problem by traditional image processing methods, and hence, machine learning algorithms have been tested to provide a feasible classification of the possible errors present in the percussion caps.	[Tellaeche, A.; Arana, R.; Ibarguren, A.; Martinez-Otzeta, J. M.] Fdn Tekniker, Eibar 20600, Gipuzkoa, Spain	Tellaeche, A (reprint author), Fdn Tekniker, Av Otaola 20, Eibar 20600, Gipuzkoa, Spain.	atellaeche@tekniker.es; rarana@tekniker.es; aibarguren@tekniker.es; jmmartinez@tekniker.es	Martinez-Otzeta, Jose Maria/K-6464-2014	Martinez-Otzeta, Jose Maria/0000-0001-5015-1315			Boehnke K.E., 2008, THESIS POLITEHNICA U; Bosche F, 2010, ADV ENG INFORM, V24, P107, DOI 10.1016/j.aei.2009.08.006; Castillo E., 1997, MONOGRAPHS COMPUTER, P481; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Draper N. R., 1998, APPL REGRESSION ANAL; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; Gonzalez R.C., 2008, DIGITAL IMAGE PROCES, VThird; Jensen F. V, 2007, INFORM SCI STAT; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kuncheva L. I., 2004, COMBINING PATTERN CL; Leopold J, 2003, MEASUREMENT, V33, P179, DOI 10.1016/S0263-2241(02)00056-8; Li QG, 2010, MEAS SCI TECHNOL, V21, DOI 10.1088/0957-0233/21/1/015702; PICONRUIZ A, 2010, DYNA, V84, P733; Quinlan J., 1986, INDUCTION DECISION T, V1, P81, DOI DOI 10.1007/BF00116251; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Shakhnarovich G., 2005, NEAREST NEIGHBOR MET; Tellaeche A, 2008, PATTERN RECOGN, V41, P521, DOI 10.1016/j.pateog.2007.07.007	19	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13768-6	LECT NOTES ARTIF INT			2010	6076						270	277				8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	BTF66	WOS:000286842000033		
S	Hua, Q; Ji, AB; He, Q			IEEE	Hua, Qiang; Ji, Aibing; He, Qiang			Multiple Real-valued K Nearest Neighbor Classifiers System by Feature Grouping	IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS (SMC 2010)	IEEE International Conference on Systems Man and Cybernetics Conference Proceedings		English	Proceedings Paper	IEEE International Conference on Systems, Man and Cybernetics	OCT 10-13, 2010	Istanbul, TURKEY	IEEE			FEATURE SUBSETS	This paper proposes a method to fuse Real-valued K nearest neighbor classifier by feature grouping. Real-valued K nearest neighbor classifier can approximate continuous-valued target functious, which can provide more information than crisp K nearest neighbor classifier in fusion. In addition real-valued K nearest neighbor classifier is sensitive to feature perturbation. Therefore, when multiple real-valued K nearest neighbor classifiers are fused by feature grouping, the performance of the fusion is better than single classifier. In order to validate the performance of fusion, four datasets are selected from vel Repository. Experimental results show that the performance of fusion is better than single classifier and multiple classifier system by other perturbations.	[Hua, Qiang; Ji, Aibing] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Engn, Nanjing 210016, Peoples R China	Hua, Q (reprint author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Engn, Nanjing 210016, Peoples R China.	huaq@nuaa.edu.cn					[Anonymous], Croel repository; [Anonymous], UCI REP MACH LEARN D; Bay S. D., 1999, Intelligent Data Analysis, V3, DOI 10.1016/S1088-467X(99)00018-9; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Bryll R, 2003, PATTERN RECOGN, V36, P1291, DOI 10.1016/S0031-3203(02)00121-8; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Mitchell T. M., 2003, MACHINE LEARNING; Vishwath P., 2004, Information fusion, P239; Wang LJ, 2008, INT J INNOV COMPUT I, V4, P369	11	0	0	1	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1062-922X		978-1-4244-6588-0	IEEE SYS MAN CYBERN			2010												4	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Information Systems	Computer Science	BWU85	WOS:000295015304022		
S	Wu, QO; Tan, SB; Duan, MY; Cheng, XQ		Cheng, PJ; Kan, MY; Lam, W; Nakov, P		Wu, Qiong; Tan, Songbo; Duan, Miyi; Cheng, Xueqi			A Two-Stage Algorithm for Domain Adaptation with Application to Sentiment Transfer Problems	INFORMATION RETRIEVAL TECHNOLOGY	Lecture Notes in Computer Science		English	Proceedings Paper	6th Asia Information Retrieval Societies Conference	DEC 01-03, 2010	Taipei, TAIWAN	Natl Taiwan Univ, Natl Sci Council, Republ China, Minist Educ, Republ China		Domain Adaptation; Sentiment Classification; Information Retrieval	CLASSIFICATION; REFINEMENT; EM	Classification systems are typically domain-specific, and the performance decreases sharply when transferred from one domain to another domain. Building these systems involves annotating a large amount of data for every domain, which needs much human labor. So, a reasonable way is to utilize labeled data in one existing (or called source) domain for classification in target domain. To address this problem, we propose a two-stage algorithm for domain adaptation. At the first transition stage, we share the information between the source domain and the target domain to get some most confidently labeled documents in the target domain, and at the second transmission stage, we exploit them to label the target-domain data via following the intrinsic structure revealed by the target domain. The experimental results on sentiment data indicate that the proposed approach could improve the performance of domain adaptation dramatically.	[Wu, Qiong; Tan, Songbo; Duan, Miyi; Cheng, Xueqi] Chinese Acad Sci, Inst Comp Technol, Beijing 100864, Peoples R China	Wu, QO (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing 100864, Peoples R China.	wuqiong@software.ict.ac.cn; tansongbo@software.ict.ac.cn; duanmiyi@software.ict.ac.cn; cxq@ict.ac.cn	Cheng, Xueqi/F-1706-2010; Tan, Songbo/A-7450-2012				Andreevskaia A., 2008, ACL 2008, P290; AUE A, 2005, RANLP 2005; Carroll S.M., 1989, P IJCNN P, V1, P607; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cui H., 2006, AM ASS ART INT P 200, P1265; Dai W, 2007, AAAI, P540; Daume H, 2006, J ARTIF INTELL RES, V26, P101; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1; JIANG J, 2007, CIKM 2007, P401; JOACHIMS T, 1998, TEXT CATEGORIZATION, P137; Joachims T., 1999, TRANSDUCTIVE INFEREN, P200; LANQUILLON C, 2000, LNCS LNAI, V1910, P167; LEWIS D, 1992, THESIS AMHERST MA US; Luo P., 2008, CIKM 2008, P103; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pang B., 2002, EMNLP 02, V10, P79; QUINLAN JR, 1986, MACH LEARN, V1, P1, DOI DOI 10.1023/A:1022643204877; Tan S., 2005, CIKM 2005, P469; TAN S, 2009, ECIR 2009, P337; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tan SH, 2007, RAFFLES B ZOOL, pIII; WU Q, 2009, ACL 2009, P317; Xing DK, 2007, LECT NOTES ARTIF INT, V4702, P324; Zhou D., 2003, NIPS, P169	24	2	2	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17186-4	LECT NOTES COMPUT SC			2010	6458						443	453				11	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Computer Science	BUF65	WOS:000289174800043		
B	Kruatrachue, B; Choowong, T			IEEE	Kruatrachue, Boontee; Choowong, Teeratorn			Prototype Selection using Reinforcement Learning and Minimal Consistent Subset Identification guide	INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010)			English	Proceedings Paper	International Conference on Control, Automation and Systems (ICCAS 2010)	OCT 27-30, 2010	Gyeonggi do, SOUTH KOREA	Natl IT Ind Promot Agcy, Korean Federat Sci & Technol Soc, Korea Natl Tourism Org, Hyundai Heavy Ind Co, POSCO, LS Ind Syst Co, Samsung Heavy Ind Co, Autopower Co, Gangneung Wonju Natl Univ		reinforcement learning; prototype selection; minimal consistent subset; nearest neighbor classification	CLASSIFICATION	This paper try to apply Reinforcement Learning (RL) to a task with large number of states. This usually is a difficult task since RL has less chance to visit all state or has enough number of visit to learn average reward accurately. Moreover, RL may not be able to learn or obtain any optimal solution as RL learn by averaging rewards from each action performing in each state. In order to alleviate this RL learning problem, any solution to a task such as, non-optimal algorithm or heuristics can collaborate with RL by using their knowledge to prune the non-optimal action in each state. This reduces search space of RL and helps it learn faster. A Minimal consistent subset problem is used as an example to demonstrate how RL can learn faster with the help of other heuristics.	[Kruatrachue, Boontee; Choowong, Teeratorn] King Mongkuts Inst Technol Ladkrabang, Fac Engn, Bangkok, Thailand	Kruatrachue, B (reprint author), King Mongkuts Inst Technol Ladkrabang, Fac Engn, Bangkok, Thailand.	booontee@yahoo.com; teeraongawa@hotmail.com					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Sutton R.S., 1998, REINFORCEMENT LEARNI; *U CA DEP INF COMP, 1998, UCI MACH LEARN REP	5	0	0	0	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-89-93215-02-1				2010							2320	2323				4	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Automation & Control Systems; Computer Science; Engineering	BWU79	WOS:000294964400496		
S	Saeedmanesh, M; Izadi, T; Ahvar, E		Ao, SI; Castillo, O; Douglas, C; Feng, DD; Lee, JA		Saeedmanesh, M.; Izadi, T.; Ahvar, E.			HDM: A Hybrid Data Mining Technique for Stock Exchange Prediction	INTERNATIONAL MULTICONFERENCE OF ENGINEERS AND COMPUTER SCIENTISTS (IMECS 2010), VOLS I-III	Lecture Notes in Engineering and Computer Science		English	Proceedings Paper	International Multi-Conference of Engineers and Computer Scientists 2010	MAR 17-19, 2010	Hong Kong, PEOPLES R CHINA	IAENG Soc Artificial Intelligence, IAENG Soc Bioinformat, IAENG Soc Comp Sci, IAENG Soc Data Mining, IAENG Soc Elect Engn, IAENG Soc Imaging Engn, IAENG Soc Ind Engn, IAENG Soc Internet Comp & Web Serv, IAENG Soc Sci Comp, IAENG Soc Software Engn, IAENG Soc Wireless Networks		stock exchange; data mining; prediction	ARTIFICIAL NEURAL-NETWORKS; CLASSIFICATION; INDEX	This paper(3) addresses the accuracy of predictions in stock exchange using data mining methods. To do this we modeled the problem by means of a time series. After this, a novel data mining technique is used to classify data. The proposed technique combines the advantages of time series analysis and data mining approaches in order to enhance the prediction accuracy. In order to evaluate the proposed technique, it is compared with the well known data mining techniques. In comparisons we used the Dow Jones Industrial data for all methods to have fair comparison. Results show that the proposed technique has at least 34% improvement in prediction accuracy.	[Saeedmanesh, M.; Izadi, T.] Azad Univ, Dept Comp Engn, Mashhad, Iran	Saeedmanesh, M (reprint author), Azad Univ, Dept Comp Engn, Mashhad, Iran.	m.saeedmanesh@iau-aligudarz.ac.ir; t-izadi@iau-arak.ac.ir; ehssana2000@yahoo.com					Athitsos V, 2005, PROC CVPR IEEE, P486; Athitsos V., 2005, P CVPR 05 IEEE COMP; Baestaens D.J.E., 1996, FORECASTING FINANCIA, P254; Bauer R., 1994, GENETIC ALGORITHMS I; Caldwell R., 1997, P 1 INFFC FIN TECHN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Creedy J., 1997, NONLINEAR EC MODELS; Hann TH, 1996, NEUROCOMPUTING, V10, P323, DOI 10.1016/0925-2312(95)00137-9; Kamijo K., 1990, P INT JOINT C NEUR N, P215; Kantardzic M., 2003, DATA MINING CONCEPTS; Katz J.O., 1994, NEUROVEST J, V2, P5; Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0; Kohara K., 1997, International Journal of Intelligent Systems in Accounting, Finance and Management, V6, DOI 10.1002/(SICI)1099-1174(199703)6:1<11::AID-ISAF115>3.3.CO;2-V; Latourrette M, 2000, P 11 EUR C MACH LEAR, P238; Peng J, 2001, CVPR 01, P58; Quah TS, 1999, EXPERT SYST APPL, V17, P295, DOI 10.1016/S0957-4174(99)00041-X; Tang ZhaoHui, 2005, DATA MINING SQL SERV; Trippi R.R., 1992, J PORTFOLIO MANAGE, V19, P309; Tsaih R, 1998, DECIS SUPPORT SYST, V23, P161, DOI 10.1016/S0167-9236(98)00028-1; Weigend AS, 1993, TIME SERIES PREDICTI; Witten I.H., 2000, DATA MINING PRACTICA; Yoon Y., 1991, P 24 ANN HAW INT C S, P156; YU XH, 1992, IEEE T NEURAL NETWOR, V3, P1019, DOI 10.1109/72.165604; Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7; Zhang H., 2006, CVPR, P2126	25	0	0	0	0	INT ASSOC ENGINEERS-IAENG	HONG KONG	UNIT1, 1-F, 37-39 HUNG TO ROAD, KWUN TONG, HONG KONG, 00000, PEOPLES R CHINA	2078-0958		978-988-17012-8-2	LECT NOTES ENG COMP			2010							587	592				6	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	BAB67	WOS:000303703800108		
J	Yang, CH; Chuang, LY; Yang, CH				Yang, Cheng-Huei; Chuang, Li-Yeh; Yang, Cheng-Hong			IG-GA: A Hybrid Filter/Wrapper Method for Feature Selection of Microarray Data	JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING			English	Article						Feature selection; Information gain (IG); Genetic algorithms (GA); K-nearest neighbor (K-NN); Leave-one-out cross-validation (LOOCV)	GENETIC ALGORITHMS; CLASSIFICATION; INFORMATION	Gene expression profiles have great potential as a medical diagnostic tool since they represent the state of a cell at the molecular level. Available training data sets for classification of cancer types generally have a fairly small sample size compared to the number of genes involved. This fact poses an insurmountable problem to some classification methodologies due to training data limitations. Feature selection is considered a problem of global combinatorial optimization in machine learning, which reduces the number of features, removes irrelevant, noisy and redundant data, and results in acceptable classification accuracy. Hence, selecting relevant genes from the microarray data poses a formidable challenge to researchers due to the high-dimensionality of features, multi-class categories being involved, and the usually small sample size. To overcome this difficulty, a good selection method for genes relevant for sample classification is needed in order to improve prediction accuracy, and to avoid incomprehensibility due to the large number of genes investigated. In this paper, we proposed a filter method (information gain, IG) and a wrapper method (genetic algorithm, GA) for feature selection in microarray data sets. IG was used to select important feature subsets (genes) from all features in the gene expression data, and a GA was employed for actual feature selection. The K-nearest neighbor (K-NN) method with leave-one-out cross-validation (LOOCV) served as an evaluator of the IG-GA. The proposed method was applied and compared to eleven classification problems taken from the literature. Experimental results show that our method simplifies the number of gene expression levels effectively and either obtains higher classification accuracy or uses fewer features compared to other feature selection methods.	[Chuang, Li-Yeh] I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung 800, Taiwan; [Yang, Cheng-Huei] Natl Kaohsiung Marine Univ, Dept Elect Commun Engn, Kaohsiung 811, Taiwan; [Yang, Cheng-Hong] Toko Univ, Dept Network Syst, Chiayi 613, Taiwan; [Yang, Cheng-Hong] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan	Chuang, LY (reprint author), I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung 800, Taiwan.	chuang@isu.edu.tw; chyang@cc.kuas.edu.tw	Chuang, Li-Yeh/E-5005-2011; Yang, Cheng-Hong/M-7984-2013	Yang, Cheng-Hong/0000-0002-2741-0072	National Science Council in Taiwan [NSC 94-2622-E-151-025-CC3, NSC 94-2311-B037-001, NSC 93-2213-E-214-037, NSC 92-2213-E-214-036]	This work was partly supported by the National Science Council in Taiwan under grants NSC 94-2622-E-151-025-CC3, NSC 94-2311-B037-001, NSC 93-2213-E-214-037, and NSC 92-2213-E-214-036.	BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2000, P 13 ANN C COMP LEAR, P35; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN, P1; Davis L., 1990, MACH LEARN, V117; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Dias AHF, 2002, IEEE T MAGN, V38, P1133, DOI 10.1109/20.996290; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Goldberg D.E., GENETIC ALGORITHMS S; Hodges J., 1951, 4 USAF SCH AV MED, P261; Holland J., 1992, ADAPTATION NATURE AR; HOU ESH, 1994, IEEE T PARALL DISTR, V5, P113, DOI 10.1109/71.265940; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; KIM S, 2001, P 2001 C EV COMP, V2, P1253; Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255; Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131; Martin-Valdivia MT, 2008, INFORM PROCESS MANAG, V44, P1146, DOI 10.1016/j.ipm.2007.09.014; Mitchell T. M., 1997, MACHINE LEARNING; MUKRAS R, 2007, P IJCAI TEXTL WORKSH; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Platt JC, 2000, ADV NEUR IN, V12, P547; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; TSAI CF, 2002, P JOINT C INF SCI, V3, P362; Turing A. M., 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433; Vafaie H., 1992, Proceedings. Fourth International Conference on Tools with Artificial Intelligence, TAI '92 (Cat. No. 92CH3203-7), DOI 10.1109/TAI.1992.246402; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; Zhang HB, 2002, PATTERN RECOGN, V35, P701, DOI 10.1016/S0031-3203(01)00046-2; Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267	31	4	4	0	4	DEPT BIOMEDICAL ENGINEERING	TAINAN CITY	NAT CHENG KUNG UNIV, NO 1 UNIVERSITY RD, TAINAN CITY, TAIWAN 701, PEOPLES R CHINA	1609-0985			J MED BIOL ENG	J. Med. Biol. Eng.		2010	30	1					23	28				6	Engineering, Biomedical	Engineering	571HU	WOS:000275743700003		
J	Mariolis, IG; Dermatas, ES				Mariolis, I. G.; Dermatas, E. S.			Automated assessment of textile seam quality based on surface roughness estimation	JOURNAL OF THE TEXTILE INSTITUTE			English	Article						machine vision; seam pucker; quality control; kNNc		In this paper the issue of automated seam quality control is addressed, focusing especially on seam pucker evaluation. Currently this task is accomplished by human experts considering five grades of quality. The proposed method estimates surface roughness of seam specimens producing robust and efficient novel features highly correlated to quality grades (QGs). At the initial stage, oblique illumination is applied and two-dimensional images of the specimens are acquired. The images are automatically rotated and centered in respect to the seam line and segmented into four regions. Each region produces an intensity curve through averaging, and roughness estimation is performed based on intensity mean deviation. Finally, a QG is assigned to each specimen using a k-nearest neighbor classifier (kNNc). A data set containing 211 seam specimens, created by two different kinds of fabric, has been used for testing and a correct classification rate of 81.04% has been produced matching up to the performance of human experts.	[Mariolis, I. G.; Dermatas, E. S.] Univ Patras, Dept Elect Engn & Comp Sci, Patras 26500, Greece	Mariolis, IG (reprint author), Univ Patras, Dept Elect Engn & Comp Sci, Patras 26500, Greece.	mariolis@george.wcl2.ee.upatras.gr		Mariolis, Ioannis/0000-0002-9507-5026			Aibara T, 1999, P SOC PHOTO-OPT INS, V3652, P110, DOI 10.1117/12.341130; Bahlmann C, 1999, PATTERN RECOGN, V32, P1049, DOI 10.1016/S0031-3203(98)00128-9; Cohen J, 1960, EDUC PSYCHOL MEAS, V20, P46; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; *ISO DIS, 1981, 7770 ISODIS; Kang TJ, 2005, TEXT RES J, V75, P751, DOI 10.1177/0040517505058855; Koehl L, 2007, STUD COMP INTELL, P39; Kohavi R., 1995, P 14 INT JOINT C ART, V2, P1137; Krause E. F., 1987, TAXICAB GEOMETRY; Mariolis IG, 2006, 37 INT S NOV TEXT LJ; Seber G. A. F., 1984, MULTIVARIATE OBSERVA; Spath H., 1985, CLUSTER DISSECTION A; Witten H., 2005, DATA MINING PRACTICA, V2nd; Zaouali R, 2007, J TEXT I, V98, P443, DOI 10.1080/00405000701489156	14	2	2	0	6	TAYLOR & FRANCIS LTD	ABINGDON	4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0040-5000			J TEXT I	J. Text. Inst.		2010	101	7					653	659	PII 923153509	10.1080/00405000902732883		7	Materials Science, Textiles	Materials Science	612TA	WOS:000278924800008		
S	Yusof, Y; Rana, OF		Setchi, R; Jordanov, I; Howlett, RJ; Jain, LC		Yusof, Yuhanis; Rana, Omer F.			Classification of Software Artifacts Based on Structural Information	KNOWLEDGE-BASED AND INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS, PT IV	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	14th International Conference on Knowledge-Based and Intelligent Information and Engineering Systems	SEP 08-10, 2010	Cardiff, WALES	Cardiff Univ, Sch Engn, KES Int		classification; software metrics; decision tree; k-nearest neighborhood; discriminant analysis		Classification of software artifacts, in particularly the source code files, are currently performed by administrator of a repository. Even though there exist automated classification on these repositories, nevertheless existing approach focuses on semantic analysis of keywords found in the artifact. This paper presents the use of structural information, that is the software metrics, in determining the appropriate application domain for a particular artifact. Results obtained from the study show that there is a difference in the metrics' trend between files of different application domain. It is also learned that results obtained using k-nearest neighborhood outperformed C4.5 decision tree and the one generated based on Discriminant; Analysis in classifying files of database and graphics domain.	[Yusof, Yuhanis] Univ Utara Malaysia, Coll Arts & Sci, Sintok 06010, Kedah, Malaysia	Yusof, Y (reprint author), Univ Utara Malaysia, Coll Arts & Sci, Informat Technol Bldg, Sintok 06010, Kedah, Malaysia.	yuhanis@uum.edu.my; o.f.rana@cs.cardiff.ac.uk		Yusof, Yuhanis/0000-0002-2720-2441			Chung KP, 2005, INT CONF E BUS ENG, P346; Cohen S., 2003, P 29 VLDB C BERL GER; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; *DSFP, DSFP MOD FOR SVM SUP; FUCHS NE, 1992, SOFTWARE ENG J, V7, P323; Ganti V, 1999, COMPUTER, V32, P38, DOI 10.1109/2.781633; Kawaguchi S., 2004, Proceedings. 11th Asia-Pacific Software Engineering Conference; KAWAGUCHI S, 2002, P 6 INT WORKSH PRINC, P195; Klecka W., 1980, DISCRIMINANT ANAL; Kwon OW, 2003, INFORM PROCESS MANAG, V39, P25, DOI 10.1016/S0306-4573(02)00022-5; Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229; MARCUS A, 2004, WCRE 04, P214; NAGAPPAN N, 2004, MACH LEARN, P60; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Ruggieri S, 2002, IEEE T KNOWL DATA EN, V14, P438, DOI 10.1109/69.991727; SHAFIA, 2010, EUROPEAN J SCI RES, V41, P109; *U WAIK, WEK; Ugurel S., 2002, P 8 ACM SIGKDD INT C, P632; WALTERS S, 2005, CATALOGING CLASSIFIC, V41, P163, DOI 10.1300/J104v41n01_08; C C CODE COUNTER	21	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15383-9	LECT NOTES ARTIF INT			2010	6279						546	555				10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	BUI34	WOS:000289445700058		
S	Rathi, Y; Malcolm, J; Michailovich, O; Goldstein, J; Seidman, L; McCarley, RW; Westin, CF; Shenton, ME		Jiang, T; Navab, N; Pluim, JPW; Viegever, MA		Rathi, Yogesh; Malcolm, James; Michailovich, Oleg; Goldstein, Jill; Seidman, Larry; McCarley, Robert W.; Westin, Carl-Fredrik; Shenton, Martha E.			Biomarkers for Identifying First-Episode Schizophrenia Patients Using Diffusion Weighted Imaging	MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI 2010, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	13th International Conference on Medical Image Computing and Computer-Assisted Intervention	SEP 20-24, 2010	Beijing, PEOPLES R CHINA	MICCAI Soc	China Natl Convent Ctr		DENSITY-FUNCTION; TENSOR IMAGES; WHITE-MATTER; MRI; CLASSIFICATION; DECONVOLUTION; TRACTOGRAPHY; FRAMEWORK	Recent advances in diffusion weighted MR imaging (dMRI) has made it a tool of choice for investigating white matter abnormalities of the brain and central nervous system. In this work, we design a system that detects abnormal features (biomarkers) of first-episode schizophrenia patients and then classifies them using these features. We use two different models of the dMRI data, namely, spherical harmonics and the two-tensor model. The algorithm works by first computing several diffusion measures from each model. An affine-invariant representation of each subject is then computed, thus avoiding the need for registration. This representation is used within a kernel based feature selection algorithm to determine the biomarkers that are statistically different between the two populations. Confirmation of how well these biomarkers identify each population is obtained by using several classifiers such as, k-nearest neighbors, Parzen window classifier, and support vector machines to separate 21 first-episode patients from 20 age-matched normal controls. Classification results using leave-manyout cross-validation scheme are given for each representation. This algorithm is a first step towards early detection of schizophrenia.	[Rathi, Yogesh; Goldstein, Jill; Seidman, Larry; Westin, Carl-Fredrik; Shenton, Martha E.] Harvard Univ, Sch Med, Boston, MA 02115 USA	Rathi, Y (reprint author), Harvard Univ, Sch Med, Boston, MA 02115 USA.		McCarley, Robert/N-5562-2014	McCarley, Robert/0000-0001-5705-7495			Anderson AW, 2005, MAGNET RESON MED, V54, P1194, DOI 10.1002/mrm.20667; Barmpoutis A., 2009, NEUROIMAGE; BASSER PJ, 1994, BIOPHYS J, V66, P259; Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018; Budde MD, 2007, MAGN RESON MED, V57, P688, DOI 10.1002/mrm.21200; Caan MWA, 2006, MED IMAGE ANAL, V10, P841, DOI 10.1016/j.media.2006.07.006; Caprihan A, 2008, NEUROIMAGE, V42, P675, DOI 10.1016/j.neuroimage.2008.04.255; CHENEVERT TL, 1990, RADIOLOGY, V177, P401; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Davatzikos C, 2005, ARCH GEN PSYCHIAT, V62, P1218, DOI 10.1001/archpsyc.62.11.1218; Descoteaux M, 2007, MAGN RESON MED, V58, P497, DOI 10.1002/mrm.21277; Friedman JI, 2008, AM J PSYCHIAT, V165, P1024, DOI 10.1176/appi.ajp.2008.07101640; GRETTON A., 2008, J MACHINE LEARNING R, V1, P1; Jain A. K., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop; Jansons KM, 2003, INVERSE PROBL, V19, P1031, DOI 10.1088/0266-5611/19/5/303; Jian B, 2007, IEEE T MED IMAGING, V26, P1464, DOI 10.1109/TMI.2007.907552; Khurd P, 2007, LECT NOTES COMPUT SC, V4584, P581; Kindlmann G, 2007, IEEE T MED IMAGING, V26, P1483, DOI 10.1109/TMI.2007.907277; Kubicki M, 2007, J PSYCHIAT RES, V41, P15, DOI 10.1016/j.jspychires.2005.05.005; Malcolm JG, 2009, LECT NOTES COMPUT SC, V5636, P126, DOI 10.1007/978-3-642-02498-6_11; McGlashan TH, 1996, SCHIZOPHRENIA BULL, V22, P197; Ozarslan E, 2005, MAGNET RESON MED, V53, P866, DOI 10.1002/mrm.20411; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403; Pohl KM, 2009, LECT NOTES COMPUT SC, V5636, P300, DOI 10.1007/978-3-642-02498-6_25; Schobel SA, 2009, ARCH GEN PSYCHIAT, V66, P938, DOI 10.1001/archgenpsychiatry.2009.115; Scholkopf B., 1999, ADV KERNEL METHODS S; Tournier JD, 2004, NEUROIMAGE, V23, P1176, DOI 10.1016/j.neuroimage.2004.07.037; Tuch DS, 2004, MAGNET RESON MED, V52, P1358, DOI 10.1002/mrm.20279	29	5	5	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15704-2	LECT NOTES COMPUT SC			2010	6361						657	665				9	Computer Science, Software Engineering; Computer Science, Theory & Methods; Neuroimaging; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	Computer Science; Neurosciences & Neurology; Imaging Science & Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging	BTS19	WOS:000287946100080		
S	Freiman, M; Sela, Y; Edrei, Y; Pappo, O; Joskowicz, L; Abramovitch, R		Karssemeijer, N; Summers, RM		Freiman, M.; Sela, Y.; Edrei, Y.; Pappo, O.; Joskowicz, L.; Abramovitch, R.			Multi-class SVM model for fMRI-based classification and grading of liver fibrosis	MEDICAL IMAGING 2010: COMPUTER - AIDED DIAGNOSIS	Proceedings of SPIE		English	Proceedings Paper	Conference on Medical Imaging 2010 - Computer-Aided Diagnosis	FEB 16-18, 2010	San Diego, CA	SPIE, Medtronic, Inc, Aeroflex, Inc, Tungsten Heavy Powder, Inc		Abdominal; Characterization; Machine Learning	MR ELASTOGRAPHY; VECTOR MACHINES; BIOPSY; DIAGNOSIS; PERFUSION; HYPERCAPNIA; HYPEROXIA; CIRRHOSIS	We present a novel non-invasive automatic method for the classification and grading of liver fibrosis from fMRI maps based on hepatic hemodynamic changes. This method automatically creates a model for liver fibrosis grading based on training datasets. Our supervised learning method evaluates hepatic hemodynamics from an anatomical MRI image and three T2*-W fMRI signal intensity time-course scans acquired during the breathing of air, air-carbon dioxide, and carbogen. It constructs a statistical model of liver fibrosis from these fMRI scans using a binary-based one-against-all multi class Support Vector Machine (SVM) classifier. We evaluated the resulting classification model with the leave-one out technique and compared it to both full multi-class SVM and K-Nearest Neighbor (KNN) classifications. Our experimental study analyzed 57 slice sets from 13 mice, and yielded a 98.2% separation accuracy between healthy and low grade fibrotic subjects, and an overall accuracy of 84.2% for fibrosis grading. These results are better than the existing image-based methods which can only discriminate between healthy and high grade fibrosis subjects. With appropriate extensions, our method may be used for non-invasive classification and progression monitoring of liver fibrosis in human patients instead of more invasive approaches, such as biopsy or contrast-enhanced imaging.	[Freiman, M.; Sela, Y.; Joskowicz, L.] Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91905 Jerusalem, Israel	Freiman, M (reprint author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91905 Jerusalem, Israel.	freiman@cs.huji.ac.il					Annet L, 2007, J MAGN RESON IMAGING, V25, P122, DOI 10.1002/jmri.20771; Annet L, 2003, RADIOLOGY, V229, P409, DOI 10.1148/radiol.2292021128; Barasli H, 2008, HEPATOLOGY, V48, P1232, DOI 10.1002/hep.22394; Barash H, 2007, RADIOLOGY, V243, P727, DOI 10.1148/radiol.2433060433; BATTS KP, 1995, AM J SURG PATHOL, V19, P1409, DOI 10.1097/00000478-199512000-00007; Bonekamp S, 2009, J HEPATOL, V50, P17, DOI 10.1016/j.jhep.2008.10.016; Bravo AA, 2001, NEW ENGL J MED, V344, P495, DOI 10.1056/NEJM200102153440706; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Freiman M, 2008, LECT NOTES COMPUT SC, V5241, P85, DOI 10.1007/978-3-540-85988-8_11; Friedman SL, 2003, J HEPATOL, V38, pS38, DOI 10.1016/S0168-8278(02)00429-4; GARCIATSAO G, 1993, ANN INTERN MED, V118, P150; Hagiwara M, 2008, RADIOLOGY, V246, P926, DOI 10.1148/radiol.2463070077; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huwart L, 2006, NMR BIOMED, V19, P173, DOI 10.1002/nbm.1030; Kato H, 2007, AM J ROENTGENOL, V189, P117, DOI 10.2214/AJR.07.2070; Mazza E, 2008, LECT NOTES COMPUT SC, V5242, P726, DOI 10.1007/978-3-540-85990-1_87; NORD HJ, 1982, GASTROINTEST ENDOSC, V28, P102; Pandharipande PV, 2005, RADIOLOGY, V234, P661, DOI 10.1148/radiol.2343031362; PICCININO F, 1986, J HEPATOL, V2, P165, DOI 10.1016/S0168-8278(86)80075-7; Popov Y, 2005, J HEPATOL, V43, P1045, DOI 10.1016/j.jhep.2005.06.025; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Rohlfing T, 2004, MED PHYS, V31, P427, DOI 10.1118/1.1644513; Rouviere O, 2006, RADIOLOGY, V240, P440, DOI 10.1148/radiol.2402050606; Thorsten J., 1999, ADV KERNEL METHODS S, P169; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vapnik V. N., 1995, NATURE STAT LEARNING	27	0	0	1	2	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-8025-5	PROC SPIE			2010	7624								76240S	10.1117/12.841242		8	Engineering, Biomedical; Optics; Radiology, Nuclear Medicine & Medical Imaging	Engineering; Optics; Radiology, Nuclear Medicine & Medical Imaging	BSK55	WOS:000284752400026		
S	Chen, C; Chernoff, K; Karemore, G; Lo, P; Nielsen, M; Lauze, F		Dawant, BM; Haynor, DR		Chen, C.; Chernoff, K.; Karemore, G.; Lo, P.; Nielsen, M.; Lauze, F.			Classification in medical images using adaptive metric k-NN	MEDICAL IMAGING 2010: IMAGE PROCESSING	Proceedings of SPIE		English	Proceedings Paper	Conference on Medical Imaging 2010 - Image Processing	FEB 14-16, 2010	San Diego, CA	SPIE, Medtronic, Inc., Aeroflex, Inc., OpenXi, Tungsten Heavy Powder, Inc.		k-NN; metric; Mahalanobis distance; covariance matrix; cardiovascular disease; mammograms; breast cancer		The performance of the k-nearest neighborhoods (k-NN) classifier is highly dependent on the distance metric used to identify the k nearest neighbors of the query points. The standard Euclidean distance is commonly used in practice. This paper investigates the performance of k-NN classifier with respect to different adaptive metrics in the context of medical imaging. We propose using adaptive metrics such that the structure of the data is better described, introducing some unsupervised learning knowledge in k-NN. We investigated four different metrics are estimated: a theoretical metric based on the assumption that images are drawn from Brownian Image Model (BIM), the normalized metric based on variance of the data, the empirical metric is based on the empirical covariance matrix of the unlabeled data, and an optimized metric obtained by minimizing the classification error. The spectral structure of the empirical covariance also leads to Principal Component Analysis (PCA) performed on it which results the subspace metrics. The metrics are evaluated on two data sets: lateral X-rays of the lumbar aortic/spine region, where we use k-NN for performing abdominal aorta calcification detection; and mammograms, where we use k-NN for breast cancer risk assessment. The results show that appropriate choice of metric can improve classification.	[Chen, C.; Chernoff, K.; Karemore, G.; Lo, P.; Nielsen, M.; Lauze, F.] Univ Copenhagen, DIKU, Copenhagen, Denmark	Chen, C (reprint author), Univ Copenhagen, DIKU, Univ Pk 1, Copenhagen, Denmark.	chen@diku.dk					CHERNOFF K, 2009, THESIS U COPENHAGEN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Globerson A., 2005, ADV NEURAL INFORM PR, V18, P451; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P513; Hastie T, 2009, ELEMENTS STAT LEARNI, V2nd; Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT; Pedersen KS, 2003, LECT NOTES COMPUT SC, V2695, P281; SUZUKI K, 2010, ALGORITHMS, V3; Weinberger K. Q., 2006, P ADV NEUR INF PROC, P1473; Xiang SM, 2008, PATTERN RECOGN, V41, P3600, DOI 10.1016/j.patcog.2008.05.018; Xing E.P., 2003, ADV NEURAL INFORMATI, V15, P505; Yang L, 2007, P SOC PHOTO-OPT INS, V6514, pH5141, DOI 10.1117/12.710076	13	0	0	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-8024-8	PROC SPIE			2010	7623								76230S	10.1117/12.844338		9	Optics; Radiology, Nuclear Medicine & Medical Imaging	Optics; Radiology, Nuclear Medicine & Medical Imaging	BSO04	WOS:000285048800026		
J	Chuang, LY; Yang, CS; Wu, KC; Yang, CH				Chuang, L. -Y.; Yang, C. -S.; Wu, K. -C.; Yang, C. -H.			Correlation-based Gene Selection and Classification Using Taguchi-BPSO	METHODS OF INFORMATION IN MEDICINE			English	Article						Microarray data; correlation-based feature selection; Taguchi-binary particle swarm optimization; K-nearest neighbor	MICROARRAY DATA; CANCER CLASSIFICATION; EXPRESSION; PREDICTION; ALGORITHM; BIOINFORMATICS; IDENTIFICATION; OPTIMIZATION; CLASSIFIERS; INFORMATION	Background: Microarray data with reference to gene expression profiles have provided some valuable results related to a variety of problems, and contributed to advances in clinical medicine. Microarray data characteristically have a high dimension and small sample size, which makes it difficult for a general classification method to obtain correct data for classification. However, not every gene is potentially relevant for distinguishing the sample class. Thus, in order to analyze gene expression profiles correctly, feature (gene) selection is crucial for the classification process, and an effective gene extraction method is necessary for eliminating irrelevant genes and decreasing the classification error rate. Objective: The purpose of gene expression analysis is to discriminate between classes of samples, and to predict the relative importance of each gene for sample classification. Method: In this paper, correlation-based feature selection (CFS) and Taguchi-binary particle swarm optimization (TBPSO) were combined into a hybrid method, and the K-nearest neighbor (K-NN) with leave-one-out cross-validation (LOOCV) method served as a classifier for ten gene expression profiles. Results: Experimental results show that this hybrid method effectively simplifies feature selection by reducing the number of features needed. The classification error rate obtained by the proposed method had the lowest classification error rate for all of the ten gene expression data set problems tested. For six of the gene expression profile data sets a classification error rate of zero could be reached. Conclusion: The introduced method outperformed five other methods from the literature in terms of classification error rate. It could thus constitute a valuable tool for gene expression analysis in future studies.	[Yang, C. -H.] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan; [Chuang, L. -Y.] I Shou Univ, Inst Biotechnol & Chem Engn, Kaohsiung, Taiwan; [Yang, C. -S.] Natl Cheng Kung Univ, Inst Biomed Engn, Tainan 70101, Taiwan; [Yang, C. -S.] Chiayi Christian Hosp, Dept Plast Surg, Chiayi, Taiwan; [Wu, K. -C.] Natl Kaohsiung Univ Appl Sci, Dept Comp Sci & Informat Engn, Kaohsiung 807, Taiwan; [Yang, C. -H.] Toko Univ, Dept Network Syst, Chiayi, Taiwan	Yang, CH (reprint author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.	chyang@cc.kuas.edu.tw					Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Huerta EB, 2006, LECT NOTES COMPUT SC, V3907, P34; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Chang TC, 2006, INT J ADV MANUF TECH, V31, P164, DOI 10.1007/s00170-005-0180-0; Chen WC, 2008, EXPERT SYST APPL, V35, P843, DOI 10.1016/j.cswa.2007.07.037; Chuang LY, 2008, COMPUT BIOL CHEM, V32, P29, DOI 10.1016/j.compbiolchem.2007.09.005; Conover WJ, 1980, PRACTICAL NONPARAMET; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Deb K, 2003, BIOSYSTEMS, V72, P111, DOI 10.1016/S0303-2647(03)00138-2; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Fix E., 1951, TECHNICAL REPORT; Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Guyon I., 2003, Journal of Machine Learning Research, V3, DOI 10.1162/153244303322753616; Hall M.A., 1999, THESIS U WAIKATO; Huang HL, 2007, BIOSYSTEMS, V90, P78, DOI 10.1016/j.biosystems.2006.07.002; Inza I, 2004, ARTIF INTELL MED, V31, P91, DOI 10.1016/j.artmed.2004.01.007; KENNEDY J, 1997, 1997 IEEE INT C SYST, V4105, P4104; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kodaz H, 2009, EXPERT SYST APPL, V36, P3086, DOI 10.1016/j.eswa.2008.01.026; Kohavi R, 1997, ARTIF INTELL, V1, P273; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Liu H., 1998, FEATURE SELECTION KN; Liu XX, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-76; Loughrey J., 2005, RES DEV INTELLIGENT, VXXI, P33; Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424; Okun O, 2009, ARTIF INTELL MED, V45, P151, DOI 10.1016/j.artmed.2008.08.004; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060; REUNANEN J, 2003, J MACHINE LEARNING R, V3; Ross DT, 2000, NAT GENET, V24, P227, DOI 10.1038/73432; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1007/BF00993504; Secrest BR, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P198, DOI 10.1109/SIS.2003.1202268; Shi XH, 2005, INFORM PROCESS LETT, V93, P255, DOI 10.1016/j.ipl.2004.11.003; Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Sohn SY, 2007, PATTERN RECOGN, V40, P33, DOI 10.1016/j.patcog.2006.06.027; STONE M, 1974, J R STAT SOC B, V36, P111; Taguchi G, 2000, ROBUST ENG; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019; Tsai JT, 2004, IEEE T EVOLUT COMPUT, V8, P365, DOI 10.1109/TEVC.2004.826895; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Verron S, 2008, J PROCESS CONTR, V18, P479, DOI 10.1016/j.jprocont.2007.08.003; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001; WOLPERT DH, 1993, SFITR92035001; Wu Y, 2000, TAGUCHI METHODS ROBU; Xiong MM, 2001, GENOME RES, V11, P1878; Yang CH, 2008, LECT NOTES COMPUT SC, V5326, P112; YANG CS, IJCNN 2008, P2147; Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267	54	4	4	3	5	SCHATTAUER GMBH-VERLAG MEDIZIN NATURWISSENSCHAFTEN	STUTTGART	HOLDERLINSTRASSE 3, D-70174 STUTTGART, GERMANY	0026-1270			METHOD INFORM MED	Methods Inf. Med.		2010	49	3					254	268		10.3414/ME09-01-0010		15	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Computer Science; Health Care Sciences & Services; Medical Informatics	611MC	WOS:000278818400006	20135079	
S	Hoelzl, G		Phan, T; Montanari, R; Zerfos, P		Hoelzl, Gerold			A Personalised Body Motion Sensitive Training System Based on Auditive Feedback	MOBILE COMPUTING, APPLICATIONS AND SERVICES	Lecture Notes of the Institute for Computer Sciences Social Informatics and Telecommunications Engineering		English	Proceedings Paper	1st International Conference on Mobile Computing, Applications, and Services (MobiCASE 2009)	OCT 26-29, 2009	San Diego, CA	ICST				In this paper the architecture and functionality of a personalized body motion sensitive training system based on auditive feedback is discussed. The system supports recognition of body motion using body worn sensors and gives the user feedback about his or her current status in adaptively selecting audio files accompanying the speed and path of exercise.	Johannes Kepler Univ Linz, A-4040 Linz, Austria	Hoelzl, G (reprint author), Johannes Kepler Univ Linz, A-4040 Linz, Austria.	gerold.hoelzl@gmail.com					Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1; Beigl M., 2004, P 1 INT WORKSH NETW, P153; Bringmann B, 2005, LECT NOTES ARTIF INT, V3721, P46; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dideles M., 2003, CROSSROADS, V9; Estrin D., 2002, IEEE Pervasive Computing, V1, DOI 10.1109/MPRV.2002.993145; Gemperle F., 1998, INT S WEAR COMP, P116; Hainsworth S.W., 2003, TECHNIQUES AUTOMATED; Hay J. G., 1978, BIOMECHANICS SPORTS, P07632; Heinz E. A., 2006, P IEEE S COMP INT GA, P98; Jensen K., 2003, APPL SIGNAL PROCESSI, P87; Krassi B.A., 2001, P 12 C EXTR ROB; Lee S. W., 2001, CONTROL APPL 2001 CC, P1152; Lukowicz P, 2004, LECT NOTES COMPUT SC, V3001, P18; Lukowicz P., 2002, WEAR COMP IEEE INT S, P133; Lukowicz P, 2006, LECT NOTES COMPUT SC, V3968, P101	16	0	0	0	0	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1867-8211		978-3-642-12606-2	L N INST COMP SCI SO			2010	35						12	25				14	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Telecommunications	Computer Science; Telecommunications	BBJ27	WOS:000307044100002		
S	Rafique, U; Huang, SY		Dix, J; Witteveen, C		Rafique, Umair; Huang, Shell Ying			Preference Generation for Autonomous Agents	MULTIAGENT SYSTEM TECHNOLOGIES	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	8th International Workshop on Multi-Agent Systems Technologies	SEP 27-29, 2010	Leipzig, GERMANY			Autonomous Agents; BDI; Goal Generation; Preference Generation	LEARNING ALGORITHMS	An intelligent agent situated in an environment needs to know the preferred states it is expected to achieve or maintain so that it can work towards achieving or maintaining them. We refer to all these preferred states as "preferences". The preferences an agent has selected to bring about at a given time are called "goals". This selection of preferences as goals is generally referred to as "goal generation". Basic aim behind goal generation is to provide the agent with a way of getting new goals. Although goal generation results in an increase in the agent's knowledge about its goals, the overall autonomy of the agent does not increase as its goals are derived from its preferences (which are programmed). We argue that to achieve greater autonomy, an agent must be able to generate new preferences. In this paper we discuss how an agent can generate new preferences based on analogy between new objects and the objects it has known preferences for.	[Rafique, Umair; Huang, Shell Ying] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore	Rafique, U (reprint author), Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.	umai0001@ntu.edu.sg; assyhuang@ntu.edu.sg					AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Bratman M., 1987, INTENTION PLANS PRAC; Broersen J., 2002, COGNITIVE SCI Q, V2, P428; Clement B. J., 1999, Proceedings Sixteenth National Conference on Artificial Intelligence (AAI-99). Eleventh Innovative Applications of Artificial Intelligence Conference (IAAI-99); COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DIGNUM F, 2002, COGNITIVE SCI Q, V2; Maslow A. H., 1954, MOTIVATION PERSONALI; PEREIRA CD, 2008, P AAMAS 08 IFAAMAS, P397; RAFIQUE U, 2009, P ICAI 09, V2, P582; Reiss S, 2004, REV GEN PSYCHOL, V8, P179, DOI 10.1037/1089-2680.8.3.179; SIMON HA, 1967, PSYCHOL REV, V74, P29, DOI 10.1037/h0024127; Simpson R, 2006, LECT NOTES COMPUT SC, V4008, P71; THANGARAJAH J., 2002, AUSTR COMPUTER SCI C, V24, P259; Thangarajah J., 2003, P 18 INT JOINT C ART, P721; THANGARAJAH J, 2007, CP 07 WORKSH CONSTR; Thangarajah J., 2003, P 2 INT JOINT C AUT, P401; Thomason R. H., 2000, P 7 INT C PRINC KNOW, P702; van Riemsdijk M. Birna, 2008, P 7 INT C AUT AG MUL, P713; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256; Wilson DR, 1997, J ARTIF INTELL RES, V6, P1	20	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-16177-3	LECT NOTES ARTIF INT			2010	6251						173	184				12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BUF32	WOS:000289106100017		
J	Temel, T				Temel, Turgay			A NEW DIGITAL COCHLEA MODEL NEURO-SPIKE REPRESENTATION OF AUDITORY SIGNALS AND ITS APPLICATION TO CLASSIFICATION OF BAT-LIKE BIOSONAR ECHOES	NEURAL NETWORK WORLD			English	Article						Audio processing systems; pattern recognition and classification; cochlea model; spike coding	STATISTICS; TRAINS	For an improved neuro-spike representation of auditory signals within cochlea models, a new digital ARMA-type low-pass filter structure is proposed. It is compared to more conventional AR-type counterpart on a classification of biosonar echoes, in which echoes from various tree species insonified with a bat-like chirp call are converted to biologically plausible feature vectors. Next, parametric and non-parametric models of the class-conditional densities are built from the echo feature vectors. The models are deployed in single-shot and sequential-decision classification algorithms. The results indicate that the proposed ARMA filter structure offers an improved single-echo classification performance, which leads to faster sequential-decision making than its AR-type counterpart.	Bahcesehir Univ, Fac Engn, TR-34349 Istanbul, Turkey	Temel, T (reprint author), Bahcesehir Univ, Fac Engn, TR-34349 Istanbul, Turkey.	turgaytemel@hotmail.com					AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bishop C. M., 2006, PATTERN RECOGNITION; Carmena JM, 2004, INFORM SCIENCES, V161, P71, DOI 10.1016/j.ins.2003.03.009; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959; Davis S., 1980, IEEE T ACOUST SPEECH, V28, P357; Dempster A, 1977, J ROYAL STAT SOC B, V39, P38, DOI DOI 10.2307/2984875; Destexhe A, 2004, NATURE, V431, P789, DOI 10.1038/nature03011; Dragalin VP, 1999, IEEE T INFORM THEORY, V45, P2448, DOI 10.1109/18.796383; ELLIOT P, 2004, BIOL CONSERV, V120, P600, DOI 10.1016/j.biocon.2004.04.001; GONG G, 1986, J AM STAT ASSOC, V81, P108, DOI 10.2307/2287975; Grunwald JE, 2004, P NATL ACAD SCI USA, V101, P5670, DOI 10.1073/pnas.0308029101; Hafner V, 2005, ADAPT BEHAV, V13, P87, DOI 10.1177/105971230501300202; Kim SM, 2003, J ACOUST SOC AM, V114, P3179, DOI 10.1121/1.1624070; Kuc R, 2001, J ACOUST SOC AM, V110, P2198, DOI 10.1121/1.1401741; Llyod S., 1982, IEEE T INFORM THEORY, V28, P129; Lyon R. F., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing; LYON RF, 1988, IEEE T ACOUST SPEECH, V36, P1119, DOI 10.1109/29.1639; MEDDIS R, 1986, J ACOUST SOC AM, V79, P702, DOI 10.1121/1.393460; Mino H, 2007, IEEE T BIO-MED ENG, V54, P360, DOI 10.1109/TBME.2006.890486; MOORE GP, 1970, BIOPHYS J, V10, P876; MULLER R, 2000, P ICSC S INT SYST AP, P915; MULLER R, 2003, NETWORK-COMP NEURAL, V14, P596; Patterson R., 1996, ADV SPEECH HEARING L, V3; PERKEL DH, 1967, BIOPHYS J, V7, P419; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Roxin A, 2008, J NEUROSCI, V28, P10734, DOI 10.1523/JNEUROSCI.1016-08.2008; SANDERSO.AC, 1973, BIOPHYS J, V13, P218; Sanderson MI, 2003, J ACOUST SOC AM, V114, P1648, DOI 10.1121/1.1598195; Scott A., 2002, NEUROSCIENCE MATH PR; Slaney M., 1993, VISUAL REPRESENTATIO, P95; Tetzlaff T, 2008, NEURAL COMPUT, V20, P2133, DOI 10.1162/neco.2008.05-07-525; WANG M, 2006, THESIS U TUEBINGEN G; Zeddies DG, 2004, J ACOUST SOC AM, V116, P426, DOI 10.1121/1.1755237	34	0	0	3	5	ACAD SCIENCES CZECH REPUBLIC, INST COMPUTER SCIENCE	182 07 PRAGUE 8	POD VODARENSKOU VEZI 2, 182 07 PRAGUE 8, 00000, CZECH REPUBLIC	1210-0552			NEURAL NETW WORLD	Neural Netw. World		2010	20	2					223	239				17	Computer Science, Artificial Intelligence	Computer Science	593EA	WOS:000277434000004		
J	Boostani, R; Dehzangi, O; Jarchi, D; Zolghadri, MJ				Boostani, Reza; Dehzangi, Omid; Jarchi, Delaram; Zolghadri, Mansoor J.			AN EFFICIENT PATTERN CLASSIFICATION APPROACH: COMBINATION OF WEIGHTED LDA WITH WEIGHTED NEAREST NEIGHBOR	NEURAL NETWORK WORLD			English	Article						LDA; PCA; weighted nearest neighbor (WNN); weighted LDA (WLDA)	FACE RECOGNITION; RULE	Linear discriminant analysis (LDA) is a versatile method in all pattern recognition fields but it suffers from some limitations. In a multi-class problem, when samples of a class are far from other classes samples, it leads to bias of the whole decision boundaries of LDA in favor of the farthest class. To overcome this drawback, this study is aimed at minimizing this bias by redefining the between- and within-class scatter matrices via incorporating weight vectors derived from Fisher value of classes pairs. After projecting the input patterns into a lower-dimensional space in which the class samples are more separable, a new version of nearest neighbor (NN) method with an adaptive distance measure is employed to classify the transformed samples. To speed up the adaptive distance routine, an iterative learning algorithm that minimizes the error rate is presented. This efficient method is applied to six standard datasets driven from the UCI repository dataset and test results are evaluated from three aspects in terms of accuracy, robustness, and complexity. Results show the supremacy of the proposed two-layer classifier in comparison with the combination of different versions of LDA and NN methods from the three points of view. Moreover, the proposed classifier is assessed in the noisy environment of those datasets and the achieved results confirm the high robustness of the introduced scheme when compared to others.	[Boostani, Reza; Dehzangi, Omid; Jarchi, Delaram; Zolghadri, Mansoor J.] Shiraz Univ, Fac Elect & Comp Engn, Shiraz, Iran	Boostani, R (reprint author), Shiraz Univ, Fac Elect & Comp Engn, Shiraz, Iran.	boostani@shirazu.ac.ir; dehzangi@cse.shirazu.ac.ir; jarchi@cse.shirazu.ac.ir; zjahromi@shirazu.ac.ir		Zolghadri Jahromi, Mansoor/0000-0003-3815-1528			Asuncion A., 2007, UCI MACHINE LEARNING; BAILEY, 1978, IEEE T SYST MAN CYB, V8, P311; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, NEAREST NEIGHBOR NN; Duda R O, 2001, PATTERN CLASSIFICATI; Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6; Fisher RA, 1936, ANN EUGENIC, V7, P179; Fukunaga K, 1990, INTRO STAT PATTERN C; Goldberger J., 2004, NEURAL INFORM PROCES, V17, P513; JARCHI D, 2006, T ENG COMPUTATIONAL, V18, P18; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Jing XY, 2004, IEEE T SYST MAN CY B, V34, P1942, DOI 10.1109/TSMCB.2004.831770; LETTE F, 2007, J NEURAL ENG, V4, pR1; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; MACLEOD JES, 1987, IEEE T SYST MAN CYB, V17, P689, DOI 10.1109/TSMC.1987.289362; Pang YW, 2006, NEUROCOMPUTING, V69, P949, DOI 10.1016/j.neucom.2005.07.005; RASSON JP, 2000, J NEURAL NETWORK WOR, V10, P279; Sanz SS, 2009, NEURAL NETW WORLD, V19, P37; Wang Jing, 2006, Cancer Inform, V2, P87; Wang JG, 2006, PATTERN RECOGN, V39, P417, DOI 10.1016/j.patcog.2005.08.009; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER K, 2006, ADV NEURAL INFORM PR, P18; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982; Zuo WM, 2006, IEEE T SYST MAN CY B, V36, P946, DOI 10.1109/TSMCB.2005.863377	25	1	2	3	6	ACAD SCIENCES CZECH REPUBLIC, INST COMPUTER SCIENCE	182 07 PRAGUE 8	POD VODARENSKOU VEZI 2, 182 07 PRAGUE 8, 00000, CZECH REPUBLIC	1210-0552			NEURAL NETW WORLD	Neural Netw. World		2010	20	5					621	635				15	Computer Science, Artificial Intelligence	Computer Science	689GM	WOS:000284915500004		
J	Zhao, X; Saeedi, S; El-Sheimy, N; Syed, Z; Goodall, C			ION	Zhao, X.; Saeedi, S.; El-Sheimy, N.; Syed, Z.; Goodall, C.			Towards Arbitrary Placement of Multi-sensors Assisted Mobile Navigation System	PROCEEDINGS OF THE 23RD INTERNATIONAL TECHNICAL MEETING OF THE SATELLITE DIVISION OF THE INSTITUTE OF NAVIGATION (ION GNSS 2010)			English	Proceedings Paper	23rd International Technical Meeting of the Satellite Division of the Institute-of-Navigation (ION GNSS-2010)	SEP 21-24, 2010	Portland, OR					Multi-sensors assisted navigation system is one of the most promising solutions for GPS-denied areas. However, as the portable positioning device can be arbitrarily placed on the user's body, it violates the assumed condition of sensor enabled positioning: the alignment. This poses great challenge since sensors 'placement greatly impacts on the positioning solution. The paper attempts to solve this problem by classifying the placement mode from the accelerometer and gyro signals. Then the system adapts proper pedestrian dead reckoning algorithms according to the identified device placement. Six commonly used placement modes including belt, pocket, backpack, in-hand dangling, messaging and near the ear talking are considered as the study cases in this paper. Simple time and frequency domain features are extracted from the inertial sensors then some machine learning algorithms, such as k-nearest neighbour, artificial neural networks, and support vector machines are applied for classification. Subsequently, step detections can be conducted by selecting the most appropriate sensor. Stride length and heading can be further estimated. From some preliminary field test results, the placement-aware solution shows significant improvement over conventional pedestrian solutions. The system fits for a variety of applications in the mass market, such as E-911, personnel/patient monitoring, indoor positioning, and many other location-based services.	[Zhao, X.; Saeedi, S.; Syed, Z.] Univ Calgary, MMSS Res Grp, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada	Zhao, X (reprint author), Univ Calgary, MMSS Res Grp, Dept Geomat Engn, Calgary, AB T2N 1N4, Canada.						BEGG R, 2006, COMPUTATIONAL INTELL, P243; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FOODY GM, 2004, TRANSACTIONS, V42, P1335; KWAKKEL S, 2008, 20279 UCGE; MOGHAVVEMI M, 2000, POWER, V28, P167; Shin E.-H., 2005, 20219 UCGE; SYED ZF, 2009, 20288 UCGE; Zhao X., 2009, ION GNSS 2009 SAV GA	8	4	4	0	0	INST NAVIGATION	WASHINGTON	815 15TH ST NW, STE 832, WASHINGTON, DC 20005 USA							2010							556	564				9	Remote Sensing	Remote Sensing	BUY82	WOS:000290734900046		
S	Dragomir, EG		Vlada, M; Albeanu, G; Popovici, DM		Dragomir, Elia Georgiana			Teaching Performance Evaluation Using Supervised Machine Learning Techniques	PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON VIRTUAL LEARNING, ICVL 2010	Proceedings of the International Conference on Virtual learning		English	Proceedings Paper	5th International Conference on Virtual Learning	OCT 29-31, 2010	Targu Mures, ROMANIA	INTUITION Consortium Network Excellence Europe, Univ Bucharest, Natl Authority Sci Res, Autoritatea Natl Cercetare Stiintif, Univ Med Pharm Targu Mures, Siveco Romania, Intel Co	Univ Med & Pharm Targu Mures	Teaching performance evaluation; K-Nearest Neighbor; Support Vector Machine	SUPPORT VECTOR MACHINES	Teaching performance evaluation can be done using multiple sources, like students, peers and teachers themselves. Even though only peers have the substantive expertise for a relevant evaluation, it is generally well-known that students are qualified to assess some of the classroom teaching aspects: clarity of the presentation, interpersonal rapport with students etc. The core idea of this research is to study if there can be built a computational model that uses past students evaluation in order to predict future teaching performance assessments. There can be designed different system based on supervised machine learning techniques. In this paper there are built several models based on two classification techniques: K-Nearest Neighbor and Support Vector Machine with the purpose of finding a model that has the smaller classification error of the new cases.	[Dragomir, Elia Georgiana] Univ Petr Gas Ploiesti, Dept Informat, RO-100680 Ploiesti, Romania		elia.dragomir@yahoo.com	Dragomir, Elia Georgiana/C-1977-2015				Aleamoni L. M., 1981, STUDENT RATINGS OF I; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Hart P., 1967, IEEE TRANSACTIONS ON, VIT-13; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Joachims T., 1998, PROCEEDINGS OF THE E; Maglogiannis I., 2007, EMERGING ARTIFICIAL, P14; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Radhika Z., 2009, INT J COMPUTER THEOR, V1, P1793; Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799	10	0	0	1	1	BUCHAREST UNIVERSITY PRESS	BUCHAREST	SOS PANDURI NR 90-92, BUCHAREST, 050663, ROMANIA	1844-8933			PROC INT C VIRTUAL L			2010							390	394				5	Computer Science, Interdisciplinary Applications; Education & Educational Research	Computer Science; Education & Educational Research	BGP09	WOS:000323685800056		
B	Jin, X; Mukherjee, K; Gupta, S; Ray, A			ASME	Jin, Xin; Mukherjee, Kushal; Gupta, Shalabh; Ray, Asok			WAVELET-BASED FEATURE EXTRACTION FOR BEHAVIOR RECOGNITION IN MOBILE ROBOTS	PROCEEDINGS OF THE ASME DYNAMIC SYSTEMS AND CONTROL CONFERENCE 2010, VOL 1			English	Proceedings Paper	ASME Dynamic Systems and Control Conference	SEP 12-15, 2010	Cambridge, MA				TIME-SERIES ANALYSIS	This paper introduces a dynamic data-driven method for behavior recognition in mobile robots. The core concept of the paper is built upon the principle of symbolic dynamic filtering (SDF) that is used to extract relevant information in complex dynamical systems. The objective here is to identify the robot behavior from time-series data of piezoelectric sensor signals from the pressure sensitive floor in a laboratory environment. A symbolic feature extraction method is presented by partitioning of two-dimensional wavelet images of sensor time-series data. The K-nearest neighbors (k-NN) algorithm is used to identify the patterns extracted by SDF. The proposed method is validated by experimentation, on a networked robotics test bed to detect and identify the type and motion profile of mobile robots.	[Jin, Xin; Mukherjee, Kushal; Gupta, Shalabh; Ray, Asok] Penn State Univ, Dept Mech Engn, University Pk, PA 16802 USA	Ray, A (reprint author), Penn State Univ, Dept Mech Engn, University Pk, PA 16802 USA.	xuj103@psu.edu; kum162@psu.edu; szg107@psu.edu; axr2@psu.edu					Abry P., 1997, ONDELETTES TURBULENC; Buhl M, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.046213; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fukunaga K., 1990, STAT PATTERN RECOGNI; Gerkey BP, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P317; Gupta S, 2009, J STAT PHYS, V134, P337, DOI 10.1007/s10955-009-9679-3; Gupta S., 2007, PATTERN RECOGN, P17; Gupta S, 2007, MECH SYST SIGNAL PR, V21, P866, DOI 10.1016/j.ymssp.2005.08.022; Lee T. W., 1998, INDEPENDENT COMPONEN; Lind D., 1995, INTRO SYMBOLIC DYNAM; Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1; Pittner S, 1999, IEEE T PATTERN ANAL, V21, P83, DOI 10.1109/34.745739; Rajagopalan V, 2006, SIGNAL PROCESS, V86, P3309, DOI 10.1016/j.sigpro.2006.01.014; Ray A, 2004, SIGNAL PROCESS, V84, P1115, DOI 10.1016/j.sigpro.2004.03.011; Ray A., 2008, APPL PHYS LETT, V92; Ray S, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P233, DOI 10.1109/NNSP.2001.943128; Rosipal R, 2000, PERSP NEURAL COMP, P321	17	0	0	0	1	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA			978-0-7918-4417-5				2010							875	882				8	Automation & Control Systems; Engineering, Multidisciplinary	Automation & Control Systems; Engineering	BFG61	WOS:000319789100113		
S	Coelho, F; Braga, AP; Verleysen, M		Bloch, I; Cesar, RM		Coelho, Frederico; Braga, Antonio Padua; Verleysen, Michel			Multi-Objective Semi-Supervised Feature Selection and Model Selection Based on Pearson's Correlation Coefficient	PROGRESS IN PATTERN RECOGNITION, IMAGE ANALYSIS, COMPUTER VISION, AND APPLICATIONS	Lecture Notes in Computer Science		English	Proceedings Paper	15th Iberoamerican Congress on Pattern Recognition	NOV 08-11, 2010	Sao Paulo, BRAZIL	Brazilian Bioethanol Sci & Technol Lab, Brazilian Neural Networks Soc, Coordenacao Aperfeicoamento Pessoal Nivel Superior, Chilean Assoc Pattern Recognit, Natl Council Technol & Sci Dev, Cuban Assoc Pattern Recognit, Fundacao Amparo Pesquisa Estado Sao Paulo, Fed Univ ABC, Int Assoc Pattern Recognit, Inst Telecom, Telecom ParisTech, Mexican Assoc Comp Vision, Neural Comp & Robot, Portuguese Assoc Pattern Recognition, Spanish Assoc Pattern Recognit & Image Anal, Brazilian Comp Soc, Special Interest Grp Pattern Recognit, Univ Sao Paulo		Semi-supervised; feature selection; Pearson; Relief	CLASSIFICATION	This paper presents a Semi-Supervised Feature Selection Method based on a univariate relevance measure applied to a multiobjective approach of the problem. Along the process of decision of the optimal solution within Pareto-optimal set, atempting to maximize the relevance indexes of each feature, it is possible to determine a minimum set of relevant features and, at the same time, to determine the optimal model of the neural network.	[Coelho, Frederico; Braga, Antonio Padua] Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil	Coelho, F (reprint author), Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil.	fredgfc@ufmg.br; apbraga@ufmg.br; michel.verleysen@uclouvain.be	Braga, Antonio/A-2912-2008	Braga, Antonio/0000-0002-9007-0920			Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; BLAND RG, 1981, OPER RES, V29, P1039, DOI 10.1287/opre.29.6.1039; Chankong V, 1983, MULTIOBJECTIVE DECIS; Chapelle O., 2006, SEMISUPERVISED LEARN; COELHO F, 2010, SOFT COMPUTING FUSIO; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dy JG, 2004, J MACH LEARN RES, V5, P845; Fisher RA, 1936, ANN EUGENIC, V7, P179; KASABOV N, 2004, P INT C NEUR NETW SI; KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129; KIRA K, 1992, MACHINE LEARNING /, P249; Kruskal J, 1978, MULTIDIMENSIONAL SCA; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Le Cun Y., 1990, ADV NEURAL INFORMATI, V2, P598; Liang F, 2007, STAT SCI, V22, P189, DOI 10.1214/088342307000000032; Malerba D, 2009, ENG APPL ARTIF INTEL, V22, P109, DOI 10.1016/j.engappai.2008.04.005; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Parma GG, 2003, INT J ADAPT CONTROL, V17, P501, DOI 10.1002/acs.758; Press W. H., 1992, NUMERICAL RECIPES C; Teixeira RD, 2000, NEUROCOMPUTING, V35, P189, DOI 10.1016/S0925-2312(00)00327-1; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang JH, 2009, J MACH LEARN RES, V10, P719; WU J, 2009, LNCS LNAI, V5446, P345; Zhang D., 2007, SIAM DATA MINING, P629	25	1	1	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-16686-0	LECT NOTES COMPUT SC			2010	6419						509	516				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BUV07	WOS:000290420500067		
J	Yang, L; Xia, JF; Gui, J				Yang, Lei; Xia, Jun-Feng; Gui, Jie			Prediction of Protein-Protein Interactions from Protein Sequence Using Local Descriptors	PROTEIN AND PEPTIDE LETTERS			English	Article; Proceedings Paper	5th International Conference on Intelligent Computing	SEP 16-19, 2009	Ulsan, SOUTH KOREA	IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China		Feature representation; KNNs; local descriptors; PPIs prediction; protein sequence; sequence-based method	RESIDUE CONSERVATION; INTERACTION SITES; CLASSIFICATION; INFORMATION	With a huge amount of protein sequence data, the computational method for protein-protein interaction (PPI) prediction using only the protein sequences information have drawn increasing interest. In this article, we propose a sequence-based method based on a novel representation of local protein sequence descriptors. Local descriptors account for the interactions between residues in both continuous and discontinuous regions of a protein sequence, so this method enables us to extract more PPI information from the sequence. A series of elaborate experiments are performed to optimize the prediction model by varying the parameter k and the distance measuring function of the k-nearest neighbors learning system and the ways of coding a protein pair. When performed on the PPI data of Saccharomyces cerevisiae, the method achieved 86.15% prediction accuracy with 81.03% sensitivity at the precision of 90.24%. An independent data set of 986 Escherichia coli PPIs was used to evaluate this prediction model and the prediction accuracy is 73.02%. Given the complex nature of PPIs, the performance of our method is promising, and it can be a helpful supplement for PPIs prediction.	[Yang, Lei; Xia, Jun-Feng] Chinese Acad Sci, Hefei Inst Intelligent Machines, Intelligent Comp Lab, Hefei 230031, Anhui, Peoples R China; [Yang, Lei; Xia, Jun-Feng; Gui, Jie] Univ Sci & Technol China, Sch Life Sci, Hefei 230027, Anhui, Peoples R China; [Gui, Jie] Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China	Xia, JF (reprint author), Chinese Acad Sci, Hefei Inst Intelligent Machines, Intelligent Comp Lab, POB 1130, Hefei 230031, Anhui, Peoples R China.	jfxia@mail.ustc.edu.cn					Bock JR, 2003, BIOINFORMATICS, V19, P125, DOI 10.1093/bioinformatics/19.1.125; Bock JR, 2001, BIOINFORMATICS, V17, P455, DOI 10.1093/bioinformatics/17.5.455; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Chen XW, 2009, BIOINFORMATICS, V25, P585, DOI 10.1093/bioinformatics/btp039; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cui J, 2007, MOL IMMUNOL, V44, P514, DOI 10.1016/j.molimm.2006.02.010; Davies MN, 2008, BIOINFORMATICS, V24, P1980, DOI 10.1093/bioinformatics/btn382; Guo YZ, 2008, NUCLEIC ACIDS RES, V36, P3025, DOI 10.1093/nar/gkn159; Huang DS, 2006, PATTERN RECOGN, V39, P2293, DOI 10.1016/j.patcog.2005.11.012; Ito T, 2001, P NATL ACAD SCI USA, V98, P4569, DOI 10.1073/pnas.061034498; Li JJ, 2006, INT J BIOL MACROMOL, V38, P241, DOI 10.1016/j.ijbiomac.2006.02.024; Liu L, 2009, BIOCHEM BIOPH RES CO, V380, P318, DOI 10.1016/j.bbrc.2009.01.077; Marcotte EM, 1999, SCIENCE, V285, P751, DOI 10.1126/science.285.5428.751; Marcotte EM, 1999, NATURE, V402, P83; Marcotte EM, 2001, BIOINFORMATICS, V17, P359, DOI 10.1093/bioinformatics/17.4.359; Najafabadi HS, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-5-r87; Pazos F, 1997, J MOL BIOL, V271, P511, DOI 10.1006/jmbi.1997.1198; Pazos F, 2001, PROTEIN ENG, V14, P609, DOI 10.1093/protein/14.9.609; Shen JW, 2007, P NATL ACAD SCI USA, V104, P4337, DOI 10.1073/pnas.0607879104; Tong JC, 2008, FRONT BIOSCI, V13, P6072, DOI 10.2741/3138; Uetz P, 2000, NATURE, V403, P623; Wang B, 2006, PROTEIN PEPTIDE LETT, V13, P999, DOI 10.2174/092986606778777498; Wang B, 2006, FEBS LETT, V580, P380, DOI 10.1016/j.febslet.2005.11.081; Williams NE, 2000, METHOD CELL BIOL, V62, P449; Xenarios I, 2002, NUCLEIC ACIDS RES, V30, P303, DOI 10.1093/nar/30.1.303; Xia JF, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-174; Xia JF, 2010, PROTEIN PEPTIDE LETT, V17, P137; Zhao XM, 2005, NEURAL NETWORKS, V18, P1019, DOI 10.1016/j.neunet.2005.07.002; Zhu H, 2001, SCIENCE, V293, P2101, DOI 10.1126/science.1062191	29	14	14	8	11	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y26, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	0929-8665			PROTEIN PEPTIDE LETT	Protein Pept. Lett.		2010	17	9					1085	1090				6	Biochemistry & Molecular Biology	Biochemistry & Molecular Biology	644ZU	WOS:000281421500004	20509850	
S	Derrac, J; Garcia, S; Herrera, F		Unay, D; Cataltepe, Z; Aksoy, S		Derrac, Joaquin; Garcia, Salvador; Herrera, Francisco			IFS-CoCo in the Landscape Contest: Description and Results	RECOGNIZING PATTERNS IN SIGNALS, SPEECH, IMAGES, AND VIDEOS	Lecture Notes in Computer Science		English	Proceedings Paper	20th International Conference on Pattern Recognition Conference	APR 23-26, 2010	Istanbul, TURKEY			Evolutionary Algorithms; Feature selection; Instance selection; Cooperative coevolution; Nearest neighbor	CLASSIFICATION; ALGORITHMS	In this work, we describe the main features of IFS-CoCo, a coevolutionary method performing instance and feature selection for nearest neighbor classifiers. The coevolutionary model and several related background topics are revised, in order to present the method to the ICPR'10 contest "Classifier domains of competence: The Landscape contest". The results obtained show that our proposal is a very competitive approach in the domains considered, outperforming both the benchmark results of the contest and the nearest neighbor rule.	[Derrac, Joaquin; Herrera, Francisco] Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR, E-18071 Granada, Spain	Derrac, J (reprint author), Univ Granada, Dept Comp Sci & Artificial Intelligence, CITIC UGR, E-18071 Granada, Spain.	jderrac@decsai.ugr.es; sglopez@ujaen.es; herrera@decsai.ugr.es	Herrera, Francisco/C-6856-2008; Garcia, Salvador/N-3624-2013	Herrera, Francisco/0000-0002-7283-312X; Garcia, Salvador/0000-0003-4494-7565			Aha D. W., 1997, LAZY LEARNING; Cano JR, 2003, IEEE T EVOLUT COMPUT, V7, P561, DOI 10.1109/TEVC.2003.819265; Chen YH, 2009, J MACH LEARN RES, V10, P747; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Derrac J, 2010, PATTERN RECOGN, V43, P2082, DOI 10.1016/j.patcog.2009.12.012; Eshelman LJ, 1991, CHC ADAPTIVE SEARCH, P265; Freitas A.A., 2002, DATA MINING KNOWLEDG; Ghosh A, 2005, EVOLUTIONARY COMPUTA; Ho SY, 2002, PATTERN RECOGN LETT, V23, P1495, DOI 10.1016/S0167-8655(02)00109-5; Jansen T, 2004, EVOL COMPUT, V12, P405, DOI 10.1162/1063656043138905; LIU H, 2007, CHPMN HLL CRC DTA; LIU H, 2001, INT SERIES ENG COMPU; Potter MA, 2000, EVOL COMPUT, V8, P1, DOI 10.1162/106365600568086; PRICE PW, 1998, BIOL EVOLUTION; Pyle D, 1999, M KAUFMANN SERIES DA; ROSIN CD, 1997, EVOLUTIONARY COMPUTA, V15, P1; Smith J. E., 2003, INTRO EVOLUTIONARY C; WHITLEY D, 1998, P 3 ANN C GEN PROGRA, P504; Wiegand R.P., 2003, THESIS G MASON U FAI; Wolpert DH, 2005, IEEE T EVOLUT COMPUT, V9, P721, DOI 10.1109/TEVC.2005.856205; Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653	21	0	0	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-17710-1	LECT NOTES COMPUT SC			2010	6388						56	65				10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BUN10	WOS:000289811600006		
S	He, Q; Zhuang, FZ; Li, JC; Shi, ZZ		Yu, J; Greco, S; Lingras, P; Wang, G; Skowron, A		He, Qing; Zhuang, Fuzhen; Li, Jincheng; Shi, Zhongzhi			Parallel Implementation of Classification Algorithms Based on MapReduce	ROUGH SET AND KNOWLEDGE TECHNOLOGY (RSKT)	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	5th International Conference on Rough Set and Knowledge Technology (RSKT)	OCT 15-17, 2010	Beijing, PEOPLES R CHINA	Beijing Jiaotong Univ, Natl Nat Sci Fdn China (NSFC), Int Rough Set Soc (IRSS), Chinese Assoc Artificial Intelligence, Rough Sets & Soft Computat Soc (CRSSC)		Data Mining; Classification; Parallel Implementation; Large Dataset; MapReduce		Data mining has attracted extensive research for several decades. As an important task of data mining, classification plays an important role in information retrieval, web searching, CRM, etc. Most of the present classification techniques are serial, which become impractical for large dataset. The computing resource is under-utilized and the executing time is not waitable. Provided the program mode of MapReduce, we propose the parallel implementation methods of several classification algorithms, such as k-nearest neighbors, naive bayesian model and decision tree, etc. Preparatory experiments show that the proposed parallel methods can not only process large dataset, but also can be extended to execute on a cluster, which can significantly improve the efficiency.	[He, Qing; Zhuang, Fuzhen; Li, Jincheng; Shi, Zhongzhi] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China	He, Q (reprint author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	heq@ics.ict.ac.cn; zhuangfz@ics.ict.ac.cn; lijincheng@ics.ict.ac.cn; shizz@ics.ict.ac.cn					Buyya R., 2008, P 10 IEEE INT C HIGH; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B. V., 1991, NEAREST NEIGHBOR NN; Dean Jeffrey, 2004, P 6 S OP SYST DES IM; Duda R O, 2001, PATTERN CLASSIFICATI; Elsayed T., 2008, P 46 ANN M ASS COMP, P262; Michie D., 1994, MACHINE LEARNING NEU; Mitchell T. M., 1997, MACHINE LEARNING; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; Quinlan J.R., 1997, C4 5 PROGRAMS MACHIN; Weiss Aaron, 2007, Networker, V11, DOI 10.1145/1327512.1327513; Weiss S.M., 1991, NEURAL NETS MACHINE	12	5	6	0	4	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-16247-3	LECT NOTES ARTIF INT			2010	6401						655	662				8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BDT68	WOS:000314802800089		
S	Zhu, PF; Hu, QH; Yang, YB		Szczuka, M; Kryszkiewicz, M; Ramanna, S; Jensen, R; Hu, QH		Zhu, Pengfei; Hu, Qinghua; Yang, Yongbin			Weighted Nearest Neighbor Classification via Maximizing Classification Consistency	ROUGH SETS AND CURRENT TRENDS IN COMPUTING, PROCEEDINGS	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	7th International Conference on Rough Sets and Current Trends in Computing	JUN 28-30, 2010	Warsaw, POLAND		Univ Warsaw			The nearest neighbor classification is a. simple and effective technique for pattern recognition. The performance of this technique is known to be sensitive to the distance function used in classifying a test instance. In this paper, we propose a technique to learn sample weights via, maximizing classification consistency. Experimental analysis shows that the distance trained in this way enlarges the classification consistency on several datasets and has a strong ability to tolerate noise. Moreover, the proposed approach has better performance than nearest neighbor classification and several state-of-the-art methods.	[Zhu, Pengfei; Hu, Qinghua; Yang, Yongbin] Harbin Inst Technol, Harbin 150001, Peoples R China	Zhu, PF (reprint author), Harbin Inst Technol, Harbin 150001, Peoples R China.	huqinghua@hit.edu.cn; huqinghua@hit.edu.cn					Asuncion A., 2007, UCI MACHINE LEARNING; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; GILADBACHRACH R, 2004, ICML 2004; Hastie T, 1996, ADV NEUR IN, V8, P409; Howe N, 1997, LECT NOTES ARTIF INT, V1266, P455; Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017; HU X, 1999, KNOWL INF SYST, V1, P33; KOHAVI R, 1997, LNCS, V1224, P455; Morsi NN, 1998, FUZZY SET SYST, V100, P327, DOI 10.1016/S0165-0114(97)00104-8; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; SLEZAK D, 2009, INFORM SCI, V1789, P197; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER K, ADV NEURAL INFORM PR, V18; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; YAO Y, 2008, INFORM SCI, V78, P3356	16	0	0	0	1	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-13528-6	LECT NOTES ARTIF INT			2010	6086						347	355				9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BQR34	WOS:000281605400037		
S	Bounhas, M; Mellouli, K; Prade, H; Serrurier, M		Deshpande, A; Hunter, A		Bounhas, Myriam; Mellouli, Khaled; Prade, Henri; Serrurier, Mathieu			From Bayesian Classifiers to Possibilistic Classifiers for Numerical Data	SCALABLE UNCERTAINTY MANAGEMENT, SUM 2010	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	4th Annual International Conference on Scalable Uncertainty Management (SUM)	SEP 27-29, 2010	Toulouse, FRANCE			Naive Possibilistic Classifier; Possibility Theory; Naive Bayesian Classifier; Gaussian Distribution; Kernel Density; Numerical Data	NETWORK CLASSIFIERS; CLASSIFICATION	Naive Bayesian classifiers are well-known for their simplicity and efficiency. They rely on independence hypotheses, together with a normality assumption, which may be too demanding, when dealing with numerical data. Possibility distributions are more compatible with the representation of poor data. This paper investigates two kinds of possibilistic elicitation methods that will be embedded into possibilistic naive classifiers. The first one is derived from a probability-possibility transformation of Gaussian distributions (or mixtures of them), which introduces some further tolerance. The second kind is based on a direct interpretation of data in fuzzy histogram or possibilistic formats that exploit an idea of proximity between attribute values in different ways. Besides, possibilistic classifiers may be allowed to leave the classification open between several classes in case of insufficient information for choosing one (which may be of interest when the number of classes is large). The experiments reported show the interest of possibilistic classifiers.	[Bounhas, Myriam; Mellouli, Khaled] ISG Tunis, Lab LARODEC, Le Bardo 2000, Tunisia	Bounhas, M (reprint author), ISG Tunis, Lab LARODEC, 41 Rue Liberte, Le Bardo 2000, Tunisia.	Myriam_Bounhas@yahoo.fr; Khaled.Mellouli@topnet.tn; Prade@irit.fr; Serrurier@irit.fr					Ben Amor N, 2004, IEEE INT CONF FUZZY, P653; Ben Amor N, 2002, INT J UNCERTAIN FUZZ, V10, P117; Benferhat S, 2008, LECT NOTES ARTIF INT, V5291, P63, DOI 10.1007/978-3-540-87993-0_7; Bishop C.M., 1996, NEURAL NETWORKS PATT; Borgelt C., 1999, P 7 EUR C INT TECHN, P556; Borgelt C., 1998, P 7 IEEE INT C FUZZ, P663; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Denton A., 2004, P 4 SIAM INT C DAT M; Dubois D, 1993, P 5 INT FUZZ SYST AS; Dubois D., 1998, HDB DEFEASIBLE REASO, V1, P169; DUBOIS D, 1992, FUZZY SET SYST, V49, P65, DOI 10.1016/0165-0114(92)90110-P; Dubois D., 1993, FUZZY LOGIC STATE AR, P103; Dubois D., 2004, Reliable Computing, V10, DOI 10.1023/B:REOM.0000032115.22510.b5; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Grossman D., 2004, P MACH LEARN, P46; Haouari B, 2009, FUZZY SET SYST, V160, P3224, DOI 10.1016/j.fss.2009.01.009; Jenhani Ilyes, 2008, International Journal of Approximate Reasoning, V48, DOI 10.1016/j.ijar.2007.12.002; John G., 1995, P 11 C UNC ART INT; Kotsiantis S B, 2007, Informatica, V31; Langley P., 1994, P 10 C UNC ART INT, P399; Langley P., 1992, P AAAI 1992, V7, P223; Mertz J., UCI REPOSITORY MACHI; Pearl J, 1988, PROBABILISTIC REASON; Perez A, 2009, INT J APPROX REASON, V50, P341, DOI 10.1016/j.ijar.2008.08.008; Qin B., 2009, IEEE INT C DAT ENG; Quinlan J. R., 1986, Machine Learning, V1, DOI 10.1023/A:1022643204877; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P224, DOI 10.1016/S0019-9958(64)90131-7; Strauss O., 2000, P 15 ICPR BARC SPAIN, P2684; Sudkamp T, 2000, P 90 IEEE INT C FUZZ, P735; Yamada K, 2001, IFSA WORLD C 20 NAFI, V1, P70; Zaffalon M, 2002, J STAT PLAN INFER, V105, P5, DOI 10.1016/S0378-3758(01)00201-4	31	1	1	0	0	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-15950-3	LECT NOTES ARTIF INT			2010	6379						112	125				14	Computer Science, Artificial Intelligence	Computer Science	BDB30	WOS:000312447800015		
J	Chakrabarti, A; Regev, O				Chakrabarti, Amit; Regev, Oded			AN OPTIMAL RANDOMIZED CELL PROBE LOWER BOUND FOR APPROXIMATE NEAREST NEIGHBOR SEARCHING	SIAM JOURNAL ON COMPUTING			English	Article						cell probe model; nearest neighbor search; round elimination	PROTEIN SECONDARY STRUCTURE; COMMUNICATION COMPLEXITY; PREDICTION	We consider the approximate nearest neighbor search problem on the Hamming cube {0, 1}(d). We show that a randomized cell probe algorithm that uses polynomial storage and word size d(O(1)) requires a worst case query time of O(log log d/log log log d). The approximation factor may be as loose as 2log(1-eta d) for any fixed eta > 0. Our result fills a major gap in the study of this problem since all earlier lower bounds either did not allow randomization [A. Chakrabarti et al., A lower bound on the complexity of approximate nearest-neighbor searching on the Hamming cube, in Discrete and Computational Geometry, Springer, Berlin, 2003, pp. 313-328; D. Liu, Inform. Process. Lett., 92 (2004), pp. 23-29] or did not allow approximation [A. Borodin, R. Ostrovsky, and Y. Rabani, Proceedings of the 31st Annual ACM Symposium on Theory of Computing, 1999, pp. 312-321; O. Barkol and Y. Rabani, Proceedings of the 32nd Annual ACM Symposium on Theory of Computing, 2000, pp. 388-396; T. S. Jayram et al., J. Comput. System Sci., 69 (2004), pp. 435-447]. We also give a cell probe algorithm that proves that our lower bound is optimal. Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the "richness technique" [P. B. Miltersen et al., J. Comput. System Sci., 57 (1998), pp. 37-49] used in a lot of recent research around this problem would not have helped here. Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [A. Chakrabarti et al., Proceedings of the 42nd Annual IEEE Symposium on Foundations of Computer Science, 2001, pp. 270-278; Z. Bar-Yossef et al., Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002, pp. 209-218; P. Sen, Proceedings of the 18th Annual IEEE Conference on Computational Complexity, 2003, pp. 73-83; R. Jain, J. Radhakrishnan, and P. Sen, Proceedings of the 30th International Colloquium on Automata, Languages and Programming, 2003, pp. 300-315].	[Chakrabarti, Amit] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA; [Chakrabarti, Amit] Inst Adv Study, Princeton, NJ 08540 USA; [Regev, Oded] Tel Aviv Univ, Blavatnik Sch Comp Sci, IL-69978 Tel Aviv, Israel; [Regev, Oded] Univ Calif Berkeley, Berkeley, CA 94720 USA	Chakrabarti, A (reprint author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.	ac@cs.dartmouth.edu; odedr@post.tau.ac.il			NSF [CCR-9987845, CCF-0448277]; Binational Science Foundation; Israel Science Foundation; European Commission; IST [015848]; Army Research Office [DAAD19-03-1-0082]; European Research Council (ERC)	Computer Science Department, Dartmouth College, Hanover, NH 03755 (ac@cs.dartmouth.edu). This work was partly done while this author was at the Institute for Advanced Study, Princeton, NJ. This author's work was supported in part by NSF grants CCR-9987845 and CCF-0448277.Blavatnik School of Computer Science, Tel Aviv University, Tel Aviv 69978, Israel (odedr@post.tau.ac.il). This work was partly done while this author was at the University of California, Berkeley. This author's research was supported by the Binational Science Foundation, the Israel Science Foundation, the European Commission under the Integrated Project QAP funded by the IST directorate as contract 015848, Army Research Office grant DAAD19-03-1-0082, and a European Research Council (ERC) Starting Grant.	ANDONI A, 2006, P 47 ANN IEEE S FDN, P449; Barkol O., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, DOI 10.1145/335305.335350; Bar-Yossef Z., 2002, Proceedings 43rd Annual IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2002.1181944; Beame P., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301323; BEAME P, 2003, COMMUNICATION; Borodin A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, DOI 10.1145/301250.301330; Miltersen P. B., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, DOI 10.1145/195058.195415; CHAKRABARTI A, 2003, DISCRETE COMPUT GEOM, P313; Chakrabarti A., 2004, Proceedings. 45th Annual IEEE Symposium on Foundations of Computer Science; Chakrabarti A., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959901; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R. O., 1973, PATTERN CLASSIFICATI; FREDMAN ML, 1984, J ACM, V31, P538, DOI 10.1145/828.1884; Har-Peled S., 2001, Proceedings 42nd IEEE Symposium on Foundations of Computer Science, DOI 10.1109/SFCS.2001.959884; HARSHA P, 2007, P 22 CCC, P10, DOI DOI 10.1109/CCC.2007.32; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Jain R., 2003, P 30 INT C AUT LANG, P300; Jayram TS, 2004, J COMPUT SYST SCI, V69, P435, DOI 10.1016/j.jcss.2004.04.006; Kushilevitz E, 2000, SIAM J COMPUT, V30, P457, DOI 10.1137/S0097539798347177; Liu D, 2004, INFORM PROCESS LETT, V92, P23, DOI 10.1016/j.ipl.2004.06.001; Miltersen PB, 1998, J COMPUT SYST SCI, V57, P37, DOI 10.1006/jcss.1998.1577; NEWMAN I, 1991, INFORM PROCESS LETT, V39, P67, DOI 10.1016/0020-0190(91)90157-D; Overmars M., 2000, COMPUTATIONAL GEOMET, V2nd; Patrascu M, 2009, SIAM J COMPUT, V39, P730, DOI 10.1137/070684859; SALAMOV AA, 1995, J MOL BIOL, V247, P11, DOI 10.1006/jmbi.1994.0116; Salton G, 1983, INTRO MODERN INFORM; Sen P., 2003, Proceedings 18th IEEE Annual Conference on Computational Complexity; Yao AC, 1977, P 18 ANN IEEE S FDN, P222, DOI DOI 10.1109/SFCS.1977.24; YAO ACC, 1981, J ACM, V28, P615, DOI 10.1145/322261.322274; YI TM, 1993, J MOL BIOL, V232, P1117, DOI 10.1006/jmbi.1993.1464	31	0	2	0	1	SIAM PUBLICATIONS	PHILADELPHIA	3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA	0097-5397			SIAM J COMPUT	SIAM J. Comput.		2010	39	5					1919	1940		10.1137/080729955		22	Computer Science, Theory & Methods; Mathematics, Applied	Computer Science; Mathematics	595BC	WOS:000277584700009		
S	Ozer, S; Chen, CH; Yetik, IS		Hancock, ER; Wilson, RC; Windeatt, T; Ulusoy, I; Escolano, F		Ozer, Sedat; Chen, Chi Hau; Yetik, Imam Samil			Using K-NN SVMs for Performance Improvement and Comparison to K-Highest Lagrange Multipliers Selection	STRUCTURAL, SYNTACTIC, AND STATISTICAL PATTERN RECOGNITION	Lecture Notes in Computer Science		English	Proceedings Paper	Joint IAPR International Workshop on SSPR & SPR	AUG 18-20, 2010	Izmir, TURKEY	IAPR, Pattern Anal Stat Modelling & Comp Learning		Support Vector Machine; KNN SVM; Post-processing; Support Vector Reduction	SUPPORT VECTOR MACHINE	Support Vector Machines (SVM) can perform very well on noise free data sets and can usually achieve good classification accuracies when the data is noisy. However, because of the overfitting problem, the accuracy decreases if the SVM is modeled improperly or if the data is excessively noisy or nonlinear. For SVM, most of the misclassification occurs when the test data lies closer to the decision boundary. Therefore in this paper, we investigate the effect of Support Vectors found by SVM, and their effect on the decision when used with the Gaussian kernel. Based on the discussion results we also propose a new technique to improve the performance of SVM by creating smaller clusters along the decision boundary in the higher dimensional space. In this way we reduce the overfitting problem that occurs because of the model selection or the noise effect. As an alternative SVM tuning method, we also propose using only K highest Lagrange multipliers to summarize the decision boundary instead of the whole support vectors and compare the performances. Thus with test results, we show that the number of Support Vectors can be decreased further by using only a fraction of the support vectors found at the training step as a post-processing method.	[Ozer, Sedat] Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08903 USA	Ozer, S (reprint author), Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08903 USA.	sozer@umassd.edu; cchen@umassd.edu; yetik@iit.edu					Artan Y, 2008, I S BIOMED IMAGING, P488, DOI 10.1109/ISBI.2008.4541039; Asuncion A., UCI MACHINE LEARNING; Bishop C. M., 2006, PATTERN RECOGNITION; Canu S., 2005, SVM KERNEL METHODS M; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DECOSTE D, 2003, 20 INT C MACH LEARN; El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569; LUCEY S, 2008, IEEE C COMP VIS PATT, P1; MING T, 2003, IEEE INTELLIGENT TRA, V1, P373; Ozer S, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: FROM NANO TO MACRO, VOLS 1 AND 2, P73, DOI 10.1109/ISBI.2009.5192986; OZER S, 2008, 19 INT C PATT REC IC; Vapnik V., 1998, STAT LEARNING THEORY; Zhang H, 2006, IEEE C COMP VIS PATT; Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113	14	0	0	0	31	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-14979-5	LECT NOTES COMPUT SC			2010	6218						532	539				8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Computer Science	BTB95	WOS:000286412900052		
S	Metzler, J; Willersinn, D		Rahman, Z; Reichenbach, SE; Neifeld, MA		Metzler, Juergen; Willersinn, Dieter			Human Detection in MOUT Scenarios using Covariance Descriptors and Supervised Manifold Learning	VISUAL INFORMATION PROCESSING XIX	Proceedings of SPIE		English	Proceedings Paper	Conference on Visual Information Processing XIX	APR 06-07, 2010	Orlando, FL	SPIE		covariance descriptor; human detection; Laplacian Eigenmaps; military operations in urban terrain; region covariance; supervised manifold learning	NONLINEAR DIMENSIONALITY REDUCTION; COMPONENT ANALYSIS; IMAGE; FRAMEWORK; NETWORKS	Military Operations in Urban Terrain (MOUT) require the capability to perceive and to analyse the situation around a patrol in order to recognize potential threats. As in MOUT scenarios threats usually arise from humans one important task is the robust detection of humans. Detection of humans in MOUT by image processing systems can be very challenging, e.g., due to complex outdoor scenes where humans have a weak contrast against the background or are partially occluded. Porikli et al. introduced covariance descriptors and showed their usefulness for human detection in complex scenes. However, these descriptors do not lie on a vector space and so well-known machine learning techniques need to be adapted to train covariance descriptor classifiers. We present a novel approach based on manifold learning that simplifies the classification of covariance descriptors. In this paper, we apply this approach for detecting humans. We describe our human detection method and evaluate the detector on benchmark data sets generated from real-world image sequences captured during MOUT exercises.	[Metzler, Juergen; Willersinn, Dieter] Fraunhofer Inst Optron Syst Technol & Image Explo, D-76131 Karlsruhe, Germany	Metzler, J (reprint author), Fraunhofer Inst Optron Syst Technol & Image Explo, Fraunhoferstr 1, D-76131 Karlsruhe, Germany.						Belkin M., 2002, NEURAL COMPUT, V4, P1373; Belkin M, 2002, ADV NEUR IN, V14, P585; Camastra F., 2007, ADV INFORM KNOWLEDGE; Cayton L, 2005, ALGORITHMS MANIFOLD; Chung F., 1996, CBMS LECT FRESN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dalal N., 2005, COMPUTER VISION PATT; Forstner W., 1987, P ISPRS INT C FAST P, P281; Forstner W., 1999, METRIC COVARIANCE MA; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; GNANADESIKAN R, 1969, MULTIVARIATE ANAL, V2; GREG A, 2003, CVPR, V2, P681; Harris C., 1988, P 4 ALV VIS C, P147; HEINZE N, 2007, SPIE DEF SEC S ORL; Horn R. A., 1985, MATRIX ANAL; HUBNER Y, 2008, P SPIE DEF SEC EUR C; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; KENDALL WS, 1990, P LOND MATH SOC, V61, P371; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; Kruger W., 2001, MACH VISION APPL, V13, P30; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Lee DJ, 2004, P SOC PHOTO-OPT INS, V5438, P81, DOI 10.1117/12.542981; Leibe B, 2004, ECCV 04 WORKSH STAT; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; PAISITKRIANGKRA S, 2008, P IEEE C DIG IM COMP, P53; Pearson K, 1901, PHILOS MAG, V2, P559; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Porikli F., 2005, P IEEE C COMP VIS PA; Porikli F, 2006, IEEE IMAGE PROC, P1581, DOI 10.1109/ICIP.2006.312610; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul L K, 2003, J MACHINE LEARNING R, P119, DOI DOI 10.1162/153244304322972667; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SKOVGAARD LT, 1984, SCAND J STAT, V11, P211; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TUZEL O, 2006, EUR C COMP VIS GRAZ, V2, P589; Tuzel O., 2007, CVPR; Utsumi A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P39; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; von Luxburg U., 2007, TR149 M PLANCK I BIO	42	0	0	1	1	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X		978-0-8194-8165-8	PROC SPIE			2010	7701								770106	10.1117/12.850213		11	Engineering, Electrical & Electronic; Optics	Engineering; Optics	BSO07	WOS:000285051200005		
S	Yu, XA; Wei, X; Lin, X		Wang, FL; Gong, ZG; Luo, XF; Lei, JS		Yu, Xiao; Wei, Xu; Lin, Xia			Algorithms of BBS Opinion Leader Mining Based on Sentiment Analysis	WEB INFORMATION SYSTEMS AND MINING	Lecture Notes in Computer Science		English	Proceedings Paper	International Conference on Web Information Systems and Mining	OCT 23-24, 2010	Sanya, PEOPLES R CHINA	Hainan Province Inst Comp, Qiongzhou Univ		social network; Opinion Leader; community discovery; sentiment analysis		Opinion leaders play a crucial role in online communities, which can guide the direction of public opinion. Most proposed algorithms on opinion leaders mining in internet social network are based on network structure and usually omit the fact that opinion leaders are field-limited and the opinion sentiment orientation analysis is the vital factor of one's authority. We propose a method to find the interest group based on topic content analysis, which combine the advantages of clustering and classification algorithms. Then we use the method of sentiment analysis to define the authority value as the weight of the link between users. On this basis, an algorithm named LeaderRank is proposed to identify the opinion leaders in BBS, and experiments indicate that LeaderRank algorithm can effectively improve the accuracy of leaders mining.	[Yu, Xiao; Wei, Xu; Lin, Xia] Huazhong Univ Sci & Technol, Elect & Informat Engn Dept, Wuhan 430074, Peoples R China	Yu, XA (reprint author), Huazhong Univ Sci & Technol, Elect & Informat Engn Dept, Wuhan 430074, Peoples R China.	xiaoyu@mail.hust.edu.cn; xuwei@mail.hust.edu.cn; xialin@mail.hust.edu.cn					COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; MATSUMURA N, 2002, WWW 2002; NEWMAN ME, 2004, J PHYS REV E; Scott J., 2000, SOCIAL NETWORK ANALY; WU F, 2003, J EURO PHYS J B, V38, P331; YANG S, 2009, EMOTION MINING RES M, P71; ZHAI ZW, 2008, J IEEE P WEB INTELLI; ZHANG J, 2007, J WWW 2007; Zhou HM, 2009, ISI: 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P266	9	2	3	2	9	SPRINGER-VERLAG BERLIN	BERLIN	HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY	0302-9743		978-3-642-16514-6	LECT NOTES COMPUT SC			2010	6318						360	369				10	Computer Science, Information Systems; Computer Science, Theory & Methods	Computer Science	BTB82	WOS:000286404600045		
S	Rajan, P; Canto, M; Gorospe, E; Almario, A; Kage, A; Winter, C; Hager, G; Wittenberg, T; Munzenmayer, C		Dossel, O; Schlegel, WC		Rajan, P.; Canto, M.; Gorospe, E.; Almario, A.; Kage, A.; Winter, C.; Hager, G.; Wittenberg, T.; Muenzenmayer, C.			AUTOMATED DIAGNOSIS OF BARRETT'S ESOPHAGUS WITH ENDOSCOPIC IMAGES	WORLD CONGRESS ON MEDICAL PHYSICS AND BIOMEDICAL ENGINEERING, VOL 25, PT 4: IMAGE PROCESSING, BIOSIGNAL PROCESSING, MODELLING AND SIMULATION, BIOMECHANICS	IFMBE Proceedings		English	Proceedings Paper	World Congress on Medical Physics and Biomedical Engineering	SEP 07-12, 2009	Munich, GERMANY	IUPESM, IOMP			TEXTURE CLASSIFICATION; FEATURES	In this paper, we describe current progress on the development of a Computer Assisted Diagnosis System (CAD) for the classification of Barrett's esophagus and associated neoplasia. Barrett's esophagus is a condition in which normal squamous mucosa is replaced by columnar epithelium, which is similar to the lining of the intestine. Barrett's esophagus as a known precancerous condition leading to esophageal cancer. Diagnosis is performed via histological analysis of tissue located during endoscopic examination. We compare four different automated classification tools (SVM, KNN, and Boosting) operating on three different imaging modalities (white light, narrow-band, and acetic acid chromoendoscopy) for lesion classification. Preliminary results suggest that narrow band imaging is more effective than either of the other two modalities for disease assessment.	[Rajan, P.; Hager, G.] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Munzenmayer, C (reprint author), Fraunhofer Inst Integrated Circuits IIS, Wolfsmantel 33, Erlangen, Germany.	christian.muenzenmayer@iis.fraunhofer.de					Bishop C. M., 2006, PATTERN RECOGNITION; Camilleri M, 2005, CLIN GASTROENTEROL H, V3, P543, DOI 10.1053/S1542-3565(05)00153-9; CHEN YQ, 1995, PATTERN RECOGN, V28, P537, DOI 10.1016/0031-3203(94)00116-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Fortun PJ, 2006, ALIMENT PHARM THERAP, V23, P735, DOI 10.1111/j.1365-2036.2006.02823.x; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Guelrud M, 1998, GASTROINTEST ENDOSC, P57; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Kage A., 2008, BILDVERARBEITUNG MED, P272, DOI 10.1007/978-3-540-78640-5_55; Mitchell TM, 1999, COMMUN ACM, V42, P30, DOI 10.1145/319382.319388; Munzenmayer C, 2006, THESIS U KOBLENZ LAN; OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I; Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010; Wanderley JFC, 2001, IEEE T IMAGE PROCESS, V10, P1630, DOI 10.1109/83.967391; Wittenberg T, 2003, ADV QUANTITATIVE LAR	15	0	0	0	1	SPRINGER	NEW YORK	233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES	1680-0737		978-3-642-03881-5	IFMBE PROC			2010	25		4				2189	2192				4	Engineering, Biomedical	Engineering	BZB27	WOS:000300975300581		
J	Marchiori, E				Marchiori, Elena			Class Conditional Nearest Neighbor for Large Margin Instance Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computing methodologies; artificial intelligence; learning; heuristics design; machine learning	LARGE DATA SETS; LEARNING ALGORITHMS; CLASSIFICATION; NETWORKS; RULE; CLASSIFIERS; CONDENSATION	This paper presents a relational framework for studying properties of labeled data points related to proximity and labeling information in order to improve the performance of the 1NN rule. Specifically, the class conditional nearest neighbor (ccnn) relation over pairs of points in a labeled training set is introduced. For a given class label c, this relation associates to each point a its nearest neighbor computed among only those points with class label c (excluded a). A characterization of ccnn in terms of two graphs is given. These graphs are used for defining a novel scoring function over instances by means of an information-theoretic divergence measure applied to the degree distributions of these graphs. The scoring function is employed to develop an effective large margin instance selection method, which is empirically demonstrated to improve storage and accuracy performance of the 1NN rule on artificial and real-life data sets.	Radboud Univ Nijmegen, Inst Comp & Informat Sci, Fac Sci, NL-6525 ED Nijmegen, Netherlands	Marchiori, E (reprint author), Radboud Univ Nijmegen, Inst Comp & Informat Sci, Fac Sci, Toernooiveld 1, NL-6525 ED Nijmegen, Netherlands.	elenam@cs.ru.nl			NWO [639.023.604]	The author thanks the editor and the reviewers for their constructive comments and the ML and SNN groups at the Radboud University for useful discussions. This work was partially supported by the NWO project 639.023.604.	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1593, DOI 10.1109/TKDE.2007.190665; Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645; BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839; Bartlett PL, 1997, ADV NEUR IN, V9, P134; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; Brighton H, 1999, LECT NOTES ARTIF INT, V1704, P283; Cameron-Jones R. M., 1995, P 8 AUSTR JOINT C AR, P99; Chapelle O., 2005, P 10 INT WORKSH ART, P57; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Crammer K., 2002, P 17 C NEUR INF PROC, P462; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; DASARATHY BV, 1995, OPT ENG, V34, P2785, DOI 10.1117/12.210755; DASARATHY BV, 1995, P SOC PHOTO-OPT INS, P34; Demsar J, 2006, J MACH LEARN RES, V7, P1; Domeniconi C, 2002, IEEE T PATTERN ANAL, V24, P1281, DOI 10.1109/TPAMI.2002.1033219; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Garcia S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006; GILADBACHRACH R, 2004, P INT C MACH LEARN; Grother PJ, 1997, PATTERN RECOGN, V30, P459, DOI 10.1016/S0031-3203(96)00098-2; Hammer B, 2005, NEURAL PROCESS LETT, V21, P109, DOI 10.1007/s11063-004-1547-1; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Jankowski N., 2004, ARTIF INTELL, P580; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Krishna K, 2000, IEEE T NEURAL NETWOR, V11, P1361, DOI 10.1109/72.883447; Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3; LIN J, 1991, IEEE T INFORM THEORY, V37, P1; Marchiori E, 2008, J MACH LEARN RES, V9, P997; MCCAMMON RB, 1972, J SEDIMENT PETROL, V42, P422; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Peng J, 2004, IEEE T PATTERN ANAL, V26, P656; Pkalska E., 2006, Pattern Recognition, V39, DOI 10.1016/j.patcog.2005.06.012; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; Sanchez JS, 2007, PATTERN ANAL APPL, V10, P189, DOI 10.1007/s10044-007-0061-2; Schapire R.E., 1997, P 14 INT C MACH LEAR, P322; Tahir MA, 2007, PATTERN RECOGN LETT, V28, P438, DOI 10.1016/j.patrec.2006.08.016; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; TOUSSAINT G, 2002, P INTERFACE 2002 34, P83; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang JG, 2007, PATTERN RECOGN LETT, V28, P207, DOI 10.1016/j.patrec.2006.07.002; WEINBERGER KQ, 2006, P C NEUR INF PROC SY; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721; Wilson HR, 1997, VISUAL NEUROSCI, V14, P403	46	23	27	3	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					364	370		10.1109/TPAMI.2009.56		7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	532IT	WOS:000272741500013	20075464	
J	Depeursinge, A; Iavindrasana, J; Hidki, A; Cohen, G; Geissbuhler, A; Platon, A; Poletti, PA; Muller, H				Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning			Comparative Performance Analysis of State-of-the-Art Classification Algorithms Applied to Lung Tissue Categorization	JOURNAL OF DIGITAL IMAGING			English	Article						Quantitative image analysis; feature extraction; texture analysis; chest high-resolution CT; supervised learning; support vector machines	COMPUTER-AIDED DIAGNOSIS; DISEASE PATTERNS; RECOGNITION; SEGMENTATION; RETRIEVAL; IMAGES; SYSTEM	In this paper, we compare five common classifier families in their ability to categorize six lung tissue patterns in high-resolution computed tomography (HRCT) images of patients affected with interstitial lung diseases (ILD) and with healthy tissue. The evaluated classifiers are naive Bayes, k-nearest neighbor, J48 decision trees, multilayer perceptron, and support vector machines (SVM). The dataset used contains 843 regions of interest (ROI) of healthy and five pathologic lung tissue patterns identified by two radiologists at the University Hospitals of Geneva. Correlation of the feature space composed of 39 texture attributes is studied. A grid search for optimal parameters is carried out for each classifier family. Two complementary metrics are used to characterize the performances of classification. These are based on McNemar's statistical tests and global accuracy. SVM reached best values for each metric and allowed a mean correct prediction rate of 88.3% with high class-specific precision on testing sets of 423 ROIs.	[Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Mueller, Henning] Univ Hosp Geneva, Serv Med Informat, CH-1211 Geneva 14, Switzerland; [Depeursinge, Adrien; Iavindrasana, Jimison; Hidki, Asmaa; Cohen, Gilles; Geissbuhler, Antoine; Platon, Alexandra; Poletti, Pierre-Alexandre; Mueller, Henning] Univ Geneva, CH-1211 Geneva, Switzerland; [Platon, Alexandra; Poletti, Pierre-Alexandre] Univ Hosp Geneva, Serv Emergency Radiol, CH-1211 Geneva 14, Switzerland; [Mueller, Henning] Univ Appl Sci, Sierre, Switzerland	Depeursinge, A (reprint author), Univ Hosp Geneva, Serv Med Informat, 24 Rue Micheli du Crest, CH-1211 Geneva 14, Switzerland.	adrien.depeursinge@sim.hcuge.ch			Swiss National Science Foundation [200020-118638/1]; University and Hospitals of Geneva [05-9-II]; EU [IST 032691]	We thank Dr. Melanie Hilario for her valuable comments on the methodology for benchmarking the classifiers. This work was supported by the Swiss National Science Foundation (FNS) with grant 200020-118638/1, the equalization fund of University and Hospitals of Geneva (grant 05-9-II), and the EU 6th Framework Program in the context of the KnowARC project (IST 032691).	Aisen AM, 2003, RADIOLOGY, V228, P265, DOI 10.1148/radiol.2281020126; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bishop C. M., 2006, PATTERN RECOGNITION; Bishop C.M., 1995, NEURAL NETWORKS PATT; Burges C. J. C., 1998, DATA MIN KNOWL DISC, V2, DOI DOI 10.1023/A:1009715923555; CABAN J, 2007, MEDICAL IMAGING 2007, V6514; Chang C.C., 2001, LIBSVM LIB SUPPORT V; Cohen G, 2006, ARTIF INTELL MED, V37, P7, DOI 10.1016/j.artmed.2005.03.002; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Depeursinge A., 2007, 29 ANN INT C IEEE EM, P6259, DOI 10.1109/IEMBS.2007.4353786; DEPEURSINGE A, 2006, SWISS C MED INF SSIM; Depeursinge A., 2007, MED IMAGING 2007 COM, V6514, p65143P; DIETTERICH TG, 1998, NEURAL COMPUT, V10, P7; Flaherty KR, 2004, AM J RESP CRIT CARE, V170, P904, DOI 10.1164/rccm.200402-147OC; Frank E, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P1305, DOI 10.1007/0-387-25465-X_62; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Kubat M., 1997, P 14 INT C MACH LEAR, P179; Mller H., 2004, INT J MED INFORM, V73, P1; Nishikawa RA, 2007, COMPUT MED IMAG GRAP, V31, P224, DOI 10.1016/j.compmedimag.2007.02.009; Quinlan JR, 1986, MACH LEARN, V1, P106; Shamsheyeva A, 2004, P SOC PHOTO-OPT INS, V5370, P1548, DOI 10.1117/12.534877; Shamsheyeva A, 2004, Proceedings of the 2004 Intelligent Sensors, Sensor Networks & Information Processing Conference, P439; Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768; STARK P, 2007, HIGH RESOLUTION COMP; Tourassi GD, 1999, RADIOLOGY, V213, P317; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648; van der Walt C., 2006, P 16 ANN S PATT REC, P166; Van De Ville D, 2005, IEEE T IMAGE PROCESS, V14, P1798, DOI 10.1109/TIP.2005.857249; Vapnik V., 1999, NATURE STAT LEARNING; Witten I. H., 2005, MORGAN KAUFMANN SERI, V2nd; Wong JSJ, 2006, LECT NOTES COMPUT SC, V4304, P233; Zavaletta V. A., 2007, MED IMAGING 2007 PHY, V6511, p65111Q; Zrimec T, 2007, ST HEAL T, V129, P1324	35	8	8	0	1	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	0897-1889			J DIGIT IMAGING	J. Digit. Imaging	FEB	2010	23	1					18	30		10.1007/s10278-008-9158-4		13	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	546ZD	WOS:000273853400004	18982390	
J	Biau, G; Cerou, F; Guyader, A				Biau, Gerard; Cerou, Frederic; Guyader, Arnaud			On the Rate of Convergence of the Bagged Nearest Neighbor Estimate	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						bagging; resampling; nearest neighbor estimate; rates of convergence	NONPARAMETRIC REGRESSION	Bagging is a simple way to combine estimates in order to improve their performance. This method, suggested by Breiman in 1996, proceeds by resampling from the original data set, constructing a predictor from each subsample, and decide by combining. By bagging an n-sample, the crude nearest neighbor regression estimate is turned into a consistent weighted nearest neighbor regression estimate, which is amenable to statistical analysis. Letting the resampling size k(n) grows appropriately with n, it is shown that this estimate may achieve optimal rate of convergence, independently from the fact that resampling is done with or without replacement. Since the estimate with the optimal rate of convergence depends on the unknown distribution of the observations, adaptation results by data-splitting are presented.	[Biau, Gerard] Univ Paris 06, LSTA, F-75013 Paris, France; [Biau, Gerard] Univ Paris 06, LPMA, F-75013 Paris, France; [Cerou, Frederic] INRIA Rennes Bretagne Atlantique, Aspi Project Team, F-35042 Rennes, France; [Guyader, Arnaud] Univ Rennes 2, F-35043 Rennes, France	Biau, G (reprint author), Univ Paris 06, LSTA, Boite 158,175 Rue Chevaleret, F-75013 Paris, France.	GERARD.BIAU@UPMC.FR; FREDERIC.CEROU@INRIA.FR; ARNAUD.GUYADER@UHB.FR					BIAU G, 2008, LAYERED NEAREST NEIG; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Buhlmann P, 2002, ANN STAT, V30, P927; Buja A, 2006, STAT SINICA, V16, P323; Cover T. M., 1968, P HAW INT C SYST SCI, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; Devroye L., 1996, PROBABILISTIC THEORY; Dietterich T., 2000, LECT NOTES COMPUTER, P1; Fix E., 1952, 11 USAF SCH AV MED; Fix E., 1951, 4 USAF SCH AV MED; Friedman JH, 2007, J STAT PLAN INFER, V137, P669, DOI 10.1016/j.jspi.2006.06.002; Gradshteyn I. S., 2007, TABLE INTEGRALS SERI; GYORFI L, 1978, IEEE T INFORM THEORY, V29, P509; Gyorfi L, 2002, DISTRIBUTION FREE TH; Hall P, 2005, J ROY STAT SOC B, V67, P363, DOI 10.1111/j.1467-9868.2005.00506.x; Ibragimov I., 1981, STAT ESTIMATION ASYM, P669; Ibragimov I. A., 1982, THEOR PROBAB APPL, V27, P81; IBRAGIMOV IA, 1980, DOKL AKAD NAUK SSSR+, V252, P780; KOLMOGOROV A. N., 1961, AM MATH SOC TRANSL, V17, P277; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; Lin Y, 2006, J AM STAT ASSOC, V101, P578, DOI 10.1198/016214505000001230; PSALTIS D, 1994, IEEE T INFORM THEORY, V40, P820, DOI 10.1109/18.335893; Steele BM, 2009, MACH LEARN, V74, P235, DOI 10.1007/s10994-008-5096-0; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Venkatesh S. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, DOI 10.1145/130385.130396	28	14	15	1	1	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	FEB	2010	11						687	712				26	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	589XC	WOS:000277186500010		
J	Huang, Y; Xu, D; Cham, TJ				Huang, Yi; Xu, Dong; Cham, Tat-Jen			Face and Human Gait Recognition Using Image-to-Class Distance	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY			English	Article						Face recognition; human gait recognition; image-to-class distance	ALGORITHMS; CHALLENGE	We propose a new distance measure for face recognition and human gait recognition. Each probe image (a face image or an average human silhouette image) is represented as a set of local features uniformly sampled over a grid with fixed spacing, and each gallery image is represented as a set of local features sampled at each pixel. We formulate an integer programming problem to compute the distance (referred to as the image-to-class distance) from one probe image to all the gallery images belonging to a certain class, in which any feature of the probe image can be matched to only one feature from one of the gallery images. Considering computational efficiency as well as the fact that face images or average human silhouette images are roughly aligned in the preprocessing step, we also enforce a spatial neighborhood constraint by only allowing neighboring features that are within a given spatial distance to be considered for feature matching. The integer programming problem is further treated as a classical minimum-weight bipartite graph matching problem, which can be efficiently solved with the Kuhn-Munkres algorithm. We perform comprehensive experiments on three benchmark face databases: 1) the CMU PIE database; 2) the FERET database; and 3) the FRGC database, as well as the USF Human ID gait database. The experiments clearly demonstrate the effectiveness of our image-to-class distance.	[Huang, Yi; Cham, Tat-Jen] Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore	Huang, Y (reprint author), Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.	hu0005yi@ntu.edu.sg; dongxu@ntu.edu.sg; ASTJCham@ntu.edu.sg	Xu, Dong/A-3694-2011		Singapore National Research Foundation Interactive Digital Media Research and Development Program [NRF2008IDM-IDM004-018]; MOE AcRF Tier-1 [RG63/07]	Manuscript received September 19, 2008; revised March 19, 2009 and June 10, 2009. First version published November 3, 2009; current version published March 5, 2010. This work was supported by the Singapore National Research Foundation Interactive Digital Media Research and Development Program, under research Grant NRF2008IDM-IDM004-018 and MOE AcRF Tier-1 Grant RG63/07. This paper was recommended by Associate Editor S. Pankanti.	BELHUMEUR P, 1997, IEEE T PATTERN ANAL, V7, P711; BOIMAN O, 2006, P NEUR INF PROC SYST; Boiman O., 2008, P IEEE C COMP VIS PA, P1; CHEN LB, 2004, P AS C COMP VIS; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644; Cootes T., 1999, P BRIT MACH VIS C, V1, P173; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Liu Z., 2004, P IEEE COMP SOC C CO, V4, P211; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863; Lucey S., 2004, P IEEE C COMP VIS PA, V2, P855, DOI 10.1109/CVPR.2004.1315254; LUCEY S, 2005, P BRIT MACH VIS C; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 2005, PROC CVPR IEEE, P947; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Shan S., 2004, P IEEE INT C AUT FAC, P314; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Sivic J., 2003, Proceedings Ninth IEEE International Conference on Computer Vision; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139758; Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418; Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769; Xu D, 2008, IEEE T IMAGE PROCESS, V17, P2256, DOI 10.1109/TIP.2008.2004430	28	16	16	4	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1051-8215			IEEE T CIRC SYST VID	IEEE Trans. Circuits Syst. Video Technol.	MAR	2010	20	3					431	438		10.1109/TCSVT.2009.2035852		8	Engineering, Electrical & Electronic	Engineering	565ND	WOS:000275299600009		
J	Ghasemzadeh, H; Loseu, V; Jafari, R				Ghasemzadeh, Hassan; Loseu, Vitali; Jafari, Roozbeh			Structural Action Recognition in Body Sensor Networks: Distributed Classification Based on String Matching	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Body sensor networks (BSNs); collaborative signal processing; distributed computing; motion primitives; physical movement monitoring	CLUSTER-ANALYSIS	Mobile sensor-based systems are emerging as promising platforms for healthcare monitoring. An important goal of these systems is to extract physiological information about the subject wearing the network. Such information can be used for life logging, quality of life measures, fall detection, extraction of contextual information, and many other applications. Data collected by these sensor nodes are overwhelming, and hence, an efficient data processing technique is essential. In this paper, we present a system using inexpensive, off-the-shelf inertial sensor nodes that constructs motion transcripts from biomedical signals and identifies movements by taking collaboration between the nodes into consideration. Transcripts are built of motion primitives and aim to reduce the complexity of the original data. We then label each primitive with a unique symbol and generate a sequence of symbols, known as motion template, representing a particular action. This model leads to a distributed algorithm for action recognition using edit distance with respect to motion templates. The algorithm reduces the number of active nodes during every classification decision. We present our results using data collected from five normal subjects performing transitional movements. The results clearly illustrate the effectiveness of our framework. In particular, we obtain a classification accuracy of 84.13% with only one sensor node involved in the classification process.	[Ghasemzadeh, Hassan; Loseu, Vitali; Jafari, Roozbeh] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA	Ghasemzadeh, H (reprint author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.	h.ghasemzadeh@utdallas.edu; vitali.loseu@utdallas.edu; rjafari@utdallas.edu					AFALG J, 2007, ADV KNOWL DISCOVERY, P23; Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fihl P, 2006, LECT NOTES COMPUT SC, V4069, P375; FINDLEY LJ, 1981, J NEUROL NEUROSUR PS, V44, P534, DOI 10.1136/jnnp.44.6.534; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Ghasemzadeh H, 2009, IEEE J SEL AREA COMM, V27, P58, DOI 10.1109/JSAC.2009.090107; GHASEMZADEH H, 2009, 31 ANN INT C IEEE EN; GHASEMZADEH H, 2009, P IEEE ACM DES AUT T, P1; Guenterberg E., 2009, P 5 IEEE INT C DISTR, P145; GUERRAFILHO G, FS 05, P70; GUIMARAES G, 2005, P 18 INT C INN APPL, P332; HARMS H, P 4 INT C BOD AR NET; HUSZ Z, P IEEE C ADV VID SIG, P330; Hyman L.M, 1975, PHONOLOGY THEORY ANA; JENKINS OC, P 2 INT JOINT C AUT, P225; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KANG S, 2008, P 6 INT C MOB SYST A, P267, DOI DOI 10.1145/1378600.1378630; Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707; MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1234/12345678; McLachlan GJ, 2008, EM ALGORITHM EXTENSI, V2nd; Musaloiu R., 2007, INT J SENS NETW, V3, P43; Niwase N, 2005, IEICE T INF SYST, VE88D, P2492, DOI 10.1093/ietisy/e88-d.11.2492; POLASTRE J, P 4 INT S INF PROC S, P364; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Stergiou N., 2003, INNOVATIVE ANAL HUMA; STIEFMEIER T, P ICST 2 INT C BOD A, P1; Veltink P H, 1996, IEEE Trans Rehabil Eng, V4, P375, DOI 10.1109/86.547939; Zappi P, 2008, LECT NOTES COMPUT SC, V4913, P17	31	18	20	3	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	MAR	2010	14	2					425	435		10.1109/TITB.2009.2036722		11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	570IG	WOS:000275666100030	20007039	
J	Roh, SB; Ahn, TC; Pedrycz, W				Roh, Seok-Beom; Ahn, Tae-Chon; Pedrycz, Witold			The Refinement of Models With the Aid of the Fuzzy k-Nearest Neighbors Approach	IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT			English	Article						Fuzzy k-nearest neighbors (kNN); global model; incremental model; local model; model refinement	CLASSIFICATION; REGRESSION	In this paper, we propose a new design methodology that supports the development of hybrid incremental models. These models result through an iterative process in which a parametric model and a nonparametric model are combined so that their underlying and complementary functionalities become fully exploited. The parametric component of the hybrid model captures some global relationships between the input variables and the output variable. The nonparametric model focuses on capturing local input-output relationships and thus augments the behavior of the model being formed at the global level. In the underlying design, we consider linear and quadratic regression to be a parametric model, whereas a fuzzy k-nearest neighbors model serves as the nonparametric counterpart of the overall model. Numeric results come from experiments that were carried out on some low-dimensional synthetic data sets and several machine learning data sets from the University of California-Irvine Machine Learning Repository.	[Roh, Seok-Beom; Ahn, Tae-Chon] Wonkwang Univ, Dept Elect Elect & Informat Engn, Iksan 570749, South Korea; [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland; [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2G7, Canada	Roh, SB (reprint author), Wonkwang Univ, Dept Elect Elect & Informat Engn, Iksan 570749, South Korea.	nado@wonkwang.ac.kr; tcahn@wonkwang.ac.kr; pedrycz@ee.ualberta.ca			Wonkwang University	Manuscript received October 8, 2008; revised April 14, 2009. First published September 22, 2009; current version published February 10, 2010. This work was supported in part by the Wonkwang University (2007). The Associate Editor coordinating the review process for this paper was Dr. Gilles Mauris.	Blanzieri E, 2008, IEEE T GEOSCI REMOTE, V46, P1804, DOI 10.1109/TGRS.2008.916090; CHEN S, 1999, J CHIN CHEM SOC-TAIP, V4, P239; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Ferrari S, 2005, IEEE T INSTRUM MEAS, V54, P1463, DOI 10.1109/TIM.2005.851471; Guvenir HA, 2000, KNOWL-BASED SYST, V13, P207; Hardie W., 1990, APPL NONPARAMETRIC R; Hastie T, 2001, ELEMENTS STAT LEARNI; Li W, 2008, IEEE T INSTRUM MEAS, V57, P2273, DOI 10.1109/TIM.2008.922092; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Pedrycz W, 2007, IEEE T FUZZY SYST, V15, P507, DOI 10.1109/TFUZZ.2006.889967; Pedrycz W, 2008, IEEE T INSTRUM MEAS, V57, P829, DOI 10.1109/TIM.2007.913809; Samaniego L, 2008, IEEE T GEOSCI REMOTE, V46, P2112, DOI 10.1109/TGRS.2008.916629; VARALLYAY G, 2006, AGROKEM TALAJTAN, V55, P1; Wang N, 2007, INFORM SCIENCES, V177, P3882, DOI 10.1016/j.ins.2007.03.002; Weatherspoon MH, 2007, IEEE T INSTRUM MEAS, V56, P2067, DOI 10.1109/TIM.2007.895585	15	4	4	2	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9456			IEEE T INSTRUM MEAS	IEEE Trans. Instrum. Meas.	MAR	2010	59	3					604	615		10.1109/TIM.2009.2025070		12	Engineering, Electrical & Electronic; Instruments & Instrumentation	Engineering; Instruments & Instrumentation	553RC	WOS:000274383500014		
J	Wei, JM; Wang, SQ; Yuan, XJ				Wei, Jin-Mao; Wang, Shu-Qin; Yuan, Xiao-Jie			Ensemble Rough Hypercuboid Approach for Classifying Cancers	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Rough sets; rough hypercuboid; explicit region; implicit region; gene expression data	GENE-EXPRESSION SIGNATURES; ARTIFICIAL NEURAL-NETWORKS; FEATURE-SELECTION; NEAREST-NEIGHBOR; MOLECULAR CLASSIFICATION; SUBCELLULAR-LOCALIZATION; CLASS PREDICTION; SETS; PROTEINS; INFORMATION	Cancer classification is the critical basis for patient-tailored therapy. Conventional histological analysis tends to be unreliable because different tumors may have similar appearance. The advances in microarray technology make individualized therapy possible. Various machine learning methods can be employed to classify cancer tissue samples based on microarray data. However, few methods can be elegantly adopted for generating accurate and reliable as well as biologically interpretable rules. In this paper, we introduce an approach for classifying cancers based on the principle of minimal rough fringe. For training rough hypercuboid classifiers from gene expression data sets, the method dynamically evaluates all available genes and sifts the genes with the smallest implicit regions as the dimensions of implicit hypercuboids. An unseen object is predicted to be a certain class if it falls within the corresponding class hypercuboid. Based upon the method, ensemble rough hypercuboid classifiers are subsequently constructed. Experimental results on some open cancer gene expression data sets show that the proposed method is capable of generating accurate and interpretable rules compared with some other machine learning methods. Hence, it is a feasible way of classifying cancer tissues in biomedical applications.	[Wei, Jin-Mao; Yuan, Xiao-Jie] Nankai Univ, Coll Informat Tech Sci, Tianjin 300071, Peoples R China; [Wang, Shu-Qin] NE Normal Univ, Coll Math & Stat, Changchun 130024, Jilin, Peoples R China; [Wang, Shu-Qin] NE Normal Univ, MOE, Key Lab Appl Stat, Changchun 130024, Jilin, Peoples R China	Wei, JM (reprint author), Nankai Univ, Coll Informat Tech Sci, Weijin Rd 94, Tianjin 300071, Peoples R China.	weijm@nankai.edu.cn; wangsq562@nenu.edu.cn; yuanxj@nankai.edu.cn			Science Foundation of Jilin Province [20040529]; Industrialization Foundation of Changchun High-Tech [06GJ20]; National 863 High Technology Research and Development Program of China [2009AA01Z152]	This work was supported by the Science Foundation of Jilin Province under grant 20040529, the Industrialization Foundation of Changchun High-Tech under grant 06GJ20, and the National 863 High Technology Research and Development Program of China under grant 2009AA01Z152. Guo-Ying Wang and Yang Xu collected and preprocessed the data.	Ali K., 1995, LINK ERROR CORRELATI; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ananthanarayana VS, 2003, PATTERN RECOGN LETT, V24, P851, DOI 10.1016/S0167-8655(02)00197-6; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Bazan J., 1994, P S METH INT SYST, P346; BAZAN JG, 1996, P 6 INT C INF PROC M, V3, P1147; Bazan JG, 2006, FUND INFORM, V72, P37; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Bi YX, 2006, ARTIF INTELL REV, V26, P191, DOI 10.1007/s10462-007-9049-y; BUNDY A, 1985, ARTIF INTELL, V27, P137, DOI 10.1016/0004-3702(85)90052-9; CHOU KC, 1995, CRIT REV BIOCHEM MOL, V30, P275, DOI 10.3109/10409239509083488; Chou KC, 2006, CURR MED CHEM, V13, P3263, DOI 10.2174/092986706778773077; Chou KC, 1996, ANAL BIOCHEM, V233, P1, DOI 10.1006/abio.1996.0001; Chou KC, 2007, BIOCHEM BIOPH RES CO, V357, P633, DOI 10.1016/j.bbrc.2007.03.162; Chou KC, 2006, BIOCHEM BIOPH RES CO, V347, P150, DOI 10.1016/j.bbrc.2006.06.059; Chou KC, 2004, CURR MED CHEM, V11, P2105; Chou KC, 2007, BIOCHEM BIOPH RES CO, V360, P339, DOI 10.1016/j.bbrc.2007.06.027; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich T., 2000, LECT NOTES COMPUTER, P1; Duda R. O., 1973, PATTERN CLASSIFICATI; Geman D, 2004, STAT APPL GENET MOL, V3, P19; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Greco S, 2001, EUR J OPER RES, V129, P1, DOI 10.1016/S0377-2217(00)00167-3; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; HU Q, 2006, P 2006 IEEE C MACH L, P13; Hu QH, 2007, PATTERN RECOGN, V40, P3728, DOI 10.1016/j.patcog.2007.04.022; Hu X, 2001, P IEEE INT C DAT MIN, P233; Kedarisetti KD, 2006, BIOCHEM BIOPH RES CO, V348, P981, DOI 10.1016/j.bbrc.2006.07.141; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kim D, 2001, PATTERN RECOGN, V34, P1613, DOI 10.1016/S0031-3203(00)00057-1; Kim HC, 2003, PATTERN RECOGN, V36, P2757, DOI 10.1016/S0031-3203(03)00175-4; Kittler J, 1998, PATTERN ANAL APPL, V1, P18, DOI 10.1007/BF01238023; Lin T. Y., 1997, ROUGH SETS DATA MINI; Lubec G, 2005, PROG NEUROBIOL, V77, P90, DOI 10.1016/j.pneurobio.2005.10.001; Nguyen HS, 2006, LECT NOTES COMPUT SC, V4100, P334; PAWLAK Z, 1988, INT J MAN MACH STUD, V29, P81, DOI 10.1016/S0020-7373(88)80032-4; Pawlak Z., 1991, ROUGH SETS THEORETIC; PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; ROYA A, 2003, PATTERN RECOGN, V24, P895; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; SALZBERG S, 1991, MACH LEARN, V6, P251, DOI 10.1007/BF00114779; Shen HB, 2007, BIOCHEM BIOPH RES CO, V355, P1006, DOI 10.1016/j.bbrc.2007.02.071; Shen HB, 2007, PROTEIN ENG DES SEL, V20, P39, DOI 10.1093/protein-gzl053; Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170; Shen Q, 2002, PATTERN RECOGN, V35, P2425, DOI 10.1016/S0031-3203(01)00229-1; Sindhwani V., 2001, P 1 SIAM INT C DAT M, P5; Statnikov A, 2005, BIOINFORMATICS, V21, P631, DOI 10.1093/bioinformatics/bti033; Su AI, 2001, CANCER RES, V61, P7388; Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4; Tan AC, 2005, BIOINFORMATICS, V21, P3896, DOI 10.1093/bioinformatics/bti631; Theodoridis S., 2003, PATTERN RECOGNITION, Vsecond; THORNTON C, 1987, P INT JOINT C ART IN, P301; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; Tumer K., 1996, Connection Science, V8, DOI 10.1080/095400996116839; Vapnik V. N., 1995, NATURE STAT LEARNING; Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003; Wei JM, 2007, KNOWL-BASED SYST, V20, P695, DOI 10.1016/j.knosys.2006.10.001; WETTSCHERECK D, 1995, MACH LEARN, V19, P5, DOI 10.1007/BF00994658; Yao X, 1998, IEEE T SYST MAN CY B, V28, P417, DOI 10.1109/3477.678637; Yao YY, 2001, INT J INTELL SYST, V16, P87, DOI 10.1002/1098-111X(200101)16:1<87::AID-INT7>3.0.CO;2-S; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6; Zhong N, 2001, J INTELL INF SYST, V16, P199, DOI 10.1023/A:1011219601502; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhou ZH, 2005, IEEE T SYST MAN CY B, V35, P725, DOI 10.1109/TSMCB.2005.845396	69	9	10	5	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	MAR	2010	22	3					381	391		10.1109/TKDE.2009.114		11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	545BL	WOS:000273707000006		
J	Zheng, WM; Lin, ZC; Tang, XO				Zheng, Wenming; Lin, Zhouchen; Tang, Xiaoou			A Rank-One Update Algorithm for Fast Solving Kernel Foley-Sammon Optimal Discriminant Vectors	IEEE TRANSACTIONS ON NEURAL NETWORKS			English	Article						Dimensionality reduction; discriminant analysis; kernel Foley-Sammon optimal discriminant vectors (KFSODVs); principal eigenvector	FACE-RECOGNITION; COMPONENT ANALYSIS; FEATURE-EXTRACTION; OPTIMAL SET; CLASSIFICATION; TRANSFORMATION; CRITERION; LDA	Discriminant analysis plays an important role in statistical pattern recognition. A popular method is the Foley-Sammon optimal discriminant vectors (FSODVs) method, which aims to find an optimal set of discriminant vectors that maximize the Fisher discriminant criterion under the orthogonal constraint. The FSODVs method outperforms the classic Fisher linear discriminant analysis (FLDA) method in the sense that it can solve more discriminant vectors for recognition. Kernel Foley-Sammon optimal discriminant vectors (KFSODVs) is a nonlinear extension of FSODVs via the kernel trick. However, the current KFSODVs algorithm may suffer from the heavy computation problem since it involves computing the inverse of matrices when solving each discriminant vector, resulting in a cubic complexity for each discriminant vector. This is costly when the number of discriminant vectors to be computed is large. In this paper, we propose a fast algorithm for solving the KFSODVs, which is based on rank-one update (ROU) of the eigensytems. It only requires a square complexity for each discriminant vector. Moreover, we also generalize our method to efficiently solve a family of optimally constrained generalized Rayleigh quotient (OCGRQ) problems which include many existing dimensionality reduction techniques. We conduct extensive experiments on several real data sets to demonstrate the effectiveness of the proposed algorithms.	[Zheng, Wenming] Southeast Univ, Res Ctr Learning Sci, Minist Educ, Key Lab Child Dev & Learning Sci, Nanjing 210096, Jiangsu, Peoples R China; [Lin, Zhouchen; Tang, Xiaoou] Microsoft Res Asia, Beijing 100080, Peoples R China	Zheng, WM (reprint author), Southeast Univ, Res Ctr Learning Sci, Minist Educ, Key Lab Child Dev & Learning Sci, Nanjing 210096, Jiangsu, Peoples R China.	wenming_zheng@seu.edu.cn; zhoulin@microsoft.com; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012		Natural Science Foundation of China (NSFC) [60503023, 60872160]; Southeast University of China [XJ2008320]	This work was supported in part by the Natural Science Foundation of China (NSFC) under Grants 60503023 and 60872160, and in part by the Science Technology Foundation of Southeast University of China under Grant XJ2008320.	Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; BELHUMEUR P, 1997, IEEE T PATTERN ANAL, V7, P711; Cai D., 2005, P 28 ANN INT ACM SIG, P3, DOI 10.1145/1076034.1076039; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121; Fisher RA, 1936, ANN EUGENIC, V7, P179; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; Fukunaga K., 1990, INTRO STAT PATTERN R; Golub G. H., 1996, MATRIX COMPUTATIONS, VThird; Graham D. B., 1998, NATO ASI SERIES F, V163, P446; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4; Liang YX, 2007, PATTERN RECOGN, V40, P3606, DOI 10.1016/j.patcog.2007.03.030; Liang ZZ, 2005, PATTERN RECOGN, V38, P307, DOI 10.1016/j.patcog.2004.06.006; LIU K, 1992, PATTERN RECOGN, V25, P731, DOI 10.1016/0031-3203(92)90136-7; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Martinez A., 1998, 24 CVC TECH; OKADA T, 1985, PATTERN RECOGN, V18, P139, DOI 10.1016/0031-3203(85)90037-8; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Qin AK, 2005, PATTERN RECOGN, V38, P613, DOI 10.1016/j.patcog.2004.09.007; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SWETS D, 1996, IEEE T PATTERN ANAL, V8, P831; WANG X, 2003, P 9 IEEE INT C COMP, V1, P13; Wang XG, 2004, PROC CVPR IEEE, P564; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230; Ye JP, 2005, J MACH LEARN RES, V6, P483; Zheng WM, 2005, IEEE T NEURAL NETWOR, V16, P1, DOI 10.1109/TNN.2004.836239; Zheng WM, 2009, IEEE SIGNAL PROC LET, V16, P766, DOI 10.1109/LSP.2009.2023939; Zheng WM, 2006, NEURAL COMPUT, V18, P979	31	1	1	5	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9227			IEEE T NEURAL NETWOR	IEEE Trans. Neural Netw.	MAR	2010	21	3					393	403		10.1109/TNN.2009.2037149		11	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Computer Science; Engineering	562HH	WOS:000275040300003	20089474	
J	Caulier, Y				Caulier, Yannick			Inspection of complex surfaces by means of structured light patterns	OPTICS EXPRESS			English	Article								This paper addresses the generalization of a surface inspection methodology developed within an industrial context for the characterization of specular cylindrical surfaces. The principle relies on the interpretation of a stripe pattern, obtained after projecting a structured light onto the surface to be inspected. The main objective of this paper is to apply this technique to a broader range of surface geometries and types, i.e. to free-form rough and free-form specular shapes. One major purpose of this paper is to propose a general free-form stripe image interpretation approach on the basis of a four step procedure: (i) comparison of different feature-based image content description techniques, (ii) determination of optimal feature sub-groups, (iii) fusion of the most appropriate ones, and (iv) selection of the optimal features. The first part of this paper is dedicated to the general problem statement with the definition of different image data sets that correspond to various types of free-form rough and specular shapes recorded with a structured illumination. The second part deals with the definition and optimization of the most appropriate pattern recognition process. It is shown that this approach leads to an increase in the classification rates of more than 2 % between the initial fused set and the selected one. Then, it is demonstrated that with approximately a fourth of the initial features, similar high classification rates of free-form surfaces can be obtained. (C) 2010 Optical Society of America	Fraunhofer Inst Integrated Circuits IIS, Dept Proc Integrated Inspect Syst, D-91058 Erlangen, Germany	Caulier, Y (reprint author), Fraunhofer Inst Integrated Circuits IIS, Dept Proc Integrated Inspect Syst, D-91058 Erlangen, Germany.	yannick.caulier@iis.fraunhofer.de			Bavarian Research Foundation BFS (Bayerische Forschungsstiftung)	The author would like to thank the Bavarian Research Foundation BFS (Bayerische Forschungsstiftung) for its financial support.	*AC 3D, 2005, FE SUBSTR BUMP INSP; BESL JP, 1985, ACM COMPUT SURV, V17, P75; CAULIER Y, 2007, EURASIP J IMAGE VIDE, V2007; CAULIER Y, 2008, J OPT ENG, V47; *COM AG, 2005, FEINF FOX HIGH RES 2; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DELCROIX G, 2001, INT SOC ELECT IMAGIN, V10, P196; Gutierrez-Osuna R, 2002, IEEE SENS J, V2, P189, DOI 10.1109/JSEN.2002.800688; HUANG Z, 1992, 11 INT C IM SPEECH S, V3, P105; Kammel S, 2004, THESIS U KARLSRUHE; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence; Kunttu I, 2006, MACH VISION APPL, V17, P211, DOI 10.1007/s00138-006-0030-6; Leon FP, 1997, P SOC PHOTO-OPT INS, V3208, P394; LI WB, 2005, IEEE T ANTENN PROPAG, V53, P1154; MARINO P, 1999, 25 ANN C IEEE IND EL, V3, P1330; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P208, DOI 10.1109/70.54736; PERNKOPF F, 2004, P 17 INT C PATT REC; PETZ M, 2002, OPTICAL 3D MEASUREME; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; REINDL I, 2007, IEEE C INSTR MEAS IM; SEULIN R, 2001, 5 INT C QUAL CONTR A; *SOLV, 2007, PREC 3D WAF BUMP INS; SOON HS, 2005, FRINGE 2005 FAULT DE; Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6; UNSALAN C, 1998, THESIS U HACETTEPE T; Weska J. S., 1978, COMPUT GRAPHICS IMAG, V7, P259; WILLIAMS A, 2008, INSPECT MAGAZINE; Witten I. H., 2008, M KAUFMANN SERIES DA; WOODHAM RJ, 1991, PHOTOMETRIC STEREO L	29	6	7	2	6	OPTICAL SOC AMER	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	1094-4087			OPT EXPRESS	Opt. Express	MAR 29	2010	18	7					6642	6660		10.1364/OE.18.006642		19	Optics	Optics	582MP	WOS:000276602000024	20389688	
J	Ghiassi, M; Burnley, C				Ghiassi, M.; Burnley, C.			Measuring effectiveness of a dynamic artificial neural network algorithm for classification problems	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Classification; Dynamic artificial neural networks; Discriminant analysis; Nearest neighbor; Support vector machines; Pattern recognition	NEAREST-NEIGHBOR CLASSIFICATION; SUPPORT VECTOR MACHINES; DISCRIMINANT-ANALYSIS; COVARIANCE MATRICES; CLASSIFIERS	Classification is the process of assigning an object to one of a set of classes based on its attributes. Classification problems have been examined in fields as diverse as biology, medicine, business, image recognition, and forensics. Developing more accurate and widely applicable classification methods has significant implications in these and many other fields. This paper presents a dynamic artificial neural network (DAN2) as an alternate approach for solving classification problems. We show DAN2 to be an effective approach and compare its performance with linear discriminant analysis, quadratic discriminant analysis, k-nearest neighbor algorithms, support vector machines, and traditional artificial neural networks using benchmark and real-world application data sets. These data sets vary in the number of classes (two vs. multiple) and the source of the data (synthetic vs. real-world). We found DAN2 to be a very effective classification method for two-class data sets with accuracy improvements as high as 37.2% when compared to the other methods. We also introduce a hierarchical DAN2 model for multiple class data sets that shows marked improvements (up to 89%) over all other methods, and offers better accuracy in all cases. (C) 2009 Elsevier Ltd. All rights reserved.	[Ghiassi, M.; Burnley, C.] Santa Clara Univ, Santa Clara, CA 95053 USA	Ghiassi, M (reprint author), Santa Clara Univ, 316 P Lucas Hall,500 El Camino Real, Santa Clara, CA 95053 USA.	mghiassi@scu.edu; corrinaburnley@gmail.com					Amasyali MF, 2008, IEEE T NEURAL NETWOR, V19, P356, DOI 10.1109/TNN.2007.910729; ANDERSON TW, 1962, ANN MATH STAT, V33, P420, DOI 10.1214/aoms/1177704568; Asuncion A., 2007, UCI MACHINE LEARNING; Berardi VL, 1999, DECISION SCI, V30, P659, DOI 10.1111/j.1540-5915.1999.tb00902.x; BILLINGS SA, 2002, NEURAL NETWORKS, V15, P262; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; CHAOVALITWONGSE W, 2007, IEEE T SYSTEMS MAN A, V37; CHRISTIANINI N., 2000, INTRO SUPPORT VECTOR; Chu S, 1998, SCIENCE, V282, P699, DOI 10.1126/science.282.5389.699; CLUNIESROSS CW, 1960, BIOMETRIKA, V47, P185, DOI 10.2307/2332972; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CURRAM SP, 1994, J OPER RES SOC, V45, P440, DOI 10.2307/2584215; Duda R O, 2001, PATTERN CLASSIFICATI; ENAS GG, 1986, COMPUT MATH APPL-A, V12, P235, DOI 10.1016/0898-1221(86)90076-3; Fisher RA, 1936, ANN EUGENIC, V7, P465; FIX E, 1951, 4 USAF SCH AV; FIX E, 1952, 11 USAF SCH AV; Ghiassi M., 2005, INT J FORECASTING, V21, P241; Ghiassi M, 2005, NEUROCOMPUTING, V63, P397, DOI 10.1016/j.neucom.2004.03.014; HART A, 1992, J OPER RES SOC, V43, P215, DOI 10.1057/jors.1992.31; Kim N, 2003, IEEE T NEURAL NETWOR, V14, P1065, DOI 10.1109/TNN.2003.816037; Lachenbruch P. A., 1973, COMMUN STAT, V1, P39, DOI 10.1080/03610917308542640; Lee J, 2007, IEEE T GEOSCI REMOTE, V45, P2953, DOI 10.1109/TGRS.2007.900675; Liang Yulan, 2005, Int J Bioinform Res Appl, V1, P399, DOI 10.1504/IJBRA.2005.008443; MARKS S, 1974, J AM STAT ASSOC, V69, P555, DOI 10.2307/2285696; Muezzinoglu MK, 2006, PATTERN RECOGN, V39, P747, DOI 10.1016/j.patcog.2005.10.026; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Panel on Discrimination Analysis Classification and Clustering, 1989, STAT SCI, V4, P34; Porter WA, 1996, INFORM SCIENCES, V94, P151, DOI 10.1016/0020-0255(96)00130-2; *RAPIDMINERCOMMUNI, 2008, RAP 1 GMBH VERS 4 2; RIPLEY BD, 1994, J ROY STAT SOC B MET, V56, P409; RUBIN PA, 1990, DECISION SCI, V21, P373, DOI 10.1111/j.1540-5915.1990.tb01691.x; SMITH CAB, 1947, ANN EUGENIC, V13, P272; *SPSS INC, 2000, CLEM DAT MIN SYST; Tsai CF, 2008, EXPERT SYST, V25, P380, DOI 10.1111/j.1468-0394.2008.00449.x; Viaene S, 2002, J RISK INSUR, V69, P373, DOI 10.1111/1539-6975.00023; YOON YO, 1993, J OPER RES SOC, V44, P51, DOI 10.2307/2584434; Zhang GP, 2001, COMPUT OPER RES, V28, P1183, DOI 10.1016/S0305-0548(00)00033-2	38	10	12	3	6	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	APR	2010	37	4					3118	3128		10.1016/j.eswa.2009.09.017		11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Computer Science; Engineering; Operations Research & Management Science	551JB	WOS:000274202900047		
J	Biau, G; Cerou, F; Guyader, A				Biau, Gerard; Cerou, Frederic; Guyader, Arnaud			Rates of Convergence of the Functional k-Nearest Neighbor Estimate	IEEE TRANSACTIONS ON INFORMATION THEORY			English	Article						Compact embedding; nearest neighbor estimate; rates of convergence; regression estimation; reproducing kernel Hilbert space; Sobolev space		Let F be a separable Banach space, and let (X,Y) be a random pair taking values in F x R. Motivated by a broad range of potential applications, we investigate rates of convergence of the k-nearest neighbor estimate r(n)(x) of the regression function r(x) = E[Y vertical bar X = x], based on n independent copies of the pair (X, Y). Using compact embedding theory, we present explicit and general finite sample bounds on the expected squared difference E[r(n)(X) - r(X)](2) and particularize our results to classical function spaces such as Sobolev spaces, Besov spaces, and reproducing kernel Hilbert spaces.	[Biau, Gerard] Univ Paris 06, LSTA, F-75013 Paris, France; [Biau, Gerard] Univ Paris 06, LPMA, F-75013 Paris, France; [Cerou, Frederic; Guyader, Arnaud] INRIA Rennes Bretagne Atlantique Aspi Project Tea, F-35042 Rennes, France; [Guyader, Arnaud] Univ Rennes 2, F-35043 Rennes, France	Biau, G (reprint author), Univ Paris 06, LSTA, F-75013 Paris, France.	gerard.biau@upmc.fr; Fred-eric.Cerou@inria.fr; arnaud.guyader@uhb.fr					ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI DOI 10.2307/1990404; CEROU F, 2006, ESAIM-PROBAB STAT, V10, P340, DOI 10.1051/ps:2006014; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Cucker F, 2002, B AM MATH SOC, V39, P1; Devroye L., 1996, PROBABILISTIC THEORY; EDMUNDS LE, 1996, FUNCTION SPACES ENTR; Fix E., 1952, 11 USAF SCH AV MED; Fix E., 1951, 4 USAF SCH AV MED; Gyorfi L, 2002, DISTRIBUTION FREE TH; IBRAGIMOV I, 1981, STAT ESTIMATION SYMP; KOLMOGOROV A. N., 1961, AM MATH SOC TRANSL, V17, P277; KULKARNI SR, 1995, IEEE T INFORM THEORY, V41, P1028, DOI 10.1109/18.391248; PREISS D, 1981, COMMENT MATH U CAROL, V1, P181; Ramsay J. O., 1997, FUNCTIONAL DATA ANAL; Scholkopf B., 2002, LEARNING KERNELS; Shawe- Taylor J., 2004, KERNEL METHODS PATTE; STONE CJ, 1977, ANN STAT, V5, P595, DOI 10.1214/aos/1176343886; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635	18	5	5	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9448	1557-9654		IEEE T INFORM THEORY	IEEE Trans. Inf. Theory	APR	2010	56	4					2034	2040		10.1109/TIT.2010.2040857		7	Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	574OG	WOS:000275999500042		
J	Cheng, HB; Tan, PN; Jin, R				Cheng, Haibin; Tan, Pang-Ning; Jin, Rong			Efficient Algorithm for Localized Support Vector Machine	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Classification; support vector machine; kernel-based learning; local learning	NEAREST-NEIGHBOR CLASSIFIERS; CLASSIFICATION	This paper presents a framework called Localized Support Vector Machine (LSVM) for classifying data with nonlinear decision surfaces. Instead of building a sophisticated global model from the training data, LSVM constructs multiple linear SVMs, each of which is designed to accurately classify a given test example. A major limitation of this framework is its high computational cost since a unique model must be constructed for each test example. To overcome this limitation, we propose an efficient implementation of LSVM, termed Profile SVM (PSVM). PSVM partitions the training examples into clusters and builds a separate linear SVM model for each cluster. Our empirical results show that 1) LSVM and PSVM outperform nonlinear SVM for all 20 of the evaluated data sets and 2) PSVM achieves comparable performance as LSVM in terms of model accuracy but with significant computational savings. We also demonstrate the efficacy of the proposed approaches in terms of classifying data with spatial and temporal dependencies.	[Cheng, Haibin] Yahoo Labs, Santa Clara, CA 95051 USA; [Tan, Pang-Ning; Jin, Rong] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48823 USA	Cheng, HB (reprint author), Yahoo Labs, 2627 Pilot Knob Dr, Santa Clara, CA 95051 USA.	hcheng@yahoo-inc.com; ptan@msu.edu; rongjin@msu.edu			US National Science Foundation (NSF) [0712987]	The authors would like to thank Dr Ron Bekkerman, Dr Chih-Chung Chang, and Dr Chih-Jen Lin for sharing the Enron e-mail data and LIBSVM [9] tools. This work is partially supported by the US National Science Foundation (NSF)-III Grant No. 0712987.	Aizerman M.A., 1964, AUTOMAT REM CONTR, V25, P821; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; BACH F, 2004, UCBCSD041307 EL ENG; Bekkerman Ron, 2004, AUTOMATIC CATEGORIZA; Bellman R., 1961, ADAPTIVE CONTROL PRO; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262; Burges C. J. C., 1998, DATA MIN KNOWL DISC, V2, DOI DOI 10.1023/A:1009715923555; Chang C.C., 2001, LIBSVM LIB SUPPORT V; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Frohlich H, 2005, P IEEE INT JOINT C N, V3, P1431, DOI 10.1109/IJCNN.2005.1556085; Gilardi N., 2000, J GEOGRAPHIC INFORMA, V4, P11; Gunn S. R., 1998, SUPPORT VECTOR MACHI; Hand DJ, 2003, PATTERN RECOGN LETT, V24, P1555, DOI 10.1016/S0167-8655(02)00394-X; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; HECHENBICHLER K, 2006, 386 SFB; Joachims T., 1999, P INT C MACH LEARN; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; KIRITCHENKO S, 2004, P INT INT INF SYST I, P523; KOPERSKI K, 1998, P INT S SPAT DAT HAN; Lau K W, 2008, Pattern Recognition, V41, DOI 10.1016/j.patcog.2007.08.013; Lin Chih-Jen, 2001, COMP METHODS MULTICL; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Newman D., 1998, UCI REPOSITORY MACHI; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; PAWLAK M, 1994, P INT C PATT REC; Platt JC, 2000, ADV NEUR IN, V12, P547; Rifkin R, 2004, J MACH LEARN RES, V5, P101; RODDICK JF, 2001, TEMPORAL SPATIAL SPA; Schrijver A., 1998, THEORY LINEAR INTEGE; Vapnik V., 1998, STAT LEARNING THEORY; Vincent P, 2001, ADV NEURAL INFORM PR, P985; Weinberger K., 2005, ADV NEURAL INFORM PR, V18, P1473; Zhang H, 2006, P IEEE C COMP VIS PA	35	13	14	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347			IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	APR	2010	22	4					537	549		10.1109/TKDE.2009.116		13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Computer Science; Engineering	557FK	WOS:000274654800006		
J	Maas, MC; van der Laan, DJ; van Eijk, CWE; Schaart, DR; Beekman, FJ; Bruyndonckx, P; Lemaitre, C				Maas, Marnix C.; van der Laan, D. J. (Jan); van Eijk, Carel W. E.; Schaart, Dennis R.; Beekman, Freek J.; Bruyndonckx, Peter; Lemaitre, Cedric			Model of the point spread function of monolithic scintillator PET detectors for perpendicular incidence	MEDICAL PHYSICS			English	Article						avalanche photodiodes; positron emission tomography; solid scintillation detectors	SMALL-ANIMAL PET; HIGH-RESOLUTION; SIMULATION TOOLKIT; APD ARRAYS; BLOCKS; LSO; RECONSTRUCTION; DIMENSIONS; SCANNER; MODULES	Methods: A PSF model was developed that essentially consists of two convolved components, one accounting for the spatial distribution of the energy deposited by annihilation photons within the crystal, and the other for the influences of statistical signal fluctuations and electronic noise. The model was validated through comparison with spatial resolution measurements on a detector consisting of an LYSO:Ce(3+) crystal read out by two APD arrays. Results: The model is shown to describe the measured detector spatial response well at the noise levels found in the experiments. In addition, it is demonstrated how the model can be used to correct the measured spatial response for the influence of the finite diameter of the annihilation photon beam used in the experiments, thus obtaining an estimate of the intrinsic detector PSF. Conclusions: Despite its simplicity, the proposed model is an accurate tool for analyzing the detector PSF of monolithic scintillator detectors and can be used to estimate the intrinsic detector PSF from the measured one.	[Maas, Marnix C.; van der Laan, D. J. (Jan); van Eijk, Carel W. E.; Schaart, Dennis R.; Beekman, Freek J.] Delft Univ Technol, NL-2629 JB Delft, Netherlands; [Beekman, Freek J.] Univ Med Ctr Utrecht, Rudolf Magnus Inst, Utrecht, Netherlands; [Beekman, Freek J.] Image Sci Inst, Utrecht, Netherlands; [Bruyndonckx, Peter; Lemaitre, Cedric] Vrije Univ Brussels, B-1050 Brussels, Belgium	Schaart, DR (reprint author), Delft Univ Technol, Mekelweg 15, NL-2629 JB Delft, Netherlands.	d.r.schaart@tudelft.nl	Schaart, Dennis/C-7136-2014; Maas, Marnix/J-5101-2014	Schaart, Dennis/0000-0002-3199-5608; 			Abreu MC, 2006, IEEE T NUCL SCI, V53, P71, DOI 10.1109/TNS.2006.870173; Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8; Aliaga RJ, 2006, IEEE T NUCL SCI, V53, P776, DOI 10.1109/TNS.2006.875438; Bruyndonckx P, 2006, IEEE NUCL SCI CONF R, P2518, DOI 10.1109/NSSMIC.2006.354422; Bruyndonckx P, 2008, IEEE T NUCL SCI, V55, P918, DOI 10.1109/TNS.2008.922811; Bruyndonckx P, 2004, IEEE T NUCL SCI, V51, P2520, DOI 10.1109/TNS.2004.835782; Bruyndonckx P, 2006, IEEE T NUCL SCI, V53, P2536, DOI 10.1109/TNS.2006.882799; CHERRY S, 2004, PHYS MED BIOL, V13, pR48; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Jan S, 2004, PHYS MED BIOL, V49, P4543, DOI 10.1088/0031-9155/49/19/007; JEAN YC, 1990, PHYS REV B, V42, P9705, DOI 10.1103/PhysRevB.42.9705; Joung J, 2002, NUCL INSTRUM METH A, V489, P584, DOI 10.1016/S0168-9002(02)00861-6; KARP JS, 1990, J NUCL MED, V31, P617; Krishnamoorthy S, 2005, IEEE NUCL SCI CONF R, P2845; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Leahy RM, 2000, STAT COMPUT, V10, P147, DOI 10.1023/A:1008946426658; LeBlanc JW, 2004, IEEE T NUCL SCI, V51, P746, DOI 10.1109/TNS.2004.829754; Lerche CW, 2009, NUCL INSTRUM METH A, V604, P359, DOI 10.1016/j.nima.2009.01.060; Maas MC, 2008, IEEE T NUCL SCI, V55, P842, DOI 10.1109/TNS.2008.921493; Maas MC, 2004, IEEE NUCL SCI CONF R, P2942; Maas MC, 2009, PHYS MED BIOL, V54, P1893, DOI 10.1088/0031-9155/54/7/003; McCallum S, 2005, PHYS MED BIOL, V50, P4187, DOI 10.1088/0031-9155/50/17/019; MIYAOKA RS, 2008, IEEE NUCL SCI S, P4688; Moehrs S, 2006, PHYS MED BIOL, V51, P1113, DOI 10.1088/0031-9155/51/5/004; Panin VY, 2006, IEEE T MED IMAGING, V25, P907, DOI 10.1109/TMI.2006.876171; Qi JY, 1998, PHYS MED BIOL, V43, P1001, DOI 10.1088/0031-9155/43/4/027; Schaart DR, 2009, PHYS MED BIOL, V54, P3501, DOI 10.1088/0031-9155/54/11/015; van der Laan DJ, 2007, NUCL INSTRUM METH A, V571, P227, DOI 10.1016/j.nima.2006.10.069; VANEIJK CWE, 2008, IEEE NUCL SCI S, P3861; Vaska P, 2004, IEEE NUCL SCI CONF R, P3463; Webb AR, 2002, STAT PATTERN RECOGNI	31	5	5	1	2	AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS	MELVILLE	STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA	0094-2405			MED PHYS	Med. Phys.	APR	2010	37	4					1904	1913		10.1118/1.3355889		10	Radiology, Nuclear Medicine & Medical Imaging	Radiology, Nuclear Medicine & Medical Imaging	577GT	WOS:000276211200055	20443512	
J	Toyama, J; Kudo, M; Imai, H				Toyama, Jun; Kudo, Mineichi; Imai, Hideyuki			Probably correct k-nearest neighbor search in high dimensions	PATTERN RECOGNITION			English	Article						Pattern recognition; The k-nearest neighbor method; Probably correct algorithm; PAC framework	ALGORITHM; RULE	A novel approach for k-nearest neighbor (k-NN) searching with Euclidean metric is described. It is well known that many sophisticated algorithms cannot beat the brute-force algorithm when the dimensionality is high. In this study, a probably correct approach, in which the correct set of k-nearest neighbors is obtained in high probability, is proposed for greatly reducing the searching time. We exploit the marginal distribution of the k th nearest neighbors in low dimensions, which is estimated from the stored data (an empirical percentile approach). We analyze the basic nature of the marginal distribution and show the advantage of the implemented algorithm, which is a probabilistic variant of the partial distance searching. Its query time is sublinear in data size n, that is, O(mn delta) with S=o(1) in n and delta <= 1, for any fixed dimension m. (C) 2009 Elsevier Ltd. All rights reserved.	[Toyama, Jun; Kudo, Mineichi; Imai, Hideyuki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Div Comp Sci, Sapporo, Hokkaido 0600814, Japan	Kudo, M (reprint author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Div Comp Sci, Sapporo, Hokkaido 0600814, Japan.	mine@main.ist.hokudai.ac.jp	Kudo, Mineichi/B-9973-2011				Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; Andoni Alexandr, 2006, NEAREST NEIGHBOR MET; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Baccini A., 1996, P INT C ORD SYMB DAT, P359, DOI 10.1007/978-3-642-61159-9_32; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; Berchtold S., 1998, P 14 IEEE C DAT ENG, P23; Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28; Califano A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), DOI 10.1109/CVPR.1991.139656; CHANG CC, 1993, PATTERN RECOGN LETT, V14, P625, DOI 10.1016/0167-8655(93)90047-H; Cheng D. Y., 1984, P IEEE INT C AC SPEE, P372; Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), DOI 10.1109/ICDE.2000.839417; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CUNN YL, MNIST DATASET HANDWR; DASARATHY BV, 1994, IEEE T SYST MAN CYB, V24, P511, DOI 10.1109/21.278999; Djouadi A, 1997, IEEE T PATTERN ANAL, V19, P277, DOI 10.1109/34.584107; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; Fukunaga K., 1990, INTRO STAT PATTERN R; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Guttman A., 1984, ACM SIGMOD, P47; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, DOI 10.1145/276698.276876; Kleinberg J.M., 1997, P 29 ANN ACM S THEOR, P599, DOI 10.1145/258533.258653; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; MANEEWONGVATANA S, 2001, LECT NOTES COMPUTER, V2513, P172; McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB; Wolfson H.J., 1990, P 1 EUR C COMP VIS, P526	31	8	10	1	3	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0031-3203			PATTERN RECOGN	Pattern Recognit.	APR	2010	43	4					1361	1372		10.1016/j.patcog.2009.09.026		12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	561CW	WOS:000274954100014		
J	Wei, XL; Li, KC				Wei, Xuelian; Li, Ker-Chau			Exploring the within- and between-class correlation distributions for tumor classification	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						cancer research; gene expression	GENE-EXPRESSION; PROSTATE-CANCER; PREDICTION; PATTERNS; LUNG; ADENOCARCINOMA; DISCOVERY; LEUKEMIA; LOCI	To many biomedical researchers, effective tumor classification methods such as the support vector machine often appear like a black box not only because the procedures are complex but also because the required specifications, such as the choice of a kernel function, suffer from a clear guidance either mathematically or biologically. As commonly observed, samples within the same tumor class tend to be more similar in gene expression than samples from different tumor classes. But can this well-received observation lead to a useful procedure of classification and prediction? To address this issue, we first conceived a statistical framework and derived general conditions to serve as the theoretical foundation that supported the aforementioned empirical observation. Then we constructed a classification procedure that fully utilized the information obtained by comparing the distributions of within-class correlations with between-class correlations via Kullback-Leibler divergence. We compared our approach with many machine-learning techniques by applying to 22 binary- and multiclass gene-expression datasets involving human cancers. The results showed that our method performed as efficiently as support vector machine and Naive Bayesian and outperformed other learning methods (decision trees, linear discriminate analysis, and k-nearest neighbor). In addition, we conducted a simulation study and showed that our method would be more effective if the arriving new samples are subject to the often-encountered baseline shift or increased noise level problems. Our method can be extended for general classification problems when only the similarity scores between samples are available.	[Wei, Xuelian; Li, Ker-Chau] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Li, Ker-Chau] Acad Sinica, Inst Stat Sci, Taipei 115, Taiwan	Li, KC (reprint author), Univ Calif Los Angeles, Dept Stat, 8125 Math Sci Bldg,Box 951554, Los Angeles, CA 90095 USA.	kcli@stat.ucla.edu			National Science Foundation [DMS0406091, DMS-0707160]; National Science Council, Taiwan [NSC95-3114-P-002-005-Y, NSC97-2627-P-001-003, NSC98-2314-B-001-001-MY3]	This work was supported in part by National Science Foundation Grants DMS0406091 and DMS-0707160 and by National Science Council Grants from Taiwan NSC95-3114-P-002-005-Y, NSC97-2627-P-001-003, and NSC98-2314-B-001-001-MY3.	Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765; Berry R, 2000, AM J HUM GENET, V67, P82, DOI 10.1086/302994; Berthon P, 1998, AM J HUM GENET, V62, P1416, DOI 10.1086/301879; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DONG JT, 1995, SCIENCE, V268, P884, DOI 10.1126/science.7754374; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Fukunaga K., 1990, INTRO STAT PATTERN R, P592; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Lapointe J, 2004, P NATL ACAD SCI USA, V101, P811, DOI 10.1073/pnas.0304146101; Patrick E. A., 1972, FUNDAMENTALS PATTERN; Perou CM, 2000, NATURE, V406, P747, DOI 10.1038/35021093; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Qiu P, 2005, BIOINFORMATICS, V21, P3114, DOI 10.1093/bioinformatics/bti483; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100; VINCENT T, 2005, CANC PRINCIPLES PRAC; Welsh JB, 2001, CANCER RES, V61, P5974; Wigle DA, 2002, CANCER RES, V62, P3005; Witte JS, 2000, AM J HUM GENET, V67, P92, DOI 10.1086/302960; Wong DJ, 2008, CANCER RES, V68, P369, DOI 10.1158/0008-5472.CAN-07-0382; Xu JF, 2001, HUM GENET, V108, P335, DOI 10.1007/s004390100488; Yeoh EJ, 2002, CANCER CELL, V1, P133, DOI 10.1016/S1535-6108(02)00032-6	27	11	11	2	4	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424			P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	APR 13	2010	107	15					6737	6742		10.1073/pnas.0910140107		6	Multidisciplinary Sciences	Science & Technology - Other Topics	583AC	WOS:000276642100034	20339085	
J	Kassner, A; Thornhill, RE				Kassner, A.; Thornhill, R. E.			Texture Analysis: A Review of Neurologic MR Imaging Applications	AMERICAN JOURNAL OF NEURORADIOLOGY			English	Review							ACUTE ISCHEMIC-STROKE; MAGNETIC-RESONANCE SPECTROSCOPY; PROGRESSIVE MULTIPLE-SCLEROSIS; BRAIN-TUMOR CHARACTERIZATION; EUROPEAN-ECONOMIC-COMMUNITY; CONCERTED RESEARCH-PROJECT; FOCAL CORTICAL DYSPLASIA; PATTERN-RECOGNITION; TISSUE CHARACTERIZATION; INTRACRANIAL TUMORS	Texture analysis describes a variety of image-analysis techniques that quantify the variation in surface intensity or patterns, including some that are imperceptible to the human visual system Texture analysis may be particularly well-suited for lesion segmentation and characterization and for the longitudinal monitoring of disease or recovery We begin this review by outlining the general procedure for performing texture analysis, identifying some potential pitfalls and strategies for avoiding them We then provide an overview of some intriguing neuro-MR imaging applications of texture analysis, particularly in the characterization of brain tumors, prediction of seizures in epilepsy, and a host of applications to MS	[Kassner, A.; Thornhill, R. E.] Univ Toronto, Dept Med Imaging, Toronto, ON M5S 3E2, Canada; [Kassner, A.; Thornhill, R. E.] Hosp Sick Children, Div Physiol & Expt Med, Toronto, ON M5G 1X8, Canada	Kassner, A (reprint author), Univ Toronto, Dept Med Imaging, Fitzgerald Bldg,Room 125,150 Coll St, Toronto, ON M5S 3E2, Canada.		Kassner, Andrea/F-3847-2010		Canadian Stroke Network; Canadian Institutes of Health Research; Canada Research Chair Program	this work was supported by the Canadian Stroke Network, the Canadian Institutes of Health Research, and the Canada Research Chair Program	ANDERSON RE, 1989, JAMA-J AM MED ASSOC, V261, P1610, DOI 10.1001/jama.261.11.1610; Antel SB, 2003, NEUROIMAGE, V19, P1748, DOI 10.1016/S1053-8119(03)00226-X; Avoli M, 1999, ANN NEUROL, V46, P816, DOI 10.1002/1531-8249(199912)46:6<816::AID-ANA3>3.0.CO;2-O; Barkovich AJ, 1996, J CLIN NEUROPHYSIOL, V13, P481, DOI 10.1097/00004691-199611000-00003; Bernasconi A, 2001, ANN NEUROL, V49, P770, DOI 10.1002/ana.1013; Bonilha L, 2003, EPILEPSIA, V44, P1546, DOI 10.1111/j.0013-9580.2003.27103.x; Breij ECW, 2008, ANN NEUROL, V63, P16, DOI 10.1002/ana.21311; Brown R, 2008, CLIN CANCER RES, V14, P2357, DOI 10.1158/1078-0432.CCR-07-1964; CHIEN YP, 1974, IEEE T SYST MAN CYB, VMC 4, P145, DOI 10.1109/TSMC.1974.5409108; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DARLING EM, 1968, IEEE T SYST SCI CYB, VSSC4, P38, DOI 10.1109/TSSC.1968.300186; Daubechies I., 1992, 10 LECT WAVELETS; Davies GR, 2005, J NEUROL, V252, P1037, DOI 10.1007/s00415-005-0808-x; Drabycz S., 2009, NEUROIMAGE, V49, P1398; EARNEST F, 1988, RADIOLOGY, V166, P823; Freeborough PA, 1998, IEEE T MED IMAGING, V17, P475, DOI 10.1109/42.712137; Gabor D., 1946, J IND ELECT ENG LOND, V93, P445, DOI 10.1049/ji-3-2.1946.0076; Galloway MM, 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6; Georgiadis P, 2009, MAGN RESON IMAGING, V27, P120, DOI 10.1016/j.mri.2008.05.017; Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007; Gibbs P, 2003, MAGNET RESON MED, V50, P92, DOI 10.1002/mrm.10496; GOROVITZ S, 1976, FDN ETHICS ITS RELAT, P248; Hacke W, 2008, NEW ENGL J MED, V359, P1317, DOI 10.1056/NEJMoa0804656; HALL EL, 1971, IEEE T COMPUT, VC 20, P1032, DOI 10.1109/T-C.1971.223399; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Herlidou-Meme S, 2003, MAGN RESON IMAGING, V21, P989, DOI 10.1016/S0730-725X(03)00212-1; HSU SY, 1979, COMPUT VISION GRAPH, V9, P117, DOI 10.1016/0146-664X(79)90052-2; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391; KAIZER H, 1955, 121 BOST U RES LAB; Kassner A, 2009, AM J NEURORADIOL, V30, P1864, DOI 10.3174/ajnr.A1774; Kassner A, 2005, AM J NEURORADIOL, V26, P2213; Kassner A, 2009, J MAGN RESON IMAGING, V30, P933, DOI 10.1002/jmri.21940; LARSSON HBW, 1990, MAGNET RESON MED, V16, P117, DOI 10.1002/mrm.1910160111; LERSKI RA, 1993, MAGN RESON IMAGING, V11, P873, DOI 10.1016/0730-725X(93)90205-R; LERSKI R A, 1979, Ultrasound in Medicine and Biology, V5, P341, DOI 10.1016/0301-5629(79)90004-8; Li DKB, 1999, ANN NEUROL, V46, P197, DOI 10.1002/1531-8249(199908)46:2<197::AID-ANA9>3.0.CO;2-P; Mahmoud-Ghoneim Doaa, 2008, BMC Med Imaging, V8, P18, DOI 10.1186/1471-2342-8-18; Mahmoud-Ghoneim D, 2003, MAGN RESON IMAGING, V21, P983, DOI 10.1016/S0730-725X(03)00201-7; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mayerhoefer ME, 2005, J MAGN RESON IMAGING, V22, P674, DOI 10.1002/jmri.20429; Mikulis DJ, 2007, J MAGN RESON IMAGING, V26, P838, DOI 10.1002/jmri.21041; Provenzale JM, 2006, RADIOLOGY, V239, P632, DOI 10.1148/radiol.2393042031; Roberts HC, 2000, AM J NEURORADIOL, V21, P891; Rovaris M, 2006, LANCET NEUROL, V5, P343, DOI 10.1016/S1474-4422(06)70410-0; Sankar T, 2008, HUM BRAIN MAPP, V29, P931, DOI 10.1002/hbm.20437; SCHAD LR, 1993, MAGN RESON IMAGING, V11, P889, DOI 10.1016/0730-725X(93)90206-S; Schmierer K, 2004, ANN NEUROL, V56, P407, DOI 10.1002/ana.20202; Seppa M, 2005, NEUROIMAGE, V26, P1, DOI 10.1016/j.neuroimage.2005.01.030; Stockwell RG, 2007, DIGIT SIGNAL PROCESS, V17, P371, DOI 10.1016/j.dsp.2006.04.006; Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367; Theocharakis P, 2009, MAGN RESON IMAGING, V27, P417, DOI 10.1016/j.mri.2008.07.014; TOFTS PS, 1991, MAGNET RESON MED, V17, P357, DOI 10.1002/mrm.1910170208; Tourassi GD, 1999, RADIOLOGY, V213, P317; Tozer DJ, 2009, J MAGN RESON IMAGING, V30, P506, DOI 10.1002/jmri.21885; Tzacheva AA, 2003, J MAGN RESON IMAGING, V17, P337, DOI 10.1002/jmri.10259; vanBuchem MA, 1996, MAGNET RESON MED, V36, P632, DOI 10.1002/mrm.1910360420; Waubant E, 2006, DIS MARKERS, V22, P235; WEINSHENKER BG, 1989, BRAIN, V112, P133, DOI 10.1093/brain/112.1.133; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269; Wolinsky JS, 2002, MULT SCLER, V8, P85, DOI 10.1177/135245850200800118; Woods BJ, 2007, J MAGN RESON IMAGING, V25, P495, DOI 10.1002/jmri.20837; Yu O, 2001, MAGN RESON IMAGING, V19, P1305, DOI 10.1016/S0730-725X(01)00464-7; Yu O, 1999, MAGN RESON IMAGING, V17, P1261, DOI 10.1016/S0730-725X(99)00062-4; Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147; Zhang J, 2008, MAGN RESON IMAGING, V26, P1160, DOI 10.1016/j.mri.2008.01.016; Zhang YY, 2009, NEUROIMAGE, V47, P107, DOI 10.1016/j.neuroimage.2009.03.075; Zhu H, 2003, MED PHYS, V30, P1134, DOI 10.1118/1.1576931	69	48	49	4	15	AMER SOC NEURORADIOLOGY	OAK BROOK	2210 MIDWEST RD, OAK BROOK, IL 60521 USA	0195-6108			AM J NEURORADIOL	Am. J. Neuroradiol.	MAY	2010	31	5					809	816		10.3174/ajnr.A2061		8	Clinical Neurology; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	599MH	WOS:000277916600005	20395383	
J	Whiting, JS; Dinerstein, J; Egbert, PK; Ventura, D				Whiting, Jeffrey S.; Dinerstein, Jonathan; Egbert, Parris K.; Ventura, Dan			COGNITIVE AND BEHAVIORAL MODEL ENSEMBLES FOR AUTONOMOUS VIRTUAL CHARACTERS	COMPUTATIONAL INTELLIGENCE			English	Article						behavioral animation; cognitive modeling; ensembles; autonomous agents; AI-based animation	ANIMATION; AGENTS	Cognitive and behavioral models have become popular methods for creating autonomous self-animating characters. Creating these models present the following challenges: (1) creating a cognitive or behavioral model is a time-intensive and complex process that must be done by an expert programmer and (2) the models are created to solve a specific problem in a given environment and because of their specific nature cannot be easily reused. Combining existing models together would allow an animator, without the need for a programmer, to create new characters in less time and to leverage each model's strengths, resulting in an increase in the character's performance and in the creation of new behaviors and animations. This article provides a framework that can aggregate existing behavioral and cognitive models into an ensemble. An animator has only to rate how appropriately a character performs in a set of scenarios and the system then uses machine learning to determine how the character should act given the current situation. Empirical results from multiple case studies validate the approach.	[Whiting, Jeffrey S.; Dinerstein, Jonathan; Egbert, Parris K.; Ventura, Dan] Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA	Ventura, D (reprint author), Brigham Young Univ, Dept Comp Sci, Provo, UT 84602 USA.	ventura@cs.byu.edu					Andrews J. R., 1983, CONTROL MANUFACTURIN, P243; BLUMBERG B, 2002, P 29 ANN C COMP GRAP, P417, DOI 10.1145/566570.566597; BLUMBERG BM, 1995, P SIGGRAPH, V95, P47; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1023/A:1018054314350; Burke R, 2001, P GAM DEV C SAN JOS, P147; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1; Dinerstein J, 2004, COMPUT ANIMAT VIRT W, V15, P95, DOI 10.1002/cav.8; Dinerstein J, 2005, COMPUT INTELL, V21, P90, DOI 10.1111/j.0824-7935.2005.00266.x; Dinerstein J, 2005, ACM T GRAPHIC, V24, P262, DOI 10.1145/1061347.1061352; Dinerstein J, 2008, COMPUT INTELL, V24, P235; Faloutsos P, 2001, COMP GRAPH, P251; Freund Y., 1996, P 13 INT C MACH LEAR, P148; FUNGE J, 1999, P SIGGRAPH 99, P29, DOI 10.1145/311535.311538; Gervasi V, 2004, DISCRETE APPL MATH, V144, P324, DOI 10.1016/j.dam.2003.11.010; HART PE, 1968, IEEE T SYST SCI SSC, V4, P100, DOI DOI 10.1109/TSSC.1968.300136; JORDAN MI, 1993, P INT JOINT C NEUR N, V2; Reynolds C., 1987, ACM SIGGRAPH COMPUTE, V21, P25, DOI DOI 10.1145/37402.37406; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; TOMLINSON B, 2003, LECT NOTES COMPUTER, V2564, P35; Tu X, 1994, P SIGGRAPH 94, P43, DOI DOI 10.1145/192161.192170; Weiss G., 1999, MULTIAGENT SYSTEMS M; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; YOON SY, 2000, P 17 NAT C ART INT 1, P249	25	1	1	0	2	WILEY-BLACKWELL	MALDEN	COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA	0824-7935			COMPUT INTELL-US	Comput. Intell.	MAY	2010	26	2					142	159				18	Computer Science, Artificial Intelligence	Computer Science	588PA	WOS:000277083200002		
J	Korfiatis, PD; Karahaliou, AN; Kazantzi, AD; Kalogeropoulou, C; Costaridou, LI				Korfiatis, Panayiotis D.; Karahaliou, Anna N.; Kazantzi, Alexandra D.; Kalogeropoulou, Cristina; Costaridou, Lena I.			Texture-Based Identification and Characterization of Interstitial Pneumonia Patterns in Lung Multidetector CT	IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE			English	Article						Image segmentation; image texture analysis; respiratory system	HIGH-RESOLUTION CT; COMPUTER-AIDED DIAGNOSIS; GROUND-GLASS; CLASSIFICATION; SEGMENTATION; QUANTIFICATION; DISEASE; TOMOGRAPHY; FIBROSIS; MDCT	Identification and characterization of diffuse parenchyma lung disease (DPLD) patterns challenges computer-aided schemes in computed tomography (CT) lung analysis. In this study, an automated scheme for volumetric quantification of interstitial pneumonia (IP) patterns, a subset of DPLD, is presented, utilizing a multidetector CT (MDCT) dataset. Initially, lung-field segmentation is achieved by 3-D automated gray-level thresholding combined with an edge-highlighting wavelet preprocessing step, followed by a texture-based border refinement step. The vessel tree volume is identified and removed from lung field, resulting in lung parenchyma (LP) volume. Following, identification and characterization of IP patterns is formulated as a three-class pattern classification of LP into normal, ground glass, and reticular patterns, by means of k-nearest neighbor voxel classification, exploiting 3-D cooccurrence features. Performance of the proposed scheme in indentifying and characterizing ground glass and reticular patterns was evaluated by means of volume overlap (ground glass: 0.734 +/- 0.057, reticular: 0.815 +/- 0.037), true-positive fraction (ground glass: 0.638 +/- 0.055, reticular: 0.942 +/- 0.023) and false-positive fraction (ground glass: 0.361 +/- 0.027, reticular: 0.147 +/- 0.032) on five MDCT scans.	[Korfiatis, Panayiotis D.; Karahaliou, Anna N.; Costaridou, Lena I.] Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece; [Kazantzi, Alexandra D.; Kalogeropoulou, Cristina] Univ Hosp Patras, Dept Radiol, Patras 26500, Greece	Korfiatis, PD (reprint author), Univ Patras, Sch Med, Dept Med Phys, Patras 26500, Greece.	korfp@upatras.gr; karahaliou.a@med.upatras.gr; akazantzi@yahoo.gr; rat@upatras.gr; costarid@upatras.gr			University of Patras [C. 180]	This work was supported in part by the Caratheodory Programe (C. 180) of the University of Patras.	Chabat F, 2003, RADIOLOGY, V228, P871, DOI 10.1148/radiol.2283020505; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; EINSLEIN K, 1977, STAT METHODS DIGITAL, P76; Aziz ZA, 2004, THORAX, V59, P506, DOI 10.1136/thx.2003.020396; Haralick R. M., 1973, IEEE T SYST MAN CYB, V6, P610; Kauczor HU, 2000, AM J ROENTGENOL, V175, P1329; Korfiatis P, 2008, MED PHYS, V35, P5290, DOI 10.1118/1.3003066; Korfiatis P, 2007, BRIT J RADIOL, V80, P996, DOI 10.1259/bjr/20861881; KORFIATIS P, P 8 IEEE INT C BIOIN, P1; Marten K, 2009, EUR RADIOL, V19, P324, DOI 10.1007/s00330-008-1152-1; Sensakovic WF, 2006, MED PHYS, V33, P3085, DOI 10.1118/1.2214165; Sluimer I, 2005, IEEE T MED IMAGING, V24, P1025, DOI 10.1109/TMI.2005.851757; Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753; Sluimer IC, 2006, MED PHYS, V33, P2610, DOI 10.1118/1.2207131; Sluimer IC, 2003, MED PHYS, V30, P3081, DOI 10.1118/1.1624771; Uchiyama Y, 2003, MED PHYS, V30, P2440, DOI 10.1118/1.1597431; Xu Y, 2006, ACAD RADIOL, V13, P969, DOI 10.1016/j.acra.2006.04.017; Xu Y, 2006, IEEE T MED IMAGING, V25, P464; Zavaletta VA, 2007, ACAD RADIOL, V14, P772, DOI 10.1016/j.acra.2007.03.009; Zhou C, 2007, MED PHYS, V34, P4567, DOI 10.1118/1.2804558	20	17	17	0	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1089-7771			IEEE T INF TECHNOL B	IEEE T. Inf. Technol. Biomed.	MAY	2010	14	3					675	680		10.1109/TITB.2009.2036166		6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Medical Informatics	Computer Science; Mathematical & Computational Biology; Medical Informatics	607WP	WOS:000278538300016	19906596	
J	El-Yaniv, R; Wiener, Y				El-Yaniv, Ran; Wiener, Yair			On the Foundations of Noise-free Selective Classification	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						classification with a reject option; selective classification; perfect learning; high performance classification; risk-coverage trade-off	REJECT-OPTION; CLASSIFIERS; BOUNDS; RULE	We consider selective classification, a term we adopt here to refer to 'classification with a reject option.' The essence in selective classification is to trade-off classifier coverage for higher accuracy. We term this trade-off the risk-coverage (RC) trade-off. Our main objective is to characterize this trade-off and to construct algorithms that can optimally or near optimally achieve the best possible trade-offs in a controlled manner. For noise-free models we present in this paper a thorough analysis of selective classification including characterizations of RC trade-offs in various interesting settings.	[El-Yaniv, Ran; Wiener, Yair] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	El-Yaniv, R (reprint author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	RANI@CS.TECHNION.AC.IL; WYAIR@TX.TECHNION.AC.IL					Anthony M, 1999, NEURAL NETWORK LEARN; Antos A, 1998, MACH LEARN, V30, P31, DOI 10.1023/A:1007454427662; Atlas L., 1990, NEURAL INFORM PROCES, P566; BARTLETT PL, 2007, M980 FLOR STAT U DEP; Bentley J. L., 1978, J ACM, V25; Blumer A., 1989, J ACM, V36; Bounsiar A., 2006, INT J COMPUTATIONAL, V3, P312; Chow C.K., 1957, Institute of Radio Engineers Transactions on Electronic Computers, VEC-6; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Freund Y, 2004, ANN STAT, V32, P1698, DOI 10.1214/009053604000000058; Friedman E., 2009, P 22 ANN C LEARN THE; Fumera G., 2002, P 1 INT WORKSH PATT, P811; FUMERA G, 2000, P SSPR SPR, P863; Hanczar B, 2008, BIOINFORMATICS, V24, P1889, DOI 10.1093/bioinformatics/btn349; Hanneke S., 2009, THESIS CARNEGIE MELL; Hanneke S., 2007, ICML 07, P353; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; HELLMAN ME, 1970, IEEE T SYST SCI CYB, VSSC6, P179, DOI 10.1109/TSSC.1970.300339; Herbei R, 2006, CAN J STAT, V34, P709; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Landgrebe TCW, 2006, PATTERN RECOGN LETT, V27, P908, DOI 10.1016/j.patrec.2005.10.015; Langford J, 2005, J MACH LEARN RES, V6, P273; MELTZER PS, 2001, NATURE MED, V7; Mitchell T., 1977, IJCAI 77, P305; Pietraszek T, 2005, P 22 INT C MACH LEAR, P665, DOI 10.1145/1102351.1102435; PREPARATA FP, 1990, COMPUTATIONAL GOMETR; Santos-Pereira CM, 2005, PATTERN RECOGN LETT, V26, P943, DOI 10.1016/j.patrec.2004.09.042; Tortorella F, 2000, LECT NOTES COMPUT SC, V1876, P611; Tsybakov AB, 2004, ANN STAT, V32, P135; Vapnik V., 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Wegkamp M, 2007, ELECTRON J STAT, V1, P155, DOI 10.1214/07-EJS058; YOGANANDA AP, 2007, ICML 07, P713	35	9	9	1	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.	MAY	2010	11						1605	1641				37	Automation & Control Systems; Computer Science, Artificial Intelligence	Automation & Control Systems; Computer Science	658WB	WOS:000282522000002		
J	Olvera-Lopez, JA; Carrasco-Ochoa, JA; Martinez-Trinidad, JF				Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.			A new fast prototype selection method based on clustering	PATTERN ANALYSIS AND APPLICATIONS			English	Article						Prototype selection; Supervised classification; Instance-based classifiers; Border prototypes; Data reduction; Clustering	NEAREST-NEIGHBOR RULE; LEARNING ALGORITHMS; INSTANCE SELECTION; CLASSIFICATION	In supervised classification, a training set T is given to a classifier for classifying new prototypes. In practice, not all information in T is useful for classifiers, therefore, it is convenient to discard irrelevant prototypes from T. This process is known as prototype selection, which is an important task for classifiers since through this process the time for classification or training could be reduced. In this work, we propose a new fast prototype selection method for large datasets, based on clustering, which selects border prototypes and some interior prototypes. Experimental results showing the performance of our method and comparing accuracy and runtimes against other prototype selection methods are reported.	[Arturo Olvera-Lopez, J.; Ariel Carrasco-Ochoa, J.; Francisco Martinez-Trinidad, J.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Puebla 72000, Mexico	Olvera-Lopez, JA (reprint author), Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrrique Erro 1,Sta Maria Tonantzintla, Puebla 72000, Mexico.	aolvera@ccc.inaoep.mx; ariel@ccc.inaoep.mx; fmartine@ccc.inaoep.mx					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068; Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878; CHIDANANDAGOWDA K, 1979, IEEE T INFORM THEORY, V25, P488; Chien-Hsing C., 2006, P 18 INT C PATT REC, P556; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; CRISTANNI N, 2000, INTRO SUPPORT VECTOR; Devijver P. A., 1980, Proceedings of the 5th International Conference on Pattern Recognition; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Duda R.O., 2000, PATTERN CLASSIFICATI, VSecond; Frank E., 2005, DATA MINING PRACTICA; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Karacali B, 2003, IEEE T NEURAL NETWOR, V14, P127, DOI 10.1109/TNN.2002.804315; Kuncheva LI, 1998, IEEE T SYST MAN CY C, V28, P160, DOI 10.1109/5326.661099; Liu H, 2002, DATA MIN KNOWL DISC, V6, P115, DOI 10.1023/A:1014056429969; Lumini A, 2006, PATTERN RECOGN, V39, P495, DOI 10.1016/j.patcog.2005.11.004; *MATHWORKS INC, 1994, NAT; Mollineda RA, 2002, PATTERN RECOGN, V35, P2771, DOI 10.1016/S0031-3203(01)00208-4; Quinlan J. R., 1993, C4 5 PROGRAMS MACHIN; Raicharoen T, 2005, PATTERN RECOGN LETT, V26, P1554, DOI 10.1016/j.patrec.2005.01.003; Spillmann B, 2006, LECT NOTES COMPUT SC, V4109, P287; TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448; Vapnik V., 1998, STAT LEARNING THEORY; Vapnik V. N., 1995, NATURE STAT LEARNING; VENMANN CJ, 2002, IEEE T PATTERN ANAL, V24, P1273; VENMANN CJ, 2005, IEEE T PATTERN ANAL, V27, P1417; Vojtech F., 2004, STAT PATTERN RECOGNI; WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137; Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721	29	22	25	0	2	SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1433-7541			PATTERN ANAL APPL	Pattern Anal. Appl.	MAY	2010	13	2					131	141		10.1007/s10044-008-0142-x		11	Computer Science, Artificial Intelligence	Computer Science	587VR	WOS:000277023400001		
